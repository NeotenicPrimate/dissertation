{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run './model/multi_corpus.py'\n",
    "%run './model/ergm_functions.py'\n",
    "%run './constants.py'\n",
    "\n",
    "sns.set(rc = {'figure.figsize':(15,8)})\n",
    "\n",
    "import multiprocessing as mp\n",
    "import polars as pl\n",
    "from itertools import combinations\n",
    "# mp.set_start_method('forkserver')\n",
    "import math\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import scipy as sp\n",
    "\n",
    "from itertools import product\n",
    "from scipy.special import comb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import os\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import norm\n",
    "\n",
    "import pytensor.tensor as pt\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# RANDOM_SEED = 8927\n",
    "# rng = np.random.default_rng(RANDOM_SEED)\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = co_citation_graphs(n_edges=10)\n",
    "Gs = {field_name: corpus['G'] for (field_name, corpus) in corpora.items()}\n",
    "Dfs = {field_name: corpus['Df'] for (field_name, corpus) in corpora.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = []\n",
    "dist = {}\n",
    "\n",
    "for (field_name, d) in corpora.items():\n",
    "\n",
    "    print(field_name)\n",
    "\n",
    "    G = d['G']\n",
    "    df = d['Df']\n",
    "\n",
    "    observed = nx.to_numpy_array(G, weight=None)\n",
    "\n",
    "    βs_xs = {\n",
    "        'Density': delta_edges(G),\n",
    "        # 'Triangles': delta_triangles(G),\n",
    "        # 'Stars': delta_star(G, 3),\n",
    "        # 'Betweenness': delta_betweenness(G),\n",
    "        # 'Closeness': delta_closeness(G),\n",
    "        # 'Eigenvector': delta_eigenvector(G),\n",
    "        'Centralization': delta_centralization(G),\n",
    "        # 'Clustering': delta_clustering(G),\n",
    "        # 'Transitivity': delta_transitivity(G),\n",
    "        # 'Cliques': delta_cliques(G),\n",
    "        # 'Components': delta_components(G),\n",
    "        # 'Gini': delta_gini(G),\n",
    "        'Louvain': delta_louvain(G),\n",
    "        # 'Date': date(G, df, 5)\n",
    "        # 'Geodesic': delta_geodesic(G),\n",
    "    }\n",
    "\n",
    "    dist[field_name] = βs_xs\n",
    "\n",
    "    with pm.Model() as model:\n",
    "\n",
    "        βs = []\n",
    "        xs = []\n",
    "        for β_name, x in βs_xs.items():\n",
    "            β = pm.Normal(β_name, sigma=1, initval=None)\n",
    "            βs.append(β)\n",
    "            xs.append(x)\n",
    "\n",
    "        μ = sum(β * x for β, x in zip(βs, xs))\n",
    "\n",
    "        # likelihood = pm.math.sigmoid(μ)\n",
    "        likelihood = pm.math.exp(μ)\n",
    "\n",
    "        pm.Bernoulli(name='logit', p=likelihood, observed=observed)\n",
    "\n",
    "        trace = pm.sample(\n",
    "            tune=1000,\n",
    "            draws=2000,\n",
    "            chains=4,\n",
    "            # init = 'adapt_diag',\n",
    "            cores=4,\n",
    "            # step=pm.Metropolis(),\n",
    "            step=pm.NUTS(),\n",
    "            # random_seed=12345,\n",
    "        )\n",
    "\n",
    "        trace.to_netcdf(os.path.join(os.path.join(OUTPUT_PATH, f'co_citation_traces'), f'{field_name}.nc'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_value_stars(p_value):\n",
    "    match p_value:\n",
    "        case _ if p_value <= 0.001:\n",
    "            stars = '***'\n",
    "        case _ if p_value <= 0.01:\n",
    "            stars =  '**'\n",
    "        case _ if p_value <= 0.05:\n",
    "            stars =  '*'  \n",
    "        case _:\n",
    "            stars = ' '\n",
    "    return stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_path = os.path.join(OUTPUT_PATH, f'co_citation_traces')\n",
    "\n",
    "co_citation_coef = []\n",
    "co_citation_se = []\n",
    "\n",
    "for file in os.listdir(traces_path):\n",
    "\n",
    "    field_name = file.split('.')[0]\n",
    "    trace = az.from_netcdf(os.path.join(traces_path, file))\n",
    "\n",
    "    summary = az.summary(trace, kind=\"stats\")\n",
    "    summary.index.name = 'beta'\n",
    "    df = pl.from_pandas(summary, include_index=True)\n",
    "    df = df.with_columns(pl.col('beta').str.replace('_', ' '))\n",
    "\n",
    "    df = (\n",
    "        df\n",
    "        .with_columns((pl.col('mean') / pl.col('sd')).round(4).alias('z_score'))\n",
    "        .with_columns((pl.col('z_score').abs().apply(norm.sf).round(4).alias('p_value')))\n",
    "        .with_columns(pl.col('p_value').apply(p_value_stars).alias('significance'))\n",
    "    )\n",
    "\n",
    "    df_coef = (\n",
    "        df.select(\n",
    "            pl.col('beta'),\n",
    "            pl.concat_str(\n",
    "                [\n",
    "                    pl.col('mean'),\n",
    "                    pl.col('significance')\n",
    "                ],\n",
    "                # sep=''\n",
    "            ).alias(field_name),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df_se = (\n",
    "        df.select(\n",
    "            pl.col('beta'),\n",
    "            pl.concat_str(\n",
    "                [\n",
    "                    pl.lit('('),\n",
    "                    pl.col('sd'),\n",
    "                    pl.lit(')'),\n",
    "                ]\n",
    "            ).alias(field_name),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    co_citation_coef.append(df_coef)\n",
    "    co_citation_se.append(df_se)\n",
    "\n",
    "iter_dfs = iter(co_citation_coef)\n",
    "co_citation_df_coef = next(iter_dfs)\n",
    "for df in iter_dfs:\n",
    "    co_citation_df_coef = co_citation_df_coef.join(df, on='beta', how='inner')\n",
    "\n",
    "iter_dfs = iter(co_citation_se)\n",
    "co_citation_df_se = next(iter_dfs)\n",
    "for df in iter_dfs:\n",
    "    co_citation_df_se = co_citation_df_se.join(df, on='beta', how='inner')\n",
    "\n",
    "columns = sorted(co_citation_df_coef.select(pl.all().exclude('beta')).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = co_citation_df_coef.select(pl.concat_str(pl.all(), sep=' & ').alias('all_fields'))\n",
    "se_df = co_citation_df_se.select(pl.concat_str(pl.all().exclude('beta').alias('all_fields'), sep=' & '))\n",
    "\n",
    "coef_df = coef_df['all_fields'].to_list()\n",
    "se_df = se_df['all_fields'].to_list()\n",
    "\n",
    "row_str = ''\n",
    "for i in range(len(se_df)):\n",
    "    row_str += f'{coef_df[i]} \\\\\\ \\n & {se_df[i]} \\\\\\ \\n \\\\addlinespace[0.5em] \\n'\n",
    "\n",
    "alignments = ''.join(['c']*len(columns)*2)\n",
    "\n",
    "new_columns = []\n",
    "for col in columns:\n",
    "    if ' & ' in col:\n",
    "        first, second = col.split(' & ')\n",
    "        s = f'\\\\begin{{tabular}}{{cc}} {first} \\& \\\\\\ {second} \\\\end{{tabular}}'\n",
    "        new_columns.append(s)\n",
    "    elif ' ' in col:\n",
    "        first, second = col.split(' ')\n",
    "        s = f'\\\\begin{{tabular}}{{cc}} {first} \\\\\\ {second} \\\\end{{tabular}}'\n",
    "        new_columns.append(s)\n",
    "    else:\n",
    "        s = f'\\\\begin{{tabular}}{{cc}} {col} \\\\end{{tabular}}'\n",
    "        new_columns.append(s)\n",
    "new_columns = ' \\n& '.join(new_columns)\n",
    "\n",
    "\n",
    "table_str = f\"\"\"\n",
    "\\\\begin{{tabular}}{{l*{{{len(columns)*2}}}{{c}}}}\n",
    "\\\\toprule\n",
    "\\\\addlinespace[0.7em]\n",
    "& {new_columns} \\\\\\ \n",
    "\\\\midrule\n",
    "\\\\midrule\n",
    "\\\\addlinespace[0.5em]\n",
    "{row_str}\n",
    "\\\\bottomrule\n",
    "\\end{{tabular}}\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(LATEX_TABLE_PATH, 'co_citation_ergm_model.tex'), \"w+\") as file:\n",
    "    file.write(table_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for field_name, features in dist.items():\n",
    "    df = pl.DataFrame()\n",
    "    for feature_name, mat in features.items():\n",
    "        df = df.with_columns(\n",
    "            pl.Series(\n",
    "                feature_name,\n",
    "                mat.reshape(np.multiply(*mat.shape))\n",
    "            )\n",
    "        )\n",
    "    df = df.with_columns(\n",
    "        pl.Series(\n",
    "            'Field',\n",
    "            np.full((len(df)), field_name)\n",
    "        )\n",
    "    )\n",
    "    dfs.append(df)\n",
    "df = pl.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.select(pl.all().exclude('Field')).columns\n",
    "n_cols = len(cols)\n",
    "\n",
    "fig, axs = plt.subplots(n_cols, figsize=(16, 10*n_cols))\n",
    "for col, ax in zip(cols, axs):\n",
    "    sns.stripplot(data=df.to_pandas(), x=col, y=\"Field\", ax=ax)\n",
    "    ax.spines['top'].set_color('k')\n",
    "    ax.spines['top'].set_linewidth(1)\n",
    "    ax.spines['bottom'].set_color('k')\n",
    "    ax.spines['bottom'].set_linewidth(1)\n",
    "    ax.spines['right'].set_color('k')\n",
    "    ax.spines['right'].set_linewidth(1)\n",
    "    ax.spines['left'].set_color('k')\n",
    "    ax.spines['left'].set_linewidth(1)\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pandas().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(rc={'figure.figsize':(16, 12)})\n",
    "sns.set_style('darkgrid', {'axes.linewidth': 1, 'axes.edgecolor': 'black', 'axes.spines.left': True, 'axes.spines.bottom': True, 'axes.spines.right': True, 'axes.spines.top': True})\n",
    "\n",
    "pp = sns.pairplot(df.to_pandas(), vars=None, hue='Field', corner=True, grid_kws={'layout_pad': 0.5}) # , corner=True , grid_kws={\"despine\": False}\n",
    "\n",
    "pp.map_lower(plt.scatter, alpha = 0.6, linewidth=1, edgecolor='k')\n",
    "\n",
    "# pp.map_lower(sns.scatterplot)\n",
    "# g.map_lower(sns.kdeplot, hue=None, levels=5, color=\".2\")\n",
    "# pp.map_diag(plt.kdeplot, alpha=1)\n",
    "# pp.map_upper(sns.kdeplot, shade=True)\n",
    "\n",
    "# for ax in pp.axes.flat:\n",
    "#     if ax:\n",
    "#         ax.spines['top'].set_color('k')\n",
    "#         ax.spines['top'].set_linewidth(1)\n",
    "#         ax.spines['bottom'].set_color('k')\n",
    "#         ax.spines['bottom'].set_linewidth(1)\n",
    "#         ax.spines['right'].set_color('k')\n",
    "#         ax.spines['right'].set_linewidth(1)\n",
    "#         ax.spines['left'].set_color('k')\n",
    "#         ax.spines['left'].set_linewidth(1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_style('darkgrid', {'axes.linewidth': 1, 'axes.edgecolor':'black'})\n",
    "\n",
    "# fig, ax = plt.subplots(1)\n",
    "jp = sns.jointplot(data=df, x=\"Eigenvector_centrality\", y=\"Transitivity\", hue=\"Field\", height=15, space=0)\n",
    "jp.plot_marginals(sns.kdeplot)\n",
    "\n",
    "jp.ax_marg_x.set_facecolor('w')\n",
    "jp.ax_marg_y.set_facecolor('w')\n",
    "\n",
    "# for col, ax in zip(cols, axs):\n",
    "#     sns.stripplot(data=df.to_pandas(), x=col, y=\"Field\", ax=ax)\n",
    "jp.ax.spines['top'].set_color('k')\n",
    "jp.spines['top'].set_linewidth(1)\n",
    "jp.spines['bottom'].set_color('k')\n",
    "jp.spines['bottom'].set_linewidth(1)\n",
    "jp.spines['right'].set_color('k')\n",
    "jp.spines['right'].set_linewidth(1)\n",
    "jp.spines['left'].set_color('k')\n",
    "jp.spines['left'].set_linewidth(1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_path = os.path.join(OUTPUT_PATH, f'co_citation_traces')\n",
    "\n",
    "co_citation_coef = []\n",
    "\n",
    "for file in os.listdir(traces_path):\n",
    "\n",
    "    field_name = file.split('.')[0]\n",
    "    trace = az.from_netcdf(os.path.join(traces_path, file))\n",
    "\n",
    "    summary = az.summary(trace, kind=\"stats\")\n",
    "    summary.index.name = 'beta'\n",
    "    df = pl.from_pandas(summary, include_index=True)\n",
    "    df = df.with_columns(pl.col('beta').str.replace('_', ' '))\n",
    "\n",
    "    df = (\n",
    "        df\n",
    "        .with_columns((pl.col('mean') / pl.col('sd')).round(4).alias('z_score'))\n",
    "        .with_columns((pl.col('z_score').abs().apply(norm.sf).round(4).alias('p_value')))\n",
    "    )\n",
    "\n",
    "    df_coef = (\n",
    "        df.select(\n",
    "            pl.col('beta'),\n",
    "            pl.when(pl.col('p_value') > 0.05).then(0).otherwise(pl.col('mean')).alias(field_name)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    co_citation_coef.append(df_coef)\n",
    "\n",
    "iter_dfs = iter(co_citation_coef)\n",
    "co_citation_df_coef = next(iter_dfs)\n",
    "for df in iter_dfs:\n",
    "    co_citation_df_coef = co_citation_df_coef.join(df, on='beta', how='inner')\n",
    "\n",
    "columns = co_citation_df_coef['beta'].to_list()\n",
    "vec_df = co_citation_df_coef.select(pl.all().exclude('beta')).transpose(include_header=True, header_name='Field', column_names=columns)\n",
    "field_names = vec_df['Field'].to_list()\n",
    "vecs = vec_df.select(pl.all().exclude('Field')).to_numpy()\n",
    "\n",
    "scaled_data = StandardScaler().fit_transform(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(random_state=42)\n",
    "embs = reducer.fit_transform(scaled_data)\n",
    "\n",
    "sns.set()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "\n",
    "plt.scatter(embs[:, 0], embs[:, 1], alpha=1, edgecolor='k')\n",
    "\n",
    "# ax.set_title(f'{field_name.capitalize()}', fontweight='semibold', fontsize=20)\n",
    "\n",
    "for field_name, (x, y) in zip(field_names, embs):\n",
    "    plt.text(x, y+0.05, field_name)\n",
    "\n",
    "\n",
    "ax.spines['top'].set_color('k')\n",
    "ax.spines['top'].set_linewidth(1)\n",
    "ax.spines['bottom'].set_color('k')\n",
    "ax.spines['bottom'].set_linewidth(1)\n",
    "ax.spines['right'].set_color('k')\n",
    "ax.spines['right'].set_linewidth(1)\n",
    "ax.spines['left'].set_color('k')\n",
    "ax.spines['left'].set_linewidth(1)\n",
    "\n",
    "# fig.tight_layout()\n",
    "# plt.savefig(f'{OBSIDIAN_IMG_PATH}/co_citation_umap_node2vec.png')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
