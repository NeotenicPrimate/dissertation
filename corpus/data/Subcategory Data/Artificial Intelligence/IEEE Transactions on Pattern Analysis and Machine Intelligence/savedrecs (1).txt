PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	BREU, H; GIL, J; KIRKPATRICK, D; WERMAN, M				BREU, H; GIL, J; KIRKPATRICK, D; WERMAN, M			LINEAR-TIME EUCLIDEAN DISTANCE TRANSFORM ALGORITHMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						DISTANCE TRANSFORM; VORONOI DIAGRAM; ALGORITHM; EUCLIDEAN DISTANCE	IMAGES	Two linear time (and hence asymptotically optimal) algorithms for computing the Euclidean distance transform of a two-dimensional binary image are presented. The algorithms are based on the construction and regular sampling of the Voronoi diagram whose sites consist of the unit (feature) pixels in the image. The first algorithm, which is of primarily theoretical interest, constructs the complete Voronoi diagram, The second, more practical, algorithm constructs the Voronoi diagram where it intersects the horizontal lines passing through the image pixel centers. Extensions to higher dimensional images and to other distance functions are also discussed.	TECHNION ISRAEL INST TECHNOL,FAC COMP SCI,IL-32000 HAIFA,ISRAEL; HEBREW UNIV JERUSALEM,INST COMP SCI,IL-91904 JERUSALEM,ISRAEL	Technion Israel Institute of Technology; Hebrew University of Jerusalem	BREU, H (corresponding author), UNIV BRITISH COLUMBIA,DEPT COMP SCI,VANCOUVER,BC V6T 1Z5,CANADA.							ARCE, 1980, IM, P1122; ARCELLI C, 1986, PATTERN RECOGN, P383; BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; BORGEFORS G, 1984, COMPUT VISION GRAPH, V27, P321, DOI 10.1016/0734-189X(84)90035-5; BORGEFORS G, 1986, P INT JOINT C PATT R, P336; CLARKSON K, 1987, 19TH P ANN ACM S THE, P56; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; DAS PP, 1987, INFORM SCIENCES, V42, P113, DOI 10.1016/0020-0255(87)90019-3; Dirichlet G. L., 1850, J REINE ANGEW MATH, V40, P209, DOI DOI 10.1515/CRLL.1850.40.209; FAIRFIELD J, 1983, IEEE T PATTERN ANAL, V32, P104; KLEIN F, 1987, PATTERN RECOGN LETT, V5, P19, DOI 10.1016/0167-8655(87)90022-5; KOLOUNTZAKIS MN, 1992, INFORM PROCESS LETT, V43, P181, DOI 10.1016/0020-0190(92)90197-4; Paglieroni D. W., 1992, Machine Vision and Applications, V5, P47, DOI 10.1007/BF01213529; PAGLIERONI DW, 1992, CVGIP-GRAPH MODEL IM, V54, P56, DOI 10.1016/1049-9652(92)90034-U; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; RAGNEMALM I, 1992, CVGIP-IMAG UNDERSTAN, V56, P399, DOI 10.1016/1049-9660(92)90050-D; ROSENFEL.A, 1966, J ACM, V13, P471; ROSENFELD A, 1978, DIGITAL PICTURE PROC; Voronoi G, 1908, J REINE ANGEW MATH, V134, P198, DOI 10.1515/crll.1908.134.198; Yamada H., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P69; YAMASHITA M, 1986, PATTERN RECOGN, V19, P237, DOI 10.1016/0031-3203(86)90014-2	21	316	336	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1995	17	5					529	533		10.1109/34.391389	http://dx.doi.org/10.1109/34.391389			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QW394					2022-12-18	WOS:A1995QW39400009
J	Kulkarni, G; Premraj, V; Ordonez, V; Dhar, S; Li, SM; Choi, Y; Berg, AC; Berg, TL				Kulkarni, Girish; Premraj, Visruth; Ordonez, Vicente; Dhar, Sagnik; Li, Siming; Choi, Yejin; Berg, Alexander C.; Berg, Tamara L.			BabyTalk: Understanding and Generating Simple Image Descriptions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; image description generation	OBJECT; TREES	We present a system to automatically generate natural language descriptions from images. This system consists of two parts. The first part, content planning, smooths the output of computer vision-based detection and recognition algorithms with statistics mined from large pools of visually descriptive text to determine the best content words to use to describe an image. The second step, surface realization, chooses words to construct natural language sentences based on the predicted content and general statistics from natural language. We present multiple approaches for the surface realization step and evaluate each using automatic measures of similarity to human generated reference descriptions. We also collect forced choice human evaluations between descriptions from the proposed generation system and descriptions from competing approaches. The proposed system is very effective at producing relevant sentences for images. It also generates descriptions that are notably more true to the specific image content than previous work.	[Kulkarni, Girish; Premraj, Visruth; Ordonez, Vicente; Dhar, Sagnik; Li, Siming; Choi, Yejin; Berg, Alexander C.; Berg, Tamara L.] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA	State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	Kulkarni, G (corresponding author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.	girish86@gmail.com; visroo@gmail.com; vicente.ordonez@gmail.com; sagnik.dhar@gmail.com; seemingly@gmail.com; ychoi@cs.stonybrook.edu; aberg@cs.stonybrook.edu; tlberg@cs.stonybrook.edu			US National Science Foundation Faculty Early Career Development (CAREER) Award [1054133]; Div Of Information & Intelligent Systems [1054133] Funding Source: National Science Foundation	US National Science Foundation Faculty Early Career Development (CAREER) Award(National Science Foundation (NSF)); Div Of Information & Intelligent Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This work was supported in part by US National Science Foundation Faculty Early Career Development (CAREER) Award #1054133 for T. L. Berg and by the Stony Brook University Vice President of Research for Y. Choi and A. C. Berg.	Aker A, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1250; [Anonymous], 2011, P C EMP METH NAT LAN; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Barnard K., 2001, P IEEE C COMP VIS PA; BERG T, 2004, P IEEE C COMP VIS PA; Berg T. L., 2010, P EUR C COMP VIS; Berg Tamara L., 2004, WHOS PICTURE; BERG TL, 2006, P IEEE C COMP VIS PA; de Marnee M.-C., 2009, STANDORD TYPED DEPEN; Deng J., 2009, 2009 IEEE C COMP VIS, P248, DOI [DOI 10.1109/CVPR.2009.5206848, 10.1109/CVPR.2009.5206848]; Desai C., 2009, P 12 IEEE INT C COMP; Duygulu P., 2002, P EUR C COMP VIS; Everingham M, 2006, P BRIT MACHINE VISIO, V4, P6; Farhadi A., 2010, P EUR C COMP VIS; Farhadi A., 2009, P IEEE C COMP VIS PA; Fei-Fei L., 2004, J VISION, V4; Felzenszwalb P.F., 2012, DISCRIMINATIVELY TRA; Feng YS, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1239; Ferrari V., 2007, P NEUR INF PROC SYST; Gupta A., 2008, P EUR C COMP VIS; Gupta A., 2009, P IEEE C COMP VIS PA; Gupta S., 2009, P IEEE COMP VIS PATT; Gupta S, 2010, AAAI CONF ARTIF INTE, P1083; Kojima A, 2002, INT J COMPUT VISION, V50, P171, DOI 10.1023/A:1020346032608; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; Kulkarni Girish, 2011, P IEEE C COMP VIS PA; Kumar N., 2009, P 12 IEEE INT C COMP; Kuznetsova P., 2012, P C ASS COMP LING; Lampert C. H., 2009, P IEEE C COMP VIS PA; Li LJ, 2010, INT J COMPUT VISION, V88, P147, DOI 10.1007/s11263-009-0265-6; Li S., 2011, P 15 C COMPUTATIONAL, P220; LIN CY, 2003, P C N AM CHAPT ASS C; Ordonez V., 2011, P ADV NEUR INF PROC, V24, P1; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Rashtchian Cyrus, 2010, P NAACL HLT WORKSH C; Saenko K., 2008, P NEUR INF PROC SYST; Schroff F., 2007, P 11 IEEE INT C COMP; Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1; Sivic J., 2009, P IEEE C COMP VIS PA; Torralba A, 2010, COMMUN ACM, V53, P107, DOI 10.1145/1666420.1666446; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P3697, DOI 10.1109/TIT.2005.856938; Wang J., 2009, P BRIT MACH VIS C; Yanai K., 2006, P 15 INT C WORLD WID, P923; Yanai K., 2005, P 13 ANN ACM INT C M; Yao BZ, 2010, P IEEE, V98, P1485, DOI 10.1109/JPROC.2010.2050411; Zacks JM, 2001, J EXP PSYCHOL GEN, V130, P29, DOI 10.1037//0096-3445.130.1.29; Zhou Liang., 2004, P ACL WORKSH TEXT SU	48	315	359	0	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2013	35	12					2891	2903		10.1109/TPAMI.2012.162	http://dx.doi.org/10.1109/TPAMI.2012.162			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	245YV	22848128	Green Submitted			2022-12-18	WOS:000326502200007
J	Yang, QX; Wang, L; Yang, RG; Stewenius, H; Nister, D				Yang, Qingxiong; Wang, Liang; Yang, Ruigang; Stewenius, Henrik; Nister, David			Stereo Matching with Color-Weighted Correlation, Hierarchical Belief Propagation, and Occlusion Handling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D/stereo scene analysis; segmentation; Markov random fields	VARIABLE WINDOW	In this paper, we formulate a stereo matching algorithm with careful handling of disparity, discontinuity, and occlusion. The algorithm works with a global matching stereo model based on an energy-minimization framework. The global energy contains two terms, the data term and the smoothness term. The data term is first approximated by a color-weighted correlation, then refined in occluded and low-texture areas in a repeated application of a hierarchical loopy belief propagation algorithm. The experimental results are evaluated on the Middlebury data sets, showing that our algorithm is the top performer among all the algorithms listed there.	[Yang, Qingxiong] Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA; [Wang, Liang; Yang, Ruigang] Univ Kentucky, Dept Comp Sci, Lexington, KY 40507 USA; [Stewenius, Henrik] Google Switzerland, CH-8002 Zurich, Switzerland; [Nister, David] Microsoft Corp, Redmond, WA 98052 USA	University of Illinois System; University of Illinois Urbana-Champaign; University of Kentucky; Google Incorporated; Microsoft	Yang, QX (corresponding author), Univ Illinois, Dept Elect & Comp Engn, 1520 Beckman Inst,405 N Mathews, Urbana, IL 61801 USA.	quang6@uiuc.edu; lwangd@cs.uky.edu; ryang@cs.uky.edu; hstewenius@gmail.com; dnister@microsoft.com	Yang, Qingxiong/K-1729-2015	Yang, Qingxiong/0000-0002-4378-2335; Yang, Ruigang/0000-0001-5296-6307				Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269; Bleyer M, 2004, IEEE IMAGE PROC, P2997; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 1998, IEEE T PATTERN ANAL, V20, P1283, DOI 10.1109/34.735802; Chen L., 2005, P INT C INF FUS; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Egnal G, 2002, IEEE T PATTERN ANAL, V24, P1127, DOI 10.1109/TPAMI.2002.1023808; Elidan G., 2006, P 22 C UNC ART INT; Felzenszwalb PR, 2004, PROC CVPR IEEE, P261; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Hirschmuller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56; HIRSCHMULLER H., 2006, P IEEE C COMP VIS PA, V2, P2386, DOI DOI 10.1109/CVPR.2006.294; Ihler AT, 2005, J MACH LEARN RES, V6, P905; KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690; Klaus A, 2006, INT C PATT RECOG, P15; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Scharstein D., 2008, MIDDLEBURY STEREO VI; Sun J, 2005, PROC CVPR IEEE, P399; Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509; Tao H, 2000, FIFTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P246, DOI 10.1109/WACV.2000.895429; Tappen M., 2003, P IEEE INT C COMP VI, V1, P508; Veksler O, 2003, PROC CVPR IEEE, P556; Veksler O, 2002, IEEE T PATTERN ANAL, V24, P1654, DOI 10.1109/TPAMI.2002.1114859; Weiss Y, 2001, IEEE T INFORM THEORY, V47, P736, DOI 10.1109/18.910585; Yang Q., 2006, P IEEE C COMP VIS PA, P2347; Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70	27	315	393	1	65	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2009	31	3					492	504		10.1109/TPAMI.2008.99	http://dx.doi.org/10.1109/TPAMI.2008.99			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	394VO	19147877				2022-12-18	WOS:000262480200008
J	Li, SZ; Zhang, ZQ				Li, SZ; Zhang, ZQ			FloatBoost learning and statistical face detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern classification; boosting learning; AdaBoost; FloatBoost; feature selection; statistical models; face detection	ADDITIVE LOGISTIC-REGRESSION; FLOATING SEARCH METHODS; VIEW; RECOGNITION; FEATURES	A novel learning procedure, called FloatBoost, is proposed for learning a boosted classifier for achieving the minimum error rate. FloatBoost learning uses a backtrack mechanism after each iteration of AdaBoost learning to minimize the error rate directly, rather than minimizing an exponential function of the margin as in the traditional AdaBoost algorithms. A second contribution of the paper is a novel statistical model for learning best weak classifiers using a stagewise approximation of the posterior probability. These novel techniques lead to a classifier which requires fewer weak classifiers than AdaBoost yet achieves lower error rates in both training and testing, as demonstrated by extensive experiments. Applied to face detection, the FloatBoost learning method, together with a proposed detector pyramid architecture, leads to the first real-time multiview face detection system reported.	Microsoft Res Asia, Beijing Sigma Ctr 3F, Beijing 100080, Peoples R China; Univ Illinois, Beckman Inst 2323, Urbana, IL 61801 USA	Microsoft; Microsoft Research Asia; University of Illinois System; University of Illinois Urbana-Champaign	Li, SZ (corresponding author), Microsoft Res Asia, Beijing Sigma Ctr 3F, 49 Zhichun Rd, Beijing 100080, Peoples R China.	szli@microsoft.com; zzhang6@uiuc.edu						Amit Y, 1997, IEEE T PATTERN ANAL, V19, P1300, DOI 10.1109/34.632990; [Anonymous], 1994, INTRO COMPUTATIONAL; BICHSEL M, 1994, CVGIP-IMAG UNDERSTAN, V59, P254, DOI 10.1006/ciun.1994.1017; Breiman L, 1998, ANN STAT, V26, P801; Buhlmann P, 2000, ANN STAT, V28, P377; Crow F. C., 1984, Computers & Graphics, V18, P207; FERAUD J, 2000, P 4 IEEE INT C AUT F; FLEURET F, 2001, INT J COMPUT VISION, V20, P1157; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; GONG S, 1996, P IEEE INT C FAC GES; HJELMAS BKL, 2001, COMPUTER VISION IMAG, V3, P236; HUANG J, 1998, P INT C PATT REC; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Kittler J., 1980, PATTERN RECOGN, P41; KUCHINSKY A, 1999, P ACM SIG CHI 99 C M; Li SZ, 2002, LECT NOTES COMPUT SC, V2353, P67; LI SZ, 2004, IN PRESS HDB FACE RE; LI SZ, 2002, P NEUR INF PROC SYST; LI Y, 2000, IEEE INT C AUT FAC G, P300; Lienhart R, 2002, IEEE IMAGE PROC, P900; Liu CJ, 2003, IEEE T PATTERN ANAL, V25, P725, DOI 10.1109/TPAMI.2003.1201822; Mason L, 2000, ADV NEUR IN, P221; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; Ng J., 1999, Proceedings International Workshop on Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems. In Conjunction with ICCV'99 (Cat. No.PR00378), P14, DOI 10.1109/RATFG.1999.799218; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772; PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Schapire RE, 1998, ANN STAT, V26, P1651; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Schneiderman H, 2004, INT J COMPUT VISION, V56, P151, DOI 10.1023/B:VISI.0000011202.85607.00; SCHNEIDERMAN H, 2000, P IEEE CS C COMP VIS; SCHNEIDERMAN H, 2000, THESIS RI; Simard Patrice Y, 1998, NEURAL NETWORKS TRIC; SIMARD PY, 1998, ADV NEURAL INFORMATI, V11, P571; Somol P, 1999, PATTERN RECOGN LETT, V20, P1157, DOI 10.1016/S0167-8655(99)00083-5; Stearns S. D., 1976, 3rd International Joint Conference on Pattern Recognition, P71; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Tieu K, 2000, PROC CVPR IEEE, P228, DOI 10.1109/CVPR.2000.855824; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Viola P., 2001, IEEE COMP SOC C COMP; VIOLA P, 2001, IEEE ICCV WORKSH STA; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; YANG MH, 2000, P NEUR INF PROC SYST, P855; ZEMEL RS, 2001, ADV NEURAL INFORMATI, V13	48	315	334	0	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2004	26	9					1112	1123		10.1109/TPAMI.2004.68	http://dx.doi.org/10.1109/TPAMI.2004.68			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	837CM	15742888				2022-12-18	WOS:000222605100002
J	Wilson, AD; Bobick, AF				Wilson, AD; Bobick, AF			Parametric hidden Markov models for gesture recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						gesture recognition; hidden Markov models; expectation-maximization algorithm; time-series modeling; computer vision		A new method for the representation, recognition, and interpretation of parameterized gesture is presented. By parameterized gesture we mean gestures that exhibit a systematic spatial variation; one example is a point gesture where the relevant parameter is the two-dimensional direction. Our approach is to extend the standard hidden Markov model method of gesture recognition by including a global parametric variation in the output probabilities of the HMM states, Using a linear model of dependence, we formulate an expectation-maximization (EM) method for training the parametric HMM. During testing; a similar EM algorithm simultaneously maximizes the output likelihood of the PHMM for the given sequence and estimates the quantifying parameters. Using visually derived and directly measured three-dimensional hand position measurements as input, we present results that demonstrate the recognition superiority of the PHMM over standard HMM techniques, as well as greater robustness in parameter estimation with respect to noise in the input features. Last, we extend the PHMM to handle arbitrary smooth (nonlinear) dependencies. The nonlinear formulation requires the use of a generalized expectation-maximization (GEM) algorithm for both training and the simultaneous recognition of the gesture and estimation of the value of the parameter. We present results on a pointing gesture, where the nonlinear approach permits the natural spherical coordinate parameterization of pointing direction.	MIT, Media Lab, Vis & Modeling Grp, Cambridge, MA 02139 USA; Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA	Massachusetts Institute of Technology (MIT); University System of Georgia; Georgia Institute of Technology	Wilson, AD (corresponding author), MIT, Media Lab, Vis & Modeling Grp, 20 Ames St, Cambridge, MA 02139 USA.	drew@media.mit.edu						AZARBAYEJANI A, 1996, P 13 INT C PATT REC; Bengio Y., 1995, Advances in Neural Information Processing Systems 7, P427; Bishop, 1995, NEURAL NETWORKS PATT; BISHOP CM, 1996, ADV NEURAL INFORMATI, V8, P402; BOBICK A, 1996, P INT C PATT REC, V1, P307; Bobick AF, 1997, IEEE T PATTERN ANAL, V19, P1325, DOI 10.1109/34.643892; BREGLER C, 1994, ADV NEURAL INFORMATI, V6, P43; BRIEMAN L, 1973, STATISTICS; Campbell LW, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P157, DOI 10.1109/AFGR.1996.557258; CAMPBELL LW, 1995, P INT C COMP VIS; CASSELL J, 1991, POETICS TODAY, V12, P375, DOI 10.2307/1772644; Darrell T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P335, DOI 10.1109/CVPR.1993.341109; Darrell T., 1994, Proceedings of the Workshop on Visual Behaviors, P68, DOI 10.1109/VL.1994.365599; GALES MJF, 1997, 291 CUEDFINFENG; Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79; Jensen F.V., 1996, INTRO BAYESIAN NETWO; Kahn R. E., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P569, DOI 10.1109/ISCV.1995.477062; McNeill D., 1992, HAND MIND WHAT GESTU; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Omohundro SM, 1996, ADV NEUR IN, V8, P402; POIZNER H, 1983, P ACM SIGGRAPH SIGAR, P148; SCHLENZIG J, 1994, P 28 AS C SIGN SYST; Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI [10.1109/MASSP.1986.1165342, 10.1002/0471250953.bia03as18]; STARNER T, 1995, P INT WORKSH AUT FAC; TENENBAUM JB, 1997, ADV NEURAL INFORMATI, V9; TEUKOLSKY SA, 1991, NUMERICAL RECIPES C; Wilson AD, 1997, PROC CVPR IEEE, P948, DOI 10.1109/CVPR.1997.609442; Wilson AD, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P329, DOI 10.1109/ICCV.1998.710739; WILSON AD, 1998, P COMP VIS PATT REC; WILSON AD, 1995, P IEEE INT S COMP VI; Yacoob Y, 1999, COMPUT VIS IMAGE UND, V73, P232, DOI 10.1006/cviu.1998.0726; Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161	32	315	328	0	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1999	21	9					884	900		10.1109/34.790429	http://dx.doi.org/10.1109/34.790429			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	234TZ					2022-12-18	WOS:000082501600005
J	Kristan, M; Matas, J; Leonardis, A; Vojir, T; Pflugfelder, R; Fernandez, G; Nebehay, G; Porikli, F; Cehovin, L				Kristan, Matej; Matas, Jiri; Leonardis, Ales; Vojir, Tomas; Pflugfelder, Roman; Fernandez, Gustavo; Nebehay, Georg; Porikli, Fatih; Cehovin, Luka			A Novel Performance Evaluation Methodology for Single-Target Trackers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Performance analysis; single-target tracking; model-free tracking; tracker evaluation methodology; tracker evaluation datasets; tracker evaluation system	VISUAL TRACKING; OBJECT TRACKING; MEAN-SHIFT; MOTION; FACE	This paper addresses the problem of single-target tracker performance evaluation. We consider the performance measures, the dataset and the evaluation system to be the most important components of tracker evaluation and propose requirements for each of them. The requirements are the basis of a new evaluation methodology that aims at a simple and easily interpretable tracker comparison. The ranking-based methodology addresses tracker equivalence in terms of statistical significance and practical differences. A fully-annotated dataset with per-frame annotations with several visual attributes is introduced. The diversity of its visual properties is maximized in a novel way by clustering a large number of videos according to their visual attributes. This makes it the most sophistically constructed and annotated dataset to date. A multi-platform evaluation system allowing easy integration of third-party trackers is presented as well. The proposed evaluation methodology was tested on the VOT2014 challenge on the new dataset and 38 trackers, making it the largest benchmark to date. Most of the tested trackers are indeed state-of-the-art since they outperform the standard baselines, resulting in a highly-challenging benchmark. An exhaustive analysis of the dataset from the perspective of tracking difficulty is carried out. To facilitate tracker comparison a new performance visualization technique is proposed.	[Kristan, Matej; Cehovin, Luka] Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana 1000, Slovenia; [Matas, Jiri; Vojir, Tomas] Czech Tech Univ, Fac Elect Engn, Prague 16627, Czech Republic; [Leonardis, Ales] Univ Birmingham, Sch Comp Sci, Birmingham B15 2TT, W Midlands, England; [Pflugfelder, Roman; Fernandez, Gustavo; Nebehay, Georg] Austrian Inst Technol, A-2444 Seibersdorf, Austria; [Porikli, Fatih] NICTA, Canberra, ACT 0200, Australia; [Porikli, Fatih] Australian Natl Univ, Canberra, ACT 0200, Australia	University of Ljubljana; Czech Technical University Prague; University of Birmingham; Austrian Institute of Technology (AIT); Australian National University; Australian National University	Kristan, M (corresponding author), Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana 1000, Slovenia.	matej.kristan@fri.uni-lj.si; matas@cmp.felk.cvut.cz; ales.leonardis@fri.uni-lj.si; vojirtom@fel.cvut.cz; roman.pflugfelder@ait.ac.at; GustavoJavier.Fernandez@ait.ac.at; georg.nebehay.fl@ait.ac.at; fatih.porikli@gmail.com; luka.cehovin@fri.uni-lj.si	, Matas/AAW-3282-2020	Cehovin Zajc, Luka/0000-0003-2823-272X	Slovenian research agency [P2-0095, P2-0214, J2-4284, J2-3607]; EU project EPiCS [257906]; CTU Project [SGS15/155/OHK3/2T/13]; Czech Science Foundation [GACR P103/12/G084]	Slovenian research agency(Slovenian Research Agency - Slovenia); EU project EPiCS; CTU Project; Czech Science Foundation(Grant Agency of the Czech Republic)	This work was supported in part by the following research programs and projects: Slovenian research agency research programs and projects P2-0095, P2-0214, J2-4284, J2-3607, the EU project EPiCS (grant agreement no 257906), the CTU Project SGS15/155/OHK3/2T/13 and by The Czech Science Foundation Project GACR P103/12/G084.	Adam A., 2006, IEEE C COMP VIS PATT; ANDERSON TW, 1952, ANN MATH STAT, V23, P193, DOI 10.1214/aoms/1177729437; Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; Bar-Shalom Y., 2001, ESTIMATION APPL TRAC, P438; Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309; Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960; Briechle K, 2001, PROC SPIE, V4387, P95, DOI 10.1117/12.421129; Cai ZW, 2014, IEEE T IMAGE PROCESS, V23, P5497, DOI 10.1109/TIP.2014.2364919; Carvalho P, 2012, IMAGE VISION COMPUT, V30, P630, DOI 10.1016/j.imavis.2012.06.002; Cehovin L., 2015, ARXIV150205803CSCV; Cehovin L., 2013, VISUAL OBJECT TRACKI; Cehovin L, 2014, IEEE WINT CONF APPL, P540, DOI 10.1109/WACV.2014.6836055; Cehovin L, 2013, IEEE T PATTERN ANAL, V35, P941, DOI 10.1109/TPAMI.2012.145; Chu Dung M., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P103, DOI 10.1109/AVSS.2010.85; Collins R., 2005, INT WORKSH PERF EV T; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Danelljan M, 2014, BRIT MACHINE VISIO, P1; Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143; Demsar J, 2006, J MACH LEARN RES, V7, P1; Demsar J., 2008, P WORKSH EV METH MAC, P1; Doermann D, 2000, INT C PATT RECOG, P167, DOI 10.1109/ICPR.2000.902888; Duffner S., 2014, P WORKSH VIS OBJ TRA, P1; Duffner S, 2013, IEEE I CONF COMP VIS, P2480, DOI 10.1109/ICCV.2013.308; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Felsberg M, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P121, DOI 10.1109/ICCVW.2013.22; Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Gabriel P., 2003, ADV CONCEPTS INTELLI, P166; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; Geiger A., 2012, P IEEE COMP SOC C CO; Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919; Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251; Henriques J. F., 2012, EUR C COMP VIS, P702, DOI DOI 10.1007/978-3-642-33765-9_50; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274; Jaynes C., 2002, P 3 INT WORKSH PERF, P32; Karasulu B, 2011, MULTIMED TOOLS APPL, V55, P677, DOI 10.1007/s11042-010-0591-2; Kasturi R, 2009, IEEE T PATTERN ANAL, V31, P319, DOI 10.1109/TPAMI.2008.57; Kristan M., 2014, P COMP VIS WINT WORK, P61; Kristan M., 2016, EUR C COMP VIS, V9914, P777; Kristan M., 2005, COMP VIS WINT WORKSH, P155; Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14; Kristan M, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P98, DOI 10.1109/ICCVW.2013.20; Kristan M, 2010, IEEE T SYST MAN CY B, V40, P1505, DOI 10.1109/TSMCB.2010.2041662; Kristan M, 2009, COMPUT VIS IMAGE UND, V113, P598, DOI 10.1016/j.cviu.2008.01.009; Kwon J, 2009, PROC CVPR IEEE, P1208, DOI 10.1109/CVPRW.2009.5206502; Leal-Taixe L., 2015, ARXIV; Lebeda K, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P153, DOI 10.1109/ICCVW.2013.26; Li AN, 2016, IEEE T PATTERN ANAL, V38, P335, DOI 10.1109/TPAMI.2015.2417577; Li HX, 2011, PROC CVPR IEEE, P1305, DOI 10.1109/CVPR.2011.5995483; Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039; Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18; Maresca ME, 2013, LECT NOTES COMPUT SC, V8157, P419, DOI 10.1007/978-3-642-41184-7_43; Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; Nam H, 2014, LECT NOTES COMPUT SC, V8693, P112, DOI 10.1007/978-3-319-10602-1_8; Navidi W.C., 2011, STAT ENG SCI, V3rd ed.; Nawaz T, 2013, IEEE T IMAGE PROCESS, V22, P1354, DOI 10.1109/TIP.2012.2228497; Nebehay G, 2014, IEEE WINT CONF APPL, P862, DOI 10.1109/WACV.2014.6836013; Nummiaro K., 2003, Acta Automatica Sinica, V29, P345; Ofjall K., 2014, P WORKSH VIS OBJ TRA, P218; Pang Y, 2013, IEEE I CONF COMP VIS, P2784, DOI 10.1109/ICCV.2013.346; Perez P, 2002, LECT NOTES COMPUT SC, V2350, P661; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Salti S, 2012, IEEE T IMAGE PROCESS, V21, P4334, DOI 10.1109/TIP.2012.2206035; SanMiguel JC, 2012, IEEE T IMAGE PROCESS, V21, P2812, DOI 10.1109/TIP.2011.2182520; Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891; Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Vojir T., 2011, P COMP VIS WINT WORK, P91; Vojir T, 2014, PATTERN RECOGN LETT, V49, P250, DOI 10.1016/j.patrec.2014.03.025; Wu H, 2010, IEEE T PATTERN ANAL, V32, P1443, DOI 10.1109/TPAMI.2009.135; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Yi K. M., 2012, P 27 C IM VIS COMP N, P25; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Young D. P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P317; Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62	81	314	329	9	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2016	38	11					2137	2155		10.1109/TPAMI.2016.2516982	http://dx.doi.org/10.1109/TPAMI.2016.2516982			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DZ6AW	26766217	Green Published, Green Submitted			2022-12-18	WOS:000385945000001
J	Courty, N; Flamary, R; Tuia, D; Rakotomamonjy, A				Courty, Nicolas; Flamary, Remi; Tuia, Devis; Rakotomamonjy, Alain			Optimal Transport for Domain Adaptation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Unsupervised domain adaptation; optimal transport; transfer learning; visual adaptation; classification	ALGORITHM	Domain adaptation is one of the most challenging tasks of modern data analytics. If the adaptation is done correctly, models built on a specific data representation become more robust when confronted to data depicting the same classes, but described by another observation system. Among the many strategies proposed, finding domain-invariant representations has shown excellent properties, in particular since it allows to train a unique classifier effective in all domains. In this paper, we propose a regularized unsupervised optimal transportation model to perform the alignment of the representations in the source and target domains. We learn a transportation plan matching both PDFs, which constrains labeled samples of the same class in the source domain to remain close during transport. This way, we exploit at the same time the labeled samples in the source and the distributions observed in both domains. Experiments on toy and challenging real visual adaptation examples show the interest of the method, that consistently outperforms state of the art approaches. In addition, numerical experiments show that our approach leads to better performances on domain invariant deep learning features and can be easily adapted to the semi-supervised case where few labeled samples are available in the target domain.	[Courty, Nicolas] Univ Bretagne Sud, IRISA Lab, F-35000 Rennes, France; [Flamary, Remi] Univ Cote Azur, OCA, Lagrange Lab, UMR CNRS 7293, F-06108 Nice, France; [Tuia, Devis] Univ Zurich, Dept Geog, CH-8057 Zurich, Switzerland; [Rakotomamonjy, Alain] Normandie Univ, UR, LITIS, F-76800 St Etienne Du Rouvray, France	UDICE-French Research Universities; Universite Cote d'Azur; Observatoire de la Cote d'Azur; University of Zurich	Courty, N (corresponding author), Univ Bretagne Sud, IRISA Lab, F-35000 Rennes, France.	Nicolas.Courty@irisa.fr; remi.flamary@unice.fr; devis.tuia@geo.uzh.ch; alain.rakoto@insa-rouen.fr	Flamary, Rémi/AAC-1958-2022; Tuia, Devis/AAE-9339-2019; Jeong, Yongwook/N-7413-2016	Flamary, Rémi/0000-0002-4212-6627; Tuia, Devis/0000-0003-0374-2459; 	Swiss National Science Foundation [PP00P2-150593]; CNRS PEPS Fascido program under the Topase project	Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission); CNRS PEPS Fascido program under the Topase project	This work was partly funded by the Swiss National Science Foundation under the grant PP00P2-150593 and by the CNRS PEPS Fascido program under the Topase project.	Ahuja R. K., 1993, NETWORK FLOWS THEORY; [Anonymous], 2014, ICML; Benamou JD, 2000, NUMER MATH, V84, P375, DOI 10.1007/s002119900117; Bertsekas D. P., 1999, NONLINEAR PROGRAM, V2nd; Bonneel N, 2015, J MATH IMAGING VIS, V51, P22, DOI 10.1007/s10851-014-0506-3; Bonneel N, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024192; Bredies K., 2005, EQUIVALENCE GEN COND; Bredies K, 2009, COMPUT OPTIM APPL, V42, P173, DOI 10.1007/s10589-007-9083-3; Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57; Caetano TS, 2006, IEEE T PATTERN ANAL, V28, P1646, DOI 10.1109/TPAMI.2006.207; Caetano TS, 2009, IEEE T PATTERN ANAL, V31, P1048, DOI 10.1109/TPAMI.2009.28; Carlier G., 2014, TECH REP; Carreira-Perpinan MA, 2014, AAAI CONF ARTIF INTE, P1715; Courty N., 2014, LNCS, P1; CUTURI M., 2013, P INT C ADV NEURAL I, V26; Cuturi M, 2014, PR MACH LEARN RES, V32, P685; Cuturi M, 2014, J MACH LEARN RES, V15, P533; Daume III H., 2007, P WORKSH DOM AD NAT, P53; Donahue J., 2014, ICML, P647; Ferradans S., 2013, PROC 4 INT C SCALE S, P428, DOI [10.1007/978-3-642-38267-3_36.31, 10.1007/978-3-642-38267-3_36]; Gangbo W, 1996, ACTA MATH-DJURSHOLM, V177, P113, DOI 10.1007/BF02392620; Germain P., 2013, INT C MACH LEARN, P738; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Griffin G., 2007, TECH REP; Ham J., 2005, P ANN C UNC ART INT, P120; Hoffman Judy, 2013, ARXIV13013224; Jhuo IH, 2012, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2012.6247924; Kantorovitch L, 1942, CR ACAD SCI URSS, V37, P199; Knight PA, 2008, SIAM J MATRIX ANAL A, V30, P261, DOI 10.1137/060659624; Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702; Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274; Luo B, 2001, IEEE T PATTERN ANAL, V23, P1120, DOI 10.1109/34.954602; Mansour Y., 2009, P COLT, P19; Pal D., 2010, INT C ART INT STAT, P129; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P53, DOI 10.1109/MSP.2014.2347059; Rabin J, 2012, LECT NOTES COMPUT SC, V6667, P435, DOI 10.1007/978-3-642-24785-9_37; Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923; Si S, 2010, IEEE T KNOWL DATA EN, V22, P929, DOI 10.1109/TKDE.2009.126; Sugiyama M., 2008, NIPS, P1433; Tuia D., 2015, P 8 INT WORKSH AN MU, P1; Tuia D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148655; Villani C, 2009, GRUNDLEHR MATH WISS, V338, P5; Wang C., 2011, P IJCAI, V22, P1541; Wang C., 2011, MANIFOLD LEARNING TH; Wang C, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1273; Zhang K., 2013, INT C MACH LEARN, P388; Zheng JJ, 2012, INT C PATT RECOG, P2095	53	313	319	6	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2017	39	9					1853	1865		10.1109/TPAMI.2016.2615921	http://dx.doi.org/10.1109/TPAMI.2016.2615921			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FC4WC	27723579	Green Submitted			2022-12-18	WOS:000406840800012
J	Xu, L; Jia, JY; Matsushita, Y				Xu, Li; Jia, Jiaya; Matsushita, Yasuyuki			Motion Detail Preserving Optical Flow Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Optical flow; image motion; video motion; variational methods; optimization; features	ALGORITHM	A common problem of optical flow estimation in the multiscale variational framework is that fine motion structures cannot always be correctly estimated, especially for regions with significant and abrupt displacement variation. A novel extended coarse-to-fine (EC2F) refinement framework is introduced in this paper to address this issue, which reduces the reliance of flow estimates on their initial values propagated from the coarse level and enables recovering many motion details in each scale. The contribution of this paper also includes adaptation of the objective function to handle outliers and development of a new optimization procedure. The effectiveness of our algorithm is demonstrated by Middlebury optical flow benchmarkmarking and by experiments on challenging examples that involve large-displacement motion.	[Xu, Li; Jia, Jiaya] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China; [Matsushita, Yasuyuki] Microsoft Res Asia, Beijing 100080, Peoples R China	Chinese University of Hong Kong; Microsoft; Microsoft Research Asia	Xu, L (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.	xuli@cse.cuhk.edu.hk; leojia@cse.cuhk.edu.hk; yasumat@microsoft.com	Jia, Jiaya/I-3251-2012	Matsushita, Yasuyui/0000-0002-1935-4752	Research Grants Council of the Hong Kong SAR [412911]; NSF of China [61133009]	Research Grants Council of the Hong Kong SAR(Hong Kong Research Grants Council); NSF of China(National Natural Science Foundation of China (NSFC))	The authors would like to thank the associate editor and all the anonymous reviewers for their time and effort. This work is supported by a grant from the Research Grants Council of the Hong Kong SAR (Project No. 412911) and by NSF of China (key project No. 61133009).	Alvarez L., 1999, P 16 C EC DIF APL LA, P1349; ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; Baker S., 2007, P 11 IEEE INT C COMP; Baker S., 2009, MSRTR2009179; BERGEN JR, 1992, LECT NOTES COMPUT SC, V588, P237; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Brox T., 2009, P IEEE C COMP VIS PA; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Bruhn A, 2005, IEEE I CONF COMP VIS, P749; Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43; Geiger D., 1989, 1114 AI MIT; Goldfarb D., 2007, 0709 RIC U; Hale ET, 2008, SIAM J OPTIMIZ, V19, P1107, DOI 10.1137/070698920; Haussecker HW, 2001, IEEE T PATTERN ANAL, V23, P661, DOI 10.1109/34.927465; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Lei C., 2009, P 12 IEEE INT C COMP; Lempitsky V, 2008, PROC CVPR IEEE, P3184; Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7_3; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Memin E, 2002, INT J COMPUT VISION, V46, P129, DOI 10.1023/A:1013539930159; Roth S, 2005, IEEE I CONF COMP VIS, P42; Rother C., 2007, P IEEE C COMP VIS PA; Sand P., 2006, CVPR, P2195; Scharstein D, 2007, P IEEE C COMP VIS PA; Seitz S.M., 2009, P 12 IEEE INT C COMP; Sizintsev M., 1996, P BRIT MACH VIS C, P237; Steinbrucker F., 2009, P 12 IEEE INT C COMP; Sun DQ, 2008, LECT NOTES COMPUT SC, V5304, P83; Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939; Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265; Wedel A., 2009, P 12 IEEE INT C COMP; Wedel A., 2008, P DAGST VIS MOT AN W; Werlberger M., 2009, P BRIT MACH VIS C; Werlberger M., 2010, P IEEE C COMP VIS PA; Xiao JJ, 2006, LECT NOTES COMPUT SC, V3951, P211; Xu L., 2010, P IEEE C COMP VIS PA; Xu L, 2008, LECT NOTES COMPUT SC, V5302, P671; Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22; Zimmer H., 2009, P INT C EN MIN METH; Zimmer H, 2011, INT J COMPUT VISION, V93, P368, DOI 10.1007/s11263-011-0422-6	45	313	351	3	52	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2012	34	9					1744	1757		10.1109/TPAMI.2011.236	http://dx.doi.org/10.1109/TPAMI.2011.236			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	974DD	22156095	Green Submitted			2022-12-18	WOS:000306409100008
J	Raguram, R; Chum, O; Pollefeys, M; Matas, J; Frahm, JM				Raguram, Rahul; Chum, Ondrej; Pollefeys, Marc; Matas, Jiri; Frahm, Jan-Michael			USAC: A Universal Framework for Random Sample Consensus	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						RANSAC; robust estimation	GEOMETRY ESTIMATION; EPIPOLAR GEOMETRY; ROBUST; RANSAC	A computational problem that arises frequently in computer vision is that of estimating the parameters of a model from data that have been contaminated by noise and outliers. More generally, any practical system that seeks to estimate quantities from noisy data measurements must have at its core some means of dealing with data contamination. The random sample consensus (RANSAC) algorithm is one of the most popular tools for robust estimation. Recent years have seen an explosion of activity in this area, leading to the development of a number of techniques that improve upon the efficiency and robustness of the basic RANSAC algorithm. In this paper, we present a comprehensive overview of recent research in RANSAC-based robust estimation by analyzing and comparing various approaches that have been explored over the years. We provide a common context for this analysis by introducing a new framework for robust estimation, which we call Universal RANSAC (USAC). USAC extends the simple hypothesize-and-verify structure of standard RANSAC to incorporate a number of important practical and computational considerations. In addition, we provide a general-purpose C++ software library that implements the USAC framework by leveraging state-of-the-art algorithms for the various modules. This implementation thus addresses many of the limitations of standard RANSAC within a single unified package. We benchmark the performance of the algorithm on a large collection of estimation problems. The implementation we provide can be used by researchers either as a stand-alone tool for robust estimation or as a benchmark for evaluating new techniques.	[Raguram, Rahul] Apple Comp Inc, Cupertino, CA 95014 USA; [Chum, Ondrej; Matas, Jiri] Czech Tech Univ, Ctr Machine Percept, CR-16635 Prague, Czech Republic; [Pollefeys, Marc] ETH, Dept Comp Sci, CH-8092 Zurich, Switzerland; [Frahm, Jan-Michael] Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA	Apple Inc; Czech Technical University Prague; Swiss Federal Institutes of Technology Domain; ETH Zurich; University of North Carolina; University of North Carolina Chapel Hill	Raguram, R (corresponding author), Apple Comp Inc, 1 Infinite Loop, Cupertino, CA 95014 USA.	rraguram@apple.com; chum@cmp.felk.cvut.cz; marc.pollefeys@inf.ethz.ch; matas@cmp.felk.cvut.cz; jmf@cs.unc.edu	Pollefeys, Marc/I-7607-2013; Chum, Ondrej/F-5262-2015; , Matas/AAW-3282-2020	Chum, Ondrej/0000-0001-7042-1810	US National Science Foundation (NSF) [IIS-0916829]; Department of Energy (DOE) [DE-FG52-08NA28778]; GACR [P103/12/2310]; EC [FP7-ICT-270138 DARWIN]; 4DVideo ERC Starting Grant [210806]	US National Science Foundation (NSF)(National Science Foundation (NSF)); Department of Energy (DOE)(United States Department of Energy (DOE)); GACR(Grant Agency of the Czech Republic); EC(European CommissionEuropean Commission Joint Research Centre); 4DVideo ERC Starting Grant	The authors are grateful to the sponsors of this research. R. Raguram and J-M. Frahm were supported by US National Science Foundation (NSF) Grant IIS-0916829 and Department of Energy (DOE) Award DE-FG52-08NA28778. O. Chum and J. Matas were supported by GACR P103/12/2310 and EC project FP7-ICT-270138 DARWIN. M. Pollefeys gratefully acknowledges the support of the 4DVideo ERC Starting Grant Nr. 210806.	Agarwal S., 2009, P IEEE INT C COMP VI; [Anonymous], P IEEE COMP SOC C CO; Capel D., 2005, P BRIT MACH VIS C; Chen HF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P878, DOI 10.1109/ICCV.2003.1238441; Chin T.-J., 2009, P 12 IEEE INT C COMP; Chin T.-J., 2010, P EUR C COMP VIS; Chli M, 2008, LECT NOTES COMPUT SC, V5302, P72, DOI 10.1007/978-3-540-88682-2_7; Choi J., 2009, P IEEE C COMP VIS PA; Chum O, 2005, PROC CVPR IEEE, P772; Chum O, 2004, INT C PATT RECOG, P112, DOI 10.1109/ICPR.2004.1334020; Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236; Chum O., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P623; Chum O., 2005, P IEEE C COMP VIS PA; Chum O, 2008, IEEE T PATTERN ANAL, V30, P1472, DOI 10.1109/TPAMI.2007.70787; Clipp B., 2010, P IEEE RSJ INT C INT; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Frahm J.-M., 2006, P COMP VIS PATT REC, V1, P453, DOI DOI 10.1109/CVPR.2006.235; Frahm JM, 2010, LECT NOTES COMPUT SC, V6314, P368, DOI 10.1007/978-3-642-15561-1_27; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Hough P., 1962, US Patent, Patent No. 3.069.654; Huber P., 1981, ROBUST STAT; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; Jung IK, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P538, DOI 10.1109/ICCV.2001.937672; Lee KM, 1998, IEEE T PATTERN ANAL, V20, P200, DOI 10.1109/34.659940; Li HD, 2009, IEEE I CONF COMP VIS, P1074, DOI 10.1109/ICCV.2009.5459398; Malis E., 2006, P IEEE RSJ INT C INT; Matas J, 2005, IEEE I CONF COMP VIS, P1727; Miller JV, 1996, PROC CVPR IEEE, P300, DOI 10.1109/CVPR.1996.517089; Myatt D. R., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P458; Neira J, 2001, IEEE T ROBOTIC AUTOM, V17, P890, DOI 10.1109/70.976019; Ni K., 2009, P 12 IEEE INT C COMP; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; NISTER D, 2004, PROC CVPR IEEE, P652, DOI DOI 10.1109/CVPR.2004.1315094; NISTER D, 2003, P 9 IEEE INT C COMP; Pollefeys M, 2008, INT J COMPUT VISION, V78, P143, DOI 10.1007/s11263-007-0086-4; Raguram R., 2009, P 12 IEEE INT C COMP; Raguram R., 2011, P IEEE INT C COMP VI; Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4_37; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; Sattler T., 2009, P 12 IEEE INT C COMP; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; SIEGEL AF, 1982, BIOMETRIKA, V69, P242, DOI 10.1093/biomet/69.1.242; Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; Tanaka K, 2006, IEEE INT CONF ROBOT, P68, DOI 10.1109/ROBOT.2006.1641163; Toldo R, 2008, LECT NOTES COMPUT SC, V5302, P537, DOI 10.1007/978-3-540-88682-2_41; Tordoff B, 2002, LECT NOTES COMPUT SC, V2350, P82; Torii A., 2009, P IEEE INT C COMP VI; Torr PHS, 1998, COMPUT VIS IMAGE UND, V71, P312, DOI 10.1006/cviu.1997.0559; Tukey J. W., 1977, EXPLORATORY DATA ANA; Tuytelaars T., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P412; Wald A., 1947, SEQUENTIAL ANAL; Wang HZ, 2004, IEEE T PATTERN ANAL, V26, P1459, DOI 10.1109/TPAMI.2004.109; ZHANG W, 2006, P ROB SCI SYST C; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4	56	311	330	8	52	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2013	35	8					2022	2038		10.1109/TPAMI.2012.257	http://dx.doi.org/10.1109/TPAMI.2012.257			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	164AP	23787350				2022-12-18	WOS:000320381400016
J	Quattoni, A; Wang, S; Morency, LP; Collins, M; Darrell, T				Quattoni, Ariadna; Wang, Sybor; Morency, Louis-Philippe; Collins, Michael; Darrell, Trevor			Hidden conditional random fields	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object recognition; model; supervised learning; classification		We present a discriminative latent variable model for classification problems in structured domains where inputs can be represented by a graph of local observations. A hidden-state Conditional Random Field framework learns a set of latent variables conditioned on local features. Observations need not be independent and may overlap in space and time.	MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT)	Quattoni, A (corresponding author), MIT, Comp Sci & Artificial Intelligence Lab, 32 Vassar St, Cambridge, MA 02139 USA.	ariadna@csail.mit.edu; sybor@mit.edu; lmorency@mit.edu; mcollins@csail.mit.edu; trevor@csail.mit.edu	Morency, Louis-Philippe/B-2006-2008					ASSAN M, 1997, P INT C GEST WORKSH; BRAND M, 1996, P IEEE C COMP VIS PA; DEMIRDJIAN D, 2002, P INT C MULT INT; FERGUS R, 2003, P IEEE INT C COMP VI; Fujie S, 2004, RO-MAN 2004: 13TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P159, DOI 10.1109/ROMAN.2004.1374748; Gunawardana A, 2005, P INTERSPEECH; KAPOOR A, 2001, P WORKSH PERSP US IN; KOO T, 2005, P IEEE C EMP METH NA; KUENSCH AKH, 2005, ANN APPL PROBABILITY, V5; KUMAR S, 2004, P SNOWB LEARN WORKSH; Kumar S., 2003, P IEEE INT C COMP VI; LAFFERTY J, 2001, P IEEE INT C MACH LE; LOWE D, 1999, P IEEE C INT C COMP; MCCALLUM A, 2000, P IEEE C EMP METH NA; MORENCY LP, 2005, P INT C MULT INT; MORENCY LP, 2000, P IEEE C COMP VIS PA; Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226; Quattoni A., 2004, P IEEE C NEUR INF PR; RATNAPARKHI A, 1996, P IEEE C EMP METH NA; SMINCHISESCU C, 2005, P IEEE INT C COMP VI; STARNER T, 1995, P IEEE S COMP VIS; TORRALBA A, 2004, P IEEE C NEURAL INF; WANG S, 2006, P IEEE C COMP VIS PA; YANG M, 2000, P IEEE EUR C COMP VI	24	310	323	0	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2007	29	10					1848	1853		10.1109/TPAMI.2007.1124	http://dx.doi.org/10.1109/TPAMI.2007.1124			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	199LA	17699927				2022-12-18	WOS:000248696100012
J	Ong, SCW; Ranganath, S				Ong, SCW; Ranganath, S			Automatic sign language analysis: A survey and the future beyond lexical meaning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review						sign language recognition; hand tracking; hand gesture recognition; gesture analysis; head tracking; head gesture recognition; face tracking; facial expression recognition; review	RULE-BASED APPROACH; RECOGNITION SYSTEM; TRACKING; MOTION; MODEL; GESTURES	Research in automatic analysis of sign language has largely focused on recognizing the lexical (or citation) form of sign gestures as they appear in continuous signing, and developing algorithms that scale well to large vocabularies. However, successful recognition of lexical signs is not sufficient for a full understanding of sign language communication. Nonmanual signals and grammatical processes which result in systematic variations in sign appearance are integral aspects of this communication but have received comparatively little attention in the literature. In this survey, we examine data acquisition, feature extraction and classification methods employed for the analysis of sign language gestures. These are discussed with respect to issues such as modeling transitions between signs in continuous signing, modeling inflectional processes, signer independence, and adaptation. We further examine works that attempt to analyze nonmanual signals and discuss issues related to integrating these with (hand) sign gestures. We also discuss the overall progress toward a true test of sign recognition systems-dealing with natural signing by native signers. We suggest some future directions for this research and also point to contributions it can make to other fields of research. Web-based supplemental materials (appendicies) which contain several illustrative examples and videos of signing can be found at www.computer.org/publications/dlib.	Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore	National University of Singapore	Ong, SCW (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, 4 Engn Dr 3, Singapore 117576, Singapore.	engp0560@nus.edu.sg; elesr@nus.edu.sg						Akyol S., 2001, Proceedings of the IASTED International Conference Signal Processing, Pattern Recognition, and Applications, P48; AKYOL S, 2002, P ITEA WORKSH VIRT H, P61; Al-Jarrah O, 2001, ARTIF INTELL, V133, P117, DOI 10.1016/S0004-3702(01)00141-2; [Anonymous], 1998, STAT METHODS SPEECH; [Anonymous], 1995, TUTORIAL LEARNING BA; Assan M., 1997, P GEST WORKSH, P97; Baker C., 1978, UNDERSTING LANGUA, P27; Bartlett MS, 1998, P SOC PHOTO-OPT INS, V3299, P528, DOI 10.1117/12.320144; Battison Robbin., 2003, LEXICAL BORROWING AM; Bauer B, 2002, INT C PATT RECOG, P434, DOI 10.1109/ICPR.2002.1048332; BAUER B, 2001, P 10 AACH S SIGN THE, P101; Bauer B., 2001, AUTOMATIC SIGN LANGU, V2298, P64; BILLINGHURST M, 1998, ACM SIGGRAPH COMPUTE, V32, P60; BIRK H, 1997, P SCAND C IM AN, P261; BLACK MJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P374, DOI 10.1109/ICCV.1995.466915; BLACKSTONE S, 1986, AUGMENTATIVE COMMUNI; BOSSARD B, 2003, P GEST WORKSH, P90; BOURLARD H, 1995, P TAMP WORKSH ROB ME, P1; Bowden R, 2002, IMAGE VISION COMPUT, V20, P597, DOI 10.1016/S0262-8856(02)00049-5; BRADSKI G, 1998, INTERL TECHNICAL J; BRAFFORT A, 1996, PROGR GESTURAL INTER, P17; Braffort A., 2001, P GEST WORKSH, P1; Brashear H, 2003, SEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P45, DOI 10.1109/ISWC.2003.1241392; Brentari D., 1995, HDB PHONOLOGICAL THE, P615; Bridges Byron, 1996, DEAF TEND YOUR NONMA; Canzler U., 2002, P IAPR WORKSH MACH V, P318; Chen FS, 2003, IMAGE VISION COMPUT, V21, P745, DOI 10.1016/S0262-8856(03)00070-2; Choi HI, 1999, EXPERT SYST APPL, V17, P213, DOI 10.1016/S0957-4174(99)00035-4; Cootes T. F., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P227, DOI 10.1109/AFGR.2000.840639; Corazza S., 1990, SIGN LANGUAGE RES TH; COX E, 1993, IEEE SPECTRUM, V30, P27, DOI 10.1109/6.208359; Crowley JL, 2000, COMMUN ACM, V43, P54, DOI 10.1145/330534.330540; Cui Y, 2000, COMPUT VIS IMAGE UND, V78, P157, DOI 10.1006/cviu.2000.0837; Cui YT, 1999, IEEE T PATTERN ANAL, V21, P798, DOI 10.1109/34.784311; Deng JW, 2002, INT C PATT RECOG, P283, DOI 10.1109/ICPR.2002.1044688; Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905; DORNER B., 1994, THESIS S FRASER U; DOWNTON AC, 1992, IEE CONF PUBL, V354, P274; DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361; Edwards A.D., 1997, P INT GEST WKSP GEST, P13; Ekman P., 1982, EMOTION HUMAN FACE; Erdem UM, 2002, INT C PATT RECOG, P460, DOI 10.1109/ICPR.2002.1044759; ERENSHTEYN R, 1996, P INT C PATT REC, V3, P431; Fang G., 2001, P GEST WORKSH, P76; Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3; Fasel B, 2000, INT C PATT RECOG, P1100, DOI 10.1109/ICPR.2000.905664; Fillbrandt H, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P181; Gao W, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P553; Gao W, 2000, INT J PATTERN RECOGN, V14, P587, DOI 10.1142/S0218001400000386; GAO W, 2000, P 3 INT C MULT INT, P564; Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; GIBET S, 1997, P GEST WORKSH; Gupta L, 2001, IEEE T SYST MAN CY C, V31, P114, DOI 10.1109/5326.923274; Handouyahia M., 1999, Proceedings Vision Interface '99, P210; Harling Philip A, 1996, P GESTURE WORKSHOP P, P75; Hernandez-Rebollar JL, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P547, DOI 10.1109/AFGR.2004.1301590; Hernandez-Rebollar JL, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P185, DOI 10.1109/ICMI.2002.1166990; Hienz H, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P323, DOI 10.1109/AFGR.1996.557285; HIENZ H, 1997, P INT GEST WORKSH GE, P135; HOLDEN EJ, 2000, P INT WORKSH THEOR F, P270; HOMMEL G, 1994, P 4 INT SCI C, V2, pF47; Huang CL, 2001, MACH VISION APPL, V12, P243, DOI 10.1007/s001380050144; Huang CL, 1998, MACH VISION APPL, V10, P292, DOI 10.1007/s001380050080; Imagawa K, 2000, INT C PATT RECOG, P849, DOI 10.1109/ICPR.2000.903050; Imagawa K, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P462, DOI 10.1109/AFGR.1998.670991; JANG JSR, 1993, IEEE T SYST MAN CYB, V23, P665, DOI 10.1109/21.256541; Johnston T., 1989, THESIS U SYDNEY; Kadous Mohammed Waleed, 1996, P WORKSH INT GEST LA, P165; Kadous MW, 1999, MACHINE LEARNING, PROCEEDINGS, P454; Kambhatla N, 1997, NEURAL COMPUT, V9, P1493, DOI 10.1162/neco.1997.9.7.1493; KANDA K, 2001, P GEST WORKSH, P181; KENDON A, 1993, TOOLS, LANGUAGE AND COGNITION IN HUMAN EVOLUTION, P43; Kendon A., 1988, CROSS CULTURAL PERSP, P131; Kennaway R., 2003, P INT GEST WORKSH GE, P300; Kim JS, 1996, IEEE T SYST MAN CY B, V26, P354, DOI 10.1109/3477.485888; Klima E., 1979, SIGNS LANGUAGE; Kobayashi T, 1997, INT CONF ACOUST SPEE, P3081, DOI 10.1109/ICASSP.1997.595443; KOIZUMI A, 2002, P INT C LANG RES EV, V3, P927; KONG SG, 2004, COMPUTER VISION IMAG; Kong WW, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P535, DOI 10.1109/AFGR.2004.1301588; Kramer J., 1987, P 3 ANN C COMP TECHN, P335; Kruger V, 2000, INT C PATT RECOG, P127, DOI 10.1109/ICPR.2000.905289; La Cascia M, 2000, IEEE T PATTERN ANAL, V22, P322, DOI 10.1109/34.845375; Liang RH, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P558, DOI 10.1109/AFGR.1998.671007; Liddell Scott, 1989, SIGN LANG STUD, V64, P195, DOI DOI 10.1353/SLS.1989.0027; Liddell Scott K., 2003, GRAMMAR GESTURE MEAN; Lu S., 1997, P GEST WORKSH, P259; MA J, 2000, P INT C ADV MULT INT, P582; Matsuo H., 1997, P INT GEST WORKSH, P273; McGuire RM, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P620, DOI 10.1109/AFGR.2004.1301602; McNeill D., 1992, HAND MIND WHAT GESTU; MING KW, 2002, P INT C CONTR AUT RO, V2, P716; MURAKAMI K, 1991, P SIGCHI C HUM FACT, P237; Nam Y, 1999, IEEE T SYST MAN CY A, V29, P514, DOI 10.1109/3468.784178; Neidle C, 2001, BEHAV RES METH INS C, V33, P311, DOI 10.3758/BF03195384; Neidle C., 2000, SYNTAX AM SIGN LANGU; Nolker C, 2002, IEEE T NEURAL NETWOR, V13, P983, DOI 10.1109/TNN.2002.1021898; Ong EJ, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P889; Ong SCW, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P559, DOI 10.1109/AFGR.2004.1301592; PADDEN CA, 1983, THESIS U CALIF SAN D; Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976; Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226; Pentland A, 2000, IEEE T PATTERN ANAL, V22, P107, DOI 10.1109/34.824823; PERLMUTTER D, 1993, PHONETICS PHONOLOGY, V3, P227; POIZNER H, 1983, P ACM SIGGRAPH SIGAR, P271; QUEK F, 1994, P VIRT REAL SOFTW TE, P17; REHG JM, 1994, P EUR C COMP VIS, V2, P35; Sagawa H., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P434, DOI 10.1109/AFGR.2000.840671; SAGAWA H, 1999, P GEST WORKSH, P197; SAGAWA H, 2000, P ACM C UN US, P149, DOI DOI 10.1145/355460.355552; Sako H., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P643, DOI 10.1109/ICPR.1996.547025; Sandler W., 1989, PHONOLOGICAL REPRESE; SHERRAH J, 2000, P BRIT MACH VIS C, P252; *SIGN FACT, 1996, SIGN LANGUAGE J  SPR; SIMPSON PK, 1992, IEEE T NEURAL NETWOR, V3, P776, DOI 10.1109/72.159066; Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811; Stokoe, 1960, SIGN LANGUAGE STRUCT, V8; STURMAN DJ, 1994, IEEE COMPUT GRAPH, V14, P30, DOI 10.1109/38.250916; Su MC, 2000, IEEE T SYST MAN CY C, V30, P276, DOI 10.1109/5326.868448; Su MC, 2001, IEEE T NEUR SYS REH, V9, P191, DOI 10.1109/7333.928579; Supalla T., 1978, UNDERSTANDING LANGUA, P91; Supalla Ted., 1996, NOUN CLASSES CATEGOR, P181, DOI DOI 10.1075/TSL.7.13SUP; SUTHERLAND A, 1996, P GEST WORKSH, P31; SUTTONSPENCE R, 1998, LINGUISTICS BRIT SIG; Sweeney G. J., 1996, P GEST WORKSH, P7; TAMURA S, 1988, PATTERN RECOGN, V21, P343, DOI 10.1016/0031-3203(88)90048-9; TANG J, 2000, P INT C ADV MULT INT, P72; Tanibata N, 2002, P INT C VIS INT, P391; Terrillon J. C., 2002, P INT C VIS INT, P369; *U ILL URB CHAMP S, 1994, POW GLOV SER INT; Vamplew P., 1998, Australian Journal of Intelligent Information Processing Systems, V5, P94; VAMPLEW P, 1996, THESIS U TASMANIA; VIOLA P, 2001, P IEEE WORKSH STAT C; *VIRT TECHN INC, 1995, CYBERGLOVE US MAN; Vogler C, 1997, IEEE SYS MAN CYBERN, P156, DOI 10.1109/ICSMC.1997.625741; Vogler C, 2000, WORKSHOP ON HUMAN MOTION, PROCEEDINGS, P33, DOI 10.1109/HUMO.2000.897368; Vogler C, 2001, COMPUT VIS IMAGE UND, V81, P358, DOI 10.1006/cviu.2000.0895; Vogler C. P., 2003, THESIS U PENNSYLVANI; *VPL RES INC, 1987, DATAGLOVE MOD 2 US M; Waldron M. B., 1995, IEEE Transactions on Rehabilitation Engineering, V3, P261, DOI 10.1109/86.413199; Wang CL, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P411, DOI 10.1109/AFGR.2002.1004188; Wang CL, 2001, LECT NOTES COMPUT SC, V2195, P150; Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0; Watanabe T, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P428, DOI 10.1109/AFGR.1998.670986; Wilbur RB, 2000, SIGNS OF LANGUAGE REVISITED, P215; WILBUR RB, 1993, PHONETICS PHONOLOGY, V3, P135; Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429; WU J, 2000, P INT C ADV MULT INT, P599; WU J, 2001, P INT GEST WORKSH GE, P96; Wu LZ, 1999, IEEE T MULTIMEDIA, V1, P334, DOI 10.1109/6046.807953; Wu Y, 2000, PROC CVPR IEEE, P88, DOI 10.1109/CVPR.2000.854749; XU M, 2000, P 3 INT C ADV MULT I, P572; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803; Young S, 1996, IEEE SIGNAL PROC MAG, V13, P45, DOI 10.1109/79.536824; Young S., 1995, HTK BOOK HTK VERSION; Yuan Q, 2002, INT C PATT RECOG, P75, DOI 10.1109/ICPR.2002.1044616; Zieren J., 2002, Pattern Recognition. 24th DAGM Symposium. Proceedings (Lecture Notes in Computr Science Vol.2449), P531; ZIMMERMAN T, 1986, P SIGCHI GI C HUM FA, P189; [No title captured]; 1991, POLHEMUS 3SPACE USER	162	310	318	0	62	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2005	27	6					873	891		10.1109/TPAMI.2005.112	http://dx.doi.org/10.1109/TPAMI.2005.112			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	915TR	15943420	Green Published			2022-12-18	WOS:000228334700004
J	Yilmaz, A; Li, X; Shah, M				Yilmaz, A; Li, X; Shah, M			Contour-based object tracking with occlusion handling in video acquired using mobile cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						contour tracking; shape priors; occlusion handling; level sets	SEGMENTATION	We propose a tracking method which tracks the complete object regions, adapts to changing visual features, and handles occlusions. Tracking is achieved by evolving the contour from frame to frame by minimizing some energy functional evaluated in the contour vicinity defined by a band. Our approach has two major components related to the visual features and the object shape. Visual features (color, texture) are modeled by semiparametric models and are fused using independent opinion polling. Shape priors consist of shape level sets and are used to recover the missing object regions during occlusion. We demonstrate the performance of our method on real sequences with and without object occlusions.	Univ Cent Florida, Sch Comp Sci, Orlando, FL 32816 USA; Univ Cent Florida, Dept Math, Orlando, FL 32816 USA	State University System of Florida; University of Central Florida; State University System of Florida; University of Central Florida	Yilmaz, A (corresponding author), Univ Cent Florida, Sch Comp Sci, 4000 Cent Florida Blvd, Orlando, FL 32816 USA.	yilmaz@cs.ucf.edu; xli@math.ucf.edu; shah@cs.ucf.edu	Yilmaz, Alper/B-5609-2013; Li, Xin/V-7387-2017	Yilmaz, Alper/0000-0003-0755-2628; Shah, Mubarak/0000-0001-6172-5572				Bertalmio M, 2000, IEEE T PATTERN ANAL, V22, P733, DOI 10.1109/34.865191; CASELLES V, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P694, DOI 10.1109/ICCV.1995.466871; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; CREMERS D, 2002, P EUR C COMP VIS; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; JEHANBESSON S, 2001, P IEEE INT C COMP VI; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Kass Michael, 1988, INT J COMPUTER VISIO, V988; Mansouri AR, 2002, IEEE T PATTERN ANAL, V24, P947, DOI 10.1109/TPAMI.2002.1017621; Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758; Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068; RITSCHER J, 2000, P EUR C COMP VIS, V2; SETHIAN J, 1999, LEVEL SET METHODS EV, P33018; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; YEZZI A, 2001, P WORKSH MATH METH B; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	17	310	337	0	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2004	26	11					1531	1536		10.1109/TPAMI.2004.96	http://dx.doi.org/10.1109/TPAMI.2004.96			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	852EC	15521500				2022-12-18	WOS:000223737000012
J	Nagy, G				Nagy, G			Twenty years of document image analysis in PAMI	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document image analysis; image processing; OCR; character recognition; forms processing; graphics recognition	OPTICAL CHARACTER-RECOGNITION; AUTOMATIC SCRIPT IDENTIFICATION; LINE-DRAWING INTERPRETATION; ENGINEERING DRAWINGS; PATTERN-RECOGNITION; TEXT RECOGNITION; BINARIZATION METHODS; LAYOUT ANALYSIS; SEGMENTATION; SYSTEM	The contributions to document image analysis of 99 papers published in the IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) are clustered, summarized, interpolated, interpreted, and tactfully evaluated.	Rensselaer Polytech Inst, Troy, NY 12180 USA	Rensselaer Polytechnic Institute	Nagy, G (corresponding author), Rensselaer Polytech Inst, Troy, NY 12180 USA.	nagy@ecse.rpi.edu		Nagy, George/0000-0002-0521-1443				AGHAJAN HK, 1994, IEEE T PATTERN ANAL, V16, P1057, DOI 10.1109/34.334386; ALYOUSEFI H, 1992, IEEE T PATTERN ANAL, V14, P853, DOI 10.1109/34.149585; AVIITZHAK HI, 1995, IEEE T PATTERN ANAL, V17, P418, DOI 10.1109/34.385977; AVIITZHAK HI, 1995, IEEE T PATTERN ANAL, V17, P218, DOI 10.1109/34.368165; BAIRD HS, 1990, IEEE T PATTERN ANAL, V12, P552, DOI 10.1109/34.56191; Bazzi I, 1999, IEEE T PATTERN ANAL, V21, P495, DOI 10.1109/34.771314; BERG JL, 1993, COMP STAND INTER, V15, P1, DOI 10.1016/0920-5489(93)90022-J; BUNKE H, 1982, IEEE T PATTERN ANAL, V4, P574, DOI 10.1109/TPAMI.1982.4767310; BURR DJ, 1981, IEEE T PATTERN ANAL, V3, P708, DOI 10.1109/TPAMI.1981.4767176; CABRELLI CA, 1990, IEEE T PATTERN ANAL, V12, P1190, DOI 10.1109/34.62608; Casey RG, 1996, IEEE T PATTERN ANAL, V18, P690, DOI 10.1109/34.506792; Cesarini F, 1998, IEEE T PATTERN ANAL, V20, P730, DOI 10.1109/34.689303; Chaudhuri BB, 1997, IEEE T PATTERN ANAL, V19, P182, DOI 10.1109/34.574803; COHEN E, 1994, IEEE T PATTERN ANAL, V16, P1049, DOI 10.1109/34.329003; DiZenzo S, 1996, IEEE T PATTERN ANAL, V18, P83, DOI 10.1109/34.476016; Dori D, 1999, IEEE T PATTERN ANAL, V21, P202, DOI 10.1109/34.754586; DORI D, 1995, IEEE T PATTERN ANAL, V17, P1057, DOI 10.1109/34.473231; ESPOSITO F, 1992, IEEE T PATTERN ANAL, V14, P390, DOI 10.1109/34.120333; Etemad K, 1997, IEEE T PATTERN ANAL, V19, P92, DOI 10.1109/34.566817; FLETCHER LA, 1988, IEEE T PATTERN ANAL, V10, P910, DOI 10.1109/34.9112; Garris MD, 1996, IEEE T PATTERN ANAL, V18, P653, DOI 10.1109/34.506417; GOTOH T, 1988, IEEE T PATTERN ANAL, V10, P393, DOI 10.1109/34.3903; GU YX, 1983, IEEE T PATTERN ANAL, V5, P83, DOI 10.1109/TPAMI.1983.4767349; HAVELOCK DI, 1989, IEEE T PATTERN ANAL, V11, P1065, DOI 10.1109/34.42837; HAVELOCK DI, 1991, IEEE T PATTERN ANAL, V13, P380, DOI 10.1109/34.88574; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716; Ho TK, 1997, IEEE T PATTERN ANAL, V19, P1067, DOI 10.1109/34.625107; Hochberg J, 1997, IEEE T PATTERN ANAL, V19, P176, DOI 10.1109/34.574802; Hoover A, 1996, IEEE T PATTERN ANAL, V18, P673, DOI 10.1109/34.506791; HUANG XF, 1993, IEEE T PATTERN ANAL, V15, P838, DOI 10.1109/34.236243; HULL JJ, 1982, IEEE T PATTERN ANAL, V4, P520, DOI 10.1109/TPAMI.1982.4767297; Hull JJ, 1996, IEEE T PATTERN ANAL, V18, P1251, DOI 10.1109/34.546261; HULL JJ, 1983, IEEE T PATTERN ANAL, V5, P384, DOI 10.1109/TPAMI.1983.4767408; Jain AK, 1998, IEEE T PATTERN ANAL, V20, P294, DOI 10.1109/34.667886; JOSEPH E, 1994, IEEE T PATTERN ANAL, V16, P630, DOI 10.1109/34.295907; JOSEPH SH, 1992, IEEE T PATTERN ANAL, V14, P928, DOI 10.1109/34.161351; Jung DM, 1996, IEEE T PATTERN ANAL, V18, P734, DOI 10.1109/34.506795; KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274, DOI 10.1109/TPAMI.1987.4767901; Kam AC, 1996, IEEE T PATTERN ANAL, V18, P945, DOI 10.1109/34.537350; KANAI J, 1995, IEEE T PATTERN ANAL, V17, P86, DOI 10.1109/34.368146; Kanungo T, 1999, IEEE T PATTERN ANAL, V21, P179, DOI 10.1109/34.748827; KASTURI R, 1990, IEEE T PATTERN ANAL, V12, P978, DOI 10.1109/34.58870; KAWAGUCHI E, 1980, IEEE T PATTERN ANAL, V2, P27, DOI 10.1109/TPAMI.1980.4766967; KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109; KOPEC GE, 1994, IEEE T PATTERN ANAL, V16, P602, DOI 10.1109/34.295905; Kopec GE, 1997, IEEE T PATTERN ANAL, V19, P1313, DOI 10.1109/34.643891; KRISHNAMOORTHY M, 1993, IEEE T PATTERN ANAL, V15, P737, DOI 10.1109/34.221173; KUO SS, 1994, IEEE T PATTERN ANAL, V16, P842, DOI 10.1109/34.308482; LAI CP, 1994, IEEE T PATTERN ANAL, V16, P848, DOI 10.1109/34.308483; LEE KH, 1992, IEEE T PATTERN ANAL, V14, P1122, DOI 10.1109/34.166629; Lee SW, 1996, IEEE T PATTERN ANAL, V18, P1045, DOI 10.1109/34.541415; Li YH, 1996, IEEE T PATTERN ANAL, V18, P99, DOI 10.1109/34.481536; Liu WY, 1998, IEEE T PATTERN ANAL, V20, P424, DOI 10.1109/34.677280; Liu Y, 1997, IEEE T PATTERN ANAL, V19, P540, DOI 10.1109/34.589217; Lu ZY, 1998, IEEE T PATTERN ANAL, V20, P431, DOI 10.1109/34.677283; Messmer BT, 1998, IEEE T PATTERN ANAL, V20, P493, DOI 10.1109/34.682179; MULDER JA, 1988, IEEE T PATTERN ANAL, V10, P866, DOI 10.1109/34.9108; MULLIN JK, 1981, IEEE T PATTERN ANAL, V3, P347, DOI 10.1109/TPAMI.1981.4767108; NAGAHASHI H, 1986, IEEE T PATTERN ANAL, V8, P112, DOI 10.1109/TPAMI.1986.4767759; NAGY G, 1987, IEEE T PATTERN ANAL, V9, P710, DOI 10.1109/TPAMI.1987.4767969; NALWA VS, 1989, IEEE T PATTERN ANAL, V11, P1117, DOI 10.1109/34.42842; NALWA VS, 1988, IEEE T PATTERN ANAL, V10, P514, DOI 10.1109/34.3914; NAMANE A, 1990, IEEE T PATTERN ANAL, V12, P600, DOI 10.1109/34.56197; O'Gorman L, 1998, IEEE T PATTERN ANAL, V20, P1097, DOI 10.1109/34.722623; OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677; OOMMEN BJ, 1987, IEEE T PATTERN ANAL, V9, P676, DOI 10.1109/TPAMI.1987.4767962; OZAKI A, 1988, IEEE T PATTERN ANAL, V10, P331; ROCHA J, 1995, IEEE T PATTERN ANAL, V17, P903, DOI 10.1109/34.406657; ROCHA J, 1994, IEEE T PATTERN ANAL, V16, P393, DOI 10.1109/34.277592; Samet H, 1996, IEEE T PATTERN ANAL, V18, P783, DOI 10.1109/34.531799; Sarker P, 1998, IEEE T PATTERN ANAL, V20, P344, DOI 10.1109/34.667892; Sawaki M, 1998, IEEE T PATTERN ANAL, V20, P1103, DOI 10.1109/34.722625; SHINGHAL R, 1980, IEEE T PATTERN ANAL, V2, P181, DOI 10.1109/TPAMI.1980.4766998; SHINITZKY M, 1984, PHYSL MEMBRANE FLUID, V1, P2; Simon A, 1997, IEEE T PATTERN ANAL, V19, P273, DOI 10.1109/34.584106; SINHA RMK, 1993, IEEE T PATTERN ANAL, V15, P915, DOI 10.1109/34.232077; Spitz AL, 1997, IEEE T PATTERN ANAL, V19, P235, DOI 10.1109/34.584100; STENTIFORD FWM, 1985, IEEE T PATTERN ANAL, V7, P349, DOI 10.1109/TPAMI.1985.4767665; STRINGA L, 1990, IEEE T PATTERN ANAL, V12, P1210, DOI 10.1109/34.62612; SUEN CY, 1979, IEEE T PATTERN ANAL, V1, P164, DOI 10.1109/TPAMI.1979.4766902; Tan TN, 1998, IEEE T PATTERN ANAL, V20, P751, DOI 10.1109/34.689305; TANAKA E, 1987, IEEE T PATTERN ANAL, V9, P806, DOI 10.1109/TPAMI.1987.4767987; Tang YY, 1997, IEEE T PATTERN ANAL, V19, P921, DOI 10.1109/34.608296; TAXT T, 1989, IEEE T PATTERN ANAL, V11, P1322, DOI 10.1109/34.41371; TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P312, DOI 10.1109/34.368197; TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P1191, DOI 10.1109/34.476511; Trier OD, 1997, IEEE T PATTERN ANAL, V19, P399, DOI 10.1109/34.588025; ULICHNEY RA, 1982, IEEE T PATTERN ANAL, V4, P331, DOI 10.1109/TPAMI.1982.4767254; WANG L, 1993, IEEE T PATTERN ANAL, V15, P1053, DOI 10.1109/34.254062; WANG MX, 1987, J NANJING FOR U, V9, P1; WANG QR, 1984, IEEE T PATTERN ANAL, V6, P406, DOI 10.1109/TPAMI.1984.4767546; WANG YP, 1990, IEEE T PATTERN ANAL, V12, P1080, DOI 10.1109/34.61707; WATANABE T, 1995, IEEE T PATTERN ANAL, V17, P432, DOI 10.1109/34.385976; YAJIMA S, 1981, IEEE T PATTERN ANAL, V3, P221, DOI 10.1109/TPAMI.1981.4767085; YAMADA H, 1993, IEEE T PATTERN ANAL, V15, P380, DOI 10.1109/34.206957; YANNAKOUDAKIS EJ, 1988, IEEE T PATTERN ANAL, V10, P960, DOI 10.1109/34.9119; Yu B, 1996, IEEE T PATTERN ANAL, V18, P1127, DOI 10.1109/34.544084; Yu YH, 1997, IEEE T PATTERN ANAL, V19, P868, DOI 10.1109/34.608290; Zramdini A, 1998, IEEE T PATTERN ANAL, V20, P877, DOI 10.1109/34.709616	99	310	333	6	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2000	22	1					38	62		10.1109/34.824820	http://dx.doi.org/10.1109/34.824820			25	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	286WR					2022-12-18	WOS:000085472300003
J	Heath, MD; Sarkar, S; Sanocki, T; Bowyer, KW				Heath, MD; Sarkar, S; Sanocki, T; Bowyer, KW			A robust visual method for assessing the relative performance of edge-detection algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						experimental comparison of algorithms; edge detector comparison; low level processing; performance evaluation; analysis of variance; human rating	NOISY IMAGES	A new method for evaluating edge detection algorithms is presented and applied to measure the relative performance of algorithms by Canny, Nalwa-Binford, Iverson-Zucker, Bergholm, and Rothwell. The basic measure of performance is a visual rating score which indicates the perceived quality of the edges for identifying an object. The process of evaluating edge detection algorithms with this performance measure requires the collection of a set of gray-scale images, optimizing the input parameters for each algorithm, conducting visual evaluation experiments and applying statistical analysis methods. The novel aspect of this work is the use of a visual task and real images of complex scenes in evaluating edge detectors. The method is appealing because, by definition, the results agree with visual evaluations of the edge images.	UNIV S FLORIDA,DEPT PSYCHOL,TAMPA,FL 33620	State University System of Florida; University of South Florida	Heath, MD (corresponding author), UNIV S FLORIDA,DEPT COMP SCI & ENGN,TAMPA,FL 33620, USA.		Sarkar, Sudeep/A-8213-2009; Sarkar, Sudeep/ABD-7629-2021	Sarkar, Sudeep/0000-0001-7332-4207; Sarkar, Sudeep/0000-0001-7332-4207; Bowyer, Kevin/0000-0002-7562-4390				ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325; BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9, P726, DOI 10.1109/TPAMI.1987.4767980; BOYER KL, 1992, SPIE, V1708, P353; Bryant D. J., 1979, Proceedings of the 1979 IEEE Computer Society Conference on Pattern Recognition and Image Processing, P138; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Cho K., 1996, IEEE INT S COMP VIS, P491, DOI 10.1109/ISCV.1995.477049; CHUANG ER, 1993, PATTERN RECOGN, V26, P1673, DOI 10.1016/0031-3203(93)90022-O; CINQUE L, 1994, CVGIP-IMAG UNDERSTAN, V60, P250, DOI 10.1006/cviu.1994.1056; FARAG AA, 1995, PATTERN RECOGN, V28, P611, DOI 10.1016/0031-3203(94)00131-5; FRAM JR, 1975, IEEE T COMPUT, VC 24, P616, DOI 10.1109/T-C.1975.224274; GOKMEN M, 1993, IEEE T PATTERN ANAL, V15, P492, DOI 10.1109/34.211469; GREGSON PH, 1993, IEEE T PATTERN ANAL, V15, P682, DOI 10.1109/34.221169; HEATH M, 1996, COMPUTER VISION PATT; HIGGINS WE, 1994, PATTERN RECOGN, V27, P277, DOI 10.1016/0031-3203(94)90059-0; IVERSON LA, 1995, IEEE T PATTERN ANAL, V17, P982, DOI 10.1109/34.464562; JIANG XY, 1995, P AS C COMP VIS, P415; KANUNGO T, 1995, IEEE T IMAGE PROCESS, V4, P1667, DOI 10.1109/83.475516; KEPPEL G, 1991, DESIGN ANAL; KITCHEN L, 1981, IEEE T SYST MAN CYB, V11, P597, DOI 10.1109/TSMC.1981.4308758; MINTZ D, 1994, CVGIP-IMAG UNDERSTAN, V59, P137, DOI 10.1006/ciun.1994.1009; Nalwa V. S., 1993, GUIDED TOUR COMPUTER; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; Palmer PL, 1996, COMPUT VIS IMAGE UND, V63, P476, DOI 10.1006/cviu.1996.0036; PARK DJ, 1995, PATTERN RECOGN, V28, P211, DOI 10.1016/0031-3203(94)00097-6; PARK DJ, 1994, PATTERN RECOGN, V27, P765, DOI 10.1016/0031-3203(94)90161-9; RAMESH V, 1992, SPIE, V1708, P252; RAO KR, 1994, IEEE T PATTERN ANAL, V16, P1169, DOI 10.1109/34.387490; Roberts L, 1965, MACHINE PERCEPTION 3; ROTHWELL CA, 1995, INT S COMP VIS COR G, P395; SARKAR S, 1991, CVGIP-IMAG UNDERSTAN, V54, P224, DOI 10.1016/1049-9660(91)90065-W; Shen J, 1995, PATTERN RECOGN, V28, P1871, DOI 10.1016/0031-3203(95)00056-9; SHEN J, 1995, PATTERN RECOGN, V28, P1159, DOI 10.1016/0031-3203(95)00005-K; SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420; Sobel I., 1970, CAMERA MODELS MACHIN; SRINIVASAN V, 1994, PATTERN RECOGN, V27, P1653, DOI 10.1016/0031-3203(94)90084-1; STRICKLAND RN, 1993, OPT ENG, V32, P944, DOI 10.1117/12.130263; TADROUS PJ, 1995, PATTERN RECOGN, V28, P1575, DOI 10.1016/0031-3203(95)00029-Y; TAN TN, 1995, PATTERN RECOGN, V28, P1283, DOI 10.1016/0031-3203(94)00017-G; THOMPSON WB, 1993, IEEE T PATTERN ANAL, V15; VANDERHEIJDEN F, 1995, IEEE T PATTERN ANAL, V17, P16, DOI 10.1109/34.368155; WALPOLE RE, 1985, PROBABILITY STATISTI, pCH11; ZHAN SM, 1994, CVGIP-IMAG UNDERSTAN, V59, P242, DOI 10.1006/cviu.1994.1018; ZHOU YT, 1989, IEEE T PATTERN ANAL, V11, P84, DOI 10.1109/34.23115; Zhu QM, 1996, IMAGE VISION COMPUT, V14, P21, DOI 10.1016/0262-8856(95)01036-X; ZIOU D, 1993, PATTERN RECOGN, V26, P1305, DOI 10.1016/0031-3203(93)90137-L	45	310	327	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1997	19	12					1338	1359		10.1109/34.643893	http://dx.doi.org/10.1109/34.643893			22	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YK781					2022-12-18	WOS:A1997YK78100003
J	Maio, D; Maltoni, D				Maio, D; Maltoni, D			Direct gray-scale minutiae detection in fingerprints	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fingerprints; minutiae; feature extraction; gray scale images; directional image	IMAGES; RECOGNITION; SYSTEM	Most automatic systems for fingerprint comparison are based on minutiae matching. Minutiae are essentially terminations and bifurcations of the ridge lines that constitute a fingerprint pattern. Automatic minutiae detection is an extremely critical process, especially in low-quality fingerprints where noise and contrast deficiency can originate pixel configurations similar to minutiae or hide real minutiae. Several approaches have been proposed in the literature; although rather different from each other, all these methods transform fingerprint images into binary images. In this work we propose an original technique, based on ridge line following, where the minutiae are extracted directly from gray scale images. The results achieved are compared with those obtained through some methods based on image binarization. In spite of a greater conceptual complexity, the method proposed performs better both in terms of efficiency and robustness.	UNIV BOLOGNA,DEIS,CSITE CNR,I-40136 BOLOGNA,ITALY; UNIV BOLOGNA,DEIS,I-47023 CESENA,ITALY	University of Bologna; University of Bologna	Maio, D (corresponding author), UNIV BOLOGNA,CORSO LAUREA SCI INFORMAZ,VIA SACCHI 3,I-47023 CESENA,ITALY.							*AM NAT STAND I, 1986, FING ID DAT FORM INF; ARCELLI C, 1985, IEEE T PATTERN ANAL, V7, P463, DOI 10.1109/TPAMI.1985.4767685; BARUCH O, 1988, PATTERN RECOGN LETT, V8, P271, DOI 10.1016/0167-8655(88)90034-7; BRESENHAM JE, 1965, IBM SYST J, V4, P25, DOI 10.1147/sj.41.0025; CHAPEL C, 1971, FINGERPRINTING MANUA; COETZEE L, 1993, PATTERN RECOGN, V26, P1441, DOI 10.1016/0031-3203(93)90151-L; DONAHUE MJ, 1993, CVGIP-IMAG UNDERSTAN, V57, P185, DOI 10.1006/ciun.1993.1012; DYER CR, 1979, IEEE T PATTERN ANAL, V1, P88, DOI 10.1109/TPAMI.1979.4766880; Galton Francis, 1892, FINGER PRINTS; GAMBLE FT, 1992, APPL OPTICS, V31, P652, DOI 10.1364/AO.31.000652; Henry ER., 1900, CLASSIFICATION USES; Hollingum J., 1992, Sensor Review, V12, P12, DOI 10.1108/eb007878; HUNG DCD, 1993, PATTERN RECOGN, V26, P1661, DOI 10.1016/0031-3203(93)90021-N; IGAKI S, 1992, APPL OPTICS, V31, P1794, DOI 10.1364/AO.31.001794; KAWAGOE M, 1984, PATTERN RECOGN, V17, P295, DOI 10.1016/0031-3203(84)90079-7; LEBOUCHER L, 1994, PATTERN RECOGN LETT, V15, P309, DOI 10.1016/0167-8655(94)90064-7; LEUNG MT, 1990, P 10 C COMP COMM SYS, P582; Leung WF, 1991, P IEEE WORKSH NEUR N, P226; LIN CH, 1982, J FORENSIC SCI, P290; MEHTRE B, 1986, P 2 INT C ADV PATT R; Mehtre B. M., 1993, Machine Vision and Applications, V6, P124, DOI 10.1007/BF01211936; MEHTRE BM, 1987, PATTERN RECOGN, V20, P429, DOI 10.1016/0031-3203(87)90069-0; MOAYER B, 1986, IEEE T PATTERN ANAL, V8, P376, DOI 10.1109/TPAMI.1986.4767798; Moenssens A.A., 1971, FINGERPRINT TECHNIQU; OGORMAN L, 1989, PATTERN RECOGN, V22, P29, DOI 10.1016/0031-3203(89)90035-6; Pernus F., 1980, Proceedings of the 5th International Conference on Pattern Recognition, P1380; SHERLOCK BG, 1992, ELECTRON LETT, V28, P1720, DOI 10.1049/el:19921093; SHERLOCK BG, 1994, P C VIS IM SIGN PROC, P87; Stock R.M., 1969, XM2478X11317 CORN AE; SZEKELY EN, 1993, MICROPROCESS MICROSY, V17, P215; VERMA MR, 1987, PATTERN RECOGN, V20, P513, DOI 10.1016/0031-3203(87)90078-1; WANG L, 1993, IEEE T PATTERN ANAL, V15, P1053, DOI 10.1109/34.254062; WANG L, 1993, CVGIP-IMAG UNDERSTAN, V58, P352, DOI 10.1006/ciun.1993.1047; Watson C. I., 1992, FINGERPRINT DATABASE; Weber D. M., 1992, Proceedings of the 1992 South African Symposium on Communications and Signal Processing. COMSIG '92 (Cat. No.92TH0482-0), P99, DOI 10.1109/COMSIG.1992.274304; Wegstein J.H., 1982, AUTOMATED FINGERPRIN; XIAO Q, 1991, PATTERN RECOGN, V24, P985, DOI 10.1016/0031-3203(91)90095-M	37	310	351	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1997	19	1					27	40		10.1109/34.566808	http://dx.doi.org/10.1109/34.566808			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WE528		Green Submitted			2022-12-18	WOS:A1997WE52800003
J	DECASTRO, E; MORANDI, C				DECASTRO, E; MORANDI, C			REGISTRATION OF TRANSLATED AND ROTATED IMAGES USING FINITE FOURIER-TRANSFORMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV ANCONA,DIPARTIMENTO ELETTRON & AUTOMAT,I-60100 ANCONA,ITALY	Marche Polytechnic University	DECASTRO, E (corresponding author), UNIV BOLOGNA,DIPARTIMENTO ELETTRON INFORMAT & SISTEMIST,VIALE RISORGIMENTO 2,I-40136 BOLOGNA,ITALY.							AGGARWAL JK, 1981, P IEEE, V69, P562, DOI 10.1109/PROC.1981.12025; AGGARWAL JK, 1983, IMAGE SEQUENCE PROCE, P40; ALLINEY S, 1986, IEEE T PATTERN ANAL, V8, P222, DOI 10.1109/TPAMI.1986.4767775; Cafforio C., 1983, P IM SEQ PROC DYN SC, P104; De Castro E., 1986, Advances in Image Processing and Pattern Recognition. Proceedings of the International Conference, P328; DECASTRO E, 1984, T ACCADEMIA SCI  APR; DECASTRO E, 1982, ATTI ACCADEMIA SC 13, V9, P233; Huang T.S., 1981, IMAGE SEQUENCE ANAL, P1; KUGLIN CD, 1975, 1975 P IEEE INT C CY, P163; Nagel H.-H., 1983, IMAGE SEQUENCE PROCE, P2; NAGEL HH, 1981, IMAGE SEQUENCE ANAL, P19; PAPOULIS A, 1968, SYSTEMS TRANSFORMS A; PEARSON JJ, P SPIE, V119, P197	13	310	365	3	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1987	9	5					700	703		10.1109/TPAMI.1987.4767966	http://dx.doi.org/10.1109/TPAMI.1987.4767966			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	J7393	21869430				2022-12-18	WOS:A1987J739300013
J	Weng, JY; Zhang, YL; Hwang, WS				Weng, JY; Zhang, YL; Hwang, WS			Candid covariance-free incremental principal component analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						principal component analysis; incremental principal component analysis; stochastic gradient ascent (SGA); generalized hebbian algorithm (GHA); orthogonal complement	RECOGNITION; APPEARANCE; NETWORK	Appearance-based image analysis techniques require fast computation of principal components of high-dimensional image vectors. We introduce a fast incremental principal component analysis (IPCA) algorithm, called candid covariance-free IPCA (CCIPCA), used to compute the principal components of a sequence of samples incrementally without estimating the covariance matrix (so covariance-free). The new method is motivated by the concept of statistical efficiency (the estimate has the smallest variance given the observed data). To do this, it keeps the scale of observations and computes the mean of observations incrementally, which is an efficient estimate for some well-known distributions (e.g., Gaussian), although the highest possible efficiency is not guaranteed in our case because of unknown sample distribution. The method is for real-time applications and, thus, it does not allow iterations. It converges very fast for high-dimensional image vectors. Some links between IPCA and the development of the cerebral cortex are also discussed.	Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Michigan State University	Weng, JY (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.							Chen SY, 2000, IEEE T NEURAL NETWOR, V11, P1300, DOI 10.1109/72.883430; Cui Y, 2000, COMPUT VIS IMAGE UND, V78, P157, DOI 10.1006/cviu.2000.0837; Fisz M., 1963, PROBABILITY THEORY M; Golub G. H., 1996, MATRIX COMPUTATIONS; Hertz J., 1991, INTRO THEORY NEURAL, DOI DOI 10.1201/9780429499661; Kandel E.R., 1991, PRINC NEUROSCI; Kreyszig E., 1988, ADV ENG MATH; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; OJA E, 1985, J MATH ANAL APPL, V106, P69, DOI 10.1016/0022-247X(85)90131-3; OJA E, 1983, SUBSPACE METHODS PAT; Owsley N. L., 1978, Proceedings of the 1978 IEEE International Conference on Acoustics, Speech and Signal Processing, P109; Phillips PJ, 1997, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.1997.609311; Press W. H., 1986, NUMERICAL RECIPES C; RUBNER J, 1990, BIOL CYBERN, V62, P193, DOI 10.1007/BF00198094; SANGER TD, 1989, NEURAL NETWORKS, V2, P459, DOI 10.1016/0893-6080(89)90044-0; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; THOMPSON PA, 1979, P 13 AS C CIRC SYST, P529; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WENG J, 2000, P 1 IEEE RAS INT C H; WENG J, 2000, P NSF DARPA WORKSH D; Weng J., 1993, MOTION STRUCTURE IMA; Zhang Y., 2001, MSUCSE0123 MICH STAT	22	308	347	2	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2003	25	8					1034	1040		10.1109/TPAMI.2003.1217609	http://dx.doi.org/10.1109/TPAMI.2003.1217609			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	702XJ		Green Submitted			2022-12-18	WOS:000184249800010
J	Latecki, LJ; Lakamper, R				Latecki, LJ; Lakamper, R			Shape similarity measure based on correspondence of visual parts	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape representation; shape similarity measure; visual parts; discrete curve evolution		A cognitively motivated similarity measure is presented and its properties are analyzed with respect to retrieval of similar objects in image databases of silhouettes of 2D objects. To reduce influence of digitization noise. as well as segmentation errors, the shapes are simplified by a novel process of digital curve evolution. To compute our similarity measure, we first establish the best possible correspondence of visual parts (without explicitly computing the visual parts). Then, the similarity between corresponding parts is computed and aggregated. We applied our similarity measure to shape matching of object contours in various image databases and compared it to well-known approaches in the literature. The experimental results justify that our shape matching procedure gives an intuitive shape correspondence and is stable with respect to noise distortions.	Univ Hamburg, Dept Math Appl, D-20146 Hamburg, Germany	University of Hamburg	Latecki, LJ (corresponding author), Univ Hamburg, Dept Math Appl, Bundesstr 55, D-20146 Hamburg, Germany.			Latecki, Longin Jan/0000-0002-5102-8244				ARKIN EM, 1991, IEEE T PATTERN ANAL, V13, P209, DOI 10.1109/34.75509; Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1; Hoffman DD, 1997, COGNITION, V63, P29, DOI 10.1016/S0010-0277(96)00791-3; HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Latecki L. J., 2000, P IEEE C COMP VIS PA; Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738; LATECKI LJ, 1999, SCAL SPAC THEOR COMP; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; MOKHTARIAN F, 1997, IMAGE DATABASES MULT, P51, DOI DOI 10.1142/9789812797988_; Sclaroff S, 1997, PATTERN RECOGN, V30, P627, DOI 10.1016/S0031-3203(96)00108-2; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; Siddiqi K, 1996, PERCEPTION, V25, P399, DOI 10.1068/p250399	13	308	334	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2000	22	10					1185	1190		10.1109/34.879802	http://dx.doi.org/10.1109/34.879802			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	369LQ					2022-12-18	WOS:000165067100012
J	CHRISTMAS, WJ; KITTLER, J; PETROU, M				CHRISTMAS, WJ; KITTLER, J; PETROU, M			STRUCTURAL MATCHING IN COMPUTER VISION USING PROBABILISTIC RELAXATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						MATCHING; PROBABILISTIC RELAXATION; OBJECT RECOGNITION	OBJECT RECOGNITION; 3-D OBJECTS; REPRESENTATION; OPTIMIZATION; IMAGES	In this paper, we develop the theory of probabilistic relaxation for matching features extracted from 2D images, derive as limiting cases the various heuristic formulae used by researchers in matching problems, and state the conditions under which they apply. We successfully apply our theory to the problem of matching and recognizing aerial road network images based on road network models and to the problem of edge matching in a stereo pair. For this purpose, each line network is represented by an attributed relational graph where each node is a straight line segment characterized by certain attributes and related with every other node via a set of binary relations.			CHRISTMAS, WJ (corresponding author), UNIV SURREY,DEPT ELECTR & ELECT ENGN,VIS SPEECH & SIGNAL PROC GRP,GUILDFORD GU2 5XH,SURREY,ENGLAND.			Christmas, William/0000-0002-6796-3536				ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; BAIRD HS, 1985, MODEL BASED IMAGE MA; Ballard D.H., 1982, COMPUTER VISION; BEVERIDGE JR, 1992, C COMPUTER VISION PA, P432; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P137, DOI 10.1109/TPAMI.1984.4767499; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P340, DOI 10.1109/TPAMI.1984.4767527; BIENENSTOCK E, 1988, NEURAL INFORMATION P, P211; Blake A, 1983, PATTERN RECOGN LETT, V1, P393, DOI 10.1016/0167-8655(83)90077-6; BOLLES RC, 1979, P SOC PHOTOOPT INSTR, V182, P140; BOYER KL, 1988, IEEE T PATTERN ANAL, V10, P144, DOI 10.1109/34.3880; CASS T, 1992, 2 EUR C COMP VIS, P834; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; FAUGERAS OD, 1981, IEEE T PATTERN ANAL, V3, P412, DOI 10.1109/TPAMI.1981.4767127; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GHARHAMAN DE, 1980, IEEE T SYST MAN CYB, V10, P181; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; HANCOCK ER, 1990, IEEE T PATTERN ANAL, V12, P165, DOI 10.1109/34.44403; HOPFIELD JJ, 1984, P NATL ACAD SCI-BIOL, V81, P3088, DOI 10.1073/pnas.81.10.3088; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; KIRBY RL, 1980, COMPUT VISION GRAPH, V13, P158, DOI 10.1016/S0146-664X(80)80038-4; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; KITTLER J, 1986, COMPUT VISION GRAPH, V34, P257, DOI 10.1016/S0734-189X(86)80041-X; Kittler J., 1989, International Journal of Pattern Recognition and Artificial Intelligence, V3, P29, DOI 10.1142/S021800148900005X; KOCH C, 1986, P NATL ACAD SCI USA, V83, P4263, DOI 10.1073/pnas.83.12.4263; LI SZ, 1992, PATTERN RECOGN, V25, P583, DOI 10.1016/0031-3203(92)90075-T; LI SZQ, 1993, OPT ENG, V32, P1213, DOI 10.1117/12.134184; PELEG S, 1980, IEEE T PATTERN ANAL, V2, P362, DOI 10.1109/TPAMI.1980.4767035; PETROU M, 1993, IEE PROC-I, V140, P331, DOI 10.1049/ip-i-2.1993.0049; RADIG B, 1984, PATTERN RECOGN, V17, P161, DOI 10.1016/0031-3203(84)90043-8; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144; STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785; ULLMAN S, 1979, COMPUT VISION GRAPH, V10, P115, DOI 10.1016/0146-664X(79)90045-5; VAIDYA NM, C COMPUTER VISION PA, P76; WELLS WM, 1991, C COMPUTER VISION PA, P486; WITKIN A, 1987, INT J COMPUT VISION, V1, P133, DOI 10.1007/BF00123162; YAMAMOTO K, 1979, COMPUTER GRAPHICS IM, V10, P256; YANG B, 1989, IMAGE VISION COMPUT, V7, P135, DOI 10.1016/0262-8856(89)90008-5; ZUCKER S, 1978, IEEE PRIP C CHICAGO, P167; [No title captured]	44	308	332	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1995	17	8					749	764		10.1109/34.400565	http://dx.doi.org/10.1109/34.400565			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RL035					2022-12-18	WOS:A1995RL03500002
J	Sivic, J; Zisserman, A				Sivic, Josef; Zisserman, Andrew			Efficient Visual Search of Videos Cast as Text Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object recognition; viewpoint and scale invariance; text retrieval	RECOGNITION	We describe an approach to object retrieval that searches for and localizes all of the occurrences of an object in a video, given a query image of the object. The object is represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination, and partial occlusion. The temporal continuity of the video within a shot is used to track the regions in order to reject those that are unstable. Efficient retrieval is achieved by employing methods from statistical text retrieval, including inverted file systems, and text and document frequency weightings. This requires a visual analogy of a word, which is provided here by vector quantizing the region descriptors. The final ranking also depends on the spatial layout of the regions. The result is that retrieval is immediate, returning a ranked list of shots in the manner of Google [6]. We report results for object retrieval on the full-length feature films "Groundhog Day," "Casablanca," and " Run Lola Run," including searches from within the movie and specified by external images downloaded from the Internet. We investigate retrieval performance with respect to different quantizations of region descriptors and compare the performance of several ranking measures. Performance is also compared to a baseline method implementing standard frame to frame matching.	[Sivic, Josef] Ecole Normale Super, Lab Informat, WILLOW Project Team, CNRS ENS INRIA UMR 8548, F-75230 Paris 05, France; [Zisserman, Andrew] Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England	UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS); University of Oxford	Sivic, J (corresponding author), Ecole Normale Super, Lab Informat, WILLOW Project Team, CNRS ENS INRIA UMR 8548, 45 Rue Ulm, F-75230 Paris 05, France.	josef@di.ens.fr; az@robots.ox.ac.uk			Mathematical and Physical Sciences Division, University of Oxford; EC Project Vibes	Mathematical and Physical Sciences Division, University of Oxford; EC Project Vibes	The authors are very grateful for suggestions from and discussions with Mike Brady, Alyosha Efros, Michael Isard, Joe Levy, and David Lowe. They would like to thank James Philbin for developing the user interface. This work was funded by the Mathematical and Physical Sciences Division, University of Oxford and EC Project Vibes. This work was carried out while Josef Sivic was with the Department of Engineering at the University of Oxford.	Aherne FJ, 1998, KYBERNETIKA, V34, P363; Awais M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.60; Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463; Baumberg A, 2000, PROC CVPR IEEE, P774, DOI 10.1109/CVPR.2000.855899; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Brin S., 1998, P PAP PRES 7 INT WOR; Carmichael O, 2004, IEEE T PATTERN ANAL, V26, P1537, DOI 10.1109/TPAMI.2004.128; CHUM O., 2007, P INT C COMP VIS; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Ferrari V, 2004, LECT NOTES COMPUT SC, V3021, P40; GRAUMAN K, 2005, P INT C COMP VIS OCT, V1, P357; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Lafferty John, 2001, P 24 ANN INT ACM SIG, P111, DOI DOI 10.1145/383952.383970; Lepetit V, 2005, PROC CVPR IEEE, P775; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Lindeberg T, 1994, P 3 EUR C COMP VIS, P389; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lowe DG, 2001, PROC CVPR IEEE, P682; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2003, PROC CVPR IEEE, P257; MIKOLAJCZYK K, 2002, P ECCV, V1, P128; NISTER D, 2006, P IEEE C COMP VIS PA, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; OBDRZALEK S, 2005, P BRIT MACH VIS C; OBDRZALEK S, 2002, P BRIT MACH VIS C, P113; OGILVIE P, 2002, P IN EV XML RETR WOR; Philbin J, 2007, CVPR; Pilet J, 2005, PROC CVPR IEEE, P822, DOI 10.1109/CVPR.2005.293; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Richardson SL, 2006, DIAM RELAT MATER, V15, P707, DOI 10.1016/j.diamond.2005.12.043; Rothganger F, 2004, PROC CVPR IEEE, P914; Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414; Schaffalitzky F, 2003, COMPUT VIS IMAGE UND, V92, P236, DOI 10.1016/j.cviu.2003.06.008; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; SILPAANAN C, 2004, P AUSTR C ROB AUT; Sivic J, 2005, LECT NOTES COMPUT SC, V3568, P226; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Sivic J, 2006, INT J COMPUT VISION, V67, P189, DOI 10.1007/s11263-005-4264-y; Squire DM, 2000, PATTERN RECOGN LETT, V21, P1193, DOI 10.1016/S0167-8655(00)00081-7; TELL D, 2002, P 7 EUR C COMP VIS C, P68; Tuytelaars T., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P412; Varma M, 2004, IMAGE VISION COMPUT, V22, P1175, DOI 10.1016/j.imavis.2004.03.012; Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4; Witten I.H., 1999, MORGAN KAUFMANN SERI	44	307	329	0	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2009	31	4					591	606		10.1109/TPAMI.2008.111	http://dx.doi.org/10.1109/TPAMI.2008.111			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	407WX	19229077	Green Submitted			2022-12-18	WOS:000263396100002
J	Mian, AS; Bennamoun, M; Owens, R				Mian, Ajmal S.; Bennamoun, Mohammed; Owens, Robyn			An efficient multimodal 2D-3D hybrid approach to automatic face recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						biometrics; face recognition; rejection classifier; 3D shape representation	3D	We present a fully automatic face recognition algorithm and demonstrate its performance on the FRGC v2.0 data. Our algorithm is multimodal (2D and 3D) and performs hybrid ( feature based and holistic) matching in order to achieve efficiency and robustness to facial expressions. The pose of a 3D face along with its texture is automatically corrected using a novel approach based on a single automatically detected point and the Hotelling transform. A novel 3D Spherical Face Representation (SFR) is used in conjunction with the Scale-Invariant Feature Transform ( SIFT) descriptor to form a rejection classifier, which quickly eliminates a large number of candidate faces at an early stage for efficient recognition in case of large galleries. The remaining faces are then verified using a novel region-based matching approach, which is robust to facial expressions. This approach automatically segments the eyes-forehead and the nose regions, which are relatively less sensitive to expressions and matches them separately using a modified Iterative Closest Point (ICP) algorithm. The results of all the matching engines are fused at the metric level to achieve higher accuracy. We use the FRGC benchmark to compare our results to other algorithms that used the same database. Our multimodal hybrid algorithm performed better than others by achieving 99.74 percent and 98.31 percent verification rates at a 0.001 false acceptance rate ( FAR) and identification rates of 99.02 percent and 95.37 percent for probes with a neutral and a nonneutral expression, respectively.	Univ Western Australia, Sch Comp Sci & Software Engn, Crawley, WA 6009, Australia	University of Western Australia	Mian, AS (corresponding author), Univ Western Australia, Sch Comp Sci & Software Engn, 35 Stirling Highway, Crawley, WA 6009, Australia.	ajmal@csse.uwa.edu.au; bennamou@csse.uwa.edu.au; robyn.owens@uwa.edu.au	Bennamoun, Mohammed/C-2789-2013; Mian, Ajmal/A-9474-2008	Bennamoun, Mohammed/0000-0002-6603-3257; Mian, Ajmal/0000-0002-5206-3842				ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; Baker S, 1996, PROC CVPR IEEE, P544, DOI 10.1109/CVPR.1996.517125; Bartlett MS, 1998, P SOC PHOTO-OPT INS, V3299, P528, DOI 10.1117/12.320144; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005; Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y; CHANG K, 2003, P ACM WORKSH MULT US, P25; Chang K., 2005, P IEEE WORKSH FAC RE; Chang KI, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P187; Chin-Seng Chua, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P233, DOI 10.1109/AFGR.2000.840640; Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186; Cox IJ, 1996, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.1996.517076; Gonzalez R C, 1992, DIGITAL IMAGE PROCES; HUANG J, 2003, P INT C AUD VID BAS; HUSKEN M, 2005, P IEEE WORKSH REC GR; Jain A, 2000, COMMUN ACM, V43, P90, DOI 10.1145/328236.328110; Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; KOVESI P., 2006, MATLAB OCTAVE FUNCTI; LANITIS A, 1995, IMAGE VISION COMPUT, V13, P393, DOI 10.1016/0262-8856(95)99726-H; Lin D., 2006, 2006 IEEE COMP SOC C, P1355; Liu CJ, 2000, IEEE T PATTERN ANAL, V22, P570, DOI 10.1109/34.862196; LOWE D, 2006, DEMO SOFTWARE SIFT; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15; MAURER T, 2005, P IEEE WORKSH FAC RE; Medioni G, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P232; MIAN A, 2006, P 3 INT S 3D DAT PRO; Mian AS, 2006, IEEE T PATTERN ANAL, V28, P1584, DOI 10.1109/TPAMI.2006.213; MIAN AS, 2006, P BRIT MACH VISION C, V66, P19; MIAN AS, 2006, P EUROP C COM VIS, V3, P344; *MIN 3D DIG, 2006, NON CONT 3D LAS SCAN; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; PASSALIS G, 2005, P IEEE WORKSH FAC RE; PENTLAND A, 1994, P IEEE COMP VIS PATT; PHILLIPS PJ, 2005, P IEEE COMPUTER VISO; PHILLIPS PJ, 1998, C ADV NEUR INF PROCE, V11, P803; PHILLIPS PJ, 2006, P INT C AUT FAC GEST; SAMARIA F, 1994, IMAGE VISION COMPUT, V12, P537, DOI 10.1016/0262-8856(94)90007-8; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; WANG Y, 2001, P INT C AUD VID BAS, P26; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; Xu CH, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P308; YAN P, 2004, P IEEE COMP VIS PAT, P308; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	47	307	324	0	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2007	29	11					1927	1943		10.1109/TPAMI.2007.1105	http://dx.doi.org/10.1109/TPAMI.2007.1105			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	208UE	17848775				2022-12-18	WOS:000249343900005
J	Xu, C; Tao, DC; Xu, C				Xu, Chang; Tao, Dacheng; Xu, Chao			Multi-View Intact Space Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-view learning; robust algorithms	BREAKDOWN POINTS; COVERING NUMBER; REGULARIZATION	It is practical to assume that an individual view is unlikely to be sufficient for effective multi-view learning. Therefore, integration of multi-view information is both valuable and necessary. In this paper, we propose the Multi-view Intact Space Learning (MISL) algorithm, which integrates the encoded complementary information in multiple views to discover a latent intact representation of the data. Even though each view on its own is insufficient, we show theoretically that by combing multiple views we can obtain abundant information for latent intact space learning. Employing the Cauchy loss (a technique used in statistical learning) as the error measurement strengthens robustness to outliers. We propose a new definition of multi-view stability and then derive the generalization error bound based on multi-view stability and Rademacher complexity, and show that the complementarity between multiple views is beneficial for the stability and generalization. MISL is efficiently optimized using a novel Iteratively Reweight Residuals (IRR) technique, whose convergence is theoretically analyzed. Experiments on synthetic data and real-world datasets demonstrate that MISL is an effective and promising algorithm for practical applications.	[Xu, Chang; Xu, Chao] Peking Univ, Minist Educ, Key Lab Machine Percept, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China; [Tao, Dacheng] Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, Ultimo, NSW 2007, Australia; [Tao, Dacheng] Univ Technol Sydney, Fac Engn & Informat Technol, Ultimo, NSW 2007, Australia	Peking University; University of Technology Sydney; University of Technology Sydney	Xu, C (corresponding author), Peking Univ, Minist Educ, Key Lab Machine Percept, Beijing 100871, Peoples R China.	xuchang@pku.edu.cn; dacheng.tao@uts.edu.au; xuchao@cis.pku.edu.cn	Xu, Chang/AAG-9337-2019	Xu, Chang/0000-0002-4756-0609	Australian Research Council [FT-130101457, DP-140102164]; NSFC [61375026, 2015BAF15B00]; JCYJ [20120614152136201]	Australian Research Council(Australian Research Council); NSFC(National Natural Science Foundation of China (NSFC)); JCYJ	The authors would like to thank the Associate Editor and all anonymous reviewers for their positive support and constructive comments for improving the quality of this paper. The work was supported in part by Australian Research Council Projects FT-130101457 and DP-140102164, NSFC 61375026, 2015BAF15B00 and JCYJ 20120614152136201. The authors Chang Xu and Dacheng Tao have contributed equally to the paper. Dacheng Tao is the corresponding author of the article.	Abney S, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P360; Akaho S, 2006, CS0609071 ARXIV; Ando R.K, 2007, P INT C MACH LEARN; Archambeau C., 2009, ADV NEURAL INFORM PR, P73; Bach F.R., 2004, P INT C MACH LEARN; Bach F. R., 2005, 688 TR U CAL DEP STA; Balcan M.-F., 2004, NIPS, P89; Bartlett P. L., 2003, Journal of Machine Learning Research, V3, P463, DOI 10.1162/153244303321897690; Bickel S., 2004, P INT C DAT MIN, V36; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Chaudhuri K., 2009, P INT C MACH LEARN; Chen N, 2012, IEEE T PATTERN ANAL, V34, P2365, DOI 10.1109/TPAMI.2012.64; Gonen M, 2011, J MACH LEARN RES, V12, P2211; Gui J, 2014, IEEE T IMAGE PROCESS, V23, P3126, DOI 10.1109/TIP.2014.2326001; He XM, 2000, BIOMETRIKA, V87, P675, DOI 10.1093/biomet/87.3.675; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Jia Y., 2010, NIPS, V10, P982; Kakade SM, 2007, LECT NOTES COMPUT SC, V4539, P82, DOI 10.1007/978-3-540-72927-3_8; Kontorovich L, 2008, ANN PROBAB, V36, P2126, DOI 10.1214/07-AOP384; Kumar A., 2011, ADV NEURAL INFORM PR, P1413; Kumar A, 2010, NIPS 2010 WORKSH NEW; Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302; Luo Y, 2013, IEEE T NEUR NET LEAR, V24, P709, DOI 10.1109/TNNLS.2013.2238682; Memisevic R, 2012, IEEE T PATTERN ANAL, V34, P778, DOI 10.1109/TPAMI.2011.154; Mizera I, 2002, STAT PROBABIL LETT, V57, P79, DOI 10.1016/S0167-7152(02)00057-3; Muslea I., 2002, INT C MACH LEARN, VVolume 2, P435; Muslea I, 2006, J ARTIF INTELL RES, V27, P203, DOI 10.1613/jair.2005; Nigam K., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P86, DOI 10.1145/354756.354805; Ning F, 2005, IEEE T IMAGE PROCESS, V14, P1360, DOI 10.1109/TIP.2005.852470; Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491; Rey W., 1983, INTRO ROBUST QUASIRO, V983; Salzmann Mathieu, 2010, P 13 INT C ART INT S, P701; Shon A.P., 2005, P ADV NEUR INF PROC, P1233; Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130; Sindhwani V., 2005, P WORKSH LEARN MULT; Singer I., 2007, DUALITY NONCONVEX AP; Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531; Soomro K., 2012, CRCVTR1201; VOSS H, 1980, COMPUTING, V25, P243, DOI 10.1007/BF02242002; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang W., 2013, P AS C MACH LEARN CA, P467; Wang W., 2010, P INT C MACH LEARN; Wang W, 2007, LECT NOTES ARTIF INT, V4701, P454; Wang XC, 2013, IEEE T IMAGE PROCESS, V22, P2646, DOI 10.1109/TIP.2013.2255300; Wang YH, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366184; White M, 2012, P ADV NEUR INF PROC, P1682; Xu C., 2013, ARXIV; Xu C., 2013, P 5 INT C INTERNET M, P7; Xu C, 2014, IEEE T PATTERN ANAL, V36, P1559, DOI 10.1109/TPAMI.2013.2296528; Xu Z., 2010, P INT C MACH LEARN; Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377; Yu SP, 2011, J MACH LEARN RES, V12, P2649; Zhang T, 2002, J MACH LEARN RES, V2, P527, DOI 10.1162/153244302760200713; Zhou DX, 2002, J COMPLEXITY, V18, P739, DOI 10.1006/jcom.2002.0635; Zhou ZH, 2005, IEEE T KNOWL DATA EN, V17, P1529, DOI 10.1109/TKDE.2005.186	59	306	315	8	87	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2015	37	12					2531	2544		10.1109/TPAMI.2015.2417578	http://dx.doi.org/10.1109/TPAMI.2015.2417578			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CW2OK	26539856	Green Submitted			2022-12-18	WOS:000364831700014
J	Hinterstoisser, S; Cagniart, C; Ilic, S; Sturm, P; Navab, N; Fua, P; Lepetit, V				Hinterstoisser, Stefan; Cagniart, Cedric; Ilic, Slobodan; Sturm, Peter; Navab, Nassir; Fua, Pascal; Lepetit, Vincent			Gradient Response Maps for Real-Time Detection of Textureless Objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; real-time detection and object recognition; tracking; multimodality template matching		We present a method for real-time 3D object instance detection that does not require a time-consuming training stage, and can handle untextured objects. At its core, our approach is a novel image representation for template matching designed to be robust to small image transformations. This robustness is based on spread image gradient orientations and allows us to test only a small subset of all possible pixel locations when parsing the image, and to represent a 3D object with a limited set of templates. In addition, we demonstrate that if a dense depth sensor is available we can extend our approach for an even better performance also taking 3D surface normal orientations into account. We show how to take advantage of the architecture of modern computers to build an efficient but very discriminant representation of the input images that can be used to consider thousands of templates in real time. We demonstrate in many experiments on real data that our method is much faster and more robust with respect to background clutter than current state-of-the-art methods.	[Hinterstoisser, Stefan; Cagniart, Cedric; Ilic, Slobodan; Navab, Nassir] Tech Univ Munich, Dept Comp Aided Med Procedures CAMP, D-85478 Garching, Germany; [Sturm, Peter] INRIA Grenoble Rhone Alpes, STEEP Team, F-38334 Saint Ismier, France; [Fua, Pascal; Lepetit, Vincent] Ecole Polytech Fed Lausanne, Comp Vis Lab CVLAB, CH-1015 Lausanne, Switzerland	Technical University of Munich; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Hinterstoisser, S (corresponding author), Tech Univ Munich, Dept Comp Aided Med Procedures CAMP, D-85478 Garching, Germany.	hinterst@in.tum.de; cagniart@in.tum.de; Slobodan.Ilic@in.tum.de; Peter.Sturm@inrialpes.fr; navab@in.tum.de; pascal.fua@epfl.ch; vincent.lepetit@epfl.ch	Peters, Terry M/K-6853-2013	Peters, Terry M/0000-0003-1440-7488; Ilic, Slobodan/0000-0002-3413-1936; Fua, Pascal/0000-0002-6702-9970	BMBF [01IM08002]; Alexander-von-Humboldt Foundation	BMBF(Federal Ministry of Education & Research (BMBF)); Alexander-von-Humboldt Foundation(Alexander von Humboldt Foundation)	The authors thank Stefan Holzer and Kurt Konolige for the useful discussions and their valuable suggestions. This project was funded by the BMBF project AVILUSplus (01IM08002). P. Sturm is grateful to the Alexander-von-Humboldt Foundation for a Research Fellowship supporting his sabbatical at TU Munchen. Nassir Navab and Vincent Lepetit are joint senior authors of this paper.	Amit Y, 2004, IEEE T PATTERN ANAL, V26, P1606, DOI 10.1109/TPAMI.2004.111; Blake G, 2009, IEEE SIGNAL PROC MAG, V26, P26, DOI 10.1109/MSP.2009.934110; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; BOSCH A., 2007, P IEEE INT C COMP VI; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Dalal N., 2005, HISTOGRAMS ORIENTED; Enzweiler M., 2010, P IEEE C COMP VIS PA; Ess A., 2007, P IEEE INT C COMP VI; FERGUS R, 2006, INT J COMPUTER VISIO; FERRARI V, 2009, INT J COMPUTER VISIO; Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7; GAVRILA DM, 1999, P IEEE INT C COMP VI; Hinterstoisser S., 2010, P IEEE C COMP VIS PA; Hinterstoisser S., 2011, P IEEE INT C C UNPUB; Hinterstoisser S, 2011, INT J COMPUT VISION, V91, P107, DOI 10.1007/s11263-010-0379-x; Holzer S., 2009, P IEEE C COMP VIS PA; Huang C., 2005, P IEEE C COMP VIS PA; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Kalal Z., 2010, P IEEE C COMP VIS PA; Liebelt J., 2010, P IEEE C COMP VIS PA; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Muja M, 2011, IEEE INT CONF ROBOT; Ozuysal M, 2010, IEEE T PATTERN ANAL, V32, P448, DOI 10.1109/TPAMI.2009.23; Olson CF, 1997, IEEE T IMAGE PROCESS, V6, P103, DOI 10.1109/83.552100; Ozuysal M., 2009, P IEEE C COMP VIS PA; Rucklidge WJ, 1997, INT J COMPUT VISION, V24, P251, DOI 10.1023/A:1007975324482; Stark M., 2010, P BRIT MACH VIS C; Steger C., 2002, INT ARCH PHOT REM SE, V34; Su H., 2009, P IEEE INT C COMP VI; Sun M., 2010, P EUR C COMP VIS; Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77; Viola P., 2003, P IEEE C COMP VIS PA; Wojek C., 2009, P IEEE C COMP VIS PA	33	306	337	8	54	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2012	34	5					876	888		10.1109/TPAMI.2011.206	http://dx.doi.org/10.1109/TPAMI.2011.206			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	911VJ	22442120	Green Submitted			2022-12-18	WOS:000301747400004
J	Zitnick, CL; Kanade, T				Zitnick, CL; Kanade, T			A cooperative algorithm for stereo matching and occlusion detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						stereo vision; occlusion detection; 3D vision	BINOCULAR STEREO	This paper presents a stereo algorithm for obtaining disparity maps with occlusion explicitly detected. To produce smooth and detailed disparity maps, two assumptions that were originally proposed by Marr and Poggio are adopted: uniqueness and continuity. That is, the disparity maps have a unique value per pixel and are continuous almost everywhere. These assumptions are enforced within a three-dimensional array of match Values in disparity space. Each match value corresponds to a pixel in an image and a disparity relative to another image. An iterative algorithm updates the match values by diffusing support among neighboring values and inhibiting others along similar lines of sight. By applying the uniqueness assumption, occluded regions can be explicitly identified. To demonstrate the effectiveness of the algorithm, we present the processing results from synthetic and real image pairs, including ones with ground-truth values for quantitative comparison with other methods.	Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Zitnick, CL (corresponding author), Carnegie Mellon Univ, Inst Robot, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	clz@cs.cmu.edu; tk@cs.cmu.edu						BAKER HH, 1981, P 7 INT JOINT C ART, P631; Barnard S.T., 1987, ENCY ARTIFICIAL INTE, P1083; BELHUMEUR PN, 1992, P IEEE C COMP VIS PA; Boykov Y, 1998, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.1998.698673; Collins RT, 1996, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.1996.517097; FORSTNER W, 1986, PATTERN RECOGN, V2, P57; Fua P., 1993, Machine Vision and Applications, V6, P35, DOI 10.1007/BF01212430; GEIGER D, 1995, INT J COMPUT VISION, V14, P211, DOI 10.1007/BF01679683; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; INTILLE S, 1994, P EUR C COMP VIS, V801, P179; KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690; LLOYD SA, 1987, COMPUT VISION GRAPH, V39, P202, DOI 10.1016/S0734-189X(87)80166-4; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARR D, 1976, SCIENCE, V194, P209; Moravec H, 1996, PERCEPTION; Mori K., 1973, COMPUT GRAPHICS IMAG, V2, P393; Nakamura Y, 1996, PROC CVPR IEEE, P371, DOI 10.1109/CVPR.1996.517099; Nishihara H.K., 1984, P 1 INT S ROB RES CA, P489; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; PANTON DJ, 1978, PHOTOGRAMM ENG REM S, V44, P1499; POGGIO T, 1999, COMMUNICATION    AUG; POLLARD SB, 1985, PERCEPTION, V14, P449, DOI 10.1068/p140449; PRAZDNY K, 1985, BIOL CYBERN, V52, P93, DOI 10.1007/BF00363999; Scharstein D, 1998, INT J COMPUT VISION, V28, P155, DOI 10.1023/A:1008015117424; SZELISKI R, 1999, P VIS ALG 99 WORKSH; WOOD GA, 1983, PHOTOGRAMM ENG REM S, V49, P537; Yagi, 1973, COMPUT VISION GRAPH, V2, P131; Zitnick C. L., 1998, CMURI9830; [No title captured]	30	305	344	1	51	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2000	22	7					675	684		10.1109/34.865184	http://dx.doi.org/10.1109/34.865184			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	347LV		Green Submitted			2022-12-18	WOS:000088931800003
J	DERICHE, R				DERICHE, R			FAST ALGORITHMS FOR LOW-LEVEL VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											DERICHE, R (corresponding author), INST NATL RECH INFORMAT & AUTOMAT,2004 ROUTE LUCIOLES,F-06565 VALBONNE,FRANCE.		Deriche, Rachid/AAM-9869-2021	Deriche, Rachid/0000-0002-4643-8417				BURT PJ, 1983, COMPUT VISION GRAPH, V21, P368, DOI 10.1016/S0734-189X(83)80049-8; CANNY JF, 1983, MIT720 TEFCH REP; CHEN JS, 1987, IEEE T PATTERN ANAL, V9, P584, DOI 10.1109/TPAMI.1987.4767946; CROWLEY JL, 1984, IEEE T PATTERN ANAL, V6, P156, DOI 10.1109/TPAMI.1984.4767500; DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164; DERICHE R, 1987, FEB P INT WORKSH MAC, P18; DERICHE R, 1987, 1ST P INT C COMP VIS; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; SHEN J, 1986, P CVPR, P10; THURSTON M, 1971, IEEE T COMPUTERS C, V20, P562; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P187; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729	14	305	316	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1990	12	1					78	87		10.1109/34.41386	http://dx.doi.org/10.1109/34.41386			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CG247					2022-12-18	WOS:A1990CG24700008
J	FLETCHER, LA; KASTURI, R				FLETCHER, LA; KASTURI, R			A ROBUST ALGORITHM FOR TEXT STRING SEPARATION FROM MIXED TEXT GRAPHICS IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PENN STATE UNIV,DEPT ELECT ENGN,UNIVERSITY PK,PA 16802	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park			Fletcher, Lloyd/G-2845-2010	Fletcher, Lloyd/0000-0002-3213-3815				BLEY H, 1984, COMPUT VISION GRAPH, V28, P271, DOI 10.1016/S0734-189X(84)80008-0; CHEN WH, 1980, P IEEE, V68, P786; FLETCHER LA, 1986, THESIS PENNSYLVANIA; FOITH JP, 1981, DIGITAL IMAGE PROCES; Huang C. L., 1986, Proceedings of the SPIE - The International Society for Optical Engineering, V635, P288, DOI 10.1117/12.964142; KARIMA M, 1985, IEEE COMPUT GRAPHICS, V5, P24; PRATT WK, 1978, DIGITAL IMAGE PROCES, P523; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2; SLATER RN, 1984, COMPUT GRAPHICS WORL, V48, P45; WAHL FM, 1982, COMPUT VISION GRAPH, V20, P375, DOI 10.1016/0146-664X(82)90059-4; WATSON LT, 1984, PATTERN RECOGN, V17, P493, DOI 10.1016/0031-3203(84)90047-5; WONG KY, 1982, IBM J RES DEV, V6, P642; [No title captured]	13	305	346	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1988	10	6					910	918		10.1109/34.9112	http://dx.doi.org/10.1109/34.9112			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q9971					2022-12-18	WOS:A1988Q997100012
J	Davison, AJ; Murray, DW				Davison, AJ; Murray, DW			Simultaneous localization and map-building using active vision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						active vision; simultaneous localization and map-building; mobile robots		An active approach to sensing can provide the focused measurement capability over a wide field of view which allows correctly formulated Simultaneous Localization and Map-Building (SLAM) to be implemented with vision, permitting repeatable long-term localization using only naturally occurring, automatically-detected features. In this paper, we present the first example of a general system for autonomous localization using active vision, enabled here by a high-performance stereo head, addressing such issues as uncertainty-based measurement selection, automatic map-maintenance, and goal-directed steering. We present varied real-time experiments in a complex environment.	Univ Oxford, Dept Engn Sci, Robot Res Grp, Oxford OX1 3PJ, England	University of Oxford	Davison, AJ (corresponding author), Univ Oxford, Dept Engn Sci, Robot Res Grp, Oxford OX1 3PJ, England.	ajd@robots.ox.ac.uk; dwm@robots.ox.ac.uk						Ayache N, 1991, ARTIFICIAL VISION MO; BEARDSLEY PA, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P58, DOI 10.1109/ICCV.1995.466806; BOUGT JY, 1995, ICCV5, P645; CASTELLANOS JA, 1998, THESIS U ZARAGOZA SP; CHIUSO A, 2000, P 6 EUR C COMP VIS; Chong KS, 1999, INT J ROBOT RES, V18, P3; Davison AJ, 2001, ROBOT AUTON SYST, V36, P171, DOI 10.1016/S0921-8890(01)00141-5; DAVISON AJ, 1998, P 5 EUR C COMP VIS F, P809; DAVISON AJ, 2000, P IEEE RSJ C INT ROB; DAVISON AJ, 1998, THESIS U OXFORD; DURRANTWHYTE H, 1994, IND ROBOT, V21, P11, DOI 10.1108/EUM0000000004145; DURRANTWHYTE HF, 1999, P 9 INT S ROB RES SN, P121; Grossman CRS, 1999, BEHAV SOC SCI LIBR, V17, P11, DOI 10.1300/J103v17n02_02; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; HARRIS C, 1992, ACTIVE VISION; HARRIS CG, 1987, P 3 ALV VIS C, P233; KNIGHT JGH, 2001, P IEEE RSJ C INT ROB; LAND MF, 1994, NATURE, V369, P742, DOI 10.1038/369742a0; LEONARD JJ, 2000, ROBOTICS RES; MACCORMICK J, 2000, P 6 EUR C COMP VIS; Murray DW, 1997, PERCEPTION, V26, P1519, DOI 10.1068/p261519; NAYAR S, 1997, P IEEE C COMP VIS PA; Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705; SANDINI G, 1990, P IEEE INT WORKSH RO; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Smith R., 1987, P 4 INT S ROB RES; Thrun S., 2000, P IEEE INT C ROB AUT; Thrun S., 1998, MACHINE LEARNING, V31; TISTARELLI M, 1992, CVGIP-IMAG UNDERSTAN, V56, P108, DOI 10.1016/1049-9660(92)90089-L; Torr P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P485, DOI 10.1109/ICCV.1998.710762; Whaite P, 1997, IEEE T PATTERN ANAL, V19, P193, DOI 10.1109/34.584097	31	303	320	3	74	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2002	24	7					865	880		10.1109/TPAMI.2002.1017615	http://dx.doi.org/10.1109/TPAMI.2002.1017615			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	566UF		Green Submitted			2022-12-18	WOS:000176446100001
J	Oh, W; Lindquist, WB				Oh, W; Lindquist, WB			Image thresholding by indicator kriging	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image segmentation; spatial thresholding; indicator kriging	SELECTION METHOD; DOCUMENT IMAGES; SEGMENTATION; ENTROPY; CLASSIFICATION; BINARIZATION; HISTOGRAM	We consider the problem of segmenting a digitized image consisting of two univariate populations. Assume a priori knowledge allows incomplete assignment of voxels in the image, in the sense that a fraction of the voxels can be identified as belonging to population II0, a second fraction to II1, and the remaining fraction have no a priori identification. Based upon estimates of the short length scale spatial covariance of the image, we develop a method utilizing indicator kriging to complete the image segmentation.	SUNY Stony Brook, Dept Appl Math & Stat, Stony Brook, NY 11794 USA	State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	Oh, W (corresponding author), SUNY Stony Brook, Dept Appl Math & Stat, Stony Brook, NY 11794 USA.							ABUTALEB AS, 1989, COMPUT VISION GRAPH, V47, P22, DOI 10.1016/0734-189X(89)90051-0; Bernsen J., 1986, P 8 INT C PATT REC P, P1251; CHOS CK, 1972, COMPUTERS BIOMEDICAL, V5, P388; Deravi F, 1983, PATTERN RECOGN LETT, V1, P417, DOI 10.1016/0167-8655(83)90080-6; Deutsch Clayton V., 1998, GSLIB GEOSTATISTICAL, V40; DFEUTSCH CV, 1995, COMPUT GEOSCI, V22, P765; EIKVIL L, 1991, P 1 INT C DOC AN REC, P435; FREDRICH JT, 1995, SCIENCE, V268, P276, DOI 10.1126/science.268.5208.276; Johannsen G., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P140; Journel A.G, 1989, FUNDAMENTALS GEOSTAT; Journel A. G., 1986, P 19 APCOM S LITTL C, P15; KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2; KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0; MARDIA KV, 1988, IEEE T PATTERN ANAL, V10, P919, DOI 10.1109/34.9113; MARDIA KV, 1984, COMMUN STAT-THEOR M, V13, P2181, DOI 10.1080/03610928408828822; NAKAGAWA Y, 1979, PATTERN RECOGN, V11, P191, DOI 10.1016/0031-3203(79)90006-2; Niblack W., 1986, ADV COMPUTER GRAPHIC; OGORMAN L, 1994, CVGIP-GRAPH MODEL IM, V56, P494, DOI 10.1006/cgip.1994.1044; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J; PAL NR, 1992, INT J SYST SCI, V23, P1903, DOI 10.1080/00207729208949429; PAPPAS TN, 1992, IEEE T SIGNAL PROCES, V40, P901, DOI 10.1109/78.127962; PUN T, 1980, SIGNAL PROCESS, V2, P223, DOI 10.1016/0165-1684(80)90020-1; RIDLER TW, 1978, IEEE T SYST MAN CYB, V8, P630, DOI 10.1109/tsmc.1978.4310039; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; SPANNE P, 1994, PHYS REV LETT, V73, P2001, DOI 10.1103/PhysRevLett.73.2001; SWITZER P, 1980, MATH GEOL, V12, P367; TAXT T, 1989, IEEE T PATTERN ANAL, V11, P1322, DOI 10.1109/34.41371; Tek H, 1997, COMPUT VIS IMAGE UND, V65, P246, DOI 10.1006/cviu.1996.0579; TITTERINGTON DM, 1985, STAT ANAL FINITE MIX; Tou JT, 1974, PATTERN RECOGN; TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P1191, DOI 10.1109/34.476511; VELASCO FRD, 1980, IEEE T SYST MAN CYB, V10, P771, DOI DOI 10.1109/TSMC.1980.4308400; WESZKA JS, 1978, IEEE T SYST MAN CYB, V8, P622, DOI 10.1109/TSMC.1978.4310038; WHITE JM, 1983, IBM J RES DEV, V27, P400, DOI 10.1147/rd.274.0400; WONG AKC, 1989, IEEE T SYST MAN CYB, V19, P866, DOI 10.1109/21.35351; YANOWITZ SD, 1989, COMPUT VISION GRAPH, V46, P82, DOI 10.1016/S0734-189X(89)80017-9; Zhang YJ, 1996, PATTERN RECOGN, V29, P1335, DOI 10.1016/0031-3203(95)00169-7	38	303	318	1	52	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1999	21	7					590	602		10.1109/34.777370	http://dx.doi.org/10.1109/34.777370			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	216YT					2022-12-18	WOS:000081472600002
J	Sanchez-Reillo, R; Sanchez-Avila, C; Gonzalez-Marcos, A				Sanchez-Reillo, R; Sanchez-Avila, C; Gonzalez-Marcos, A			Biometric identification through hand geometry measurements	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						hand geometry; classification; verification; biometric systems; Euclidean distance; Hamming distance; Gaussian mixture models; radial basis functions	MIXTURE SPEAKER MODELS	A work in defining and implementing a biometric system based on hand geometry identification is presented here. Hand features are extracted from a color photograph taken when the user has placed his hand on a platform designed for such a task. Different pattern recognition techniques have been tested to be used in classification and/or verification from Euclidean distance to neural networks. Experimental results, up to a 97 percent rate of success in classification. will show the possibility of using this system in medium/high security environments with full acceptance from all users.	ETSI Telecommun, Dept Tecnol Foton, E-28040 Madrid, Spain; ETSI Telecommun, Dept Matemat Aplicada, E-28040 Madrid, Spain		Sanchez-Reillo, R (corresponding author), ETSI Telecommun, Dept Tecnol Foton, Ciudad Univ S-N, E-28040 Madrid, Spain.		Avila, Carmen Sanchez/I-2225-2015; MARCOS, ANA PILAR GONZALEZ/L-3220-2017; Sanchez-Reillo, Raul/Z-3333-2019	MARCOS, ANA PILAR GONZALEZ/0000-0002-0757-2445; Sanchez-Reillo, Raul/0000-0003-4239-985X; SANCHEZ AVILA, MARIA DEL CARMEN/0000-0002-7690-1011				[Anonymous], 1973, PATTERN CLASSIFICATI; Haykin S, 1998, NEURAL NETWORKS COMP, V2nd; HUSH DR, 1993, IEEE SIGNAL PROC JAN, P8; Jain A. K., 1988, FUNDAMENTALS DIGITAL; JAIN AK, 1999, BIOMETRICS PERSONAL, P411; Lippman R. P., 1987, IEEE ASSP MAGAZI APR, P4; MILLER B, 1998, IEEE SPECTRUM    FEB, P22; REYNOLDS DA, 1995, SPEECH COMMUN, V17, P91, DOI 10.1016/0167-6393(95)00009-D; REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379; SCHALKOFF RJ, 1989, DIGITAL PROCESSING C; Schurmann J, 1996, PATTERN CLASSIFICATI	11	302	309	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2000	22	10					1168	1171		10.1109/34.879796	http://dx.doi.org/10.1109/34.879796			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	369LQ					2022-12-18	WOS:000165067100009
J	Bulling, A; Ward, JA; Gellersen, H; Troster, G				Bulling, Andreas; Ward, Jamie A.; Gellersen, Hans; Troester, Gerhard			Eye Movement Analysis for Activity Recognition Using Electrooculography	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Ubiquitous computing; feature evaluation and selection; pattern analysis; signal processing	CONTEXT; SYSTEM	In this work, we investigate eye movement analysis as a new sensing modality for activity recognition. Eye movement data were recorded using an electrooculography (EOG) system. We first describe and evaluate algorithms for detecting three eye movement characteristics from EOG signals-saccades, fixations, and blinks-and propose a method for assessing repetitive patterns of eye movements. We then devise 90 different features based on these characteristics and select a subset of them using minimum redundancy maximum relevance (mRMR) feature selection. We validate the method using an eight participant study in an office environment using an example set of five activity classes: copying a text, reading a printed paper, taking handwritten notes, watching a video, and browsing the Web. We also include periods with no specific activity (the NULL class). Using a support vector machine (SVM) classifier and person-independent (leave-one-person-out) training, we obtain an average precision of 76.1 percent and recall of 70.5 percent over all classes and participants. The work demonstrates the promise of eye-based activity recognition (EAR) and opens up discussion on the wider applicability of EAR to other activities that are difficult, or even impossible, to detect using common sensing modalities.	[Bulling, Andreas] Univ Cambridge, Comp Lab, Cambridge CB3 0FD, England; [Ward, Jamie A.; Gellersen, Hans] Univ Lancaster, Sch Comp & Commun, InfoLab 21, Lancaster LA1 4WA, England; [Troester, Gerhard] Swiss Fed Inst Technol, Dept Informat Technol & Elect Engn, CH-8092 Zurich, Switzerland	University of Cambridge; Lancaster University; Swiss Federal Institutes of Technology Domain; ETH Zurich	Bulling, A (corresponding author), Univ Cambridge, Comp Lab, 15 JJ Thomson Ave,William Gates Bldg, Cambridge CB3 0FD, England.	andreas.bulling@acm.org; j.ward@comp.lancs.ac.uk; hwg@comp.lancs.ac.uk; troester@ife.ee.ethz.ch		Bulling, Andreas/0000-0001-6317-7303; Gellersen, Hans/0000-0003-2233-2121	Engineering and Physical Sciences Research Council [EP/H005064/1] Funding Source: researchfish; EPSRC [EP/H005064/1] Funding Source: UKRI	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		Abowd D., 1998, Virtual Reality, V3, P200, DOI 10.1007/BF01408562; Bannach D, 2008, IEEE PERVAS COMPUT, V7, P22, DOI 10.1109/MPRV.2008.36; Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1; Barea R, 2002, IEEE T NEUR SYS REH, V10, P209, DOI 10.1109/TNSRE.2002.806829; Brown M, 2006, DOC OPHTHALMOL, V113, P205, DOI 10.1007/s10633-006-9030-0; Bulling A, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P84, DOI 10.1145/1409635.1409647; Bulling A, 2008, LECT NOTES COMPUT SC, V5013, P19, DOI 10.1007/978-3-540-79576-6_2; Bulling A, 2011, IEEE PERVAS COMPUT, V10, P48, DOI 10.1109/MPRV.2010.49; Bulling A, 2009, UBICOMP'09: PROCEEDINGS OF THE 11TH ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P41; Bulling A, 2009, J AMB INTEL SMART EN, V1, P157, DOI 10.3233/AIS-2009-0020; Canosa RL, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1498700.1498705; Chen YX, 2004, IEEE INT CONF ROBOT, P243; Chouhan VS, 2007, ICCTA 2007: INTERNATIONAL CONFERENCE ON COMPUTING: THEORY AND APPLICATIONS, PROCEEDINGS, P512; Crammer K, 2003, J MACH LEARN RES, V3, P951, DOI 10.1162/jmlr.2003.3.4-5.951; Dempere-Marco L, 2002, IEEE T MED IMAGING, V21, P741, DOI 10.1109/TMI.2002.801153; Ding QP, 2005, P ANN INT IEEE EMBS, P6829; DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009; Duchowski AT, 2007, EYE TRACKING METHODO; Elhelw M, 2008, ACM T APPL PERCEPT, V5, DOI 10.1145/1279640.1279643; Gu JJ, 2001, IEEE INT CONF ROBOT, P1555, DOI 10.1109/ROBOT.2001.932832; HACISALIHZADE SS, 1992, IEEE T SYST MAN CYB, V22, P474, DOI 10.1109/21.155948; Hayhoe M, 2005, TRENDS COGN SCI, V9, P188, DOI 10.1016/j.tics.2005.02.009; Henderson JM, 2003, TRENDS COGN SCI, V7, P498, DOI 10.1016/j.tics.2003.09.006; KARSON CN, 1981, PSYCHIAT RES, V5, P243, DOI 10.1016/0165-1781(81)90070-6; Keat FT, 2003, TENCON IEEE REGION, P825; Kern N, 2007, PERS UBIQUIT COMPUT, V11, P251, DOI 10.1007/s00779-006-0086-3; Lin C.-J., 2008, LIBLINEAR LIB LARGE; Liversedge SP, 2000, TRENDS COGN SCI, V4, P6, DOI 10.1016/S1364-6613(99)01418-7; Logan B, 2007, LECT NOTES COMPUT SC, V4717, P483; Manor BR, 2003, J NEUROSCI METH, V128, P85, DOI 10.1016/S0165-0270(03)00151-1; Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280; Na Pan, 2007, 2007 Joint Meeting of the 6th International Symposium on Noninvasive Functional Source Imaging of the Brain and Heart and the International Conference on Functional Biomedical Imaging, P177; Najafi B, 2003, IEEE T BIO-MED ENG, V50, P711, DOI 10.1109/TBME.2003.812189; Palomba D, 2000, INT J PSYCHOPHYSIOL, V36, P45, DOI 10.1016/S0167-8760(99)00099-9; Peng H., 2008, MRMR FEATURE SELECTI; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159; Salvucci D. D., 2000, P 2000 S EYE TRACKIN, P71, DOI [DOI 10.1145/355017.355028, 10.1145/355017.355028]; Salvucci DD, 2001, HUM-COMPUT INTERACT, V16, P39, DOI 10.1207/S15327051HCI1601_2; Schleicher R, 2008, ERGONOMICS, V51, P982, DOI 10.1080/00140130701817062; Huynh T, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P10; Taschenbuch H., 2001, SENSATION PERCEPTION; Tinati MA, 2006, INT J BIOMED IMAGING, V2006, DOI 10.1155/IJBI/2006/97157; Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594; Ward JA, 2006, IEEE T PATTERN ANAL, V28, P1553, DOI 10.1109/TPAMI.2006.197; Wijesoma WS, 2005, IEEE INT CONF ROBOT, P1085; Xu LS, 2005, IEEE T BIO-MED ENG, V52, P1973, DOI 10.1109/TBME.2005.856296	46	301	315	13	61	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2011	33	4					741	753		10.1109/TPAMI.2010.86	http://dx.doi.org/10.1109/TPAMI.2010.86			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	721QT	20421675	Green Submitted			2022-12-18	WOS:000287370400007
J	Ben-Ezra, M; Nayar, SK				Ben-Ezra, M; Nayar, SK			Motion-based motion deblurring	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						sharpening and deblurring; inverse filtering; motion; motion blur; point spread function; resolution; hybrid imaging	IMAGE MOTION; BLUR; RESTORATION; SUPERRESOLUTION; IDENTIFICATION; PARAMETERS; SMEAR	Motion blur due to camera motion can significantly degrade the quality of an image. Since the path of the camera motion can be arbitrary, deblurring of motion blurred images is a hard problem. Previous methods to deal with this problem have included blind restoration of motion blurred images, optical correction using stabilized lenses, and special CMOS sensors that limit the exposure time in the presence of motion. In this paper, we exploit the fundamental trade off between spatial resolution and temporal resolution to construct a hybrid camera that can measure its own motion during image integration. The acquired motion information is used to compute a point spread function (PSF) that represents the path of the camera during integration. This PSF is then used to deblur the image. To verify the feasibility of hybrid imaging for motion deblurring, we have implemented a prototype hybrid camera. This prototype system was evaluated in different indoor and outdoor scenes using long exposures and complex camera motion paths. The results show that, with minimal resources, hybrid imaging outperforms previous approaches to the motion blur problem. We conclude with a brief discussion on how our ideas can be extended beyond the case of global camera motion to the case where individual objects in the scene move with different velocities.	Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Columbia University	Ben-Ezra, M (corresponding author), Columbia Univ, Dept Comp Sci, 1214 Amsterdam Ave, New York, NY 10027 USA.	moshe@cs.columbia.edu; nayar@cs.columbia.edu						Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; BASCLE B, 1996, P EUR C COMP VIS, P573; Besuievsky G, 1998, WSCG '98, VOL 1, P35; BOTTINI S, 1981, P 2 INT C VIS PSYCH, P143; Brostow GJ, 2001, COMP GRAPH, P561, DOI 10.1145/383259.383325; Chen WG, 1996, IEEE T PATTERN ANAL, V18, P412, DOI 10.1109/34.491622; Csillag P, 1996, P SOC PHOTO-OPT INS, V2727, P604, DOI 10.1117/12.233275; FABIAN R, 1991, CVGIP-GRAPH MODEL IM, V53, P403, DOI 10.1016/1049-9652(91)90025-F; Fox J. S., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P360, DOI 10.1109/CVPR.1988.196260; Glassner A, 1999, IEEE COMPUT GRAPH, V19, P82, DOI 10.1109/38.799751; Hamamoto T, 2001, IEEE J SOLID-ST CIRC, V36, P580, DOI 10.1109/4.913735; Hammett ST, 1997, VISION RES, V37, P2505, DOI 10.1016/S0042-6989(97)00059-X; Hammett ST, 1998, VISION RES, V38, P2099, DOI 10.1016/S0042-6989(97)00430-6; JANSSON PA, 1997, DECONVOLUTION IMAGE; Jianchao Y., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P180, DOI 10.1109/ICIP.1999.821591; KOLB C, 1995, COMPUTER GRAPHICS, V29, P317; Lee SH, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P755, DOI 10.1109/ICIP.1997.648071; Liu XQ, 2001, INT CONF ACOUST SPEE, P1841, DOI 10.1109/ICASSP.2001.941301; Lucas Bruce D, 1981, P 7 INT JOINT C ART, DOI DOI 10.1042/CS0730285; MACADAM DP, 1970, J OPT SOC AM, V60, P1617, DOI 10.1364/JOSA.60.001617; Majchrzak D, 2000, INT C PATT RECOG, P836, DOI 10.1109/ICPR.2000.903674; MAKKAD SS, 1993, OPT ENG, V32, P1915, DOI 10.1117/12.143301; Max N. L., 1985, Computer Graphics, V19, P85, DOI 10.1145/325165.325188; Mayntx C., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P885, DOI 10.1109/ICIP.1999.823025; Potmesil M., 1983, Computer Graphics, V17, P389, DOI 10.1145/964967.801169; Rav-Acha A, 2000, FIFTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P22, DOI 10.1109/WACV.2000.895398; Rekleitis IM, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P791, DOI 10.1109/ICIP.1996.560852; Sawhney HS, 2001, COMP GRAPH, P451, DOI 10.1145/383259.383312; SHECHTMAN E, 2002, P 7 EUR C COMP VIS, V1, P753; Shekarforoush H, 1999, J OPT SOC AM A, V16, P481, DOI 10.1364/JOSAA.16.000481; Stern A, 2002, APPL OPTICS, V41, P2164, DOI 10.1364/AO.41.002164; Stern A, 1997, J OPT SOC AM A, V14, P388, DOI 10.1364/JOSAA.14.000388; Tull DL, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P85, DOI 10.1109/ICIP.1996.560375; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Wang YF, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1029, DOI 10.1109/ICCV.1998.710843; Wloka MM, 1996, VISUAL COMPUT, V12, P283; YITZHAKY Y, 1995, PROC SPIE, V2470, P2, DOI 10.1117/12.210038; Yitzhaky Y, 1998, J OPT SOC AM A, V15, P1512, DOI 10.1364/JOSAA.15.001512; Yitzhaky Y, 2000, OPT ENG, V39, P2083, DOI 10.1117/1.1305319; Zhang YN, 2000, PATTERN RECOGN LETT, V21, P425, DOI 10.1016/S0167-8655(00)00014-3	40	301	360	3	85	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2004	26	6					689	698						10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	811EZ	18579930				2022-12-18	WOS:000220756500003
J	Ochs, P; Malik, J; Brox, T				Ochs, Peter; Malik, Jitendra; Brox, Thomas			Segmentation of Moving Objects by Long Term Video Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Motion segmentation; point trajectories; variational methods	MOTION SEGMENTATION; OPTICAL-FLOW; GRAPH CUTS; RECOGNITION; FRAMEWORK	Motion is a strong cue for unsupervised object-level grouping. In this paper, we demonstrate that motion will be exploited most effectively, if it is regarded over larger time windows. Opposed to classical two-frame optical flow, point trajectories that span hundreds of frames are less susceptible to short-term variations that hinder separating different objects. As a positive side effect, the resulting groupings are temporally consistent over a whole video shot, a property that requires tedious post-processing in the vast majority of existing approaches. We suggest working with a paradigm that starts with semi-dense motion cues first and that fills up textureless areas afterwards based on color. This paper also contributes the Freiburg-Berkeley motion segmentation (FBMS) dataset, a large, heterogeneous benchmark with 59 sequences and pixel-accurate ground truth annotation of moving objects.	[Ochs, Peter; Brox, Thomas] Univ Freiburg, Dept Comp Sci, D-79110 Freiburg, Germany; [Ochs, Peter; Brox, Thomas] Univ Freiburg, BIOSS Ctr Biol Signalling Studies, D-79110 Freiburg, Germany; [Malik, Jitendra] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA	University of Freiburg; University of Freiburg; University of California System; University of California Berkeley	Ochs, P (corresponding author), Univ Freiburg, Dept Comp Sci, D-79110 Freiburg, Germany.	ochs@cs.uni-freiburg.de; malik@eecs.berkeley.edu; brox@cs.uni-freiburg.de			Post-Doc program of the German Academic Exchange Service (DAAD); ONR MURI [N00014-06-1-0734]; German Research Foundation (DFG) [BR3815/5-1]	Post-Doc program of the German Academic Exchange Service (DAAD)(Deutscher Akademischer Austausch Dienst (DAAD)); ONR MURI(MURIOffice of Naval Research); German Research Foundation (DFG)(German Research Foundation (DFG))	We thank T. Pock for valuable comments on the variational model. We thank R. Vidal for allowing us to use some of the sequences from Hopkins 155 in our benchmark dataset, and the reviewers for suggestions that improved the manuscript. This work was supported by a fellowship within the Post-Doc program of the German Academic Exchange Service (DAAD), by ONR MURI N00014-06-1-0734, and by the German Research Foundation (DFG) grant BR3815/5-1.	Amiaz T, 2006, INT J COMPUT VISION, V68, P111, DOI 10.1007/s11263-005-6206-0; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Ayvaci A, 2012, INT J COMPUT VISION, V97, P322, DOI 10.1007/s11263-011-0490-7; Bai X., 2007, P 11 INT C COMP VIS; Belongie S., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P751, DOI 10.1007/BFb0055702; Beymer D, 1997, PROC CVPR IEEE, P495, DOI 10.1109/CVPR.1997.609371; Birchfield S., 2008, P INT C CVPR ANCH AK; Boult T. E., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P179, DOI 10.1109/WVM.1991.212809; Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5; Brendel W., 2009, P INT C COMP VIS KYO; Brostow G. J., 2006, P INT C COMP VIS PAT; Brostow GJ, 2008, LECT NOTES COMPUT SC, V5302, P44, DOI 10.1007/978-3-540-88682-2_5; Brox T., 2010, P ECCV; Brox T, 2006, LECT NOTES COMPUT SC, V3951, P471; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Brox T, 2009, INT J COMPUT VISION, V84, P184, DOI 10.1007/s11263-008-0153-5; Chambolle A, 2012, SIAM J IMAGING SCI, V5, P1113, DOI 10.1137/110856733; Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1; Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286; Cheriyadat A., 2009, P ICCV; COSTEIRA J, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1071, DOI 10.1109/ICCV.1995.466815; Cremers D, 2005, INT J COMPUT VISION, V62, P249, DOI 10.1007/s11263-005-4882-4; Cremers D., 2011, ADV MARKOV RANDOM FI; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Fradet M, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P7, DOI 10.1109/CVMP.2009.24; Fragkiadaki K., 2011, P INT C CVPR; Fragkiadaki K., 2012, P INT C CVPR PROV RI; Fragkiadaki K, 2012, LECT NOTES COMPUT SC, V7576, P552, DOI 10.1007/978-3-642-33715-4_40; Gear CW, 1998, INT J COMPUT VISION, V29, P133, DOI 10.1023/A:1008026310903; Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233; Grundmann M, 2010, PROC CVPR IEEE, P2141, DOI 10.1109/CVPR.2010.5539893; Koffka K., 1935, PRINCIPLES GESTALT P; Komodakis N, 2008, COMPUT VIS IMAGE UND, V112, P14, DOI 10.1016/j.cviu.2008.06.007; Komodakis N, 2007, IEEE T PATTERN ANAL, V29, P1436, DOI 10.1109/TPAMI.2007.1061; Kumar MP, 2008, INT J COMPUT VISION, V76, P301, DOI 10.1007/s11263-007-0064-x; Lauer F, 2009, IEEE I CONF COMP VIS, P678, DOI 10.1109/ICCV.2009.5459173; Lellmann J, 2009, IEEE I CONF COMP VIS, P646, DOI 10.1109/ICCV.2009.5459176; Lezama J., 2011, P INT C CVPR PROV RI; Li Ting, 2007, P IEEE C COMP VIS PA, P1; Liu G., 2010, P 27 INT C MACHINE L, P663, DOI DOI 10.1109/ICDMW.2010.64; Liu RS, 2012, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2012.6247726; Lucas B.D., 1981, IJCAI 81 P 7 INT JOI, P674, DOI DOI 10.1109/HPDC.2004.1323531; Ng AY, 2002, ADV NEUR IN, V14, P849; Nieuwenhuis C, 2010, LECT NOTES COMPUT SC, V6376, P483; OCHS P, 2011, P ICCV, P1583; Ochs P, 2012, PROC CVPR IEEE, P614, DOI 10.1109/CVPR.2012.6247728; Ommer B, 2009, INT J COMPUT VISION, V83, P57, DOI 10.1007/s11263-009-0211-7; Ostrovsky Y, 2009, PSYCHOL SCI, V20, P1484, DOI 10.1111/j.1467-9280.2009.02471.x; Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065; Price BL, 2009, IEEE I CONF COMP VIS, P779, DOI 10.1109/ICCV.2009.5459293; Rao SM, 2008, NEUROPSYCHOLOGY, V22, P1, DOI 10.1037/0894-4105.22.1.1; Sand Peter, 2008, International Journal of Computer Vision, V80, P72, DOI 10.1007/s11263-008-0136-6; Schindler K, 2008, INT J COMPUT VISION, V79, P159, DOI 10.1007/s11263-007-0111-7; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shi JB, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1154, DOI 10.1109/ICCV.1998.710861; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Sinha SN, 2011, MACH VISION APPL, V22, P207, DOI 10.1007/s00138-007-0105-z; Sinop A. K., 2007, P ICCV; Sivic J, 2006, INT J COMPUT VISION, V67, P189, DOI 10.1007/s11263-005-4264-y; Sturgess P., 2009, P BMVC; Sun DQ, 2012, PROC CVPR IEEE, P1768, DOI 10.1109/CVPR.2012.6247873; Sundaram N., 2010, LNCS; Tron R, 2007, PROC CVPR IEEE, P41, DOI 10.1109/cvpr.2007.382974; Unger M., 2008, P BMVC, P1; Vazquez-Reina A., 2010, P ECCV; Vidal R, 2008, INT J COMPUT VISION, V79, P85, DOI 10.1007/s11263-007-0099-z; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Wojek C, 2013, IEEE T PATTERN ANAL, V35, P882, DOI 10.1109/TPAMI.2012.174; Xiao JJ, 2005, IEEE T PATTERN ANAL, V27, P1644, DOI 10.1109/TPAMI.2005.202; Yan JY, 2006, LECT NOTES COMPUT SC, V3954, P94; Zach Christopher, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563089; Zappella L, 2011, PATTERN RECOGN, V44, P454, DOI 10.1016/j.patcog.2010.08.015; Zhang G., 2012, P INT C PATT REC TSU	73	300	316	2	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2014	36	6					1187	1200		10.1109/TPAMI.2013.242	http://dx.doi.org/10.1109/TPAMI.2013.242			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AI8AJ	26353280	Green Submitted			2022-12-18	WOS:000337124200011
J	Li, W; Duan, LX; Xu, D; Tsang, IW				Li, Wen; Duan, Lixin; Xu, Dong; Tsang, Ivor W.			Learning with Augmented Features for Supervised and Semi-Supervised Heterogeneous Domain Adaptation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Heterogeneous domain adaptation; domain adaptation; transfer learning; augmented features	EVENT RECOGNITION; MULTIPLE; VIDEOS	In this paper, we study the heterogeneous domain adaptation (HDA) problem, in which the data from the source domain and the target domain are represented by heterogeneous features with different dimensions. By introducing two different projection matrices, we first transform the data from two domains into a common subspace such that the similarity between samples across different domains can be measured. We then propose a new feature mapping function for each domain, which augments the transformed samples with their original features and zeros. Existing supervised learning methods (e. g., SVM and SVR) can be readily employed by incorporating our newly proposed augmented feature representations for supervised HDA. As a showcase, we propose a novel method called Heterogeneous Feature Augmentation (HFA) based on SVM. We show that the proposed formulation can be equivalently derived as a standard Multiple Kernel Learning (MKL) problem, which is convex and thus the global solution can be guaranteed. To additionally utilize the unlabeled data in the target domain, we further propose the semi-supervised HFA (SHFA) which can simultaneously learn the target classifier as well as infer the labels of unlabeled target samples. Comprehensive experiments on three different applications clearly demonstrate that our SHFA and HFA outperform the existing HDA methods.	[Li, Wen; Xu, Dong] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; [Duan, Lixin] Inst Infocomm Res, Singapore 138632, Singapore; [Tsang, Ivor W.] Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, Sydney, NSW 2007, Australia	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R); University of Technology Sydney	Li, W (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.	wli1@e.ntu.edu.sg; lxduan@gmail.com; dongxu@ntu.edu.sg; ivor.tsang@gmail.com	Xu, Dong/A-3694-2011	Xu, Dong/0000-0003-2775-9730; Tsang, Ivor/0000-0001-8095-4637	Singapore MOE [ARC42/13]	Singapore MOE(Ministry of Education, Singapore)	This work is supported by the Singapore MOE Tier 2 Grant (ARC42/13).	Amini  M.-R., 2009, P NIPS; [Anonymous], [No title captured]; Bay H., 2006, P ECCV; Blitzer J., 2007, P 45 ACL PRAG CZECH; Blitzer J., 2006, P EMNLP SYDN NSW AUS; Chen L, 2013, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2013.344; Daume III H., 2010, P NIPS; Daume III H., 2007, P ACL; Duan L., 2012, P INT C MACH LEARN, V1, P711; Duan LX, 2012, PROC CVPR IEEE, P1338, DOI 10.1109/CVPR.2012.6247819; Duan Lixin, 2012, IEEE Trans Neural Netw Learn Syst, V23, P504, DOI 10.1109/TNNLS.2011.2178556; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114; Dudik M., 2012, P 15 AISTATS LA PALM; Gehler P. V., 2008, 178 MAX PLANCK I BIO; Harel M., 2011, P 28 ICML BELL WA US; Kloft M, 2011, J MACH LEARN RES, V12, P953; Kulis B., 2011, P CVPR; Kulis B, 2009, J MACH LEARN RES, V10, P341; LI W, 2011, P ICCV, P2049, DOI DOI 10.1109/ICCV.2011.6126478; Li W, 2012, PROC CVPR IEEE, P2368, DOI 10.1109/CVPR.2012.6247949; Li Y.-F., 2009, P AISTATS CLEARW BEA; Mutapcic A, 2009, OPTIM METHOD SOFTW, V24, P381, DOI 10.1080/10556780802712889; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Prettenhofer P., 2010, P 48 ACL UPPS SWED; Prettenhofer Peter, 2010, P ACL; Saenko K., 2010, P ECCV; Scholkopf B, 1999, IEEE T NEURAL NETWOR, V10, P1000, DOI 10.1109/72.788641; Shi X., 2010, P ICDM SYDN NSW AUST; Tan M., 2010, P 27 ICML HAIF ISR; Wang C., 2011, P 22 IJCAI; Wei B., 2010, P ACL; Yang Q., 2009, P ACL IJCNLP SING; Zhu X.J., 2005, COMPUT SCI; Zhu Y., 2011, P AAAI	36	299	309	9	98	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2014	36	6					1134	1148		10.1109/TPAMI.2013.167	http://dx.doi.org/10.1109/TPAMI.2013.167			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AI8AJ	26353276				2022-12-18	WOS:000337124200007
J	Vasilevskiy, A; Siddiqi, K				Vasilevskiy, A; Siddiqi, K			Flux maximizing geometric flows	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						geometric active contours; gradient flows; shape analysis; divergence and flux; blood vessel segmentation	SHAPE; SNAKES; AXIOMS; CURVES; MODEL	Several geometric active contour models have been proposed for segmentation in computer vision and image analysis. The essential idea is to evolve a curve (in 2D) or a surface (in 3D) under constraints from image forces so that it clings to features of interest in an intensity image. Recent variations on this theme take into account properties of enclosed regions and allow for multiple curves or surfaces to be simultaneously represented. However, it is still unclear how to apply these techniques to images of narrow elongated structures, such as blood vessels, where intensity contrast may be low and reliable region statistics cannot be computed. To address this problem, we derive the gradient flows which maximize the rate of increase of flux of an appropriate vector field through a curve (in 2D) or a surface (in 3D). The key idea is to exploit the direction of the vector field along with its magnitude. The calculations lead to a simple and elegant interpretation which is essentially parameter free and has the same form in both dimensions. We illustrate its advantages with several level-set-based segmentations of 2D and 3D angiography images of blood vessels.	IBM Canada Ltd, Java JIT Dev Grp, Markham, ON L6G 1C7, Canada; McGill Univ, Sch Comp Sci, Montreal, PQ AH3A 2A7, Canada; McGill Univ, Ctr Intelligent Machines, Montreal, PQ AH3A 2A7, Canada	International Business Machines (IBM); McGill University; McGill University	Vasilevskiy, A (corresponding author), IBM Canada Ltd, Java JIT Dev Grp, 8200 Warden Ave, Markham, ON L6G 1C7, Canada.	avasilev@ca.ibm.com; siddiqi@cim.mcgill.ca		Siddiqi, Kaleem/0000-0002-7347-9716				ALVAREZ L, 1992, CR ACAD SCI I-MATH, V315, P265; ALVAREZ L, 1992, CR ACAD SCI I-MATH, V315, P135; Ambrosio L, 1996, J DIFFER GEOM, V43, P693; Bullitt E, 1999, LECT NOTES COMPUT SC, V1613, P308; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; CASELLES V, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P694, DOI 10.1109/ICCV.1995.466871; CHAN T, 2000, P AS C SIGN SYST OCT; Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195; GAGE M, 1986, J DIFFER GEOM, V23, P69; GRAYSON MA, 1987, J DIFFER GEOM, V26, P285; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; KIMIA BB, 1990, LECT NOTES COMPUT SC, V427, P402, DOI 10.1007/BFb0014889; KIMMEL R, 2001, CIS200104 TECHN CTR; KOLLER TM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P864, DOI 10.1109/ICCV.1995.466846; Krissian K, 1998, PROC CVPR IEEE, P722, DOI 10.1109/CVPR.1998.698683; KRISSIAN K, 1997, P INT C SCAL SPAC, P345; Lorigo LM, 2001, MED IMAGE ANAL, V5, P195, DOI 10.1016/S1361-8415(01)00040-8; Lorigo LM, 1999, LECT NOTES COMPUT SC, V1613, P126; Lorigo LM, 2000, PROC CVPR IEEE, P444, DOI 10.1109/CVPR.2000.855853; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; MALLADI R, 1993, P SOC PHOTO-OPT INS, V2031, P246, DOI 10.1117/12.146630; MALLADI R, 1994, P 3 EUR C COMP VIS, P3; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; McInerney T, 2000, MED IMAGE ANAL, V4, P73, DOI 10.1016/S1361-8415(00)00008-6; McInerney T, 1999, IEEE T MED IMAGING, V18, P840, DOI 10.1109/42.811261; MCINERNEY T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P840, DOI 10.1109/ICCV.1995.466850; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Paragios N, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P153, DOI 10.1109/VLSM.2001.938894; Paragios N., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P926, DOI 10.1109/ICCV.1999.790347; SETHIAN JA, 1990, J DIFFER GEOM, V31, P131; Siddiqi K, 1998, IEEE T IMAGE PROCESS, V7, P433, DOI 10.1109/83.661193; Tek H, 1997, COMPUT VIS IMAGE UND, V65, P246, DOI 10.1006/cviu.1996.0579; Tschumperle D, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P3, DOI 10.1109/VLSM.2001.938875; Vemuri BC, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P81, DOI 10.1109/VLSM.2001.938885; Weickert J, 1997, LECT NOTES COMPUT SC, V1252, P3; Wilson DL, 1997, LECT NOTES COMPUT SC, V1230, P423; Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186; Yezzi A.  Jr., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P898, DOI 10.1109/ICCV.1999.790317; [No title captured]	41	299	316	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2002	24	12					1565	1578		10.1109/TPAMI.2002.1114849	http://dx.doi.org/10.1109/TPAMI.2002.1114849			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	618YA		Green Submitted			2022-12-18	WOS:000179444600002
J	BERGHOLM, F				BERGHOLM, F			EDGE FOCUSING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											BERGHOLM, F (corresponding author), ROYAL INST TECHNOL,DEPT COMP SCI & NUMERICAL ANAL,NADA,S-10044 STOCKHOLM 70,SWEDEN.							BERGHOLM F, 1984, TRITANAE8472 ROY I T; BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; Canny J., 1986, IEEE T PATTERN ANAL, VPAMI-8; CANNY JF, 1983, MIT720 TECH REP; EKLUNDH JO, 1982, 6TH P INT C PATT REC, P1109; GRIMSON WEL, 1981, IMAGES SURFACES; HAY GA, 1977, J THEOR BIOL, V67, P221, DOI 10.1016/0022-5193(77)90196-5; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; LOWE D, 1984, THESIS STANFORD U; LOWE DG, 1985, IEEE T PATTERN ANAL, V7, P320, DOI 10.1109/TPAMI.1985.4767660; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; ROSENFELD A, 1971, IEEE T COMPUT, V20, P512; SJOBERG F, 1987, TRITANAP8705 ROY I T; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729	16	297	308	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1987	9	6					726	741		10.1109/TPAMI.1987.4767980	http://dx.doi.org/10.1109/TPAMI.1987.4767980			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	K6735	21869435				2022-12-18	WOS:A1987K673500001
J	Kasturi, R; Goldgof, D; Soundararajan, P; Manohar, V; Garofolo, J; Bowers, R; Boonstra, M; Korzhova, V; Zhang, J				Kasturi, Rangachar; Goldgof, Dmitry; Soundararajan, Padmanabhan; Manohar, Vasant; Garofolo, John; Bowers, Rachel; Boonstra, Matthew; Korzhova, Valentina; Zhang, Jing			Framework for Performance Evaluation of Face, Text, and Vehicle Detection and Tracking in Video: Data, Metrics, and Protocol	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Performance evaluation; object detection and tracking; baseline algorithms; face; text; vehicle	ALGORITHMS; IMAGES	Common benchmark data sets, standardized performance metrics, and baseline algorithms have demonstrated considerable impact on research and development in a variety of application domains. These resources provide both consumers and developers of technology with a common framework to objectively compare the performance of different algorithms and algorithmic improvements. In this paper, we present such a framework for evaluating object detection and tracking in video: specifically for face, text, and vehicle objects. This framework includes the source video data, ground-truth annotations (along with guidelines for annotation), performance metrics, evaluation protocols, and tools including scoring software and baseline algorithms. For each detection and tracking task and supported domain, we developed a 50-clip training set and a 50-clip test set. Each data clip is approximately 2.5 minutes long and has been completely spatially/temporally annotated at the I-frame level. Each task/domain, therefore, has an associated annotated corpus of approximately 450,000 frames. The scope of such annotation is unprecedented and was designed to begin to support the necessary quantities of data for robust machine learning approaches, as well as a statistically significant comparison of the performance of algorithms. The goal of this work was to systematically address the challenges of object detection and tracking through a common evaluation framework that permits a meaningful objective comparison of techniques, provides the research community with sufficient data for the exploration of automatic modeling techniques, encourages the incorporation of objective evaluation into the development process, and contributes useful lasting resources of a scale and magnitude that will prove to be extremely useful to the computer vision research community for years to come.	[Kasturi, Rangachar; Goldgof, Dmitry; Soundararajan, Padmanabhan; Manohar, Vasant; Boonstra, Matthew; Korzhova, Valentina; Zhang, Jing] Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA; [Garofolo, John; Bowers, Rachel] Natl Inst Stand & Technol, Gaithersburg, MD 20899 USA	State University System of Florida; University of South Florida; National Institute of Standards & Technology (NIST) - USA	Kasturi, R (corresponding author), Univ S Florida, Dept Comp Sci & Engn, 4202 E Fowler Ave,ENB 118, Tampa, FL 33620 USA.	rlk@cse.udf.edu; goldgof@cse.udf.edu; paddu.sound@gmail.com; vmanohar@cse.udf.edu; john.garofolo@nist.gov; boonstra@cse.udf.edu; korzhova@cse.udf.edu; jzhang2@cse.udf.edu	Goldgof, Dmitry/ABF-1366-2020					Abd-Almageed W., 2006, Multimodal Technologies for Perception of Humans. First International Evaluation Workshop on Classification of Events, Activities and Relationships, CLEAR 2006. Revised Selected Papers (Lecture Notes in Computer Science Vol.4122), P209; ANTANI S, 2000, P INT WORKSH DOC AN, P507; BLACK J, 2003, P IEEE PERF EV TRACK; Blackburn D. M., 2001, FACIAL RECOGNITION V; BROWN LW, 2005, P IEEE PERF EV TRACK; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; Cappelli R, 2006, IEEE T PATTERN ANAL, V28, P3, DOI 10.1109/TPAMI.2006.20; COLLINS R, 2005, P IEEE INT WORKSH PE, P17; Crandall D., 2003, International Journal on Document Analysis and Recognition, V5, P138, DOI 10.1007/s10032-002-0091-7; Cucchiara R., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P618, DOI 10.1109/ICIAP.1999.797665; Doermann D, 2000, INT C PATT RECOG, P167, DOI 10.1109/ICPR.2000.902888; FISCUS JG, 2007, P MULT TECHN PERC HU; FISHER RB, 2004, P IEEE PERF EV TRACK; FREDMAN ML, 1987, J ACM, V34, P596, DOI 10.1145/28869.28874; GAROFOLO J, 2007, IEEE SIGNAL PROCESSI, V24, P154; Heath MD, 1997, IEEE T PATTERN ANAL, V19, P1338, DOI 10.1109/34.643893; Hoover A, 1996, IEEE T PATTERN ANAL, V18, P673, DOI 10.1109/34.506791; Hua XS, 2004, IEEE T CIRC SYST VID, V14, P498, DOI 10.1109/TCSVT.2004.825538; Jung K, 2004, PATTERN RECOGN, V37, P977, DOI 10.1016/j.patcog.2003.10.012; Kim Z, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P524; Knuth DE., 1993, STANFORD GRAPH BASE; LIBERMAN M, 1998, P 1 INT C LANG RES E; Lienhart R, 2002, IEEE IMAGE PROC, P900; Manohar V, 2006, LECT NOTES COMPUT SC, V3852, P151; Manohar V, 2006, LECT NOTES COMPUT SC, V3872, P576; MANOHAR V, 2006, P 9 IEEE INT WORKSH, P1; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Montgomery D. C., 2005, DESIGN ANAL EXPT, V6th; MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003; Nascimento JC, 2006, IEEE T MULTIMEDIA, V8, P761, DOI 10.1109/TMM.2006.876287; Papadimitriou C. H., 1982, COMBINATORIAL OPTIMI; Phillips PJ, 2005, PROC CVPR IEEE, P947; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Rockafellar R.T, 1984, NETWORK FLOWS MONOTR; Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39; Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315; SMITH K, 2005, P IEEE EMP EV METH C; SONG X, 2006, MULTIMODAL TECHNOLOG, P216; Stiefelhagen R., 2006, MULTIMODAL TECHNOLOG, P1; Sun ZH, 2006, IEEE T PATTERN ANAL, V28, P694, DOI 10.1109/TPAMI.2006.104; Taj M., 2006, Multimodal Technologies for Perception of Humans. First International Evaluation Workshop on Classification of Events, Activities and Relationships, CLEAR 2006. Revised Selected Papers (Lecture Notes in Computer Science Vol.4122), P190; Viola P., 2002, INT J COMPUTER VISIO; Wilson C, 2004, 7123 NISTIR; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883; Young D. P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P317; ZHAI Y, 2006, MULTIMODAL TECHNOLOG, P200; Zhu ZG, 2000, IMAGE VISION COMPUT, V18, P781, DOI 10.1016/S0262-8856(99)00046-3; 2008, AUGMENTED MULTIPARTY; 2008, PETS METRICS; 2008, CLASSIFICATION EVENT; 2008, P TEXT RETRIEVAL C V; 2008, INTEL OPEN SOURCE CO; 2008, EVALUATION TRAITEMEN; 2008, COMPUTERS HUMAN INTE; 2008, NIST RICH TRANSCRIPT; 2008, COGNITIVE AGENT LEAR	57	296	310	0	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2009	31	2					319	336		10.1109/TPAMI.2008.57	http://dx.doi.org/10.1109/TPAMI.2008.57			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	385XL	19110496				2022-12-18	WOS:000261846800009
J	Klassen, E; Srivastava, A; Mio, W; Joshi, SH				Klassen, E; Srivastava, A; Mio, W; Joshi, SH			Analysis of planar shapes using geodesic paths on shape spaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	4th International Workshop on Energy Minimization Methods in Computer Vision and Pattern Recognition	JUL 07-09, 2003	LISBON, PORTUGAL	Int Assoc Pattern Recognit, Inst Super Tecnico, Inst Telecommun		shape metrics; geodesic paths; shape statistics; intrinsic mean shapes; shape-based clustering; shape interpolation		For analyzing shapes of planar, closed curves, we propose differential geometric representations of curves using their direction functions and curvature functions. Shapes are represented as elements of infinite-dimensional spaces and their pairwise differences are quantified using the lengths of geodesics connecting them on these spaces. We use a Fourier basis to represent tangents to the shape spaces and then use a gradient-based shooting method to solve for the tangent that connects any two shapes via a geodesic. Using the Surrey fish database, we demonstrate some applications of this approach: 1) interpolation and extrapolations of shape changes, 2) clustering of objects according to their shapes, 3) statistics on shape spaces, and 4) Bayesian extraction of shapes in low-quality images.	Florida State Univ, Dept Math, Tallahassee, FL 32306 USA; Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA; Florida State Univ, Dept Elect Engn, Tallahassee, FL 32306 USA	State University System of Florida; Florida State University; State University System of Florida; Florida State University; State University System of Florida; Florida State University	Klassen, E (corresponding author), Florida State Univ, Dept Math, Tallahassee, FL 32306 USA.	klassen@math.fsu.edu; anuj@stat.fsu.edu; mio@math.fsu.edu; joshi@eng.fsu.edu	Srivastava, Anuj/F-7417-2011; Srivastava, Anuj/L-4705-2019; Joshi, Sudhanshu/L-2284-2019	Joshi, Sudhanshu/0000-0003-4748-5001				Bhattacharya R, 2002, J STAT PLAN INFER, V108, P23, DOI 10.1016/S0378-3758(02)00268-9; Bookstein FL., 1986, STAT SCI, V1, P181, DOI [DOI 10.1214/SS/1177013696, 10.1214/ss/1177013696]; Cohen I, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P396, DOI 10.1109/ICCV.1998.710749; Cremers D, 2002, LECT NOTES COMPUT SC, V2351, P93; CREMERS D, 2003, P 2 IEEE WORKSH VAR; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Grenander U, 2000, IEEE T INFORM THEORY, V46, P1658, DOI 10.1109/18.850712; Grenander U, 1998, Q APPL MATH, V56, P617, DOI 10.1090/qam/1668732; Grenander U., 1993, GEN PATTERN THEORY; JOSHI S, 2003, P 12 IEEE WORKSH STA; KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502; KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81; Kent JT, 2001, BIOMETRIKA, V88, P469, DOI 10.1093/biomet/88.2.469; Lang S., 1999, FUNDAMENTALS DIFFERE; Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802; Le HL, 2001, ADV APPL PROBAB, V33, P324, DOI 10.1017/S0001867800010818; Marques JS, 1997, PATTERN RECOGN LETT, V18, P49, DOI 10.1016/S0167-8655(96)00120-1; MAUREL P, 2003, P 2 IEEE WORKSH VAR; Miller MI, 2001, INT J COMPUT VISION, V41, P61, DOI 10.1023/A:1011161132514; MIO W, IN PRESS Q APPL MATH; Mokhtarian F., 1996, P INT WORKSH IM DAT, P35; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; Srivastava A, 2002, IEEE T SIGNAL PROCES, V50, P299, DOI 10.1109/78.978385; SRIVASTAVA A, 2003, TC03 FLOR STAT U DEP; SRIVASTAVA A, 2003, P 2 IEEE WORKSH VAR; Tagare HD, 2002, J MATH IMAGING VIS, V16, P57, DOI 10.1023/A:1013938519103; WOODS RP, 2002, CHARACTERIZING VOLUM; Younes L, 1999, IMAGE VISION COMPUT, V17, P381, DOI 10.1016/S0262-8856(98)00125-5	30	296	304	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2004	26	3					372	383		10.1109/TPAMI.2004.1262333	http://dx.doi.org/10.1109/TPAMI.2004.1262333			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	773WZ	15376883				2022-12-18	WOS:000188949400007
J	Liu, Y; Cheng, MM; Hu, XW; Bian, JW; Zhang, L; Bai, X; Tang, JH				Liu, Yun; Cheng, Ming-Ming; Hu, Xiaowei; Bian, Jia-Wang; Zhang, Le; Bai, Xiang; Tang, Jinhui			Richer Convolutional Features for Edge Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Edge detection; deep learning; richer convolutional features		Edge detection is a fundamental problem in computer vision. Recently, convolutional neural networks (CNNs) have pushed forward this field significantly. Existing methods which adopt specific layers of deep CNNs may fail to capture complex data structures caused by variations of scales and aspect ratios. In this paper, we propose an accurate edge detector using richer convolutional features (RCF). RCF encapsulates all convolutional features into more discriminative representation, which makes good usage of rich feature hierarchies, and is amenable to training via backpropagation. RCF fully exploits multiscale and multilevel information of objects to perform the image-to-image prediction holistically. Using VGG16 network, we achieve state-of-the-art performance on several available datasets. When evaluating on the well-known BSDS500 benchmark, we achieve ODS F-measure of 0.811 while retaining a fast speed (8 FPS). Besides, our fast version of RCF achieves ODS F-measure of 0.806 with 30 FPS. We also demonstrate the versatility of the proposed method by applying RCF edges for classical image segmentation.	[Liu, Yun; Cheng, Ming-Ming; Bian, Jia-Wang] Nankai Univ, Coll Comp Sci, Tianjin 300350, Peoples R China; [Zhang, Le] Agcy Sci Technol & Res, Adv Digital Sci Ctr, Inst Infocomm Res, Singapore 138602, Singapore; [Bai, Xiang] Huazhong Univ Sci & Technol, Wuhan 430074, Hubei, Peoples R China; [Tang, Jinhui] Nanjing Univ Sci & Technol, Sch Comp Sience & Engn, Nanjing 210094, Jiangsu, Peoples R China; [Hu, Xiaowei] Nankai Univ, Comp Sci, Tianjin 300071, Peoples R China	Nankai University; Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R); Huazhong University of Science & Technology; Nanjing University of Science & Technology; Nankai University	Cheng, MM (corresponding author), Nankai Univ, Coll Comp Sci, Tianjin 300350, Peoples R China.	nk12csly@mail.nankai.edu.cn; cmm@nankai.edu.cn; xiaowei.hu@mail.nankai.edu.cn; jiawang.bian@gmail.com; zhang.le@adsc.com.sg; xbai@hust.edu.cn; jinhuitang@njust.edu.cn	Cheng, Ming-Ming/A-2527-2009; Bian, Jia-Wang/AAP-2274-2020; Bian, Jia-Wang/AAH-4463-2019	Cheng, Ming-Ming/0000-0001-5550-8758; Bian, Jia-Wang/0000-0003-2046-3363; Bian, Jia-Wang/0000-0003-2046-3363; Liu, Yun/0000-0001-6143-0264; Tang, Jinhui/0000-0001-9008-222X	NSFC [61620106008, 61572264]; national youth talent support program, Tianjin Natural Science Foundation for Distinguished Young Scholars [17JCJQJC43700]; Huawei Innovation Research Program	NSFC(National Natural Science Foundation of China (NSFC)); national youth talent support program, Tianjin Natural Science Foundation for Distinguished Young Scholars; Huawei Innovation Research Program(Huawei Technologies)	This research was supported by NSFC (NO. 61620106008, 61572264), the national youth talent support program, Tianjin Natural Science Foundation for Distinguished Young Scholars (NO. 17JCJQJC43700), Huawei Innovation Research Program. A preliminary version of this work has been published in CVPR 2017 [1].	[Anonymous], 2018, ARXIV180305196; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Bertasius G, 2015, IEEE I CONF COMP VIS, P504, DOI 10.1109/ICCV.2015.65; Bertasius G, 2015, PROC CVPR IEEE, P4380, DOI 10.1109/CVPR.2015.7299067; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Cheng MM, 2016, LECT NOTES COMPUT SC, V9907, P867, DOI 10.1007/978-3-319-46487-9_53; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Dollar P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144; Ganin Y, 2015, LECT NOTES COMPUT SC, V9004, P536, DOI 10.1007/978-3-319-16808-1_36; Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23; Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79; Hallman S, 2015, PROC CVPR IEEE, P1732, DOI 10.1109/CVPR.2015.7298782; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hou Q, 2018, ARXIV180309859; Kokkinos I., 2015, INT C LEARN REPR; Liang YQ, 2014, P AMER CONTR CONF, P678, DOI 10.1109/ACC.2014.6858926; Liu C, 2017, IEEE INT CONF COMP V, P1739, DOI 10.1109/ICCVW.2017.204; Liu Xiao-Chang, 2017, P S NONPH AN REND LO; Liu Y, 2016, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.2016.32; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Maninis KK, 2016, LECT NOTES COMPUT SC, V9905, P580, DOI 10.1007/978-3-319-46448-0_35; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Mely DA, 2016, VISION RES, V120, P93, DOI 10.1016/j.visres.2015.11.007; Pont-Tuset J, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481406; Qu ZL, 2015, FRONT MECH ENG, V10, P1, DOI 10.1007/s11465-015-0325-2; Ren ZL, 2013, PROC CVPR IEEE, P2011, DOI 10.1109/CVPR.2013.262; Shen W, 2015, PROC CVPR IEEE, P3982, DOI 10.1109/CVPR.2015.7299024; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Simonyan K, 2015, 3 INT C LEARN REPR I; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; Wang YP, 2019, IEEE T IMAGE PROCESS, V28, P1285, DOI 10.1109/TIP.2018.2874279; Xie SN, 2017, INT J COMPUT VISION, V125, P3, DOI 10.1007/s11263-017-1004-z; Xu D., 2017, P INT C NEUR INF PRO, P3961; Xu YX, 2018, FOOD BIOSCI, V22, P1, DOI 10.1016/j.fbio.2017.12.010; Yang JM, 2016, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2016.28; Yu Z., 2017, P IEEE C COMP VIS PA, P21; Zeng C, 2017, 2017 IEEE 2ND ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P1, DOI 10.1109/IAEAC.2017.8053964; Zhao K, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1191; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	46	294	321	38	203	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2019	41	8					1939	1946		10.1109/TPAMI.2018.2878849	http://dx.doi.org/10.1109/TPAMI.2018.2878849			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IG2BD	30387723	Green Submitted			2022-12-18	WOS:000473598800011
J	Kakadiaris, IA; Passalis, G; Toderici, G; Murtuza, MN; Lu, YL; Karampatziakis, N; Theoharis, T				Kakadiaris, Ioannis A.; Passalis, Georgios; Toderici, George; Murtuza, Mohammed N.; Lu, Yunliang; Karampatziakis, Nikos; Theoharis, Theoharis			Three-dimensional face recognition in the presence of facial expressions: An annotated deformable model approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face and gesture recognition; information search and retrieval	3D	In this paper, we present the computational tools and a hardware prototype for 3D face recognition. Full automation is provided through the use of advanced multistage alignment algorithms, resilience to facial expressions by employing a deformable model framework, and invariance to 3D capture devices through suitable preprocessing steps. In addition, scalability in both time and space is achieved by converting 3D facial scans into compact metadata. We present our results on the largest known, and now publicly available, Face Recognition Grand Challenge 3D facial database consisting of several thousand scans. To the best of our knowledge, this is the highest performance reported on the FRGC v2 database for the 3D modality.	Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA; Univ Athens, Dept Informat, Athens 15784, Greece; Univ Athens, CBL, Athens 15784, Greece; Univ Houston, Dept Comp Sci, CBL, Houston, TX 77204 USA	Cornell University; National & Kapodistrian University of Athens; National & Kapodistrian University of Athens; University of Houston System; University of Houston	Kakadiaris, IA (corresponding author), Cornell Univ, Dept Comp Sci, 5132 Upson Hall, Ithaca, NY 14853 USA.	ikakadia@central.uh.edu; passalis@yahoo.com; toderici@cs.uh.edu; najamm@gmail.com; yunliang.lu@gmail.com; just.nikos@gmail.com; theotheo@di.uoa.gr	Theoharis, Theoharis/AAN-2555-2020					BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005; Chang K, 2005, PROC SPIE, V5779, P132, DOI 10.1117/12.604171; CHANG K, 2005, P IEEE COMP VIS PATT, P157; Chang KI, 2005, IEEE T PATTERN ANAL, V27, P619, DOI 10.1109/TPAMI.2005.70; Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007; FARKAS LG, 1994, ANTHR HEAD FACE; Gu XF, 2002, ACM T GRAPHIC, V21, P355; HUSKEN M, 2005, P IEEE COMP SOC C CO, P174; JOHNSON A, 1997, THESIS CARNEGIEMELLO; KAKADIARIS I, 2006, P SPIE DEF SEC S APR; Kakadiaris IA, 2005, PROC CVPR IEEE, P1022; Kakadiaris IA, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P505, DOI 10.1109/ICDSP.2002.1028138; KAKADIARIS IA, 2002, P BRIT MACH VIS C SE, P303; LIN WY, 2006, P IEEE C COMP VIS PA, V2, P1369; Loop C., 1987, SMOOTH SUBDIVISION S; Lu X, 2006, P IEEE COMP SOC C CO, P1377, DOI DOI 10.1109/CVPR..96; Mandal C, 1997, VISUALIZATION '97 - PROCEEDINGS, P371, DOI 10.1109/VISUAL.1997.663905; Mandal C, 2000, COMPUT AIDED DESIGN, V32, P479, DOI 10.1016/S0010-4485(00)00037-3; MAURER T, 2005, P IEEE WORKSH FAC RE; Metaxas DN, 2002, IEEE T PATTERN ANAL, V24, P1310, DOI 10.1109/TPAMI.2002.1039203; PAN G, 2005, P IEEE WORKSH FAC RE, P175; Papaioannou G, 2002, IEEE T PATTERN ANAL, V24, P114, DOI 10.1109/34.982888; PASSALIS G, 2005, P IEEE WORKSH FAC RE, P171; Phillips PJ, 2005, PROC CVPR IEEE, P947; Phillips PJ, 2000, COMPUTER, V33, P56, DOI 10.1109/2.820040; Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983; RUS T, 2006, P IEEE COMP VIS PATT, P1391; Russ TD, 2004, 38TH ANNUAL 2004 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P338, DOI 10.1109/CCST.2004.1405415; Siarry P, 1997, ACM T MATH SOFTWARE, V23, P209, DOI 10.1145/264029.264043; SIMONCELLI EP, 1992, IEEE T INFORM THEORY, V38, P587, DOI 10.1109/18.119725; Stollnitz E.J., 1996, WAVELETS COMPUTER GR; Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241; Wang Z, 2005, INT CONF ACOUST SPEE, P573; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; FACE RECOGNITION VEN	36	294	306	0	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2007	29	4					640	649		10.1109/TPAMI.2007.1017	http://dx.doi.org/10.1109/TPAMI.2007.1017			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HJ	17299221	Green Submitted			2022-12-18	WOS:000244855600012
J	Gao, YS; Leung, MKH				Gao, YS; Leung, MKH			Face recognition using line edge map	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face recognition; line edge map; line segment Hausdorff distance; structural information	NEURAL-NETWORK; IMAGES; AUTHENTICATION; IDENTIFICATION; CLASSIFICATION; ILLUMINATION	The automatic recognition of human faces presents a significant challenge to the pattern recognition research community. Typically, human faces are very similar in structure with minor differences from person to person. They are actually within one class OF "human face." Furthermore, lighting condition changes, facial expressions, and pose variations further complicate the face recognition task as one of the difficult problems in pattern analysis. This paper proposed a novel concept, "faces can be recognized using line edge map." A compact face feature, Line Edge Map (LEM), is generated for face coding and recognition. A thorough investigation on the proposed concept is conducted which covers all aspects on human face recognition, 1,e., face recognition, under 1) controlled/ideal condition and size variation, 2) varying lighting condition, 3) varying facial expression, and 4) varying pose. The system performances are also compared with the eigenface method, one of the best face recognition techniques, and reported experimental results of other methods. A face prefiltering technique is proposed to speed up the searching process. It is a very encouraging finding that the proposed face recognition technique has performed superior to the eigenface method in most of the comparison experiments. This research demonstrates that LEM together with the proposed generic line segment Hausdorff distance measure provide a new way for face coding and recognition.	Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Gao, YS (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Nanyang Ave, Singapore 639798, Singapore.	asysgao@ntu.edu.sg; asmkleung@ntu.edu.sg	Gao, Yongsheng/A-1436-2008	Gao, Yongsheng/0000-0002-5382-5351				Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229; [Anonymous], 2002, FAC DAT; BARON RJ, 1981, INT J MAN MACH STUD, V15, P137, DOI 10.1016/S0020-7373(81)80001-6; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; *BERN U, 2002, FAC DAT; BICHSEL M, 1991, THESIS EIDGENOSSISCH; BIEDERMAN I, 1988, COGNITIVE PSYCHOL, V20, P38, DOI 10.1016/0010-0285(88)90024-2; BRUCE V, 1992, APPL COGNITIVE PSYCH, V6, P619, DOI 10.1002/acp.2350060705; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; COX I, 1996, COMPUTER VISION PATT; Craw I, 1999, IEEE T PATTERN ANAL, V21, P725, DOI 10.1109/34.784286; Duc B, 1999, IEEE T IMAGE PROCESS, V8, P504, DOI 10.1109/83.753738; GAO Y, 1999, P IEEE 2 WORKSH AUT, P173; GOLDSTEIN AJ, 1971, PR INST ELECTR ELECT, V59, P748, DOI 10.1109/PROC.1971.8254; GRUDIN MA, 1997, THESIS LIVERPOOL J M; Huang T.S., 1993, P 4 INT C COMP VIS B, P121; KANADE T, 1973, PICTURE PROCESSING; Kaya Y., 1972, FRONTIERS PATTERN RE, V1, P265; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kotropoulos C, 2000, IEEE T IMAGE PROCESS, V9, P555, DOI 10.1109/83.841933; KUNG SY, 1995, IEEE T NEURAL NETWOR, V6, P170, DOI 10.1109/72.363439; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195; LEUNG MK, 1990, PATTERN RECOGN, V23, P69, DOI 10.1016/0031-3203(90)90049-Q; Lin SH, 1997, IEEE T NEURAL NETWOR, V8, P114, DOI 10.1109/72.554196; Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413; Manjunath B. S., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P373, DOI 10.1109/CVPR.1992.223162; Martinez A., 1998, 24 CVC, P24; MILLER B, 1994, IEEE SPECTRUM, V31, P22, DOI 10.1109/6.259484; MOSES Y, 1992, P EUR C COMP VIS, P820; MOSES Y, 1993, THEIS WEIZMAN I SCI; Otten R.H.J.M., 1989, ANNEALING ALGORITHM; PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814; Pentland A, 2000, COMPUTER, V33, P50, DOI 10.1109/2.820039; *PURD U, 2002, FAC DAT; Samaria F., 1994, P 2 IEEE WORKSH APPL; SAMARIA F, 1993, IMAGE PROCESSING THE; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; STONHAM TJ, 1984, ASPECTS FACE PROCESS, P426; SUNG KK, 1995, COMPUTER ANAL IMAGE, P432; Takacs B, 1998, PATTERN RECOGN, V31, P1873, DOI 10.1016/S0031-3203(98)00076-4; Tamura S, 1996, PATTERN RECOGN, V29, P331, DOI 10.1016/0031-3203(95)00073-9; Tong Y.L., 1990, MULTIVARIATE NORMAL, V1, P0172; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Van Laarhoven P.J., 1987, SIMULATED ANNEALING, P7; Wiskott L, 1996, NEUROIMAGE, V4, pS14, DOI 10.1006/nimg.1996.0043; Zhao L, 1999, PATTERN RECOGN, V32, P547, DOI 10.1016/S0031-3203(98)00119-8	49	294	323	0	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2002	24	6					764	779		10.1109/TPAMI.2002.1008383	http://dx.doi.org/10.1109/TPAMI.2002.1008383			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	556JU		Green Published, Green Submitted			2022-12-18	WOS:000175846300005
J	Brown, M; Hua, G; Winder, S				Brown, Matthew; Hua, Gang; Winder, Simon			Discriminative Learning of Local Image Descriptors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image descriptors; local features; discriminative learning; SIFT	RECOGNITION	In this paper, we explore methods for learning local image descriptors from training data. We describe a set of building blocks for constructing descriptors which can be combined together and jointly optimized so as to minimize the error of a nearest-neighbor classifier. We consider both linear and nonlinear transforms with dimensionality reduction, and make use of discriminant learning techniques such as Linear Discriminant Analysis (LDA) and Powell minimization to solve for the parameters. Using these techniques, we obtain descriptors that exceed state-of-the-art performance with low dimensionality. In addition to new experiments and recommendations for descriptor learning, we are also making available a new and realistic ground truth data set based on multiview stereo data.	[Brown, Matthew] Ecole Polytech Fed Lausanne, Comp Vis Lab, EPFL IC CVLAB, CH-1015 Lausanne, Switzerland; [Hua, Gang] Nokia Res Ctr Hollywood, Santa Monica, CA 90404 USA; [Winder, Simon] Microsoft Res, Microsoft Res Redmond, Interact Visual Media Grp, Redmond, WA 98052 USA	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Nokia Corporation; Nokia Bell Labs; Microsoft	Brown, M (corresponding author), Ecole Polytech Fed Lausanne, Comp Vis Lab, EPFL IC CVLAB, BC 309,Stn 14, CH-1015 Lausanne, Switzerland.	matthew.brown@epfl.ch; ganghua@gmail.com; swinder@microsoft.com						BABENKO B, 2007, P IEEE INT C COMP VI; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Belongie S., 2000, ADV NEURAL INFORM PR; Berg AC, 2001, PROC CVPR IEEE, P607; BROWN M, 2005, P 5 INT C 3D IM MOD; Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3; Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945; Chen HT, 2005, PROC CVPR IEEE, P846; DUCHENE J, 1988, IEEE T PATTERN ANAL, V10, P978, DOI 10.1109/34.9121; Fergus R., 2003, P IEEE C COMP VIS PA; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Goesele M., 2006, P IEEE C COMP VIS PA; Goesele M., 2007, P IEEE INT C COMP VI; Grauman K, 2005, P IEEE INT C COMP VI; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Hua G, 2007, P IEEE INT C COMP VI; HUA G, 2007, P IEEE C COMP VIS PA; HUBEL DH, 1979, SCI AM, V241, P150, DOI 10.1038/scientificamerican0979-150; Ke Y, 2004, PROC CVPR IEEE, P506; Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Mikolajczyk K., 2007, P IEEE INT C COMP VI; Moreels P, 2005, IEEE I CONF COMP VIS, P800; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Philbin J, 2007, CVPR; Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; ROTHWELL CA, 1992, LECT NOTES COMPUT SC, V588, P757; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Shotton J, 2008, P IEEE C COMP VIS PA; Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Strecha C., 2008, P IEEE C COMP VIS PA; Szeliski R., 2004, MSRTR200492; TOLA E, 2008, P IEEE C COMP VIS PA; Winder S., 2009, P IEEE C COMP VIS PA; Winder S. A. J., 2007, P IEEE C COMP VIS PA; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4	43	293	323	1	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2011	33	1					43	57		10.1109/TPAMI.2010.54	http://dx.doi.org/10.1109/TPAMI.2010.54			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	681AC	21088318	Green Published			2022-12-18	WOS:000284277600004
J	DICKMANNS, ED; MYSLIWETZ, BD				DICKMANNS, ED; MYSLIWETZ, BD			RECURSIVE 3-D ROAD AND RELATIVE EGO-STATE RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						INTELLIGENT CONTROL; PARALLEL ARCHITECTURES; REALTIME MACHINE VISION; RECURSIVE ESTIMATION; SPATIOTEMPORAL MODELING; 3-D IMAGE SEQUENCE PROCESSING; VISUAL NAVIGATION (OF ROAD VEHICLES)	VEHICLES	The general problem of recognizing both horizontal and vertical road curvature parameters while driving along the road has been solved recursively. A differential geometry representation decoupled for the two curvature components has been selected. Based on the planar solution of [7] and its refinements, a simple spatio-temporal model of the driving process allows us to take both spatial and temporal constraints into account effectively. The estimation process determines nine road and vehicle state parameters recursively at 25 Hz (40 ms) using four Intel 80286 and one 386 microprocessor. Results with the test vehicle (VaMoRs), which is a 5-ton van, are given for a hilly country road.	BAASEL LASERTECH,STARNBERG,GERMANY		DICKMANNS, ED (corresponding author), UNIV MUNICH,DEPT AEROSP TECHNOL,MUNICH,GERMANY.							BERGEN JR, 1990, DEC P ISR C AI COMP; Bierman G. J., 1975, Proceedings of the 1975 IEEE Conference on Decision Control including the 14th Symposium on Adaptive Processes, P337; Bierman G.J., 1977, FACTORIZATION METHOD; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; DEMENTHON D, 1987, IEEE INT C ROB AUT R, P1444; Dickmanns E.D., 1988, MACH VISION APPL, V1, P241; DICKMANNS ED, 1990, IEEE T SYST MAN CYB, V20, P1273, DOI 10.1109/21.61200; DICKMANNS ED, 1988, Z FLUGWISS WELTRAUM, V12, P71; DICKMANNS ED, 1986, MOBILE ROBOTS, V727, P161; DICKMANNS ED, 1988, 19TH P INT S EXP ROB; DICKMANNS ED, 1990, AUG P IEEE WORKSH IN; DICKMANNS ED, 1985, P C AUT 1985 AFCET T, P233; DICKMANNS ED, 1988, MACHINE VISION APPLI, V1, P5223; DICKMANNS ED, 1989, INTELLIGENT AUTONOMO, V2; EBERL G, 1987, THESIS U BUNDESWEHR; GRAEFE V, 1984, ROBOTICS ARTIFICIAL, P301; HARRIS C, 1990, SEP P BRIT MACH VIS, P73; HEEL J, 1990, MIT1190 AI MEM; Kalman RE., 1960, J BASIC ENG-T ASME, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; KARMANN KP, 1990, ICPR, V1, P268; KLUGE K, 1989, IEEE T ROBOTIC AUTOM, P1148; Maybeck P. S., 1982, STOCHASTIC MODELS ES; Meissner H., 1983, IMAGE SEQUENCE PROCE, P532; MYSLIWETZ B, 1987, NOV P SPIE C MOB ROB, V852; MYSLIWETZ B, 1990, THESIS U BUNDESWEHR; OZAWA S, 1985, PATTERN RECOGN, V19, P123; PELE S, 1990, JUN P INT C PATT REC, P109; Pollard S. B., 1990, Robotics Research. Fifth International Symposium, P174; RIVES P, 1986, DEC P C INT AUT SYST, P522; SAKURAI K, 1987, ANAL ROAD IMAGE SEEN, P6511; SCHELL FR, 1989, AGARD C P, V455; WUENSCHE HJ, 1988, BEWEGUNGSSTEUERUNG R, V20; ZHANG Z, 1990, 9TH P EUR C ART INT, P747; [No title captured]; [No title captured]	35	293	332	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1992	14	2					199	213		10.1109/34.121789	http://dx.doi.org/10.1109/34.121789			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC029					2022-12-18	WOS:A1992HC02900008
J	Jing, LL; Tian, YL				Jing, Longlong; Tian, Yingli			Self-Supervised Visual Feature Learning With Deep Neural Networks: A Survey	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Visualization; Videos; Training; Learning systems; Feature extraction; Annotations; Self-supervised learning; unsupervised learning; convolutional neural network; transfer learning; deep learning	CLASSIFICATION; MACHINE	Large-scale labeled data are generally required to train deep neural networks in order to obtain better performance in visual feature learning from images or videos for computer vision applications. To avoid extensive cost of collecting and annotating large-scale datasets, as a subset of unsupervised learning methods, self-supervised learning methods are proposed to learn general image and video features from large-scale unlabeled data without using any human-annotated labels. This paper provides an extensive review of deep learning-based self-supervised general visual feature learning methods from images or videos. First, the motivation, general pipeline, and terminologies of this field are described. Then the common deep neural network architectures that used for self-supervised learning are summarized. Next, the schema and evaluation metrics of self-supervised learning methods are reviewed followed by the commonly used datasets for images, videos, audios, and 3D data, as well as the existing self-supervised visual feature learning methods. Finally, quantitative performance comparisons of the reviewed methods on benchmark datasets are summarized and discussed for both image and video feature learning. At last, this paper is concluded and lists a set of promising future directions for self-supervised visual feature learning.	[Jing, Longlong] CUNY, Grad Ctr, Dept Comp Sci, New York, NY 10016 USA; [Tian, Yingli] CUNY City Coll, Dept Elect Engn, New York, NY 10031 USA; [Tian, Yingli] CUNY, Grad Ctr, Dept Comp Sci, New York, NY 10031 USA	City University of New York (CUNY) System; City University of New York (CUNY) System; City College of New York (CUNY); City University of New York (CUNY) System	Tian, YL (corresponding author), CUNY City Coll, Dept Elect Engn, New York, NY 10031 USA.; Tian, YL (corresponding author), CUNY, Grad Ctr, Dept Comp Sci, New York, NY 10031 USA.	ljing@gradcenter.cuny.edu; ytian@ccny.cuny.edu			National Science Foundation [IIS-1400802]	National Science Foundation(National Science Foundation (NSF))	This material is based upon work supported by the National Science Foundation under award number IIS-1400802.	Abu-El-Haija S., 2016, ARXIV; Achlioptas Panos, 2017, ARXIV170702392; Agrawal P, 2015, IEEE I CONF COMP VIS, P37, DOI 10.1109/ICCV.2015.13; Ahsan U, 2019, IEEE WINT CONF APPL, P179, DOI 10.1109/WACV.2019.00025; Alwassel Humam, 2019, ARXIV191112667; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2017, P IEEE INT C COMP VI; Arandjelovic R, 2017, IEEE I CONF COMP VIS, P609, DOI 10.1109/ICCV.2017.73; Arjovsky M, 2017, PR MACH LEARN RES, V70; Babaeizadeh Mohammad, 2018, ICLR; Bau D, 2017, PROC CVPR IEEE, P3319, DOI 10.1109/CVPR.2017.354; Bau David, 2019, INT C LEARN REPR ICL; Bojanowski P., 2017, P INT C MACH LEARN; Brattoli B, 2017, PROC CVPR IEEE, P3747, DOI 10.1109/CVPR.2017.399; Brock A., 2019, INT C LEARNING REPRE; Buchler U, 2018, LECT NOTES COMPUT SC, V11219, P797, DOI 10.1007/978-3-030-01267-0_47; Cai J., 2018, P EUROPEAN C COMPUTE, P666; Carl V., 2016, ADV NEURAL INFORM PR, V29, P613, DOI DOI 10.13016/M26GIH-TNYZ; Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9; Chang Angel X., 2015, ARXIV151203012CSGR P; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen T, 2020, PR MACH LEARN RES, V119; Chen T, 2019, PROC CVPR IEEE, P12146, DOI 10.1109/CVPR.2019.01243; Coates Adam, 2011, AISTATS, V6, DOI DOI 10.1177/1753193410390845; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Doersch C, 2017, IEEE I CONF COMP VIS, P2070, DOI 10.1109/ICCV.2017.226; Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Donahue Jeff, 2017, INT C LEARN REPR ICL; Dosovitskiy A., 2017, C ROBOT LEARNING, P1; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Faktor A., 2014, P BRIT MACH VIS C, V2; Feng YT, 2019, AAAI CONF ARTIF INTE, P8279; Fernando B, 2017, PROC CVPR IEEE, P5729, DOI 10.1109/CVPR.2017.607; Gadelha M, 2018, LECT NOTES COMPUT SC, V11211, P105, DOI 10.1007/978-3-030-01234-2_7; Gan C, 2018, PROC CVPR IEEE, P5589, DOI 10.1109/CVPR.2018.00586; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Gemmeke JF, 2017, INT CONF ACOUST SPEE, P776, DOI 10.1109/ICASSP.2017.7952261; Ghadiyaram D, 2019, PROC CVPR IEEE, P12038, DOI 10.1109/CVPR.2019.01232; Gidaris Spyros, 2018, ARXIV180307728; Girdhar R, 2016, LECT NOTES COMPUT SC, V9910, P484, DOI 10.1007/978-3-319-46466-4_29; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Gomez L, 2017, PROC CVPR IEEE, P2017, DOI 10.1109/CVPR.2017.218; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Goyal P, 2019, IEEE I CONF COMP VIS, P6400, DOI 10.1109/ICCV.2019.00649; Han TD, 2019, IEEE INT CONF COMP V, P1483, DOI 10.1109/ICCVW.2019.00186; Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685; Hassani K, 2019, IEEE I CONF COMP VIS, P8159, DOI 10.1109/ICCV.2019.00825; He K., 2019, P IEEE C COMP VIS PA; He KM, 2019, IEEE I CONF COMP VIS, P4917, DOI 10.1109/ICCV.2019.00502; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hensel M, 2017, ADV NEUR IN, V30; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hong WX, 2018, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2018.00145; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659; Iizuka S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925974; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Iyer G., 2018, P IEEE C COMP VIS PA; Jayaraman D, 2016, PROC CVPR IEEE, P3852, DOI 10.1109/CVPR.2016.418; Jayaraman D, 2015, IEEE I CONF COMP VIS, P1413, DOI 10.1109/ICCV.2015.166; Jenni S, 2018, PROC CVPR IEEE, P2733, DOI 10.1109/CVPR.2018.00289; JiajunWu Chengkai Zhang, 2016, ADV NEURAL INFORM PR, V29, DOI DOI 10.5555/3157096.3157106; Jiang HZ, 2018, LECT NOTES COMPUT SC, V11215, P20, DOI 10.1007/978-3-030-01252-6_2; Jing L., 2020, SELF SUPERVISTED MOD; Jing L., 2020, P IEEE C COMPUTER VI; Jing Longlong, 2018, ARXIV181111387, P2; Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453; Kay W., 2017, ARXIV PREPRINT ARXIV; Kim D, 2019, AAAI CONF ARTIF INTE, P8545; Kim D, 2018, IEEE WINT CONF APPL, P793, DOI 10.1109/WACV.2018.00092; Kolesnikov A, 2019, PROC CVPR IEEE, P1920, DOI 10.1109/CVPR.2019.00202; Korbar B, 2018, ADV NEUR IN, V31; Krahenbuhl P, 2018, PROC CVPR IEEE, P2955, DOI 10.1109/CVPR.2018.00312; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Krizhevsky A., 2009, TR2009 U TOR DEP COM, P32; Kuehne H, 2013, HIGH PERFORMANCE COMPUTING IN SCIENCE AND ENGINEERING '12: TRANSACTIONS OF THE HIGH PERFORMANCE COMPUTING CENTER, STUTTGART (HLRS) 2012, P571, DOI 10.1007/978-3-642-33374-3_41; Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z; Larsson G, 2017, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2017.96; Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Lee HY, 2017, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2017.79; Li D, 2016, LECT NOTES COMPUT SC, V9908, P678, DOI 10.1007/978-3-319-46493-0_41; Li Wen, 2017, ARXIV170802862; Li Y, 2016, PROC CVPR IEEE, P1619, DOI 10.1109/CVPR.2016.179; Liang XD, 2017, IEEE I CONF COMP VIS, P1762, DOI 10.1109/ICCV.2017.194; Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu J, 2018, PR MACH LEARN RES, V80; Luo ZL, 2017, PROC CVPR IEEE, P7101, DOI 10.1109/CVPR.2017.751; Mahendran Aravindh, 2018, ACCV; Mathieu M., 2016, INT C LEARN REPR ICL; McCormac J, 2017, IEEE I CONF COMP VIS, P2697, DOI 10.1109/ICCV.2017.292; Meister S, 2018, AAAI CONF ARTIF INTE, P7251; Misra I, 2016, LECT NOTES COMPUT SC, V9905, P527, DOI 10.1007/978-3-319-46448-0_32; Monfort M, 2020, IEEE T PATTERN ANAL, V42, P502, DOI 10.1109/TPAMI.2019.2901464; Mundhenk TN, 2018, PROC CVPR IEEE, P9339, DOI 10.1109/CVPR.2018.00973; Ng A.Y., 2011, NIPS WORKSH DEEP LEA; Noroozi M, 2018, PROC CVPR IEEE, P9359, DOI 10.1109/CVPR.2018.00975; Noroozi M, 2017, IEEE I CONF COMP VIS, P5899, DOI 10.1109/ICCV.2017.628; Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5; Owens A., 2018, P EUR C COMP VIS; Owens A, 2016, LECT NOTES COMPUT SC, V9905, P801, DOI 10.1007/978-3-319-46448-0_48; Pathak D, 2017, PROC CVPR IEEE, P6024, DOI 10.1109/CVPR.2017.638; Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278; Patrick Mandela, 2020, ARXIV200304298; Piczak KJ, 2015, IEEE INT WORKS MACH; Piczak KJ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1015, DOI 10.1145/2733373.2806390; Piergiovanni AJ, 2019, PROC CVPR IEEE, P9937, DOI 10.1109/CVPR.2019.01018; Radford A., 2016, INT C LEARN REPR; Reda FA, 2018, LECT NOTES COMPUT SC, V11211, P747, DOI 10.1007/978-3-030-01234-2_44; Redmon J., 2016, P IEEE C COMPUTER VI, P779, DOI DOI 10.1109/CVPR.2016.91; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ren ZZ, 2018, PROC CVPR IEEE, P762, DOI [10.1109/CVPR.2018.00086, 10.1109/CVPR.2018.00104]; Roma G, 2013, IEEE WORK APPL SIG; Sailor HB, 2017, INTERSPEECH, P3107, DOI 10.21437/Interspeech.2017-831; Saito M, 2017, IEEE I CONF COMP VIS, P2849, DOI 10.1109/ICCV.2017.308; Salimans T., 2016, ADV NEUR IN, P2234; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Santa Cruz R, 2019, IEEE T PATTERN ANAL, V41, P3100, DOI 10.1109/TPAMI.2018.2873701; Sayed N., 2018, GCPR; Shah Shital, 2018, FIELD SERVICE ROBOTI, P621, DOI [10.1007/978-3-319-67361-5_40, DOI 10.1007/978-3-319-67361-5_40]; Sharma A, 2016, LECT NOTES COMPUT SC, V9915, P236, DOI 10.1007/978-3-319-49409-8_20; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shi XJ, 2015, ADV NEUR IN, V28; Simonyan K, 2014, ADV NEUR IN, V27; Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28; Soomro K., 2012, ARXIV; Srivastava N, 2015, PR MACH LEARN RES, V37, P843; Stowell D, 2015, IEEE T MULTIMEDIA, V17, P1733, DOI 10.1109/TMM.2015.2428998; Stretcu O., 2015, P BRIT MACH VIS C, V1; Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802; Tian Y., 2020, ECCV, P776, DOI [10.48550/arXiv.1906.05849, DOI 10.1007/978-3-030-58621-8_45]; Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675; Tran D, 2016, IEEE COMPUT SOC CONF, P402, DOI 10.1109/CVPRW.2016.57; Tulyakov S, 2018, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2018.00165; van den Oord Aaron, 2018, ARXIV180703748; Villegas Ruben, 2017, ICLR, DOI DOI 10.48550/ARXIV.1706.08033; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang JL, 2019, PROC CVPR IEEE, P4001, DOI 10.1109/CVPR.2019.00413; Wang XL, 2017, IEEE I CONF COMP VIS, P1338, DOI 10.1109/ICCV.2017.149; Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320; Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362; Wei C., 2019, P IEEE C COMP VIS PA; Wei DL, 2018, PROC CVPR IEEE, P8052, DOI 10.1109/CVPR.2018.00840; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801; Xie JY, 2016, PR MACH LEARN RES, V48; Xu DJ, 2019, PROC CVPR IEEE, P10326, DOI 10.1109/CVPR.2019.01058; Yang JW, 2016, PROC CVPR IEEE, P5147, DOI 10.1109/CVPR.2016.556; Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029; Yi L, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980238; Yin ZC, 2018, PROC CVPR IEEE, P1983, DOI 10.1109/CVPR.2018.00212; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang CX, 2018, PROTEINS, V86, P136, DOI 10.1002/prot.25414; Zhang L, 2019, INT CONF 3D VISION, P395, DOI 10.1109/3DV.2019.00051; Zhang R., 2017, ACM T GRAPHIC; Zhang R, 2017, PROC CVPR IEEE, P645, DOI 10.1109/CVPR.2017.76; Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40; Zhang Yinda, 2018, ECCV, P784; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhao YH, 2019, PROC CVPR IEEE, P1009, DOI 10.1109/CVPR.2019.00110; Zhou BL, 2019, INT J COMPUT VISION, V127, P302, DOI 10.1007/s11263-018-1140-0; Zhou Bolei, 2016, PLACES IMAGE DATABAS; Zhou Bolei, 2014, ADV NEURAL INFORM PR, P7, DOI DOI 10.5555/2968826.2968881; Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zou YL, 2018, LECT NOTES COMPUT SC, V11209, P38, DOI 10.1007/978-3-030-01228-1_3	186	292	297	120	161	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2021	43	11					4037	4058		10.1109/TPAMI.2020.2992393	http://dx.doi.org/10.1109/TPAMI.2020.2992393			22	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WA1JH	32386141	Green Submitted			2022-12-18	WOS:000702649700025
J	Esposito, F; Malerba, D; Semeraro, G				Esposito, F; Malerba, D; Semeraro, G			A comparative analysis of methods for pruning decision trees	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						decision trees; top-down induction of decision trees; simplification of decision trees; pruning and grafting operators; optimal pruning; comparative studies	INDUCTION; RULES; BIAS	In this paper, we address the problem of retrospectively pruning decision trees induced from data, according to a top-down approach. This problem has received considerable attention in the areas of pattern recognition and machine learning, and many distinct methods have been proposed in literature. We make a comparative study of six well-known pruning methods with the aim of understanding their theoretical foundations, their computational complexity, and the strengths and weaknesses of their formulation. Comments on the characteristics of each method are empirically supported. In particular, a wide experimentation performed on several data sets leads us to opposite conclusions on the predictive accuracy of simplified trees from some drawn in the literature. We attribute this divergence to differences in experimental designs. Finally, we prove and make use of a property of the reduced error pruning method to obtain an objective evaluation of the tendency to overprune/underprune observed in each method.			Esposito, F (corresponding author), UNIV BARI,DIPARTIMENTO INFORMAT,VIA ORABONA 4,I-70126 BARI,ITALY.		Esposito, Floriana/M-6038-2019; Malerba, Donato/H-3850-2012; Semeraro, Giovanni/AAC-2156-2020	Malerba, Donato/0000-0001-8432-4608; Semeraro, Giovanni/0000-0001-6883-1853; Esposito, Floriana/0000-0002-1075-3239				BOHANEC M, 1994, MACH LEARN, V15, P223, DOI 10.1023/A:1022685808937; BUNTINE W, 1992, MACH LEARN, V8, P75, DOI 10.1023/A:1022686419106; Buntine W., 1990, THESIS U TECHNOLOGY; CESTNIK B, 1991, LECT NOTES ARTIFICIA, P138; Cestnik G., 1987, PROGR MACHINE LEARNI, P31; Edgington E. S., 1987, RANDOMIZATION TESTS; EFRON B, 1983, AM STAT, V37, P36, DOI 10.2307/2685844; ESPOSITO F, 1993, LECT NOTES ARTIF INT, V667, P165; Fayyad UM, 1992, P 10 NAT C ART INT S, P104; GELFAND SB, 1991, IEEE T PATTERN ANAL, V13, P138; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; HOLTE RC, 1989, 11TH P INT JOINT C A, P813; KITTLER J, 1980, IEEE T PATTERN ANAL, V4, P215; KOHAVI R, 1995, P 12 INT C MACH LEAR, P304; Malerba D, 1996, LEARNING DATA, P365, DOI [10.1007/978-1-4612-2404-4_35, DOI 10.1007/978-1-4612-2404-4_35]; MALERBA D, 1994, P 5 IT WORKSH MACH L, P33; Mingers J., 1989, Machine Learning, V3, P319, DOI 10.1007/BF00116837; Mingers J., 1989, Machine Learning, V4, P227, DOI 10.1023/A:1022604100933; MINGERS J, 1987, J OPER RES SOC, V38, P39, DOI 10.1057/jors.1987.5; MURPHY PM, 1996, UCI RESPOSITORY MACH; NIBLETT T, 1986, P EXPERT SYSTEMS 86; NIBLETT T, 1987, PROGR MACHINE LEARNI, P67; Olshen R., 1984, CLASSIFICATION REGRE; Quinlan J., 2014, C4 5 PROGRAMS MACHIN, DOI DOI 10.1007/BF00993309; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; QUINLAN JR, 1989, INFORM COMPUT, V80, P227, DOI 10.1016/0890-5401(89)90010-2; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150; SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458; SCHAFFER C, 1993, MACH LEARN, V10, P153, DOI 10.1023/A:1022653209073; SCHAFFER C, 1992, P 10 NAT C ART INT, P147; SCHAFFER C, 1992, P 9 INT C MACH LEARN, P394; WATKINS CJC, 1989, PROGR MACHINE LEARNI, P79; WHITE AP, 1994, MACH LEARN, V15, P321, DOI 10.1023/A:1022694010754	34	292	320	1	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1997	19	5					476	491		10.1109/34.589207	http://dx.doi.org/10.1109/34.589207			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XB163					2022-12-18	WOS:A1997XB16300006
J	Jain, AK; Zhong, Y; Lakshmanan, S				Jain, AK; Zhong, Y; Lakshmanan, S			Object matching using deformable templates	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object matching; deformable templates; image database; image segmentation; Bayesian optimization; multiresolution algorithm	HOUGH TRANSFORM; GLOBAL OPTIMIZATION; RESTORATION; MODELS; IMAGES	We propose a general object localization and retrieval scheme based on object shape using deformable templates. Prior knowledge of an object shape is described by a prototype template which consists of the representative contour/edges, and a set of probabilistic deformation transformations on the template. A Bayesian scheme, which is based on this prior knowledge and the edge information in the input image, is employed to find a match between the deformed template and objects in the image. Computational efficiency is achieved via a coarse-to-fine implementation of the matching algorithm. Our method has been applied to retrieve objects with a variety of shapes from images with complex background. The proposed scheme is invariant to location, rotation, and moderate scale changes of the template.	UNIV MICHIGAN, DEPT ELECT & COMP ENGN, DEARBORN, MI 48128 USA	University of Michigan System; University of Michigan	Jain, AK (corresponding author), MICHIGAN STATE UNIV, DEPT COMP SCI, E LANSING, MI 48824 USA.			Lakshmanan, Sridhar/0000-0001-7387-3943				AMIT Y, 1991, J AM STAT ASSOC, V86, P376, DOI 10.2307/2290581; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BURR DJ, 1981, IEEE T PATTERN ANAL, V3, P708, DOI 10.1109/TPAMI.1981.4767176; Chakraborty A., 1994, Proceedings 1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.94CH3405-8), P624, DOI 10.1109/CVPR.1994.323790; CHOW YS, 1991, HANDS PATTERN THEORE; COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675; COOTES TF, 1994, P BRIT MACH VIS C, V1, P327; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238; FIGUEIREDO M, 1992, IEEE T MED IMAGING, V11, P416; GELFAND SB, 1993, SIAM J CONTROL OPTIM, V31, P111, DOI 10.1137/0331009; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GEMAN S, 1986, SIAM J CONTROL OPTIM, V24, P1031, DOI 10.1137/0324060; GEMAN S, 1995, COMMUNICATION    APR; GIDAS B, 1985, 24TH P IEEE C DEC CO, P774; GORKANI MM, 1994, P 12 INT C PATT REC, V67, pA459; Grenander U., 1994, J ROY STAT SOC, V56, P1; GRENANDER U, 1993, ADV APPL STAT STAT I, V1, P89; Grenander U., 1976, APPL MATH SCI, V18; HOLT B, 1994, P SOC PHOTO-OPT INS, V2185, P70, DOI 10.1117/12.171782; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LAKSHMANAN S, IN PRESS IEEE T PATT; LEAVERS VF, 1993, CVGIP-IMAG UNDERSTAN, V58, P250, DOI 10.1006/ciun.1993.1041; LEYMARIE F, 1993, IEEE T PATTERN ANAL, V15, P617, DOI 10.1109/34.216733; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; MILLER MI, 1993, P NATL ACAD SCI USA, V90, P11944, DOI 10.1073/pnas.90.24.11944; MOSHFEGHI M, 1994, IEEE T IMAGE PROCESS, V3, P128, DOI 10.1109/83.277895; STORVIK G, 1994, IEEE T PATTERN ANAL, V16, P976, DOI 10.1109/34.329011; SZELISKI R, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P194, DOI 10.1109/CVPR.1994.323829; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; WITKIN A, 1987, INT J COMPUT VISION, V1, P133, DOI 10.1007/BF00123162; YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169	35	292	359	1	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1996	18	3					267	278		10.1109/34.485555	http://dx.doi.org/10.1109/34.485555			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UA455					2022-12-18	WOS:A1996UA45500004
J	Torresani, L; Hertzmann, A; Bregler, C				Torresani, Lorenzo; Hertzmann, Aaron; Bregler, Christoph			Nonrigid structure-from-motion: Estimating shape and motion with hierarchical priors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nonrigid structure-from-motion; probabilistic principal components analysis; factor analysis; linear dynamical systems; expectation-maximization	BIOLOGICAL MOTION	This paper describes methods for recovering time-varying shape and motion of nonrigid 3D objects from uncalibrated 2D point tracks. For example, given a video recording of a talking person, we would like to estimate the 3D shape of the face at each instant and learn a model of facial deformation. Time-varying shape is modeled as a rigid transformation combined with a nonrigid deformation. Reconstruction is ill-posed if arbitrary deformations are allowed, and thus additional assumptions about deformations are required. We first suggest restricting shapes to lie within a low-dimensional subspace and describe estimation algorithms. However, this restriction alone is insufficient to constrain reconstruction. To address these problems, we propose a reconstruction method using a Probabilistic Principal Components Analysis (PPCA) shape model and an estimation algorithm that simultaneously estimates 3D shape and motion for each instant, learns the PPCA model parameters, and robustly fills-in missing data points. We then extend the model to represent temporal dynamics in object shape, allowing the algorithm to robustly handle severe cases of missing data.	[Torresani, Lorenzo] Microsoft Res, Cambridge CB3 0FB, England; [Hertzmann, Aaron] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 2E4, Canada; [Bregler, Christoph] NYU, Courant Inst, New York, NY 10003 USA	Microsoft; University of Toronto; New York University	Torresani, L (corresponding author), Microsoft Res, 7 JJ Thomson Ave, Cambridge CB3 0FB, England.	ltorre@microsoft.com; hertzman@dgp.toronto.edu; bregler@courant.nyu.edu		Hertzmann, Aaron/0000-0001-9667-0292				Barbic J, 2005, ACM T GRAPHIC, V24, P982, DOI 10.1145/1073204.1073300; Bascle B, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P323, DOI 10.1109/ICCV.1998.710738; Bishop CM, 1999, IEE CONF PUBL, P509, DOI 10.1049/cp:19991160; BLANZ V, 1999, P 26 ANN C COMP GRAP, P187, DOI DOI 10.1145/311535.311556; Brand M, 2005, PROC CVPR IEEE, P122; Brandt Tobias, 2001, Curr Treat Options Neurol, V3, P463, DOI 10.1007/s11940-001-0034-5; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Buchanan AM, 2005, PROC CVPR IEEE, P316; Cootes T. E, 2001, P SPIE MED IMAGING; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; Dellaert F, 2003, MACH LEARN, V50, P45, DOI 10.1023/A:1020245811187; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Gelman A., 2003, BAYESIAN DATA ANAL, DOI 10.1201/b16018; Ghahramani Z., 1996, CRGTR962 U TOR; Ghahramani Zoubin, 1996, CRGTR961 U TOR; Han M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P163, DOI 10.1109/ICCV.2001.937513; Hartley R., 2003, MULTIPLE VIEW GEOMET; JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378; MACKAY DJC, 1995, NETWORK-COMP NEURAL, V6, P469, DOI 10.1088/0954-898X/6/3/011; Parke FI, 1972, P ACM ANN C, V1, P451; Pavlovic V, 2001, ADV NEUR IN, V13, P981; Roweis S, 1998, ADV NEUR IN, V10, P626; Shumway R. H., 1982, Journal of Time Series Analysis, V3, P253, DOI 10.1111/j.1467-9892.1982.tb00349.x; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torresani L, 2004, LECT NOTES COMPUT SC, V3022, P299; Torresani L, 2001, PROC CVPR IEEE, P493; TORRESANI L, 2004, P ANN C ADV NEUR INF, P1555; Troje NF, 2002, J VISION, V2, P371, DOI 10.1167/2.5.2; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; ULLMAN S, 1984, PERCEPTION, V13, P255, DOI 10.1068/p130255; WANG JM, 2006, P ANN C ADV NEUR INF, P1441; Xiao J, 2006, INT J COMPUT VISION, V67, P233, DOI 10.1007/s11263-005-3962-9; Yezzi AJ, 2003, INT J COMPUT VISION, V53, P153, DOI 10.1023/A:1023048024042	35	291	294	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2008	30	5					878	892		10.1109/TPAMI.2007.70752	http://dx.doi.org/10.1109/TPAMI.2007.70752			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	272SI	18369256				2022-12-18	WOS:000253879700010
J	PARENT, P; ZUCKER, SW				PARENT, P; ZUCKER, SW			TRACE INFERENCE, CURVATURE CONSISTENCY, AND CURVE DETECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											PARENT, P (corresponding author), MCGILL UNIV,DEPT ELECT ENGN,MCGILL RES CTR INTELLIGENT MACHINES,COMP VIS & ROBOT LAB,MONTREAL H3A 2A7,QUEBEC,CANADA.							ATTNEAVE F, 1959, APPLICATIONS INFORMA; BARROW HG, 1981, ARTIF INTELL, V17, P75, DOI 10.1016/0004-3702(81)90021-7; BINFORD TO, 1981, ARTIF INTELL, V17, P205, DOI 10.1016/0004-3702(81)90025-4; BRADY M, 1984, ROBOT RES, P37; DAVIS LS, 1981, ARTIF INTELL, V17, P245, DOI 10.1016/0004-3702(81)90026-6; DAVIS LS, 1977, IEEE T PATTERN ANAL; Do Carmo M.P., 2016, DIFFERENTIAL GEOMETR, Vsecond; Faugeras O., 1979, Proceedings of the 1979 IEEE Computer Society Conference on Pattern Recognition and Image Processing, P318; FISCHLER MA, 1983, 1983 P IM UND WORKSH; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HARTSHORNE R, 1972, ALGEBRAIC GEOMETRY; Hedlund M., 1982, Proceedings of PRIP 82. IEEE Computer Society Conference on Pattern Recognition and Image Processing, P93; HOFFMAN D, 1986, PIXELS PREDICATES; HUBEL DH, 1977, PROC R SOC SER B-BIO, V198, P1, DOI 10.1098/rspb.1977.0085; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; IVERSON L, 1987, P IEEE WORKSHOP COMP; KOENDERINK JJ, 1982, PERCEPTION, V11, P129, DOI 10.1068/p110129; MARTELLI A, 1976, COMMUN ACM, V19, P73, DOI 10.1145/359997.360004; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; MOHAMMED JL, 1983, IEEE T PATTERN ANAL, V5, P330, DOI 10.1109/TPAMI.1983.4767394; MONTANARI U, 1971, COMMUN ACM, V14, P335, DOI 10.1145/362588.362594; Papoulis A., 2002, PROBABILITY RANDOM V; PARENT P, IN PRESS IEEE T PATT; PARENT P, 1985, TR8515R MCG U COMP V; PELEG S, 1978, IEEE T SYST MAN CYB, V8, P548; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SANDER P, 1988, TRCIM886 MCG U MCG R; TERZOPOULOS D, 1986, PIXELS PREDICATES; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9; ZUCKER SW, 1986, HUM NEUROBIOL, V5, P121; ZUCKER SW, 1977, IEEE T COMPUT, V26, P394, DOI 10.1109/TC.1977.1674848; ZUCKER SW, 1977, IEEE T COMPUT, V26, P92; ZUCKER SW, 1988, TRCIM8817 MCG U MCG; ZUCKER SW, 1982, TR828R MCG U COMP VI; ZUCKER SW, 2ND P ICCV TARP SPRI; ZUCKER SW, 1985, COMPUT VISION GRAPHI; ZUCKER SW, 1984, MULTIRESOLUTION IMAG	39	291	298	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1989	11	8					823	839		10.1109/34.31445	http://dx.doi.org/10.1109/34.31445			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AH079		Green Submitted			2022-12-18	WOS:A1989AH07900004
J	Cai, ZW; Vasconcelos, N				Cai, Zhaowei; Vasconcelos, Nuno			Cascade R-CNN: High Quality Object Detection and Instance Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Detectors; Object detection; Training; Proposals; Task analysis; Computer architecture; Feature extraction; Object detection; high quality; cascade; bounding box regression; instance segmentation		In object detection, the intersection over union (IoU) threshold is frequently used to define positives/negatives. The threshold used to train a detector defines its quality. While the commonly used threshold of 0.5 leads to noisy (low-quality) detections, detection performance frequently degrades for larger thresholds. This paradox of high-quality detection has two causes: 1) overfitting, due to vanishing positive samples for large thresholds, and 2) inference-time quality mismatch between detector and test hypotheses. A multi-stage object detection architecture, the Cascade R-CNN, composed of a sequence of detectors trained with increasing IoU thresholds, is proposed to address these problems. The detectors are trained sequentially, using the output of a detector as training set for the next. This resampling progressively improves hypotheses quality, guaranteeing a positive training set of equivalent size for all detectors and minimizing overfitting. The same cascade is applied at inference, to eliminate quality mismatches between hypotheses and detectors. An implementation of the Cascade R-CNN without bells or whistles achieves state-of-the-art performance on the COCO dataset, and significantly improves high-quality detection on generic and specific object datasets, including VOC, KITTI, CityPerson, and WiderFace. Finally, the Cascade R-CNN is generalized to instance segmentation, with nontrivial improvements over the Mask R-CNN.	[Cai, Zhaowei; Vasconcelos, Nuno] Univ Calif San Diego, Dept Elect & Comp Engn, San Diego, CA 92093 USA	University of California System; University of California San Diego	Cai, ZW (corresponding author), Univ Calif San Diego, Dept Elect & Comp Engn, San Diego, CA 92093 USA.	zwcai@ucsd.edu; nuno@ucsd.edu		Vasconcelos, Nuno/0000-0002-9024-4302	NSF [IIS-1546305, IIS-1637941]	NSF(National Science Foundation (NSF))	This work was funded by NSF Awards IIS-1546305 and IIS-1637941, and a GPU donation from NVIDIA. The authors would also like to thank Kaiming He for valuable discussions.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; Bharat Singh, 2017, Arxiv, DOI arXiv:1704.04503; Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644; Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22; Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343; Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Dollar P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094; Elkan C., 2001, INT JOINT C ART INT, V17, P973, DOI DOI 10.5555/1642194.1642224; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Gidaris S, 2016, PROC CVPR IEEE, P789, DOI 10.1109/CVPR.2016.92; Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135; Gidaris Spyros, 2016, ARXIV160604446; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Han Song, 2015, ADV NEURAL INFORM PR, P1135, DOI DOI 10.5555/2969239.2969366; He KM, 2019, IEEE I CONF COMP VIS, P4917, DOI 10.1109/ICCV.2019.00502; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378; Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48; Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45; Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170; Li ZM, 2018, LECT NOTES COMPUT SC, V11213, P339, DOI 10.1007/978-3-030-01240-3_21; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913; Liu W, 2018, LECT NOTES COMPUT SC, V11218, P643, DOI 10.1007/978-3-030-01264-9_38; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Masnadi-Shirazi H, 2011, IEEE T PATTERN ANAL, V33, P294, DOI 10.1109/TPAMI.2010.71; Najibi M, 2016, PROC CVPR IEEE, P2369, DOI 10.1109/CVPR.2016.260; Ouyang WL, 2017, IEEE I CONF COMP VIS, P1956, DOI 10.1109/ICCV.2017.214; Peng C, 2018, PROC CVPR IEEE, P6181, DOI 10.1109/CVPR.2018.00647; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Saberian MJ, 2012, IEEE T PATTERN ANAL, V34, P2005, DOI 10.1109/TPAMI.2011.281; Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89; Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wu X., 2018, ABS180308208 CORR, V401, P1; Wu YX, 2018, LECT NOTES COMPUT SC, V11217, P3, DOI 10.1007/978-3-030-01261-8_1; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yan JJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P392, DOI 10.1109/ICCVW.2013.126; Yang B, 2016, PROC CVPR IEEE, P6043, DOI 10.1109/CVPR.2016.650; Yang S, 2016, PROC CVPR IEEE, P5525, DOI 10.1109/CVPR.2016.596; Yoo D, 2015, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2015.305; Zagoruyko S, 2016, 5 INT C LEARN REPRES, DOI DOI 10.5244/C.30.87; Zhang SS, 2017, PROC CVPR IEEE, P4457, DOI 10.1109/CVPR.2017.474; Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442	63	290	300	81	268	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2021	43	5					1483	1498		10.1109/TPAMI.2019.2956516	http://dx.doi.org/10.1109/TPAMI.2019.2956516			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RJ3YD	31794388	Green Submitted			2022-12-18	WOS:000637533800002
J	Shi, JP; Yan, Q; Xu, L; Jia, JY				Shi, Jianping; Yan, Qiong; Xu, Li; Jia, Jiaya			Hierarchical Image Saliency Detection on Extended CSSD	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Saliency detection; region scale	OBJECT DETECTION; ATTENTION; MODEL	Complex structures commonly exist in natural images. When an image contains small-scale high-contrast patterns either in the background or foreground, saliency detection could be adversely affected, resulting erroneous and non-uniform saliency assignment. The issue forms a fundamental challenge for prior methods. We tackle it from a scale point of view and propose a multi-layer approach to analyze saliency cues. Different from varying patch sizes or downsizing images, we measure region-based scales. The final saliency values are inferred optimally combining all the saliency cues in different scales using hierarchical inference. Through our inference model, single-scale information is selected to obtain a saliency map. Our method improves detection quality on many images that cannot be handled well traditionally. We also construct an extended Complex Scene Saliency Dataset (ECSSD) to include complex but general natural images.	[Shi, Jianping; Jia, Jiaya] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China; [Yan, Qiong; Xu, Li] Lenovo, Image & Visual Comp Lab, Shatin, Hong Kong, Peoples R China	Chinese University of Hong Kong; Legend Holdings; Lenovo	Shi, JP; Jia, JY (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.; Yan, Q; Xu, L (corresponding author), Lenovo, Image & Visual Comp Lab, Shatin, Hong Kong, Peoples R China.	jpshi@cse.cuhk.edu.hk; june232.ustc@gmail.com; nathan.xuli@gmail.com; leojia@cse.cuhk.edu.hk	Jia, Jiaya/I-3251-2012		Research Grants Council of the Hong Kong Special Administrative Region [413110]	Research Grants Council of the Hong Kong Special Administrative Region(Hong Kong Research Grants Council)	The authors would like to thank Xin Tao and Qi Zhang for their help to build the extended Complex Scene Saliency Dataset. The work described in this paper was supported by a grant from the Research Grants Council of the Hong Kong Special Administrative Region (Project No. 413110).	Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66; Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30; Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711; Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Endres I, 2010, LECT NOTES COMPUT SC, V6315, P575, DOI 10.1007/978-3-642-15555-0_42; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929; Gonzalez R.C., 2006, DIGITAL IMAGE PROCES; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; Hiremath P.S., 2008, INT J IMAGE PROCESS, V2, P10; Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Kai-Yueh Chang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2129, DOI 10.1109/CVPR.2011.5995415; Khuwuthyakorn P, 2010, LECT NOTES COMPUT SC, V6312, P636, DOI 10.1007/978-3-642-15552-9_46; Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; Ladicky L, 2014, IEEE T PATTERN ANAL, V36, P1056, DOI 10.1109/TPAMI.2013.165; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43; Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047; Ma Y.-F, 2003, P 11 ACM INT C MULTI, P374; Macaluso E, 2002, CEREB CORTEX, V12, P357, DOI 10.1093/cercor/12.4.357; Murphy KP, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P467; NAPPER GENEVIEVE A, VISION RES, V37, P1557, DOI [10.1016/S0042-6989(03, DOI 10.1016/S0042-6989(96)00269-6, 10.1016/s0042-6989(96)00269-6, DOI 10.1016/S0042-6989(99)00163-7]; Palmer S. E., 1999, VISION SCI PHOTONS P, V1; Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743; Scharfenberger C, 2013, PROC CVPR IEEE, P979, DOI 10.1109/CVPR.2013.131; Schmidt M, 2007, UGM MATLAB CODE UNDI; Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093; Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758; Siva P, 2013, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2013.416; Sun Y, 2008, COMPUT VIS IMAGE UND, V112, P126, DOI 10.1016/j.cviu.2008.01.005; Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4; Toet A, 2011, IEEE T PATTERN ANAL, V33, P2131, DOI 10.1109/TPAMI.2011.53; Walther D., 2002, BIOL MOTIVATED COMPU, P251; Wei YT, 2012, COMM COM INF SC, V310, P9; Wu S., 2010, ADV NEURAL INFORM PR, P2478; Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153; Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407; Zhai Y., 2006, PROC14TH ACM INT C M, DOI [10.1145/1180639.1180824, DOI 10.1145/1180639.1180824]	48	290	323	2	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2016	38	4					717	729		10.1109/TPAMI.2015.2465960	http://dx.doi.org/10.1109/TPAMI.2015.2465960			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DH1MW	26959676				2022-12-18	WOS:000372549700009
J	Ambikasaran, S; Foreman-Mackey, D; Greengard, L; Hogg, DW; O'Neil, M				Ambikasaran, Sivaram; Foreman-Mackey, Daniel; Greengard, Leslie; Hogg, David W.; O'Neil, Michael			Fast Direct Methods for Gaussian Processes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gaussian process; covariance function; covariance matrix; determinant; hierarchical off-diagonal low-rank; direct solver; fast multipole method; Bayesian analysis; likelihood; evidence	FAST FOURIER-TRANSFORMS; INTEGRAL-EQUATIONS; APPROXIMATION; ALGORITHM; DETERMINANT; SOLVER	A number of problems in probability and statistics can be addressed using the multivariate normal (Gaussian) distribution. In the one-dimensional case, computing the probability for a given mean and variance simply requires the evaluation of the corresponding Gaussian density. In the n-dimensional setting, however, it requires the inversion of an n x n covariance matrix, C, as well as the evaluation of its determinant, det(C). In many cases, such as regression using Gaussian processes, the covariance matrix is of the form C = sigma I-2 + K, where K is computed using a specified covariance kernel which depends on the data and additional parameters (hyperparameters). The matrix C is typically dense, causing standard direct methods for inversion and determinant evaluation to require O(n(3)) work. This cost is prohibitive for large-scale modeling. Here, we show that for the most commonly used covariance functions, the matrix C can be hierarchically factored into a product of block low-rank updates of the identity matrix, yielding an O(n log(2) n) algorithm for inversion. More importantly, we show that this factorization enables the evaluation of the determinant det(C), permitting the direct calculation of probabilities in high dimensions under fairly broad assumptions on the kernel defining K. Our fast algorithm brings many problems in marginalization and the adaptation of hyperparameters within practical reach using a single CPU core. The combination of nearly optimal scaling in terms of problem size with high-performance computing resources will permit the modeling of previously intractable problems. We illustrate the performance of the scheme on standard covariance kernels.	[Ambikasaran, Sivaram; Greengard, Leslie; O'Neil, Michael] NYU, Courant Inst, New York, NY 10025 USA; [Foreman-Mackey, Daniel; Hogg, David W.] NYU, Dept Phys, New York, NY 10025 USA; [Greengard, Leslie] Simons Fdn, Simons Ctr Data Anal, New York, NY USA; [O'Neil, Michael] NYU, Polytech Sch Engn, New York, NY 10025 USA	New York University; New York University; New York University; New York University Tandon School of Engineering	Ambikasaran, S; Greengard, L; O'Neil, M (corresponding author), NYU, Courant Inst, New York, NY 10025 USA.; Foreman-Mackey, D; Hogg, DW (corresponding author), NYU, Dept Phys, New York, NY 10025 USA.; Greengard, L (corresponding author), Simons Fdn, Simons Ctr Data Anal, New York, NY USA.; O'Neil, M (corresponding author), NYU, Polytech Sch Engn, New York, NY 10025 USA.	sivaram@cims.nyu.edu; danfm@nyu.edu; greengard@cims.nyu.edu; david.hogg@nyu.edu; oneil@cims.nyu.edu	Ambikasaran, Sivaram/AAF-9023-2019	Ambikasaran, Sivaram/0000-0003-2978-6281; Greengard, Leslie/0000-0003-2895-8715; O'Neil, Michael/0000-0003-2724-215X	Air Force Office of Scientific Research under NSSEFF Program [FA9550-10-1-0180]; AIG-NYU Award [A15-0098-001]; Simons Foundation; NASA [NNX12AI50G]; US National Science Foundation (NSF) [IIS-1124794]; Gordon and Betty Moore Foundation; Alfred P. Sloan Foundation; Div Of Information & Intelligent Systems [1124794] Funding Source: National Science Foundation	Air Force Office of Scientific Research under NSSEFF Program; AIG-NYU Award; Simons Foundation; NASA(National Aeronautics & Space Administration (NASA)); US National Science Foundation (NSF)(National Science Foundation (NSF)); Gordon and Betty Moore Foundation(Gordon and Betty Moore Foundation); Alfred P. Sloan Foundation(Alfred P. Sloan Foundation); Div Of Information & Intelligent Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	The authors would like to thank Iain Murray for several useful and detailed discussions. Research by S. Ambikasaran and M. O'Neil was supported in part by the Air Force Office of Scientific Research under NSSEFF Program Award FA9550-10-1-0180 and AIG-NYU Award #A15-0098-001. Research by L. Greengard was supported in part by the Simons Foundation and the Air Force Office of Scientific Research under NSSEFF Program Award FA9550-10-1-0180. Research by D. Foreman-Mackey and D. W. Hogg was supported in part by NASA grant NNX12AI50G, US National Science Foundation (NSF) grant IIS-1124794, the Gordon and Betty Moore Foundation, and the Alfred P. Sloan Foundation.	Akritas AG, 1996, MATH COMPUT SIMULAT, V42, P585, DOI 10.1016/S0378-4754(96)00035-3; Ambikasaran S., 2013, THESIS STANFORD U ST; Ambikasaran S, 2013, FAST DIRECT SOLVER D; Ambikasaran S, 2013, IMA VOL MATH APPL, V156, P101, DOI 10.1007/978-1-4614-7434-0_5; Ambikasaran S, 2013, COMPUTAT GEOSCI, V17, P913, DOI 10.1007/s10596-013-9364-0; Ambikasaran S, 2013, J SCI COMPUT, V57, P477, DOI 10.1007/s10915-013-9714-z; Aminfar A., 2014, ARXIVORGABS14035337; Anitescu M, 2012, SIAM J SCI COMPUT, V34, pA240, DOI 10.1137/110831143; [Anonymous], [No title captured]; [Anonymous], 2013, APPROXIMATION THEORY; Barry RP, 1999, LINEAR ALGEBRA APPL, V289, P41, DOI 10.1016/S0024-3795(97)10009-X; Borm S., 2003, LECT NOTES, V21; Brent R. P., 2013, ARXIVORGABS14017084; Cappe O., 2005, SPR S STAT; Chalupka K, 2013, J MACH LEARN RES, V14, P333; Chandrasekaran S, 2006, SIAM J MATRIX ANAL A, V28, P603, DOI 10.1137/S0895479803436652; Chatfield C., 2003, ANAL TIME SERIES INT, DOI 10.4324/9780203491683; Chen J, 2014, SIAM J SCI COMPUT, V36, pA289, DOI 10.1137/120903002; Dietrich CR, 1997, SIAM J SCI COMPUT, V18, P1088, DOI 10.1137/S1064827592240555; DUTT A, 1993, SIAM J SCI COMPUT, V14, P1368, DOI 10.1137/0914081; DUTT A, 1995, APPL COMPUT HARMON A, V2, P85, DOI 10.1006/acha.1995.1007; Fong W, 2009, J COMPUT PHYS, V228, P8712, DOI 10.1016/j.jcp.2009.08.031; Foreman-Mackey D., 2014, FAST GAUSSIAN PROCES; Frieze A, 2004, J ACM, V51, P1025, DOI 10.1145/1039488.1039494; Gimbutas Z, 2002, SIAM J SCI COMPUT, V24, P796, DOI 10.1137/S1064827500381148; Golub G.H., 1996, MATRIX COMPUTATIONS, V3; Goreinov SA, 1997, LINEAR ALGEBRA APPL, V261, P1, DOI 10.1016/S0024-3795(96)00301-1; Grasedyck L, 2003, COMPUTING, V70, P295, DOI 10.1007/s00607-003-0019-1; GREENGARD L, 1991, SIAM J SCI STAT COMP, V12, P79, DOI 10.1137/0912004; GREENGARD L, 1987, J COMPUT PHYS, V73, P325, DOI 10.1016/0021-9991(87)90140-9; Greengard L, 2009, ACTA NUMER, V18, P243, DOI 10.1017/S0962492906410011; Gu M, 1996, SIAM J SCI COMPUT, V17, P848, DOI 10.1137/0917055; Hackbusch W, 1999, COMPUTING, V62, P89, DOI 10.1007/s006070050015; Hackbusch W, 2000, COMPUTING, V64, P21; Hackbusch W, 2002, COMPUTING, V69, P1, DOI 10.1007/s00607-002-1450-4; HAGER WW, 1989, SIAM REV, V31, P221, DOI 10.1137/1031049; Hartikainen Jouni, 2010, Proceedings of the 2010 IEEE International Workshop on Machine Learning for Signal Processing (MLSP), P379, DOI 10.1109/MLSP.2010.5589113; Hensman J., 2013, P 20 9 C UNCERTAINTY, P282, DOI DOI 10.1093/IMAIAI/IAX023; Ho KL, 2012, SIAM J SCI COMPUT, V34, pA2507, DOI 10.1137/120866683; Li JY, 2014, WATER RESOUR RES, V50, P3734, DOI 10.1002/2013WR014607; Liberty E, 2007, P NATL ACAD SCI USA, V104, P20167, DOI 10.1073/pnas.0709640104; MacKay D. J. C., 1998, Neural Networks and Machine Learning. Proceedings, P133; Martinsson PG, 2005, J COMPUT PHYS, V205, P1, DOI 10.1016/j.jcp.2004.10.033; Miranian L, 2003, LINEAR ALGEBRA APPL, V367, P1, DOI 10.1016/S0024-3795(02)00572-4; Olver FWJ., 2010, NIST HDB MATH FUNCTI; Pace RK, 2004, COMPUT STAT DATA AN, V45, P179, DOI 10.1016/S0167-9473(02)00321-3; Pan CT, 2000, LINEAR ALGEBRA APPL, V316, P199, DOI 10.1016/S0024-3795(00)00120-8; Quinonero-Candela JQ, 2005, J MACH LEARN RES, V6, P1939; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Sarkka S, 2013, IEEE SIGNAL PROC MAG, V30, P51, DOI 10.1109/MSP.2013.2246292; Shen Y., 2006, ADV NEURAL INFORM PR, P1225; SHERMAN J, 1950, ANN MATH STAT, V21, P124, DOI 10.1214/aoms/1177729893; Smola AJ, 2001, ADV NEUR IN, V13, P619; Snelson E, 2007, THESIS U COLL LONDON; Snelson Edward, 2007, P 11 INT C ARTIFICIA, P524; Solin A, 2013, PHYS REV E, V88, DOI 10.1103/PhysRevE.88.052909; Townsend A, 2015, P ROY SOC A-MATH PHY, V471, DOI 10.1098/rspa.2014.0585; Woodbury M. A., 1950, 42 PRINC U STAT RES; Woolfe F, 2008, APPL COMPUT HARMON A, V25, P335, DOI 10.1016/j.acha.2007.12.002; Yang C., 2005, ADV NEURAL INFORM PR, V17, P1561; YING L, 2009, MULTISCALE MODELING, P00139; Ying LX, 2004, J COMPUT PHYS, V196, P591, DOI 10.1016/j.jcp.2003.11.021; Zhao KZ, 2005, IEEE T ELECTROMAGN C, V47, P763, DOI 10.1109/TEMC.2005.857898	65	290	289	3	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2016	38	2					252	265		10.1109/TPAMI.2015.2448083	http://dx.doi.org/10.1109/TPAMI.2015.2448083			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DD5UI	26761732	Green Submitted			2022-12-18	WOS:000369989600005
J	Gupta, A; Kembhavi, A; Davis, LS				Gupta, Abhinav; Kembhavi, Aniruddha; Davis, Larry S.			Observing Human-Object Interactions: Using Spatial and Functional Compatibility for Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action recognition; object recognition; functional recognition	REPRESENTATION	Interpretation of images and videos containing humans interacting with different objects is a daunting task. It involves understanding scene/event, analyzing human movements, recognizing manipulable objects, and observing the effect of the human movement on those objects. While each of these perceptual tasks can be conducted independently, recognition rate improves when interactions between them are considered. Motivated by psychological studies of human perception, we present a Bayesian approach which integrates various perceptual tasks involved in understanding human-object interactions. Previous approaches to object and action recognition rely on static shape/appearance feature matching and motion analysis, respectively. Our approach goes beyond these traditional approaches and applies spatial and functional constraints on each of the perceptual elements for coherent semantic interpretation. Such constraints allow us to recognize objects and actions when the appearances are not discriminative enough. We also demonstrate the use of such constraints in recognition of actions from static images without using any motion information.	[Gupta, Abhinav; Davis, Larry S.] Univ Maryland, Dept Comp Sci, AV Williams Bldg, College Pk, MD 20742 USA; [Kembhavi, Aniruddha] Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA	University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park	Gupta, A (corresponding author), Univ Maryland, Dept Comp Sci, AV Williams Bldg, College Pk, MD 20742 USA.	agupta@cs.umd.edu; anikem@umd.edu; lsd@cs.umd.edu			VACE	VACE	The authors would like to acknowledge VACE for supporting the research. The authors would like to thank Vitaladevuni Shiv and Mohamed Hussein for providing the code for reach motion detection and object detection, respectively. The authors would also like to thank the authors of [29] for providing the image data set for croquetshot action in the paper, the subjects who helped in collection of human- object interaction data set (videos), and Swati Jarial for the help in formation of static image data set. A preliminary version of this paper appears in [18].	Agarwal A., 2004, P IEEE C COMP VIS PA; Bach P, 2005, J EXP PSYCHOL HUMAN, V31, P465, DOI 10.1037/0096-1523.31.3.465; BERG A, 2001, P IEEE C COMP VIS PA; BLAKE A, 2004, P EUR C COMP VIS; Bobick AF, 1997, IEEE T PATTERN ANAL, V19, P1325, DOI 10.1109/34.643892; BOSCH A., 2007, P IEEE INT C COMP VI; Bub DN, 2006, APHASIOLOGY, V20, P1112, DOI 10.1080/02687030600741667; Chao LL, 2000, NEUROIMAGE, V12, P478, DOI 10.1006/nimg.2000.0635; Dalal N., 2005, HISTOGRAMS ORIENTED; DAVIS J, 2002, P IEEE WORKSH MOT VI; Duric Z, 1996, IEEE T PATTERN ANAL, V18, P579, DOI 10.1109/34.506409; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468; Filipovych R., 2008, P IEEE C COMP VIS PA; Gallese V, 1996, BRAIN, V119, P593, DOI 10.1093/brain/119.2.593; GUERRA G, 2005, P ASS ADV ART INT WO; Gupta A., 2008, P IEEE C COMP VIS PA; GUPTA A, 2008, P C NEUR INF PROC SY; Gupta A., 2007, P IEEE C COMP VIS PA; Gupta A., 2008, P EUR C COMP VIS; Gupta A., 2009, P IEEE C COMP VIS PA; Gupta A, 2008, IEEE T PATTERN ANAL, V30, P493, DOI 10.1109/TPAMI.2007.1173; Helbig HB, 2006, EXP BRAIN RES, V174, P221, DOI 10.1007/s00221-006-0443-5; HOIEM D, 2006, P IEEE C COMP VIS PA; Johnson-Frey SH, 2003, NEURON, V39, P1053, DOI 10.1016/S0896-6273(03)00524-5; Kourtzi Z, 2000, J COGNITIVE NEUROSCI, V12, P48, DOI 10.1162/08989290051137594; Kourtzi Z, 2004, TRENDS COGN SCI, V8, P47, DOI 10.1016/j.tics.2003.12.001; KUNIYOSHI Y, 2003, P IEEE ENG MED BIOL; LI L.-J., 2007, P IEEE INT C COMP VI; Mann JM, 2006, AM J PUBLIC HEALTH, V96, P1940, DOI 10.2105/AJPH.96.11.1940; MARTENIUK RG, 1987, CAN J PSYCHOL, V41, P365, DOI 10.1037/h0084157; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; MOORE D, 1999, P IEEE INT C COMP VI; MURASE H, 1993, P NATL C ART INT; MURPHY K, 2004, P C NEUR INF PROC SY; MURPHY KP, 2003, P C NEUR INF PROC SY; NAGEL HH, 1988, IMAGE VISION COMPUT, V6, P59, DOI 10.1016/0262-8856(88)90001-7; Nelissen K, 2005, SCIENCE, V310, P332, DOI 10.1126/science.1115593; NEVATIA R., 2007, P IEEE INT C COMP VI; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; PEURSUM P, 2005, P IEEE INT C COMP VI; PRASAD V, 2006, P C ART MOT DEF OBJ; Rabinovich A., 2007, P IEEE INT C COMP VI; Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748; RIVLIN E, 1994, P IEEE C COMP VIS PA; SHAH M, 1997, MOTION BASED RECOGNI; SMYTH I, 1984, PSYCHOL HUMAN MOVEME; STARK L, 1991, P IEEE C COMP VIS PA; Sudderth E.B., 2005, P IEEE INT C COMP VI; Sullivan J., 2002, P EUR C COMP VIS; TODOROVIC S, 2008, P IEEE C COMP VIS PA; TORRALBA A, 2001, P IEEE INT C COMP VI; Urgesi C, 2006, J NEUROSCI, V26, P7942, DOI 10.1523/JNEUROSCI.1289-06.2006; VAINA LM, 1991, INT J INTELL SYST, V6, P313, DOI 10.1002/int.4550060306; VEZHNEVETS A, 2005, P GRAPH; WANG Y, 2006, P IEEE C COMP VIS PA; Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429; WU B., 2005, P IEEE INT C COMP VI; Wu JX, 2007, IEEE I CONF COMP VIS, P290, DOI 10.1109/ICCV.2007.4408865; Yilmaz A., 2005, P IEEE C COMP VIS PA; Zhu Q., 2006, P IEEE C COMP VIS PA	62	290	303	0	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2009	31	10					1775	1789		10.1109/TPAMI.2009.83	http://dx.doi.org/10.1109/TPAMI.2009.83			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	483VK	19696449				2022-12-18	WOS:000268996500005
J	LANE, JM; RIESENFELD, RF				LANE, JM; RIESENFELD, RF			THEORETICAL DEVELOPMENT FOR THE COMPUTER-GENERATION AND DISPLAY OF PIECEWISE POLYNOMIAL SURFACES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV UTAH,DEPT COMP SCI,SALT LAKE CITY,UT 84112	Utah System of Higher Education; University of Utah	LANE, JM (corresponding author), BOEING COMMERCIAL AIRPLANE CO,SEATTLE,WA 98124, USA.							[Anonymous], 1974, COMPUTER AIDED GEOME; Bezier P, 1974, COMPUTER AIDED GEOME; Bezier P. E., 1972, NUMERICAL CONTROL MA; Catmull E., 1974, THESIS U UTAH; CURRY HB, 1966, J ANAL MATH, V17, P71, DOI 10.1007/BF02788653; DUBE RP, 1978, CAD              MAR; GORDON WJ, 1974, COMPUTER AIDED GEOME; Knuth D. E., 1969, ART COMPUTER PROGRAM, V1; LANE JE, UNPUBLISHED; LANE JM, 1979, UUCS79115 U UT TECH; LITTLE FE, COMMUNICATION; RIESENFELD RF, 1975, COMPUT GRAPHICS IMAG, V4, P304; SCHUMAKER RA, 1974, COMPUTING SURVEYS, V6; SHAMOS M, 1975, THESIS YALE U; WU SC, 1977, COMMUN ASS COMPU OCT	17	290	321	2	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	1					35	46		10.1109/TPAMI.1980.4766968	http://dx.doi.org/10.1109/TPAMI.1980.4766968			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	JD568	22499621				2022-12-18	WOS:A1980JD56800005
J	Herrera, CD; Kannala, J; Heikkila, J				Herrera, Daniel C.; Kannala, Juho; Heikkila, Janne			Joint Depth and Color Camera Calibration with Distortion Correction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Camera calibration; depth camera; camera pair; distortion; Kinect		We present an algorithm that simultaneously calibrates two color cameras, a depth camera, and the relative pose between them. The method is designed to have three key features: accurate, practical, and applicable to a wide range of sensors. The method requires only a planar surface to be imaged from various poses. The calibration does not use depth discontinuities in the depth image, which makes it flexible and robust to noise. We apply this calibration to a Kinect device and present a new depth distortion model for the depth sensor. We perform experiments that show an improved accuracy with respect to the manufacturer's calibration.	[Herrera, Daniel C.; Kannala, Juho; Heikkila, Janne] Univ Oulu, Dept Elect & Informat Engn, FI-90014 Oulu, Finland	University of Oulu	Herrera, CD (corresponding author), Univ Oulu, Dept Elect & Informat Engn, POB 4500, FI-90014 Oulu, Finland.	dherrera@ee.oulu.f.i; jkannala@ee.oulu.f.i; jth@ee.oulu.f.i			Academy of Finland [127702]	Academy of Finland(Academy of Finland)	This project has been funded by the Academy of Finland's project #127702.	Barry DA, 2000, MATH COMPUT SIMULAT, V53, P95, DOI 10.1016/S0378-4754(00)00172-5; BROWN DC, 1971, PHOTOGRAMM ENG, V37, P855; Burrus N, 2011, KINECT CALIBRATION; Cui Y, 2010, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2010.5540082; Fuchs S., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587828; Heikkila J, 2000, IEEE T PATTERN ANAL, V22, P1066, DOI 10.1109/34.879788; Herrera D, 2011, LECT NOTES COMPUT SC, V6855, P437, DOI 10.1007/978-3-642-23678-5_52; Kim Y., 2008, P IEEE CS COMP VIS P; Lichti D., 2008, INT ARCH PHOTOGRA B5, VXXXVII, P927; Lindner M, 2007, PROC SPIE, V6764, DOI 10.1117/12.752808; Scaramuzza D, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P4170, DOI 10.1109/iros.2007.4399276; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Smisek J, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS); Unnikrishnan R., 2005, CMURITR0509; Zhang Cha, 2011, P INT C MULT EXP; Zhang Q., 2004, PROC IEEERSJ INT C I, P2301, DOI 10.1109/IROS.2004.1389752; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718; Zhu J., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587761	18	287	324	2	134	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2012	34	10					2058	2064		10.1109/TPAMI.2012.125	http://dx.doi.org/10.1109/TPAMI.2012.125			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	988WY	22641701				2022-12-18	WOS:000307522700015
J	LEE, DT				LEE, DT			MEDIAL AXIS TRANSFORMATION OF A PLANAR SHAPE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											LEE, DT (corresponding author), NORTHWESTERN UNIV, DEPT ELECT ENGN & COMP SCI, EVANSTON, IL 60201 USA.							BADLER NI, 1979, AUG P PATT REC IM PR, P286; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; BLUM H, 1967, P S MOD PERC SPEECH, P362; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V11, P123, DOI 10.1016/0146-664X(79)90062-5; CALABI L, 1968, AM MATH MON, V75, P335, DOI 10.2307/2313409; DESOUZA PV, 1977, COMPUT BIOMED RES, V10, P333, DOI 10.1016/0010-4809(77)90003-9; Kirkpatrick D. G., 1979, 20th Annual Symposium of Foundations of Computer Science, P18, DOI 10.1109/SFCS.1979.15; LEE DT, 1981, SIAM J COMPUT, V10, P73, DOI 10.1137/0210006; Mead C, 1980, INTRO VLSI SYSTEMS; MONTANARI U, 1968, J ACM, V15, P600, DOI 10.1145/321479.321486; MONTANARI U, 1969, J ACM, V16, P534, DOI 10.1145/321541.321543; PFALTZ JL, 1967, COMMUN ACM, V10, P119, DOI 10.1145/363067.363120; PREPARATA FP, 1977, 6TH P S MATH F COMP, P443; Shamos M.I, 1975, PROBLEMS COMPUTATION; Shamos M.I., 1975, 16 ANN S FDN COMPUTE, P151	15	287	321	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	4					363	369		10.1109/TPAMI.1982.4767267	http://dx.doi.org/10.1109/TPAMI.1982.4767267			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NT735	21869050				2022-12-18	WOS:A1982NT73500002
J	Liu, J; Shahroudy, A; Perez, M; Wang, G; Duan, LY; Kot, AC				Liu, Jun; Shahroudy, Amir; Perez, Mauricio; Wang, Gang; Duan, Ling-Yu; Kot, Alex C.			NTU RGB+D 120: A Large-Scale Benchmark for 3D Human Activity Understanding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Benchmark testing; Cameras; Deep learning; Semantics; Lighting; Skeleton; Activity understanding; video analysis; 3D action recognition; RGB plus D vision; deep learning; large-scale benchmark	ACTION RECOGNITION; ACTIONLET ENSEMBLE; FEATURES	Research on depth-based human activity analysis achieved outstanding performance and demonstrated the effectiveness of 3D representation for action recognition. The existing depth-based and RGB+D-based action recognition benchmarks have a number of limitations, including the lack of large-scale training samples, realistic number of distinct class categories, diversity in camera views, varied environmental conditions, and variety of human subjects. In this work, we introduce a large-scale dataset for RGB+D human action recognition, which is collected from 106 distinct subjects and contains more than 114 thousand video samples and 8 million frames. This dataset contains 120 different action classes including daily, mutual, and health-related activities. We evaluate the performance of a series of existing 3D activity analysis methods on this dataset, and show the advantage of applying deep learning methods for 3D-based human action recognition. Furthermore, we investigate a novel one-shot 3D activity recognition problem on our dataset, and a simple yet effective Action-Part Semantic Relevance-aware (APSR) framework is proposed for this task, which yields promising results for recognition of the novel action classes. We believe the introduction of this large-scale dataset will enable the community to apply, adapt, and develop various data-hungry learning techniques for depth-based and RGB+D-based human activity understanding.	[Liu, Jun; Perez, Mauricio; Kot, Alex C.] Nanyang Technol Univ, Sch Elect & Elect Engn, Rapid Rich Object Search Lab, Singapore 639798, Singapore; [Shahroudy, Amir] Chalmers Univ Technol, Dept Elect Engn, S-41296 Gothenburg, Sweden; [Duan, Ling-Yu] Peking Univ, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China; [Duan, Ling-Yu] Peng Cheng Lab, Shenzhen 518000, Peoples R China; [Wang, Gang] Alibaba Grp, Hangzhou 310052, Peoples R China	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Chalmers University of Technology; Peking University; Peng Cheng Laboratory; Alibaba Group	Liu, J (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Rapid Rich Object Search Lab, Singapore 639798, Singapore.; Duan, LY (corresponding author), Peking Univ, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China.	jliu029@ntu.edu.sg; amirsh@chalmers.se; mauricio001@ntu.edu.sg; wanggang@ntu.edu.sg; lingyu@pku.edu.cn; eackot@ntu.edu.sg	Perez, Mauricio Lisboa/AAG-8901-2020; Shahroudy, Amir/T-2261-2017	Perez, Mauricio Lisboa/0000-0002-4296-9202; Kot, Alex/0000-0001-6262-8125; Shahroudy, Amir/0000-0002-1045-6437; Liu, Jun/0000-0002-4365-4165	National Research Foundation, Prime Minister's Office, Singapore, under the NRF-NSFC [NRF2016NRF-NSFC001-098]; National Natural Science Foundation of China [61661146005, U1611461]; National Basic Research Program of China [2015CB351806]	National Research Foundation, Prime Minister's Office, Singapore, under the NRF-NSFC(National Research Foundation, Singapore); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China(National Basic Research Program of China)	This research was carried out at the Rapid-Rich Object Search (ROSE) Lab at the Nanyang Technological University, Singapore, and is supported by the National Research Foundation, Prime Minister's Office, Singapore, under the NRF-NSFC grant NRF2016NRF-NSFC001-098. This work is supported in part by the National Natural Science Foundation of China under Grants 61661146005 and U1611461, and by the National Basic Research Program of China under Grant 2015CB351806. The authors would like to thank Dr. Q. Ke, Dr. M. Liu, and Dr. J.-F. Hu for helping in testing their methods on this dataset. We acknowledge the NVIDIA AI Technology Centre for the GPU donation.	Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011; [Anonymous], 2015, RSC SMART MATER; Baradel F., 2017, ARXIV170310106; Baradel F, 2018, PROC CVPR IEEE, P469, DOI 10.1109/CVPR.2018.00056; Ben Tanfous A, 2018, PROC CVPR IEEE, P2840, DOI 10.1109/CVPR.2018.00300; Bloom V., 2012, 2012 IEEE COMPUTER S, P7, DOI DOI 10.1109/CVPRW.2012.6239175; Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698; Cavazza J, 2017, IEEE COMPUT SOC CONF, P1251, DOI 10.1109/CVPRW.2017.165; Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781; Chen HZ, 2016, PATTERN RECOGN, V55, P148, DOI 10.1016/j.patcog.2016.01.020; Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006; Cheng ZW, 2012, LECT NOTES COMPUT SC, V7584, P52, DOI 10.1007/978-3-642-33868-7_6; De Boom C, 2016, PATTERN RECOGN LETT, V80, P150, DOI 10.1016/j.patrec.2016.06.012; Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714; Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772; Fanello SR, 2013, LECT NOTES COMPUT SC, V7887, P31; Graves A, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P273, DOI 10.1109/ASRU.2013.6707742; Guo YL, 2014, IEEE T PATTERN ANAL, V36, P2270, DOI 10.1109/TPAMI.2014.2316828; Gupta S, 2016, PROC CVPR IEEE, P2827, DOI 10.1109/CVPR.2016.309; Gupta S, 2015, INT J COMPUT VISION, V112, P133, DOI 10.1007/s11263-014-0777-6; Han F, 2017, COMPUT VIS IMAGE UND, V158, P85, DOI 10.1016/j.cviu.2017.01.011; Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378; Howard A. G., 2017, MOBILENETS EFFICIENT; Hu JF, 2018, LECT NOTES COMPUT SC, V11211, P346, DOI 10.1007/978-3-030-01234-2_21; Hu JF, 2019, IEEE T PATTERN ANAL, V41, P2568, DOI 10.1109/TPAMI.2018.2863279; Hu JF, 2017, IEEE T PATTERN ANAL, V39, P2186, DOI 10.1109/TPAMI.2016.2640292; Hu JF, 2015, PROC CVPR IEEE, P5344, DOI 10.1109/CVPR.2015.7299172; Huang ZW, 2017, PROC CVPR IEEE, P1243, DOI 10.1109/CVPR.2017.137; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Ke Q., 2018, COMPUTER VISION ASSI; Ke QH, 2018, IEEE T IMAGE PROCESS, V27, P2842, DOI 10.1109/TIP.2018.2812099; Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486; Ke QH, 2017, IEEE SIGNAL PROC LET, V24, P731, DOI 10.1109/LSP.2017.2690339; Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207; Konecny J, 2014, J MACH LEARN RES, V15, P2513; Kong Y, 2015, PROC CVPR IEEE, P1054, DOI 10.1109/CVPR.2015.7298708; Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Li C, 2017, IEEE I CONF COMP VIS, P3667, DOI 10.1109/ICCV.2017.394; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273; Liu C., 2017, P WORKSH VIS AN SMAR, DOI DOI 10.1145/3132734.3132739; Liu J, 2018, IEEE T IMAGE PROCESS, V27, P1586, DOI 10.1109/TIP.2017.2785279; Liu J, 2020, IEEE T PATTERN ANAL, V42, P1453, DOI 10.1109/TPAMI.2019.2898954; Liu J, 2018, PROC CVPR IEEE, P8349, DOI 10.1109/CVPR.2018.00871; Liu J, 2018, IEEE T PATTERN ANAL, V40, P3007, DOI 10.1109/TPAMI.2017.2771306; Liu J, 2017, PROC CVPR IEEE, P3671, DOI 10.1109/CVPR.2017.391; Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50; Liu MY, 2018, PROC CVPR IEEE, P1159, DOI 10.1109/CVPR.2018.00127; Liu MY, 2017, IEEE INT CON MULTI, P925, DOI 10.1109/ICME.2017.8019438; Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030; Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713; Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019; Lu CW, 2014, PROC CVPR IEEE, P772, DOI 10.1109/CVPR.2014.104; Lun R, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415550083; Luo JJ, 2013, IEEE I CONF COMP VIS, P1809, DOI 10.1109/ICCV.2013.227; Luo ZL, 2017, PROC CVPR IEEE, P7101, DOI 10.1109/CVPR.2017.751; Luvizon DC, 2018, PROC CVPR IEEE, P5137, DOI 10.1109/CVPR.2018.00539; Mao Ye, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P149, DOI 10.1007/978-3-642-44964-2_8; Mikolov Tomas., 2013, ADV NEURAL INF PROCE, V2, P3111, DOI DOI 10.5555/2999792.2999959; Ni BB, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS); Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76; Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Rahmani H, 2017, IEEE I CONF COMP VIS, P5833, DOI 10.1109/ICCV.2017.621; Rahmani H, 2016, IEEE T PATTERN ANAL, V38, P2430, DOI 10.1109/TPAMI.2016.2533389; Rahmani H, 2015, PROC CVPR IEEE, P2458, DOI 10.1109/CVPR.2015.7298860; Rahmani H, 2014, LECT NOTES COMPUT SC, V8690, P742, DOI 10.1007/978-3-319-10605-2_48; Rahmani H, 2014, IEEE WINT CONF APPL, P626, DOI 10.1109/WACV.2014.6836044; Ravi S., 2017, INT C LEARN REPR, P12; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Shahroudy A, 2018, IEEE T PATTERN ANAL, V40, P1045, DOI 10.1109/TPAMI.2017.2691321; Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115; Shahroudy A, 2016, IEEE T PATTERN ANAL, V38, P2123, DOI 10.1109/TPAMI.2015.2505295; Shahroudy A, 2014, 2014 6TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING (ISCCSP), P73, DOI 10.1109/ISCCSP.2014.6877819; Shi ZY, 2017, PROC CVPR IEEE, P4684, DOI 10.1109/CVPR.2017.498; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Simonyan K, 2014, ADV NEUR IN, V27; Soomro K., 2012, CRCVTR1201; Sung J., 2011, P 16 AAAI C PLAN ACT, P47; Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558; Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460; Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82; Vinyals O., 2016, P 30 INT C NEUR INF, P3637, DOI 10.5555/3157382.3157504; Wan J, 2016, IEEE T PATTERN ANAL, V38, P1626, DOI 10.1109/TPAMI.2015.2513479; Wang HS, 2017, PROC CVPR IEEE, P3633, DOI 10.1109/CVPR.2017.387; Wang J, 2014, PROC CVPR IEEE, P2649, DOI 10.1109/CVPR.2014.339; Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Wang J, 2018, PROC CVPR IEEE, P1149, DOI 10.1109/CVPR.2018.00126; Wang KZ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P97, DOI 10.1145/2647868.2654912; Wang P, 2017, PROC CVPR IEEE, P6212, DOI 10.1109/CVPR.2017.658; Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007; Wang PC, 2017, PROC CVPR IEEE, P416, DOI 10.1109/CVPR.2017.52; Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550; Wei P, 2013, IEEE I CONF COMP VIS, P3272, DOI 10.1109/ICCV.2013.406; WHO, 2012, GLOBAL TUBERCULOSIS REPORT 2012, P1; Xu N, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1195, DOI 10.1145/2733373.2806315; Yang HT, 2018, PROC CVPR IEEE, P1450, DOI 10.1109/CVPR.2018.00157; Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108; Zamani H, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P505, DOI 10.1145/3077136.3080831; Zhang BY, 2019, IEEE T CIRCUITS-II, V66, P2052, DOI 10.1109/TCSII.2019.2899829; Zhang J, 2016, PATTERN RECOGN, V60, P86, DOI 10.1016/j.patcog.2016.05.019; Zhang PF, 2017, IEEE I CONF COMP VIS, P2136, DOI 10.1109/ICCV.2017.233; Zhang SY, 2018, IEEE T MULTIMEDIA, V20, P2330, DOI 10.1109/TMM.2018.2802648; Zhang YP, 2012, IEEE VTS VEH TECHNOL; Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24; Zhu WT, 2016, AAAI CONF ARTIF INTE, P3697; Zolfaghari M, 2017, IEEE I CONF COMP VIS, P2923, DOI 10.1109/ICCV.2017.316	111	286	299	31	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2020	42	10					2684	2701		10.1109/TPAMI.2019.2916873	http://dx.doi.org/10.1109/TPAMI.2019.2916873			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NL5QY	31095476	Green Submitted			2022-12-18	WOS:000567471300026
J	Mahadevan, V; Vasconcelos, N				Mahadevan, Vijay; Vasconcelos, Nuno			Spatiotemporal Saliency in Dynamic Scenes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Spatiotemporal saliency; background subtraction; dynamic backgrounds; motion saliency; dynamic texture; discriminant center-surround architecture; video modeling	MOTION; TRACKING; OBJECT	A spatiotemporal saliency algorithm based on a center-surround framework is proposed. The algorithm is inspired by biological mechanisms of motion-based perceptual grouping and extends a discriminant formulation of center-surround saliency previously proposed for static imagery. Under this formulation, the saliency of a location is equated to the power of a predefined set of features to discriminate between the visual stimuli in a center and a surround window, centered at that location. The features are spatiotemporal video patches and are modeled as dynamic textures, to achieve a principled joint characterization of the spatial and temporal components of saliency. The combination of discriminant center-surround saliency with the modeling power of dynamic textures yields a robust, versatile, and fully unsupervised spatiotemporal saliency algorithm, applicable to scenes with highly dynamic backgrounds and moving cameras. The related problem of background subtraction is treated as the complement of saliency detection, by classifying nonsalient (with respect to appearance and motion dynamics) points in the visual field as background. The algorithm is tested for background subtraction on challenging sequences, and shown to substantially outperform various state-of-the-art techniques. Quantitatively, its average error rate is almost half that of the closest competitor.	[Mahadevan, Vijay; Vasconcelos, Nuno] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA	University of California System; University of California San Diego	Mahadevan, V (corresponding author), Univ Calif San Diego, Dept Elect & Comp Engn, 9500 Gilman Dr, La Jolla, CA 92093 USA.	vmahadev@ucsd.edu; nuno@ece.ucsd.edu	Zheng, Zhenzhu/F-1081-2011	Vasconcelos, Nuno/0000-0002-9024-4302	US National Science Foundation [IIS-0448609, IIS-0534985]	US National Science Foundation(National Science Foundation (NSF))	This research was supported by US National Science Foundation Awards IIS-0448609 and IIS-0534985. The authors thank Professor Ahmed Elgammal for providing the code for nonparametric background subtraction using kernel density estimates from [12], Professory Stan Sclaroff for providing some of the test sequences, and Antoni Chan and Dashan Gao for useful discussions.	BENCE MM, 2003, NATURE, V423, P401; Born RT, 2000, NEURON, V26, P725, DOI 10.1016/S0896-6273(00)81208-8; BOULT T, 2005, COASTAL SURVEILLANCE; Bugeau A., 2007, P IEEE C COMP VIS PA; Chan AB, 2005, PROC CVPR IEEE, P846; CHAN AB, 2004, SVCLT200402 U CAL DE; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; GAO D, 2007, NEURAL COMPUT, V21, P239; HAYMAN E, 2003, P INT C COMP VIS; HUBEL DH, 1965, J NEUROPHYSIOL, V28, P229, DOI 10.1152/jn.1965.28.2.229; IRANI M, 1994, INT J COMPUT VISION, V12, P5, DOI 10.1007/BF01420982; Itti L, 2005, PROC CVPR IEEE, P631; Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7; Itti L., 2004, NEUROMORPHIC ENG, V1, P10; KULLBACK S, 1968, INFORM THEORY STAT; Monnet A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1305; NOTHDURFT HC, 1993, VISION RES, V33, P1937, DOI 10.1016/0042-6989(93)90020-W; Ren Y, 2003, MACH VISION APPL, V13, P332, DOI 10.1007/s00138-002-0091-0; SHEILA VK, 1992, INT CHICKPEA NEWSLET, V27, P11; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Vasconcelos N, 2003, PROC CVPR IEEE, P762; VISSER R, 2002, P INT C IM VID RETR, P250; Wixson L, 2000, IEEE T PATTERN ANAL, V22, P774, DOI 10.1109/34.868680; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Zhong J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P44, DOI 10.1109/ICCV.2003.1238312; Zivkovic Z, 2004, P INT C PATT REC	30	286	306	0	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2010	32	1					171	177		10.1109/TPAMI.2009.112	http://dx.doi.org/10.1109/TPAMI.2009.112			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	520FQ	19926907				2022-12-18	WOS:000271826700014
J	Matthews, I; Cootes, TF; Bangham, JA; Cox, S; Harvey, R				Matthews, I; Cootes, TF; Bangham, JA; Cox, S; Harvey, R			Extraction of visual features for lipreading	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						audio-visual speech recognition; statistical methods; active appearance model; sieve; connected-set morphology	ACTIVE SHAPE MODELS; SCALE-SPACE; RECOGNITION; INTEGRATION; TRANSFORMS; PERCEPTION	The multimodal nature of speech is often ignored in human-computer interaction, but lip deformations and other body motion, such as those of the head, convey additional information. We integrate speech cues from many sources and this improves intelligibility, especially when the acoustic signal is degraded. This paper shows how this additional, often complementary, visual speech information can be used for speech recognition. Three methods for parameterizing lip image sequences for recognition using hidden Markov models are compared. Two of these are top-down approaches that fit a model of the inner and outer lip contours and derive lipreading features from a principal component analysis of shape or shape and appearance, respectively. The third, bottom-up, method uses a nonlinear scale-space analysis to form features directly from the pixel intensity. All methods are compared on a multitalker visual speech recognition task of isolated letters.	Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; Univ Manchester, Manchester M13 9PT, Lancs, England	Carnegie Mellon University; University of Manchester	Matthews, I (corresponding author), Carnegie Mellon Univ, Inst Robot, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	iainm@cs.cmu.edu; T.Cootes@man.ac.uk; ab@sys.uea.ac.uk; sjc@sys.uea.ac.uk; rwh@sys.uea.ac.uk	Harvey, Richard/AAA-7738-2020	Harvey, Richard/0000-0001-9925-8316; Cootes, Timothy/0000-0002-2695-9063; Cox, Stephen/0000-0002-6356-3068				ADJOUDANI A, 1996, HUMANS MACHINES MODE, V150, P461; ATAL BS, 1971, J ACOUST SOC AM, V50, P637, DOI 10.1121/1.1912679; Bangham J. A., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P189; Bangham J. A., 1994, Signal Processing VII, Theories and Applications. Proceedings of EUSIPCO-94. Seventh European Signal Processing Conference, P1621; Bangham JA, 1996, J ELECTRON IMAGING, V5, P283, DOI 10.1117/12.243349; Bangham JA, 1996, IEEE T PATTERN ANAL, V18, P529, DOI 10.1109/34.494642; Bangham JA, 1996, IEEE T IMAGE PROCESS, V5, P1043, DOI 10.1109/83.503918; Bangham JA, 1996, IEEE T PATTERN ANAL, V18, P520, DOI 10.1109/34.494641; Basu S., 1998, P INT C COMP VIS; Benoit C., 1997, P ESCA WORKSH AUD VI; BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209; Bosson A., 1998, P IEEE INT C IM PROC; BREGLER C, 1994, INT CONF ACOUST SPEE, P669, DOI 10.1109/ICASSP.1994.389567; BREGLER C, 1993, P INT C AC SPEECH SI, V1, P557; Bregler C., 1996, NATO ASI F, P409; BREGLER C, 1997, COMP IMAG VIS, V9, P301; Brooke N., 1994, P I ACOUSTICS, V16, P15; Brooke N.M., 1994, P I ACOUST, V16, P123; Campbell R., 1987, HEARING EYE PSYCHOL, P3, DOI DOI 10.2307/1423237; CAMPBELL R, 1998, HEARING EYE 2; Chatfield C., 1991, INTRO MULTIVARIATE A; Chen T, 1998, P IEEE, V86, P837, DOI 10.1109/5.664274; CHIBELUSHI CC, 1996, IEE C INT AUD VIS PR; COIANIZ T, 1996, IEEE T SPEECH AUDIO, P391; Cootes T., 1994, P BRIT MACH VIS C, V1, P327; COOTES TF, 1994, IMAGE VISION COMPUT, V12, P355, DOI 10.1016/0262-8856(94)90060-4; COOTES TF, 1999, P BRIT MACH VIS C, V1, P173; COOTES TF, 1998, P EUR C COMP VIS, V2, P484; Cox S., 1997, P ESCA WORKSH AUD VI; DAUTRICH BA, 1983, IEEE T ACOUST SPEECH, V31, P793, DOI 10.1109/TASSP.1983.1164172; DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420; DUCHNOWSKI P, 1995, INT CONF ACOUST SPEE, P109, DOI 10.1109/ICASSP.1995.479285; Edwards GJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P300, DOI 10.1109/AFGR.1998.670965; EDWARDS GJ, 1998, P EUR C COMP VIS, P582; ERBER NP, 1975, J SPEECH HEAR DISORD, V40, P481, DOI 10.1044/jshd.4004.481; FURUI S, 1984, IEEE T ACOUSTICS SPE; GOLDSCHEN AJ, 1993, THESIS G WASHINGTON; Goldschen Alan J, 1997, COMPUTATIONAL IMAGIN, P321; Green K., 1998, HEARING EYE 2 ADV PS, P3; Harvey R, 1997, PROC CVPR IEEE, P582, DOI 10.1109/CVPR.1997.609384; HARVEY R, 1997, P BRIT MACH VIS C, V1, P11; HASLAM J, 1994, P BRIT MACH VIS C, P33; Hennecke M. E, 1997, THESIS STANFORD U; HENNECKE ME, 1996, NATO ASI SERIES F, P331; HILL A, 1994, BMVC94 - PROCEEDINGS OF THE 5TH BRITISH MACHINE VISION CONFERENCE, VOLS 1 AND 2, P429; HOLMES A, 1999, P BRIT MACH VIS C, V2, P614; KAUCIC R, 1998, P 6 INT C COMP VIS; Kaucic R., 1996, P EUR C COMP VIS, P376; LEVINSON SE, 1983, AT&T TECH J, V62, P1035, DOI 10.1002/j.1538-7305.1983.tb03114.x; LI N, 1997, COMPUTATIONAL IMAGIN, P345; Lindeberg T., 1994, SCALE SPACE THEORY C; Luettin J, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P58, DOI 10.1109/ICSLP.1996.607024; Luettin J, 1997, COMPUT VIS IMAGE UND, V65, P163, DOI 10.1006/cviu.1996.0570; MACDONALD J, 1978, PERCEPT PSYCHOPHYS, V24, P253, DOI 10.3758/BF03206096; Mase K., 1991, Systems and Computers in Japan, V22, P67; Matheron G., 1975, RANDOM SETS INTEGRAL; Matthews I., 1998, THESIS U E ANGLIA; MATTHEWS I, 1998, P EUR C COMP VIS, P514; MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0; MEIER U, 1997, P IABSE C COMP CONST, P113; MOROVEC K, 1999, P BRIT MACH VIS C, V1, P113; MOVELLAN JR, 1996, NATO ASI SER, P473; NEELY KK, 1956, J ACOUST SOC AM, V28, P1275, DOI 10.1121/1.1908620; NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308; O'Neill JJ, 1954, J SPEECH HEAR DISORD, V19, P429, DOI 10.1044/jshd.1904.429; PETAJAN E, 1996, NATO ASI SERIES F, P425; Petajan E. D., 1984, THESIS U ILLINOIS UR; PETAJAN ED, 1987, 1125187101211 TM AT; PITAS I, 1990, IEEE T PATTERN ANAL, V12, P38, DOI 10.1109/34.41382; Potamianos Gerasimos, 1997, P AVSP 97, P65; Poynton C. A., 1996, TECHNICAL INTRO DIGI; SANCHEZ MUR, 1997, P INT C AC SPEECH SI; Schwartz J.-L., 1998, HEARING EYE, P85; SHAH M, 1997, COMPUTAITONAL IMAGIN, V9; Silsbee PL, 1996, IEEE T SPEECH AUDI P, V4, P337, DOI 10.1109/89.536928; SILSBEE PL, 1994, IEEE IMAGE PROC, P323, DOI 10.1109/ICIP.1994.413328; STORK DG, 1996, NATO ASI SERIES F, V150; SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309; Tomlinson MJ, 1996, INT CONF ACOUST SPEE, P821, DOI 10.1109/ICASSP.1996.543247; VOGT M, 1997, P ESCA WORKSH AUD VI, P125; WALDEN BE, 1977, J SPEECH HEAR RES, V20, P130, DOI 10.1044/jshr.2001.130; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; Yang J., 1998, AVSP 98 INT C AUD VI, P79; Young S., 1996, HTK BOOK; YUHAS BP, 1989, IEEE COMMUN MAG, V27, P65, DOI 10.1109/35.41402; YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169; [No title captured]	89	286	299	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2002	24	2					198	213		10.1109/34.982900	http://dx.doi.org/10.1109/34.982900			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	516DC					2022-12-18	WOS:000173535700005
J	Chang, XJ; Yu, YL; Yang, Y; Xing, EP				Chang, Xiaojun; Yu, Yao-Liang; Yang, Yi; Xing, Eric P.			Semantic Pooling for Complex Event Analysis in Untrimmed Videos	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Complex event detection; event recognition; event recounting; semantic saliency; nearly-isotonic SVM	RECOGNITION; MINIMIZATION; NONCONVEX; FEATURES; OBJECTS	Pooling plays an important role in generating a discriminative video representation. In this paper, we propose a new semantic pooling approach for challenging event analysis tasks (e.g., event detection, recognition, and recounting) in long untrimmed Internet videos, especially when only a few shots/segments are relevant to the event of interest while many other shots are irrelevant or even misleading. The commonly adopted pooling strategies aggregate the shots indifferently in one way or another, resulting in a great loss of information. Instead, in this work we first define a novel notion of semantic saliency that assesses the relevance of each shot with the event of interest. We then prioritize the shots according to their saliency scores since shots that are semantically more salient are expected to contribute more to the final event analysis. Next, we propose a new isotonic regularizer that is able to exploit the constructed semantic ordering information. The resulting nearly-isotonic support vector machine classifier exhibits higher discriminative power in event analysis tasks. Computationally, we develop an efficient implementation using the proximal gradient algorithm, and we prove new and closed-form proximal steps. We conduct extensive experiments on three real-world video datasets and achieve promising improvements.	[Chang, Xiaojun; Yang, Yi] Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, Sydney, NSW 2007, Australia; [Yu, Yao-Liang; Xing, Eric P.] Carnegie Mellon Univ, Machine Learning Dept, Pittsburgh, PA 15213 USA	University of Technology Sydney; Carnegie Mellon University	Chang, XJ (corresponding author), Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, Sydney, NSW 2007, Australia.	cxj273@gmail.com; yaoliang@cs.cmu.edu; yi.yang@uts.edu.au; epxing@cs.cmu.edu	yang, yang/GWB-9426-2022; yang, yang/HGT-7999-2022; Chang, Xiaojun/A-2055-2015; Yang, Yi/B-9273-2017; yang, yang/GVT-5210-2022	Chang, Xiaojun/0000-0002-7778-8807; Yang, Yi/0000-0002-0512-880X; 	NIH [R01GM087694, P30DA035778]; Data to Decisions Cooperative Research Centre; NSFC [U1509206]; NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES [R01GM114311, R01GM087694] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON DRUG ABUSE [P30DA035778] Funding Source: NIH RePORTER	NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Data to Decisions Cooperative Research Centre; NSFC(National Natural Science Foundation of China (NSFC)); NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS)); NATIONAL INSTITUTE ON DRUG ABUSE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Drug Abuse (NIDA)European Commission)	We thank the reviewers and the associate editor for numerous critical comments that largely improved our manuscript. We thank Mark Schmidt for sharing prettyPlot. This work was supported by NIH R01GM087694 and P30DA035778, the Data to Decisions Cooperative Research Centre www.d2dcrc.com.au, and NSFC (U1509206).	Aly R., TRECVID 2013; Barlow RE, 1972, STAT INFERENCE UNDER; Bird S., 2006, P ACL WORKSH EFF TOO, P69; Bolte J, 2014, MATH PROGRAM, V146, P459, DOI 10.1007/s10107-013-0701-9; Bossard L, 2013, IEEE I CONF COMP VIS, P1193, DOI 10.1109/ICCV.2013.151; Cao LL, 2012, LECT NOTES COMPUT SC, V7573, P688, DOI 10.1007/978-3-642-33709-3_49; Chang X, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P581, DOI 10.1145/2733373.2806218; Chang XJ, 2015, PR MACH LEARN RES, V37, P1348; Clinch Sarah, 2013, P 2 ACM INT S PERV D, P25; Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628; Davies PL, 2001, ANN STAT, V29, P1, DOI 10.1214/aos/996986501; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114; FUKUSHIMA M, 1981, INT J SYST SCI, V12, P989, DOI 10.1080/00207728108963798; Graf H., 2004, ADV NEURAL INFORM PR, V17, P521; Gupta A, 2009, PROC CVPR IEEE, P2012, DOI 10.1109/CVPRW.2009.5206492; Habibian A., 2015, ARXIV151102492; Izadinia H, 2012, LECT NOTES COMPUT SC, V7575, P430, DOI 10.1007/978-3-642-33765-9_31; Jiang Y.-G., 2011, ICMR, P1; Joachims T., 2006, P 12 ACM SIGKDD INT, V06, P217, DOI DOI 10.1145/1150402.1150429; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; KOCH C, 1985, HUM NEUROBIOL, V4, P219; Lai KT, 2014, LECT NOTES COMPUT SC, V8691, P675, DOI 10.1007/978-3-319-10578-9_44; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Lan ZZ, 2015, PROC CVPR IEEE, P204, DOI 10.1109/CVPR.2015.7298616; Laptev I, 2007, COMPUT VIS IMAGE UND, V108, P207, DOI 10.1016/j.cviu.2006.11.023; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820; Li LJ, 2007, IEEE I CONF COMP VIS, P345; Li WX, 2013, IEEE I CONF COMP VIS, P2728, DOI 10.1109/ICCV.2013.339; Liu D, 2013, PROC CVPR IEEE, P803, DOI 10.1109/CVPR.2013.109; Liu JC, 2012, LECT NOTES COMPUT SC, V7576, P397, DOI [10.1007/978-3-642-33715-4_29, 10.1007/978-3-642-33167-1_23]; Liu JE, 2013, IEEE WORK APP COMP, P339, DOI 10.1109/WACV.2013.6475038; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Ma ZG, 2014, IEEE T PATTERN ANAL, V36, P1789, DOI 10.1109/TPAMI.2014.2306419; Ma Z, 2013, IEEE T MULTIMEDIA, V15, P1628, DOI 10.1109/TMM.2013.2264928; McAuley J, 2012, LECT NOTES COMPUT SC, V7575, P828, DOI 10.1007/978-3-642-33765-9_59; Mettes P, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P427, DOI 10.1145/2671188.2749404; Mikolov Tomas., 2013, ADV NEURAL INFORM PR, P3111, DOI DOI 10.1162/JMLR.2003.3.4-5.951; Nagel  Markus, 2015, P BRIT MACH VIS C; Natarajan P, 2012, PROC CVPR IEEE, P1298, DOI 10.1109/CVPR.2012.6247814; Ni BB, 2015, IEEE T PATTERN ANAL, V37, P1615, DOI 10.1109/TPAMI.2014.2362935; Oneata D, 2013, IEEE I CONF COMP VIS, P1817, DOI 10.1109/ICCV.2013.228; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Rahimi A., 2006, P ADV NEUR INF PROC, P1313; Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Sharma S., 2016, ARXIV151104119; Simonyan K., 2015, P INT C LEARN REPR, P1245; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Soomro K., 2012, ARXIV; Sun C., 2014, P INT C MULT RETR, P241; Sun C, 2014, PROC CVPR IEEE, P2569, DOI 10.1109/CVPR.2014.329; Tamrakar A, 2012, PROC CVPR IEEE, P3681, DOI 10.1109/CVPR.2012.6248114; Tan C.C., 2011, P 19 ACM INT C MULT, P655, DOI DOI 10.1145/2072298.2072411; Tang KV, 2013, IEEE I CONF COMP VIS, P2696, DOI 10.1109/ICCV.2013.335; Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808; Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802; Tibshirani RJ, 2011, TECHNOMETRICS, V53, P54, DOI 10.1198/TECH.2010.10111; Vahdat A, 2013, IEEE I CONF COMP VIS, P1185, DOI 10.1109/ICCV.2013.463; Vedaldi Andrea, 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wu F, 2009, IEEE T MULTIMEDIA, V11, P868, DOI 10.1109/TMM.2009.2021724; Wu Z., 2015, ARXIV150401561; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789; Yang Sen, 2012, KDD, P922; Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170; Yao-Liang Y., 2013, ADV NEURAL INFORM PR, V26, P91; Yu S.-I., TRECVID 2014; Yu Y., 2013, P 30 INT C MACH LEAR, P570; Yuan JH, 2007, IEEE T CIRC SYST VID, V17, P168, DOI 10.1109/TCSVT.2006.888023; Zha S., 2015, P BRIT MACH VIS C; Zhang XS, 2015, IEEE T MULTIMEDIA, V17, P1562, DOI 10.1109/TMM.2015.2449660	75	285	287	0	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2017	39	8					1617	1632		10.1109/TPAMI.2016.2608901	http://dx.doi.org/10.1109/TPAMI.2016.2608901			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EZ3JD	28113653	Green Accepted			2022-12-18	WOS:000404606300010
J	Bulacu, M; Schomaker, L				Bulacu, Marius; Schomaker, Lambert			Text-independent writer identification and verification using textural and allographic features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						handwriting analysis; writer identification and verification; behavioral biometrics; joint directional probability distributions; grapheme-emission probability distribution	HANDWRITING IDENTIFICATION; RECOGNITION; ONLINE	The identification of a person on the basis of scanned images of handwriting is a useful biometric modality with application in forensic and historic document analysis and constitutes an exemplary study area within the research field of behavioral biometrics. We developed new and very effective techniques for automatic writer identification and verification that use probability distribution functions (PDFs) extracted from the handwriting images to characterize writer individuality. A defining property of our methods is that they are designed to be independent of the textual content of the handwritten samples. Our methods operate at two levels of analysis: the texture level and the character-shape (allograph) level. At the texture level, we use contour-based joint directional PDFs that encode orientation and curvature information to give an intimate characterization of individual handwriting style. In our analysis at the allograph level, the writer is considered to be characterized by a stochastic pattern generator of ink-trace fragments, or graphemes. The PDF of these simple shapes in a given handwriting sample is characteristic for the writer and is computed using a common shape codebook obtained by grapheme clustering. Combining multiple features (directional, grapheme, and run-length PDFs) yields increased writer identification and verification performance. The proposed methods are applicable to free-style handwriting (both cursive and isolated) and have practical feasibility, under the assumption that a few text lines of handwritten material are available in order to obtain reliable probability estimates.	Univ Groningen, AI Inst, NL-9712 TS Groningen, Netherlands	University of Groningen	Bulacu, M (corresponding author), Univ Groningen, AI Inst, Grote Kruisstraat 2-1, NL-9712 TS Groningen, Netherlands.	bulacu@ai.rug.nl; schomaker@ai.rug.nl	Schomaker, Lambert/GYU-5840-2022; Schomaker, Lambert RB/A-9489-2008	Schomaker, Lambert RB/0000-0003-2351-930X				ARAZI B, 1983, IEEE T SYST MAN CYB, V13, P635, DOI 10.1109/TSMC.1983.6313153; ARAZI B, 1977, IEEE T SYST MAN CYB, V7, P878; Bensefia A, 2005, PATTERN RECOGN LETT, V26, P2080, DOI 10.1016/j.patrec.2005.03.024; Bensefia A, 2003, PROC INT CONF DOC, P946; Bensefia A, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P274, DOI 10.1109/IWFHR.2002.1030922; Bulacu M, 2005, PROC INT CONF DOC, P1275, DOI 10.1109/ICDAR.2005.4; Bulacu M, 2003, PROC INT CONF DOC, P937; Bulacu M, 2003, LECT NOTES COMPUT SC, V2756, P460; Crettez J.-P., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P489, DOI 10.1109/ICDAR.1995.599041; Cristianini N., 2000, INTRO SUPPORT VECTOR; DAUGMAN J, 2000, TR482 U CAMBR COMP L; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; DINSTEIN I, 1982, IEEE T SYST MAN CYB, V12, P405; Drouhard J.-P., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P807, DOI 10.1109/ICDAR.1995.602024; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Fairhurst MC, 2003, PROC INT CONF DOC, P1108; Favata JT, 1996, INT J IMAG SYST TECH, V7, P304, DOI 10.1002/(SICI)1098-1098(199624)7:4<304::AID-IMA5>3.0.CO;2-C; Franke K., 2001, International Journal on Document Analysis and Recognition, V3, P218, DOI 10.1007/PL00013565; GUYON I, 1994, INT C PATT RECOG, P29, DOI 10.1109/ICPR.1994.576870; Hertel C, 2003, LECT NOTES COMPUT SC, V2688, P679; Huber R.A., 1999, HANDWRITING IDENTIFI; Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996; Joachims T., 1999, ADV KERNEL METHODS S; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kohonen T., 1988, SELF ORG ASS MEMORY; Liu C.L., 1997, ELECT LETT COMPUTER, V20, P1019, DOI DOI 10.5565/REV/ELCVIA.97; MAARSE F, 1988, HUMAN COMPUTER INTER, P353; MAARSE FJ, 1983, ACTA PSYCHOL, V54, P131, DOI 10.1016/0001-6918(83)90028-8; MAARSE FJ, 1987, THESIS U NIJMEGEN NE; Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071; Marti UV, 2001, INT J PATTERN RECOGN, V15, P65, DOI 10.1142/S0218001401000848; Martinsons MG, 2001, J INFORM SCI, V27, P101, DOI 10.1177/016555150102700205; Morris R. N., 2000, FORENSIC HANDWRITING; Neyman J, 1933, PHILOS T R SOC LOND, V231, P289, DOI 10.1098/rsta.1933.0009; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; PLAMONDON R, 1989, PATTERN RECOGN, V22, P107, DOI 10.1016/0031-3203(89)90059-9; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; Prabhakar S., 2003, HDB FINGERPRINT RECO; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Roli F, 2002, LECT NOTES COMPUT SC, V2364, P325; SAID H, 1998, P 9 BRIT MACH VIS C, P478; Said HES, 2000, PATTERN RECOGN, V33, P149, DOI 10.1016/S0031-3203(99)00006-0; Schlapbach A, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P167, DOI 10.1109/IWFHR.2004.107; Schlapbach A, 2005, PROC INT CONF DOC, P131, DOI 10.1109/ICDAR.2005.139; SCHMIDT RA, 1975, PSYCHOL REV, V82, P225, DOI 10.1037/h0076770; Schomaker L, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P185, DOI 10.1109/IWFHR.2004.22; Schomaker L, 2004, IEEE T PATTERN ANAL, V26, P787, DOI 10.1109/TPAMI.2004.18; Schomaker L., 2000, FORENSIC WRITER IDEN; SCHOMAKER L, 1991, THESIS U NIJMEGEN NE; Srihari SN, 2005, PROC INT CONF DOC, P1105, DOI 10.1109/ICDAR.2005.33; Srihari SN, 2003, PROC INT CONF DOC, P1096; Srihari SN, 2002, J FORENSIC SCI, V47, P856; Tan TN, 1998, IEEE T PATTERN ANAL, V20, P751, DOI 10.1109/34.689305; Tomai CI, 2004, INT C PATT RECOG, P638, DOI 10.1109/ICPR.2004.1334329; Van Der Maaten L., 2005, P 17 BELG NETH C ART, P260; VANERP M, 2003, P 11 C INT GRAPH SOC, P282; Vinciarelli A, 2002, PATTERN RECOGN, V35, P1433, DOI 10.1016/S0031-3203(01)00129-7; Zhang B, 2003, PROC INT CONF DOC, P1142; Zhang B, 2003, PROC INT CONF DOC, P1086; Zhu Y, 2001, IEEE T PATTERN ANAL, V23, P1192, DOI 10.1109/34.954608; Zimmermann M, 2002, INT C PATT RECOG, P35, DOI 10.1109/ICPR.2002.1047394; Zois EN, 2000, PATTERN RECOGN, V33, P385, DOI 10.1016/S0031-3203(99)00063-1	62	285	298	4	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2007	29	4					701	717		10.1109/TPAMI.2007.1009	http://dx.doi.org/10.1109/TPAMI.2007.1009			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HJ	17299226	Green Submitted			2022-12-18	WOS:000244855600017
J	Meer, P; Georgescu, B				Meer, P; Georgescu, B			Edge detection with embedded confidence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						edge detection; performance assessment; gradient estimation; window operators	3-MODULE STRATEGY; OPERATORS; PERFORMANCE	Computing the weighted average of the pixel values in a window is a basic module in many computer vision operators. The process is reformulated in a linear vector space and the role of the different subspaces is emphasized. Within this framework well-known artifacts of the gradient-based edge detectors, such as large spurious responses can be explained quantitatively. It is also shown, that template matching with a template derived from the input data is meaningful since it provides an independent measure of confidence in the presence of the employed edge model. The widely used three-step edge detection procedure: gradient estimation, nonmaxima suppression, hysteresis thresholding; is generalized to include the information provided by the confidence measure. The additional amount of computation is minimal and experiments with several standard test images show the ability of the new procedure to detect weak edges.	Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08854 USA; Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA	Rutgers State University New Brunswick; Rutgers State University New Brunswick	Meer, P (corresponding author), Rutgers State Univ, Dept Elect & Comp Engn, 94 Brett Rd, Piscataway, NJ 08854 USA.							Ando S, 2000, IEEE T PATTERN ANAL, V22, P179, DOI 10.1109/34.825756; Ando S, 2000, IEEE T PATTERN ANAL, V22, P252, DOI 10.1109/34.841757; Baker S, 1998, INT J COMPUT VISION, V27, P27, DOI 10.1023/A:1007901712605; BLICHER AP, 1985, CS851041 STANF U DEP; Cho K, 1997, IEEE T PATTERN ANAL, V19, P1185, DOI 10.1109/34.632979; DEMICHELI E, 1989, IEEE T PATTERN ANAL, V11, P1106, DOI 10.1109/34.42841; Demigny D, 1997, IEEE T PATTERN ANAL, V19, P1199, DOI 10.1109/34.632980; FLECK MM, 1992, IEEE T PATTERN ANAL, V14, P337, DOI 10.1109/34.120328; FREI W, 1977, IEEE T COMPUT, V26, P988, DOI 10.1109/TC.1977.1674733; Golub G. H., 1996, MATRIX COMPUTATIONS; Graham A., 1981, KRONECKER PRODUCTS M; Haralick RM., 1992, COMPUTER ROBOT VISIO; Heath MD, 1997, IEEE T PATTERN ANAL, V19, P1338, DOI 10.1109/34.643893; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; HUMMEL RA, 1979, COMPUT VISION GRAPH, V9, P40, DOI 10.1016/0146-664X(79)90081-9; IVERSON LA, 1995, IEEE T PATTERN ANAL, V17, P982, DOI 10.1109/34.464562; KRUEGER WM, 1989, IEEE T PATTERN ANAL, V11, P1252, DOI 10.1109/34.41364; LACROIX V, 1988, IEEE T PATTERN ANAL, V10, P803, DOI 10.1109/34.9103; Lan ZD, 1998, MACH VISION APPL, V10, P256, DOI 10.1007/s001380050077; LENZ R, 1995, J VIS COMMUN IMAGE R, V6, P209, DOI 10.1006/jvci.1995.1019; Lim JS, 1990, 2 DIMENSIONAL SIGNAL; MEER P, 1989, PATTERN RECOGN, V22, P491, DOI 10.1016/0031-3203(89)90019-8; Meer P., 1992, Journal of Visual Communication and Image Representation, V3, P58, DOI 10.1016/1047-3203(92)90030-W; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; O'Rourke J, 1998, COMPUTATIONAL GEOMET; PARK RH, 1990, IEEE T PATTERN ANAL, V12, P223; Proakis J. G., 1995, DIGITAL COMMUNICATIO; RAMESH V, 1994, P 1994 ARPA IM UND W, P675; SHIN M, 1998, EMPIRICAL EVALUATION, P235; STRANG G, 1988, LINEAR ALGEBRA ITS A; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769	31	285	349	0	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2001	23	12					1351	1365		10.1109/34.977560	http://dx.doi.org/10.1109/34.977560			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	500NY					2022-12-18	WOS:000172634700002
J	GRIMSON, WEL				GRIMSON, WEL			COMPUTATIONAL EXPERIMENTS WITH A FEATURE BASED STEREO ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MIT,ARTIFICIAL INTELLIGENCE LAB,CAMBRIDGE,MA 02139	Massachusetts Institute of Technology (MIT)								Arnold R. D., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238, P281; BAKER HH, 1981, 7TH P INT JOINT C AR, P631; BAKER HH, 1982, STANCS82930 STANF U; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BERRY RN, 1948, J EXP PSYCHOL, V38, P708, DOI 10.1037/h0057362; CANNY JF, 1983, MIT TR720 ART INT LA; CRICK FHC, 1980, CEREB CORTEX, P505; DUWAER AL, 1981, VISION RES, V21, P1727, DOI 10.1016/0042-6989(81)90205-4; DUWAER AL, 1981, PERCEPT PSYCHOPHYS, V29, P295, DOI 10.3758/BF03207338; FRISBY J, 1980, VISION RES, V20, P727, DOI 10.1016/0042-6989(80)90099-1; GRIMSON WEL, 1983, COMPUT VISION GRAPH, V24, P28, DOI 10.1016/0734-189X(83)90019-1; GRIMSON WEL, 1982, PHILOS T ROY SOC B, V298, P395, DOI 10.1098/rstb.1982.0088; GRIMSON WEL, 1983, COMPUT VISION GRAPH, V22, P39, DOI 10.1016/0734-189X(83)90095-6; GRIMSON WEL, 1981, PHILOS T ROY SOC B, V292, P217, DOI 10.1098/rstb.1981.0031; GRIMSON WEL, 1980, MIT565 AI LAB MEM; GRIMSON WEL, 1981, IMAGES SURFACES COMP; HILDRETH EC, 1980, MIT597 AI LAB TECH R; HILDRETH EC, 1980, THESIS MIT CAMBRIDGE; Howard H J, 1919, Trans Am Ophthalmol Soc, V17, P195; JULESZ B, 1960, AT&T TECH J, V39, P1125, DOI 10.1002/j.1538-7305.1960.tb03954.x; JULESZ B, 1971, F CYCLOPEAN PERCEPTI; KAK AC, UNPUB HDB IND ROBOTI; KAK AC, 1983, TREE8344 PURD U TECH; KASS M, 1983, 8TH P INT JOINT C AR, P1043; KASS MH, 1984, THESIS MIT CAMBRIDGE; LONGUETHIGGINS HC, 1982, PERCEPTION, V11, P377, DOI 10.1068/p110377; MACVICARWHELAN PJ, 1981, 7TH P INT JOINT C AR, P752; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MARR D, 1977, MIT451 AI LAB MEM; MARR D, 1978, LECTURES MATH LIFE S, V10, P101; MARR D, 1979, J OPT SOC AM, V70, P868; MARR D, 1980, MIT558 MEM; Marr D., 1982, VISION; MAYHEW J, 1982, PERCEPTION, V11, P387, DOI 10.1068/p110387; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; MAYHEW JEW, 1982, NATURE, V297, P376, DOI 10.1038/297376a0; Moravec H., 1977, P 5 INT JOINT C ART, VVolume 1, P584; Moravec H.P., 1980, AIM340 STANF ART INT; MOWFORTH P, 1981, PERCEPTION, V10, P299, DOI 10.1068/p100299; NIELSEN KRK, 1983, MIT743 ART INT LAB M; NISHIHARA HK, 1981, APR P DARPA IM UND W, P114; OHTA Y, 1983, CMUCS83162 CARN U TE; PRAZDNY K, 1982, P AAAI, P1; PRAZDNY K, 1983, 8TH P IJCAI KARLSR, P1050; SCHUMER R A, 1982, Investigative Ophthalmology and Visual Science, V22, P272; TERZOPOULOS D, 1982, MIT671 ART INT LAB M; TERZOPOULOS D, 1983, MULTIRESOLUTION IMAG; TERZOPOULOS D, 1984, THESIS MIT CAMBRIDGE; TYLER CW, 1977, P SPIE, V120; WILSON HR, 1979, VISION RES, V19, P19, DOI 10.1016/0042-6989(79)90117-2; WILSON HR, 1983, PHYSICAL BIOL PROCES, P88; Woodburne LS, 1934, AM J PSYCHOL, V46, P273, DOI 10.2307/1416560	53	285	300	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	1					17	34		10.1109/TPAMI.1985.4767615	http://dx.doi.org/10.1109/TPAMI.1985.4767615			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ABF09	21869237	Green Submitted			2022-12-18	WOS:A1985ABF0900002
J	Gao, SH; Tsang, IWH; Chia, LT				Gao, Shenghua; Tsang, Ivor Wai-Hung; Chia, Liang-Tien			Laplacian Sparse Coding, Hypergraph Laplacian Sparse Coding, and Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Laplacian sparse coding; hypergraph Laplacian sparse coding; image classification; semi-auto image tagging; locality preserving		Sparse coding exhibits good performance in many computer vision applications. However, due to the overcomplete codebook and the independent coding process, the locality and the similarity among the instances to be encoded are lost. To preserve such locality and similarity information, we propose a Laplacian sparse coding (LSc) framework. By incorporating the similarity preserving term into the objective of sparse coding, our proposed Laplacian sparse coding can alleviate the instability of sparse codes. Furthermore, we propose a Hypergraph Laplacian sparse coding (HLSc), which extends our Laplacian sparse coding to the case where the similarity among the instances defined by a hypergraph. Specifically, this HLSc captures the similarity among the instances within the same hyperedge simultaneously, and also makes the sparse codes of them be similar to each other. Both Laplacian sparse coding and Hypergraph Laplacian sparse coding enhance the robustness of sparse coding. We apply the Laplacian sparse coding to feature quantization in Bag-of-Words image representation, and it outperforms sparse coding and achieves good performance in solving the image classification problem. The Hypergraph Laplacian sparse coding is also successfully used to solve the semi-auto image tagging problem. The good performance of these applications demonstrates the effectiveness of our proposed formulations in locality and similarity preservation.	[Gao, Shenghua; Tsang, Ivor Wai-Hung; Chia, Liang-Tien] Nanyang Technol Univ, Sch Comp Engn, Nanyang Ave, Singapore 639798, Singapore	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Gao, SH (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Nanyang Ave, Singapore 639798, Singapore.	gaos0004@ntu.edu.sg; ivortsang@ntu.edu.sg; asltchia@ntu.edu.sg	Chia, Liang-Tien/A-9874-2008; Tsang, Ivor/E-8653-2011	Tsang, Ivor/0000-0003-2211-8176; Tsang, Ivor/0000-0001-8095-4637				Agarwal S., 2006, P INT C MACH LEARN; Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Ameesh M., 2008, P EUR C COMP VIS; Bengio S., 2009, P ADV NEUR INF PROC; Boiman O., 2008, P IEEE C COMP VIS PA; Boureau Y.-L., 2010, P INT C MACH LEARN; Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Chen X., 2010, TECHNICAL REPORT; Chen Yutian, 2010, UAI; Cheng H., 2009, P IEEE INT C COMP VI; Chua Tat-Seng, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646452; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Donoho D., 2004, TECHNICAL REPORT; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Eriksson A., 2010, P IEEE C COMP VIS PA; Friedman J., 2010, TECHNICAL REPORT; Gao S., 2010, PROC ACM INTL CONF M; Gao SH, 2010, LECT NOTES COMPUT SC, V6314, P1; Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943; Grauman K, 2005, P IEEE INT C COMP VI; Jacob L., 2009, P INT C MACH LEARN; Kavukcuoglu K., 2008, TECHNICAL REPORT; Kim S., 2010, P INT C MACH LEARN; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Lee H., 2006, P ADV NEUR INF PROC; LI L.-J., 2007, P IEEE INT C COMP VI; Liu X., 2010, P IEEE C COMP VIS PA; Liu Y., IEEE T PATT IN PRESS; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; LU Z. W., 2009, P IEEE C COMP VIS PA; Mairal J., 2008, P ADV NEUR INF PROC; Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452; Mairal J, 2010, J MACH LEARN RES, V11, P19; Makadia A, 2010, INT J COMPUT VISION, V90, P88, DOI 10.1007/s11263-010-0338-6; Mosci S., 2010, NIPS, P1; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Sigurbjornsson B., 2008, P 17 INT C WORLD WID, P327, DOI DOI 10.1145/1367497.1367542; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Song Y., 2008, P ANN INT ACM SIGIR; VANGEMERT J, 2008, P EUR C COMP VIS; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wang C., 2009, P IEEE INT C AC SPEE; Wang C., 2009, P IEEE C COMP VIS PA; WANG G., 2009, P IEEE C COMP VIS PA; Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Wu J., 2009, P IEEE INT C COMP VI; Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757; Yuan M, 2006, J R STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Zhou D., 2006, ADV NEURAL INFORM PR	51	284	303	4	78	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2013	35	1					92	104		10.1109/TPAMI.2012.63	http://dx.doi.org/10.1109/TPAMI.2012.63			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	037SV	22392702				2022-12-18	WOS:000311127700010
J	Marcel, S; Millan, JDR				Marcel, Sebastien; Millan, Jose del R.			Person authentication using brainwaves (EEG) and maximum a posteriori model adaptation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						emerging technologies; electroencephalogram; biometry; signal processing; probabilistic algorithms; machine learning		In this paper, we investigate the use of brain activity for person authentication. It has been shown in previous studies that the brain-wave pattern of every individual is unique and that the electroencephalogram ( EEG) can be used for biometric identification. EEG-based biometry is an emerging research topic and we believe that it may open new research directions and applications in the future. However, very little work has been done in this area and was focusing mainly on person identification but not on person authentication. Person authentication aims to accept or to reject a person claiming an identity, i.e., comparing a biometric data to one template, while the goal of person identification is to match the biometric data against all the records in a database. We propose the use of a statistical framework based on Gaussian Mixture Models and Maximum A Posteriori model adaptation, successfully applied to speaker and face authentication, which can deal with only one training session. We perform intensive experimental simulations using several strict train/test protocols to show the potential of our method. We also show that there are some mental tasks that are more appropriate for person authentication than others.	IDIAP Res Inst, CH-1920 Martigny, Switzerland		Marcel, S (corresponding author), IDIAP Res Inst, Rue Simplon 4, CH-1920 Martigny, Switzerland.	marcel@idiap.ch; jose.millan@idiap.ch	del R. Millan, Jose/F-1696-2011	del R. Millan, Jose/0000-0001-5819-1522; Marcel, Sebastien/0000-0002-2497-9140				Babiloni F, 2000, IEEE T REHABIL ENG, V8, P186, DOI 10.1109/86.847810; Cardinaux F, 2003, LECT NOTES COMPUT SC, V2688, P911; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278; Millan JD, 2002, HDB BRAIN THEORY NEU; MOURINO J, 2003, THESIS U POLITECNICA; PALANIAPPAN R, 2003, P 4 INT C INF COMM S, P15; Paranjape RB, 2001, CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING 2001, VOLS I AND II, CONFERENCE PROCEEDINGS, P1363, DOI 10.1109/CCECE.2001.933649; PERRIN F, 1990, ELECTROEN CLIN NEURO, V76, P565; PERRIN F, 1989, ELECTROEN CLIN NEURO, V72, P184, DOI 10.1016/0013-4694(89)90180-6; POULOS M, P 6 INT C EL CIRC SY, V1, P283; Reynolds D.A., 2000, DIGITAL SIGNAL PROCE; Varsta M, 2000, INT C PATT RECOG, P907, DOI 10.1109/ICPR.2000.906221; Verlinde P., 2000, Information Fusion, V1, P17, DOI 10.1016/S1566-2535(00)00002-6; WELCH PD, 1967, IEEE T ACOUST SPEECH, VAU15, P70, DOI 10.1109/TAU.1967.1161901; Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3	17	284	298	0	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2007	29	4					743	748		10.1109/TPAMI.2007.1012	http://dx.doi.org/10.1109/TPAMI.2007.1012			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HJ	17299229	Green Submitted			2022-12-18	WOS:000244855600020
J	Jacob, M; Unser, M				Jacob, M; Unser, M			Design of steerable filters for feature detection using Canny-like criteria	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						steerable; feature; edge; detection; ridge; contours; boundary; lines	CORNER	We propose a general approach for the design of 2D feature detectors from a class of steerable functions based on the optimization of a Canny-like criterion. In contrast with previous computational designs, our approach is truly 2D and provides filters that have closed-form expressions. It also yields operators that have a better orientation selectivity than the classical gradient or Hessian-based detectors. We illustrate the method with the design of operators for edge and ridge detection. We present some experimental results that demonstrate the performance improvement of these new feature detectors. We propose computationally efficient local optimization algorithms for the estimation of feature orientation. We also introduce the notion of shape-adaptable feature detection and use it for the detection of image corners.	Swiss Fed Inst Technol, Biomed Imaging Grp, CH-1015 Lausanne, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Jacob, M (corresponding author), Swiss Fed Inst Technol, Biomed Imaging Grp, CH-1015 Lausanne, Switzerland.	Mathews.Jacob@ieee.org; michael.unser@epfl.ch	Unser, Michael/A-1550-2008; Jacob, Mathews/GZA-5643-2022; Jacob, Mathews/F-9205-2011	Jacob, Mathews/0000-0001-6196-3933				BHARATH AA, 1998, P 9 BRIT MACH VIS C, P144; Campisi P, 2002, IEEE T IMAGE PROCESS, V11, P37, DOI 10.1109/83.977881; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Demigny D, 2002, IEEE T IMAGE PROCESS, V11, P728, DOI 10.1109/TIP.2002.800887; DERICHE R, 1993, INT J COMPUT VISION, V10, P101, DOI 10.1007/BF01420733; DERICHE R, 1990, IEEE T PATTERN ANAL, V12, P78, DOI 10.1109/34.41386; DERICHE R, 1990, P 10 INT C PATT REC, V1, P240; Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822; Eberly D., 1994, Journal of Mathematical Imaging and Vision, V4, P353, DOI 10.1007/BF01262402; Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Jacob M, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING, PROCEEDINGS, P597, DOI 10.1109/ISBI.2002.1029328; Kitchen L, 1982, PATTERN RECOGN LETT, V1, P95, DOI 10.1016/0167-8655(82)90020-4; Manduchi R, 1998, IEEE T SIGNAL PROCES, V46, P1168, DOI 10.1109/78.668570; PERONA P, 1995, IEEE T PATTERN ANAL, V17, P488, DOI 10.1109/34.391394; Press W.H., 1997, NUMER RECIPES C; Rasband WS., 2004, IMAGE J; Ruzon M. A., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P160, DOI 10.1109/CVPR.1999.784624; SARKAR S, 1991, IEEE T PATTERN ANAL, V13, P1154, DOI 10.1109/34.103275; Simoncelli EP, 1996, IEEE T IMAGE PROCESS, V5, P1377, DOI 10.1109/83.535851; Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444; Teo PC, 1999, IEEE T PATTERN ANAL, V21, P552, DOI 10.1109/34.771325; WANG H, 1995, IMAGE VISION COMPUT, V13, P695, DOI 10.1016/0262-8856(95)98864-P; Zheng ZQ, 1999, PATTERN RECOGN LETT, V20, P149, DOI 10.1016/S0167-8655(98)00134-2	24	283	306	3	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2004	26	8					1007	1019		10.1109/TPAMI.2004.44	http://dx.doi.org/10.1109/TPAMI.2004.44			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	827BE	15641731	Green Submitted			2022-12-18	WOS:000221872400005
J	Pankanti, S; Prabhakar, S; Jain, AK				Pankanti, S; Prabhakar, S; Jain, AK			On the individuality of fingerprints	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fingerprints; individuality; identification; minutiae; probability of correspondence; biometric authentication		Fingerprint identification is based on two basic premises: 1) persistence: the basic characteristics of fingerprints do not change with time and 2) individuality: the fingerprint is unique to an individual. The validity of the first premise has been established by the anatomy and morphogenesis of friction ridge skin. While the second premise has been generally accepted to be true based on empirical results, the underlying scientific basis of fingerprint individuality has not been formally established. As a result, the validity of fingerprint evidence is now being challenged in several court cases. A scientific basis for establishing fingerprint individuality will not only result in the admissibility of fingerprint identification in the courts of law, but will also establish an upper bound on the performance of an automatic fingerprint verification system. We address the problem of fingerprint individuality by quantifying the amount of information available in minutiae features to establish a correspondence between two fingerprint images. We derive an expression which estimates the probability of a false correspondence between minutiae-based representations from two arbitrary fingerprints belonging to different fingers. For example, the probability that a fingerprint with 36 minutiae points will share 12 minutiae points with another arbitrarily chosen fingerprint with 36 minutiae points is 6.10 x 10(-8). These probability estimates are compared with typical fingerprint matcher accuracy results. Our results show that 1) contrary to the popular belief, fingerprint matching is not infallible and leads to some false associations, 2) while there is an overwhelming amount of discriminatory information present in the fingerprints, the strength of the evidence degrades drastically with noise in the sensed fingerprint images, 3) the performance of the state-of-the-art automatic fingerprint matchers is not even close to the theoretical limit, and 4) because automatic fingerprint verification systems based on minutia use only a part of the discriminatory information present in the fingerprints, it may be desirable to explore additional complementary representations of fingerprints for automatic matching.	IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA; DigitalPersona Inc, Redwood City, CA 94063 USA; Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	International Business Machines (IBM); Michigan State University	Pankanti, S (corresponding author), IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.	sharat@watson.ibm.com; salilp@digitalpersona.com; jain@cse.msu.edu						AMY L, 1948, ANN MED LEGALE, V28, P96; BALTHAZARD V, 1911, COMPTES RENDUS ACAD, V1862; Cha SH, 2001, PROC INT CONF DOC, P1022, DOI 10.1109/ICDAR.2001.953940; Champod C., 1996, P INT S FING DET ID, P305; Cole SA., 2001, SUSPECT IDENTITIES H; Cummins H, 1943, FINGERPRINTS PALMS S, V1st; DAUGMAN J, 1999, BIOMETRICS PERSONAL; Galton Francis, 1892, FINGER PRINTS; GUPTA SR, 1968, INT CRIMINAL POLICE, V218; Henry E., 1900, CLASSIFICATION USES, P54; Jain A, 2001, IEICE T INF SYST, VE84D, P788; Jain AK, 1997, P IEEE, V85, P1365, DOI 10.1109/5.628674; Jain AK, 2000, IEEE T IMAGE PROCESS, V9, P846, DOI 10.1109/83.841531; Jain AK, 2001, LECT NOTES COMPUT SC, V2091, P211; KINGSTON CR, 1964, THESIS U CALIFORNIA; Lee HC, 2001, ADV FINGERPRINT TECH; MAIO D, 2000, P 15 IAPR INT C PATT; MEAGHER SB, 1999, 50K FINGERPRINT COMP; NEWMAN A, 2002, NY TIMES         JAN; OSTERBURG JW, 1977, J AM STAT ASSOC, V72, P772; PEARSON K, 1930, LIFE LETT F GALTON A, V3; Rice J. A., 1995, MATH STAT DATA ANAL; Roddy AR, 1997, P IEEE, V85, P1390, DOI 10.1109/5.628710; Roxburgh T., 1933, SANKHYA INDIAN J STA, V1, P189; SCLOVE SL, 1979, J AM STAT ASSOC, V74, P588, DOI 10.2307/2286975; STILES MR, 2000, GOVT POST DAUBERT HE; Stoney D.A., 1985, THESIS U CALIFORNIA; STONEY DA, 1988, AM J PHYS ANTHROPOL, V77, P367, DOI 10.1002/ajpa.1330770309; STONEY DA, 1986, J FORENSIC SCI, V31, P1187; TRAURING M, 1963, NATURE, V197, P938, DOI 10.1038/197938a0; WAYMAN JL, 2002, DAUBERT HEARING FING; Wentworth B., 1918, PERSONAL IDENTIFICAT; 2002, LATENT PRINT EXAMINA	33	282	300	1	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2002	24	8					1010	1025		10.1109/TPAMI.2002.1023799	http://dx.doi.org/10.1109/TPAMI.2002.1023799			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	578JY					2022-12-18	WOS:000177115100001
J	Schuler, CJ; Hirsch, M; Harmeling, S; Scholkopf, B				Schuler, Christian J.; Hirsch, Michael; Harmeling, Stefan; Schoelkopf, Bernhard			Learning to Deblur	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	27th IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 23-28, 2014	Columbus, OH	Comp Vis Fdn, IEEE, IEEE Comp Soc		Sharpening and deblurring; neural networks; machine learning	BLIND DECONVOLUTION; BLUR IDENTIFICATION; IMAGE; NETWORKS	We describe a learning-based approach to blind image deconvolution. It uses a deep layered architecture, parts of which are borrowed from recent work on neural network learning, and parts of which incorporate computations that are specific to image deconvolution. The system is trained end-to-end on a set of artificially generated training examples, enabling competitive performance in blind deconvolution, both with respect to quality and runtime.	[Schuler, Christian J.; Hirsch, Michael; Harmeling, Stefan; Schoelkopf, Bernhard] MPI Intelligent Syst, Spemannstr 38, D-72076 Tubingen, Germany; [Harmeling, Stefan] Univ Dusseldorf, Dusseldorf, Germany	Max Planck Society; Heinrich Heine University Dusseldorf	Schuler, CJ (corresponding author), MPI Intelligent Syst, Spemannstr 38, D-72076 Tubingen, Germany.	cschuler@tuebingen.mpg.de; mhirsch@tuebingen.mpg.de; harmeling@tuebingen.mpg.de; bs@tuebingen.mpg.de	Schölkopf, Bernhard/A-7570-2013	Schölkopf, Bernhard/0000-0002-8177-0925				Aizenberg I, 2006, ADV SOFT COMP, P441, DOI 10.1007/3-540-34783-6_45; Bengio Y, 2010, 1355 DIRO U MONTR; BOTTOU L, 1991, ADV NEURAL INFORMATI, V3, P781; CHO CM, 1991, IEEE IJCNN, P2558, DOI 10.1109/IJCNN.1991.170774; Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491; De Ridder D, 2003, ADV IMAG ELECT PHYS, V126, P351, DOI 10.1016/S1076-5670(03)80019-8; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; Harmeling S., 2010, ADV NEURAL INFORM PR, V23, P829; Hirsch M, 2011, IEEE I CONF COMP VIS, P463, DOI 10.1109/ICCV.2011.6126276; Hirsch M, 2010, PROC CVPR IEEE, P607, DOI 10.1109/CVPR.2010.5540158; Hu Z, 2012, LECT NOTES COMPUT SC, V7576, P59, DOI 10.1007/978-3-642-33715-4_5; Hu Z, 2010, IEEE IMAGE PROC, P1169, DOI 10.1109/ICIP.2010.5651892; Khare C., 2011, IMAGE, V2, P25; Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521; Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; Michaeli T, 2014, LECT NOTES COMPUT SC, V8691, P783, DOI 10.1007/978-3-319-10578-9_51; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Schmidt U, 2013, PROC CVPR IEEE, P604, DOI 10.1109/CVPR.2013.84; Schuler CJ, 2013, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.2013.142; STERITI RJ, 1994, OPT LETT, V19, P575, DOI 10.1364/OL.19.000575; Sun J., 2015, ARXIV E PRINTS; Sun LH, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL WORKSHOP ON COMPUTER SCIENCE IN SPORTS, P1; Tansley JE, 1996, FUND THEOR, V62, P319; Wang C, 2013, IEEE T IMAGE PROCESS, V22, P884, DOI 10.1109/TIP.2012.2219548; Xu L., 2014, INT C NEUR INF PROC, V27, P1790; Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147; Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157; Zeiler M.D., 2012, ARXIV E PRINTS; Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474; Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957; Zhang H., 2013, ARXIV E PRINTS; Zhong L, 2013, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2013.85; Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278	36	281	307	16	105	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2016	38	7							1439	10.1109/TPAMI.2015.2481418	http://dx.doi.org/10.1109/TPAMI.2015.2481418			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	DO6MH	26415157				2022-12-18	WOS:000377897100013
J	WENG, JY; HUANG, TS; AHUJA, N				WENG, JY; HUANG, TS; AHUJA, N			MOTION AND STRUCTURE FROM 2 PERSPECTIVE VIEWS - ALGORITHMS, ERROR ANALYSIS, AND ERROR ESTIMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											WENG, JY (corresponding author), UNIV ILLINOIS, COORDINATED SCI LAB, URBANA, IL 61801 USA.							ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; Bottema O., 1979, THEORETICAL KINEMATI; BROIDA TJ, 1986, JUN P IEEE C COMP VI, P176; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808; DAVIS LS, 1983, COMPUT VISION GRAPH, V23, P313, DOI 10.1016/0734-189X(83)90029-4; DRESCHLER L, 1982, COMPUT VISION GRAPH, V20, P199, DOI 10.1016/0146-664X(82)90081-8; FANG JQ, 1984, IEEE T PATTERN ANAL, V6, P545, DOI 10.1109/TPAMI.1984.4767569; FAUGERAS OD, 1983, 8TH P INT JOINT C AR, P996; FAUGERAS OD, 1987, JUN P INT C COMP VIS; GLAZER F, 1983, JUN P IEEE C COMP VI, P432; GU WK, 1987, IEEE T PATTERN ANAL, V9, P390, DOI 10.1109/TPAMI.1987.4767921; Hamilton W.R., 1969, ELEMENTS QUATERNIONS; HEEGER DJ, 1987, JUN P INT C COMP VIS, P181; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HUANG TS, 1985, MAR P TOP M MACH VIS; Kitchen L, 1982, PATTERN RECOGN LETT, V1, P95, DOI 10.1016/0167-8655(82)90020-4; Longuet-Higgins H. C., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P395; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MITICHE A, 1986, HDB PATTERN RECOGNIT; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; SHARIAT H, 1987, FEB P IM UND WORKSH, P694; Shuster M.D., 1978, P GUID CONTR C PAL A, P88; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; VERRI A, 1987, 1ST P INT C COMP VIS, P171; WENG J, 1988, 2ND P INT C COMP VIS, P64; WENG J, 1988, JUN P IEEE C COMP VI; WENG JY, 1987, IEEE T PATTERN ANAL, V9, P370, DOI 10.1109/TPAMI.1987.4767920; Wilkinson JH., 1965, ALGEBRAIC EIGENVALUE; YASUMOTO Y, 1986, IEEE T PATTERN ANAL, V8, P464, DOI 10.1109/TPAMI.1986.4767810; ZHUANG XH, 1986, J OPT SOC AM A, V3, P1492, DOI 10.1364/JOSAA.3.001492; Zuniga O. A., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P30	37	281	311	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1989	11	5					451	476		10.1109/34.24779	http://dx.doi.org/10.1109/34.24779			26	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	U3604					2022-12-18	WOS:A1989U360400002
J	Corneanu, CA; Simon, MO; Cohn, JF; Guerrero, SE				Adrian Corneanu, Ciprian; Oliu Simon, Marc; Cohn, Jeffrey F.; Escalera Guerrero, Sergio			Survey on RGB, 3D, Thermal, and Multimodal Approaches for Facial Expression Recognition: History, Trends, and Affect-Related Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Facial expression; affect; emotion recognition; RGB; 3D; thermal; multimodal	AUTOMATIC FACE SEGMENTATION; EMOTION RECOGNITION; ANIMATION PARAMETERS; BODY; MODEL; AUDIO; VIDEO; EXTRACTION; SEQUENCES; DATABASE	Facial expressions are an important way through which humans interact socially. Building a system capable of automatically recognizing facial expressions from images and video has been an intense field of study in recent years. Interpreting such expressions remains challenging and much research is needed about the way they relate to human affect. This paper presents a general overview of automatic RGB, 3D, thermal and multimodal facial expression analysis. We define a new taxonomy for the field, encompassing all steps from face detection to facial expression recognition, and describe and classify the state of the art methods accordingly. We also present the important datasets and the bench-marking of most influential methods. We conclude with a general discussion about trends, important questions and future lines of research.	[Adrian Corneanu, Ciprian; Oliu Simon, Marc; Escalera Guerrero, Sergio] Univ Autonoma Barcelona, Comp Vis Ctr, E-08193 Barcelona, Spain; [Adrian Corneanu, Ciprian; Oliu Simon, Marc; Escalera Guerrero, Sergio] Univ Barcelona, Dept Appl Math, E-08007 Barcelona, Spain; [Cohn, Jeffrey F.] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; [Cohn, Jeffrey F.] Univ Pittsburgh, Dept Psychol, Pittsburgh, PA 15260 USA	Autonomous University of Barcelona; Centre de Visio per Computador (CVC); University of Barcelona; Carnegie Mellon University; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh	Corneanu, CA (corresponding author), Univ Autonoma Barcelona, Comp Vis Ctr, E-08193 Barcelona, Spain.; Corneanu, CA (corresponding author), Univ Barcelona, Dept Appl Math, E-08007 Barcelona, Spain.	cipriancorneanu@ub.edu; moliusimon@gmail.com; jeffcohn@cs.cmu.edu; sergio@maia.ub.es	Escalera, Sergio/L-2998-2015	Escalera, Sergio/0000-0003-0617-8873				Abadi Mojtaba Khomami, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163100; Aleksic PS, 2006, IEEE T INF FOREN SEC, V1, P3, DOI 10.1109/TIFS.2005.863510; Alyuz N, 2012, LECT NOTES COMPUT SC, V7585, P557, DOI 10.1007/978-3-642-33885-4_56; Alyuz N, 2010, IEEE T INF FOREN SEC, V5, P425, DOI 10.1109/TIFS.2010.2054081; Ambadar Z, 2009, J NONVERBAL BEHAV, V33, P17, DOI 10.1007/s10919-008-0059-5; [Anonymous], 2004, PROC IEEE C COMPUT V; [Anonymous], CHAPTER AFFECTIVE CO; [Anonymous], 2014, ARXIV14101037; [Anonymous], 2006, P 8 INT C MULT INT B, DOI DOI 10.1145/1180995.1181031; [Anonymous], 2016, DATASET 02 IRIS THER; [Anonymous], 2011, P INT C MULT INT ACM; [Anonymous], 2007, FACE RECOGNITION, DOI [10.5772/4847, DOI 10.5772/4847]; Ashraf AB, 2009, IMAGE VISION COMPUT, V27, P1788, DOI 10.1016/j.imavis.2009.05.007; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Bakkes S., 2012, P SE 8 AUSTR C INT E, V3, P4, DOI DOI 10.1145/2336727.2336731; Barrett LF, 2011, CURR DIR PSYCHOL SCI, V20, P400, DOI 10.1177/0963721411429125; Bartlett M. S., 2006, Journal of Multimedia, V1, DOI 10.4304/jmm.1.6.22-35; Batrinca L.M., 2011, P 13 INT C MULT INT, P255, DOI [10.1145/2070481.2070528, DOI 10.1145/2070481.2070528]; Berretti S, 2011, VISUAL COMPUT, V27, P1021, DOI 10.1007/s00371-011-0611-x; Besl Paul J, 1992, ROBOTICS DL TENTATIV, P586, DOI DOI 10.1109/34.121791; Biel JI, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P119, DOI 10.1145/2522848.2522877; Biel JI, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P53; Biel JI, 2013, IEEE T MULTIMEDIA, V15, P41, DOI 10.1109/TMM.2012.2225032; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Blom P.M., 2014, P 10 AAAI C ART INT, P30; Bosch N., 2015, P 20 INT C INTELLIGE, P379; Burrows A., 2014, HDB BIOMETRICS, P1; Busso C., 2004, ANAL EMOTION RECOGNI, P205, DOI DOI 10.1145/1027933.1027968; Castellano G, 2013, INT J HUM ROBOT, V10, DOI 10.1142/S0219843613500102; Chai D, 1999, IEEE T CIRC SYST VID, V9, P551, DOI 10.1109/76.767122; Chang Y, 2005, LECT NOTES COMPUT SC, V3723, P293; Chastel A., 2002, LEONARDO ART ARTIST; Chen LS, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P366, DOI 10.1109/AFGR.1998.670976; Cohen I, 2003, PROC CVPR IEEE, P595; Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X; Cohn Jeffrey F., 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPR.2009.5204260; Cohn J. F., 2004, INT J WAVELETS MULTR, V2, P121, DOI [10.1142/S021969130400041X, DOI 10.1142/S021969130400041X]; Colombo A, 2006, PATTERN RECOGN, V39, P444, DOI 10.1016/j.patcog.2005.09.009; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; D'Mello SK, 2010, USER MODEL USER-ADAP, V20, P147, DOI 10.1007/s11257-010-9074-4; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976; Dapogny Arnaud, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163111; Darwin C., 1872, P374; De la Torre F., 2011, VISUAL ANAL HUMANS L, P377; De Silva L. C., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P332, DOI 10.1109/AFGR.2000.840655; De Silva LC, 1997, ICICS - PROCEEDINGS OF 1997 INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATIONS AND SIGNAL PROCESSING, VOLS 1-3, P397, DOI 10.1109/ICICS.1997.647126; Dhall Abhinav, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P878, DOI 10.1109/FG.2011.5771366; Dhall A., 2011, TRCS112 AUSTR NAT U; Dhall A., 2014, P 16 INT C MULTIMODA, P461, DOI [10.1145/2663204.2666275, DOI 10.1145/2663204.2666275]; Dhall A, 2015, IEEE INT CONF AUTOMA; Dhall A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS); Dhall A, 2012, INT C PATT RECOG, P3525; Duchenne deBoulogne GB, 1990, MECH HUMAN FACIAL EX; Duric Z, 2002, P IEEE, V90, P1272, DOI 10.1109/JPROC.2002.801449; Eibl-Eibesfeldt I., 1989, HUMAN ETHOLOGY; EKMAN P, 1979, ANNU REV PSYCHOL, V30, P527, DOI 10.1146/annurev.ps.30.020179.002523; EKMAN P, 1994, PSYCHOL BULL, V115, P268, DOI 10.1037/0033-2909.115.2.268; EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068; EKMAN P, 1990, J PERS SOC PSYCHOL, V58, P342, DOI 10.1037/0022-3514.58.2.342; Ekman P., 1993, HIL0984 U CAL; Ekman P., 2002, FACIAL ACTION CODING; Ekman P, 1971, NEBRASKA S MOTIVATIO, P207; Ekman P., 1978, FACIAL ACTION CODING; el Kaliouby R, 2005, REAL-TIME VISION FOR HUMAN-COMPUTER INTERACTION, P181; Fanelli G, 2013, IEEE INT CONF AUTOMA; Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3; Fragopanagos N, 2005, NEURAL NETWORKS, V18, P389, DOI 10.1016/j.neunet.2005.03.006; Fridlund A. J., 1997, EMOTION, P90; Frijda N. H., 1997, PSYCHOL FACIAL EXPRE, P78, DOI [10.1017/cbo9780511659911.006, DOI 10.1017/CBO9780511659911.006]; Garidakis G., 2006, P INT C MULT INT, P146, DOI DOI 10.1145/1180995.1181029; Geetha A, 2009, EXPERT SYST APPL, V36, P303, DOI 10.1016/j.eswa.2007.09.002; Gehrig T., 2013, P 2013 EM REC WILD C, P9; Girard JM, 2015, BEHAV RES METHODS, V47, P1136, DOI 10.3758/s13428-014-0536-1; Girard JM, 2015, PATTERN RECOGN LETT, V66, P13, DOI 10.1016/j.patrec.2014.10.004; Girard JM, 2014, IMAGE VISION COMPUT, V32, P641, DOI 10.1016/j.imavis.2013.12.007; Gong B, 2009, ACM MULTIMEDIA, P569, DOI 10.3969/j.issn.1000-6729.2011.01.011; Gray H., 1966, ANATOMY HUMAN BODY; Greenblatt S., 1994, UNIVERSAL LANGUAGE M, V21, P56; Greenwald M. K., 1989, J PSYCHOPHYSIOL, V3, P51; Gross I. R., 2008, P IEEE INT C AUT FAC, P1; Gu WF, 2012, PATTERN RECOGN, V45, P80, DOI 10.1016/j.patcog.2011.05.006; Gunes H, 2005, IEEE SYS MAN CYBERN, P3437; Haggard E, 1966, METHODS RES PSYCHOTH, P154; Hammal Z, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P47, DOI 10.1145/2388676.2388688; Hao Tang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563052; Hayat M, 2013, IEEE WORK APP COMP, P83, DOI 10.1109/WACV.2013.6475003; He L., P 5 INT WORKSH AUD V, P73; He S, 2013, INT CONF AFFECT, P239, DOI 10.1109/ACII.2013.46; Hernandez B, 2007, COMPUT VIS IMAGE UND, V106, P258, DOI 10.1016/j.cviu.2006.08.012; Hernandez-Vela A, 2012, PROC CVPR IEEE, P726, DOI 10.1109/CVPR.2012.6247742; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Huang T. S., 1998, P ATR WORKSH VIRT CO, P1; Igual L, 2014, PATTERN RECOGN, V47, P659, DOI 10.1016/j.patcog.2013.08.006; Ijjina EP, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P392, DOI 10.1109/ICMLA.2014.70; Ioannou S, 2014, PSYCHOPHYSIOLOGY, V51, P951, DOI 10.1111/psyp.12243; Irani Ramin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P88, DOI 10.1109/CVPRW.2015.7301341; Ishiguro H, 2001, IND ROBOT, V28, P498, DOI 10.1108/01439910110410051; Izard, 1983, MAXIMALLY DISCRIMINA; Izard C. E., 1983, SYSTEM IDENTIFYING A; Izard C. E., 1971, FACE EMOTION; Jack Rachael E, 2009, Curr Biol, V19, P1543, DOI 10.1016/j.cub.2009.07.051; Jain V., 2014, P 4 INT WORKSH AUD V, P87; Jeni L.A., 2013, P 2013 10 IEEE INT C, P1; Ji QA, 2006, IEEE T SYST MAN CY A, V36, P862, DOI 10.1109/TSMCA.2005.855922; Jones M.J., 2003, TR200396 MITS EL RES; Joshi J, 2012, INT C PATT RECOG, P2634; Kaltwang S, 2012, LECT NOTES COMPUT SC, V7432, P368, DOI 10.1007/978-3-642-33191-6_36; Kanade Takeo, 2000, P 4 IEEE INT C AUT F, P1, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]; Kapoor A, 2007, INT J HUM-COMPUT ST, V65, P724, DOI 10.1016/j.ijhcs.2007.02.003; Keltner D., 2000, HDB EMOTIONS, P236; Kessous L, 2010, J MULTIMODAL USER IN, V3, P33, DOI 10.1007/s12193-009-0025-5; Koda Y., 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P955, DOI 10.1109/ROMAN.2009.5326321; Koelstra S, 2010, IEEE T PATTERN ANAL, V32, P1940, DOI 10.1109/TPAMI.2010.50; Kohler CG, 2008, SCHIZOPHR RES, V105, P49, DOI 10.1016/j.schres.2008.05.010; Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954; Kuncheva L., 2014, COMBINING PATTERN CL; Lakshmi H. V., 2010, J COMPUT THEORY ENG, V2, P1793; Lemaire P., 2013, P 2013 10 IEEE INT C, P1; LEVENSON RW, 1990, PSYCHOPHYSIOLOGY, V27, P363, DOI 10.1111/j.1469-8986.1990.tb02330.x; Li HL, 2008, J VIS COMMUN IMAGE R, V19, P320, DOI 10.1016/j.jvcir.2008.04.001; Li YS, 2013, INT J ANTENN PROPAG, V2013, DOI 10.1155/2013/472645; Littlewort G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P298, DOI 10.1109/FG.2011.5771414; Littlewort GC, 2009, IMAGE VISION COMPUT, V27, P1797, DOI 10.1016/j.imavis.2008.12.010; Littlewort GC, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P15; Liu M., 2013, 10 IEEE INT C WORKSH, P1, DOI [DOI 10.1109/FG.2013.6553734, DOI 10.1128/GEN0MEA.00300-13]; Liu MY, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P525, DOI 10.1145/2522848.2531738; Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226; Liu Mengyi, 2014, P INT C MULTIMODAL I, P494, DOI DOI 10.1145/2663204.2666274; LIU P, 2014, PROC CVPR IEEE, P1805, DOI DOI 10.1109/CVPR.2014.233; Liu ZL, 2011, LECT NOTES COMPUT SC, V6975, P240, DOI 10.1007/978-3-642-24571-8_26; Lucas GM, 2015, INT CONF AFFECT, P539, DOI 10.1109/ACII.2015.7344622; Lucey P., 2010, P IEEE COMP SOC C CO, P94, DOI [10.1109/CVPRW.2010.5543262, DOI 10.1109/CVPRW.2010.5543262]; Lucey P, 2011, IEEE T SYST MAN CY B, V41, P664, DOI 10.1109/TSMCB.2010.2082525; Lucey S., 2007, INVESTIGATING SPONTA; Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413; Maalej A, 2011, PATTERN RECOGN, V44, P1581, DOI 10.1016/j.patcog.2011.02.012; Maat L, 2007, LECT NOTES COMPUT SC, V4451, P251; Mao ZL, 2004, INT C PATT RECOG, P144, DOI 10.1109/ICPR.2004.1334489; Martinez A, 2012, J MACH LEARN RES, V13, P1589; Mase K., 1991, Systems and Computers in Japan, V22, P67; Matsumoto D., 2008, HDB EMOTIONS, V3, P211, DOI DOI 10.1016/J.BRAT.2006.05.004; Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4; McDuff D, 2014, IMAGE VISION COMPUT, V32, P630, DOI 10.1016/j.imavis.2014.01.004; McDuff D, 2013, IEEE COMPUT SOC CONF, P881, DOI 10.1109/CVPRW.2013.130; McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20; Memisevic, 2013, ICMI 13, P543; Mpiperis I, 2008, INT CONF ACOUST SPEE, P2133, DOI 10.1109/ICASSP.2008.4518064; Nair P, 2009, IEEE T MULTIMEDIA, V11, P611, DOI 10.1109/TMM.2009.2017629; Nguyen H, 2014, LECT NOTES COMPUT SC, V8333, P397, DOI 10.1007/978-3-642-53842-1_34; Nicolle J, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P501; Niedenthal PM, 2007, SCIENCE, V316, P1002, DOI 10.1126/science.1136930; Osadchy M, 2007, J MACH LEARN RES, V8, P1197; Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424; Pantic M, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P1026; Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976; Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075; Pardas M, 2002, SIGNAL PROCESS-IMAGE, V17, P675, DOI 10.1016/S0923-5965(02)00078-4; Paul E., 1997, WHAT FACE REVEALS BA, V2, P331; Pavlidis I, 2007, COMPUT VIS IMAGE UND, V108, P150, DOI 10.1016/j.cviu.2006.11.018; Peng Liu, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163094; Pfister T, 2011, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2011.6126401; Polikovsky S., 2009, 3 INT C CRIM DET PRE, P1, DOI [10.1049/ic.2009.0244, DOI 10.1049/IC.2009.0244]; Prkachin KM, 2008, PAIN, V139, P267, DOI 10.1016/j.pain.2008.04.010; Queirolo CC, 2010, IEEE T PATTERN ANAL, V32, P206, DOI 10.1109/TPAMI.2009.14; Kassim SRA, 2006, IEEE IMAGE PROC, P661; Ranzato M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2857, DOI 10.1109/CVPR.2011.5995710; Rastegari M, 2011, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2011.6126556; Rifai S, 2012, LECT NOTES COMPUT SC, V7577, P808, DOI 10.1007/978-3-642-33783-3_58; Roger R. W. Highfield, 2009, NEW SCI; Romdhani S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P59; RUSSELL JA, 1994, PSYCHOL BULL, V115, P102, DOI 10.1037/0033-2909.115.1.102; RUSSELL JA, 1977, J RES PERS, V11, P273, DOI 10.1016/0092-6566(77)90037-X; Russell JA, 2003, ANNU REV PSYCHOL, V54, P329, DOI 10.1146/annurev.psych.54.101601.145102; Ryan Andrew, 2009, 2009 IEEE 43rd International Carnahan Conference on Security Technology. ICCST 2009, P172, DOI 10.1109/CCST.2009.5335546; SAMAL A, 1992, PATTERN RECOGN, V25, P65, DOI 10.1016/0031-3203(92)90007-6; Sanchez-Cortes Dairazalia, 2013, P 12 INT C MOB UB MU, P22; Sandbach G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P406, DOI 10.1109/FG.2011.5771434; Sandbach G, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P738, DOI 10.1109/ICCVW.2013.101; Sandbach G, 2012, IEEE IMAGE PROC, P1813, DOI 10.1109/ICIP.2012.6467234; Sandbach G, 2012, IMAGE VISION COMPUT, V30, P683, DOI 10.1016/j.imavis.2012.06.005; Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127; Savran A, 2008, PROC CVPR IEEE, P985; Savran A, 2015, IEEE T CYBERNETICS, V45, P1927, DOI 10.1109/TCYB.2014.2362101; Savran A, 2011, EUR SIGNAL PR CONF, P1969; Savran A, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P485; Savran A, 2012, IMAGE VISION COMPUT, V30, P774, DOI 10.1016/j.imavis.2011.11.008; Savran A, 2012, PATTERN RECOGN, V45, P767, DOI 10.1016/j.patcog.2011.07.022; Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6; Scherer S, 2013, IEEE INT CONF AUTOMA; Schmidt KL, 2001, YEARB PHYS ANTHROPOL, V44, P3, DOI 10.1002/ajpa.20001; Sebe N, 2007, IMAGE VISION COMPUT, V25, P1856, DOI 10.1016/j.imavis.2005.12.021; Sebe N, 2006, INT C PATT RECOG, P1136; Segundo MP, 2010, IEEE T SYST MAN CY B, V40, P1319, DOI 10.1109/TSMCB.2009.2038233; Senoussaoui M., 2014, P 4 INT WORKSH AUD V, P57, DOI DOI 10.1145/2661806.2661819; Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005; Shariff AF, 2011, CURR DIR PSYCHOL SCI, V20, P395, DOI 10.1177/0963721411424739; Shimada Keiji, 2013, International Journal of Computer Theory and Engineering, V5, P24, DOI 10.7763/IJCTE.2013.V5.640; Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381; Shreve Matthew, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P51, DOI 10.1109/FG.2011.5771451; Shreve M., 2009, PROC WORKSHOP APPL C, P1; Sidorov M., 2014, P 4 INT WORKSH AUD V, P81, DOI DOI 10.1145/2661806.2661816; Sikka K, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P517, DOI 10.1145/2522848.2531741; Sirohey S. A., 1998, CSTR3176 U MAR; Sobottka K, 1998, SIGNAL PROCESS-IMAGE, V12, P263, DOI 10.1016/S0923-5965(97)00042-8; Sobottka K, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P236, DOI 10.1109/AFGR.1996.557270; Soladie C, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P493; Song I, 2014, I SYMP CONSUM ELECTR, P566; Soyel H, 2007, LECT NOTES COMPUT SC, V4633, P831; Suwa M., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P408; Szeptycki P, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P32, DOI 10.1109/BTAS.2009.5339052; Tam GKL, 2013, IEEE T VIS COMPUT GR, V19, P1199, DOI 10.1109/TVCG.2012.310; Tan CT., 2012, P 8 AUSTR C INT ENT, V2012, P5, DOI DOI 10.1145/2336727.2336732; Tang H, 2008, IEEE INT CONF AUTOMA, P110; Tena J.R., 2006, 2006 IEEE INT C VIDE, P81; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; Trujillo L., 2005, PROC IEEE COMPUT SOC, P14; Tsalakanidou F, 2009, PROC CVPR IEEE, P763; Tsalakanidou F, 2010, PATTERN RECOGN, V43, P1763, DOI 10.1016/j.patcog.2009.12.009; Valstar Michel F., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P921, DOI 10.1109/FG.2011.5771374; Van den Stock J, 2007, EMOTION, V7, P487, DOI 10.1037/1528-3542.7.3.487; Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Vretos N, 2011, IEEE IMAGE PROC, P773, DOI 10.1109/ICIP.2011.6116669; Vuong Le, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P414, DOI 10.1109/FG.2011.5771435; Vural E., 2007, INT WORKSH HUM COMP, P6, DOI [DOI 10.1007/978-3-540-75773-3_2, 10.1007/978-3-540-75773-3_2]; Walecki R., 2015, P IEEE INT C AUT FAC, P1, DOI DOI 10.1109/FG.2015.7163137; Wallace V.F., 1983, EMFACS 7 EMOTIONAL F, V2, P1; Waller BM, 2008, PHYSIOL BEHAV, V95, P93, DOI 10.1016/j.physbeh.2008.05.002; Waller BM, 2008, EMOTION, V8, P435, DOI 10.1037/1528-3542.8.3.435; Waller BM, 2012, INT J PRIMATOL, V33, P809, DOI 10.1007/s10764-012-9611-6; Wang J, 2005, FACIAL EXPRESSION RE; Wang J., 2006, COMPUTER VISION PATT, V2, P1399, DOI [10.1109/CVPR.2006.14, DOI 10.1109/CVPR.2006.14]; Wang SF, 2014, FRONT COMPUT SCI-CHI, V8, P609, DOI 10.1007/s11704-014-3295-3; Wang SF, 2010, IEEE T MULTIMEDIA, V12, P682, DOI 10.1109/TMM.2010.2060716; WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063; Wei J, 2013, IEEE ICCE, P1, DOI 10.1109/ICCE.2013.6486769; Williamson JR., 4 INT WORKSH ORL FL, DOI [10.1145/2661806, DOI 10.1145/2661806]; Wollmer M, 2013, IMAGE VISION COMPUT, V31, P153, DOI 10.1016/j.imavis.2012.03.001; Wu, 2014, P 16 INT C MULT INT, P481; Wu B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P79; Wu CC, 2015, IEEE GLOB COMM CONF, DOI [10.1109/GLOCOM.2015.7417352, 10.1109/FG.2015.7163116]; Wu LZ, 1999, IEEE T MULTIMEDIA, V1, P334, DOI 10.1109/6046.807953; Wu Q, 2011, LECT NOTES COMPUT SC, V6975, P152, DOI 10.1007/978-3-642-24571-8_16; Xi Zhao, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3724, DOI 10.1109/ICPR.2010.907; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yan W.-J., 2013, 2013 10 IEEE INT C W, P1, DOI DOI 10.1109/FG.2013.6553799; Yin LJ, 2006, INT C PATT RECOG, P1248; Yin LJ, 2008, IEEE INT CONF AUTOMA, P116; Yoshitomi Y, 2000, IEEE RO-MAN 2000: 9TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P178, DOI 10.1109/ROMAN.2000.892491; Yoshitomi Y, 1997, RO-MAN '97 SENDAI: 6TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P380, DOI 10.1109/ROMAN.1997.647016; Yoshitomi Y, 2010, INT CONF APPL COMPUT, P182; Zafeiriou Stefanos, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2860, DOI 10.1109/CVPRW.2009.5206584; Zaker N., 2012, P IEEE INT C DEV LEA, P1; Zeng Z., 2006, J MULTIMEDIA, V1, P1, DOI DOI 10.4304/jmm.1.5.1-8; Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52; Zeng ZH, 2008, IEEE T MULTIMEDIA, V10, P570, DOI 10.1109/TMM.2008.921737; Zhang C., 2010, MSRTR201066; Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002; Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110; Zhao X, 2013, IMAGE VISION COMPUT, V31, P231, DOI 10.1016/j.imavis.2012.10.001; Zhi RC, 2011, IEEE T SYST MAN CY B, V41, P38, DOI 10.1109/TSMCB.2010.2044788	266	280	292	38	250	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2016	38	8			SI		1548	1568		10.1109/TPAMI.2016.2515606	http://dx.doi.org/10.1109/TPAMI.2016.2515606			21	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DR5EO	26761193	Green Submitted, Green Accepted			2022-12-18	WOS:000379926200006
J	Elad, A; Kimmel, R				Elad, A; Kimmel, R			On bending invariant signatures for surfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						MDS (Multi-Dimensional Scaling); FMTD (Fast Marching Method on Triangulate Domains); isometric signature; classification; geodesic distance		Isometric surfaces share the same geometric structure, also known as the "first fundamental form." For example, all possible bendings of a given surface that includes all length preserving deformations without tearing or stretching the surface are considered to be isometric. We present a method to construct a bending invariant signature for such surfaces. This invariant representation is an embedding of the geometric structure of the surface in a small dimensional Euclidean space in which geodesic distances are approximated by Euclidean ones. The bending invariant representation is constructed by first measuring the intergeodesic distances between uniformly distributed points on the surface. Next, a multidimensional scaling (MDS) technique is applied to extract coordinates in a finite dimensional Euclidean space in which geodesic distances are replaced by Euclidean ones. Applying this transform to various surfaces with similar geodesic structures (first fundamental form) maps them into similar signature surfaces. We thereby translate the problem of matching nonrigid objects in various postures into a simpler problem of matching rigid objects. As an example, we show a simple surface classification method that uses our bending invariant signatures.	IoIMAGE Ltd, IL-46733 Herzliya Pituach, Israel; Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Elad, A (corresponding author), IoIMAGE Ltd, 3 Maskitt St,POB 12414, IL-46733 Herzliya Pituach, Israel.	asi@ioimage.com; ron@cs.technion.ac.il						AHERNE FJ, 1997, P 8 BRIT MACH VIS C, P480; ARMAN F, 1993, COMPUT SURV, V25, P5, DOI 10.1145/151254.151255; Ashbrook AP, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P503; ASHBROOK AP, 1995, P IEEE IM PROC; ASHBROOK AP, 1995, P 9 SCAND C IM AN, V1, P271; Barequet G, 1997, IEEE T PATTERN ANAL, V19, P929, DOI 10.1109/34.615444; BESL P, 1990, MACHINE VISION 3 DIM; BESL PJ, 1985, COMPUT SURV, V17, P75, DOI 10.1145/4078.4081; BESL PJ, 1988, P IEEE, V76, P936, DOI 10.1109/5.5966; BESL PJ, 1994, OBJECT RECOGNITION, P191; Bloomenthal J, 1999, SHAPE MODELING INTERNATIONAL '99 - INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P44, DOI 10.1109/SMA.1999.749322; Borg I., 1997, MODERN MULTIDIMENSIO; BRONSTEIN A, 2003, P AUD VID BAS BIOM P, P62; Cox M. A. A., 1994, MULTIDIMENSIONAL SCA; ELAD A, 2001, P COMP VIS PATT REC; Eldar Y, 1997, IEEE T IMAGE PROCESS, V6, P1305, DOI 10.1109/83.623193; Faloutsos C., 1995, P 1995 ACM SIGMOD IN, P163; Faugeras O. D., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P796; Faugeras O. D., 1983, P INT JOINT C ART IN, V8, P996; Grossmann R, 2002, IEEE T PATTERN ANAL, V24, P433, DOI 10.1109/34.993552; Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282; HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073; Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431; Kreyszig E., 1991, DIFFERENTIAL GEOMETR; Kruskal JosephB., 1978, MULTIDIMENSIONAL SCA, DOI [10.4135/9781412985130, DOI 10.4135/9781412985130]; LAVALLEE S, 1995, IEEE T PATTERN ANAL, V17, P378, DOI 10.1109/34.385980; Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2; MELAX S, 1998, GAME DEV J       NOV; Osada R, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P154, DOI 10.1109/SMA.2001.923386; POPE A, 1994, TR9404 U BRIT COL; Potmesil M., 1979, Proceedings of the 1979 IEEE Computer Society Conference on Pattern Recognition and Image Processing, P553; SCHWARTZ EL, 1989, IEEE T PATTERN ANAL, V11, P1005, DOI 10.1109/34.35506; Storti D. W., 1997, Proceedings. Fourth Symposium on Solid Modeling and Applications, P141, DOI 10.1145/267734.267771; TAL A, UNPUB IEEE T NEURAL; TSITSIKLIS JN, 1995, IEEE T AUTOMAT CONTR, V40, P1528, DOI 10.1109/9.412624; Zigelman G, 2002, IEEE T VIS COMPUT GR, V8, P198, DOI 10.1109/2945.998671; [No title captured]	37	280	304	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2003	25	10					1285	1295		10.1109/TPAMI.2003.1233902	http://dx.doi.org/10.1109/TPAMI.2003.1233902			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	723ZE		Green Submitted			2022-12-18	WOS:000185460800008
J	Bai, X; Latecki, LJ; Liu, WY				Bai, Xiang; Latecki, Longin Jan; Liu, Wen-Yu			Skeleton pruning by contour partitioning with discrete curve evolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						skeleton; skeleton pruning; contour partition; discrete curve evolution	EUCLIDEAN SKELETON; SHAPE; DECOMPOSITION; RECOGNITION; MULTISCALE; ALGORITHM	In this paper, we introduce a new skeleton pruning method based on contour partitioning. Any contour partition can be used, but the partitions obtained by Discrete Curve Evolution ( DCE) yield excellent results. The theoretical properties and the experiments presented demonstrate that obtained skeletons are in accord with human visual perception and stable, even in the presence of significant noise and shape variations, and have the same topology as the original skeletons. In particular, we have proven that the proposed approach never produces spurious branches, which are common when using the known skeleton pruning methods. Moreover, the proposed pruning method does not displace the skeleton points. Consequently, all skeleton points are centers of maximal disks. Again, many existing methods displace skeleton points in order to produces pruned skeletons.	Huazhong Univ Sci & Technol, Dept Elect & Informat Engn, N1 Hall,D425,Luoyu Rd 1043, Wuhan 430074, Hubei, Peoples R China; Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA	Huazhong University of Science & Technology; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University	Bai, X (corresponding author), Huazhong Univ Sci & Technol, Dept Elect & Informat Engn, N1 Hall,D425,Luoyu Rd 1043, Wuhan 430074, Hubei, Peoples R China.	baihouxiang@hotmail.com; latecki@temple.edu; liuwy@hust.edu.cn	Liu, Wenyu/AAG-1426-2019	Liu, Wenyu/0000-0002-4582-7488; Latecki, Longin Jan/0000-0002-5102-8244				ARCELLI C, 1993, IMAGE VISION COMPUT, V11, P163, DOI 10.1016/0262-8856(93)90055-L; ARCELLI C, 1985, IEEE T PATTERN ANAL, V7, P463, DOI 10.1109/TPAMI.1985.4767685; ASLAN C, 2005, P INT C COMP VIS; BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; Borgefors G, 2001, IEEE T PATTERN ANAL, V23, P1296, DOI 10.1109/34.969119; BRANDT JW, 1992, CVGIP-IMAG UNDERSTAN, V55, P329, DOI 10.1016/1049-9660(92)90030-7; CHIN FYL, 1995, P 6 INT S ALG COMP, P382; Choi HI, 1997, PAC J MATH, V181, P57, DOI 10.2140/pjm.1997.181.57; Choi WP, 2003, PATTERN RECOGN, V36, P721, DOI 10.1016/S0031-3203(02)00098-5; Di Ruberto C, 2004, PATTERN RECOGN, V37, P21, DOI 10.1016/j.patcog.2003.07.004; Dimitrov P, 2000, PROC CVPR IEEE, P417, DOI 10.1109/CVPR.2000.855849; DIMITROV P, 2003, P INT C COMP VIS PAT; Ge YR, 1996, IEEE T PATTERN ANAL, V18, P1055, DOI 10.1109/34.544075; GOLD CM, 1999, P ICA WORKSH MAP GEN; Golland P, 2000, PROC CVPR IEEE, P10, DOI 10.1109/CVPR.2000.855792; KIMMEL R, 1995, COMPUT VIS IMAGE UND, V62, P382, DOI 10.1006/cviu.1995.1062; Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802; Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738; Latecki LJ, 2000, J ELECTRON IMAGING, V9, P317, DOI 10.1117/1.482748; Latecki LJ, 2002, PATTERN RECOGN, V35, P15, DOI 10.1016/S0031-3203(01)00039-5; LATECKI LJ, 2000, P C COMP VIS PATT RE; LATECKI LJ, 1999, P INT C SCAL SPAC 99; LEYMARIE F, 1992, IEEE T PATTERN ANAL, V14, P56, DOI 10.1109/34.107013; LIU T, 1998, P INT C COMP VIS JAN; Malandain G, 1998, IMAGE VISION COMPUT, V16, P317, DOI 10.1016/S0262-8856(97)00074-7; MAYY AN, 1994, P IEEE C COMP VIS PA, P638; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; OGNIEWICZ RL, 1995, PATTERN RECOGN, V28, P343, DOI 10.1016/0031-3203(94)00105-U; PIZER SM, 1987, IEEE T PATTERN ANAL, V9, P505, DOI 10.1109/TPAMI.1987.4767938; Pudney C, 1998, COMPUT VIS IMAGE UND, V72, P404, DOI 10.1006/cviu.1998.0680; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; Shaked D, 1998, COMPUT VIS IMAGE UND, V69, P156, DOI 10.1006/cviu.1997.0598; SIDDIQI K, 1995, IEEE T PATTERN ANAL, V17, P239, DOI 10.1109/34.368189; Siddiqi K, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P215, DOI 10.1109/ICCV.1998.710721; Siddiqi K, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P222, DOI 10.1109/ICCV.1998.710722; Siddiqi K, 2002, INT J COMPUT VISION, V48, P215, DOI 10.1023/A:1016376116653; Torsello A, 2004, COMPUT VIS IMAGE UND, V95, P1, DOI 10.1016/j.cviu.2004.03.006; Vasilevskiy A, 2002, IEEE T PATTERN ANAL, V24, P1565, DOI 10.1109/TPAMI.2002.1114849; Xie WJ, 2003, PATTERN RECOGN, V36, P1529, DOI 10.1016/S0031-3203(02)00348-5; ZHU SC, 1995, P INT C COMP VIS	41	279	307	2	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2007	29	3					449	462		10.1109/TPAMI.2007.59	http://dx.doi.org/10.1109/TPAMI.2007.59			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	125CY	17224615				2022-12-18	WOS:000243420500007
J	Veenman, CJ; Reinders, MJT; Backer, E				Veenman, CJ; Reinders, MJT; Backer, E			A maximum variance cluster algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						cluster analysis; partitional clustering; cluster tendency assessment; cluster validity	IMAGE SEGMENTATION	We present a partitional cluster algorithm that minimizes the sum-of-squared-error criterion while imposing a hard constraint on the cluster variance. Conceptually, hypothesized clusters act in parallel and cooperate with their neighboring clusters in order to minimize the criterion and to satisfy the variance constraint. In order to enable the demarcation of the cluster neighborhood without crucial parameters, we introduce the notion of foreign cluster samples. Finally, we demonstrate a new method for cluster tendency assessment based on varying the variance constraint parameter.	Delft Univ Technol, Fac Infomat Technol & Syst, Dept Mediamat, NL-2600 GA Delft, Netherlands	Delft University of Technology	Veenman, CJ (corresponding author), Delft Univ Technol, Fac Infomat Technol & Syst, Dept Mediamat, POB 5031, NL-2600 GA Delft, Netherlands.	C.J.Veenman@its.tudelft.nl; M.J.T.Reinders@its.tudelft.nl; E.Backer@its.tudelft.nl						ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913; ANDREY P, 1994, PATTERN RECOGN, V27, P659, DOI 10.1016/0031-3203(94)90045-0; Andrey P, 1998, IEEE T PATTERN ANAL, V20, P252, DOI 10.1109/34.667883; ANGELINE PJ, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P264; Babu GP, 2000, IEEE T SYST MAN CY B, V30, P10, DOI 10.1109/3477.826943; Bezdek JC, 1998, IEEE T SYST MAN CY B, V28, P301, DOI 10.1109/3477.678624; BROWN DE, 1992, PATTERN RECOGN, V25, P401, DOI 10.1016/0031-3203(92)90088-Z; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Di Nola A, 2000, NINTH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS (FUZZ-IEEE 2000), VOLS 1 AND 2, P953, DOI 10.1109/FUZZY.2000.839162; Dunn J. C., 1974, Journal of Cybernetics, V4, P95, DOI 10.1080/01969727408546059; GOWDA KC, 1978, PATTERN RECOGN, V10, P105; Hall LO, 1999, IEEE T EVOLUT COMPUT, V3, P103, DOI 10.1109/4235.771164; Holland J.H., 1975, ADAPTATION NATURAL A, DOI DOI 10.7551/MITPRESS/1090.001.0001; HOROWITZ SL, 1976, J ACM, V23, P368, DOI 10.1145/321941.321956; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Ingrassia S., 1992, Statistics and Computing, V2, P203, DOI 10.1007/BF01889680; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; JARVIS RA, 1973, IEEE T COMPUT, VC-22, P1025, DOI 10.1109/T-C.1973.223640; KLEIN RW, 1989, PATTERN RECOGN, V22, P213, DOI 10.1016/0031-3203(89)90067-8; Krishna K, 1999, IEEE T SYST MAN CY B, V29, P433, DOI 10.1109/3477.764879; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Pauwels EJ, 1999, COMPUT VIS IMAGE UND, V75, P73, DOI 10.1006/cviu.1999.0763; SELIM SZ, 1991, PATTERN RECOGN, V24, P1003, DOI 10.1016/0031-3203(91)90097-O; THEORODORIS S, 1999, PATTERN RECOGNITION; TITTERINGTON DM, 1990, STAT ANAL FINITE MIX; VanLe T, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON EVOLUTIONARY COMPUTATION, VOLS 1 AND 2, P753, DOI 10.1109/ICEC.1995.487480; VEENMAN CJ, 2001, UNPUB IEEE T IMAGE P; Zhao LH, 1996, IEEE C EVOL COMPUTAT, P716, DOI 10.1109/ICEC.1996.542690	29	279	311	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2002	24	9					1273	1280		10.1109/TPAMI.2002.1033218	http://dx.doi.org/10.1109/TPAMI.2002.1033218			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	587KW		Green Submitted			2022-12-18	WOS:000177640500010
J	SHAPIRO, LG; HARALICK, RM				SHAPIRO, LG; HARALICK, RM			STRUCTURAL DESCRIPTIONS AND INEXACT MATCHING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									VIRGINIA POLYTECH INST & STATE UNIV, DEPT ELECT ENGN, BLACKSBURG, VA 24061 USA	Virginia Polytechnic Institute & State University	SHAPIRO, LG (corresponding author), VIRGINIA POLYTECH INST & STATE UNIV, DEPT COMP SCI, BLACKSBURG, VA 24061 USA.		Haralick, Robert/AAW-5151-2020	manickam, vijayabhama.M/0000-0001-9437-9477				BARNHART CL, 1958, AM COLLEGE DICT; BARROW HG, 1972, FRONTIERS PATTERN RE, P1; Davis L. S., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing, P275; GASCHING J, 1972, 5TH P INT JOINT C AR, P457; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; HARALICK RM, 1978, IEEE T SYST MAN CYB, V8, P600, DOI 10.1109/TSMC.1978.4310036; HARALICK RM, 1978, INFORM SCIENCES, V14, P199, DOI 10.1016/0020-0255(78)90043-9; HARALICK RM, 1979, 6TH P INT JOINT C AR; HARALICK RM, 1978, COMPUTER VISION SYST; MACKWORTH AK, 1977, ARTIF INTELL, V8, P99, DOI 10.1016/0004-3702(77)90007-8; MONTANAR.U, 1974, INFORM SCIENCES, V7, P95, DOI 10.1016/0020-0255(74)90008-5; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SHAPIRO LG, 1978, MAY P IEEE C PATT RE, P238; SHAPIRO LG, 1980, IEEE T PATTERN ANAL; TSAI WH, 1979, ERROR CORRECTING ISO; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; WALTZ DL, 1972, MIT A1271 TECH REP; Zucker S. W., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing, P410	18	279	282	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	5					504	519		10.1109/TPAMI.1981.4767144	http://dx.doi.org/10.1109/TPAMI.1981.4767144			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MQ358	21868971	Green Published, Green Submitted			2022-12-18	WOS:A1981MQ35800002
J	Lu, JW; Liong, VE; Zhou, XZ; Zhou, J				Lu, Jiwen; Liong, Venice Erin; Zhou, Xiuzhuang; Zhou, Jie			Learning Compact Binary Face Descriptor for Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; heterogeneous face matching; feature learning; binary feature; compact feature; biometrics	PATTERNS; GABOR; REPRESENTATION; SCALE; VERIFICATION; MAGNITUDES; EIGENFACES; HISTOGRAM; FEATURES; MODEL	Binary feature descriptors such as local binary patterns (LBP) and its variations have been widely used in many face recognition systems due to their excellent robustness and strong discriminative power. However, most existing binary face descriptors are hand-crafted, which require strong prior knowledge to engineer them by hand. In this paper, we propose a compact binary face descriptor (CBFD) feature learning method for face representation and recognition. Given each face image, we first extract pixel difference vectors (PDVs) in local patches by computing the difference between each pixel and its neighboring pixels. Then, we learn a feature mapping to project these pixel difference vectors into low-dimensional binary vectors in an unsupervised manner, where 1) the variance of all binary codes in the training set is maximized, 2) the loss between the original real-valued codes and the learned binary codes is minimized, and 3) binary codes evenly distribute at each learned bin, so that the redundancy information in PDVs is removed and compact binary codes are obtained. Lastly, we cluster and pool these binary codes into a histogram feature as the final representation for each face image. Moreover, we propose a coupled CBFD (C-CBFD) method by reducing the modality gap of heterogeneous faces at the feature level to make our method applicable to heterogeneous face recognition. Extensive experimental results on five widely used face datasets show that our methods outperform state-of-the-art face descriptors.	[Lu, Jiwen; Zhou, Jie] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China; [Liong, Venice Erin] Univ Illinois, Adv Digital Sci Ctr, Singapore 138632, Singapore; [Zhou, Xiuzhuang] Capital Normal Univ, Coll Informat Engn, Beijing 100048, Peoples R China	Tsinghua University; Capital Normal University	Lu, JW (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.	elujiwen@gmail.com; venice.l@adsc.com.sg; xiuzhuang.zhou@cnu.edu.cn; jzhou@tsinghua.edu.cn	Lu, Jiwen/C-5291-2009	Lu, Jiwen/0000-0002-6121-5529	National Natural Science Foundation of China [61225008, 61373090]; National Basic Research Program of China [2014CB349304]; Ministry of Education of China [20120002110033]; Tsinghua University Initiative Scientific Research Program; Agency for Science, Technology and Research (A*STAR) of Singapore	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China(National Basic Research Program of China); Ministry of Education of China(Ministry of Education, China); Tsinghua University Initiative Scientific Research Program; Agency for Science, Technology and Research (A*STAR) of Singapore(Agency for Science Technology & Research (A*STAR))	This work is supported by the National Natural Science Foundation of China under Grant 61225008 and Grant 61373090, the National Basic Research Program of China under Grant 2014CB349304, the Ministry of Education of China under Grant 20120002110033, the Tsinghua University Initiative Scientific Research Program, and a research grant for the Human Centric Cyber Systems (HCCS) Program at the Advanced Digital Sciences Center (ADSC) from the Agency for Science, Technology and Research (A*STAR) of Singapore.	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Arashloo S. R., 2013, P IEEE 6 INT C BIOM, P1, DOI DOI 10.1109/BTAS.2013.6712721; Barkan O, 2013, IEEE I CONF COMP VIS, P1960, DOI 10.1109/ICCV.2013.246; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024; Beveridge J. R., 2013, P 6 INT C BIOMETRICS, P1; Cao Q, 2013, IEEE I CONF COMP VIS, P2408, DOI 10.1109/ICCV.2013.299; CAO ZM, 2010, PROC CVPR IEEE, P2707, DOI DOI 10.1109/CVPR.2010.5539992; Chen D, 2012, LECT NOTES COMPUT SC, V7574, P566, DOI 10.1007/978-3-642-33712-3_41; Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389; Cui Z, 2013, PROC CVPR IEEE, P3554, DOI 10.1109/CVPR.2013.456; Deniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004; Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557; Gong Y., 2012, ADV NEURAL INFORM PR, P1196; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242; Huang Gary B, 2014, 14003 U MASS AMH DEP, V14, P1; Huang Gary B., 2007, 0749 U MASS, P7; HUANG GB, 2012, PROC CVPR IEEE, P2518, DOI DOI 10.1109/CVPR; Hyvarinen A, 2009, COMPUT IMAGING VIS, V39, P151; Kan MN, 2012, LECT NOTES COMPUT SC, V7572, P808, DOI 10.1007/978-3-642-33718-5_58; Kittler J., 2004, P EUR C COMP VIS, P469; Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496; Le Q.V., 2011, NEURIPS, P1017; Lee HT, 2009, ACM T WEB, V3, DOI 10.1145/1541822.1541823; Lei Z, 2007, LECT NOTES COMPUT SC, V4642, P49; Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112; Lei Z, 2011, IEEE T IMAGE PROCESS, V20, P247, DOI 10.1109/TIP.2010.2060207; Li SZ, 2013, IEEE COMPUT SOC CONF, P348, DOI 10.1109/CVPRW.2013.59; Li X, 2013, PROC CVPR IEEE, P2419, DOI 10.1109/CVPR.2013.313; Lin DH, 2006, LECT NOTES COMPUT SC, V3954, P13; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70; Maturana D., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P470, DOI 10.1109/FG.2011.5771444; Maturana D., 2010, P 10 AS C COMP VIS, P618; Meng X, 2006, INT C PATT RECOG, P536; Meyers E, 2008, INT J COMPUT VISION, V76, P93, DOI 10.1007/s11263-007-0058-8; Mohammad Norouzi, 2012, ADV NEURAL INFORM PR, P1061; Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974; Nguyen Hieu V, 2010, P AS C COMP VIS, P709, DOI DOI 10.1007/978-3-642-19309-5_55; Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Rifai S., 2011, PROC INT C MACH LEAR; Seo HJ, 2011, IEEE T INF FOREN SEC, V6, P1275, DOI 10.1109/TIFS.2011.2159205; Sharma A., 2012, CVPR, DOI DOI 10.1109/CVPR.2012.6247923; Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350; Sharma G, 2012, LECT NOTES COMPUT SC, V7578, P1, DOI 10.1007/978-3-642-33786-4_1; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Sun Y, 2013, IEEE I CONF COMP VIS, P1489, DOI 10.1109/ICCV.2013.188; Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P235; Trzcinski T, 2012, LECT NOTES COMPUT SC, V7572, P228, DOI 10.1007/978-3-642-33718-5_17; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; ul Hussain S, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.99; Verschae R., 2008, P WORKSH FAC REAL LI, P1; Vu NS, 2013, IEEE T INF FOREN SEC, V8, P295, DOI 10.1109/TIFS.2012.2224866; Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994; Wang K., 2013, P IEEE INT C COMP VI, P2407; Weiss Y, 2009, ADV NEURAL INFORM PR, P1753; Weiss Yair, 2008, ADV NEURAL INFORM PR, P1753; Wen ZW, 2013, MATH PROGRAM, V142, P397, DOI 10.1007/s10107-012-0584-1; Wolf L., 2008, P REAL LIF IM WORKSH, P1; Xie SF, 2009, SIGNAL PROCESS, V89, P2333, DOI 10.1016/j.sigpro.2009.02.016; Yi D, 2013, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2013.454; Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956; Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882; Zhang WC, 2005, IEEE I CONF COMP VIS, P786; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	71	278	288	7	158	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2015	37	10					2041	2056		10.1109/TPAMI.2015.2408359	http://dx.doi.org/10.1109/TPAMI.2015.2408359			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CQ7VL	26340256				2022-12-18	WOS:000360813400008
J	Proenca, H; Filipe, S; Santos, R; Oliveira, J; Alexandre, LA				Proenca, Hugo; Filipe, Silvio; Santos, Ricardo; Oliveira, Jaoo; Alexandre, Luis A.			The UBIRIS.v2: A Database of Visible Wavelength Iris Images Captured On-the-Move and At-a-Distance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Iris recognition; biometrics; noncooperative image acquisition; visible-light iris images; covert recognition	RECOGNITION	The iris is regarded as one of the most useful traits for biometric recognition and the dissemination of nationwide iris-based recognition systems is imminent. However, currently deployed systems rely on heavy imaging constraints to capture near infrared images with enough quality. Also, all of the publicly available iris image databases contain data correspondent to such imaging constraints and therefore are exclusively suitable to evaluate methods thought to operate on these type of environments. The main purpose of this paper is to announce the availability of the UBIRIS.v2 database, a multisession iris images database which singularly contains data captured in the visible wavelength, at-a-distance (between four and eight meters) and on on-the-move. This database is freely available for researchers concerned about visible wavelength iris recognition and will be useful in accessing the feasibility and specifying the constraints of this type of biometric recognition.	[Proenca, Hugo; Filipe, Silvio; Santos, Ricardo; Oliveira, Jaoo; Alexandre, Luis A.] Univ Beira Interior, Dept Informat, P-6201001 Covilha, Portugal	Universidade da Beira Interior	Proenca, H (corresponding author), Univ Beira Interior, Dept Informat, Rua Marques DAvila e Bolama, P-6201001 Covilha, Portugal.	hugomcp@di.ubi.pt; sfilipe@di.ubi.pt; rsantos@di.ubi.pt; joliveira@di.ubi.pt; lfbaa@di.ubi.pt	Proença, Hugo/F-9499-2010; Alexandre, Luís/E-8770-2013; Filipe, Sílvio/F-5781-2010	Proença, Hugo/0000-0003-2551-8570; Alexandre, Luís/0000-0002-5133-5025; Filipe, Sílvio/0000-0002-2890-0380	Fundacao para a Ciencia e Tecnologia (FCT); FEDER [PTDC/EIA/69106/2006]	Fundacao para a Ciencia e Tecnologia (FCT)(Portuguese Foundation for Science and TechnologyEuropean Commission); FEDER(European Commission)	The authors acknowledge the financial support given by "Fundacao para a Ciencia e Tecnologia (FCT)" and "FEDER" in the scope of the PTDC/EIA/69106/2006 research project "BIOREC: Non-Cooperative Biometric Recognition." Also, they acknowledge all of the volunteers who agreed to participate in the imaging sessions of the UBIRIS.v2 database.	[Anonymous], 2004, MMU IR IM DAT; [Anonymous], 2006, IR CHALL EV; Boles WW, 1998, IEEE T SIGNAL PROCES, V46, P1185, DOI 10.1109/78.668573; Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005; Boyce C., 2006, 2006 C COMP VIS PATT, P51; Chen FH, 2006, NAT CLIN PRACT RHEUM, V2, P373, DOI 10.1038/ncprheum0216; Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350; Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540; Dobes M., 2004, UPOL IRIS IMAGE DATA; Duda R.O., 1973, J ROYAL STAT SOC SER; Fancourt C, 2005, LECT NOTES COMPUT SC, V3546, P1; Guyon I, 1998, IEEE T PATTERN ANAL, V20, P52, DOI 10.1109/34.655649; He YQ, 2006, INT C PATT RECOG, P557; Huang YP, 2002, 2002 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-4, PROCEEDINGS, P450; *I AUT CHIN AC SCI, 2004, CASIA IR IM DAT; IBG: International biometric group, 2005, INT BIOM GROUP IND T; KALKA ND, 2006, P 2006 SPIE C BIOM T; Ma L, 2004, PATTERN RECOGN, V37, P1287, DOI 10.1016/j.patcog.2004.02.001; Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145; Matey J.R., 2007, ADV BIOMETRICS SENSO, P107; Narayanswamy R, 2005, APPL OPTICS, V44, P701, DOI 10.1364/AO.44.000701; *NAT I STAND TECHN, 2007, MBGC MULT GRAND CHAL; Park KR, 2005, IEEE T SYST MAN CY C, V35, P441, DOI 10.1109/TSMCC.2005.848168; Proenca H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119; PROENCA H, 2007, P IEEE 1 INT C BIOM, P27; Ross A., 2004, P 2004 BIOM CONS C S; Schuckers SAC, 2007, IEEE T SYST MAN CY B, V37, P1176, DOI 10.1109/TSMCB.2007.904831; *UK PASSP SERV BIO, 2005, AT OR; University of Bath, 2004, U BATH IR IM DAT; Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669	30	278	281	1	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2010	32	8					1529	1535		10.1109/TPAMI.2009.66	http://dx.doi.org/10.1109/TPAMI.2009.66			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	611XQ	20558882				2022-12-18	WOS:000278858600014
J	Chang, KI; Bowyer, KW; Flynn, PJ				Chang, KI; Bowyer, KW; Flynn, PJ			An evaluation of multimodal 2D+3D face biometrics	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						biometrics; face recognition; three-dimensional face; multimodal; multisample	RECOGNITION	We report on the largest experimental study to date in multimodal 2D+3D face recognition, involving 198 persons in the gallery and either 198 or 670 time-lapse probe images. PCA-based methods are used separately for each modality and match scores in the separate face spaces are combined for multimodal recognition. Major conclusions are: 1) 2D and 3D have similar recognition performance when considered individually, 2) combining 2D and 3D results using a simple weighting scheme outperforms either 2D or 3D alone, 3) combining results from two or more 2D images using a similar weighting scheme also outperforms a single 2D image, and 4) combined 2D+3D outperforms the multiimage 2D result. This is the first ( so far, only) work to present such an experimental control to substantiate multimodal performance improvement.	Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA	University of Notre Dame	Chang, KI (corresponding author), Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.	kchang@cse.nd.edu; kwb@cse.nd.edu; flynn@cse.nd.edu	Flynn, Patrick J/J-3388-2013	Flynn, Patrick J/0000-0002-5446-114X; Bowyer, Kevin/0000-0002-7562-4390				BEUMIER C, 2000, 11 PORT C PATT REC, P95; BOWYER K, 2004, P INT C PATT REC; CHANG K, 2003, P ACM WORKSH MULT US, P25; Chang KI, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P43, DOI 10.1109/AFGR.2004.1301507; GIVENS G, 2003, P WORKSH STAT AN COM; Lao SH, 2000, INT C PATT RECOG, P911, DOI 10.1109/ICPR.2000.906222; MIN J, 2003, TR037 U NOTR DAM; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Poh N, 2002, NEURAL NETWORKS FOR SIGNAL PROCESSING XII, PROCEEDINGS, P375, DOI 10.1109/NNSP.2002.1030049; Tsalakanidou F, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P266, DOI 10.1109/AFGR.2004.1301542; Wang YJ, 2002, PATTERN RECOGN LETT, V23, P1191, DOI 10.1016/S0167-8655(02)00066-1; YAMBOR WS, 2000, P 2 WORKSH EMP EV CO	12	278	285	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2005	27	4					619	624		10.1109/TPAMI.2005.70	http://dx.doi.org/10.1109/TPAMI.2005.70			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	895FG	15794165				2022-12-18	WOS:000226845700011
J	Koppula, HS; Saxena, A				Koppula, Hema S.; Saxena, Ashutosh			Anticipating Human Activities Using Object Affordances for Reactive Robotic Response	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						RGBD Data; 3D activity understanding; human activity anticipation; machine learning; robotics perception	ACTIVITY RECOGNITION; PARTICLE FILTERS; CONTEXT	An important aspect of human perception is anticipation, which we use extensively in our day-to-day activities when interacting with other humans as well as with our surroundings. Anticipating which activities will a human do next (and how) can enable an assistive robot to plan ahead for reactive responses. Furthermore, anticipation can even improve the detection accuracy of past activities. The challenge, however, is two-fold: We need to capture the rich context for modeling the activities and object affordances, and we need to anticipate the distribution over a large space of future human activities. In this work, we represent each possible future using an anticipatory temporal conditional random field (ATCRF) that models the rich spatial-temporal relations through object affordances. We then consider each ATCRF as a particle and represent the distribution over the potential futures using a set of particles. In extensive evaluation on CAD-120 human activity RGB-D dataset, we first show that anticipation improves the state-of-the-art detection results. We then show that for new subjects (not seen in the training set), we obtain an activity anticipation accuracy (defined as whether one of top three predictions actually happened) of 84.1, 74.4 and 62.2 percent for an anticipation time of 1, 3 and 10 seconds respectively. Finally, we also show a robot using our algorithm for performing a few reactive responses.	[Koppula, Hema S.; Saxena, Ashutosh] Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA	Cornell University	Koppula, HS (corresponding author), Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA.	hema@cs.cornell.edu; asaxena@cs.cornell.edu			ARO [W911NF-12-1-0267]; Microsoft Faculty Fellowship; US National Science Foundation (NSF); Google PhD Fellowship	ARO; Microsoft Faculty Fellowship(Microsoft); US National Science Foundation (NSF)(National Science Foundation (NSF)); Google PhD Fellowship(Google Incorporated)	The authors would like to thank Rudhir Gupta and Jerry Yeh for useful discussions. This work was partially supported by ARO award W911NF-12-1-0267, and by Microsoft Faculty Fellowship, US National Science Foundation (NSF) Career Award and Google PhD Fellowship. Parts of this work have been published at ICML 2013 and RSS 2013. The paper at RSS 2013 received the best student paper award and was the runnerup for the Best Paper Award.	Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653; Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821; Delaitre V, 2012, LECT NOTES COMPUT SC, V7577, P284, DOI 10.1007/978-3-642-33783-3_21; Diankov R., 2010, THESIS; Doucet A., 2000, P 16 C UNC ART INT, P176, DOI DOI 10.1049/IET-SPR:20070075.; Dragan A., 2012, C ROB SCI SYST SYDN; Duchenne O, 2009, IEEE I CONF COMP VIS, P1491, DOI 10.1109/ICCV.2009.5459279; Faraway JJ, 2007, J R STAT SOC C-APPL, V56, P571, DOI 10.1111/j.1467-9876.2007.00592.x; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Fox D., 2001, NEUR INF PROC SYST V; Fox E., 2008, ADV NEURAL INFORM PR, V21, P457; Fu YW, 2012, LECT NOTES COMPUT SC, V7575, P530, DOI 10.1007/978-3-642-33765-9_38; Gaidon A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3201, DOI 10.1109/CVPR.2011.5995646; Gibson J.J., 1979, ECOLOGICAL APPROACH; Gong SG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P742, DOI 10.1109/ICCV.2003.1238423; Grabner H, 2011, PROC CVPR IEEE, P1529, DOI 10.1109/CVPR.2011.5995327; Guizzo E, 2012, IEEE SPECTRUM, V49, P34, DOI 10.1109/MSPEC.2012.6309254; Gupta A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1961, DOI 10.1109/CVPR.2011.5995448; Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83; Gustafsson F, 2002, IEEE T SIGNAL PROCES, V50, P425, DOI 10.1109/78.978396; HAMMER PL, 1984, MATH PROGRAM, V28, P121, DOI 10.1007/BF02612354; Harchaoui Z., 2008, ADV NEURAL INFORM PR, P609; Hermans T., 2011, INT C ROB AUT WORKSH; Hess R, 2009, PROC CVPR IEEE, P240, DOI 10.1109/CVPRW.2009.5206801; Hongeng S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1455, DOI 10.1109/ICCV.2003.1238661; Jensfelt P., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P2531, DOI 10.1109/ROBOT.2000.846409; Jia ZY, 2013, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2013.8; Jiang Y., 2012, P INT C MACH LEARN, P1543; Jiang Y, 2013, PROC CVPR IEEE, P2993, DOI 10.1109/CVPR.2013.385; Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353; Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]; Ke Y, 2007, IEEE I CONF COMP VIS, P1424; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; Kitani KM, 2012, LECT NOTES COMPUT SC, V7575, P201, DOI 10.1007/978-3-642-33765-9_15; Kjellstrom H, 2011, COMPUT VIS IMAGE UND, V115, P81, DOI 10.1016/j.cviu.2010.08.002; Koppula H. S., 2011, ADV NEURAL INFORM PR, P244; Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446; Kuderer M., 2012, C ROB SCI SYST SYDN; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Laxton BM, 2007, PROC CVPR IEEE, P799; Ly DL, 2012, PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P967, DOI 10.1145/2330163.2330297; Maji S., 2011, CVPR, DOI DOI 10.1109/CVPR.2011.5995631; Min JK, 2011, IEEE SYS MAN CYBERN, P1319, DOI 10.1109/ICSMC.2011.6083808; Hoai M, 2012, PROC CVPR IEEE, P2863, DOI 10.1109/CVPR.2012.6248012; Minh Hoai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3265, DOI 10.1109/CVPR.2011.5995470; Nguyen MH, 2009, IEEE I CONF COMP VIS, P1925, DOI 10.1109/ICCV.2009.5459426; Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P593; Montemerlo M, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P695, DOI 10.1109/ROBOT.2002.1013439; Natarajan P., 2007, IEEE WORKSH MOT VID; Nguyen M. H., 2012, ARTIF INTELL, P520; Ni BB, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS); Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29; Nikolaidis S, 2013, ACMIEEE INT CONF HUM, P33, DOI 10.1109/HRI.2013.6483499; Oh SM, 2008, INT J COMPUT VISION, V77, P103, DOI 10.1007/s11263-007-0062-z; Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010; Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124; Rohrbach M, 2012, LECT NOTES COMPUT SC, V7572, P144, DOI 10.1007/978-3-642-33718-5_11; Rohrbach M, 2012, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2012.6247801; Rother C, 2007, PROC CVPR IEEE, P1784; Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349; Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806; Sarawagi Sunita, 2004, ADV NEURAL INF PROCE, P1185; Satkin S, 2010, LECT NOTES COMPUT SC, V6311, P536, DOI 10.1007/978-3-642-15549-9_39; Schulz Dirk, 2003, P 18 INT JOINT C ART, P921; Shi QF, 2011, INT J COMPUT VISION, V93, P22, DOI 10.1007/s11263-010-0384-0; Shotton J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI 10.1109/TPAMI.2012.241; Simon T, 2010, PROC CVPR IEEE, P2737, DOI 10.1109/CVPR.2010.5539998; Sminchisescu C, 2005, IEEE I CONF COMP VIS, P1808; Sun J, 2010, INT J ROBOT RES, V29, P174, DOI 10.1177/0278364909356602; Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591; Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808; Tran SD, 2008, LECT NOTES COMPUT SC, V5303, P610, DOI 10.1007/978-3-540-88688-4_45; Wang Z., 2012, C ROB SCI SYST SYDN; Wang ZH, 2013, PROC CVPR IEEE, P1690, DOI 10.1109/CVPR.2013.221; Xing Z., 2008, P 2008 SIAM INT C DA, P644; Xuan X., 2007, P 24 INT C MACH LEAR, P1055, DOI DOI 10.1145/1273496.1273629; Yang WL, 2010, PROC CVPR IEEE, P2030, DOI 10.1109/CVPR.2010.5539879; YAO BP, 2010, PROC CVPR IEEE, P17, DOI DOI 10.1109/CVPR.2010.5540235; Zhang H., 2011, INTELLIGENT ROBOTS S, P2044, DOI DOI 10.1109/IROS.2011.6094489; Zhu YY, 2013, PROC CVPR IEEE, P2491, DOI 10.1109/CVPR.2013.322; Ziebart BD, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3931, DOI 10.1109/IROS.2009.5354147	81	277	283	4	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2016	38	1					14	29		10.1109/TPAMI.2015.2430335	http://dx.doi.org/10.1109/TPAMI.2015.2430335			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CY8OW	26656575	Green Submitted			2022-12-18	WOS:000366669200002
J	Ward, JA; Lukowicz, P; Troster, G; Starner, TE				Ward, Jamie A.; Lukowicz, Paul; Troester, Gerhard; Starner, Thad E.			Activity recognition of assembly tasks using body-worn microphones and accelerometers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pervasive computing; wearable computers and body area networks; classifier evaluation; industry	PHYSICAL-ACTIVITY; VALIDATION	In order to provide relevant information to mobile users, such as workers engaging in the manual tasks of maintenance and assembly, a wearable computer requires information about the user's specific activities. This work focuses on the recognition of activities that are characterized by a hand motion and an accompanying sound. Suitable activities can be found in assembly and maintenance work. Here, we provide an initial exploration into the problem domain of continuous activity recognition using on-body sensing. We use a mock "wood workshop" assembly task to ground our investigation. We describe a method for the continuous recognition of activities (sawing, hammering, filing, drilling, grinding, sanding, opening a drawer, tightening a vise, and turning a screwdriver) using microphones and three-axis accelerometers mounted at two positions on the user's arms. Potentially "interesting" activities are segmented from continuous streams of data using an analysis of the sound intensity detected at the two different locations. Activity classification is then performed on these detected segments using linear discriminant analysis (LDA) on the sound channel and hidden Markov models (HMMs) on the acceleration data. Four different methods at classifier fusion are compared for improving these classifications. Using user-dependent training, we obtain continuous average recall and precision rates (for positive activities) of 78 percent and 74 percent, respectively. Using user-independent training (leave-one-out across five users), we obtain recall rates of 66 percent and precision rates of 63 percent. In isolation, these activities were recognized with accuracies of 98 percent, 87 percent, and 95 percent for the user-dependent, user-independent, and user-adapted cases, respectively.	ETH, Inst Elect, Zurich, Switzerland; Univ Passau, Dept Comp Sci, D-94030 Passau, Germany; Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA	Swiss Federal Institutes of Technology Domain; ETH Zurich; University of Passau; University System of Georgia; Georgia Institute of Technology	Ward, JA (corresponding author), ETH, Inst Elect, Zurich, Switzerland.	ward@ife.ee.ethz.ch; paul.kukowicz@umit.at; troester@ife.ee.ethz.ch; thad@cc.gatech.edu	Ward, Jamie/AAH-2775-2020	Ward, Jamie/0000-0002-9637-6066				Abowd D., 1998, Virtual Reality, V3, P200, DOI 10.1007/BF01408562; AMFT O, 2005, P IEEE INT S WEAR CO; Aminian K, 1999, MED BIOL ENG COMPUT, V37, P304, DOI 10.1007/BF02513304; Aminian K, 2004, COMPUT ANIMAT VIRT W, V15, P79, DOI 10.1002/cav.2; ANTIFAKOS S, 2002, P 4 INT C UB COMP UB, P351; Bao L., 2004, PERVASIVE; BONATO P, 2005, J NEUROENG REHABILIT, V2; Bouten CVC, 1997, IEEE T BIO-MED ENG, V44, P136, DOI 10.1109/10.554760; Brashear H, 2003, SEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P45, DOI 10.1109/ISWC.2003.1241392; BUCHLER M, 2002, THESIS ETH ZURICH; Bussmann JBJ, 2001, BEHAV RES METH INS C, V33, P349, DOI 10.3758/BF03195388; Clarkson B., 1998, ENERGY, V400, P20; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; FANG G, 2003, P INT C MULT INT NOV; Fawcett T., 2004, ROC GRAPHS NOTES PRA; FEINER S, 1993, COMMUN ACM, V36, P53, DOI 10.1145/159544.159587; Ho T, 2002, HYBRID METHODS PATTE; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716; Hoover A, 1996, IEEE T PATTERN ANAL, V18, P673, DOI 10.1109/34.506791; Junker H, 2004, EIGHTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P188, DOI 10.1109/ISWC.2004.12; Kern N, 2002, SIXTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P186, DOI 10.1109/ISWC.2002.1167247; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Lampe M., 2004, P 2004 ACM S APPL CO, P1586, DOI 10.1145/967900.968217; Mantyla T.J., 2001, P IEEE INT C SYST MA, V3494, P747, DOI DOI 10.1109/ICSMC.2001.973004; MINNEN D, 2003, P IEEE C COMP VIS PA; MURPHY K, HMM TOOLBOX MATLAB; OGRIS G, 2005, P IEEE INT S WEAR CO; Peltonen V, 2002, INT CONF ACOUST SPEE, P1941; Phillips IT, 1999, IEEE T PATTERN ANAL, V21, P849, DOI 10.1109/34.790427; PROVOST F, 1998, P 15 INT MON LAUND C; Randell C, 2000, FOURTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, DIGEST OF PAPERS, P175, DOI 10.1109/ISWC.2000.888488; REHG JM, 1993, DIGITEYES VISION BAS; Schlenzig J., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P187, DOI 10.1109/ACV.1994.341308; Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI [10.1109/MASSP.1986.1165342, 10.1002/0471250953.bia03as18]; STAGER M, 2004, P IEEE INT S WEAR CO; Stager M., 2003, P IEEE INT S WEAR CO; STARNER T, 1994, INT CONF ACOUST SPEE, P125; Starner T, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P50, DOI 10.1109/ISWC.1998.729529; Tapia EM, 2004, LECT NOTES COMPUT SC, V3001, P158, DOI 10.1007/978-3-540-24646-6_10; Uiterwaal M, 1998, J MED ENG TECHNOL, V22, P168, DOI 10.3109/03091909809032535; Van Laerhoven K, 2000, FOURTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, DIGEST OF PAPERS, P77, DOI 10.1109/ISWC.2000.888468; Van Rijsbergen CJ, 1979, INFORM RETRIEVAL; Veltink P H, 1996, IEEE Trans Rehabil Eng, V4, P375, DOI 10.1109/86.547939; Vogler C., 1998, P INT C COMP VIS; WARD JA, 2005, P SOC 05 C OCT; Wetzler M., 2003, CLIN PATHOLOGICAL ST; WILSON AD, 1995, P IEEE INT S COMP VI; Wu HD, 2000, IEEE T INSTRUM MEAS, V49, P493, DOI 10.1109/19.850382; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943	49	277	287	1	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2006	28	10					1553	1567		10.1109/TPAMI.2006.197	http://dx.doi.org/10.1109/TPAMI.2006.197			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	071ME	16986539	Green Submitted			2022-12-18	WOS:000239605500002
J	Sebastian, TB; Klein, PN; Kimia, BB				Sebastian, TB; Klein, PN; Kimia, BB			On aligning curves	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						curve alignment; recognition; dynamic programming; prototypes; correspondence	STRING CORRECTION PROBLEM; RECOGNITION; SHAPES; CLASSIFICATION; SIMILARITY; CONTOUR; DESCRIPTORS; RETRIEVAL; DISTANCES; OBJECTS	We present a novel approach to finding a correspondence (alignment) between two curves. The correspondence is based on a notion of an alignment curve which treats both curves symmetrically. We then define a similarity metric based on the alignment curve using two intrinsic properties of the curve, namely, length and curvature. The optimal correspondence is found by an efficient dynamic-programming method both for aligning pairs of curve segments and pairs of closed curves, and is effective in the presence of a variety of transformations of the curve. Finally, the correspondence is shown in application to handwritten character recognition, prototype formation, and object recognition, and is potentially useful in other applications such as registration and tracking.	Brown Univ, Div Engn, Providence, RI 02912 USA; Brown Univ, Dept Comp Sci, Providence, RI 02912 USA	Brown University; Brown University	Sebastian, TB (corresponding author), Brown Univ, Div Engn, Providence, RI 02912 USA.	tbs@ems.brown.edu; klein@cs.brown.edu; kimia@cs.brown.edu						ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1; Bellman R., 1962, APPL DYNAMIC PROGRAM; BELONGIE S, 2001, P INT C COMP VIS ICC, pR1; BELONGIE S, 2000, IEEE WORKSH CONT BAS; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BRIN S, 1995, P 21 INT C VER LARG, P574; COHEN I, 1992, P EUR C COMP VIS, P458; Connell SD, 1998, INT C PATT RECOG, P182, DOI 10.1109/ICPR.1998.711110; Gdalyahu Y, 1999, IEEE T PATTERN ANAL, V21, P1312, DOI 10.1109/34.817410; GUPTA L, 1987, PATTERN RECOGN, V20, P267, DOI 10.1016/0031-3203(87)90001-X; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850; LIU HC, 1990, IEEE T PATTERN ANAL, V12, P1072, DOI 10.1109/34.61706; MAES M, 1990, INFORM PROCESS LETT, V35, P73, DOI 10.1016/0020-0190(90)90109-B; MARZAL A, 1993, IEEE T PATTERN ANAL, V15, P926, DOI 10.1109/34.232078; Milios E, 2000, IEEE T IMAGE PROCESS, V9, P141, DOI 10.1109/83.817606; Rangarajan A, 1997, LECT NOTES COMPUT SC, V1230, P29; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; SCHWARTZ JT, 1987, INT J ROBOT RES, V6, P29, DOI 10.1177/027836498700600203; SEBASTIAN T, 2000, 184 LEMS BROWN U; SEBASTIAN TB, 2002, P 7 EUR C COMP VIS M; Tagare HD, 1997, IEEE T MED IMAGING, V16, P108, DOI 10.1109/42.552060; Tagare HD, 1999, IEEE T MED IMAGING, V18, P570, DOI 10.1109/42.790457; TAPPERT CC, 1982, IBM J RES DEV, V26, P765, DOI 10.1147/rd.266.0765; TSAI WH, 1985, IEEE T PATTERN ANAL, V7, P453, DOI 10.1109/TPAMI.1985.4767684; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/h0026750; UEDA N, 1993, IEEE T PATTERN ANAL, V15, P337, DOI 10.1109/34.206954; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; UMEYAMA S, 1993, IEEE T PATTERN ANAL, V15, P136, DOI 10.1109/34.192485; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; WALLACE TP, 1980, COMPUT VISION GRAPH, V13, P99, DOI 10.1016/S0146-664X(80)80035-9; Wirtz B, 1997, PROC INT CONF DOC, P268, DOI 10.1109/ICDAR.1997.619854; Yianilos P.N., 1993, ACM SIAM S DISCR ALG, P311; Younes L, 1998, SIAM J APPL MATH, V58, P565, DOI 10.1137/S0036139995287685; [No title captured]	39	277	295	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2003	25	1					116	125		10.1109/TPAMI.2003.1159951	http://dx.doi.org/10.1109/TPAMI.2003.1159951			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	628NL					2022-12-18	WOS:000180002300010
J	PANJWANI, DK; HEALEY, G				PANJWANI, DK; HEALEY, G			MARKOV RANDOM-FIELD MODELS FOR UNSUPERVISED SEGMENTATION OF TEXTURED COLOR IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						SEGMENTATION; COLOR; TEXTURE; MARKOV RANDOM FIELDS; MACHINE VISION; COMPUTER VISION; COLOR VISION	SPATIAL-INTERACTION; NEIGHBORS; CHOICE	We present an unsupervised segmentation algorithm which uses Markov random field models for color textures. These models characterize a texture in terms of spatial interaction within each color plane and interaction between different color planes. The models are used by a segmentation algorithm based on agglomerative hierarchical clustering, At the heart of agglomerative clustering is a stepwise optimal merging process that at each iteration maximizes a global performance functional based on the conditional pseudolikelihood of the image. A test for stopping the clustering is applied based on rapid changes in the pseudolikelihood, We provide experimental results that illustrate the advantages of using color texture models and that demonstrate the performance of the segmentation algorithm on color images of natural scenes. Most of the processing during segmentation is local making the algorithm amenable to high performance parallel implementation.	UNIV CALIF IRVINE,DEPT ELECT & COMP ENGN,IRVINE,CA 92717	University of California System; University of California Irvine	PANJWANI, DK (corresponding author), MENTOR GRAPH CORP,8005 SW BOECKMAN RD,WILSONVILLE,OR 97070, USA.							Bajcsy R., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P785, DOI 10.1109/ICPR.1990.118217; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BEULIEU JM, 1989, IEEE T PATTERN ANAL, V11, P150; CHELLAPPA R, 1983, IEEE T ACOUST SPEECH, V31, P836, DOI 10.1109/TASSP.1983.1164145; CHELLAPPA R, 1985, IEEE T SYST MAN CYB, V8, P298; CHEN PC, 1980, COMPUT VISION GRAPH, V12, P153, DOI 10.1016/0146-664X(80)90009-X; COHEN FS, 1992, CVGIP-GRAPH MODEL IM, V54, P239, DOI 10.1016/1049-9652(92)90054-2; Cohen FS., 1986, MODELLING APPL STOCH, P243, DOI 10.1007/978-1-4613-2267-2_10; COOPER DB, 1980, COMPUT GRAPHICS  APR, P326; Daily M. J., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P304, DOI 10.1109/CVPR.1989.37865; Gagalowicz A., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P412; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HEALEY G, 1992, IEEE T SYST MAN CYB, V22, P64, DOI 10.1109/21.141311; HEALEY GE, 1992, PHYSICS BASED VISION; KASHYAP RL, 1981, COMPUT VISION GRAPH, V15, P301, DOI 10.1016/S0146-664X(81)80014-7; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; KLINKER GJ, 1990, INT J COMPUT VISION, V4, P7, DOI 10.1007/BF00137441; LAKSHMANAN S, 1989, IEEE T PATTERN ANAL, V11, P799, DOI 10.1109/34.31443; LARIMORE WE, 1977, P IEEE, V65, P961, DOI 10.1109/PROC.1977.10593; MANJUNATH BS, 1991, IEEE T PATTERN ANAL, V13, P478, DOI 10.1109/34.134046; OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7; PANJWANI D, 1993, THESIS U CALIFORNIA; PANJWANI D, 1994, 1ST P IEEE INT C IM; PAVLIDIS T, 1991, STRUCTURAL PATTERN R; POGGIO T, 1988, SCIENCE, V242, P436, DOI 10.1126/science.3175666; SCHARCANSKI J, 1992, SPIE, V1818, P156; SILVERMAN JF, 1988, IEEE T PATTERN ANAL, V10, P482, DOI 10.1109/34.3912; WOODS JW, 1972, IEEE T INFORM THEORY, V18, P232, DOI 10.1109/TIT.1972.1054786; WRIGHT WA, 1989, IMAGE VISION COMPUT, V7, P144, DOI 10.1016/0262-8856(89)90009-7; YAKIMOVSKY Y, 1976, J ACM, V23, P599, DOI 10.1145/321978.321981	30	276	302	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1995	17	10					939	954		10.1109/34.464559	http://dx.doi.org/10.1109/34.464559			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RX289					2022-12-18	WOS:A1995RX28900002
J	Deisenroth, MP; Fox, D; Rasmussen, CE				Deisenroth, Marc Peter; Fox, Dieter; Rasmussen, Carl Edward			Gaussian Processes for Data-Efficient Learning in Robotics and Control	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Policy search; robotics; control; Gaussian processes; Bayesian inference; reinforcement learning		Autonomous learning has been a promising direction in control and robotics for more than a decade since data-driven learning allows to reduce the amount of engineering knowledge, which is otherwise required. However, autonomous reinforcement learning (RL) approaches typically require many interactions with the system to learn controllers, which is a practical limitation in real systems, such as robots, where many interactions can be impractical and time consuming. To address this problem, current learning approaches typically require task-specific knowledge in form of expert demonstrations, realistic simulators, pre-shaped policies, or specific knowledge about the underlying dynamics. In this paper, we follow a different approach and speed up learning by extracting more information from data. In particular, we learn a probabilistic, non-parametric Gaussian process transition model of the system. By explicitly incorporating model uncertainty into long-term planning and controller learning our approach reduces the effects of model errors, a key problem in model-based learning. Compared to state-of-the art RL our model-based policy search method achieves an unprecedented speed of learning. We demonstrate its applicability to autonomous learning in real robot and control tasks.	[Deisenroth, Marc Peter] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England; [Deisenroth, Marc Peter] Tech Univ Darmstadt, Dept Comp Sci, Darmstadt, Germany; [Fox, Dieter] Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA; [Rasmussen, Carl Edward] Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England	Imperial College London; Technical University of Darmstadt; University of Washington; University of Washington Seattle; University of Cambridge	Deisenroth, MP (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Comp, 180 Queens Gate, London SW7 2AZ, England.			Rasmussen, Carl Edward/0000-0001-8899-7850	EC [270327]; ONR MURI [N00014-09-1-1052]; Intel Labs; Department of Computing, Imperial College London; Engineering and Physical Sciences Research Council [EP/J012300/1] Funding Source: researchfish; EPSRC [EP/J012300/1] Funding Source: UKRI	EC(European CommissionEuropean Commission Joint Research Centre); ONR MURI(MURIOffice of Naval Research); Intel Labs; Department of Computing, Imperial College London; Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The research leading to these results has received funding from the EC's Seventh Framework Programme (FP7/2007-2013) under grant agreement #270327, ONR MURI grant N00014-09-1-1052, Intel Labs, and the Department of Computing, Imperial College London.	ABBEEL P, 2006, P 23 INT C MACH LEAR; Astrom K. J., 2008, ADAPTIVE CONTROL, V2; Atkeson C.G., 1997, P IEEE INT C ROB AUT; Auer P., 2002, J MACHINE LEARNING R, V3, P397, DOI [10.5555/944919.944941, DOI 10.4271/610369]; Bagnell J., 2001, P INT C ROB AUT; Bischoff B., 2013, P EUR C MACH LEARN K; Brochu E., 2009, ABS10122599 CORR; Chaloner K, 1995, STAT SCI, V10, P273, DOI 10.1214/ss/1177009939; COULOM R, 2002, THESIS I NATL POLYTE; Deisenroth M., 2011, P ROB SCI SYST; Deisenroth M.P., 2013, MULTITASK POLICY RES; Deisenroth M.P., 2013, FDN TRENDS ROBOTICS, V2; Deisenroth M. P., 2010, EFFICIENT REINFORCEM; Deisenroth MP, 2009, NEUROCOMPUTING, V72, P1508, DOI 10.1016/j.neucom.2008.12.019; Deisenroth MP, 2011, P P 28 INT C MACH LE; Doya K, 2000, NEURAL COMPUT, V12, P219, DOI 10.1162/089976600300015961; Engel Y., 2003, P INT C MACH LEARN; Englert P., 2013, P IEEE INT C ROB AUT; Fabri S, 1998, AUTOMATICA, V34, P245, DOI 10.1016/S0005-1098(97)00181-7; Feldbaum A.A., 1960, AUTOMAT REM CONTR, V21, P874; Forster D., 2009, ROBOTIC UNICYCLE; Hall J., 2011, P IEEE INT C DEC CON; Jervis T.T., 1992, CUEDFINFENGTR115 U C; Kimura H., 1999, P 16 INT C MACH LEAR; KO J, 2007, P IEEE INT C ROB AUT; Ko J., 2008, P IEEE RSJ INT C INT; Ko J., 2009, P ROB SCI SYST; Kording KP, 2004, P NATL ACAD SCI USA, V101, P9839, DOI 10.1073/pnas.0308394101; Kupcsik A., 2013, P AAAI C ART INT; Lizotte D.J., 2008, THESIS U ALBERTA EDM; MacKay D. J. C., 2003, INFORM THEORY INFERE, P269; McFarlane D. C., 1989, LECT NOTES CONTROL I, V138; McHutchon A., 2011, P ADV NEUR INF PROC; Naveh Y, 1999, DYNAM CONTROL, V9, P279, DOI 10.1023/A:1026481216262; Ng A. Y., 2000, P C UNC ART INT; Ng A.Y., 2008, STANFORD ENG EVERYWH; Ng A. Y., 2004, P ADV NEUR INF PROC; Osborne M.A., 2009, P INT C LEARN INT OP; Peters J., 2006, P IEEE RSJ INT C INT; Peters J, 2008, NEURAL NETWORKS, V21, P682, DOI 10.1016/j.neunet.2008.02.003; Quinonero-Candela J., 2003, P IEEE INT C AC SPEE; Rasmussen C., 2004, P ADV NEUR INF PROC; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Schaal Z., 1997, P ADV NEUR INF PROC; Schneider J.G., 1997, P ADV NEUR INF PROC; Snelson E., 2006, P ADV NEUR INF PROC; Srinivas N, 2010, P INT C MACH LEARN; Sutton Richard S, 1998, INTRO REINFORCEMENT, V2; Turner R., 2010, P INT C ART INT STAT; Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167; Watkins C.J.C.H., 1989, LEARNING DELAYED REW; WAWRZYNSKI P, 2004, P INT JOINT C NEUR N; Wilson A., 2010, P EUR C MACH LEARN K; Wittenmark B, 1995, P IFAC S AD SYST CON	56	275	283	4	62	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2015	37	2					408	423		10.1109/TPAMI.2013.218	http://dx.doi.org/10.1109/TPAMI.2013.218			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VD	26353251	Green Submitted, Green Accepted, hybrid			2022-12-18	WOS:000349625500016
J	Lu, JW; Tan, YP; Wang, G				Lu, Jiwen; Tan, Yap-Peng; Wang, Gang			Discriminative Multimanifold Analysis for Face Recognition from a Single Training Sample per Person	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; manifold learning; subspace learning; single training sample per person	NONLINEAR DIMENSIONALITY REDUCTION; EXPRESSION VARIANT FACES; 2-DIMENSIONAL PCA; IMAGE; REPRESENTATION; FRAMEWORK; HISTOGRAM; PATTERNS; MODEL; FLDA	Conventional appearance-based face recognition methods usually assume that there are multiple samples per person (MSPP) available for discriminative feature extraction during the training phase. In many practical face recognition applications such as law enhancement, e-passport, and ID card identification, this assumption, however, may not hold as there is only a single sample per person (SSPP) enrolled or recorded in these systems. Many popular face recognition methods fail to work well in this scenario because there are not enough samples for discriminant learning. To address this problem, we propose in this paper a novel discriminative multimanifold analysis (DMMA) method by learning discriminative features from image patches. First, we partition each enrolled face image into several nonoverlapping patches to form an image set for each sample per person. Then, we formulate the SSPP face recognition as a manifold-manifold matching problem and learn multiple DMMA feature spaces to maximize the manifold margins of different persons. Finally, we present a reconstruction-based manifold-manifold distance to identify the unlabeled subjects. Experimental results on three widely used face databases are presented to demonstrate the efficacy of the proposed approach.	[Lu, Jiwen] Adv Digital Sci Ctr, Singapore 138632, Singapore; [Tan, Yap-Peng; Wang, Gang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Lu, JW (corresponding author), Adv Digital Sci Ctr, 1 Fusionopolis Way,08-10,Connexis N Tower, Singapore 138632, Singapore.	jiwen.lu@adsc.com.sg; eyptan@ntu.edu.sg; wanggang@ntu.edu.sg	Wang, Gang/B-7027-2013; Tan, Yap-Peng/A-5158-2011; Lu, Jiwen/C-5291-2009	Lu, Jiwen/0000-0002-6121-5529				Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Cai D., 2007, P IEEE INT C COMP VI, P1; Chen HT, 2005, PROC CVPR IEEE, P846; Chen SC, 2004, PATTERN RECOGN LETT, V25, P1173, DOI 10.1016/j.patrec.2004.03.012; Chen SC, 2004, PATTERN RECOGN, V37, P1553, DOI 10.1016/j.patcog.2003.12.010; Deng WH, 2010, PATTERN RECOGN, V43, P1748, DOI 10.1016/j.patcog.2009.12.004; Fu Y, 2008, IEEE T INF FOREN SEC, V3, P91, DOI 10.1109/TIFS.2007.916280; Gao QX, 2008, APPL MATH COMPUT, V205, P726, DOI 10.1016/j.amc.2008.05.019; Geng X, 2005, IEEE T SYST MAN CY B, V35, P1098, DOI 10.1109/TSMCB.2005.850151; Gottumukkal R, 2004, PATTERN RECOGN LETT, V25, P429, DOI 10.1016/j.patrec.2003.11.005; Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009; He XF, 2005, IEEE I CONF COMP VIS, P1208; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Hu HF, 2008, PATTERN RECOGN, V41, P2045, DOI 10.1016/j.patcog.2007.10.029; Jain A.K., 1982, HDB STAT, P835, DOI 10.1016/S0169-7161(82)02042-2; Jebara T., 2009, P 26 ANN INT C MACHI, P441, DOI [10.1145/1553374.1553432, DOI 10.1145/1553374.1553432]; Kanan HR, 2008, PATTERN RECOGN, V41, P3799, DOI 10.1016/j.patcog.2008.05.024; Kim TK, 2005, IEEE T PATTERN ANAL, V27, P318, DOI 10.1109/TPAMI.2005.58; Lanitis A., 2008, IEEE INT C AUT FAC G, P1, DOI DOI 10.1109/AFGR.2008.4813349; Lei Z, 2011, IEEE T IMAGE PROCESS, V20, P247, DOI 10.1109/TIP.2010.2060207; Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277; Lu JW, 2011, IEEE I CONF COMP VIS, P1943, DOI 10.1109/ICCV.2011.6126464; Lu JW, 2010, IEEE T SYST MAN CY B, V40, P958, DOI 10.1109/TSMCB.2009.2032926; Lu JW, 2010, IEEE T INF FOREN SEC, V5, P71, DOI 10.1109/TIFS.2009.2035976; Luo J, 2007, INT CONF ACOUST SPEE, P593; Martinez A. M., 1998, TECHNICAL REPORT; Martinez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Ridder D., 2003, LNCS, P175, DOI DOI 10.1007/3-540-44989-2_40; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Schwartz WR, 2010, LECT NOTES COMPUT SC, V6316, P476, DOI 10.1007/978-3-642-15567-3_35; Si S, 2010, IEEE T KNOWL DATA EN, V22, P929, DOI 10.1109/TKDE.2009.126; Su Y, 2010, PROC CVPR IEEE, P2699, DOI 10.1109/CVPR.2010.5539990; Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013; Tan XY, 2005, IEEE T NEURAL NETWOR, V16, P875, DOI 10.1109/TNN.2005.849817; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vu N.-S., 2011, P INT JOINT C BIOM, P1; Vu NS, 2010, LECT NOTES COMPUT SC, V6311, P313; Wang R., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587719; Wang R., 2009, IEEE C COMP VIS PATT, DOI DOI 10.1109/IWISA.2009.5073030; Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57; Wang XG, 2006, INT J COMPUT VISION, V70, P91, DOI 10.1007/s11263-006-8098-z; Wu JX, 2002, PATTERN RECOGN LETT, V23, P1711, DOI 10.1016/S0167-8655(02)00134-4; Yan SC, 2007, IEEE T INF FOREN SEC, V2, P69, DOI 10.1109/TIFS.2006.890313; Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P212, DOI 10.1109/TIP.2006.884929; Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097; Yang MH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P215; YAO B, 2009, P INT C COMP VIS ICC, P1; Yu WW, 2006, IMAGE VISION COMPUT, V24, P239, DOI 10.1016/j.imavis.2005.11.006; Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956; Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882; Zhang DQ, 2005, NEUROCOMPUTING, V69, P224, DOI 10.1016/j.neucom.2005.06.004; Zhang DQ, 2005, APPL MATH COMPUT, V163, P895, DOI 10.1016/j.amc.2004.04.016; Zhang WC, 2005, IEEE I CONF COMP VIS, P786; Zou J, 2007, IEEE T IMAGE PROCESS, V16, P2617, DOI 10.1109/TIP.2007.904421	60	275	292	7	109	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2013	35	1					39	51		10.1109/TPAMI.2012.70	http://dx.doi.org/10.1109/TPAMI.2012.70			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	037SV	22431525				2022-12-18	WOS:000311127700006
J	Wang, LM; Xiong, YJ; Wang, Z; Qiao, Y; Lin, DH; Tang, XO; Van Gool, L				Wang, Limin; Xiong, Yuanjun; Wang, Zhe; Qiao, Yu; Lin, Dahua; Tang, Xiaoou; Van Gool, Luc			Temporal Segment Networks for Action Recognition in Videos	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action recognition; temporal segment networks; temporal modeling; good practices; ConvNets	REPRESENTATION; VECTOR	We present a general and flexible video-level framework for learning action models in videos. This method, called temporal segment network (TSN), aims to model long-range temporal structure with a new segment-based sampling and aggregation scheme. This unique design enables the TSN framework to efficiently learn action models by using the whole video. The learned models could be easily deployed for action recognition in both trimmed and untrimmed videos with simple average pooling and multi-scale temporal window integration, respectively. We also study a series of good practices for the implementation of the TSN framework given limited training samples. Our approach obtains the state-the-of-art performance on five challenging action recognition benchmarks: HMDB51 (71.0 percent), UCF101 (94.9 percent), THUMOS14 (80.1 percent), ActivityNet v1.2 (89.6 percent), and Kinetics400 (75.7 percent). In addition, using the proposed RGB difference as a simple motion representation, our method can still achieve competitive accuracy on UCF101 (91.0 percent) while running at 340 FPS. Furthermore, based on the proposed TSN framework, we won the video classification track at the ActivityNet challenge 2016 among 24 teams.	[Wang, Limin] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China; [Xiong, Yuanjun] Amazon Web Serv, Seattle, WA 98101 USA; [Wang, Zhe] Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA; [Qiao, Yu] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China; [Lin, Dahua; Tang, Xiaoou] Chinese Univ Hong Kong, Dept Informat Engn, Shatin, Hong Kong, Peoples R China; [Van Gool, Luc] Swiss Fed Inst Technol, Comp Vis Lab, CH-8092 Zurich, Switzerland	Nanjing University; Amazon.com; University of California System; University of California Irvine; Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS; Chinese University of Hong Kong; Swiss Federal Institutes of Technology Domain; ETH Zurich	Wang, LM (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.	lmwang.nju@gmail.com; yuanjx@amazon.com; buptwangzhe2012@gmail.com; yu.qiao@siat.ac.cn; dhlin@ie.cuhk.edu.hk; xtang@ie.cuhk.edu.hk; vangool@vision.ee.ethz.ch	Lin, Dahua/W-6576-2019; Qiao, Yu/ABD-5787-2021; Wang, Limin/AAE-3419-2019	Lin, Dahua/0000-0002-8865-7896; Wang, Limin/0000-0002-3674-7718; Wang, Zhe/0000-0002-1385-9012	National Science Foundation of China [61321491, U1613211]; Collaborative Innovation Center of Novel Software Technology and Industrialization, Shenzhen Research Program [JCYJ20170818164704758, JCYJ20150925163005055]; Big Data Collaboration Research grant from SenseTime Group (CUHK) [TS1610626]; Early Career Scheme of Hong Kong [24204215]; ERC Advanced Grant VarCity	National Science Foundation of China(National Natural Science Foundation of China (NSFC)); Collaborative Innovation Center of Novel Software Technology and Industrialization, Shenzhen Research Program; Big Data Collaboration Research grant from SenseTime Group (CUHK); Early Career Scheme of Hong Kong; ERC Advanced Grant VarCity	This work is supported by the National Science Foundation of China (No. 61321491, No. U1613211), Collaborative Innovation Center of Novel Software Technology and Industrialization, Shenzhen Research Program (JCYJ20170818164704758, JCYJ20150925163005055), the Big Data Collaboration Research grant from SenseTime Group (CUHK Agreement No. TS1610626), the Early Career Scheme of Hong Kong (No. 24204215), and ERC Advanced Grant VarCity. Limin Wang and Yuanjun Xiong equally contribute to this work.	Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Cai ZW, 2014, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2014.83; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Diba A, 2016, EFFICIENT 2 STREAM M; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213; Feichtenhofer Christoph, 2016, NIPS; Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176; Forsyth DA, 2005, FOUND TRENDS COMPUT, V1, P77, DOI 10.1561/0600000005; Gaidon A, 2013, IEEE T PATTERN ANAL, V35, P2782, DOI 10.1109/TPAMI.2013.65; Gong GM, 2013, 2013 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM DESIGN AND ENGINEERING APPLICATIONS (ISDEA), P13, DOI 10.1109/ISDEA.2012.10; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Heilbron Fabian Caba, 2015, IEEE C COMP VIS PATT; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Idrees H, 2017, COMPUT VIS IMAGE UND, V155, P1, DOI 10.1016/j.cviu.2016.10.018; Jain A, 2013, PROC CVPR IEEE, P2571, DOI 10.1109/CVPR.2013.332; Jain M, 2015, PROC CVPR IEEE, P46, DOI 10.1109/CVPR.2015.7298599; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jiang Y.-G., 2014, THUMOS CHALLENGE ACT; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Kay W., 2017, ARXIV PREPRINT ARXIV; Klaser Alexander, 2008, BMVC; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Ni BB, 2015, PROC CVPR IEEE, P3698, DOI 10.1109/CVPR.2015.7298993; Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29; Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013; Pirsiavash H, 2014, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2014.85; Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590; Raptis M, 2012, PROC CVPR IEEE, P1242, DOI 10.1109/CVPR.2012.6247807; Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Shen L, 2016, LECT NOTES COMPUT SC, V9911, P467, DOI 10.1007/978-3-319-46478-7_29; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Soomro K., 2012, ARXIV; Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Szegedy C., 2016, P IEEE C COMP VIS PA, P2818, DOI DOI 10.1109/CVPR.2016.308; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang H, 2013, COLLOID POLYM SCI, V291, P1001, DOI 10.1007/s00396-012-2822-8; Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2; Wang LM, 2018, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2018.00155; Wang LM, 2018, INT J COMPUT VISION, V126, P390, DOI 10.1007/s11263-017-1043-5; Wang LM, 2017, IEEE T IMAGE PROCESS, V26, P2055, DOI 10.1109/TIP.2017.2675339; Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059; Wang LM, 2016, INT J COMPUT VISION, V119, P254, DOI 10.1007/s11263-015-0859-0; Wang LM, 2014, LECT NOTES COMPUT SC, V8693, P565, DOI 10.1007/978-3-319-10602-1_37; Wang LM, 2013, PROC CVPR IEEE, P2674, DOI 10.1109/CVPR.2013.345; Wang LM, 2014, IEEE T IMAGE PROCESS, V23, P810, DOI 10.1109/TIP.2013.2295753; Wang Limin, 2015, ARXIV150702159; Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48; Wu ZX, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P461, DOI 10.1145/2733373.2806222; Xiong YJ, 2015, PROC CVPR IEEE, P1600, DOI 10.1109/CVPR.2015.7298768; Yi Zhu, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P668, DOI 10.1007/978-3-319-46604-0_47; Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22; Zhang BW, 2016, PROC CVPR IEEE, P2718, DOI 10.1109/CVPR.2016.297; Zhang WY, 2013, IEEE I CONF COMP VIS, P2248, DOI 10.1109/ICCV.2013.280; Zhou MM, 2014, INTERNATIONAL CONFERENCE ON EDUCATION AND SOCIAL SCIENCES (INTCESS14), VOLS I AND II, P487; Zhu J, 2013, IEEE I CONF COMP VIS, P3559, DOI 10.1109/ICCV.2013.442; Zhu WJ, 2016, PROC CVPR IEEE, P1991, DOI 10.1109/CVPR.2016.219; Zhu ZY, 2016, INTERSPEECH, P1305, DOI 10.21437/Interspeech.2016-256	79	274	290	13	79	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2019	41	11					2740	2755		10.1109/TPAMI.2018.2868668	http://dx.doi.org/10.1109/TPAMI.2018.2868668			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD2XM	30183621	Green Submitted, Green Accepted			2022-12-18	WOS:000489838200013
J	Wang, J; Liu, ZC; Wu, Y; Yuan, JS				Wang, Jiang; Liu, Zicheng; Wu, Ying; Yuan, Junsong			Learning Actionlet Ensemble for 3D Human Action Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action recognition; Kinect; ensemble method; human pose; human-object interaction		Human action recognition is an important yet challenging task. Human actions usually involve human-object interactions, highly articulated motions, high intra-class variations, and complicated temporal structures. The recently developed commodity depth sensors open up new possibilities of dealing with this problem by providing 3D depth data of the scene. This information not only facilitates a rather powerful human motion capturing technique, but also makes it possible to efficiently model human-object interactions and intra-class variations. In this paper, we propose to characterize the human actions with a novel actionlet ensemble model, which represents the interaction of a subset of human joints. The proposed model is robust to noise, invariant to translational and temporal misalignment, and capable of characterizing both the human motion and the human-object interactions. We evaluate the proposed approach on three challenging action recognition datasets captured by Kinect devices, a multiview action recognition dataset captured with Kinect device, and a dataset captured by a motion capture system. The experimental evaluations show that the proposed approach achieves superior performance to the state-of-the-art algorithms.	[Wang, Jiang; Wu, Ying] Northwestern Univ, Dept EECS, Evanston, IL 60208 USA; [Liu, Zicheng] Microsoft Res, Redmond, WA 98052 USA; [Yuan, Junsong] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore	Northwestern University; Microsoft; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Wang, J (corresponding author), Northwestern Univ, Dept EECS, Evanston, IL 60208 USA.	wangjiangb@gmail.com; zliu@microsoft.com; yingwu@eecs.northwestern.edu; jsyuan@ntu.edu.sg	Wu, Ying/B-7283-2009; Yuan, Junsong/R-4352-2019; Yuan, Junsong/A-5171-2011	Koochak, Atousa/0000-0001-6547-2728	National Science Foundation [IIS-0347877, IIS-0916607]; U.S. Army Research Laboratory; U.S. Army Research Office [ARO W911NF-08-1-0504]; DARPA [FA 8650-11-1-7149]	National Science Foundation(National Science Foundation (NSF)); U.S. Army Research Laboratory(United States Department of DefenseUS Army Research Laboratory (ARL)); U.S. Army Research Office; DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	This work was supported in part by National Science Foundation grant IIS-0347877, IIS-0916607, U.S. Army Research Laboratory and the U.S. Army Research Office under grant ARO W911NF-08-1-0504, and DARPA Award FA 8650-11-1-7149. Part of this work was done when J. Wang is doing an internship at Microsoft Research Redmond.	Agrawal R., 1994, P 20 INT C VER LARG, V1215, P487; Bourdev L., 2009, P CVPR; Campbell L., 1995, P 5 ICCV CAMBR MA US; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Chaudhry R., 2013, P HAU3D13 PORTL OR U; Chen H.S., 2006, P 4 ACM INT WORKSHOP, P171, DOI [10.1145/1178782.1178808, DOI 10.1145/1178782.1178808]; Dai S., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383028; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Desai C., 2012, P 12 ECCV BERL GERM; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Frieman JH, 2008, ANN APPL STAT, V2, P916, DOI 10.1214/07-AOAS148; Han L, 2010, IMAGE VISION COMPUT, V28, P836, DOI 10.1016/j.imavis.2009.08.003; Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Lazebnik S., 2006, P IEEE COMP SOC C CV, V2; Li L., 2011, P 28 ICML BELL WA US; Li W., 2010, P HUM COMM BEH AN WO; Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359; Maji S., 2011, P IEEE C CVPR PROV R; Martens J., 2011, P 28 ICML BELL WA US; Muller M., P 2006 ACM SIGGRAPH, P137; Ning HZ, 2008, LECT NOTES COMPUT SC, V5303, P419, DOI 10.1007/978-3-540-88688-4_31; Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007; Oppenheim AV, 1999, PRENTICE HALL SIGNAL; Raptis M., P 2011 ACM SIGGRAPH, P147; Shotton J., 2011, P CVPR; Sung J., 2012, P IEEE ICRA; Vieira A. W., 2012, P 17 IBER C PATT REC; Wang J., 2012, P IEEE C CVPR PROV R; Wang J., 2012, P ACML; Wang J, 2012, ELECTRON J QUAL THEO, P1; Wu TF, 2004, J MACH LEARN RES, V5, P975; Xia L., P CVPR 2012 HAU3D WO; Yang X., P CVPR 2012 HAU3D WO; Yang X., 2012, P 20 ACM INT C MULT; Yao B., 2010, P IEEE C CVPR SAN FR; Yuan J., 2011, P IEEE C CVPR PROV R; Yun K., P IEEE COMP SOC C CV; Zhu L. L., 2008, P IEEE C CVPR ANCH A	40	274	287	3	67	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2014	36	5					914	927		10.1109/TPAMI.2013.198	http://dx.doi.org/10.1109/TPAMI.2013.198			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AH3VN	26353226				2022-12-18	WOS:000336054200007
J	Kim, KI; Jung, K; Kim, JH				Kim, KI; Jung, K; Kim, JH			Texture-based approach for text detection in images using support vector machines and continuously adaptive mean shift algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						text detection; image indexing; texture analysis; support vector machine; CAMSHIFT	TRACKING	The current paper presents a novel texture-based method for detecting texts in images. A support vector machine (SVM) is used to analyze the textural properties of texts. No external texture feature extraction module is used; rather, the intensities of the raw pixels that make up the textural pattern are fed directly to the SVM, which works well even in high-dimensional spaces. Next, text regions are identified by applying a continuously adaptive mean shift algorithm (CAMSHIFT) to the results of the texture analysis. The combination of CAMSHIFT and SVMs produces both robust and efficient text detection, as time-consuming texture analyses for less relevant pixels are restricted, leaving only a small part of the input image to be texture-analyzed.	Korea Adv Inst Sci & Technol, Dept Comp Sci, Taejon 305701, South Korea; Sungkyunkwan Univ, Inst Informat Commun & Technol, Suwon 440746, Kyunggi Do, South Korea	Korea Advanced Institute of Science & Technology (KAIST); Sungkyunkwan University (SKKU)	Kim, KI (corresponding author), Korea Adv Inst Sci & Technol, Dept Comp Sci, Taejon 305701, South Korea.	kimki@ai.kaist.ac.kr; jungkeechul@naver.com; jkim@ai.kaist.ac.kr	Kim, Jin Hyung/C-1923-2011					Agnihotri L, 1999, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES (CBAIVL'99) - PROCEEDINGS, P109, DOI 10.1109/IVL.1999.781133; Bradski GR, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P214, DOI 10.1109/ACV.1998.732882; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416; Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264137; Duda R.O., 1973, J ROYAL STAT SOC SER; Haykin S., 1999, NEURAL NETWORKS COMP; Idris F, 1997, J VIS COMMUN IMAGE R, V8, P146, DOI 10.1006/jvci.1997.0355; Jain A. K., 1989, FUNDAMENTALS DIGITAL; Jain AK, 1998, PATTERN RECOGN, V31, P2055, DOI 10.1016/S0031-3203(98)00067-3; Jain AK, 1996, PATTERN RECOGN, V29, P743, DOI 10.1016/0031-3203(95)00131-X; Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169; Ki-Young Jeong, 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P319, DOI 10.1109/ICIP.1999.817127; Kim E.Y., 2000, P INT C ADV PATT REC, P412; Kim EY, 2000, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS - 2000 DIGEST OF TECHNICAL PAPERS, P358, DOI 10.1109/ICCE.2000.854683; Kim KI, 1999, ELECTRON LETT, V35, P1935, DOI 10.1049/el:19991317; Kumar V. P., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P96, DOI 10.1109/AFGR.2000.840618; Li HP, 2000, IEEE T IMAGE PROCESS, V9, P147, DOI 10.1109/83.817607; Li HP, 2000, INT C PATT RECOG, P223, DOI 10.1109/ICPR.2000.906053; Lienhart R., 1996, Proceedings ACM Multimedia 96, P11, DOI 10.1145/244130.244137; *MOCA PROJ, PRAKT INF, V4; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Osuna E, 1997, NEURAL NETWORKS FOR SIGNAL PROCESSING VII, P276, DOI 10.1109/NNSP.1997.622408; Scholkopf B, 1997, IEEE T SIGNAL PROCES, V45, P2758, DOI 10.1109/78.650102; SCHOLKOPF B, 1997, THESIS MUNICH; Smith MA, 1997, PROC CVPR IEEE, P775, DOI 10.1109/CVPR.1997.609414; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Wu V, 1999, IEEE T PATTERN ANAL, V21, P1224, DOI 10.1109/34.809116; ZHONG Y, 1995, PATTERN RECOGN, V28, P1523, DOI 10.1016/0031-3203(95)00030-4; Zhong Y, 2000, IEEE T PATTERN ANAL, V22, P385, DOI 10.1109/34.845381	33	274	296	2	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2003	25	12					1631	1639						9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	746UA		Green Accepted			2022-12-18	WOS:000186765000014
J	Ansar, A; Daniilidis, K				Ansar, A; Daniilidis, K			Linear pose estimation from points or lines	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pose estimation; exterior orientation; absolute orientation; camera localization	CLOSED-FORM SOLUTION; ORIENTATION; IMAGES	Estimation of camera pose from an image of n points or lines with known correspondence is a thoroughly studied problem in computer vision. Most solutions are iterative and depend on nonlinear optimization of some geometric constraint, either on the world coordinates or on the projections to the image plane. For real-time applications, we are interested in linear or closed-form solutions free of initialization. We present a general framework which allows for a novel set of linear solutions to the pose estimation problem for both n points and n lines. We then analyze the sensitivity of our solutions to image noise and show that the sensitivity analysis can be used as a conservative predictor of error for our algorithms. We present a number of simulations which compare our results to two other recent linear algorithms, as well as to iterative approaches. We conclude with tests on real imagery in an augmented reality setup.	CALTECH, Jet Prop Lab, Pasadena, CA 91109 USA; Univ Penn, GRASP Lab, Philadelphia, PA 19104 USA	California Institute of Technology; National Aeronautics & Space Administration (NASA); NASA Jet Propulsion Laboratory (JPL); University of Pennsylvania	Ansar, A (corresponding author), CALTECH, Jet Prop Lab, 4800 Oak Grove Dr, Pasadena, CA 91109 USA.			Daniilidis, Kostas/0000-0003-0498-0758				Abdel-Aziz Y., 1971, P S CLOSE RANGE PHOT, P1, DOI [10.14358/PERS.81.2.103, DOI 10.1080/10671188.1967.10616517]; Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355; DEMENTHON DF, 1995, INT J COMPUT VISION, V15, P123, DOI 10.1007/BF01450852; DHOME M, 1989, IEEE T PATTERN ANAL, V11, P1265, DOI 10.1109/34.41365; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Fiore PD, 2001, IEEE T PATTERN ANAL, V23, P140, DOI 10.1109/34.908965; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GANAPATHY S, 1984, P INT C ROBOTICS, P130; Haralick R. M., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P592, DOI 10.1109/CVPR.1991.139759; HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063; HORAUD R, 1989, COMPUT VISION GRAPH, V47, P33, DOI 10.1016/0734-189X(89)90052-2; HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; HUANG TS, 1990, ELSEVIER SCI PUBLICA, V2, P243; KUMAR R, 1994, CVGIP-IMAG UNDERSTAN, V60, P313, DOI 10.1006/ciun.1994.1060; LENZ RK, 1988, IEEE T PATTERN ANAL, V10, P713, DOI 10.1109/34.6781; LIU YC, 1990, IEEE T PATTERN ANAL, V12, P28, DOI 10.1109/34.41381; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199; MAYBANK S, 1993, THEORY RECONSTRUCTIO; Navab N., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P254, DOI 10.1109/CVPR.1993.340981; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Quan L, 1999, IEEE T PATTERN ANAL, V21, P774, DOI 10.1109/34.784291; Stewart G., 1990, MATRIX PERTURBATION; THOMPSON EH, 1966, PHOTOGRAMM REC, V10, P201; Triggs B., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P278, DOI 10.1109/ICCV.1999.791231; YI SK, 1994, MACH VISION APPL, V7, P93, DOI 10.1007/BF01215805	28	274	323	2	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2003	25	5					578	589		10.1109/TPAMI.2003.1195992	http://dx.doi.org/10.1109/TPAMI.2003.1195992			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	669FY		Green Published			2022-12-18	WOS:000182342300004
J	Wu, ZF; Huang, YZ; Wang, L; Wang, XG; Tan, TN				Wu, Zifeng; Huang, Yongzhen; Wang, Liang; Wang, Xiaogang; Tan, Tieniu			A Comprehensive Study on Cross-View Gait Based Human Identification with Deep CNNs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deep learning; CNN; human identification; gait; cross-view	RECOGNITION; PERFORMANCE; PROJECTION	This paper studies an approach to gait based human identification via similarity learning by deep convolutional neural networks (CNNs). With a pretty small group of labeled multi-view human walking videos, we can train deep networks to recognize the most discriminative changes of gait patterns which suggest the change of human identity. To the best of our knowledge, this is the first work based on deep CNNs for gait recognition in the literature. Here, we provide an extensive empirical evaluation in terms of various scenarios, namely, cross-view and cross-walking-condition, with different preprocessing approaches and network architectures. The method is first evaluated on the challenging CASIA-B dataset in terms of cross-view gait recognition. Experimental results show that it outperforms the previous state-of-the-art methods by a significant margin. In particular, our method shows advantages when the cross-view angle is large, i.e., no less than 36 degree. And the average recognition rate can reach 94 percent, much better than the previous best result (less than 65 percent). The method is further evaluated on the OU-ISIR gait dataset to test its generalization ability to larger data. OU-ISIR is currently the largest dataset available in the literature for gait recognition, with 4,007 subjects. On this dataset, the average accuracy of our method under identical view conditions is above 98 percent, and the one for cross-view scenarios is above 91 percent. Finally, the method also performs the best on the USF gait dataset, whose gait sequences are imaged in a real outdoor scene. These results show great potential of this method for practical applications.	[Wu, Zifeng] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [Huang, Yongzhen; Wang, Liang; Tan, Tieniu] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Ctr Res Intelligent Percept & Comp, Beijing 100190, Peoples R China; [Wang, Xiaogang] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; Institute of Automation, CAS; Chinese University of Hong Kong	Wu, ZF (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.	zifeng.wu@adelaide.edu.au; yzhuang@nlpr.ia.ac.cn; wangliang@nlpr.ia.ac.cn; xgwang@ee.cuhk.edu.hk; tnt@nlpr.ia.ac.cn			National Basic Research Program of China [2012CB316300]; National Natural Science Foundation of China [61525306, 61420106015]	National Basic Research Program of China(National Basic Research Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work is jointly supported by National Basic Research Program of China (2012CB316300), National Natural Science Foundation of China (61525306, 61420106015). Y. Huang and T. Tan are the corresponding authors of this paper.	[Anonymous], 2014, 1 INT WORKSH ACT REC; Ariyanto G., 2011, 2011 INT JOINT C BIO, P1, DOI [DOI 10.1109/IJCB.2011.6117582, 10.1109/IJCB.2011.6117582]; Bashir K., 2009, 3 INT C IMAGING CRIM, P1, DOI DOI 10.1049/IC.2009.0230; Bialkowski A, 2012, 2012 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING TECHNIQUES AND APPLICATIONS (DICTA); Bissacco A, 2009, INT J COMPUT VISION, V85, P101, DOI 10.1007/s11263-009-0248-7; Bodor R, 2009, IMAGE VISION COMPUT, V27, P1194, DOI 10.1016/j.imavis.2008.11.008; Bouchrika I, 2011, J FORENSIC SCI, V56, P882, DOI 10.1111/j.1556-4029.2011.01793.x; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Farhadi A, 2008, LECT NOTES COMPUT SC, V5302, P154, DOI 10.1007/978-3-540-88682-2_13; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Goffredo M, 2010, IEEE T SYST MAN CY B, V40, P997, DOI 10.1109/TSMCB.2009.2031091; Grushin A, 2013, IEEE IJCNN; Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38; He ZF, 2009, IEEE T PATTERN ANAL, V31, P1670, DOI 10.1109/TPAMI.2008.183; Hinton GE, 2012, IMPROVING NEURAL NET, DOI DOI 10.9774/GLEAF.978-1-909493-38-4_2; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hu HF, 2013, IEEE T CIRC SYST VID, V23, P1274, DOI 10.1109/TCSVT.2013.2242640; Hu MD, 2013, IEEE T INF FOREN SEC, V8, P2034, DOI 10.1109/TIFS.2013.2287605; Huang G.B., 2008, WORKSH FAC REAL LIF; Iwama H, 2012, IEEE T INF FOREN SEC, V7, P1511, DOI 10.1109/TIFS.2012.2204253; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kusakunniran Worapan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1058, DOI 10.1109/ICCVW.2009.5457587; Kusakunniran W, 2014, IEEE T IMAGE PROCESS, V23, P696, DOI 10.1109/TIP.2013.2294552; Kusakunniran W, 2013, IEEE T INF FOREN SEC, V8, P1642, DOI 10.1109/TIFS.2013.2252342; Kusakunniran W, 2012, IEEE T CIRC SYST VID, V22, P966, DOI 10.1109/TCSVT.2012.2186744; Kusakunniran W, 2010, PROC CVPR IEEE, P974, DOI 10.1109/CVPR.2010.5540113; Lai ZH, 2014, IEEE T CIRC SYST VID, V24, P1651, DOI 10.1109/TCSVT.2014.2305495; Lam THW, 2011, PATTERN RECOGN, V44, P973, DOI 10.1016/j.patcog.2010.10.011; Larsen PK, 2008, J FORENSIC SCI, V53, P1149, DOI 10.1111/j.1556-4029.2008.00807.x; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; LeCun Y., 1989, ADV NEURAL INFORM PR, V2; LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907; Liu F, 2015, NEUROCOMPUTING, V168, P599, DOI 10.1016/j.neucom.2015.05.065; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12; Martin-Felez R, 2014, PATTERN RECOGN, V47, P3793, DOI 10.1016/j.patcog.2014.06.010; Nair V, 2010, P 27 INT C MACHINE L, P807; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Sermanet P., 2013, ARXIV PREPRINT ARXIV; Shi XS, 2014, PATTERN RECOGN, V47, P2447, DOI 10.1016/j.patcog.2014.01.007; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Sun Y, 2013, IEEE I CONF COMP VIS, P1489, DOI 10.1109/ICCV.2013.188; Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; Veeriah V., 2015, ARXIV150406678; Wang C, 2010, LECT NOTES COMPUT SC, V6311, P257, DOI 10.1007/978-3-642-15549-9_19; WANG H, 2013, INT C COMP VIS, DOI DOI 10.1109/ICCV.2013.441; Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013; Wu ZF, 2014, INT C PATT RECOG, P1538, DOI 10.1109/ICPR.2014.273; Yang B., 2015, ARXIV150407339; Yu SQ, 2006, INT C PATT RECOG, P441; Zhao GY, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P529	58	273	302	11	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	2					209	226		10.1109/TPAMI.2016.2545669	http://dx.doi.org/10.1109/TPAMI.2016.2545669			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8HZ	27019478				2022-12-18	WOS:000395553400001
J	Pereira, JC; Coviello, E; Doyle, G; Rasiwasia, N; Lanckriet, GRG; Levy, R; Vasconcelos, N				Costa Pereira, Jose; Coviello, Emanuele; Doyle, Gabriel; Rasiwasia, Nikhil; Lanckriet, Gert R. G.; Levy, Roger; Vasconcelos, Nuno			On the Role of Correlation and Abstraction in Cross-Modal Multimedia Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multimedia; content-based retrieval; multimodal; cross-modal; image and text; retrieval model; semantic spaces; kernel correlation; logistic regression	KNOWLEDGE DISCOVERY; IMAGE RETRIEVAL; MEDIA; ANNOTATION	The problem of cross-modal retrieval from multimedia repositories is considered. This problem addresses the design of retrieval systems that support queries across content modalities, for example, using an image to search for texts. A mathematical formulation is proposed, equating the design of cross-modal retrieval systems to that of isomorphic feature spaces for different content modalities. Two hypotheses are then investigated regarding the fundamental attributes of these spaces. The first is that low-level cross-modal correlations should be accounted for. The second is that the space should enable semantic abstraction. Three new solutions to the cross-modal retrieval problem are then derived from these hypotheses: correlation matching (CM), an unsupervised method which models cross-modal correlations, semantic matching (SM), a supervised technique that relies on semantic representation, and semantic correlation matching (SCM), which combines both. An extensive evaluation of retrieval performance is conducted to test the validity of the hypotheses. All approaches are shown successful for text retrieval in response to image queries and vice versa. It is concluded that both hypotheses hold, in a complementary form, although evidence in favor of the abstraction hypothesis is stronger than that for correlation.	[Doyle, Gabriel; Levy, Roger] Univ Calif San Diego, Dept Linguist, La Jolla, CA 92093 USA; [Doyle, Gabriel; Levy, Roger] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA; [Rasiwasia, Nikhil] Yahoo Labs, Bangalore 560037, Karnataka, India	University of California System; University of California San Diego; University of California System; University of California San Diego	Pereira, JC (corresponding author), Univ Calif San Diego, Dept Elect & Comp Engn, EBU 1, Room 5101,Mail Code 0409,9500 Gilman Dr, La Jolla, CA 92093 USA.	josecp@ucsd.edu; ecoviell@ucsd.edu; gdoyle@ucsd.edu; nikhil.rasiwasia@gmail.com; gert@ece.ucsd.edu; rlevy@ucsd.edu; nuno@ece.ucsd.edu		Vasconcelos, Nuno/0000-0002-9024-4302; Costa Pereira, Jose/0000-0003-1117-3671	FCT [SFRH/BD/40963/2007]; US National Science Foundation [CCF-0830535]	FCT(Portuguese Foundation for Science and TechnologyEuropean Commission); US National Science Foundation(National Science Foundation (NSF))	This work was funded by FCT graduate Fellowship SFRH/BD/40963/2007 and US National Science Foundation grant CCF-0830535. The authors would like to thank Malcolm Slaney for helpful discussions.	Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Barnard K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P408, DOI 10.1109/ICCV.2001.937654; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Boughorbel S, 2005, IEEE IMAGE PROC, P2629; Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Denoyer L, 2004, INFORM PROCESS MANAG, V40, P807, DOI 10.1016/j.ipm.2004.04.009; Doyle G., 2009, P 26 ANN INT C MACH, P281, DOI [DOI 10.1145/1553374.1553410, 10. 1145/1553374. 1553410]; Eck D., 2008, ADV NEURAL INFORM PR, P385; Escalante H. J., 2008, PROC ACM INT C MULTI, P172; Feng SL, 2004, PROC CVPR IEEE, P1002; Fisher JW, 2001, ADV NEUR IN, V13, P772; Frankel C., 1996, TECHNICAL REPORT; Griffin G., 2006, TECHNICAL REPORT; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Hsu W, 2009, IEEE INT CON MULTI, P1448, DOI 10.1109/ICME.2009.5202775; Huang T, 2011, P 20 INT C WORLD WID, P297, DOI DOI 10.1145/1963405.1963449; Iria J., 2009, P ACM INT C IM VID R, P1; Jeon J., 2003, P 26 ANN INT ACM SIG, P119, DOI [DOI 10.1145/860435.860459, 10.1145/860435.860459]; Jolliffe IT, 2002, ENCY STATIST BEHAV S, DOI [10.1007/0-387-22440-8_13, 10.1007/b98835]; Khan I., 2009, P 33 WORKSH AUSTR AS; Kliegr T., 2008, P 9 INT WORKSH MULT, P8; Lavrenko V., 2004, P ADV NEUR INF PROC, V16; Li D., 2003, P 11 ACM INT C MULTI, P604, DOI DOI 10.1145/957013.957143; Li W., 1997, P ACM S APPL COMP, P136; LOGAN B, 2001, P IEEE INT C MULT EX, P745; Mahadevan V., 2011, ADV NEURAL INFORM PR, P918; Manning C.D., 2008, INTRO INFORM RETRIEV; Meadow C. T., 2007, TEXT INFORM RETRIEVA; Mei T, 2010, IEEE MULTIMEDIA, V17, P16, DOI 10.1109/MMUL.2010.82; Monay F, 2007, IEEE T PATTERN ANAL, V29, P1802, DOI 10.1109/TPAMI.2007.1097; Mori Y., 2000, P RECH INF ASS ORD; Nakamura S, 2002, IEEE T NEURAL NETWOR, V13, P854, DOI 10.1109/TNN.2002.1021886; Paramita ML, 2010, LECT NOTES COMPUT SC, V6242, P45, DOI 10.1007/978-3-642-15751-6_6; Pereira JC, 2012, PROC CVPR IEEE, P3093, DOI 10.1109/CVPR.2012.6248041; Pham T.-T., 2007, P 16 ACM C C INF KNO, P439; Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.1002/ACP.3140; Rasiwasia N, 2010, ACM MM, DOI DOI 10.1145/1873951.1873987; Rasiwasia N, 2007, IEEE T MULTIMEDIA, V9, P923, DOI 10.1109/TMM.2007.900138; Saberian MJ, 2011, ADV NEURAL INFORM PR, P2124; Salton G., 1971, SMART RETRIEVAL SYST; Salton G., 1983, INTRO MODERN INFORM; Sclaroff S, 1999, COMPUT VIS IMAGE UND, V75, P86, DOI 10.1006/cviu.1999.0765; Slaney M, 2002, INT CONF ACOUST SPEE, P4108; Smeaton A.F., 2006, MIR 2006 P 8 ACM INT, P321, DOI DOI 10.1145/1178677.1178722; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tsikrika T, 2009, LECT NOTES COMPUT SC, V5706, P539, DOI 10.1007/978-3-642-04447-2_66; Turnbull D, 2008, IEEE T AUDIO SPEECH, V16, P467, DOI 10.1109/TASL.2007.913750; Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560; Vasconcelos N, 2004, IEEE T SIGNAL PROCES, V52, P2322, DOI 10.1109/TSP.2004.831125; Vasconcelos N, 2007, COMPUTER, V40, P20, DOI 10.1109/MC.2007.239; Vinokourov A., 2003, P 4 INT S IND COMP A; Vinokourov A., 2003, ADV NEURAL INFORM PR, P1497; Wang G, 2009, PROC CVPR IEEE, P1367, DOI 10.1109/CVPRW.2009.5206816; WANG JZ, 2002, P 10 ACM INT C MULT, P436; Westerveld T., 2000, CONTENT BASED MULTIM, P276; Yang Y., 2009, P 17 ACM INT C MULTI, V17, P175, DOI DOI 10.1145/1631272.1631298; Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359; Zhang H., 2007, PROC 15 ACM INT C MU, P273; Zhuang YT, 2008, IEEE T MULTIMEDIA, V10, P221, DOI 10.1109/TMM.2007.911822; Zhuang YT, 2007, J VLSI SIG PROC SYST, V46, P153, DOI 10.1007/s11265-006-0020-y	68	273	288	4	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2014	36	3					521	535		10.1109/TPAMI.2013.142	http://dx.doi.org/10.1109/TPAMI.2013.142			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AA9YX	24457508	Green Submitted			2022-12-18	WOS:000331450100010
J	Zhu, ML; Martinez, AM				Zhu, Manli; Martinez, Aleix M.			Subclass discriminant analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						feature extraction; discriminant analysis; pattern recognition; classification; eigenvalue decomposition; stability criterion; mixture of Gaussians	FEATURE-EXTRACTION; RECOGNITION; LDA; REDUCTION	Over the years, many Discriminant Analysis ( DA) algorithms have been proposed for the study of high- dimensional data in a large variety of problems. Each of these algorithms is tuned to a specific type of data distribution ( that which best models the problem at hand). Unfortunately, in most problems the form of each class pdf is a priori unknown, and the selection of the DA algorithm that best fits our data is done over trial- and- error. Ideally, one would like to have a single formulation which can be used for most distribution types. This can be achieved by approximating the underlying distribution of each class with a mixture of Gaussians. In this approach, the major problem to be addressed is that of determining the optimal number of Gaussians per class, i. e., the number of subclasses. In this paper, two criteria able to find the most convenient division of each class into a set of subclasses are derived. Extensive experimental results are shown using five databases. Comparisons are given against Linear Discriminant Analysis ( LDA), Direct LDA ( DLDA), Heteroscedastic LDA ( HLDA), Nonparametric DA ( NDA), and Kernel- Based LDA ( K- LDA). We show that our method is always the best or comparable to the best.	Ohio State Univ, Dept Elect & Comp Engn, Dreese Lab 205, Columbus, OH 43210 USA	University System of Ohio; Ohio State University	Zhu, ML (corresponding author), Ohio State Univ, Dept Elect & Comp Engn, Dreese Lab 205, 2015 Neil Ave, Columbus, OH 43210 USA.	zhum@ece.osu.edu; aleix@ece.osu.edu	Martinez, Aleix M/A-2380-2008		NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERS [R01DC005241] Funding Source: NIH RePORTER; NIDCD NIH HHS [R01 DC 005241] Funding Source: Medline	NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Deafness & Other Communication Disorders (NIDCD)); NIDCD NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Deafness & Other Communication Disorders (NIDCD))		Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; DELATORRE F, 2004, P BRIT MACH VIS C SE; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724; Fisher RA, 1938, ANN EUGENIC, V8, P376, DOI 10.1111/j.1469-1809.1938.tb02189.x; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Hastie T, 1996, J ROY STAT SOC B MET, V58, P155; HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989; HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; KOONTZ WLG, 1972, IEEE T COMPUT, VC 21, P171, DOI 10.1109/TC.1972.5008922; Leibe B., 2003, P IEEE C COMP VIS PA; Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13; Loog M, 2001, IEEE T PATTERN ANAL, V23, P762, DOI 10.1109/34.935849; MACLANCHLAN GJ, 1988, MIXTURE MODELS INFER; Martinez AM, 2005, IEEE T PATTERN ANAL, V27, P1934, DOI 10.1109/TPAMI.2005.250; Martinez AM, 2001, IEEE T SYST MAN CY B, V31, P669, DOI 10.1109/3477.956029; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; MCLANCHLAN GJ, 2004, DISCRIMINANT ANAL ST; Newman C. B. D., 1998, UCI REPOSITORY MACHI; Rao CR, 2002, LINEAR STAT INFERENC; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; Yang J, 2005, IEEE T PATTERN ANAL, V27, P230, DOI 10.1109/TPAMI.2005.33; Yang MH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P215; Yang MH, 2001, COMPUT VIS IMAGE UND, V84, P264, DOI 10.1006/cviu.2001.0937; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X; Zhou SK, 2004, INT C PATT RECOG, P191, DOI 10.1109/ICPR.2004.1333736; ZHU M, 2003, P IEEE WORKSH COMP V; ZHU M, 2004, P IEEE WORKSH LEARN	31	273	284	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2006	28	8					1274	1286		10.1109/TPAMI.2006.172	http://dx.doi.org/10.1109/TPAMI.2006.172			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	051LK	16886863				2022-12-18	WOS:000238162400009
J	Li, ZC; Liu, J; Tang, JH; Lu, HQ				Li, Zechao; Liu, Jing; Tang, Jinhui; Lu, Hanqing			Robust Structured Subspace Learning for Data Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Data representation; latent subspace; image understanding; feature learning; structure preserving	IMAGE ANNOTATION; DIMENSIONALITY REDUCTION; FRAMEWORK; WEB; CLASSIFICATION	To uncover an appropriate latent subspace for data representation, in this paper we propose a novel Robust Structured Subspace Learning (RSSL) algorithm by integrating image understanding and feature learning into a joint learning framework. The learned subspace is adopted as an intermediate space to reduce the semantic gap between the low-level visual features and the high-level semantics. To guarantee the subspace to be compact and discriminative, the intrinsic geometric structure of data, and the local and global structural consistencies over labels are exploited simultaneously in the proposed algorithm. Besides, we adopt the l(2,1)-norm for the formulations of loss function and regularization respectively to make our algorithm robust to the outliers and noise. An efficient algorithm is designed to solve the proposed optimization problem. It is noted that the proposed framework is a general one which can leverage several well-known algorithms as special cases and elucidate their intrinsic relationships. To validate the effectiveness of the proposed method, extensive experiments are conducted on diversity datasets for different image understanding tasks, i.e., image tagging, clustering, and classification, and the more encouraging results are achieved compared with some state-of-the-art approaches.	[Li, Zechao; Tang, Jinhui] Nanjing Univ Sci & Technol, Sch Engn & Comp Sci, Nanjing 210094, Jiangsu, Peoples R China; [Liu, Jing; Lu, Hanqing] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China	Nanjing University of Science & Technology; Chinese Academy of Sciences; Institute of Automation, CAS	Liu, J (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China.	zechao.li@njust.edu.cn; jliu@nlpr.ia.ac.cn; jinhuitang@njust.edu.cn; luhq@nlpr.ia.ac.cn			973 Program [2014CB347600]; National Natural Science Foundation of China [61402228, 61472422, 61332016, 61103059]; Natural Science Fund for Distinguished Young Scholars of Jiangsu Province [BK2012033]; National Laboratory of Pattern Recognition	973 Program(National Basic Research Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Fund for Distinguished Young Scholars of Jiangsu Province; National Laboratory of Pattern Recognition	This work was partially supported by the 973 Program (Project No. 2014CB347600), the National Natural Science Foundation of China (Grant No. 61402228, 61472422, 61332016, 61103059), Natural Science Fund for Distinguished Young Scholars of Jiangsu Province under Grant BK2012033 and the Open Projects Program of National Laboratory of Pattern Recognition. Jing Liu is the corresponding author.	Ando RK, 2005, J MACH LEARN RES, V6, P1817; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Cai D., 2010, P ACM SIGKDD INT C K, P333, DOI 10.1145/1835804.1835848; Cai D., 2007, IEEE C COMP VIS ICCV, P1, DOI DOI 10.1109/ICCV.2007.4408856; Cai D, 2007, IEEE DATA MINING, P73, DOI 10.1109/ICDM.2007.89; Chen WY, 2011, IEEE T PATTERN ANAL, V33, P568, DOI 10.1109/TPAMI.2010.88; Cheng QA, 2011, IEEE T PATTERN ANAL, V33, P1217, DOI 10.1109/TPAMI.2010.195; Chua Tat-Seng, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646452; Chung F.R.K., 1997, CBMS REGIONAL C SERI, V92; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; Duda R. O., 2001, PATTERN CLASSIFICATI; Gourier N., 2004, PROC ICPR INT WORKSH, P1; He X, 2005, ADV NEURAL INFORM PR; He XF, 2005, IEEE I CONF COMP VIS, P1208; He XF, 2004, ADV NEUR IN, V16, P153; Higham N. J., 2002, ACCURACY STABILITY N; Huiskes Mark J, 2008, P 1 ACM INT C MULTIM, P39, DOI DOI 10.1145/1460096.1460104; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Kuhn H., 1951, P 2 BERK S MATH STAT, P481, DOI DOI 10.1007/BF01582292; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Li Z., 2012, PROC NATL CONF ARTIF, V2, P1026; Li ZC, 2014, IEEE T KNOWL DATA EN, V26, P2138, DOI 10.1109/TKDE.2013.65; Li ZC, 2014, COMPUT VIS IMAGE UND, V124, P71, DOI 10.1016/j.cviu.2014.02.001; Li Zheng, 2010, Proceedings of the SICE 2010 - 49th Annual Conference of the Society of Instrument and Control Engineers of Japan, P1187, DOI 10.1145/1873951.1874183; Liu J, 2009, PATTERN RECOGN, V42, P218, DOI 10.1016/j.patcog.2008.04.012; Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413; Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1021, DOI 10.1109/TMM.2012.2187179; Nie F., 2010, ADV NEURAL INFORM PR, V1, P1813, DOI DOI 10.1007/978-3-319-10690-8_12; Qi GJ, 2012, IEEE T PATTERN ANAL, V34, P850, DOI 10.1109/TPAMI.2011.191; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Sun LA, 2011, IEEE T PATTERN ANAL, V33, P194, DOI 10.1109/TPAMI.2010.160; Tang J., 2011, ACM T INTEL SYST TEC, P14, DOI [10.1145/1899412.1899418, DOI 10.1145/1899412.1899418]; Tang JH, 2010, IEEE T MULTIMEDIA, V12, P131, DOI 10.1109/TMM.2009.2037373; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Xiang SM, 2010, IEEE T PATTERN ANAL, V32, P2039, DOI 10.1109/TPAMI.2010.35; Yang Y., 2011, P 22 INT JOINT C ART, P1589, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-267; Yang Y, 2012, IEEE T IMAGE PROCESS, V21, P1339, DOI 10.1109/TIP.2011.2169269; Yu L., 2010, ACM T KNOWL DISCOV D, V4, P1817; Zeng H, 2011, IEEE T PATTERN ANAL, V33, P1532, DOI 10.1109/TPAMI.2010.215; Zheng Z., 2007, P 24 INT C MACH LEAR, P1151, DOI DOI 10.1145/1273496.1273641; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	45	272	284	3	119	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2015	37	10					2085	2098		10.1109/TPAMI.2015.2400461	http://dx.doi.org/10.1109/TPAMI.2015.2400461			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CQ7VL	26353186				2022-12-18	WOS:000360813400011
J	Zhao, QB; Zhang, LQ; Cichocki, A				Zhao, Qibin; Zhang, Liqing; Cichocki, Andrzej			Bayesian CP Factorization of Incomplete Tensors with Automatic Rank Determination	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Tensor factorizations; tensor completion; rank determination; Bayesian inference; image synthesis; inpainting	CANONICAL POLYADIC DECOMPOSITION; COMPLETION; ALGORITHMS	CANDECOMP/PARAFAC (CP) tensor factorization of incomplete data is a powerful technique for tensor completion through explicitly capturing the multilinear latent factors. The existing CP algorithms require the tensor rank to be manually specified, however, the determination of tensor rank remains a challenging problem especially for CP rank. In addition, existing approaches do not take into account uncertainty information of latent factors, as well as missing entries. To address these issues, we formulate CP factorization using a hierarchical probabilistic model and employ a fully Bayesian treatment by incorporating a sparsity-inducing prior over multiple latent factors and the appropriate hyperpriors over all hyperparameters, resulting in automatic rank determination. To learn the model, we develop an efficient deterministic Bayesian inference algorithm, which scales linearly with data size. Our method is characterized as a tuning parameter-free approach, which can effectively infer underlying multilinear factors with a low-rank constraint, while also providing predictive distributions over missing entries. Extensive simulations on synthetic data illustrate the intrinsic capability of our method to recover the ground-truth of CP rank and prevent the overfitting problem, even when a large amount of entries are missing. Moreover, the results from real-world applications, including image inpainting and facial image synthesis, demonstrate that our method outperforms state-of-the-art approaches for both tensor factorization and tensor completion in terms of predictive performance.	[Zhao, Qibin; Cichocki, Andrzej] RIKEN Brain Sci Inst, Lab Adv Brain Signal Proc, Wako, Saitama, Japan; [Zhao, Qibin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China; [Zhang, Liqing] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Key Lab Shanghai Educ Commiss Intelligent Interac, Shanghai 200030, Peoples R China; [Cichocki, Andrzej] Polish Acad Sci, Syst Res Inst, PL-01447 Warsaw, Poland	RIKEN; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Polish Academy of Sciences; Systems Research Institute of the Polish Academy of Sciences	Zhao, QB (corresponding author), RIKEN Brain Sci Inst, Lab Adv Brain Signal Proc, Wako, Saitama, Japan.	qbzhao@brain.riken.jp; zhang-lq@cs.sjtu.edu.cn; a.cichocki@riken.jp	Cichocki, Andrzej/AAI-4209-2020; Zhao, Qibin/D-1689-2014; Cichocki, Andrzej/A-1545-2015	Cichocki, Andrzej/0000-0002-8364-7226	National Natural Science Foundation of China [61202155, 61272251, 91120305]; National Basic Research Program of China [2015CB856004]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China(National Basic Research Program of China)	This work was partially supported by the National Natural Science Foundation of China (Grant No. 61202155). The work of Liqing Zhang was partially supported by the National Natural Science Foundation of China (Grant Nos 61272251, 91120305) and the National Basic Research Program of China (Grant No 2015CB856004). Q. Zhao is the corresponding author.	Acar E, 2011, CHEMOMETR INTELL LAB, V106, P41, DOI 10.1016/j.chemolab.2010.08.004; Alexeev B, 2011, ANN IEEE CONF COMPUT, P283, DOI 10.1109/CCC.2011.28; Allman ES, 2013, SIAM J MATRIX ANAL A, V34, P1014, DOI 10.1137/120899066; Phan AH, 2013, INT CONF ACOUST SPEE, P3233, DOI 10.1109/ICASSP.2013.6638255; [Anonymous], 2008, P 25 INT C MACH LEAR; Babacan SD, 2012, IEEE T SIGNAL PROCES, V60, P3964, DOI 10.1109/TSP.2012.2197748; Bishop CM, 1999, ADV NEUR IN, V11, P382; Bro R, 1997, CHEMOMETR INTELL LAB, V38, P149, DOI 10.1016/S0169-7439(97)00032-4; Burgisser P, 2011, ACM S THEORY COMPUT, P509; Chen YL, 2014, IEEE T PATTERN ANAL, V36, P577, DOI 10.1109/TPAMI.2013.164; Chu W., 2009, PROC 12 INT C ARTIF, V5, P89; Cichocki Andrzej, 2009, NONNEGATIVE MATRIX T, P2; de Silva V, 2008, SIAM J MATRIX ANAL A, V30, P1084, DOI 10.1137/06066518X; Gandy S, 2011, INVERSE PROBL, V27, DOI 10.1088/0266-5611/27/2/025010; Harshman R.A., 1970, MULTIMODAL FACTOR AN; HASTAD J, 1990, J ALGORITHMS, V11, P644, DOI 10.1016/0196-6774(90)90014-6; Hayashi K., 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P216, DOI 10.1109/ICDM.2010.39; Huang JZ, 2011, COMPUT VIS IMAGE UND, V115, P1610, DOI 10.1016/j.cviu.2011.06.011; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Kressner D, 2014, BIT, V54, P447, DOI 10.1007/s10543-013-0455-z; Lakshminarayanan B., 2011, P 14 INT C ART INT S, P425; Lawrence N.D., 2009, P 26 ANN INT C MACHI, P601, DOI DOI 10.1145/1553374.1553452; Lim Y.J., 2007, P KDD CUP WORKSHOP, V7, P15; Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39; Mackay D. J. C., 1994, MODELS NEURAL NETWOR, P211, DOI DOI 10.1007/978-1-4612-0723-8_6; Narita A, 2012, DATA MIN KNOWL DISC, V25, P298, DOI 10.1007/s10618-012-0280-z; Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58; Salakhutdinov R., 2007, ADV NEURAL INF PROCE, V20, P1257; Sheng G., 2012, J CHINA U POSTS TELE, V19, P172; Signoretto M., 2013, MACH LEARN, P1; Sorber L., 2013, TENSORLAB V1 0; Sorber L, 2013, SIAM J OPTIMIZ, V23, P695, DOI 10.1137/120868323; Sorensen M, 2012, SIAM J MATRIX ANAL A, V33, P1190, DOI 10.1137/110830034; Tan HC, 2014, NEUROCOMPUTING, V133, P161, DOI 10.1016/j.neucom.2013.11.020; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464; Winn J, 2005, J MACH LEARN RES, V6, P661; Xiong Liang, 2010, P SIAM DAT MIN, V2010; Xu D, 2008, IEEE T CIRC SYST VID, V18, P36, DOI 10.1109/TCSVT.2007.903317; Xu D, 2009, IEEE T IMAGE PROCESS, V18, P1671, DOI 10.1109/TIP.2009.2018015; Xu D, 2009, IEEE T PATTERN ANAL, V31, P1913, DOI 10.1109/TPAMI.2009.51; Xu Zenglin, 2012, ICML; Zhong GQ, 2014, NEURAL COMPUT, V26, P761, DOI 10.1162/NECO_a_00570	44	272	278	10	79	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2015	37	9					1751	1763		10.1109/TPAMI.2015.2392756	http://dx.doi.org/10.1109/TPAMI.2015.2392756			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CO5RQ	26353124	Green Submitted			2022-12-18	WOS:000359216600002
J	Lin, ZC; Shum, HY				Lin, ZC; Shum, HY			Fundamental limits of reconstruction-based superresolution algorithms under local translation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						superresolution; reconstruction-based algorithms; conditioning analysis; fundamental limits; magnification factor	IMAGE; RESOLUTION	Superresolution is a technique that can produce images of a higher resolution than that of the originally captured ones. Nevertheless, improvement in resolution using such a technique is very limited in practice. This makes it significant to study the problem: "Do fundamental limits exist for superresolution?" In this paper, we focus on a major class of superresolution algorithms, called the reconstruction-based algorithms, which compute high-resolution images by simulating the image formation process. Assuming local translation among low-resolution images, this paper is the first attempt to determine the explicit limits of reconstruction-based algorithms, under both real and synthetic conditions. Based on the perturbation theory of linear systems, we obtain the superresolution limits from the conditioning analysis of the coefficient matrix. Moreover, we determine the number of low-resolution images that are sufficient to achieve the limit. Both real and synthetic experiments are carried out to verify our analysis.	Microsoft Res Asia, Beijing 100080, Peoples R China	Microsoft; Microsoft Research Asia	Lin, ZC (corresponding author), Microsoft Res Asia, Sigma Bldg,Zhichun Rd 49,Haidian Dist, Beijing 100080, Peoples R China.	zhoulin@microsoft.com; hshum@microsoft.com						Baker S, 2000, PROC CVPR IEEE, P372, DOI 10.1109/CVPR.2000.854852; Baker S, 1999, CMURITR9932; BARBE DF, 1980, CHARGE COUPLED DEVIC; BASCLE B, 1996, P EUR C COMP VIS, P573; Borman S., 1998, SPATIAL RESOLUTION E; BOSE NK, 1993, P IEEE INT C AC SPEE, V5, P269; Cheeseman P., 1994, FIA9412 NASA; Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118; FORBES K, 1994, J OPT SOC AM A, V11, P1727, DOI 10.1364/JOSAA.11.001727; Freeman W. T., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1182, DOI 10.1109/ICCV.1999.790414; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116; Higham N.J., 1994, P S APPL MATH, V48, P49; IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L; LIN Z, 2001, P IEEE C COMP VIS PA, V1, P1171; MANN S, 1994, IEEE IMAGE PROC, P363, DOI 10.1109/ICIP.1994.413336; MILINAZZO F, 1987, IEEE T ACOUST SPEECH, V35, P471, DOI 10.1109/TASSP.1987.1165145; Rajan D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P113, DOI 10.1109/ICCV.2001.937506; Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915; Tsai, 1984, ADV COMPUTER VISION, V1, P317; XU SF, 1995, THEORY METHODS MATRI	22	272	326	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2004	26	1					83	97		10.1109/TPAMI.2004.1261081	http://dx.doi.org/10.1109/TPAMI.2004.1261081			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	752LF	15382688				2022-12-18	WOS:000187161400007
J	LENZ, RK; TSAI, RY				LENZ, RK; TSAI, RY			TECHNIQUES FOR CALIBRATION OF THE SCALE FACTOR AND IMAGE CENTER FOR HIGH-ACCURACY 3-D MACHINE VISION METROLOGY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											LENZ, RK (corresponding author), IBM CORP,THOMAS J WATSON RES CTR,YORKTOWN HTS,NY 10598, USA.							ABDELAZIZ YI, 1974, PHOTOGRAMMETRY SERIE, V36; ABDELAZIZ YI, 1971, JAN P S CLOS RANG PH, P1; BROWN DC, 1971, PHOTOGRAMM ENG, V37, P855; COHEN RR, 1982, HDB ARTIFICIAL INTEL, V3; Dainis A., 1985, P 1985 IEEE INT C RO, P92; Duda RO, 1973, PATTERN RECOGNITION; FAIG W, 1975, PHOTOGRAMM ENG REM S, V41, P1479; GANAPATHY S, 1984, P INT C ROBOTICS, P130; GENNERY D, 1979, P 10 IM UND WORKSH, P101; HALL EL, 1982, MAY P IEEE WORKSH IN; Isaguirre A, 1985, P INT C ROB AUT, P74; ITOH H, 1984, 7TH P INT C PATT REC, V1, P192; Karara H.M., 1979, HDB NONTOPOGRAPHIC P; LENZ RK, IN PRESS IEEE T PATT; LENZ RK, 1988, JUN P CVPR; LUH JYS, 1985, IEEE T PATTERN ANAL, V7, P35, DOI 10.1109/TPAMI.1985.4767616; MALHOTRA, 1971, P S CLOASE RANGE PHO; MARTINS HA, 1981, COMPUT VISION GRAPH, V17, P173, DOI 10.1016/0146-664X(81)90024-1; MORAVEC H, 1981, ROBOT ROVER VISUAL N; OKAMOTO A, 1984, PHOTOGRAMM ENG REM S, V50, P705; OKAMOTO A, 1981, PHOTOGRAMM ENG REM S, V47, P1437; SOBEL I, 1974, ARTIF INTELL, V5, P185, DOI 10.1016/0004-3702(74)90029-0; STRAT TM, 1984, OCT P DARPA IM UND W, P264; SUTHERLAND IE, 1974, P IEEE, V62, P453, DOI 10.1109/PROC.1974.9449; TSAI R, 1985, IBM RC51342 RES REP; TSAI RY, 1988, IN PRESS VISION  NOV; WONG KW, 1975, PHOTOGRAMM ENG REM S, V41, P1355; YAKIMOVSKY Y, 1978, COMPUT VISION GRAPH, V7, P195, DOI 10.1016/0146-664X(78)90112-0; 1980, MANUAL PHOTOGRAMMETR; [No title captured]	30	272	338	1	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1988	10	5					713	720		10.1109/34.6781	http://dx.doi.org/10.1109/34.6781			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q4255					2022-12-18	WOS:A1988Q425500012
J	Fu, YW; Hospedales, TM; Xiang, T; Gong, SG				Fu, Yanwei; Hospedales, Timothy M.; Xiang, Tao; Gong, Shaogang			Transductive Multi-View Zero-Shot Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Transducitve learning; multi-view Learning; transfer Learning; zero-shot Learning; heterogeneous hypergraph	RECOGNITION; OBJECTS	Most existing zero-shot learning approaches exploit transfer learning via an intermediate semantic representation shared between an annotated auxiliary dataset and a target dataset with different classes and no annotation. A projection from a low-level feature space to the semantic representation space is learned from the auxiliary dataset and applied without adaptation to the target dataset. In this paper we identify two inherent limitations with these approaches. First, due to having disjoint and potentially unrelated classes, the projection functions learned from the auxiliary dataset/domain are biased when applied directly to the target dataset/domain. We call this problem the projection domain shift problem and propose a novel framework, transductive multi-view embedding, to solve it. The second limitation is the prototype sparsity problem which refers to the fact that for each target class, only a single prototype is available for zero-shot learning given a semantic representation. To overcome this problem, a novel heterogeneous multi-view hypergraph label propagation method is formulated for zero-shot learning in the transductive embedding space. It effectively exploits the complementary information offered by different semantic representations and takes advantage of the manifold structures of multiple representation spaces in a coherent manner. We demonstrate through extensive experiments that the proposed approach (1) rectifies the projection shift between the auxiliary and target domains, (2) exploits the complementarity of multiple semantic representations, (3) significantly outperforms existing methods for both zero-shot and N-shot recognition on three image and video benchmark datasets, and (4) enables novel cross-view annotation tasks.	[Fu, Yanwei] Disney Res, Pittsburgh, PA 15213 USA; [Hospedales, Timothy M.; Xiang, Tao; Gong, Shaogang] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England	University of London; Queen Mary University London	Fu, YW (corresponding author), Disney Res, Pittsburgh, PA 15213 USA.	y.fu@qmul.ac.uk; t.hospedales@qmul.ac.uk; t.xiang@qmul.ac.uk; s.gong@qmul.ac.uk		Fu, Yanwei/0000-0002-6595-6893; Hospedales, Timothy/0000-0003-4867-7486				Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111; [Anonymous], 2014, 2 INT C LEARN REPR I; [Anonymous], 2011, TECH REP CNS T 2011; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Brown P. F., 1992, Computational Linguistics, V18, P467; Chatfield K., 2014, ARXIV E PRINTS; Chen XL, 2013, IEEE I CONF COMP VIS, P1409, DOI 10.1109/ICCV.2013.178; Donahue J., 2013, INT C MACH LEARN; Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPR.2009.5206747, 10.1109/CVPRW.2009.5206747]; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368; Frome Andrea, 2013, NEURIPS; Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P584, DOI 10.1007/978-3-319-10605-2_38; Fu YW, 2012, LECT NOTES COMPUT SC, V7575, P530, DOI 10.1007/978-3-642-33765-9_38; Fu YW, 2014, IEEE T PATTERN ANAL, V36, P303, DOI 10.1109/TPAMI.2013.128; Fu YW, 2010, IEEE T MULTIMEDIA, V12, P717, DOI 10.1109/TMM.2010.2052025; Fujiwara Y, 2014, PR MACH LEARN RES, V32, P784; Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Hong CQ, 2013, NEUROCOMPUTING, V118, P79, DOI 10.1016/j.neucom.2013.02.017; Hospedales T. M., 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P251, DOI 10.1109/ICDM.2011.90; Huang YC, 2010, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2010.5540012; Huang YC, 2009, PROC CVPR IEEE, P1738, DOI 10.1109/CVPRW.2009.5206795; Hwang SJ, 2012, INT J COMPUT VISION, V100, P134, DOI 10.1007/s11263-011-0494-3; Hwang SJ, 2011, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2011.5995543; Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140; Lampert CH, 2008, FOUND TRENDS COMPUT, V4, P193, DOI 10.1561/0600000027; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413; Li X, 2014, IEEE T KNOWL DATA EN, V26, P2588, DOI 10.1109/TKDE.2013.126; Mikolov T., 2013, P WORKSHOP INT C LEA; Palatucci Mark, 2009, ADV NEURAL INFORM PR, P1410; Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281; Pentina A, 2014, PR MACH LEARN RES, V32, P991; Rohrbach M, 2012, P IEEE C COMP VIS PA, P1641; Rohrbach M, 2010, PROC CVPR IEEE, P910, DOI 10.1109/CVPR.2010.5540121; ROSCH E, 1977, THINKING READINGCO; Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2; Scheirer WJ, 2012, PROC CVPR IEEE, P2933, DOI 10.1109/CVPR.2012.6248021; Socher R, 2010, PROC CVPR IEEE, P966, DOI 10.1109/CVPR.2010.5540112; Socher Richard, 2013, NEURIPS; Sugiyama M., 2007, ADV NEURAL INFORM PR, P1337; Sun L., 2008, HYPERGRAPH SPECTRAL, P668, DOI [10.1145/1401890.1401971, DOI 10.1145/1401890.1401971]; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261; Wang XY, 2013, IEEE I CONF COMP VIS, P2120, DOI 10.1109/ICCV.2013.264; Wang Y., 2007, P 16 ACM C INF KNOWL, P995; Watts D.J., 2004, SMALL WORLDS DYNAMIC; Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918; Yu FLX, 2013, PROC CVPR IEEE, P771, DOI 10.1109/CVPR.2013.105; Zhou D., 2007, P 24 INT C MACHINE L, P1159, DOI DOI 10.1145/1273496.1273642; Zhou DY, 2004, ADV NEUR IN, V16, P321; ZHU X, 2007, 1530 U WISC MAD DEP	57	271	290	4	56	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2015	37	11					2332	2345		10.1109/TPAMI.2015.2408354	http://dx.doi.org/10.1109/TPAMI.2015.2408354			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CS9KW	26440271	Green Submitted, Green Published			2022-12-18	WOS:000362411000014
J	Lu, JW; Zhou, XZ; Tan, YP; Shang, YY; Zhou, J				Lu, Jiwen; Zhou, Xiuzhuang; Tan, Yap-Pen; Shang, Yuanyuan; Zhou, Jie			Neighborhood Repulsed Metric Learning for Kinship Verification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face and gesture recognition; kinship verification; metric learning; multiview learning; biometrics	HUMAN AGE ESTIMATION; FACIAL EXPRESSION RECOGNITION; SINGLE TRAINING SAMPLE; FACE RECOGNITION; DIMENSIONALITY REDUCTION; DISCRIMINANT-ANALYSIS; MANIFOLD ANALYSIS; FRAMEWORK	Kinship verification from facial images is an interesting and challenging problem in computer vision, and there are very limited attempts on tackle this problem in the literature. In this paper, we propose a new neighborhood repulsed metric learning (NRML) method for kinship verification. Motivated by the fact that interclass samples (without a kinship relation) with higher similarity usually lie in a neighborhood and are more easily misclassified than those with lower similarity, we aim to learn a distance metric under which the intraclass samples (with a kinship relation) are pulled as close as possible and interclass samples lying in a neighborhood are repulsed and pushed away as far as possible, simultaneously, such that more discriminative information can be exploited for verification. To make better use of multiple feature descriptors to extract complementary information, we further propose a multiview NRML (MNRML) method to seek a common distance metric to perform multiple feature fusion to improve the kinship verification performance. Experimental results are presented to demonstrate the efficacy of our proposed methods. Finally, we also test human ability in kinship verification from facial images and our experimental results show that our methods are comparable to that of human observers.	[Lu, Jiwen] Adv Digital Sci Ctr, Singapore 138632, Singapore; [Zhou, Xiuzhuang; Shang, Yuanyuan] Capital Normal Univ, Coll Informat Engn, Beijing 100048, Peoples R China; [Tan, Yap-Pen] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; [Zhou, Jie] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China	Capital Normal University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Tsinghua University	Lu, JW (corresponding author), Adv Digital Sci Ctr, 1 Fusionopolis Way,08-10,Connexis North Tower, Singapore 138632, Singapore.	jiwen.lu@adsc.com.sg; zxz@xeehoo.com; eyptan@ntu.edu.sg; syy@bao.ac.cn; jzhou@tsinghua.edu.cn	Wang, Gang/B-7027-2013; Tan, Yap-Peng/A-5158-2011; Lu, Jiwen/C-5291-2009	Lu, Jiwen/0000-0002-6121-5529	Agency for Science, Technology and Research (A*STAR) of Singapore; National Natural Science Foundation of China [11178017, 61225008, 61373090, 61020106004]; Beijing Natural Science Foundation of China [4132014]	Agency for Science, Technology and Research (A*STAR) of Singapore(Agency for Science Technology & Research (A*STAR)); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Natural Science Foundation of China(Beijing Natural Science Foundation)	This work was partly supported by the research grant for the Human Sixth Sense Program at the Advanced Digital Sciences Center from the Agency for Science, Technology and Research (A*STAR) of Singapore, and research grants from the National Natural Science Foundation of China under grants 11178017, 61225008, 61373090, and 61020106004, and the Beijing Natural Science Foundation of China under grant 4132014. The authors would like to thank Mr. Junlin Hu at the Nanyang Technological University, Singapore, for his help on collecting partial of the kinship data sets and conducting partial experiments in this paper.	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Alvergne A, 2009, J VISION, V9, DOI 10.1167/9.6.23; Bach F., 2004, P 21 INT C MACH LEAR, P1; Bailly-Bailliere E., 2003, LNCS, P1057; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bickel S, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P19, DOI 10.1109/ICDM.2004.10095; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; Cao ZM, 2010, PROC CVPR IEEE, P2707, DOI 10.1109/CVPR.2010.5539992; Chen HT, 2005, PROC CVPR IEEE, P846; Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Dal Martello M., 2006, J VISION, V6; Dal Martello MF, 2010, J VISION, V10, DOI 10.1167/10.8.9; DeBruine LM, 2009, VISION RES, V49, P38, DOI 10.1016/j.visres.2008.09.025; Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590; Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3; Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847; Fu Y, 2008, IEEE T INF FOREN SEC, V3, P91, DOI 10.1109/TIFS.2007.916280; Fu Yun, 2011, 22 INT JOINT C ART I, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-422; Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Goldberger J., 2004, ADV NEURAL INFORM PR, P2539; Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280; Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681; Gutta S, 2000, IEEE T NEURAL NETWOR, V11, P948, DOI 10.1109/72.857774; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Nguyen HV, 2011, LECT NOTES COMPUT SC, V6493, P709; Hu HF, 2008, PATTERN RECOGN, V41, P2045, DOI 10.1016/j.patcog.2007.10.029; Kaminski G, 2010, PSYCHOL SCI, V21, P1746, DOI 10.1177/0956797610388045; Kaminski G, 2009, P ROY SOC B-BIOL SCI, V276, P3193, DOI 10.1098/rspb.2009.0677; Lanitis A., 2008, IEEE INT C AUT FAC G, P1, DOI DOI 10.1109/AFGR.2008.4813349; Li ZF, 2011, IEEE T INF FOREN SEC, V6, P1028, DOI 10.1109/TIFS.2011.2156787; Ling HB, 2010, IEEE T INF FOREN SEC, V5, P82, DOI 10.1109/TIFS.2009.2038751; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277; Lu JW, 2013, IEEE T HUM-MACH SYST, V43, P249, DOI 10.1109/TSMCC.2012.2192727; Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70; Lu JW, 2012, PROC CVPR IEEE, P2594, DOI 10.1109/CVPR.2012.6247978; Lu JW, 2011, IEEE I CONF COMP VIS, P1943, DOI 10.1109/ICCV.2011.6126464; Lu JW, 2011, INT CONF ACOUST SPEE, P1477; Lu JW, 2010, IEEE T SYST MAN CY B, V40, P958, DOI 10.1109/TSMCB.2009.2032926; Lu JW, 2010, IEEE T INF FOREN SEC, V5, P71, DOI 10.1109/TIFS.2009.2035976; Lu JW, 2010, IEEE SIGNAL PROC LET, V17, P185, DOI 10.1109/LSP.2009.2035017; Moghaddam B., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P306, DOI 10.1109/AFGR.2000.840651; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244; Ou Y., 2005, INT JOINT C NEUR NET, P1; Ramanathan N, 2006, IEEE T IMAGE PROCESS, V15, P3349, DOI 10.1109/TIP.2006.881993; Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Ruping S., 2005, P IEEE INT C MACH LE; Schiffman SS, 1981, INTRO MULTIDIMENSION; Shan SG, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P314; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57; Wang XG, 2006, INT J COMPUT VISION, V70, P91, DOI 10.1007/s11263-006-8098-z; Weinberger K., 2005, P C ADV NEUR INF PRO; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; Wolf L., 2008, P EUR C COMP VIS WOR; Xia SY, 2012, IEEE T MULTIMEDIA, V14, P1046, DOI 10.1109/TMM.2012.2187436; Xia TA, 2010, IEEE T SYST MAN CY B, V40, P1438, DOI 10.1109/TSMCB.2009.2039566; Xie B, 2011, IEEE T SYST MAN CY B, V41, P1088, DOI 10.1109/TSMCB.2011.2106208; Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P212, DOI 10.1109/TIP.2006.884929; Yang MH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P215; Yu WW, 2006, IMAGE VISION COMPUT, V24, P239, DOI 10.1016/j.imavis.2005.11.006; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; Zhao Z., 2008, J MACH LEARN RES, V4, P36; Zheng WM, 2006, IEEE T NEURAL NETWOR, V17, P233, DOI 10.1109/TNN.2005.860849; Zhou D., 2007, P 24 INT C MACHINE L, P1159, DOI DOI 10.1145/1273496.1273642; Zhou X., 2011, P 19 ACM INT C MULT, P953, DOI DOI 10.1145/2072298.2071911; Zien A., 2007, P 24 INT C MACH LEAR, V1, P1191, DOI DOI 10.1145/1273496.1273646	73	271	283	6	98	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2014	36	2					331	345		10.1109/TPAMI.2013.134	http://dx.doi.org/10.1109/TPAMI.2013.134			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	278OL	24356353				2022-12-18	WOS:000328899500010
J	Ali, S; Shah, M				Ali, Saad; Shah, Mubarak			Human Action Recognition in Videos Using Kinematic Features and Multiple Instance Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action recognition; motion; video analysis; principal component analysis; kinematic features		We propose a set of kinematic features that are derived from the optical flow for human action recognition in videos. The set of kinematic features includes divergence, vorticity, symmetric and antisymmetric flow fields, second and third principal invariants of flow gradient and rate of strain tensor, and third principal invariant of rate of rotation tensor. Each kinematic feature, when computed from the optical flow of a sequence of images, gives rise to a spatiotemporal pattern. It is then assumed that the representative dynamics of the optical flow are captured by these spatiotemporal patterns in the form of dominant kinematic trends or kinematic modes. These kinematic modes are computed by performing Principal Component Analysis (PCA) on the spatiotemporal volumes of the kinematic features. For classification, we propose the use of multiple instance learning (MIL) in which each action video is represented by a bag of kinematic modes. Each video is then embedded into a kinematic-mode-based feature space and the coordinates of the video in that space are used for classification using the nearest neighbor algorithm. The qualitative and quantitative results are reported on the benchmark data sets.	[Ali, Saad] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; [Shah, Mubarak] Univ Cent Florida, Comp Vis Lab, Sch Elect Engn & Comp Sci, Harris Corp Engn Ctr, Orlando, FL 32816 USA	Carnegie Mellon University; State University System of Florida; University of Central Florida	Ali, S (corresponding author), Carnegie Mellon Univ, Inst Robot, 5000 Forbes Ave,NSH 4130, Pittsburgh, PA 15213 USA.	saada@cs.cmu.edu; shah@eecs.ucf.edu		Shah, Mubarak/0000-0001-6172-5572				Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744; AGGARWAL JK, 1994, P WORKSH MOT NONR AR; ARBEL T, 2000, P BRIT MACH VIS C; BLACK MJ, 1997, P IEEE INT C COMP VI; Blank M., 2005, P IEEE INT C COMP VI; Bobick A.F., 1996, P IEEE CS C COMP VIS; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; CARLSSON C, 2001, P WORKSH MOD VERS EX; CEDRAS C, 1995, IMAGE VISION COMPUT, V13, P129, DOI 10.1016/0262-8856(95)93154-K; Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248; CHEUNG KM, 2003, P IEEE CS C COMP VIS; DARRELL T, 1993, P ADV NEUR INF PROC; Dollar P., 2005, P IEEE INT WORKSH VS; Durbin PA, 2003, STAT THEORY MODELING; Efros A. A., 2003, P IEEE INT C COMP VI; HOEY J, 2000, P IEEE CS C COMP VIS; JIANG H, 2006, P IEEE CS C COMP VIS; JU SX, 1996, P 2 INT C AUT FAC GE; Ke Y., 2005, P IEEE INT C COMP VI; KIM TK, 2007, P IEEE CS C COMP VIS; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378; Laptev I., 2008, P IEEE CS C COMP VIS; LITTLE J, 1995, P INT S COMP VIS; Little J, 1998, J COMPUT VIS RES, V1, P2; LIU J, 2008, P IEEE CS C COMP VIS; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mahmood T, 2001, P IEEE WORKSH DET RE; Maron O, 1998, LEARNING AMBIGUITY; Niebles J. C., 2006, P BRIT MACH VIS C; OIKONOMOPOULOUS.A, 2005, P IEEE INT C MULT EX; Schuldt C., 2004, P IEEE INT C PATT RE; Scovanner P., 2007, P ACM INT C MULT; SHECHTMAN E, 2005, P IEEE CS C COMP VIS; SIROVICH L, 1987, Q APPL MATH, V45, P561, DOI 10.1090/qam/910462; STARNER T, 1995, P INT WORKSH AUT FAC; Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013; Wong S., 2007, P IEEE INT C COMP VI; Yacoob Y, 1999, COMPUT VIS IMAGE UND, V73, P232, DOI 10.1006/cviu.1998.0726; YAMATO J, 1992, P IEEE CS C COMP VIS; Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96; Yilmaz A., 2005, P IEEE CS C COMP VIS	41	270	280	0	51	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2010	32	2					288	303		10.1109/TPAMI.2008.284	http://dx.doi.org/10.1109/TPAMI.2008.284			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	532IT	20075459				2022-12-18	WOS:000272741500008
J	Chan, AB; Vasconcelos, N				Chan, Antoni B.; Vasconcelos, Nuno			Modeling, clustering, and segmenting video with mixtures of dynamic textures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						dynamic texture; temporal textures; video modeling; video clustering; motion segmentation; mixture models; linear dynamical systems; time-series clustering; Kalman filter; probabilistic models; expectation-maximization	MAXIMUM-LIKELIHOOD; LINEAR-MODELS	Adynamic texture is a spatio-temporal generative model for video, which represents video sequences as observations from a linear dynamical system. This work studies the mixture of dynamic textures, a statistical model for an ensemble of video sequences that is sampled from a finite collection of visual processes, each of which is a dynamic texture. An expectation-maximization (EM) algorithm is derived for learning the parameters of the model, and the model is related to previous works in linear systems, machine learning, time-series clustering, control theory, and computer vision. Through experimentation, it is shown that the mixture of dynamic textures is a suitable representation for both the appearance and dynamics of a variety of visual processes that have traditionally been challenging for computer vision (for example, fire, steam, water, vehicle and pedestrian traffic, and so forth). When compared with state-of-the-art methods in motion segmentation, including both temporal texture methods and traditional representations (for example, optical flow or other localized motion representations), the mixture of dynamic textures achieves superior performance in the problems of clustering and segmenting video of such processes.	[Chan, Antoni B.; Vasconcelos, Nuno] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA	University of California System; University of California San Diego	Chan, AB (corresponding author), Univ Calif San Diego, Dept Elect & Comp Engn, Gilman Dr,Mail Code 0409, La Jolla, CA 92093 USA.	abchan@ucsd.edu; nuno@ece.ucsd.edu	Chan, Antoni/D-7858-2013	Chan, Antoni/0000-0002-2886-2513; Vasconcelos, Nuno/0000-0002-9024-4302				Anandan P., 1993, MOTION ANAL IMAGE SE, P1; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Bauer D, 2005, J TIME SER ANAL, V26, P631, DOI 10.1111/j.1467-9892.2005.00441.x; BROWN RG, 1983, IEEE T CIRCUITS SYST, V30, P765, DOI 10.1109/TCS.1983.1085288; Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; Chan AB, 2005, PROC CVPR IEEE, P846; Chan AB, 2005, IEEE I CONF COMP VIS, P641; CHAN AB, 2006, ADV NEURAL INFORM PR, V18, P203; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; COOPER L, 2005, P IEEE INT C COMP VI; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Digalakis V, 1993, IEEE T SPEECH AUDI P, V1, P431, DOI 10.1109/89.242489; Doretto G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1236; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Fitzpatrick JJ, 2001, APPL NURS RES, V14, P1, DOI 10.1053/apnr.2001.22463; Forsyth DA, 2002, PRENT HALL PROF TECH; Frey B. J., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P416, DOI 10.1109/CVPR.1999.786972; Ghahramani Z, 2000, NEURAL COMPUT, V12, P831, DOI 10.1162/089976600300015619; Ghahramani Z., 1996, CRGTR962 U TOTR DEP; Ghahramani Z., 1997, EM ALGORITHM MIXTURE; GHOREYSHI A, 2006, P EUR C COMP VIS DYN; HANSEN M, 1994, P ARPA IM UND WORKSH, P457; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; IRANI M, 1992, LECT NOTES COMPUT SC, V588, P282; Isard M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P107, DOI 10.1109/ICCV.1998.710707; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jensen F.V., 2007, BAYESIAN NETWORKS DE, DOI 10.1007/978-0-387-68282-2; Jepson A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P760, DOI 10.1109/CVPR.1993.341161; Kakizawa Y, 1998, J AM STAT ASSOC, V93, P328, DOI 10.2307/2669629; Kay S. M., 1993, FUNDAMENTALS STAT SI; KIM CJ, 1994, J ECONOMETRICS, V60, P1, DOI 10.1016/0304-4076(94)90036-1; LAINIOTIS DG, 1976, P IEEE, V64, P1126, DOI 10.1109/PROC.1976.10284; Liao TW, 2005, PATTERN RECOGN, V38, P1857, DOI 10.1016/j.patcog.2005.01.025; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; MAGILL DT, 1965, IEEE T AUTOMAT CONTR, VAC10, P434, DOI 10.1109/TAC.1965.1098191; Narendra KS, 1997, IEEE T AUTOMAT CONTR, V42, P171, DOI 10.1109/9.554398; Oh SM, 2005, IEEE I CONF COMP VIS, P1161; OVERSCHEE PV, 1994, AUTOMATICA, V30, P75; Pavlovic V., 2000, ADV NEURAL INFORM PR, V13; PAVLOVIC VI, 1999, P IEEE C COMP VIS PA; Roweis S, 1999, NEURAL COMPUT, V11, P305, DOI 10.1162/089976699300016674; Saisan P, 2001, PROC CVPR IEEE, P58; Sawhney HS, 1996, IEEE T PATTERN ANAL, V18, P814, DOI 10.1109/34.531801; SHI J, 1999, P INT C COMP VIS, P1154; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shumway R. H., 1982, Journal of Time Series Analysis, V3, P253, DOI 10.1111/j.1467-9892.1982.tb00349.x; SHUMWAY RH, 1991, J AM STAT ASSOC, V86, P763, DOI 10.2307/2290410; Singhal A, 2002, P AMER CONTR CONF, V1-6, P3931, DOI 10.1109/ACC.2002.1024543; Soatto S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P439, DOI 10.1109/ICCV.2001.937658; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Vasconcelos N, 2004, IEEE T SIGNAL PROCES, V52, P2322, DOI 10.1109/TSP.2004.831125; Vasconcelos N, 2001, IEEE T PATTERN ANAL, V23, P217, DOI 10.1109/34.908972; Vidal R, 2005, PROC CVPR IEEE, P516; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Weiss Y, 1997, PROC CVPR IEEE, P520, DOI 10.1109/CVPR.1997.609375; Wu Y, 2003, PROC CVPR IEEE, P295; Xiong YM, 2004, PATTERN RECOGN, V37, P1675, DOI 10.1016/j.patcog.2003.12.018; Young S. J., 2006, HTK BOOK; 2008, MIXTURES DYNAMIC TEX	62	270	283	1	44	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2008	30	5					909	926		10.1109/TPAMI.2007.70738	http://dx.doi.org/10.1109/TPAMI.2007.70738			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	272SI	18369258	Green Submitted			2022-12-18	WOS:000253879700012
J	Lorigo, LM; Govindaraju, V				Lorigo, LM; Govindaraju, V			Offline Arabic handwriting recognition: A survey	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review						computer vision; document analysis; handwriting analysis; optical character recognition	OFF-LINE RECOGNITION; CHARACTER-RECOGNITION; WORD RECOGNITION; ONLINE RECOGNITION; SYSTEM; SEGMENTATION; INFORMATION; SCRIPT; MODEL	The automatic recognition of text on scanned images has enabled many applications such as searching for words in large volumes of documents, automatic sorting of postal mail, and convenient editing of previously printed documents. The domain of handwriting in the Arabic script presents unique technical challenges and has been addressed more recently than other domains. Many different methods have been proposed and applied to various types of images. This paper provides a comprehensive review of these methods. It is the first survey to focus on Arabic handwriting recognition and the first Arabic character recognition survey to provide recognition rates and descriptions of test data for the approaches discussed. It includes background on the field, discussion of the methods, and future research directions.	SUNY Buffalo, Dept Comp Sci & Engn, Amherst, NY 14228 USA	State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Lorigo, LM (corresponding author), SUNY Buffalo, Dept Comp Sci & Engn, 520 Lee Entrance,Suite 202,UB Commons, Amherst, NY 14228 USA.	lmlorigo@buffalo.edu; govind@buffalo.edu						ABDELAZIM HY, 1995, INT J COMPUTERS THEI, V2, P43; Abuhaiba ISI, 1998, COMPUT VIS IMAGE UND, V71, P19, DOI 10.1006/cviu.1997.0629; Abuhaiba ISI, 2003, ARAB J SCI ENG, V28, P77; ABUHAIBA ISI, 1993, PATTERN RECOGN, V26, P1009, DOI 10.1016/0031-3203(93)90002-E; ABUHAIBA ISI, 1994, IEEE T PATTERN ANAL, V16, P664, DOI 10.1109/34.295912; Al-Badr B., 1998, International Journal on Document Analysis and Recognition, V1, P147, DOI 10.1007/s100320050014; Al-Badr B., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P355, DOI 10.1109/ICDAR.1995.599012; Al-Ma'adeed S, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P485, DOI 10.1109/IWFHR.2002.1030957; Al-Ohali Y, 2003, PATTERN RECOGN, V36, P111, DOI 10.1016/S0031-3203(02)00064-X; Al-Shaher AA, 2003, PATTERN RECOGN, V36, P2805, DOI 10.1016/S0031-3203(03)00139-0; Al-Sughaiyer IA, 2004, J AM SOC INF SCI TEC, V55, P189, DOI 10.1002/asi.10368; ALBADR B, 1995, SIGNAL PROCESS, V41, P49, DOI 10.1016/0165-1684(94)00090-M; ALEMAMI S, 1990, IEEE T PATTERN ANAL, V12, P704, DOI 10.1109/34.56214; Alherbish J, 1997, SECOND IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATIONS, PROCEEDINGS, P286, DOI 10.1109/ISCC.1997.616013; ALKHARASHI IA, 1994, J AM SOC INFORM SCI, V45, P548, DOI 10.1002/(SICI)1097-4571(199409)45:8<548::AID-ASI3>3.0.CO;2-X; ALKHARASHI IA, 1999, P INT GLOB SUMM; Alma'adeed S, 2004, KNOWL-BASED SYST, V17, P75, DOI 10.1016/j.knosys.2004.03.002; Alma'adeed S, 2002, INT C PATT RECOG, P481, DOI 10.1109/ICPR.2002.1047981; ALMUALLIM H, 1987, IEEE T PATTERN ANAL, V9, P715, DOI 10.1109/TPAMI.1987.4767970; ALQAHTANI SA, 2004, P 8 IASTED INT C ART; ALQAHTANI SA, 2004, P 4 IASTED INT C VIS; ALSHAHER A, 2002, P 13 BRIT MACH VIS C, P497; ALYOUSEFI H, 1992, IEEE T PATTERN ANAL, V14, P853, DOI 10.1109/34.149585; Amin A, 1998, PATTERN RECOGN, V31, P517, DOI 10.1016/S0031-3203(97)00084-8; Amin A, 1996, PATTERN RECOGN, V29, P663, DOI 10.1016/0031-3203(95)00110-7; Amin A, 2003, PATTERN RECOGN LETT, V24, P3187, DOI 10.1016/j.patrec.2003.08.004; Amin A., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P392; Bazzi I, 1999, IEEE T PATTERN ANAL, V21, P495, DOI 10.1109/34.771314; BENAMARA N, 2000, P C INT FRANC ECR DO; CHEN MY, 1995, IEEE T IMAGE PROCESS, V4, P1675, DOI 10.1109/83.477074; CHEN YS, 1985, P NAT COMP S, P295; Clocksin WF, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P664, DOI 10.1109/ICIAP.2003.1234126; Cootes TF, 1999, IMAGE VISION COMPUT, V17, P567, DOI 10.1016/S0262-8856(98)00175-9; Decerbo M, 2005, PROC INT CONF DOC, P411, DOI 10.1109/ICDAR.2005.189; Dehghan M, 2001, PATTERN RECOGN, V34, P1057, DOI 10.1016/S0031-3203(00)00051-0; Dehghani A, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P506, DOI 10.1109/ITCC.2001.918847; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; E-Hajj R, 2005, PROC INT CONF DOC, P893; ELDABI SS, 1990, PATTERN RECOGN, V23, P485, DOI 10.1016/0031-3203(90)90069-W; ELDIN AS, 1998, P SPIE C OPT PATT RE, P331; ELSADANY TA, 1989, IBM SYST J, V28, P600, DOI 10.1051/epjap/2011100487; ELSHEIKH TS, 1988, PATTERN RECOGN, V21, P293, DOI 10.1016/0031-3203(88)90042-8; ELWAKIL MS, 1989, PATTERN RECOGN, V22, P97, DOI 10.1016/0031-3203(89)90058-7; FAHMY MMM, 2001, STUDIES INFORM CONTR, V10; Farah N, 2005, PROC INT CONF DOC, P222, DOI 10.1109/ICDAR.2005.57; Farah N, 2004, LECT NOTES COMPUT SC, V3192, P420; Farooq F, 2005, PROC INT CONF DOC, P267, DOI 10.1109/ICDAR.2005.191; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; GILLIES A, 1999, P S DOC IM UND TECHN; GORAINE H, 1992, COMPUTER, V25, P71, DOI 10.1109/2.144444; Hamami L, 2002, ARAB J SCI ENG, V27, P57; HARATY R, 2002, P INT C COMP SCI SOF; HARATY R, 2003, P ACS IEEE INT C COM; HARATY R, 2002, P INT AR C INF TECHN; Haraty R., 2004, INT ARAB J INF TECHN, V1, P156; Hashemi M. R., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P869, DOI 10.1109/ICDAR.1995.602039; Hopley R. L., 1997, P S DOC IM UND TECHN, P303; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; Jin JM, 2005, PROC SPIE, V5676, P48, DOI 10.1117/12.585711; Kanoun S, 2005, PROC INT CONF DOC, P1025, DOI 10.1109/ICDAR.2005.44; KANUNGO T, 1999, P SPIE C DOC REC RET, V6, P109; Khorsheed MS, 2002, PATTERN ANAL APPL, V5, P31, DOI 10.1007/s100440200004; Khorsheed MS, 2003, PATTERN RECOGN LETT, V24, P2235, DOI 10.1016/S0167-8655(03)00050-3; KHORSHEED MS, 1999, P BRIT MACH VIS C, P422; KIM G, 1999, ADV HANDWRITING RECO, P163; Lorigo L, 2005, PROC INT CONF DOC, P605, DOI 10.1109/ICDAR.2005.207; Maddouri SS, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P128, DOI 10.1109/IWFHR.2002.1030898; Madhvanath S, 2001, IEEE T PATTERN ANAL, V23, P149, DOI 10.1109/34.908966; Madhvanath S, 1999, IEEE T PATTERN ANAL, V21, P928, DOI 10.1109/34.790433; Makhoul J, 1998, PATTERN RECOGN, V31, P1285, DOI 10.1016/S0031-3203(97)00152-0; Margner V, 2005, PROC INT CONF DOC, P70, DOI 10.1109/ICDAR.2005.52; Miled H., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P69, DOI 10.1109/ICDAR.2001.953757; Mokbel C., 2002, P INT C RES TRENDS S; Mostafa K, 1999, P SOC PHOTO-OPT INS, V3651, P73, DOI 10.1117/12.335805; Motawa D, 1997, PROC INT CONF DOC, P625, DOI 10.1109/ICDAR.1997.620580; Mozaffari S, 2005, PROC INT CONF DOC, P237, DOI 10.1109/ICDAR.2005.221; NATARAJAN P, 2003, P S DOC IM UND TECHN, P47; Nouh A., 1984, Arab Gulf Journal of Scientific Research, V2, P329; NOUH A, 1980, J ENG SCI, V6, P185; Olivier C., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P264, DOI 10.1109/ICPR.1996.546952; PARHAMI B, 1981, PATTERN RECOGN, V14, P395, DOI 10.1016/0031-3203(81)90084-4; Park HS, 1996, PATTERN RECOGN, V29, P231, DOI 10.1016/0031-3203(95)00081-X; Pechwitz M, 2003, PROC INT CONF DOC, P890; Pechwitz M, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P479, DOI 10.1109/IWFHR.2002.1030956; QUINLAN JR, 1990, MACH LEARN, V5, P239, DOI 10.1007/BF00117105; Romeo-Pakker K., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P874, DOI 10.1109/ICDAR.1995.602040; Safabakhsh R, 2005, ARAB J SCI ENG, V30, P95; Sari T, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P452, DOI 10.1109/IWFHR.2002.1030952; Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI [10.1109/MASSP.1986.1165342, 10.1002/0471250953.bia03as18]; Sellami M, 1998, P C AFR RECH INF, P122; *SIL INT, 2000, ETHN LANG WORLD; Soleymani M., 2003, INT J COMPUTATIONAL, V1, P193; Souici L, 2004, LECT NOTES COMPUT SC, V3192, P331; Souici-Meslati L, 2004, ARAB J SCI ENG, V29, P177; touj Sameh, 2005, INT ARAB J INFORM TE, V2; TRENKEL J, 1995, P S DOC IM UND TECHN, P191; TRENKLE J, 2001, P S DOC IM UND TECHN; TRENKLE J, 1997, P S DOC IM UND TECHN, P155; Vinciarelli A, 2004, IEEE T PATTERN ANAL, V26, P709, DOI 10.1109/TPAMI.2004.14; YASEEN M, 2001, P ACL EACL 2001 WORK, P58; YMIN A, 1996, P 13 INT C PATT REC, V3, P215	101	270	277	4	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2006	28	5					712	724		10.1109/TPAMI.2006.102	http://dx.doi.org/10.1109/TPAMI.2006.102			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	020CO	16640258				2022-12-18	WOS:000235885700004
J	AZARBAYEJANI, A; PENTLAND, AP				AZARBAYEJANI, A; PENTLAND, AP			RECURSIVE ESTIMATION OF MOTION, STRUCTURE, AND FOCAL LENGTH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						STRUCTURE FROM MOTION; CAMERA MODEL; CAMERA CALIBRATION; RECURSIVE ESTIMATION; 3D REPRESENTATION; 3D MODELING	SEQUENCE; IMAGES	We present a formulation for recursive recovery of motion, pointwise structure, and focal length from feature correspondences tracked through an image sequence. In addition to adding focal length to the state vector, several representational improvements are made over earlier structure from motion formulations, yielding a stable and accurate estimation framework which applies uniformly to both true perspective and orthographic projection. Results on synthetic and real imagery illustrate the performance of the estimator.			AZARBAYEJANI, A (corresponding author), MIT, MEDIA LAB, CAMBRIDGE, MA 02139 USA.							AYACHE N, 1989, IEEE T ROBOTIC AUTOM, V5, P804, DOI 10.1109/70.88101; AZARBAYEJANAI A, 1993, 1993 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION : PROCEEDINGS, P294; AZARBAYEJANI A, 1993, IEEE T PATTERN ANAL, V15, P602, DOI 10.1109/34.216730; AZARBAYEJANI AJ, 1994, 2ND CAS BAS VIS WORK; BROIDA TJ, 1990, IEEE T AERO ELEC SYS, V26, P639, DOI 10.1109/7.55557; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; Brown R. G., 1983, INTRO RANDOM SIGNAL; DICKMANNS ED, 1988, MACH VISION APPL, V1, P223; DUTTA R, 1989, 1989 IEEE C COMP VIS; FAUGERAS O, 1992, JUN P EUR C COMP VIS, P563; FAUGERAS OD, 1986, APR P IEEE C ROB AUT; Gelb A., 1974, APPL OPTIMAL ESTIMAT; HEEL J, 1990, ICCV 90; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; KUMAR R, 1992, 1992 IEEE C COMP VIS, P209; KUMAR RVR, 1989, JUN P IEEE C COMP VI, P136; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032; OLIENSIS J, 1991, OCT IEEE WORKSH VIS, P8; POELMAN CJ, 1992, CMUCS92208 CARN MELL; SHASHUA A, 1993, FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION : PROCEEDINGS, P583; SOATTO S, 1993, 1993 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION : PROCEEDINGS, P428; SPETSAKIS M, 1991, INT J COMPUT VISION, V6, P245, DOI 10.1007/BF00115698; SZELISKI R, 1993, 1993 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION : PROCEEDINGS, P752; SZELISKI R, 1993, CRL933 DIG EQ CORP C; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Weinshall D., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P675, DOI 10.1109/ICCV.1993.378147; WENG J, 1989, JUN P IEEE C COMP VI, P144; WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074; YOUNG GSJ, 1990, IEEE T PATTERN ANAL, V12, P735, DOI 10.1109/34.57666	32	269	286	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1995	17	6					562	575		10.1109/34.387503	http://dx.doi.org/10.1109/34.387503			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QZ940					2022-12-18	WOS:A1995QZ94000002
J	Wang, JD; Zhang, T; Song, JK; Sebe, N; Shen, HT				Wang, Jingdong; Zhang, Ting; Song, Jingkuan; Sebe, Nicu; Shen, Heng Tao			A Survey on Learning to Hash	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Similarity search; approximate nearest neighbor search; hashing; learning to hash; quantization; pairwise similarity preserving; multiwise similarity preserving; implicit similarity preserving	APPROXIMATE NEAREST-NEIGHBOR; BINARY-CODES; ITERATIVE QUANTIZATION; PRODUCT QUANTIZATION; PROCRUSTEAN APPROACH; IMAGE; SEARCH; GRAPH; ALGORITHMS; DISTANCE	Nearest neighbor search is a problem of finding the data points from the database such that the distances from them to the query point are the smallest. Learning to hash is one of the major solutions to this problem and has been widely studied recently. In this paper, we present a comprehensive survey of the learning to hash algorithms, categorize them according to the manners of preserving the similarities into: pairwise similarity preserving, multiwise similarity preserving, implicit similarity preserving, as well as quantization, and discuss their relations. We separate quantization from pairwise similarity preserving as the objective function is very different though quantization, as we show, can be derived from preserving the pairwise similarities. In addition, we present the evaluation protocols, and the general performance analysis, and point out that the quantization algorithms perform superiorly in terms of search accuracy, search time cost, and space cost. Finally, we introduce a few emerging topics.	[Wang, Jingdong] Microsoft Res, Visual Comp Grp, Beijing 100080, Peoples R China; [Zhang, Ting] Univ Sci & Technol China, Dept Automat, Hefei 230000, Anhui, Peoples R China; [Song, Jingkuan; Shen, Heng Tao] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 610051, Sichuan, Peoples R China; [Sebe, Nicu] Univ Trento, Dept Informat Engn & Comp Sci, I-38122 Trento, Italy	Microsoft; Chinese Academy of Sciences; University of Science & Technology of China, CAS; University of Electronic Science & Technology of China; University of Trento	Shen, HT (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 610051, Sichuan, Peoples R China.	jingdw@microsoft.com; zting@mail.ustc.edu.cn; jingkuan.song@gmail.com; niculae.sebe@unitn.it; shenhengtao@hotmail.com	Wang, Jingdong/E-9920-2017; Shen, Heng Tao/ABD-5331-2021	Wang, Jingdong/0000-0002-4888-4445; Sebe, Niculae/0000-0002-6597-7248	National Nature Science Foundation of China [61632007]	National Nature Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was partially supported by the National Nature Science Foundation of China No. 61632007. Heng Tao Shen is the corresponding author.	Andoni A, 2006, ANN IEEE SYMP FOUND, P459; Babenko A, 2015, PROC CVPR IEEE, P4240, DOI 10.1109/CVPR.2015.7299052; Babenko A, 2014, PROC CVPR IEEE, P931, DOI 10.1109/CVPR.2014.124; Babenko A, 2012, PROC CVPR IEEE, P3069, DOI 10.1109/CVPR.2012.6248038; Balu R., 2014, P IEEE INT C AC SPEE, P6884; BENTLEY JL, 1977, INFORM PROCESS LETT, V6, P209, DOI 10.1016/0020-0190(77)90070-9; Bergamo A., 2011, NIPS, V24, P2088; Boufounos PT, 2008, 2008 42ND ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, VOLS 1-3, P16, DOI 10.1109/CISS.2008.4558487; Brandt J, 2010, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2010.5539852; Broder AZ, 1998, COMPRESSION AND COMPLEXITY OF SEQUENCES 1997 - PROCEEDINGS, P21, DOI 10.1109/SEQUEN.1997.666900; Broder AZ, 1997, COMPUT NETWORKS ISDN, V29, P1157, DOI 10.1016/S0169-7552(97)00031-7; Cakir F, 2015, IEEE I CONF COMP VIS, P1044, DOI 10.1109/ICCV.2015.125; Carreira-Perpinan MA, 2015, PROC CVPR IEEE, P557, DOI 10.1109/CVPR.2015.7298654; Charikar M. S., 2002, P 34 ANN ACM S THEOR, P380, DOI DOI 10.1145/509907.509965; Cherian A, 2014, PR MACH LEARN RES, V32, P1053; Cherian A, 2012, IEEE IMAGE PROC, P2417, DOI 10.1109/ICIP.2012.6467385; Chum O, 2010, IEEE T PATTERN ANAL, V32, P371, DOI 10.1109/TPAMI.2009.166; Church K. W., 2006, NIPS, P873; Dai Q, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1247, DOI 10.1145/2964284.2964331; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dasgupta A., 2011, P 17 ACM SIGKDD INT, P1073; Dean T, 2013, PROC CVPR IEEE, P1814, DOI 10.1109/CVPR.2013.237; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Ding K, 2015, IEEE I CONF COMP VIS, P1098, DOI 10.1109/ICCV.2015.131; Du Chao, 2014, CORR; Fan LX, 2013, IEEE I CONF COMP VIS, P2616, DOI 10.1109/ICCV.2013.325; Fei-Fei L., 2004, P WORKSH GEN MOD BAS; Gan Junhao, 2012, P 2012 ACM SIGMOD IN, P541; Gao LL, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P903, DOI 10.1145/2733373.2806360; Ge TZ, 2014, LECT NOTES COMPUT SC, V8695, P250, DOI 10.1007/978-3-319-10584-0_17; Ge TZ, 2013, PROC CVPR IEEE, P2946, DOI 10.1109/CVPR.2013.379; Gong Y., 2012, ADV NEURAL INFORM PR, P1196; Gong YC, 2013, PROC CVPR IEEE, P484, DOI 10.1109/CVPR.2013.69; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; Gordo A, 2014, IEEE T PATTERN ANAL, V36, P33, DOI 10.1109/TPAMI.2013.101; Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541; He J., 2010, P ACM SIGKDD INT C K, P1129; He JF, 2011, PROC CVPR IEEE, P753, DOI 10.1109/CVPR.2011.5995518; Heo JP, 2014, PROC CVPR IEEE, P2139, DOI 10.1109/CVPR.2014.274; Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024; Hinton G., 2007, INT J APPROX REASON, V50, P969; Huang L., 2013, IJCAI, P1422; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Irie G, 2015, IEEE I CONF COMP VIS, P1886, DOI 10.1109/ICCV.2015.219; Irie G, 2014, PROC CVPR IEEE, P2123, DOI 10.1109/CVPR.2014.272; Jain H, 2016, LECT NOTES COMPUT SC, V9911, P681, DOI 10.1007/978-3-319-46478-7_42; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2008, INT CONF ACOUST SPEE, P825, DOI 10.1109/ICASSP.2008.4517737; Jegou H, 2012, INT CONF ACOUST SPEE, P2029, DOI 10.1109/ICASSP.2012.6288307; Jegou H, 2011, INT CONF ACOUST SPEE, P861; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Ji JQ, 2013, IEEE DATA MINING, P301, DOI 10.1109/ICDM.2013.119; Ji Jianqiu, 2012, ADV NEURAL INFORM PR, P108; Jiang QY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2248; Jiang Y.-G., 2011, P 1 ACM INT C MULT R, P16; Jiang YG, 2013, IEEE T MULTIMEDIA, V15, P442, DOI 10.1109/TMM.2012.2231061; JIANG ZY, 2016, P INT C MULT MOD, V80, P325; Jin ZM, 2013, IEEE I CONF COMP VIS, P257, DOI 10.1109/ICCV.2013.39; Joly A, 2011, PROC CVPR IEEE, P873, DOI 10.1109/CVPR.2011.5995709; Kalantidis Y, 2014, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR.2014.298; Koudas N, 2004, PROC INT CONF DATA, P6, DOI 10.1109/ICDE.2004.1319980; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kulis Brian, 2009, ADV NEURAL INFORM PR, P1042; Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947; LeCun Y., 2001, INTELLIGENT SIGNAL P, P306; Leng C, 2015, PROC CVPR IEEE, P2503, DOI 10.1109/CVPR.2015.7298865; Li P., 2012, 26 ANN C NEUR INF PR, V25, P3113; Li P., 2006, P 12 ACM SIGKDD INT, P287, DOI [10.1145/1150402.1150436, DOI 10.1145/1150402.1150436]; Li P, 2013, IEEE T MULTIMEDIA, V15, P141, DOI 10.1109/TMM.2012.2199970; Li Ping, 2010, ADV NEURAL INFORM PR, P1387; Li Ping, 2010, P 19 INT C WORLD WID, P671, DOI DOI 10.1145/1772690.1772759; Li W.-J., 2012, P ADV NEUR INF PROC, P1646; Lin GS, 2014, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2014.253; Lin GS, 2013, IEEE I CONF COMP VIS, P2552, DOI 10.1109/ICCV.2013.317; Lin RS, 2010, PROC CVPR IEEE, P848, DOI 10.1109/CVPR.2010.5540129; Lin Y, 2013, PROC CVPR IEEE, P446, DOI 10.1109/CVPR.2013.64; Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862; Liu DR, 2013, ALLERGY ASTHMA CL IM, V9, DOI 10.1186/1710-1492-9-30; Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227; Liu L, 2017, IEEE T IMAGE PROCESS, V26, P107, DOI 10.1109/TIP.2016.2619262; Liu W., 2014, ADV NEURAL INFORM PR, V4, P3419; Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912; Liu W, 2011, SER INF MANAGE SCI, V10, P1; Liu Wei, 2012, ICML, P467; Liu X., 2013, P 27 AAAI C ART INT; Liu XL, 2015, IEEE I CONF COMP VIS, P1107, DOI 10.1109/ICCV.2015.132; Liu XL, 2016, IEEE T IMAGE PROCESS, V25, P907, DOI 10.1109/TIP.2015.2505180; Liu XL, 2014, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2014.275; Liu Y, 2013, NEUROCOMPUTING, V119, P49, DOI 10.1016/j.neucom.2012.02.051; Liu Y, 2012, IEEE T IMAGE PROCESS, V21, P4480, DOI 10.1109/TIP.2012.2207394; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lv Q, 2007, P 33 INT C VER LARG, P950, DOI DOI 10.1145/1143844.1143857; Martinez J, 2016, LECT NOTES COMPUT SC, V9906, P137, DOI 10.1007/978-3-319-46475-6_9; Matsui Y, 2015, IEEE I CONF COMP VIS, P1940, DOI 10.1109/ICCV.2015.225; Matsushita Y, 2009, LECT NOTES COMPUT SC, V5414, P374, DOI 10.1007/978-3-540-92957-4_33; Mohammad Norouzi, 2012, ADV NEURAL INFORM PR, P1061; Moon Y., 2015, P ACM S CLOUD COMP, P235; Motwani R, 2007, SIAM J DISCRETE MATH, V21, P930, DOI 10.1137/050646858; Mu YD, 2012, INT J MULTIMED INF R, V1, P59, DOI 10.1007/s13735-012-0003-7; Mu YD, 2010, PROC CVPR IEEE, P3344, DOI 10.1109/CVPR.2010.5540024; Muja M., 2012, 2012 Canadian Conference on Computer and Robot Vision, P404, DOI 10.1109/CRV.2012.60; Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Mukherjee L, 2015, IEEE I CONF COMP VIS, P4184, DOI 10.1109/ICCV.2015.476; Norouzi M., 2011, INT C MACHINE LEARNI, P353; Norouzi M, 2013, PROC CVPR IEEE, P3017, DOI 10.1109/CVPR.2013.388; Norouzi M, 2012, PROC CVPR IEEE, P3108, DOI 10.1109/CVPR.2012.6248043; ODonnell R., 2011, INNOVATIONS COMPUTER, P275; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Panigrahy R, 2006, PROCEEDINGS OF THE SEVENTHEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1186, DOI 10.1145/1109557.1109688; Pauleve L, 2010, PATTERN RECOGN LETT, V31, P1348, DOI 10.1016/j.patrec.2010.04.004; Pennington Jeffrey., 2014, P 2014 C EMP METH NA, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]; PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009; Qin D., 2014, P BRIT MACH VIS C; Qin D., 2014, P 2014 C NEUR INF PR, P172; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Sanchez J, 2011, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2011.5995504; Sandhawalia H, 2010, INT CONF ACOUST SPEE, P1242, DOI 10.1109/ICASSP.2010.5495403; Shao J, 2012, PATTERN RECOGN LETT, V33, P271, DOI 10.1016/j.patrec.2011.10.018; Shen FM, 2016, IEEE T IMAGE PROCESS, V25, P5610, DOI 10.1109/TIP.2016.2612883; Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598; Shen FM, 2013, PROC CVPR IEEE, P1562, DOI 10.1109/CVPR.2013.205; Shi XS, 2016, LECT NOTES COMPUT SC, V9911, P419, DOI 10.1007/978-3-319-46478-7_26; Shrivastava Anshumali, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P474, DOI 10.1007/978-3-642-33460-3_36; Shrivastava A, 2014, PR MACH LEARN RES, V32; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Song DJ, 2015, IEEE I CONF COMP VIS, P1922, DOI 10.1109/ICCV.2015.223; Song J., 2013, P 2013 ACM SIGMOD IN, P785, DOI [10.1145/2463676.2465274, DOI 10.1145/2463676.2465274]; Song JK, 2016, IEEE T MULTIMEDIA, V18, P484, DOI 10.1109/TMM.2016.2515990; Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Do TT, 2016, LECT NOTES COMPUT SC, V9906, P802, DOI 10.1007/978-3-319-46475-6_49; Do TT, 2016, LECT NOTES COMPUT SC, V9909, P219, DOI 10.1007/978-3-319-46454-1_14; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Vedaldi A, 2012, PROC CVPR IEEE, P2320, DOI 10.1109/CVPR.2012.6247943; Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153; von Ahn L., 2006, P SIGCHI C HUMAN FAC, P55, DOI DOI 10.1145/1124772.1124782; Wang J., 2014, ARXIV14082927; Wang J., 2010, ICML, P1127; Wang JC, 2014, KEY ENG MATER, V579-580, P517, DOI 10.4028/www.scientific.net/KEM.579-580.517; Wang JF, 2015, IEEE T KNOWL DATA EN, V27, P180, DOI 10.1109/TKDE.2014.2324592; Wang Jianfeng, 2013, P 21 ACM INT C MULTI, P133; Wang J, 2013, IEEE I CONF COMP VIS, P2128, DOI 10.1109/ICCV.2013.265; Wang JD, 2014, IEEE T PATTERN ANAL, V36, P388, DOI 10.1109/TPAMI.2013.125; Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976; Wang J, 2013, IEEE I CONF COMP VIS, P3032, DOI 10.1109/ICCV.2013.377; Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48; Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994; Wang JQ, 2012, PROCEEDINGS OF THE 8TH EURO-ASIA CONFERENCE ON ENVIRONMENT AND CSR: TOURISM, MICE, HOSPITALITY MANAGEMENT AND EDUCATION SESSION, PT III, P179; Wang QF, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P1185, DOI 10.1145/2505515.2507851; Wang XJ, 2016, PROC CVPR IEEE, P2018, DOI 10.1109/CVPR.2016.222; Weiss Y., 2008, P NIPS, P1753; Weiss Y, 2012, LECT NOTES COMPUT SC, V7576, P340, DOI 10.1007/978-3-642-33715-4_25; Wu CX, 2013, IEEE T KNOWL DATA EN, V25, P1380, DOI 10.1109/TKDE.2012.76; Xia RK, 2014, AAAI CONF ARTIF INTE, P2156; Xu B, 2013, P INT JOINT C ART IN, P1820; Xu H, 2011, IEEE I CONF COMP VIS, P1631, DOI 10.1109/ICCV.2011.6126424; Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345; Yang HC, 2014, PROC CVPR IEEE, P1955, DOI 10.1109/CVPR.2014.251; Yang Q., 2013, P 23 INT JOINT C ART, P1855; Yang Yang, 2015, IEEE Transactions on Big Data, V1, P162, DOI 10.1109/TBDATA.2016.2516024; Yu FX, 2014, PR MACH LEARN RES, V32, P946; Zhang D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P18; Zhang HW, 2016, AAAI CONF ARTIF INTE, P3669; Zhang L, 2013, PROCEEDINGS OF THE EIGHTH INTERNATIONAL SYMPOSIUM ON VITICULTURE AND ENOLOGY (2013), P123; Zhang SF, 2016, IEEE DATA MINING, P1347, DOI [10.1109/ICDM.2016.0184, 10.1109/ICDM.2016.100]; Zhang T., 2014, PR MACH LEARN RES, P838; Zhang T, 2016, PROC CVPR IEEE, P2036, DOI 10.1109/CVPR.2016.224; Zhang T, 2015, PROC CVPR IEEE, P4548, DOI 10.1109/CVPR.2015.7299085; Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763; Zhao K, 2014, AAAI CONF ARTIF INTE, P2874; Zhen Y, 2013, DATA MIN KNOWL DISC, V26, P255, DOI 10.1007/s10618-012-0249-y; Zhu X., 2013, P 21 ACM INT C MULTI, P143, DOI [10.1145/2502081.2502107, DOI 10.1145/2502081.2502107]; Zhu XF, 2013, ACM T INFORM SYST, V31, DOI 10.1145/2457465.2457469; Zhuang Y, 2011, P ACM INT C MULT, P1457, DOI DOI 10.1145/2072298.2072039	179	268	272	4	95	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2018	40	4					769	790		10.1109/TPAMI.2017.2699960	http://dx.doi.org/10.1109/TPAMI.2017.2699960			22	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FY2ZU	28475044	Green Published			2022-12-18	WOS:000426687100001
J	Liu, F; Picard, RW				Liu, F; Picard, RW			Periodicity, directionality, and randomness: Wold features for image modeling and retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Wold-based image modeling; pattern analysis; texture modeling; digital libraries; content-based image retrieval	SEGMENTATION	One of the fundamental challenges in pattern recognition is choosing a set of features appropriate to a class of problems. In applications such as database retrieval, it is important that image features used in pattern comparison provide good measures of image perceptual similarities. In this paper, we present an image model with a new set of features that address the challenge of perceptual similarity. The model is based on the 20 Weld decomposition of homogeneous random fields. The three resulting mutually orthogonal subfields have perceptual properties which can be described as ''periodicity,'' ''directionality,'' and ''randomness,'' approximating what are indicated to be the three most important dimensions of human texture perception. The method presented here improves upon earlier Weld-based models in its tolerance to a variety of local inhomogeneities which arise in natural textures and its invariance under image transformation such as rotation. An image retrieval algorithm based on the new texture model is presented. Different types of image features are aggregated for similarity comparison by using a Bayesian probabilistic approach. The effectiveness of the Weld model at retrieving perceptually similar natural textures is demonstrated in comparison to that of two other well-known pattern recognition methods. The Weld model appears to offer a perceptually more satisfying measure of pattern similarity while exceeding the performance of these other methods by traditional pattern recognition criteria. Examples of natural scene Weld texture modeling are also presented.			Liu, F (corresponding author), MIT, MEDIA LAB, 20 AMES ST, CAMBRIDGE, MA 02139 USA.		Picard, Rosalind/A-5095-2009	Picard, Rosalind/0000-0002-5661-0022				Brodatz P., 1966, TEXTURES PHOTOGRAPHI; Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353; FRANCOS JM, 1993, IEEE T SIGNAL PROCES, V41, P2665, DOI 10.1109/78.229897; FRANCOS JM, 1995, IEEE T IMAGE PROCESS, V4, P1655, DOI 10.1109/83.475515; FRANCOS JM, 1993, SIGNAL PROCESSING IT, P207; Francos JM, 1995, ANN APPL PROBAB, V5, P248, DOI 10.1214/aoap/1177004839; FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5; HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; KHOTANZAD A, 1989, IEEE T PATTERN ANAL, V11, P414, DOI 10.1109/34.19038; LIU F, 1994, P INT C PATT REC JER, V2, P184; MANJUNATH BS, 1996, IN PRESS IEEE T PATT; MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5; MARZETTA TL, 1980, IEEE T ACOUST SPEECH, V28, P725, DOI 10.1109/TASSP.1980.1163468; NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173; PENTLAND A, 1995, INT J COMPUTER VISIO; Picard R. W., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P638, DOI 10.1109/CVPR.1993.341050; PICARD RW, 1994, P IEEE C AC SPEECH S, pV129; PICARD RW, 1993, P IEEE C AC SPEECH S, pV161; Rao A. R., 1993, Proceedings Visualization '93. (Cat. No.93CH3354-8), P220, DOI 10.1109/VISUAL.1993.398872; RICHARDSON CH, 1992, SYMBOLIC KNOWLEDGE B, P142; ROSENFELD A, 1979, P IEEE, V67, P764, DOI 10.1109/PROC.1979.11326; Rudin W., 1987, REAL COMPLEX ANAL, V3rd; SRIRAM R, 1994, P ICPR JERUSALEM, V3, P35; TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999; WHITTLE P, 1954, BIOMETRIKA, V41, P434	26	268	277	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1996	18	7					722	733		10.1109/34.506794	http://dx.doi.org/10.1109/34.506794			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UZ457					2022-12-18	WOS:A1996UZ45700004
J	Yin, M; Gao, JB; Lin, ZC				Yin, Ming; Gao, Junbin; Lin, Zhouchen			Laplacian Regularized Low-Rank Representation and Its Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Low-rank representation; graph; Hyper-Laplacian; manifold structure; Laplacian Matrix; regularization	DIMENSIONALITY REDUCTION; FACE RECOGNITION; MATRIX RECOVERY; LEAST-SQUARES; GRAPH; FRAMEWORK	Low-rank representation (LRR) has recently attracted a great deal of attention due to its pleasing efficacy in exploring low-dimensional subspace structures embedded in data. For a given set of observed data corrupted with sparse errors, LRR aims at learning a lowest-rank representation of all data jointly. LRR has broad applications in pattern recognition, computer vision and signal processing. In the real world, data often reside on low-dimensional manifolds embedded in a high-dimensional ambient space. However, the LRR method does not take into account the non-linear geometric structures within data, thus the locality and similarity information among data may be missing in the learning process. To improve LRR in this regard, we propose a general Laplacian regularized low-rank representation framework for data representation where a hypergraph Laplacian regularizer can be readily introduced into, i.e., a Non-negative Sparse Hyper-Laplacian regularized LRR model (NSHLRR). By taking advantage of the graph regularizer, our proposed method not only can represent the global low-dimensional structures, but also capture the intrinsic non-linear geometric information in data. The extensive experimental results on image clustering, semi-supervised image classification and dimensionality reduction tasks demonstrate the effectiveness of the proposed method.	[Yin, Ming] Guangdong Univ Technol, Sch Automat, Guangzhou 510006, Guangdong, Peoples R China; [Yin, Ming] Minist Educ, Key Lab Autonomous Syst & Networked Control, Guangzhou 510640, Guangdong, Peoples R China; [Gao, Junbin] Charles Sturt Univ, Sch Comp & Math, Bathurst, NSW 2795, Australia; [Lin, Zhouchen] Peking Univ, Sch EECS, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China; [Lin, Zhouchen] Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Shanghai 200240, Peoples R China	Guangdong University of Technology; Charles Sturt University; Peking University; Shanghai Jiao Tong University	Yin, M (corresponding author), Guangdong Univ Technol, Sch Automat, Guangzhou 510006, Guangdong, Peoples R China.; Yin, M (corresponding author), Minist Educ, Key Lab Autonomous Syst & Networked Control, Guangzhou 510640, Guangdong, Peoples R China.; Gao, JB (corresponding author), Charles Sturt Univ, Sch Comp & Math, Bathurst, NSW 2795, Australia.; Lin, ZC (corresponding author), Peking Univ, Sch EECS, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China.; Lin, ZC (corresponding author), Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Shanghai 200240, Peoples R China.	yiming@gdut.edu.cn; jbgao@csu.edu.au; zlin@pku.edu.cn	Gao, Junbin/C-6566-2008; Gao, Junbin/A-1766-2009	Gao, Junbin/0000-0001-9803-0256; Yin, Ming/0000-0002-7037-1048	Australian Research Council (ARC) [DP130100364]; Foundation of Key Laboratory of Autonomous Systems and Networked Control, Ministry of Education, P.R. China [2013A06]; Guangdong Natural Science Foundation [2014A030313511]; National Natural Science Foundation (NSF) of China [61333013, 61322306, 61272341, 61231002]; National Basic Research Program of China (973 Program) [2015CB352502]; Microsoft Research Asia Collaborative Research Program	Australian Research Council (ARC)(Australian Research Council); Foundation of Key Laboratory of Autonomous Systems and Networked Control, Ministry of Education, P.R. China(Ministry of Education, China); Guangdong Natural Science Foundation(National Natural Science Foundation of Guangdong Province); National Natural Science Foundation (NSF) of China(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China (973 Program)(National Basic Research Program of China); Microsoft Research Asia Collaborative Research Program(Microsoft)	The research project is supported by the Australian Research Council (ARC) through the grant DP130100364. Ming Yin is supported by the Foundation of Key Laboratory of Autonomous Systems and Networked Control, Ministry of Education, P.R. China (No. 2013A06), and Guangdong Natural Science Foundation (No. 2014A030313511) also in part supported by National Natural Science Foundation (NSF) of China (grant nos. 61333013 and 61322306). Zhouchen Lin is supported by National Basic Research Program of China (973 Program) (grant no. 2015CB352502), National Natural Science Foundation (NSF) of China (grant nos. 61272341 and 61231002), and Microsoft Research Asia Collaborative Research Program. Zhouchen Lin is the corresponding author.	[Anonymous], 2009, P INT WORKSH COMP AD; Babacan SD, 2012, IEEE T SIGNAL PROCES, V60, P3964, DOI 10.1109/TSP.2012.2197748; Belkin M, 2002, ADV NEUR IN, V14, P585; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bull G., 2012, PUBL N CAROLINA COOP, P1; Cai D, 2007, IEEE DATA MINING, P73, DOI 10.1109/ICDM.2007.89; Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231; Cai D, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1010; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Chen CF, 2012, PROC CVPR IEEE, P2618, DOI 10.1109/CVPR.2012.6247981; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S1064827596304010; Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764; Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; De la Torre F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P362, DOI 10.1109/ICCV.2001.937541; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Doyle P. G., 1984, RANDOM WALKS ELECT N; Gao JB, 2008, NEURAL COMPUT, V20, P555, DOI 10.1162/neco.2007.11-06-397; Gao SH, 2013, IEEE T PATTERN ANAL, V35, P92, DOI 10.1109/TPAMI.2012.63; Hadsell R., 2006, 2006 IEEE COMPUTER S, P1735, DOI DOI 10.1109/CVPR.2006.100; He XF, 2005, IEEE I CONF COMP VIS, P1208; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; He XF, 2011, IEEE T KNOWL DATA EN, V23, P1406, DOI 10.1109/TKDE.2010.259; Ji S., 2009, P 26 ANN INT C MACH, P457, DOI DOI 10.1145/1553374.1553434; Jolliffe IT, 2002, ENCY STATIST BEHAV S, DOI [10.1007/0-387-22440-8_13, 10.1007/b98835]; Kim H, 2008, SIAM J MATRIX ANAL A, V30, P713, DOI 10.1137/07069239X; Li Pu, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P410, DOI 10.1007/978-3-642-33460-3_32; Lin Z., 2013, J MACH LEARN RES, P1; Lin Z., 2011, PROC INT 25 C NEURAL, P612, DOI DOI 10.1007/S11263-013-0611-6; Lin Z, 2009, UILUENG092215 UIUC; Liu G., 2010, P 27 INT C MACHINE L, P663, DOI DOI 10.1109/ICDMW.2010.64; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu GC, 2011, IEEE I CONF COMP VIS, P1615, DOI 10.1109/ICCV.2011.6126422; Liu Guangcan, 2012, J MACH LEARN RES P T, P703; Lu XQ, 2013, IEEE T GEOSCI REMOTE, V51, P4009, DOI 10.1109/TGRS.2012.2226730; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Tao M, 2011, SIAM J OPTIMIZ, V21, P57, DOI 10.1137/100781894; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Toh KC, 2010, PAC J OPTIM, V6, P615; Wang JD, 2009, IEEE T PATTERN ANAL, V31, P1600, DOI 10.1109/TPAMI.2008.216; Wen ZW, 2010, MATH PROGRAM COMPUT, V2, P203, DOI 10.1007/s12532-010-0017-1; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Wright Y., 2009, ADV NEURAL INFORM PR, V22, DOI DOI 10.5555/2984093.2984326; Wu L., 2012, IEEE T PAT UNPUB AUG; Yang SY, 2013, IET IMAGE PROCESS, V7, P131, DOI 10.1049/iet-ipr.2012.0322; Yin M, 2013, IEEE IMAGE PROC, P3770, DOI 10.1109/ICIP.2013.6738777; Zhang Zhengdong, 2010, P AS C COMP VIS; Zhang ZY, 2013, IEEE T PATTERN ANAL, V35, P1717, DOI 10.1109/TPAMI.2012.274; Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535; Zheng YG, 2013, NEUROCOMPUTING, V122, P398, DOI 10.1016/j.neucom.2013.06.013; Zhou D., 2006, ADV NEURAL INF PROCE, V19, P1601; Zhu Xiaojin., 2003, P ICLR, P912; Zhuang LS, 2012, PROC CVPR IEEE, P2328, DOI 10.1109/CVPR.2012.6247944	56	267	286	13	162	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2016	38	3					504	517		10.1109/TPAMI.2015.2462360	http://dx.doi.org/10.1109/TPAMI.2015.2462360			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE6JD	27046494				2022-12-18	WOS:000370738900007
J	Karsch, K; Liu, C; Kang, SB				Karsch, Kevin; Liu, Ce; Kang, Sing Bing			DepthTransfer: Depth Extraction from Video Using Non-Parametric Sampling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Depth estimation; monocular depth; motion estimation; data-driven; 2D-to-3D	SCENE	We describe a technique that automatically generates plausible depth maps from videos using non-parametric depth sampling. We demonstrate our technique in cases where past methods fail (non-translating cameras and dynamic scenes). Our technique is applicable to single images as well as videos. For videos, we use local motion cues to improve the inferred depth maps, while optical flow is used to ensure temporal depth consistency. For training and evaluation, we use a Kinect-based system to collect a large data set containing stereoscopic videos with known depths. We show that our depth estimation technique outperforms the state-of-the-art on benchmark databases. Our technique can be used to automatically convert a monoscopic video into stereo for 3D visualization, and we demonstrate this through a variety of visually pleasing results for indoor and outdoor scenes, including results from the feature film Charade.	[Karsch, Kevin] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; [Liu, Ce] Microsoft Res New England, Cambridge, MA 02142 USA; [Kang, Sing Bing] Microsoft Res, Redmond, WA 98052 USA	University of Illinois System; University of Illinois Urbana-Champaign; Microsoft; Microsoft	Karsch, K (corresponding author), Univ Illinois, Dept Comp Sci, 1304 W Springfield Ave, Urbana, IL 61801 USA.	karsch1@illinois.edu; celiu@microsoft.com; sbkang@microsoft.com						[Anonymous], 2006, P 2006 IEEE COMP SOC, DOI DOI 10.1109/CVPR.2006.23; Batra D, 2012, PROC CVPR IEEE, P2136, DOI 10.1109/CVPR.2012.6247920; Changchang Wu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3113, DOI 10.1109/CVPR.2011.5995551; Colombari A., 2005, P IEE EUR C VIS MED, P194; Guttmann M, 2009, IEEE I CONF COMP VIS, P136, DOI 10.1109/ICCV.2009.5459158; Han F, 2003, FIRST IEEE INTERNATIONAL WORKSHOP ON HIGHER-LEVEL KNOWLEDGE IN 3D MODELING AND MOTION ANALYSIS, PROCEEDINGS, P12; Hassner T., 2006, 2006 C COMP VIS PATT, P15, DOI DOI 10.1109/CVPRW.2006.76; He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168; Heikkila M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68; Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232; Hoiem D., 2007, INT J COMPUT VISION, V91, P328; Horry Y., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P225, DOI 10.1145/258734.258854; Klein Gunnewiek R., 2009, P SPIE, V723713; Konrad J., 2012, PROC SPIE, V82880F; Konrad J., 2012, P IEEE COMP SOC C CO, P16; Koppal SJ, 2011, IEEE COMPUT GRAPH, V31, P20, DOI 10.1109/MCG.2010.37; Li C., 2010, ADV NEURAL INFORM PR, V23, P1351; Liao M, 2012, IEEE T VIS COMPUT GR, V18, P1079, DOI 10.1109/TVCG.2011.114; Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823; Liu C., 2009, THESIS MIT CAMBRIDGE; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131; Liu C, 2009, PROC CVPR IEEE, P1972, DOI 10.1109/CVPRW.2009.5206536; Luo K, 2009, J ZHEJIANG UNIV-SC A, V10, P1738, DOI 10.1631/jzus.A0820806; Maire M., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587420; Oh BM, 2001, COMP GRAPH, P433; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253; Rubinstein M, 2012, LECT NOTES COMPUT SC, V7574, P85, DOI 10.1007/978-3-642-33712-3_7; Saxena A., 2005, ADV NEURAL INFO P SY, V18; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Sheikh Y., 2009, IEEE 12 INT C COMP V; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Tappen MF, 2012, LECT NOTES COMPUT SC, V7578, P236, DOI 10.1007/978-3-642-33786-4_18; Van Pernis A., 2008, SPIE; Wang OL, 2011, PITUITARY, 3RD EDITION, P47, DOI 10.1016/B978-0-12-380926-1.10003-3; Ward B, 2011, IEEE COMPUT GRAPH, V31, P36, DOI 10.1109/MCG.2010.103; Zhang GF, 2011, IEEE T PATTERN ANAL, V33, P603, DOI 10.1109/TPAMI.2010.115; Zhang GF, 2009, IEEE T VIS COMPUT GR, V15, P828, DOI 10.1109/TVCG.2009.47; Zhang GF, 2009, IEEE T PATTERN ANAL, V31, P974, DOI 10.1109/TPAMI.2009.52; Zhang L, 2002, J VISUAL COMP ANIMAT, V13, P225, DOI 10.1002/vis.291; Zhang L, 2011, IEEE T BROADCAST, V57, P372, DOI 10.1109/TBC.2011.2122930	42	267	288	1	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2014	36	11					2144	2158		10.1109/TPAMI.2014.2316835	http://dx.doi.org/10.1109/TPAMI.2014.2316835			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR6OI	26353057	Green Submitted			2022-12-18	WOS:000343702400003
J	Li, J; Wang, JZ				Li, Jia; Wang, James Z.			Real-time computerized annotation of pictures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image annotation; tagging; statistical learning; modeling; clustering		Developing effective methods for automated annotation of digital pictures continues to challenge computer scientists. The capability of annotating pictures by computers can lead to breakthroughs in a wide range of applications, including Web image search, online picture-sharing communities, and scientific experiments. In this work, the authors developed new optimization and estimation techniques to address two fundamental problems in machine learning. These new techniques serve as the basis for the Automatic Linguistic Indexing of Pictures-Real Time (ALIPR) system of fully automatic and high-speed annotation for online pictures. In particular, the D2-clustering method, in the same spirit as K-Means for vectors, is developed to group objects represented by bags of weighted vectors. Moreover, a generalized mixture modeling technique (kernel smoothing as a special case) for nonvector data is developed using the novel concept of Hypothetical Local Mapping (HLM). ALIPR has been tested by thousands of pictures from an Internet photo-sharing site, unrelated to the source of those pictures used in the training process. Its performance has also been studied at an online demonstration site, where arbitrary users provide pictures of their choices and indicate the correctness of each annotation word. The experimental results show that a single computer processor can suggest annotation terms in real time and with good accuracy.	[Li, Jia] Penn State Univ, Dept Stat, University Pk, PA 16802 USA; [Wang, James Z.] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; [Wang, James Z.] Penn State Univ, Coll Informat Sci & Technol, University Pk, PA 16802 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park; Carnegie Mellon University; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park	Li, J (corresponding author), Penn State Univ, Dept Stat, University Pk, PA 16802 USA.	jiali@stat.psu.edu; jwang@ist.psu.edu		Wang, James/0000-0003-4379-4173				BAGDANOV A, 2007, P INT WORKSH MULT IN, P79; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Beymer D, 1996, SCIENCE, V272, P1905, DOI 10.1126/science.272.5270.1905; Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61; Chang SF, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P531, DOI 10.1109/ICIP.1998.727321; Chen YX, 2004, J MACH LEARN RES, V5, P913; DATTA R, 2008, IN PRESS ACM COMPUTI; Daubechies I., 1992, SOC IND APPL MATH, DOI [10.1137/1.9781611970104, DOI 10.1137/1.9781611970104]; Evans M., 2000, STAT DISTRIBUTIONS; Gonzalez R.C., 2006, DIGITAL IMAGE PROCES; Hastie T, 2009, ELEMENTS STAT LEARNI; HE J, 2004, P 6 ACM SIGMM INT WO, P15; He X., 2004, P 12 ANN ACM INT C M, P17, DOI [10.1145/1027527.1027532, DOI 10.1145/1027527.1027532]; Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MALLOWS CL, 1972, ANN MATH STAT, V43, P508, DOI 10.1214/aoms/1177692631; Mclachlan G., 2000, WILEY SER PROB STAT; Monay F, 2003, P 11 ACM INT C MULT, P275, DOI DOI 10.1145/957013.957070; Quack T., 2004, P 12 ANN ACM INT C M, P508; Rachev S., 1984, THEOR PROBAB APPL+, V29, P625, DOI 10.1137/1129093; Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701; Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510; Singh PJ, 2003, INT J FATIGUE, V25, P1, DOI 10.1016/S0142-1123(02)00067-1; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151; Tieu K, 2004, INT J COMPUT VISION, V56, P17, DOI 10.1023/B:VISI.0000004830.93820.78; Tomasi C, 2004, NATURE, V428, P378, DOI 10.1038/428378a; Tong S., 2001, PROC ACM INT C MULTI, V9, P107; Vasconcelos N, 2005, IEEE T MULTIMEDIA, V7, P127, DOI 10.1109/TMM.2004.840596; Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109; WANG JZ, 2002, P 10 ACM INT C MULT, P436; Zhang C, 2002, IEEE T MULTIMEDIA, V4, P260, DOI 10.1109/TMM.2002.1017738	34	267	281	1	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2008	30	6					985	1002		10.1109/TPAMI.2007.70847	http://dx.doi.org/10.1109/TPAMI.2007.70847			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	286UW	18421105				2022-12-18	WOS:000254872500005
J	Dosovitskiy, A; Fischer, P; Springenberg, JT; Riedmiller, M; Brox, T				Dosovitskiy, Alexey; Fischer, Philipp; Springenberg, Jost Tobias; Riedmiller, Martin; Brox, Thomas			Discriminative Unsupervised Feature Learning with Exemplar Convolutional Neural Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolutional networks; unsupervised learning; feature learning; image classification; descriptor matching		Deep convolutional networks have proven to be very successful in learning task specific features that allow for unprecedented performance on various computer vision tasks. Training of such networks follows mostly the supervised learning paradigm, where sufficiently many input-output pairs are required for training. Acquisition of large training sets is one of the key challenges, when approaching a new task. In this paper, we aim for generic feature learning and present an approach for training a convolutional network using only unlabeled data. To this end, we train the network to discriminate between a set of surrogate classes. Each surrogate class is formed by applying a variety of transformations to a randomly sampled 'seed' image patch. In contrast to supervised network training, the resulting feature representation is not class specific. It rather provides robustness to the transformations that have been applied during training. This generic feature representation allows for classification results that outperform the state of the art for unsupervised learning on several popular datasets (STL-10, CIFAR-10, Caltech-101, Caltech-256). While features learned with our approach cannot compete with class specific features from supervised training on a classification task, we show that they are advantageous on geometric matching problems, where they also outperform the SIFT descriptor.	[Dosovitskiy, Alexey; Fischer, Philipp; Springenberg, Jost Tobias; Riedmiller, Martin; Brox, Thomas] Univ Freiburg, Dept Comp Sci, Freiburg, Germany	University of Freiburg	Dosovitskiy, A (corresponding author), Univ Freiburg, Dept Comp Sci, Freiburg, Germany.	dosovits@cs.uni-freiburg.de; fischer@cs.uni-freiburg.de; springj@cs.uni-freiburg.de; riedmiller@cs.uni-freiburg.de; brox@cs.uni-freiburg.de			ERC Starting Grant VideoLearn [279401]; BrainLinks-BrainTools Cluster of Excellence - German Research Foundation [EXC 1086]; Deutsche Telekom Stifung	ERC Starting Grant VideoLearn; BrainLinks-BrainTools Cluster of Excellence - German Research Foundation; Deutsche Telekom Stifung	Alexey Dosovitskiy, Philipp Fischer, and Thomas Brox acknowledge funding by the ERC Starting Grant VideoLearn (279401). Jost Tobias Springenberg and Martin Riedmiller are supported by the BrainLinks-BrainTools Cluster of Excellence funded by the German Research Foundation (EXC 1086). Philipp Fischer acknowledges a fellowship by the Deutsche Telekom Stifung.	Ahmed A, 2008, LECT NOTES COMPUT SC, V5304, P69, DOI 10.1007/978-3-540-88690-7_6; Amini MR, 2002, FR ART INT, V77, P390; [Anonymous], 2014, 2 INT C LEARN REPR I; [Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Bo L., 2012, EXPT ROBOTICS, V88, P387; Bo LF, 2013, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2013.91; Boureau YL, 2011, IEEE I CONF COMP VIS, P2651, DOI 10.1109/ICCV.2011.6126555; Coates A., 2011, ADV NEURAL INFORM PR, P2528, DOI DOI 10.1016/J.PSYCHRES.2009.03.008; Coates Adam, 2011, AISTATS, V6, DOI DOI 10.1177/1753193410390845; Collobert R, 2011, J MACH LEARN RES, V12, P2493; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Donahue J, 2014, PR MACH LEARN RES, V32; DRUCKER H, 1992, IEEE T NEURAL NETWOR, V3, P991, DOI 10.1109/72.165600; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Grandvalet Y., 2006, SEMISUPERVISED LEARN, P1, DOI [10.7551/mitpress/9780262033589.001.0001, DOI 10.7551/MITPRESS/9780262033589.001.0001]; Griffin Gregory, 2007, CALTECH 256 OBJECT C; Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Hinton G. E., 2012, ARXIVCS12070580V3; Hui K. Y, 2013, INT C MACH LEARN, P352; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Jia Y., P ACM MULT, P675; Kavukcuoglu Koray, 2010, ADV NEURAL INFORM PR, V23, P1090; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Krizhevsky Alex., 2009, LEARNING MULTIPLE LA, P6; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI 10.1109/CVPR.2015.7298965; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Rifai S., 2011, P ADV NEUR INF PROC; Saxe A. M., 2011, P ICML, P1089; Simard P., 1992, ADV NEURAL INFORM PR, P895; Singh S, 2012, LECT NOTES COMPUT SC, V7573, P73, DOI 10.1007/978-3-642-33709-3_6; Sohn Kihyuk, 2012, ICML; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Swersky K., 2013, ADV NEURAL INFORM PR, P2004, DOI DOI 10.1038/S41598-021-83582-6; Vincent P., 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Wager Stefan, 2013, ADV NEURAL INFORM PR, P351; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zou W., 2012, ADV NEURAL INFORM PR, P3203; Zuo Z, 2014, LECT NOTES COMPUT SC, V8689, P552, DOI 10.1007/978-3-319-10590-1_36	46	265	276	2	54	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2016	38	9					1734	1747		10.1109/TPAMI.2015.2496141	http://dx.doi.org/10.1109/TPAMI.2015.2496141			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DT4EK	26540673	Green Submitted			2022-12-18	WOS:000381432700002
J	Lin, T; Zha, HB				Lin, Tong; Zha, Hongbin			Riemannian manifold learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						dimensionality reduction; manifold learning; manifold reconstruction; Riemannian manifolds; Riemannian normal coordinates	NONLINEAR DIMENSIONALITY REDUCTION; INTRINSIC DIMENSIONALITY; DIFFUSION MAPS; EIGENMAPS; FRAMEWORK; DESIGN	Recently, manifold learning has been widely exploited in pattern recognition, data analysis, and machine learning. This paper presents a novel framework, called Riemannian manifold learning (RML), based on the assumption that the input high-dimensional data lie on an intrinsically low-dimensional Riemannian manifold. The main idea is to formulate the dimensionality reduction problem as a classical problem in Riemannian geometry, that is, how to construct coordinate charts for a given Riemannian manifold? We implement the Riemannian normal coordinate chart, which has been the most widely used in Riemannian geometry, for a set of unorganized data points. First, two input parameters (the neighborhood size k and the intrinsic dimension d) are estimated based on an efficient simplicial reconstruction of the underlying manifold. Then, the normal coordinates are computed to map the input high-dimensional data into a low-dimensional space. Experiments on synthetic data, as well as real-world images, demonstrate that our algorithm can learn intrinsic geometric structures of the data, preserve radial geodesic distances, and yield regular embeddings.	[Lin, Tong; Zha, Hongbin] Peking Univ, Sch EECS, Key Lab Machine Percept, Beijing 100871, Peoples R China	Peking University	Lin, T (corresponding author), Peking Univ, Sch EECS, Key Lab Machine Percept, Sci Bldg, Beijing 100871, Peoples R China.	lintong@cis.pku.edu.cn; zha@cis.pku.edu.cn						Atiyah M, 2002, B LOND MATH SOC, V34, P1, DOI 10.1112/S0024609301008566; Balasubramanian M, 2002, SCIENCE, V295; BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bengio Y, 2004, ADV NEUR IN, V16, P177; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Brand  M., 2003, ADV NEURAL INFORM PR, P961, DOI DOI 10.1109/34.682189; Brun A, 2005, LECT NOTES COMPUT SC, V3540, P920; Bruske J, 1998, IEEE T PATTERN ANAL, V20, P572, DOI 10.1109/34.682189; Camastra F, 2002, IEEE T PATTERN ANAL, V24, P1404, DOI 10.1109/TPAMI.2002.1039212; Camastra F, 2003, PATTERN RECOGN, V36, P2945, DOI 10.1016/S0031-3203(03)00176-6; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P31, DOI 10.1016/j.acha.2005.07.005; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006; CORMEN TH, 2001, INTRO ALGORTITHMS; Cox T.F., 1994, MULTIDIMENSIONAL SCA; Cramer J.S., 2003, ORIGINS LOGISTIC REG; DESILVA V, 2003, ADV NEURAL INFORM PR, V15, P705; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100; Donoho DL, 2002, 200227 STANF U DEP S; DONOHO DL, 2000, P AMS MATH CHALL 21; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; EBERLY D, 2005, COMPUTING GEODESICS; EBERLY D, 1999, DISTANCE POINT GEN Q; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; Freedman D, 2002, IEEE T PATTERN ANAL, V24, P1349, DOI 10.1109/TPAMI.2002.1039206; Fukunaga K., 1976, IEEE T COMPUT, V20, P165; GOLUB GH, 2004, CONSTRAINED LEAST SQ; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Jolliffe I., 1989, APPL OPTICS; Jost J., 2008, RIEMANNIAN GEOMETRY, V42005; Kegl B, 2000, IEEE T PATTERN ANAL, V22, P281, DOI 10.1109/34.841759; Kohonen T, 2001, SELF ORGANIZING MAPS; Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1393, DOI 10.1109/TPAMI.2006.184; Law MHC, 2006, IEEE T PATTERN ANAL, V28, P377, DOI 10.1109/TPAMI.2006.56; Lee John M, 2018, INTRO RIEMANNIAN MAN; Levina E., 2005, ADV NEURAL INFORM PR, V17, P777, DOI DOI 10.5555/2976040.2976138; Lin T, 2006, LECT NOTES COMPUT SC, V3951, P44; Nadler B, 2006, APPL COMPUT HARMON A, V21, P113, DOI 10.1016/j.acha.2005.07.004; PETTIS KW, 1979, IEEE T PATTERN ANAL, V1, P25, DOI 10.1109/TPAMI.1979.4766873; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; RAGINSKY M, 2005, P ADV NEURAL INFORM; Riemann B, 1873, NATURE, V8, P14; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268; SHA F, 2005, P 22 INT C MACH LEAR, P785; Smolinski P, 2001, COMPUT APPL ENG EDUC, V9, P1, DOI 10.1002/cae.1000; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TRUNK GV, 1976, IEEE T COMPUT, V25, P165, DOI 10.1109/TC.1976.5009231; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; VERVEER PJ, 1995, IEEE T PATTERN ANAL, V17, P81, DOI 10.1109/34.368147; Wang A, 2005, IIE TRANS, V37, P17, DOI 10.1080/07408170590516773; Weinberger KQ, 2004, PROC CVPR IEEE, P988; Wittman T, 2005, MANI MATLAB DEMO; Yang J, 2005, IEEE T PATTERN ANAL, V27, P230, DOI 10.1109/TPAMI.2005.33; Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154; [No title captured]	57	265	304	7	65	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2008	30	5					796	809		10.1109/TPAMI.2007.70735	http://dx.doi.org/10.1109/TPAMI.2007.70735			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	272SI	18369250				2022-12-18	WOS:000253879700004
J	Alpert, S; Galun, M; Brandt, A; Basri, R				Alpert, Sharon; Galun, Meirav; Brandt, Achi; Basri, Ronen			Image Segmentation by Probabilistic Bottom-Up Aggregation and Cue Integration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; image segmentation; cue integration; segmentation evaluation	COLOR	We present a bottom-up aggregation approach to image segmentation. Beginning with an image, we execute a sequence of steps in which pixels are gradually merged to produce larger and larger regions. In each step, we consider pairs of adjacent regions and provide a probability measure to assess whether or not they should be included in the same segment. Our probabilistic formulation takes into account intensity and texture distributions in a local area around each region. It further incorporates priors based on the geometry of the regions. Finally, posteriors based on intensity and texture cues are combined using "a mixture of experts" formulation. This probabilistic approach is integrated into a graph coarsening scheme, providing a complete hierarchical segmentation of the image. The algorithm complexity is linear in the number of the image pixels and it requires almost no user-tuned parameters. In addition, we provide a novel evaluation scheme for image segmentation algorithms, attempting to avoid human semantic considerations that are out of scope for segmentation algorithms. Using this novel evaluation scheme, we test our method and provide a comparison to several existing segmentation algorithms.	[Alpert, Sharon; Galun, Meirav; Brandt, Achi; Basri, Ronen] Weizmann Inst Sci, Fac Math & Comp Sci, IL-76100 Rehovot, Israel	Weizmann Institute of Science	Alpert, S (corresponding author), Weizmann Inst Sci, Fac Math & Comp Sci, POB 26, IL-76100 Rehovot, Israel.	sharon.alpert@weizmann.ac.il; meirav.galun@weizmann.ac.il; achi.brandt@weizmann.ac.il; ronen.basri@weizmann.ac.il			European Community [IST-2002-506766 Aim@Shape]; US-Israel Binational Science Foundation [2002/254]; A.M.N. Fund for the promotion of science, culture, and arts in Israel; Israel Institute of Technology; Moross Foundation	European Community(European Commission); US-Israel Binational Science Foundation(US-Israel Binational Science Foundation); A.M.N. Fund for the promotion of science, culture, and arts in Israel; Israel Institute of Technology; Moross Foundation	Research was supported in part by the European Community grant IST-2002-506766 Aim@Shape, by the US-Israel Binational Science Foundation grant number 2002/254, by the A.M.N. Fund for the promotion of science, culture, and arts in Israel, and by the Israel Institute of Technology. The vision group at the Weizmann Institute is supported in part by the Moross Foundation.	Alpert S, 2007, P IEEE C COMP VIS PA; Arbelaez P., 2010, UCBEECS201017; BRANNIGAN A, 1986, AUST NZ J CRIMINOL, V19, P23, DOI 10.1016/0096-3003(86)90095-0; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cour T, 2005, PROC CVPR IEEE, P1124; Cox I. J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P557, DOI 10.1109/ICPR.1996.546886; Cremers D, 2003, PROC CVPR IEEE, P53; Duda R.O., 2000, PATTERN CLASSIFICATI; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Ge F., 2006, IEEE COMP SOC C COMP, V1, P1146, DOI DOI 10.1109/CVRR.2006.147; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Liu C., 2006, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2006.207; Ma Y, 2007, IEEE T PATTERN ANAL, V29, P1546, DOI 10.1109/TP'AMI.2007.1085; MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923; Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800; MANJUNATH BS, 1991, IEEE T PATTERN ANAL, V13, P478, DOI 10.1109/34.134046; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; Nguyen HT, 2006, IEEE COMP SOC C COMP, V2006, P985; PANJWANI DK, 1995, IEEE T PATTERN ANAL, V17, P939, DOI 10.1109/34.464559; PAVLIDIS T, 1990, IEEE T PATTERN ANAL, V12, P225, DOI 10.1109/34.49050; Rabinovich A., 2006, P IEEE C COMP VIS PA, P1130; Ren X., 2005, P ADV NEUR INF PROC; Sethian J, 1998, LEVEL SET METHODS FA; Sharon E, 2006, NATURE, V442, P810, DOI 10.1038/nature04977; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Van Rijsbergen CJ, 1979, INFORM RETRIEVAL; Veksler O, 2000, PROC CVPR IEEE, P339, DOI 10.1109/CVPR.2000.855838; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; Wang S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P517, DOI 10.1109/ICCV.2001.937560; Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P975, DOI 10.1109/ICCV.1999.790354; WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673; [No title captured]	38	264	292	2	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2012	34	2					315	327		10.1109/TPAMI.2011.130	http://dx.doi.org/10.1109/TPAMI.2011.130			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	862PJ	21690639	Green Submitted			2022-12-18	WOS:000298105500010
J	Ling, H; Okada, K				Ling, Haibin; Okada, Kazunori			An efficient Earth Mover's Distance algorithm for robust histogram comparison	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Earth Mover's Distance; transportation problem; histogram-based descriptor; SIFT; shape context; spin image; shape matching; interest point matching	TEXTURE REPRESENTATION; OBJECT RECOGNITION; COLOR	We propose EMD-L-1: a fast and exact algorithm for computing the Earth Mover's Distance ( EMD) between a pair of histograms. The efficiency of the new algorithm enables its application to problems that were previously prohibitive due to high time complexities. The proposed EMD-L-1 significantly simplifies the original linear programming formulation of EMD. Exploiting the L-1 metric structure, the number of unknown variables in EMD-L-1 is reduced to O(N) from O(N-2) of the original EMD for a histogram with N bins. In addition, the number of constraints is reduced by half and the objective function of the linear program is simplified. Formally, without any approximation, we prove that the EMD-L-1 formulation is equivalent to the original EMD with a L-1 ground distance. To perform the EMD-L-1 computation, we propose an efficient tree-based algorithm, Tree-EMD. Tree-EMD exploits the fact that a basic feasible solution of the simplex algorithm-based solver forms a spanning tree when we interpret EMD-L-1 as a network flow optimization problem. We empirically show that this new algorithm has an average time complexity of O(N-2), which significantly improves the best reported supercubic complexity of the original EMD. The accuracy of the proposed methods is evaluated by experiments for two computation-intensive problems: shape recognition and interest point matching using multidimensional histogram-based local features. For shape recognition, EMD-L-1 is applied to compare shape contexts on the widely tested MPEG7 shape data set, as well as an articulated shape data set. For interest point matching, SIFT, shape context and spin image are tested on both synthetic and real image pairs with large geometrical deformation, illumination change, and heavy intensity noise. The results demonstrate that our EMD-L-1-based solutions outperform previously reported state-of-the-art features and distance measures in solving the two tasks.	Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA; Univ Maryland, UMIACS, College Pk, MD 20742 USA; San Francisco State Univ, Dept Comp Sci, San Francisco, CA 94132 USA	University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park; California State University System; San Francisco State University	Ling, H (corresponding author), Univ Maryland, Dept Comp Sci, A V Williams Bldg, College Pk, MD 20742 USA.	hbling@umiacs.umd.edu; kazokada@sfsu.edu	Okada, Kazunori/A-3385-2008	Okada, Kazunori/0000-0002-4060-2829				Ahuja R. K., 1993, NETWORK FLOWS THEORY; Androutsos D, 1999, COMPUT VIS IMAGE UND, V75, P46, DOI 10.1006/cviu.1999.0767; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Cohen S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1076, DOI 10.1109/ICCV.1999.790393; Darabiha A, 2003, PROC CVPR IEEE, P203; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; Grauman K, 2004, PROC CVPR IEEE, P220; Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P1274, DOI 10.1109/TIP.2003.816010; HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Hillier F.S., 1990, INTRO MATH PROGRAMMI; Hitchcock F.L., 1941, J MATH PHYS, V20, P224, DOI DOI 10.1002/SAPM1941201224; Holmes AS, 2002, IMAGE VISION COMPUT, V20, P331, DOI 10.1016/S0262-8856(02)90005-3; Holmes AS, 2002, IMAGE VISION COMPUT, V20, P701, DOI 10.1016/S0262-8856(02)00060-4; INDYK P, 2003, P 3 WORKSH STAT COMP; Jalba AC, 2006, IEEE T IMAGE PROCESS, V15, P331, DOI 10.1109/TIP.2005.860606; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; JONES DG, 1992, LECT NOTES COMPUT SC, V588, P395; KARMARKAR N, 1984, COMBINATORICA, V4, P373, DOI 10.1007/BF02579150; Ke Y, 2004, PROC CVPR IEEE, P506; Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850; Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; LING H, 2006, P EUR C COMP VIS, V3, P330; Ling HB, 2005, IEEE I CONF COMP VIS, P1466; Ling HB, 2005, PROC CVPR IEEE, P719; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MALLOWS CL, 1972, ANN MATH STAT, V43, P508, DOI 10.1214/aoms/1177692631; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; MOKHTARIAN F, 1997, EFFICIENT ROBUST RET, P51; MORI G, 2003, P IEEE C COMP VIS PA, V1, P1063; Mortensen EN, 2005, PROC CVPR IEEE, P184; NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173; Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648; Papadimitriou C. H., 1982, COMBINATORIAL OPTIMI; PELEG S, 1989, IEEE T PATTERN ANAL, V11, P739, DOI 10.1109/34.192468; RACHEV ST, 1984, THEOR PROBAB APPL, V29; Rubner Y, 2001, COMPUT VIS IMAGE UND, V84, P25, DOI 10.1006/cviu.2001.0934; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Rubner Yossi, 2001, PERCEPTUAL METRICS I; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; SHEN HC, 1983, COMPUT VISION GRAPH, V23, P187, DOI 10.1016/0734-189X(83)90112-3; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tan HK, 2005, IEEE I CONF COMP VIS, P1222; Thayananthan A, 2003, PROC CVPR IEEE, P127; Tu ZW, 2004, LECT NOTES COMPUT SC, V3023, P195; WERMAN M, 1985, COMPUT VISION GRAPH, V32, P328, DOI 10.1016/0734-189X(85)90055-6; Wesolowsky G. O., 1993, Location Science, V1, P5; ZHU J, 2003, 1NORM SUPPORT VECTOR, P16	51	264	280	3	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2007	29	5					840	853		10.1109/TPAMI.2007.1058	http://dx.doi.org/10.1109/TPAMI.2007.1058			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HK	17356203				2022-12-18	WOS:000244855700007
J	Pelillo, M; Siddiqi, K; Zucker, SW				Pelillo, M; Siddiqi, K; Zucker, SW			Matching hierarchical structures using association graphs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						maximal subtree isomorphisms; association graphs; maximal cliques; replicator dynamical systems; shock trees; shape recognition	MAXIMUM CLIQUE PROBLEM; OPTIMIZATION PROBLEMS; ALGORITHM; RECOGNITION; SHAPE; DYNAMICS; NETWORKS	It is well-known that the problem of matching two relational structures can be posed as an equivalent problem of finding a maximal clique in a (derived) "association graph." However, it is not clear how to apply this approach to computer vision problems where the graphs are hierarchically organized, i.e., are trees, since maximal cliques are not constrained to preserve the partial order. Here, we provide a solution to the problem of matching two trees by constructing the association graph using the graph-theoretic concept of connectivity. We prove that, in the new formulation, there is a one-to-one correspondence between maximal cliques and maximal subtree isomorphisms. This allows us to cast the tree matching problem as an indefinite quadratic program using the Motzkin-Straus theorem, and we use "replicator" dynamical systems developed in theoretical biology to solve it. Such continuous solutions to discrete problems are attractive because they can motivate analog and biological implementations. The framework is also extended to the matching of attributed trees by using weighted association graphs. We illustrate the power of the approach by matching articulated and deformed shapes described by shock trees.	Univ Venice, Dipartimento Informat, I-30172 Venice, Italy; McGill Univ, Sch Comp Sci, Montreal, PQ H3A 2A7, Canada; McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada; Yale Univ, Dept Comp Sci, New Haven, CT 06520 USA; Yale Univ, Dept Elect Engn, New Haven, CT 06520 USA; Yale Univ, Ctr Computat Vis & Control, New Haven, CT 06520 USA	Universita Ca Foscari Venezia; McGill University; McGill University; Yale University; Yale University; Yale University	Pelillo, M (corresponding author), Univ Venice, Dipartimento Informat, Via Torino 155, I-30172 Venice, Italy.	pelillo@dsi.unive.it; siddiqi@cim.mcgill.ca; xucker-steven@cs.yale.edu		Siddiqi, Kaleem/0000-0002-7347-9716				AMBLER AP, 1973, P 3 INT JOINT C ART, P298; Ballard D.H., 1982, COMPUTER VISION; Barrow H. G., 1976, Information Processing Letters, V4, P83, DOI 10.1016/0020-0190(76)90049-1; BARTOLI M, 1999, CS9912 U CA FOSC VEN; BAUM LE, 1967, B AM MATH SOC, V73, P360, DOI 10.1090/S0002-9904-1967-11751-8; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; Bomze IM, 1997, J GLOBAL OPTIM, V10, P143, DOI 10.1023/A:1008230200610; Bomze IM, 1998, J GLOBAL OPTIM, V13, P369, DOI 10.1023/A:1008369322970; BOMZE IM, 1999, CS9913 U CA FOSC VEN; BOMZE IM, 1999, HDB COMBINATORIAL OP, V4; BROCKETT R, 1992, P IEEE C AC SPEECH S; CROW J F, 1970, P591, DOI 10.1093/bioinformatics/btr330; DURBIN R, 1987, NATURE, V326, P689, DOI 10.1038/326689a0; Fisher R.A., 1930, GENETICAL THEORY NAT; FU YT, 1986, J PHYS A-MATH GEN, V19, P1605, DOI 10.1088/0305-4470/19/9/033; Garey M., 1979, GUIDE NP COMPLETENES; GIBBONS L. E., 1996, CLIQUES COLORING SAT, V26, P103; Gibbons LE, 1997, MATH OPER RES, V22, P754, DOI 10.1287/moor.22.3.754; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Grotschel M., 1988, GEOMETRIC ALGORITHMS; Harary F., 1994, GRAPH THEORY; HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141; HORAUD R, 1989, IEEE T PATTERN ANAL, V11, P1168, DOI 10.1109/34.42855; JAGOTA A, 1995, IEEE T NEURAL NETWOR, V6, P724, DOI 10.1109/72.377977; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; KIMIA BB, 1990, LECT NOTES COMPUT SC, V427, P402; KOSOWSKY JJ, 1994, NEURAL NETWORKS, V7, P477, DOI 10.1016/0893-6080(94)90081-7; LI JT, 1994, IEEE T KNOWL DATA EN, V6, P559; Liu TL, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1129, DOI 10.1109/ICCV.1998.710858; LOSERT V, 1983, J MATH BIOL, V17, P241, DOI 10.1007/BF00305762; LU SY, 1984, IEEE T PATTERN ANAL, V6, P249, DOI 10.1109/TPAMI.1984.4767511; Lyubich Yu. I., 1980, Problems of Information Transmission, V16, P66; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; MATULA DW, 1968, SIAM REV, V10, P273; Miller DA, 1999, NEURAL COMPUT, V11, P21, DOI 10.1162/089976699300016782; MILLER DA, 1992, NEURAL COMPUT, V4, P167, DOI 10.1162/neco.1992.4.2.167; MOTZKIN TS, 1965, CANADIAN J MATH, V17, P533, DOI 10.4153/CJM-1965-053-6; NEFF M, 1988, P C APPL NAT LANG PR, P84; OGAWA H, 1986, PATTERN RECOGN, V19, P35, DOI 10.1016/0031-3203(86)90029-4; OHLSSON M, 1993, NEURAL COMPUT, V5, P331, DOI 10.1162/neco.1993.5.2.331; PARDALOS PM, 1990, INT J COMPUT MATH, V33, P209, DOI 10.1080/00207169008803851; Pardalos PM, 1996, NONLINEAR OPTIMIZATION AND APPLICATIONS, P313; Pelillo M, 1997, J MATH IMAGING VIS, V7, P309, DOI 10.1023/A:1008255111261; Pelillo M., 1995, Journal of Artificial Neural Networks, V2, P313; Pelillo M, 1998, INT C PATT RECOG, P1316, DOI 10.1109/ICPR.1998.711944; PELILLO M, 1999, NEURAL COMPUTATION, V11; PELILLO M, 1995, J ARTIF NEURONETW, V0002, P00411; Pla F, 1997, COMPUT VIS IMAGE UND, V66, P271, DOI 10.1006/cviu.1996.0512; RADIG B, 1984, PATTERN RECOGN, V17, P161, DOI 10.1016/0031-3203(84)90043-8; Rangarajan A, 1996, IEEE T NEURAL NETWOR, V7, P1365, DOI 10.1109/72.548165; REYNER SW, 1977, SIAM J COMPUT, V6, P730, DOI 10.1137/0206053; ROM H, 1993, IEEE T PATTERN ANAL, V15, P973, DOI 10.1109/34.254054; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Samet H., 1990, DESIGN ANAL SPATIAL, V85; SHAPIRO BA, 1990, COMPUT APPL BIOSCI, V6, P309; SHASHA D, 1994, IEEE T SYST MAN CYB, V24, P668, DOI 10.1109/21.286387; Siddiqi K, 1996, PROC CVPR IEEE, P507, DOI 10.1109/CVPR.1996.517119; Siddiqi K, 1999, IMAGE VISION COMPUT, V17, P365, DOI 10.1016/S0262-8856(98)00130-9; SIDDIQI K, 1999, IN PRESS INT J COMPU; Weibull J.W., 1997, EVOLUTIONARY GAME TH; WILF HS, 1986, J COMBINATORIAL TH B, V50, P113; YANG B, 1989, IMAGE VISION COMPUT, V7, P135, DOI 10.1016/0262-8856(89)90008-5; Zarantonello E. A., 1971, CONTRIBUTIONS NONLIN, P603; Zhu SC, 1996, INT J COMPUT VISION, V20, P187; [No title captured]; [No title captured]	66	263	272	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1999	21	11					1105	1120		10.1109/34.809105	http://dx.doi.org/10.1109/34.809105			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	259YG		Green Submitted			2022-12-18	WOS:000083921100001
J	Wu, D; Pigou, L; Kindermans, PJ; Le, NDH; Shao, L; Dambre, J; Odobez, JM				Wu, Di; Pigou, Lionel; Kindermans, Pieter-Jan; Nam Do-Hoang Le; Shao, Ling; Dambre, Joni; Odobez, Jean-Marc			Deep Dynamic Neural Networks for Multimodal Gesture Segmentation and Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deep learning; convolutional neural networks; deep belief networks; hidden Markov models; gesture recognition		This paper describes a novel method called Deep Dynamic Neural Networks (DDNN) for multimodal gesture recognition. A semi-supervised hierarchical dynamic framework based on a Hidden Markov Model (HMM) is proposed for simultaneous gesture segmentation and recognition where skeleton joint information, depth and RGB images, are the multimodal input observations. Unlike most traditional approaches that rely on the construction of complex handcrafted features, our approach learns high-level spatiotemporal representations using deep neural networks suited to the input modality: a Gaussian-Bernouilli Deep Belief Network (DBN) to handle skeletal dynamics, and a 3D Convolutional Neural Network (3DCNN) to manage and fuse batches of depth and RGB images. This is achieved through the modeling and learning of the emission probabilities of the HMM required to infer the gesture sequence. This purely data driven approach achieves a Jaccard index score of 0.81 in the ChaLearn LAP gesture spotting challenge. The performance is on par with a variety of state-of-the-art hand-tuned feature-based approaches and other learning-based methods, therefore opening the door to the use of deep learning techniques in order to further explore multimodal time series data.	[Wu, Di] IDIAP, Percept & Act Understanding, Martigny, Valais, Switzerland; [Pigou, Lionel; Dambre, Joni] Univ Ghent, ELIS, Ghent, Oost Vlaanderen, Belgium; [Kindermans, Pieter-Jan] TU Berlin, Machine Learning Grp, Berlin, Germany; [Nam Do-Hoang Le; Odobez, Jean-Marc] IDIAP Res Inst, Comp Vis, Martigny, Valais, Switzerland; [Shao, Ling] Northumbria Univ, Dept Comp Sci & Digital Technol, Newcastle Upon Tyne, Tyne & Wear, England	Ghent University; Technical University of Berlin; Northumbria University	Wu, D (corresponding author), IDIAP, Percept & Act Understanding, Martigny, Valais, Switzerland.	dwu@idiap.ch; lionel.pigou@ugent.be; p.kindermans@tu-berlin.de; nam.le@idiap.ch; ling.shao@ieee.org; joni.dambre@ugent.be; odobez@idiap.ch	Shao, Ling/D-3535-2011; Dambre, Joni/C-2926-2013	Dambre, Joni/0000-0002-9373-1210; Shao, Ling/0000-0002-8264-6117				[Anonymous], 2013, P ACM CHAL MULT MOD; Baccouche M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.124; Bastien F., 2012, P DEEP LEARN UNS FEA; Bishop C.M, 2006, PATTERN RECOGN; Bourlard H., 1994, CONNECTIONIST SPEECH; Camgoz N. C., 2014, EUR C COMP VIS, P579; Chang JY, 2014, WORKSH EUR C COMP VI, P503; Chaudhry R, 2013, IEEE COMPUT SOC CONF, P471, DOI 10.1109/CVPRW.2013.153; Chen G., 2014, P EUR C COMP VIS WOR, P608; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Dosovitskiy A., 2014, ADV NEURAL INFORM PR, P766; Escalera S, 2015, LECT NOTES COMPUT SC, V8925, P459, DOI 10.1007/978-3-319-16178-5_32; Evangelidis GD, 2015, LECT NOTES COMPUT SC, V8925, P595, DOI 10.1007/978-3-319-16178-5_42; Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137; Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23; Guyon I., 2012, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPRW.2012.6239178; Han J., 2013, IEEE TRANS SYST MAN, V43, P1317; Hannun A., 2014, ARXIV14125567; Hinton G.E., 2012, COMPUT SCI, V3, P212, DOI DOI 10.9774/GLEAF.978-1-909493-38-42; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Kindermans P J, 2012, ADV NEURAL INF PROCE, P719; Klaser A, 2008, P BRIT MACH VIS C MB, P275; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496; Liang B., 2014, P COMP VIS WORKSH, P623; Liu L, 2014, PATTERN RECOGN, V47, P3819, DOI 10.1016/j.patcog.2014.07.006; Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557; Mnih V., 2013, PLAYING ATARI DEEP R, P1; Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382; Monnier C, 2015, LECT NOTES COMPUT SC, V8925, P491, DOI 10.1007/978-3-319-16178-5_34; Morris A, 2001, SPEECH COMMUN, V34, P25, DOI 10.1016/S0167-6393(00)00044-3; Mualler M., 2006, P 2006 ACM SIGGRAPH, P137; Nandakumar K, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P475, DOI 10.1145/2522848.2532593; Neverova N, 2014, ARXIV150100102; Neverova N., 2013, P 15 IEEE INT C COMP, P474; Neverova N, 2015, LECT NOTES COMPUT SC, V8925, P474, DOI 10.1007/978-3-319-16178-5_33; Ngiam J, 2011, P 28 INT C MACH LEAR, V28, P689, DOI DOI 10.5555/3104482.3104569; Nowozin S, 2012, ACTION POINTS REPRES; Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007; PENG X, 2014, WORKSH EUR C COMP VI, P518; Pigou L., 2014, P EUR C COMP VIS PAT, P1; Renals S, 1994, IEEE T SPEECH AUDI P, V2, P161, DOI 10.1109/89.260359; Salakhutdinov R., 2009, THESIS; Schmidhuber J, 2014, ARXIV14047828; Scovanner P., 2007, ACM MM, P357; Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Simon F., 2012, P SIGCHI C HUM FACT, P1737, DOI DOI 10.1145/2207676.2208303; Socher R., 2012, ADV NEURAL INF PROCE, P665, DOI DOI 10.1002/2014GB005021; Sutskever I., 2013, P 30 INT C MACH LEAR, P1139, DOI DOI 10.1007/S00287-015-0911-Z; Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang H, 2009, J OPTOELECTRON BIOME, V1, P1; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Wang S. B., 2006, PROC IEEE COMPUT SOC, P1521, DOI DOI 10.1109/CVPR.2006.132; Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48; Wu D., 2014, COMP VIS ECCV 2014 W, P552; Wu D, 2014, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2014.98; Wu D, 2013, IEEE T CIRC SYST VID, V23, P236, DOI 10.1109/TCSVT.2012.2203731; Wu JX, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P453; Yao A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.67; Yu D., 2012, AUTOMATIC SPEECH REC	67	262	276	20	207	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2016	38	8			SI		1583	1597		10.1109/TPAMI.2016.2537340	http://dx.doi.org/10.1109/TPAMI.2016.2537340			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DR5EO	26955020	Green Submitted, Green Accepted			2022-12-18	WOS:000379926200008
J	Monro, DM; Rakshit, S; Zhang, DX				Monro, Donald M.; Rakshit, Soumyadip; Zhang, Dexin			DCT-based iris recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						biometrics; iris recognition; discrete cosine transform; image preprocessing; statistical analysis		This paper presents a novel iris coding method based on differences of discrete cosine transform (DCT) coefficients of overlapped angular patches from normalized iris images. The feature extraction capabilities of the DCT are optimized on the two largest publicly available iris image data sets, 2,156 images of 308 eyes from the CASIA database and 2,955 images of 150 eyes from the Bath database. On this data, we achieve 100 percent Correct Recognition Rate (CRR) and perfect Receiver-Operating Characteristic (ROC) Curves with no registered false accepts or rejects. Individual feature bit and patch position parameters are optimized for matching through a product-of-sum approach to Hamming distance calculation. For verification, a variable threshold is applied to the distance metric and the False Acceptance Rate (FAR) and False Rejection Rate (FRR) are recorded. A new worst-case metric is proposed for predicting practical system performance in the absence of matching failures, and the worst case theoretical Equal Error Rate (EER) is predicted to be as low as 2: 59 x 10(-4) on the available data sets.	Univ Bath, Dept Elect & Elect Engn, Bath BA2 7AY, Avon, England	University of Bath	Monro, DM (corresponding author), Univ Bath, Dept Elect & Elect Engn, Claverton Down, Bath BA2 7AY, Avon, England.	d.m.monro@bath.ac.uk; s.rakshit@bath.ac.uk						ADLER FH, 1965, PHYSL EYE; AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784; Atos Origin, 2005, UK PASSP SERV BIOM E; Boles WW, 1998, IEEE T SIGNAL PROCES, V46, P1185, DOI 10.1109/78.668573; BOLES WW, 1997, P 1 IEEE INT C KNOWL, V2, P533; *BRIT STAND I, 1994, 6082511994 BS EN BRI; Cui JL, 2004, INT C PATT RECOG, P471, DOI 10.1109/ICPR.2004.1333804; Daugman J, 2003, PATTERN RECOGN, V36, P279, DOI 10.1016/S0031-3203(02)00030-4; Daugman J, 2001, INT J COMPUT VISION, V45, P25, DOI 10.1023/A:1012365806338; Daugman J, 2001, P ROY SOC B-BIOL SCI, V268, P1737, DOI 10.1098/rspb.2001.1696; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; Dobes M., 2007, IRIS DATABASE; FUKUNAGA AK, 1990, INTRO STAT PATTERN R; Hafed ZM, 2001, INT J COMPUT VISION, V43, P167, DOI 10.1023/A:1011183429707; Huang YP, 2002, 2002 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-4, PROCEEDINGS, P450; IBG: International biometric group, 2005, INT BIOM GROUP IND T; *ICNIRP, 1997, GUID LIM EXP BROAD B; Jain AK, 2004, INT C PATT RECOG, P935, DOI 10.1109/ICPR.2004.1334413; Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349; Kalka ND, 2006, PROC SPIE, V6202, DOI 10.1117/12.666448; KRONFELD P, 1962, GROSS ANATOMY EMBRYO; LIU XM, 2005, P 4 IEEE WORKSH AUT; Ma L, 2004, IEEE T IMAGE PROCESS, V13, P739, DOI 10.1109/TIP.2004.827237; Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145; MANSFIELD AJ, 2002, BEST PRACTICES STAND; Meng, 1994, MULTIMEDIA SYSTEMS, V2, P204, DOI [10.1007/BF01215398, DOI 10.1007/BF01215398]; Monro D.M., 2005, P IEEE INT C IM PROC, V3, P277, DOI DOI 10.1109/ICIP.2005.1530382; *MULT U, 2007, MMU IR IM DAT; NEWSOME DA, 1971, AM J OPHTHALMOL, V71, P553, DOI 10.1016/0002-9394(71)90133-4; Pratt W, 1991, DIGITAL IMAGE PROCES; Proenca H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119; ROSS A, 2004, P 12 EUR SIGN PROC C, P1221; RYOUNG PK, 2005, IEEE T SYST MAN CYB, V35, P441; *TLV, 2001, P AM C GOV IND HYG; Travieso CM, 2004, 38TH ANNUAL 2004 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P321, DOI 10.1109/CCST.2004.1405412; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Uenohara M, 1997, IEEE T PATTERN ANAL, V19, P891, DOI 10.1109/34.608291; VETTERLI M, 1985, P IEEE ICASSP, P1538; Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669; Wyatt HJ, 2000, VISION RES, V40, P2167, DOI 10.1016/S0042-6989(00)00068-7; Zeng YH, 2001, IEEE T SIGNAL PROCES, V49, P2774, DOI 10.1109/78.960425; Zhang NF, 1999, SCANNING, V21, P246; 2007, CASIA IRIS IMAGE DAT	44	262	278	1	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2007	29	4					586	595		10.1109/TPAMI.2007.1002	http://dx.doi.org/10.1109/TPAMI.2007.1002			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HJ	17299216				2022-12-18	WOS:000244855600007
J	Gupta, R; Hartley, RI				Gupta, R; Hartley, RI			Linear pushbroom cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pushbroom sensor; fundamental matrix; satellite cameras; photogrammetry	RELATIVE ORIENTATION; MOTION	Modeling and analyzing pushbroom sensors commonly used in satellite imagery is difficult and computationally intensive due to the motion of an orbiting satellite with respect to the rotating earth, and the nonlinearity of the mathematical model involving orbital dynamics. in this paper, a simplified model of a pushbroom sensor (the linear pushbroom model) is introduced. It has the advantage of computational simplicity while at the same time giving very accurate results compared with the full orbiting pushbroom model. Besides remote sensing, the linear pushbroom model is also useful in many other imaging applications. Simple noniterative methods are given for solving the major standard photogrammetric problems for the linear pushbroom model: computation of the model parameters from ground-control points; determination of relative model parameters from image correspondences between two images; and scene reconstruction given image correspondences and ground-control points. The linear pushbroom model reads to theoretical insights that are approximately valid for the full model as well. The epipolar geometry of linear pushbroom cameras in investigated and shown to be totally different from that of a perspective camera. Nevertheless, a matrix analogous to the fundamental matrix of perspective cameras is shown to exist for linear pushbroom sensors. From this it is shown that a scene is determined up to an affine transformation from two Views with linear pushbroom cameras.			Gupta, R (corresponding author), GE CO, CORP RES & DEV, 1 RIVER RD, SCHENECTADY, NY 12301 USA.			Hartley, Richard/0000-0002-5005-0191				FAUGERAS O, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P951, DOI 10.1109/ICCV.1995.466832; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P564; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; GANAPATHY S, 1989, PATTERN RECOGN, V2, P410; Golub Gene H., 2013, MATRIX COMPUTATION, V3; GUPTA R, 1995, P 2 AS C COMP VIS SI; HANNAH MJ, 1980, P IM UND WORKSH COLL, P210; Hartley R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P761, DOI 10.1109/CVPR.1992.223179; Hartley R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P549, DOI 10.1109/CVPR.1993.341076; HARTLEY RI, 1992, LECT NOTES COMPUT SC, V588, P579; HARTLEY RI, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1064; Hartley RI, 1996, INFORMATION INTELLIGENCE AND SYSTEMS, VOLS 1-4, P2475, DOI 10.1109/ICSMC.1996.561292; HORN BKP, 1991, J OPT SOC AM A, V8, P1630, DOI 10.1364/JOSAA.8.001630; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; NOBLE A, 1994, P IEEE ROB AUT C; SPETSAKIS ME, 1992, IEEE T PATTERN ANAL, V14, P959, DOI 10.1109/34.161355; *SPOT IM CORP, 1990, SPOT US HDB; Strat T, 1987, RECOVERING CAMERA PA, P93; SUTHERLAND IE, 1974, P IEEE, V62, P453, DOI 10.1109/PROC.1974.9449; TAM AP, 1990, THESIS DEP SURVEYING; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; Wolfram S., 1988, MATH SYSTEM DOING MA	25	262	276	4	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1997	19	9					963	975		10.1109/34.615446	http://dx.doi.org/10.1109/34.615446			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XX985					2022-12-18	WOS:A1997XX98500003
J	MARTIN, WN; AGGARWAL, JK				MARTIN, WN; AGGARWAL, JK			VOLUMETRIC DESCRIPTIONS OF OBJECTS FROM MULTIPLE VIEWS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV TEXAS,IMAGE & SIGNAL ANAL LAB,AUSTIN,TX 78712	University of Texas System; University of Texas Austin								AGGARWAL JK, 1981, P IEEE, V69, P562, DOI 10.1109/PROC.1981.12025; AGGARWAL JK, 1981, PROGR PATTERN RECOGN, V1, P337; AGIN GJ, 1976, IEEE T COMPUT, V25, P439, DOI 10.1109/TC.1976.1674626; BADLER N, 1978, COMPUT GRAPHICS, V12, P153; BAKER HH, 1977, 2ND P IJCAI LOND, P649; BARROW HG, 1976, SRI121 AI CTR TECH N; BAUMGART BG, 1974, STANFORD AI LAB MEMO, V249; Blum H., 1964, MODELS PERCEPTION SP, P362; BRAID IC, 1975, COMMUN ACM, V18, P209, DOI 10.1145/360715.360727; BROOKS RA, 1981, STANCS81861 STANF U; CLARK JH, 1976, COMMUN ACM, V19, P547, DOI 10.1145/360349.360354; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; FREEMAN H, 1979, P WORKSHOP REPRESENT; FUCHS H, 1977, COMMUN ACM, V20, P693, DOI 10.1145/359842.359846; Hanson A., 1978, COMPUTER VISION SYST, P303; Herman G, 1980, IMAGE RECONSTRUCTION; HERMAN GT, 1978, COMPUT VISION GRAPH, V7, P130, DOI 10.1016/S0146-664X(78)80018-5; HOLLERBACH J, 1975, MIT AITR346; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; HORN BKP, 1977, ARTIFICIAL INTELL J, V8, P231; Huffman D, 1971, MACHINE INTELLIGENCE; JACKINS CL, 1980, COMPUT VISION GRAPH, V14, P249, DOI 10.1016/0146-664X(80)90055-6; LEVINTHAL C, 1972, NATURE, V236, P207, DOI 10.1038/236207a0; MACKWORTH AK, 1973, ARTIF INTELL, V4, P121, DOI 10.1016/0004-3702(73)90003-9; MARR D, 1979, AUG P IJCAI6 TOK, P1108; MARTIN WN, 1978, COMPUT VISION GRAPH, V7, P356, DOI 10.1016/S0146-664X(78)80003-3; MARTIN WN, 1981, TR815 U TEX LAB IM S, P51; MIYAMOTO E, 1975, MAY IEEE C COMP GRAP; NAGEL HH, 1981, COMPUTER, V14, P29, DOI 10.1109/C-M.1981.220560; NAGEL HH, 1981, IMAGE SEQUENCE ANAL, P19; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; NEVATIA R, 1976, COMPUT GRAPH IMAGE P, V5, P203; NEWMAN WM, 1979, PRINCIPLES INTERACTI, P229; NITZAN D, 1977, P IEEE, V65, P206, DOI 10.1109/PROC.1977.10458; OROURKE J, 1979, IEEE T PATTERN ANAL, V1, P295, DOI 10.1109/TPAMI.1979.4766925; Requicha A. A. G., 1980, Computing Surveys, V12, P437, DOI 10.1145/356827.356833; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; ROBERTS LG, 1977, COMPUTER METHODS IMA, P285; ROSENFELD A, 1976, DIGITAL PICTURE PROC, P336; SHIRAI Y, 1971, 2ND INT JOINT C ART, P71; SOROKA BI, 1978, IEEE C PATTERN RECOG; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; VOELCKER HB, 1974, U ROCHESTER PROD AUT, V22; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19; WEBB JA, 1981, COMPUTER, V14, P40, DOI 10.1109/C-M.1981.220561; WILL PM, 1971, 2ND P INT JOINT C AR, P66; WOODHAM RJ, 1977, 5TH P INT JOINT C AR, P635	47	262	285	1	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	2					150	158		10.1109/TPAMI.1983.4767367	http://dx.doi.org/10.1109/TPAMI.1983.4767367			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QJ974	21869096				2022-12-18	WOS:A1983QJ97400003
J	Banfield, RE; Hall, LO; Bowyer, KW; Kegelmeyer, WP				Banfield, Robert E.; Hall, Lawrence O.; Bowyer, Kevin W.; Kegelmeyer, W. P.			A comparison of decision tree ensemble creation techniques	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						classifier ensembles; bagging; boosting; random forests; random subspaces; performance evaluation	CLASSIFIERS	We experimentally evaluate bagging and seven other randomization-based approaches to creating an ensemble of decision tree classifiers. Statistical tests were performed on experimental results from 57 publicly available data sets. When cross-validation comparisons were tested for statistical significance, the best method was statistically more accurate than bagging on only eight of the 57 data sets. Alternatively, examining the average ranks of the algorithms across the group of data sets, we find that boosting, random forests, and randomized trees are statistically significantly better than bagging. Because our results suggest that using an appropriate ensemble size is important, we introduce an algorithm that decides when a sufficient number of classifiers has been created for an ensemble. Our algorithm uses the out-of-bag error estimate, and is shown to result in an accurate ensemble for those methods that incorporate bagging into the construction of the ensemble.	Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA; Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA; Sandia Natl Labs, Biosyst Res, Livermore, CA 94551 USA	State University System of Florida; University of South Florida; University of Notre Dame; United States Department of Energy (DOE); Sandia National Laboratories	Banfield, RE (corresponding author), Univ S Florida, Dept Comp Sci & Engn, ENB118, Tampa, FL 33620 USA.	rbanfiel@csee.usf.edu; hall@csee.usf.edu; kwb@cse.nd.edu; wpk@california.sandia.gov		Bowyer, Kevin/0000-0002-7562-4390				Alpaydin E, 1999, NEURAL COMPUT, V11, P1885, DOI 10.1162/089976699300016007; Banfield R., 2005, OPENDT; Banfield RE, 2003, LECT NOTES COMPUT SC, V2709, P306; BANFIELD RE, 2006, P 2006 INT C SYST MA; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Breiman L, 1998, ANN STAT, V26, P841; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1998, ANN STAT, V26, P801; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Eibl G, 2002, LECT NOTES ARTIF INT, V2430, P72; Freund Y, 1998, ANN STAT, V26, P824; Freund Y, 1996, P 13 INT C MACH LEAR, P148, DOI DOI 10.5555/3091696.3091715; Hallencreutz D, 2003, EUR PLAN STUD, V11, P533, DOI 10.1080/09654310303654; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601; Johnson R. A., 2014, APPL MULTIVARIATE ST, V6; Merz C., 2006, UCI REPOSITORY MACHI; Quinlan J., 2014, C4 5 PROGRAMS MACHIN, DOI DOI 10.1007/BF00993309; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; SCHAPIRE RE, 1997, P 14 INT C MACH LEAR, P322; Witten IH, 1999, DATA MINING PRACTICA	23	261	265	1	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2007	29	1					173	180		10.1109/TPAMI.2007.250609	http://dx.doi.org/10.1109/TPAMI.2007.250609			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	104VI	17108393				2022-12-18	WOS:000241988300015
J	Zhang, YM; Ji, Q				Zhang, YM; Ji, Q			Active and dynamic information fusion for facial expression understanding from image sequences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						facial expression analysis; dynamic Bayesian networks; visual information fusion; active sensing	AUTOMATIC-ANALYSIS; EXPERT-SYSTEM; RECOGNITION; EMOTION; FACE; PARAMETERS; MODELS	This paper explores the use of multisensory information fusion technique with Dynamic Bayesian networks (DBNs) for modeling and understanding the temporal behaviors of facial expressions in image sequences. Our facial feature detection and tracking based on active IR illumination provides reliable visual information under variable lighting and head motion. Our approach to facial expression recognition lies in the proposed dynamic and probabilistic framework based on combining DBNs with Ekman's Facial Action Coding System (FACS) for systematically modeling the dynamic and stochastic behaviors of spontaneous facial expressions. The framework not only provides a coherent and unified hierarchical probabilistic framework to represent spatial and temporal information related to facial expressions, but also allows us to actively select the most informative visual cues from the available information sources to minimize the ambiguity in recognition. The recognition of facial expressions is accomplished by fusing not only from the current visual observations, but also from the previous visual evidences. Consequently, the recognition becomes more robust and accurate through explicitly modeling temporal behavior of facial expression. In this paper, we present the theoretical foundation underlying the proposed probabilistic and dynamic framework for facial expression modeling and understanding. Experimental results demonstrate that our approach can accurately and robustly recognize spontaneous facial expressions from an image sequence under different conditions.	Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA	Rensselaer Polytechnic Institute	Zhang, YM (corresponding author), Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, JEC 6003,110 8th St, Troy, NY 12180 USA.	zhangy5@rpi.edu; qji@ecse.rpi.edu						Bartlett MS, 1996, ADV NEUR IN, V8, P823; BARTLETT MS, 2001, MPLABTR200108 U CAL; BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037/0022-3514.37.11.2049; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277; Cohn JF, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P396, DOI 10.1109/AFGR.1998.670981; COLMENAREZ A, 1999, P INT C COMP VIS PAT; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; COTTRELL G, 1991, ADV NEURAL INFORM PR, P564; Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905; EKMAN P, 1992, PHILOS T ROY SOC B, V335, P63, DOI 10.1098/rstb.1992.0008; Ekman P., 2002, FACIAL ACTION CODING; Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232; Farkas LG, 1994, ANTHROPOMETRY HEAD F; Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3; Goldenstein SK, 2003, IEEE T PATTERN ANAL, V25, P801, DOI 10.1109/TPAMI.2003.1206510; Huang CL, 1997, J VIS COMMUN IMAGE R, V8, P278, DOI 10.1006/jvci.1997.0359; KATO M, 1991, VISUAL COMPUTING, P39; KEARNEY GD, 1993, COGNITIVE SCI, V17, P589, DOI 10.1207/s15516709cog1704_5; KOBAYASHI H, 1992, IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION : PROCEEDINGS, P381; Lanitis A, 1997, IEEE T PATTERN ANAL, V19, P743, DOI 10.1109/34.598231; LIEN JJJ, 2000, J ROBOTICS AUTONOMOU, V31, P131; Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413; MASE K, 1991, IEICE TRANS COMMUN, V74, P3474; Maybeck P. S., 1979, MATH SCI ENG; MORIMOTO C, 1999, P IEEE INT C COMP VI; *MPEG, 1998, 14496MPEG4 ISOIEC; OLIVER N, 1997, P IEEE C COMP VIS PA; PADGETT C, 1997, ADV NEURAL INFORMATI, V9; Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976; Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2; PAVLOVIC VI, 1999, THESIS U ILLINOIS UR; PEARL J, 1988, PROBABILITY REASONIN; Pighin F, 2002, INT J COMPUT VISION, V50, P143, DOI 10.1023/A:1020393915769; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RAHARDJA A, 1991, P SOC PHOTO-OPT INS, V1607, P62; Rosenblum M., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P43, DOI 10.1109/MNRAO.1994.346256; Rosenblum M, 1996, IEEE T NEURAL NETWOR, V7, P1121, DOI 10.1109/72.536309; SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x; Tao H, 2002, INT J COMPUT VISION, V50, P111, DOI 10.1023/A:1020389714861; TERZOPOULOS D, 1993, IEEE T PATTERN ANAL, V15, P569, DOI 10.1109/34.216726; Thalmann NM, 1998, P IEEE, V86, P870, DOI 10.1109/5.664277; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; USHIDA H, 1993, SECOND IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1 AND 2, P594, DOI 10.1109/FUZZY.1993.327421; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; YACOOB Y, 1994, INT C PATT RECOG, P747; Yacoob Y, 1996, IEEE T PATTERN ANAL, V18, P636, DOI 10.1109/34.506414; ZHANG Y, 2003, P 9 IEEE INT C COMP; Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990; Zhao J., 1996, Progress in Neural Information Processing. Proceedings of the International Conference on Neural Information Processing, P454; ZHU Z, 2002, P INT C PATT REC AUG	51	261	280	1	52	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2005	27	5					699	714		10.1109/TPAMI.2005.93	http://dx.doi.org/10.1109/TPAMI.2005.93			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	905LI	15875792	Green Submitted			2022-12-18	WOS:000227569300004
J	NALWA, VS; BINFORD, TO				NALWA, VS; BINFORD, TO			ON DETECTING EDGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									STANFORD UNIV,INFORMAT SYST LAB,STANFORD,CA 94305	Stanford University	NALWA, VS (corresponding author), STANFORD UNIV,ARTIFICIAL INTELLIGENCE LAB,STANFORD,CA 94305, USA.							ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325; Andrews H.C., 1977, DIGITAL IMAGE RESTOR; BINFORD TO, 1981, ARTIF INTELL, V17, P205, DOI 10.1016/0004-3702(81)90025-4; BLICHER P, 1984, THESIS U CALIFORNIA; BRADY M, 1982, COMPUT SURV, V14, P3, DOI 10.1145/356869.356871; CANNY FJ, 1983, MIT AITR720 ART INT; Davis L. S., 1975, COMPUT VISION GRAPH, V4, P248, DOI [DOI 10.1016/0146-664X(75)90012-X, 10.1016/0146-664X(75)90012-X]; Goodman J. W., 2005, MCGRAW HILL PHYS QUA; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; LECLERC Y, 1984, TR8319R MCGILL U COM; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; NALWA VS, 1984, OCT IM UND WORKSH NE; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; OGORMAN F, 1978, ARTIF INTELL, V10, P215, DOI 10.1016/S0004-3702(78)80013-7; Oppenheim A.V., 1975, DIGIT SIGNAL PROCESS; Prewitt, 1970, PICTURE PROCESSING P, V10, P15, DOI DOI 10.4236/AD.2014.22003; SHANMUGAM KS, 1979, IEEE T PATTERN ANAL, V1, P37, DOI 10.1109/TPAMI.1979.4766874; Turner K., 1974, THESIS U EDINBURGH	19	261	289	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1986	8	6					699	714		10.1109/TPAMI.1986.4767852	http://dx.doi.org/10.1109/TPAMI.1986.4767852			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	E4469	21869366				2022-12-18	WOS:A1986E446900002
J	AYACHE, N; FAUGERAS, OD				AYACHE, N; FAUGERAS, OD			HYPER - A NEW APPROACH FOR THE RECOGNITION AND POSITIONING OF TWO-DIMENSIONAL OBJECTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											AYACHE, N (corresponding author), INST NATL RECH INFORMAT & AUTOMAT,COMP VIS & ROBOT GRP,F-78153 LE CHESNAY,FRANCE.							AMBLER AP, 1973, P 3 INT JOINT C ART, P298; Anderson B. D. O., 1979, OPTIMAL FILTERING; AYACHE N, 1983, SYSTEME VISION BIDIM; AYACHE N, ICPR 84 MONTREAL; AYACHE N, 1983, 9EME P C TRAIT SIGN, P611; AYACHE N, 1983, JUN P COMP VIS PATT, P492; AYACHE NJ, 1982, 6TH P INT C PATT REC; BHANU B, 1984, IEEE T PATTERN ANAL, V6; BOLLES RC, 1982, JUN P IEEE C PATT RE, P498; CHIEZE JP, 1979, LOGICIEL ANAL CONTOU; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; DESSIMOZ JD, 1979, 9TH P S IND ROB WASH; FAUGERAS OD, 1983, 8TH P INT JOINT C AR, P996; GRIMSON WEL, MIT841 AI LAB MEM; GRIMSON WEL, 1985, MAR IEEE COMP SOC IN; HATTICH W, 1982, 6TH P INT C PATT REC, P670; Keskes N., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P855; LUX A, 1984, 4EME P C REC FORM IN, P223; Marr D., 1982, VISION; Pavlidis T., 1977, STRUCTURAL PATTERN R; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; RUMMEL P, 1982, 6TH P ICPR MUN, P1014; SEGEN J, 1982, P SOC PHOTO-OPT INST, V360, P132; Serra J, 1982, IMAGE ANAL MATH MORP; TURNEY JL, 1984, P INT SOC OPT ENG, V521, P108; ZIMMERMAN NJ, 1983, IND APPLICATIONS IMA	26	260	272	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1986	8	1					44	54		10.1109/TPAMI.1986.4767751	http://dx.doi.org/10.1109/TPAMI.1986.4767751			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AWT86	21869322	Green Submitted			2022-12-18	WOS:A1986AWT8600006
J	Lu, CY; Feng, JS; Chen, YD; Liu, W; Lin, ZC; Yan, SC				Lu, Canyi; Feng, Jiashi; Chen, Yudong; Liu, Wei; Lin, Zhouchen; Yan, Shuicheng			Tensor Robust Principal Component Analysis with a New Tensor Nuclear Norm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Principal component analysis; Sparse matrices; Matrix decomposition; Numerical models; Noise measurement; Convex functions; Tensor robust PCA; convex optimization; tensor nuclear norm; tensor singular value decomposition	FACTORIZATION; MATRICES	In this paper, we consider the Tensor Robust Principal Component Analysis (TRPCA) problem, which aims to exactly recover the low-rank and sparse components from their sum. Our model is based on the recently proposed tensor-tensor product (or t-product) [14]. Induced by the t-product, we first rigorously deduce the tensor spectral norm, tensor nuclear norm, and tensor average rank, and show that the tensor nuclear norm is the convex envelope of the tensor average rank within the unit ball of the tensor spectral norm. These definitions, their relationships and properties are consistent with matrix cases. Equipped with the new tensor nuclear norm, we then solve the TRPCA problem by solving a convex program and provide the theoretical guarantee for the exact recovery. Our TRPCA model and recovery guarantee include matrix RPCA as a special case. Numerical experiments verify our results, and the applications to image recovery and background modeling problems demonstrate the effectiveness of our method.	[Lu, Canyi] Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA; [Feng, Jiashi; Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119077, Singapore; [Chen, Yudong] Cornell Univ, Sch Operat Res & Informat Engn, Ithaca, NY 14850 USA; [Liu, Wei] Tencent AI Lab, Shenzhen, Peoples R China; [Lin, Zhouchen] Peking Univ, Sch Elect Engn & Comp Sci, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China	Carnegie Mellon University; National University of Singapore; Cornell University; Tencent; Peking University	Lin, ZC (corresponding author), Peking Univ, Sch Elect Engn & Comp Sci, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China.	canyil@andrew.com.edu; elefjia@nus.edu.sg; yudong.chen@cornell.edu; wl2223@columbia.edu; zlin@pku.edu.cn; eleyans@nus.edu.sg	Yan, Shuicheng/HCI-1431-2022; Feng, Jiashi/AGX-6209-2022	Liu, Wei/0000-0002-3865-8145	National University of Singapore [R-263-000-C08-133]; Ministry of Education of Singapore AcRF Tier One [R-263-000-C21-112]; National Science Foundation [1657420, CCF-1704828]; National Natural Science Foundation (NSF) of China [61625301, 61731018]; National Basic Research Program of China (973 Program) [2015CB352502]; Qualcomm; Microsoft Research Asia	National University of Singapore(National University of Singapore); Ministry of Education of Singapore AcRF Tier One(Ministry of Education, Singapore); National Science Foundation(National Science Foundation (NSF)); National Natural Science Foundation (NSF) of China(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China (973 Program)(National Basic Research Program of China); Qualcomm; Microsoft Research Asia(Microsoft)	J. Feng is supported by National University of Singapore startup grant R-263-000-C08-133 and Ministry of Education of Singapore AcRF Tier One grant R-263-000-C21-112. Y. Chen is supported by the National Science Foundation under CRII award 1657420 and grant CCF-1704828. Z. Lin is supported by National Natural Science Foundation (NSF) of China (grant nos. 61625301 and 61731018), National Basic Research Program of China (973 Program) (grant no. 2015CB352502), Qualcomm, and Microsoft Research Asia.	Anandkumar A, 2016, JMLR WORKSH CONF PRO, V51, P268; Atkinson K, 2009, TEXTS APPL MATH, V39, P1, DOI 10.1007/978-1-4419-0458-4_1; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Chen YD, 2015, IEEE T INFORM THEORY, V61, P2909, DOI 10.1109/TIT.2015.2415195; Fazel M., 2002, MATRIX RANK MINIMIZA; Hao N, 2013, SIAM J IMAGING SCI, V6, P437, DOI 10.1137/110842570; Hillar CJ, 2013, J ACM, V60, DOI 10.1145/2512329; Kernfeld E, 2015, LINEAR ALGEBRA APPL, V485, P545, DOI 10.1016/j.laa.2015.07.021; Kilmer ME, 2013, SIAM J MATRIX ANAL A, V34, P148, DOI 10.1137/110837711; Kilmer ME, 2011, LINEAR ALGEBRA APPL, V435, P641, DOI 10.1016/j.laa.2010.09.020; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39; Lu CY, 2018, IEEE T PATTERN ANAL, V40, P527, DOI 10.1109/TPAMI.2017.2689021; Lu CY, 2016, PROC CVPR IEEE, P5249, DOI 10.1109/CVPR.2016.567; Lu CY, 2015, AAAI CONF ARTIF INTE, P1805; Martin CD, 2013, SIAM J SCI COMPUT, V35, pA474, DOI 10.1137/110841229; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Mu C, 2014, PR MACH LEARN RES, V32, P73; Rojo O, 2004, LINEAR ALGEBRA APPL, V392, P211, DOI 10.1016/j.laa.2004.06.013; Romera-Paredes B., 2013, ADV NEURAL INFORM PR, V2, P2967; Semerci O, 2014, IEEE T IMAGE PROCESS, V23, P1678, DOI 10.1109/TIP.2014.2305840; Tomioka R., 2011, ARXIV10100789; Waters A. E., 2011, 25 ANN C NEURAL INFO, P1089; WATSON GA, 1992, LINEAR ALGEBRA APPL, V170, P33, DOI 10.1016/0024-3795(92)90407-2; Zhang AR, 2018, IEEE T INFORM THEORY, V64, P7311, DOI 10.1109/TIT.2018.2841377; Zhang ZM, 2017, IEEE T SIGNAL PROCES, V65, P1511, DOI 10.1109/TSP.2016.2639466; Zhang ZM, 2014, PROC CVPR IEEE, P3842, DOI 10.1109/CVPR.2014.485	31	259	269	35	185	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2020	42	4					925	938		10.1109/TPAMI.2019.2891760	http://dx.doi.org/10.1109/TPAMI.2019.2891760			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LE2GI	30629495	hybrid, Green Submitted			2022-12-18	WOS:000526541100010
J	Pascual-Montano, A; Carazo, JM; Kochi, K; Lehmann, D; Pascual-Marqui, RD				Pascual-Montano, A; Carazo, JM; Kochi, K; Lehmann, D; Pascual-Marqui, RD			Nonsmooth nonnegative matrix factorization (nsNMF)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nonnegative matrix factorization; constrained optimization; datamining; mining methods and algorithms; pattern analysis; feature extraction or construction; sparse; structured; and very large systems	MICROARRAY DATA; LOCALIZATION; EEG	We propose a novel nonnegative matrix factorization model that aims at finding localized, part-based, representations of nonnegative multivariate data items. Unlike the classical nonnegative matrix factorization (NMF) technique, this new model, denoted '' nonsmooth nonnegative matrix factorization '' (nsNMF), corresponds to the optimization of an unambiguous cost function designed to explicitly represent sparseness, in the form of nonsmoothness, which is controlled by a single parameter. In general, this method produces a set of basis and encoding vectors that are not only capable of representing the original data, but they also extract highly localized patterns, which generally lend themselves to improved interpretability. The properties of this new method are illustrated with several data sets. Comparisons to previously published methods show that the new nsNMF method has some advantages in keeping faithfulness to the data in the achieving a high degree of sparseness for both the estimated basis and the encoding vectors and in better interpretability of the factors.	Univ Complutense Madrid, Fac Ciencias Fis, Comp Architecture & Syst Engn Dept, E-28040 Madrid, Spain; Univ Autonoma Madrid, Natl Biotechnol Ctr, CSIC, E-28049 Madrid, Spain; Univ Hosp Psychiat, Key Inst Brain Mind Res, CH-8029 Zurich, Switzerland	Complutense University of Madrid; Autonomous University of Madrid; Consejo Superior de Investigaciones Cientificas (CSIC)	Pascual-Montano, A (corresponding author), Univ Complutense Madrid, Fac Ciencias Fis, Comp Architecture & Syst Engn Dept, E-28040 Madrid, Spain.	pascual@fis.ucm.es; carazo@cnb.uam.es; kieko@access.unizh.ch; dlehmann@key.unizh.ch; pascualm@key.unizh.ch	Pascual-Marqui, Roberto D./A-2012-2008; Garcia, Jose Maria Carazo/E-9234-2016	Pascual-Marqui, Roberto D./0000-0002-5029-4065; Garcia, Jose Maria Carazo/0000-0003-0788-8447				Brunet JP, 2004, P NATL ACAD SCI USA, V101, P4164, DOI 10.1073/pnas.0308531101; Buchsbaum G, 2002, VISION RES, V42, P559, DOI 10.1016/S0042-6989(01)00303-0; CHANG JH, 2002, P 7 PAC RIM INT C AR; Chen M, 2003, ADV ENVIRON RES, V8, P93, DOI 10.1016/S1093-0191(02)00145-4; Donoho D., 2003, P 17 ANN C NEUR INF; Dugas M, 2004, BIOINFORMATICS, V20, P931, DOI 10.1093/bioinformatics/bth009; Feng T., 2002, P 2 INT C DEV LEARN; Guillamet D, 2002, LECT NOTES ARTIF INT, V2504, P336; Harpur GF, 1996, NETWORK-COMP NEURAL, V7, P277, DOI 10.1088/0954-898X/7/2/007; Heger A, 2003, BIOINFORMATICS, V19, pi130, DOI 10.1093/bioinformatics/btg1017; Hoyer P., 2002, P IEEE WORKSH NEUR N; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; Hyvarinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71; Kim PM, 2003, GENOME RES, V13, P1706, DOI 10.1101/gr.903503; Kluger Y, 2003, GENOME RES, V13, P703, DOI 10.1101/gr.648603; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Liu W., 2003, P IEEE INT C AC SPEE; Madeira SC, 2004, IEEE ACM T COMPUT BI, V1, P24, DOI 10.1109/TCBB.2004.2; Mel BW, 1999, NATURE, V401, P759, DOI 10.1038/44507; *MIT CTR BIOL COMP, 2005, CBCL FAC DAT; Mulert C, 2004, NEUROIMAGE, V22, P83, DOI 10.1016/j.neuroimage.2003.10.051; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203; Paatero P, 2003, ENVIRON SCI TECHNOL, V37, P2460, DOI 10.1021/es0261978; Pascual-Marqui RD., 1999, INT J BIOELECTROMAGN, V1, P1, DOI DOI 10.1186/1743-0003-5-25; PASCUALMARQUI RD, 1994, INT J PSYCHOPHYSIOL, V18, P49, DOI 10.1016/0167-8760(84)90014-X; Ramanath R, 2004, COLOR RES APPL, V29, P29, DOI 10.1002/col.10211; Ramanath R., 2003, P APPL IM PATT REC A; Sheng QZ, 2003, BIOINFORMATICS, V19, pII196, DOI 10.1093/bioinformatics/btg1078; SMARAGDIS P, 2003, P IEEE WORKSH APPL S; SRINIVASAN SH, 2002, P 6 WORKSH COMP LANG; TANAY A, IN PRESS HDB COMPUTA; TANAY A, 2002, HDB COMPUTATIONAL MO, V18, P136; Turner H, 2005, COMPUT STAT DATA AN, V48, P235, DOI 10.1016/j.csda.2004.02.003; Van Mechelen I, 2004, STAT METHODS MED RES, V13, P363, DOI 10.1191/0962280204sm373ra; Yao J, 2005, NEUROIMAGE, V25, P369, DOI 10.1016/j.neuroimage.2004.11.036	36	259	275	4	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2006	28	3					403	415		10.1109/TPAMI.2006.60	http://dx.doi.org/10.1109/TPAMI.2006.60			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	001FB	16526426				2022-12-18	WOS:000234517900006
J	Geman, D; Jedynak, B				Geman, D; Jedynak, B			An active testing model for tracking roads in satellite images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						decision tree; model-based tracking; active testing; roads; SPOT images	EFFICIENT DECISION TREES; RECOGNITION; CLASSIFICATION; CONSTRUCTION; ENTROPY	We present a new approach for tracking roads from satellite images, and thereby illustrate a general computational strategy (''active testing'') for tracking 1D structures and other recognition tasks in computer vision. Our approach is related to recent work in active vision on ''where to look next'' and motivated by the ''divide-and-conquer'' strategy of parlor games such as ''twenty Questions''. We choose ''tests'' (matched filters for short road segments) one at a time in order to remove as much uncertainty as possible about the ''true hypothesis'' (road position) given the results of the previous tests. The tests are chosen on-line based on a statistical model for the joint distribution of tests and hypotheses. The problem of minimizing uncertainty (measured by entropy) is formulated in simple and explicit analytical terms. To execute this entropy testing rule we then alternate between data collection and optimization: At each iteration new image data are examined and a new entropy minimization problem is solved (exactly), resulting in a new image location to inspect, and so forth. We report experiments using panchromatic SPOT satellite imagery with a ground resolution of ten meters: Given a starting point and starting direction, we are able to rapidly track highways in southern France over distances on the order of one hundred kilometers without manual intervention.	INRIA ROCQUENCOURT, LE CHESNAY, FRANCE		Geman, D (corresponding author), UNIV MASSACHUSETTS, DEPT MATH & STAT, AMHERST, MA 01003 USA.		Geman, Donald/A-3325-2010; jedynak, bruno m/A-8198-2009					ARKIN E, 1993, 9TH P ACM S COMP GEO; BARZOHAR M, 1993, BROWNLEMS118 TECHN R; BLANC HV, 1993, APPLICATION GROUPEME; Boggess J.E., 1993, IDENTIFICATION ROADS; Chernoff H., 1972, SEQUENTIAL ANAL OPTI; CHOU PA, 1991, IEEE T PATTERN ANAL, V13, P340, DOI 10.1109/34.88569; DAOUD M, 1989, APPLICATION THEORIE, P699; Duda R.O., 1973, J ROYAL STAT SOC SER; ESTIVAL I, 1986, OCT P C PATT REC, P856; FISCHLER MA, 1981, COMPUT VISION GRAPH, V15, P201, DOI 10.1016/0146-664X(81)90056-3; Garey M. R., 1974, Acta Informatica, V3, P347, DOI 10.1007/BF00263588; GAREY MR, 1972, SIAM J APPL MATH, V23, P173, DOI 10.1137/0123019; GARNESSON P, 1991, MESSIE SYSTEME ANAL; GEMAN D, 1993, 2155 TECHN REP; GEMAN D, 1991, P IGRASS 91 HELSINKI; Gittins J., 1989, MULTIARMED BANDIT AL; GRAFFIGNE C, 1989, MODELISATION RESEAUX; GU YX, 1983, IEEE T PATTERN ANAL, V5, P83, DOI 10.1109/TPAMI.1983.4767349; HANSEN C, 1988, DEC P INT C COMP VIS, P275; Haralick R.M., 1992, COMPUTER ROBOT VISIO, V1; HARTMANN CRP, 1982, IEEE T INFORM THEORY, V28, P565, DOI 10.1109/TIT.1982.1056522; HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898; Hyafil L., 1976, Information Processing Letters, V5, P15, DOI 10.1016/0020-0190(76)90095-8; JEDYNAK B, 1995, THESIS U PARIS SUD; KELLER I, 1994, RECHERCHE MEILLEUR M; KUMAR PR, 1985, SIAM J CONTROL OPTIM, V23, P329, DOI 10.1137/0323023; KURZYNSKI MW, 1983, PATTERN RECOGN, V16, P81, DOI 10.1016/0031-3203(83)90011-0; Lawler E. L., 2001, COMBINATORIAL OPTIMI; LIN YK, 1983, PATTERN RECOGN, V16, P69, DOI 10.1016/0031-3203(83)90010-9; LOVELAND DW, 1985, ACTA INFORM, V22, P101, DOI 10.1007/BF00290148; MERLE N, 1993, 8TH SCIA C; MIYAKAWA M, 1989, IEEE T COMPUT, V38, P130, DOI 10.1109/12.8736; NEVIATA R, 1982, IEEE T PATTERN A SEP, P476; Olshen R., 1984, CLASSIFICATION REGRE; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; RIMEY RD, 1994, INT J COMPUT VISION, V12, P173, DOI 10.1007/BF01421202; ROUX M, 1992, THESIS ECOLE NATIONA; SANDELIUS M, 1961, AM MATH MON, V68, P133, DOI 10.2307/2312475; SERENDERO MA, 1989, THESIS U NICE; SPIRKOVSKA L, 1993, PATTERN RECOGN, V26, P727, DOI 10.1016/0031-3203(93)90125-G; SWAIN M, 1988, P DARPA IMAGE UNDERS; SWAIN MJ, 1993, INT J COMPUT VISION, V11, P109, DOI 10.1007/BF01469224; VANDERBRUG GJ, 1976, IEEE T GEOSCI REMOTE, V14, P37, DOI 10.1109/TGE.1976.294463; Wang F., 1988, IEEE T GEOSCIENCE RE, V26; WANG QR, 1984, IEEE T PATTERN ANAL, V6, P406, DOI 10.1109/TPAMI.1984.4767546; WATANABE S, 1981, PATTERN RECOGN, V13, P381, DOI 10.1016/0031-3203(81)90094-7; ZIMMERMAN S, 1959, AM MATH MONTHLY, V66, P690; [No title captured]	48	259	280	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1996	18	1					1	14		10.1109/34.476006	http://dx.doi.org/10.1109/34.476006			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TP315		Green Submitted			2022-12-18	WOS:A1996TP31500001
J	DHOME, M; RICHETIN, M; LAPRESTE, JT; RIVES, G				DHOME, M; RICHETIN, M; LAPRESTE, JT; RIVES, G			DETERMINATION OF THE ATTITUDE OF 3-D OBJECTS FROM A SINGLE PERSPECTIVE VIEW	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											DHOME, M (corresponding author), UNIV BLAISE PASCAL CLERMONT FERRAND,ELECTR LAB,CNRS,ARTIFICIAL VIS RES GRP,F-63177 CLERMONT FERRAND,FRANCE.							BARNARD ST, 1985, COMPUT VISION GRAPH, V29, P87, DOI 10.1016/S0734-189X(85)90152-5; DHOME M, 1987, IEEE T PATTERN ANAL, V9, P429, DOI 10.1109/TPAMI.1987.4767924; DURAND E, 1961, SOLUTIONS NUMERIQUES, V1, P247; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; HARALICK RM, 1980, COMPUT VISION GRAPH, V13, P191, DOI 10.1016/0146-664X(80)90046-5; HORAUD R, 1987, IEEE T PATTERN ANAL, V9, P401, DOI 10.1109/TPAMI.1987.4767922; KANADE T, 1981, COMPUTER VISION, V17; LAPRESTE JT, 1986, P NATO ADV RES WORKS; LOWE DG, 1985, PERCEPTION ORG VISUA, pCH7; RICHETIN M, 1985, JUN P C COMP VIS PAT, P464; *RICHETIN M, 1987, 6TH P AFCET C PATT R, P671; RIVES G, 1985, 2TH P SPIE INT TECH, P300; SHAKUNAGA T, 1986, JUN P INT C COMP VIS, P594; [No title captured]	14	259	283	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1989	11	12					1265	1278		10.1109/34.41365	http://dx.doi.org/10.1109/34.41365			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB716					2022-12-18	WOS:A1989CB71600003
J	GEIGER, D; GUPTA, A; COSTA, LA; VLONTZOS, J				GEIGER, D; GUPTA, A; COSTA, LA; VLONTZOS, J			DYNAMIC-PROGRAMMING FOR DETECTING, TRACKING, AND MATCHING DEFORMABLE CONTOURS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						DYNAMIC PROGRAMMING; DEFORMABLE CONTOURS; SNAKES; CONTOUR SEGMENTATION; TRACKING; MATCHING; OPTIMAL SOLUTIONS	RECOGNITION; ALGORITHM	The problem of segmenting an image into separate regions and tracking them over time is one of the most significant problems in vision. Terzopoulos et al have proposed an approach to detect the contour regions of complex shapes, assuming a user selected initial contour not very far from the desired solution. We propose to further explore the information provided by the user's selected points and apply an optimal method to detect contours which allows a segmentation of the image. The method is based on dynamic programming (DP), and applies to a wide variety of shapes. It is exact and not iterative. We also consider a multiscale approach capable of speeding up the algorithm by a factor of 20, although at the expense of losing the guaranteed optimality characteristic. The problem of tracking and matching these contours is addressed. For tracking, the final contour obtained at one frame is sampled and used as initial points for the next frame. Then, the same DP process is applied. For matching, a novel strategy is proposed where the solution is a smooth displacement field in which unmatched regions are allowed while cross vectors are not. The algorithm is again based on DP and the optimal solution is guaranteed. We have demonstrated the algorithms on natural objects in a large spectrum of applications, including interactive segmentation and automatic tracking of the regions of interest in medical images.	SIEMENS CORP RES INC,PRINCETON,NJ 08540; USP,LSI,SAO PAULO,SP,BRAZIL	Siemens AG; Universidade de Sao Paulo	GEIGER, D (corresponding author), NYU,COURANT INST,251 MERCER ST,NEW YORK,NY 10012, USA.							AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681; AYACHE N, 1992, ACTIVE VISION, pCH20; Ballard D.H., 1982, COMPUTER VISION; Barzohar M., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P459, DOI 10.1109/CVPR.1993.341090; Bellman R., 1962, APPL DYNAMIC PROGRAM; BLAKE A, 1990, 1 ECCV, P73; COHEN I, 1992, CVGIP-IMAG UNDERSTAN, V56, P242, DOI 10.1016/1049-9660(92)90041-Z; GEIGER D, 1992, COMPUTER VISION ECCV, V588, P423; GEIGER D, 1993, P IEEE C COMPUTER VI; GREGOR J, 1993, IEEE T PATTERN ANAL, V15, P129, DOI 10.1109/34.192484; GUEZIEC A, 1992, 2ND ECCV; Hospital M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P728; KASS M, 1987, 1ST P INT C COMP VIS, P259; MONTANARI U, 1971, COMMUN ACM, P335; MORTENSEN E, 1992, COMPUT CARDIOL, P635; PENTLAND A, 1989, P ACM SIGGRAPH, P215; PENTLAND AP, 1991, IEEE T PATTERN ANAL, V13; POPE DL, 1985, RADIOLOGY, V155, P513, DOI 10.1148/radiology.155.2.3885315; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; TERZOPOLIS D, 1987, 1ST P INT C COMP VIS, P269; UEDA N, 1992, LECT NOTES COMPUT SC, V588, P453; Wu Y., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P913, DOI 10.1109/ICPR.1990.118240; YUILLE A, 1992, ACTIVE VISION; [No title captured]	24	258	303	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1995	17	3					294	302		10.1109/34.368194	http://dx.doi.org/10.1109/34.368194			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QM090					2022-12-18	WOS:A1995QM09000006
J	STEIN, F; MEDIONI, G				STEIN, F; MEDIONI, G			STRUCTURAL INDEXING - EFFICIENT 3-D OBJECT RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						FEATURE DETECTION; HASHING; INDEXING; MODELBASED RECOGNITION; POSE ESTIMATION; RANGE-IMAGE UNDERSTANDING; 3-D OBJECT RECOGNITION	REPRESENTATION; SYSTEM	We present an approach for the recognition of multiple 3-D object models from three 3-D scene data. We work on dense data, but neither the models nor the scene data have to be complete. We are addressing the problem in a realistic environment; the viewpoint is arbitrary, the objects vary widely in complexity, and we make no assumptions about the structure of the surface. Our approach is novel in that it uses two different types of primitives for matching: small surface patches, where differential properties can be reliably computed, and lines corresponding to depth or orientation discontinuities. These are represented by splashes and 3-D curves, respectively. We show how both of these primitives can be encoded by a set of super segments, consisting of connected linear segments. These super segments are entered into a table and provide the essential mechanism for fast retrieval and matching. We address in detail the issues of robustness and stability of our features. The acquisition of the 3-D models is performed automatically by computing splashes in highly structured areas of the objects and by using boundary and surface edges for the generation of 3-D curves. For every model, all features are recorded in a database. The scene is screened for highly structured areas, and splashes are computed in these areas and encoded. 3-D curves, corresponding to depth or orientation discontinuities, are also encoded. These features are used to retrieve hypotheses from the database. Clusters of mutually consistent hypotheses represent instances of models. The precise pose of a model instance in the scene is found by applying a least squares match on all corresponding features. We present results with our current system (three dimensional object recognition based on super segments (TOSS)) and discuss further extensions.			STEIN, F (corresponding author), UNIV SO CALIF,INST ROBOT & INTELLIGENT SYST,LOS ANGELES,CA 90089, USA.							Besl P J., 1990, MACHINE VISION 3 DIM, P25; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P340, DOI 10.1109/TPAMI.1984.4767527; BOLLES RC, 1986, INT J ROBOT RES, V5, P3, DOI 10.1177/027836498600500301; BREUEL TM, 1989, P DARPA IU WORKSHOP, P805; CHEN CH, 1989, IEEE T SYST MAN CYB, V19, P1535, DOI 10.1109/21.44070; FAN TJ, 1989, IEEE T PATTERN ANAL, V11, P1140, DOI 10.1109/34.42853; FAN TJ, 1990, DESCRIBING RECOGNIZI; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; FLYNN PJ, 1989, JUN P C COMP VIS PAT, P110; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; GRIMSON WEL, 1988, DEC P ICCV TAMP, P218; HORAUD P, 1984, MAR P INT C ROB ATL, P78; IKEUCHI K, 1987, FEB P DARPA IM UND W, P321; KALVIN A, 1986, INT J ROBOT RES, V5, P38, DOI 10.1177/027836498600500403; KISHON E, 1990, APR P EUR C COMP VIS, P589; LAMDAN Y, 1988, APR P IEEE INT C ROB; LAMDAN Y, 1988, JUN P INT C NEUR NET, V2, P218; PARVIN B, 1989, JUN P INT C NEUR NET, V2, P281; RADACK GM, 1989, COMPUT VISION GRAPH, V45, P380, DOI 10.1016/0734-189X(89)90090-X; SAINTMARC P, 1991, IEEE T PATTERN ANAL, V13, P514, DOI 10.1109/34.87339; SATO K, 1987, JUN P IEEE INT C COM, P657; STEIN F, 1990, JUN P INT C REC ATL; STEIN F, 1990, SEP P DARPA IM UND W; Vitter JS, 1987, DESIGN ANAL COALESCE	25	258	279	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1992	14	2					125	145		10.1109/34.121785	http://dx.doi.org/10.1109/34.121785			21	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC029					2022-12-18	WOS:A1992HC02900004
J	WOLFF, LB; BOULT, TE				WOLFF, LB; BOULT, TE			CONSTRAINING OBJECT FEATURES USING A POLARIZATION REFLECTANCE MODEL	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CIRCUIT BOARD INSPECTION; COMPUTER VISION; EDGE LABELING; MACHINE VISION; MATERIAL CLASSIFICATION; POLARIZATION OF LIGHT; REFLECTANCE MODEL; SEPARATION OF REFLECTION COMPONENTS; SURFACE NORMAL DETERMINATION	SPECULAR SURFACES; ROUGH-SURFACE; COLOR	A growing trend in computer vision has been the use of physical reflectance models, predicting reflected radiant intensity and color, to obtain constraints on object features. Until recently, relatively little attention has been paid to analysis of the reflected polarization state of light and what feature constraints this might provide to an automated vision system. Even though there is no analogy with human vision, we demonstrate that a wealth of constraint information can be obtained by resolving polarization components of reflected light with a polarizing filter placed in front of a camera sensor. We present a polarization reflectance model known as the Fresnel reflectance model because of its use of the Fresnel reflection coefficients. This reflectance model accurately predicts the magnitudes of polarization components of reflected light, and all the polarization-based methods presented in this paper follow from this model. We demonstrate the capability of polarization-based methods to segment material surfaces according to varying levels of relative electrical conductivity, in particular distinguishing dielectrics, which are nonconducting, and metals, which are highly conductive. Polarization-based methods can provide cues for distinguishing different intensity-edge types arising from intrinsic light-dark or color variations, intensity edges caused by specularities, and intensity edges caused by occluding contours where the viewing direction becomes nearly orthogonal to surface normals. Analysis of reflected polarization components is also shown to enable the separation of diffuse and specular components of reflection, unobscuring intrinsic surface detail saturated by specular glare. Finally, we address polarization-based methods used for constraining surface normals.	COLUMBIA UNIV,DEPT COMP SCI,NEW YORK,NY 10027	Columbia University			Boult, Terrance E./AAT-2134-2021	Boult, Terrance E./0000-0001-5007-2529				BAHAR E, 1987, J GEOPHYS RES-OCEANS, V92, P5209, DOI 10.1029/JC092iC05p05209; Beckmann P., 1968, DEPOLARIZATION ELECT; Beckmann Petr, 1987, SCATTERING ELECTROMA, P4; Born M.A.X., 1980, PRINCIPLES OPTICS, VSixth, P1, DOI 10.1016/B978-0-08-026482-0.50008-6; BOULT TE, 1991, JUN P IEEE C COMP VI; Brelstaff G., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P297, DOI 10.1109/CCV.1988.590004; BRELSTAFF G, 1989, THESIS U EDINBURGH; Cook R. L., 1981, Computer Graphics, V15, P307, DOI 10.1145/965161.806819; FOBRUS K, 1977, MIT AI422 MEM; GERSHON R, 1987, 1ST P INT C COMP VIS, P161; Grainger J. F., 1971, POLARIZED LIGHT OPTI; HEALEY G, 1989, J OPT SOC AM A, V6, P920, DOI 10.1364/JOSAA.6.000920; HEALEY G, 1988, APR SPIE P OPT ELE O; HEALEY G, COMMUNICATION; HEALEY G, 1988, APR P DARAP IM UND W, P1140; Horn Berthold K. P., 1975, PSYCHOL COMPUTER VIS, P115; IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167; KLINKER G, 1987, 1ST P INT C COMP VIS, P145; KLINKER GJ, 1988, THESIS CARNEGIE MELL; KOSHIKAWA K, 1979, 6TH P INT JOINT C AR, P493; KOSHIKAWA K, 1987, ADV ROBOTICS, V2; MARION H, 1980, CLASSICAL ELECTROMAG; Marr D., 1982, VISION; NAYAR SK, 1988, CMU RITR8814 TECH RE; NAYAR SK, 1987, P SPIE OPT ILLUMIN 2, V850, P122; PORTER GB, 1981, P SOC PHOTO-OPT INST, V281, P176, DOI 10.1117/12.965745; SANDERSON AC, 1988, IEEE T PATTERN ANAL, V10, P44, DOI 10.1109/34.3866; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; Siegel R., 1981, THERMAL RAD HEAT TRA; TAGARE HD, 1989, JUN P IEEE C COMP VI, P38; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; TROWBRIDGE TS, 1975, J OPT SOC AM, V65, P531, DOI 10.1364/JOSA.65.000531; TSAI R, 1986, JUN P INT C COMP VIS, P364; ULLMAN S, 1976, BIOL CYBERN, V21, P205, DOI 10.1007/BF00344165; WOLFF LB, 1990, IEEE T PATTERN ANAL, V12, P1059, DOI 10.1109/34.61705; WOLFF LB, 1989, JUN P IEEE C COMP VI, P363; WOLFF LB, 1987, NOV P OPT ILL IM SEN, V850, P110; WOLFF LB, 1989, NOV P OPT ILL IM SEN, V1194, P287; WOLFF LB, 1989, MAY P DARPA IM UND W, P232; WOLFF LB, 1991, THESIS COLUMBIA U; WOLFF LB, 1989, JUN P IEEE C COMP VI, P387; WOODHAM RJ, 1978, MIT ALTR457 LAB TECH	42	258	289	4	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1991	13	7					635	657		10.1109/34.85655	http://dx.doi.org/10.1109/34.85655			23	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GA139					2022-12-18	WOS:A1991GA13900003
J	ZHENG, QF; CHELLAPPA, R				ZHENG, QF; CHELLAPPA, R			ESTIMATION OF ILLUMINANT DIRECTION, ALBEDO, AND SHAPE FROM SHADING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						EARLY VISION; ILLUMINANT DIRECTION ESTIMATION; REGULARIZATION; SHAPE FROM SHADING		A robust approach to recovery of shape from shading information is presented. Assuming uniform albedo and Lambertian surface for the imaging model, we first present methods for the estimation of illuminant direction and surface albedo. Two methods for estimating the azimuth of the illuminant are presented. One is based on local estimates on smooth patches. The other method uses shading information along image contours. The elevation of the illuminant and surface albedo are estimated from image statistics, taking into consideration the effect of self-shadowing. With the estimated reflectance map parameters, we then compute the surface shape using a new procedure that implements the smoothness constraint by requiring the gradients of reconstructed intensity to be close to the gradients of the input image. The new algorithm is data driven, stable, updates the surface slope and height maps simultaneously, and significantly reduces the residual errors in irradiance and integrability terms. A hierarchical implementation of the SFS algorithm is presented. Typical results on synthetic and real images are given to illustrate the usefulness of our approach.	UNIV MARYLAND,INST ADV COMP STUDIES,DEPT ELECT ENGN,COLLEGE PK,MD 20702; UNIV MARYLAND,CTR AUTOMATED RES,COLLEGE PK,MD 20702	University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park			Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/AAV-8690-2020					BROOKS MJ, 1985, AUG P INT JOINT C AR, P932; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; FRANKOT RT, 1990, ARTIFICIAL INTELL, V43; Horn B., 1986, ROBOT VISION, P1; Horn B.K., 1990, INT J COMPUT VISION, V5, P584; Horn B.K.P., 1970, THESIS MIT CAMBRIDGE; Horn B.K.P., 1989, SHAPE SHADING; Horn Berthold K. P., 1975, PSYCHOL COMPUTER VIS, P115; HORN BKP, 1981, P IEEE, V69, P14, DOI 10.1109/PROC.1981.11918; HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3; HURLBERT AC, 1989, MIT AI1154 LAB TECH; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; KLINKER GJ, 1988, INT J COMPUT VISION, V2, P7, DOI 10.1007/BF00836279; LEE CH, 1989, SHAPE SHADING, P323; MALIK J, 1989, IEEE T PATTERN ANAL, V11, P555, DOI 10.1109/34.24791; PELEG S, 1990, IEEE T PATTERN ANAL, V12, P1206, DOI 10.1109/34.62611; Pentland A, 1988, P INT C COMP VIS, P404; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P153, DOI 10.1007/BF00127815; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P170, DOI 10.1109/TPAMI.1984.4767501; PENTLAND AP, 1982, J OPT SOC AM, V72, P448, DOI 10.1364/JOSA.72.000448; RAMACHANDRAN VS, 1988, NATURE, V331, P163, DOI 10.1038/331163a0; SHAO M, 1988, JUN P COMP VIS PATT, P530; SIMCHONY T, 1990, IEEE T PATTERN ANAL, V12, P435, DOI 10.1109/34.55103; SZELISKI R, 1990, IEEE T PATTERN ANAL, V12, P513, DOI 10.1109/34.56188; ZHENG Q, 1990, USCSIPI159 U SO CAL	25	258	302	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1991	13	7					680	702		10.1109/34.85658	http://dx.doi.org/10.1109/34.85658			23	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GA139					2022-12-18	WOS:A1991GA13900006
J	ARBTER, K; SNYDER, WE; BURKHARDT, H; HIRZINGER, G				ARBTER, K; SNYDER, WE; BURKHARDT, H; HIRZINGER, G			APPLICATION OF AFFINE-INVARIANT FOURIER DESCRIPTORS TO RECOGNITION OF 3-D OBJECTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									N CAROLINA STATE UNIV,CTR COMMUN & SIGNAL PROC,RALEIGH,NC 27695; TECH UNIV HAMBURG,HAMBURG,GERMANY	University of North Carolina; North Carolina State University; Hamburg University of Technology	ARBTER, K (corresponding author), DEUTSCH FORSCHUNGSANSTALT LUFT & RAUMFAHRT EV,WESSELING,GERMANY.		Burkhardt, Hans/M-5895-2019					ARBTER K, 1989, PIXELS FEATURES; ARBTER K, 1984, Z FLUGWISSENSCHAFTEN, V5; BURKHARDT H, 1979, FORTSCHRITTBERICH 10; COSGRIFF RL, 1960, AD254792; CRIMMINS TR, 1982, IEEE T SYST MAN CYBE, V12; Duda R.O., 1973, J ROYAL STAT SOC SER; EICHMANN G, P SPIE, P482; GRANLUND GH, 1972, IEEE T COMPUT, V21; KUHL FP, 1982, COMPUT GRAPHICS IMAG, V18; LANZO M, 1987, 871 TECH REP; LIN CC, 1986, JUN P IEEE C COMP VI; MA J, 1986, COMPUT VISION GRAPH, V34, P282, DOI 10.1016/S0734-189X(86)80043-3; MITCHELL OR, 1984, OPT ENG, V23; Miyatake T., 1983, Transactions of the Information Processing Society of Japan, V24, P64; NAAS J, 1961, MATH WORTERBUCH; Papoulis A., 1962, FOURIER INTEGRAL ITS; PERSOON E, 1974, 2ND P IJCPR; PERSOON E, 1977, IEEE T SYST MAN CYBE, V7; RICHARD CW, 1974, IEEE T SYST MAN CYBE, V4; THOMPSON DW, 1987, P C ROBOTICS AUTOMAT; WALLACE TP, 1980, COMPUT VISION GRAPH, V13, P99, DOI 10.1016/S0146-664X(80)80035-9; WALLACE TP, 1980, IEEE T PATTERN ANAL, V2; ZAHN CT, 1972, IEEE T COMPUT, V21	23	258	290	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1990	12	7					640	647		10.1109/34.56206	http://dx.doi.org/10.1109/34.56206			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DK894		Green Submitted			2022-12-18	WOS:A1990DK89400003
J	Zhang, CQ; Fu, HZ; Hu, QH; Cao, XC; Xie, Y; Tao, DC; Xu, D				Zhang, Changqing; Fu, Huazhu; Hu, Qinghua; Cao, Xiaochun; Xie, Yuan; Tao, Dacheng; Xu, Dong			Generalized Latent Multi-View Subspace Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustering methods; Correlation; Electronic mail; Neural networks; Task analysis; Clustering algorithms; Minimization; Multi-view clustering; subspace clustering; latent representation; neural networks	ALGORITHM; SPARSE	Subspace clustering is an effective method that has been successfully applied to many applications. Here, we propose a novel subspace clustering model for multi-view data using a latent representation termed Latent Multi-View Subspace Clustering (LMSC). Unlike most existing single-view subspace clustering methods, which directly reconstruct data points using original features, our method explores underlying complementary information from multiple views and simultaneously seeks the underlying latent representation. Using the complementarity of multiple views, the latent representation depicts data more comprehensively than each individual view, accordingly making subspace representation more accurate and robust. We proposed two LMSC formulations: linear LMSC (lLMSC), based on linear correlations between latent representation and each view, and generalized LMSC (gLMSC), based on neural networks to handle general relationships. The proposed method can be efficiently optimized under the Augmented Lagrangian Multiplier with Alternating Direction Minimization (ALM-ADM) framework. Extensive experiments on diverse datasets demonstrate the effectiveness of the proposed method.	[Zhang, Changqing; Hu, Qinghua] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China; [Fu, Huazhu] Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates; [Cao, Xiaochun] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China; [Xie, Yuan] Chinese Acad Sci, Inst Automat, Res Ctr Precis Sensing & Control, Beijing 100190, Peoples R China; [Tao, Dacheng] Univ Sydney, Fac Engn & Informat Technol, Sch Informat Technol, UBTECH Sydney Artificial Intelligence Ctr, 6 Cleveland St, Darlington, NSW 2008, Australia; [Xu, Dong] Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia	Tianjin University; Chinese Academy of Sciences; Institute of Information Engineering, CAS; Chinese Academy of Sciences; Institute of Automation, CAS; University of Sydney; University of Sydney	Zhang, CQ; Hu, QH (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.	zhangchangqing@tju.edu.cn; huazhufu@gmail.com; huqinghua@tju.edu.cn; caoxiaochun@iie.ac.cn; yuan.xie@ia.ac.cn; dacheng.tao@sydney.edu.au; dong.xu@sydney.edu.au	Xu, Dong/A-3694-2011; Fu, Huazhu/A-1411-2014	Xu, Dong/0000-0003-2775-9730; Fu, Huazhu/0000-0002-9702-5524; xie, yuan/0000-0001-6945-7437	National Natural Science Foundation of China [61602337, 61732011, 61432011, U1435212, U1636214, 61733007, 61602345]; NIH [CA206100, MH100217]; Australian Research Council Projects [FL-170100117, DP-180103424]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Australian Research Council Projects(Australian Research Council)	This work was supported by the National Natural Science Foundation of China (No. 61602337, 61732011, 61432011, U1435212, U1636214, 61733007 and 61602345), NIH Projects (No. CA206100 and MH100217), and Australian Research Council Projects (No. FL-170100117 and DP-180103424). Changqing Zhang and Huazhu Fu contributed equally to this work.	Abavisani M., 2016, P BRIT MACH VIS C; Abavisani M, 2018, INFORM FUSION, V39, P168, DOI 10.1016/j.inffus.2017.05.002; Amini M.R., 2009, ADV NEURAL INFORM PR, P28, DOI DOI 10.5555/2984093.2984097; Andrew Galen, 2013, ICML; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2006, P 23 INT C MACH LEAR; Arora R, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6854050; BARTELS RH, 1972, COMMUN ACM, V15, P820, DOI 10.1145/361573.361582; Bradley PS, 2000, J GLOBAL OPTIM, V16, P23, DOI 10.1023/A:1008324625522; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Cai X., 2013, P 23 INT JOINT C ART, P2598, DOI DOI 10.5555/2540128.2540503; CAO XC, 2015, PROC CVPR IEEE, P586, DOI DOI 10.1109/CVPR.2015.7298657; Chaudhuri K., 2009, PROC INT C MACHINE L, P129, DOI DOI 10.1145/1553374.1553391; Cheng B, 2011, IEEE I CONF COMP VIS, P2439, DOI 10.1109/ICCV.2011.6126528; Cortes, 2009, NEURAL INF PROCESS S; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; De Sa V.R., 2005, ICML WORKSHOP LEARNI, P20; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Feng JS, 2014, PROC CVPR IEEE, P3818, DOI 10.1109/CVPR.2014.482; Gao HC, 2015, IEEE I CONF COMP VIS, P4238, DOI 10.1109/ICCV.2015.482; He J., 2011, PROC INT C MACH LEAR, P25; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hu H, 2014, PROC CVPR IEEE, P3834, DOI 10.1109/CVPR.2014.484; Ji P, 2017, ADV NEUR IN, V30; Jiao H, 2015, ASIA PAC J MANAG, V32, P1083, DOI 10.1007/s10490-015-9427-y; KETTENRING JR, 1971, BIOMETRIKA, V58, P433, DOI 10.1093/biomet/58.3.433; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar A., 2011, P 28 INT C MACH LEAR, P393, DOI DOI 10.5555/3104482.3104532; Kumar Abhishek, 2011, NEURIPS, P2, DOI DOI 10.5555/2986459.2986617; Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140; Lang CY, 2012, IEEE T IMAGE PROCESS, V21, P1327, DOI 10.1109/TIP.2011.2169274; Lin Z., 2011, PROC INT 25 C NEURAL, P612, DOI DOI 10.1007/S11263-013-0611-6; Liu G., 2010, P 27 INT C MACHINE L, P663, DOI DOI 10.1109/ICDMW.2010.64; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu GC, 2011, IEEE I CONF COMP VIS, P1615, DOI 10.1109/ICCV.2011.6126422; Liu J., 2013, PROC SOC IND APPL MA, P252, DOI [10.1137/1.9781611972832.28, DOI 10.1137/1.9781611972832.28]; Luo Y, 2015, IEEE T KNOWL DATA EN, V27, P3111, DOI 10.1109/TKDE.2015.2445757; Ng AY, 2002, ADV NEUR IN, V14, P849; Parsons L., 2004, ACM SIGKDD EXPLOR NE, V6, P90, DOI [10.1145/1007730.1007731, DOI 10.1145/1007730.1007731]; Patel VM, 2013, IEEE I CONF COMP VIS, P225, DOI 10.1109/ICCV.2013.35; Peng X., 2016, IJCAI, P1925; Peng Xingchao, 2017, VISDA VISUAL DOMAIN; Rastogi Pushpendre, 2015, P 2015 C N AM CHAPT, P556, DOI DOI 10.3115/V1/N15-1058; Sharma A., 2012, CVPR, DOI DOI 10.1109/CVPR.2012.6247923; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shuhang G., 2014, ADV NEURAL INFORM PR, V27, P793; Tang J, 2013, HANDBOOK OF PROTEOLYTIC ENZYMES, VOLS 1 AND 2, 3RD EDITION, P27, DOI 10.1016/B978-0-12-382219-2.00003-X; Tang W, 2009, IEEE DATA MINING, P1016, DOI 10.1109/ICDM.2009.125; Tzortzis G, 2012, IEEE DATA MINING, P675, DOI 10.1109/ICDM.2012.43; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vidal R, 2005, IEEE T PATTERN ANAL, V27, P1945, DOI 10.1109/TPAMI.2005.244; Vidal R, 2011, IEEE SIGNAL PROC MAG, V28, P52, DOI 10.1109/MSP.2010.939739; Wahba Grace, 1965, SIAM REV, V7, P409, DOI DOI 10.1137/1007077; White Martha, 2012, ADV NEURAL INFORM PR, P1682; Xia RK, 2014, AAAI CONF ARTIF INTE, P2149; Xie Y, 2018, INT J COMPUT VISION, V126, P1157, DOI 10.1007/s11263-018-1086-2; Xu C, 2014, IEEE T PATTERN ANAL, V36, P1559, DOI 10.1109/TPAMI.2013.2296528; Xu JL, 2016, PROC CVPR IEEE, P5356, DOI 10.1109/CVPR.2016.578; Yin M, 2016, PROC CVPR IEEE, P5157, DOI 10.1109/CVPR.2016.557; Zhang CQ, 2017, PROC CVPR IEEE, P4333, DOI 10.1109/CVPR.2017.461; Zhang CQ, 2017, IEEE T IMAGE PROCESS, V26, P648, DOI 10.1109/TIP.2016.2627806; Zhang CQ, 2015, IEEE I CONF COMP VIS, P1582, DOI 10.1109/ICCV.2015.185; Zhang Z, 2019, IEEE T PATTERN ANAL, V41, P1774, DOI 10.1109/TPAMI.2018.2847335; Zhu XW, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON THE MODERN DEVELOPMENT OF HUMANITIES AND SOCIAL SCIENCE, P387	64	257	265	14	126	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2020	42	1					86	99		10.1109/TPAMI.2018.2877660	http://dx.doi.org/10.1109/TPAMI.2018.2877660			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JV3VQ	30369436				2022-12-18	WOS:000502294300007
J	Kemelmacher-Shlizerman, I; Basri, R				Kemelmacher-Shlizerman, Ira; Basri, Ronen			3D Face Reconstruction from a Single Image Using a Single Reference Face Shape	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; photometry; shape from shading; 3D reconstruction; lighting; single images; face; depth reconstruction	ILLUMINATION; RECOGNITION	Human faces are remarkably similar in global properties, including size, aspect ratio, and location of main features, but can vary considerably in details across individuals, gender, race, or due to facial expression. We propose a novel method for 3D shape recovery of faces that exploits the similarity of faces. Our method obtains as input a single image and uses a mere single 3D reference model of a different person's face. Classical reconstruction methods from single images, i.e., shape-from-shading, require knowledge of the reflectance properties and lighting as well as depth values for boundary conditions. Recent methods circumvent these requirements by representing input faces as combinations (of hundreds) of stored 3D models. We propose instead to use the input image as a guide to "mold" a single reference model to reach a reconstruction of the sought 3D shape. Our method assumes Lambertian reflectance and uses harmonic representations of lighting. It has been tested on images taken under controlled viewing conditions as well as on uncontrolled images downloaded from the Internet, demonstrating its accuracy and robustness under a variety of imaging conditions and overcoming significant differences in shape between the input and reference individuals including differences in facial expressions, gender, and race.	[Kemelmacher-Shlizerman, Ira] Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA; [Basri, Ronen] Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel	University of Washington; University of Washington Seattle; Weizmann Institute of Science	Kemelmacher-Shlizerman, I (corresponding author), Univ Washington, Dept Comp Sci & Engn, Box 352350, Seattle, WA 98195 USA.	kemelmi@cs.washington.edu; ronen.basri@weizmann.ac.il			Israel Science Foundation [266/02]; European Commission [IST-2002-506766]	Israel Science Foundation(Israel Science Foundation); European Commission(European CommissionEuropean Commission Joint Research Centre)	This research was supported in part by the Israel Science Foundation grant number 266/02 and by the European Commission Project IST-2002-506766 Aim Shape. The vision group at the Weizmann Institute is supported in part by the Moross Laboratory for Vision Research and Robotics.	Atick JJ, 1996, NEURAL COMPUT, V8, P1321, DOI 10.1162/neco.1996.8.6.1321; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Castelan M, 2007, IEEE T IMAGE PROCESS, V16, P1139, DOI 10.1109/TIP.2006.891351; Chandraker M.K., 2007, P IEEE C COMP VIS PA; Cootes Timothy F, 1998, P EUR C COMP VIS; Dovgard R, 2004, P EUR C COMP VIS; Dupuis P, 1994, ANN APPL PROBAB, V4, P287, DOI 10.1214/aoap/1177005063; EDWARDS GJ, 1996, P 2 INT C AUT FAC GE, V2; Frolova D, 2004, LECT NOTES COMPUT SC, V3021, P574; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Hernandez C, 2008, IEEE T PATTERN ANAL, V30, P548, DOI 10.1109/TPAMI.2007.70820; Horn B.K.P., 1975, PSYCHOL COMPUTER VIS; Horn B.K.P., 1989, SHAPE SHADING; HURSH TM, 1976, MEASURES MAN; Katz S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276407; KEMELMACHER I, 2006, P EUR C COMP VIS, V1, P277; Kimmel R, 2001, J MATH IMAGING VIS, V14, P237, DOI 10.1023/A:1011234012449; Lanitis A, 1997, IEEE T PATTERN ANAL, V19, P743, DOI 10.1109/34.598231; Marschner S., 1999, P 10 EUR WORKSH REND, P139; Moses Y, 1996, PERCEPTION, V25, P443, DOI 10.1068/p250443; PENTLAND AP, 1982, J OPT SOC AM, V72, P448, DOI 10.1364/JOSA.72.000448; RAMACHANDRAN VS, 1990, AI AND THE EYE, P21; RAMACHANDRAN VS, 1988, NATURE, V331, P163, DOI 10.1038/331163a0; Ramamoorthi R, 2001, J OPT SOC AM A, V18, P2448, DOI 10.1364/JOSAA.18.002448; ROUY E, 1992, SIAM J NUMER ANAL, V29, P867, DOI 10.1137/0729053; Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964; Shimshoni I, 2000, INT J COMPUT VISION, V39, P97, DOI 10.1023/A:1008118909580; Sim T., 2001, P CVPR WORKSH MOD VE; SMITH WAP, 2005, P IEEE INT C COMP VI; TSAI PS, 1998, P OPT ENG APR, P121; *USF DARPA, 2010, HUM ID 3D FAC DAT; Zhang L., 2003, P IEEE C COMP VIS PA; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; Zhao WY, 2001, INT J COMPUT VISION, V45, P55, DOI 10.1023/A:1012369907247; ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658; ZHOU S, 2004, P EUR C COMP VIS	38	257	272	3	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2011	33	2					394	405		10.1109/TPAMI.2010.63	http://dx.doi.org/10.1109/TPAMI.2010.63			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	694QR	21193812				2022-12-18	WOS:000285313200014
J	Junejo, IN; Dexter, E; Laptev, I; Perez, P				Junejo, Imran N.; Dexter, Emilie; Laptev, Ivan; Perez, Patrick			View-Independent Action Recognition from Temporal Self-Similarities	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human action recognition; human action synchronization; view invariance; temporal self-similarities; local temporal descriptors	RECURRENCE PLOTS	This paper addresses recognition of human actions under view changes. We explore self-similarities of action sequences over time and observe the striking stability of such measures across views. Building upon this key observation, we develop an action descriptor that captures the structure of temporal similarities and dissimilarities within an action sequence. Despite this temporal self-similarity descriptor not being strictly view-invariant, we provide intuition and experimental validation demonstrating its high stability under view changes. Self-similarity descriptors are also shown to be stable under performance variations within a class of actions when individual speed fluctuations are ignored. If required, such fluctuations between two different instances of the same action class can be explicitly recovered with dynamic time warping, as will be demonstrated, to achieve cross-view action synchronization. More central to the current work, temporal ordering of local self-similarity descriptors can simply be ignored within a bag-of-features type of approach. Sufficient action discrimination is still retained in this way to build a view-independent action recognition system. Interestingly, self-similarities computed from different image features possess similar properties and can be used in a complementary fashion. Our method is simple and requires neither structure recovery nor multiview correspondence estimation. Instead, it relies on weak geometric properties and combines them with machine learning for efficient cross-view action recognition. The method is validated on three public data sets. It has similar or superior performance compared to related methods and it performs well even in extreme conditions, such as when recognizing actions from top views while using side views only for training.	[Junejo, Imran N.] Univ Sharjah, Dept Comp Sci, Sharjah, U Arab Emirates; [Dexter, Emilie] INRIA Rennes Bretagne Atlantique, Rennes, France; [Laptev, Ivan] INRIA paris Rocquencourt ENS, F-75013 Paris, France; [Perez, Patrick] Thomson R&D, F-35576 Cesson Sevigne, France	University of Sharjah	Junejo, IN (corresponding author), Univ Sharjah, Dept Comp Sci, POB 27272, Sharjah, U Arab Emirates.	ijunejo@sharjah.ac.ae; emilie.dexter@inria.fr; ivan.laptev@inria.fr; Patrick.Perez@thomson.net	Junejo, Imran/ABA-2975-2020		QUAERO; MSR/INRIA joint laboratory	QUAERO; MSR/INRIA joint laboratory	This work was partially funded by the QUAERO project and the MSR/INRIA joint laboratory.	Ahmad M, 2006, INT C PATT RECOG, P263; Ali S., 2007, P IEEE INT C COMP VI; [Anonymous], 2009, BMVC 2009 BRIT MACH; BenAbdelkader C, 2004, EURASIP J APPL SIG P, V2004, P572, DOI 10.1155/S1110865704309236; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Bradley E, 2002, CHAOS, V12, P596, DOI 10.1063/1.1488255; Carlsson S, 2003, INT J ROBOT RES, V22, P359, DOI 10.1177/0278364903022006002; Carlsson S, 2000, LECT NOTES COMPUT SC, V1842, P472; Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; de Sa JPM, 2007, APPL STAT USING SPSS; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; ECKMANN JP, 1987, EUROPHYS LETT, V4, P973, DOI 10.1209/0295-5075/4/9/004; Farhadi A, 2008, LECT NOTES COMPUT SC, V5302, P154, DOI 10.1007/978-3-540-88682-2_13; Gilbert A, 2008, LECT NOTES COMPUT SC, V5302, P222, DOI 10.1007/978-3-540-88682-2_18; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Grundmann M, 2008, INT C PATT RECOG, P725; Ikizler N, 2007, LECT NOTES COMPUT SC, V4814, P271; Iwanski JS, 1998, CHAOS, V8, P861, DOI 10.1063/1.166372; JIA K, 2008, P IEEE CS C COMP VIS; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I., 2008, P IEEE CS C COMP VIS; Laptev I, 2007, COMPUT VIS IMAGE UND, V108, P207, DOI 10.1016/j.cviu.2006.11.023; LELE S, 1993, MATH GEOL, V25, P573, DOI 10.1007/BF00890247; Li Rui, 2007, P IEEE INT C COMP VI; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; LV F, 2007, P IEEE CS C COMP VIS; MARSZALEK M, 2007, P PASCAL VOC 07 CHAL; Marwan N, 2007, PHYS REP, V438, P237, DOI 10.1016/j.physrep.2006.11.001; McGuire G, 1997, PHYS LETT A, V237, P43, DOI 10.1016/S0375-9601(97)00697-X; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; Morency L.P., 2007, P IEEE CS C COMP VIS; Natarajan P, 2008, 2008 IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING, P87; Niebles J. C., 2006, P BRIT MACH VIS C; OGALE A, 2006, P W DYN VIS, P115; Parameswaran V, 2006, INT J COMPUT VISION, V66, P83, DOI 10.1007/s11263-005-3671-4; Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Shechtman E, 2005, PROC CVPR IEEE, P405; SHECHTMAN E, 2007, P IEEE CS C COMP VIS; SHEN Y, 2008, P IEEE CS C COMP VIS; SMINCHISESCU C, 2005, P IEEE CS C COMP VIS; Syeda-Mahmood T, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P64, DOI 10.1109/EVENT.2001.938868; TOMASI C, 1994, P IEEE CS C COMP VIS; WANG L, 2007, P IEEE CS C COMP VIS; Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0; WANG SB, 2006, P IEEE CS C COMP VIS; WEINLAND D, 2007, P IEEE INT C COMP VI; WEINLAND D, 2008, P IEEE CS C COMP VIS; Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013; YAN P, 2008, P IEEE CS C COMP VIS; Yilmaz A, 2005, IEEE I CONF COMP VIS, P150; Yilmaz A, 2005, PROC CVPR IEEE, P984	53	257	267	0	57	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2011	33	1					172	185		10.1109/TPAMI.2010.68	http://dx.doi.org/10.1109/TPAMI.2010.68			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	681AC	21088326	Green Submitted			2022-12-18	WOS:000284277600013
J	TERZOPOULOS, D; WATERS, K				TERZOPOULOS, D; WATERS, K			ANALYSIS AND SYNTHESIS OF FACIAL IMAGE SEQUENCES USING PHYSICAL AND ANATOMICAL MODELS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COMPUTER GRAPHICS; COMPUTER VISION; DEFORMABLE MODELS; FACE MODELING; FACIAL IMAGE ANALYSIS; FACIAL IMAGE SYNTHESIS; NONRIGID MOTION ANALYSIS; PHYSICS-BASED MODELING; SNAKES; TRACKING	FINITE-ELEMENT MODEL; SKIN DEFORMATION; TISSUE	We present a new approach to the analysis of dynamic facial images for the purposes of estimating and resynthesizing dynamic facial expressions. The approach exploits a sophisticated generative model of the human face originally developed for realistic facial animation. The face model, which may be simulated and rendered at interactive rates on a graphics workstation, incorporates a physics-based synthetic facial tissue and a set of anatomically motivated facial muscle actuators. We consider the estimation of dynamic facial muscle contractions from video sequences of expressive human faces. We develop an estimation technique that uses deformable contour models (snakes) to track the nonrigid motions of facial features in video images. The technique estimates muscle actuator controls with sufficient accuracy to permit the face model to resynthesize transient expressions.	DIGITAL EQUIPMENT CORP, CAMBRIDGE RES LAB, CAMBRIDGE, MA 02139 USA; SCHLUMBERGER INC, COMP SCI LAB, AUSTIN, TX USA; SCHLUMBERGER INC, PALO ALTO RES LAB, PALO ALTO, CA USA	Schlumberger; Schlumberger	TERZOPOULOS, D (corresponding author), UNIV TORONTO, DEPT COMP SCI, TORONTO M5S 1A4, ONTARIO, CANADA.							Aizawa K., 1989, Signal Processing: Image Communication, V1, P139, DOI 10.1016/0923-5965(89)90006-4; BLEDSOE WW, 1966, PRI22 PAN RES INC RE; Bruce V., 1988, RECOGNIZING FACES; CHOI CS, 1991, P INT C ACOUSTICS SP, P2737; Davies G, 1981, PERCEIVING REMEMBERI; DENG X, 1988, THESIS COLUMBIA U NE; Ekman P., 1977, FACIAL ACTION CODING; EKMAN P, 1971, UNMASKING HUMAN FACE; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; FORCHHEIMER R, 1989, IEEE T ACOUST SPEECH, V37, P2008, DOI 10.1109/29.45550; GOLDSTEI.AA, 1972, AT&T TECH J, V51, P399, DOI 10.1002/j.1538-7305.1972.tb01927.x; Hill D. R., 1988, Visual Computer, V3, P277, DOI 10.1007/BF01914863; Kanade T., 1973, THESIS KYOTO U; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kaya Y., 1972, FRONTIERS PATTERN RE, V1, P265; KENEDI RM, 1975, PHYS MED BIOL, V20, P699, DOI 10.1088/0031-9155/20/5/001; Komatsu K., 1988, Visual Computer, V3, P265, DOI 10.1007/BF01914861; LARRABEE WF, 1986, LARYNGOSCOPE, V96, P413; LARRABEE WF, 1986, LARYNGOSCOPE, V96, P406; LARRABEE WF, 1986, LARYNGOSCOPE, V96, P399; LEE Y, 1993, IN PRESS MAY P GRAPH; LEWIS JP, 1987, P HUMAN FACTORS COMP, P143; Magnenat-Thalmann N., 1988, Visual Computer, V3, P290, DOI 10.1007/BF01914864; MASE K, 1991, IEICE TRANS COMMUN, V74, P3474; PARKE FI, 1982, IEEE COMPUT GRAPH, V2, P61; PIEPER S, 1989, THESIS MIT CAMBRIDGE; Press WH, 1986, NUMERICAL RECIPES C, V818; SAKAI T, 1969, PATTERN RECOGN, V1, P233, DOI 10.1016/0031-3203(69)90006-5; SHAKLETON MA, 1991, P COMPUT VISION PATT, P573; Terzopoulos D., 1988, Visual Computer, V4, P306, DOI 10.1007/BF01908877; TERZOPOULOS D, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P727; TERZOPOULOS D, 1987, TECHNICAL DIGEST SER, V12, P160; Terzopoulos D, 1986, 60 SCHLUMB PAL ALT R; WAITE JB, 1990, BRIT TELECOM TECHNOL, V8, P127; Waters, 2005, COMPUT GRAPH, V21, P17, DOI [10.1145/37402.37405, DOI 10.1145/37402.37405]; Waters K., 1991, Journal of Visualization and Computer Animation, V2, P123, DOI 10.1002/vis.4340020405; WILLIAMS L, COMPUT GRAPH, V24, P235; YUIOLLE AL, 1989, JUN P COMP VIS PATT, P104	38	257	283	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1993	15	6					569	579		10.1109/34.216726	http://dx.doi.org/10.1109/34.216726			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LF257					2022-12-18	WOS:A1993LF25700005
J	Ding, CX; Choi, J; Tao, DC; Davis, LS				Ding, Changxing; Choi, Jonghyun; Tao, Dacheng; Davis, Larry S.			Multi-Directional Multi-Level Dual-Cross Patterns for Robust Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; face image descriptors; face image representation	REPRESENTATION; HISTOGRAM; SCALE; MODEL	To perform unconstrained face recognition robust to variations in illumination, pose and expression, this paper presents a new scheme to extract "Multi-Directional Multi-Level Dual-Cross Patterns" (MDML-DCPs) from face images. Specifically, the MDML-DCPs scheme exploits the first derivative of Gaussian operator to reduce the impact of differences in illumination and then computes the DCP feature at both the holistic and component levels. DCP is a novel face image descriptor inspired by the unique textural structure of human faces. It is computationally efficient and only doubles the cost of computing local binary patterns, yet is extremely robust to pose and expression variations. MDML-DCPs comprehensively yet efficiently encodes the invariant characteristics of a face image from multiple levels into patterns that are highly discriminative of inter-personal differences but robust to intra-personal variations. Experimental results on the FERET, CAS-PERL-R1, FRGC 2.0, and LFW databases indicate that DCP outperforms the state-of-the-art local descriptors (e.g., LBP, LTP, LPQ, POEM, tLBP, and LGXP) for both face identification and face verification tasks. More impressively, the best performance is achieved on the challenging LFW and FRGC 2.0 databases by deploying MDML-DCPs in a simple recognition scheme.	[Ding, Changxing; Tao, Dacheng] Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, 81 Broadway St, Ultimo, NSW 2007, Australia; [Ding, Changxing; Tao, Dacheng] Univ Technol Sydney, Fac Engn & Informat Technol, 81 Broadway St, Sydney, NSW 2007, Australia; [Choi, Jonghyun; Davis, Larry S.] Univ Maryland, Inst Adv Comp Studies, College Pk, MD 20742 USA	University of Technology Sydney; University of Technology Sydney; University System of Maryland; University of Maryland College Park	Ding, CX; Tao, DC (corresponding author), Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, 81 Broadway St, Ultimo, NSW 2007, Australia.; Ding, CX; Tao, DC (corresponding author), Univ Technol Sydney, Fac Engn & Informat Technol, 81 Broadway St, Sydney, NSW 2007, Australia.; Choi, J; Davis, LS (corresponding author), Univ Maryland, Inst Adv Comp Studies, College Pk, MD 20742 USA.	changxing.ding@student.uts.edu.au; jhchoi@umiacs.umd.edu; dacheng.tao@uts.edu.au; lsd@umiacs.umd.edu	Ding, Changxing/L-7075-2019	Choi, Jonghyun/0000-0002-7934-8434	Australian Research Council [DP-140102164, FT-130101457]; China Scholarship Council; US National Science foundation (NSF) [IIS1262121]	Australian Research Council(Australian Research Council); China Scholarship Council(China Scholarship Council); US National Science foundation (NSF)(National Science Foundation (NSF))	This work is partially supported by Australian Research Council Projects DP-140102164 and FT-130101457. C. Ding is partially supported by China Scholarship Council. J. Choi and L. S. Davis are partially supported by the US National Science foundation (NSF) Grant IIS1262121.	Ahonen T., 2008, PATTERN RECOGN, P1; Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Akhtar Z, 2013, LECT NOTES COMPUT SC, V8157, P309, DOI 10.1007/978-3-642-41184-7_32; Barkan O, 2013, IEEE I CONF COMP VIS, P1960, DOI 10.1109/ICCV.2013.246; Beveridge JR, 2015, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2015.7163156; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CAO ZM, 2010, PROC CVPR IEEE, P2707, DOI DOI 10.1109/CVPR.2010.5539992; Chan CH, 2013, IEEE T PATTERN ANAL, V35, P1164, DOI 10.1109/TPAMI.2012.199; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chen D, 2012, LECT NOTES COMPUT SC, V7574, P566, DOI 10.1007/978-3-642-33712-3_41; Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389; Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089; Ding CX, 2015, IEEE T IMAGE PROCESS, V24, P980, DOI 10.1109/TIP.2015.2390959; Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557; Huang GB, 2007, 07 UMASS TR; Hwang W, 2011, IEEE T IMAGE PROCESS, V20, P1152, DOI 10.1109/TIP.2010.2083674; Jonghyun Choi, 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P121, DOI 10.1109/WACV.2012.6163014; Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112; Li P, 2012, IEEE T PATTERN ANAL, V34, P144, DOI 10.1109/TPAMI.2011.104; Liu TL, 2016, IEEE T PATTERN ANAL, V38, P447, DOI 10.1109/TPAMI.2015.2456899; Liu ZM, 2009, LECT NOTES COMPUT SC, V5558, P122; Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Phillips J.J., 2005, PROC CVPR IEEE, V1, P947, DOI DOI 10.1109/CVPR.2005.268; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Prince SJD, 2008, IEEE T PATTERN ANAL, V30, P970, DOI 10.1109/TPAMI.2008.48; Prince SJD, 2007, IEEE I CONF COMP VIS, P1751; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Su Y, 2009, IEEE T IMAGE PROCESS, V18, P1885, DOI 10.1109/TIP.2009.2021737; Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P235; Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645; Trefny J, 2010, P COMP VIS WINT WORK, P37; ul Hussain S, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.99; ul Hussain S, 2012, LECT NOTES COMPUT SC, V7573, P716, DOI 10.1007/978-3-642-33709-3_51; Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230; Wright J, 2009, PROC CVPR IEEE, P1502, DOI 10.1109/CVPRW.2009.5206786; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397; Xie SF, 2009, SIGNAL PROCESS, V89, P2333, DOI 10.1016/j.sigpro.2009.02.016; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578; Yan Li, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P601, DOI 10.1007/978-3-642-37444-9_47; Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956; Zhang WC, 2005, IEEE I CONF COMP VIS, P786	46	256	262	3	153	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2016	38	3					518	531		10.1109/TPAMI.2015.2462338	http://dx.doi.org/10.1109/TPAMI.2015.2462338			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE6JD	27046495	Green Accepted, Green Submitted, Green Published			2022-12-18	WOS:000370738900008
J	Levin, A; Weiss, Y; Durand, F; Freeman, WT				Levin, Anat; Weiss, Yair; Durand, Fredo; Freeman, William T.			Understanding Blind Deconvolution Algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Blind deconvolution; motion deblurring; natrual image statistics; statistical estimation	PHASE; IMAGE; EQUALIZATION	Blind deconvolution is the recovery of a sharp version of a blurred image when the blur kernel is unknown. Recent algorithms have afforded dramatic progress, yet many aspects of the problem remain challenging and hard to understand. The goal of this paper is to analyze and evaluate recent blind deconvolution algorithms both theoretically and experimentally. We explain the previously reported failure of the naive MAP approach by demonstrating that it mostly favors no-blur explanations. We show that, using reasonable image priors, a naive simulations MAP estimation of both latent image and blur kernel is guaranteed to fail even with infinitely large images sampled from the prior. On the other hand, we show that since the kernel size is often smaller than the image size, a MAP estimation of the kernel alone is well constrained and is guaranteed to succeed to recover the true blur. The plethora of recent deconvolution techniques makes an experimental evaluation on ground-truth data important. As a first step toward this experimental evaluation, we have collected blur data with ground truth and compared recent algorithms under equal settings. Additionally, our data demonstrate that the shift-invariant blur assumption made by most algorithms is often violated.	[Levin, Anat] Weizmann Inst Sci, Dept Math & Comp Sci, IL-76100 Rehovot, Israel; [Weiss, Yair] Hebrew Univ Jerusalem, Sch Engn & Comp Sci, IL-91904 Jerusalem, Israel; [Durand, Fredo; Freeman, William T.] MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA; [Freeman, William T.] MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA	Weizmann Institute of Science; Hebrew University of Jerusalem; Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT)	Levin, A (corresponding author), Weizmann Inst Sci, Dept Math & Comp Sci, IL-76100 Rehovot, Israel.	anat.levin@weizmann.ac.il; yweiss@cs.huji.ac.il; fredopdurand@gmail.com; billf@mit.edu		Levin, Anat/0000-0002-9849-9043	Israel Science Foundation; US-Israel Bi-National Science Foundation; Royal Dutch/Shell Group; NGA [NEGI-1582-04-0004]; MURI [N00014-06-1-0734]; US National Science Foundation (NSF) [0447561]; Microsoft Research New Faculty; Sloan Fellowship	Israel Science Foundation(Israel Science Foundation); US-Israel Bi-National Science Foundation(US-Israel Binational Science Foundation); Royal Dutch/Shell Group; NGA; MURI(MURI); US National Science Foundation (NSF)(National Science Foundation (NSF)); Microsoft Research New Faculty(Microsoft); Sloan Fellowship(Alfred P. Sloan Foundation)	The authors thank the Israel Science Foundation, US-Israel Bi-National Science Foundation, the Royal Dutch/Shell Group, NGA NEGI-1582-04-0004, MURI Grant N00014-06-1-0734, US National Science Foundation (NSF) CAREER award 0447561. F. Durand acknowledges a Microsoft Research New Faculty Fellowship and a Sloan Fellowship.	AYERS GR, 1988, OPT LETT, V13, P547, DOI 10.1364/OL.13.000547; Brainard DH, 1997, J OPT SOC AM A, V14, P1393, DOI 10.1364/JOSAA.14.001393; Bronstein MM, 2005, IEEE T IMAGE PROCESS, V14, P726, DOI 10.1109/TIP.2005.847322; Cho S., 2009, P ACM SIGGRAPH; Fergus R., 2006, P ACM SIGGRAPH; FIENUP JR, 1982, APPL OPTICS, V21, P2758, DOI 10.1364/AO.21.002758; GERCHBERG RW, 1972, OPTIK, V35, P237; GODARD DN, 1980, IEEE T COMMUN, V28, P1867, DOI 10.1109/TCOM.1980.1094608; Gonzalez R.C., 2006, DIGITAL IMAGE PROCES; HAYES MH, 1982, IEEE T ACOUST SPEECH, V30, P140, DOI 10.1109/TASSP.1982.1163863; JIA J, 2007, P IEEE C COMP VIS PA; Johnson CR, 1998, P IEEE, V86, P1927, DOI 10.1109/5.720246; Joshi N., 2008, P IEEE C COMP VIS PA; KATSAGGELOS AK, 1991, IEEE T SIGNAL PROCES, V39, P729, DOI 10.1109/78.80894; Kay S. M, 1997, FUNDAMENTALS STAT SI; Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268; LANE RG, 1987, J OPT SOC AM A, V4, P180, DOI 10.1364/JOSAA.4.000180; Levin A., 2007, P ACM SIGGRAPH; Levin A., 2009, MITCSAILTR2009014; Levin Anat, 2006, P ADV NEUR INF PROC; Likas AC, 2004, IEEE T SIGNAL PROCES, V52, P2222, DOI 10.1109/TSP.2004.831119; Miskin J.W., 2000, P ADV IND COMP AN; Molina R., 1997, P IEEE INT C AC SPEE; Roth S., 2005, P IEEE CS C COMP VIS; SHALVI O, 1990, IEEE T INFORM THEORY, V36, P312, DOI 10.1109/18.52478; Shan Q., 2007, P IEEE 11 INT C COMP; Shan Q., 2008, P ACM SIGGRAPH; Simoncelli E.P., 1999, BAYESIAN INFERENCE W; THIEBAUT E, 1995, J OPT SOC AM A, V12, P485, DOI 10.1364/JOSAA.12.000485; WEISS Y, 2007, P IEEE C COMP VIS PA; Whyte O., 2010, P IEEE C COMP VIS PA; Xu L., 2010, P 11 EUR C COMP VIS	32	256	279	4	75	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2011	33	12					2354	2367		10.1109/TPAMI.2011.148	http://dx.doi.org/10.1109/TPAMI.2011.148			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	834RE	21788664				2022-12-18	WOS:000295980000004
J	Wang, XG; Tang, XO				Wang, XG; Tang, XO			A unified framework for subspace face recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face recognition; subspace analysis; PCA; LDA; Bayesian analysis; eigenface	EIGENFACES	PCA, LDA, and Bayesian analysis are the three most representative subspace face recognition approaches. In this paper, we show that they can be unified under the same framework. We first model face difference with three components: intrinsic difference, transformation difference, and noise. A unified framework is then constructed by using this face difference model and a detailed subspace analysis on the three components. We explain the inherent relationship among different subspace methods and their unique contributions to the extraction of discriminating information from the face difference. Based on the framework, a unified subspace analysis method is developed using PCA, Bayes, and LDA as three steps. A 3D parameter space is constructed using the three subspace dimensions as axes. Searching through this parameter space, we achieve better recognition performance than standard subspace methods.	Chinese Univ Hong Kong, Dept Informat Engn, HSH, Shatin, Hong Kong, Peoples R China	Chinese University of Hong Kong	Wang, XG (corresponding author), Chinese Univ Hong Kong, Dept Informat Engn, HSH, 826B, Shatin, Hong Kong, Peoples R China.	xgwang1@ie.cuhk.edu.hk; xtang@ie.cuhk.edu.hk	Tang, Xiaoou/G-6509-2012; Wang, Xiaogang/L-4369-2014	Wang, Xiaogang/0000-0002-9021-0954				Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Fukunnaga K., 1991, INTRO STAT PATTERN R, V2nd; Kim HC, 2002, INT C PATT RECOG, P486, DOI 10.1109/ICPR.2002.1048344; KRAMER MA, 1991, AICHE J, V32, P1010; Liu CJ, 1998, INT C PATT RECOG, P1368, DOI 10.1109/ICPR.1998.711956; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Liu QS, 2002, INT C PATT RECOG, P362, DOI 10.1109/ICPR.2002.1048314; Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P780, DOI 10.1109/TPAMI.2002.1008384; MOSES Y, 1994, P EUR C COMP VIS, P286; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WANG X, 2003, P ACM SIGGM 2003 MUL; Wang XG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P679, DOI 10.1109/ICCV.2003.1238413; Yang MH, 2000, IEEE IMAGE PROC, P37, DOI 10.1109/ICIP.2000.900886; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X; YUNEN PC, 2002, PATTERN RECOGN, V35, P1247; Zhao W, 1998, PROC CVPR IEEE, P164, DOI 10.1109/CVPR.1998.698604	19	256	281	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2004	26	9					1222	U3		10.1109/TPAMI.2004.57	http://dx.doi.org/10.1109/TPAMI.2004.57			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	837CM	15742896				2022-12-18	WOS:000222605100010
J	SCLAROFF, S; PENTLAND, AP				SCLAROFF, S; PENTLAND, AP			MODAL MATCHING FOR CORRESPONDENCE AND RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CORRESPONDENCE; SHAPE DESCRIPTION; SHAPE INVARIANTS; OBJECT RECOGNITION; DEFORMATION; FINITE ELEMENT METHODS; MODAL ANALYSIS; VIBRATION MODES; EIGENMODES	MODELS; FORM; DEFORMATIONS	Modal matching is a new method for establishing correspondences and computing canonical descriptions, The method is based on the idea of describing objects in terms of generalized symmetries, as defined by each object's eigenmodes. The resulting modal description is used for object recognition and categorization, where shape similarities are expressed as the amounts of modal deformation energy needed to align the two objects, In general, modes provide a global-to-local ordering of shape deformation and thus allow for selecting which types of deformations are used in object alignment and comparison, In contrast to previous techniques, which required correspondence to be computed with an initial or prototype shape, modal matching utilizes a new type of finite element formulation that allows for an object's eigenmodes to be computed directly from available image information, This improved formulation provides greater generality and accuracy, and is applicable to data of any dimensionality, Correspondence results with 2D contour and point feature data are shown, and recognition experiments with 2D images of hand tools and airplanes are described.	MIT, MEDIA LAB, CAMBRIDGE, MA 02139 USA	Massachusetts Institute of Technology (MIT)	SCLAROFF, S (corresponding author), BOSTON UNIV, DEPT COMP SCI, 111 CUMMINGTON ST, BOSTON, MA 02215 USA.							Ballard D., 1982, COMPUTER VISION; Bathe Klaus Jurgen., 1982, J PRESS VESSEL TECHN; BAUMBERG A, 1994, MAY P EUR C COMP VIS, P299; BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003; BLAKE A, 1993, INT J COMPUT VISION, V11, P127, DOI 10.1007/BF01469225; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; COHEN I, 1992, MAY P EUR C COMP VIS; COOTES TF, 1992, IMAGE VISION COMPUT, V10, P289, DOI 10.1016/0262-8856(92)90044-4; Duncan J. S., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P318, DOI 10.1109/CVPR.1991.139709; Gupta A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P756, DOI 10.1109/CVPR.1993.341159; HALLINAN PW, 1993, 936 HARV ROB LAB TEC; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; KANADE T, 1983, P IEEE, V71, P789, DOI 10.1109/PROC.1983.12679; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; MURASE H, 1993, JUN P IEEE WORKSH QU, P39; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P730, DOI 10.1109/34.85661; Pentland A. P., 1990, Computer Graphics, V24, P185, DOI 10.1145/91394.91444; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P107, DOI 10.1007/BF00127812; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; POGGIO T, 1989, MIT1140 ART INT LAB; POWELL M, 1985, DAMPT1985NA12 CAMBR; RICHARDS W, 1985, COMPUT VISION GRAPH, V31, P265, DOI 10.1016/0734-189X(85)90031-3; SAMAL A, 1993, SPIE J ELECTRONIC IM, V2, P253; Sclaroff S., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P308, DOI 10.1109/ICCV.1993.378200; SCLAROFF S, 1995, MIT TR311 MED LAB VI; SCLAROFF S, 1995, THESIS MIT CAMBRIDGE; SCLAROFF S, 1994, 2ND P CAD BAS VIS WO, P258; SCOTT G, 1991, P ROY SOC LONDON, VB, P21; SEDERBERG TW, 1992, COMP GRAPH, V26, P25, DOI 10.1145/142920.134001; SHAPIRO L, 1991, VISION BASED MOTION; SHAPIRO LS, 1992, IMAGE VISION COMPUT, V10, P283, DOI 10.1016/0262-8856(92)90043-3; Staib L. H., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P98, DOI 10.1109/CVPR.1989.37834; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; THORPE C, 1993, SEP P COMP VIS SPAC; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; VANOEFFELEN MP, 1983, PATTERN RECOGN, V16, P341, DOI 10.1016/0031-3203(83)90040-7; WANG Z, 1994, P IEEE C COMP VIS PA, P129; Wolberg G, 1990, DIGITAL IMAGE WARPIN; WOOD D, 1979, JANES WORLD AIRCRAFT	46	256	269	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1995	17	6					545	561		10.1109/34.387502	http://dx.doi.org/10.1109/34.387502			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QZ940					2022-12-18	WOS:A1995QZ94000001
J	Barron, JT; Malik, J				Barron, Jonathan T.; Malik, Jitendra			Shape, Illumination, and Reflectance from Shading	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; machine learning; intrinsic images; shape from shading; color constancy; shape estimation	NATURAL IMAGES; COLOR; STATISTICS; CONSTANCY	A fundamental problem in computer vision is that of inferring the intrinsic, 3D structure of the world from flat, 2D images of that world. Traditional methods for recovering scene properties such as shape, reflectance, or illumination rely on multiple observations of the same scene to overconstrain the problem. Recovering these same properties from a single image seems almost impossible in comparison-there are an infinite number of shapes, paint, and lights that exactly reproduce a single image. However, certain explanations are more likely than others: surfaces tend to be smooth, paint tends to be uniform, and illumination tends to be natural. We therefore pose this problem as one of statistical inference, and define an optimization problem that searches for the most likely explanation of a single image. Our technique can be viewed as a superset of several classic computer vision problems (shape-from-shading, intrinsic images, color constancy, illumination estimation, etc) and outperforms all previous solutions to those constituent problems.	[Barron, Jonathan T.; Malik, Jitendra] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA	University of California System; University of California Berkeley	Barron, JT (corresponding author), Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.	barron@eecs.berkeley.edu; malik@eecs.berkeley.edu			US National Science Foundation (NSF) GRFP; ONR MURI [N00014-10-10933]	US National Science Foundation (NSF) GRFP(National Science Foundation (NSF)); ONR MURI(MURIOffice of Naval Research)	J.B. was supported by US National Science Foundation (NSF) GRFP and ONR MURI N00014-10-10933. Thanks to Trevor Darrell, Bruno Olshausen, David Forsyth, Bill Freeman, Ted Adelson, and Estee Schwartz. Jonathan Barron is the corresponding author.	Adelson E. H., 1996, PERCEPTION BAYESIAN; [Anonymous], 2007, CVPR; Barron J. T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2521, DOI 10.1109/CVPR.2011.5995392; Barron JT, 2013, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2013.10; Barron JT, 2012, PROC CVPR IEEE, P334, DOI 10.1109/CVPR.2012.6247693; Barron JT, 2012, LECT NOTES COMPUT SC, V7575, P57, DOI 10.1007/978-3-642-33765-9_5; Barrow H., 1978, COMPUTER VISION SYST; Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7; Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611; Bell M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P670, DOI 10.1109/ICCV.2001.937585; Bell S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462002; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Boyaci H, 2006, VISUAL NEUROSCI, V23, P311, DOI 10.1017/S0952523806233431; BRADY M, 1984, IEEE T PATTERN ANAL, V6, P288, DOI 10.1109/TPAMI.1984.4767521; Brainard DH, 1997, J OPT SOC AM A, V14, P1393, DOI 10.1364/JOSAA.14.001393; Brooks MJ, 1989, SHAPE SHADING; Chen J., 2007, P ACM SIGGRAPH PAP; Dror R, 2004, J VISION, V4, P821, DOI 10.1167/4.9.11; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Finayson GD, 2001, IEEE T PATTERN ANAL, V23, P1209, DOI 10.1109/34.969113; Finlayson GD, 2009, INT J COMPUT VISION, V85, P35, DOI 10.1007/s11263-009-0243-z; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P671, DOI 10.1109/34.85657; Forsyth DA, 2011, INT J COMPUT VISION, V91, P280, DOI 10.1007/s11263-010-0396-9; FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770; Gilchrist A., 2006, SEEING BLACK WHITE; Grosse R, 2009, IEEE I CONF COMP VIS, P2335, DOI 10.1109/ICCV.2009.5459428; Hartley R., 2003, MULTIPLE VIEW GEOMET; HILBERT D, 1956, GEOMETRY IMAGINATION; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; Horn B. K., 1974, COMPUT VISION GRAPH, V3, P277, DOI DOI 10.1016/0146-664X(74)90022-7; Horn B. K. P., 1970, AITR232 MIT COMP SCI; Horn B.K.P., 1975, PSYCHOL COMPUTER VIS; Huang JG, 2000, PROC CVPR IEEE, P324, DOI 10.1109/CVPR.2000.855836; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; Jianbing Shen, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3481, DOI 10.1109/CVPR.2011.5995507; Jinggang Huang, 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P541, DOI 10.1109/CVPR.1999.786990; Johnson M. K., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2553, DOI 10.1109/CVPR.2011.5995510; KLINKER GJ, 1990, INT J COMPUT VISION, V4, P7, DOI 10.1007/BF00137441; Koenderink JJ, 1996, PERCEPTION, V25, P155, DOI 10.1068/p250155; KOENDERINK JJ, 1984, PERCEPTION, V13, P321, DOI 10.1068/p130321; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; MALIK J, 1987, INT J COMPUT VISION, V1, P73, DOI 10.1007/BF00128527; MALONEY LT, 1986, J OPT SOC AM A, V3, P29, DOI 10.1364/JOSAA.3.000029; Mamassian P, 1996, PERCEPTION, V25, P95, DOI 10.1068/p250095; MORETON HP, 1992, COMP GRAPH, V26, P167, DOI 10.1145/142920.134035; Omer I, 2004, PROC CVPR IEEE, P946; Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640; Ramamoorthi R, 2001, COMP GRAPH, P497, DOI 10.1145/383259.383317; Rindfleisch T., 1966, PHOTOGRAMMETRIC ENG, V40, P101; Romeiro F, 2010, LECT NOTES COMPUT SC, V6311, P45, DOI 10.1007/978-3-642-15549-9_4; Roth S, 2005, PROC CVPR IEEE, P860; Rother C., 2011, ADV NEURAL INFORM PR, P765; RUDERMAN DL, 1994, PHYS REV LETT, V73, P814, DOI 10.1103/PhysRevLett.73.814; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Tappen MF, 2005, IEEE T PATTERN ANAL, V27, P1459, DOI 10.1109/TPAMI.2005.185; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767; Triggs B., 2000, LECT NOTES COMPUTER, V1883, P298, DOI [DOI 10.1007/3-540-44480-7, DOI 10.1007/3-540-44480-7_21]; Woodford O, 2009, IEEE T PATTERN ANAL, V31, P2115, DOI 10.1109/TPAMI.2009.131; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Xu DX, 1998, NEURAL NETWORKS FOR SIGNAL PROCESSING VIII, P155, DOI 10.1109/NNSP.1998.710645; Yu YZ, 1999, COMP GRAPH, P215; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284	64	255	278	1	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2015	37	8					1670	1687		10.1109/TPAMI.2014.2377712	http://dx.doi.org/10.1109/TPAMI.2014.2377712			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CM3ON	26353003	Green Submitted			2022-12-18	WOS:000357591900011
J	Teoh, ABJ; Goh, A; Ngo, DCL				Teoh, Andrew B. J.; Goh, Alwyn; Ngo, David C. L.			Random multispace quantization as an analytic mechanism for BioHashing of biometric and random identity inputs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						cancellable biometrics; BioHashing; random multispace quantization; face recognition	CRYPTOGRAPHIC KEY GENERATION; RECOGNITION	Biometric analysis for identity verification is becoming a widespread reality. Such implementations necessitate large-scale capture and storage of biometric data, which raises serious issues in terms of data privacy and (if such data is compromised) identity theft. These problems stem from the essential permanence of biometric data, which (unlike secret passwords or physical tokens) cannot be refreshed or reissued if compromised. Our previously presented biometric-hash framework prescribes the integration of external (password or token-derived) randomness with user-specific biometrics, resulting in bitstring outputs with security characteristics (i.e., noninvertibility) comparable to cryptographic ciphers or hashes. The resultant BioHashes are hence cancellable, i.e., straightforwardly revoked and reissued (via refreshed password or reissued token) if compromised. BioHashing furthermore enhances recognition effectiveness, which is explained in this paper as arising from the Random Multispace Quantization (RMQ) of biometric and external random inputs.	Corentix Technol Sdn Bhd, Petaling Jaya 47301, Selangor, Malaysia; Multimedia Univ, Fac Informat Sci & Technol, Melaka 75450, Malaysia	Multimedia University	Teoh, ABJ (corresponding author), Multimedia Univ, Fac Informat Sci & Technol, Jalan Ayer Keroh Lama, Melaka 75450, Malaysia.	bjteoh@mmu.edu.my; alwyn@corentix.com; david.ngo@mmu.edu.my	Ngo, David C. L./E-3307-2012; Teoh, Andrew Beng Jin/F-4422-2010	Teoh, Andrew Beng Jin/0000-0001-5063-9484				Ang R, 2005, LECT NOTES COMPUT SC, V3574, P242; Arriaga R. I., 1999, P 40 ANN S FDN COMP, P616; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bolle RM, 2002, PATTERN RECOGN, V35, P2727, DOI 10.1016/S0031-3203(01)00247-3; CHUNG YW, 2005, P 1 SKLOIS C INF SEC, P358; Clancy T.C., 2003, P 2003 ACM SIGMM WOR, P45; Daugman J, 2003, PATTERN RECOGN, V36, P279, DOI 10.1016/S0031-3203(02)00030-4; DAUGMAN J, 2002, 482 CAMBR U COMP LAB; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; DAVID FN, 1949, BIOMETRIKA, V36, P394, DOI 10.1093/biomet/36.3-4.394; Davida GI, 1998, 1998 IEEE SYMPOSIUM ON SECURITY AND PRIVACY - PROCEEDINGS, P148, DOI 10.1109/SECPRI.1998.674831; DEMMEL JW, 1990, CS90113 U TENN COMP; Goh A, 2003, LECT NOTES COMPUT SC, V2828, P1; HOFFER JA, 1989, P 22 ANN HAW INT C S, V4, P348; Johnson W. B., 1984, CONT MATH, V26, P189, DOI DOI 10.1090/CONM/026/737400; Juels A, 1999, 6TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P28, DOI 10.1145/319709.319714; Juels A, 2002, ISIT: 2002 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, PROCEEDINGS, P408, DOI 10.1109/ISIT.2002.1023680; Kaski S, 1998, IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, P413, DOI 10.1109/IJCNN.1998.682302; MALTONI D, 2003, HDB FINGERPRINT RECO, P301; Menezes AJ, 1997, HDB APPL CRYPTOGRAPH; Monrose F, 1999, 6TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P73, DOI 10.1145/319709.319720; Monrose F, 2001, P IEEE S SECUR PRIV, P202, DOI 10.1109/SECPRI.2001.924299; NGO CLD, 2004, FRONT VIEW FACIAL FE; Phillips PJ, 1997, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.1997.609311; Savvides M., 2005, P INT C PATT REC, V3, P922; SOUTAR C, 1999, ICSA GUIDE CRYPTOGRA, P649; Teoh ABJ, 2005, PATTERN RECOGN LETT, V26, P1454, DOI 10.1016/j.patrec.2004.11.021; Teoh ABJ, 2004, COMPUT SECUR, V23, P606, DOI 10.1016/j.cose.2004.06.002; Tulyakov S, 2005, LECT NOTES COMPUT SC, V3687, P30; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; VIVEROS R, 1994, AM STAT, V48, P243, DOI 10.2307/2684728; YIP WK, 2005, P 4 IEEE WORKSH AUT, P27	32	255	268	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2006	28	12					1892	1901		10.1109/TPAMI.2006.250	http://dx.doi.org/10.1109/TPAMI.2006.250			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	093UL	17108365				2022-12-18	WOS:000241195700001
J	Lei, Z; Pietikainen, M; Li, SZ				Lei, Zhen; Pietikainen, Matti; Li, Stan Z.			Learning Discriminant Face Descriptor	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; discriminant face descriptor; image filter learning; discriminant learning; heterogeneous face recognition	LOCAL BINARY PATTERNS; RECOGNITION; REPRESENTATION; CLASSIFICATION; HISTOGRAM; SCALE; MODEL	Local feature descriptor is an important module for face recognition and those like Gabor and local binary patterns (LBP) have proven effective face descriptors. Traditionally, the form of such local descriptors is predefined in a handcrafted way. In this paper, we propose a method to learn a discriminant face descriptor (DFD) in a data-driven way. The idea is to learn the most discriminant local features that minimize the difference of the features between images of the same person and maximize that between images from different people. In particular, we propose to enhance the discriminative ability of face representation in three aspects. First, the discriminant image filters are learned. Second, the optimal neighborhood sampling strategy is soft determined. Third, the dominant patterns are statistically constructed. Discriminative learning is incorporated to extract effective and robust features. We further apply the proposed method to the heterogeneous (cross-modality) face recognition problem and learn DFD in a coupled way (coupled DFD or C-DFD) to reduce the gap between features of heterogeneous face images to improve the performance of this challenging problem. Extensive experiments on FERET, CAS-PEAL-R1, LFW, and HFB face databases validate the effectiveness of the proposed DFD learning on both homogeneous and heterogeneous face recognition problems. The DFD improves POEM and LQP by about 4.5 percent on LFW database and the C-DFD enhances the heterogeneous face recognition performance of LBP by over 25 percent.	[Lei, Zhen; Li, Stan Z.] Chinese Acad Sci, Ctr Biometr & Secur Res, Beijing 100190, Peoples R China; [Lei, Zhen; Li, Stan Z.] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China; [Pietikainen, Matti] Univ Oulu, Ctr Machine Vis Res, FI-90014 Oulu, Finland	Chinese Academy of Sciences; Chinese Academy of Sciences; Institute of Automation, CAS; University of Oulu	Lei, Z (corresponding author), Chinese Acad Sci, Ctr Biometr & Secur Res, Room 1402,Intelligent Bldg,95 Zhongguancun Donglu, Beijing 100190, Peoples R China.	zlei@nlpr.ia.ac.cn; mkp@ee.oulu.f.i; szli@nlpr.ia.ac.cn			Chinese National Natural Science Foundation [61103156]; National IoT RD Project [2150510]; National Science and Technology Support Program Project [2013BAK02B01]; Chinese Academy of Sciences [KGZD-EW-102-2]; European Union [257289]; AuthenMetric RD Funds	Chinese National Natural Science Foundation(National Natural Science Foundation of China (NSFC)); National IoT RD Project; National Science and Technology Support Program Project; Chinese Academy of Sciences(Chinese Academy of Sciences); European Union(European Commission); AuthenMetric RD Funds	This work was supported by the Chinese National Natural Science Foundation Project #61103156, National IoT R&D Project #2150510, National Science and Technology Support Program Project #2013BAK02B01, Chinese Academy of Sciences Project No. KGZD-EW-102-2, European Union FP7 Project #257289 (TABULA RASA), and AuthenMetric R&D Funds. The authors would like to thank Dr. Guoying Zhao for her valuable comments on this paper.	Ahonen T., 2008, P 19 INT C PATT REC; Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Berg T, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.129; Cao ZM, 2010, PROC CVPR IEEE, P2707, DOI 10.1109/CVPR.2010.5539992; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644, DOI 10.1109/TPAMI.2002.1114855; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; del Solar J.R., 2009, EURASIP J ADV SIGNAL, V2009; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557; Guo YM, 2012, PATTERN RECOGN, V45, P3834, DOI 10.1016/j.patcog.2012.04.003; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Huang G.B., 2008, WORKSHOP FACESREAL L; Jain A. K., 2011, HDB FACE RECOGNITION, V1; Klare B.F., 2010, P 20 INT C PATT REC; Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180; Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48; Kumar R, 2009, PROC CVPR IEEE, P150, DOI 10.1109/CVPRW.2009.5206837; Lei Z., 2012, P AS C COMP VIS ACCV; Lei Z., 2012, P IEEE C COMP VIS PA; Lei Z, 2007, LECT NOTES COMPUT SC, V4642, P49; Lei Z, 2011, IEEE T IMAGE PROCESS, V20, P247, DOI 10.1109/TIP.2010.2060207; Li S. Z., 2009, P 6 IEEE WORKSH OBJ; Li S.Z., 2005, HDB FACE RECOGNITION; Li SZ, 2000, IEEE T PATTERN ANAL, V22, P1335, DOI 10.1109/34.888719; Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maturana D., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P470, DOI 10.1109/FG.2011.5771444; Maturana D., 2010, P 10 AS C COMP VIS, P618; Meng X., 2006, P 18 INT C PATT REC; Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X; Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1; Seo HJ, 2011, IEEE T INF FOREN SEC, V6, P1275, DOI 10.1109/TIFS.2011.2159205; Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758; ul Hussain S, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.99; Vapnik V.N, 1998, STAT LEARNING THEORY; Wolf Lior, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P88; Wolf L., 2008, P REAL LIF IM WORKSH; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xie SF, 2009, SIGNAL PROCESS, V89, P2333, DOI 10.1016/j.sigpro.2009.02.016; Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757; Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286; Ye J., 2004, P 18 ANN C NEUR INF; Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956; Zhang W., 2011, P IEEE C COMP VIS PA; Zhang WC, 2005, IEEE I CONF COMP VIS, P786; Zhao SQ, 2008, IEEE IMAGE PROC, P2144, DOI 10.1109/ICIP.2008.4712212; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	56	254	265	0	91	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2014	36	2					289	302		10.1109/TPAMI.2013.112	http://dx.doi.org/10.1109/TPAMI.2013.112			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	278OL	24356350				2022-12-18	WOS:000328899500007
J	Ma, Y; Derksen, H; Hong, W; Wright, J				Ma, Yi; Derksen, Harm; Hong, Wei; Wright, John			Segmentation of Multivariate mixed data via lossy data coding and compression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multivariate mixed data; data segmentation; data clustering; rate distortion; lossy coding; lossy compression; image segmentation; microarray data clustering	PRINCIPLE; MIXTURES	In this paper, based on ideas from lossy data coding and compression, we present a simple but effective technique for segmenting multivariate mixed data that are drawn from a mixture of Gaussian distributions, which are allowed to be almost degenerate. The goal is to find the optimal segmentation that minimizes the overall coding length of the segmented data, subject to a given distortion. By analyzing the coding length/rate of mixed data, we formally establish some strong connections of data segmentation to many fundamental concepts in lossy data compression and rate-distortion theory. We show that a deterministic segmentation is approximately the (asymptotically) optimal solution for compressing mixed data. We propose a very simple and effective algorithm that depends on a single parameter, the allowable distortion. At any given distortion, the algorithm automatically determines the corresponding number and dimension of the groups and does not involve any parameter estimation. Simulation results reveal intriguing phase-transition-like behaviors of the number of segments when changing the level of distortion or the amount of outliers. Finally, we demonstrate how this technique can be readily applied to segment real imagery and bioinformatic data.	Univ Illinois, Dept Elect & Comp Engn, Coordinated Sci Lab, Urbana, IL 61801 USA; Univ Michigan, Dept Math, Ann Arbor, MI 48109 USA; Texas Instruments Inc, DSP Solut Res & Dev Ctr, Dallas, TX 75266 USA	University of Illinois System; University of Illinois Urbana-Champaign; University of Michigan System; University of Michigan; Texas Instruments	Ma, Y (corresponding author), Univ Illinois, Dept Elect & Comp Engn, Coordinated Sci Lab, 1308 W Main St, Urbana, IL 61801 USA.	yima@uiuc.edu; hderksen@umich.edu; weihong@ti.com; jnwright@uiuc.edu						Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554; BENSON HP, 1994, HDB GLOBAL OPTIMIZAT; Boyd S, 2004, CONVEX OPTIMIZATION; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Donoho DL, 1998, IEEE T INFORM THEORY, V44, P2435, DOI 10.1109/18.720544; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; FORGY EW, 1965, BIOMETRICS, V21, P768; Ghahramani Z, 2000, ADV NEUR IN, V12, P449; Ghahramani Z., 1996, CRGTR961 U TOR DEP C; Ghahramani Zoubin, 1996, CRGTR961 U TOR; Hamkins J, 2002, IEEE T INFORM THEORY, V48, P2980, DOI 10.1109/TIT.2002.804056; Hansen MH, 2001, J AM STAT ASSOC, V96, P746, DOI 10.1198/016214501753168398; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; HO J, 2003, P INT C COMP VIS PAT; Horn R. A., 1986, MATRIX ANAL; JANCEY RC, 1966, AUST J BOT, V14, P127, DOI 10.1071/BT9660127; KAMVAR S, 2002, 200211 STANF U DEP C; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; MADIMAN M, 2004, P 2004 IEEE INT S IN; Malina H Z, 2001, BMC Physiol, V1, P7, DOI 10.1186/1472-6793-1-7; McLachlan, 1997, EM ALGORITHM EXTENSI; Mori G, 2005, IEEE I CONF COMP VIS, P1417; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788; ROSE K, 1994, IEEE T INFORM THEORY, V40, P1939, DOI 10.1109/18.340468; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Tse D., 2005, FUNDAMENTALS WIRELES, DOI [10.1017/CBO9780511807213, DOI 10.1017/CBO9780511807213]; Ueda N, 2000, NEURAL COMPUT, V12, P2109, DOI 10.1162/089976600300015088; Vidal R., 2005, IEEE T PATTERN ANAL, V27, P1; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; XING EP, 2002, P ANN C NEUR INF PRO; YANG A, 2006, SEGMENTATION NATURAL; ZHU SC, 2002, P 7 EUR C COMP VIS 4, P793	36	253	280	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2007	29	9					1546	1562		10.1109/TPAMI.2007.1085	http://dx.doi.org/10.1109/TPAMI.2007.1085			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	189CD	17627043	Green Submitted			2022-12-18	WOS:000247965600005
J	GEMAN, D; GEMAN, S; GRAFFIGNE, C; DONG, P				GEMAN, D; GEMAN, S; GRAFFIGNE, C; DONG, P			BOUNDARY DETECTION BY CONSTRAINED OPTIMIZATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									BROWN UNIV,DIV APPL MATH,PROVIDENCE,RI 02912; UNIV PARIS 11,EQUIPE STAT APPL,F-91405 ORSAY,FRANCE	Brown University; UDICE-French Research Universities; Universite Paris Saclay	GEMAN, D (corresponding author), UNIV MASSACHUSETTS,DEPT MATH & STAT,AMHERST,MA 01003, USA.		Geman, Donald/A-3325-2010					ARTS E, 1986, NATO ADV STUDY I PAT; BESAG J, 1986, J R STAT SOC B, V48, P259; Blake A, 1983, PATTERN RECOGN LETT, V1, P393, DOI 10.1016/0167-8655(83)90077-6; BONOMI E, 1984, SIAM REV, V26, P551, DOI 10.1137/1026105; BRANDT A, 1987, 1986 P INT C MATH; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; CANNON TM, 1978, APPL OPTICS, V17, P3385; CHALMOND B, 1987, IMAGE RESTORATION US; CHIANG TS, 1987, EIGENVALUES OPTIMAL; COHEN FS, 1987, IEEE T PATTERN ANAL, V9, P195, DOI 10.1109/TPAMI.1987.4767895; DERIN H, 1986, COMPUT VISION GRAPH, V35, P72, DOI 10.1016/0734-189X(86)90126-X; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; DERIN H, 1986, PARALLEL IMAGE SEGME; DEVIJVER PA, 1987, PATTERN RECOGN, P141; GAGALOWICZ A, 1985, COMPUT VISION GRAPH, V30, P289, DOI 10.1016/0734-189X(85)90162-8; GEMAN D, 1987, IMAGE VISION COM MAY; GEMAN D, 1987, 35 BROWN U DIV APPL; GEMAN D, 1987, PATTERN RECOGNITION; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Geman S., 1987, B ISI, V52; GEMAN S, 1987, 1986 P INT C MATH; GIDAS B, 1985, J STAT PHYS, V39, P73, DOI 10.1007/BF01007975; GIDAS B, 1989, IEEE T PATTERN ANAL, V11, P164, DOI 10.1109/34.16712; GRAFFIGNE C, 1987, THESIS BROWN U; GREEN PJ, 1986, J R STAT SOC B, V48, P259; GREIG DM, 1986, J ROY STAT SOC B MET, V48, P259; GRENANDER U, 1984, TUTORIAL PATTERN THE; GRIMSON WEL, 1985, COMPUT VISION GRAPH, V30, P316, DOI 10.1016/0734-189X(85)90163-X; Hajek B., 1985, 24TH P C DEC CONTR, P755; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HOLLEY R, 1987, SIMULATED ANNEALING; HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3; KASHKO A, 1987, PARALLEL STOCHASTIC; KASHKO A, 1986, MARKOV RANDOM FANTAS; KASHYAP RL, 1989, IEEE T PATTERN ANAL, V2, P58; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; LAWS K, 1980, USCIPI940 REP; LINSKER R, 1984, IBM J RES DEV, V28, P613, DOI 10.1147/rd.285.0613; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; MARROQUIN JL, 1984, MIT792 ART INT LAB M; MODESTINO JW, 1981, IEEE T PATTERN ANAL, V3, P557, DOI 10.1109/TPAMI.1981.4767148; MOUSSOUR.J, 1974, J STAT PHYS, V10, P11, DOI 10.1007/BF01011714; MURRAY DW, 1987, IEEE T PATTERN ANAL, V9, P220, DOI 10.1109/TPAMI.1987.4767896; PAVLIDIS T, 1986, 8TH INT C PATT REC P; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; RIPLEY BD, 1986, CAN J STAT, V14, P83, DOI 10.2307/3314656; ROSENFELD A, 1979, P IEEE, V67, P764, DOI 10.1109/PROC.1979.11326; SILVERMAN BW, 1986, J ROY STAT SOC B MET, V48, P259; SIMCHONY T, 1988, STOCHASTIC DETERMINI; SWENDSEN RH, 1987, PHYS REV LETT, V58, P86, DOI 10.1103/PhysRevLett.58.86; SZU H, 1986, P SPIE C REAL TIME S, V9, P698; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; THOMPSON WB, 1977, IEEE T COMPUT, V26, P272, DOI 10.1109/TC.1977.1674818; TRIENDL E, 1980, 5TH P IEEE INT C PAT, P1100; TRIENDL EE, 1973, KYBERNETIK, V13, P1, DOI 10.1007/BF00289105; VONDERMALSBURG C, 1986, NATO ASI SERIES; VOORHEES H, 1987, THESIS MIT; YASNOFF WA, 1977, PATTERN RECOGN, V9, P217, DOI 10.1016/0031-3203(77)90006-1; ZOBRIST AL, 1975, IEEE T COMPUT, VC 24, P718, DOI 10.1109/T-C.1975.224292; [No title captured]	60	253	265	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1990	12	7					609	628		10.1109/34.56204	http://dx.doi.org/10.1109/34.56204			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DK894		Green Submitted			2022-12-18	WOS:A1990DK89400001
J	Wang, WG; Shen, JB; Yang, RG; Porikli, F				Wang, Wenguan; Shen, Jianbing; Yang, Ruigang; Porikli, Fatih			Saliency-Aware Video Object Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video saliency; video object segmentation; geodesic distance; spatiotemporal object prior	TRACKING; OPTIMIZATION; EXTRACTION	Video saliency, aiming for estimation of a single dominant object in a sequence, offers strong object-level cues for unsupervised video object segmentation. In this paper, we present a geodesic distance based technique that provides reliable and temporally consistent saliency measurement of superpixels as a prior for pixel-wise labeling. Using undirected intra-frame and inter-frame graphs constructed from spatiotemporal edges or appearance and motion, and a skeleton abstraction step to further enhance saliency estimates, our method formulates the pixel-wise segmentation task as an energy minimization problem on a function that consists of unary terms of global foreground and background models, dynamic location models, and pairwise terms of label smoothness potentials. We perform extensive quantitative and qualitative experiments on benchmark datasets. Our method achieves superior performance in comparison to the current state-of-the-art in terms of accuracy and speed.	[Wang, Wenguan; Shen, Jianbing] Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China; [Yang, Ruigang] Univ Kentucky, Lexington, KY 40507 USA; [Porikli, Fatih] Australian Natl Univ, Res Sch Engn, Canberra, ACT 0200, Australia; [Porikli, Fatih] NICTA, Canberra, ACT 0200, Australia	Beijing Institute of Technology; University of Kentucky; Australian National University; Australian National University	Shen, JB (corresponding author), Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.	shenjianbing@bit.edu.cn; ryang@cs.uky.edu; fatih.porikli@anu.edu.au	Wang, Wenguan/AAA-5782-2022; Shen, Jianbing/U-8796-2019	Wang, Wenguan/0000-0002-0802-9567; Yang, Ruigang/0000-0001-5296-6307; Shen, Jianbing/0000-0002-4109-8353	National Basic Research Program of China (973 Program) [2013CB328805]; National Natural Science Foundation of China [61272359]; Australian Research Council's Discovery Projects funding scheme [DP150104645]; Fok Ying-Tong Education Foundation for Young Teachers	National Basic Research Program of China (973 Program)(National Basic Research Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Australian Research Council's Discovery Projects funding scheme(Australian Research Council); Fok Ying-Tong Education Foundation for Young Teachers	This work was supported in part by the National Basic Research Program of China (973 Program) (No. 2013CB328805), the National Natural Science Foundation of China (No. 61272359), the Australian Research Council's Discovery Projects funding scheme (DP150104645), and the Fok Ying-Tong Education Foundation for Young Teachers. Specialized Fund for Joint Building Program of Beijing Municipal Education Commission. Jianbing Shen is the corresponding author.	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226; [Anonymous], P BRIT MACH VIS C; Bai XF, 2007, IEEE IC COMP COM NET, P1; Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613; Borji A, 2012, PROC CVPR IEEE, P470, DOI 10.1109/CVPR.2012.6247710; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Brendel W, 2009, IEEE I CONF COMP VIS, P833, DOI 10.1109/ICCV.2009.5459242; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21; Carreira J, 2010, PROC CVPR IEEE, P3241, DOI 10.1109/CVPR.2010.5540063; Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193; Chockalingam P, 2009, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2009.5459276; Criminisi A, 2008, LECT NOTES COMPUT SC, V5302, P99, DOI 10.1007/978-3-540-88682-2_9; Criminisi A, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1857907.1857910; Endres I, 2010, LECT NOTES COMPUT SC, V6315, P575, DOI 10.1007/978-3-642-15555-0_42; Fragkiadaki K, 2015, PROC CVPR IEEE, P4083, DOI 10.1109/CVPR.2015.7299035; Fragkiadaki K, 2012, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2012.6247883; Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166; Gao D, 2008, ADV NEURAL INFORM PR, P497; Gao F, 2007, PR IEEE COMP DESIGN, P3; Godec M, 2011, IEEE I CONF COMP VIS, P81, DOI 10.1109/ICCV.2011.6126228; Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272; Grundmann M, 2010, PROC CVPR IEEE, P2141, DOI 10.1109/CVPR.2010.5539893; Guo C., 2008, P CVPR, P1, DOI DOI 10.1109/CVPR.2008.4587715; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jang WD, 2016, PROC CVPR IEEE, P696, DOI 10.1109/CVPR.2016.82; JOHNSON DB, 1977, J ACM, V24, P1, DOI 10.1145/321992.321993; Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499; Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471; Leordeanu M, 2012, LECT NOTES COMPUT SC, V7575, P516, DOI 10.1007/978-3-642-33765-9_37; Lezama J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3369, DOI 10.1109/CVPR.2011.6044588; Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273; Ma TY, 2012, PROC CVPR IEEE, P670, DOI 10.1109/CVPR.2012.6247735; Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112; Ochs P, 2012, PROC CVPR IEEE, P614, DOI 10.1109/CVPR.2012.6247728; Ochs P, 2011, IEEE I CONF COMP VIS, P1583, DOI 10.1109/ICCV.2011.6126418; Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743; Price BL, 2010, PROC CVPR IEEE, P3161, DOI 10.1109/CVPR.2010.5540079; Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15; Smith TJ, 2013, J VISION, V13, DOI 10.1167/13.8.16; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; Tsai D, 2012, INT J COMPUT VISION, V100, P190, DOI 10.1007/s11263-011-0512-5; Tsai YH, 2016, PROC CVPR IEEE, P3899, DOI 10.1109/CVPR.2016.423; Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385; Wang WG, 2017, IEEE T VIS COMPUT GR, V23, P2014, DOI 10.1109/TVCG.2016.2600594; Wang WG, 2016, IEEE T IMAGE PROCESS, V25, P5025, DOI 10.1109/TIP.2016.2601784; Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013; Wang Wenguan, 2015, IEEE Trans Image Process, V24, P3137, DOI 10.1109/TIP.2015.2438550; Wen LY, 2015, PROC CVPR IEEE, P2226, DOI 10.1109/CVPR.2015.7298835; Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961; Xiao FY, 2016, PROC CVPR IEEE, P933, DOI 10.1109/CVPR.2016.107; Xu CL, 2012, LECT NOTES COMPUT SC, V7577, P626, DOI 10.1007/978-3-642-33783-3_45; Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407; Zhang D., IEEE T NEURAL NETW L, V27, P1163; Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4; Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87; Zhou F, 2014, PROC CVPR IEEE, P3358, DOI 10.1109/CVPR.2014.429; Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360	66	252	264	6	75	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2018	40	1					20	33		10.1109/TPAMI.2017.2662005	http://dx.doi.org/10.1109/TPAMI.2017.2662005			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FP7IH	28166489	Green Submitted			2022-12-18	WOS:000417806000003
J	Geiger, A; Lauer, M; Wojek, C; Stiller, C; Urtasun, R				Geiger, Andreas; Lauer, Martin; Wojek, Christian; Stiller, Christoph; Urtasun, Raquel			3D Traffic Scene Understanding from Movable Platforms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D scene understanding; autonomous driving; 3D scene layout estimation	TRACKING; SYSTEM; MCMC	In this paper, we present a novel probabilistic generative model for multi-object traffic scene understanding from movable platforms which reasons jointly about the 3D scene layout as well as the location and orientation of objects in the scene. In particular, the scene topology, geometry, and traffic activities are inferred from short video sequences. Inspired by the impressive driving capabilities of humans, our model does not rely on GPS, lidar, or map knowledge. Instead, it takes advantage of a diverse set of visual cues in the form of vehicle tracklets, vanishing points, semantic scene labels, scene flow, and occupancy grids. For each of these cues, we propose likelihood functions that are integrated into a probabilistic generative model. We learn all model parameters from training data using contrastive divergence. Experiments conducted on videos of 113 representative intersections show that our approach successfully infers the correct layout in a variety of very challenging scenarios. To evaluate the importance of each feature cue, experiments using different feature combinations are conducted. Furthermore, we show how by employing context derived from the proposed method we are able to improve over the state-of-the-art in terms of object detection and object orientation estimation in challenging and cluttered urban environments.	[Geiger, Andreas] MPI Intelligent Syst, D-72076 Tubingen, Germany; [Geiger, Andreas] KIT, Inst Measurement & Control, D-76131 Karlsruhe, Germany; [Lauer, Martin; Stiller, Christoph] Karlsruhe Inst Technol, Inst Measurement & Control, D-76131 Karlsruhe, Germany; [Wojek, Christian] MPI Informat, D-66123 Saarbrucken, Germany; [Urtasun, Raquel] Toyota Technol Inst, Chicago, IL 60637 USA	Max Planck Society; Helmholtz Association; Karlsruhe Institute of Technology; Helmholtz Association; Karlsruhe Institute of Technology; Max Planck Society; Toyota Technological Institute - Chicago	Geiger, A (corresponding author), MPI Intelligent Syst, D-72076 Tubingen, Germany.	andreas.geiger@tue.mpg.de; lauer@kit.edu; cwojek@mpi-inf.mpg.de; stiller@kit.edu; rurtasun@ttic.edu	Stiller, Christoph/C-8850-2009	Stiller, Christoph/0000-0003-4165-2075				Alon Y., 2006, P CVPR; Alvarez J. M., 2010, P CVPR; Aly M., 2008, P 4 EINDH NETH; Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116; Andriluka M., 2010, P CVPR; Bao S., 2010, P CVPR; Barinova O., 2010, P ECCV; Bishop C.M, 2006, PATTERN RECOGN; Breitenstein M., 2009, P ICCV; Broggi A, 2012, ANNU REV CONTROL, V36, P161, DOI 10.1016/j.arcontrol.2012.03.012; Brostow G. J., 2008, P ECCV; Brubaker M. A., 2013, P CVPR; Buehler M, 2009, SPRINGER TRAC ADV RO, V56, P1, DOI 10.1007/978-3-642-03991-1; Choi W., 2010, P ECCV; Choi W., 2012, P ECCV; CRISMAN JD, 1993, IEEE T ROBOTIC AUTOM, V9, P49, DOI 10.1109/70.210794; Dahlkamp H., 2006, P RSS PHIL PA US; Danescu R, 2009, IEEE T INTELL TRANSP, V10, P272, DOI 10.1109/TITS.2009.2018328; deBoor C., 1978, APPL MATH SCI SERIES, V27; Desai C., 2009, P ICCV; DICKMANNS ED, 1992, IEEE T PATTERN ANAL, V14, P199, DOI 10.1109/34.121789; Enkelmann W., 1995, P 4 DETR MI US; Ess A., 2009, P BMVC; Ess A, 2009, IEEE T PATTERN ANAL, V31, P1831, DOI 10.1109/TPAMI.2009.109; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7; Gavrila DM, 2007, IEEE T PATTERN ANAL, V29, P1408, DOI 10.1109/TPAMI.2007.1062; Geiger A., 2013, THESIS KIT KARLSRUHE; Geiger A., 2012, P CVPR; Geiger A., 2011, P 4 BAD BAD GERM; Geiger A., 2011, P NIPS; Geiger A., 2011, P CVPR; Geiger A., 2010, P ACCV QUEENST NZ; Geiger A, 2012, IEEE T INTELL TRANSP, V13, P1008, DOI 10.1109/TITS.2012.2189882; Gengenbach V., 1995, P 4 DETR MI US; Gupta A., 2010, P ECCV; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; Kalman RE., 1960, T ASME J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; Kastrinaki V, 2003, IMAGE VISION COMPUT, V21, P359, DOI 10.1016/S0262-8856(03)00004-0; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; Kosecka J., 2002, P ECCV; Kuettel D., 2010, P CVPR; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Kumar S., 2005, P ICCV; Leibe B, 2008, IEEE T PATTERN ANAL, V30, P1683, DOI 10.1109/TPAMI.2008.170; Lutzeler M., 2000, P 4 DEARB MI US; McCall JC, 2006, IEEE T INTELL TRANSP, V7, P20, DOI 10.1109/TITS.2006.869595; Nedovic V, 2010, IEEE T PATTERN ANAL, V32, P1673, DOI 10.1109/TPAMI.2009.174; Pomerleau D., 1995, Proceedings of the Intelligent Vehicles '95. Symposium (Cat. No.95TH8132), P506, DOI 10.1109/IVS.1995.528333; Ramanan D., 2003, P CVPR; Rasmussen C., 2003, P 4; Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Singh G., 2012, P ICRA SAINT PAUL MN; Thrun S., 2005, PROBABILISTIC ROBOTI; Torralba A., 2004, P CVPR; Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87; Wojek C., 2008, P ECCV; Wojek C, 2013, IEEE T PATTERN ANAL, V35, P882, DOI 10.1109/TPAMI.2012.174; Yamaguchi K., 2011, P CVPR; Yu Q, 2009, IEEE T PATTERN ANAL, V31, P2196, DOI 10.1109/TPAMI.2008.253; Zhu Q., 2012, P 4 ALC HEN SPAIN	64	252	270	2	57	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2014	36	5					1012	1025		10.1109/TPAMI.2013.185	http://dx.doi.org/10.1109/TPAMI.2013.185			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AH3VN	26353233	Green Submitted			2022-12-18	WOS:000336054200014
J	GEIGER, D; GIROSI, F				GEIGER, D; GIROSI, F			PARALLEL AND DETERMINISTIC ALGORITHMS FROM MRFS - SURFACE RECONSTRUCTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						BAYES THEORY; IMAGE ENHANCEMENT; IMAGE SEGMENTATION; INTEGRATION; MARKOV RANDOM FIELDS; MEAN FIELD TECHNIQUES; MEAN FIELD THEORY; PARALLEL ALGORITHMS; SURFACE RECONSTRUCTION		In recent years many researchers have investigated the use of Bayesian and the special case of Markov random fields (MRF's) for computer vision. They can be applied for example to reconstruct surfaces from sparse and noisy depth data coming from the output of a visual process, or to integrate early vision processes to label physical discontinuities. Drawbacks of MRF models are the computational complexity of the implementation and the difficulty in estimating the parameters of the model. In this paper we derive deterministic approximations to MRF's models. One of the models is shown to give in a natural way the graduated nonconvexity (GNC) algorithm proposed by Blake and Zisserman. This model can be applied to smooth a field preserving its discontinuities. A class of more complex models is then proposed in order to deal with a variety of vision problems. All the theoretical results are obtained in the framework of statistical mechanics and mean field techniques. A parallel, iterative algorithm to solve the deterministic equations of the two models is presented, together with some experiments on synthetic and real images.	MIT,ARTIFICIAL INTELLIGENCE LAB,CAMBRIDGE,MA 02139	Massachusetts Institute of Technology (MIT)				Girosi, Federico/0000-0003-3937-2285				BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962; CANNY JF, 1983, TM720 MIT ART INT LA; CHOU PB, 1988, P IMAGE UNDERSTANDIN, P214; GAMBLE E, 1989, IEEE T SYST MAN  DEC; GEIGER D, 1987, AUG P IJCAI; GEIGER D, 1990, IN PRESS INT J COMP; GEIGER D, 1990, 7TH P IEEE ISR S ART; GEIGER D, 1989, MIT AI1114 ART INT L; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GIROSI F, 1989, EXTENSIONS THEORY NE; HARRIS J, 1990, SCIENCE, P1209; KIRKPATRICK S, 1983, SCIENCE, V220, P219; KOCH C, 1986, P NATL ACAD SCI USA, V83, P4263, DOI 10.1073/pnas.83.12.4263; LAMBLE EB, 1987, MIT AI970 ART INT LA; LUMSDAINE A, 1990, IN PRESS VLSI SIGNAL; MARROQUIN JL, 1987, P INT C COMPUTER VIS; MARROQUIN JL, 1985, P IMAGE UNDERSTANDIN, P293; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; TERZOPOULOS D, 1984, THESIS MIT CAMBRIDGE; Tikhonov A., 1977, SOLUTIONS ILL POSED; WAHBA G, 1977, SIAM J NUMER ANAL, V14; ZERUBIA J, 1990, SEP P EUR SIGN PROC	23	252	255	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1991	13	5					401	412		10.1109/34.134040	http://dx.doi.org/10.1109/34.134040			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FQ207					2022-12-18	WOS:A1991FQ20700001
J	PORAT, M; ZEEVI, YY				PORAT, M; ZEEVI, YY			THE GENERALIZED GABOR SCHEME OF IMAGE REPRESENTATION IN BIOLOGICAL AND MACHINE VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											PORAT, M (corresponding author), TECHNION ISRAEL INST TECHNOL,DEPT ELECT ENGN,IL-32000 HAIFA,ISRAEL.							BASTIAANS MJ, 1981, OPT ENG, V20, P594, DOI 10.1117/12.7972768; CAELLI T, 1982, J OPT SOC AM, V72, P1375, DOI 10.1364/JOSA.72.001375; CAMPBELL FW, 1968, J PHYSIOL-LONDON, V197, P551, DOI 10.1113/jphysiol.1968.sp008574; Daugman J. G., 1985, J OPT SOC AM, V2, P74; DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DAVIS MJ, 1979, J CHEM PHYS, V71, P3383, DOI 10.1063/1.438727; EINZIGER PD, 1986, TECHNION EE PUBL, V587; FISCHETTI MA, 1985, IEEE SPECTRUM, V22, P38, DOI 10.1109/MSPEC.1985.6370589; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; GAFNI H, 1977, BIOL CYBERN, V28, P73, DOI 10.1007/BF00335287; GOODMAN JW, 1970, IBM J RES DEV, V14, P478, DOI 10.1147/rd.145.0478; GRAHAM N, 1971, VISION RES, V11, P251, DOI 10.1016/0042-6989(71)90189-1; Higgins JR., 2004, COMPLETENESS BASIS P; HORIUCHI K, 1968, INFORM CONTROL, V13, P53, DOI 10.1016/S0019-9958(68)90787-0; HUBEL DH, 1982, NATURE, V299, P515, DOI 10.1038/299515a0; JACOBSON L, 1984, IEEE T PATTERN ANAL, V6, P325, DOI 10.1109/TPAMI.1984.4767525; JANSSEN AJE, 1984, P INT C ACOUST SPEEC, pB41; JANSSEN AJEM, 1982, J MATH PHYS, V23, P720, DOI 10.1063/1.525426; KOENDERINK JJ, 1978, BIOL CYBERN, V30, P157, DOI 10.1007/BF00337144; KRONAUER RE, 1985, IEEE T SYST MAN CYB, V15, P91, DOI 10.1109/TSMC.1985.6313397; KRONAUER RE, COMMUNICATION; KULIKOWSKI JJ, 1982, BIOL CYBERN, V43, P187, DOI 10.1007/BF00319978; MACKAY DM, 1981, NATURE, V289, P117, DOI 10.1038/289117a0; MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297; Marr D., 1982, VISION; Mead C, 1980, INTRO VLSI SYSTEMS; MORLET J, 1982, GEOPHYSICS, V47, P203, DOI 10.1190/1.1441328; OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022; POLLEN DA, 1983, IEEE T SYST MAN CYB, V13, P907, DOI 10.1109/TSMC.1983.6313086; POLLEN DA, 1981, SCIENCE, V212, P1409, DOI 10.1126/science.7233231; PORAT M, 1985, ACTA POLYTECH SC AP, P166; PORAT M, 1985, EE519 TECHN DEP EL E; Pumpa O., 1978, RIGAS BALSS; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; SAKITT B, 1982, BIOL CYBERN, V43, P97, DOI 10.1007/BF00336972; SCHWARTZ EL, 1980, VISION RES, V20, P645, DOI 10.1016/0042-6989(80)90090-5; Swarztrauber PN., 1982, PARALLEL COMPUTATION; TOOTELL RBH, 1982, SCIENCE, V218, P902, DOI 10.1126/science.7134981; WALACH E, 1986, SIGNAL PROCESSING, V3; WATSON AB, 1983, NASA84353 AM RES CTR; Wigner E, 1932, PHYS REV, V40, P0749, DOI 10.1103/PhysRev.40.749; WOODWARD PM, 1953, PROBABILITY INFORMAT; YOUNG RA, 1985, GMR4920 GEN MOT REP; ZEEVI YY, 1984, J OPT SOC AM A, V1, P1248; ZEEVI YY, 1986, J OPT SOC AM A, V3, P115; ZEEVI YY, 1988, THEORETICAL FDN COMP, P1197; ZEEVI YY, 1982, 2 P IM C PHOEN, P260	49	252	268	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1988	10	4					452	468		10.1109/34.3910	http://dx.doi.org/10.1109/34.3910			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	P1493					2022-12-18	WOS:A1988P149300003
J	Bishop, TE; Favaro, P				Bishop, Tom E.; Favaro, Paolo			The Light Field Camera: Extended Depth of Field, Aliasing, and Superresolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computational photography; superresolution; deconvolution; blind deconvolution; multiview stereo; shape from defocus	RECONSTRUCTION; LIMITS	Portable light field (LF) cameras have demonstrated capabilities beyond conventional cameras. In a single snapshot, they enable digital image refocusing and 3D reconstruction. We show that they obtain a larger depth of field but maintain the ability to reconstruct detail at high resolution. In fact, all depths are approximately focused, except for a thin slab where blur size is bounded, i.e., their depth of field is essentially inverted compared to regular cameras. Crucial to their success is the way they sample the LF, trading off spatial versus angular resolution, and how aliasing affects the LF. We show that applying traditional multiview stereo methods to the extracted low-resolution views can result in reconstruction errors due to aliasing. We address these challenges using an explicit image formation model, and incorporate Lambertian and texture preserving priors to reconstruct both scene depth and its superresolved texture in a variational Bayesian framework, eliminating aliasing by fusing multiview information. We demonstrate the method on synthetic and real images captured with our LF camera, and show that it can outperform other computational camera systems.	[Bishop, Tom E.] Anthrop Technol Ltd, London W11 4AT, England; [Favaro, Paolo] Univ Edinburgh, Edinburgh EH14 4AS, Midlothian, Scotland; [Favaro, Paolo] Heriot Watt Univ, Joint Res Inst Image & Signal Proc, Edinburgh EH14 4AS, Midlothian, Scotland	University of Edinburgh; Heriot Watt University	Bishop, TE (corresponding author), Anthrop Technol Ltd, 22 Baseline Studios,Whitchurch Rd, London W11 4AT, England.	T.E.Bishop@gmail.com; Paolo.Favaro@hw.ac.uk			EPSRC [EP/F023073/1(P)]; Engineering and Physical Sciences Research Council [EP/F023073/1] Funding Source: researchfish; EPSRC [EP/F023073/1] Funding Source: UKRI	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The authors wish to thank Mohammad Taghizadeh and the diffractive optics group at Heriot-Watt University for providing them with the microlens arrays and for stimulating discussions, and Mark Stewart for designing and building their microlens array interface. This work has been supported by EPSRC grant EP/F023073/1(P).	ADELSON EH, 1992, IEEE T PATTERN ANAL, V14, P99, DOI 10.1109/34.121783; Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; Ben-Ezra M., 2004, P IEEE CS C COMP VIS, V2; Bishop T.E., 2008, P IEEE 15 INT IM PRO; Bishop T.E., 2009, P 12 IEEE INT C C CO; Bishop T.E., 2008, THESIS U EDINBURGH; Bishop T.E., 2009, P IEEE INT C COMP PH; Borman S, 1999, 1998 MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, PROCEEDINGS, P374, DOI 10.1109/MWSCAS.1998.759509; Born M., 1986, PRINCIPLES OPTICS, P705; Bovik A, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P1; Cathey WT, 2002, APPL OPTICS, V41, P6080, DOI 10.1364/AO.41.006080; Chai JX, 2000, COMP GRAPH, P307, DOI 10.1145/344779.344932; Chan WS, 2007, MULTIDIM SYST SIGN P, V18, P83, DOI 10.1007/s11045-007-0022-3; Farsiu S, 2004, INT J IMAG SYST TECH, V14, P47, DOI 10.1002/ima.20007; Fife K, 2006, IEEE CUST INTEGR CIR, P281, DOI 10.1109/CICC.2006.320859; Georgeiv T., 2006, LIGHT FIELD CAMERA D; Georgiev T., 2009, P EUR 2009; HUNT B, 2005, INT J IMAGING SYSTEM, V6, P297; Isaksen A, 2000, COMP GRAPH, P297, DOI 10.1145/344779.344929; Katsaggelos A. K., 2007, SUPER RESOLUTION IMA; Levin A., 2008, EUR C COMP VIS, P619; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Levoy M, 2006, ACM T GRAPHIC, V25, P924, DOI 10.1145/1141911.1141976; Liang C.-K., 2007, IEEE ICIP 07, pV233; Lippmann G., 1908, J PHYS THEOR APPL, V7, P821, DOI [DOI 10.1051/JPHYSTAP:019080070082100, 10.1051/jphystap:019080070082100]; LUMSDAINE A, 2008, FULL RESOLUTION LIGH; Lumsdaine A., 2009, P IEEE INT C COMP PH; Nagahara H., 2008, P 10 EUR C COMP VIS; Ng MK, 2005, J MATH IMAGING VIS, V23, P367, DOI 10.1007/s10851-005-2028-5; Ng R, 2005, ACM T GRAPHIC, V24, P735, DOI 10.1145/1073204.1073256; Ng R., 2005, 200502 CSTR STANF U; PAPOULIS A, 1977, IEEE T CIRCUITS SYST, V24, P652, DOI 10.1109/TCS.1977.1084284; Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207; Robinson D, 2004, IEEE T IMAGE PROCESS, V13, P1185, DOI 10.1109/TIP.2004.832923; Stewart J., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P150; Vaish V, 2006, P 2006 IEEE COMP SOC, V2, P2331, DOI DOI 10.1109/CVPR.2006.244; Veeraraghavan A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239520; Wang ZZ, 2005, IMAGE VISION COMPUT, V23, P393, DOI 10.1016/j.imavis.2004.11.001; Zhou C., 2009, P IEEE INT C COMP PH	39	251	356	5	72	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2012	34	5					972	986		10.1109/TPAMI.2011.168	http://dx.doi.org/10.1109/TPAMI.2011.168			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	911VJ	21844629				2022-12-18	WOS:000301747400011
J	Rasmussen, C; Hager, GD				Rasmussen, C; Hager, GD			Probabilistic data association methods for tracking complex visual objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						visual tracking; data association; color regions; textured regions; snakes	MOTION	We describe a framework that explicitly reasons about data association to improve tracking performance in many difficult visual environments. A hierarchy of tracking strategies results from ascribing ambiguous or missing data to: 1) noise-like visual occurrences, 2) persistent, known scene elements (i.e., other tracked objects), or 3) persistent, unknown scene elements. First, we introduce a randomized tracking algorithm adapted from an existing probabilistic data association filter (PDAF) that is resistant to clutter and follows agile motion. The algorithm is applied to three different tracking modalities-homogeneous regions, textured regions, and snakes-and extensibly defined for straightforward inclusion of other methods. Second, we add the capacity to track multiple objects by adapting to vision a joint PDAF which oversees correspondence choices between same-modality trackers and image features. We then derive a related technique that allows mixed tracker modalities and handles object overlaps robustly. Finally, we represent complex objects as conjunctions of cues that are diverse both geometrically (e.g., parts) and qualitatively (e.g., attributes). Rigid and hinge constraints between part trackers and multiple descriptive attributes for individual parts render the whole object more distinctive, reducing susceptibility to mistracking. Results are given for diverse objects such as people, microscopic cells, and chess pieces.	NIST, Gaithersburg, MD 20899 USA; Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA	National Institute of Standards & Technology (NIST) - USA; Johns Hopkins University	Rasmussen, C (corresponding author), NIST, 100 Bur Dr, Gaithersburg, MD 20899 USA.	crasmuss@nist.gov; hager@cs.jhu.edu						Bar-Shalom Y., 1988, TRACKING DATA ASS; BASU S, 1996, P INT C PATT REC; BERGEN JR, 1992, P EUR C COMP VIS, P237; BLAKE A, 1995, ARTIF INTELL, V78, P179, DOI 10.1016/0004-3702(95)00032-1; Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CHAM TJ, 1999, P COMP VIS PATT REC, V2, P239; COX IJ, 1993, INT J COMPUT VISION, V10, P53, DOI 10.1007/BF01440847; Duda R.O., 1973, J ROYAL STAT SOC SER; FOLEY J, 1989, COMPUTER GRAPHICS PR; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; Horn B., 1986, ROBOT VISION, P1; Hoschek J, 1993, FUNDAMENTALS COMPUTE; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; ISARD M, 1996, P EUR C COMP VIS, P343; Kalman RE., 1960, T ASME J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; KLINKER GJ, 1990, INT J COMPUT VISION, V4, P7, DOI 10.1007/BF00137441; Knill D. C., 1996, PERCEPTION BAYESIAN, P1, DOI [10.1017/cbo9780511984037, DOI 10.1017/CBO9780511984037, 10.1017/CBO9780511984037]; KOLLER D, 1994, P EUR C COMP VIS, P189; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; MACCORMICK J, 1999, P INT C COMP VIS; MENDEL JM, 1987, LESSONS DIGITAL ESTI; Morris DD, 1998, PROC CVPR IEEE, P289, DOI 10.1109/CVPR.1998.698622; Mumford D., 1996, PERCEPTION BAYESIAN, P25; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P730, DOI 10.1109/34.85661; Press WH., 1993, NUMERICAL RECIPES C; RASMUSSEN C, 2000, THESIS YALE U NEW HA; RASMUSSEN C, 1996, DCSRR1114 YAL U; REHG JM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P612, DOI 10.1109/ICCV.1995.466882; Ripley BD., 1996; Shi J., 1994, P C COMP VIS PATT RE; Sobel, 1990, MACHINE VISION 3 DIM, P376, DOI [DOI 10.13140/RG.2.1.1912.4965, 10.13140/RG.2.1.1912.4965]; Terzopoulos D., 1992, ACTIVE VISION, P3; Watt A.H., 1992, ADV ANIMATION RENDER; YAMAMOTO M, 1991, P C COMP VIS PATT RE	35	251	301	0	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2001	23	6					560	576		10.1109/34.927458	http://dx.doi.org/10.1109/34.927458			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	438DC					2022-12-18	WOS:000169037600002
J	PENTLAND, A; SCLAROFF, S				PENTLAND, A; SCLAROFF, S			CLOSED-FORM SOLUTIONS FOR PHYSICALLY BASED SHAPE MODELING AND RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						DEFORMABLE MODELS; FINITE ELEMENT METHOD; MODEL ANALYSIS; MODAL-BASED VISION; OBJECT RECOGNITION; PHYSICALLY BASED MODELING; SHAPE REPRESENTATION; 3-D SHAPE RECOVERY	PERCEPTUAL ORGANIZATION	We present a closed-form, physically based solution for recovering a 3-D solid model from collections of 3-D surface measurements. Given a sufficient number of independent measurements, the solution is overconstrained and unique except for rotational symmetries. We then present a physically based object-recognition method that allows simple, closed-form comparisons of recovered 3-D solid models. The performance of these methods is evaluated using both synthetic range data with various signal-to-noise ratios and using laser rangefinder data.			PENTLAND, A (corresponding author), MIT,MEDIA LAB,VIS & MODELING GRP,CAMBRIDGE,MA 02139, USA.							Bathe Klaus Jurgen., 1982, J PRESS VESSEL TECHN; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; BINFORD TO, 1971, DEC IEEE C SYST CONT; Boult T. E., 1987, P WORKSH SPAT REAS M, P128; DARRELL T, 1990, 3RD P INT C COMP VIS; ESSA I, 1990, THESIS MIT; HOFFMAN D, 1985, PIXELS PREDICATES; LEYTON M, 1984, BIOL CYBERN, V51, P141, DOI 10.1007/BF00346136; Marr D., 1978, P ROYAL SOC LONDON B; MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P1121, DOI 10.1109/34.42852; Pentland A., 1990, Computer Graphics, V24, P143, DOI 10.1145/91394.91444; Pentland A., 1989, Computer Graphics, V23, P215, DOI 10.1145/74334.74355; PENTLAND A, 1990, INT J COMPUT VISION, P107; PENTLAND A, 1987, 1ST INT C COMP VIS, P612; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; SEGERLIND LJ, 1984, APPLIED FINITE ELEME; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; TERZOPOULOS D, 1987, INT J COMPUT VISION, V1, P211, DOI 10.1007/BF00127821; Winston P., 1983, P AAAI 83 WASHINGTON, P433	19	251	263	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1991	13	7					715	729		10.1109/34.85660	http://dx.doi.org/10.1109/34.85660			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GA139					2022-12-18	WOS:A1991GA13900008
J	THORPE, C; HERBERT, MH; KANADE, T; SHAFER, SA				THORPE, C; HERBERT, MH; KANADE, T; SHAFER, SA			VISION AND NAVIGATION FOR THE CARNEGIE-MELLON NAVLAB	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									CARNEGIE MELLON UNIV,INST ROBOT,PITTSBURGH,PA 15213	Carnegie Mellon University	THORPE, C (corresponding author), CARNEGIE MELLON UNIV,DEPT COMP SCI,NAVLAB PROJECT,PITTSBURGH,PA 15213, USA.							ANNARATONE M, 1987, P AFIPS NAT COMPUT C; BHATT R, 1987, P IEEE INT C ROBOTIC; Brooks R. A., 1986, IEEE J ROBOTICS AUTO, V2; DAVIS LS, 1986, OPT ENG, V25; DEMENTHON D, 1986, 210 U MAR CTR AUT RE; Duda R.O., 1973, J ROYAL STAT SOC SER; HEBERT M, 1986, P IEEE INT C ROBOTIC; KUAN D, 1987, P IEEE INT C ROBOTIC; PARODI M, 1986, P IEEE INT C ROBOTIC; SHAFER S, 1986, P IEEE INT C ROBOTIC; SINGH J, 1986, NAVLAB AUTONOMOUS VE; THORPE C, 1986, OCT P SPIE; TURK MA, 1987, P IEEE INT C ROBOTIC; WALLACE R, 1986, P IEEE INT C ROBOTIC; WAXMAN AM, 1987, IEEE J ROBOTICS AUTO, V3	15	251	275	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1988	10	3					362	373		10.1109/34.3900	http://dx.doi.org/10.1109/34.3900			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	N5337		Green Published			2022-12-18	WOS:A1988N533700007
J	Guha, T; Ward, RK				Guha, Tanaya; Ward, Rabab Kreidieh			Learning Sparse Representations for Human Action Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action recognition; dictionary learning; expression recognition; overcomplete; orthogonal matching pursuit; sparse representation; spatio-temporal descriptors		This paper explores the effectiveness of sparse representations obtained by learning a set of overcomplete basis (dictionary) in the context of action recognition in videos. Although this work concentrates on recognizing human movements-physical actions as well as facial expressions-the proposed approach is fairly general and can be used to address other classification problems. In order to model human actions, three overcomplete dictionary learning frameworks are investigated. An overcomplete dictionary is constructed using a set of spatio-temporal descriptors (extracted from the video sequences) in such a way that each descriptor is represented by some linear combination of a small number of dictionary elements. This leads to a more compact and richer representation of the video sequences compared to the existing methods that involve clustering and vector quantization. For each framework, a novel classification algorithm is proposed. Additionally, this work also presents the idea of a new local spatio-temporal feature that is distinctive, scale invariant, and fast to compute. The proposed approach repeatedly achieves state-of-the-art results on several public data sets containing various physical actions and facial expressions.	[Guha, Tanaya; Ward, Rabab Kreidieh] Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC V6T 1Z4, Canada	University of British Columbia	Guha, T (corresponding author), Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC V6T 1Z4, Canada.	tanaya@ece.ubc.ca; rababw@ece.ubc.ca		Guha, Tanaya/0000-0003-2167-4891				Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284; Baraniuk RG, 2009, FOUND COMPUT MATH, V9, P51, DOI 10.1007/s10208-007-9011-z; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; EFROS AA, 2003, P 9 IEEE INT C COMP; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Eldar YC, 2009, INT CONF ACOUST SPEE, P2885, DOI 10.1109/ICASSP.2009.4960226; Engan K., 1999, P IEEE INT C AUD SPE; Fathi A, 2008, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2008.4587735; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68; Jurie F., 2005, P 10 IEEE INT C COMP; Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Lewicki MS, 2000, NEURAL COMPUT, V12, P337, DOI 10.1162/089976600300015826; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mairal J., 2008, P IEEE C COMP VIS PA; Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Peyre G, 2009, J MATH IMAGING VIS, V34, P17, DOI 10.1007/s10851-008-0120-3; Riemenschneider M. D. Hayko, 2009, P BRIT MACH VIS C; Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727; Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446; Scovanner P., 2007, ACM MM, P357; Thurau C., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587721; Wang H., 2009, P BRIT MACH VIS C SE; Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1762, DOI 10.1109/TPAMI.2009.43; Wohlberg B, 2003, IEEE T SIGNAL PROCES, V51, P3053, DOI 10.1109/TSP.2003.819006; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yan Zhu, 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P660, DOI 10.1007/978-3-642-19309-5_51; Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757; Yao A, 2010, PROC CVPR IEEE, P2061, DOI 10.1109/CVPR.2010.5539883; Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201; Zhang ZM, 2008, LECT NOTES COMPUT SC, V5305, P817, DOI 10.1007/978-3-540-88693-8_60	36	250	267	0	84	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2012	34	8					1576	1588		10.1109/TPAMI.2011.253	http://dx.doi.org/10.1109/TPAMI.2011.253			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	957UE	22745001				2022-12-18	WOS:000305188500010
J	Su, MS; Chou, CH				Su, MS; Chou, CH			A modified version of the K-means algorithm with a distance based on cluster symmetry	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						data clustering; pattern recognition; k-means algorithm; face detection		In this paper, we propose a modified version of the K-means algorithm to cluster data. The proposed algorithm adopts a novel nonmetric distance measure based on the idea of "point symmetry." This kind of "point symmetry distance" can be applied in data clustering and human face detection. Several data sets are used to illustrate its effectiveness.	Natl Cent Univ, Dept Comp Sci & Informat Engn, Chungli 320, Taiwan; Tamkang Univ, Dept Elect Engn, Tamsui 25137, Taiwan	National Central University; Tamkang University	Su, MS (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, Chungli 320, Taiwan.							ATTNEAVE F, 1955, Am J Psychol, V68, P209, DOI 10.2307/1418892; BALL GH, 1964, P INT C MICR CIRC TH, P281; Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; BLOSTEIN D, 1989, IEEE T PATTERN ANAL, V11, P1233, DOI 10.1109/34.41363; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; Duda R.O., 1973, J ROYAL STAT SOC SER; GONZALEZ RC, 1989, DIGITAL IMAGE PROCES; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Kanatani K, 1997, IEEE T PATTERN ANAL, V19, P246, DOI 10.1109/34.584101; KOHONEN T, 1989, SELF ORG ASS MEM; KOHONEN T, 1988, IEEE COMPUT, V27, P11; Mao JC, 1996, IEEE T NEURAL NETWOR, V7, P16, DOI 10.1109/72.478389; Miller W., 1972, SYMMETRY GROUPS THEI; REISFELD D, 1995, INT J COMPUT VISION, V14, P119, DOI 10.1007/BF01418978; RUSPINI EH, 1969, INFORM CONTROL, V15, P22, DOI 10.1016/S0019-9958(69)90591-9; Su MC, 1999, IEICE T FUND ELECTR, VE82A, P680; SU MC, 1999, P 5 INT C SCI C DEC, P206; SU MC, 1997, P IEEE INT C SYST MA, P1; Tou JT, 1974, PATTERN RECOGN; Weyl H., 1952, SYMMETRY; ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083	24	250	279	1	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2001	23	6					674	680		10.1109/34.927466	http://dx.doi.org/10.1109/34.927466			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	438DC					2022-12-18	WOS:000169037600010
J	Hofmann, T; Buhmann, JM				Hofmann, T; Buhmann, JM			Pairwise data clustering by deterministic annealing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							VECTOR QUANTIZATION; EM ALGORITHM; OPTIMIZATION; DISTRIBUTIONS; FILTERS	Partitioning a data set and extracting hidden structure from the data arises in different application areas of pattern recognition, speech and image processing. Pairwise data clustering is a combinatorial optimization method for data grouping which extracts hidden structure from proximity data. We describe a deterministic annealing approach to painwise clustering which shares the robustness properties of maximum entropy inference. The resulting Gibbs probability distributions are estimated by mean-field approximation. A new structure-preserving algorithm to cluster dissimilarity data and to simultaneously embed these data in a Euclidian vector space is discussed which can be used for dimensionality reduction and data visualization. The suggested embedding algorithm which outperforms conventional approaches has been implemented to analyze dissimilarity data from protein analysis and from linguistics. The algorithm for pairwise data clustering is used to segment textured images.			Hofmann, T (corresponding author), UNIV BONN,INST INFORMATIK 3,ROMERSTR 164,D-53117 BONN,GERMANY.		Buhmann, Joachim/AAU-4760-2020; WU, TAKLON/A-2827-2010					BAVELIER D, 1993, 34 ANN M PSYCH SOC W; BREGLER C, 1994, ADV NEURAL INFORMATI, V6; BUHMANN J, 1993, IEEE T INFORM THEORY, V39, P1133, DOI 10.1109/18.243432; BUHMANN J, 1993, NEURAL COMPUT, V5, P75, DOI 10.1162/neco.1993.5.1.75; CERNY V, 1985, J OPTIMIZ THEORY APP, V45, P41, DOI 10.1007/BF00940812; CHOU PA, 1989, IEEE T ACOUST SPEECH, V37, P31, DOI 10.1109/29.17498; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Duda R.O., 1973, J ROYAL STAT SOC SER; FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594; Gardiner C. W., 1983, HDB STOCHASTIC METHO; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204; Gersho A., 1992, VECTOR QUANTIZATION; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; HOFMANN T, 1996, P INT C IM PROC LAUS; HOFMANN T, 1996, P KNOWL DISC DAT MIN; HOFMANN T, 1996, IAITR962 RHEINISCHE; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; JAYNES ET, 1982, P IEEE, V70, P939, DOI 10.1109/PROC.1982.12425; JAYNES ET, 1957, PHYS REV, V108, P171, DOI 10.1103/PhysRev.108.171; JULESZ B, 1961, IEEE T INFORM THEORY, P84; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kohonen Teuvo, 1984, SELF ORG ASS MEMORY; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P115, DOI 10.1007/BF02289694; Mclachlan G., 1988, MIXTURE MODELS; MEZARD M, 1987, SPIN GLASS THEORY BE; Peierls R, 1938, PHYS REV, V54, P918, DOI 10.1103/PhysRev.54.918; Ritter H., 1992, NEURAL COMPUTATION S; ROSE K, 1992, IEEE T INFORM THEORY, V38, P1249, DOI 10.1109/18.144705; ROSE K, 1990, PATTERN RECOGN LETT, V11, P589, DOI 10.1016/0167-8655(90)90010-Y; ROSE K, 1993, IEEE T PATTERN ANAL, V15, P785, DOI 10.1109/34.236251; ROSE K, 1990, PHYS REV LETT, V65, P945, DOI 10.1103/PhysRevLett.65.945; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Simic PD, 1990, NETWORK-COMP NEURAL, V1, P89, DOI 10.1088/0954-898X/1/1/007; Simic PD, 1991, NEURAL COMPUT, V3, P268, DOI 10.1162/neco.1991.3.2.268; THOULESS DJ, 1977, PHILOS MAG, V35, P593, DOI 10.1080/14786437708235992; TIKOCHINSKY Y, 1984, PHYS REV A, V30, P2638, DOI 10.1103/PhysRevA.30.2638; YUILLE AL, 1994, NEURAL COMPUT, V6, P334, DOI 10.1162/neco.1994.6.2.334; Yuille AL, 1990, NEURAL COMPUT, V2, P1, DOI 10.1162/neco.1990.2.1.1	47	250	253	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1997	19	1					1	14		10.1109/34.566806	http://dx.doi.org/10.1109/34.566806			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WE528					2022-12-18	WOS:A1997WE52800001
J	Kviatkovsky, I; Adam, A; Rivlin, E				Kviatkovsky, Igor; Adam, Amit; Rivlin, Ehud			Color Invariants for Person Reidentification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Surveillance applications; person reidentification; color invariant signatures	RECOGNITION; TRACKING; OBJECTS	We revisit the problem of specific object recognition using color distributions. In some applications-such as specific person identification-it is highly likely that the color distributions will be multimodal and hence contain a special structure. Although the color distribution changes under different lighting conditions, some aspects of its structure turn out to be invariants. We refer to this structure as an intradistribution structure, and show that it is invariant under a wide range of imaging conditions while being discriminative enough to be practical. Our signature uses shape context descriptors to represent the intradistribution structure. Assuming the widely used diagonal model, we validate that our signature is invariant under certain illumination changes. Experimentally, we use color information as the only cue to obtain good recognition performance on publicly available databases covering both indoor and outdoor conditions. Combining our approach with the complementary covariance descriptor, we demonstrate results exceeding the state-of-the-art performance on the challenging VIPeR and CAVIAR4REID databases.	[Kviatkovsky, Igor; Adam, Amit; Rivlin, Ehud] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Kviatkovsky, I (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	kviat@cs.technion.ac.il; amita@cs.technion.ac.il; ehudr@cs.technion.ac.il						[Anonymous], 2012, VIPER VIEWPOINT INVA; Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P435, DOI 10.1109/AVSS.2010.34; BARNARD K, 1999, THESIS SIMON FRASER; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Berwick D, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P165, DOI 10.1109/ICCV.1998.710714; Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Farenzena M, 2010, P IEEE C COMP VIS PA, P2360; Finlayson G, 2005, PATTERN RECOGN, V38, P179, DOI 10.1016/j.patcog.2004.04.010; Finlayson G. D., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P164, DOI 10.1109/ICCV.1993.378223; FINLAYSON GD, 1994, J OPT SOC AM A, V11, P1553, DOI 10.1364/JOSAA.11.001553; Forstner W., 1999, TECHNICAL REPORT; FUNT BV, 1995, IEEE T PATTERN ANAL, V17, P522, DOI 10.1109/34.391390; Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3; Gevers T, 2004, IEEE T CIRC SYST VID, V14, P776, DOI 10.1109/TCSVT.2004.828347; Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602; Gheissari N., 2006, P IEEE C COMP VIS PA, V2, P1528, DOI DOI 10.1109/CVPR.2006.223; Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21; Hamdoun O, 2008, 2008 SECOND ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P140; HEALEY G, 1994, J OPT SOC AM A, V11, P3003, DOI 10.1364/JOSAA.11.003003; Javed O, 2005, PROC CVPR IEEE, P26; Jeong K, 2008, MACH VISION APPL, V19, P443, DOI 10.1007/s00138-007-0079-x; Jojic N, 2009, PROC CVPR IEEE, P2044, DOI 10.1109/CVPRW.2009.5206581; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Kviatkovsky I., 2012, THESIS TECHNION ISRA; Lin Z, 2008, LECT NOTES COMPUT SC, V5358, P23, DOI 10.1007/978-3-540-89639-5_3; Madden C, 2007, MACH VISION APPL, V18, P233, DOI 10.1007/s00138-007-0070-6; Matas J, 2000, LECT NOTES COMPUT SC, V1842, P48; Matas J., 1996, THESIS U AMSTERDAM; Metternich MJ, 2010, LECT NOTES COMPUT SC, V6010, P18, DOI 10.1007/978-3-642-14298-7_2; Miller EG, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P607, DOI 10.1109/ICCV.2001.937574; Moon H, 2001, PERCEPTION, V30, P303, DOI 10.1068/p2896; Park U, 2006, INT C PATT RECOG, P1204; Porikli F, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P133; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Stokman H, 2007, IEEE T PATTERN ANAL, V29, P371, DOI 10.1109/TPAMI.2007.58; Swain M. J., 1990, P 3 INT C COMP VIS, P390, DOI DOI 10.1109/ICCV.1990.139558; Tao H, 2007, PETS WORKSH; Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589; Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010; Zhu Qiang, 2006, CVPR, DOI DOI 10.1109/CVPR.2006.119	42	249	261	1	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2013	35	7					1622	1634		10.1109/TPAMI.2012.246	http://dx.doi.org/10.1109/TPAMI.2012.246			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	146AG	23681991				2022-12-18	WOS:000319060600007
J	Comaniciu, D				Comaniciu, D			An algorithm for data-driven bandwidth selection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						variable-bandwidth mean shift; bandwidth selection; multiscale analysis; Jensen-Shannon divergence; feature space	IMAGE SEGMENTATION	The analysis of a feature space that exhibits multiscale patterns often requires kernel estimation techniques with locally adaptive bandwidths, such as the variable-bandwidth mean shift. Proper selection of the kernel bandwidth is, however, a critical step for superior space analysis and partitioning. This paper presents a mean shift-based approach for local bandwidth selection in the multimodal, multivariate case. Our method is based on a fundamental property of normal distributions regarding the bias of the normalized density gradient. We demonstrate that, within the large sample approximation, the local covariance is estimated by the matrix that maximizes the magnitude of the normalized mean shift vector. Using this property, we develop a reliable algorithm which takes into account the stability of local bandwidth estimates across scales. The validity of our theoretical results is proven in various space partitioning experiments involving the variable-bandwidth mean shift.	Siemens Corp Res, Real Time Vis & Modeling Dept, Princeton, NJ 08540 USA	Siemens AG	Comaniciu, D (corresponding author), Siemens Corp Res, Real Time Vis & Modeling Dept, 755 Coll Rd E, Princeton, NJ 08540 USA.	comanici@scr.siemens.com		Comaniciu, Dorin/0000-0002-5238-8647				ABRAMSON IS, 1982, ANN STAT, V10, P1217, DOI 10.1214/aos/1176345986; Ahuja N, 1996, IEEE T PATTERN ANAL, V18, P1211, DOI 10.1109/34.546258; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Comaniciu D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P438, DOI 10.1109/ICCV.2001.937550; Comaniciu D, 1999, PATTERN ANAL APPL, V2, P22, DOI 10.1007/s100440050011; El-Yaniv R, 1998, ADV NEUR IN, V10, P465; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; GEVERS T, 2001, P INT C COMP VIS JUL, V1, P615; GODTLIEBSEN F, 1999, UNPUB SIGNIFICANCE S; HALL P, 1995, ANN STAT, V23, P1, DOI 10.1214/aos/1176324451; Irani M, 2000, LECT NOTES COMPUT SC, V1842, P539; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Jones MC, 1996, J AM STAT ASSOC, V91, P401, DOI 10.2307/2291420; Kauffman L., 1990, FINDING GROUPS DATA; KULLBACK S, 1997, INFORMATION THEORY S; Leung Y, 2000, IEEE T PATTERN ANAL, V22, P1396, DOI 10.1109/34.895974; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P159, DOI 10.1007/BF02294245; PARK BU, 1990, J AM STAT ASSOC, V85, P66, DOI 10.2307/2289526; Pauwels EJ, 1999, COMPUT VIS IMAGE UND, V75, P73, DOI 10.1006/cviu.1999.0763; REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034; SHEATHER SJ, 1991, J ROY STAT SOC B MET, V53, P683; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; Simonoff J.S., 1996, SMOOTING METHODS STA, V2nd; STOKER TM, 1993, J AM STAT ASSOC, V88, P855, DOI 10.2307/2290774; Wand M.P., 1995, KERNEL SMOOTHING	28	249	304	3	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2003	25	2					281	288		10.1109/TPAMI.2003.1177159	http://dx.doi.org/10.1109/TPAMI.2003.1177159			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	637NX					2022-12-18	WOS:000180519800012
J	LEE, CH; LANDGREBE, DA				LEE, CH; LANDGREBE, DA			FEATURE-EXTRACTION BASED ON DECISION BOUNDARIES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						DECISION BOUNDARY; DECISION BOUNDARY FEATURE MATRIX; DISCRIMINANTLY INFORMATIVE; DISCRIMINANTLY REDUNDANT; EFFECTIVE DECISION BOUNDARY; FEATURE EXTRACTION; INTRINSIC DISCRIMINANT DIMENSION		In this paper, a novel approach to feature extraction for classification is proposed based directly on the decision boundaries. We note that feature extraction is equivalent to retaining informative features or eliminating redundant features; thus, the terms ''discriminantly information feature'' and ''discriminantly redundant feature'' are first defined relative to feature extraction for classification. Next, it is shown how discriminantly redundant features and discriminantly informative features are related to decision boundaries. A novel characteristic of the proposed method arises by noting that usually only a portion of the decision boundary is effective in discriminating between classes, and the concept of the effective decision boundary is therefore introduced. Next, a procedure to extract discriminantly informative features based on a decision boundary is proposed. The proposed feature extraction algorithm has several desirable properties: 1) It predicts the minimum number of features necessary to achieve the same classification accuracy as in the original space for a given pattern recognition problem; 2) it finds the necessary feature vectors. The proposed algorithm does not deteriorate under the circumstances of equal class means or equal class covariances as some previous algorithms do. Experiments show that the performance of the proposed algorithm compares favorably with those of previous algorithms.			LEE, CH (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.							BIEHL LL, 1982, P INT S MACHINE PROC, P169; CULLEN CG, 1972, MATRICES LINEAR TRAN; Devijver PA, 1982, PATTERN RECOGNITION; Duda R.O., 1973, J ROYAL STAT SOC SER; FOLEY DH, 1975, IEEE T COMPUT, VC 24, P281, DOI 10.1109/T-C.1975.224208; FUKUNAGA K, 1970, IEEE T COMPUT, VC 19, P311, DOI 10.1109/T-C.1970.222918; FUKUNAGA K, 1972, INTRO STATISTICAL PA; HEYDORN RP, 1971, IEEE T COMPUT, P1051; KAZAKOS D, 1978, IEEE T INFORM THEORY, V24, P651, DOI 10.1109/TIT.1978.1055919; LEE C, 1992, THESIS PURDUE U W LA; LEE C, 1991, 44TH P SPSES ANN C, P475; LONGSTAFF ID, 1987, IEEE T PATTERN ANAL, V9, P321, DOI 10.1109/TPAMI.1987.4767906; MALINA W, 1981, IEEE T PATTERN ANAL, V3, P611, DOI 10.1109/TPAMI.1981.4767154; MORGERA SD, 1984, IEEE T PATTERN ANAL, V6, P601, DOI 10.1109/TPAMI.1984.4767573; Richards J.A., 2013, REMOTE SENSING DIGIT, V5th, DOI [10.1007/978-3-642-30062-2, DOI 10.1007/978-3-642-30062-2]; Swain P. H., 1973, 1st International Joint Conference on Pattern Recognition, P536; Swain P.H., 1978, REMOTE SENSING QUANT	17	249	264	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1993	15	4					388	400		10.1109/34.206958	http://dx.doi.org/10.1109/34.206958			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KU543					2022-12-18	WOS:A1993KU54300006
J	ABUMOSTAFA, YS; PSALTIS, D				ABUMOSTAFA, YS; PSALTIS, D			RECOGNITIVE ASPECTS OF MOMENT INVARIANTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											ABUMOSTAFA, YS (corresponding author), CALTECH,DIV ENGN & APPL SCI,PASADENA,CA 91125, USA.							ABUMOSTAFA Y, UNPUB INFORMATION TH; ABUMOSTAFA Y, 1983, JUN P IEEE C COMP VI, P114; Born M., 1975, PRINCIPLES OPTICS, VFifth; CORMACK AM, 1963, J APPL PHYS, V34, P2722, DOI 10.1063/1.1729798; Duda R.O., 1973, J ROYAL STAT SOC SER; DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; Gonzalez R.C., 1977, DIGITAL IMAGE PROCES; HSU YN, 1982, APPL OPTICS, V21, P4012, DOI 10.1364/AO.21.004012; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; MAITRA S, 1979, P IEEE, V67, P697, DOI 10.1109/PROC.1979.11309; REDDI SS, 1981, IEEE T PATTERN ANAL, V3, P240, DOI 10.1109/TPAMI.1981.4767087; Rice J.R., 1981, MATRIX COMPUTATION M; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920	13	249	259	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	6					698	706		10.1109/TPAMI.1984.4767594	http://dx.doi.org/10.1109/TPAMI.1984.4767594			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TX361	22499651	Green Accepted, Green Published			2022-12-18	WOS:A1984TX36100004
J	Yang, B; Lei, Y; Liu, JM; Li, WJ				Yang, Bo; Lei, Yu; Liu, Jiming; Li, Wenjie			Social Collaborative Filtering by Trust	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Recommender system; collaborative filtering; trust network; matrix factorization	RECOMMENDATION	Recommender systems are used to accurately and actively provide users with potentially interesting information or services. Collaborative filtering is a widely adopted approach to recommendation, but sparse data and cold-start users are often barriers to providing high quality recommendations. To address such issues, we propose a novel method that works to improve the performance of collaborative filtering recommendations by integrating sparse rating data given by users and sparse social trust network among these same users. This is a model-based method that adopts matrix factorization technique that maps users into low-dimensional latent feature spaces in terms of their trust relationship, and aims to more accurately reflect the users reciprocal influence on the formation of their own opinions and to learn better preferential patterns of users for high-quality recommendations. We use four large-scale datasets to show that the proposed method performs much better, especially for cold start users, than state-of-the-art recommendation algorithms for social collaborative filtering based on trust.	[Yang, Bo] Jilin Univ, Sch Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China; [Yang, Bo] Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engineer, Changchun 130012, Jilin, Peoples R China; [Lei, Yu; Li, Wenjie] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China; [Liu, Jiming] Hong Kong Baptist Univ, Dept Comp Sci, Kowloon Tong, Hong Kong, Peoples R China	Jilin University; Jilin University; Hong Kong Polytechnic University; Hong Kong Baptist University	Yang, B (corresponding author), Jilin Univ, Sch Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.; Yang, B (corresponding author), Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engineer, Changchun 130012, Jilin, Peoples R China.	ybo@jlu.edu.cn; csylei@comp.polyu.edu.hk; jiming@comp.hkbu.edu.hk; cswjli@comp.polyu.edu.hk	Li, Wenjie/AAQ-7622-2020	Li, Wenjie/0000-0002-7360-8864	National Natural Science Foundation of China [61373053, 61133011, 61572226, 61300146, 61272291]; Jilin Province Natural Science Foundation [20150101052JC]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Jilin Province Natural Science Foundation	This work was funded by the National Natural Science Foundation of China under grants 61373053, 61133011, 61572226, 61300146, and 61272291, and Jilin Province Natural Science Foundation under grant 20150101052JC.	Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99; [Anonymous], 2008, P 25 INT C MACH LEAR; Bai TS, 2015, SECOND EUROPEAN NETWORK INTELLIGENCE CONFERENCE (ENIC 2015), P60, DOI 10.1109/ENIC.2015.17; Bedi P, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2677; Breese J. S., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P43; Chaney A.J.B., 2015, P 9 ACM C REC SYST, P43, DOI DOI 10.1145/2792838.2800193; Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776; Dueck D., 2004, PSI200423; Golbeck J.A., 2005, THESIS; Gopalan P, 2015, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P326; GRANOVETTER MS, 1973, AM J SOCIOL, V78, P1360, DOI 10.1086/225469; Hofmann T, 2004, ACM T INFORM SYST, V22, P89, DOI 10.1145/963770.963774; Jamali M., 2010, P 4 ACM C RECOMMENDE, P135, DOI [10.1145/1864708.1864736, DOI 10.1145/1864708.1864736]; Jamali M, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P397; Kautz H, 1997, COMMUN ACM, V40, P63, DOI 10.1145/245108.245123; Koren Y., 2008, P 14 ACM SIGKDD INT, P426, DOI DOI 10.1145/1401890.1401944; Koren Y, 2010, COMMUN ACM, V53, P89, DOI 10.1145/1721654.1721677; Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263; Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344; Liu N. N., 2008, P 31 ANN INT ACM SIG, P83, DOI DOI 10.1145/1390334.1390351; Ma H, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961201; Ma Hao, 2011, WSDM, P287; Massa P, 2004, LECT NOTES COMPUT SC, V3290, P492, DOI 10.1007/978-3-540-30468-5_31; Massa P, 2007, RECSYS 07: PROCEEDINGS OF THE 2007 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P17; Rennie J. D., 2005, P 22 INT C MACHINE L, P713; Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121; Resnick P., 1994, Transcending Boundaries, CSCW '94. Proceedings of the Conference on Computer Supported Cooperative Work, P175, DOI 10.1145/192844.192905; Salakhutdinov R., 2007, ADV NEURAL INF PROCE, V20, P1257; Sarwar Badrul, 2001, P 10 INT C WORLD WID, P285, DOI 10.1145/371920.372071; Si L., 2003, MACHINE LEARNING INT, V20, P704; Sinha R., 2001, P DELOS NSF WORKSH P, P64; Victor P, 2011, IEEE INTELL SYST, V26, P48, DOI 10.1109/MIS.2011.22; Victor P, 2009, FUZZY SET SYST, V160, P1367, DOI 10.1016/j.fss.2008.11.014; Wang J., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P501, DOI 10.1145/1148170.1148257; Yang B., 2013, P 23 INT JOINT C ART, P2747; Yang Xiwang, 2012, P 18 ACM SIGKDD INT, P1267, DOI [DOI 10.1145/2339530.2339728, 10.1145/2339530.2339728]; Zhang Y, 2007, P 30 ANN INT ACM SIG, P47, DOI [10.1145/1277741.1277752, DOI 10.1145/1277741.1277752]; Zhao T, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P1643, DOI 10.1145/2505515.2505592; Zhou YH, 2008, LECT NOTES COMPUT SC, V5034, P337, DOI 10.1007/978-3-540-68880-8_32; Ziegler CN, 2004, LECT NOTES COMPUT SC, V2995, P251	41	248	296	13	128	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2017	39	8					1633	1647		10.1109/TPAMI.2016.2605085	http://dx.doi.org/10.1109/TPAMI.2016.2605085			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EZ3JD	27608451				2022-12-18	WOS:000404606300011
J	Li, SQ; Xu, C; Xie, M				Li, Shiqi; Xu, Chi; Xie, Ming			A Robust O(n) Solution to the Perspective-n-Point Problem	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Perspective-n-point problem; camera pose estimation; augmented reality	POSE ESTIMATION; OBJECT POSE; EFFICIENT	We propose a noniterative solution for the Perspective-n-Point (PnP) problem, which can robustly retrieve the optimum by solving a seventh order polynomial. The central idea consists of three steps: 1) to divide the reference points into 3-point subsets in order to achieve a series of fourth order polynomials, 2) to compute the sum of the square of the polynomials so as to form a cost function, and 3) to find the roots of the derivative of the cost function in order to determine the optimum. The advantages of the proposed method are as follows: First, it can stably deal with the planar case, ordinary 3D case, and quasi-singular case, and it is as accurate as the state-of-the-art iterative algorithms with much less computational time. Second, it is the first noniterative PnP solution that can achieve more accurate results than the iterative algorithms when no redundant reference points can be used (n <= 5). Third, large-size point sets can be handled efficiently because its computational complexity is O(n).	[Li, Shiqi; Xu, Chi] Huazhong Univ Sci & Technol, Sch Mech Sci & Engn, Wuhan 430074, Peoples R China; [Xie, Ming] Nanyang Technol Univ, Sch Mech & Aerosp Engn, Singapore 639798, Singapore	Huazhong University of Science & Technology; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Xu, C (corresponding author), Huazhong Univ Sci & Technol, Sch Mech Sci & Engn, Wuhan 430074, Peoples R China.	sqli@mail.hust.edu.cn; xuchi.hust@yahoo.com.cn; mmxie@ntu.edu.sg	Xie, Ming/A-3821-2011	Xie, Ming/0000-0002-1696-9030; Xu, Chi/0000-0002-5301-9376				Abdel-Aziz Y., 1971, P S CLOSE RANGE PHOT, P1, DOI [10.14358/PERS.81.2.103, DOI 10.1080/10671188.1967.10616517]; ABIDI MA, 1995, IEEE T PATTERN ANAL, V17, P534, DOI 10.1109/34.391388; [Anonymous], 2000, P EUR C COMP VIS; Ansar A, 2003, IEEE T PATTERN ANAL, V25, P578, DOI 10.1109/TPAMI.2003.1195992; Bujnak M., 2008, P IEEE C COMP VIS PA; DEMENTHON D, 1992, IEEE T PATTERN ANAL, V14, P1100, DOI 10.1109/34.166625; DEMENTHON DF, 1992, LECT NOTES COMPUT SC, V588, P335, DOI 10.1007/BF01450852; Fiore PD, 2001, IEEE T PATTERN ANAL, V23, P140, DOI 10.1109/34.908965; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Forsyth DA, 2002, PRENT HALL PROF TECH; Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599; HARALICK RM, 1994, INT J COMPUT VISION, V13, P331, DOI 10.1007/BF02028352; Hartley R., 2003, MULTIPLE VIEW GEOMET; Horaud R, 1997, INT J COMPUT VISION, V22, P173, DOI 10.1023/A:1007940112931; Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188; Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6; Li SQ, 2011, INT J PATTERN RECOGN, V25, P627, DOI 10.1142/S0218001411008774; Li SQ, 2011, COMPUT ANIMAT VIRT W, V22, P47, DOI 10.1002/cav.385; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199; Malik S, 2002, PROC C VIS INTERFACE, V1, P12; McGlone J. C., 2004, MANUAL PHOTOGRAMMETR, VFifth; Oberkampf D, 1996, COMPUT VIS IMAGE UND, V63, P495, DOI 10.1006/cviu.1996.0037; Pirker K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.115; Press W.H., 2007, NUMERICAL RECIPES; Quan L, 1999, IEEE T PATTERN ANAL, V21, P774, DOI 10.1109/34.784291; Schweighofer G, 2006, IEEE T PATTERN ANAL, V28, P2024, DOI 10.1109/TPAMI.2006.252; Skrypnyk I, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P110, DOI 10.1109/ISMAR.2004.53; Triggs B., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P278, DOI 10.1109/ICCV.1999.791231; UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573; WOLFE WJ, 1991, IEEE T PATTERN ANAL, V13, P66, DOI 10.1109/34.67632; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718; Zhi L., 2002, AMSS ACAD SIN, V21, P239	33	248	282	6	58	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2012	34	7					1444	1450		10.1109/TPAMI.2012.41	http://dx.doi.org/10.1109/TPAMI.2012.41			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	943PZ	22331854				2022-12-18	WOS:000304138300015
J	MANJUNATH, BS; CHELLAPPA, R				MANJUNATH, BS; CHELLAPPA, R			UNSUPERVISED TEXTURE SEGMENTATION USING MARKOV RANDOM FIELD MODELS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						ESTIMATION; GIBBS DISTRIBUTION; MARKOV RANDOM FIELD; RELAXATION; SEGMENTATION; SIMULATED ANNEALING	GIBBS RANDOM-FIELDS; IMAGES	We consider the problem of unsupervised segmentation of textured images. The only explicit assumption made is that the intensity data can be modeled by a Gauss Markov random field (GMRF). The image is divided into number of nonoverlapping regions and the GMRF parameters are computed from each of these regions. A simple clustering method is used to merge regions. The parameters of the model estimated from the clustered segments are then used in two different schemes, one being an approximation to the maximum a posteriori estimate of the labels and the other minimizing the percentage misclassification error. Our approach is contrasted with a recently published algorithm [1] which detailed an interesting simultaneous parameter estimation and segmentation scheme. We compare the results of the adaptive segmentation algorithm in [1] with a simple nearest neighbor classification scheme to show that if enough information is available, simple techniques could be used as alternatives to computationally expensive schemes.			MANJUNATH, BS (corresponding author), UNIV SO CALIF,DEPT ELECT ENGN SYST,LOS ANGELES,CA 90089, USA.		Chellappa, Rama/AAJ-1504-2020; Manjunath, B S/AAM-8190-2020; Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/B-6573-2012	Manjunath, B S/0000-0003-2804-3611; 				BESAG J, 1986, J R STAT SOC B, V48, P259; Chellappa R., 1985, PATTERN RECOGNITION, V2, P79; COHEN FS, 1987, IEEE T PATTERN ANAL, V9, P195, DOI 10.1109/TPAMI.1987.4767895; COHEN FS, 1986, 861 U RHOD ISL DEP E; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; LAKSHMANAN S, 1989, IEEE T PATTERN ANAL, V11, P799, DOI 10.1109/34.31443; MANJUNATH BS, 1990, IEEE T ACOUST SPEECH, V38, P1039, DOI 10.1109/29.56064; MARROQUIN JL, 1985, THESIS MIT ARTIFICIA; WON CS, UNSUPERVISED IMAGE 1	11	248	261	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1991	13	5					478	482		10.1109/34.134046	http://dx.doi.org/10.1109/34.134046			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FQ207					2022-12-18	WOS:A1991FQ20700007
J	HUERTAS, A; MEDIONI, G				HUERTAS, A; MEDIONI, G			DETECTION OF INTENSITY CHANGES WITH SUBPIXEL ACCURACY USING LAPLACIAN GAUSSIAN MASKS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											HUERTAS, A (corresponding author), UNIV SO CALIF,DEPT ELECT ENGN,INTELLIGENT SYST GRP,LOS ANGELES,CA 90089, USA.							BERZINS V, 1984, COMPUT VISION GRAPH, V27, P195, DOI 10.1016/S0734-189X(84)80043-2; BINFORD TO, 1981, ARTIF INTELL, V17, P205, DOI 10.1016/0004-3702(81)90025-4; BRADY M, 1982, COMPUT SURV, V14, P3, DOI 10.1145/356869.356871; BRADY M, 1983, COMPUT VISION GRAPH, V22, P70, DOI 10.1016/0734-189X(83)90096-8; CANNY FR, 1983, MIT720 ART INT LAB T; Davis L. S., 1975, COMPUT VISION GRAPH, V4, P248, DOI [DOI 10.1016/0146-664X(75)90012-X, 10.1016/0146-664X(75)90012-X]; GRIMSON WEL, 1980, APR P DARPA IM UND W, P128; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HILDRETH EC, 1983, COMPUT VISION GRAPH, V22, P1, DOI 10.1016/0734-189X(83)90093-2; HILDRETH EC, 1980, MIT AITR579 REP; HILDRETH EC, 1982, 2ND P INT COMP ENG C; HUERTAS A, 1985, 3RD P IEEE WORKSH CO, P63; HUERTAS A, 1981, USCIPI1010 U SO CAL; KING D, 1982, ISG102 U SO CAL TECH; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MEDIONI G, 1983, JUN P DARPA IM UND W; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; NISHIHARA HK, 1981, APR P DARPA IM UND W, P114; Pratt W.K, 1977, DIGITAL IMAGE PROCES; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8	20	248	273	2	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1986	8	5					651	664		10.1109/TPAMI.1986.4767838	http://dx.doi.org/10.1109/TPAMI.1986.4767838			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	D7584	21869362				2022-12-18	WOS:A1986D758400006
J	Turaga, P; Veeraraghavan, A; Srivastava, A; Chellappa, R				Turaga, Pavan; Veeraraghavan, Ashok; Srivastava, Anuj; Chellappa, Rama			Statistical Computations on Grassmann and Stiefel Manifolds for Image and Video-Based Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image and video models; feature representation; statistical models; manifolds; Stiefel; Grassmann	FACE RECOGNITION; ILLUMINATION; VIEW	In this paper, we examine image and video-based recognition applications where the underlying models have a special structure-the linear subspace structure. We discuss how commonly used parametric models for videos and image sets can be described using the unified framework of Grassmann and Stiefel manifolds. We first show that the parameters of linear dynamic models are finite-dimensional linear subspaces of appropriate dimensions. Unordered image sets as samples from a finite-dimensional linear subspace naturally fall under this framework. We show that an inference over subspaces can be naturally cast as an inference problem on the Grassmann manifold. To perform recognition using subspace-based models, we need tools from the Riemannian geometry of the Grassmann manifold. This involves a study of the geometric properties of the space, appropriate definitions of Riemannian metrics, and definition of geodesics. Further, we derive statistical modeling of inter and intraclass variations that respect the geometry of the space. We apply techniques such as intrinsic and extrinsic statistics to enable maximum-likelihood classification. We also provide algorithms for unsupervised clustering derived from the geometry of the manifold. Finally, we demonstrate the improved performance of these methods in a wide variety of vision applications such as activity recognition, video-based face recognition, object recognition from image sets, and activity-based video clustering.	[Turaga, Pavan] Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA; [Veeraraghavan, Ashok] Mitusbishi Elect Res Labs, Cambridge, MA 02139 USA; [Srivastava, Anuj] Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA; [Chellappa, Rama] Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA	University System of Maryland; University of Maryland College Park; State University System of Florida; Florida State University; University System of Maryland; University of Maryland College Park	Turaga, P (corresponding author), Univ Maryland, Ctr Automat Res, 4409 AV Williams Bldg, College Pk, MD 20742 USA.	pturaga@umiacs.umd.edu; vashok@merl.com; anuj@stat.fsu.edu; rama@umiacs.umd.edu	Srivastava, Anuj/F-7417-2011; Chellappa, Rama/B-6573-2012; Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/AAJ-1504-2020; Turaga, Pavan/W-6186-2019; Srivastava, Anuj/L-4705-2019	Srivastava, Anuj/0000-0001-7406-0338; Turaga, Pavan/0000-0002-5263-5943	US Office of Naval Research [N00014-09-1-0664]; Direct For Mathematical & Physical Scien [0915003] Funding Source: National Science Foundation	US Office of Naval Research(Office of Naval Research); Direct For Mathematical & Physical Scien(National Science Foundation (NSF)NSF - Directorate for Mathematical & Physical Sciences (MPS))	A preliminary version of this paper appeared in [1]. This work was partially supported by US Office of Naval Research Grant N00014-09-1-0664.	Absil PA, 2004, ACTA APPL MATH, V80, P199, DOI 10.1023/B:ACAP.0000013855.14971.91; Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1; Aggarwal G., 2004, P INT C PATT REC AUG; [Anonymous], 2008, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2008.4587733; Arandjelovic O, 2005, PROC CVPR IEEE, P581; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Begelfor E., 2006, 2006 IEEE COMPUTER S, V2, P2087, DOI DOI 10.1109/CVPR.2006.50; Bhattacharya R, 2003, ANN STAT, V31, P1; Bissacco A, 2001, PROC CVPR IEEE, P52; Boothby WM., 1975, INTRO DIFFERENTIABLE; Chan AB, 2008, IEEE T PATTERN ANAL, V30, P909, DOI 10.1109/TPAMI.2007.70738; Chikuse Y., 2003, STAT SPECIAL MANIFOL, DOI [10.1007/978-0-387-21540-2, DOI 10.1007/978-0-387-21540-2]; De Cock K, 2002, SYST CONTROL LETT, V46, P265, DOI 10.1016/S0167-6911(02)00135-4; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; Fukui K., 2003, P INT S ROB RES, P192; GALLIVAN K, 2003, P IEEE 12 WORKSH STA; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Goodall CR, 1999, J COMPUT GRAPH STAT, V8, P143, DOI 10.2307/1390631; Hamm J., 2008, THESIS U PENNSYLVANI; Hamm J., 2008, P INT C MACH LEARN I, P376, DOI DOI 10.1145/1390156.1390204; KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502; Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Lee KC, 2003, PROC CVPR IEEE, P313; Lin D., 2006, IEEE CVPR, V2, P1727; LUI YM, 2009, P IEEE 3 INT C BIOM; Lui YM, 2008, LECT NOTES COMPUT SC, V5303, P44, DOI 10.1007/978-3-540-88688-4_4; *NIST, 2011, NIST MULT BIOM GRAND; Patrangenaru V., 2003, P 22 LEEDS ANN STAT; Pelletier B, 2005, STAT PROBABIL LETT, V73, P297, DOI 10.1016/j.spl.2005.04.004; PENNEC X, 2008, P EM TRENDS VIS COMP, P347; Pennec X, 2006, J MATH IMAGING VIS, V25, P127, DOI 10.1007/s10851-006-6228-4; Porikli F, 2006, P IEEE COMP SOC C CO, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]; Saisan P, 2001, PROC CVPR IEEE, P58; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Srivastava A, 2005, IEEE T PATTERN ANAL, V27, P590, DOI 10.1109/TPAMI.2005.86; Srivastava A, 2004, ADV APPL PROBAB, V36, P43, DOI 10.1239/aap/1077134463; Subbarao R, 2009, INT J COMPUT VISION, V84, P1, DOI 10.1007/s11263-008-0195-8; Turaga Pavan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2435, DOI 10.1109/CVPRW.2009.5206710; Turaga P, 2009, COMPUT VIS IMAGE UND, V113, P353, DOI 10.1016/j.cviu.2008.08.009; TUZEL O, 2006, P EUR C COMP VIS GRA, V2, P589; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; VANOVERSCHEE P, 1993, AUTOMATICA, V29, P649, DOI 10.1016/0005-1098(93)90061-W; Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246; Veeraraghavan A, 2009, IEEE T IMAGE PROCESS, V18, P1326, DOI 10.1109/TIP.2009.2017143; WANG Y, 2006, P IEEE C COMP VIS PA, P1654; Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013; Yamaguchi O, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P318, DOI 10.1109/AFGR.1998.670968; Zhou SK, 2006, IEEE T PATTERN ANAL, V28, P917, DOI 10.1109/TPAMI.2006.120	50	247	250	0	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2011	33	11					2273	2286		10.1109/TPAMI.2011.52	http://dx.doi.org/10.1109/TPAMI.2011.52			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	820MM	21422487	Green Submitted			2022-12-18	WOS:000294910000012
J	Park, U; Tong, YY; Jain, AK				Park, Unsang; Tong, Yiying; Jain, Anil K.			Age-Invariant Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; facial aging; aging modeling; aging simulation; 3D face model		One of the challenges in automatic face recognition is to achieve temporal invariance. In other words, the goal is to come up with a representation and matching scheme that is robust to changes due to facial aging. Facial aging is a complex process that affects both the 3D shape of the face and its texture (e. g., wrinkles). These shape and texture changes degrade the performance of automatic face recognition systems. However, facial aging has not received substantial attention compared to other facial variations due to pose, lighting, and expression. We propose a 3D aging modeling technique and show how it can be used to compensate for the age variations to improve the face recognition performance. The aging modeling technique adapts view-invariant 3D face models to the given 2D face aging database. The proposed approach is evaluated on three different databases (i.g., FG-NET, MORPH, and BROWNS) using FaceVACS, a state-of-the-art commercial face recognition engine.	[Park, Unsang; Tong, Yiying; Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA; [Jain, Anil K.] Korea Univ, World Class Univ Program, Dept Brain & Cognit Engn, Seoul 136701, South Korea	Michigan State University; Korea University	Park, U (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, 3105 Engn Bldg, E Lansing, MI 48824 USA.	parkunsa@cse.msu.edu; ytong@cse.msu.edu; jain@cse.msu.edu	Tong, Yiying/D-9202-2012	Tong, Yiying/0000-0002-7929-4333	Direct For Computer & Info Scie & Enginr [0747120, 0811313] Funding Source: National Science Foundation	Direct For Computer & Info Scie & Enginr(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))		Albert A., 2004, AGING ADULT SKULL FA; [Anonymous], 2010, FG NET AGING DATABAS; [Anonymous], 2010, FACEVACS SOFTWARE DE; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Farkas LG, 1994, ANTHROPOMETRY HEAD F; Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733; Haibin Ling, 2007, 2007 11th IEEE International Conference on Computer Vision, P1; Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091; Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553; Nixon N, 2007, BROWN SISTERS 33 YEA; OToole AJ, 1997, PERCEPTION, V26, P719, DOI 10.1068/p260719; Park U., 2008, 2008 8 IEEE INT C AU, P1, DOI 10.1109/AFGR.2008.4813408; Patterson E., 2006, INT C VIS IM IM PROC, V171, pC176; Phillips P.J., 2007, 7408 NISTIR; Pighin F, 2002, INT J COMPUT VISION, V50, P143, DOI 10.1023/A:1020393915769; PITTENGER JB, 1975, J EXP PSYCHOL HUMAN, V1, P374, DOI 10.1037/0096-1523.1.4.374; Ramanathan N, 2005, PROC CVPR IEEE, P462; RAMANATHAN N, 2006, P IEEE C COMP VIS PA, V1, P387; Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341; Scherbaum K, 2007, COMPUT GRAPH FORUM, V26, P285, DOI 10.1111/j.1467-8659.2007.01050.x; STEGMANN MB, 2003, P INT C MED IM COMP, P951; Suo J. L., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383055; Thompson DW, 1992, GROWTH FORM, V2nd, DOI DOI 10.1017/CBO978110732585210.1017/CBO9781107325852; Wang JY, 2006, INT C PATT RECOG, P913	25	246	271	1	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2010	32	5					947	U194		10.1109/TPAMI.2010.14	http://dx.doi.org/10.1109/TPAMI.2010.14			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	569AW	20299717				2022-12-18	WOS:000275569300014
J	Bergevin, R; Soucy, M; Gagnon, H; Laurendeau, D				Bergevin, R; Soucy, M; Gagnon, H; Laurendeau, D			Towards a general multi-view registration technique	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multiple view registration; model building; three-dimensional objects; range images; surface modeling; multiple view integration		We present an algorithm that reduces significantly the level of the registration errors between all pairs in a set of range views. This algorithm refines initial estimates of the transformation matrices obtained from either the calibrated acquisition setup or a crude manual alignment. It is an instance of a category of registration algorithms known as iterated closest-point (ICP) algorithms. The algorithm considers the network of views as a whole and minimizes the registration errors of all views simultaneously. This leads to a well-balanced network of views in which the registration errors are equally distributed, an objective not met by previously published ICP algorithms which all process the views sequentially. Experimental results show that this refinement technique improves the calibrated registrations and the quality of the integrated model for complex multipart objects. In the case of scenes comprising man-made objects of very simple shapes, the basic algorithm faces problems common to all ICP algorithms and must thus be extended.			Bergevin, R (corresponding author), UNIV LAVAL, DEPT ELECT & COMP ENGN, COMP VIS & SYST LAB, QUEBEC CITY, PQ G1K 7P4, CANADA.			Bergevin, Robert/0000-0002-1115-7471				BERALDIN JA, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P163, DOI 10.1109/ICPR.1992.201532; BERGEVIN R, 1995, COMPUT VIS IMAGE UND, V61, P1, DOI 10.1006/cviu.1995.1001; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BLAIS G, 1993, TRCIM9316 MCGILL U C; BOULANGER P, 1992, P 3 INT C RAP PROT D, P213; CHEN Y, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2724, DOI 10.1109/ROBOT.1991.132043; Ferrie F. P., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P117; GAGNON H, 1994, P IEEE C COMP VIS PA; Kamgar-Parsi B., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P282, DOI 10.1109/CVPR.1989.37862; KISHON E, 1987, P AAAI WORKSHOP SPAT, P250; POTMESIL M, 1983, 8TH P INT JOINT C AI, P1089; RIOUX M, 1984, APPL OPTICS, V23, P3837, DOI 10.1364/AO.23.003837; RODRIGUEZ JJ, 1989, P WORKSHOP INTERPRET, P200; SOUCY M, 1995, MACH VISION APPL, V8, P53, DOI 10.1007/BF01213638; SOUCY M, 1995, IEEE T PATTERN ANAL, V17, P344, DOI 10.1109/34.385982; Soucy M., 1992, THESIS LAVAL U QUEBE; Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149	18	246	281	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1996	18	5					540	547		10.1109/34.494643	http://dx.doi.org/10.1109/34.494643			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL691					2022-12-18	WOS:A1996UL69100006
J	Mori, G; Belongie, S; Malik, J				Mori, G; Belongie, S; Malik, J			Efficient shape matching using shape contexts	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape; object recognition; optical character recognition	OBJECT RECOGNITION	We demonstrate that shape contexts can be used to quickly prune a search for similar shapes. We present two algorithms for rapid shape retrieval: representative shape contexts, performing comparisons based on a small number of shape contexts, and shapemes, using vector quantization in the space of shape contexts to obtain prototypical shape pieces.	Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada; Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA; Univ Calif Berkeley, Elect Engn & Comp Sci Div, Berkeley, CA 94720 USA	Simon Fraser University; University of California System; University of California San Diego; University of California System; University of California Berkeley	Mori, G (corresponding author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.	mori@cs.sfu.ca; sjb@cs.ucsd.edu; malik@cs.berkeley.edu	Rohlf, F J/A-8710-2008	Belongie, Serge/0000-0002-0388-5217				Amit Y, 1997, IEEE T PATTERN ANAL, V19, P1300, DOI 10.1109/34.632990; Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; Burges CJC, 1997, ADV NEUR IN, V9, P375; Carlsson S, 1999, LECT NOTES COMPUT SC, V1681, P58; Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733; Dorko G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P634; Fergus R, 2003, PROC CVPR IEEE, P264; Frome A, 2004, LECT NOTES COMPUT SC, V3023, P224; GAVRILA DM, 1999, P IEEE INT C COMP VI, P87, DOI DOI 10.1109/ICCV.1999.791202; Huttenlocher DP, 1999, IEEE T PATTERN ANAL, V21, P951, DOI 10.1109/34.790437; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Johnson AE, 1997, PROC CVPR IEEE, P684, DOI 10.1109/CVPR.1997.609400; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Leibe B, 2003, PROC CVPR IEEE, P409; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MARTIN D, 2002, ADV NEURAL INF PROCE; Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X; Mori G, 2003, PROC CVPR IEEE, P134; Mori G, 2001, PROC CVPR IEEE, P723; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; SEBASTIAN T, 2002, P EUR C COMP VIS, V3, P731; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; SHARVIT D, 1998, J VISUAL COMM IM JUN; SNODGRASS JG, 1980, J EXP PSYCHOL-HUM L, V6, P174, DOI 10.1037/0278-7393.6.2.174; Thayananthan A, 2003, PROC CVPR IEEE, P127; Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; VONAHN L, 2002, CMUCS02117; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	35	245	281	0	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2005	27	11					1832	1837		10.1109/TPAMI.2005.220	http://dx.doi.org/10.1109/TPAMI.2005.220			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	963SN	16285381	Green Submitted			2022-12-18	WOS:000231826300013
J	Yacoob, Y; Davis, LS				Yacoob, Y; Davis, LS			Recognizing human facial expressions from long image sequences using optical flow	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face expression recognition; non-rigid motion analysis; optical flow; tracking	RECOGNITION; FACE	An approach to the analysis and representation of facial dynamics for recognition of facial expressions from image sequences is presented. The algorithms utilize optical Row computation to identify the direction of rigid and nonrigid motions that are caused by human facial expressions. A mid-level symbolic representation motivated by psychological considerations is developed. Recognition of six facial expressions, as well as eye blinking, is demonstrated on a large set of image sequences.			Yacoob, Y (corresponding author), UNIV MARYLAND, CTR AUTOMAT RES, COMP VIS LAB, COLLEGE PK, MD 20742 USA.							ABDELMOTTALEB M, 1993, IEEE C COMPUTER VISI, P321; BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037/0022-3514.37.11.2049; BEYMER D, 1993, 1431 MIT AI; BLACK MJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P374, DOI 10.1109/ICCV.1995.466915; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; CHELLAPPA R, 1994, CARTR731 U MARY; Ekman P., 2002, FACIAL ACTION CODING; Ekman P., 1975, UNMASKING FACE; ESSA IA, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P76, DOI 10.1109/CVPR.1994.323813; ESSA IA, 1994, 303 MIT MED LAB PERC; LI HB, 1993, IEEE T PATTERN ANAL, V15, P545, DOI 10.1109/34.216724; MASE K, 1991, IEICE TRANS COMMUN, V74, P3474; MATSUNO K, 1994, P ECCV, P513; ROSENBLUM M, 1994, IEEE WORKSH MOT NONR, P43; TERZOPOULOS D, 1993, IEEE T PATTERN ANAL, V15, P569, DOI 10.1109/34.216726; YACOOB Y, 1994, CVGIP-IMAG UNDERSTAN, V60, P168, DOI 10.1006/ciun.1994.1045; YOUNG AW, 1989, HDB RES FACE PROCESS; YUILLE AL, 1989, IEEE COMP SOC C COMP, P104	18	245	252	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1996	18	6					636	642		10.1109/34.506414	http://dx.doi.org/10.1109/34.506414			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UR254					2022-12-18	WOS:A1996UR25400007
J	BLAIS, G; LEVINE, MD				BLAIS, G; LEVINE, MD			REGISTERING MULTIVIEW RANGE DATA TO CREATE 3D COMPUTER OBJECTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						RANGE; MULTIVIEW; 3D; IMAGE REGISTRATION; SIMULATED ANNEALING; SURFACE MODELS; SURFACE INTEGRATION; RANGEFINDER CALIBRATION		This research deals with the problem of range image registration for the purpose of building surface models of three-dimensional objects. The registration task involves finding the translation and rotation parameters which properly align overlapping views of the object so as to reconstruct from these partial surfaces, an integrated surface representation of the object. The approach taken is to express the registration task as an optimization problem. We define a function which measures the quality of the alignment between the partial surfaces contained in two range images as produced by a set of motion parameters. This function computes a sum of Euclidean distances between a set of control points on one of the surfaces to corresponding points on the other. The strength of this approach resides in the method used to determine point correspondences across range images. It is based on reversing the rangefinder calibration process, resulting in a set of equations which can be used to directly compute the location of a point in a range image corresponding to an arbitrary point in three-dimensional space. A stochastic optimization technique, very fast simulated reannealing (VFSR), is used to minimize the cost function. Dual-view registration experiments yielded excellent results in very reasonable computational time, A multiview registration experiment was also performed, but a large processing time was required. A complete surface model of a typical 3D object was then constructed from the integration of its multiple partial views. The effectiveness with which registration of range images can be accomplished makes this method attractive for many practical applications where surface models of 3D objects must be constructed.	MCGILL UNIV, CTR INTELLIGENT MACHINES, MONTREAL, PQ, CANADA; MCGILL UNIV, DEPT ELECT ENGN, MONTREAL, PQ, CANADA	McGill University; McGill University	BLAIS, G (corresponding author), BELL NO RES LTD, VERDUN, PQ, CANADA.							BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BLAIS G, 1993, THESIS MCGILL U; CHAMPLEBOUX G, 1992, JUN CVPR 92; CHEN HH, 1991, IEEE T PATTERN ANAL, V13, P530, DOI 10.1109/34.87340; Cheng J.-C., 1991, International Journal of Pattern Recognition and Artificial Intelligence, V5, P399, DOI 10.1142/S0218001491000223; CHENG Y, 1991, 1991 P IEEE INT C RO; Huber P., 1981, ROBUST STATISTICS, DOI [10.1002/0471725250, 10.1002/0471725250.ch1]; INGBER L, 1989, MATH COMPUT MODEL, V12, P967, DOI 10.1016/0895-7177(89)90202-1; POTMESIL M, 1983, 8TH INT JOINT C ART, V2; SABATA B, 1991, CVGIP-IMAG UNDERSTAN, V54, P309, DOI 10.1016/1049-9660(91)90032-K; SHAH MA, 1984, COMPUT VISION GRAPH, V28, P345, DOI 10.1016/S0734-189X(84)80012-2; SOUCY G, 1992, THESIS MCGILL U; Szeliski R., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P207, DOI 10.1109/CCV.1988.589992; WHAITE P, 1991, IEEE T PATTERN ANAL, V13, P1038, DOI 10.1109/34.99237; WHAITE P, 1992, JUN P IEEE COMP SOC, P3	15	245	309	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1995	17	8					820	824		10.1109/34.400574	http://dx.doi.org/10.1109/34.400574			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RL035					2022-12-18	WOS:A1995RL03500010
J	Almazan, J; Gordo, A; Fornes, A; Valveny, E				Almazan, Jon; Gordo, Albert; Fornes, Alicia; Valveny, Ernest			Word Spotting and Recognition with Embedded Attributes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Word image representation; attribute-based representation; handwritten text; scene text; word spotting; word recognition	CLASSIFICATION; QUANTIZATION; MODELS	This paper addresses the problems of word spotting and word recognition on images. In word spotting, the goal is to find all instances of a query word in a dataset of images. In recognition, the goal is to recognize the content of the word image, usually aided by a dictionary or lexicon. We describe an approach in which both word images and text strings are embedded in a common vectorial subspace. This is achieved by a combination of label embedding and attributes learning, and a common subspace regression. In this subspace, images and strings that represent the same word are close together, allowing one to cast recognition and retrieval tasks as a nearest neighbor problem. Contrary to most other existing methods, our representation has a fixed length, is low dimensional, and is very fast to compute and, especially, to compare. We test our approach on four public datasets of both handwritten documents and natural images showing results comparable or better than the state-of-the-art on spotting and recognition tasks.	[Almazan, Jon; Fornes, Alicia; Valveny, Ernest] Univ Autonoma Barcelona, Comp Vis Ctr, E-08193 Barcelona, Spain; [Gordo, Albert] Xerox Res Ctr Europe, Comp Vis Grp, Meylan, France	Autonomous University of Barcelona; Centre de Visio per Computador (CVC); Xerox	Almazan, J (corresponding author), Univ Autonoma Barcelona, Comp Vis Ctr, E-08193 Barcelona, Spain.	almazan@cvc.uab.es; albert.gordo@xrce.xerox.com; afornes@cvc.uab.es; ernest@cvc.uab.es	Valveny, Ernest/GSN-8920-2022; Fornes, Alicia/C-6715-2015	Fornes, Alicia/0000-0002-9692-5336	EU [ERC-2010-AdG-20100407-269796]; UAB [471-01-8/09];  [TIN2011-24631];  [TIN2009-14633-C03-03];  [TIN2012-37475-C02-02]	EU(European Commission); UAB; ; ; 	J. Almazan, A. Fornes, and E. Valveny are partially supported by the Spanish projects TIN2011-24631, TIN2009-14633-C03-03, TIN2012-37475-C02-02, by the EU project ERC-2010-AdG-20100407-269796 and by a research grant of the UAB (471-01-8/09). A preliminary version of this paper [1] appears in ICCV2013.	Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111; Aldavert D, 2013, PROC INT CONF DOC, P511, DOI 10.1109/ICDAR.2013.108; Almazan J, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.67; Almazan J, 2013, IEEE I CONF COMP VIS, P1017, DOI 10.1109/ICCV.2013.130; Bengio Samy, 2010, ADV NEURAL INFORM PR, V1, P163, DOI [10.5555/2997189.2997208, DOI 10.5555/2997189.2997208]; Bissacco A, 2013, IEEE I CONF COMP VIS, P785, DOI 10.1109/ICCV.2013.102; Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/cvpr.2008.4587586; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Espana-Boquera S, 2011, IEEE T PATTERN ANAL, V33, P767, DOI 10.1109/TPAMI.2010.141; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Fischer A., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3416, DOI 10.1109/ICPR.2010.834; Fischer A, 2012, PATTERN RECOGN LETT, V33, P934, DOI 10.1016/j.patrec.2011.09.009; Frinken V, 2012, IEEE T PATTERN ANAL, V34, P211, DOI 10.1109/TPAMI.2011.113; Gatos Basilis, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P271, DOI 10.1109/ICDAR.2009.236; Goel V, 2013, PROC INT CONF DOC, P398, DOI 10.1109/ICDAR.2013.87; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Jaakkola TS, 1999, ADV NEUR IN, V11, P487; Jegou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Keaton P, 1997, WORKSHOP ON DOCUMENT IMAGE ANALYSIS (DIA'97), PROCEEDINGS, P74, DOI 10.1109/DIA.1997.627095; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Leslie Christina, 2002, Pac Symp Biocomput, P564; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; Lu SJ, 2008, IEEE T PATTERN ANAL, V30, P1913, DOI 10.1109/TPAMI.2008.89; Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229; Manmatha R, 2005, IEEE T PATTERN ANAL, V27, P1212, DOI 10.1109/TPAMI.2005.150; Manmatha R, 1996, PROC CVPR IEEE, P631, DOI 10.1109/CVPR.1996.517139; Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071; Mishra A, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.127; Mishra A, 2013, IEEE I CONF COMP VIS, P3040, DOI 10.1109/ICCV.2013.378; Mishra A, 2012, PROC CVPR IEEE, P2687, DOI 10.1109/CVPR.2012.6247990; Neumann L, 2013, IEEE I CONF COMP VIS, P97, DOI 10.1109/ICCV.2013.19; Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097; Perronnin Florent, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P106, DOI 10.1109/ICDAR.2009.16; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Rahimi A., 2007, 21 ANN C ADV NEUR IN; Rath T. M., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P369, DOI 10.1145/1008992.1009056; Rath TM, 2007, INT J DOC ANAL RECOG, V9, P139, DOI 10.1007/s10032-006-0027-8; Rodriguez-Serrano J., 2008, INT C FRONT HANDWR R; Rodriguez-Serrano JA, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.5; Rodriguez-Serrano JA, 2012, IEEE T PATTERN ANAL, V34, P2108, DOI 10.1109/TPAMI.2012.25; Rohrbach M, 2011, PROC CVPR IEEE, P1641, DOI 10.1109/CVPR.2011.5995627; Rusinol M, 2011, PROC INT CONF DOC, P63, DOI 10.1109/ICDAR.2011.22; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Sanchez J, 2012, PATTERN RECOGN LETT, V33, P2216, DOI 10.1016/j.patrec.2012.07.019; Scheirer WJ, 2012, PROC CVPR IEEE, P2933, DOI 10.1109/CVPR.2012.6248021; Siddiquie B, 2011, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2011.5995329; Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56; Vinciarelli A, 2002, INT C PATT RECOG, P81, DOI 10.1109/ICPR.2002.1047800; Wah C, 2013, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2013.106; Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402; Weston J, 2010, MACH LEARN, V81, P21, DOI 10.1007/s10994-010-5198-3; Yalniz I. Z., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P48, DOI 10.1109/DAS.2012.18	59	242	253	2	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2014	36	12					2552	2566		10.1109/TPAMI.2014.2339814	http://dx.doi.org/10.1109/TPAMI.2014.2339814			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AT5MW	26353157				2022-12-18	WOS:000344988000016
J	Lhuillier, M; Quan, L				Lhuillier, M; Quan, L			A quasi-dense approach to surface reconstruction from uncalibrated images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						three-dimensional reconstruction; surface reconstruction; structure from motion; 3D modeling; matching; uncertainty; variational calculus; level-set method	ROBUST; PROPAGATION; STEREO	This paper proposes a quasi-dense approach to 3D surface model acquisition from uncalibrated images. First, correspondence information and geometry are computed based on new quasi-dense point features that are resampled subpixel points from a disparity map. The quasi-dense approach gives more robust and accurate geometry estimations than the standard sparse approach. The robustness is measured as the success rate of full automatic geometry estimation with all involved parameters fixed. The accuracy is measured by a fast gauge-free uncertainty estimation algorithm. The quasi-dense approach also works for more largely separated images than the sparse approach, therefore, it requires fewer images for modeling. More importantly, the quasi-dense approach delivers a high density of reconstructed 3D points on which a surface representation can be reconstructed. This fills the gap of insufficiency of the sparse approach for surface reconstruction, essential for modeling and visualization applications. Second, surface reconstruction methods from the given quasi-dense geometry are also developed. The algorithm optimizes new unified functionals integrating both 3D quasi-dense points and 2D image information, including silhouettes. Combining both 3D data and 2D images is more robust than the existing methods using only 2D information or only 3D data. An efficient bounded regularization method is proposed to implement the surface evolution by level-set methods. Its properties are discussed and proven for some cases. As a whole, a complete automatic and practical system of 3D modeling from raw images captured by hand-held cameras to surface representation is proposed. Extensive experiments demonstrate the superior performance of the quasi-dense approach with respect to the standard sparse approach in robustness, accuracy, and applicability.	CNRS, LASMEA, UMR UBP 6602, 24 Ave Landais, F-63177 Clermont Ferrand, France; HKUST, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	Centre National de la Recherche Scientifique (CNRS); Universite Clermont Auvergne (UCA); Hong Kong University of Science & Technology	Lhuillier, M (corresponding author), CNRS, LASMEA, UMR UBP 6602, 24 Ave Landais, F-63177 Clermont Ferrand, France.	Maxime.Lhuillier@lasmea.univ-bpclermont.fr; quan@cs.ust.hk						*2D3 LTD, 2000, BOUJOU; Beardsley P., 1996, P EUR C COMP VIS, P683; Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890; Brown D.C., 1976, INT ARCH PHOTOGRAMME, V21; Caselles V, 1997, IEEE T PATTERN ANAL, V19, P394, DOI 10.1109/34.588023; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; DEVERNAY F, 1995, P INT SOC OPT ENG C, V2567; FAUGERAS O, 1998, P 5 EUR C COMP VIS, P379; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FITZGIBBON AW, 1998, P EUR C COMP VIS, P311; Fua P, 1997, INT J COMPUT VISION, V24, P19, DOI 10.1023/A:1007918123901; FUA P, 1995, P INT SOC PHOTO REM; Gibson S, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P37, DOI 10.1109/ISMAR.2002.1115068; Gomes J, 2000, J VIS COMMUN IMAGE R, V11, P209, DOI 10.1006/jvci.1999.0439; Guenin BM, 1998, P IEEE SEMICOND THER, P55, DOI 10.1109/STHERM.1998.660387; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; HARTLEY RI, 1993, P 2 EUR US WORKSH IN, P187; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HEYDEN A, 1995, THESIS LUND I TECHNO; HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011; KICHENASSAMY S, 1995, P 5 INT C COMP VIS J; KOLMOGOROV V, 2002, P 7 EUR C COMP VIS; Kutulakos K. N., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P307, DOI 10.1109/ICCV.1999.791235; LAVEAU S, 1996, THESIS ECOLE POLYTEC; Lhuillier M, 2002, IEEE T PATTERN ANAL, V24, P1140, DOI 10.1109/TPAMI.2002.1023810; LHUILLIER M, 2003, P 9 INT C COMP VIS; LHUILLIER M, 2002, P 7 EUR C COMP VIS, V2, P125; Lucas Bruce, 1981, IJCAI; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; MCLAUCHLAN PF, 2000, P VIS ALG WORKSH; MORRIS DD, 1999, P INT WORKSH VIS ALG; Morris VJ, 2001, LEBENSM-WISS TECHNOL, V34, P3, DOI 10.1006/fstl.2000.0706; Narayanan PJ, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P3, DOI 10.1109/ICCV.1998.710694; Nister D, 2000, LECT NOTES COMPUT SC, V1842, P649; Nister D., 2001, THESIS ROYAL I TECHN; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705; POLLEFEYS M, 1998, P EUR WORKSH 3D STRU, P139; POLLEFEYS M, 2002, P 7 EUR C COMP VIS M; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Pritchett P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P754, DOI 10.1109/ICCV.1998.710802; QUAN L, 1995, IEEE T PATTERN ANAL, V17, P34; Seitz SM, 1997, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.1997.609462; Sethian J. A., 1999, LEVEL SET METHODS FA; Slama CC., 1980, MANUAL PHOTOGRAMMETR, V4th edn; Strecha C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1194; SZELISKI R, 1993, CVGIP-IMAG UNDERSTAN, V58, P23, DOI 10.1006/ciun.1993.1029; SZELISKI R, 1993, ROBUST SHAPE RECOVER; Tang CK, 2002, IEEE T PATTERN ANAL, V24, P858, DOI 10.1109/TPAMI.2002.1008395; TELL B, 2000, P 6 EUR C COMP VIS, P814; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; Torr PHS, 1997, IMAGE VISION COMPUT, V15, P591, DOI 10.1016/S0262-8856(97)00010-3; TORR PHS, 2002, P BRIT MACH VIS C, P414; Triggs B, 1997, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.1997.609388; Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298; Tuytelaars T, 2000, P 11 BRIT MACH VIS C; Whitaker RT, 1998, INT J COMPUT VISION, V29, P203, DOI 10.1023/A:1008036829907; ZHANG Z, 2001, MSRTR2001101; Zhang ZK, 2000, 2000 IEEE HONG KONG ELECTRON DEVICES MEETING, PROCEEDINGS, P68, DOI 10.1109/HKEDM.2000.904218; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4; Zhao HK, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P194, DOI 10.1109/VLSM.2001.938900; Zhao HK, 2000, COMPUT VIS IMAGE UND, V80, P295, DOI 10.1006/cviu.2000.0875	65	242	297	2	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2005	27	3					418	433		10.1109/TPAMI.2005.44	http://dx.doi.org/10.1109/TPAMI.2005.44			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	887IW	15747796	Green Submitted			2022-12-18	WOS:000226300200010
J	Larranaga, P; Poza, M; Yurramendi, Y; Murga, RH; Kuijpers, CMH				Larranaga, P; Poza, M; Yurramendi, Y; Murga, RH; Kuijpers, CMH			Structure learning of Bayesian networks by genetic algorithms: A performance analysis of control parameters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian network; genetic algorithm; structure learning; combinatorial optimization; performance analysis	CONVERGENCE	We present a new approach to structure learning in the field of Bayesian networks: We tackle the problem of the search for the best Bayesian network structure, given a database of cases, using the genetic algorithm philosophy for searching among alternative structures. We start by assuming an ordering between the nodes of the network structures. This assumption is necessary to guarantee that the networks that are created by the genetic algorithms are legal Bayesian network structures. Next, we release the ordering assumption by using a ''repair operator'' which converts illegal structures into legal ones. We present empirical results and analyze them statistically. The best results are obtained with an elitist genetic algorithm that contains a local optimizer.			Larranaga, P (corresponding author), UNIV BASQUE COUNTRY,DEPT COMP SCI & ARTIFICIAL INTELLIGENCE,POB 649,E-20080 SAN SEBASTIAN,SPAIN.		Larranaga, Pedro/F-9293-2013	Larranaga, Pedro/0000-0003-0652-9872				ACID S, 1991, LECT NOTES COMPUTER, V548; ALIFERIS CF, 1994, UNCERTAINTY ARTIFICI; Bacchus F., 1993, UNCERTAINTY ARTIFICI, P243; Beinlinch I., 1989, 2ND P EUR C ART INT, P247; Bouckaert R., 1994, P 10 INT C UNC ART I, P102; Bouckaert R. R., 1992, P 8 C UNC ART INT, P9; Bouckaert RR, 1993, Lecture Notes in Computer Science, V747, P41; Bremermann H. J., 1965, BIOPHYSICS CYBERNETI, P157; CHAKRABORTY UK, 1993, INFORM PROCESS LETT, V46, P199, DOI 10.1016/0020-0190(93)90027-7; Chickering D., 1995, 5 INT WORKSH ART INT, P112; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1023/A:1022649401552; Davis L, 1991, HDB GENETIC ALGORITH, DOI DOI 10.1.1.87.3586; EIBEN AE, 1990, COMPUTING SCI NOTES; Fogel L. J., 1962, IND RES AUTONOMOUS A; FUNG RM, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P762; Goldberg DE, 1989, GENETIC ALGORITHMS S; Hartl R. F., 1990, GLOBAL CONVERGENCE P; Heckerman D., 1994, MSRTR9409; HERSKOVITS E, 1990, KSL9022 STANF U KNOW; HERSKOVITS EH, 1991, THESIS STANFORD U ME; Hoffgen K., 1993, 464 U DORTM; HOLLAND J, 1975, ADAPTATION NATURAL A; Inc S. P. S. S., 1988, SPSS X USERS GUIDE; JANIKOV C, 1990, CONVERGENCE PROBLEM; JENSEN FV, 1993, 932003 IR U AALB DEP; Kanal, 1988, UNCERTAINTY ARTIFICI, P149, DOI DOI 10.1016/B978-0-444-70396-5.50019-4; KJAERULFF U, 1992, P 8 C UNC ART INT, P121; LAM W, 1994, COMPUTATIONAL INTELL, V10; Larranaga P., 1995, 5 INT WORKSH ART INT, P310; LARRANAGA P, 1993, LECT NOTES COMPUTER, V747, P227; LARRANAGA P, 1994, STUDIES CLASSIFICATI, P300; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; LAURITZEN SL, 1993, P 4 INT WORKSH ART I, P93; MADIGAN D, 1993, P 4 INT WORKSH ART I, P331; Matzkevich I., 1992, P 8 C UNC ART INT, P191; MECHLING R, 1993, P 4 INT WORKSH ART I, P405; Neapolitan R.E., 1990, PROBABILISTIC REASON; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; PROVAN GM, 1995, 5 INT WORKSH ART INT, P450; PROVAN GM, 1995, P 4 INT WORKSH ART I, P469; Rebane G., 1989, UNCERTAINTY ARTIFICI, P175; Rechenberg I, 1973, OPTIMIERUNG TECHNISC; Robinson R.W., 1997, LECT NOTES MATH, V622, P28; RUDOLPH G, 1994, IEEE T NEURAL NETWOR, V5, P96, DOI 10.1109/72.265964; Schwefel H.P., 1977, EVOLUTIONSSTRATEGIEN, P123, DOI [10.1007/978-3-0348-5927-15, DOI 10.1007/978-3-0348-5927-15]; Singh M., 1993, Uncertainty in Artificial Intelligence. Proceedings of the Ninth Conference (1993), P259; Suzuki J., 1993, Uncertainty in Artificial Intelligence. Proceedings of the Ninth Conference (1993), P266; WEDELIN D, 1993, THESIS CHALMERS U TE	49	242	269	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1996	18	9					912	926		10.1109/34.537345	http://dx.doi.org/10.1109/34.537345			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VK799					2022-12-18	WOS:A1996VK79900005
J	Bai, X; Latecki, LJ				Bai, Xiang; Latecki, Longin Jan			Path similarity skeleton graph matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						skeleton; skeleton graph; graph matching; shape recognition; geodesic path	OBJECT RECOGNITION; SHAPE; SHOCKS	This paper proposes a novel graph matching algorithm and applies it to shape recognition based on object silhouettes. The main idea is to match skeleton graphs by comparing the geodesic paths between skeleton endpoints. In contrast to typical tree or graph matching methods, we do not consider the topological graph structure. Our approach is motivated by the fact that visually similar skeleton graphs may have completely different topological structures. The proposed comparison of geodesic paths between endpoints of skeleton graphs yields correct matching results in such cases. The skeletons are pruned by contour partitioning with Discrete Curve Evolution, which implies that the endpoints of skeleton branches correspond to visual parts of the objects. The experimental results demonstrate that our method is able to produce correct results in the presence of articulations, stretching, and contour deformations.	[Bai, Xiang] Huazhong Univ Sci & Technol, Elect & Informat Engn Dept, Wuhan 430074, Hubei, Peoples R China; [Latecki, Longin Jan] Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA	Huazhong University of Science & Technology; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University	Bai, X (corresponding author), Huazhong Univ Sci & Technol, Elect & Informat Engn Dept, Wuhan 430074, Hubei, Peoples R China.	xiang.bai@gmail.com; latecki@temple.edu		Latecki, Longin Jan/0000-0002-5102-8244				Aach J, 2001, BIOINFORMATICS, V17, P495, DOI 10.1093/bioinformatics/17.6.495; Aslan C, 2005, IEEE I CONF COMP VIS, P1339; August J, 1999, COMPUT VIS IMAGE UND, V76, P231, DOI 10.1006/cviu.1999.0802; BAI X, 1950, INT J PATTE IN PRESS; BAI X, 2006, P INT C DISC GEOM CO, P567; Bai X, 2007, IEEE T PATTERN ANAL, V29, P449, DOI 10.1109/TPAMI.2007.59; Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; Choi HI, 1997, PAC J MATH, V181, P57, DOI 10.2140/pjm.1997.181.57; Choi WP, 2003, PATTERN RECOGN, V36, P721, DOI 10.1016/S0031-3203(02)00098-5; Chu S, 2002, P SIAM INT C DAT MIN; Cyr CM, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P254, DOI 10.1109/ICCV.2001.937526; Das G, 1997, LECT NOTES ARTIF INT, V1263, P88; DEMIRCI F, 2004, P 8 EUR C COMP VIS P, P322; Demirci MF, 2006, INT J COMPUT VISION, V69, P203, DOI 10.1007/s11263-006-6993-y; Di Ruberto C, 2004, PATTERN RECOGN, V37, P21, DOI 10.1016/j.patcog.2003.07.004; Geiger D, 2003, IEEE T PATTERN ANAL, V25, P86, DOI 10.1109/TPAMI.2003.1159948; Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; KIM WY, 1991, IEEE T PATTERN ANAL, V13, P224, DOI 10.1109/34.75511; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802; Latecki LJ, 2005, FIFTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P701; Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738; Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850; Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41; OGNIEWICZ RL, 1995, PATTERN RECOGN, V28, P343, DOI 10.1016/0031-3203(94)00105-U; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; Pelillo M, 2002, IEEE T PATTERN ANAL, V24, P1535, DOI 10.1109/TPAMI.2002.1046176; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Sebastian T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P755, DOI 10.1109/ICCV.2001.937602; Sebastian TB, 2005, SIGNAL PROCESS, V85, P247, DOI 10.1016/j.sigpro.2004.10.016; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; Shaked D, 1998, COMPUT VIS IMAGE UND, V69, P156, DOI 10.1006/cviu.1997.0598; Shokoufandeh A, 2005, IEEE T PATTERN ANAL, V27, P1125, DOI 10.1109/TPAMI.2005.142; SIDDIQI K, 1995, IEEE T PATTERN ANAL, V17, P239, DOI 10.1109/34.368189; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; Siddiqi K, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P222, DOI 10.1109/ICCV.1998.710722; Siddiqi K, 1999, IMAGE VISION COMPUT, V17, P365, DOI 10.1016/S0262-8856(98)00130-9; Torsello A, 2005, IEEE T PATTERN ANAL, V27, P1087, DOI 10.1109/TPAMI.2005.146; Torsello A, 2004, COMPUT VIS IMAGE UND, V95, P1, DOI 10.1016/j.cviu.2004.03.006; Torsello A, 2003, PATTERN RECOGN LETT, V24, P1089, DOI 10.1016/S0167-8655(02)00255-6; Tu ZW, 2004, LECT NOTES COMPUT SC, V3023, P195; Vlachos M, 2002, PROC INT CONF DATA, P673, DOI 10.1109/ICDE.2002.994784; Vlachos M, 2003, P 9 ACM SIGKDD INT C, P216, DOI DOI 10.1145/956750.956777; Yi BK, 1998, PROC INT CONF DATA, P201, DOI 10.1109/ICDE.1998.655778; Zhu SC, 1996, INT J COMPUT VISION, V20, P187; [No title captured]	50	241	280	2	49	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2008	30	7					1282	1292		10.1109/TPAMI.2007.70769	http://dx.doi.org/10.1109/TPAMI.2007.70769			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	307CA	18550909	Green Submitted			2022-12-18	WOS:000256294100013
J	BOUMAN, C; LIU, BD				BOUMAN, C; LIU, BD			MULTIPLE RESOLUTION SEGMENTATION OF TEXTURED IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CLUSTERING; MARKOV RANDOM FIELD; MULTIRESOLUTION; MULTISCALE; SIMULATED ANNEALING; TEXTURE SEGMENTATION; UNSUPERVISED SEGMENTATION	STATISTICAL-ANALYSIS; SPATIAL-INTERACTION; RELAXATION; ALGORITHM; MODELS	This paper presents a multiple resolution algorithm for segmenting images into regions with differing statistical behaviour. In addition, an algorithm is developed for determining the number of statistically distinct regions in an image and estimating the parameters of those regions. Both algorithms use a causal Gaussian autoregressive (AR) model to describe the mean, variance and spatial correlation of the image textures. Together the algorithms may be used to perform unsupervised texture segmentation. The multiple resolution segmentation algorithm first segments images at coarse resolution and then progresses to finer resolutions until individual pixels are classified. This method results in accurate segmentations and requires significantly less computation than some previously known methods. The field containing the classification of each pixel in the image is modeled as a Markov random field (MRF). Segmentation at each resolution is then performed by maximizing the a posteriori probability of this field subject to the resolution constraint. At each resolution, the a posteriori probability is maximized by a deterministic greedy algorithm which iteratively chooses the classification of individual pixels or pixel blocks. The unsupervised parameter estimation algorithm determines both the number of textures and their parameters by minimizing a global criteria based on the AIC information criterion. Clusters corresponding to the individual textures are formed by alternately estimating the cluster parameters and repartitioning the data into those clusters. Concurrently, the number of distinct textures is estimated by combining clusters until a minimum of the criteria is reached.	PRINCETON UNIV,DEPT ELECT ENGN,PRINCETON,NJ 08544	Princeton University	BOUMAN, C (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.							AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1986, J R STAT SOC B, V48, P259; BOUMAN C, 1988, NOV P SPIE C VIS COM, P512; BOUMAN C, 1988, APR P IEEE INT C AC, P1124; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; DERIN H, 1987, COMPUT VISION GRAPH, V40, P54, DOI 10.1016/0734-189X(87)90056-9; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; Duda R.O., 1973, J ROYAL STAT SOC SER; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HUTCHINSON J, 1988, COMPUTER, V21, P53; JAIN AK, 1981, P IEEE, V69, P502, DOI 10.1109/PROC.1981.12021; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; Knuth D., 1973, ART COMPUTER PROGRAM, V3; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; REDNER E, 1984, SIAM REV, V26; SILVEY SD, 1975, STATISTICAL INFERENC; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767; WON CS, 1989, P ICASSP 87 DALLAS; ZHANG J, 1988, P ICASSP 88 NEW YORK; ZHANG J, 1988, 1988 P C INF SCI SYS	22	241	267	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1991	13	2					99	113		10.1109/34.67641	http://dx.doi.org/10.1109/34.67641			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EY699					2022-12-18	WOS:A1991EY69900001
J	LEVINE, MD; NAZIF, AM				LEVINE, MD; NAZIF, AM			DYNAMIC MEASUREMENT OF COMPUTER GENERATED IMAGE SEGMENTATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV CAIRO,DEPT ELECT ENGN,CAIRO,EGYPT	Egyptian Knowledge Bank (EKB); Cairo University	LEVINE, MD (corresponding author), MCGILL UNIV,DEPT ELECT ENGN,COMP VISION & ROBOT LAB,MONTREAL H3A 2T5,QUEBEC,CANADA.							ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325; BRYANT DJ, 1979, AUG IEEE C PATT REC, P138; CAMPBELL FW, 1968, J PHYSIOL-LONDON, V197, P551, DOI 10.1113/jphysiol.1968.sp008574; COLEMAN GB, 1977, USCIPI750 U SO CAL I; FRAM JR, 1975, IEEE T COMPUT, VC 24, P616, DOI 10.1109/T-C.1975.224274; KITCHEN L, 1981, IEEE T SYST MAN CYB, V11, P597, DOI 10.1109/TSMC.1981.4308758; Koffka K., 1963, PRINCIPLES GESTALT P, V2nd; Levine M., 1982, MULTICOMPUTERS IMAGE, P149; LEVINE MD, 1984, PATTERN RECOGN LETT, V2, P243, DOI 10.1016/0167-8655(84)90032-1; LEVINE MD, 1981, IEEE T PATTERN ANAL, V3, P540, DOI 10.1109/TPAMI.1981.4767147; LEVINE MD, UNPUB COMPUT VISION; LEVINE MD, 1983, TR839 MCGILL U COMP; LEVINE MD, 1982, TR821 MCGILL U DEP E; LEVINE MD, 1980, STRUCTURED COMPUTER, P57; MATSUYAMA T, 1982, COMPUT VISION GRAPH, V18, P259, DOI 10.1016/0146-664X(82)90035-1; NAZIF A, 1982, 4TH P INT C CAN SOC; NAZIF A, 1981, 7TH C CAN SOC MAN CO; NAZIF AM, 1984, IEEE T PATTERN ANAL, V6, P555, DOI 10.1109/TPAMI.1984.4767570; Pratt W. K., 1978, DIGITAL IMAGE PROCES, P495; RISEMAN EM, 1977, COMPUT VISION GRAPH, V6, P221, DOI 10.1016/S0146-664X(77)80028-2; YASNOFF WA, 1977, PATTERN RECOGN, V9, P217, DOI 10.1016/0031-3203(77)90006-1	22	241	270	1	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	2					155	164		10.1109/TPAMI.1985.4767640	http://dx.doi.org/10.1109/TPAMI.1985.4767640			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ACP84	21869254				2022-12-18	WOS:A1985ACP8400003
J	Kim, KI; Jung, K; Park, SH; Kim, HJ				Kim, KI; Jung, K; Park, SH; Kim, HJ			Support vector machines for texture classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						support vector machines; texture analysis; pattern classification; machine learning; feature extraction	SEGMENTATION	This paper investigates the application of support vector machines (SVMs) in texture classification. Instead of relying on an external feature extractor, the SVM receives the gray-level values of the raw pixels, as SVMs can generalize well even in high-dimensional spaces. Furthermore, it is shown that SVMs can incorporate conventional texture feature extraction methods within their own architecture, while also providing solutions to problems inherent in these methods. One-against-others decomposition is adopted to apply binary SVMs to multitexture classification, plus a neural network is used as an arbitrator to make final classifications from several one-against-others SVM outputs. Experimental results demonstrate the effectiveness of SVMs in texture classification.	Korea Adv Inst Sci & Technol, Dept Comp Sci, Artificial Intelligence Lab, Taejon 305701, South Korea; Michigan State Univ, Dept Comp Sci & Engn, Pattern Recognit & Image Proc Lab, E Lansing, MI 48824 USA; Chosun Univ, Coll Elect & Informat, Comp Engn Div, Kwangju 501759, South Korea; Kyungpook Natl Univ, Dept Comp Engn, Taegu 702701, South Korea	Korea Advanced Institute of Science & Technology (KAIST); Michigan State University; Chosun University; Kyungpook National University	Kim, KI (corresponding author), Korea Adv Inst Sci & Technol, Dept Comp Sci, Artificial Intelligence Lab, Taejon 305701, South Korea.	kimki@ai.kaist.ac.kr; jungke@msu.edu; sehyun@chosun.ac.kr; hjkim@ailab.knu.ac.kr						Brodatz P., 1966, TEXTURES PHOTOGRAPHI; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CHEN JL, 1995, IEEE T IMAGE PROCESS, V4, P603, DOI 10.1109/83.382495; Chen YQ, 1997, INT J SYST SCI, V28, P669, DOI 10.1080/00207729708929427; Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264137; DIACONIS P, 1981, J MATH PSYCHOL, V24, P112, DOI 10.1016/0022-2496(81)90039-0; DUNN DF, 1992, P SPIE INTELLIGENCE, V11, P51; GREENSPAN H, 1994, IEEE T PATTERN ANAL, V16, P894, DOI 10.1109/34.310685; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Haykin S., 1999, NEURAL NETWORKS COMP, P1; HSU CW, 2001, COMPARISON METHODS M; Jain AK, 1996, IEEE T PATTERN ANAL, V18, P195, DOI 10.1109/34.481543; JAIN AK, 1990, 1990 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, P14, DOI 10.1016/0031-3203(91)90143-S; Kim HJ, 1998, ELECTRON LETT, V34, P2394, DOI 10.1049/el:19981674; Laws K. I., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238, P376; LAWS KI, 1980, THESIS U SO CALIF; Li S., 1995, MARKOV RANDOM FIELD, P1; Lu CS, 1997, PATTERN RECOGN, V30, P729, DOI 10.1016/S0031-3203(96)00116-1; MAYORAZ E, 1998, 9806 IDIAPPR DALL MO; MUHAMAD AK, 1994, ENG APPL ARTIF INTEL, V7, P381, DOI 10.1016/0952-1976(94)90004-3; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; Scholkopf B, 1997, IEEE T SIGNAL PROCES, V45, P2758, DOI 10.1109/78.650102; SCHOLKOPF B, 1995, P 1 INT C KNOWL DISC, P252; SCHOLKOPF B, 1997, THESIS MUNICH; Tuceryan M., 1993, HDB PATTERN RECOGNIT, P235, DOI DOI 10.1142/9789814343138_0010; Yuille AL, 2000, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2000.855869; ZHU SC, 1998, INT J COMPUTER VISIO, V27	29	240	256	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2002	24	11					1542	1550						9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	608KY		Green Accepted			2022-12-18	WOS:000178846400012
J	Subbarao, M; Tyan, JK				Subbarao, M; Tyan, JK			Selecting the optimal focus measure for autofocusing and depth-from-focus	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						focus measure; focusing; autofocusing; depth-from-focus; focus analysis		A method is described for selecting the optimal focus measure with respect to gray-level noise from a given set of focus measures in passive autofocusing and depth-from-focus applications. The method is based on two new metrics that have been defined for estimating the noise-sensitivity of different focus measures. The first metric-the Autofocusing Uncertainty Measure (AUM)-is useful in understanding the relation between gray-level noise and the resulting error in lens position for autofocusing. The second metric Autofocusing Root-Mean-Square Error(ARMS error)-is an improved metric closely related to AUM. AUM and ARMS error metrics are based on a theoretical noise sensitivity analysis of focus measures, and they are related by a monotonic expression. The theoretical results are validated by actual and simulation experiments. For a given camera, the optimally accurate focus measure may change from one object tb the other depending on their focused images. Therefore, selecting the optimal focus measure from a given set involves computing all focus measures in the set.	SUNY Stony Brook, Dept Elect Engn, Stony Brook, NY 11794 USA	State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	Subbarao, M (corresponding author), SUNY Stony Brook, Dept Elect Engn, Stony Brook, NY 11794 USA.							KROTKOV E, 1987, INT J COMPUT VISION, V1, P223, DOI 10.1007/BF00127822; Nayar S. K., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P302, DOI 10.1109/CVPR.1992.223259; SUBBARAO M, 1993, OPT ENG, V32, P2824, DOI 10.1117/12.147706; SUBBARAO M, 1995, P SOC PHOTO-OPT INS, V2598, P89, DOI 10.1117/12.220891; SUBBARAO M, 1996, P SPIE C, V2909, P162; TYAN JK, 1997, THESIS SUNY STONY BR	6	239	270	5	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1998	20	8					864	870		10.1109/34.709612	http://dx.doi.org/10.1109/34.709612			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	110GT					2022-12-18	WOS:000075372700010
J	KASHYAP, RL; KHOTANZAD, A				KASHYAP, RL; KHOTANZAD, A			A MODEL-BASED METHOD FOR ROTATION INVARIANT TEXTURE CLASSIFICATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									SO METHODIST UNIV,DEPT ELECT ENGN,DALLAS,TX 75275	Southern Methodist University	KASHYAP, RL (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.							AHUJA N, 1981, IEEE T PATTERN ANAL, V3, P1, DOI 10.1109/TPAMI.1981.4767045; BAJCSY R, 1973, 3RD P INT JOINT C AR, P572; BRODATZ P, 1956, TEXTURE PHOTOGRAPHIC; CHEN CH, 1982, 6TH P INT C PATT REC, P1074; CONNERS RW, 1980, IEEE T PATTERN ANAL, V2, P204, DOI 10.1109/TPAMI.1980.4767008; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P251, DOI 10.1109/TPAMI.1979.4766921; DAVIS LS, 1981, PATTERN RECOGN, V13, P219, DOI 10.1016/0031-3203(81)90098-4; DAVIS LS, 1980, DIGITAL IMAGE PROCES, P189; DEGUCHI K, 1982, 6TH P IEEE INT C PAT, P90; DESOUZA P, 1982, PATTERN RECOGN, V15, P471, DOI 10.1016/0031-3203(82)90025-5; FAUGERAS OD, 1980, IEEE T PATTERN ANAL, V2, P323, DOI 10.1109/TPAMI.1980.4767031; Galloway M, 1974, COMPUT GRAPHICS IMAG, V4, P172; GONZALEZ RC, 1977, DIGITAL IMAGE PROCES, P119; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HASSNER M, 1980, COMPUT GRAPHICS IMAG, V12, P371; Kashyap RL, 1982, PATTERN RECOGN LETT, V1, P43, DOI 10.1016/0167-8655(82)90050-2; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; KASHYAP RL, 1981, PROGR PATTERN RECOGN, V1, P149; KASHYAP RL, 1980, 5TH P IEEE INF C PAT, P1103; KHOTANZAD A, 1983, THESIS PURDUE U W LA; LU SY, 1979, COMPUT VISION GRAPH, V9, P234, DOI 10.1016/0146-664X(79)90039-X; MODESTINO JW, 1981, IEEE T PATTERN ANAL, V3, P557, DOI 10.1109/TPAMI.1981.4767148; TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999; TAMURA H, 1977, P IEEE COMPUT SOC C, P289; VICKERS V, 1982, IEEE T PATTERN ANAL, V4, P61; VILNROTTER FM, 1981, VSCISG100 U SO CAL D; WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777; Zucker SW., 1976, COMPUTER GRAPHICS IM, V5, P190, DOI [10.1016/0146-664X(76)90027-7, DOI 10.1016/0146-664X(76)90027-7]	30	239	250	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1986	8	4					472	481		10.1109/TPAMI.1986.4767811	http://dx.doi.org/10.1109/TPAMI.1986.4767811			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	C7400					2022-12-18	WOS:A1986C740000006
J	Peng, HW; Li, B; Ling, HB; Hu, WM; Xiong, WH; Maybank, SJ				Peng, Houwen; Li, Bing; Ling, Haibin; Hu, Weiming; Xiong, Weihua; Maybank, Stephen J.			Salient Object Detection via Structured Matrix Decomposition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Salient object detection; matrix decomposition; low rank; structured sparsity; subspace learning	VISUAL-ATTENTION; REGION DETECTION; MODEL	Low-rank recovery models have shown potential for salient object detection, where a matrix is decomposed into a low-rank matrix representing image background and a sparse matrix identifying salient objects. Two deficiencies, however, still exist. First, previous work typically assumes the elements in the sparse matrix are mutually independent, ignoring the spatial and pattern relations of image regions. Second, when the low-rank and sparse matrices are relatively coherent, e. g., when there are similarities between the salient objects and background or when the background is complicated, it is difficult for previous models to disentangle them. To address these problems, we propose a novel structured matrix decomposition model with two structural regularizations: (1) a tree-structured sparsity-inducing regularization that captures the image structure and enforces patches from the same object to have similar saliency values, and (2) a Laplacian regularization that enlarges the gaps between salient objects and the background in feature space. Furthermore, high-level priors are integrated to guide the matrix decomposition and boost the detection. We evaluate our model for salient object detection on five challenging datasets including single object, multiple objects and complex scene images, and show competitive results as compared with 24 state-of-the-art methods in terms of seven performance metrics.	[Peng, Houwen; Li, Bing; Hu, Weiming; Xiong, Weihua] Chinese Acad Sci, CAS Ctr Excellence Brain Sci & Intelligence Techn, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China; [Peng, Houwen; Ling, Haibin] Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA; [Maybank, Stephen J.] Birkbeck Coll, Dept Comp Sci & Informat Syst, London WC1E 7HX, England	Chinese Academy of Sciences; Institute of Automation, CAS; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University; University of London; Birkbeck University London	Peng, HW (corresponding author), Chinese Acad Sci, CAS Ctr Excellence Brain Sci & Intelligence Techn, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China.; Peng, HW (corresponding author), Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA.	houwen.peng@nlpr.ia.ac.cn; bli@nlpr.ia.ac.cn; hbling@temple.edu; wmhu@nlpr.ia.ac.cn; wallace.xiong@gmail.com; sjmaybank@dcs.bbk.ac.uk	Li, Bing/AAX-5919-2021		973 basic research program of China [2014CB349303]; Natural Science Foundation of China [61472421, 61370038, 61303086]; Strategic Priority Research Program of the CAS [XDB02070003]; US National Science Foundation Grants [IIS-1218156, IIS-1350521]	973 basic research program of China(National Basic Research Program of China); Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Strategic Priority Research Program of the CAS; US National Science Foundation Grants(National Science Foundation (NSF))	The authors would like to thank the reviewers and editor for their helpful comments to improve the paper. They thank Dr. Wenbin Zou, Congyan Lang, and Rongrong Ji for providing their code, results or helpful suggestions. This work is partly supported by the 973 basic research program of China (Grant No. 2014CB349303), the Natural Science Foundation of China (Grant Nos. 61472421, 61370038, and 61303086), and the Strategic Priority Research Program of the CAS (Grant No. XDB02070003). Ling is supported in part by the US National Science Foundation Grants nos. IIS-1218156 and IIS-1350521. Bing Li is the joint first author of this paper.	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Batra D, 2011, INT J COMPUT VISION, V93, P273, DOI 10.1007/s11263-010-0415-x; Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833; Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727; Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30; Bruce N. D. B., 2005, ADV NEURAL INF PROCE, P155; Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333; Chen T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618470; Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401; Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Feichtinger H.G., 1998, GABOR ANAL ALGORITHM; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Gao D, 2007, P ADV NEUR INF PROC, P497; Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272; Hamm J., 2008, P INT C MACH LEARN I, P376, DOI DOI 10.1145/1390156.1390204; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0; Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267; Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jenatton R., 2011, J MACH LEARN RES, V12, P7; Jia K, 2012, LECT NOTES COMPUT SC, V7575, P331, DOI 10.1007/978-3-642-33765-9_24; Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209; Jiang H., 2011, P BRIT MACH VIS C, P1; Jiang HP, 2013, SCI WORLD J, DOI 10.1155/2013/289537; Jiang M, 2014, LECT NOTES COMPUT SC, V8695, P17, DOI 10.1007/978-3-319-10584-0_2; Judd T., 2012, MIT CSAIL TR; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118; Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499; KOCH C, 1985, HUM NEUROBIOL, V4, P219; Lang CY, 2012, IEEE T IMAGE PROCESS, V21, P1327, DOI 10.1109/TIP.2011.2169274; Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147; Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413; Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370; Lin Z., 2011, PROC INT 25 C NEURAL, P612, DOI DOI 10.1007/S11263-013-0611-6; Liu F, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1477, DOI 10.1109/ICME.2006.262821; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu J., 2010, 23TH ANN C ADV NEURA, P1459; Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70; Lu S, 2014, PROC CVPR IEEE, P3390, DOI 10.1109/CVPR.2014.433; Mai L, 2013, PROC CVPR IEEE, P1131, DOI 10.1109/CVPR.2013.150; Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467; Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39; Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151; Margolin R, 2013, VISUAL COMPUT, V29, P381, DOI 10.1007/s00371-012-0740-x; Movahedi Vida, 2010, P IEEE C COMP VIS PA, P49, DOI DOI 10.1109/CVPRW.2010.5543739; Navalpakkam V., 2006, P IEEE COMPUTER SOC, V2, P2049, DOI DOI 10.1109/CVPR.2006.54; Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708; Peng H., 2013, P 27 AAAI C ART INT, P796; Peng H., 2014, P EUR C COMPUT VIS, P1; Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743; Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27; Rutishauser U, 2004, PROC CVPR IEEE, P37; Scharfenberger C, 2013, PROC CVPR IEEE, P979, DOI 10.1109/CVPR.2013.131; Shen X., 2012, P IEEE C COMP VIS PA, P2296; Shi KY, 2013, PROC CVPR IEEE, P2115, DOI 10.1109/CVPR.2013.275; Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444; Sun J, 2013, INT J COMPUT VISION, V104, P135, DOI 10.1007/s11263-013-0618-z; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001; Wang P, 2012, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2012.6248054; Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200; Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153; Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407; Yang JM, 2012, PROC CVPR IEEE, P2296, DOI 10.1109/CVPR.2012.6247940; Zhai Y., 2006, PROC14TH ACM INT C M, DOI [10.1145/1180639.1180824, DOI 10.1145/1180639.1180824]; Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26; Zhao Q, 2013, SIGNAL PROCESS, V93, P1401, DOI 10.1016/j.sigpro.2012.06.014; Zhao Q, 2012, J VISION, V12, DOI 10.1167/12.6.22; Zhao Q, 2011, J VISION, V11, DOI 10.1167/11.3.9; Zhou D. Y., 2003, P ADV NEURAL INFORM; Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360; Zou WB, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.78; [No title captured]	85	238	267	6	64	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2017	39	4					818	832		10.1109/TPAMI.2016.2562626	http://dx.doi.org/10.1109/TPAMI.2016.2562626			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EP9UD	28113696	Green Accepted, hybrid			2022-12-18	WOS:000397717600016
J	Vetter, T; Poggio, T				Vetter, T; Poggio, T			Linear object classes and image synthesis from a single example image	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D object recognition; rotation invariance; deformable templates; image synthesis	RECOGNITION; MODELS	The need to generate new views of a 3D object from a single real image arises in several fields, including graphics and object recognition. While the traditional approach relies on the use of 3D models, we have recently introduced [1], [2], [3] simpler techniques that are applicable under restricted conditions. The approach exploits image transformations that are specific to the relevant object class, and learnable from example Views of other ''prototypical'' objects df the same class. In this paper, we introduce such a technique by extending the notion of linear class proposed by Poggio and Vetter. For linear object classes, it is shown that linear transformations can be learned exactly from a basis set of 2D prototypical views. We demonstrate the approach on artificial objects and then show preliminary evidence that the technique can effectively ''rotate'' high-resolution face images from a single 2D view.	MIT,CTR COMPUTAT & BIOL LEARNING,CAMBRIDGE,MA 02139	Massachusetts Institute of Technology (MIT)	Vetter, T (corresponding author), MAX PLANCK INST BIOL CYBERNET,SPEMANNSTR 38,D-72076 TUBINGEN,GERMANY.							BEIER T, 1992, P SIGGRAPH 92, P35; BERGEN JR, 1987, J OPT SOC AM A, V4, P35; BERGEN JR, 1990, HIERARCHICAL MOTION; BEYMER D, 1993, AI MEMO, V1431; BEYMER D, 1995, IN PRESS AI MEMO ART; BEYMER D, 1993, AI MEMO ARTIFICIAL I, V1461; BEYMER D, 1995, P 5 INT C COMP VIS; HURLBERT AC, 1988, SCIENCE, V239, P482, DOI 10.1126/science.3340834; Jones M., 1995, P 5 INT C COMP VIS; KALOCSAI P, 1994, ANN M ASS RES VIS OP; POGGIO T, 1992, AI MEMO ARTIFICIAL I, V1347; POGGIO T, 1992, 1354 MIT MED LAB PER; SCHYNS P, 1993, AI MEMO ARTIFICIAL I, V1404; TROJE N, 1995, VISION RES, V36, P1761; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; VETTER T, 1994, CURR BIOL, V4, P18, DOI 10.1016/S0960-9822(00)00004-X; VETTER T, 1994, SPATIAL VISION, V8, P443, DOI 10.1163/156856894X00107; WOLBERG G, 1990, IMAGE WARPING	19	238	258	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1997	19	7					733	742		10.1109/34.598230	http://dx.doi.org/10.1109/34.598230			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM693		Green Submitted			2022-12-18	WOS:A1997XM69300007
J	TERZOPOULOS, D				TERZOPOULOS, D			THE COMPUTATION OF VISIBLE-SURFACE REPRESENTATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											TERZOPOULOS, D (corresponding author), SCHLUMBERGER PALO ALTO RES, RES STAFF, 3340 HILLVIEW AVE, PALO ALTO, CA 94304 USA.							ABRAMOWITZ M., 1965, HDB MATH FUNCTIONS; Barrow H., 1978, COMPUT VIS SYST, V2, P2; BARROW HG, 1981, ARTIF INTELL, V17, P75, DOI 10.1016/0004-3702(81)90021-7; BARROW HG, 1979, P DARPA IMAGE UNDERS, P76; BESL PJ, 1986, COMPUT VISION GRAPH, V33, P33, DOI 10.1016/0734-189X(86)90220-3; Blake A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P62; BLAKE A, 1984, P NAT C ARTIFICIAL I, P23; Blake A, 1983, PATTERN RECOGN LETT, V1, P393, DOI 10.1016/0167-8655(83)90077-6; BOLONDI G, 1976, GEOPHYSICS, V41, P1377, DOI 10.1190/1.1440688; Boult T. E., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P68; BRADDICK O, 1978, HDB SENSORY PHYSL, V8, P3; BRADY M, 1983, COMPUT VISION GRAPH, V22, P70, DOI 10.1016/0734-189X(83)90096-8; BRADY M, 1985, COMPUT VISION GRAPH, V32, P1, DOI 10.1016/0734-189X(85)90001-5; BRIGGS IC, 1974, GEOPHYSICS, V39, P39, DOI 10.1190/1.1440410; BURT P, 1980, SCIENCE, V208, P615, DOI 10.1126/science.7367885; CHAVENT G, 1973, IFAC S IDENTIFICATIO; Clarke F.H, 1990, CANADIAN MATH SOC SE, V2; COCHRAN S, 1985, ISG108 U SO CAL DEP; COLLETT TS, 1985, PROC R SOC SER B-BIO, V224, P43, DOI 10.1098/rspb.1985.0020; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; ERMOLIEV YM, 1982, PROGR NONDIFFERENTIA; Fan T, 1985, P DARPA IMAGE UNDERS, P232; Franke R., 1985, Computer-Aided Geometric Design, V2, P87, DOI 10.1016/0167-8396(85)90011-1; Franke R., 1983, SURFACES CAGD, P135; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; GRIMSON WEL, 1985, COMPUT VISION GRAPH, V30, P316, DOI 10.1016/0734-189X(85)90163-X; GRIMSON WEL, 1983, COMPUT VISION GRAPH, V22, P39, DOI 10.1016/0734-189X(83)90095-6; GRIMSON WEL, 1981, IMAGES SURFACES COMP; Hackbusch W., 1985, MULTIGRID METHODS AP; HAGEMAN LA, 1981, APPLIED ITERATIVE ME; HARRIS J, 1986, THESIS MIT CAMBRIDGE; HORN BKP, 1982, REPRESENTATION 3 DIM; Karplus W. J, 1958, ANALOG SIMULATION SO; KASS M, 1986, PIXELS PREDICATES, P78; KOCH C, 1986, P NATL ACAD SCI USA, V83, P4263, DOI 10.1073/pnas.83.12.4263; LANGRIDGE DJ, 1984, COMPUT VISION GRAPH, V27, P291, DOI 10.1016/0734-189X(84)90033-1; LECLERC YG, 1987, IEEE T PATTERN ANAL, V9, P341, DOI 10.1109/TPAMI.1987.4767918; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; Marr D., 1982, VISION COMPUTATIONAL; MARROQUIN JL, 1984, MIT AI792 AI LAB MEM; Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; POLIS MP, 1976, P IEEE, V64, P45, DOI 10.1109/PROC.1976.10066; Rockafellar R. T., 1981, THEORY SUBGRADIENTS; Schumaker LL, 1976, APPROXIMATION THEORY, VII, P203; SHIAU JH, 1985, THESIS U WISCONSIN M; Strang G., 1973, ANAL FINITE ELEMENT; Szilard R, 1974, THEORY ANAL PLATES; TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767; TERZOPOULOS D, 1983, 8TH P INT JOINT C AR, P1073; TERZOPOULOS D, 1984, THESIS MIT CAMBRIDGE; TERZOPOULOS D, 1985, P DARPA IMAGE UNDERS, P156; Tikhonov A.N., 1977, SOLUTION ILL POSED P; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; VEMURI BC, 1986, IMAGE VISION COMPUT, V4, P107, DOI 10.1016/0262-8856(86)90029-6; WAHBA G, 1980, APPROXIMATION THEORY, V3, P905; WASSERSTROM E, 1973, SIAM REV, V15, P89, DOI 10.1137/1015003; WOODHAM RJ, 1981, ARTIF INTELL, V17, P117, DOI 10.1016/0004-3702(81)90022-9; ZIENKIEWICZ OC, 1979, FINITE ELEMENT METHO; ZUCKER SW, 1977, IEEE T COMPUT, V26, P394, DOI 10.1109/TC.1977.1674848; ZUCKER SW, 1984, MULTIRESOLUTION IMAG, P200	65	237	248	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1988	10	4					417	438		10.1109/34.3908	http://dx.doi.org/10.1109/34.3908			22	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	P1493					2022-12-18	WOS:A1988P149300001
J	Zhang, ZP; Luo, P; Loy, CC; Tang, XO				Zhang, Zhanpeng; Luo, Ping; Loy, Chen Change; Tang, Xiaoou			Learning Deep Representation for Face Alignment with Auxiliary Attributes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face Alignment; face landmark detection; deep learning; convolutional network		In this study, we show that landmark detection or face alignment task is not a single and independent problem. Instead, its robustness can be greatly improved with auxiliary information. Specifically, we jointly optimize landmark detection together with the recognition of heterogeneous but subtly correlated facial attributes, such as gender, expression, and appearance attributes. This is non-trivial since different attribute inference tasks have different learning difficulties and convergence rates. To address this problem, we formulate a novel tasks-constrained deep model, which not only learns the inter-task correlation but also employs dynamic task coefficients to facilitate the optimization convergence when learning multiple complex tasks. Extensive evaluations show that the proposed task-constrained learning (i) outperforms existing face alignment methods, especially in dealing with faces with severe occlusion and pose variation, and (ii) reduces model complexity drastically compared to the state-of-the-art methods based on cascaded deep model.	[Zhang, Zhanpeng; Luo, Ping; Loy, Chen Change; Tang, Xiaoou] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China	Chinese University of Hong Kong	Zhang, ZP; Luo, P; Loy, CC; Tang, XO (corresponding author), Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China.	zz013@ie.cuhk.edu.hk; pluo@ie.cuhk.edu.hk; ccloy@ie.cuhk.edu.hk; xtang@ie.cuhk.edu.hk	Luo, Ping/HGE-7623-2022; zhang, zhanpeng/AAE-7897-2019; Luo, Ping/GPG-2707-2022	Luo, Ping/0000-0002-6685-7950; Loy, Chen Change/0000-0001-5345-1591				Ahmed A, 2008, LECT NOTES COMPUT SC, V5304, P69, DOI 10.1007/978-3-540-88690-7_6; Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442; Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191; Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chen D, 2014, LECT NOTES COMPUT SC, V8694, P109, DOI 10.1007/978-3-319-10599-4_8; CHEN K, 2013, PROC CVPR IEEE, P2467, DOI DOI 10.1109/CVPR.2013.319; Collobert R., 2008, P 25 ICML, V25, P160, DOI DOI 10.1145/1390156.1390177; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cootes TF, 2012, LECT NOTES COMPUT SC, V7578, P278, DOI 10.1007/978-3-642-33786-4_21; Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976; Dollar P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094; Gupta A. K., 1999, MATRIX VARIATE DISTR; Huang ZW, 2013, IEEE I CONF COMP VIS, P3296, DOI 10.1109/ICCV.2013.409; Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90; Kazemi V., 2014, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2014.241; Koestinger M., 2011, ICCV WORKSH, DOI [10.1109/ICCVW.2011.6130513, DOI 10.1109/ICCVW.2011.6130513]; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar N, 2008, LECT NOTES COMPUT SC, V5305, P340, DOI 10.1007/978-3-540-88693-8_25; Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li SJ, 2015, INT J COMPUT VISION, V113, P19, DOI 10.1007/s11263-014-0767-8; Liu XM, 2007, PROC CVPR IEEE, P2264; LIU YT, 2013, IEEE DATA MINING, P399, DOI DOI 10.1109/ICDMW.2013.158; Lu C., 2015, AAAI C ART INT AUST; Luo P, 2013, IEEE I CONF COMP VIS, P2864, DOI 10.1109/ICCV.2013.356; Messer K., 1999, AUDIO VIDEO BASED BI, P72; Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37; Moody J., 1995, ADV NEURAL INFORM PR, V4, P950; NELDER JA, 1972, J R STAT SOC SER A-G, V135, P370, DOI 10.2307/2344614; Pedersoli M, 2014, PROC CVPR IEEE, P3694, DOI 10.1109/CVPR.2014.472; Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59; Shi W. L. Baoguang, 2014, ARXIV14095230; Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239; Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996; Weston Jason, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P639, DOI 10.1007/978-3-642-35289-8_34; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yang H, 2013, IEEE I CONF COMP VIS, P1936, DOI 10.1109/ICCV.2013.243; Yu X, 2013, IEEE I CONF COMP VIS, P1944, DOI 10.1109/ICCV.2013.244; Yuille AL, 2002, ADV NEUR IN, V14, P1033; Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1; Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7; Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	51	236	245	1	86	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2016	38	5					918	930		10.1109/TPAMI.2015.2469286	http://dx.doi.org/10.1109/TPAMI.2015.2469286			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DJ4GZ	27046839	Green Submitted			2022-12-18	WOS:000374164700007
J	Ge, WN; Collins, RT; Ruback, RB				Ge, Weina; Collins, Robert T.; Ruback, R. Barry			Vision-Based Analysis of Small Groups in Pedestrian Crowds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pedestrian detection and tracking; pedestrian groups; crowd dynamics	TRACKING; MOTION; SYSTEM	Building upon state-of-the-art algorithms for pedestrian detection and multi-object tracking, and inspired by sociological models of human collective behavior, we automatically detect small groups of individuals who are traveling together. These groups are discovered by bottom-up hierarchical clustering using a generalized, symmetric Hausdorff distance defined with respect to pairwise proximity and velocity. We validate our results quantitatively and qualitatively on videos of real-world pedestrian scenes. Where human-coded ground truth is available, we find substantial statistical agreement between our results and the human-perceived small group structure of the crowd. Results from our automated crowd analysis also reveal interesting patterns governing the shape of pedestrian groups. These discoveries complement current research in crowd dynamics, and may provide insights to improve evacuation planning and real-time situation awareness during public disturbances.	[Ge, Weina] GE Global Res, Comp Vis Lab, Niskayuna, NY 12309 USA; [Collins, Robert T.] Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA; [Ruback, R. Barry] Penn State Univ, Dept Sociol, University Pk, PA 16802 USA	General Electric; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park	Ge, WN (corresponding author), GE Global Res, Comp Vis Lab, Niskayuna, NY 12309 USA.	gewe@ge.com; rcollins@cse.psu.edu; rbr3@psu.edu			US National Science Foundation (NSF) [0729363]	US National Science Foundation (NSF)(National Science Foundation (NSF))	This research was supported by the US National Science Foundation's (NSF) Human and Social Dynamics Program, Grant No. 0729363.	Albiol A., 2009, PROC IEEE INT WORKSH, P31; Ali S, 2008, LECT NOTES COMPUT SC, V5303, P1, DOI 10.1007/978-3-540-88688-4_1; Anderson M., 2003, P EUR SIGGR S COMP A; Andrade EL, 2006, INT C PATT RECOG, P175; [Anonymous], 1991, MYTH MADDING CROWD; Antonini G, 2006, INT J COMPUT VISION, V69, P159, DOI 10.1007/s11263-005-4797-0; Arandjelovic O., 2008, P BRIT MACH VIS ASS, P1; AVENI AF, 1977, SOCIOMETRY, V40, P96, DOI 10.2307/3033551; Blue VJ, 2001, TRANSPORT RES B-METH, V35, P293, DOI 10.1016/S0191-2615(99)00052-1; Brostow G.J., 2006, P IEEE INT C COMP VI, P594, DOI DOI 10.1109/CVPR.2006.320; Brown R.W., 1954, HDB SOCIAL PSYCHOL, V2, P833; CAMPBELL DT, 1958, BEHAV SCI, V3, P14, DOI 10.1002/bs.3830030103; Cartwright D, 1968, GROUP DYNAMICS RES T, V3rd, P3; Chan A. B., 2009, P IEEE INT WORKSH PE; Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569; Cheriyadat AM, 2008, IEEE J-STSP, V2, P568, DOI 10.1109/JSTSP.2008.2001306; Cupillard F., 2001, P EUR WORKSH ADV VID; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Doucet A., 2009, HDB NONLINEAR FILTER; French AP, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P212, DOI 10.1109/AVSS.2007.4425312; Gatica-Perez D, 2009, IMAGE VISION COMPUT, V27, P1775, DOI 10.1016/j.imavis.2009.01.004; Ge W., 2009, P IEEE C COMP VIS PA; Gong SG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P742, DOI 10.1109/ICCV.2003.1238423; HALL ET, 1963, AM ANTHROPOL, V65, P1003, DOI 10.1525/aa.1963.65.5.02a00020; Haritaoglu I, 2001, PROC CVPR IEEE, P431; HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282; Hoogs A., 2008, P 23 AAAI C ART INT, P1551; Hoogs A., 2008, P IEEE WORKSH MOT VI, P1; Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274; JOHNSON NR, 1987, SOC PROBL, V34, P362, DOI 10.1525/sp.1987.34.4.03a00040; Keith Still G., 2000, THESIS U WARWICK; Kilambi P, 2008, COMPUT VIS IMAGE UND, V110, P43, DOI 10.1016/j.cviu.2007.02.003; Kong D, 2006, INT C PATT RECOG, P1187; Kratz L., 2010, P IEEE C COMP VIS PA; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Lau B, 2010, INT J SOC ROBOT, V2, P19, DOI 10.1007/s12369-009-0036-0; Lee KH, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P109; Li Y., 2009, P IEEE C COMP VIS PA; Marana AN, 1998, SIBGRAPI '98 - INTERNATIONAL SYMPOSIUM ON COMPUTER GRAPHICS, IMAGE PROCESSING, AND VISION, PROCEEDINGS, P354, DOI 10.1109/SIBGRA.1998.722773; Mardia KV, 1998, STAT SHAPE ANAL; May A.D., 1990, TRAFFIC FLOW FUNDAME; MCPHAIL C, 1982, SOCIOL METHOD RES, V10, P347, DOI 10.1177/0049124182010003007; McPhail C., 2003, WITHS LIFE COU UNPUB; Mehran Ramin, 2009, P IEEE C COMP VIS PA; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; Moussaid M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010047; Musse SR, 1997, P WORKSH COMP AN SIM, P39, DOI DOI 10.1007/978-3-7091-6874-5_3; Naturel X, 2008, INT C PATT RECOG, P3019; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Pellegrini S., 2009, P IEEE INT C COMP VI; Qiu FS, 2010, SIMUL MODEL PRACT TH, V18, P190, DOI 10.1016/j.simpat.2009.10.005; Rabaud V., 2006, PROC IEEE COMPUT SOC, V1, P705, DOI DOI 10.1109/CVPR.2006.92; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Robin T, 2009, TRANSPORT RES B-METH, V43, P36, DOI 10.1016/j.trb.2008.06.010; Rodriguez M., 2009, P IEEE INT C COMP VI; Ryoo MS, 2008, 2008 IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING, P95; Schadschneider A, 2002, PEDESTRIAN AND EVACUATION DYNAMICS, P75; Scovanner P., 2009, P IEEE INT C COMP VI; Jacques JCS, 2007, PATTERN ANAL APPL, V10, P321, DOI 10.1007/s10044-007-0070-1; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Sugimura D, 2009, IEEE I CONF COMP VIS, P1467, DOI 10.1109/ICCV.2009.5459286; Tieu K., 2006, P EUR C COMP VIS, P111; Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734; White W., 1998, CITY REDISCOVERING C; Yersin B., 2009, P S INT 3D GRAPH GAM; Yu G.M.Q., 2007, P IEEE C COMP VIS PA; Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4; Zhang WD, 2008, SIGNAL PROCESS-IMAGE, V23, P739, DOI 10.1016/j.image.2008.09.001; Zhao T, 2003, PROC CVPR IEEE, P459, DOI 10.1109/NSSMIC.2003.1352083	71	236	252	2	99	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2012	34	5					1003	1016		10.1109/TPAMI.2011.176	http://dx.doi.org/10.1109/TPAMI.2011.176			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	911VJ	21844622				2022-12-18	WOS:000301747400013
J	Sun, YJ; Todorovic, S; Goodison, S				Sun, Yijun; Todorovic, Sinisa; Goodison, Steve			Local-Learning-Based Feature Selection for High-Dimensional Data Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature selection; local learning; logistical regression; l(1) regularization; sample complexity	GENE; CLASSIFICATION; REDUCTION	This paper considers feature selection for data classification in the presence of a huge number of irrelevant features. We propose a new feature-selection algorithm that addresses several major issues with prior work, including problems with algorithm implementation, computational complexity, and solution accuracy. The key idea is to decompose an arbitrarily complex nonlinear problem into a set of locally linear ones through local learning, and then learn feature relevance globally within the large margin framework. The proposed algorithm is based on well-established machine learning and numerical analysis techniques, without making any assumptions about the underlying data distribution. It is capable of processing many thousands of features within minutes on a personal computer while maintaining a very high accuracy that is nearly insensitive to a growing number of irrelevant features. Theoretical analyses of the algorithm's sample complexity suggest that the algorithm has a logarithmical sample complexity with respect to the number of features. Experiments on 11 synthetic and real-world data sets demonstrate the viability of our formulation of the feature-selection problem for supervised learning and the effectiveness of our algorithm.	[Sun, Yijun] Univ Florida, Interdisciplinary Ctr Biotechnol Res, Gainesville, FL 32610 USA; [Todorovic, Sinisa] Oregon State Univ, Sch Elect Engn & Comp Sci, Kelley Engn Ctr 2107, Corvallis, OR 97331 USA; [Goodison, Steve] Univ Texas MD Anderson Canc Ctr, Canc Res Inst, Orlando, FL 32827 USA	State University System of Florida; University of Florida; Oregon State University; University of Texas System; UTMD Anderson Cancer Center	Sun, YJ (corresponding author), Univ Florida, Interdisciplinary Ctr Biotechnol Res, POB 103622, Gainesville, FL 32610 USA.	sunyijun@biotech.ufl.edu; sinisa@eecs.oregonstate.edu; Steven.Goodison@orlandohealth.com	Sun, Yijun/F-9698-2017		Susan Komen Breast Cancer Foundation [BCTR0707587]; NATIONAL CANCER INSTITUTE [R01CA116161, R01CA108597] Funding Source: NIH RePORTER	Susan Komen Breast Cancer Foundation(Susan G. Komen Breast Cancer Foundation); NATIONAL CANCER INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI))	The authors thank the associate editor Dr. Olivier Chapelle and three anonymous reviewers for numerous suggestions that significantly improved the quality of the paper. This work is in part supported by the Susan Komen Breast Cancer Foundation under grant No. BCTR0707587.	Anthony M., 1999, NEURAL NETWORK LEARN, V9; Asuncion A, 2007, UCI MACHINE LEARNING; Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bartlett PL, 1998, IEEE T INFORM THEORY, V44, P525, DOI 10.1109/18.661502; Bishop C.M, 2006, PATTERN RECOGN; BREIMAN L, 1995, TECHNOMETRICS, V37, P373, DOI 10.2307/1269730; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Cucker F, 2002, B AM MATH SOC, V39, P1; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dietterich TG, 1997, AI MAG, V18, P97; Dietterich TG, 1994, J ARTIF INTELL RES, V2, P263; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Elisseeff A., 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616; Gilad-Bachrach R., 2004, P 21 INT C MACH LEAR, P43; Goldberger Jacob, 2005, ADV NEURAL INFORM PR, V17, P8, DOI DOI 10.1109/TCSVT.2013.2242640; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hilario M, 2008, BRIEF BIOINFORM, V9, P102, DOI 10.1093/bib/bbn005; Horn R. A., 1986, MATRIX ANAL; Kenji K, 1992, P 9 INT WORKSH MACH, P249, DOI DOI 10.1016/B978-1-55860-247-2.50037-1; Koller D, 1996, P 13 INT C MACH LEAR, V96, P284; Kononenko I., 1994, MACHINE LEARNING ECM, P171, DOI [10.1007/3-540-57868-4_57, DOI 10.1007/3-540-57868-4_57]; Kress R., 1998, NUMERICAL ANAL; Kushner HJ., 2003, STOCHASTIC APPROXIMA; Lafferty J, 2006, STAT SINICA, V16, P307; Lal TN, 2006, STUD FUZZ SOFT COMP, V207, P137; Lu Y, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON CONSTRUCTION & REAL ESTATE MANAGEMENT, VOLS 1 AND 2, P189; Meier L, 2008, J R STAT SOC B, V70, P53, DOI 10.1111/j.1467-9868.2007.00627.x; Ng A. Y., 2004, P 21 INT C MACH LEAR, P78, DOI DOI 10.1145/1015330.1015435; NG A. Y., 2001, P 18 INT C MACH LEAR, P377; Park MY, 2007, J ROY STAT SOC B, V69, P659, DOI 10.1111/j.1467-9868.2007.00607.x; Pollard David, 1984, CONVERGENCE STOCHAST; Pudil P, 1998, IEEE INTELL SYST APP, V13, P66, DOI 10.1109/5254.671094; ROSSET S, 2005, ADV NEURAL INFORM PR, V17, P1153; Roth V, 2004, IEEE T NEURAL NETWOR, V15, P16, DOI 10.1109/TNN.2003.809398; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Schapire RE, 1998, ANN STAT, V26, P1651; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Stephenson AJ, 2005, CANCER-AM CANCER SOC, V104, P290, DOI 10.1002/cncr.21157; Sun Y., 2005, P 22 INT C MACH LEAR, P872; Sun Y, 2006, P 23 INT C MACH LEAR, P913, DOI DOI 10.1145/1143844.1143959; Sun YJ, 2007, BIOINFORMATICS, V23, P30, DOI 10.1093/bioinformatics/btl543; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vapnik V., 1974, THEORY PATTERN RECOG; Vapnik V.N, 1998, STAT LEARNING THEORY; Wang YX, 2005, LANCET, V365, P671, DOI 10.1016/S0140-6736(05)17947-1; Weinberger Kilian Q, 2006, ADV NEURAL INFORM PR, P1473, DOI DOI 10.1007/978-3-319-13168-9_; Weston J, 2001, ADV NEUR IN, V13, P668; Zezula P., 2006, SIMILARITY SEARCH ME, V32, DOI 10.1007/0-387-29151-2; Zhang T, 2002, J MACH LEARN RES, V2, P527, DOI 10.1162/153244302760200713; Zhu J., 2004, P 16 ADV NEUR INF PR; [No title captured]	53	236	240	1	58	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2010	32	9					1610	1626		10.1109/TPAMI.2009.190	http://dx.doi.org/10.1109/TPAMI.2009.190			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	626MB	20634556	Green Submitted, Green Accepted			2022-12-18	WOS:000279969000006
J	Zaslavskiy, M; Bach, F; Vert, JP				Zaslavskiy, Mikhail; Bach, Francis; Vert, Jean-Philippe			A Path Following Algorithm for the Graph Matching Problem	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graph algorithms; graph matching; convex programming; gradient methods; machine learning; classification; image processing	ASSIGNMENT PROBLEM; DECOMPOSITION; ISOMORPHISM; RECOGNITION	We propose a convex-concave programming approach for the labeled weighted graph matching problem. The convex-concave programming formulation is obtained by rewriting the weighted graph matching problem as a least-square problem on the set of permutation matrices and relaxing it to two different optimization problems: a quadratic convex and a quadratic concave optimization problem on the set of doubly stochastic matrices. The concave relaxation has the same global minimum as the initial graph matching problem, but the search for its global minimum is also a hard combinatorial problem. We, therefore, construct an approximation of the concave problem solution by following a solution path of a convex-concave problem obtained by linear interpolation of the convex and concave formulations, starting from the convex relaxation. This method allows to easily integrate the information on graph label similarities into the optimization problem, and therefore, perform labeled weighted graph matching. The algorithm is compared with some of the best performing graph matching methods on four data sets: simulated graphs, QAPLib, retina vessel images, and handwritten Chinese characters. In all cases, the results are competitive with the state of the art.	[Zaslavskiy, Mikhail; Vert, Jean-Philippe] Mines ParisTech, Ctr Computat Biol, F-77305 Fontainebleau, France; [Zaslavskiy, Mikhail] Mines ParisTech, Ctr Math Morphol, F-77305 Fontainebleau, France; [Zaslavskiy, Mikhail; Vert, Jean-Philippe] INSERM, Inst Curie, U900, F-75248 Paris, France; [Bach, Francis] INRIA, Willow Project Team, Lab Informat, ENS,CNRS,UMR 8548, F-75214 Paris, France	UDICE-French Research Universities; PSL Research University Paris; MINES ParisTech; UDICE-French Research Universities; PSL Research University Paris; MINES ParisTech; UDICE-French Research Universities; PSL Research University Paris; UNICANCER; Institut Curie; Institut National de la Sante et de la Recherche Medicale (Inserm); Centre National de la Recherche Scientifique (CNRS); Inria; UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS); Universite Paris Cite	Zaslavskiy, M (corresponding author), Mines ParisTech, Ctr Computat Biol, 35 Rue St Honore, F-77305 Fontainebleau, France.	mikhail.zaslavskiy@ensmp.fr; francis.bach@inria.fr; Jean-Philippe.Vert@mines.org		Vert, Jean-Philippe/0000-0001-9510-8441				Allgower E. L., 1990, NUMERICAL CONTINUATI; ALMOHAMAD HA, 1993, IEEE T PATTERN ANAL, V15, P522, DOI 10.1109/34.211474; Anstreicher KM, 2001, MATH PROGRAM, V89, P341, DOI 10.1007/PL00011402; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bertsekas D. P., 1999, NONLINEAR PROGRAM, V2nd; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Borwein J., 2006, CONVEX ANAL NONLINEA, DOI [10.1007/978-0-387-31256-9, DOI 10.1007/978-0-387-31256-9]; Boyd S., 2003, CONVEX OPTIMIZATION; BREIN K, 2005, NUCL ACIDS RES, V33; Caelli T, 2004, IEEE T PATTERN ANAL, V26, P515, DOI 10.1109/TPAMI.2004.1265866; Carcassoni M, 2003, PATTERN RECOGN, V36, P193, DOI 10.1016/S0031-3203(02)00054-7; CELA E, 2007, QUADRATIC ASSIGNMENT; Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228; CORDELLA LP, 1991, P 10 INT C IM AN PRO, V2, P1038; CREMERS D, 2001, P 23 DAGM S PATT REC, V2191; Filatov A., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P845, DOI 10.1109/ICDAR.1995.602033; Frank M., 1956, NAVAL RES LOGISTICS, V3, P95, DOI [DOI 10.1002/NAV.3800030109, 10.1002/nav.3800030109]; Garey M., 1979, GUIDE NP COMPLETENES; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; LEE RB, 1999, P 10 C ATM RAD MAD W, P284; Luo B, 2000, LECT NOTES COMPUT SC, V1876, P226; MCGINNIS LF, 1983, OPER RES, V31, P277, DOI 10.1287/opre.31.2.277; Milnor J, 1969, TOPOLOGY DIFFERENTIA; Rockafeller R.T., 1970, CONVEX ANAL; SAITO T, 1985, IEICE T D, V68, P757; Schellewald C, 2005, LECT NOTES COMPUT SC, V3757, P171, DOI 10.1007/11585978_12; SCHMIDT DC, 1976, J ACM, V23, P433, DOI 10.1145/321958.321963; SHAPIRO LS, 1992, IMAGE VISION COMPUT, V10, P283, DOI 10.1016/0262-8856(92)90043-3; SINGH R, 2007, P 11 INT C RES COMP; Taylor WR, 2002, MOL CELL PROTEOMICS, V1, P334, DOI 10.1074/mcp.T200001-MCP200; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; WALTER T, 2003, EUROPEAN J OPHTHALMO, V13; Wang HF, 2006, PATTERN RECOGN, V39, P1012, DOI 10.1016/j.patcog.2005.05.013; Wang YH, 2004, P ANN INT IEEE EMBS, V26, P2972; Watts D.J., 2001, PHYS REV, P64	40	236	248	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2009	31	12					2227	2242		10.1109/TPAMI.2008.245	http://dx.doi.org/10.1109/TPAMI.2008.245			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	511BY	19834143	Green Submitted			2022-12-18	WOS:000271140100010
J	Zhao, T; Nevatia, R; Wu, B				Zhao, Tao; Nevatia, Ram; Wu, Bo			Segmentation and tracking of multiple humans in crowded environments	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multiple human segmentation; multiple human tracking; Markov chain Monte Carlo		Segmentation and tracking of multiple humans in crowded situations is made difficult by interobject occlusion. We propose a model-based approach to interpret the image observations by multiple partially occluded human hypotheses in a Bayesian framework. We define a joint image likelihood for multiple humans based on the appearance of the humans, the visibility of the body obtained by occlusion reasoning, and foreground/background separation. The optimal solution is obtained by using an efficient sampling method, data-driven Markov chain Monte Carlo (DDMCMC), which uses image observations for proposal probabilities. Knowledge of various aspects, including human shape, camera model, and image cues, are integrated in one theoretically sound framework. We present experimental results and quantitative evaluation, demonstrating that the resulting approach is effective for very challenging data.	[Zhao, Tao] Intuit Surg Inc, Sunnyvale, CA 94086 USA; [Nevatia, Ram; Wu, Bo] Univ So Calif, Inst Robot & Intelligent Syst, USC Viterbi Sch Engn, Los Angeles, CA 90089 USA	University of Southern California	Zhao, T (corresponding author), Intuit Surg Inc, 950 Kifer Rd, Sunnyvale, CA 94086 USA.	taozhao@alumni.usc.edu; nevatia@usc.edu; bowu@usc.edu						BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; *CAVIAR, 2008, CAVIAR DAT SET; CHHEN I, 1999, P IEEE C COMP VIS PA, V2, P2319; Collins RT, 2003, PROC CVPR IEEE, P234; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Davis L, 2000, INT C PATT RECOG, P171, DOI 10.1109/ICPR.2000.902889; Deutscher J, 2000, PROC CVPR IEEE, P126, DOI 10.1109/CVPR.2000.854758; Elgammal AM, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P145, DOI 10.1109/ICCV.2001.937617; FLEURET F, 2005, P 10 INT C COMP VIS, V1, P694; Fujiyoshi H, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P15, DOI 10.1109/ACV.1998.732852; Gavrila D. M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P87, DOI 10.1109/ICCV.1999.791202; GEMAN S, 1986, SIAM J CONTROL OPTIM, V24, P1031, DOI 10.1137/0324060; GREEN PJ, 2003, T DIMENSIONAL MARKOV; Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; Hongeng S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P84, DOI 10.1109/ICCV.2001.937608; Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594; Kang BM, 2003, PROC CVPR IEEE, P267; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Lee MW, 2006, IEEE T PATTERN ANAL, V28, P905, DOI 10.1109/TPAMI.2006.110; Liu J.S, 2001, M CARLO STRATEGIES S; Lv FJ, 2006, IEEE T PATTERN ANAL, V28, P1513, DOI 10.1109/TPAMI.2006.178; MacCormick J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P572, DOI 10.1109/ICCV.1999.791275; MITTAL A, 2002, P 7 EUR C COMP VIS, V2, P18; Nillius P., 2006, P 2006 IEEE COMP SOC, V2, P2187; OKUMA K, 2004, P EUR C COMP VIS, P28; Papageorgiou C., 1998, P INT VEH, P241; PEREZ DG, 2005, P INT WORKSH IM AN M; Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520; PREZ P, 2002, P 7 EUR C COMP VIS, V1, P661; Ramanan D, 2005, PROC CVPR IEEE, P271; Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458; RITTSCHER J, 2005, P IEEE C COMP VIS PA, V2, P487; ROSALES R, 1999, P IEEE C COMP VIS PA, V2, P2117; Rue H, 1999, BIOMETRIKA, V86, P649, DOI 10.1093/biomet/86.3.649; Siebel NT, 2002, LECT NOTES COMPUT SC, V2353, P373; Smith K, 2005, PROC CVPR IEEE, P962; Song X, 2004, INT C PATT RECOG, P159, DOI 10.1109/ICPR.2004.1333728; Song XF, 2005, IEEE I CONF COMP VIS, P1124; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Tao H, 2002, IEEE T PATTERN ANAL, V24, P75, DOI 10.1109/34.982885; Tao H., 1999, P WORKSH VIS ALG; Tierney L., 1996, MARKOV CHAIN MONTE C, P59; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Weiss Y, 2000, NEURAL COMPUT, V12, P1, DOI 10.1162/089976600300015880; WU B, 2005, P IEEE INT C COMP VI, V1, P90; Yu T, 2004, PROC CVPR IEEE, P834; Zhao T, 2005, PROC CVPR IEEE, P976; Zhao T, 2004, PROC CVPR IEEE, P406; Zhao T, 2004, IEEE T PATTERN ANAL, V26, P1208, DOI 10.1109/TPAMI.2004.73; Zhao T, 2003, PROC CVPR IEEE, P459, DOI 10.1109/NSSMIC.2003.1352083; 2008, CLEAR06 EV CAMP WORK	57	236	256	1	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2008	30	7					1198	1211		10.1109/TPAMI.2007.70770	http://dx.doi.org/10.1109/TPAMI.2007.70770			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	307CA	18550903				2022-12-18	WOS:000256294100007
J	Kokiopoulou, E; Saad, Y				Kokiopoulou, Effrosyni; Saad, Yousef			Orthogonal neighborhood preserving projections: A projection-based dimensionality reduction technique	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						linear dimensionality reduction; face recognition; data visualization		This paper considers the problem of dimensionality reduction by orthogonal projection techniques. The main feature of the proposed techniques is that they attempt to preserve both the intrinsic neighborhood geometry of the data samples and the global geometry. In particular, we propose a method, named Orthogonal Neighborhood Preserving Projections, which works by first building an "affinity" graph for the data in a way that is similar to the method of Locally Linear Embedding ( LLE). However, in contrast with the standard LLE where the mapping between the input and the reduced spaces is implicit, ONPP employs an explicit linear mapping between the two. As a result, handling new data samples becomes straightforward, as this amounts to a simple linear transformation. We show how we can define kernel variants of ONPP, as well as how we can apply the method in a supervised setting. Numerical experiments are reported to illustrate the performance of ONPP and to compare it with a few competing methods.	Ecole Polytech Fed Lausanne, Swiss Fed Inst Technol, Signal Proc Inst, CH-1015 Lausanne, Switzerland; Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; University of Minnesota System; University of Minnesota Twin Cities	Kokiopoulou, E (corresponding author), Ecole Polytech Fed Lausanne, Swiss Fed Inst Technol, Signal Proc Inst, LTS4 Lab,Bat ELD 241,Stn 11, CH-1015 Lausanne, Switzerland.	effrosyni.kokiopoulou@epfl.ch; saad@cs.umn.edu		Saad, Yousef or Youcef/0000-0002-8614-5360				Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bengio Y, 2004, ADV NEURAL INFORM PR, V16; CAI D, 2005, P 28 ANN INT ACM C R; Cramer J.S., 2003, ORIGINS LOGISTIC REG; Graham D., 1998, FACE RECOGNITION, V163, P446, DOI DOI 10.1007/978-3-642-72201-1_25; He X., 2003, P ADV NEUR INF PROC; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Kokiopoulou E., 2005, P 5 IEEE INT C DAT M; MARTINEZ A, 1998, CVC24; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saad Y, 1992, NUMERICAL METHODS LA; Samaria F., 1994, P 2 IEEE WORKSH APPL; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Vapnik V.N, 1998, STAT LEARNING THEORY	16	236	254	3	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2007	29	12					2143	2156		10.1109/TPAMI.2007.1131	http://dx.doi.org/10.1109/TPAMI.2007.1131			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	219LY	17934224	Green Submitted			2022-12-18	WOS:000250087900007
J	Jain, AK; Chen, Y; Demirkus, M				Jain, Anil K.; Chen, Yi; Demirkus, Meltem			Pores and ridges: High-resolution fingerprint matching using Level 3 features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fingerprint recognition; high-resolution fingerprints; minutia; Level 3 features; extended feature set; pores; ridge contours; hierarchical matching	SYSTEM	Fingerprint friction ridge details are generally described in a hierarchical order at three different levels, namely, Level 1 (pattern), Level 2 (minutia points), and Level 3 (pores and ridge contours). Although latent print examiners frequently take advantage of Level 3 features to assist in identification, Automated Fingerprint Identification Systems (AFIS) currently rely only on Level 1 and Level 2 features. In fact, the Federal Bureau of Investigation's (FBI) standard of fingerprint resolution for AFIS is 500 pixels per inch (ppi), which is inadequate for capturing Level 3 features, such as pores. With the advances in fingerprint sensing technology, many sensors are now equipped with dual resolution (500 ppi/1,000 ppi) scanning capability. However, increasing the scan resolution alone does not necessarily provide any performance improvement in fingerprint matching, unless an extended feature set is utilized. As a result, a systematic study to determine how much performance gain one can achieve by introducing Level 3 features in AFIS is highly desired. We propose a hierarchical matching system that utilizes features at all the three levels extracted from 1,000 ppi fingerprint scans. Level 3 features, including pores and ridge contours, are automatically extracted using Gabor filters and wavelet transform and are locally matched using the Iterative Closest Point (ICP) algorithm. Our experiments show that Level 3 features carry significant discriminatory information. There is a relative reduction of 20 percent in the equal error rate (EER) of the matching system when Level 3 features are employed in combination with Level 1 and 2 features. This significant performance gain is consistently observed across various quality fingerprint images.	Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Michigan State University	Jain, AK (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, 3115 Engn Bldg, E Lansing, MI 48824 USA.	jain@cse.msu.edu; chenyi1@cse.msu.edu; demirkus@cse.msu.edu						[Anonymous], 2004, P 2 COST ACT WORKSH; Ashbaugh D.R, 1999, CRC SER PR CRIM; Ashbaugh D.R., 1992, J FORENSIC IDENTIFIC, V42, P106; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Burrus C.S., 1997, INTRO WAVELETS WAVEL; Chen Y, 2005, LECT NOTES COMPUT SC, V3546, P160; Cummins H, 1961, FINGER PRINTS PALMS; GALTON F, 1965, FINGERPRINTS; Galton Francis, 1888, NATURE, V38, P201; HIRSCH W, 1973, J MENT DEFIC RES, V17, P58; Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565; Jain AK, 1999, PATTERN RECOGN LETT, V20, P1371, DOI 10.1016/S0167-8655(99)00108-7; JAIN AK, 2006, P INT C PATTERN RECO, V43, P477; Locard E., 1912, BIOL REV SCI MED, V2, P357; MCCABE R, 2005, SUMMARY APRIL 2005 A; Meagher S., 2005, P ANSI NIST ITL 1 20; Nixon KA, 2005, P SOC PHOTO-OPT INS, V5779, P214, DOI 10.1117/12.606643; Pankanti S, 2002, IEEE T PATTERN ANAL, V24, P1010, DOI 10.1109/TPAMI.2002.1023799; Parziale G, 2006, LECT NOTES COMPUT SC, V3832, P244; Roddy AR, 1997, P IEEE, V85, P1390, DOI 10.1109/5.628710; Ross A, 2006, IEEE T PATTERN ANAL, V28, P19, DOI 10.1109/TPAMI.2006.11; ROWE RK, 2005, P SPIE C BIOM TECHN, P90; Sangiorgi S, 2004, J ANAT, V204, P123, DOI 10.1111/j.1469-7580.2004.00251.x; STOSZ JD, 1994, P SOC PHOTO-OPT INS, V2277, P210, DOI 10.1117/12.191885; THORTON J, 2000, P 84 ANN TRAIN C CAL; Wentworth B, 1932, PERSONAL IDENTIFICAT; Xia XW, 2003, PATTERN RECOGN, V36, P361, DOI 10.1016/S0031-3203(02)00036-5	27	236	251	6	58	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2007	29	1					15	27		10.1109/TPAMI.2007.250596	http://dx.doi.org/10.1109/TPAMI.2007.250596			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	104VI	17108380				2022-12-18	WOS:000241988300002
J	Klare, BF; Jain, AK				Klare, Brendan F.; Jain, Anil K.			Heterogeneous Face Recognition Using Kernel Prototype Similarities	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Heterogeneous face recognition; prototypes; nonlinear similarity; discriminant analysis; local descriptors; random subspaces; thermal image; infrared image; forensic sketch	DISCRIMINANT-ANALYSIS; SKETCH SYNTHESIS; CLASSIFICATION; FEATURES	Heterogeneous face recognition (HFR) involves matching two face images from alternate imaging modalities, such as an infrared image to a photograph or a sketch to a photograph. Accurate HFR systems are of great value in various applications (e. g., forensics and surveillance), where the gallery databases are populated with photographs (e. g., mug shot or passport photographs) but the probe images are often limited to some alternate modality. A generic HFR framework is proposed in which both probe and gallery images are represented in terms of nonlinear similarities to a collection of prototype face images. The prototype subjects (i.e., the training set) have an image in each modality (probe and gallery), and the similarity of an image is measured against the prototype images from the corresponding modality. The accuracy of this nonlinear prototype representation is improved by projecting the features into a linear discriminant subspace. Random sampling is introduced into the HFR framework to better handle challenges arising from the small sample size problem. The merits of the proposed approach, called prototype random subspace (P-RS), are demonstrated on four different heterogeneous scenarios: 1) near infrared (NIR) to photograph, 2) thermal to photograph, 3) viewed sketch to photograph, and 4) forensic sketch to photograph.	[Klare, Brendan F.] Noblis, Falls Church, VA 22042 USA; [Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA; [Jain, Anil K.] Korea Univ, Dept Brain & Cognit Engn, Seoul, South Korea	Michigan State University; Korea University	Klare, BF (corresponding author), Noblis, 3150 Fairview Pk Dr, Falls Church, VA 22042 USA.	brendan.klare@noblis.org; jain@cse.msu.edu			World Class University (WCU) program; Ministry of Education, Science and Technology through the National Research Foundation of Korea [R31-10008]	World Class University (WCU) program; Ministry of Education, Science and Technology through the National Research Foundation of Korea	The authors would like to thank Scott McCallum and the rest of the his team at the Pinellas County Sheriff's Office, and Captain Greg Michaud from the Michigan State Police for their gracious support of this research. They would also like to thank Rong Jin and Serhat Bucak for their feedback on this research. This manuscript benefited from the value observations provided in the review process. Anil Jain's research was partially supported by the World Class University (WCU) program funded by the Ministry of Education, Science and Technology through the National Research Foundation of Korea (R31-10008).	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; [Anonymous], 2012, FACEVACS SOFTW DEV K; Balcan MF, 2006, MACH LEARN, V65, P79, DOI 10.1007/s10994-006-7550-1; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bhatt H.S., 2010, 2010 4 IEEE INT C BI, P1, DOI [10.1109/btas.2010.5634507, DOI 10.1109/BTAS.2010.5634507]; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1; Dong Yi, 2009, Advances in Biometrics. Proceedings Third International Conference, ICB 2009, P733; Gao XN, 2008, IEEE T CIRC SYST VID, V18, P487, DOI 10.1109/TCSVT.2008.918770; GIBSON L, 2008, FORENSIC ART ESSENTI; Grother P.J., 2010, NATL I STANDARDS TEC, V7709; Gyaourova A, 2012, IEEE T INF FOREN SEC, V7, P518, DOI 10.1109/TIFS.2011.2172429; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601; Kim KI, 2002, IEEE SIGNAL PROC LET, V9, P40, DOI 10.1109/97.991133; Klare B., 2010, P IEEE C BIOM THEOR; KLARE B, 2010, P INT C PATT REC; KLARE B, 2010, P SPIE C BIOM TECHN; Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180; Lei Z, 2009, PROC CVPR IEEE, P1123, DOI 10.1109/CVPRW.2009.5206860; Li J, 2008, IEEE IMAGE PROC, P465, DOI 10.1109/ICIP.2008.4711792; Li S. Z., 2009, ENCY BIOMETRICS; Li SZ, 2007, IEEE T PATTERN ANAL, V29, P627, DOI 10.1109/TPAMI.2007.1014; Liao S., 2009, P 3 INT C ADV BIOM; LIN D, 2006, P EUR C COMP VIS; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Liu QS, 2005, PROC CVPR IEEE, P1005; Liu QS, 2004, IEEE T CIRC SYST VID, V14, P42, DOI 10.1109/TCSVT.2003.818352; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu JW, 2005, PATTERN RECOGN LETT, V26, P181, DOI 10.1016/j.patrec.2004.09.014; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629; Martinez A., 1998, AR FACE DATABASE; MESSER K, 1999, P AUD VID BAS BIOM P; Meyers E, 2008, INT J COMPUT VISION, V76, P93, DOI 10.1007/s11263-007-0058-8; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Phillips P., 1997, P IEEE C COMP VIS PA; Quattoni A., 2008, P IEEE C COMP VIS PA; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819; Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645; Tang XO, 2004, IEEE T CIRC SYST VID, V14, P50, DOI 10.1109/TCSVT.2003.818353; Taylor K.T., 2001, FORENSIC ART ILLUSTR; WANG XG, 2004, P IEEE C COMP VIS PA; Wang XG, 2006, INT J COMPUT VISION, V70, P91, DOI 10.1007/s11263-006-8098-z; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X; Zhang W., 2010, P EUR C COMP VIS; Zhang W., 2011, P IEEE C COMP VIS PA	47	235	240	1	44	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2013	35	6					1410	1422		10.1109/TPAMI.2012.229	http://dx.doi.org/10.1109/TPAMI.2012.229			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	129QV	23599055	Green Submitted			2022-12-18	WOS:000317857900011
J	Morris, BT; Trivedi, MM				Morris, Brendan Tran; Trivedi, Mohan Manubhai			Trajectory Learning for Activity Understanding: Unsupervised, Multilevel, and Long-Term Adaptive Approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Trajectory clustering; real-time activity analysis; abnormality detection; trajectory learning; activity prediction	PATTERNS; CLASSIFICATION; RECOGNITION; SYSTEM	Society is rapidly accepting the use of video cameras in many new and varied locations, but effective methods to utilize and manage the massive resulting amounts of visual data are only slowly developing. This paper presents a framework for live video analysis in which the behaviors of surveillance subjects are described using a vocabulary learned from recurrent motion patterns, for real-time characterization and prediction of future activities, as well as the detection of abnormalities. The repetitive nature of object trajectories is utilized to automatically build activity models in a 3-stage hierarchical learning process. Interesting nodes are learned through Gaussian mixture modeling, connecting routes formed through trajectory clustering, and spatio-temporal dynamics of activities probabilistically encoded using hidden Markov models. Activity models are adapted to small temporal variations in an online fashion using maximum likelihood regression and new behaviors are discovered from a periodic retraining for long-term monitoring. Extensive evaluation on various data sets, typically missing from other work, demonstrates the efficacy and generality of the proposed framework for surveillance-based activity analysis.	[Morris, Brendan Tran; Trivedi, Mohan Manubhai] Univ Calif San Diego, Comp Vis & Robot Res Lab, La Jolla, CA 92093 USA	University of California System; University of California San Diego	Morris, BT (corresponding author), Univ Calif San Diego, Comp Vis & Robot Res Lab, La Jolla, CA 92093 USA.	b1morris@ucsd.edu; mtrivedi@ucsd.edu		Morris, Brendan/0000-0002-8592-8806	NSF-ITR; UC Discovery	NSF-ITR(National Science Foundation (NSF)); UC Discovery(University of California System)	The authors would like to thank the reviewers for all their insightful comments, NSF-ITR and UC Discovery for support, and their CVRR colleagues for their continued assistance.	Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744; Atev S, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P4851, DOI 10.1109/IROS.2006.282362; Bashir F, 2005, IEEE IMAGE PROC, P3401; Bashir FI, 2007, IEEE T IMAGE PROCESS, V16, P1912, DOI 10.1109/TIP.2007.898960; Demirdjian D, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P70, DOI 10.1109/ACV.2002.1182159; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dickinson P., 2008, P IEEE WORKSH MOT VI; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Gales MJF, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1832, DOI 10.1109/ICSLP.1996.607987; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Hu WM, 2007, IEEE T IMAGE PROCESS, V16, P1168, DOI 10.1109/TIP.2006.891352; Hu WM, 2006, IEEE T PATTERN ANAL, V28, P1450, DOI 10.1109/TPAMI.2006.176; Hu WM, 2004, IEEE T SYST MAN CY B, V34, P1618, DOI 10.1109/TSMCB.2004.826829; HUANG K, 2005, P IEEE CS C COMP VIS; Johnson N, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P583; Junejo IN, 2004, INT C PATT RECOG, P716, DOI 10.1109/ICPR.2004.1334359; Makris D, 2005, IEEE T SYST MAN CY B, V35, P397, DOI 10.1109/TSMCB.2005.846652; Messelodi S, 2005, PATTERN ANAL APPL, V8, P17, DOI 10.1007/s10044-004-0239-9; Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280; Morris Brendan, 2009, 2009 IEEE International Conference on Vehicular Electronics and Safety (ICVES 2009), P80, DOI 10.1109/ICVES.2009.5400238; Morris Brendan T., 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P154, DOI 10.1109/AVSS.2008.65; Morris B, 2009, PROC CVPR IEEE, P312, DOI 10.1109/CVPRW.2009.5206559; Morris BT, 2008, IEEE T CIRC SYST VID, V18, P1114, DOI 10.1109/TCSVT.2008.927109; Morris BT, 2008, IEEE T INTELL TRANSP, V9, P425, DOI 10.1109/TITS.2008.922970; Morris BT, 2010, IEEE INTELL SYST, V25, P50, DOI 10.1109/MIS.2010.81; Naftel A, 2006, MULTIMEDIA SYST, V12, P227, DOI [10.1007/s00530-006-0058-5, 10.1007/S00530-006-0058-5]; Ng AY, 2002, ADV NEUR IN, V14, P849; Owens J, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P77, DOI 10.1109/VS.2000.856860; Pedrycz W, 2005, KNOWLEDGE-BASED CLUSTERING: FROM DATA TO INFORMATION GRANULES, P1, DOI 10.1002/0471708607; Piciarelli C, 2006, PATTERN RECOGN LETT, V27, P1835, DOI 10.1016/j.patrec.2006.02.004; Porikli F, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1171, DOI 10.1109/ICME.2004.1394427; Rabiner L., 1993, FUNDAMENTALS SPEECH; RUSSELL MJ, 1985, P IEEE INT C AC SPEE, P5; Sumpter N, 2000, IMAGE VISION COMPUT, V18, P697, DOI 10.1016/S0262-8856(99)00073-6; Swears Eran, 2008, 2008 IEEE Workshop on Motion and Video Computing, P1, DOI 10.1109/WMVC.2008.4544063; Trivedi MM, 2005, IEEE INTELL SYST, V20, P58, DOI 10.1109/MIS.2005.86; Vlachos M, 2002, PROC INT CONF DATA, P673, DOI 10.1109/ICDE.2002.994784; Wang X., 2008, P IEEE C COMP VIS PA, P1; Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010; Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87; Xiang T, 2008, IEEE T PATTERN ANAL, V30, P893, DOI 10.1109/TPAMI.2007.70731; Yan W, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P370; Zhang Z, 2006, INT C PATT RECOG, P1135	43	235	244	2	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2011	33	11					2287	2301		10.1109/TPAMI.2011.64	http://dx.doi.org/10.1109/TPAMI.2011.64			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	820MM	21422488				2022-12-18	WOS:000294910000013
J	Chum, O; Matas, J				Chum, Ondrej; Matas, Jiri			Optimal Randomized RANSAC	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						RANSAC; randomized RANSAC		A randomized model verification strategy for RANSAC is presented. The proposed method finds, like RANSAC, a solution that is optimal with user-specified probability. The solution is found in time that is close to the shortest possible and superior to any deterministic verification strategy. A provably fastest model verification strategy is designed for the (theoretical) situation when the contamination of data by outliers is known. In this case, the algorithm is the fastest possible (on the average) of all randomized RANSAC algorithms guaranteeing a confidence in the solution. The derivation of the optimality property is based on Wald's theory of sequential decision making, in particular, a modified sequential probability ratio test (SPRT). Next, the R-RANSAC with SPRT algorithm is introduced. The algorithm removes the requirement for a priori knowledge of the fraction of outliers and estimates the quantity online. We show experimentally that on standard test data, the method has performance close to the theoretically optimal and is 2 to 10 times faster than standard RANSAC and is up to four times faster than previously published methods.	[Chum, Ondrej; Matas, Jiri] Czech Tech Univ, Dept Cybernet, Fac Elect Engn, Prague 12135, Czech Republic; [Matas, Jiri] Univ Oxford, Dept Elect Engn, Visual Geometry Grp, Oxford OX1 2JD, England	Czech Technical University Prague; University of Oxford	Chum, O (corresponding author), Czech Tech Univ, Dept Cybernet, Fac Elect Engn, Karlovo Namesti 13, Prague 12135, Czech Republic.	chum@cmp.felk.cvut.cz; matas@cmp.felk.cvut.cz	Chum, Ondrej/F-5262-2015; , Matas/AAW-3282-2020	Chum, Ondrej/0000-0001-7042-1810				Capel D., 2005, P BRIT MACH VIS C 20, P629; Chum O, 2004, INT C PATT RECOG, P112, DOI 10.1109/ICPR.2004.1334020; Chum O., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P623; CHUM O, 2003, P ANN S GERM ASS PAT; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Hartley R., 2003, MULTIPLE VIEW GEOMET; LEE PM, 2007, SEQUENTIAL PROBABILI; Matas J, 2004, IMAGE VISION COMPUT, V22, P837, DOI 10.1016/j.imavis.2004.02.009; Matas J, 2005, IEEE I CONF COMP VIS, P1727; Myatt D. R., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P458; Nister D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P199; TORDOFF B, 2002, P 7 ECCV, V1, P82; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Torr PHS, 1998, COMPUT VIS IMAGE UND, V71, P312, DOI 10.1006/cviu.1997.0559; Wald A., 1947, SEQUENTIAL ANAL; 2006, P IEEE INT WORKSH 25	16	235	266	5	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2008	30	8					1472	1482		10.1109/TPAMI.2007.70787	http://dx.doi.org/10.1109/TPAMI.2007.70787			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	312OC	18566499	Green Submitted			2022-12-18	WOS:000256679700012
J	Zheng, YF; Doermann, D				Zheng, YF; Doermann, D			Robust point matching for nonrigid shapes by preserving local neighborhood structures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						point matching; shape matching; image registration; nonrigid shapes; relaxation labeling	RELAXATION LABELING PROCESSES; REGISTRATION; ALGORITHM	In previous work on point matching, a set of points is often treated as an instance of a joint distribution to exploit global relationships in the point set. For nonrigid shapes, however, the local relationship among neighboring points is stronger and more stable than the global one. In this paper, we introduce the notion of a neighborhood structure for the general point matching problem. We formulate point matching as an optimization problem to preserve local neighborhood structures during matching. Our approach has a simple graph matching interpretation, where each point is a node in the graph, and two nodes are connected by an edge if they are neighbors. The optimal match between two graphs is the one that maximizes the number of matched edges. Existing techniques are leveraged to search for an optimal solution with the shape context distance used to initialize the graph matching, followed by relaxation labeling updates for refinement. Extensive experiments show the robustness of our approach under deformation, noise in point locations, outliers, occlusion, and rotation. It outperforms the shape context and TPS-RPM algorithms on most scenarios.	Univ Maryland, Inst Adv Comp Studies, Language & Media Proc Lab, College Pk, MD 20742 USA	University System of Maryland; University of Maryland College Park	Zheng, YF (corresponding author), Univ Maryland, Inst Adv Comp Studies, Language & Media Proc Lab, College Pk, MD 20742 USA.	zhengyf@cfar.umd.edu; doermann@cfar.umd.edu	Zheng, Yefeng/ABG-7053-2020	Zheng, Yefeng/0000-0003-2195-2847				Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Brown L.G., 1992, ACM COMPUT SURV, V24, P325, DOI DOI 10.1145/146370.146374; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; FIELD DJ, 1993, VISION RES, V33, P173, DOI 10.1016/0042-6989(93)90156-Q; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; Kanji G., 1999, 100 STAT TESTS; Pelillo M, 1999, NEURAL COMPUT, V11, P1933, DOI 10.1162/089976699300016034; Pelillo M, 1997, J MATH IMAGING VIS, V7, P309, DOI 10.1023/A:1008255111261; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; TON JC, 1989, IEEE T GEOSCI REMOTE, V27, P642, DOI 10.1109/TGRS.1989.35948; Zheng Y., 2004, LAMPTR117 U MAR	15	235	265	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2006	28	4					643	649		10.1109/TPAMI.2006.81	http://dx.doi.org/10.1109/TPAMI.2006.81			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	011FK	16566512				2022-12-18	WOS:000235253300013
J	Howland, P; Park, H				Howland, P; Park, H			Generalizing discriminant analysis using the generalized singular value decomposition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						linear discriminant analysis; latent semantic indexing; principal component analysis; generalized singular value decomposition; QR decomposition; trace optimization		Discriminant analysis has been used for decades to extract features that preserve class separability. It is commonly defined as an optimization problem involving covariance matrices that represent the scatter within and between clusters. The requirement that one of these matrices be nonsingular limits its application to data sets with certain relative dimensions. We examine a number of optimization criteria, and extend their applicability by using the generalized singular value decomposition to circumvent the nonsingularity requirement. The result is a generalization of discriminant analysis that can be applied even when the sample size is smaller than the dimension of the sample data. We use classification results from the reduced representation to compare the effectiveness of this approach with some alternatives, and conclude with a discussion of their relative merits.	Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA	University of Minnesota System; University of Minnesota Twin Cities	Howland, P (corresponding author), Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.	howland@cs.umn.edu; hpark@cs.umn.edu						[Anonymous], 1987, MATRIX THEORY 2 COUR; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Berry MW, 1995, SIAM REV, V37, P573, DOI 10.1137/1037127; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Howland P, 2003, SIAM J MATRIX ANAL A, V25, P165, DOI 10.1137/S0895479801393666; HOWLAND P, 2003, 041 U MINN DEP COMP; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; KOWALSKI G, 1997, INFORMATION RETRIEVA; Lawson C. L., 1995, SOLVING LEAST SQUARE; PAIGE CC, 1981, SIAM J NUMER ANAL, V18, P398, DOI 10.1137/0718026; Park H, 2003, BIT, V43, P427, DOI 10.1023/A:1026039313770; SCHUBERT H, 1995, FEMS MICROBIOL ECOL, V18, P237, DOI 10.1111/j.1574-6941.1995.tb00180.x; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; Theodoridis S., 2008, PATTERN RECOGN; Torkkola K., 2001, P IEEE ICDM WORKSH T; VANLOAN CF, 1976, SIAM J NUMER ANAL, V13, P76, DOI 10.1137/0713009; Yang H, 2003, PATTERN RECOGN, V36, P563, DOI 10.1016/S0031-3203(02)00048-1; [No title captured]	21	235	259	1	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2004	26	8					995	1006		10.1109/TPAMI.2004.46	http://dx.doi.org/10.1109/TPAMI.2004.46			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	827BE	15641730	Green Submitted			2022-12-18	WOS:000221872400004
J	Liu, AA; Su, YT; Nie, WZ; Kankanhalli, M				Liu, An-An; Su, Yu-Ting; Nie, Wei-Zhi; Kankanhalli, Mohan			Hierarchical Clustering Multi-Task Learning for Joint Human Action Grouping and Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action recognition; multi-task learning; task grouping; task relatedness measure	CONTEXT; TASKS	This paper proposes a hierarchical clustering multi-task learning (HC-MTL) method for joint human action grouping and recognition. Specifically, we formulate the objective function into the group-wise least square loss regularized by low rank and sparsity with respect to two latent variables, model parameters and grouping information, for joint optimization. To handle this non-convex optimization, we decompose it into two sub-tasks, multi-task learning and task relatedness discovery. First, we convert this non-convex objective function into the convex formulation by fixing the latent grouping information. This new objective function focuses on multi-task learning by strengthening the shared-action relationship and action-specific feature learning. Second, we leverage the learned model parameters for the task relatedness measure and clustering. In this way, HC-MTL can attain both optimal action models and group discovery by alternating iteratively. The proposed method is validated on three kinds of challenging datasets, including six realistic action datasets (Hollywood2, YouTube, UCF Sports, UCF50, HMDB51 & UCF101), two constrained datasets (KTH & TJU), and two multi-view datasets (MV-TJU & IXMAS). The extensive experimental results show that: 1) HC-MTL can produce competing performances to the state of the arts for action recognition and grouping; 2) HC-MTL can overcome the difficulty in heuristic action grouping simply based on human knowledge; 3) HC-MTL can avoid the possible inconsistency between the subjective action grouping depending on human knowledge and objective action grouping based on the feature subspace distributions of multiple actions. Comparison with the popular clustered multi-task learning further reveals that the discovered latent relatedness by HC-MTL aids inducing the group-wise multi-task learning and boosts the performance. To the best of our knowledge, ours is the first work that breaks the assumption that all actions are either independent for individual learning or correlated for joint modeling and proposes HC-MTL for automated, joint action grouping and modeling.	[Liu, An-An; Su, Yu-Ting; Nie, Wei-Zhi] Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China; [Kankanhalli, Mohan] Natl Univ Singapore, Sch Comp, Singapore, Singapore	Tianjin University; National University of Singapore	Liu, AA (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.	anan0422@gmail.com; ytsu@tju.edu.cn; weizhinie@tju.edu.cn; mohan@comp.nus.edu.sg	Kankanhalli, Mohan/Q-9284-2019; Nie, Weizhi/ABF-5316-2021	Kankanhalli, Mohan/0000-0002-4846-2015; 	National Natural Science Foundation of China [61472275, 61100124, 61502337]; Tianjin Research Program of Application Foundation and Advanced Technology [15JCYBJC16200]; China Scholarship Council [201506255073]; Elite Scholar Program of Tianjin University [2014XRG-0046]; Singapore National Research Foundation under its International Research Centre @ Singapore Funding Initiative	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Tianjin Research Program of Application Foundation and Advanced Technology; China Scholarship Council(China Scholarship Council); Elite Scholar Program of Tianjin University; Singapore National Research Foundation under its International Research Centre @ Singapore Funding Initiative(National Research Foundation, Singapore)	This work was supported in part by the National Natural Science Foundation of China (61472275, 61100124, 61502337), the Tianjin Research Program of Application Foundation and Advanced Technology (15JCYBJC16200), the grant of China Scholarship Council (201506255073), the grant of Elite Scholar Program of Tianjin University (2014XRG-0046). Mohan's research is supported by the Singapore National Research Foundation under its International Research Centre @ Singapore Funding Initiative and administered by the IDM Programme Office. An-An Liu is the corresponding author of this paper.	Ando RK, 2005, J MACH LEARN RES, V6, P1817; Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8; Boyd S, 2004, CONVEX OPTIMIZATION; Burghouts G., 2013, P ICCV WORKSH THUMOS, P1; Chen J., 2014, LOW RANK SPARSE MODE, P151; Chen J., 2011, PROC 17 ACM SIGKDD I, P42; Cho H., 2013, DES AUT C DAC 2013 5, P1, DOI [10.1145/2463209.2488859, DOI 10.1109/CGO.2013.6494982]; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Fasheng Wang, 2013, Wireless Algorithms, Systems, and Applications. 8th International Conference, WASA 2013. Proceedings. LNCS 7992, P1, DOI 10.1007/978-3-642-39701-1_1; Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176; Gao Y, 2014, IEEE T IMAGE PROCESS, V23, P5400, DOI 10.1109/TIP.2014.2364536; Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034; Hoai M., 2014, P AS C COMP VIS, P3, DOI DOI 10.1007/978-3-319-16814-21; Ji RR, 2014, IEEE T IMAGE PROCESS, V23, P3099, DOI 10.1109/TIP.2014.2324291; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Jiang YG, 2012, LECT NOTES COMPUT SC, V7576, P425, DOI 10.1007/978-3-642-33715-4_31; Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353; Jones S, 2014, PROC CVPR IEEE, P604, DOI 10.1109/CVPR.2014.84; Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057; Liu AA, 2015, NEUROCOMPUTING, V151, P544, DOI 10.1016/j.neucom.2014.04.090; Liu JG, 2009, PROC CVPR IEEE, P1996; Luo G, 2014, IEEE T PATTERN ANAL, V36, P2466, DOI 10.1109/TPAMI.2014.2329301; Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557; Narayan S, 2014, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR.2014.337; Nesterov Y, 2014, INTRO LECT CONVEX OP; Ng AY, 2002, ADV NEUR IN, V14, P849; Peng X., 2014, ARXIV14054506; Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38; Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4; Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727; Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806; Soomro K., 2012, ARXIVPREPRINT, P2556; Sun L, 2014, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2014.336; Tran D, 2008, LECT NOTES COMPUT SC, V5302, P548, DOI 10.1007/978-3-540-88682-2_42; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang H, 2009, J OPTOELECTRON BIOME, V1, P1; Wang HM, 2013, SCI WORLD J, DOI [10.1155/2013/865645, 10.1155/2013/658793]; Wang LM, 2013, PROC CVPR IEEE, P2674, DOI 10.1109/CVPR.2013.345; Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013; Wu BX, 2014, PROC CVPR IEEE, P2609, DOI 10.1109/CVPR.2014.334; Wu D, 2014, NEUROCOMPUTING, V127, P98, DOI 10.1016/j.neucom.2013.08.038; Wu JZ, 2014, IEEE T MULTIMEDIA, V16, P147, DOI 10.1109/TMM.2013.2283846; Wu XX, 2013, IEEE T CIRC SYST VID, V23, P1422, DOI 10.1109/TCSVT.2013.2244794; Wu XX, 2011, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.2011.5995624; Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365; Xu XX, 2013, IEEE T NEUR NET LEAR, V24, P749, DOI 10.1109/TNNLS.2012.2237183; Xu Z., 2015, CELL MOL NEUROBIOL, P1; Yang XD, 2014, LECT NOTES COMPUT SC, V8690, P727, DOI 10.1007/978-3-319-10605-2_47; Yuan CF, 2013, PROC CVPR IEEE, P423, DOI 10.1109/CVPR.2013.61; Zhang H, 2014, PROC CVPR IEEE, P2067, DOI 10.1109/CVPR.2014.265; Zhang XL, 2015, IEEE T PATTERN ANAL, V37, P28, DOI 10.1109/TPAMI.2014.2343221; Zhang Z, 2013, IEEE T INF FOREN SEC, V8, P1600, DOI 10.1109/TIFS.2013.2258152; Zhou Jiayu, 2011, Adv Neural Inf Process Syst, V2011, P702; Zhou Q, 2013, IEEE I CONF COMP VIS, P2264, DOI 10.1109/ICCV.2013.281	59	234	243	10	139	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2017	39	1					102	114		10.1109/TPAMI.2016.2537337	http://dx.doi.org/10.1109/TPAMI.2016.2537337			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EF6DP	26955018				2022-12-18	WOS:000390421300010
J	Klare, BF; Li, ZF; Jain, AK				Klare, Brendan F.; Li, Zhifeng; Jain, Anil K.			Matching Forensic Sketches to Mug Shot Photos	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; forensic sketch; viewed sketch; local feature discriminant analysis; feature selection; heterogeneous face recognition	FACE RECOGNITION; FEATURES	The problem of matching a forensic sketch to a gallery of mug shot images is addressed in this paper. Previous research in sketch matching only offered solutions to matching highly accurate sketches that were drawn while looking at the subject (viewed sketches). Forensic sketches differ from viewed sketches in that they are drawn by a police sketch artist using the description of the subject provided by an eyewitness. To identify forensic sketches, we present a framework called local feature-based discriminant analysis (LFDA). In LFDA, we individually represent both sketches and photos using SIFT feature descriptors and multiscale local binary patterns (MLBP). Multiple discriminant projections are then used on partitioned vectors of the feature-based representation for minimum distance matching. We apply this method to match a data set of 159 forensic sketches against a mug shot gallery containing 10,159 images. Compared to a leading commercial face recognition system, LFDA offers substantial improvements in matching forensic sketches to the corresponding face images. We were able to further improve the matching performance using race and gender information to reduce the target gallery size. Additional experiments demonstrate that the proposed framework leads to state-of-the-art accuracys when matching viewed sketches.	[Klare, Brendan F.; Li, Zhifeng; Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48823 USA; [Jain, Anil K.] Korea Univ, Dept Brain & Cognit Engn, Seoul, South Korea	Michigan State University; Korea University	Klare, BF (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, 3208 Engn Bldg, E Lansing, MI 48823 USA.	klarebre@msu.edu; zfli@msu.edu; jain@cse.msu.edu			Ministry of Education, Science, and Technology [R31-2008-000-10008-0]	Ministry of Education, Science, and Technology(Ministry of Education, Science & Technology (MEST), Republic of Korea)	The authors would like to thank Lois Gibson, Karen Taylor, Sheila Meese (and other Michigan State Police forensic artists), and Scott McCallum (PCSO) for providing forensic sketches and the mated photographs. They would like to further thank Lois Gibson for granting permission to publish her collection of sketches. They would also like to thank Professor Xiaoou Tang for sharing the CUHK sketch database. Gratitude is given to Morpho for their support of this research. Anil Jain's research was partially supported by the World Class University program through the National Research Foundation of Korea funded by the Ministry of Education, Science, and Technology (R31-2008-000-10008-0).	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; *COGN SYST GMBH, 2010, FACEVACS SOFTW DEV K; Frowd C, 2007, BRIT J PSYCHOL, V98, P61, DOI 10.1348/000712606X104481; Gao XN, 2008, IEEE T CIRC SYST VID, V18, P487, DOI 10.1109/TCSVT.2008.918770; GIBSON L, 2008, FORENSIC ART ESSENTI; Jain Anil K, 2004, P INT C BIOM AUTH; KLARE B, 2010, MSUCSE103; KLARE B, 2010, P INT C PATT REC; KLARE B, 2010, P SPIE C BIOM TECHN; Lei Z, 2009, PROC CVPR IEEE, P1123, DOI 10.1109/CVPRW.2009.5206860; LI Y, 2006, INT CONF ACOUST SPEE, pA357; LIAO S, 2009, P 3 INT C BIOM; LIN D, 2006, P EUR C COMP VIS; Liu CF, 2007, ADV INTEL SYS RES, DOI 10.2991/iske.2007.250; Liu QS, 2005, PROC CVPR IEEE, P1005; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu JW, 2005, PATTERN RECOGN LETT, V26, P181, DOI 10.1016/j.patrec.2004.09.014; Martinez A., 1998, AR FACE DATABASE; Messer K., 1999, P 2 INT C AUDIO VIDE; Meyers E, 2008, INT J COMPUT VISION, V76, P93, DOI 10.1007/s11263-007-0058-8; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; NIZAMI H, 2009, P IEEE C BIOM THEOR; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5; Tang XO, 2004, IEEE T CIRC SYST VID, V14, P1, DOI 10.1109/TCSVT.2003.818389; Tang XO, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P687, DOI 10.1109/ICCV.2003.1238414; Taylor K.T., 2001, FORENSIC ART ILLUSTR; UHL R, 1996, P IEEE C COMP VIS PA; Wang XG, 2006, INT J COMPUT VISION, V70, P91, DOI 10.1007/s11263-006-8098-z; Xiao B, 2009, SIGNAL PROCESS, V89, P1576, DOI 10.1016/j.sigpro.2009.02.008; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X; Yuen PC, 2007, IEEE T SYST MAN CY A, V37, P493, DOI 10.1109/TSMCA.2007.897588; ZHONG J, 2007, P IEEE C AC SPEECH S	35	233	246	0	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2011	33	3					639	646		10.1109/TPAMI.2010.180	http://dx.doi.org/10.1109/TPAMI.2010.180			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	706FZ	20921585	Green Submitted			2022-12-18	WOS:000286204700015
J	Poelman, CJ; Kanade, T				Poelman, CJ; Kanade, T			A paraperspective factorization method for shape and motion recovery	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion analysis; shape recovery; factorization method; three-dimensional vision; image sequence analysis; singular value decomposition	IMAGE	The factorization method, first developed by Tomasi and Kanade, recovers both the shape of an object and its motion from a sequence of images, using many images and tracking many feature points to obtain highly redundant feature position information. The method robustly processes the feature trajectory information using singular value decomposition (SVD), taking advantage of the linear algebraic properties of orthographic projection. However, an orthographic formulation limits the range of motions the method can accommodate. Paraperspective projection, first introduced by Ohta, is a projection model that closely approximates perspective projection by modeling several effects not modeled under orthographic projection, while retaining linear algebraic properties. Our paraperspective factorization method can be applied to a much wider range of motion scenarios, including image sequences containing motion toward the camera and aerial image sequences of terrain taken from a low-altitude airplane.	CARNEGIE MELLON UNIV,SCH COMP SCI,PITTSBURGH,PA 15213	Carnegie Mellon University	Poelman, CJ (corresponding author), USAF,PHILLIPS LAB,SATELLITE ASSESSMENT CTR,WSAT,ALBUQUERQUE,NM 87117, USA.							ALOIMONOS JY, 1990, IMAGE VISION COMPUT, V8, P177; BROIDA TJ, 1990, IEEE T AERO ELEC SYS, V26, P639, DOI 10.1109/7.55557; COSTEIRA J, 1994, CMUCSTR94220; Lucas Bruce, 1981, IJCAI; MUNDY JL, 1992, GEOMETRIC INVARIANCE, P512; OHTA Y, 1981, P INT JOINT C ART IN, P746; POELMAN CJ, 1993, CMUCS93219; Press WH, 1988, NUMERICAL RECIPES C; QUAN L, 1994, 26 LIFIACNRSINRIA; RUHE A, 1980, SIAM REV, V22; SZELISKI R, 1993, 933 CAMBR RES LAB DI; TAYLOR C, 1991, IEEE WORKSH VIS MOT, P2242; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; TOMASI C, 1991, CMUCS91172; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; WEINSHALL D, 1993, P 4 INT C COMP VIS B, P675	16	233	250	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1997	19	3					206	218		10.1109/34.584098	http://dx.doi.org/10.1109/34.584098			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR582		Green Submitted			2022-12-18	WOS:A1997WR58200002
J	Rajwade, A; Rangarajan, A; Banerjee, A				Rajwade, Ajit; Rangarajan, Anand; Banerjee, Arunava			Image Denoising Using the Higher Order Singular Value Decomposition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image denoising; singular value decomposition (SVD); higher order singular value decomposition (HOSVD); coefficient thresholding; learning orthonormal bases; patch similarity	SPACE; MATRIX	In this paper, we propose a very simple and elegant patch-based, machine learning technique for image denoising using the higher order singular value decomposition (HOSVD). The technique simply groups together similar patches from a noisy image (with similarity defined by a statistically motivated criterion) into a 3D stack, computes the HOSVD coefficients of this stack, manipulates these coefficients by hard thresholding, and inverts the HOSVD transform to produce the final filtered image. Our technique chooses all required parameters in a principled way, relating them to the noise model. We also discuss our motivation for adopting the HOSVD as an appropriate transform for image denoising. We experimentally demonstrate the excellent performance of the technique on grayscale as well as color images. On color images, our method produces state-of-the-art results, outperforming other color image denoising algorithms at moderately high noise levels. A criterion for optimal patch-size selection and noise variance estimation from the residual images (after denoising) is also presented.	[Rajwade, Ajit] DA IICT, Gandhinagar 382007, Gujarat, India; [Rangarajan, Anand; Banerjee, Arunava] Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA	Dhirubhai Ambani Institute of Information & Communication Technology; State University System of Florida; University of Florida	Rajwade, A (corresponding author), DA IICT, Post Bag 4, Gandhinagar 382007, Gujarat, India.	avr@cise.ufl.edu; anand@cise.ufl.edu; arunava@cise.ufl.edu	Rangarajan, Anand/A-8652-2009	Rangarajan, Anand/0000-0001-8695-8436; Banerjee, Arunava/0000-0001-9381-4940	US National Science Foundation (NSF) [IIS 1143963]; Div Of Information & Intelligent Systems [1143963] Funding Source: National Science Foundation	US National Science Foundation (NSF)(National Science Foundation (NSF)); Div Of Information & Intelligent Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This work is partially supported by the US National Science Foundation (NSF) IIS 1143963. The authors acknowledge helpful conversations with Brett Presnell, Baba Vemuri, Yair Weiss, and Andrew Zisserman. Supplemental material and C/MATLAB code (under the terms of the GNU General Public License, GPL version 2) can be accessed at http://www.cise.ufl.edu/similar to avr or http://www.cise.ufl.edu/similar to anand/publications.html.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; ANDREWS HC, 1976, IEEE T ACOUST SPEECH, V24, P26, DOI 10.1109/TASSP.1976.1162766; Awate SP, 2006, IEEE T PATTERN ANAL, V28, P364, DOI 10.1109/TPAMI.2006.64; Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024; Buades A, 2006, NUMER MATH, V105, P1, DOI [10.1007/s00211-006-0029-y, 10.1007/s00211-006-0029-v]; Chatterjee P, 2009, IEEE T IMAGE PROCESS, V18, P1438, DOI 10.1109/TIP.2009.2018575; Coifman R., 1995, TECHNICAL REPORT; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Dabov K., 2009, P WORKSH SIGN PROC A; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; de Lathauwer L., 1997, THESIS KATHOLIEKE U; Ding C, 2005, SIAM PROC S, P32; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Gurumoorthy KS, 2010, IEEE T IMAGE PROCESS, V19, P322, DOI 10.1109/TIP.2009.2034991; Hyvarinen A., 1999, INTELLIGENT SIGNAL P, P1; Lansel S., 2006, DENOISELAB; Letexier D, 2008, IEEE SIGNAL PROC LET, V15, P229, DOI 10.1109/LSP.2007.916045; Lewicki MS, 2000, NEURAL COMPUT, V12, P337, DOI 10.1162/089976600300015826; Mairal J, 2008, MULTISCALE MODEL SIM, V7, P214, DOI 10.1137/070697653; Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452; Muresan DD, 2003, IEEE IMAGE PROC, P101; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Popat K, 1997, IEEE T IMAGE PROCESS, V6, P268, DOI 10.1109/83.551697; Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640; Rangarajan A, 2001, LECT NOTES COMPUT SC, V2134, P153; Rosenfeld A., 1982, DIGITAL PICTURE PROC; Rudin L. I., 1994, Proceedings ICIP-94 (Cat. No.94CH35708), P31, DOI 10.1109/ICIP.1994.413269; Sendur L, 2002, IEEE T SIGNAL PROCES, V50, P2744, DOI 10.1109/TSP.2002.804091; Simoncelli E.P., 1999, BAYESIAN INFERENCE W, V141, P291, DOI DOI 10.1007/978-1-4612-0567-8; Subakan O., 2007, P 11 INT C COMP VIS, P1; Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Tschumperle D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87; Vasilescu M., 2002, PATTERN RECOGN, P511; Wang Z, 2003, CONF REC ASILOMAR C, P1398; Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1; Yaroslavasky L., 2001, P SPIE SERIES NONLIN, P1; Ye JP, 2005, MACH LEARN, V61, P167, DOI 10.1007/s10994-005-3561-6; You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184; Yu G., 2010, COMPUTING RES REPOSI; Zhang D, 2002, IEEE T CIRC SYST VID, V12, P331, DOI 10.1109/TCSVT.2002.1003472; Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023; Zhou M., 2011, INT C ART INT STAT, V15, P883; Zhou MY, 2012, IEEE T IMAGE PROCESS, V21, P130, DOI 10.1109/TIP.2011.2160072; Zoran D., 2011, P IEEE INT C COMP VI	46	232	247	5	131	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2013	35	4					849	862		10.1109/TPAMI.2012.140	http://dx.doi.org/10.1109/TPAMI.2012.140			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	089ST	22732660				2022-12-18	WOS:000314931000007
J	Jing, Y; Baluja, S				Jing, Yushi; Baluja, Shumeet			VisualRank: Applying PageRank to large-scale image search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image ranking; content-based image retrieval; eigenvector centrality; graph theory		Because of the relative ease in understanding and processing text, commercial image-search systems often rely on techniques that are largely indistinguishable from text search. Recently, academic studies have demonstrated the effectiveness of employing image-based features to provide either alternative or additional signals to use in this process. However, it remains uncertain whether such techniques will generalize to a large number of popular Web queries and whether the potential improvement to search quality warrants the additional computational cost. In this work, we cast the image-ranking problem into the task of identifying "authority" nodes on an inferred visual similarity graph and propose VisualRank to analyze the visual link structures among images. The images found to be "authorities" are chosen as those that answer the image-queries well. To understand the performance of such an approach in a real system, we conducted a series of large-scale experiments based on the task of retrieving images for 2,000 of the most popular products queries. Our experimental results show significant improvement, in terms of user satisfaction and relevancy, in comparison to the most recent Google Image Search results. Maintaining modest computational cost is vital to ensuring that this procedure can be used in practice; we describe the techniques required to make this system practical for large-scale deployment in commercial search engines.	[Jing, Yushi] Georgia Inst Technol, Mountain View, CA 94043 USA; [Jing, Yushi; Baluja, Shumeet] Google Inc, Res Grp, Mountain View, CA 94043 USA	University System of Georgia; Georgia Institute of Technology; Google Incorporated	Jing, Y (corresponding author), Georgia Inst Technol, 1600 Amphitheater Pkwy, Mountain View, CA 94043 USA.	jing@google.com; shumeet@google.com						BALUJA S, 2008, P 17 INT WORLD WID W; Bay H., 2006, EUR C COMP VIS ECCV, P404, DOI [10.1007/11744023_32, DOI 10.1007/11744023_32]; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248; Fergus R, 2004, LECT NOTES COMPUT SC, V3021, P242; Fergus R, 2003, PROC CVPR IEEE, P264; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Frome A, 2007, IEEE I CONF COMP VIS, P94; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Haveliwala TH, 2003, IEEE T KNOWL DATA EN, V15, P784, DOI 10.1109/TKDE.2003.1208999; He X., 2002, P IEEE INT C MULT EX, V1, P25; Hsu W.H., 2007, P ACM INT C MULT, P971, DOI DOI 10.1145/1291233.1291446.ISBN; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Indyk P, 2000, ANN IEEE SYMP FOUND, P189, DOI 10.1109/SFCS.2000.892082; JING Y, 2007, P 6 INT C IM VID RET, P280; Joshi D, 2006, ACM T MULTIM COMPUT, V2, P68, DOI 10.1145/1126004.1126008; Ke Y, 2004, PROC CVPR IEEE, P506; KE Y, 2004, P 12 ACM INT C MULT, P869, DOI DOI 10.1145/1027527.1027729]; Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140; Kondor R.I., 2002, P 19 INT C MACHINE L, P315; Lazebnik S, 2003, PROC CVPR IEEE, P319; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Ma WY, 1999, MULTIMEDIA SYST, V7, P184, DOI 10.1007/s005300050121; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; NISTER D, 2006, P IEEE C COMP VIS PA, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; NOWAK E, 2007, P C COMP VIS PATT RE; PARK G, 2003, LECT NOTES COMPUTER, V27, P499; Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143; Philbin J., 2007, P C COMP VIS PATT RE; Salton G., 1983, INTRO MODERN INFORM; Schindler G., 2007, P C COMP VIS PATT RE; SIMON I, 2007, P 12 INT C COMP VIS; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; UCHIHASHI S, 2005, P 4 INT C IM VID RET, P650; Weinberger K., 2006, P 18 C ADV NEUR INF, P1437; WINDER S, 2007, PROF C COMP VIS PATT; XING E, 2002, P 15 C ADV NEUR INF, V15, P450; Zhu X., 2003, INT C MACH LEARN	42	232	267	2	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2008	30	11					1877	1890		10.1109/TPAMI.2008.121	http://dx.doi.org/10.1109/TPAMI.2008.121			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	347AC	18787237				2022-12-18	WOS:000259110000002
J	Pentland, A				Pentland, A			Looking at people: Sensing for ubiquitous and wearable computing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review						looking at people; face recognition; gesture recognition; visual interface; appearance-based vision; wearable computing; ubiquitious	OBJECT REPRESENTATION; FACIAL EXPRESSIONS; AUGMENTED REALITY; MOTION ESTIMATION; FACE-RECOGNITION; IMAGE SEQUENCES; OPTICAL-FLOW; MODELS; EIGENFACES; TRACKING	The research topic of looking at people, that is, giving machines the ability to detect, track, and identify people and more generally, to interpret human behavior, has become a central topic in machine vision research. Initially thought to be the research problem that would be hardest to solve, it has proven remarkably tractable and has even spawned several thriving commercial enterprises. The principle driving application for this technology is "fourth generation" embedded computing: "smart"' environments and portable or wearable devices. The key technical goals are to determine the computer's context with respect to nearby humans (e.g., who, what, when, where, and why) so that the computer can act or respond appropriately without detailed instructions. This paper will examine the mathematical tools that have proven successful, provide a taxonomy of the problem domain, and then examine the state-of-the-art. Four areas will receive particular attention: person identification, surveillance/monitoring, 3D methods, and smart rooms/perceptual user interfaces. Finally, the paper will discuss some of the research challenges and opportunities.	MIT, Media Lab, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT)	Pentland, A (corresponding author), MIT, Media Lab, 20 Ames St, Cambridge, MA 02139 USA.	pentland@media.mit.edu						ABDI H, 1988, ARTIF INTELL, P151; AKITA K, 1984, PATTERN RECOGN, V17, P73, DOI 10.1016/0031-3203(84)90036-0; AZARBAYEJANI A, 1993, IEEE T PATTERN ANAL, V15, P602, DOI 10.1109/34.216730; BADLER NI, 1979, COMPUT SURV, V11, P19, DOI 10.1145/356757.356760; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Black M. J., 1998, Intelligent Environments. Papers from the 1998 AAAI Symposium, P1; Black M.J., 1995, P IEEE INT C COMP VI; BLAKE A, 1995, ARTIF INTELL, V78, P179, DOI 10.1016/0004-3702(95)00032-1; BOBICK A, 1997, P ROYAL SOC B, V352, P1270; BOBICK A, 1999, PRESENCE-TELEOP VIRT, V8, P367; Bolt R. A., 1980, Computer Graphics, V14, P262, DOI 10.1145/965105.807503; BOULT T, 1998, DARPA IM UND WORKSH; BREGLER C, 1998, IEEE C COMP VIS PATT; BREMOND F, 1998, P DARPA IM UND WORKS; Cassell J., 1998, COMPUTER VISION HUMA; Cerezo E, 1999, VISUAL COMPUT, V15, P124, DOI 10.1007/s003710050167; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; Cipolla R., 1998, COMPUTER VISION HUMA; COHEN M, 1998, P AAAI SPRING S SER, P26; COTTRELL GW, 1990, INTERNATIONAL NEURAL NETWORK CONFERENCE, VOLS 1 AND 2, P322; CRAW I, 1987, PATTERN RECOGN LETT, V5, P183, DOI 10.1016/0167-8655(87)90039-0; Crowley JL, 1997, PROC CVPR IEEE, P640, DOI 10.1109/CVPR.1997.609393; DARRELL T, 1998, AAAI SPRING S SER ST, P44; Darrell TJ, 1996, IEEE T PATTERN ANAL, V18, P1236, DOI 10.1109/34.546259; DeCarlo D, 1996, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.1996.517079; DIBERNARDO E, 1998, COMPUTER VISION HUMA; Ekman P., 2002, FACIAL ACTION CODING; ESSA I, 1996, P IEEE INT C FAC GES; Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232; Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724; Freeman W.T., 1995, P INT WORKSH AUT FAC, P179; Friedmann M., 1992, PRESENCE, V1, P139; FURNAS GW, 1987, COMMUN ACM, V30, P964, DOI 10.1145/32206.32212; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056; Grimson WEL, 1998, PROC CVPR IEEE, P22, DOI 10.1109/CVPR.1998.698583; HARITAOGLU I, 1998, W4 WHO WHAT REAL TIM; HOGG D, 1983, IMAGE VISION COMPUT, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3; Ishikawa T, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P342, DOI 10.1109/AFGR.1998.670972; IVANOV Y, 1999, P IEEE WORKSH VID SU; JAAKKOLA T, 1999, P C NEUR INF PROC DE; JEBARA T, 1998, P IEEE INT C COMP VI; Jo KH, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P468, DOI 10.1109/AFGR.1998.670992; KAKADIARIS I, 1996, P IEEE C COMP VIS PA; KANADE T, 1977, INTERDISCIPLINARY SY, V47; KAUTH R, 1997, P 11 INT S REM SENS; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; Kohonen T., 1989, SELF ORG ASSOCIATIVE, V3rd; KONOLIGE K, 1998, DARPA IM UND WORKSH; KRUGER M, 1983, VIRTUAL REALITY; KUNIYOSHI Y, 1993, IJCAI-93, VOLS 1 AND 2, P1600; Kutulakos KN, 1998, IEEE T VIS COMPUT GR, V4, P1, DOI 10.1109/2945.675647; Lee Y., 1995, P 22 ANN C COMP GRAP, P55, DOI [10.1145/218380.218407, DOI 10.1145/218380.218407]; LI HB, 1993, IEEE T PATTERN ANAL, V15, P545, DOI 10.1109/34.216724; LIPTON A., 1998, P IEEE WORKSH APPL C; Lucente M., 1998, Intelligent Environments. Papers from the 1998 AAAI Symposium, P87; MAES P, 1993, P SIGGRAPH 93 VIS, P115; MAGGIONI C, 1998, GESTURE COMPUTER HIS; MANN S, 1997, PERSONAL TECHNOLOGIE, V1; Mase K., 1987, Proceedings of the 1987 International Conference on Systems, Man, and Cybernetics (Cat. No.87CH2503-1), P970; MASE K, 1989, P OPT SOC AM TOP M M, P1565; MASE K, 1998, COMPUTER VISION HUMA; McNeil D., 1992, HAND MIND WHAT GESTU; Moezzi S, 1996, IEEE COMPUT GRAPH, V16, P58, DOI 10.1109/38.544073; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; Moghaddam B, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P30, DOI 10.1109/AFGR.1998.670921; NAGEL HH, 1994, P EUR C COMP VIS, V2, P338; NARAYANAN P, 1998, P INT C COMP VIS GRE; Oliver N, 1997, PROC CVPR IEEE, P123, DOI 10.1109/CVPR.1997.609309; OLIVER N, 1998, P IEEE C COMP VIS PA; Olson T. J., 1997, P DARPA IM UND WORKS, P159; Oren M, 1997, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.1997.609319; Pavlovic V., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P609, DOI 10.1109/CVPR.1999.784983; Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226; Pavlovic VI, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P30, DOI 10.1109/AFGR.1996.557240; Penev PS, 1996, NETWORK-COMP NEURAL, V7, P477, DOI 10.1088/0954-898X/7/3/002; Pentland A, 1999, NEURAL COMPUT, V11, P229, DOI 10.1162/089976699300016890; Pentland A., 1998, SCI AM, P90; Pentland AP, 1996, SCI AM, V274, P68, DOI 10.1038/scientificamerican0496-68; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0; POLANA R, 1994, P IEEE INT C COMP VI; QUEK FKH, 1995, IMAGE VISION COMPUT, V13, P511, DOI 10.1016/0262-8856(95)94384-C; RAO RPN, 1995, ARTIF INTELL, V78, P461, DOI 10.1016/0004-3702(95)00026-7; REHG J, 1996, P EUR C COMP VIS, V2, P35; REKIMOTO J, 1998, P IEEE INT S WEAR CO, P18; Rosenberg Y, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P238, DOI 10.1109/ACV.1998.732887; Rowley HA, 1996, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.1996.517075; SCHIELE B, 1995, P INT C AUT FAC GEST; SCHIELE B, 1996, P 13 INT C PATT REC, VB, P50; Schneiderman H, 1998, PROC CVPR IEEE, P45, DOI 10.1109/CVPR.1998.698586; SELINGER A, 1998, DARPA IM UND WORKSH; SHAFER A, 1998, P DARPA NIST SMART S; Sharma R, 1998, P IEEE, V86, P853, DOI 10.1109/5.664275; SISKIND JM, 1995, ARTIF INTELL REV, V8, P371, DOI 10.1007/BF00849726; SPERLING G, 1985, COMPUT VISION GRAPH, V31, P335, DOI 10.1016/0734-189X(85)90034-9; Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811; Starner T, 1997, PRESENCE-TELEOP VIRT, V6, P386, DOI 10.1162/pres.1997.6.4.386; Stein R, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P18, DOI 10.1109/ISWC.1998.729525; Stillman S., 1999, P INT C AUD VID BAS, P96; SUNG K, 1994, P IMAGE UNDERSTANDIN, V2, P843; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Turk M, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P368, DOI 10.1109/AFGR.1996.557293; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; VALENTIN D, 1994, PATTERN RECOGN, V27, P1209, DOI 10.1016/0031-3203(94)90006-X; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Waibel A, 1996, ARTIF INTELL REV, V10, P299, DOI 10.1007/BF00127684; WATERS K, 1998, COMPUTER VISION HUMA; WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94; WILLSKY A, 1986, LECT NOTES CONTROL I, V77; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; WREN C, 1999, 498 MIT MED LAB; Wren CR, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P22, DOI 10.1109/AFGR.1998.670920; YACHIDA M, 1998, COMPUTER VISION HUMA; Yacoob Y, 1996, IEEE T PATTERN ANAL, V18, P636, DOI 10.1109/34.506414; YACOOB Y, 1998, COMPUTER VISION HUM; Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161; 1998, P IEEE C AUT FAC GES; 1995, INT C AUT FAC GEST R; 1998, P DARPA IM UND WORKS	123	232	249	2	104	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2000	22	1					107	119		10.1109/34.824823	http://dx.doi.org/10.1109/34.824823			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	286WR					2022-12-18	WOS:000085472300006
J	ZABRODSKY, H; PELEG, S; AVNIR, D				ZABRODSKY, H; PELEG, S; AVNIR, D			SYMMETRY AS A CONTINUOUS FEATURE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						SYMMETRY; LOCAL SYMMETRY; SYMMETRY DISTANCE; SIMILARITY MEASURE; OCCLUSION; FUZZY SHAPES; FACE ORIENTATION	SHAPE; RECONSTRUCTION; OBJECT; IMAGES	Symmetry is treated as a continuous feature and a Continuous Measure of Distance from Symmetry in shapes is defined. The Symmetry Distance (SD) of a shape is defined to be the minimum mean squared distance required to move points of the original shape in order to obtain a symmetrical shape. This general definition of a symmetry measure enables a comparison of the ''amount'' of symmetry of different shapes and the ''amount'' of different symmetries of a single shape. This measure is applicable to any type of symmetry in any dimension. The Symmetry Distance gives rise to a method of reconstructing symmetry of occluded shapes. We extend the method to deal with symmetries of noisy and fuzzy data. Finally, we consider grayscale images as 3D shapes, and use the Symmetry Distance to find the orientation of symmetric objects from their images, acid to find locally symmetric regions in images.	HEBREW UNIV JERUSALEM,DEPT ORGAN CHEM,IL-91904 JERUSALEM,ISRAEL	Hebrew University of Jerusalem	ZABRODSKY, H (corresponding author), HEBREW UNIV JERUSALEM,INST COMP SCI,IL-91904 JERUSALEM,ISRAEL.		Peleg, Shmuel/B-7454-2011; Avnir, David/AAK-4189-2021	Peleg, Shmuel/0000-0002-4468-2619; 				Alt H., 1987, ACM J COMPUTING, V4, P308; AMOROS JL, 1975, LAUE METHOD; ATALLAH MJ, 1985, IEEE T COMPUT, V34, P663, DOI 10.1109/TC.1985.1676605; ATTNEAVE F, 1955, Am J Psychol, V68, P209, DOI 10.2307/1418892; AVNIR D, 1991, J MOL STRUCT, V94, P211; BIGUN J, 1988, P 9 ICPR ROM, P345; BLAKE A, 1993, MAY P INT C PATT REC, P724; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; BONNEH Y, 1993, MAY P INT C PATT REC, P461; BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302; DEGROOT MH, 1975, PROBABILITY STATISTI; GILAT G, 1989, J PH A, V22, P545; GROSS AD, 1994, INT J COMPUT VISION, V13, P91, DOI 10.1007/BF01420797; Grunbaum B., 1963, P S PURE MATHEMATICS, V7, P233; Hel-Or Y., 1991, COMPUTER VISION GRAP, V53; HU MK, 1962, IRE T INFORMATION TH, V20, P179; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; KASS M, 1988, INT J COMPUTER VISIO, V1, P322; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; Leyton M., 1992, SYMMETRY CAUSALITY M; MAROLA G, 1989, IEEE T PATTERN ANAL, V11, P104, DOI 10.1109/34.23119; Miller W., 1972, SYMMETRY GROUPS THEI; MITSUMOTO H, 1992, IEEE T PATTERN ANAL, V14, P941, DOI 10.1109/34.161352; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; NALWA VS, 1989, IEEE T PATTERN ANAL, V11, P1117, DOI 10.1109/34.42842; OH WG, 1988, P INT C PATT REC, P1043; PONCE J, 1990, COMPUT VISION GRAPH, V52, P328, DOI 10.1016/0734-189X(90)90079-B; REISFELD D, 1992, JUN P INT C PATT REC, P117; TERZOPOULOS D, 1987, INT J COMPUT VISION, V1, P211, DOI 10.1007/BF00127821; Weyl H., 1952, SYMMETRY; YODOGAWA E, 1982, PERCEPT PSYCHOPHYS, V32, P230, DOI 10.3758/BF03206227; ZABRODSKY H, 1995, J AM CHEM SOC, V117, P462, DOI 10.1021/ja00106a053; ZABRODSKY H, 1993, J AM CHEM SOC, V115, P8278, DOI 10.1021/ja00071a042; Zabrodsky H, 1990, J VIS COMMUN IMAGE R, V1, P189; ZABRODSKY H, 1994, MAY P EUR C COMP VIS; ZABRODSKY H, 1994, OCT P INT C PATT REC, P499; ZABRODSKY H, 1993, THESIS HEBREW U JERU; [No title captured], DOI DOI 10.1145/356924.356930	39	232	247	4	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1995	17	12					1154	1166		10.1109/34.476508	http://dx.doi.org/10.1109/34.476508			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TJ275					2022-12-18	WOS:A1995TJ27500003
J	HUNTER, GM; STEIGLITZ, K				HUNTER, GM; STEIGLITZ, K			OPERATIONS ON IMAGES USING QUAD TREES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PRINCETON UNIV,DEPT ELECT ENGN & COMP SCI,PRINCETON,NJ 08540	Princeton University	HUNTER, GM (corresponding author), DECIS & DESIGNS INC,MCLEAN,VA 22101, USA.							Aho AV, 1974, DESIGN ANAL COMPUTER; HOROWITZ SL, 1976, J ACM, V23, P368, DOI 10.1145/321941.321956; HUNTER GM, 1977, COMPUT GRAPH, V2, P225, DOI 10.1016/0097-8493(77)90019-X; HUNTER GM, 1975, 182 PRINC U DEP EL E; HUNTER GM, 1978, THESIS PRINCETON U; Klinger A., 1976, COMPUT VISION GRAPH, V5, P68, DOI [10.1016/S0146-664X(76)80006-8, DOI 10.1016/S0146-664X(76)80006-8]; Knuth D., 1973, ART COMPUTER PROGRAM, V2nd; NEGROPONTE N, 1977, COMPUT GRAPH, V2, P179, DOI 10.1016/0097-8493(77)90041-3; NEWMAN WM, 1973, PRINCIPLES INTERACTI; Pavlidis T., 1976, ACM Transactions on Mathematical Software, V2, P305, DOI 10.1145/355705.355706; Tanimoto S. L., 1976, Computer Graphics and Image Processing, V5, P333, DOI 10.1016/S0146-664X(76)80012-3; TANIMOTO SL, 1977, JUN P IEEE C PATT RE, P25	12	232	243	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	2					145	153		10.1109/TPAMI.1979.4766900	http://dx.doi.org/10.1109/TPAMI.1979.4766900			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HA304	21868843				2022-12-18	WOS:A1979HA30400004
J	Caetano, TS; McAuley, JJ; Cheng, L; Le, QV; Smola, AJ				Caetano, Tiberio S.; McAuley, Julian J.; Cheng, Li; Le, Quoc V.; Smola, Alex J.			Learning Graph Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graph matching; learning; support vector machines; structured estimation; optimization	ALGORITHM; MODELS	As a fundamental problem in pattern recognition, graph matching has applications in a variety of fields, from computer vision to computational biology. In graph matching, patterns are modeled as graphs and pattern recognition amounts to finding a correspondence between the nodes of different graphs. Many formulations of this problem can be cast in general as a quadratic assignment problem, where a linear term in the objective function encodes node compatibility and a quadratic term encodes edge compatibility. The main research focus in this theme is about designing efficient algorithms for approximately solving the quadratic assignment problem since it is NP-hard. In this paper, we turn our attention to a different question: how to estimate compatibility functions such that the solution of the resulting graph matching problem best matches the expected solution that a human would manually provide. We present a method for learning graph matching: The training examples are pairs of graphs and the "labels" are matches between them. Our experimental results reveal that learning can substantially improve the performance of standard graph matching algorithms. In particular, we find that simple linear assignment with such a learning scheme outperforms Graduated Assignment with bistochastic normalization, a state-of-the-art quadratic assignment relaxation algorithm.	[Caetano, Tiberio S.; McAuley, Julian J.] NICTA, Stat Machine Learning Grp, Canberra, ACT 2601, Australia; [Caetano, Tiberio S.; McAuley, Julian J.] Australian Natl Univ, Res Sch Informat Sci & Engn, Canberra, ACT 0200, Australia; [Cheng, Li] TTI Chicago, Chicago, IL 60637 USA; [Le, Quoc V.] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA; [Smola, Alex J.] Yahoo Res, Santa Clara, CA 95051 USA	Australian National University; Australian National University; Stanford University	Caetano, TS (corresponding author), NICTA, Stat Machine Learning Grp, Locked Bag 8001, Canberra, ACT 2601, Australia.	tiberio.caetano@nicta.com.au; julian.mcauley@nicta.com.au; licheng@tti-c.org; quocle@stanford.edu; alex@smola.org	Cheng, Li/AAU-6734-2020	Cheng, Li/0000-0003-3261-3533	Australian Government's Backing Australia's Ability; Australian Research Council's ICT Centre of Excellence program	Australian Government's Backing Australia's Ability(Australian GovernmentDepartment of Industry, Innovation and Science); Australian Research Council's ICT Centre of Excellence program(Australian Research Council)	The authors thank Gideon Dror, James Petterson, and Choon Hui Teo for comments on the paper. They also thank Longbin Chen and Choon Hui Teo for code. NICTA is funded by the Australian Government's Backing Australia's Ability initiative and the Australian Research Council's ICT Centre of Excellence program.	Ahuja RK, 2001, OPER RES, V49, P771, DOI 10.1287/opre.49.5.771.10607; [Anonymous], 2002, LEARNING KERNELS; Anstreicher KM, 2003, MATH PROGRAM, V97, P27, DOI 10.1007/s10107-003-0437-z; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BONEV B, 2007, P GRAPH BAS REPR PAT, P340; Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1; BRONSTEIN AM, 2007, INT J COMPUTER VISIO; Caelli T, 2004, IEEE T PATTERN ANAL, V26, P515, DOI 10.1109/TPAMI.2004.1265866; Caetano TS, 2006, IEEE T PATTERN ANAL, V28, P1646, DOI 10.1109/TPAMI.2006.207; Caetano TS, 2004, PROC CVPR IEEE, P466; CAETANO TS, 2007, P INT C COMP VIS; Carcassoni M, 2003, PATTERN RECOGN, V36, P193, DOI 10.1016/S0031-3203(02)00054-7; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; COUR T, 2006, P C NEUR INF PROC SY; Finley T., 2008, P INT C MACH LEARN; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Griffin Gregory, 2007, CALTECH 256 OBJECT C; HANCOCK E, 2002, P JOINT INT WORKSH S, P31; JOACHIMS T, 2006, P KNOWL DISC DAT MIN; JONKER R, 1987, COMPUTING, V38, P325, DOI 10.1007/BF02278710; Kittler J., 1989, International Journal of Pattern Recognition and Artificial Intelligence, V3, P29, DOI 10.1142/S021800148900005X; LACOSTEJULIEN S, 2006, P N AM CHAPT ASS COM; Le Q. V., 2008, ADV NEURAL INFORM PR, V20, P1377; Leordeanu M., 2005, P INT C COMP VIS; LI SZ, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P866, DOI 10.1109/CVPR.1994.323915; Messmer BT, 1998, IEEE T PATTERN ANAL, V20, P493, DOI 10.1109/34.682179; Neuhaus M, 2007, INFORM SCIENCES, V177, P239, DOI 10.1016/j.ins.2006.02.013; Papadimitriou C.H., 1998, COMBINATORIAL OPTIMI, VUnabridged edition; Pelillo M, 1999, NEURAL COMPUT, V11, P1933, DOI 10.1162/089976699300016034; PELILLO M, 1994, IEEE T PATTERN ANAL, V16, P933, DOI 10.1109/34.310691; Rangarajan A, 1999, NEURAL COMPUT, V11, P1455, DOI 10.1162/089976699300016313; Rosenfeld A., 1982, DIGITAL PICTURE PROC; *SAMPL, SAMPL MOT DAT SET; Schellewald C., 2004, THESIS U MANNHEIN; SHAPIRO LS, 1992, IMAGE VISION COMPUT, V10, P283, DOI 10.1016/0262-8856(92)90043-3; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; SINKHORN R, 1964, ANN MATH STAT, V35, P876, DOI 10.1214/aoms/1177703591; Smith S. M., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P206, DOI 10.1109/ICPR.1996.546020; SMITH SM, 1992, P 3 BRIT MACH VIS C, P139; TASKAR B, 2004, P ADV NEURAL INFORM, V16; TEO C, 2007, P KNOWL DISC DAT MIN; Torsello A, 2006, IEEE T PATTERN ANAL, V28, P954, DOI 10.1109/TPAMI.2006.125; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; van Wyk MA, 2002, IEEE T PATTERN ANAL, V24, P988, DOI 10.1109/TPAMI.2002.1017624; VISHWANATHAN S, 2008, J MACHINE LEAR UNPUB; Wang HF, 2004, LECT NOTES COMPUT SC, V3138, P361; White D, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P35, DOI 10.1109/ICIAP.2007.4362754; Wilson RC, 1997, IEEE T PATTERN ANAL, V19, P634, DOI 10.1109/34.601251; MYTHOLOGICAL CREATUR	49	231	253	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2009	31	6					1048	1058		10.1109/TPAMI.2009.28	http://dx.doi.org/10.1109/TPAMI.2009.28			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431YF	19372609	Green Submitted			2022-12-18	WOS:000265100000007
J	Treibitz, T; Schechner, YY				Treibitz, Tali; Schechner, Yoav Y.			Active Polarization Descattering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; modeling and recovery of physical attributes; scene analysis-color; physics-based vision; vision in scattering media; inverse problems; polarization; image recovery	SCATTERING MEDIA; UNDERWATER VISIBILITY; LIGHT PROPAGATION; TARGET DETECTION; VISION; RECOVERY	Imaging in scattering media such as fog and water is important but challenging. Images suffer from poor visibility due to backscattering and signal attenuation. Most prior methods for scene recovery use active illumination scanners (structured and gated), which can be slow and cumbersome. On the other hand, natural illumination is inapplicable to dark environments. This paper addresses the need for a nonscanning recovery method which uses active scene irradiance. We study the formation of images under wide-field artificial illumination. Based on the formation model, this paper presents an approach for recovering the object signal. It also yields rough information about the 3D scene structure. The approach can work with compact simple hardware, having active wide-field polychromatic polarized illumination. The camera is fitted with a polarization analyzer. Two frames of the scene are instantly taken, with different states of the analyzer or light-source polarizer. A recovery algorithm follows the acquisition. It allows both the backscatter and the object reflection to be partially polarized. It thus unifies and generalizes prior polarization-based methods, which had assumed exclusive polarization of either of these components. The approach is limited to an effective range due to image noise and falloff of wide-field illumination. Thus, these limits and the noise sensitivity are analyzed. The approach particularly applies underwater. We therefore use the approach to demonstrate recovery of object signals and significant visibility enhancement in underwater field experiments.	[Treibitz, Tali; Schechner, Yoav Y.] Technion Israel Inst Technol, Dept Elect Engn, IL-3200 Haifa, Israel	Technion Israel Institute of Technology	Treibitz, T (corresponding author), Technion Israel Inst Technol, Dept Elect Engn, IL-3200 Haifa, Israel.	ttali@tx.technion.ac.il; yoav@ee.technion.ac.il		Treibitz, Tali/0000-0002-3078-282X	Taub Foundation; Alon Fellow; Israeli Science Foundation [315/04]; Ollendorff Center in the Department of Electrical Engineering, Technion; BMBF	Taub Foundation; Alon Fellow; Israeli Science Foundation(Israel Science Foundation); Ollendorff Center in the Department of Electrical Engineering, Technion; BMBF(Federal Ministry of Education & Research (BMBF))	The authors would like to thank Dori Yelin, Haim Kermany, Ben Herzberg, and, above all, Einav Namer for their help in the experimental dives. The authors would also like to thank Nadav Shashar for fruitful discussions and great help. Yoav Schechner is a Landau Fellow, supported by the Taub Foundation, and an Alon Fellow. This work was supported by the Israeli Science Foundation ( Grant 315/04) and by the Ollendorff Center in the Department of Electrical Engineering, Technion. Tali Treibitz is funded through the BMBF.	Barham P, 2000, PROCEEDINGS OF THE IEEE INTELLIGENT VEHICLES SYMPOSIUM 2000, P545, DOI 10.1109/IVS.2000.898404; Ben-Ezra M, 2000, PROC CVPR IEEE, P32, DOI 10.1109/CVPR.2000.855795; Chen T., 2007, P IEEE C COMP VIS PA; Cozman F, 1997, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.1997.609419; Cula OG, 2005, PROC CVPR IEEE, P1116; Demos SG, 1996, OPT LETT, V21, P161, DOI 10.1364/OL.21.000161; DIAMANT Y, 2008, P IEEE C COMP VIS PA; *EL TUB CTR, 1998, TLSX1008E04 EL TUB C; Farid H, 1999, J OPT SOC AM A, V16, P2136, DOI 10.1364/JOSAA.16.002136; FOURNIER GR, 1993, OPT ENG, V32, P2185, DOI 10.1117/12.143954; GIAKOS GC, 2004, P IEEE INSTR MEAS TE, V1, P430; GILBERT GD, 1967, APPL OPTICS, V6, P741, DOI 10.1364/AO.6.000741; GUPTA M, 2008, P IEEE C COMP VIS PA; Harsdorf S, 1999, P SOC PHOTO-OPT INS, V3821, P378, DOI 10.1117/12.364201; Harvey ES, 1998, MAR TECHNOL SOC J, V32, P3; Jacques SL, 2002, J BIOMED OPT, V7, P329, DOI 10.1117/1.1484498; JAFFE JS, 1990, IEEE J OCEANIC ENG, V15, P101, DOI 10.1109/48.50695; JAGGER WS, 1993, VISION RES, V33, P1755, DOI 10.1016/0042-6989(93)90166-T; Jarry G, 1998, APPL OPTICS, V37, P7357, DOI 10.1364/AO.37.007357; Kaftory R., 2007, P IEEE C COMP VIS PA, P1; Kocak DM, 2005, MAR TECHNOL SOC J, V39, P5, DOI 10.4031/002533205787442576; KOKHANOVSKY AA, 2004, LIGHT SCATTERING MED, P200; Levoy M, 2004, ACM T GRAPHIC, V23, P825, DOI 10.1145/1015706.1015806; Lewis GD, 1999, APPL OPTICS, V38, P3937, DOI 10.1364/AO.38.003937; MACKINTOSH FC, 1989, PHYS REV B, V40, P9342, DOI 10.1103/PhysRevB.40.9342; McGlamery B. L., 1979, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V208, P221; Miyazaki D, 2005, PROC CVPR IEEE, P910; Mobley C. D., 1994, LIGHT WATER RAD TRAN; Morgan SP, 2000, OPT EXPRESS, V7, P395, DOI 10.1364/OE.7.000395; Narasimhan SG, 2005, IEEE I CONF COMP VIS, P420; Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723; Nayar SK, 2006, ACM T GRAPHIC, V25, P935, DOI 10.1145/1141911.1141977; Rakovic MJ, 1999, APPL OPTICS, V38, P3399, DOI 10.1364/AO.38.003399; RATNER N, 2007, P IEEE C COMP VIS PA, P1; Sankaran V, 2002, J BIOMED OPT, V7, P300, DOI 10.1117/1.1483318; Sankaran V, 1999, OPT LETT, V24, P1044, DOI 10.1364/OL.24.001044; Schechner YY, 2007, IEEE T PATTERN ANAL, V29, P1655, DOI 10.1109/TPAMI.2007.1141; Schechner YY, 2007, IEEE T PATTERN ANAL, V29, P1339, DOI 10.1109/TPAMI.2007.1151; Schechner YY, 2005, IEEE J OCEANIC ENG, V30, P570, DOI 10.1109/JOE.2005.850871; Schechner YY, 2004, PROC CVPR IEEE, P536; Schechner YY, 2001, PROC CVPR IEEE, P325; Schechner YY, 2003, APPL OPTICS, V42, P511, DOI 10.1364/AO.42.000511; Schechner YY, 2000, J OPT SOC AM A, V17, P276, DOI 10.1364/JOSAA.17.000276; Shashar N, 2004, J EXP BIOL, V207, P3619, DOI 10.1242/jeb.01187; Shwartz S, 2005, SIGNAL PROCESS, V85, P1045, DOI 10.1016/j.sigpro.2004.11.022; Shwartz S., 1991, IEEE COMPUTER SOC C, P1984, DOI DOI 10.1109/CVPR.2006.71; STRAND MP, 1991, P SOC PHOTO-OPT INS, V1537, P151, DOI 10.1117/12.48880; Sun B, 2005, ACM T GRAPHIC, V24, P1040, DOI 10.1145/1073204.1073309; SWARTZ BA, 1991, P SOC PHOTO-OPT INS, V1537, P42, DOI 10.1117/12.49256; Treibitz T, 2006, P IEEE COMP SOC C CO; Treibitz T., 2008, P IEEE C COMP VIS PA; Tyo JS, 1996, APPL OPTICS, V35, P1855, DOI 10.1364/AO.35.001855; Wells B, 2005, LASER FOCUS WORLD, V41, pS7; Wolff LB, 1997, IMAGE VISION COMPUT, V15, P81, DOI 10.1016/S0262-8856(96)01123-7	54	231	252	12	83	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2009	31	3					385	399		10.1109/TPAMI.2008.85	http://dx.doi.org/10.1109/TPAMI.2008.85			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	394VO	19147870	Green Submitted			2022-12-18	WOS:000262480200001
J	Tong, Y; Liao, WH; Ji, Q				Tong, Yan; Liao, Wenhui; Ji, Qiang			Facial action unit recognition by exploiting their dynamic and semantic relationships	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						facial action unit recognition; facial expression analysis; facial action coding system; Bayesian networks	EXPRESSION RECOGNITION	A system that could automatically analyze the facial actions in real time has applications in a wide range of different fields. However, developing such a system is always challenging due to the richness, ambiguity, and dynamic nature of facial actions. Although a number of research groups attempt to recognize facial action units (AUs) by improving either the facial feature extraction techniques or the AU classification techniques, these methods often recognize AUs or certain AU combinations individually and statically, ignoring the semantic relationships among AUs and the dynamics of AUs. Hence, these approaches cannot always recognize AUs reliably, robustly, and consistently. In this paper, we propose a novel approach that systematically accounts for the relationships among AUs and their temporal evolutions for AU recognition. Specifically, we use a dynamic Bayesian network (DBN) to model the relationships among different AUs. The DBN provides a coherent and unified hierarchical probabilistic framework to represent probabilistic relationships among various AUs and to account for the temporal changes in facial action development. Within our system, robust computer vision techniques are used to obtain AU measurements. Such AU measurements are then applied as evidence to the DBN for inferring various AUs. The experiments show that the integration of AU relationships and AU dynamics with AU measurements yields significant improvement of AU recognition, especially for spontaneous facial expressions and under more realistic environment including illumination variation, face pose variation, and occlusion.	Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA	Rensselaer Polytechnic Institute	Tong, Y (corresponding author), Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA.	tongy2@rpi.edu; liaow@rpi.edu; jiql@rpi.edu	liao, wenhui/A-8854-2009					Bartlett MS, 2005, PROC CVPR IEEE, P568; BARTLETT MS, 2007, AUTO FACS CODING; BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037/0022-3514.37.11.2049; Bazzo JJ, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P505, DOI 10.1109/AFGR.2004.1301583; Cohen I, 2004, IEEE T PATTERN ANAL, V26, P1553, DOI 10.1109/TPAMI.2004.127; Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X; Cohn J, 1995, AM PSYCHOL SOC; Cohn JF, 2004, IEEE SYS MAN CYBERN, P610; Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905; Ekman P., 2002, FACIAL ACTION CODING; Ekman P., 2002, FACIAL ACTION CODING; ELKALIOUBY R, 2004, P IEEE INT C COMP VI; Fasel B, 2000, INT C PATT RECOG, P1100, DOI 10.1109/ICPR.2000.905664; GU H, 2004, P IEEE INT C COMP VI, V270, P870; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; Heckerman D, 1995, MSRTR9506; Huang CL, 1997, J VIS COMMUN IMAGE R, V8, P278, DOI 10.1006/jvci.1997.0359; Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611; Kapoor A, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P195; KJAERULFF U, 1995, INT J FORECASTING, V11, P89, DOI 10.1016/0169-2070(94)02003-8; Korb K.B., 2004, COM SCI DAT; Lanitis A, 1997, IEEE T PATTERN ANAL, V19, P743, DOI 10.1109/34.598231; Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406; Lien JJJ, 2000, ROBOT AUTON SYST, V31, P131, DOI 10.1016/S0921-8890(99)00103-7; Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931; Pantic M., 2005, P IEEE INT C MULT EX; Phillips PJ, 2005, PROC CVPR IEEE, P947; Scherer K., 1982, HDB METHODS NONVERBA; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SMITH E, 2001, P 8 ANN JOINT S NEUR; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; Tian YL, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P229, DOI 10.1109/AFGR.2002.1004159; Valstar M, 2004, IEEE SYS MAN CYBERN, P635; Valstar M.F., 2005, IEEE COMP SOC C COMP, DOI [10.1109/CVPR.2005.457, DOI 10.1109/CVPR.2005.457]; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang P, 2005, PROC CVPR IEEE, P373; WANG P, 2005, P IEEE INT C COMP VI, V3; Young IT, 2002, IEEE T SIGNAL PROCES, V50, P2798, DOI 10.1109/TSP.2002.804095; Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93; Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990	41	231	242	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2007	29	10					1683	1699		10.1109/TPAMI.2007.1094	http://dx.doi.org/10.1109/TPAMI.2007.1094			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	199LA	17699916	Green Submitted			2022-12-18	WOS:000248696100001
J	Kolmogorov, V; Rother, C				Kolmogorov, Vladimir; Rother, Carsten			Minimizing nonsubmodular functions with graph cuts - A review	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review						energy minimization; Markov Random Fields; quadratic pseudo-Boolean optimization; min cut/max flow; texture restoration	STATISTICAL-ANALYSIS; OPTIMIZATION; ALGORITHM	Optimization techniques based on graph cuts have become a standard tool for many vision applications. These techniques allow to minimize efficiently certain energy functions corresponding to pairwise Markov Random Fields (MRFs). Currently, there is an accepted view within the computer vision community that graph cuts can only be used for optimizing a limited class of MRF energies ( e. g., submodular functions). In this survey, we review some results that show that graph cuts can be applied to a much larger class of energy functions ( in particular, nonsubmodular functions). While these results are well-known in the optimization community, to our knowledge they were not used in the context of computer vision and MRF optimization. We demonstrate the relevance of these results to vision on the problem of binary texture restoration.	Microsoft Corp, Res, Cambridge CB3 0FB, England		Kolmogorov, V (corresponding author), UCL, Adastral Pk Campus,Adastral Pk, Martlesham Heath IP5 3RE, England.	vnk@adastral.ucl.ac.uk; carrot@microsoft.com						AGARWALA A, 2004, P ACM SIGGRAPH; Ahuja R. K., 1993, NETWORK FLOWS THEORY; ANGUELOV D, 2005, P C COMP VIS PATT R; ASPVALL B, 1982, INFORM PROCESS LETT, V14, P195, DOI 10.1016/0020-0190(82)90036-9; ASPVALL B, 1979, INFORM PROCESS LETT, V8, P121, DOI 10.1016/0020-0190(79)90002-4; Barbu A, 2005, IEEE T PATTERN ANAL, V27, P1239, DOI 10.1109/TPAMI.2005.161; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1986, J R STAT SOC B, V48, P259; BILLIONNET A, 1989, OPER RES LETT, V8, P161, DOI 10.1016/0167-6377(89)90043-6; Boros E, 2002, DISCRETE APPL MATH, V123, P155, DOI 10.1016/S0166-218X(01)00336-5; Boros E., 1991, 171991 RRR RUTCOR; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; COWELL RG, 1999, PROBABILISTIC NETWOR; CREMERS D, 2006, P EUR C COMP VIS; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gimelfarb GL, 1996, IEEE T PATTERN ANAL, V18, P1110, DOI 10.1109/34.544081; GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x; HAMMER PL, 1984, MATH PROGRAM, V28, P121, DOI 10.1007/BF02612354; HAMMER PL, 1965, OPER RES, V13, P388; Ishikawa H, 2003, IEEE T PATTERN ANAL, V25, P1333, DOI 10.1109/TPAMI.2003.1233908; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; KOLMOGOROV V, 2006, MSRTR2006100; KOLMOGOROV V, 2005, P C UNC ART INT JUL; KOVAL VK, 1976, USSR ACAD SCI AUTOMA, V8, P149; KOVTUN I, 2004, THESIS IRTC ITS NATL; KUMAR S, 2004, P 18 ANN C NEUR INF; KWATRA V, 2003, P ACM SIGGRAPH JUL; Li S., 1995, MARKOV RANDOM FIELD, P1; MUDENAGUDI U, 2006, P AS C COMP VIS; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Rother C., 2005, P C COMP VIS PATT RE; VEKSLER O, 1999, THESIS CORNELL U ITH; Wainwright M, 2004, STAT COMPUT, V14, P143, DOI 10.1023/B:STCO.0000021412.33763.d5; Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P3697, DOI 10.1109/TIT.2005.856938; Werner T., 2005, CTUCMP200525; Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420; Zhu SC, 1997, IEEE T PATTERN ANAL, V19, P1236, DOI 10.1109/34.632983	39	231	239	2	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2007	29	7					1274	1279		10.1109/TPAMI.2007.1031	http://dx.doi.org/10.1109/TPAMI.2007.1031			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	166QW	17496384				2022-12-18	WOS:000246395300014
J	Shen, FM; Xu, Y; Liu, L; Yang, Y; Huang, Z; Shen, HT				Shen, Fumin; Xu, Yan; Liu, Li; Yang, Yang; Huang, Zi; Shen, Heng Tao			Unsupervised Deep Hashing with Similarity-Adaptive and Discrete Optimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Binary codes; unsupervised deep hashing; image retrieval	BINARY-CODES; MACHINES	Recent vision and learning studies show that learning compact hash codes can facilitate massive data processing with significantly reduced storage and computation. Particularly, learning deep hash functions has greatly improved the retrieval performance, typically under the semantic supervision. In contrast, current unsupervised deep hashing algorithms can hardly achieve satisfactory performance due to either the relaxed optimization or absence of similarity-sensitive objective. In this work, we propose a simple yet effective unsupervised hashing framework, named Similarity-Adaptive Deep Hashing (SADH), which alternatingly proceeds over three training modules: deep hash model training, similarity graph updating and binary code optimization. The key difference from the widely-used two-step hashing method is that the output representations of the learned deep model help update the similarity graph matrix, which is then used to improve the subsequent code optimization. In addition, for producing high-quality binary codes, we devise an effective discrete optimization algorithm which can directly handle the binary constraints with a general hashing loss. Extensive experiments validate the efficacy of SADH, which consistently outperforms the state-of-the-arts by large gaps.	[Shen, Fumin; Xu, Yan; Yang, Yang; Shen, Heng Tao] Univ Elect Sci & Technol China, Ctr Future Media, Chengdu 611731, Sichuan, Peoples R China; [Shen, Fumin; Xu, Yan; Yang, Yang; Shen, Heng Tao] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Sichuan, Peoples R China; [Liu, Li] Univ East Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England; [Huang, Zi] Univ Queensland, Sch Informat Technol & Elect Engn, St Lucia, Qld 4072, Australia	University of Electronic Science & Technology of China; University of Electronic Science & Technology of China; University of East Anglia; University of Queensland	Shen, HT (corresponding author), Univ Elect Sci & Technol China, Ctr Future Media, Chengdu 611731, Sichuan, Peoples R China.; Shen, HT (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Sichuan, Peoples R China.	fumin.shen@gmail.com; xuyan5533@gmail.com; liuli1213@gmail.com; dlyyang@gmail.com; huang@itee.uq.edu.au; shenhengtao@hotmail.com	yang, yang/HGT-7999-2022; Shen, Heng Tao/ABD-5331-2021; yang, yang/GVT-5210-2022	HUANG, ZI/0000-0002-9738-4949	National Natural Science Foundation of China [61502081, 61572108, 61632007]; Fundamental Research Funds for the Central Universities [ZYGX2015kyqd017]; Australian Research Council [FT130101530]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Australian Research Council(Australian Research Council)	This work was supported in part by the National Natural Science Foundation of China under Project 61502081, Project 61572108, and Project 61632007, the Fundamental Research Funds for the Central Universities under Project ZYGX2015kyqd017, and Australian Research Council Project FT130101530.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2017, P CVPR; [Anonymous], 2017, P IEEE C COMP VIS PA; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Cakir F, 2015, IEEE I CONF COMP VIS, P1044, DOI 10.1109/ICCV.2015.125; Cao ZJ, 2017, IEEE I CONF COMP VIS, P5609, DOI 10.1109/ICCV.2017.598; Chua Tat-Seng, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646452; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Ge TZ, 2014, LECT NOTES COMPUT SC, V8695, P250, DOI 10.1007/978-3-319-10584-0_17; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P1344, DOI 10.1109/TIP.2017.2652730; Hu MQ, 2018, IEEE T IMAGE PROCESS, V27, P545, DOI 10.1109/TIP.2017.2749147; Jia Y., 2014, P 22 ACM INT C MULT, P675; Jiang QY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2248; Kang WC, 2016, AAAI CONF ARTIF INTE, P1230; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar S., 2007, P 7 INT JOINT C ART, P1360; Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947; Li W., 2016, INT JOINT C ARTIFICI, P1711; Li X, 2013, PROC CVPR IEEE, P2419, DOI 10.1109/CVPR.2013.313; Li XL, 2017, AAAI CONF ARTIF INTE, P2203; Lin GS, 2014, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2014.253; Lin KV, 2016, PROC CVPR IEEE, P1183, DOI 10.1109/CVPR.2016.133; Lin ZJ, 2017, IEEE T CYBERNETICS, V47, P4342, DOI 10.1109/TCYB.2016.2608906; Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862; Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227; Liu W., 2014, ADV NEURAL INFORM PR, V4, P3419; Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912; Liu W, 2011, SER INF MANAGE SCI, V10, P1; LIU XL, 2016, PROC CVPR IEEE, P5119, DOI DOI 10.1109/CVPR.2016.553; Mu YD, 2014, PROC CVPR IEEE, P979, DOI 10.1109/CVPR.2014.130; Norouzi M., 2011, INT C MACHINE LEARNI, P353; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Qin J., 2017, P IEEE C COMP VIS PA, P146; Qin J, 2017, PROC CVPR IEEE, P6728, DOI 10.1109/CVPR.2017.712; Shen FM, 2017, IEEE T MULTIMEDIA, V19, P2022, DOI 10.1109/TMM.2017.2699863; Shen FM, 2016, IEEE T IMAGE PROCESS, V25, P5610, DOI 10.1109/TIP.2016.2612883; Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598; Shen FM, 2015, IEEE T IMAGE PROCESS, V24, P1839, DOI 10.1109/TIP.2015.2405340; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134; Do TT, 2016, LECT NOTES COMPUT SC, V9909, P219, DOI 10.1007/978-3-319-46454-1_14; Tian DY, 2017, IEEE T IMAGE PROCESS, V26, P79, DOI 10.1109/TIP.2016.2617081; Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572; Wang J, 2017, IEEE INFOCOM SER, DOI 10.1007/s12083-017-0556-6; Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48; Weiss Y., 2008, NIPS, P1753; Wu B, 2016, ARXIV160407666; Xia RK, 2014, AAAI CONF ARTIF INTE, P2156; Xu H, 2011, IEEE I CONF COMP VIS, P1631, DOI 10.1109/ICCV.2011.6126424; Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345; Yang HF, 2018, IEEE T PATTERN ANAL, V40, P437, DOI 10.1109/TPAMI.2017.2666812; Yang Y, 2017, IEEE T KNOWL DATA EN, V29, P1834, DOI 10.1109/TKDE.2017.2701825; Zhang ZM, 2016, PROC CVPR IEEE, P1487, DOI 10.1109/CVPR.2016.165; Zhu X., 2013, P 21 ACM INT C MULTI, P143, DOI [10.1145/2502081.2502107, DOI 10.1145/2502081.2502107]; Zhuang BH, 2016, PROC CVPR IEEE, P5955, DOI 10.1109/CVPR.2016.641	59	230	238	5	107	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2018	40	12					3034	3044		10.1109/TPAMI.2018.2789887	http://dx.doi.org/10.1109/TPAMI.2018.2789887			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GZ4HL	29993420				2022-12-18	WOS:000449355500018
J	Liu, C; Yuen, J; Torralba, A				Liu, Ce; Yuen, Jenny; Torralba, Antonio			Nonparametric Scene Parsing via Label Transfer	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object recognition; scene parsing; label transfer; SIFT flow; Markov random fields	OBJECT; TEXTURE	While there has been a lot of recent work on object recognition and image understanding, the focus has been on carefully establishing mathematical models for images, scenes, and objects. In this paper, we propose a novel, nonparametric approach for object recognition and scene parsing using a new technology we name label transfer. For an input image, our system first retrieves its nearest neighbors from a large database containing fully annotated images. Then, the system establishes dense correspondences between the input image and each of the nearest neighbors using the dense SIFT flow algorithm [28], which aligns two images based on local image structures. Finally, based on the dense scene correspondences obtained from SIFT flow, our system warps the existing annotations and integrates multiple cues in a Markov random field framework to segment and recognize the query image. Promising experimental results have been achieved by our nonparametric scene parsing system on challenging databases. Compared to existing object recognition approaches that require training classifiers or appearance models for each object category, our system is easy to implement, has few parameters, and embeds contextual information naturally in the retrieval/alignment procedure.	[Liu, Ce] Microsoft Res New England, Cambridge, MA 02142 USA; [Liu, Ce; Yuen, Jenny; Torralba, Antonio] MIT, CSAIL, Cambridge, MA 02139 USA	Microsoft; Massachusetts Institute of Technology (MIT)	Liu, C (corresponding author), Microsoft Res New England, 1 Mem Dr, Cambridge, MA 02142 USA.	celiu@microsoft.com; jenny@csail.mit.edu; torralba@csail.mit.edu			Royal Dutch/Shell Group; NGA [NEGI-1582-04-0004]; MURI [N00014-06-1-0734]; US National Science Foundation (NSF) [IIS 0747120]; National Defense Science and Engineering Graduate Fellowship	Royal Dutch/Shell Group; NGA; MURI(MURI); US National Science Foundation (NSF)(National Science Foundation (NSF)); National Defense Science and Engineering Graduate Fellowship	Funding for this research was provided by the Royal Dutch/Shell Group, NGA NEGI-1582-04-0004, MURI Grant N00014-06-1-0734, US National Science Foundation (NSF) Career award (IIS 0747120), and a National Defense Science and Engineering Graduate Fellowship. Ce Liu wishes to thank Professor William T. Freeman and Professor Edward H. Adelson for insightful discussions.	Adelson EH, 2001, PROC SPIE, V4299, P1, DOI 10.1117/12.429489; Belongie S., 2000, P ADV NEUR INF PROC; Berg A., 2005, P IEEE C COMP VIS PA; BORG I., 2005, MODERN MULTIDIMENSIO, P207; Branson S., 2010, P EUR C COMP VIS; Choi M. J., 2010, P IEEE C COMP VIS PA; Crandall D., 2005, P IEEE C COMP VIS PA; Dalal N., 2005, HISTOGRAMS ORIENTED; Desai Chaitanya, 2009, P IEEE INT C COMP VI; Divvala S.K., 2009, P IEEE C COMP VIS PA; Efros A., 1999, P IEEE INT C COMP VI; Felzenszwalb P., 2008, P IEEE C COMP VIS PA; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Fergus R., 2003, P IEEE C COMP VIS PA; FROME A, 2006, P ADV NEUR INF PROC; GALLEGUILLOS C., 2010, P IEEE C COMP VIS PA; Grauman K, 2005, P IEEE INT C COMP VI; Gupta A., 2008, P EUR C COMP VIS; HEITZ G, 2008, P EUR C COMP VIS; HOIEM D, 2006, P IEEE C COMP VIS PA; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Liang L, 2001, ACM T GRAPHIC, V20, P127, DOI 10.1145/501786.501787; Liu C., 2009, P IEEE C COMP VIS PA; Liu C., 2008, P EUR C COMP VIS; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Murphy K., 2003, P ADV NEUR INF PROC; Nister D., 2006, P 2006 IEEE COMP SOC; OBDRZALEK S, 2005, P BRIT MACH VIS C; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Park D., 2010, P EUR C COMP VIS; Rabinovich A., 2007, P IEEE INT C COMP VI; RUSSELL B, 2007, P ADV NEUR INF PROC; Russell B.C., 2009, P ADV NEUR INF PROC; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; SAVARESE S., 2006, P IEEE C COMP VIS PA; Shakhnarovich G., 2003, P IEEE INT C COMP VI; Shechtman E, 2007, P IEEE C COMP VIS PA; Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1; Sivic J, 2003, P IEEE INT C COMP VI; Sudderth E. B., 2005, ADV NEUR INF PROC SY; Tighe J., 2010, P EUR C COMP VIS; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Turk M., 1991, P IEEE C COMP VIS PA; Viola Paul, 2001, PROC CVPR IEEE; Weber M., 2000, P EUR C COMP VIS; WINN J, 2005, P IEEE INT C COMP VI; Xiao J, 2010, P IEEE C COMP VIS PA; Yang Y., 2010, P IEEE C COMP VIS PA; [No title captured]	52	230	245	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2011	33	12					2368	2382		10.1109/TPAMI.2011.131	http://dx.doi.org/10.1109/TPAMI.2011.131			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	834RE	21709305				2022-12-18	WOS:000295980000005
J	KAUPPINEN, H; SEPPANEN, T; PIETIKAINEN, M				KAUPPINEN, H; SEPPANEN, T; PIETIKAINEN, M			AN EXPERIMENTAL COMPARISON OF AUTOREGRESSIVE AND FOURIER-BASED DESCRIPTORS IN 2D SHAPE CLASSIFICATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						SHAPE RECOGNITION; FOURIER DESCRIPTORS; AUTOREGRESSIVE MODELING; BOUNDARY MODELING	RECOGNITION; REPRESENTATION; DISCRIMINATION; MODELS	An experimental comparison of shape classification methods based on autoregressive modeling and Fourier descriptors of closed contours is carried out. The performance is evaluated using two independent sets of data: images of Letters and airplanes. Silhouette contours are extracted from non-occluded 2D objects rotated, scaled, and translated in 3D space. Several versions of both types of methods are implemented and tested systematically. The comparison clearly shows better performance of Fourier-based methods, especially for images containing noise.			KAUPPINEN, H (corresponding author), UNIV OULU,DEPT ELECT ENGN,SF-90570 OULU,FINLAND.		Rohlf, F J/A-8710-2008					Arbter K., 1989, From Pixels to Features. Proceedings of a Workshop, P153; ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206; BEBIS GN, 1992, PATTERN RECOGN, V25, P25, DOI 10.1016/0031-3203(92)90004-3; BELKASIM SO, 1991, PATTERN RECOGN, V24, P1117, DOI 10.1016/0031-3203(91)90140-Z; CHELLAPPA R, 1984, IEEE T PATTERN ANAL, V6, P102, DOI 10.1109/TPAMI.1984.4767482; DAS M, 1990, IEEE T PATTERN ANAL, V12, P97, DOI 10.1109/34.41389; DEVIJVER PA, 1982, PATTERN RECOGN, P354; DUBOIS SR, 1986, IEEE T PATTERN ANAL, V8, P55, DOI 10.1109/TPAMI.1986.4767752; EOM K, 1990, 10TH P INT C PATT RE, V1, P860; GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926; KASHYAP RL, 1981, IEEE T INFORM THEORY, V27, P627, DOI 10.1109/TIT.1981.1056390; KRZYAK A, 1989, MACH VISION APPL, P123; MITCHELL OR, 1984, OPT ENG, V23, P484, DOI 10.1117/12.7973326; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; PROKOP RJ, 1992, CVGIP-GRAPH MODEL IM, V54, P438, DOI 10.1016/1049-9652(92)90027-U; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2, P265; SEKITA I, 1992, IEEE T PATTERN ANAL, V14, P489, DOI 10.1109/34.126809; YOU Z, 1984, COMPUTER VISION GRAP, V28, P129; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	19	230	267	2	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1995	17	2					201	207		10.1109/34.368168	http://dx.doi.org/10.1109/34.368168			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE825					2022-12-18	WOS:A1995QE82500010
J	Wolf, L; Hassner, T; Taigman, Y				Wolf, Lior; Hassner, Tal; Taigman, Yaniv			Effective Unconstrained Face Recognition by Combining Multiple Descriptors and Learned Background Statistics	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face and gesture recognition; similarity measures; face recognition; image descriptors	CLASSIFICATION; FEATURES	Computer vision systems have demonstrated considerable improvement in recognizing and verifying faces in digital images. Still, recognizing faces appearing in unconstrained, natural conditions remains a challenging task. In this paper, we present a face-image, pair-matching approach primarily developed and tested on the "Labeled Faces in the Wild" (LFW) benchmark that reflects the challenges of face recognition from unconstrained images. The approach we propose makes the following contributions. 1) We present a family of novel face-image descriptors designed to capture statistics of local patch similarities. 2) We demonstrate how unlabeled background samples may be used to better evaluate image similarities. To this end, we describe a number of novel, effective similarity measures. 3) We show how labeled background samples, when available, may further improve classification performance, by employing a unique pair-matching pipeline. We present state-of-the-art results on the LFW pair-matching benchmarks. In addition, we show our system to be well suited for multilabel face classification (recognition) problem, on both the LFW images and on images from the laboratory controlled multi-PIE database.	[Wolf, Lior] Tel Aviv Univ, Blavatnik Sch Comp Sci, IL-69978 Tel Aviv, Israel; [Hassner, Tal] Open Univ Israel, Div Comp Sci, IL-43107 Raanana, Israel; [Taigman, Yaniv] Tel Aviv Univ, Sch Comp Sci, IL-65202 Tel Aviv, Israel; [Taigman, Yaniv] Face Com, IL-65202 Tel Aviv, Israel	Tel Aviv University; Open University Israel; Tel Aviv University	Wolf, L (corresponding author), Tel Aviv Univ, Blavatnik Sch Comp Sci, Schreiber Bldg,Room 103,POB 39040, IL-69978 Tel Aviv, Israel.	wolf@cs.tau.ac.il; hassner@openu.ac.il; yaniv@face.com			Israel Science Foundation [1214/06]; Ministry of Science and Technology Russia-Israel Scientific Research Cooperation	Israel Science Foundation(Israel Science Foundation); Ministry of Science and Technology Russia-Israel Scientific Research Cooperation	The authors are grateful to face.com for providing the face alignment system. Lior Wolf is supported by the Israel Science Foundation (Grant No. 1214/06) and The Ministry of Science and Technology Russia-Israel Scientific Research Cooperation. Parts of this manuscript have been published in [1], [2], [3], [4].	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; BARHILLEL A, 2003, P INT C MACH LEARN; Bart E, 2005, P BRIT MACH VIS C; Belongie S, 2001, ADV NEUR IN, V13, P831; BILENKO M, 2004, P INT C MACH LEARN; BORDES A, 2005, P EUR C MACH LEARN; Brand M, 2006, LINEAR ALGEBRA APPL, V415, P20, DOI 10.1016/j.laa.2005.07.021; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; Chapelle O., 2006, IEEE T NEURAL NETW, V20, P542; CHECHIK G, 2002, ADV NEURAL INFORM PR, P857; CRISTIANINI N, 2002, P NEUR INF PROC SYST; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; EBERT S, 2010, P EUR C COMP VIS; Edelman S., 1999, REPRESENTATION RECOG; EVERINGHAM M, 2008, P EUR C COMP VIS; FINK M, 2004, P NEUR INF PROC SYST; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Guillaumin M., 2009, P IEEE INT C COMP VI; Hastie T, 2009, ELEMENTS STAT LEARNI; Heikkila M, 2006, LECT NOTES COMPUT SC, V4338, P58; Huang G. B., 2008, P FAC REAL LIF IM WO; Huang G.B., 2008, WORKSHOP FACESREAL L; Huang G. B., 2007, P IEEE INT C COMP VI; Jain P., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587841; JAIN P, 2007, TR0748 U TEX; Joachims T., 2003, P 20 INT C MACH LEAR, P290, DOI DOI 10.1145/2612669.2612699; Kumar N., 2009, P IEEE INT C COMP VI; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; LIU W, 2008, P 10 EUR C COMP VIS, P358; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Meyers E, 2008, INT J COMPUT VISION, V76, P93, DOI 10.1007/s11263-007-0058-8; NOWAK E, 2007, P IEEE C COMP VIS PA; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Ojala T., 2001, Advances in Pattern Recognition - ICAPR 2001. Second International Conference. Proceedings (Lecture Notes in Computer Science Vol.2013), P397; Phillips P.J., 2007, 7408 NISTIR; Phillips PJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P15; Phillips PJ, 2005, PROC CVPR IEEE, P947; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Pinto N., 2009, P IEEE C COMP VIS PA; Quattoni A., 2008, P IEEE C COMP VIS PA; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819; ROSCHANI M, 2009, EVALUATION LOCAL DES; Shechtman E, 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383198; SHENTAL N, 2002, P EUR C COMP VIS; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Taigman Y., 2009, P BRIT MACH VIS C SE; Tan X., 2007, P INT C AN MOD FAC G; ULLMAN S, 2000, P BMCV 00, P73; WEINBERGER K, 2006, P NEUR INF PROC SYST; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; WOLF L, 2009, P AS C COMP VIS SEPT; Wolf L., 2008, P FACES REAL LIFE IM; Wolf L, 2009, P IEEE INT C COMP VI; WOLF L, 2006, P 9 EUR C COMP VIS, P481, DOI DOI 10.1007/11744047_37; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; XING E, 2003, P NEUR INF PROC SYST; ZHANG H, 2006, P IEEE CS C COMP VIS; 2011, LFW RESULTS	61	229	237	2	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2011	33	10					1978	1990		10.1109/TPAMI.2010.230	http://dx.doi.org/10.1109/TPAMI.2010.230			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	808HQ	21173442				2022-12-18	WOS:000293969000006
J	SETHI, IK; JAIN, R				SETHI, IK; JAIN, R			FINDING TRAJECTORIES OF FEATURE POINTS IN A MONOCULAR IMAGE SEQUENCE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MICHIGAN,DEPT ELECT ENGN & COMP SCI,ANN ARBOR,MI 48109	University of Michigan System; University of Michigan	SETHI, IK (corresponding author), WAYNE STATE UNIV,DEPT COMP SCI,DETROIT,MI 48202, USA.			Sethi, Ishwar/0000-0002-2578-111X				BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BRADY M, 1983, ARTIF INTELL, V21, P271, DOI 10.1016/S0004-3702(83)80013-7; DONNER J, 1984, J EXPT PSYCHOL HUMAN, V10, P1; DRESCHLER L, 1982, COMPUT VISION GRAPH, V20, P199, DOI 10.1016/0146-664X(82)90081-8; FLINCHBAUGH BE, 1981, ARTIF INTELL, V17, P387, DOI 10.1016/0004-3702(81)90030-8; Gibson J., 1979, ECOLOGICAL APPROACH; HAYNES SM, 1ST P C AI APPL, P251; HILDRETH EC, 1984, ARTIF INTELL, V23, P309, DOI 10.1016/0004-3702(84)90018-3; HOFFMAN D, 1980, MIT AI608 MEM; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; JAIN R, 1979, IEEE T PATTERN ANAL, V1, P206, DOI 10.1109/TPAMI.1979.4766907; JAIN R, 1983, IEEE T PATTERN ANAL, V5, P58, DOI 10.1109/TPAMI.1983.4767345; JAIN R, 1982, IEEE COMPUT      AUG; Jenkin M.R.M., 1983, P WORKSHOP MOTION RE, P66; JERIAN CP, 1983, APR P WORKSH MOT REP; JOHANSSON G, 1976, PSYCHOL RES-PSYCH FO, V38, P379, DOI 10.1007/BF00309043; MARR D, 1976, PHILOS T R SOC B, V275, P483, DOI 10.1098/rstb.1976.0090; MUTCH KM, 1985, IEEE T PATTERN ANAL, V7, P133, DOI 10.1109/TPAMI.1985.4767638; Neisser U., 1976, COGNITION REALITY; OBRIEN NG, 1984, P WORKSHOP COMPUT VI; OROURKE J, 1980, IEEE T PATTERN ANAL, V2, P522, DOI 10.1109/TPAMI.1980.6447699; PRAGER JM, 1983, COMPUT VISION GRAPH, V24, P271, DOI 10.1016/0734-189X(83)90057-9; PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077; RAMACHANDRAN VS, 1984, VISION RES, V23, P83; RASHID RF, 1980, IEEE T PATTERN ANAL, V2, P574, DOI 10.1109/TPAMI.1980.6447705; RIEGER JH, 1983, P ACM INTERDISCIPLIN, P33; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; SETHI IK, 1983, DETERMINING 3 DIMENS; SHAH MA, 1984, COMPUT VISION GRAPH, V28, P345, DOI 10.1016/S0734-189X(84)80012-2; SHAW GL, 1982, PERCEPTION, V11, P491, DOI 10.1068/p110491; TODD JT, 1982, J EXP PSYCHOL HUMAN, V8, P238, DOI 10.1037/0096-1523.8.2.238; Tsai R. Y., 1982, Proceedings of PRIP 82. IEEE Computer Society Conference on Pattern Recognition and Image Processing, P112; TSAI RY, 1981, P PRIP, P94; TSAI RY, IEEE T ACOUST SPEECH, V30, P525; TSOTSOS JK, 1980, CSRG114 U TOR DEP CO; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WAXMAN AM, 1984, P WORKSHOP COMPUT VI; WEBB JA, 1982, ARTIF INTELL, V19, P107, DOI 10.1016/0004-3702(82)90023-6; WILLIAMS TD, 1980, IEEE T PATTERN ANAL, V2, P511, DOI 10.1109/TPAMI.1980.6447697; YACHIDA M, 1981, IEEE T PATTERN ANAL, V3, P12, DOI 10.1109/TPAMI.1981.4767046	40	229	257	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1987	9	1					56	73		10.1109/TPAMI.1987.4767872	http://dx.doi.org/10.1109/TPAMI.1987.4767872			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	F3785	21869377				2022-12-18	WOS:A1987F378500005
J	Zhang, Z; Tao, DC				Zhang, Zhang; Tao, Dacheng			Slow Feature Analysis for Human Action Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human action recognition; slow feature analysis	FACE RECOGNITION; POINTS	Slow Feature Analysis (SFA) extracts slowly varying features from a quickly varying input signal [1]. It has been successfully applied to modeling the visual receptive fields of the cortical neurons. Sufficient experimental results in neuroscience suggest that the temporal slowness principle is a general learning principle in visual perception. In this paper, we introduce the SFA framework to the problem of human action recognition by incorporating the discriminative information with SFA learning and considering the spatial relationship of body parts. In particular, we consider four kinds of SFA learning strategies, including the original unsupervised SFA (U-SFA), the supervised SFA (S-SFA), the discriminative SFA (D-SFA), and the spatial discriminative SFA (SD-SFA), to extract slow feature functions from a large amount of training cuboids which are obtained by random sampling in motion boundaries. Afterward, to represent action sequences, the squared first order temporal derivatives are accumulated over all transformed cuboids into one feature vector, which is termed the Accumulated Squared Derivative (ASD) feature. The ASD feature encodes the statistical distribution of slow features in an action sequence. Finally, a linear support vector machine (SVM) is trained to classify actions represented by ASD features. We conduct extensive experiments, including two sets of control experiments, two sets of large scale experiments on the KTH and Weizmann databases, and two sets of experiments on the CASIA and UT-interaction databases, to demonstrate the effectiveness of SFA for human action recognition. Experimental results suggest that the SFA-based approach 1) is able to extract useful motion patterns and improves the recognition performance, 2) requires less intermediate processing steps but achieves comparable or even better performance, and 3) has good potential to recognize complex multiperson activities.	[Zhang, Zhang] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100864, Peoples R China; [Tao, Dacheng] Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, Fac Engn & Informat Technol, Sydney, NSW 2007, Australia	Chinese Academy of Sciences; Institute of Automation, CAS; University of Technology Sydney	Zhang, Z (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100864, Peoples R China.	zzhang@nlpr.ia.ac.cn; dacheng.tao@uts.edu.au	Tao, Dacheng/A-5449-2012		Australian ARC [ARC DP-120103730]; National Natural Science Foundation of China [60875021, 60723005]; NLPR [NLPRZY-2]; National Hi-Tech R&D Program of China [2009AA01Z318]; National Key Technology R&D Program of China [2011BAH11B01]	Australian ARC; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); NLPR; National Hi-Tech R&D Program of China(National High Technology Research and Development Program of China); National Key Technology R&D Program of China(National Key Technology R&D Program)	The authors would like to thank the anonymous reviewers and the handling associate editor for their insightful comments and also thank Dr. P. Dollar for his kind supply of the codes for spatiotemporal cuboid detection. This work is supported in part by the Australian ARC discovery project (ARC DP-120103730), the National Natural Science Foundation of China (Grant Nos. 60875021, 60723005), NLPR (2008 NLPRZY-2), National Hi-Tech R&D Program of China (2009AA01Z318), and National Key Technology R&D Program of China (2011BAH11B01).	Ali S., 2007, P IEEE INT C COMP VI; [Anonymous], 2010, CASIA ACTION DATABAS; Berkes P, 2005, J VISION, V5, P579, DOI 10.1167/5.6.9; Berkes P, 2006, NEURAL COMPUT, V18, P1868, DOI 10.1162/neco.2006.18.8.1868; Bishop, 1995, NEURAL NETWORKS PATT; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Bregonzio M., 2009, P IEEE INT C COMP VI; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chennubhotla C., 2001, P INT WORKSH STAT CO; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Franzius M, 2008, LECT NOTES COMPUT SC, V5163, P961, DOI 10.1007/978-3-540-87536-9_98; Franzius M, 2007, PLOS COMPUT BIOL, V3, P1605, DOI 10.1371/journal.pcbi.0030166; Giese MA, 2003, NAT REV NEUROSCI, V4, P179, DOI 10.1038/nrn1057; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649; Hoyer P.O., 2003, COMPUTATIONAL NEUROS; JHUANG H, 2007, P IEEE INT C COMP VI; Kadir T., 2003, International Conference on Visual Information Engineering (VIE 2003) (IEE Conf. Publ.No.495), P25, DOI 10.1049/cp:20030478; Ke Y, 2005, IEEE I CONF COMP VIS, P166; Klaser Alexander, 2008, BMVC; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Laptev I, 2006, LECT NOTES COMPUT SC, V3667, P91; Lee WT, 2009, PROC CVPR IEEE, P1590, DOI 10.1109/CVPRW.2009.5206521; Liu J., 2008, P IEEE INT C COMP VI; Mairal J., 2008, P IEEE INT C COMP VI; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Rapantzikos K, 2009, PROC CVPR IEEE, P1454, DOI 10.1109/CVPRW.2009.5206525; Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361; Ryoo M. S., 2010, OVERVIEW CONTEST SEM; Savarese S, 2008, 2008 IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING, P119; Schindler K., 2008, P IEEE INT C COMP VI; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Scovanner P., 2007, ACM MM, P357; Shang L, 2005, PROC CVPR IEEE, P1017; Shastri BJ, 2007, MACH VISION APPL, V18, P107, DOI 10.1007/s00138-006-0052-0; Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594; Wang Heng, 2009, BMVC, P1; Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1762, DOI 10.1109/TPAMI.2009.43; Weinland D., 2008, CVPR 2008, P1, DOI DOI 10.1109/CVPR.2008.4587731; Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938; Wong S., 2007, P IEEE INT C COMP VI; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Zhang ZM, 2008, LECT NOTES COMPUT SC, V5305, P817, DOI 10.1007/978-3-540-88693-8_60	48	228	248	1	91	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2012	34	3					436	450		10.1109/TPAMI.2011.157	http://dx.doi.org/10.1109/TPAMI.2011.157			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	880CH	21808089	Green Submitted			2022-12-18	WOS:000299381600002
J	Pan, ZH; Healey, G; Prasad, M; Tromberg, B				Pan, ZH; Healey, G; Prasad, M; Tromberg, B			Face recognition in hyperspectral images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face recognition; hyperspectral	COLOR	Hyperspectral cameras provide useful discriminants for human face recognition that cannot be obtained by other imaging methods. We examine the utility of using near-infrared hyperspectral images for the recognition of faces over a database of 200 subjects. The hyperspectral images were collected using a CCD camera equipped with a liquid crystal tunable filter to provide 31 bands over the near-infrared (0.7mum-1.0mum). Spectral measurements over the near-infrared allow the sensing of subsurface tissue structure which is significantly different from person to person, but relatively stable over time. The local spectral properties of human tissue are nearly invariant to face orientation and expression which allows hyperspectral discriminants to be used for recognition over a large range of poses and expressions. We describe a face recognition algorithm that exploits spectral measurements for multiple facial tissue types. We demonstrate experimentally that this algorithm can be used to recognize faces over time in the presence of changes in facial pose and expression.	Univ Calif Irvine, Comp Vis Lab, Dept Elect Engn & Comp Sci, Irvine, CA 92697 USA; Univ Calif Irvine, Beckman Laser Inst & Med Clin, Laser Microbeam & Med Program, Irvine, CA 92612 USA	University of California System; University of California Irvine; University of California System; University of California Irvine	Pan, ZH (corresponding author), Univ Calif Irvine, Comp Vis Lab, Dept Elect Engn & Comp Sci, Irvine, CA 92697 USA.	zpan@ece.uci.edu; healey@ece.uci.edu; mprasad@ece.uci.edu; tromberg@bli.uci.edu		Pan, Zhihong/0000-0003-0866-762X				ANDERSON RR, 1981, J INVEST DERMATOL, V77, P13, DOI 10.1111/1523-1747.ep12479191; Angelopoulou E, 2001, PROC CVPR IEEE, P635; Bargo Paulo R., 2001, PLEN TALK INT PHOT A; Blanz V, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P202, DOI 10.1109/AFGR.2002.1004155; Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Edwards EA, 1939, AM J ANAT, V65, P1, DOI 10.1002/aja.1000650102; Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724; GAT N, 2000, P SPIE C ALG MULT HY, V6; GROSS R, 2001, CMURITR0117; GROSS R, 2002, CMURITR0220; Healey G, 1999, IEEE T GEOSCI REMOTE, V37, P2706, DOI 10.1109/36.803418; HEALEY G, 2000, SPECTRAL IMAGING INS, V3920; HIRAOKA M, 1993, PHYS MED BIOL, V38, P1859, DOI 10.1088/0031-9155/38/12/011; Martinez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Siegel R., 1981, THERMAL RAD HEAT TRA; SOCOLINSKY D, 2002, P ITN C PATT REC; Socolinsky DA, 2001, PROC CVPR IEEE, P527; STORRING M, 1999, P 7 S INT ROB SYST J; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; Tsumura N, 1999, J OPT SOC AM A, V16, P2169, DOI 10.1364/JOSAA.16.002169; Tuchin V.V., 2000, TISSUE OPTICS LIGHT, VTT38; VANGEMERT MJC, 1989, IEEE T BIO-MED ENG, V36, P1146, DOI 10.1109/10.42108; Wilder J, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P182, DOI 10.1109/AFGR.1996.557262; WILDER J, 1994, ARTIFICIAL NEURAL NE, P520; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235	29	228	245	4	44	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2003	25	12					1552	1560		10.1109/TPAMI.2003.1251148	http://dx.doi.org/10.1109/TPAMI.2003.1251148			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	746UA		Green Submitted			2022-12-18	WOS:000186765000005
J	Kegl, B; Krzyzak, A; Linder, T; Zeger, K				Kegl, B; Krzyzak, A; Linder, T; Zeger, K			Learning and design of principal curves	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						learning systems; unsupervised learning; feature extraction; vector quantization; curve fitting; piecewise linear approximation		Principal curves have been defined as "self-consistent" smooth curves which pass through the "middle" of a d-dimensional probability distribution or data cloud. They give a summary of the data and also serve as an efficient feature extraction tool. We take a new approach by defining principal curves as continuous curves of a given length which minimize the expected squared distance between the curve and points of the space randomly chosen according to a given distribution. The new definition makes it possible to theoretically analyze principal curve learning from training data and it also leads to a new practical construction. Our theoretical learning scheme chooses a curve from a class of polygonal lines with k segments and with a given total length to minimize the average squared distance over n training points drawn independently. Convergence properties of this learning scheme are analyzed and a practical version of this theoretical algorithm is implemented. In each iteration of the algorithm, a new Vertex is added to the polygonal line and the positions of the vertices are updated so that they minimize a penalized squared distance criterion. Simulation results demonstrate that the new algorithm compares favorably with previous methods, both in terms of performance and computational complexity, and is more robust to varying data models.	Queens Univ, Dept Math & Stat, Kingston, ON K7L 3N6, Canada; Concordia Univ, Dept Comp Sci, Montreal, PQ H3G 1M8, Canada; Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA	Queens University - Canada; Concordia University - Canada; University of California System; University of California San Diego	Kegl, B (corresponding author), Queens Univ, Dept Math & Stat, Kingston, ON K7L 3N6, Canada.	kegl@mast.queensu.ca; krzyzak@cs.concordia.ca; linder@mast.queensu.ca; zeger@ucsd.edu						Ash R.B., 1972, REAL ANAL PROBABILIT; BANFIELD JD, 1992, J AM STAT ASSOC, V87, P7, DOI 10.2307/2290446; CHANG K, 1998, P IEEE INT JOINT C N, P695; Chang KY, 1998, P SOC PHOTO-OPT INS, V3307, P120, DOI 10.1117/12.304651; CLEVELAND WS, 1979, J AM STAT ASSOC, V74, P829, DOI 10.2307/2286407; DELICADO P, 1998, 309 U POMP FABR DEP; DUCHAMP T, 1996, ROBUST STAT DATA ANA, V109, P135; GERSHO A, 1992, VECTOR QUANTIZATIOND; Grother PJ, 1995, HANDPRINTED FORMS CH, P10; Hartigan J.A., 1975, CLUSTERING ALGORITHM; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; Hastie T., 1984, THESIS STANFORD U; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; KEGL B, 1999, THESIS CONCORIDA U M; Kolmogorov A. N., 1975, INTRO REAL ANAL; Kolmogorov A. N., 1961, AM MATH SOC TRANSL, V17, P277; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; MULIER F, 1995, NEURAL COMPUT, V7, P1165, DOI 10.1162/neco.1995.7.6.1165; Reinhard K., 1998, P I ACOUST, V20, P53; Singh R, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P121, DOI 10.1109/ACV.1998.732868; SUZUKI S, 1986, P 8 INT C PATT REC, P289; TARPEY T, 1995, ANN STAT, V23, P103, DOI 10.1214/aos/1176324457; Tibshirani R., 1992, Statistics and Computing, V2, P183, DOI 10.1007/BF01889678; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd	25	228	254	2	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2000	22	3					281	297		10.1109/34.841759	http://dx.doi.org/10.1109/34.841759			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	306EJ		Green Submitted			2022-12-18	WOS:000086584100006
J	Bylinskii, Z; Judd, T; Oliva, A; Torralba, A; Durand, F				Bylinskii, Zoya; Judd, Tilke; Oliva, Aude; Torralba, Antonio; Durand, Fredo			What Do Different Evaluation Metrics Tell Us About Saliency Models?	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Saliency models; evaluation metrics; benchmarks; fixation maps; saliency applications	VISUAL-ATTENTION; IMAGE RETRIEVAL; EYE-MOVEMENTS; LOCALIZATION; ALLOCATION; FOVEATION; SELECTION; SCENE; GAZE	How best to evaluate a saliency model's ability to predict where humans look in images is an open research question. The choice of evaluation metric depends on how saliency is defined and how the ground truth is represented. Metrics differ in how they rank saliency models, and this results from how false positives and false negatives are treated, whether viewing biases are accounted for, whether spatial deviations are factored in, and how the saliency maps are pre-processed. In this paper, we provide an analysis of 8 different evaluation metrics and their properties. With the help of systematic experiments and visualizations of metric computations, we add interpretability to saliency scores and more transparency to the evaluation of saliency models. Building off the differences in metric properties and behaviors, we make recommendations for metric selections under specific assumptions and for specific applications.	[Bylinskii, Zoya; Oliva, Aude; Torralba, Antonio; Durand, Fredo] MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Judd, Tilke] Google, Zurich, Switzerland	Massachusetts Institute of Technology (MIT); Google Incorporated	Bylinskii, Z (corresponding author), MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	zoya@csail.mit.edu; tilke.judd@gmail.com; oliva@csail.mit.edu; torralba@csail.mit.edu; fredo@csail.mit.edu			postgraduate scholarship (PGS-D) from the Natural Sciences and Engineering Research Council of Canada; Toyota Research Institute / MIT CSAIL Joint Research Center	postgraduate scholarship (PGS-D) from the Natural Sciences and Engineering Research Council of Canada; Toyota Research Institute / MIT CSAIL Joint Research Center	The authors would like to thank Matthias Kummerer and other attendees of the saliency tutorial at ECCV 2016 for helpful discussions about saliency evaluation. 7 Thank you also to the anonymous reviewers for many detailed suggestions. ZB was supported by a postgraduate scholarship (PGS-D) from the Natural Sciences and Engineering Research Council of Canada. Support to AO, AT, and FD was provided by the Toyota Research Institute / MIT CSAIL Joint Research Center.	Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66; Achanta R, 2009, IEEE IMAGE PROC, P1005, DOI 10.1109/ICIP.2009.5413815; Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; [Anonymous], 2006, P IEEE C COMP VIS PA; Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461; Bindemann M, 2010, VISION RES, V50, P2577, DOI 10.1016/j.visres.2010.08.016; Borji A, 2013, IEEE I CONF COMP VIS, P921, DOI 10.1109/ICCV.2013.118; Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727; Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89; Bruce NDB, 2015, VISION RES, V116, P95, DOI 10.1016/j.visres.2015.01.010; Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5; Bylinskii Z, 2015, VISION RES, V116, P258, DOI 10.1016/j.visres.2015.04.007; Bylinskii Z., 2014, MIT SALIENCY BENCHMA; Bylinskii Z, 2016, LECT NOTES COMPUT SC, V9909, P809, DOI 10.1007/978-3-319-46454-1_49; Canosa RL, 2003, P SOC PHOTO-OPT INS, V5007, P240, DOI 10.1117/12.477375; Chang CK, 2010, IEEE INT C INT ROBOT, P4147, DOI 10.1109/IROS.2010.5649136; Clarke ADF, 2014, VISION RES, V102, P41, DOI 10.1016/j.visres.2014.06.016; Dantzig G., 1951, ACTIVITY ANAL PRODUC, P359; DeCarlo D, 2002, ACM T GRAPHIC, V21, P769, DOI 10.1145/566570.566650; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Einhauser W, 2008, J VISION, V8, DOI 10.1167/8.2.2; Einhauser W, 2003, EUR J NEUROSCI, V17, P1089, DOI 10.1046/j.1460-9568.2003.02508.x; Emami M, 2013, IMAGE VISION COMPUT, V31, P796, DOI 10.1016/j.imavis.2013.08.004; Engelke U, 2013, IEEE T IMAGE PROCESS, V22, P1121, DOI 10.1109/TIP.2012.2227767; Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Frintrop S, 2007, LECT NOTES ARTIF INT, V4840, P417; Frintrop S, 2010, IEEE INT CONF ROBOT, P4531, DOI 10.1109/ROBOT.2010.5509638; Geisler WS, 1998, P SOC PHOTO-OPT INS, V3299, P294, DOI 10.1117/12.320120; Goferman S, 2010, COMPUT GRAPH FORUM, V29, P459, DOI 10.1111/j.1467-8659.2009.01615.x; Green DM, 1966, SIGNAL DETECTION THE; Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657; ITTI L, 2009, VISION RES, V49, P1295, DOI DOI 10.1016/J.VISRES.2008.09.007; Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710; Judd T., 2012, MIT CSAIL TR; Judd T, 2011, J VISION, V11, DOI 10.1167/11.4.14; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Judd Tilke, 2011, THESIS; Kim Y, 2006, IEEE T VIS COMPUT GR, V12, P925, DOI 10.1109/TVCG.2006.174; Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499; KOCH C, 1985, HUM NEUROBIOL, V4, P219; Kummerer M, 2015, P NATL ACAD SCI USA, V112, P16054, DOI 10.1073/pnas.1510393112; Kummerer M., 2014, ARXIV14097686; Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86; Le Meur O, 2007, VISION RES, V47, P2483, DOI 10.1016/j.visres.2007.06.015; Le Meur O, 2013, BEHAV RES METHODS, V45, P251, DOI 10.3758/s13428-012-0226-9; Li J, 2015, IEEE I CONF COMP VIS, P190, DOI 10.1109/ICCV.2015.30; Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147; Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047; Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045; Longhurst P., 2006, P 4 INT C COMP GRAPH, P21; Lopez-Garcia F., 2011, OBJECT RECOGNIT, V4, P185; Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410; Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467; Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39; Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4; Parkhurst DJ, 2003, SPATIAL VISION, V16, P125, DOI 10.1163/15685680360511645; Pele O, 2008, LECT NOTES COMPUT SC, V5304, P495, DOI 10.1007/978-3-540-88690-7_37; Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019; Pont-Tuset J, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481406; Princeton Vision Group NUS VIP Lab and Bethge Lab, 2016, TECHNICAL REPORT; Renninger LW, 2004, P ADV NEUR INF PROC, P1121; Riche N, 2013, IEEE I CONF COMP VIS, P1153, DOI 10.1109/ICCV.2013.147; Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Rubner Yossi, 2001, PERCEPTUAL METRICS I; Santella A., 2006, Conference on Human Factors in Computing Systems. CHI2006, P771; Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15; Sinha A. K., 2013, IJCT, V4, P821; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Suh B, 2003, P 16 ANN ACM S USER, P95, DOI [10.1145/964696.964707, DOI 10.1145/964696.964707]; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4; Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017; Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766; Tseng PH, 2009, J VISION, V9, DOI 10.1167/9.7.4; Vasconcelos N, 2004, IEEE T INFORM THEORY, V50, P1482, DOI 10.1109/TIT.2004.830760; Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001; Wang D, 2011, VISUAL COMPUT, V27, P853, DOI 10.1007/s00371-011-0559-x; Wang Jingdong, 2006, 2006 IEEE COMP SOC C, V1, P347; Wang Z, 2003, IEEE T IMAGE PROCESS, V12, P243, DOI 10.1109/TIP.2003.809015; Wilming N, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0024038; Wloka C., 2013, J VISION, V13, P239; Yun KW, 2013, PROC CVPR IEEE, P739, DOI 10.1109/CVPR.2013.101; Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32; Zhao Q, 2011, J VISION, V11, DOI 10.1167/11.3.9; Zhou Bolei, 2014, ADV NEURAL INFORM PR, P7, DOI DOI 10.5555/2968826.2968881; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	88	227	230	6	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2019	41	3					740	757		10.1109/TPAMI.2018.2815601	http://dx.doi.org/10.1109/TPAMI.2018.2815601			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HK7LA	29993800	Green Submitted, Green Published			2022-12-18	WOS:000458168800016
J	Kruger, N; Janssen, P; Kalkan, S; Lappe, M; Leonardis, A; Piater, J; Rodriguez-Sanchez, AJ; Wiskott, L				Kruger, Norbert; Janssen, Peter; Kalkan, Sinan; Lappe, Markus; Leonardis, Ales; Piater, Justus; Rodriguez-Sanchez, Antonio J.; Wiskott, Laurenz			Deep Hierarchies in the Primate Visual Cortex: What Can We Learn for Computer Vision?	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; deep hierarchies; biological modeling	INFERIOR TEMPORAL CORTEX; ANTERIOR INTRAPARIETAL AREA; VERGENCE EYE-MOVEMENTS; PARIETAL CORTEX; RECEPTIVE-FIELDS; INFEROTEMPORAL CORTEX; BINOCULAR DISPARITY; SURFACE ORIENTATION; 3-DIMENSIONAL SHAPE; OBJECT RECOGNITION	Computational modeling of the primate visual system yields insights of potential relevance to some of the challenges that computer vision is facing, such as object recognition and categorization, motion detection and activity recognition, or vision-based navigation and manipulation. This paper reviews some functional principles and structures that are generally thought to underlie the primate visual cortex, and attempts to extract biological principles that could further advance computer vision research. Organized for a computer vision audience, we present functional principles of the processing hierarchies present in the primate visual system considering recent discoveries in neurophysiology. The hierarchical processing in the primate visual system is characterized by a sequence of different levels of processing (on the order of 10) that constitute a deep hierarchy in contrast to the flat vision architectures predominantly used in today's mainstream computer vision. We hope that the functional description of the deep hierarchies realized in the primate visual system provides valuable insights for the design of computer vision algorithms, fostering increasingly productive interaction between biological and computer vision research.	[Kruger, Norbert] Univ Southern Denmark, Maersk Mc Kinney Moller Inst, DK-5230 Odense M, Denmark; [Janssen, Peter] Katholieke Univ Leuven, Div Neurophysiol, Lab Neuro & Psychofysiol, B-3000 Louvain, Belgium; [Kalkan, Sinan] Middle E Tech Univ, Dept Comp Engn, TR-06531 Ankara, Turkey; [Lappe, Markus] Univ Munster, Inst Psychol, D-48149 Munster, Germany; [Leonardis, Ales] Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana 61000, Slovenia; [Leonardis, Ales] Univ Birmingham, Sch Comp Sci, Ctr Computat Neurosci & Cognit Robot, Birmingham B15 2TT, W Midlands, England; [Piater, Justus; Rodriguez-Sanchez, Antonio J.] Univ Innsbruck, Intelligent & Interact Syst Grp, A-6020 Innsbruck, Tirol, Austria; [Wiskott, Laurenz] Ruhr Univ Bochum, Inst Neuroinformat, D-44780 Bochum, Germany	University of Southern Denmark; KU Leuven; Middle East Technical University; University of Munster; University of Ljubljana; University of Birmingham; University of Innsbruck; Ruhr University Bochum	Kruger, N (corresponding author), Univ Southern Denmark, Maersk Mc Kinney Moller Inst, DK-5230 Odense M, Denmark.	norbert@mmmi.sdu.dk	KALKAN, Sinan/AAC-3625-2019; Kalkan, Sinan/A-4843-2016; Kruger, Norbert/P-6315-2015; Wiskott, Laurenz/P-7715-2017	Kruger, Norbert/0000-0002-3931-116X; Wiskott, Laurenz/0000-0001-6237-740X; Kalkan, Sinan/0000-0003-0915-5917	EU [FP7-ICT-270273]	EU(European Commission)	This work has been funded by the EU project Xperience (FP7-ICT-270273). The authors would also like to thank Michael D'Zmura for fruitful discussions.	Amit Y, 1999, NEURAL COMPUT, V11, P1691, DOI 10.1162/089976699300016197; Amit Y., 2002, 2D OBJECT DETECTION; Andersen R. A., 2000, NEW COGNITIVE NEUROS, P515; ANDERSEN RA, 1983, J NEUROSCI, V3, P532; Anzai A, 2011, J NEUROSCI, V31, P10270, DOI 10.1523/JNEUROSCI.5956-10.2011; Bazzani L, 2011, P 28 INT C MACH LEAR, P937; BECKER S, 1992, NATURE, V355, P161, DOI 10.1038/355161a0; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Berkes P, 2005, J VISION, V5, P579, DOI 10.1167/5.6.9; Bisley JW, 2010, ANNU REV NEUROSCI, V33, P1, DOI 10.1146/annurev-neuro-060909-152823; Borra E, 2008, CEREB CORTEX, V18, P1094, DOI 10.1093/cercor/bhm146; BOWMAKER JK, 1980, J PHYSIOL-LONDON, V298, P501, DOI 10.1113/jphysiol.1980.sp013097; Bradley DC, 1998, NATURE, V392, P714, DOI 10.1038/33688; Bremmer F, 1999, ANN NY ACAD SCI, V871, P272, DOI 10.1111/j.1749-6632.1999.tb09191.x; Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603; BRUNSWIK E, 1953, AM J PSYCHOL, V66, P20, DOI 10.2307/1417965; Calow D, 2005, NETWORK-COMP NEURAL, V16, P323, DOI 10.1080/09548980600563962; Carandini M, 2012, NAT REV NEUROSCI, V13, P51, DOI 10.1038/nrn3136; Caywood MS, 2004, J NEUROPHYSIOL, V91, P2859, DOI 10.1152/jn.00775.2003; Colby CL, 1999, ANNU REV NEUROSCI, V22, P319, DOI 10.1146/annurev.neuro.22.1.319; Conway BR, 2007, NEURON, V56, P560, DOI 10.1016/j.neuron.2007.10.008; Conway BR, 2009, NEUROSCIENTIST, V15, P274, DOI 10.1177/1073858408331369; Conway BR, 2001, J NEUROSCI, V21, P2768, DOI 10.1523/JNEUROSCI.21-08-02768.2001; Cui H, 2007, NEURON, V56, P552, DOI 10.1016/j.neuron.2007.09.031; Cumming BG, 1997, NATURE, V389, P280, DOI 10.1038/38487; Cumming BG, 1999, J NEUROSCI, V19, P5602; CURCIO CA, 1990, J COMP NEUROL, V300, P5, DOI 10.1002/cne.903000103; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; DeAngelis GC, 1998, NATURE, V394, P677, DOI 10.1038/29299; DiCarlo JJ, 2007, TRENDS COGN SCI, V11, P333, DOI 10.1016/j.tics.2007.06.010; Dickinson S., 2009, OBJECT CATEGORIZATIO, P1; Dong Y, 2008, J VISION, V8, DOI 10.1167/8.7.30; DUFFY CJ, 1991, J NEUROPHYSIOL, V65, P1346, DOI 10.1152/jn.1991.65.6.1346; DUHAMEL JR, 1992, SCIENCE, V255, P90, DOI 10.1126/science.1553535; Duhamel JR, 1997, NATURE, V389, P845, DOI 10.1038/39865; DURSTELER MR, 1988, J NEUROPHYSIOL, V60, P940, DOI 10.1152/jn.1988.60.3.940; Einhauser W, 2002, EUR J NEUROSCI, V15, P475, DOI 10.1046/j.0953-816x.2001.01885.x; Elder JH, 1999, INT J COMPUT VISION, V34, P97, DOI 10.1023/A:1008183703117; Engel AK, 1997, CEREB CORTEX, V7, P571, DOI 10.1093/cercor/7.6.571; ERICKSON RG, 1991, EXP BRAIN RES, V86, P608; Ettinger G.J., 1987, TECHNICAL REPORT; Fang F, 2009, J NEUROSCI, V29, P460, DOI 10.1523/JNEUROSCI.4628-08.2009; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; Fidler S., 2008, P IEEE INT C COMP VI; Finlayson GD, 2001, J OPT SOC AM A, V18, P253, DOI 10.1364/JOSAA.18.000253; Finn IM, 2007, J NEUROSCI, V27, P9638, DOI 10.1523/JNEUROSCI.2119-07.2007; Fleet DJ, 1996, VISION RES, V36, P1839, DOI 10.1016/0042-6989(95)00313-4; FLEET DJ, 1991, CVGIP-IMAG UNDERSTAN, V53, P198, DOI 10.1016/1049-9660(91)90027-M; Franzius M, 2011, NEURAL COMPUT, V23, P2289, DOI 10.1162/NECO_a_00171; Freedman DJ, 2006, NATURE, V443, P85, DOI 10.1038/nature05078; Freedman DJ, 2001, SCIENCE, V291, P312, DOI 10.1126/science.291.5502.312; FUKUSHIMA K, 1983, IEEE T SYST MAN CYB, V13, P826, DOI 10.1109/TSMC.1983.6313076; Gail A, 2006, J NEUROSCI, V26, P9376, DOI 10.1523/JNEUROSCI.1570-06.2006; GALLESE V, 1994, NEUROREPORT, V5, P1525, DOI 10.1097/00001756-199407000-00029; GALLETTI C, 1990, EXP BRAIN RES, V82, P67; Gauthier I, 2000, NAT NEUROSCI, V3, P191, DOI 10.1038/72140; Geman S, 2002, Q APPL MATH, V60, P707, DOI 10.1090/qam/1939008; Geman S., 1999, P 11 SCAND C IM AN; GIBSON JJ, 1950, AM J PSYCHOL, V63, P367, DOI 10.2307/1418003; Gilbert CD, 2012, NEURON, V75, P250, DOI 10.1016/j.neuron.2012.06.030; Godecke I, 1996, NATURE, V379, P251, DOI 10.1038/379251a0; GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8; Gottlieb JP, 1998, NATURE, V391, P481, DOI 10.1038/35135; Gould E, 1999, SCIENCE, V286, P548, DOI 10.1126/science.286.5439.548; Gu Y, 2006, J NEUROSCI, V26, P73, DOI 10.1523/JNEUROSCI.2356-05.2006; HAWKEN MJ, 1987, PROC R SOC SER B-BIO, V231, P251, DOI 10.1098/rspb.1987.0044; Hawkins J, 2004, INTELLIGENCE; Helmholtz H. von., 1866, HDB PHYSL OPTIC; Hinkle DA, 2002, NAT NEUROSCI, V5, P665, DOI 10.1038/nn875; HOWARD IP, 2002, SEEING DEPTH, V1; HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215, DOI 10.1113/jphysiol.1968.sp008455; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837; Hung CP, 2005, SCIENCE, V310, P863, DOI 10.1126/science.1117593; ITO M, 1995, J NEUROPHYSIOL, V73, P218, DOI 10.1152/jn.1995.73.1.218; Janssen P, 2000, NEURON, V27, P385, DOI 10.1016/S0896-6273(00)00045-3; Janssen P, 2005, NAT NEUROSCI, V8, P234, DOI 10.1038/nn1386; Janssen P, 2000, SCIENCE, V288, P2054, DOI 10.1126/science.288.5473.2054; Janssen P, 2003, NEURON, V37, P693, DOI 10.1016/S0896-6273(03)00023-0; Janssen P, 2001, J NEUROSCI, V21, P9419, DOI 10.1523/JNEUROSCI.21-23-09419.2001; Janssen P, 1999, P NATL ACAD SCI USA, V96, P8217, DOI 10.1073/pnas.96.14.8217; JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233; Julesz B., 1971, FDN CYCLOPEAN PERCEP; Kandel E.R., 2000, PRINCIPLES NEURAL SC; Kanwisher N, 1997, J NEUROSCI, V17, P4302; Katsuyama N, 2010, NEUROSCIENCE, V167, P1, DOI 10.1016/j.neuroscience.2010.01.028; KELLMAN P, 1998, CRADLE KNOWLEDGE; Kiani R, 2007, J NEUROPHYSIOL, V97, P4296, DOI 10.1152/jn.00024.2007; Koch Christof, 1999, P1; Koteles K, 2008, EUR J NEUROSCI, V27, P466, DOI 10.1111/j.1460-9568.2007.06008.x; Koffka K., 1955, PRINCIPLES GESTALT P; Konig P, 2006, BIOL CYBERN, V94, P325, DOI [10.1007/s00422-006-0050-3, 10.1007/S00422-006-0050-3]; Kourtzi Z, 2006, CURR OPIN NEUROBIOL, V16, P152, DOI 10.1016/j.conb.2006.03.012; Krauzlis R J, 1994, J Comput Neurosci, V1, P265, DOI 10.1007/BF00961876; Kremers J, 2005, PRIMATE VISUAL SYSTEM: A COMPARATIVE APPROACH, P1; Krug K, 2004, J NEUROPHYSIOL, V92, P1586, DOI 10.1152/jn.00851.2003; Krug K, 2011, J NEUROSCI, V31, P17892, DOI 10.1523/JNEUROSCI.2658-11.2011; Lamme VAF, 1998, NATURE, V396, P362, DOI 10.1038/24608; Lappe M, 1996, NEURAL COMPUT, V8, P1449, DOI 10.1162/neco.1996.8.7.1449; Lappe M, 1996, J NEUROSCI, V16, P6265; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Lewis JW, 2000, J COMP NEUROL, V428, P112, DOI 10.1002/1096-9861(20001204)428:1<112::AID-CNE8>3.0.CO;2-9; Li N, 2010, NEURON, V67, P1062, DOI 10.1016/j.neuron.2010.08.029; Li S., 2011, CEREBRAL CO IN PRESS; Livingstone MS, 2001, NEURON, V30, P781, DOI 10.1016/S0896-6273(01)00313-0; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; Marr D., 1977, VISION COMPUTATIONAL; Masson GS, 1997, NATURE, V389, P283, DOI 10.1038/38496; Matsumora T, 2008, J NEUROPHYSIOL, V100, P3361, DOI 10.1152/jn.90551.2008; MAUNSELL JHR, 1983, J NEUROPHYSIOL, V49, P1127, DOI 10.1152/jn.1983.49.5.1127; Mayhew SD, 2012, J NEUROSCI, V32, P775, DOI 10.1523/JNEUROSCI.2033-11.2012; Mel BW, 1998, J NEUROSCI, V18, P4325; Mel BW, 2000, NEURAL COMPUT, V12, P731, DOI 10.1162/089976600300015574; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Movshon JA, 1996, J NEUROSCI, V16, P7733; Movshon JA, 1985, STUDY GROUP PATTERN, P117, DOI [DOI 10.1007/978-3-662-09224-8_7., DOI 10.1007/978-3-662-09224-8_]; Mruczek REB, 2007, J NEUROSCI, V27, P2825, DOI 10.1523/JNEUROSCI.4102-06.2007; Murata A, 2000, J NEUROPHYSIOL, V83, P2580, DOI 10.1152/jn.2000.83.5.2580; Nakamura H, 2001, J NEUROSCI, V21, P8174, DOI 10.1523/JNEUROSCI.21-20-08174.2001; NEWSOME WT, 1988, J NEUROPHYSIOL, V60, P604, DOI 10.1152/jn.1988.60.2.604; Nguyenkim JD, 2003, J NEUROSCI, V23, P7117, DOI 10.1523/JNEUROSCI.23-18-07117.2003; Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; OMMER B, 2007, P IEEE C COMP VIS PA; Orban GA, 2008, PHYSIOL REV, V88, P59, DOI 10.1152/physrev.00008.2007; Pack CC, 2003, NEURON, V39, P671, DOI 10.1016/S0896-6273(03)00439-2; Pack CC, 2001, NATURE, V409, P1040, DOI 10.1038/35059085; Parker AJ, 2007, NAT REV NEUROSCI, V8, P379, DOI 10.1038/nrn2131; Pasupathy A, 1999, J NEUROPHYSIOL, V82, P2490, DOI 10.1152/jn.1999.82.5.2490; Pekel M, 1996, NEUROREPORT, V7, P884, DOI 10.1097/00001756-199603220-00010; Perrone JA, 2001, NAT NEUROSCI, V4, P526, DOI 10.1038/87480; Pesaran B, 2008, NATURE, V453, P406, DOI 10.1038/nature06849; Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019; Platt ML, 1999, NATURE, V400, P233, DOI 10.1038/22268; Pouget A, 1997, J COGNITIVE NEUROSCI, V9, P222, DOI 10.1162/jocn.1997.9.2.222; Pugeault N, 2010, INT J HUM ROBOT, V7, P379, DOI 10.1142/S0219843610002209; Quiroga RQ, 2007, J NEUROPHYSIOL, V98, P1997, DOI 10.1152/jn.00125.2007; Raiguel S, 2006, J NEUROSCI, V26, P6589, DOI 10.1523/JNEUROSCI.0457-06.2006; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819; ROCKLAND KS, 1997, CEREBRAL CORTEX EXTR, V12; Rodriguez-Sanchez A. J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P4321, DOI 10.1109/CVPR.2011.5995671; Rodriguez-Sanchez AJ, 2007, INT J NEURAL SYST, V17, P275, DOI 10.1142/S0129065707001135; Rodriguez-Sanchez AJ, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0042058; Roelfsema PR, 1998, Z NATURFORSCH C, V53, P691; Rolls E., 2000, SOC NEUR ABSTR, V26, P1331; ROY JP, 1992, J NEUROSCI, V12, P2478; Rust NC, 2004, NEUROCOMPUTING, V58, P793, DOI 10.1016/j.neucom.2004.01.128; Rutishauser U, 2011, NEURAL COMPUT, V23, P735, DOI 10.1162/NECO_a_00091; Sakata H, 1997, TRENDS NEUROSCI, V20, P350, DOI 10.1016/S0166-2236(97)01067-9; SALZMAN CD, 1990, NATURE, V346, P174, DOI 10.1038/346174a0; Scalzo F., 2005, P IEEE WORKSH LEARN; Schendan HE, 2007, NEUROIMAGE, V35, P1264, DOI 10.1016/j.neuroimage.2007.01.012; Schoups A, 2001, NATURE, V412, P549, DOI 10.1038/35087601; Sereno AB, 1998, NATURE, V395, P500, DOI 10.1038/26752; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Serre T, 2010, COMMUN ACM, V53, P54, DOI 10.1145/1831407.1831425; Shadlen MN, 1996, P NATL ACAD SCI USA, V93, P628, DOI 10.1073/pnas.93.2.628; Shadlen MN, 1999, NEURON, V24, P67, DOI 10.1016/S0896-6273(00)80822-3; Shapley R, 2011, VISION RES, V51, P701, DOI 10.1016/j.visres.2011.02.012; Shi X., 2011, COMP VIS PATT REC WO, P1, DOI DOI 10.1109/ITAP.2011.6006407; Shikata E, 1996, NEUROREPORT, V7, P2389, DOI 10.1097/00001756-199610020-00022; Simoncelli EP, 2003, CURR OPIN NEUROBIOL, V13, P144, DOI 10.1016/S0959-4388(03)00047-3; Simoncelli EP, 1998, VISION RES, V38, P743, DOI 10.1016/S0042-6989(97)00183-1; Singer W, 2001, ANN NY ACAD SCI, V929, P123; SPITZER H, 1985, J NEUROPHYSIOL, V53, P1266, DOI 10.1152/jn.1985.53.5.1266; Srivastava S, 2009, J NEUROSCI, V29, P10613, DOI 10.1523/JNEUROSCI.6016-08.2009; Swaminathan SK, 2012, NAT NEUROSCI, V15, P315, DOI 10.1038/nn.3016; Taira M, 2000, J NEUROPHYSIOL, V83, P3140, DOI 10.1152/jn.2000.83.5.3140; Takemura A, 2001, J NEUROPHYSIOL, V85, P2245, DOI 10.1152/jn.2001.85.5.2245; Tanabe S, 2004, J NEUROSCI, V24, P8170, DOI 10.1523/JNEUROSCI.5292-03.2004; Tanaka K, 1996, ANNU REV NEUROSCI, V19, P109, DOI 10.1146/annurev.ne.19.030196.000545; TANAKA K, 1993, SCIENCE, V262, P685, DOI 10.1126/science.8235589; TANAKA K, 1989, J NEUROPHYSIOL, V62, P626, DOI 10.1152/jn.1989.62.3.626; TANAKA K, 1991, J NEUROPHYSIOL, V66, P170, DOI 10.1152/jn.1991.66.1.170; Tanigawa H, 2010, NAT NEUROSCI, V13, P1542, DOI 10.1038/nn.2676; Tenenbaum JB, 2011, SCIENCE, V331, P1279, DOI 10.1126/science.1192788; Theunissen FE, 2001, NETWORK-COMP NEURAL, V12, P289, DOI 10.1088/0954-898X/12/3/304; Theys T, 2012, J NEUROPHYSIOL, V107, P995, DOI 10.1152/jn.00248.2011; Thier P, 1996, P NATL ACAD SCI USA, V93, P4962, DOI 10.1073/pnas.93.10.4962; Thomas OM, 2002, NAT NEUROSCI, V5, P472, DOI 10.1038/nn837; Tompa T, 2010, BRAIN RES REV, V62, P165, DOI 10.1016/j.brainresrev.2009.10.001; Tootell RBH, 2004, CEREB CORTEX, V14, P353, DOI 10.1093/cercor/bhh001; TOVEE MJ, 1994, J NEUROPHYSIOL, V72, P1049, DOI 10.1152/jn.1994.72.3.1049; TREISMAN A, 1982, COGNITIVE PSYCHOL, V14, P107, DOI 10.1016/0010-0285(82)90006-8; Treisman A, 1996, CURR OPIN NEUROBIOL, V6, P171, DOI 10.1016/S0959-4388(96)80070-5; Tsao DY, 2003, NEURON, V39, P555, DOI 10.1016/S0896-6273(03)00459-8; TSOTSOS JK, 1990, BEHAV BRAIN SCI, V13, P423, DOI 10.1017/S0140525X00079577; Tsutsui KI, 2002, SCIENCE, V298, P409, DOI 10.1126/science.1074128; Uka T, 2006, J NEUROSCI, V26, P6791, DOI 10.1523/JNEUROSCI.5435-05.2006; Ullman S., 2006, CATEGORY LEVEL OBJEC; Ungerleider LG, 1982, ANAL VISUAL BEHAV, P549; van den Boomen C., 2012, FRONT PSYCHIAT, V16; van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P2315, DOI 10.1098/rspb.1998.0577; van Hemmen JL., 2006, PROBLEMS SYSTEMS NEU, P322, DOI [10.1093/acprof:oso/9780195148220.003.0016, DOI 10.1093/ACPROF:OSO/9780195148220.003.0016]; Verhoef BE, 2012, NEURON, V73, P171, DOI 10.1016/j.neuron.2011.10.031; Verhoef BE, 2010, CURR BIOL, V20, P909, DOI 10.1016/j.cub.2010.03.058; Vogels R, 1999, EUR J NEUROSCI, V11, P1239, DOI 10.1046/j.1460-9568.1999.00531.x; Wagemans J., PSYCHOL B IN PRESS; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; Wolfe J. M., 1998, ATTENTION; Xu F, 1996, COGNITIVE PSYCHOL, V30, P111, DOI 10.1006/cogp.1996.0005; Zeki S, 1999, P NATL ACAD SCI USA, V96, P14124, DOI 10.1073/pnas.96.24.14124; Zhou H, 2000, J NEUROSCI, V20, P6594, DOI 10.1523/JNEUROSCI.20-17-06594.2000; ZIPSER D, 1988, NATURE, V331, P679, DOI 10.1038/331679a0	207	227	231	47	298	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2013	35	8					1847	1871		10.1109/TPAMI.2012.272	http://dx.doi.org/10.1109/TPAMI.2012.272			25	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	164AP	23787340	Green Published			2022-12-18	WOS:000320381400004
J	Kulis, B; Grauman, K				Kulis, Brian; Grauman, Kristen			Kernelized Locality-Sensitive Hashing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Similarity search; locality-sensitive hashing; central limit theorem; Kernel methods; image search	FEATURES; TEXTURE; OBJECT	Fast retrieval methods are critical for many large-scale and data-driven vision applications. Recent work has explored ways to embed high-dimensional features or complex distance functions into a low-dimensional Hamming space where items can be efficiently searched. However, existing methods do not apply for high-dimensional kernelized data when the underlying feature embedding for the kernel is unknown. We show how to generalize locality-sensitive hashing to accommodate arbitrary kernel functions, making it possible to preserve the algorithm's sublinear time similarity search guarantees for a wide class of useful similarity functions. Since a number of successful image-based kernels have unknown or incomputable embeddings, this is especially valuable for image retrieval tasks. We validate our technique on several data sets, and show that it enables accurate and fast performance for several vision problems, including example-based object classification, local feature matching, and content-based retrieval.	[Kulis, Brian] Ohio State Univ, Comp Sci & Engn Dept, Columbus, OH 43210 USA; [Grauman, Kristen] Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA	University System of Ohio; Ohio State University; University of Texas System; University of Texas Austin	Kulis, B (corresponding author), Ohio State Univ, Comp Sci & Engn Dept, 395 Dreese Labs, Columbus, OH 43210 USA.	kulis@cse.ohio-state.edu; grauman@cs.utexas.edu			US National Science Foundation (NSF) [IIS-0747356]; Henry Luce Foundation	US National Science Foundation (NSF)(National Science Foundation (NSF)); Henry Luce Foundation	The authors thank the anonymous reviewers for helpful comments. They thank Rob Fergus, Antonio Torralba, and Bill Freeman for the Tiny Image data, and Yong Jae Lee for the Flickr data. This research was supported in part by US National Science Foundation (NSF) CAREER award IIS-0747356 and the Henry Luce Foundation.	ANDERSON TW, 1952, ANN MATH STAT, V23, P193, DOI 10.1214/aoms/1177729437; Andoni A., 2009, THESIS MIT; [Anonymous], 2008, P IEEE C COMP VIS PA; ATHITSOS V, 2004, P IEEE C COMP VIS PA; Balcan MF, 2006, MACH LEARN, V65, P79, DOI 10.1007/s10994-006-7550-1; BEIS J, 1997, P IEEE C COMP VIS PA; Broder A., 1997, P COMPR COMPL SEQ; CHARIKAR M, 2002, P ACM S THEOR COMP; Chum Ondrej, 2008, P BRIT MACH VIS C, P1; Ciaccia P., 1997, P INT C VER LARG DAT; Datar M., 2004, P S COMP GEOM; Davis J.V., 2007, P INT C MACH LEARN; Fei-Fei L., 2004, P WORKSH GEN MOD BAS; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Goemans MX, 1995, J ACM, V42, P1115, DOI 10.1145/227683.227684; GRAUMAN K, 2007, P IEEE C COMP VIS PA; Grauman K, 2005, P IEEE INT C COMP VI; HOFFMANNJORGENSEN J, 1976, ANN PROBAB, V4, P587, DOI 10.1214/aop/1176996029; Hua G, 2007, P IEEE INT C COMP VI; Indyk P, 1998, P 30 S THEOR COMP; Jain P., 2008, P IEEE C COMP VIS PA; Kulis B., 2009, P IEEE INT C COMP VI; Kulis B., 2009, NIPS; Kulis B, 2009, IEEE T PATTERN ANAL, V31, P2143, DOI 10.1109/TPAMI.2009.151; Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95; LING H, 2007, P IEEE INT C COMP VI; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Nister D., 2006, P 2006 IEEE COMP SOC; OBDRZALEK S, 2005, P BRIT MACH VIS C; Raginsky M, 2009, P ADV NEUR INF PROC; Rahimi A., 2007, P ADV NEUR INF PROC; Renninger LW, 2004, VISION RES, V44, P2301, DOI 10.1016/j.visres.2004.04.006; Rice J. A, 2001, MATH STAT DATA ANAL; Salakhutdinov R., 2007, P INT ACM SIGIR C RE; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shakhnarovich G., 2003, P IEEE INT C COMP VI; Snavely N., 2006, P SIGGR; Torralba A., 2008, P IEEE C COMP VIS PA; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; VARMA M, 2007, P IEEE INT C COMP VI; WEISS Y, 2009, ADV NEUR INF PROC SY; Yang J, 2005, PATTERN RECOGN, V38, P1784, DOI 10.1016/j.patcog.2005.01.023; ZHANG H, 2006, P IEEE C COMP VIS PA; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4	48	227	247	0	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2012	34	6					1092	1104		10.1109/TPAMI.2011.219	http://dx.doi.org/10.1109/TPAMI.2011.219			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	927OE	22064796				2022-12-18	WOS:000302916600005
J	Rao, S; Tron, R; Vidal, R; Ma, Y				Rao, Shankar; Tron, Roberto; Vidal, Rene; Ma, Yi			Motion Segmentation in the Presence of Outlying, Incomplete, or Corrupted Trajectories	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Motion segmentation; subspace separation; lossy compression; incomplete data; error correction; sparse representation; matrix rank minimization	FACTORIZATION	In this paper, we study the problem of segmenting tracked feature point trajectories of multiple moving objects in an image sequence. Using the affine camera model, this problem can be cast as the problem of segmenting samples drawn from multiple linear subspaces. In practice, due to limitations of the tracker, occlusions, and the presence of nonrigid objects in the scene, the obtained motion trajectories may contain grossly mistracked features, missing entries, or corrupted entries. In this paper, we develop a robust subspace separation scheme that deals with these practical issues in a unified mathematical framework. Our methods draw strong connections between lossy compression, rank minimization, and sparse representation. We test our methods extensively on the Hopkins155 motion segmentation database and other motion sequences with outliers and missing data. We compare the performance of our methods to state-of-the-art motion segmentation methods based on expectation-maximization and spectral clustering. For data without outliers or missing information, the results of our methods are on par with the state-of-the-art results and, in many cases, exceed them. In addition, our methods give surprisingly good performance in the presence of the three types of pathological trajectories mentioned above. All code and results are publicly available at http://perception.csl.uiuc.edu/coding/motion/.	[Rao, Shankar] HRL Labs LLC, Malibu, CA 90265 USA; [Tron, Roberto; Vidal, Rene] Johns Hopkins Univ, Dept Biomed Engn, Ctr Imaging Sci, Baltimore, MD 21218 USA; [Ma, Yi] Microsoft Res Asia, Beijing Sigma Ctr, Beijing 100190, Peoples R China; [Ma, Yi] Univ Illinois, Dept Elect & Comp Engn, Coordinated Sci Lab, Urbana, IL 61801 USA	HRL Laboratories; Johns Hopkins University; Microsoft; Microsoft Research Asia; University of Illinois System; University of Illinois Urbana-Champaign	Rao, S (corresponding author), HRL Labs LLC, 3011 Malibu Canyon Rd, Malibu, CA 90265 USA.	srrao@hrl.com; tron@cis.jhu.edu; rvidal@cis.jhu.edu; yima@illinois.edu	Vidal, Rene/A-3367-2010	Tron, Roberto/0000-0002-6676-8595	US National Science Foundation (NSF) [CRS-EHS-0509151, CCF-TF-0514955, N00014-05-1-0633, IIS 07-03756, IIS-0447739, EHS-0509101, N00014-05-10836, APL-934652]	US National Science Foundation (NSF)(National Science Foundation (NSF))	This work is partially supported by US National Science Foundation (NSF) grants CRS-EHS-0509151, NSF CCF-TF-0514955, ONR YIP N00014-05-1-0633, NSF IIS 07-03756, NSF CAREER IIS-0447739, NSF EHS-0509101, and ONR N00014-05-10836, and by contract JHU APL-934652.	Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554; Candes E, 2005, ANN IEEE SYMP FOUND, P295; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Candes Emmanuel J, 2009, FDN COMPUTATIONAL MA; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; Datar M., 2004, P ACM S COMP GEOM; De la Torre F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P362, DOI 10.1109/ICCV.2001.937541; Donoho DL, 2009, J AM MATH SOC, V22, P1; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Fan ZM, 2006, IEEE T PATTERN ANAL, V28, P91, DOI 10.1109/TPAMI.2006.16; Fazel M, 2003, P AMER CONTR CONF, P2156, DOI 10.1109/acc.2003.1243393; Gear CW, 1998, INT J COMPUT VISION, V29, P133, DOI 10.1023/A:1008026310903; Grant M., 2007, CVX MATLAB SOFTWARE; GRUBER A, 2004, P IEEE C COMP VIS PA, V1, P769; HARTLEY R, 2003, P AUSTR JAP ADV WORK; Ichimura N., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P600, DOI 10.1109/ICCV.1999.791279; Kanatani K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P586, DOI 10.1109/ICCV.2001.937679; KANATANI K, 2005, P AUSTR JAP ADV WORK, P23601; Ke QF, 2005, PROC CVPR IEEE, P739; Ma Y, 2007, IEEE T PATTERN ANAL, V29, P1546, DOI 10.1109/TP'AMI.2007.1085; Recht B., 2007, SIAM REV; Schindler K, 2008, INT J COMPUT VISION, V79, P159, DOI 10.1007/s11263-007-0111-7; Torr PHS, 1998, PHILOS T R SOC A, V356, P1321, DOI 10.1098/rsta.1998.0224; Tron R, 2007, PROC CVPR IEEE, P41, DOI 10.1109/cvpr.2007.382974; Vandenberghe L, 1996, SIAM REV, V38, P49, DOI 10.1137/1038003; Vidal R, 2005, IEEE T PATTERN ANAL, V27, P1945, DOI 10.1109/TPAMI.2005.244; Vidal R, 2008, INT J COMPUT VISION, V79, P85, DOI 10.1007/s11263-007-0099-z; WRIGHT J, 2008, IEEE T INFORM THEORY, P23601; Wright J, 2009, SIAM J IMAGING SCI, V2, P367, DOI 10.1137/070707312; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yan JY, 2006, LECT NOTES COMPUT SC, V3954, P94; YANG AY, 2006, P IEEE COMP VIS PATT, P23601; Zelnik-Manor L, 2003, PROC CVPR IEEE, P287	33	227	237	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2010	32	10					1832	1845		10.1109/TPAMI.2009.191	http://dx.doi.org/10.1109/TPAMI.2009.191			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	639US	20724760				2022-12-18	WOS:000281000700009
J	Yan, P; Bowyer, KW				Yan, Ping; Bowyer, Kevin W.			Biometric recognition using 3D ear shape	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						biometrics; ear biometrics; 3D shape; skin detection; curvature estimation; active contour; iterative closest point	REGISTRATION; SNAKES	Previous works have shown that the ear is a promising candidate for biometric identification. However, in prior work, the preprocessing of ear images has had manual steps and algorithms have not necessarily handled problems caused by hair and earrings. We present a complete system for ear biometrics, including automated segmentation of the ear in a profile view image and 3D shape matching for recognition. We evaluated this system with the largest experimental study to date in ear biometrics, achieving a rank-one recognition rate of 97.8 percent for an identification scenario and an equal error rate of 1.2 percent for a verification scenario on a database of 415 subjects and 1,386 total probes.	Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA	University of Notre Dame	Yan, P (corresponding author), Univ Notre Dame, Dept Comp Sci & Engn, 384 Fitzpatrick Hall, Notre Dame, IN 46556 USA.	pyan@cse.nd.edu; kwb@cse.nd.edu		Bowyer, Kevin/0000-0002-7562-4390				BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BESL PJ, 1986, COMPUT VISION GRAPH, V33, P33, DOI 10.1016/0734-189X(86)90220-3; Bhanu B, 2003, P WORKSH MULT US AUT, P91; Burge M, 2000, INT C PATT RECOG, P822, DOI 10.1109/ICPR.2000.906202; Chang K, 2003, IEEE T PATTERN ANAL, V25, P1160, DOI 10.1109/TPAMI.2003.1227990; Chen H, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P123; Chen H, 2004, INT C PATT RECOG, P574, DOI 10.1109/ICPR.2004.1334594; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Choras M., 2005, ELECT LETT COMPUTER, V5, P84, DOI DOI 10.5565/REV/ELCVIA.108; Choras M, 2006, LECT NOTES COMPUT SC, V4069, P58; CREMERS D, 2002, THESIS U MANNHEIM GE; Flynn P. J., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P261, DOI 10.1109/CVPR.1988.196246; Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242; Hurley D., 2002, IMAGE VISION COMPUT, V20, P429; Hurley DJ, 2005, COMPUT VIS IMAGE UND, V98, P491, DOI 10.1016/j.cviu.2004.11.001; Iannarelli A., 1989, EAR IDENTIFICATION; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F; Messer K., 1999, AUDIO VIDEO BASED BI, P72; Moreno B., 1999, Proceedings IEEE 33rd Annual 1999 International Carnahan Conference on Security Technology (Cat. No.99CH36303), P469, DOI 10.1109/CCST.1999.797956; Pulli K., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P160, DOI 10.1109/IM.1999.805346; Pun KH, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P164, DOI 10.1109/AFGR.2004.1301525; Shum HY, 1997, IEEE T PATTERN ANAL, V19, P1366, DOI 10.1109/34.643895; Victor B, 2002, INT C PATT RECOG, P429, DOI 10.1109/ICPR.2002.1044746; Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186; YAN P, 2005, P IEEE COMP SOC C CO, P41; YAN P, 2005, P IEEE C COMP VIS PA, P121; Yuizono T, 2002, IEEE C EVOL COMPUTAT, P237, DOI 10.1109/CEC.2002.1006240; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149	30	227	246	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2007	29	8					1297	1308		10.1109/TPAMI.2007.1067	http://dx.doi.org/10.1109/TPAMI.2007.1067			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	177XT	17568136				2022-12-18	WOS:000247186500001
J	Chen, YX; Wang, JZ				Chen, YX; Wang, JZ			A region-based fuzzy feature matching approach to content-based image retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						content-based image retrieval; image classification; similarity measure; fuzzified region features; fuzzy data analysis	CLASSIFICATION; SEGMENTATION; SIMILARITY; COLOR	This paper proposes a fuzzy logic approach, UFM(unified feature matching), for region-basedimage retrieval. In our retrieval system, an image is represented by a set of segmented regions, each of which is characterized by a fuzzy feature (fuzzy set) reflecting color, texture, and shape properties. As a result, an image is associated with a family of fuzzy features corresponding to regions. Fuzzy features naturally characterize the gradual transition between regions (blurry boundaries) within an image and incorporate the segmentation-related uncertainties into the retrieval algorithm. The resemblance of two images is then defined as the overall similarity between two families of fuzzy features and quantified by asimilarity measure, UFM measure, which integrates properties of all the regions in the images. Compared with similarity measures based on individual regions and on all regions with crisp-valued feature representations, the UFM measure greatly reduces the influence of inaccurate segmentation and provides a very intuitive quantification. The UFM has been implemented as a part of our experimental SIMPLIcity image retrieval system. The performance of the system is illustrated using examples from an image database of about 60,000 general-purpose images.	Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA; Penn State Univ, Sch Informat Sci & Technol, University Pk, PA 16802 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park	Chen, YX (corresponding author), Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA.	yixchen@cse.psu.edu; jwang@ist.psu.edu		Wang, James/0000-0003-4379-4173				Bandemer H., 1992, FUZZY DATA ANAL; Berretti S, 2000, IEEE T MULTIMEDIA, V2, P225, DOI 10.1109/6046.890058; Carson C., 1998, P 3 INT C VIS INF SY, P509, DOI DOI 10.1007/3-540-48762-X_63; Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596; Daubechies I., 1992, 10 LECT WAVELETS, DOI [10.1137/1.9781611970104.ch1, DOI 10.1137/1.9781611970104.CH1]; DelBimbo A, 1997, IEEE T PATTERN ANAL, V19, P121, DOI 10.1109/34.574790; Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238; GERSHO A, 1979, IEEE T INFORM THEORY, V25, P373, DOI 10.1109/TIT.1979.1056067; Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602; Gupta A, 1997, COMMUN ACM, V40, P70, DOI 10.1145/253769.253798; Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830; Hoppner F., 1999, FUZZY CLUSTER ANAL M; Jia LH, 2000, IEEE T IMAGE PROCESS, V9, P80, DOI 10.1109/83.817600; Jia Li, 2000, Proceedings ACM Multimedia 2000, P147; Kulkarni S., 1999, P IEEE INT JOINT C N, P846; Li J, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P754, DOI 10.1109/ICIP.2000.899564; Ma WY, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P568, DOI 10.1109/ICIP.1997.647976; Ma WY, 2000, IEEE T IMAGE PROCESS, V9, P1375, DOI 10.1109/83.855433; Mehrotra S, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P632, DOI 10.1109/MMCS.1997.609791; Minka TP, 1997, PATTERN RECOGN, V30, P565, DOI 10.1016/S0031-3203(96)00113-6; Mojsilovic A, 2000, IEEE T IMAGE PROCESS, V9, P38, DOI 10.1109/83.817597; Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143; Rubner Yossi, 1997, IM UND WORKSH, P661; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Sheikholeslami G., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P428; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151; Smith JR, 1999, COMPUT VIS IMAGE UND, V75, P165, DOI 10.1006/cviu.1999.0771; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936; Vertan C, 2000, PEACHFUZZ 2000 : 19TH INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS, P85, DOI 10.1109/NAFIPS.2000.877393; Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109; Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P85, DOI 10.1109/34.899949; Ze Wang J., 1997, International Journal on Digital Libraries, V1, P311, DOI 10.1007/s007990050026; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	35	227	251	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2002	24	9					1252	1267		10.1109/TPAMI.2002.1033216	http://dx.doi.org/10.1109/TPAMI.2002.1033216			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	587KW		Green Submitted			2022-12-18	WOS:000177640500008
J	Medioni, G; Cohen, I; Bremond, F; Hongeng, S; Nevatia, R				Medioni, G; Cohen, I; Bremond, F; Hongeng, S; Nevatia, R			Event detection and analysis from video streams	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						detection and tracking of moving objects; egomotion estimation; affine stabilization; mosaics; graph representation of objects trajectories; event analysis; geospatial and mission contexts; scenario recognition; finite automaton	ALGORITHM; TRACKING	We present a system which takes as input a video stream obtained from an airborne moving platform and produces an analysis of the behavior of the moving objects in the scene. To achieve this functionality, our system relies on two modular blocks. The first one detects and tracks moving regions in the sequence. It uses a set of features at multiple scales to stabilize the image sequence, that is, to compensate for the motion of the observe, then extracts regions with residual motion and uses an attribute graph representation to infer their trajectories. The second module takes as input these trajectories, together with user-provided information in the form of geospatial context and goal context to instantiate likely scenarios. We present details of the system, together with results on a number of real video sequences and also provide a quantitative analysis of the results.	Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA; INRIA Sophia Antipolis, Projet ORION, F-06902 Sophia Antipolis, France	University of Southern California	Medioni, G (corresponding author), Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA.	medioni@iris.usc.edu; icohen@iris.usc.edu; francois.bremond@sophia.inria.fr; hongeng@iris.usc.edu; nevatia@iris.usc.edu						BOBICK A, 1998, IEEE P COMP VIS PATT; BOBICK AF, 1998, P DARPA IM UND WORKH, P85; BRAND M, 1997, IEEE P COMP VIS PATT; BREMOND F, 1998, P DARPA IM UND WORKS; BREMOND F, 1998, INT J HUM COMP STUDI; BUXTON H, 1995, ARTIF INTELL, V78, P431, DOI 10.1016/0004-3702(95)00041-0; Cohen I, 1999, INT J COMPUT VISION, V33, P29, DOI 10.1023/A:1008161130332; Cohen I., 1999, IEEE P COMP VIS PATT; COHEN I, 1998, P DARPA IM UND WORKS; CORRALL D, 1992, 2152 VIEWS; Cox IJ, 1996, IEEE T PATTERN ANAL, V18, P138, DOI 10.1109/34.481539; COX IJ, 1995, IEEE T AERO ELEC SYS, V31, P486, DOI 10.1109/7.366332; Davis JW, 1997, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.1997.609439; DAVIS L, 1998, P DARPA IM UND WORKS, P73; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Flinchbaugh B., 1998, P DARPA IM UND WORKS, P81; GALTON A, 1993, P INT JOINT C ART IN; GRIMSON WEL, 1987, IEEE P COMP VIS PATT, P22; HARITAOGLU I, 1998, P EUR C COMP VIS; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; HERZOG G, 1995, 124 VITRA U SAARL; HONGENG S, 2000, IEEE P COMP VIS PATT; Howarth R., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P321; Huttenlocher D. P., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P93, DOI 10.1109/ICCV.1993.378231; Intille  S., 1999, IEEE P COMP VIS PATT; Intille SS, 1997, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.1997.609402; IRANI M, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P605, DOI 10.1109/ICCV.1995.466883; IRANI M, 1992, LECT NOTES COMPUT SC, V588, P282; Irani M, 1998, IEEE T PATTERN ANAL, V20, P577, DOI 10.1109/34.683770; IRANI M, 1997, P DARPA IM UND WORKS, V1, P639; KANADE T, 1998, P DARPA IM UND WORKS, P3; Lipton AJ, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P8, DOI 10.1109/ACV.1998.732851; Morimoto C, 1997, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.1997.609396; MULLER JR, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P953, DOI 10.1109/CVPR.1994.323932; NAGEL HH, 1988, IMAGE VISION COMPUT, V6, P59, DOI 10.1016/0262-8856(88)90001-7; NEUMANN B, 1989, SEMANTIC STRUCTURES, P167; PELEG S, 1990, 10TH P INT C PATT RE, V1, P109; PINHANEZ C, 1998, IEEE P COMP VIS PATT; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Schmid C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P230, DOI 10.1109/ICCV.1998.710723; STARNER T, 1995, P INT WORKSH AUT FAC; Strat T. M., 1993, P ARPA IM UND WORKSH, P217; Szeliski R., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P44, DOI 10.1109/ACV.1994.341287; SZELISKI R, 1997, P ACM SIGRAPH 97 AUG; WILSON D, 1998, IEEE P COMP VIS PATT; ZABIH R, 1995, P EUR C COMP VIS MAY; Zoghlami I, 1997, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.1997.609359	48	227	277	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2001	23	8					873	889		10.1109/34.946990	http://dx.doi.org/10.1109/34.946990			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	460AH					2022-12-18	WOS:000170283300007
J	TABATABAI, AJ; MITCHELL, OR				TABATABAI, AJ; MITCHELL, OR			EDGE LOCATION TO SUBPIXEL VALUES IN DIGITAL IMAGERY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907	Purdue University System; Purdue University; Purdue University West Lafayette Campus								Abdou I. E., 1978, QUANTITATIVE METHODS; BURNETT J, 1978, J OPT SOC AM     FEB; Davis L. S., 1975, COMPUT VISION GRAPH, V4, P248, DOI [DOI 10.1016/0146-664X(75)90012-X, 10.1016/0146-664X(75)90012-X]; DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560; Duda R. O., 1971, PATTERN CLASSIFICATI; Elderton W.P., 1969, SYSTEMS FREQUENCY CU; FREI W, 1977, IEEE T COMPUT, V26, P988, DOI 10.1109/TC.1977.1674733; GALLAGHER NC, UNPUB IEEE T ACOUST; HILL TW, THESIS ARIZONA STATE; HUECKEL MH, 1974, J ACM, V21, P350, DOI 10.1145/321812.321830; HUECKEL MH, 1973, J ACM, V20, P634, DOI 10.1145/321784.321791; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; JACOBUS CJ, 1981, IEEE T PATTERN ANAL, V3, P581, DOI 10.1109/TPAMI.1981.4767149; MACHUCA R, 1981, IEEE T PATTERN ANAL, V3, P103, DOI 10.1109/TPAMI.1981.4767057; MIKHAIL EM, 1976, 13TH C INT SOC PHOT; MIKHAIL M, 1979, 1979 AM SOC PHOT SPR; POMALAZA CA, 1980, THESIS PURDUE U; Pratt W. K., 1978, DIGITAL IMAGE PROCES; Roberts L. G., 1965, OPTICAL ELECTRO OPTI; Rosenfeld A., 1982, DIGITAL PICTURE PROC; SCHUCTER B, 1978, COMMUN ASS COMPUT MA, V21, P172; Szego G., 1975, ORTHOGONAL POLYNOMIA, VFourth; TABATABAI A, 1981, THESIS PURDUE U; Von Mises R., 1964, MATH THEORY PROBABIL	24	227	270	4	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	2					188	201		10.1109/TPAMI.1984.4767502	http://dx.doi.org/10.1109/TPAMI.1984.4767502			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SF591	21869182				2022-12-18	WOS:A1984SF59100005
J	He, ZF; Tan, TN; Sun, ZA; Qiu, XC				He, Zhaofeng; Tan, Tieniu; Sun, Zhenan; Qiu, Xianchao			Toward Accurate and Fast Iris Segmentation for Iris Biometrics	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Biometrics; iris segmentation; reflection removal; eyelid localization; eyelash and shadow detection; edge fitting	RECOGNITION; IMAGES	Iris segmentation is an essential module in iris recognition because it defines the effective image region used for subsequent processing such as feature extraction. Traditional iris segmentation methods often involve an exhaustive search of a large parameter space, which is time consuming and sensitive to noise. To address these problems, this paper presents a novel algorithm for accurate and fast iris segmentation. After efficient reflection removal, an Adaboost-cascade iris detector is first built to extract a rough position of the iris center. Edge points of iris boundaries are then detected, and an elastic model named pulling and pushing is established. Under this model, the center and radius of the circular iris boundaries are iteratively refined in a way driven by the restoring forces of Hooke's law. Furthermore, a smoothing spline-based edge fitting scheme is presented to deal with noncircular iris boundaries. After that, eyelids are localized via edge detection followed by curve fitting. The novelty here is the adoption of a rank filter for noise elimination and a histogram filter for tackling the shape irregularity of eyelids. Finally, eyelashes and shadows are detected via a learned prediction model. This model provides an adaptive threshold for eyelash and shadow detection by analyzing the intensity distributions of different iris regions. Experimental results on three challenging iris image databases demonstrate that the proposed algorithm outperforms state-of-the-art methods in both accuracy and speed.	[He, Zhaofeng] Chinese Acad Sci, Inst Automat, Ctr Biometr & Secur Res, Beijing 100190, Peoples R China; Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; Institute of Automation, CAS	He, ZF (corresponding author), Chinese Acad Sci, Inst Automat, Ctr Biometr & Secur Res, 95 Zhongguancun E Rd, Beijing 100190, Peoples R China.	zfhe@nlpr.ia.ac.cn; tnt@nlpr.ia.ac.cn; znsun@nlpr.ia.ac.cn; xcqiu@nlpr.ia.ac.cn		Wang, Yunlong/0000-0002-3535-308X	National Basic Research Program [2004CB318110]; Natural Science Foundation of China [60736018, 60335010, 60702024, 60723005]; National Hi-Tech Research and Development Program of China [2006AA01Z193, 2007AA01Z162]; Chinese Academy of Sciences	National Basic Research Program(National Basic Research Program of China); Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Hi-Tech Research and Development Program of China(National High Technology Research and Development Program of China); Chinese Academy of Sciences(Chinese Academy of Sciences)	This work is supported by research grants from the National Basic Research Program (Grant 2004CB318110), the Natural Science Foundation of China (Grants 60736018, 60335010, 60702024, and 60723005), the National Hi-Tech Research and Development Program of China (Grants 2006AA01Z193 and 2007AA01Z162), and the Chinese Academy of Sciences. The work described in this paper has been filed for patents.	Abhyankar A, 2006, PROC SPIE, V6202, DOI 10.1117/12.666435; [Anonymous], 2008, CASIA IRIS IMAGE DAT; Arvacheh EM, 2006, IEEE IMAGE PROC, P2453, DOI 10.1109/ICIP.2006.312773; BACHOO AK, 2005, P ACM INT C S AFR I, P236; Boles WW, 1998, IEEE T SIGNAL PROCES, V46, P1185, DOI 10.1109/78.668573; Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005; CAMUS TA, 2002, P 16 INT C PATT REC, V2, P414; Cho DH, 2005, Sixth International Conference on Software Engineerng, Artificial Intelligence, Networking and Parallel/Distributed Computing and First AICS International Workshop on Self-Assembling Wireless Networks, Proceedings, P254; CUI J, 2005, P INT WORKSH BIOM RE, P157; Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350; Daugman J, 2001, INT J COMPUT VISION, V45, P25, DOI 10.1023/A:1012365806338; Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540; Dorairaj V., 2005, IM PROC 2005 ICIP 20, V3, P11; Feng XH, 2006, INT C PATT RECOG, P553; Gonzales R.C., 1987, DIGITAL IMAGE PROCES; Haykin S., 1999, NEURAL NETWORKS COMP; HE Z, 2008, P INT C IM PROC; HE Z, 2008, P IEEE INT C COMP VI; He ZF, 2006, INT C PATT RECOG, P366; Huang JZ, 2004, INT C PATT RECOG, P554, DOI 10.1109/ICPR.2004.1334589; Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349; Kong WK, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P263, DOI 10.1109/ISIMP.2001.925384; LI X, 2006, P INT C BIOM, P419; LIU XM, 2005, P 4 IEEE WORKSH AUT; Ma L, 2004, IEEE T IMAGE PROCESS, V13, P739, DOI 10.1109/TIP.2004.827237; Monro D. M, 2007, P IEEE WORKSH SIGN P, P1; Proenca H, 2006, IEE P-VIS IMAGE SIGN, V153, P199, DOI 10.1049/ip-vis:20050213; Proenca H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119; REINSCH CH, 1967, NUMER MATH, V10, P177, DOI 10.1007/BF02162161; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Sun ZN, 2004, LECT NOTES COMPUT SC, V3087, P270; Tisse C., 2002, P VIS INT, P294; Trucco E, 2005, PATTERN ANAL APPL, V8, P247, DOI [10.1007/s10044-005-0004-8, 10.1007/sl0044-005-0004-8]; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; WAHBA G, 1975, NUMER MATH, V24, P383, DOI 10.1007/BF01437407; Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669; YOUNG HD, 2003, U PHYS MODERN PHYS; Yu L, 2007, PATTERN RECOGN, V40, P423, DOI 10.1016/j.patcog.2006.03.008; 2009, IRIS CHALLENGE EVALU	39	226	246	3	54	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2009	31	9					1670	1684		10.1109/TPAMI.2008.183	http://dx.doi.org/10.1109/TPAMI.2008.183			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	462QD	19574626				2022-12-18	WOS:000267369800010
J	Khan, S; Shah, M				Khan, S; Shah, M			Consistent labeling of tracked objects in multiple cameras with overlapping fields of view	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						tracking; multiple cameras; multiperspective video; surveillance; camera handoff; sensor fusion		In this paper, we address the issue of tracking moving objects in an environment covered by multiple uncalibrated cameras with overlapping fields of view, typical of most surveillance setups. In such a scenario, it is essential to establish correspondence between tracks of the same object, seen in different cameras, to recover complete information about the object. We call this the problem of consistent labeling of objects when seen in multiple cameras. We employ a novel approach of finding the limits of field of view (FOV) of each camera as visible in the other cameras. We show that, if the FOV lines are known, it is possible to disambiguate between multiple possibilities for correspondence. We present a method to automatically recover these lines by observing motion in the environment. Furthermore, once these lines are initialized, the homography between the views can also be recovered. We present results on indoor and outdoor sequences containing persons and vehicles.	Lahore Univ Management Sci, Dept Comp Sci, Sector U, DHA, Lahore 54792, Pakistan; Univ Cent Florida, Comp Vis Lab, Orlando, FL 32816 USA	Lahore University of Management Sciences; State University System of Florida; University of Central Florida	Khan, S (corresponding author), Lahore Univ Management Sci, Dept Comp Sci, Sector U, DHA, Lahore 54792, Pakistan.			Shah, Mubarak/0000-0001-6172-5572				BLACK J, 2001, P PERFORMANCE EVALUA; Cai Q, 1999, IEEE T PATTERN ANAL, V21, P1241, DOI 10.1109/34.809119; Caspi Y., 2000, IEEE P C COMP VIS PA; Chang T.-H., 2001, P IEEE WORKSH MULT T; Collins RT, 2001, P IEEE, V89, P1456, DOI 10.1109/5.959341; FUIYOSHI H, 1998, P IM UND WORKSH; JAVED O, 2002, P WORKSH MOT VID COM; Javed O., 2003, P 9 IEEE INT C COMP; KANADE T, P DARPA IM UND WORKS; Kelly P. H, 1995, P ACM C MULT, P201; Kettnaker V., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P253, DOI 10.1109/CVPR.1999.784638; KHAN S, 2001, P PERF EV TRACK SURV; Lee L, 2000, IEEE T PATTERN ANAL, V22, P758, DOI 10.1109/34.868678; PASULA H, 1999, P INT JOINT C ART IN; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; TAN TN, 1994, IMAGE VISION COMPUT, V12, P164, DOI 10.1016/0262-8856(94)90068-X; Tao H, 2002, IEEE T PATTERN ANAL, V24, P75, DOI 10.1109/34.982885; UTSUMI A, 2000, P AS C COMP VIS, P1034	18	226	254	2	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2003	25	10					1355	1360		10.1109/TPAMI.2003.1233912	http://dx.doi.org/10.1109/TPAMI.2003.1233912			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	723ZE					2022-12-18	WOS:000185460800018
J	LAKSHMANAN, S; DERIN, H				LAKSHMANAN, S; DERIN, H			SIMULTANEOUS PARAMETER-ESTIMATION AND SEGMENTATION OF GIBBS RANDOM-FIELDS USING SIMULATED ANNEALING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											LAKSHMANAN, S (corresponding author), UNIV MASSACHUSETTS,DEPT ELECT & COMP ENGN,AMHERST,MA 01003, USA.			Lakshmanan, Sridhar/0000-0001-7387-3943				BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1986, J R STAT SOC B, V48, P259; BESAG J, 1977, BIOMETRIKA, V64, P616, DOI 10.1093/biomet/64.3.616; Billingsley P., 1968, CONVERGE PROBAB MEAS; COHEN AC, 1967, TECHNOMETRICS, V9, P15, DOI 10.2307/1266315; COHEN FS, 1987, IEEE T PATTERN ANAL, V9, P195, DOI 10.1109/TPAMI.1987.4767895; CRISTI R, P ISCS 85 JAPAN; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; DERIN H, 1987, COMPUT VISION GRAPH, V40, P54, DOI 10.1016/0734-189X(87)90056-9; DERIN H, 1984, IEEE T PATTERN ANAL, V6, P707, DOI 10.1109/TPAMI.1984.4767595; DERIN H, 1986, COMPUT VISION GRAPH, V35, P72, DOI 10.1016/0734-189X(86)90126-X; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P142, DOI 10.1109/TPAMI.1987.4767880; DERIN H, 1986, 24TH P ALL COMM CONT, P705; ELLIOTT H, 1984, 1984 P INT C AC SPEE; GEMAN D, 1985, 1985 INT GEOSC REM S; GEMAN D, 1987, COMMUNICATION; GEMAN D, 1986, COMMUNICATION; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GEMAN S, 1987, P INT C MATH; HANSEN FR, 1982, COMPUT VISION GRAPH, V20, P101, DOI 10.1016/0146-664X(82)90040-5; LAKSHMANAN S, 1987, THESIS U MASSACHUSET; MORROQUIN J, 1987, J ASA, V82, P76; REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034; TITCHMARSH EC, 1939, THEORY FUNCTIONS, P13; WENDELL RE, 1976, OPER RES, V24, P643, DOI 10.1287/opre.24.4.643; YOUNES L, ESTIMATION ANNEALING	27	226	230	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1989	11	8					799	813		10.1109/34.31443	http://dx.doi.org/10.1109/34.31443			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AH079					2022-12-18	WOS:A1989AH07900002
J	BOYER, KL; KAK, AC				BOYER, KL; KAK, AC			COLOR-ENCODED STRUCTURED LIGHT FOR RAPID ACTIVE RANGING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PURDUE UNIV,SCH ELECT ENGN,ROBOT VIS LAB,W LAFAYETTE,IN 47907	Purdue University System; Purdue University; Purdue University West Lafayette Campus								BOYER KL, 1984, TREE8437 PURD U TECH; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P122, DOI 10.1109/TPAMI.1983.4767365; KAK AC, 1985, HDB IND ROBOTICS, P272; MINOU M, 1982, THESIS KYOTO U; NITZAN D, 1977, P IEEE, V65, P206, DOI 10.1109/PROC.1977.10458; Oppenheim AV, 1975, DIGIT SIGNAL PROCESS, P242; OSHIMA M, 1983, IEEE T PATTERN ANAL, V5, P353, DOI 10.1109/TPAMI.1983.4767405; OSHIMA M, 1984, PATTERN RECOGNITION, V11, P9; POSDAMER JL, 1982, COMPUT VISION GRAPH, V18, P1, DOI 10.1016/0146-664X(82)90096-X; SHIRAI Y, 1972, PATTERN RECOGN, V4, P243, DOI 10.1016/0031-3203(72)90003-9; STOCKMAN G, 1985, 3D SURFACE SENSING U; WANG YF, 1985, 3RD P WORKSH COMP VI, P96; WILL PM, 1971, ARTIF INTELL, V2, P319, DOI 10.1016/0004-3702(71)90015-4; Yang H. S., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P199; YANG HS, 1985, 3RD P WORKSH COMP VI, P38; 1981, KODAK PUBLICATION B, V3; [No title captured]	17	226	246	3	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1987	9	1					14	28		10.1109/TPAMI.1987.4767869	http://dx.doi.org/10.1109/TPAMI.1987.4767869			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	F3785	21869374				2022-12-18	WOS:A1987F378500002
J	Lu, XG; Jain, AK; Colbry, D				Lu, XG; Jain, AK; Colbry, D			Matching 2.5D face scans to 3D models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face recognition; 3D model; multimodal; surface matching; appearance-based	REGISTRATION	The performance of face recognition systems that use two-dimensional images depends on factors such as lighting and subject's pose. We are developing a face recognition system that utilizes three-dimensional shape information to make the system more robust to arbitrary pose and lighting. For each subject, a 3D face model is constructed by integrating several 2.5D face scans which are captured from different views. 2.5D is a simplified 3D (x, y, z) surface representation that contains at most one depth value (z direction) for every point in the (x, y) plane. Two different modalities provided by the facial scan, namely, shape and texture, are utilized and integrated for face matching. The recognition engine consists of two components, surface matching and appearance-based matching. The surface matching component is based on a modified Iterative Closest Point (ICP) algorithm. The candidate list from the gallery used for appearance matching is dynamically generated based on the output of the surface matching component, which reduces the complexity of the appearance-based matching stage. Three-dimensional models in the gallery are used to synthesize new appearance samples with pose and illumination variations and the synthesized face images are used in discriminant subspace analysis. The weighted sum rule is applied to combine the scores given by the two matching components. Experimental results are given for matching a database of 200 3D face models with 598 2.5D independent test scans acquired under different pose and some lighting and expression changes. These results show the feasibility of the proposed matching scheme.	Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Michigan State University	Lu, XG (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, 3115 Engn Bldg, E Lansing, MI 48824 USA.	Lvxiaogu@cse.msu.edu; jain@cse.msu.edu; colbrydi@cse.msu.edu		Colbry, Dirk/0000-0003-0666-9883				*3DIM, 2005, P 5 INT C 3 D DIG IM; Achermann B, 1997, INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA - VSMM'97, PROCEEDINGS, P129, DOI 10.1109/VSMM.1997.622339; Bartlett MS, 1998, P SOC PHOTO-OPT INS, V3299, P528, DOI 10.1117/12.320144; BELJUMEUR PN, 1997, IEEE T PATTERN ANAL, V19, P711; Bengio S., 2001, EVALUATION BIOMETRIC; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Beumier C, 2000, IMAGE VISION COMPUT, V18, P315, DOI 10.1016/S0262-8856(99)00052-9; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; BRONSTEIN A, 2003, P AUD VID BAS BIOM P, P62; Cartoux J. Y., 1989, P WORKSH INT 3D SCEN, P194; Chang K. I., 2003, P IEEE WORKSH AN MOD; Chen Q, 2001, J VLSI SIG PROC SYST, V27, P127, DOI 10.1023/A:1008131816432; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Chin-Seng Chua, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P233, DOI 10.1109/AFGR.2000.840640; COLBRY D, 2004, MSUCSE0439; Dimitrijevic M, 2004, PROC CVPR IEEE, P1034; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113; Dorai C, 1998, IEEE T PATTERN ANAL, V20, P83, DOI 10.1109/34.655652; Duda R.O., 2000, PATTERN CLASSIFICATI; Foley James D, 1996, COMPUTER GRAPHICS PR, V12110; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; GELFAND N, 2003, P INT C 3D DIG IM MO; GORDON G, 1992, P IEEE COMP SOC C CO, P108; HESHER C, 2002, P 2002 INT MULT COMP; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; Jain AK, 2002, IEEE IMAGE PROC, P57; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Lee J. C., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P722, DOI 10.1109/ICCV.1990.139627; LI KP, 1998, P IEEE INT C AC SPEE, P595; Li S.Z., 2005, HDB FACE RECOGNITION; LIEPA, 2003, P EUR ACM SIGGRAPH S, P200; LU X, 2005, P 7 IEEE WORKSH APPL; Lu XG, 2004, INT C PATT RECOG, P362, DOI 10.1109/ICPR.2004.1334127; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; *MIN, 2005, MIN VIV 910 NONC 3D; Moghaddam B, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P20; Pan G, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P193; Shan SG, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P314; Tanaka HT, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P372, DOI 10.1109/AFGR.1998.670977; TASDIZEN T, 2002, P VISUALIZATION 02; TURK G, 1994, P ACM SIGGRAPH JUL; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; *U S FLOR, 2005, USF HUMANID 3D FAC D; WEINSTEIN DM, 1998, UUCS98005; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149; Zhang ZY, 2001, PROC SPIE, V4309, P1; Zhao W., 2000, FACE RECOGNITION LIT	49	225	234	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2006	28	1					31	43		10.1109/TPAMI.2006.15	http://dx.doi.org/10.1109/TPAMI.2006.15			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	982OR	16402617	Green Submitted			2022-12-18	WOS:000233172000003
J	Loog, M; Duin, RPW				Loog, M; Duin, RPW			Linear dimensionality reduction via a heteroscedastic extension of LDA: The Chernoff criterion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						linear dimension reduction; linear discriminant analysis; Fisher criterion; Chernoff distance; Chernoff criterion	STATISTICAL PATTERN-RECOGNITION; CLASSIFICATION; DISTANCE	We propose an eigenvector-based heteroscedastic linear dimension reduction (LDR) technique for multiclass data. The technique is based on a heteroscedastic two-class technique which utilizes the so-called Chernoff criterion, and successfully extends the well-known linear discriminant analysis (LDA). The latter, which is based on the Fisher criterion, is incapable of dealing with heteroscedastic data in a proper way. For the two-class case, the between-class scatter is generalized so to capture differences in (co)variances. It is shown that the classical notion of between-class scatter can be associated with Euclidean distances between class means. From this viewpoint, the between-class scatter is generalized by employing the Chernoff distance measure, leading to our proposed heteroscedastic measure. Finally, using the results from the two-class case, a multiclass extension of the Chernoff criterion is proposed. This criterion combines separation information present in the class mean as well as the class covariance matrices. Extensive experiments and a comparison with similar dimension reduction techniques are presented.	Univ Med Ctr Utrecht, Image Sci Inst, NL-3508 GA Utrecht, Netherlands; Delft Univ Technol, Fac Elect Engn Math & Comp Sci, Informat & Commun Theory Grp, NL-2600 GA Delft, Netherlands	Utrecht University; Utrecht University Medical Center; Delft University of Technology	Loog, M (corresponding author), Univ Med Ctr Utrecht, Image Sci Inst, E-01-335,POB 85500, NL-3508 GA Utrecht, Netherlands.	marco@isi.uu.nl; r.p.w.duin@ewi.tudelft.nl						AEBERHARD S, 1994, PATTERN RECOGN, V27, P1065, DOI 10.1016/0031-3203(94)90145-7; Brunzell H, 2000, PATTERN RECOGN, V33, P1741, DOI 10.1016/S0031-3203(99)00142-9; BUTUROVIC LJ, 1994, IEEE T PATTERN ANAL, V16, P420, DOI 10.1109/34.277596; CHEN CH, 1976, INFORM SCIENCES, V10, P159, DOI 10.1016/S0020-0255(76)90746-5; CHUNG JK, 1989, J MATH ANAL APPL, V138, P280, DOI 10.1016/0022-247X(89)90335-1; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; Decell H. P.  Jr., 1977, Computers & Mathematics with Applications, V3, P71, DOI 10.1016/0898-1221(77)90116-X; Devijver PA, 1982, PATTERN RECOGNITION; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Kumar N., 1996, P JOINT M AM STAT AS; Liu XW, 2003, PROC CVPR IEEE, P229; Loog M, 2001, IEEE T PATTERN ANAL, V23, P762, DOI 10.1109/34.935849; Loog M., 1999, WBBM REPORT SERIES, V44; LOOG M, 2002, P 4 JOINT IAPR INT W, P508; Mclachlan GJ., 2005, DISCRIMINANT ANAL ST; Murphy PM, 2004, UCI REPOSITORY MACHI; Okada T., 1984, Electronics and Communications in Japan, V67, P10, DOI 10.1002/ecja.4400670603; RAO CR, 1948, J ROY STAT SOC B, V10, P159; Rice J. A., 1995, MATH STAT DATA ANAL; Rohl M., 1998, P 22 ANN GFKL C, P252; TUBBS JD, 1982, PATTERN RECOGN, V15, P167, DOI 10.1016/0031-3203(82)90068-1	24	225	231	1	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2004	26	6					732	739						8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	811EZ	18579934				2022-12-18	WOS:000220756500007
J	La Cascia, M; Sclaroff, S; Athitsos, V				La Cascia, M; Sclaroff, S; Athitsos, V			Fast, reliable head tracking under varying illumination: An approach based on registration of texture-mapped 3D models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						visual tracking; real-time vision; illumination; motion estimation; computer human interfaces	FACIAL EXPRESSIONS; MOTION	An improved technique for 3D head tracking under varying illumination conditions is proposed. The head is modeled as a texture mapped cylinder. Tracking is formulated as an image registration problem in the cylinder's texture map image. The resulting dynamic texture map provides a stabilized view of the face that can be used as input to many existing 2D techniques for face recognition, facial expressions analysis, lip reading, and eye tracking. To solve the registration problem in the presence of lighting variation and head motion, the residual error of registration is modeled as a linear combination of texture warping templates and orthogonal illumination templates. Fast and stable on-line tracking is achieved via regularized, weighted least-squares minimization of the registration error. The regularization term tends to limit potential ambiguities that arise in the warping and illumination templates. It enables stable tracking over extended sequences. Tracking does not require a precise initial fit of the model; the system is initialized automatically using a simple 2D face detector. The only assumption is that the target is facing the camera in the first frame of the sequence. The formulation is tailored to take advantage of texture mapping hardware available in many workstations, PCs, and game consoles. The nonoptimized implementation runs at about 15 frames per second on a SGI O2 graphic workstation. Extensive experiments evaluating the effectiveness of the formulation are reported. The sensitivity of the technique to illumination, regularization parameters, errors in the initial positioning, and internal camera parameters are analyzed. Examples and applications of tracking are reported.	Univ Palermo, Dipartimento Ingn Automat & Informat, I-90128 Palermo, Italy; Boston Univ, Dept Comp Sci, Image & Video Comp Grp, Boston, MA 02215 USA	University of Palermo; Boston University	La Cascia, M (corresponding author), Univ Palermo, Dipartimento Ingn Automat & Informat, Viale Sci, I-90128 Palermo, Italy.	lacascia@csai.unipa.it; sclaroff@bu.edu; athitsos@bu.edu	Athitsos, Vassilis/AAF-8496-2020; La Cascia, Marco/E-9612-2012	La Cascia, Marco/0000-0002-8766-6395				*ASC TECHN CORP, FLOCK BIRDS; AZARBAYEJANI A, 1993, IEEE T PATTERN ANAL, V15, P602, DOI 10.1109/34.216730; BASU S, 1996, P INT C PATT REC; BIRCHFIELD S, 1997, P 31 AS C SIGN SYST; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277; BLACK MJ, 1995, P 5 INT C COMP VIS; COOTES TF, 1998, P 5 EUR C COMP VIS; CROWLEY JL, 1997, P C COMP VIS PATT RE; DECARLO D, 1996, P C COMP VIS PATT RE; DELLAERT F, 1998, P IEEE WORKSH APPL C; DELLAERT F, 1998, P IEEE RSJ INT C INT; Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232; FIEGUTH P, 1997, P C COMP VIS PATT RE; GLEICHER M, 1997, P C COMP VIS PATT RE; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; HALLINAN P, 1994, P C COMP VIS PATT RE; HORN BKP, 1987, J OPTICAL SOC AM A, V4; HORPRASERT T, 1996, P INT C FAC GEST REC; Isard M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P107, DOI 10.1109/ICCV.1998.710707; JEBARA TS, 1997, P C COMP VIS PATT RE; LACASCIA M, 1998, P C COMP VIS PATT RE; LACASCIA M, 1999, P C COMP VIS PATT RE; LI HB, 1993, IEEE T PATTERN ANAL, V15, P545, DOI 10.1109/34.216724; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; OLIVIER N, 1997, P C COMP VIS PATT RE; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; SCHODL A, 1998, P 1998 WORKSH PERC U; SCLAROFF S, 1998, P 6 INT C COMP VIS; Shashua A, 1992, THESIS MIT; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767; TERZOPOULOS D, 1993, IEEE T PATTERN ANAL, V15, P569, DOI 10.1109/34.216726; Toyama K, 1999, INT J COMPUT VISION, V35, P45, DOI 10.1023/A:1008159011682; Yacoob Y, 1996, IEEE T PATTERN ANAL, V18, P636, DOI 10.1109/34.506414; YUILLE AL, 1994, P INT C PATT REC	36	225	235	0	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2000	22	4					322	336		10.1109/34.845375	http://dx.doi.org/10.1109/34.845375			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	317WT					2022-12-18	WOS:000087250500002
J	Chang, KI; Bowyer, KW; Flynn, PJ				Chang, Kyong I.; Bowyer, Kevin W.; Flynn, Patrick J.			Multiple nose region matching for 3D face recognition under varying facial expression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						biometrics; face recognition; three-dimensional face; facial expression		An algorithm is proposed for 3D face recognition in the presence of varied facial expressions. It is based on combining the match scores from matching multiple overlapping regions around the nose. Experimental results are presented using the largest database employed to date in 3D face recognition studies, over 4,000 scans of 449 subjects. Results show substantial improvement over matching the shape of a single larger frontal face region. This is the first approach to use multiple overlapping regions around the nose to handle the problem of expression variation.	Philips Med Syst, Bothell, WA 98021 USA; Univ Notre Dame, Dept Comp Engn & Sci, Notre Dame, IN 46556 USA	Philips; Philips Healthcare; University of Notre Dame	Chang, KI (corresponding author), Philips Med Syst, 22100 Bothell Everett Hwy, Bothell, WA 98021 USA.	Jin.Chang@philips.com; kwb@cse.nd.edu; Flynn@cse.nd.edu		Bowyer, Kevin/0000-0002-7562-4390				Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005; Bronstein AM, 2006, P NATL ACAD SCI USA, V103, P1168, DOI 10.1073/pnas.0508601103; Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y; Chang K, 2005, PROC SPIE, V5779, P132, DOI 10.1117/12.604171; Chang K., 2005, P IEEE WORKSH FAC RE; Chang KI, 2005, IEEE T PATTERN ANAL, V27, P619, DOI 10.1109/TPAMI.2005.70; Chin-Seng Chua, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P233, DOI 10.1109/AFGR.2000.840640; Cook J, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P502, DOI 10.1109/TDPVT.2004.1335279; GOKBERK B, 2005, P INT C AUD VID BAS, P1019; Heisele B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P153, DOI 10.1109/AFGR.2004.1301523; Hesher C, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 2, PROCEEDINGS, P201, DOI 10.1109/ISSPA.2003.1224850; HUSKEN M, 2005, P IEEE WORKSH FAC RE; KOUDELKA ML, 2005, P IEEE WORKSH FAC RE; Lu X, 2005, 5th International Workshop on Microprocessor Test and Verification: Common Challenges and Solutions, Proceedings, P97; Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15; Martinez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382; MAURER T, 2005, P IEEE WORKSH FAC RE; Medioni G, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P232; PASSALIS G, 2005, P IEEE WORKSH FAC RE; PHILLIPS J, 2002, FACIAL RECOGNITION V; Phillips PJ, 2005, PROC CVPR IEEE, P947; Tsalakanidou F, 2003, PATTERN RECOGN LETT, V24, P1427, DOI 10.1016/S0167-8655(02)00383-5; YACOOB Y, 1995, P INT WORKSH AUT FAC, P278; YAN P, 2005, P IEEE WORKSH AUT ID	24	224	239	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2006	28	10					1695	1700		10.1109/TPAMI.2006.210	http://dx.doi.org/10.1109/TPAMI.2006.210			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	071ME	16986549				2022-12-18	WOS:000239605500012
J	Wu, V; Manmatha, R; Riseman, EM				Wu, V; Manmatha, R; Riseman, EM			TextFinder: An automatic system to detect and recognize text in images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						text reading; character recognition; multimedia indexing; text detection; texture segmentation; filters; hierarchical processing; binarization; connected-components	SEGMENTATION; EXTRACTION	A robust system is proposed to automatically detect and extract text in images from different sources, including video, newspapers, advertisements, stock certificates, photographs, and checks. Text is first detected using multiscale texture segmentation and spatial cohesion constraints, then cleaned up and extracted using a histogram-based binarization algorithm. An automatic performance evaluation scheme is also proposed.	Univ Massachusetts, Dept Comp Sci, Amherst, MA 01003 USA	University of Massachusetts System; University of Massachusetts Amherst	Wu, V (corresponding author), Univ Massachusetts, Dept Comp Sci, Amherst, MA 01003 USA.							BOKSER M, 1992, P IEEE, V80, P1066, DOI 10.1109/5.156470; Etemad K, 1997, IEEE T PATTERN ANAL, V19, P92, DOI 10.1109/34.566817; FLETCHER LA, 1988, IEEE T PATTERN ANAL, V10, P910, DOI 10.1109/34.9112; Jain AK, 1998, PATTERN RECOGN, V31, P2055, DOI 10.1016/S0031-3203(98)00067-3; KAMEL M, 1993, CVGIP-GRAPH MODEL IM, V55, P203, DOI 10.1006/cgip.1993.1015; MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923; MORI S, 1992, P IEEE, V80, P1029, DOI 10.1109/5.156468; NAGY G, 1992, COMPUTER, V25, P10, DOI 10.1109/2.144436; NEVATIA R, 1977, IEEE T SYST MAN CYB, V7, P820; PALUMBO PW, 1992, COMPUTER, V25, P34, DOI 10.1109/2.144438; Smith MA, 1997, PROC CVPR IEEE, P775, DOI 10.1109/CVPR.1997.609414; WAHL FM, 1982, COMPUT VISION GRAPH, V20, P375, DOI 10.1016/0146-664X(82)90059-4; WANG D, 1989, COMPUT VISION GRAPH, V47, P327, DOI 10.1016/0734-189X(89)90116-3; WONG KY, 1982, IBM J RES DEV, V26, P647, DOI 10.1147/rd.266.0647; WU V, 1998, P SPIE 98 DOC REC JA, V5, P263; WU V, 1999, 9940 U MASS COMP SCI; ZHONG Y, 1995, PATTERN RECOGN, V28, P1523, DOI 10.1016/0031-3203(95)00030-4; ZHOU DLJ, 1998, P SPIE 98 DOC REC, V5, P130; [No title captured]	19	224	277	2	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1999	21	11					1224	1229		10.1109/34.809116	http://dx.doi.org/10.1109/34.809116			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	259YG					2022-12-18	WOS:000083921100012
J	Caspi, D; Kiryati, N; Shamir, J				Caspi, D; Kiryati, N; Shamir, J			Range imaging with adaptive color structured light	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						color; computer vision; multilevel Gray code; range sensor; shape from X; structured light; video and data projector		In range sensing with time-multiplexed structured light, there is a trade-off between accuracy, robustness and the acquisition period. The acquisition period is lower bounded by the product of the number of projection patterns and the time needed for acquiring a single image. In this paper a novel structured light method is described. Adaptation of the number and form of the projection patterns to the characteristics of the scene takes place as part of the acquisition process. Noise margins are matched to the actual noise level, thus reducing the number of projection patterns to the necessary minimum. Color is used for light plane labeling. The dimension of the pattern space (and the noise margins) are thus increased without raising the number of projection patterns. It is shown that the color of an impinging light plane can be identified from the image of the illuminated scene, even with colorful scenes, identification is local and does not rely on spatial color sequences, Therefore, in comparison to other color structured light techniques, assumptions about smoothness and color neutrality of the scene can be relaxed. The suggested approach has been implemented and the theoretical results are supported by experiments.	Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Caspi, D (corresponding author), Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.	nk@ee.technion.ac.il		Kiryati, Nahum/0000-0003-1436-2275				AGIN GJ, 1973, P 3 INT JOINT C ART, P629; ASTROM A, 1993, THESIS LINKOPING U L; Besl P. J., 1988, Machine Vision and Applications, V1, P127, DOI 10.1007/BF01212277; BLAKE A, 1993, IEEE T PATTERN ANAL, V15, P477, DOI 10.1109/34.211467; BOYER KL, 1987, IEEE T PATTERN ANAL, V9, P14, DOI 10.1109/TPAMI.1987.4767869; CARRIHILL B, 1985, COMPUT VISION GRAPH, V32, P337, DOI 10.1016/0734-189X(85)90056-8; CHAZAN G, 1995, 121 TECHN DEP EL ENG; Chen CS, 1997, IMAGE VISION COMPUT, V15, P445, DOI 10.1016/S0262-8856(96)01148-1; ER MC, 1984, IEEE T COMPUT, V33, P739, DOI 10.1109/TC.1984.5009360; Horn E, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P28, DOI 10.1109/IM.1997.603845; HUGLI H, 1988, P SOC PHOTO-OPT INS, V1010, P75; KANADE T, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P1322, DOI 10.1109/ROBOT.1991.131796; MCIVOR AM, 1994, 190 IND RES LTD; SATO K, 1985, J ROBOTIC SYST, V2, P27; Shirai Y., 1971, P 2 INT JOINT C ART, P80; SMUTNY V, 1993, P 1 CZECH PATT REC W, P59; Tajima J., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P309, DOI 10.1109/ICPR.1990.118121; Trobina M., 1995, BIWITR164 ETH ZUR	18	224	250	2	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1998	20	5					470	480		10.1109/34.682177	http://dx.doi.org/10.1109/34.682177			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZR253					2022-12-18	WOS:000073955600003
J	TRIER, OD; TAXT, T				TRIER, OD; TAXT, T			EVALUATION OF BINARIZATION METHODS FOR DOCUMENT IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						LOCALLY ADAPTIVE BINARIZATION; THRESHOLDING; EVALUATION; UTILITY MAPS; DOCUMENT IMAGES	CHARACTER-RECOGNITION; LEVEL; SEGMENTATION; ENTROPY	This paper presents an evaluation of eleven locally adaptive binarization methods for gray scale images with low contrast, variable background intensity and noise. Niblack's method with the addition of the postprocessing step of Yanowitz and Bruckstein's method added performed the best and was also one of the fastest binarization methods.	UNIV OSLO,DEPT INFORMAT,N-0316 OSLO,NORWAY	University of Oslo	TRIER, OD (corresponding author), MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48824, USA.							ABUTALEB AS, 1989, COMPUT VISION GRAPH, V47, P22, DOI 10.1016/0734-189X(89)90051-0; BERNSEN J, 1986, 8 INT C PATT REC, P1251; CHOW CK, 1972, COMPUT BIOMED RES, V5, P388, DOI 10.1016/0010-4809(72)90070-5; EIKVIL L, 1991, 1ST P INT C DOC AN R, P435; KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2; KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0; KURITA T, 1992, PATTERN RECOGN, V25, P1231, DOI 10.1016/0031-3203(92)90024-D; MARDIA KV, 1988, IEEE T PATTERN ANAL, V10, P919, DOI 10.1109/34.9113; NAKAGAWA Y, 1979, PATTERN RECOGN, V11, P191, DOI 10.1016/0031-3203(79)90006-2; Niblack W., 1986, INTRO DIGITAL IMAGE, P115; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; PARKER JR, 1991, IEEE T PATTERN ANAL, V13, P813, DOI 10.1109/34.85672; PRATT WK, 1991, DIGITAL IMAGE PROCES, P501; TAXT T, 1989, IEEE T PATTERN ANAL, V11, P1322, DOI 10.1109/34.41371; TOMINAGA H, 1993, PATTERN RECOGN LETT, V14, P257, DOI 10.1016/0167-8655(93)90090-Z; TRIER OD, IN PRESS PATTERN REC; TRIER OD, 1994, EVALUATION BINARIZAT; TRIER OD, 1994, JUN NSF ARPA WORKSH, P206; TRIER OD, 1994, 1ST P IEEE INT C IM; WHITE JM, 1983, IBM J RES DEV, V27, P400, DOI 10.1147/rd.274.0400; YANOWITZ SD, 1989, COMPUT VISION GRAPH, V46, P82, DOI 10.1016/S0734-189X(89)80017-9; 1993, 2ND P INT C DOC AN R; 1991, 1ST P INT C DOC AN R	23	224	242	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1995	17	3					312	315		10.1109/34.368197	http://dx.doi.org/10.1109/34.368197			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QM090					2022-12-18	WOS:A1995QM09000009
J	Liu, J; Shahroudy, A; Xu, D; Kot, AC; Wang, G				Liu, Jun; Shahroudy, Amir; Xu, Dong; Kot, Alex C.; Wang, Gang			Skeleton-Based Action Recognition Using Spatio-Temporal LSTM Network with Trust Gates	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action recognition; recurrent neural networks; long short-term memory; spatio-temporal analysis; tree traversal; trust gate; skeleton sequence	POSE	Skeleton-based human action recognition has attracted a lot of research attention during the past few years. Recent works attempted to utilize recurrent neural networks to model the temporal dependencies between the 3D positional configurations of human body joints for better analysis of human activities in the skeletal data. The proposed work extends this idea to spatial domain as well as temporal domain to better analyze the hidden sources of action-related information within the human skeleton sequences in both of these domains simultaneously. Based on the pictorial structure of Kinect's skeletal data, an effective tree-structure based traversal framework is also proposed. In order to deal with the noise in the skeletal data, a new gating mechanism within LSTM module is introduced, with which the network can learn the reliability of the sequential data and accordingly adjust the effect of the input data on the updating procedure of the long-term context representation stored in the unit's memory cell. Moreover, we introduce a novel multi-modal feature fusion strategy within the LSTM unit in this paper. The comprehensive experimental results on seven challenging benchmark datasets for human action recognition demonstrate the effectiveness of the proposed method.	[Liu, Jun; Shahroudy, Amir; Kot, Alex C.] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; [Wang, Gang] Alibaba Grp, Hangzhou 310052, Zhejiang, Peoples R China; [Xu, Dong] Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Alibaba Group; University of Sydney	Liu, J (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.	jliu029@ntu.edu.sg; amir3@ntu.edu.sg; dong.xu@sydney.edu.au; eackot@ntu.edu.sg; wanggang@ntu.edu.sg	Xu, Dong/A-3694-2011; Shahroudy, Amir/T-2261-2017	Xu, Dong/0000-0003-2775-9730; Liu, Jun/0000-0002-4365-4165; Shahroudy, Amir/0000-0002-1045-6437; Kot, Alex/0000-0001-6262-8125	National Research Foundation, Singapore, under its IDM Strategic Research Programme	National Research Foundation, Singapore, under its IDM Strategic Research Programme	ROSE Lab is supported by National Research Foundation, Singapore, under its IDM Strategic Research Programme. We thank NVIDIA AI Technology Centre for GPU donation.	Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Anirudh R, 2015, PROC CVPR IEEE, P3147, DOI 10.1109/CVPR.2015.7298934; [Anonymous], 2014, ISSNIP; [Anonymous], 2013, IEEE C COMP VIS PATT; Aydin R, 2014, IN C IND ENG ENG MAN, P1, DOI 10.1109/IEEM.2014.7058588; Cai XY, 2016, IEEE T MULTIMEDIA, V18, P141, DOI 10.1109/TMM.2015.2505089; Chen C, 2016, INT CONF ACOUST SPEE, P2712, DOI 10.1109/ICASSP.2016.7472170; Cheron G., 2015, P INT C COMP VIS; Chrungoo A, 2014, LECT NOTES ARTIF INT, V8755, P84, DOI 10.1007/978-3-319-11973-1_9; Cippitelli E., 2016, P 2 IET INT C TECHN, P1, DOI DOI 10.1049/IC.2016.0063; Collobert R., 2011, NIPS; Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33; Deng ZW, 2016, PROC CVPR IEEE, P4772, DOI 10.1109/CVPR.2016.516; Devanne M, 2015, IEEE T CYBERNETICS, V45, P1340, DOI 10.1109/TCYB.2014.2350774; Devanne M, 2013, LECT NOTES COMPUT SC, V8158, P456, DOI 10.1007/978-3-642-41190-8_49; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714; Escalera S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2522848.2532595; Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772; Fernando B, 2017, IEEE T PATTERN ANAL, V39, P773, DOI 10.1109/TPAMI.2016.2558148; Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176; Garcia-Hernando G, 2017, PROC CVPR IEEE, P407, DOI 10.1109/CVPR.2017.51; Gowayyed MA, 2013, IJCAI, V1, P1351; Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947; Graves A, 2012, STUD COMPUT INTELL, V385, P37; Han F, 2017, COMPUT VIS IMAGE UND, V158, P85, DOI 10.1016/j.cviu.2017.01.011; Harvey F. G., 2015, ARXIV151106653, P553; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; HU JF, 2015, PROC CVPR IEEE, P5344; Hu JF, 2016, LECT NOTES COMPUT SC, V9905, P280, DOI 10.1007/978-3-319-46448-0_17; Huang ZW, 2017, PROC CVPR IEEE, P1243, DOI 10.1109/CVPR.2017.137; Ibrahim MS, 2016, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2016.217; JAIN A, 2016, PROC CVPR IEEE, P5308, DOI DOI 10.1109/CVPR.2016.573; Jetley S., 2014, P AS C COMP VIS CHAM, P129; Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396; Jiang M, 2015, SIGNAL PROCESS-IMAGE, V33, P29, DOI 10.1016/j.image.2015.02.004; Kapsouras I, 2014, J VIS COMMUN IMAGE R, V25, P1432, DOI 10.1016/j.jvcir.2014.04.007; Li Q, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P159, DOI 10.1145/2911996.2912001; Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273; Li WB, 2015, IEEE I CONF COMP VIS, P4444, DOI 10.1109/ICCV.2015.505; Li YH, 2016, LECT NOTES COMPUT SC, V9911, P203, DOI 10.1007/978-3-319-46478-7_13; Lillo I, 2016, PROC CVPR IEEE, P1981, DOI 10.1109/CVPR.2016.218; Lillo I, 2014, PROC CVPR IEEE, P812, DOI 10.1109/CVPR.2014.109; Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50; Liu Z, 2016, IMAGE VISION COMPUT, V55, P93, DOI 10.1016/j.imavis.2016.04.004; Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019; Luo JJ, 2013, IEEE I CONF COMP VIS, P1809, DOI 10.1109/ICCV.2013.227; Luo ZL, 2017, PROC CVPR IEEE, P7101, DOI 10.1109/CVPR.2017.751; MA SG, 2016, PROC CVPR IEEE, P1942, DOI DOI 10.1109/CVPR.2016.214; Mahasseni B, 2016, PROC CVPR IEEE, P3054, DOI 10.1109/CVPR.2016.333; Meng M, 2015, IEEE INT CONF AUTOMA, DOI 10.1109/MWSYM.2015.7166850; Mesnil G, 2013, INTERSPEECH, P3738; Mikolov T, 2011, INT CONF ACOUST SPEE, P5528; Ni BB, 2016, PROC CVPR IEEE, P1020, DOI 10.1109/CVPR.2016.116; Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007; Ofli F, 2013, IEEE WORK APP COMP, P53, DOI 10.1109/WACV.2013.6474999; Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76; Pfister T, 2014, LECT NOTES COMPUT SC, V8694, P814, DOI 10.1007/978-3-319-10599-4_52; Rahmani H, 2016, PROC CVPR IEEE, P1506, DOI 10.1109/CVPR.2016.167; Rahmani H, 2015, PROC CVPR IEEE, P2458, DOI 10.1109/CVPR.2015.7298860; Rahmani H, 2014, IEEE WINT CONF APPL, P626, DOI 10.1109/WACV.2014.6836044; Richard A, 2017, PROC CVPR IEEE, P1273, DOI 10.1109/CVPR.2017.140; Salih AA, 2016, PATTERN RECOGN LETT, V83, P32, DOI 10.1016/j.patrec.2016.05.032; Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312; Shahroudy A, 2016, IEEE T PATTERN ANAL, V38, P2123, DOI 10.1109/TPAMI.2015.2505295; Shahroudy A, 2014, 2014 6TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING (ISCCSP), P73, DOI 10.1109/ISCCSP.2014.6877819; Shi ZY, 2017, PROC CVPR IEEE, P4684, DOI 10.1109/CVPR.2017.498; Shu TM, 2017, PROC CVPR IEEE, P4255, DOI 10.1109/CVPR.2017.453; Singh B, 2016, PROC CVPR IEEE, P1961, DOI 10.1109/CVPR.2016.216; Slama R, 2015, PATTERN RECOGN, V48, P556, DOI 10.1016/j.patcog.2014.08.011; Srivastava N, 2015, PR MACH LEARN RES, V37, P843; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194; Sutskever I., 2014, ARXIV14093215, DOI DOI 10.1007/S10107-014-0839-0; Tao LL, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P303, DOI 10.1109/ICCVW.2015.48; Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460; Vemulapalli R, 2016, PROC CVPR IEEE, P4471, DOI 10.1109/CVPR.2016.484; Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82; Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640; Wang CY, 2016, PROC CVPR IEEE, P2639, DOI 10.1109/CVPR.2016.289; Wang HS, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P574, DOI 10.1109/ACPR.2015.7486568; Wang J, 2013, IEEE I CONF COMP VIS, P2688, DOI 10.1109/ICCV.2013.334; Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198; Wang MS, 2017, PROC CVPR IEEE, P7408, DOI 10.1109/CVPR.2017.783; Weng JW, 2017, PROC CVPR IEEE, P445, DOI 10.1109/CVPR.2017.55; Wu JX, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P453; Wu ZX, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P461, DOI 10.1145/2733373.2806222; Xia L., 2012, IEEE COMP SOC C COMP, V2012, P20, DOI DOI 10.1109/CVPRW.2012.6239233; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Yao A, 2014, PROC CVPR IEEE, P1923, DOI 10.1109/CVPR.2014.247; Yun Kiwon, 2012, 2012 IEEE COMP SOC C, P28; Zhu F, 2016, IMAGE VISION COMPUT, V55, P42, DOI 10.1016/j.imavis.2016.06.007; Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885; Zhu Y, 2013, IEEE COMPUT SOC CONF, P486, DOI 10.1109/CVPRW.2013.78; Zou B, 2009, PATTERN RECOGN, V42, P1559, DOI 10.1016/j.patcog.2008.12.024	101	223	236	17	126	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2018	40	12					3007	3021		10.1109/TPAMI.2017.2771306	http://dx.doi.org/10.1109/TPAMI.2017.2771306			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GZ4HL	29990167	Green Submitted, Green Accepted			2022-12-18	WOS:000449355500016
J	Ding, CX; Tao, DC				Ding, Changxing; Tao, Dacheng			Trunk-Branch Ensemble Convolutional Neural Networks for Video-Based Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video-based face recognition; video surveillance; blur- and pose-robust representations; convolutional neural networks		Human faces in surveillance videos often suffer from severe image blur, dramatic pose variations, and occlusion. In this paper, we propose a comprehensive framework based on Convolutional Neural Networks (CNN) to overcome challenges in video-based face recognition (VFR). First, to learn blur-robust face representations, we artificially blur training data composed of clear still images to account for a shortfall in real-world video training data. Using training data composed of both still images and artificially blurred data, CNN is encouraged to learn blur-insensitive features automatically. Second, to enhance robustness of CNN features to pose variations and occlusion, we propose a Trunk-Branch Ensemble CNN model (TBE-CNN), which extracts complementary information from holistic face images and patches cropped around facial components. TBE-CNN is an end-to-end model that extracts features efficiently by sharing the low- and middle-level convolutional layers between the trunk and branch networks. Third, to further promote the discriminative power of the representations learnt by TBE-CNN, we propose an improved triplet loss function. Systematic experiments justify the effectiveness of the proposed techniques. Most impressively, TBE-CNN achieves state-of-the-art performance on three popular video face databases: PaSC, COX Face, and YouTube Faces. With the proposed techniques, we also obtain the first place in the BTAS 2016 Video Person Recognition Evaluation.	[Ding, Changxing] South China Univ Technol, Sch Elect & Informat Engn, 381 Wushan Rd, Guangzhou 510000, Guangdong, Peoples R China; [Tao, Dacheng] Univ Sydney, UBTech Sydney Artificial Intelligence Inst, Darlington, NSW 2008, Australia; [Tao, Dacheng] Univ Sydney, Fac Engn & Informat Technol, Sch Informat Technol, Darlington, NSW 2008, Australia	South China University of Technology; University of Sydney; University of Sydney	Ding, CX (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, 381 Wushan Rd, Guangzhou 510000, Guangdong, Peoples R China.	chxding@scut.edu.cn; dacheng.tao@sydney.edu.au	Ding, Changxing/L-7075-2019		Australian Research Council [DP-140102164, FT-130101457]	Australian Research Council(Australian Research Council)	This work is partially supported by Australian Research Council Projects FT-130101457 and DP-140102164.	Ahonen T., 2008, PATTERN RECOGN, P1; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arashloo SR, 2011, IEEE T PATTERN ANAL, V33, P1274, DOI 10.1109/TPAMI.2010.209; Barr JR, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412660024; Beveridge J. R., 2013, P 6 INT C BIOMETRICS, P1; Beveridge JR, 2015, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2015.7163156; Bicego M, 2006, LECT NOTES COMPUT SC, V3832, P113; Biswas S, 2013, IEEE T PATTERN ANAL, V35, P3037, DOI 10.1109/TPAMI.2013.68; Bourlai T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY (HST), P54, DOI 10.1109/THS.2013.6698976; Chan CH, 2013, IEEE T PATTERN ANAL, V35, P1164, DOI 10.1109/TPAMI.2012.199; Chen D, 2017, IEEE T PATTERN ANAL, V39, P32, DOI 10.1109/TPAMI.2016.2533383; Chen YC, 2012, LECT NOTES COMPUT SC, V7577, P766, DOI 10.1007/978-3-642-33783-3_55; Cui Z, 2012, PROC CVPR IEEE, P2626, DOI 10.1109/CVPR.2012.6247982; Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089; Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338; Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042; Girshick R, 2015, PROC CVPR IEEE, P437, DOI 10.1109/CVPR.2015.7298641; Gopalan R, 2012, IEEE T PATTERN ANAL, V34, P1220, DOI 10.1109/TPAMI.2012.15; Hadid A, 2009, PATTERN RECOGN, V42, P2818, DOI 10.1016/j.patcog.2009.02.011; Harandi M. T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2705, DOI 10.1109/CVPR.2011.5995564; Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7; Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242; Hu YQ, 2012, IEEE T PATTERN ANAL, V34, P1992, DOI 10.1109/TPAMI.2011.283; Huang GB, 2007, 07 UMASS TR; Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132; Huang ZW, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493448; Huang ZW, 2014, PROC CVPR IEEE, P1677, DOI 10.1109/CVPR.2014.217; Huang ZW, 2015, PATTERN RECOGN, V48, P3113, DOI 10.1016/j.patcog.2015.03.011; Jaderberg M., 2015, ADV NEURAL INFORM PR, P2017, DOI DOI 10.1038/NBT.3343; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170; Li HA, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON MANAGEMENT SCIENCE AND MANAGEMENT INNOVATION, P17; Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170; Liu J., 2015, ARXIV150607310; Liu LQ, 2014, IEEE T CIRC SYST VID, V24, P1874, DOI 10.1109/TCSVT.2014.2319671; Lu JW, 2015, PROC CVPR IEEE, P1137, DOI 10.1109/CVPR.2015.7298717; Mau S., 2013, ARXIV13036361; Nishiyama M, 2011, IEEE T PATTERN ANAL, V33, P838, DOI 10.1109/TPAMI.2010.203; Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257; Parkhi OM, 2014, PROC CVPR IEEE, P1693, DOI 10.1109/CVPR.2014.219; Parkhi Omkar M., 2015, BRIT MACH VIS C; Philip J, 2015, PALLIAT SUPPORT CARE, V13, P1519, DOI 10.1017/S1478951513000576; RoyChowdhury A., 2015, ARXIV150601342; Savalle P.-A., 2014, P EUR C COMP VIS PAT, P1; Scheirer WJ, 2016, INT CONF BIOMETR THE, DOI 10.1109/BTAS.2016.7791198; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Shao M, 2016, NEUROCOMPUTING, V171, P982, DOI 10.1016/j.neucom.2015.07.023; Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22; Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677; Sun Y., 2015, ARXIV PREPRINT ARXIV; Sun Y., 2014, ADV NEURAL INFORM PR, P1988; Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Wan L, 2015, PROC CVPR IEEE, P851, DOI 10.1109/CVPR.2015.7298686; Wang R., 2014, ARXIV14096838; Wolf L., 2011, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2011.5995566; Xu L., 2014, INT C NEUR INF PROC, V27, P1790; Yang W, 2016, PROC CVPR IEEE, P3073, DOI 10.1109/CVPR.2016.335; Yi D., 2014, LEARNING FACE REPRES, V1411, P7923; Zhang N, 2015, ARXIV151107063; Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54; Zhang TH, 2009, IEEE T KNOWL DATA EN, V21, P1299, DOI 10.1109/TKDE.2008.212; Zhu PF, 2014, IEEE T INF FOREN SEC, V9, P1120, DOI 10.1109/TIFS.2014.2324277	66	223	229	7	178	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2018	40	4					1002	1014		10.1109/TPAMI.2017.2700390	http://dx.doi.org/10.1109/TPAMI.2017.2700390			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FY2ZU	28475048	Green Accepted			2022-12-18	WOS:000426687100017
J	Duchenne, O; Bach, F; Kweon, IS; Ponce, J				Duchenne, Olivier; Bach, Francis; Kweon, In-So; Ponce, Jean			A Tensor-Based Algorithm for High-Order Graph Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hypergraphs; graph matching; image feature matching		This paper addresses the problem of establishing correspondences between two sets of visual features using higher order constraints instead of the unary or pairwise ones used in classical methods. Concretely, the corresponding hypergraph matching problem is formulated as the maximization of a multilinear objective function over all permutations of the features. This function is defined by a tensor representing the affinity between feature tuples. It is maximized using a generalization of spectral techniques where a relaxed problem is first solved by a multidimensional power method and the solution is then projected onto the closest assignment matrix. The proposed approach has been implemented, and it is compared to state-of-the-art algorithms on both synthetic and real data.	[Duchenne, Olivier; Ponce, Jean] Ecole Normale Super, Willow Lab, INRIA, F-75214 Paris 13, France; [Bach, Francis] INRIA, Sierra Lab, F-75214 Paris 13, France; [Kweon, In-So] Korea Adv Inst Sci & Technol, Dept Elect Engn, Taejon 305701, South Korea; [Kweon, In-So] Korea Adv Inst Sci & Technol, Dept Automat & Design Engn, Taejon 305701, South Korea	Inria; Inria; Korea Advanced Institute of Science & Technology (KAIST); Korea Advanced Institute of Science & Technology (KAIST)	Duchenne, O (corresponding author), Ecole Normale Super, Willow Lab, INRIA, 23 Ave Italie, F-75214 Paris 13, France.	olivier.duchenne@ens.fr; francis.bach@ens.fr; iskweon@kaist.ac.kr; jean.ponce@ens.fr	Kweon, In So/C-2023-2011		Agence Nationale de la Recherche; ERC; Korea Association of Robot industry (KAR); Korea government (MKE) [10031903]; Defense Acquisition Program Administration; Agency for Defense Development, Korea, through the Image Information Research Center at KAIST	Agence Nationale de la Recherche(French National Research Agency (ANR)); ERC(European Research Council (ERC)European Commission); Korea Association of Robot industry (KAR); Korea government (MKE)(Korean GovernmentMinistry of Trade, Industry & Energy (MOTIE), Republic of Korea); Defense Acquisition Program Administration; Agency for Defense Development, Korea, through the Image Information Research Center at KAIST	The authors would like to thank Choi Ouk for very helpful discussions, which has inspired this article a lot. This paper was supported in part by a grant from the Agence Nationale de la Recherche (MGA Project), by the ERC grants SIERRA and VideoWorld, by the Korea Association of Robot industry (KAR) grant funded by the Korea government (MKE) (No. 10031903), and by the Defense Acquisition Program Administration and Agency for Defense Development, Korea, through the Image Information Research Center at KAIST.	ALMOHAMAD HA, 1993, IEEE T PATTERN ANAL, V15, P522, DOI 10.1109/34.211474; Ballard D.H., 1982, COMPUTER VISION; Berg AC, 2005, PROC CVPR IEEE, P26; Birchfield S., 1998, KLT IMPLEMENTATION K; Caetano T., 2007, P IEEE INT C COMP VI; Cour T., 2007, P NEUR INF PROC SYST; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1324, DOI 10.1137/S0895479898346995; Duchenne O., 2009, P IEEE C COMP VIS PA; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Frobenius G, 1912, SITZBER K PREUSS AKA, P456; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Griffin Gregory, 2007, CALTECH 256 OBJECT C; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; Huttenlocher D.P., 1987, P IEEE INT C COMP VI; KOHLI P, 2007, P IEEE C COMP VIS PA; Lazebnik S., 2006, P IEEE C COMP VIS PA; Leordeanu M., 2005, P IEEE INT C COMP VI; Leordeanu M., 2007, P IEEE C COMP VIS PA; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maciel J, 2003, IEEE T PATTERN ANAL, V25, P187, DOI 10.1109/TPAMI.2003.1177151; Oliveira R., 2006, P EUR C COMP VIS; Pratikakis I., 2009, P EG WORKSH 3D OBJ R; Pritchett P., 1998, P IEEE INT C COMP VI; Regalia P.A., 2000, P IEEE INT C AC SPEE; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; Vedaldi A., 2008, MATLAB IMPLEMENTATIO; Zaslavskiy M, 2009, IEEE T PATTERN ANAL, V31, P2227, DOI 10.1109/TPAMI.2008.245; Zass R., 2008, P IEEE C COMP VIS PA; ZHANG H, 2006, P IEEE C COMP VIS PA; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zheng YF, 2006, IEEE T PATTERN ANAL, V28, P643, DOI 10.1109/TPAMI.2006.81	32	223	242	1	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2011	33	12					2383	2395		10.1109/TPAMI.2011.110	http://dx.doi.org/10.1109/TPAMI.2011.110			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	834RE	21646677	Green Submitted			2022-12-18	WOS:000295980000006
J	Jiang, XD; Mandal, B; Kot, A				Jiang, Xudong; Mandal, Bappaditya; Kot, Alex			Eigenfeature regularization and extraction in face recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face recognition; linear discriminant analysis; regularization; feature extraction; subspace methods	LINEAR DISCRIMINANT-ANALYSIS; SAMPLE; LDA; FRAMEWORK; ROBUST; MODEL; PCA	This work proposes a subspace approach that regularizes and extracts eigenfeatures from the face image. Eigenspace of the within-class scatter matrix is decomposed into three subspaces: a reliable subspace spanned mainly by the facial variation, an unstable subspace due to noise and finite number of training samples, and a null subspace. Eigenfeatures are regularized differently in these three subspaces based on an eigenspectrum model to alleviate problems of instability, overfitting, or poor generalization. This also enables the discriminant evaluation performed in the whole space. Feature extraction or dimensionality reduction occurs only at the final stage after the discriminant assessment. These efforts facilitate a discriminative and a stable low-dimensional feature representation of the face image. Experiments comparing the proposed approach with some other popular subspace methods on the FERET, ORL, AR, and GT databases show that our method consistently outperforms others.	[Jiang, Xudong; Mandal, Bappaditya; Kot, Alex] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Jiang, XD (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.	exdjiang@ntu.edu.sg; bapp0001@ntu.edu.sg; eackot@ntu.edu.sg	Jiang, Xudong/B-1555-2008	Jiang, Xudong/0000-0002-9104-2315				[Anonymous], GEORGIA TECH FACE DA; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Beveridge R., 2003, CSU FACE IDENTIFICAT; Cevikalp H, 2005, IEEE T PATTERN ANAL, V27, P4, DOI 10.1109/TPAMI.2005.9; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; Chen WS, 2005, IEEE T SYST MAN CY B, V35, P659, DOI 10.1109/TSMCB.2005.844596; Dai DQ, 2003, PATTERN RECOGN, V36, P845, DOI 10.1016/S0031-3203(02)00092-4; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Jiang XD, 2006, ELECTRON LETT, V42, P1089, DOI 10.1049/el:20062035; Ke Liu, 1992, International Journal of Pattern Recognition and Artificial Intelligence, V6, P817, DOI 10.1142/S0218001492000412; Kim J, 2005, IEEE T PATTERN ANAL, V27, P1977, DOI 10.1109/TPAMI.2005.242; Kim TK, 2005, IEEE T PATTERN ANAL, V27, P318, DOI 10.1109/TPAMI.2005.58; Kim TK, 2004, PATTERN RECOGN, V37, P1873, DOI 10.1016/j.patcog.2004.01.019; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; Liu CJ, 1998, INT C PATT RECOG, P1368, DOI 10.1109/ICPR.1998.711956; Liu CJ, 2004, IEEE T PATTERN ANAL, V26, P572, DOI 10.1109/TPAMI.2004.1273927; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Liu CJ, 2000, IEEE T IMAGE PROCESS, V9, P132, DOI 10.1109/83.817604; Liu QS, 2004, IEEE T CIRC SYST VID, V14, P42, DOI 10.1109/TCSVT.2003.818352; Liu W, 2004, LECT NOTES COMPUT SC, V3087, P32; Lu JW, 2006, IEEE T NEURAL NETWOR, V17, P166, DOI 10.1109/TNN.2005.860853; Lu JW, 2005, PATTERN RECOGN LETT, V26, P181, DOI 10.1016/j.patrec.2004.09.014; Lu JW, 2003, PATTERN RECOGN LETT, V24, P3079, DOI 10.1016/S0167-8655(03)00167-3; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P195, DOI 10.1109/TNN.2002.806647; Martinez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P780, DOI 10.1109/TPAMI.2002.1008384; Park BG, 2005, IEEE T PATTERN ANAL, V27, P1982, DOI 10.1109/TPAMI.2005.243; Phillips PJ, 2005, PROC CVPR IEEE, P947; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; Wang XG, 2004, PROC CVPR IEEE, P564; Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57; Yang H, 2003, PATTERN RECOGN, V36, P563, DOI 10.1016/S0031-3203(02)00048-1; Yang J, 2005, IEEE T PATTERN ANAL, V27, P230, DOI 10.1109/TPAMI.2005.33; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	42	223	232	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2008	30	3					383	394		10.1109/TPAMI.2007.70708	http://dx.doi.org/10.1109/TPAMI.2007.70708			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	250FT	18195434				2022-12-18	WOS:000252286100002
J	ENS, J; LAWRENCE, P				ENS, J; LAWRENCE, P			AN INVESTIGATION OF METHODS FOR DETERMINING DEPTH FROM FOCUS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						DEPTH FROM FOCUS; RANGE DETECTION		The concept of depth from focus involves calculating distances to points in an observed scene by modeling the effect that the camera's focal parameters have on images acquired with a small depth of field. This technique is passive and requires only a single camera. The most difficult segment of calculating depth from focus is deconvolving the defocus operator from the scene and modeling it. Most current methods for determining the defocus operator employ inverse filtering. This paper will reveal some fundamental problems with inverse filtering: inaccuracies in the finding the frequency domain representation, windowing effects, and border effects. A general, matrix-based method using regularization will be presented, which eliminates these problems. The new method will also be confirmed experimentally, with the results showing an rms error of 1.3%.	UNIV BRITISH COLUMBIA,DEPT ELECT ENGN,VANCOUVER V6T 1W5,BC,CANADA	University of British Columbia	ENS, J (corresponding author), INTENSE TECHNOL,RICHMOND V6X 3C8,PQ,CANADA.							Andrews H.C., 1977, DIGITAL IMAGE RESTOR; BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962; Born M., 1980, PRINCIPLES OPTICS, P180; BOVE VM, 1989, 1989 TECH DIG SERIES, V14, P118; Bracewell R., 1986, FOURIER TRANSFORM IT; ENS JE, 1990, THESIS U BRIT COLUMB; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; GIROD B, 1989, OPTICS ILLUMINATION, V1194; Gonzalez R. C., 1987, DIGITAL IMAGE PROCES; HADAMARD J, 1952, LECTURES CAUCHYS PRO; HARRIS FJ, 1978, P IEEE, V66, P51, DOI 10.1109/PROC.1978.10837; Hecht E., 1987, OPTICS; HOPKINS HH, 1955, PROC R SOC LON SER-A, V231, P91, DOI 10.1098/rspa.1955.0158; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1968, MIT160 AI MEM; HSING TR, 1981, P SOC PHOTO-OPT INST, V292, P218; LEI F, 1988, PHOTOGRAMM ENG REM S, V54, P41; PENTLAND A, 1982, APR P IM UND WORKSH, P253; PENTLAND A, 1989, IEEE COMP SOC C COMP, P256; Pentland A. P., 1985, P IJCAI 85 LOS ANGEL, V9, P988; PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940; Press W. H., 1987, NUMERICAL RECIPES; Rosenfeld A., 1982, DIGITAL PICTURE PROC, V1; SCHREIBER WF, 1986, SPRINGER SERIES INFO, V15; Subbarao M., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P149, DOI 10.1109/CCV.1988.589986; SUBBARAO M, 1987, 8702 STAT U NEW YORK; SUBBARAO M, 1987, 8703 U NEW YORK DEP; SUBBARAO M, 1989, MACHINE VISION INSPE, P101; SUBBARAO M, 1988, IEEE C COMP VIS PATT, P498; SUBBARAO M, 1987, DEC P IEEE COMP SOC, P58; von Helmholtz H., 1924, HELMHOLTZS TREATISE; [No title captured]	32	223	258	1	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1993	15	2					97	108		10.1109/34.192482	http://dx.doi.org/10.1109/34.192482			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KL910		Green Submitted			2022-12-18	WOS:A1993KL91000001
J	HOFFMAN, R; JAIN, AK				HOFFMAN, R; JAIN, AK			SEGMENTATION AND CLASSIFICATION OF RANGE IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48824	Michigan State University	HOFFMAN, R (corresponding author), UNIV ILLINOIS,DEPT ELECT ENGN & COMP SCI,CHICAGO,IL 60680, USA.							BADLER NI, 1979, P IEEE, V67, P1397, DOI 10.1109/PROC.1979.11475; Barrow H., 1978, COMPUT VIS SYST, V2, P2; BESL P, 1984, RSDTR2084 U MICH COL; BESL PJ, 1985, COMPUT SURV, V17, P75, DOI 10.1145/4078.4081; BRADY M, 1984, 1ST P IEEE C ROB, P256; COGGINS JM, 1982, THESIS MICHIGAN STAT; COLEMAN GB, 1979, P IEEE, V67, P773, DOI 10.1109/PROC.1979.11327; Conover WJ, 1980, PRACTICAL NONPARAMET; CONWAY JB, 1978, FUNCTIONS ONE COMPLE; DUBES R, 1976, PATTERN RECOGN, V8, P247, DOI 10.1016/0031-3203(76)90045-5; DUDA RO, 1979, IEEE T PATTERN ANAL, V1, P259, DOI 10.1109/TPAMI.1979.4766922; Faugeras O. D., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P8; GOWDA KC, 1978, PATTERN RECOGN, V10, P105; Gu W. K., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P192; HALL EL, 1982, COMPUTER, V15, P42; Hoffman RL, 1986, THESIS MICHIGAN STAT; HURT SL, 1984, PATTERN RECOGN, V17, P407, DOI 10.1016/0031-3203(84)90069-4; Inokuchi S., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P806; INOKUCHI S, 1982, 6TH P INT C PATT REC, P918; Ittner D. J., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P119; JARVIS RA, 1976, MICROSCOPE, V24, P163; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; LU SW, 1985, NOV P INT FED AUT CO, P389; MILGRAM DL, 1980, 5TH P INT C PATT REC, P912; MITICHE A, 1983, IEEE T PATTERN ANAL, V5, P174, DOI 10.1109/TPAMI.1983.4767369; Muller Y., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P1101; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; PONCE J, 1985, 2ND P IEEE INT C ROB, P420; POSDAMER JL, 1982, COMPUT VISION GRAPH, V18, P1, DOI 10.1016/0146-664X(82)90096-X; RADACK GM, 1984, MSCIS8413 U PENN DEP; SAMPSON RE, 1985, REAL TIME 3 DIMENSIO; STOCKMAN G, 1985, MSUENGR85024 MICH ST; Tomita F., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P186; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083	34	223	236	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1987	9	5					608	620		10.1109/TPAMI.1987.4767955	http://dx.doi.org/10.1109/TPAMI.1987.4767955			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	J7393	21869419				2022-12-18	WOS:A1987J739300002
J	GRIMSON, WEL; LOZANOPEREZ, T				GRIMSON, WEL; LOZANOPEREZ, T			LOCALIZING OVERLAPPING PARTS BY SEARCHING THE INTERPRETATION TREE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MIT, ARTIFICIAL INTELLIGENCE LAB, CAMBRIDGE, MA 02139 USA	Massachusetts Institute of Technology (MIT)	GRIMSON, WEL (corresponding author), MIT, DEPT ELECT ENGN & COMP SCI, 545 TECHNOL SQ, CAMBRIDGE, MA 02139 USA.		Lozano-Perez, Tomas/J-9374-2012	Lozano-Perez, Tomas/0000-0002-8657-2450				AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; AYACHE NJ, 1982, 6TH P INT C PATT REC; BAIRD H, 1986, MODEL BASED IMAGE MA; Ballard D.H., 1982, COMPUTER VISION; BESL PJ, 1985, COMPUT SURV, V17, P75, DOI 10.1145/4078.4081; BHANU B, 1984, IEEE T PATTERN ANAL, V6; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; BOLLES RC, 1983, 1ST INT S ROB RES BR; BRADY M, 1984, ROBOTICS RES, P413; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; DRUMHELLER M, THESIS MIT; DRUMHELLER M, MIT AI826 LAB MEM; FAUGERAS OD, 1983, 8TH P INT JOINT C AR, P996; FAUGERAS OD, P CVPR 83 WASHINGTON; FREUDER EC, 1982, J ACM, V29, P24, DOI 10.1145/322290.322292; FREUDER EC, 1978, COMMUN ACM, V21, P958, DOI 10.1145/359642.359654; GASTON PC, 1984, IEEE T PATTERN ANAL, V6, P257, DOI 10.1109/TPAMI.1984.4767518; GOAD C, 1983, P DARPA IMAGE UNDERS; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; GRIMSON WEL, 1986, J ACM, V33, P658, DOI 10.1145/6490.6492; GRIMSON WEL, MIT AI763 LAB MEM; HARALICK RM, 1980, ARTIF INTELL, V14, P263, DOI 10.1016/0004-3702(80)90051-X; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; LOWE DG, 1986, 62 COUR I ROB REP; MACKWORTH AK, 1977, ARTIF INTELL, V8, P99, DOI 10.1016/0004-3702(77)90007-8; MACKWORTH AK, 1985, ARTIF INTELL, V25, P65, DOI 10.1016/0004-3702(85)90041-4; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MONTANAR.U, 1974, INFORM SCIENCES, V7, P95, DOI 10.1016/0020-0255(74)90008-5; STOCKMAN G, 1984, TR84002 MICH STAT U; TURNEY JL, 1985, IEEE T PATTERN ANAL, V7, P410, DOI 10.1109/TPAMI.1985.4767680; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19	31	223	230	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1987	9	4					469	482		10.1109/TPAMI.1987.4767935	http://dx.doi.org/10.1109/TPAMI.1987.4767935			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	H9088	21869405				2022-12-18	WOS:A1987H908800001
J	Ramanan, D; Forsyth, DA; Zisserman, A				Ramanan, Deva; Forsyth, David A.; Zisserman, Andrew			Tracking people by learning their appearance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						people tracking; motion capture; surveillance		An open vision problem is to automatically track the articulations of people from a video sequence. This problem is difficult because one needs to determine both the number of people in each frame and estimate their configurations. But, finding people and localizing their limbs is hard because people can move fast and unpredictably, can appear in a variety of poses and clothes, and are often surrounded by limb-like clutter. We develop a completely automatic system that works in two stages; it first builds a model of appearance of each person in a video and then it tracks by detecting those models in each frame ("tracking by model-building and detection"). We develop two algorithms that build models; one bottom-up approach groups together candidate body parts found throughout a sequence. We also describe a top-down approach that automatically builds people-models by detecting convenient key poses within a sequence. We finally show that building a discriminative model of appearance is quite helpful since it exploits structure in a background (without background-subtraction). We demonstrate the resulting tracker on hundreds of thousands of frames of unscripted indoor and outdoor activity, a feature-length film ("Run Lola Run"), and legacy sports footage ( from the 2002 World Series and 1998 Winter Olympics). Experiments suggest that our system 1) can count distinct individuals, 2) can identify and track them, 3) can recover when it loses track, for example, if individuals are occluded or briefly leave the view, 4) can identify body configuration accurately, and 5) is not dependent on particular models of human motion.	Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; Univ Oxford, Dept Engn Sci, Oxford OX1 4AJ, England	University of Illinois System; University of Illinois Urbana-Champaign; University of Oxford	Ramanan, D (corresponding author), Univ Illinois, Dept Comp Sci, 3310 Siebel Hall, Urbana, IL 61801 USA.	ramanan@tti-c.org; daf@cs.uiuc.edu; az@robots.ox.ac.uk						AGARWAL A, 2004, P EUR C COMP VIS; Blackman S. S., 1999, DESIGN ANAL MODERN T; Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; COLLINS R, 2003, P INT C COMP VIS; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Deutscher J, 2000, PROC CVPR IEEE, P126, DOI 10.1109/CVPR.2000.854758; DEUTSCHER J, 2001, COMPUTER VISION PATT; Felzenszwalb P. F., 2005, INT J COMPUTER VISIO, V61; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; FREEMAN WT, 2000, IEEE T INFORM THEORY; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056; GAVRILA DM, 2000, P EUR C COMP VIS, P37; HOGG D, 1983, IMAGE VISION COMPUT, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3; HUA MHY, 2005, COMPUTER VISION PATT; IOFFE S, 2001, INT J COMPUTER VISIO; Ioffe S., 2001, P INT C COMP VIS; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Isard M., 2003, COMPUTER VISION PATT; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; KUMAR MP, 2004, P IND C VIS GRAPH IM; Lee M.W., 2004, COMPUTER VISION PATT; MORI G, 2004, COMPUTER VISION PATT; Mori G., 2002, P EUR C COMP VIS; OROURKE J, 1980, IEEE T PATTERN ANAL, V2, P522, DOI 10.1109/TPAMI.1980.6447699; Pavlovic V., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P94, DOI 10.1109/ICCV.1999.791203; RAMANAN D, 2005, COMPUTER VISION PATT; Ramanan D., 2005, THESIS U CALIFORNIA; Ramanan D., 2003, P NEUR INF PROC SYST; RAMANAN D, 2003, COMPUTER VISION PATT; REHG JM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P612, DOI 10.1109/ICCV.1995.466882; ROBERTS TJ, 2004, P EUR C COMP VIS; ROHR K, 1993, CVPR, P9; RONFARD R, 2002, P EUR C COMP VIS; Sidenbladh H., 2000, P EUR C COMP VIS; SIGAL L, 2004, COMPUTER VISION PATT; SMINCHISESCU C, 2001, COMPUTER VISION PATT; Song Y, 2000, PROC CVPR IEEE, P810, DOI 10.1109/CVPR.2000.855904; SUDDERTH EB, 2003, COMPUTER VISION PATT; Sullivan J., 2002, P EUR C COMP VIS; THAYANANTHAN A, 2003, COMPUTER VISION PATT; Toyama K, 2002, INT J COMPUT VISION, V48, P9, DOI 10.1023/A:1014899027014; Vapnik V.N, 1998, STAT LEARNING THEORY; Viola P., 2003, P INT C COMP VIS; Viola P. A., 2001, CVPR 1; Yedidia J., 2001, P INT JOINT C ART IN	46	222	229	1	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2007	29	1					65	81		10.1109/TPAMI.2007.250600	http://dx.doi.org/10.1109/TPAMI.2007.250600			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	104VI	17108384				2022-12-18	WOS:000241988300006
J	Luo, B; Hancock, ER				Luo, B; Hancock, ER			Structural graph matching using the EM algorithm and singular value decomposition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						inexact graph matching; EM algorithm; matrix factorization; mixture models; Delaunay triangulations	DISCRETE RELAXATION; PATTERN-RECOGNITION; STATISTICAL PHYSICS; SUBGRAPH; VISION; SEARCH; IMAGES	This paper describes an efficient algorithm for inexact graph matching. The method is purely structural, that is to say, it uses only the edge or connectivity structure of the graph and does not draw on node or edge attributes. We make two contributions. Commencing from: a probability distribution for matching errors, we show how the problem of graph matching can be posed as maximum-likelihood estimation using the apparatus of the EM algorithm. Our second contribution is to cast the recovery of correspondence matches, between the graph nodes in a matrix framework. This allows us to efficiently recover correspondence matches, using singular value decomposition. We experiment with the method on both real-world and synthetic data. Here, we demonstrate that the method offers comparable performance to more computationally demanding methods.	Univ York, Dept Comp Sci, York YO1 5DD, N Yorkshire, England	University of York - UK	Luo, B (corresponding author), Univ York, Dept Comp Sci, York YO1 5DD, N Yorkshire, England.	luo@cs.york.ac.uk; erh@cs.york.ac.uk	Hancock, Edwin/N-7548-2019; Hancock, Edwin R/C-6071-2008; Luo, Bin/Y-1233-2018	Hancock, Edwin/0000-0003-4496-2028; Hancock, Edwin R/0000-0003-4496-2028; Luo, Bin/0000-0001-5948-5055				AMBLER AP, 1973, P 3 INT JOINT C ART, P298; Barrow H. G., 1971, Machine Intelligence Volume 6, P377; Bishop, 1995, NEURAL NETWORKS PATT; BLAKER RE, 1987, NATO ASI SER, V30, P355; BOYER KL, 1988, IEEE T PATTERN ANAL, V10, P144, DOI 10.1109/34.3880; BRIDLE JS, 1990, P ADV NEUR INF PROC, P211; Bunke H, 1998, PATTERN RECOGN LETT, V19, P255, DOI 10.1016/S0167-8655(97)00179-7; Bunke H, 1983, PATTERN RECOGN LETT, V1, P245, DOI 10.1016/0167-8655(83)90033-8; Bunke H, 1997, INT J PATTERN RECOGN, V11, P169, DOI 10.1142/S0218001497000081; Bunke H, 1999, IEEE T PATTERN ANAL, V21, P917, DOI 10.1109/34.790431; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; Cross ADJ, 1998, IEEE T PATTERN ANAL, V20, P1236, DOI 10.1109/34.730557; Cross ADJ, 1997, PATTERN RECOGN, V30, P953, DOI 10.1016/S0031-3203(96)00123-9; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; ESHERA MA, 1986, IEEE T PATTERN ANAL, V8, P604, DOI 10.1109/TPAMI.1986.4767835; Finch AM, 1998, NEURAL COMPUT, V10, P1873, DOI 10.1162/089976698300017188; Finch AM, 1998, PATTERN RECOGN, V31, P1777, DOI 10.1016/S0031-3203(98)00010-7; Finch AM, 1997, ADV NEUR IN, V9, P438; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; HERAULT I, 1990, P BRIT MACH VIS C, P319; Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806; HORAUD R, 1989, IEEE T PATTERN ANAL, V11, P1168, DOI 10.1109/34.42855; Horaud R, 1995, PATTERN RECOGN, V28, P1855, DOI 10.1016/0031-3203(95)00048-8; HORNEGGER J, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P914, DOI 10.1109/ICCV.1995.466838; Luo B, 1999, PATTERN RECOGN LETT, V20, P635, DOI 10.1016/S0167-8655(99)00028-8; McLachlan G.J., 1988, MIXTURE MODELS INFER, V38; Moss S, 1997, IMAGE VISION COMPUT, V15, P637, DOI 10.1016/S0262-8856(97)00014-0; Pelillo M, 1999, NEURAL COMPUT, V11, P1933, DOI 10.1162/089976699300016034; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; PETERSON C, 1989, INT J NEURAL SYST, V1, P2; Rangarajan A, 1996, NEURAL COMPUT, V8, P1041, DOI 10.1162/neco.1996.8.5.1041; Ripley BD., 1996; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175; SCOTT GL, 1991, P ROY SOC B-BIOL SCI, V244, P21, DOI 10.1098/rspb.1991.0045; Sengupta K, 1998, COMPUT VIS IMAGE UND, V70, P177, DOI 10.1006/cviu.1997.0631; SHAPIRO LG, 1985, IEEE T PATTERN ANAL, V7, P90, DOI 10.1109/TPAMI.1985.4767621; SHAPIRO LS, 1992, IMAGE VISION COMPUT, V10, P283, DOI 10.1016/0262-8856(92)90043-3; Shokoufandeh A., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P491, DOI 10.1109/CVPR.1999.784726; Simic PD, 1991, NEURAL COMPUT, V3, P268, DOI 10.1162/neco.1991.3.2.268; SUGANTHAN PN, 1995, PATTERN RECOGN, V28, P997, DOI 10.1016/0031-3203(94)00166-J; Tirthapura S, 1998, P SOC PHOTO-OPT INS, V3527, P25, DOI 10.1117/12.325825; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; UTANS J, 1993, TR93004 ICSI; WELLS WM, 1991, IEEE COMP SOC COMP V, P486; Williams ML, 1999, PATTERN RECOGN, V32, P1255, DOI 10.1016/S0031-3203(98)00152-6; Wilson RC, 1997, IEEE T PATTERN ANAL, V19, P634, DOI 10.1109/34.601251; WONG AKC, 1985, IEEE T PATTERN ANAL, V7, P599, DOI 10.1109/TPAMI.1985.4767707; YUILLE AL, 1994, NEURAL COMPUT, V6, P334, DOI 10.1162/neco.1994.6.2.334; YUILLE AL, 1994, NEURAL COMPUT, V6, P341, DOI 10.1162/neco.1994.6.3.341; [No title captured]	52	222	236	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2001	23	10					1120	1136		10.1109/34.954602	http://dx.doi.org/10.1109/34.954602			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	482QK		Green Published, Green Accepted			2022-12-18	WOS:000171586600006
J	SADJADI, FA; HALL, EL				SADJADI, FA; HALL, EL			3-DIMENSIONAL MOMENT INVARIANTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											SADJADI, FA (corresponding author), UNIV TENNESSEE,DEPT ELECT ENGN,KNOXVILLE,TN 37916, USA.		Sadjadi, Firooz/AAX-3886-2021	Hall, Ernest/0000-0003-4361-8647				HALL EL, 1975, IEEE T BIO-MED ENG, V22, P518, DOI 10.1109/TBME.1975.324475; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; SADJADI FA, 1978, P IEEE C PATTERN REC; Salmon G, 1876, LESSONS INTRO MODERN, V3rd; SPAIN B, 1960, ANAL QUADRICS	5	222	242	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	2					127	136		10.1109/TPAMI.1980.4766990	http://dx.doi.org/10.1109/TPAMI.1980.4766990			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JH803	21868883				2022-12-18	WOS:A1980JH80300004
J	Malkov, YA; Yashunin, DA				Malkov, Yu A.; Yashunin, D. A.			Efficient and Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graph and tree search strategies; artificial intelligence; information search and retrieval; information storage and retrieval; information technology and systems; search process; graphs and networks; data structures; nearest neighbor search; big data; approximate search; similarity search	NETWORKS	We present a new approach for the approximate K-nearest neighbor search based on navigable small world graphs with controllable hierarchy (Hierarchical NSW, HNSW). The proposed solution is fully graph-based, without any need for additional search structures (typically used at the coarse search stage of the most proximity graph techniques). Hierarchical NSW incrementally builds a multi-layer structure consisting of a hierarchical set of proximity graphs (layers) for nested subsets of the stored elements. The maximum layer in which an element is present is selected randomly with an exponentially decaying probability distribution. This allows producing graphs similar to the previously studied Navigable Small World (NSW) structures while additionally having the links separated by their characteristic distance scales. Starting the search from the upper layer together with utilizing the scale separation boosts the performance compared to NSW and allows a logarithmic complexity scaling. Additional employment of a heuristic for selecting proximity graph neighbors significantly increases performance at high recall and in case of highly clustered data. Performance evaluation has demonstrated that the proposed general metric space search index is able to strongly outperform previous opensource state-of-the-art vector-only approaches. Similarity of the algorithm to the skip list structure allows straightforward balanced distributed implementation.	[Malkov, Yu A.] Samsung AI Ctr, Moscow, Russia; [Yashunin, D. A.] 31-33 Ul Krasnozvezdnaya, Nizhnii Novgorod 603104, Russia		Malkov, YA (corresponding author), Samsung AI Ctr, Moscow, Russia.	yurymalkov@mail.ru; yashuninda@yandex.ru			RFBR [16-31-60104 mol_a_dk]	RFBR(Russian Foundation for Basic Research (RFBR))	We thank Leonid Boytsov for many helpful discussions, assistance with Non-Metric Space Library integration and comments on the manuscript. We thank Seth Hoffert and Azat Davletshin for the suggestions on the manuscript and the algorithm and fellows who contributed to the algorithm on the github repository. We also thank Valery Kalyagin for support of this work. The reported study was funded by RFBR, according to the research project No. 16-31-60104 mol_a_dk. The work has been done while Yury A. Malkov was with the Federal state budgetary institution of science Institute of Applied Physics of the Russian Academy of Sciences, 46 Ul'yanov Street, 603950 NizhnyNovgorod, Russia. Dmitry A. Yashunin has done this work as an independent researcher.	Andoni A, 2015, ACM S THEORY COMPUT, P793, DOI 10.1145/2746539.2746553; Andoni Alexandr, 2015, ADV NEURAL INFORM PR, P1225; [Anonymous], [No title captured]; Aoyama K., 2011, P 17 ACM SIGKDD INT, P1055; ARYA S, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P271; Babenko A, 2016, PROC CVPR IEEE, P2055, DOI 10.1109/CVPR.2016.226; Babenko A, 2012, PROC CVPR IEEE, P3069, DOI 10.1109/CVPR.2012.6248038; Beaumont O, 2007, LECT NOTES COMPUT SC, V4878, P315; Beaumont Olivier, 2007, 2007 S, P1; Boguna M, 2009, NAT PHYS, V5, P74, DOI 10.1038/NPHYS1130; Boytsov L., 2013, ADV NEURAL INFORM PR, P1574; Boytsov L, 2013, LECT NOTES COMPUT SC, V8199, P280, DOI 10.1007/978-3-642-41062-8_28; Cartozo CC, 2009, PHYS REV LETT, V102, DOI 10.1103/PhysRevLett.102.238703; Chavez E, 2015, INFORM SYST, V51, P43, DOI 10.1016/j.is.2015.02.001; Chavez E, 2008, IEEE T PATTERN ANAL, V30, P1647, DOI 10.1109/TPAMI.2007.70815; Chavez E, 2010, LECT NOTES COMPUT SC, V6256, P270, DOI 10.1007/978-3-642-15992-3_29; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Deselaers T, 2008, INT C PATT RECOG, P2100; Dong X, 2011, INSECT MOL BIOL, V20, P577, DOI 10.1111/j.1365-2583.2011.01088.x; Douze M, 2016, LECT NOTES COMPUT SC, V9906, P785, DOI 10.1007/978-3-319-46475-6_48; DWYER RA, 1991, DISCRETE COMPUT GEOM, V6, P343, DOI 10.1007/BF02574694; Esuli A., 2009, COMPUTING RES REPOSI; Goodrich MT, 2006, PROCEEDINGS OF THE SEVENTHEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P384, DOI 10.1145/1109557.1109601; Gulyas A, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8651; Harwood B, 2016, PROC CVPR IEEE, P5713, DOI 10.1109/CVPR.2016.616; Houle ME, 2015, IEEE T PATTERN ANAL, V37, P136, DOI 10.1109/TPAMI.2014.2343223; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jiang ZY, 2016, AER ADV ENG RES, V80, P325; Kalantidis Y, 2014, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR.2014.298; Karbasi A, 2015, IEEE T INFORM THEORY, V61, P3056, DOI 10.1109/TIT.2015.2418284; Kleinberg J., 2000, Proceedings of the Thirty Second Annual ACM Symposium on Theory of Computing, P163, DOI 10.1145/335305.335325; Kleinberg JM, 2000, NATURE, V406, P845, DOI 10.1038/35022643; Krioukov D, 2010, PHYS REV E, V82, DOI 10.1103/PhysRevE.82.036106; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lifshits Y, 2009, PROCEEDINGS OF THE TWENTIETH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P318; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Malkov Yury, 2012, Similarity Search and Applications. Proceedings of the 5th International Conference, SISAP 2012, P132, DOI 10.1007/978-3-642-32153-5_10; Malkov Y, 2014, INFORM SYST, V45, P61, DOI 10.1016/j.is.2013.10.006; Malkov YA, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0158162; Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376; Naidan B, 2015, PROC VLDB ENDOW, V8, P1618; Navarro G, 2002, VLDB J, V11, P28, DOI 10.1007/s007780200060; Norouzi M, 2014, IEEE T PATTERN ANAL, V36, P1107, DOI 10.1109/TPAMI.2013.231; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Ponomarenko A., 2011, P INT C INF COMM TEC; Ponomarenko Alexander, 2014, DATA ANAL, P125; PUGH W, 1990, COMMUN ACM, V33, P668, DOI 10.1145/78973.78977; Rehurek Radim, 2010, P LREC 2010 WORKSH N, P45, DOI DOI 10.13140/2.1.2393.1847; Ruiz G, 2015, LECT NOTES COMPUT SC, V9371, P103, DOI 10.1007/978-3-319-25087-8_10; Tellez ES, 2016, INFORM SYST, V60, P50, DOI 10.1016/j.is.2016.03.003; Tellez ES, 2013, INFORM SYST, V38, P1019, DOI 10.1016/j.is.2012.06.005; TOUSSAINT GT, 1980, PATTERN RECOGN, V12, P261, DOI 10.1016/0031-3203(80)90066-7; TRAVERS J, 1969, SOCIOMETRY, V32, P425, DOI 10.2307/2786545; Wang J., 2015, MULTIMEDIA DATA MINI, P397, DOI 10.1007/978-3-319-14998-1_18; Wang JQ, 2012, PROCEEDINGS OF THE 8TH EURO-ASIA CONFERENCE ON ENVIRONMENT AND CSR: TOURISM, MICE, HOSPITALITY MANAGEMENT AND EDUCATION SESSION, PT III, P179; Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918; Wieschollek P, 2016, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR.2016.223; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311	59	221	226	6	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2020	42	4					824	836		10.1109/TPAMI.2018.2889473	http://dx.doi.org/10.1109/TPAMI.2018.2889473			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LE2GI	30602420	Green Submitted			2022-12-18	WOS:000526541100005
J	Zhang, Z; Liu, L; Shen, FM; Shen, HT; Shao, L				Zhang, Zheng; Liu, Li; Shen, Fumin; Shen, Heng Tao; Shao, Ling			Binary Multi-View Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Large-scale clustering; multi-view data; efficient; short binary code; discrete representation	CODES	Clustering is a long-standing important research problem, however, remains challenging when handling large-scale image data from diverse sources. In this paper, we present a novel Binary Multi-View Clustering (BMVC) framework, which can dexterously manipulate multi-view image data and easily scale to large data. To achieve this goal, we formulate BMVC by two key components: compact collaborative discrete representation learning and binary clustering structure learning, in a joint learning framework. Specifically, BMVC collaboratively encodes the multi-view image descriptors into a compact common binary code space by considering their complementary information; the collaborative binary representations are meanwhile clustered by a binary matrix factorization model, such t hat the cluster structures are optimized in the Hamming space by pure, extremely fast bit-operations. For efficiency, the code balance constraints are imposed on both binary data representations and cluster centroids. Finally, the resulting optimization problem is solved by an alternating optimization scheme with guaranteed fast convergence. Extensive experiments on four large-scale multi-view image datasets demonstrate that the proposed method enjoys the significant reduction in both computation and memory footprint, while observing superior (in most cases) or very competitive performance, in comparison with state-of-the-art clustering methods.	[Zhang, Zheng] Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld 4072, Australia; [Liu, Li; Shao, Ling] Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates; [Shen, Fumin; Shen, Heng Tao] Univ Elect Sci & Technol China, Ctr Future Media, Chengdu 611731, Sichuan, Peoples R China; [Shen, Fumin; Shen, Heng Tao] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Sichuan, Peoples R China	University of Queensland; University of Electronic Science & Technology of China; University of Electronic Science & Technology of China	Shao, L (corresponding author), Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates.	darrenzz219@gmail.com; liuli1213@gmail.com; fumin.shen@gmail.com; shenhengtao@hotmail.com; ling.shao@ieee.org	Shao, Ling/D-3535-2011; Zhang, Zheng/M-6325-2014; Shen, Heng Tao/ABD-5331-2021	Zhang, Zheng/0000-0003-1470-6998; Shao, Ling/0000-0002-8264-6117	Nature Science Foundation of China [61502081, 61702117, 61632007]; Science and Technology Program of Guangzhou [201804010355]	Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); Science and Technology Program of Guangzhou	This work is partially supported by the Nature Science Foundation of China (61502081, 61702117, 61632007), Science and Technology Program of Guangzhou (201804010355).	[Anonymous], 2013, P AAAI; Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027; Bachem O, 2016, AAAI CONF ARTIF INTE, P1459; Berkhin P, 2006, GROUPING MULTIDIMENSIONAL DATA: RECENT ADVANCES IN CLUSTERING, P25; Chaudhuri K., 2009, PROC INT C MACHINE L, P129, DOI DOI 10.1145/1553374.1553391; Chen WY, 2011, IEEE T PATTERN ANAL, V33, P568, DOI 10.1109/TPAMI.2010.88; Chen X, 2017, 2017 IEEE CONFERENCE ON ENERGY INTERNET AND ENERGY SYSTEM INTEGRATION (EI2), P252; Chen X, 2011, IEEE INT CONF ROBOT, P1311, DOI 10.1109/ICRA.2011.5980236; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Ding C, 2005, SIAM PROC S, P606; Ding YF, 2015, PR MACH LEARN RES, V37, P579; Fleuret, 2016, P 33 INT C MACH LEAR; Gong YC, 2015, PROC CVPR IEEE, P19, DOI 10.1109/CVPR.2015.7298596; Gong YC, 2013, PROC CVPR IEEE, P484, DOI 10.1109/CVPR.2013.69; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; Hamerly G., 2015, PARTITIONAL CLUSTERI, P41; Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011; Kumar A., 2011, ADV NEURAL INFORM PR, P1413; Li YQ, 2015, AAAI CONF ARTIF INTE, P2750; Liu J., 2013, PROC SOC IND APPL MA, P252, DOI [10.1137/1.9781611972832.28, DOI 10.1137/1.9781611972832.28]; Liu L, 2017, INT J COMPUT VISION, V122, P439, DOI 10.1007/s11263-016-0931-4; Liu L, 2015, IEEE I CONF COMP VIS, P2821, DOI 10.1109/ICCV.2015.323; Liu L, 2015, IEEE T IMAGE PROCESS, V24, P956, DOI 10.1109/TIP.2015.2390975; Ng A.Y., 2011, ADV NEURAL INFORM PR, V14, P849; Nie F., 2016, IJCAI, P1881; Nie FP, 2017, AAAI CONF ARTIF INTE, P2408; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Rudin W, 1964, PRINCIPLES MATH ANAL, V2nd; Schutze H., 2008, INTRO INFORM RETRIEV, V39; Shao WX, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P1012, DOI 10.1109/BigData.2016.7840701; Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887; Shen FM, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P595, DOI 10.1145/3077136.3080767; Shen FM, 2017, IEEE T MULTIMEDIA, V19, P2022, DOI 10.1109/TMM.2017.2699863; Shen FM, 2016, IEEE T IMAGE PROCESS, V25, P5610, DOI 10.1109/TIP.2016.2612883; Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598; Wang H., 2011, PROC 22 INT JOINT C, P1553, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-261; Wang JD, 2018, IEEE T PATTERN ANAL, V40, P769, DOI 10.1109/TPAMI.2017.2699960; Wu L, 2017, IMAGE VISION COMPUT, V57, P58, DOI 10.1016/j.imavis.2016.11.008; Xia TA, 2010, IEEE T SYST MAN CY B, V40, P1438, DOI 10.1109/TSMCB.2009.2039566; Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133; Xu C., 2013, ARXIV; Yang Rui, 2017, P ACM INT C MULT RET, P175; Yang Y., 2016, P 25 INT JOINT C ART, P2273; Yang Y, 2017, IEEE T KNOWL DATA EN, V29, P1834, DOI 10.1109/TKDE.2017.2701825; Zhang Z., 2018, P EUR C COMPUT VIS	47	221	226	11	61	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2019	41	7					1774	1782		10.1109/TPAMI.2018.2847335	http://dx.doi.org/10.1109/TPAMI.2018.2847335			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IC4XW	29994652				2022-12-18	WOS:000470972300019
J	Leibe, B; Schindler, K; Cornelis, N; Van Gool, L				Leibe, Bastian; Schindler, Konrad; Cornelis, Nico; Van Gool, Luc			Coupled object detection and tracking from static cameras and moving vehicles	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition	JUN 17-22, 2007	Minneapolis, MN	IEEE, hp invent, INI-GraphicsNet, VIOSO		object detection; tracking; model selection; MDL; Structure-from-Motion; mobile vision		We present a novel approach for multi-object tracking which considers object detection and spacetime trajectory estimation as a coupled optimization problem. Our approach is formulated in a Minimum Description Length hypothesis selection framework, which allows our system to recover from mismatches and temporarily lost tracks. Building upon a state-of-the-art object detector, it performs multiview/multicategory object recognition to detect cars and pedestrians in the input images. The 2D object detections are checked for their consistency with (automatically estimated) scene geometry and are converted to 3D observations which are accumulated in a world coordinate frame. A subsequent trajectory estimation module analyzes the resulting 3D observations to find physically plausible spacetime trajectories. Tracking is achieved by performing model selection after every frame. At each time instant, our approach searches for the globally optimal set of spacetime trajectories which provides the best explanation for the current image and for all evidence collected so far while satisfying the constraints that no two objects may occupy the same physical space nor explain the same image pixels at any point in time. Successful trajectory hypotheses are then fed back to guide object detection in future frames. The optimization procedure is kept efficient through incremental computation and conservative hypothesis pruning. We evaluate our approach on several challenging video sequences and demonstrate its performance on both a surveillance-type scenario and a scenario where the input videos are taken from inside a moving vehicle passing through crowded city areas.	[Leibe, Bastian; Schindler, Konrad; Van Gool, Luc] ETH, BIWI, CH-8092 Zurich, Switzerland; [Cornelis, Nico; Van Gool, Luc] Katholieke Univ Leuven, ESAT PSI VISICS IBBT, B-3001 Heverlee, Belgium	Swiss Federal Institutes of Technology Domain; ETH Zurich; KU Leuven	Leibe, B (corresponding author), ETH, BIWI, Sternwarstr 7, CH-8092 Zurich, Switzerland.	leibe@vision.ee.ethz.ch; konrad@vision.ee.ethz.ch; nico.cornelis@esat.kuleuven.be; vangool@vision.ee.ethz.ch	Leibe, Bastian/E-5499-2017	Leibe, Bastian/0000-0003-4225-0051; Pauldurai, Jona/0000-0002-7217-0872				AVIDAN S, 2005, P IEEE INT C COMP VI; Berclaz J., 2006, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2006.258; Betke M, 2000, MACH VISION APPL, V12, P69, DOI 10.1007/s001380050126; Boros E, 2002, DISCRETE APPL MATH, V123, P155, DOI 10.1016/S0166-218X(01)00336-5; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; CORNELIS N, 2006, P IEEE INT C COMP VI; Cornelis N, 2008, INT J COMPUT VISION, V78, P121, DOI 10.1007/s11263-007-0081-9; COX IJ, 1993, INT J COMPUT VISION, V10, P53, DOI 10.1007/BF01440847; Ess A., 2007, P IEEE INT C COMP VI; EVERINGHAM M, 2006, LNAI, V3944; FORTMANN TE, 1983, IEEE J OCEANIC ENG, V8, P173, DOI 10.1109/JOE.1983.1145560; GAVRILA DM, 1999, P IEEE INT C COMP VI, P87, DOI DOI 10.1109/ICCV.1999.791202; GELB A, 1996, APPL OPTIMAL ESTIMAT; GIEBEL J, 2004, P EUR C COMP VIS; GRABNER H, 2006, P IEEE C COMP VIS PA, V1, P260, DOI DOI 10.1109/CVPR.2006.215; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HOIEM D, 2006, P IEEE INT C COMP VI; HOIEM D, 2005, P IEEE INT C COMP VI; Isard M., 1998, INT J COMPUTER VISIO, V29; Kaucic R., 2005, P IEEE INT C COMP VI; KEUCHEL J, 1967, P EUR C COMP VIS, P454; KOLLER D, 1993, INT J COMPUT VISION, V10, P257, DOI 10.1007/BF01539538; KUMAR M, 2006, P IEEE INT C COMP VI; Lanz O, 2006, IEEE T PATTERN ANAL, V28, P1436, DOI 10.1109/TPAMI.2006.177; Leibe B., 2007, P IEEE INT C COMP VI; Leibe B., 2006, P BRIT MACH VIS C; LEIBE B, 2005, P IEEE INT C COMP VI; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; LEONARDIS A, 1995, INT J COMPUT VISION, V14, P253, DOI 10.1007/BF01679685; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; MIKOLAJCZYK K, 2006, P IEEE INT C COMP VI; Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4; Okuma K., 2004, P EUR C COMP VIS; Philomin V, 2000, PROCEEDINGS OF THE IEEE INTELLIGENT VEHICLES SYMPOSIUM 2000, P350, DOI 10.1109/IVS.2000.898368; REID DB, 1979, IEEE T AUTOMATIC CON, V24, P6; ROTHER C, 2007, P IEEE INT C COMP VI; Schindler K, 2006, LECT NOTES COMPUT SC, V3951, P606; STAUFFER C, 1999, P IEEE INT C COMP VI; Triggs B, 2005, P IEEE INT C COMP VI; Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; WU B, 2006, P IEEE INT C COMP VI; WU B., 2005, P IEEE INT C COMP VI; Yan F., 2006, P IEEE INT C COMP VI	46	220	223	1	52	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2008	30	10					1683	1698		10.1109/TPAMI.2008.170	http://dx.doi.org/10.1109/TPAMI.2008.170			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	336DQ	18703824	Green Submitted			2022-12-18	WOS:000258344900002
J	Collins, RT; Lipton, AJ; Kanade, T				Collins, RT; Lipton, AJ; Kanade, T			Introduction to the special section on video surveillance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; DiamondBack Vis Inc, Washington, DC USA	Carnegie Mellon University	Collins, RT (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.								0	220	252	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2000	22	8					745	746		10.1109/TPAMI.2000.868676	http://dx.doi.org/10.1109/TPAMI.2000.868676			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	354GN					2022-12-18	WOS:000089321500001
J	SAINTMARC, P; CHEN, JS; MEDIONI, G				SAINTMARC, P; CHEN, JS; MEDIONI, G			ADAPTIVE SMOOTHING - A GENERAL TOOL FOR EARLY VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CORNER DETECTION; EARLY PROCESSING; EDGE DETECTION; MULTIGRID PROCESSING; RANGE IMAGE ANALYSIS; REGION SEGMENTATION; SMOOTHING; STEREO	EDGE-DETECTION; PRIMAL SKETCH; IMAGES	We present a method to smooth a signal-whether it is an intensity image, a range image or a planar curve-while preserving discontinuities. This is achieved by repeatedly convolving the signal with a very small averaging mask weighted by a measure of the signal continuity at each point. The method is extremely attractive since edge detection can be performed after a few iterations, and features extracted from the smoothed signal are correctly localized. Hence no tracking is needed, as in Gaussian scale-space. This last property allows us to derive a new scale-space representation of a signal using the adaptive smoothing parameter k as the scale dimension. We then show how this process relates to anisotropic diffusion. When a large amount of smoothing is desired, we propose a multigrid implementation which reduces the computational time significantly. Given the local nature of the algorithm, we also propose a parallel implementation: the running time on a 16K Connection Machine is three orders of magnitude faster than on a serial machine. We then present several applications of adaptive smoothing: edge detection, range image feature extraction, corner detection, and stereo matching. Examples are given throughout the text using real images.	UNIV SO CALIF, INST ROBOT & INTELLIGENT SYST, LOS ANGELES, CA 90089 USA	University of Southern California	SAINTMARC, P (corresponding author), MATRA SEP, SIGNAL & IMAGE PROC LAB, F-78052 ST QUETIN YVELINE, FRANCE.							ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9, P726, DOI 10.1109/TPAMI.1987.4767980; BESL P, 1986, JUN P IEEE C COMP VI, P77; BRADY M, 1985, COMPUT VISION GRAPH, V32, P1, DOI 10.1016/0734-189X(85)90001-5; BRAND K, 1982, LECT NOTES MATH, P631; BURT PJ, 1983, COMPUT VISION GRAPH, V21, P368, DOI 10.1016/S0734-189X(83)80049-8; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chen J. S., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P215; CHIN RT, 1983, COMPUT VISION GRAPH, V23, P67, DOI 10.1016/0734-189X(83)90054-3; DAVIS LS, 1978, IEEE T SYST MAN CYB, V8, P705; DICKLEY FM, 1977, IEEE T PATTERN ANAL, V1, P37; DRUMHELLER M, 1986, IEEE J ROBOTIC AUTOM, P1439; FAN TJ, 1987, IEEE T ROBOTIC AUTOM, V3, P527; FAN TJ, 1988, IRIS237 U SO CAL TEC; FAN TJ, 1988, P DARPA IMAGE UNDERS, P383; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GRIMSON WEL, 1981, IMAGES SURFACES; HARALICK RM, 1983, INT J ROBOT RES, V2, P50, DOI 10.1177/027836498300200105; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HILLIS D, 1986, CONNECTION MACHINE, P204; Hummel R. A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P204; LEV A, 1977, IEEE T SYST MAN CYB, V7, P435, DOI 10.1109/TSMC.1977.4309740; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Marr D., 1982, VISION COMPUTATIONAL; MASTIN GA, 1985, COMPUT VISION GRAPH, V31, P103, DOI 10.1016/S0734-189X(85)80078-5; MEDIONI G, 1987, COMPUT VISION GRAPH, V39, P267, DOI 10.1016/S0734-189X(87)80181-0; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; Parvin B., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P23; Perona P., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P16; PERZOPOULOS D, 1983, P INT JOINT C ART IN, P1019; PONCE J, 1985, IEEE T ROBOTIC AUTOM, P420; Saint-Marc P., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P338; TUCKER LW, 1988, COMPUTER, V21, P26, DOI 10.1109/2.74; WANG DCC, 1981, COMPUT VISION GRAPH, V15, P167, DOI 10.1016/0146-664X(81)90077-0; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]	39	220	242	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1991	13	6					514	529		10.1109/34.87339	http://dx.doi.org/10.1109/34.87339			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FU372					2022-12-18	WOS:A1991FU37200002
J	NIEMINEN, A; HEINONEN, P; NEUVO, Y				NIEMINEN, A; HEINONEN, P; NEUVO, Y			A NEW CLASS OF DETAIL-PRESERVING FILTERS FOR IMAGE-PROCESSING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											NIEMINEN, A (corresponding author), TAMPERE UNIV TECHNOL,DEPT ELECT ENGN,POB 527,SF-33101 TAMPERE 10,FINLAND.							ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325; ARCE GR, 1982, IEEE T ACOUST SPEECH, V30, P894, DOI 10.1109/TASSP.1982.1163980; ARCE GR, 1984, P IEEE ICASSP84 SAN; ATAMAN E, 1981, IEEE T ACOUST SPEECH, V29, P1073, DOI 10.1109/TASSP.1981.1163659; BOVIK AC, 1983, IEEE T ACOUST SPEECH, V31, P1342, DOI 10.1109/TASSP.1983.1164247; CHIN RT, 1983, COMPUT VISION GRAPH, V23, P67, DOI 10.1016/0734-189X(83)90054-3; DAVID HA, 1980, ORDER STATISTICS; DAVIS LS, 1978, IEEE T SYST MAN CYB, V8, P705; GALLAGHER NC, 1981, IEEE T ACOUST SPEECH, V29, P1136, DOI 10.1109/TASSP.1981.1163708; HEINONEN P, 1985, MAR P IEEE INT C AC, P49; HEINONEN P, 1985, JUN P IEEE ISCAS 85, P1329; HUANG TS, 1981, TOPICS APPLIED PHYSI, V2; Narendra P. M., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing, P137; NODES TA, 1984, IEEE T COMMUN, V32, P532, DOI 10.1109/TCOM.1984.1096099; NODES TA, 1982, IEEE T ACOUST SPEECH, V30, P739, DOI 10.1109/TASSP.1982.1163951; NODES TA, 1983, IEEE T ACOUST SPEECH, V31, P1350, DOI 10.1109/TASSP.1983.1164220; Pratt W. K., 1978, DIGITAL IMAGE PROCES; RITENOUR ER, 1984, P IEEE ICASSP84 SAN; STEIN RA, 1985, P ISCAS 85, P1331	20	220	242	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1987	9	1					74	90		10.1109/TPAMI.1987.4767873	http://dx.doi.org/10.1109/TPAMI.1987.4767873			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	F3785	21869378				2022-12-18	WOS:A1987F378500006
J	Leung, Y; Zhang, JS; Xu, ZB				Leung, Y; Zhang, JS; Xu, ZB			Clustering by scale-space filtering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						hierarchical clustering; scale space theory; cluster validity	KERNEL	In pattern recognition and image processing. the major application areas of cluster analysis, human eyes seem to possess a singular aptitude to group objects and find important structures in an efficient and effective way. Thus, a clustering algorithm simulating a visual system may solve some basic problems in these areas of research. From this point of view, we propose a new approach to data clustering by modeling the blurring effect of lateral retinal interconnections based on scale space theory. In this approach, a data set is considered as an image with each light point located at a datum position. As we blur this image, smaller light blobs merge into larger ones until the whole image becomes one light blob at a low enough level of resolution. By identifying each blob with a cluster, the blurring process generates a family of clusterings along the hierarchy. The advantages of the proposed approach are: 1) The derived algorithms are computationally stable and insensitive to initialization and they are totally free from solving difficult global optimization problems. 2) It facilitates the construction of new checks on cluster validity and provides the final clustering a significant degree of robustness to noise in data and change in scale. 3) It is more robust in cases where hyperellipsoidal partitions may not be assumed. 4) It is suitable for the task of preserving the structure and integrity of the outliers in the clustering process. 5) The clustering is highly consistent with that perceived by human eyes. 6) The new approach provides a unified framework for scale-related clustering algorithms recently derived from many different fields such as estimation theory, recurrent signal processing on selforganization feature maps, information theory and statistical mechanics, and radial basis function neural networks.	Chinese Univ Hong Kong, Dept Geog, Ctr Environm Policy & Resource Management, Shatin, Hong Kong, Peoples R China; Chinese Univ Hong Kong, Joint Lab Geoinformat Sci, Shatin, Hong Kong, Peoples R China; Xi An Jiao Tong Univ, Fac Sci, Inst Informat & Syst Sci, Xian 710049, Peoples R China	Chinese University of Hong Kong; Chinese University of Hong Kong; Xi'an Jiaotong University	Leung, Y (corresponding author), Chinese Univ Hong Kong, Dept Geog, Ctr Environm Policy & Resource Management, Shatin, Hong Kong, Peoples R China.	yeeleung@cuhk.edu.hk; jszhang@xjtu.edu.cn; zbxu@xjtu.edu.cn						Allgower E. L., 1990, NUMERICAL CONTINUATI; Anderberg MR, 1973, CLUSTER ANAL APPL; [Anonymous], 1974, CLUSTER ANAL; BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; BALL G, 1976, BEHAV SCI, V12, P153; BEZDEK JC, 1980, IEEE T PATTERN ANAL, V2, P1, DOI 10.1109/TPAMI.1980.4766964; Blatt M, 1997, NEURAL COMPUT, V9, P1805, DOI 10.1162/neco.1997.9.8.1805; CELEUX G, 1992, COMPUT STAT DATA AN, V14, P315, DOI 10.1016/0167-9473(92)90042-E; Chakravarthy SV, 1996, IEEE T NEURAL NETWOR, V7, P1250, DOI 10.1109/72.536318; Coren S., 1994, SENSATION PERCEPTION; DUBES R, 1976, PATTERN RECOGN, V8, P247, DOI 10.1016/0031-3203(76)90045-5; DUDA RO, 1974, PATTERN CLASSIFICATI; FRIEDMAN HP, 1967, J AM STAT ASSOC, V62, P1159, DOI 10.2307/2283767; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; Hubel David H, 1995, EYE BRAIN VISION, P6; HUBERT L, 1974, J AM STAT ASSOC, V69, P968; HUMMEL R, 1989, IEEE T ACOUST SPEECH, V37, P2111, DOI 10.1109/29.45555; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; LIFSHITZ LM, 1987, MULTIRESOLUTION HIER; LINDEBERG T, 1990, IEEE T PATTERN ANAL, V12, P234, DOI 10.1109/34.49051; Marr D., 1982, VISION COMPUTATIONAL; Miller D, 1996, NEURAL COMPUT, V8, P425, DOI 10.1162/neco.1996.8.2.425; MULIER F, 1995, NEURAL COMPUT, V7, P1165, DOI 10.1162/neco.1995.7.6.1165; NADARAYA EA, 1964, THEOR PROBAB APPL, V74, P743; Roberts SJ, 1997, PATTERN RECOGN, V30, P261, DOI 10.1016/S0031-3203(96)00079-9; Roberts SJ, 1998, IEEE T PATTERN ANAL, V20, P1133, DOI 10.1109/34.730550; ROSE K, 1990, PATTERN RECOGN LETT, V11, P589, DOI 10.1016/0167-8655(90)90010-Y; TAVAN P, 1990, BIOL CYBERN, V64, P95, DOI 10.1007/BF02331338; Waldemark J, 1997, INT J NEURAL SYST, V8, P3, DOI 10.1142/S0129065797000033; Watson G.S., 1964, SANKHYA SER A, V26, P359, DOI DOI 10.2307/25049340; WILSON R, 1990, PATTERN RECOGN, V23, P1413, DOI 10.1016/0031-3203(90)90087-2; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; WITKIN AP, 1984, IMAGE UNDERSTANDING; WONG YF, 1993, NEURAL COMPUT, V5, P89, DOI 10.1162/neco.1993.5.1.89; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083	39	219	245	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2000	22	12					1396	1410		10.1109/34.895974	http://dx.doi.org/10.1109/34.895974			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	383UR					2022-12-18	WOS:000165901900004
J	TRUNK, GV				TRUNK, GV			PROBLEM OF DIMENSIONALITY - SIMPLE EXAMPLE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											TRUNK, GV (corresponding author), USN, RES LAB, WASHINGTON, DC 20375 USA.							Duda R.O., 1973, J ROYAL STAT SOC SER; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; Van Trees H., 2013, DETECTION ESTIMATION; [No title captured]	4	219	222	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	3					306	307		10.1109/TPAMI.1979.4766926	http://dx.doi.org/10.1109/TPAMI.1979.4766926			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC301	21868861				2022-12-18	WOS:A1979HC30100008
J	Phillips, PJ; Scruggs, WT; O'Toole, AJ; Flynn, PJ; Bowyer, KW; Schott, CL; Sharpe, M				Phillips, P. Jonathon; Scruggs, W. Todd; O'Toole, Alice J.; Flynn, Patrick J.; Bowyer, Kevin W.; Schott, Cathy L.; Sharpe, Matthew			FRVT 2006 and ICE 2006 Large-Scale Experimental Results	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Biometrics; face recognition; iris recognition; evaluations; human performance	FACE-RECOGNITION; PERFORMANCE	This paper describes the large-scale experimental results from the Face Recognition Vendor Test (FRVT) 2006 and the Iris Challenge Evaluation (ICE) 2006. The FRVT 2006 looked at recognition from high-resolution still frontal face images and 3D face images, and measured performance for still frontal face images taken under controlled and uncontrolled illumination. The ICE 2006 evaluation reported verification performance for both left and right irises. The images in the ICE 2006 intentionally represent a broader range of quality than the ICE 2006 sensor would normally acquire. This includes images that did not pass the quality control software embedded in the sensor. The FRVT 2006 results from controlled still and 3D images document at least an order-of-magnitude improvement in recognition performance over the FRVT 2002. The FRVT 2006 and the ICE 2006 compared recognition performance from high-resolution still frontal face images, 3D face images, and the single-iris images. On the FRVT 2006 and the ICE 2006 data sets, recognition performance was comparable for high-resolution frontal face, 3D face, and the iris images. In an experiment comparing human and algorithms on matching face identity across changes in illumination on frontal face images, the best performing algorithms were more accurate than humans on unfamiliar faces.	[Phillips, P. Jonathon; Schott, Cathy L.] NIST, Gaithersburg, MD 20899 USA; [Scruggs, W. Todd] Sci Applicat Int Corp, Chantilly, VA 20151 USA; [O'Toole, Alice J.] Univ Texas Dallas, Sch Behav & Brain Sci, GR4 1, Richardson, TX 75080 USA; [Flynn, Patrick J.; Bowyer, Kevin W.] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA; [Schott, Cathy L.] Schafer Corp, Arlington, VA 22203 USA; [Sharpe, Matthew] Ames HCI Grp, Moffett Field, CA 94035 USA; [Flynn, Patrick J.] Washington State Univ, Pullman, WA 99164 USA; [Flynn, Patrick J.] Ohio State Univ, Columbus, OH 43210 USA; [Bowyer, Kevin W.] ETH, Inst Informat, Zurich, Switzerland; [Bowyer, Kevin W.] Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA	National Institute of Standards & Technology (NIST) - USA; Science Applications International Corporation (SAIC); University of Texas System; University of Texas Dallas; University of Notre Dame; Washington State University; University System of Ohio; Ohio State University; Swiss Federal Institutes of Technology Domain; ETH Zurich; State University System of Florida; University of South Florida	Phillips, PJ (corresponding author), NIST, 100 Bur Dr MS 8940, Gaithersburg, MD 20899 USA.	jonathon@nist.gov; wendall.t.scruggs@saic.com; otoole@utdallas.edu; flynn@nd.edu; cschott@schafertmd.com; matthew.d.sharpe@nasa.gov	Flynn, Patrick J/J-3388-2013	Flynn, Patrick J/0000-0002-5446-114X; Bowyer, Kevin/0000-0002-7562-4390; O'Toole, Alice/0000-0001-7981-1508	US Department of Homeland Security's Science and Technology Department and Transportation Security Administration (TSA); National Intelligence's Information Technology Innovation Center; Federal Bureau of Investigation (FBI); National Institute of Justice; Technical Support Working Group (TSWG)	US Department of Homeland Security's Science and Technology Department and Transportation Security Administration (TSA)(United States Department of Homeland Security (DHS)); National Intelligence's Information Technology Innovation Center; Federal Bureau of Investigation (FBI); National Institute of Justice(US National Institute of Justice); Technical Support Working Group (TSWG)	The authors acknowledge the support of the US Department of Homeland Security's Science and Technology Department and Transportation Security Administration (TSA), the director of the National Intelligence's Information Technology Innovation Center, the Federal Bureau of Investigation (FBI), the National Institute of Justice, and the Technical Support Working Group (TSWG). The identification of any commercial product or trade name does not imply endorsement or recommendation by the National Institute of Standards and Technology, SAIC, Schafer Corp., University of Texas at Dallas, or University of Notre Dame.	*AUTHENTICORP, 2007, IR REC STUD 2006 IRI; Beveridge JR, 2005, MACH VISION APPL, V16, P128, DOI 10.1007/s00138-004-0144-7; BEVERIDGE JR, 2008, P 8 INT C AUT FAC GE; Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005; Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005; CRAWLEY MJ, 2002, STAT COMPUTING; Flom L., 1987, U.S. Patent, Patent No. [4641349, 4,641,349]; FLYNN PJ, 2008, ICE MINING QUALITY D; Grother P, 2003, LECT NOTES COMPUT SC, V2688, P937; Grother P, 2007, IEEE T PATTERN ANAL, V29, P531, DOI 10.1109/TPAMI.2007.1019; Hancock PJB, 2000, TRENDS COGN SCI, V4, P330, DOI 10.1016/S1364-6613(00)01519-9; HUSKEN M, 2005, P IEEE WORKSH FAC RE; IBG: International biometric group, 2005, INT BIOM GROUP IND T; Mansfield, 2002, BEST PRACTICES TESTI; MCCABE RM, 1997, BEST PRACTICE RECOMM; Moon H, 2001, PERCEPTION, V30, P303, DOI 10.1068/p2896; Newton EM, 2009, IEEE T SYST MAN CY A, V39, P4, DOI 10.1109/TSMCA.2008.2008210; O'Toole AJ, 2007, IEEE T PATTERN ANAL, V29, P1642, DOI 10.1109/TPAMI.2007.1107; OKADA K, 1998, FACE RECOGNITION THE, P186; PASSALIS G, 2007, IEEE T PATTERN ANAL, V29, P1; Phillips PJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P15; Phillips PJ, 2005, PROC CVPR IEEE, P947; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Phillips PJ, 2000, COMPUTER, V33, P56, DOI 10.1109/2.820040; PHILLIPS PJ, 2003, 6965 NISTIR; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	29	218	232	0	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2010	32	5					831	846		10.1109/TPAMI.2009.59	http://dx.doi.org/10.1109/TPAMI.2009.59			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	569AW	20299708				2022-12-18	WOS:000275569300005
J	Martinez-Munoz, G; Hernandez-Lobato, D; Suarez, A				Martinez-Munoz, Gonzalo; Hernandez-Lobato, Daniel; Suarez, Alberto			An Analysis of Ensemble Pruning Techniques Based on Ordered Aggregation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Ensembles of classifiers; bagging; decision trees; ensemble selection; ensemble pruning; ordered aggregation	COMBINATION; CLASSIFIERS; DIVERSITY; ACCURACY; FUSION	Several pruning strategies that can be used to reduce the size and increase the accuracy of bagging ensembles are analyzed. These heuristics select subsets of complementary classifiers that, when combined, can perform better than the whole ensemble. The pruning methods investigated are based on modifying the order of aggregation of classifiers in the ensemble. In the original bagging algorithm, the order of aggregation is left unspecified. When this order is random, the generalization error typically decreases as the number of classifiers in the ensemble increases. If an appropriate ordering for the aggregation process is devised, the generalization error reaches a minimum at intermediate numbers of classifiers. This minimum lies below the asymptotic error of bagging. Pruned ensembles are obtained by retaining a fraction of the classifiers in the ordered ensemble. The performance of these pruned ensembles is evaluated in several benchmark classification tasks under different training conditions. The results of this empirical investigation show that ordered aggregation can be used for the efficient generation of pruned ensembles that are competitive, in terms of performance and robustness of classification, with computationally more costly methods that directly select optimal or near-optimal subensembles.	[Martinez-Munoz, Gonzalo; Hernandez-Lobato, Daniel; Suarez, Alberto] Univ Autonoma Madrid, Dept Comp Sci, Escuela Poltiecn Super, Canto Blanco 28049, Spain	Autonomous University of Madrid	Martinez-Munoz, G (corresponding author), Univ Autonoma Madrid, Dept Comp Sci, Escuela Poltiecn Super, C Francisco Tomas & Valiente 11, Canto Blanco 28049, Spain.	gonzalo.martinez@uam.es; daniel.hernandez@uam.es; alberto.suarez@uam.es	Hernández-Lobato, Daniel/E-8337-2012; Suárez, Alberto/D-6293-2011; Martínez-Muñoz, Gonzalo/K-7269-2012	Hernández-Lobato, Daniel/0000-0001-5845-437X; Suárez, Alberto/0000-0003-4534-0909; Martínez-Muñoz, Gonzalo/0000-0002-6125-6056	Spanish Ministerio de Educacion y Ciencia [TIN2007-66862-C02-02]; Consejeria de Educacion de la Comunidad de Madrid	Spanish Ministerio de Educacion y Ciencia(Spanish Government); Consejeria de Educacion de la Comunidad de Madrid	The authors acknowledge support form the Spanish Ministerio de Educacion y Ciencia under Project TIN2007-66862-C02-02 and D. Hernandez-Lobato also acknowledges support from the Consejeria de Educacion de la Comunidad de Madrid.	[Anonymous], 2003, NAT COMP SER; Asuncion A, 2007, UCI MACHINE LEARNING; Bakker B, 2003, NEURAL NETWORKS, V16, P261, DOI 10.1016/S0893-6080(02)00187-9; Banfield R. E., 2005, Information Fusion, V6, P49, DOI 10.1016/j.inffus.2004.04.005; Banfield RE, 2007, IEEE T PATTERN ANAL, V29, P173, DOI 10.1109/TPAMI.2007.250609; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Breiman L., 1997, STAT BER, V26, P1683; Breiman L., 2017, CLASSIFICATION REGRE; Brodley C., 1996, P AAAI 96 WORKSH INT, P8; Canuto AMP, 2007, PATTERN RECOGN LETT, V28, P472, DOI 10.1016/j.patrec.2006.09.001; Caruana R, 2006, P 23 INT C MACH LEAR, P161, DOI [DOI 10.1145/1143844.1143865, 10.1145/1143844.1143865]; Caruana Rich, 2004, ICML, DOI DOI 10.1145/1015330.1015432; Demir C, 2005, PATTERN RECOGN LETT, V26, P2206, DOI 10.1016/j.patrec.2005.03.028; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; DOMINGOS P, 1997, P 14 INT C MACH LEAR, P98; Fan W, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P146; Freund Y., 1995, COMPUTATIONAL LEARNI, V904, P23, DOI [10.1007/3-540-59119-2_166, DOI 10.1007/3-540-59119-2_166]; Freund Y, 1996, P 13 INT C MACH LEAR, P148, DOI DOI 10.5555/3091696.3091715; Giacinto G, 2001, PATTERN RECOGN, V34, P1879, DOI 10.1016/S0031-3203(00)00150-3; Giacinto G, 2001, PATTERN RECOGN LETT, V22, P25, DOI 10.1016/S0167-8655(00)00096-9; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; HERNANDEZLOBATO D, 2006, P 7 INT C INT DAT EN, P322; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716; Krogh A., 1995, Advances in Neural Information Processing Systems 7, P231; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; Margineantu D.D., 1997, ICML, P211, DOI [10.5555/645526.757762, DOI 10.5555/645526.757762]; Martinez-Munoz G, 2004, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND APPLICATIONS, VOLS 1AND 2, P258; Martinez-Munoz G, 2007, PATTERN RECOGN LETT, V28, P156, DOI 10.1016/j.patrec.2006.06.018; MARTINEZMUNOZ G, 2006, P 23 INT C MACH LEAR, P609; MARTINEZMUNOZ G, 2007, P 17 INT C ART NEUR, P319; Meynet J, 2007, LECT NOTES COMPUT SC, V4472, P171; Nadeau C, 2003, MACH LEARN, V52, P239, DOI 10.1023/A:1024068626366; Partalas I, 2006, LECT NOTES COMPUT SC, V3955, P301; Prodromidis A. L., 2001, Knowledge and Information Systems, V3, P449, DOI 10.1007/PL00011678; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; Schapire RE, 1998, ANN STAT, V26, P1651; Tamon C, 2000, LECT NOTES ARTIF INT, V1810, P404; Tsoumakas G, 2004, LECT NOTES COMPUT SC, V3201, P465; Tsoumakas G, 2005, INTELL DATA ANAL, V9, P511, DOI 10.3233/IDA-2005-9602; Tsymbal A., 2005, Information Fusion, V6, P83, DOI 10.1016/j.inffus.2004.04.003; Tsymbal A, 2000, LECT NOTES COMPUT<D>, V1910, P116; Woods K, 1997, IEEE T PATTERN ANAL, V19, P405, DOI 10.1109/34.588027; Zhang Y, 2006, J MACH LEARN RES, V7, P1315; Zhou ZH, 2003, LECT NOTES ARTIF INT, V2639, P476; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X	49	218	233	1	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2009	31	2					245	259		10.1109/TPAMI.2008.78	http://dx.doi.org/10.1109/TPAMI.2008.78			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	385XL	19110491	Green Accepted			2022-12-18	WOS:000261846800004
J	Stenger, B; Thayananthan, A; Torr, PHS; Cipolla, R				Stenger, Bjorn; Thayananthan, Arasanathan; Torr, Philip H. S.; Cipolla, Roberto			Model-based hand tracking using a hierarchical Bayesian filter	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						probabilistic algorithms; video analysis; tracking		This paper sets out a tracking framework, which is applied to the recovery of three-dimensional hand motion from an image sequence. The method handles the issues of initialization, tracking, and recovery in a unified way. In a single input image with no prior information of the hand pose, the algorithm is equivalent to a hierarchical detection scheme, where unlikely pose candidates are rapidly discarded. In image sequences, a dynamic model is used to guide the search and approximate the optimal filtering equations. A dynamic model is given by transition probabilities between regions in parameter space and is learned from training data obtained by capturing articulated motion. The algorithm is evaluated on a number of image sequences, which include hand motion with self-occlusion in front of a cluttered background.	Toshiba Co Ltd, R&D Ctr, Kawasaki, Kanagawa 2128582, Japan; Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England; Oxford Brookes Univ, Dept Comp, Oxford OX33 1HX, England	Toshiba Corporation; University of Cambridge; Oxford Brookes University	Stenger, B (corresponding author), Toshiba Co Ltd, R&D Ctr, Kawasaki, Kanagawa 2128582, Japan.	bjorn@cantab.net; at315@cam.ac.uk; philiptorr@brookes.ac.uk; cipolla@eng.cam.ac.uk	Arandjelović, Ognjen/V-5255-2019	Arandjelović, Ognjen/0000-0002-9314-194X; Cipolla, Roberto/0000-0002-8999-2151				Athitsos V, 2003, PROC CVPR IEEE, P432; Athitsos V, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P45, DOI 10.1109/AFGR.2002.1004129; Baker S, 1996, PROC CVPR IEEE, P544, DOI 10.1109/CVPR.1996.517125; Barrow HG, 1977, P 5 INT JOINT C ART; Bergman N., 1999, THESIS LINKOPING U L; Blake A., 1998, ACTIVE CONTOURS APPL; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; Brand M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1237, DOI 10.1109/ICCV.1999.790422; BUCY RS, 1971, AUTOMATICA, V7, P287, DOI 10.1016/0005-1098(71)90121-X; Choo K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P321, DOI 10.1109/ICCV.2001.937643; DEUTSCHER J, 2000, P IEEE C COMP VIS PA, V2, P126, DOI DOI 10.1109/CVPR.2000.854758; Doucet A., 2001, SEQUENTIAL MONTE CAR; EROL A, 2005, P WORKSH VIS HUM COM; FELZENSZWALB PF, 2001, P C COMP VIS PATT RE, V1, P56; Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056; GAVRILA DM, 2000, P EUR C COMP VIS, P37; Heap T, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P344, DOI 10.1109/ICCV.1998.710741; Huttenlocher D. P., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P93, DOI 10.1109/ICCV.1993.378231; Isard M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P107, DOI 10.1109/ICCV.1998.710707; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; ISARD M, 1996, P EUR C COMP VIS, P343; Jazwinski A.H., 1970, STOCHASTIC PROCESSES; JOLIC N, 2000, P C COMP VIS PATT RE, V2, P26; LOCKTON R, 2002, P BRIT MACH VIS C, V2, P817; MACCORMICK J, 2000, P EUR C COMP VIS, V2, P3; NAVARATNAM R, 2005, P BRIT MACH VIS C, P479; OKADA R, 2006, P 7 AS C COMP VIS JA, P801; OKUMA K, 2004, P EUR C COMP VIS, P28; Olson CF, 1997, IEEE T IMAGE PROCESS, V6, P103, DOI 10.1109/83.552100; REHG JM, 1994, P EUR C COMP VIS, V2, P35; Rosales R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P378, DOI 10.1109/ICCV.2001.937543; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; Shimada N, 2001, IEEE ICCV WORKSHOP ON RECOGNITION, ANALYSIS AND TRACKING OF FACES AND GESTURES IN REAL-TIME SYSTEMS, PROCEEDINGS, P23, DOI 10.1109/RATFG.2001.938906; Sidenbladh H., 2000, LNCS, V2, P702; Sminchisescu C, 2003, INT J ROBOT RES, V22, P371, DOI 10.1177/0278364903022006003; SORENSON HW, 1988, RECURSIVE ESTIMATION, P127; STENGER B, 2004, P INT WORKSH HUM COM, P105; Stenger B., 2001, P BRIT MACH VIS C MA, VI, P63, DOI DOI 10.5244/C.15.8; THAYANANTHAN A, 2003, P BRIT MACH VIS C, V2, P589; THAYANANTHAN A, 2004, P BRIT MACH VIS C SE, P949; Toyama K, 2002, INT J COMPUT VISION, V48, P9, DOI 10.1023/A:1014899027014; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wu Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P426, DOI 10.1109/ICCV.2001.937656; Zhou HN, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1102, DOI 10.1109/ICCV.2003.1238472	46	218	234	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2006	28	9					1372	1384		10.1109/TPAMI.2006.189	http://dx.doi.org/10.1109/TPAMI.2006.189			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	062NC	16929725				2022-12-18	WOS:000238950800002
J	Tan, RT; Ikeuchi, K				Tan, RT; Ikeuchi, K			Separating reflection components of textured surfaces using a single image	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						reflection components separation; specular reflection; diffuse reflection; dichromatic reflection model; chromaticity; specular-to-diffuse mechanism; specular-free image	COLOR; MODEL	In inhomogeneous objects, highlights are linear combinations of diffuse and specular reflection components. A number of methods have been proposed to separate or decompose these two components. To our knowledge, all methods that use a single input image require explicit color segmentation to deal with multicolored surfaces. Unfortunately, for complex textured images, current color segmentation algorithms are still problematic to segment correctly. Consequently, a method without explicit color segmentation becomes indispensable and this paper presents such a method. The method is based solely on colors, particularly chromaticity, without requiring any geometrical information. One of the basic ideas is to iteratively compare the intensity logarithmic differentiation of an input image and its specular-free image. A specular-free image is an image that has exactly the same geometrical profile as the diffuse component of the input image and that can be generated by shifting each pixel's intensity and maximum chromaticity nonlinearly. Unlike existing methods using a single image, all processes in the proposed method are done locally, involving a maximum of only two neighboring pixels. This local operation is useful for handling textured objects with complex multicolored scenes. Evaluations by comparison with the results of polarizing filters demonstrate the effectiveness of the proposed method.	Univ Tokyo, Inst Ind Sci, Dept 3, Ikeuchi Lab,Meguro Ku, Tokyo 1538505, Japan	University of Tokyo	Tan, RT (corresponding author), Univ Tokyo, Inst Ind Sci, Dept 3, Ikeuchi Lab,Meguro Ku, 4-6-1 Komaba, Tokyo 1538505, Japan.	robby@cvl.iis.u-tokyo.ac.jp; ki@cvl.iis.u-tokyo.ac.jp	Tan, Robby T./F-8826-2017	Tan, Robby T./0000-0001-7532-6919				BAJSCY R, 1996, INT J COMPUT VISION, V17, P249; Beckmann Petr, 1987, SCATTERING ELECTROMA, P4; Born M., 1999, PRINCIPLES OPTICS, Vseventh, DOI DOI 10.1017/CBO9781139644181; Criminisi A, 2002, MSRTR200219; DZMURA M, 1986, J OPT SOC AM A, V3, P1662, DOI 10.1364/JOSAA.3.001662; FUNT BV, 1992, LECT NOTES COMPUT SC, V588, P124; GERSHON R, 1986, J OPT SOC AM A, V3, P1700, DOI 10.1364/JOSAA.3.001700; Gonzales R, 1993, DIGITAL IMAGE PROCES; HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126; KLINKER GJ, 1990, INT J COMPUT VISION, V4, P7, DOI 10.1007/BF00137441; Lambert J.H., 1760, PHOTOMETRIA SIVE MEN; LEE HC, 1990, IEEE T PATTERN ANAL, V12, P402, DOI 10.1109/34.50626; LEE S, 1991, THESIS U PENNSYLVANI; LEE SW, 1992, IMAGE VISION COMPUT, V10, P643, DOI 10.1016/0262-8856(92)90009-R; Lehmann TM, 2001, J OPT SOC AM A, V18, P2679, DOI 10.1364/JOSAA.18.002679; Lin HX, 2001, FUTURE GENER COMP SY, V18, P1, DOI 10.1016/S0167-739X(00)00089-3; LIN S, 2002, P EUR C COMP VIS, P210; Miyazaki T, 2003, STRESS HEALTH, V19, P3, DOI 10.1002/smi.950; NAYAR SK, 1991, IEEE T PATTERN ANAL, V13, P611, DOI 10.1109/34.85654; NAYAR SK, 1996, INT J COMPUTER VISIO, V21; OREN M, 1995, INT J COMPUT VISION, V14, P227, DOI 10.1007/BF01679684; PARKKINEN JPS, 1989, J OPTICS SOC AM A, V6; RUBIN JM, 1984, 764 AI MIT ART INT L; SATO Y, 1994, J OPTICS SOC AM A, V11; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; Tan RT, 2004, IEEE T PATTERN ANAL, V26, P1373, DOI 10.1109/TPAMI.2004.90; Tan RT, 2004, J OPT SOC AM A, V21, P321, DOI 10.1364/JOSAA.21.000321; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; WOLFF LB, 1994, J OPT SOC AM A, V11, P2956, DOI 10.1364/JOSAA.11.002956; WOLFF LB, 1991, IEEE T PATTERN ANAL, V13, P635, DOI 10.1109/34.85655; WOLFF LB, 1990, IEEE T PATTERN ANAL, V12, P1059, DOI 10.1109/34.61705; Wolff LB, 1998, INT J COMPUT VISION, V30, P55, DOI 10.1023/A:1008017513536	32	218	255	3	50	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2005	27	2					178	193		10.1109/TPAMI.2005.36	http://dx.doi.org/10.1109/TPAMI.2005.36			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	879AR	15688556	Green Submitted			2022-12-18	WOS:000225689300002
J	FORSYTH, D; MUNDY, JL; ZISSERMAN, A; COELHO, C; HELLER, A; ROTHWELL, C				FORSYTH, D; MUNDY, JL; ZISSERMAN, A; COELHO, C; HELLER, A; ROTHWELL, C			INVARIANT DESCRIPTORS FOR 3-D OBJECT RECOGNITION AND POSE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COMPUTER VISION; INVARIANTS; POSE COMPUTATION; RECOGNITION		Invariant descriptors are shape descriptors that are unaffected by object pose, by perspective projection, and by the intrinsic parameters of the camera. These descriptors can be constructed using the methods of invariant theory, which are briefly surveyed. A range of applications of invariant descriptors in three-dimensional model-based vision is demonstrated. First, a model-based vision system that recognizes curved plane objects, irrespective of their pose, is demonstrated. Curves are not reduced to polyhedral approximations but are handled as objects in their own right. Models are generated directly from image data. Once objects have been recognized, their pose can be computed. Invariant descriptors for three-dimensional objects with plane faces are described. All these ideas are demonstrated on images of real scenes. The stability of a range of invariant descriptors to measurement error is treated in detail.	GE,CTR RES & DEV,ARTIFICIAL INTELLIGENCE LAB,SCHENECTADY,NY 12306; GE,CTR RES & DEV,TECH STAFF,SCHENECTADY,NY 12306; ELSAG SPA BAILEY,GENOA,ITALY	General Electric; General Electric	FORSYTH, D (corresponding author), UNIV OXFORD,DEPT ENGN SCI,ROBOT RES GRP,OXFORD,ENGLAND.							ABHYANKAR SS, 1991, 1ST P DARPA ESPRIT J; [Anonymous], 1985, PERCEPTUAL ORG VISUA; ARNOLD VI, 1990, GRUNDLEHREN MATH WIS; ASADA H, 1984, P IEEE WORKSHOP COMP; BARRETT EB, 1991, JAN COMP VIS GRAPH I; Boothby W., 1986, INTRO DIFFERENTIABLE; BROOKS RA, 1983, IEEE T PATTERN ANAL, V5, P140, DOI 10.1109/TPAMI.1983.4767366; Canny J., 1983, TR720 MIT AI LAB; DHOME M, 1989, P ECCV, V1; DICKSON LE, 1913, ALGEBRAIC INVARIANTS; Dieudonne JA, 1971, INVARIANT THEORY OLD; Duda R.O., 1973, J ROYAL STAT SOC SER; ETTINGER GJ, 1988, IEEE C COMP VIS PATT, P32; FORSYTH DA, 1990, BRIT MACHINE VISION; FORSYTH DA, 1990, 1ST P EUR C COMP VIS; FORSYTH DA, 1991, 1ST P DARPA ESPRIT J; FORSYTH DA, 1990, P INT WORKSHOP INTEG; GANAPATHY S, 1984, P INT C ROBOTICS AUT; Grace John Hilton, 1903, ALGEBRA INVARIANTS; GRIMSON WEL, 1985, 3RD P INT S ROB RES; HARTSHORNE R, 1967, F PROJECTIVE GEOMETR; HUTTENLOCHER DP, 1988, APR P DARPA IU WORKS, P1114; IKEUCHI I, 1988, P DARPA IMAGE UNDERS, P697; Kanatani Kenichi, 1990, GROUP THEORETICAL ME, P4; KAPUR D, 1991, 1ST P DARPA ESPRIT J; LAMDAN Y, 1988, P CVPR 88; LANE EP, 1941, TREATISE PROJECTIVE; LINNAINMAA S, 1988, IEEE T PATTERN ANAL, V10, P634, DOI 10.1109/34.6772; MASCIANGELO S, 1990, P BMVC 90 OXFORD; MAYBANK SJ, 1991, 1ST P DARPA ESPRIT J; MOFFIT FH, 1990, PHOTOGRAMMETRY; MOHR R, 1991, 1ST P DARPA ESPRIT J; Morgan A. P., 1987, SOLVING POLYNOMIAL S; NIELSEN L, 1989, 6TH SCAND C IM AN OU, P969; NIELSON L, AUTOMATICA, V24, P135; OLVER PJ, 1986, APPLICATION LIE GROU; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P107, DOI 10.1007/BF00127812; PONCE J, 1991, 1ST P DARPA ESPRIT J; PONCE J, 1989, P DARPA IMAGE UNDERS, P461; PORRILL J, 1989, 5TH P ALV VIS C; ROTHWELL CA, 1991, IMAGE VISION COMPUTI; SALMON G, 1885, HIGHER ALGEBRA; Salmon George, 1879, TREATISE HIGHER PLAN, Vthird; Springer C. E., 1964, GEOMETRY ANAL PROJEC; THOMPSON DW, 1987, P IEEE C ROBOTICS AU; TSAI R, 1987, IEEE J ROBOTICS AUTO, V3; TURNBULL HW, 1928, DETERMINANTS MATRICE; VANGOOL L, 1990, P ICCV, V3; WEISS I, 1989, P DARPA IU WORKSHOP, P1125; Weyl H., 1946, CLASSICAL GROUPS	50	218	242	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1991	13	10					971	991		10.1109/34.99233	http://dx.doi.org/10.1109/34.99233			21	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GM763					2022-12-18	WOS:A1991GM76300002
J	FUKUNAGA, K; HAYES, RR				FUKUNAGA, K; HAYES, RR			EFFECTS OF SAMPLE-SIZE IN CLASSIFIER DESIGN	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											FUKUNAGA, K (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.							BEYER W, 1981, CRC STANDARD MATH TA, P44; ELSHEIKH TS, 1980, PATTERN RECOGN, V12, P115, DOI 10.1016/0031-3203(80)90035-7; FOLEY DH, 1972, IEEE T INFORM THEORY, V18, P618, DOI 10.1109/TIT.1972.1054863; FUKUNAGA K, 1972, INTRO STATISTICAL PA; HAN CP, 1970, I STAT MATH ANN, V22, P117; Jain A.K., 1982, HDB STAT, P835, DOI 10.1016/S0169-7161(82)02042-2; JAIN AK, 1976, IEEE T SYST MAN  NOV, P763; KALAYEH HM, 1983, IEEE T PATTERN ANAL, V5, P664, DOI 10.1109/TPAMI.1983.4767459; MCLACHLAN GJ, 1975, AUST J STAT, V17, P161, DOI 10.1111/j.1467-842X.1975.tb00953.x; NOVAK L, 1984, 18TH P AS C CIRC SYS; PIPBERGER H V, 1970, P109; Raudys S, 1980, IEEE Trans Pattern Anal Mach Intell, V2, P242, DOI 10.1109/TPAMI.1980.4767011	12	218	221	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1989	11	8					873	885		10.1109/34.31448	http://dx.doi.org/10.1109/34.31448			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AH079					2022-12-18	WOS:A1989AH07900007
J	Fumera, G; Roli, F				Fumera, G; Roli, F			A theoretical and experimental analysis of linear combiners for multiple classifier systems	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multiple classifier systems; linear combiners; classifier fusion; pattern classification	NEURAL-NETWORKS; COMBINATION; FUSION	In this paper, a theoretical and experimental analysis of linear combiners for multiple classifier systems is presented. Although linear combiners are the most frequently used combining rules, many important issues related to their operation for pattern classification tasks lack a theoretical basis. After a critical review of the framework developed in works by Tumer and Ghosh [30], [31] on which our analysis is based, we focus on the simplest and most widely used implementation of linear combiners, which consists of assigning a nonnegative weight to each individual classifier. Moreover, we consider the ideal performance of this combining rule, i.e., that achievable when the optimal values of the weights are used. We do not consider the problem of weights estimation, which has been addressed in the literature. Our theoretical analysis shows how the performance of linear combiners, in terms of misclassification probability, depends on the performance of individual classifiers, and on the correlation between their outputs. In particular, we evaluate the ideal performance improvement that can be achieved using the weighted average over the simple average combining rule and investigate in what way it depends on the individual classifiers. Experimental results on real data sets show that the behavior of linear combiners agrees with the predictions of our analytical model. Finally, we discuss the contribution to the state of the art and the practical relevance of our theoretical and experimental analysis of linear combiners for multiple classifier systems.	Univ Cagliari, Dept Elect & Elect Engn, I-09123 Cagliari, Italy	University of Cagliari	Fumera, G (corresponding author), Univ Cagliari, Dept Elect & Elect Engn, Piazza Armi, I-09123 Cagliari, Italy.	fumera@diee.unica.it; roli@diee.unica.it		ROLI, FABIO/0000-0003-4103-9190				Alexandre LA, 2000, INT C PATT RECOG, P495, DOI 10.1109/ICPR.2000.906120; Benediktsson JA, 1997, IEEE T NEURAL NETWOR, V8, P54, DOI 10.1109/72.554191; Bishop, 1995, NEURAL NETWORKS PATT; Breiman L, 1996, MACH LEARN, V24, P49; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; Duda R.O., 2000, PATTERN CLASSIFICATI; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Fumera G, 2003, LECT NOTES COMPUT SC, V2709, P74; FUMERA G, 2002, P SPLUSSSPR2002, P424; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; HASHEM S, 1995, IEEE T NEURAL NETWOR, V6, P792, DOI 10.1109/72.377990; HASHEM S., 1993, THESIS PURDUE U; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716; Kittler J, 2003, IEEE T PATTERN ANAL, V25, P110, DOI 10.1109/TPAMI.2003.1159950; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; KITTLER J, 2001, LECT NOTES COMPUTER, V2096; KITTLER J, 2000, LECT NOTES COMPUTER, V1857; Kuncheva L I, 2004, COMBINING PATTERN CL; Kuncheva LI, 2002, IEEE T PATTERN ANAL, V24, P281, DOI 10.1109/34.982906; LEBLANC M, 1993, 9318 U TOR DEP STAT; Perrone MP, 1993, NEURAL NETWORKS SPEE; Roli F, 1996, INT J PATTERN RECOGN, V10, P887, DOI 10.1142/S0218001496000517; Roli F, 2002, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION FUSION, VOL I, P278, DOI 10.1109/ICIF.2002.1021162; Roli F., 2004, LECT NOTES COMPUTER, V3077; Roli F., 2002, LECT NOTES COMPUTER, V2364; ROLI F, 2002, P INT WORKSH MULT CL, P252; Tax DMJ, 2000, PATTERN RECOGN, V33, P1475, DOI 10.1016/S0031-3203(99)00138-7; Tumer K, 1996, PATTERN RECOGN, V29, P341, DOI 10.1016/0031-3203(95)00085-2; TUMER K, 1996, THESIS U TEXAS AUSTI; Tumer K., 1999, COMBINING ARTIFICIAL, P127; Ueda N, 2000, IEEE T PATTERN ANAL, V22, P207, DOI 10.1109/34.825759; Verikas A, 1999, PATTERN RECOGN LETT, V20, P429, DOI 10.1016/S0167-8655(99)00012-4; Windeatt T, 2003, LECT NOTES COMPUTER, V2709	35	217	232	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2005	27	6					942	956		10.1109/TPAMI.2005.109	http://dx.doi.org/10.1109/TPAMI.2005.109			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	915TR	15943425				2022-12-18	WOS:000228334700009
J	Barsky, S; Petrou, M				Barsky, S; Petrou, M			The 4-source photometric stereo technique for three-dimensional surfaces in the presence of highlights and shadows	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						photometric stereo; surface orientation and color recovery; highlights; shadows	MULTIPLE IMAGES; SHAPE; COLOR	We present an algorithm for separating the local gradient information and Lambertian color by using 4-source color photometric stereo in the presence of highlights and shadows. We assume that the surface reflectance can be approximated by the sum of a Lambertian and a specular component. The conventional photometric method is generalized for color images. Shadows and highlights in the input images are detected using either spectral or directional cues and excluded from the recovery process, thus giving more reliable estimates of local surface parameters.	Univ Surrey, Ctr Vis Speech & Signal Proc, Sch Elect & Phys Sci, Guildford GU2 7XH, Surrey, England	University of Surrey	Barsky, S (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Sch Elect & Phys Sci, Guildford GU2 7XH, Surrey, England.							BARSKY S, 2003, THESIS U SURREY UK; CHRISTENSEN PH, 1994, INT J COMPUT VISION, V13, P213, DOI 10.1007/BF01427152; COLEMAN EN, 1982, COMPUT VISION GRAPH, V18, P309, DOI 10.1016/0146-664X(82)90001-6; Drew MS, 1997, P SOC PHOTO-OPT INS, V3016, P369, DOI 10.1117/12.274534; Drew MS, 2000, J OPT SOC AM A, V17, P1371, DOI 10.1364/JOSAA.17.001371; DREW MS, 1992, 9207 CSS LCCR TR; FINLAYSON GD, 1996, P IEEE 3 INT WORKSH; Kay G, 1995, GRAPH MODEL IM PROC, V57, P365, DOI 10.1006/gmip.1995.1032; KLINKER GJ, 1993, PHYSICAL APPROACH CO; KONTSEVICH LL, 1994, J OPT SOC AM A, V11, P1047, DOI 10.1364/JOSAA.11.001047; LEE SW, 1992, IMAGE VISION COMPUT, V10, P643, DOI 10.1016/0262-8856(92)90009-R; NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P418, DOI 10.1109/70.59367; Petrov AP, 1996, COLOR RES APPL, V21, P97, DOI 10.1002/(SICI)1520-6378(199604)21:2<97::AID-COL3>3.0.CO;2-#; PHONG BT, 1975, COMM ACM, V18; SCHLUNS K, 1993, P 5 INT C COMP AN IM, P444; Solomon F, 1996, IEEE T PATTERN ANAL, V18, P449, DOI 10.1109/34.491627; TAGARE HD, 1991, IEEE T PATTERN ANAL, V13, P133, DOI 10.1109/34.67643; WOODHAM RJ, 1994, J OPT SOC AM A, V11, P3050, DOI 10.1364/JOSAA.11.003050; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; WOODHAM RJ, 1991, PHOTOMETRIC STEREO L	20	217	232	3	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2003	25	10					1239	1252		10.1109/TPAMI.2003.1233898	http://dx.doi.org/10.1109/TPAMI.2003.1233898			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	723ZE					2022-12-18	WOS:000185460800004
J	Tico, M; Kuosmanen, P				Tico, M; Kuosmanen, P			Fingerprint matching using an orientation-based minutia descriptor	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fingerprints; matching; minutiae; orientation features	SYSTEM	We introduce a novel fingerprint representation scheme that relies on describing the orientation field of the fingerprint pattern with respect to each minutia detail. This representation allows the derivation of a similarity function between minutiae that is used to identify corresponding features and evaluate the resemblance between two fingerprint impressions. A fingerprint matching algorithm, based on the proposed representation, is developed and tested with a series of experiments conducted on two public domain collections of fingerprint images. The results reveal that our method can achieve good performance on these data collections and that it outperforms other alternative approaches implemented for comparison.	Nokia Res Ctr, FIN-33721 Tamere, Finland; Tampere Univ Technol, Inst Signal Proc, FIN-33101 Tampere, Finland	Nokia Corporation; Nokia Finland; Siemens AG; Nokia Siemens Networks; Tampere University	Tico, M (corresponding author), Nokia Res Ctr, POB 100, FIN-33721 Tamere, Finland.	tico@ieee.org; pauli.kuosmanen@tut.fi		Kuosmanen, Pauli Samuel/0000-0003-3765-7471				BALLARD DH, 1981, IEEE T PATTERN ANAL, V3, P111; Belongie S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P454, DOI 10.1109/ICCV.2001.937552; Candela G. T., 1995, PCASYSA PATTERN LEVE; GAMBLE FT, 1992, APPL OPTICS, V31, P652, DOI 10.1364/AO.31.000652; Germain RS, 1997, IEEE COMPUT SCI ENG, V4, P42, DOI 10.1109/99.641608; HRECHAK AK, 1990, PATTERN RECOGN, V23, P893, DOI 10.1016/0031-3203(90)90134-7; ISENOR DK, 1986, PATTERN RECOGN, V19, P113, DOI 10.1016/0031-3203(86)90017-8; Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996; Jain A., 1999, BIOMETRICS PERSONAL; Jain AK, 1997, P IEEE, V85, P1365, DOI 10.1109/5.628674; Jain AK, 2000, IEEE T IMAGE PROCESS, V9, P846, DOI 10.1109/83.841531; Jiang XD, 2000, INT C PATT RECOG, P1038, DOI 10.1109/ICPR.2000.906252; Lee CJ, 1999, ELECTRON LETT, V35, P288, DOI 10.1049/el:19990213; Lee H. C., 1991, ADV FINGERPRINT TECH; Maio D, 2002, IEEE T PATTERN ANAL, V24, P402, DOI 10.1109/34.990140; Rao A. R., 1990, TAXONOMY TEXTURE DES; Ratha NK, 1996, IEEE T PATTERN ANAL, V18, P799, DOI 10.1109/34.531800; STONEY DA, 1988, AM J PHYS ANTHROPOL, V77, P367, DOI 10.1002/ajpa.1330770309; Tico M, 2000, CONF REC ASILOMAR C, P1735, DOI 10.1109/ACSSC.2000.911285; Tico M, 2001, ELECTRON LETT, V37, P21, DOI 10.1049/el:20010031; TICO M, 2001, THESIS TAMPERE U TEC; Wahab A, 1998, IEE P-VIS IMAGE SIGN, V145, P160, DOI 10.1049/ip-vis:19981809; Wilson CL, 2000, PATTERN RECOGN, V33, P317, DOI 10.1016/S0031-3203(99)00052-7	23	217	237	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2003	25	8					1009	1014		10.1109/TPAMI.2003.1217604	http://dx.doi.org/10.1109/TPAMI.2003.1217604			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	702XJ					2022-12-18	WOS:000184249800006
J	TERZOPOULOS, D				TERZOPOULOS, D			IMAGE-ANALYSIS USING MULTIGRID RELAXATION METHODS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											TERZOPOULOS, D (corresponding author), MIT,ARTIFICIAL INTELLIGENCE LAB,545 TECHNOL SQ,CAMBRIDGE,MA 02139, USA.							BAJCSY R, 1982, 6TH IEEE P INT C PAT, P351; BAKHVALOV NS, 1966, ZH VYCH MAT MAT FIZ, V6, P861; BALLARD DH, 1983, NATURE, V306, P21, DOI 10.1038/306021a0; BATCHER KE, 1980, IEEE T COMPUT, V26; BLAKE A, 1984, CENTRAL PERIPHERAL M; BRADDICK O, 1978, HDB SENSORY PHYSL, V8, P3; BRADY M, 1984, IEEE T PATTERN ANAL, V6, P288, DOI 10.1109/TPAMI.1984.4767521; BRAND K, 1982, LECT NOTES MATH, V960, P631; Brandt A., 1980, Special Topics of Applied Mathematics. Functional Analysis, Numerical Analysis and Optimization. Proceedings of the Seminar, P91; BRANDT A, 1973, LECTURE NOTES PHYSIC, V18; BROOKS MJ, 1984, MIT AI813 AI LAB MEM; CORNELIUS NH, 1983, P ACM SIGGRAPH SIGAR, P50; COURANT R, 1953, METHODS MATH PHYSICS, V1; Fedorenko RP., 1961, ZH VYCH MAT MAT FIZ, V1, P922, DOI DOI 10.1016/0041-5553(62)90031-9; Forsythe G.E., 1960, PARTIAL DIFFERENTIAL, V20, P415; GEMAN S, 1985, IEEE T PATTERN ANAL, V7, P721; GLAZER F, 1984, MULTIRESOLUTION IMAG, P312; GRIMSON WEL, 1983, COMPUT VISION GRAPH, V22, P39, DOI 10.1016/0734-189X(83)90095-6; HACKBUSCH W, 1982, LECTURE NOTES MATH, V960; HAGEMAN LA, 1981, APPLIED ITERATIVE ME; HEMKER PW, 1980, C NUMERICAL SOLUTION, P59; HILDRETH EC, 1984, ARTIF INTELL, V23, P309, DOI 10.1016/0004-3702(84)90018-3; Hillis W. D., 1985, THESIS MIT CAMBRIDGE; Horn Berthold K. P., 1975, PSYCHOL COMPUTER VIS, P115; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1974, COMPUTER GRAPHICS IM, V3, P111; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; Marr D., 1977, SCIENCE, V195, P283; Nagel H.-H., 1983, IJCAI, P945; NARAYANAN KA, 1982, IEEE T SYST MAN CYB, V12, P91; NICOLAIDES RA, 1977, MATH COMPUT, V31, P892, DOI 10.2307/2006120; POGGIO T, 1984, P AARPA IM UND WORKS, P257; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; SMITH GB, 1982, P DARPA IM UND WORK, P132; Strang G., 1973, ANAL FINITE ELEMENT; TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8; TERZOPOULOS D, 1986, UNPUB IEEE T PATTERN; TERZOPOULOS D, 1982, MIT AI671 ART INT LA; TERZOPOULOS D, 1984, THESIS MIT CAMBRIDGE; Tikhonov A.N., 1977, SOLUTION ILL POSED P, V54, P266, DOI 10.1137/1021044; ULLMAN S, 1979, COMPUT VISION GRAPH, V10, P115, DOI 10.1016/0146-664X(79)90045-5	46	217	225	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1986	8	2					129	139		10.1109/TPAMI.1986.4767767	http://dx.doi.org/10.1109/TPAMI.1986.4767767			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	A1073	21869332				2022-12-18	WOS:A1986A107300001
J	Sattler, T; Leibe, B; Kobbelt, L				Sattler, Torsten; Leibe, Bastian; Kobbelt, Leif			Efficient & Effective Prioritized Matching for Large-Scale Image-Based Localization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image-based localization; location recognition; prioritized feature matching; camera pose estimation		Accurately determining the position and orientation from which an image was taken, i.e., computing the camera pose, is a fundamental step in many Computer Vision applications. The pose can be recovered from 2D-3D matches between 2D image positions and points in a 3D model of the scene. Recent advances in Structure-from-Motion allow us to reconstruct large scenes and thus create the need for image-based localization methods that efficiently handle large-scale 3D models while still being effective, i.e., while localizing as many images as possible. This paper presents an approach for large scale image-based localization that is both efficient and effective. At the core of our approach is a novel prioritized matching step that enables us to first consider features more likely to yield 2D-to-3D matches and to terminate the correspondence search as soon as enough matches have been found. Matches initially lost due to quantization are efficiently recovered by integrating 3D-to-2D search. We show how visibility information from the reconstruction process can be used to improve the efficiency of our approach. We evaluate the performance of our method through extensive experiments and demonstrate that it offers the best combination of efficiency and effectiveness among current state-of-the-art approaches for localization.	[Sattler, Torsten] Swiss Fed Inst Technol, Dept Comp Sci, Comp Vis Grp, Ramistr, CH-8092 Zurich, Switzerland; [Leibe, Bastian] Rhein Westfal TH Aachen, Comp Vis Grp, D-52062 Aachen, Germany; [Kobbelt, Leif] Rhein Westfal TH Aachen, Comp Graph Grp, D-52062 Aachen, Germany	Swiss Federal Institutes of Technology Domain; ETH Zurich; RWTH Aachen University; RWTH Aachen University	Sattler, T (corresponding author), Swiss Fed Inst Technol, Dept Comp Sci, Comp Vis Grp, Ramistr, CH-8092 Zurich, Switzerland.	sattlert@inf.ethz.ch; leibe@umic.rwth-aachen.de; kobbelt@cs.rwth-aachen.de	Sattler, Torsten/AAM-3155-2021; Leibe, Bastian/E-5499-2017	Kobbelt, Leif/0000-0002-7880-9470; Leibe, Bastian/0000-0003-4225-0051; Sattler, Torsten/0000-0001-9760-4553				Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148; Alcantarilla Pablo F., 2011, 2011 IEEE International Conference on Robotics and Automation, P6205; Aubry M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2591009; Bujnak Martin, 2010, AS C COMP VIS ACCV, P2; Byrod M, 2009, INT J COMPUT VISION, V84, P237, DOI 10.1007/s11263-009-0235-z; Cao S, 2013, PROC CVPR IEEE, P700, DOI 10.1109/CVPR.2013.96; Castle R, 2008, TWELFTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P15, DOI 10.1109/ISWC.2008.4911577; Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610; Choudhary S, 2012, LECT NOTES COMPUT SC, V7576, P130, DOI 10.1007/978-3-642-33715-4_10; Chum O, 2008, IEEE T PATTERN ANAL, V30, P1472, DOI 10.1109/TPAMI.2007.70787; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049; Donoser M, 2014, PROC CVPR IEEE, P516, DOI 10.1109/CVPR.2014.73; Eade E., 2006, IEEE COMP SOC C COMP, V1, P469, DOI [10.1109/CVPR.2006.263, DOI 10.1109/CVPR.2006.263]; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Hartley R., 2004, ROBOTICA; Hays James, 2008, CVPR, DOI DOI 10.1109/CVPR.2008.4587784; Irschara Arnold, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2599, DOI 10.1109/CVPRW.2009.5206587; Knopp J, 2010, LECT NOTES COMPUT SC, V6311, P748, DOI 10.1007/978-3-642-15549-9_54; Li YP, 2012, LECT NOTES COMPUT SC, V7572, P15, DOI 10.1007/978-3-642-33718-5_2; Li YP, 2010, LECT NOTES COMPUT SC, V6312, P791; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Middelberg S, 2014, LECT NOTES COMPUT SC, V8690, P268, DOI 10.1007/978-3-319-10605-2_18; Mikulik A, 2013, INT J COMPUT VISION, V103, P163, DOI 10.1007/s11263-012-0600-1; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Robertson D., 2004, P 15 BRIT MACH VIS C, P819; Sattler Torsten, 2012, Outdoor and Large-Scale Real-World Scene Analysis. 15th International Workshop on Theoretical Foundations of Computer Vision. Revised Selected Papers, P191, DOI 10.1007/978-3-642-34091-8_9; Sattler T, 2015, IEEE I CONF COMP VIS, P2102, DOI 10.1109/ICCV.2015.243; Sattler T, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.76; Sattler T, 2012, LECT NOTES COMPUT SC, V7572, P752, DOI 10.1007/978-3-642-33718-5_54; Sattler T, 2011, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2011.6126302; Schindler Grant, 2007, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2007.383150; Sibbing D, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P56, DOI 10.1109/3DV.2013.16; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Sivic J., 2008, COMPUTER VISION PATT, P1, DOI 10.1109/CVPR.2008.4587635; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Svarm L, 2014, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2014.75; Torii A, 2013, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2013.119; Zamir AR, 2014, IEEE T PATTERN ANAL, V36, P1546, DOI 10.1109/TPAMI.2014.2299799; Zamir AR, 2010, LECT NOTES COMPUT SC, V6314, P255, DOI 10.1007/978-3-642-15561-1_19; Zeisl B, 2015, IEEE I CONF COMP VIS, P2704, DOI 10.1109/ICCV.2015.310; Zhang W, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P33, DOI 10.1109/3dpvt.2006.80	43	216	223	1	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2017	39	9					1744	1756		10.1109/TPAMI.2016.2611662	http://dx.doi.org/10.1109/TPAMI.2016.2611662			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FC4WC	27662671				2022-12-18	WOS:000406840800004
J	Alon, J; Athitsos, V; Yuan, Q; Sclaroff, S				Alon, Jonathan; Athitsos, Vassilis; Yuan, Quan; Sclaroff, Stan			A Unified Framework for Gesture Recognition and Spatiotemporal Gesture Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gesture recognition; gesture spotting; human motion analysis; dynamic time warping; continuous dynamic programming	HIDDEN MARKOV-MODELS; HAND GESTURES; TRACKING	Within the context of hand gesture recognition, spatiotemporal gesture segmentation is the task of determining, in a video sequence, where the gesturing hand is located and when the gesture starts and ends. Existing gesture recognition methods typically assume either known spatial segmentation or known temporal segmentation, or both. This paper introduces a unified framework for simultaneously performing spatial segmentation, temporal segmentation, and recognition. In the proposed framework, information flows both bottom-up and top-down. A gesture can be recognized even when the hand location is highly ambiguous and when information about when the gesture begins and ends is unavailable. Thus, the method can be applied to continuous image streams where gestures are performed in front of moving, cluttered backgrounds. The proposed method consists of three novel contributions: a spatiotemporal matching algorithm that can accommodate multiple candidate hand detections in every frame, a classifier-based pruning framework that enables accurate and early rejection of poor matches to gesture models, and a subgesture reasoning algorithm that learns which gesture models can falsely match parts of other longer gestures. The performance of the approach is evaluated on two challenging applications: recognition of hand-signed digits gestured by users wearing short-sleeved shirts, in front of a cluttered background, and retrieval of occurrences of signs of interest in a video database containing continuous, unsegmented signing in American Sign Language (ASL).	[Alon, Jonathan; Yuan, Quan; Sclaroff, Stan] Boston Univ, Dept Comp Sci, Boston, MA 02215 USA; [Athitsos, Vassilis] Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA	Boston University; University of Texas System; University of Texas Arlington	Alon, J (corresponding author), Boston Univ, Dept Comp Sci, 111 Cummington St, Boston, MA 02215 USA.	jalon@cs.bu.edu; athitsos@uta.edu; yq@cs.bu.edu; sclaroff@cs.bu.edu	Athitsos, Vassilis/AAF-8496-2020; yuan, quan/GZM-5597-2022		US National Science Foundation [CNS-0202067, IIS-0329009, IIS-0705749, IIS-0812601]; Div Of Information & Intelligent Systems [0812601] Funding Source: National Science Foundation	US National Science Foundation(National Science Foundation (NSF)); Div Of Information & Intelligent Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This work was supported by the US National Science Foundation under Grants CNS-0202067, IIS-0329009, IIS-0705749, and IIS-0812601.	Alon J, 2005, LECT NOTES COMPUT SC, V3766, P189, DOI 10.1007/11573425_19; ALON J, 2006, BUCS2006024 BOST U D; ALON J, 2005, P IEEE WORKSH MOT VI, V2, P254; Bahlmann C, 2004, IEEE T PATTERN ANAL, V26, P299, DOI 10.1109/TPAMI.2004.1262308; Battison R, 1978, LEXICAL BORROWING AM; Bauer B, 2000, INT C PATT RECOG, P463, DOI 10.1109/ICPR.2000.906112; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; BOWDEN R, 2004, P ECCV, V1, P390; Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450; Chen FS, 2003, IMAGE VISION COMPUT, V21, P745, DOI 10.1016/S0262-8856(03)00070-2; Corradini A, 2001, IEEE ICCV WORKSHOP ON RECOGNITION, ANALYSIS AND TRACKING OF FACES AND GESTURES IN REAL-TIME SYSTEMS, PROCEEDINGS, P82, DOI 10.1109/RATFG.2001.938914; Cui Y, 2000, COMPUT VIS IMAGE UND, V78, P157, DOI 10.1006/cviu.2000.0837; Cutler R, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P416, DOI 10.1109/AFGR.1998.670984; Darrell T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P335, DOI 10.1109/CVPR.1993.341109; Darrell TJ, 1996, IEEE T PATTERN ANAL, V18, P1236, DOI 10.1109/34.546259; DREUW P, 2006, P ECCV WORKSH STAT M, P7; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jelinek Frederick, 1997, STAT METHODS SPEECH; Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198; Kahol K, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P883, DOI 10.1109/AFGR.2004.1301645; Kang H, 2004, PATTERN RECOGN LETT, V25, P1701, DOI 10.1016/j.patrec.2004.06.016; Ke Y, 2005, IEEE I CONF COMP VIS, P166; Keogh E., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P406; Kolsch M., 2004, IEEE WORKSH REAL TIM, P158, DOI DOI 10.1109/CVPR.2004.345; LAFFERTY J, 1918, P 18 INT C MACH LEAR, P282; Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904; Martin J, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P573, DOI 10.1109/AFGR.1998.671009; Morguet P, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P193, DOI 10.1109/ICIP.1998.999009; NAYAK S, 2005, P IEEE WORKSH VIS HU; Oka K, 2002, IEEE COMPUT GRAPH, V22, P64, DOI 10.1109/MCG.2002.1046630; Oka R, 1998, COMPUT J, V41, P559, DOI 10.1093/comjnl/41.8.559; Ong EJ, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P889; Ostendorf M, 1996, IEEE T SPEECH AUDI P, V4, P360, DOI 10.1109/89.536930; Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226; Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Sankoff D., 1983, TIME WARPS STRING ED, P125; Sato Y, 2002, INT C PATT RECOG, P515, DOI 10.1109/ICPR.2002.1048351; Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811; Starner T, 2000, FOURTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, DIGEST OF PAPERS, P87, DOI 10.1109/ISWC.2000.888469; STEFANOV N, 2005, REAL TIME VISION HUM, V3, P73; Stenger B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1063; SUDDERTH E, 2004, P IEEE CVPR WORKSH G; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Vogler C., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P116, DOI 10.1109/ICCV.1999.791206; Vogler C. P., 2003, THESIS U PENNSYLVANI; Wang CL, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P411, DOI 10.1109/AFGR.2002.1004188; WILLIAMS G, 1998, CS9802 U SHEFF; Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429; Yang HD, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P231; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803; Yoon HS, 2001, PATTERN RECOGN, V34, P1491, DOI 10.1016/S0031-3203(00)00096-0; Yuan Q, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P250; Zhu YX, 2002, COMPUT VIS IMAGE UND, V85, P189, DOI 10.1006/cviu.2002.0967	56	216	233	0	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2009	31	9					1685	1699		10.1109/TPAMI.2008.203	http://dx.doi.org/10.1109/TPAMI.2008.203			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	462QD	19574627				2022-12-18	WOS:000267369800011
J	Corpetti, T; Memin, E; Perez, P				Corpetti, T; Memin, E; Perez, P			Dense estimation of fluid flows	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fluid motion; continuity equation; div-curl regularization; nonconvex minimization; trajectories; vorticity; and divergence concentration	OPTICAL-FLOW; COMPUTATION; FIELDS; MODELS; IMAGES	In this paper, we address the problem of estimating and analyzing the motion of fluids in image sequences. Due to the great deal of spatial and temporal distortions that intensity patterns exhibit in images of fluids, the standard techniques from Computer Vision, originally designed for quasi-rigid motions with stable salient features, are not well adapted in this context. We thus investigate a dedicated minimization-based motion estimator. The cost function to be minimized includes a novel data term relying on an integrated version of the continuity equation of fluid mechanics, which is compatible with large displacements. This term is associated with an original second-order div-curl regularization which prevents the washing out of the salient vorticity and divergence structures. The performance of the resulting fluid flow estimator is demonstrated on meteorological satellite images. In addition, we show how the sequences of dense motion fields we estimate can be reliably used to reconstruct trajectories and to extract the regions of high vorticity and divergence.	Univ Rennes 1, IRISA, F-35042 Rennes, France; Microsoft Res, Cambridge CB2 3NH, England	Universite de Rennes; Microsoft	Corpetti, T (corresponding author), Univ Rennes 1, IRISA, F-35042 Rennes, France.	tcorpett@irisa.fr; memin@irisa.fr; pperez@microsoft.com		Corpetti, Thomas/0000-0002-0257-138X				ADRIAN RJ, 1991, ANNU REV FLUID MECH, V23, P261, DOI 10.1146/annurev.fl.23.010191.001401; Alvarez L, 2000, INT J COMPUT VISION, V39, P41, DOI 10.1023/A:1008170101536; AMINI A, 1994, P EUR C COMP VIS, P125; Bannehr L, 1996, INT J REMOTE SENS, V17, P383, DOI 10.1080/01431169608949013; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141; Bereziat D, 2000, PROC CVPR IEEE, P487, DOI 10.1109/CVPR.2000.854890; BESAG J, 1986, J R STAT SOC B, V48, P259; BLACK M, 1994, P EUR C COMP VIS STO, P138; Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148; Cohen I, 1999, INT J COMPUT VISION, V33, P29, DOI 10.1023/A:1008161130332; Fitzpatrick J. M., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P78; Fitzpatrick J. M., 1988, Electronic Imaging '88. International Electronic Imaging Exposition and Conference. Advance Printing of Paper Summaries, P347; FITZPATRICK JM, 1988, COMPUT VISION GRAPH, V44, P155, DOI 10.1016/S0734-189X(88)80003-3; FORD RM, 1995, GRAPH MODEL IM PROC, V57, P462, DOI 10.1006/gmip.1995.1040; Ford RM, 1997, PATTERN RECOGN, V30, P1991, DOI 10.1016/S0031-3203(97)00029-0; FORDE BG, 1994, SEB SEMINAR SERIES, V56, P1; GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331; Gupta SN, 1996, IEEE SIGNAL PROC LET, V3, P32, DOI 10.1109/97.484208; Haussecker HW, 2001, IEEE T PATTERN ANAL, V23, P661, DOI 10.1109/34.927465; HOLLAND PW, 1977, COMMUN STAT A-THEOR, V6, P813, DOI 10.1080/03610927708827533; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Huber P., 1981, ROBUST STAT; Ju SX, 1996, PROC CVPR IEEE, P307, DOI 10.1109/CVPR.1996.517090; Kornprobst P, 1999, J MATH IMAGING VIS, V11, P5, DOI 10.1023/A:1008318126505; Lai SH, 1998, INT J COMPUT VISION, V29, P87, DOI 10.1023/A:1008005509994; Larsen R, 1998, IEEE T GEOSCI REMOTE, V36, P256, DOI 10.1109/36.655334; MASS H, 1992, P INT C IM PROC SEPT, P530; Maurizot M, 1998, PROC CVPR IEEE, P184, DOI 10.1109/CVPR.1998.698607; Memin E, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P933, DOI 10.1109/ICCV.1998.710828; Memin E, 2001, REAL-TIME IMAGING, V7, P109, DOI 10.1006/rtim.2000.0215; Memin E, 1998, IEEE T IMAGE PROCESS, V7, P703, DOI 10.1109/83.668027; MEMIN E, 1999, P INT C COMP VIS COR, V3, P732; Nogawa H, 1997, IEEE T PATTERN ANAL, V19, P58, DOI 10.1109/34.566811; Ottenbacher A, 1997, WEATHER FORECAST, V12, P175, DOI 10.1175/1520-0434(1997)012<0175:LLCMWF>2.0.CO;2; PAPIN C, 2000, P EUR C COMP VIS, V2, P428; Peddada SD, 1996, IEEE T GEOSCI REMOTE, V34, P915, DOI 10.1109/36.508408; SHUKLA J, 1974, MON WEATHER REV, V102, P419, DOI 10.1175/1520-0493(1974)102<0419:CONDSA>2.0.CO;2; SIMPSON JJ, 1994, IEEE T GEOSCI REMOTE, V32, P479, DOI 10.1109/36.297966; SUTER D, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P939, DOI 10.1109/CVPR.1994.323929; TRIPLET JP, 1971, METEOROLOGIE GEN; WALLACE JM, 1995, ANNU REV FLUID MECH, V27, P469, DOI 10.1146/annurev.fl.27.010195.002345; Weickert J, 2001, J MATH IMAGING VIS, V14, P245, DOI 10.1023/A:1011286029287; Weickert J., 2000, COMPUTER SCI SERIES; Wernert P, 1996, AIAA J, V34, P982, DOI 10.2514/3.13177; Wildes RP, 2000, COMPUT VIS IMAGE UND, V80, P246, DOI 10.1006/cviu.2000.0874; Zhou L, 2000, PROC CVPR IEEE, P744, DOI 10.1109/CVPR.2000.854949; [No title captured]	48	216	222	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2002	24	3					365	380		10.1109/34.990137	http://dx.doi.org/10.1109/34.990137			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	524WM		Green Submitted			2022-12-18	WOS:000174035900006
J	Zhou, F; De la Torre, F; Hodgins, JK				Zhou, Feng; De la Torre, Fernando; Hodgins, Jessica K.			Hierarchical Aligned Cluster Analysis for Temporal Clustering of Human Motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Temporal segmentation; time series clustering; time series visualization; human motion analysis; kernel k-means; spectral clustering; dynamic programming	MOVEMENT; CAPTURE; VIEW	Temporal segmentation of human motion into plausible motion primitives is central to understanding and building computational models of human motion. Several issues contribute to the challenge of discovering motion primitives: the exponential nature of all possible movement combinations, the variability in the temporal scale of human actions, and the complexity of representing articulated motion. We pose the problem of learning motion primitives as one of temporal clustering, and derive an unsupervised hierarchical bottom-up framework called hierarchical aligned cluster analysis (HACA). HACA finds a partition of a given multidimensional time series into m disjoint segments such that each segment belongs to one of k clusters. HACA combines kernel k-means with the generalized dynamic time alignment kernel to cluster time series data. Moreover, it provides a natural framework to find a low-dimensional embedding for time series. HACA is efficiently optimized with a coordinate descent strategy and dynamic programming. Experimental results on Motion capture and video data demonstrate the effectiveness of HACA for segmenting complex motions and as a visualization tool. We also compare the performance of HACA to state-of-the-art algorithms for temporal clustering on data of a honey bee dance. The HACA code is available online.	[Zhou, Feng; De la Torre, Fernando; Hodgins, Jessica K.] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15232 USA	Carnegie Mellon University	Zhou, F (corresponding author), Carnegie Mellon Univ, Inst Robot, Smith Hall,5000 Forbes Ave, Pittsburgh, PA 15232 USA.	zhfe99@gmail.com; ftorre@cs.cmu.edu; jkh@cs.cmu.edu			US National Science Foundation (NSF) [EEEC-0540865, RI-1116583, CPS-0931999]	US National Science Foundation (NSF)(National Science Foundation (NSF))	This work was partially supported by the US National Science Foundation (NSF) under Grant Nos. EEEC-0540865, RI-1116583, and CPS-0931999. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.	[Anonymous], 2012, CARNEGIE MELLON U MO; [Anonymous], P 23 INT C MACH LEAR; [Anonymous], 2002, LEARNING KERNELS; Barbic J, 2004, PROC GRAPH INTERF, P185; Beaudoin P., 2008, P ACM SIGGR EUR S CO; Bertsekas D. P., 1995, DYNAMIC PROGRAMMING; Bowden R., 2000, P IEEE WORKSH HUM MO; Burkard R., 2009, ASSIGNMENT PROBLEMS; Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681; Cuturi M., 2007, P IEEE INT C AC SPEE; De la Torre F., 2007, P 11 IEEE INT C COMP; De la Torre F., 2007, P IEEE INT C MULT EX; De la Torre F, 2012, IEEE T PATTERN ANAL, V34, P1041, DOI 10.1109/TPAMI.2011.184; Del Vecchio D, 2003, AUTOMATICA, V39, P2085, DOI 10.1016/S0005-1098(03)00250-4; Desobry F, 2005, IEEE T SIGNAL PROCES, V53, P2961, DOI 10.1109/TSP.2005.851098; Dhillon I.S., 2004, ACM SIGKDD; EFROS AA, 2003, P 9 IEEE INT C COMP; Fearnhead P, 2006, STAT COMPUT, V16, P203, DOI 10.1007/s11222-006-8450-8; Fod A, 2002, AUTON ROBOT, V12, P39, DOI 10.1023/A:1013254724861; Forbes K., 2005, P ACM SIGGR EUR S CO; Fox E., 2008, P NEUR INF PROC SYST; Fox E.B., 2009, P NEUR INF PROC SYST; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; GUERRA G, 2006, J VISUAL COMP ANIMAT, V17, P207, DOI DOI 10.1002/CAV.124; Guerra G, 2007, COMPUTER, V40, P42, DOI 10.1109/MC.2007.154; Haasdonk B, 2005, IEEE T PATTERN ANAL, V27, P482, DOI 10.1109/TPAMI.2005.78; Hamid R., 2007, P 11 IEEE INT C COMP; Harchaoui Z., 2009, P NEUR INF PROC SYST; Jenkins O.C., 2002, P IEEE RSJ INT C INT; JENKINS OC, 2004, P INT C MACH LEARN; Kay S. M., 1993, FUNDAMENTALS STAT SI, V2; Keogh E. J., 2000, P 6 ACM SIGKDD INT C; Kobayashi T., 2008, P IEEE 8 INT C AUT F; Le QV, 2011, PROC CVPR IEEE; Lee JH, 2002, ACM T GRAPHIC, V21, P491; Liao TW, 2005, PATTERN RECOGN, V38, P1857, DOI 10.1016/j.patcog.2005.01.025; Liu G., 2006, P ACM SIGGR EUR S CO; Lu CM, 2004, IEEE T PATTERN ANAL, V26, P258, DOI 10.1109/TPAMI.2004.1262196; Lucas Bruce, 1981, IJCAI; Lv F., 2006, P EUR C COMP VIS; MacQueen J.B., 1967, P 5 BERK S MATH STAT; Marwan N, 2007, PHYS REP, V438, P237, DOI 10.1016/j.physrep.2006.11.001; Hoai M, 2011, PROC CVPR IEEE; Minnen D., 2007, P 22 INT C ART INT; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; Muller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247; Ng AY, 2002, ADV NEUR IN, V14, P849; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Oh SM, 2008, INT J COMPUT VISION, V77, P103, DOI 10.1007/s11263-007-0062-z; Ostendorf M, 1996, IEEE T SPEECH AUDI P, V4, P360, DOI 10.1109/89.536930; Pavlovic V., 2000, P NEUR INF PROC SYST; Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016; Roweis S, 1999, NEURAL COMPUT, V11, P305, DOI 10.1162/089976699300016674; Rui Y, 2000, P IEEE C COMP VIS PA; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81, DOI 10.1109/TPAMI.1984.4767478; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shimodaira H., 2001, P NEUR INF PROC SYST; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Turaga P, 2009, COMPUT VIS IMAGE UND, V113, P353, DOI 10.1016/j.cviu.2008.08.009; Wang J., 2003, P ACM SIGGR EUR S CO; Xuan X., 2007, P 24 INT C MACH LEAR; Yi B., 1998, P 14 INT C DAT ENG; Zass R., 2005, P 10 IEEE INT C COMP; Zelnik-Manor L, 2006, IEEE T PATTERN ANAL, V28, P1530, DOI 10.1109/TPAMI.2006.194; ZHA H, 2001, P NEUR INF PROC SYST; Zhong H., 2004, P IEEE C COMP VIS PA; Zhou F., 2008, P 8 IEEE INT C AUT F; [No title captured]	70	215	230	5	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2013	35	3					582	596		10.1109/TPAMI.2012.137	http://dx.doi.org/10.1109/TPAMI.2012.137			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	087VS	22732658	Green Submitted			2022-12-18	WOS:000314792900006
J	Lafon, S; Keller, Y; Coifman, RR				Lafon, Stephane; Keller, Yosi; Coifman, Ronald R.			Data fusion and multicue data matching by diffusion maps	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern matching; graph theory; graph algorithms; Markov processes; machine learning; data mining; image databases	DIMENSIONALITY REDUCTION; GEOMETRIC DIFFUSIONS; STRUCTURE DEFINITION; HARMONIC-ANALYSIS; TOOL	Data fusion and multicue data matching are fundamental tasks of high-dimensional data analysis. In this paper, we apply the recently introduced diffusion framework to address these tasks. Our contribution is three-fold: First, we present the Laplace-Beltrami approach for computing density invariant embeddings which are essential for integrating different sources of data. Second, we describe a refinement of the Nystrom extension algorithm called "geometric harmonics." We also explain how to use this tool for data assimilation. Finally, we introduce a multicue data matching scheme based on nonlinear spectral graphs alignment. The effectiveness of the presented schemes is validated by applying it to the problems of lipreading and image sequence alignment.	Google Inc, Mountain View, CA 94043 USA; Yale Univ, Dept Appl Math, New Haven, CT 06511 USA	Google Incorporated; Yale University	Lafon, S (corresponding author), Google Inc, 1600 Amphitheater Pkwy, Mountain View, CA 94043 USA.	stephane.lafon@gmail.com; yosi.keller@yale.edu; coifman-ronald@yale.edu						AHARON M, IN PRESS INT J COMPU; Bai X, 2004, INT C PATT RECOG, P398, DOI 10.1109/ICPR.2004.1334550; Belkin M, 2005, LECT NOTES COMPUT SC, V3559, P486, DOI 10.1007/11503415_33; Belkin M, 2002, ADV NEUR IN, V14, P585; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Belkin M., 2004, TR200406 U CHIC; BENGIO Y, 2003, 1238 U MONTR; Borg I., 1997, MODERN MULTIDIMENSIO; BREGLER C, 1998, COMPUTER VISION MAN; BREGLER C, 1993, P IEEE INT C AC SPEE; CHRISTOPH B, 1997, P 24 ANN C COMP GRAP, P353; Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P31, DOI 10.1016/j.acha.2005.07.005; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006; Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7426, DOI 10.1073/pnas.0500334102; Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7432, DOI 10.1073/pnas.0500896102; Cosatto E, 2000, IEEE T MULTIMEDIA, V2, P152, DOI 10.1109/6046.865480; DETTMER N, 1997, COMPUTATIONAL IMAGIN, P345; Diaconis Persi, 1991, ANN APPL PROBAB, V1, P36, DOI DOI 10.1214/aoap/1177005980; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100; Fitzgibbon AW, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P662, DOI 10.1109/ICCV.2001.937584; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; Gori M, 2005, IEEE T PATTERN ANAL, V27, P1100, DOI 10.1109/TPAMI.2005.138; HAM J, 2005, P 10 INT WORKSH ART, P120; Keselman Y, 2003, PROC CVPR IEEE, P850; Kondor R.I., 2002, P 19 INT C MACHINE L, P315; LAFON S, 2005, DEMO MASK ALIGNMENT; Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1393, DOI 10.1109/TPAMI.2006.184; Luettin J, 1997, COMPUT VIS IMAGE UND, V65, P163, DOI 10.1006/cviu.1996.0570; LUETTIN J, 1996, NATO ASI SERIES F, V150, P383; Matthews I, 2002, IEEE T PATTERN ANAL, V24, P198, DOI 10.1109/34.982900; Meila M., 2001, P INT WORKSH ART INT; Nadler B, 2006, APPL COMPUT HARMON A, V21, P113, DOI 10.1016/j.acha.2005.07.004; Nefian AV, 2002, EURASIP J APPL SIG P, V2002, P1274, DOI 10.1155/S1110865702206083; Press WH, 1988, NUMERICAL RECIPES C; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Tian Ying- li, 2000, P 4 AS C COMP VIS AC; Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P975, DOI 10.1109/ICCV.1999.790354; Wolfson HJ, 1997, IEEE COMPUT SCI ENG, V4, P10, DOI 10.1109/99.641604; Yu SX, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P313, DOI 10.1109/iccv.2003.1238361; ZHANG Z, 2002, CSE02019 PENN STAT U	42	215	228	0	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2006	28	11					1784	1797		10.1109/TPAMI.2006.223	http://dx.doi.org/10.1109/TPAMI.2006.223			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	083GC	17063683				2022-12-18	WOS:000240443400006
J	Wang, Y; Mori, G				Wang, Yang; Mori, Greg			Human Action Recognition by Semilatent Topic Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human action recognition; video analysis; bag-of-words; probabilistic graphical models; event and activity understanding	CATEGORIES; TRACKING	We propose two new models for human action recognition from video sequences using topic models. Video sequences are represented by a novel "bag-of-words" representation, where each frame corresponds to a "word." Our models differ from previous latent topic models for visual recognition in two major aspects: first of all, the latent topics in our models directly correspond to class labels; second, some of the latent variables in previous topic models become observed in our case. Our models have several advantages over other latent topic models used in visual recognition. First of all, the training is much easier due to the decoupling of the model parameters. Second, it alleviates the issue of how to choose the appropriate number of latent topics. Third, it achieves much better performance by utilizing the information provided by the class labels in the training set. We present action classification results on five different data sets. Our results are either comparable to, or significantly better than previously published results on these data sets.	[Wang, Yang; Mori, Greg] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	Simon Fraser University	Wang, Y (corresponding author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.	ywang12@cs.sfu.ca; mori@cs.sfu.ca	Cataldi, Antonio/AAM-7411-2021		NSERC [RGPIN-312230]	NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC))	The authors would like to thank Payam Sabzmeydani for his contribution in the early stage of this research. Thank also to the authors of [2], [12], [13], [25], [39], [50], [51], [52] for making various data sets and source codes used in this paper publicly available. This work is supported by a grant from NSERC (RGPIN-312230).	Blank M., 2005, P IEEE INT C COMP VI; Blei D. M., 2008, ADV NEURAL INFORM PR, V20; Blei D. M, 2006, ADV NEURAL INFORM PR, V18; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Bobick AF, 1997, IEEE T PATTERN ANAL, V19, P1325, DOI 10.1109/34.643892; BOSCH A, 2006, P EUR C COMP VIS, P517; Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681; Dollar P., 2005, P IEEE INT C COMP VI; Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726; FATHI A, 2008, P IEEE CS C COMP VIS; Fei-Fei L, 2005, PROC CVPR IEEE, P524; FENG X, 2002, P INT S 3D DAT PROC; Fergus R, 2005, IEEE I CONF COMP VIS, P1816; Flaherty P, 2005, BIOINFORMATICS, V21, P3286, DOI 10.1093/bioinformatics/bti515; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649; HUANG J, 2009, FITTING HIERARCHICAL; IKIZLER N, 2007, P IEEE CS C COMP VIS; JHUANG H, 2007, P IEEE INT C COMP VI; Ke Y, 2005, IEEE I CONF COMP VIS, P166; Laptev  I., 2003, P IEEE INT C COMP VI; Laptev I., 2007, P IEEE INT C COMP VI; Laptev I., 2008, P IEEE CS C COMP VIS; LAXTON B, 2007, P IEEE CS C COMP VIS; Lazebnik S, 2005, IEEE I CONF COMP VIS, P832, DOI 10.1109/ICCV.2005.10; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Little J. J., 1998, Videre, V1; LIU J, 2008, P IEEE CS C COMP VIS; Lu WL, 2009, IMAGE VISION COMPUT, V27, P189, DOI 10.1016/j.imavis.2008.02.008; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; Minka TP, 2000, ESTIMATING DIRICHLET; NIEBLES JC, 2006, P BRIT MACH VIS C, P1249; NIEBLES JC, 2007, P IEEE CS C COMP VIS; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; NOWOZIN S, 2007, P IEEE INT C COMP VI; Oliver N, 2004, COMPUT VIS IMAGE UND, V96, P163, DOI 10.1016/j.cviu.2004.02.004; Polana R, 1997, INT J COMPUT VISION, V23, P261, DOI 10.1023/A:1007975200487; RODRIGUEZ MD, 2008, P IEEE CS C COMP VIS; RUSSELL BC, 2006, P IEEE CS C COMP VIS; SCHINDLER K, 2008, P IEEE CS C COMP VIS; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Shechtman E., 2005, P INT C COMP VIS PAT; Sivic J, 2005, IEEE I CONF COMP VIS, P370; SMINCHISESCU C, 2005, P IEEE INT C COMP VI; Sullivan M., 2002, J HUMAN BEHAV SOCIAL, V5, P1, DOI [10.1300/j137v05n01_01, DOI 10.1300/J137V05N01_01]; THURAN C, 2008, P IEEE CS C COMP VIS; WANG SB, 2006, P IEEE CS C COMP VIS; WANG Y, 2007, P 2 WORKSH HUM MOT U; WONG SF, 2007, P IEEE CS C COMP VIS; Xiang T, 2006, INT J COMPUT VISION, V67, P21, DOI 10.1007/s11263-006-4329-6; YAMATO J, 1992, P IEEE CS C COMP VIS; Yang M., 2007, ADV NEURAL INF PROCE, V19, P169; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4	54	214	219	1	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2009	31	10					1762	1774		10.1109/TPAMI.2009.43	http://dx.doi.org/10.1109/TPAMI.2009.43			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	483VK	19696448				2022-12-18	WOS:000268996500004
J	Sun, YJ				Sun, Yijun			Iterative RELIEF for feature weighting: Algorithms, theories, and applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						feature weighting; feature selection; RELIEF; iterative algorithm; DNA microarray; classification	PREDICTION; CANCER; CLASSIFICATION	RELIEF is considered one of the most successful algorithms for assessing the quality of features. In this paper, we propose a set of new feature weighting algorithms that perform significantly better than RELIEF, without introducing a large increase in computational complexity. Our work starts from a mathematical interpretation of the seemingly heuristic RELIEF algorithm as an online method solving a convex optimization problem with a margin-based objective function. This interpretation explains the success of RELIEF in real application and enables us to identify and address its following weaknesses. RELIEF makes an implicit assumption that the nearest neighbors found in the original feature space are the ones in the weighted space and RELIEF lacks a mechanism to deal with outlier data. We propose an iterative RELIEF (I-RELIEF) algorithm to alleviate the deficiencies of RELIEF by exploring the framework of the Expectation-Maximization algorithm. We extend I-RELIEF to multiclass settings by using a new multiclass margin definition. To reduce computational costs, an online learning algorithm is also developed. Convergence analysis of the proposed algorithms is presented. The results of large-scale experiments on the UCI and microarray data sets are reported, which demonstrate the effectiveness of the proposed algorithms, and verify the presented theoretical results.	Univ Florida, Interdisciplinary Ctr Biotechnol Res, Gainesville, FL 32610 USA	State University System of Florida; University of Florida	Sun, YJ (corresponding author), Univ Florida, Interdisciplinary Ctr Biotechnol Res, POB 103622, Gainesville, FL 32610 USA.	sun@dsp.ufl.edu	Sun, Yijun/F-9698-2017					Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bishop, 1995, NEURAL NETWORKS PATT; Chong EK., 2013, INTRO OPTIMIZATION; Crammer K., 2002, P 17 C NEUR INF PROC; Demiriz A, 2002, MACH LEARN, V46, P225, DOI 10.1023/A:1012470815092; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2, P263; Dietterich TG, 1997, AI MAG, V18, P97; Duda R.O., 2000, PATTERN CLASSIFICATI; Elisseeff A., 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Gilad-Bachrach R., 2004, P 21 INT C MACH LEAR, P43; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Jain Anil, 1997, IEEE T PATTERN ANAL, V19; Jenssen TK, 2005, LANCET, V365, P634; Kenji K, 1992, P 9 INT WORKSH MACH, P249, DOI DOI 10.1016/B978-1-55860-247-2.50037-1; Khan J, 2001, NAT MED, V7, P673, DOI 10.1038/89044; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Kononenko I., 1994, MACHINE LEARNING ECM, P171, DOI [10.1007/3-540-57868-4_57, DOI 10.1007/3-540-57868-4_57]; Kress R., 1998, NUMERICAL ANAL; Kushner HJ., 2003, STOCHASTIC APPROXIMA; Newman C. B. D., 1998, UCI REPOSITORY MACHI; Nutt CL, 2003, CANCER RES, V63, P1602; Pudil P, 1998, IEEE INTELL SYST APP, V13, P66, DOI 10.1109/5254.671094; Ramaswamy S, 2001, P NATL ACAD SCI USA, V98, P15149, DOI 10.1073/pnas.211566398; Sato M, 2000, NEURAL COMPUT, V12, P407, DOI 10.1162/089976600300015853; Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68; Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2; Staunton JE, 2001, P NATL ACAD SCI USA, V98, P10787, DOI 10.1073/pnas.191368598; Sun Y., 2005, P 22 INT C MACH LEAR, P872; Sun Y, 2006, P 23 INT C MACH LEAR, P913, DOI DOI 10.1145/1143844.1143959; Sun YJ, 2007, BIOINFORMATICS, V23, P30, DOI 10.1093/bioinformatics/btl543; Vapnik V.N, 1998, STAT LEARNING THEORY; Wessels LFA, 2005, BIOINFORMATICS, V21, P3755, DOI 10.1093/bioinformatics/bti429; Weston J, 2001, ADV NEUR IN, V13, P668; Wettschereck D, 1997, ARTIF INTELL REV, V11, P273, DOI 10.1023/A:1006593614256	36	214	241	1	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2007	29	6					1035	1051		10.1109/TPAMI.2007.1093	http://dx.doi.org/10.1109/TPAMI.2007.1093			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	155TJ	17431301				2022-12-18	WOS:000245600800009
J	Ribaric, S; Fratric, I				Ribaric, S; Fratric, I			A biometric identification system based on eigenpalm and eigenfinger features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						biometrics; multimodal systems; hand-based identification; K-L transform; eigenpalms; eigenfingers	VERIFICATION; FUSION	This paper presents a multimodal biometric identification system based on the features of the human hand. We describe a new biometric approach to personal identification using eigenfinger and eigenpalm features, with fusion applied at the matching-score level. The identification process can be divided into the following phases: capturing the image; preprocessing; extracting and normalizing the palm and strip-like finger subimages; extracting the eigenpalm and eigenfinger features based on the K- L transform; matching and fusion; and, finally, a decision based on the (k, l)-NN classifier and thresholding. The system was tested on a database of 237 people (1,820 hand images). The experimental results showed the effectiveness of the system in terms of the recognition rate (100 percent), the equal error rate (EER = 0.58 percent), and the total error rate (TER = 0.72 percent).	Univ Zagreb, Dept Elect Microelect Comp & Intelligent Syst, Fac Elect & Comp Engn, Zagreb 10000, Croatia	University of Zagreb	Ribaric, S (corresponding author), Univ Zagreb, Dept Elect Microelect Comp & Intelligent Syst, Fac Elect & Comp Engn, Unska 3, Zagreb 10000, Croatia.	slobodan.ribaric@fer.hr; ivan.fratric@fer.hr	Ribaric, Slobodan/U-4611-2018	Ribaric, Slobodan/0000-0002-8708-8513				BREGLER C, 1994, INT CONF ACOUST SPEE, P669, DOI 10.1109/ICASSP.1994.389567; BRUNELLI R, 1995, IEEE T PATTERN ANAL, V17, P955, DOI 10.1109/34.464560; Burge M., 1996, EAR BIOMETRICS, P273, DOI DOI 10.1007/0-306-47044-6_13; CAMPBELL JP, 2000, AUTOMATED BIOMETRICS, P1437; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Duta N, 2002, PATTERN RECOGN LETT, V23, P477, DOI 10.1016/S0167-8655(01)00179-9; Golfarelli M, 1997, IEEE T PATTERN ANAL, V19, P786, DOI 10.1109/34.598237; Gonzales R, 1993, DIGITAL IMAGE PROCES; Halici U, 1999, INT SER COMPUTAT INT, P1; Hamada Y, 2000, WORKSHOP ON HUMAN MOTION, PROCEEDINGS, P161, DOI 10.1109/HUMO.2000.897387; Han CC, 2003, PATTERN RECOGN, V36, P371, DOI 10.1016/S0031-3203(02)00037-7; Hill R. B., 1999, BIOMETRICS PERSONAL, P123; HONG L, 2000, AUTOMATED BIOMETRICS, P326; *INT COMM INF TECH, 2005, M1 INT COMM INF TECH; Jain A., 1999, BIOMETRICS PERSONAL; Jain A. K., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P857, DOI 10.1109/ICIP.1999.823019; Jain AK, 1999, PATTERN RECOGN LETT, V20, P1371, DOI 10.1016/S0167-8655(99)00108-7; Jain AK, 1997, P IEEE, V85, P1365, DOI 10.1109/5.628674; Jain AK, 2004, COMMUN ACM, V47, P34, DOI 10.1145/962081.962102; Jain AK, 2002, IEEE IMAGE PROC, P57; Kittler J, 2003, IEEE T PATTERN ANAL, V25, P110, DOI 10.1109/TPAMI.2003.1159950; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kumar A., 2003, P 4 INT C AUD VID BA, P668; Lu GM, 2003, PATTERN RECOGN LETT, V24, P1463, DOI 10.1016/S0167-8655(02)00386-0; Negin M, 2000, COMPUTER, V33, P70, DOI 10.1109/2.820042; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; *REC SYST INC, 1991, PERF EV BIOM ID DEV; Ribaric S, 2003, IEE P-VIS IMAGE SIGN, V150, P409, DOI 10.1049/ip-vis:20031038; Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5; Ross A, 1999, P 2 INT C AUD VID BA, P166; Sanchez-Reillo R, 2000, IEEE T PATTERN ANAL, V22, P1168, DOI 10.1109/34.879796; Shu W, 1998, OPT ENG, V37, P2359, DOI 10.1117/1.601756; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WILDES RP, 2000, AUTOMATED BIOMETRICS, P1348; You J, 2002, PATTERN RECOGN, V35, P847, DOI 10.1016/S0031-3203(01)00100-5; Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981; Zhang D., 2000, AUTOMATED BIOMETRICS; Zhang DP, 1999, PATTERN RECOGN, V32, P691, DOI 10.1016/S0031-3203(98)00117-4; Zhang J, 1997, P IEEE, V85, P1423, DOI 10.1109/5.628712	39	214	224	2	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2005	27	11					1698	1709		10.1109/TPAMI.2005.209	http://dx.doi.org/10.1109/TPAMI.2005.209			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	963SN	16285370	Green Submitted			2022-12-18	WOS:000231826300002
J	Yang, MH; Ahuja, N; Tabb, M				Yang, MH; Ahuja, N; Tabb, M			Extraction of 2D motion trajectories and its application to hand gesture recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion segmentation; motion analysis; motion trajectory; American Sign Language; hand gesture recognition; time-delay neural network	MULTISCALE IMAGE SEGMENTATION; AMERICAN SIGN-LANGUAGE; INTEGRATED EDGE; SEQUENCES; FRAMEWORK	We present an algorithm for extracting and classifying two-dimensional motion in an image sequence based on motion trajectories. First, a multiscale segmentation is performed to generate homogeneous regions in each frame. Regions between consecutive frames are then matched to obtain two-view correspondences. Affine transformations are computed from each pair of corresponding regions to define pixel matches. Pixels matches over consecutive image pairs are concatenated to obtain pixel-level motion trajectories across the image sequence. Motion patterns are learned from the extracted trajectories using a time-delay neural network. We apply the proposed method to recognize 40 hand gestures of American Sign Language. Experimental results show that motion patterns of hand gestures can be extracted and recognized accurately using motion trajectories.	Honda Fundamental Res Labs, Mountain View, CA 94041 USA; Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; Univ Illinois, Beckman Inst, Urbana, IL 61801 USA; Vexcel Corp, Boulder, CO 80301 USA	Honda Motor Company; University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign	Yang, MH (corresponding author), Honda Fundamental Res Labs, 800 Calif St, Mountain View, CA 94041 USA.	myang@hra.com; ahuja@vision.ai.uiuc.edu; tabb@vexcel.com	Yang, Ming-Hsuan/AAE-7350-2019; Yang, Ming-Hsuan/T-9533-2019	Yang, Ming-Hsuan/0000-0003-4848-2304				Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744; AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965; Ahuja N, 1996, IEEE T PATTERN ANAL, V18, P1211, DOI 10.1109/34.546258; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BLACK MJ, 1998, P 5 EUR C COMP VIS, V1, P909; Bobick AF, 1997, IEEE T PATTERN ANAL, V19, P1325, DOI 10.1109/34.643892; Cipolla R., 1998, COMPUTER VISION HUMA; Crowley JL, 1997, PROC CVPR IEEE, P640, DOI 10.1109/CVPR.1997.609393; Cui YT, 1999, IEEE T PATTERN ANAL, V21, P798, DOI 10.1109/34.784311; Darrell T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P335, DOI 10.1109/CVPR.1993.341109; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Duda R. O., 2001, PATTERN CLASSIFICATI; Fels SS, 1998, IEEE T NEURAL NETWOR, V9, P205, DOI 10.1109/72.655042; FELSON RB, 1993, PSYCHOL PERSPECTIVES, V4, P1; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; Haynes S., 1980, COMPUTER VISION GRAP, V21, P345; HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841; Hopcroft J.E., 1972, COMPLEXITY COMPUTER, P131, DOI [10.1007/978-1-4684-2001-2, DOI 10.1007/978-1-4684-2001-2]; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378; Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904; Leonardis A., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P121, DOI 10.1109/ICCV.1990.139508; Marshall D, 2001, IEEE T PATTERN ANAL, V23, P304, DOI 10.1109/34.910883; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226; POIZNER H, 1981, J EXP PSYCHOL HUMAN, V7, P430, DOI 10.1037/0096-1523.7.2.430; PRICE K, 1979, IEEE T PATTERN ANAL, V1, P110, DOI 10.1109/TPAMI.1979.4766884; REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034; SCHLENZIG J, 1994, P 28 AS C SIGN SYST; SHAH M, 1997, MOTION BASED RECOGNI; SISKIND JM, 1996, P 4 EUR C COMP VIS, P347; SPERLING G, 1985, COMPUT VISION GRAPH, V31, P335, DOI 10.1016/0734-189X(85)90034-9; Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811; STARNER T, 1995, P INT WORKSH AUT FAC, P189; SULL S, 1994, IEEE T PATTERN ANAL, V16, P357, DOI 10.1109/34.277590; Tabb M, 1997, IEEE T IMAGE PROCESS, V6, P642, DOI 10.1109/83.568922; TABB M, 1996, THESIS U ILLINOIS UR; VERRI A, 1990, J OPT SOC AM A, V7, P912, DOI 10.1364/JOSAA.7.000912; Vogler C, 2001, COMPUT VIS IMAGE UND, V81, P358, DOI 10.1006/cviu.2000.0895; Vogler C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P363, DOI 10.1109/ICCV.1998.710744; WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701; Weiss Y, 1996, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.1996.517092; WENG JY, 1992, IEEE T PATTERN ANAL, V14, P806, DOI 10.1109/34.149592; Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429; YANG MH, 2001, FACE DETECTION HAND; Zhao M, 1998, IEEE T PATTERN ANAL, V20, P1174, DOI 10.1109/34.730553	47	214	220	2	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2002	24	8					1061	1074		10.1109/TPAMI.2002.1023803	http://dx.doi.org/10.1109/TPAMI.2002.1023803			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	578JY					2022-12-18	WOS:000177115100005
J	CHIN, RT; HARLOW, CA				CHIN, RT; HARLOW, CA			AUTOMATED VISUAL INSPECTION - A SURVEY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review									LOUISIANA STATE UNIV,COLL ENGN,DEPT ELECT ENGN,BATON ROUGE,LA 70803	Louisiana State University System; Louisiana State University	CHIN, RT (corresponding author), UNIV WISCONSIN,DEPT ELECT & COMP ENGN,MADISON,WI 53706, USA.		Chin, Roland Tai Hong/E-9856-2010					AGARWALA AK, 1977, MACHINE RECOGNITION; AGGARWAL JD, 1977, COMPUTER METHODS IMA; AGIN GJ, 1980, COMPUTER, V13, P11, DOI 10.1109/MC.1980.1653613; ALLAN R, 1978, IEEE SPECTRUM    JAN, P45; Almi L. U., 1977, Applications of Holography and Optical Data Processing, P541; AMODEI JJ, 1975, MAY P SPIE SOLV QUAL, V60, P3; ANDERSON J, 1974, OCT P AUT INSP PROD, P125; ARLAN L, 1980, FEB P SPIE OPT METR, V220; ARLAN L, 1979, JUL P SPIE IM APPL A, V182, P130; ARNST C, 1978, COMPUTER WORLD  1226, P10; ASADA H, 1979, APR P SPIE IM APPL A, V182, P14; AXELROD NN, 1972, PR INST ELECTR ELECT, V60, P447, DOI 10.1109/PROC.1972.8654; BAIRD ML, 1978, IEEE T SYST MAN CYB, V8, P133; BAIRD ML, 1978, 4TH P INT JOINT C PA, P1146; BAIRD ML, 1976, 3RD INT JOINT C PATT; Baker AJ, 1978, OPTICAL ACTA, V25, P1187; BAKER LR, 1975, OPT SPECTRA      JUL, P30; BARNARD S, 1980, 5TH P INT C PATT REC; BARTON CF, 1979, APR ASNT SPRING C SA; BATCHELOR BG, 1979, APR P SPIE IM APPL A, V182, P65; BATCHELOR BG, 1978, 4TH P INT C AUT INSP, P49; BAXTER DW, 1977, Patent No. 4056716; BENTLEY WA, 1979, AUG P SPIE OPT PATT, V201, P37; BENTLEY WA, 1980, FEB P SPIE OPT METR, V220; BERGER H, 1972, FEB P SPIE IM TECHN, V29; BIBLE RE, 1977, NOV P SPIE EFF UT OP, V129, P24; BIDDLES BJ, 1975, MAY P SPIE SOLV QUAL, V60, P34; BINFORD TO, 1976, OCT WORKSH ADV AUT; BIRTH GS, 1977, NOV P SPIE EFF UT OP, V12, P64; Bjorklund C. M., 1977, Proceedings of the International Conference on Cybernetics and Society, P690; BOOTHROYD G, 1977, 4 SME ASS C EXP DETR; BOTTOMLEY SC, 1975, MAY P SPIE SOLV QUAL, V60, P130; BOURDELAIS RJ, 1974, Patent No. 3795452; BRANAMAN LA, 1979, APR P SPIE IM APPL A, V182, P102; BRASNETT KA, 1978, MACHINE AIDED IMAGE, P168; BRES E, 1980, JUL P SPIE ADV LAS E, V247; Brook R. A., 1971, Metron, V3, P219; BROOK RA, 1977, P SOC PHOTO OPTICAL, V130, P84; BROOK RA, 1979, APR P SPIE IM APPL A, V182, P79; BRUNING JH, 1975, IEEE T ELECTRON DEVI, V22; BUCKLEY S, 1977, 4 SME ASS C; CALLEN JE, 1975, ELECTROOPT SYST  JUL, P44; Caulfield J., 1977, Proceedings of the Society of Photo-Optical Instrumentation Engineers, vol.122. Advances in Laser Engineering, P18; CEDERBERY R, 1980, 1ST P SCAND C IM AN, P270; CENTER RM, 1972, QUAL MANAGEMENT  SEP; CHENG CCK, 1978, AUG P SPIE IM UND SY, V155, P78; CHENG CK, 1975, NOV EL SYST DES C AN; CHIEN RT, 1975, IEEE T CIRCUITS SYST, VCA22, P541, DOI 10.1109/TCS.1975.1084080; CHIEN RT, 1975, 4TH P INT JOINT C AR, P742; CHIN RT, 1978, AUG P SPIE IM UND SY, V155, P199; CHIN RT, 1979, AUTOMATED VISUAL INS; CHITTINENI CB, 1980, NOV WORKSH DIG SIGN; CHRISTIANSEN D, 1978, IEEE SPECTRUM    OCT; CIARLO DR, 1975, P SOC PHOTO OPTICAL, V55, P84; CIARLO DR, 1977, UCID17391 LAWR LIV L; CLARIDGE JF, 1978, P SOC PHOTO OPTICAL, V145, P58; CLARKE GM, 1977, 3RD P INT C AUT INSP, P119; CLARKE LT, 1978, P SOC PHOTO OPTICAL, V145, P28; CLAY BD, 1978, P SOC PHOTO OPTICAL, V145, P45; COLEMAN WJ, 1977, AUG P SPIE ADV LAS E, V122, P33; COLEMAN WJ, 1974, OCT P C AUT INSP PRO, P113; COREN S, 1973, SCIENCE, V179, P503, DOI 10.1126/science.179.4072.503; CUTHBERT JD, 1974, P ICO C OPTICAL METH, P481; DAHLBERG R, 1977, COMPUT DESIGN    OCT; DAVIES DL, 1980, OPT ENG, V19, P425, DOI 10.1117/12.7972531; DAVIES DL, 1979, APR ASNT SPRING C SA; DAVIES RL, 1974, OCT P AUT INSP PROD, P223; DAY RH, 1972, SCIENCE, V175, P1335, DOI 10.1126/science.175.4028.1335; DITTRICH WA, 1974, OCT P C AUT INSP PRO, P303; DIXON RN, 1978, MACHINE AIDED IMAGE, P178; DREYFUS MG, 1975, NOV P EL SYST DES C, P791; DREYFUS MG, 1971, MFG ENG MGT      MAR, P28; DWYER SJ, 1977, 8 AUT RES COUNC REP; EDAMATSU K, 1976, FUJI ELECT J, V49, P10; Ejiri M., 1973, COMPUT VISION GRAPH, V2, P326, DOI 10.1016/0146-664X(73)90011-7; ELLINGER H, 1979, APR P SPIE IM APPL A, V182, P179; FADL MFA, 1977, NOV P SPIE EFF UT OP, V129, P2; FEHRS DL, 1972, OCT ANN M OPT SOC AM; FIGLER BD, 1980, FEB P SPIE OPT METR, V220; FIRESTAR AH, 1977, RCA ENG, V22, P10; FIRSCHEIN O, 1979, AUG IEEE PRIP C, P109; FLECKENSTEIN JT, 1974, OCT AUT INSP CONTR C; FRANZ DW, 1975, FUNCT PHOTOG     SEP, P30; FU KS, 1976, IEEE T COMPUT, V25, P1336, DOI 10.1109/TC.1976.1674602; FU KS, 1980, 5TH P INT C PATT REC; GOTO N, 1978, 4TH P INT JOINT C PA, P970; GOTO Y, 1978, J VAC SCI TECHNOL, V15, P953, DOI 10.1116/1.569683; GRAMINSKI EL, 1977, JUN P IEEE COMP SOC, P137; GROVE RC, 1980, JUL P SPIE REAL TIM, V241; HALE JAG, 1975, 4TH P INT JOINT C AR, P775; HALL EL, 1980, FEB P SPIE OPT METR, V220; HANITY DW, 1974, OCT P C AUT INSP PRO, P287; HARA Y, 1980, 5TH P INT C PATT REC; HARLOW CA, 1973, COMPUTER GRAPHICS IM, V2, P60; HARLOW CA, 1975, COMPUTER         APR, P36; HARLOW CA, 1976, ELECTRON PACKAG  SEP, P111; HARRIS DH, 1969, HUM FACTORS, V11, P139, DOI 10.1177/001872086901100207; HARRY JE, 1974, IND LASERS THEIR APP, P145; HEGLAND DE, 1976, AUTOMATION       JUN, P74; HIMMEL DP, 1978, 4TH P INT JOINT C PA, P952; HORAUD R, 1980, 5TH P INT C PATT REC; Horn B. K., 1975, COMPUT GRAPHICS IMAG, V4, P294; HSIEH YY, 1979, AUG P IEEE COMP SOC, P101; HUANG TS, 1975, MAY P SPIE SOLV QUAL, V60, P20; IGARASHI K, 1979, 9TH P INT S IND ROB, P87; IKEDA H, 1974, P ICO C OPTICAL METH, P487; INOUE T, 1977, 4 ASS C EXP DETR; INOUE T, 1977, 7TH P INT S IND ROB, P515; Ito T., 1976, 3rd International Joint Conference on Pattern Recognition, P26; JACKSON CN, 1972, P SOC PHOTO OPTICAL, V29, P11; JACKSON MT, 1980, FEB P SPIE OPT METR, V220; JANNEY DH, 1979, INT ADV NONDESTRUCTI, V6, P39; Jarvis J. F., 1976, 3rd International Joint Conference on Pattern Recognition, P189; JARVIS JF, 1980, IEEE T PATTERN ANAL, V2, P77, DOI 10.1109/TPAMI.1980.4766975; JARVIS JF, 1980, COMPUTER, V13, P32, DOI 10.1109/MC.1980.1653617; JARVIS JF, 1977, P IEEE COMPUT SOC C; JARVIS JF, 1978, 4TH P INT JOINT C PA, P961; JARVIS JF, 1977, 7TH P EIA ANN S AUT, P138; JENSEN N, 1973, MACHINE DESIGN 2 FEB, P94; JIRAUCH DH, 1966, NOV IEEE AUT SUPP SY; KANAL L, 1974, IEEE T INFORM THEORY, V20, P697, DOI 10.1109/TIT.1974.1055306; KASDAN HL, 1977, NOV P SPIE EFF UT OP, V129, P28; KASHIOKA S, 1976, IEEE T SYST MAN CYB, V6, P562, DOI 10.1109/TSMC.1976.4309551; KASVAND T, 1978, 4TH P INT JOINT C PA, P958; KAWATA S, 1979, 6 SME ASS C; KITTLER J, 1980, PATTERN RECOGN, V12, P237, DOI 10.1016/0031-3203(80)90063-1; KLEIN CA, 1979, AUG P IEEE COMP SOC, P87; KNOLL AL, 1975, TEXTILE I IND    JAN; KNOX JD, 1977, RCA ENG, V22; KOPYDLOWSKI DJ, 1979, APR P SPIE IM APPL A, V182, P118; KOSHIMIZU H, 1978, 9TH P C IM ENG JAP, P55; KOSHIMIZU H, 1979, P SOC PHOTO-OPT INS, V182, P30; KRAKANER L, 1978, 248 PRINC U COMP SCI; KRUGER RP, 1980, OPT ENG, V19, P273, DOI 10.1117/12.7972510; KRUGER RP, 1979, APR P SPIE IM APPL A, V182, P150; KRUGER RP, 1979, APR P SPIE IM APPL A, V182, P158; KRYGER DL, 1980, FEB P SPIE OPT METR, V220; KUNI A, 1977, INFORMATION CONTROL, P63; KUSE E, 1978, J SOC FABRIC SCI TEC, V34, P28; LEE DT, 1980, FEB P SPIE OPT METR, V220; LEE DT, 1978, P SPIE APPLICATION E, V143, P172; LEVY K, 1978, SOLID STATE TECH MAY, P60; LEWIS RB, 1978, P SOC PHOTO OPTICAL, V145, P38; LIN WC, 1975, P IEEE, V63, P1437, DOI 10.1109/PROC.1975.9972; LOCKE DH, 1975, MAY P SPIE SOLV QUAL, P39; LOGAN I, 1974, 2ND P INT JNT C PATT, P286; MAUGHAN WS, 1975, MAY P SPIE SOLV QUAL, V60, P99; MCFARLAND WD, 1973, THESIS U MISSOURI CO; MCFARLANE I, 1978, P SOC PHOTO OPTICAL, V145, P50; MCKEOWN PA, 1975, MAY P SPIE SOLV QUAL, V60, P77; MCLEMORE DR, 1978, P SOC PHOTO OPTICAL, V143, P129; MCMASTER RC, 1974, OCT P AUT INSP PROD, P319; MCVEY ES, 1979, PATTERN RECOGN, V11, P271, DOI 10.1016/0031-3203(79)90037-2; MEAD DC, 1975, MAY P SPIE SOLV QUAL, V60, P57; MENGERS P, 1977, RES DEV          OCT, P42; MENGERS P, 1977, OPT SPECTRA      AUG; MERCHANT ME, 1976, SURVEY CURRENT STATU; MESE M, 1977, 5TH P INT JOINT C AR, P685; MEYN J, 1978, COMPUT DESIGN    DEC; MINAMI M, 1976, OCT P KOD MICR EL SE, P67; MINAMI M, 1978, FEB C LAS EL SYST SA, P66; MOORE R, 1977, NOV P SPIE EFF UT OP, V129, P18; MORRIS RA, 1980, FEB P SPIE OPT METR, V220; MORTON RRA, 1977, SEP P SPIE AUT INSP, V130, P61; MOUNTJOY DR, 1976, THESIS U MISSOURI CO; MUNDY JL, 1977, P INT C PATT REC IM, P144; MUNDY JL, 1980, 5TH P INT C PATT REC; MUNDY JL, 1979, JUN P AFIPS NAT COMP, P227; MYERS W, 1980, COMPUTER, V13, P21, DOI 10.1109/MC.1980.1653615; NAKAGAWA Y, 1977, INFORMATION CONTROL, P63; NAKAMURA K, 1978, 4TH P INT JOINT C PA, P955; NAKASHIMA M, 1979, APR P SPIE IM APPL A, V182, P38; Nevatia R, 1978, COMPUTER VISION SYST, P81; NICHOLSON T, 1979, NEWSWEEK        0423; NITZAN D, 1976, IEEE T COMPUT, V25, P1259, DOI 10.1109/TC.1976.1674593; NORTONWAYNE L, 1974, 2ND P INT JOINT C PA, P476; NOVOTNY DB, 1978, SOLID STATE TECH MAY, P51; NOVOTNY DB, 1978, SOLID STATE TECH JUN, P59; NYYSSONEN D, 1977, APPL OPTICS, V16, P2223, DOI 10.1364/AO.16.002223; NYYSSONEN D, 1977, DEV SEMICONDUCTOR MI, V100, P127; OCALLAGHAN FG, 1975, WIN SPSE S MICR PHOT; OLSEN OA, 1976, Patent No. 3976383; PAGE LC, 1977, NOV P SPIE EFF UT OP, V129, P94; PARKS JR, 1977, J I ELECTRON RAD ENG, V47, P355, DOI 10.1049/ree.1977.0054; PARKS JR, 1977, SEP P SPIE AUT INSP, V130, P2; PARKS JR, 1978, PATTERN RECOGNITION; PAU LF, 1980, 5TH P INT C PATT REC; PAULSON R, 1975, MAY P SPIE SOLV QUAL, V60, P85; PAVLIDIS T, 1977, P IEEE COMPUTER SOC, P98; PAVLIDIS T, 1976, 222 PRINC U TECH REP; PEARSON JJ, 1977, 7TH P ANN EIA AUT IM, P170; PEARSON JJ, 1975, AUG P SPIE IM UND SY, V155, P214; PETERSON C, 1974, 2ND P INT JOINT C PA; PFOUTZ RW, 1975, MAY P SPIE SOLV QUAL, V60, P110; PORTER GB, 1980, COMPUTER, V13, P40, DOI 10.1109/MC.1980.1653619; PORTER GB, 1979, AUG P IEEE COMP SOC, P83; POULSON PD, 1975, MAY P SPIE SOLV QUAL, V60, P91; PRYOR TR, 1976, JAN SW TOOL MAN EXP; PUCH A, 1978, P SPIE IND APPLICATI, V145, P66; PUGH A, 1977, J I ELECTRON RAD ENG, V47, P377, DOI 10.1049/ree.1977.0056; PURLL DJ, 1978, P SPIE IND APPLICATI, V145, P18; PURLL DJ, 1978, P SOC PHOTO-OPT INST, V145, P9; REED WE, 1979, NONDESTRUCTIVE TESTI; REMBOLD U, 1977, COMPUTERS MANUFACTUR; RESTRICK RC, 1977, P SPIE SOLID STATE I, V116, P76; ROSEN CA, 1977, COMPUTER, V10, P12, DOI 10.1109/C-M.1977.217596; ROSENFELD A, 1978, COMPUT VISION GRAPH, V7, P211, DOI 10.1016/0146-664X(78)90113-2; ROSENFELD A, 1979, COMPUT VISION GRAPH, V9, P354, DOI 10.1016/0146-664X(79)90100-X; ROSENFELD A, 1980, COMPUT VISION GRAPH, V13, P46, DOI 10.1016/0146-664X(80)90116-1; Rosenfeld A., 1973, Computing Surveys, V5, P81, DOI 10.1145/356616.356617; ROSENFELD A, 1977, COMPUT VISION GRAPH, V6, P157, DOI 10.1016/S0146-664X(77)80010-5; ROSENFELD A, 1976, COMPUT GRAPHICS IMAG, V5, P215; ROSENFELD A, 1975, COMPUTER GRAPHICS IM, V4, P133; ROSENFELD A, 1974, COMPUTER GRAPHICS IM, V3, P178; ROSENFELD A, 1972, COMPUTER GRAPHICS IM, V1, P394; SANDLAND P, 1977, DEV SEMICONDUCTOR MI, V100, P26; SAWAJI M, 1979, P SOC PHOTO OPTICAL, V182, P6; SCHOONARD JW, 1973, HUMAN FACTORS    FEB; SCHROEDER DD, 1980, IEEE T COMPON HYBR, V3, P367, DOI 10.1109/TCHMT.1980.1135620; SEARLE RH, 1977, 4 ASS C EXP DEARB; SEARLE RH, 1978, 2ND MINN EL MAN ASS; SELLNER HR, 1978, AUG P SPIE IM UND SY, V155, P241; SHIBUYA A, 1976, J TEXT MACH SOC JAPA, V29, P22; SITTIG EK, 1973, OCT P KOD MICR SEM A; SKINNER JG, 1977, P SOC PHOTO OPTICAL, V100, P20; SKRAMSTAD T, 1980, 1ST P SCAND C IM AN, P302; SKURLA JP, 1975, OCT ISA IND OR C EXH; SMITH PH, 1979, AUG P IEEE COMP SOC, P653; SNOW KA, 1978, P SPIE, V135, P96; SNYDER CRR, 1972, J EXP PSYCHOL, V92, P428, DOI 10.1037/h0032268; SOUTHWARD GR, 1973, EE SYST ENG TODA JUL; SOUTHWORTH GR, 1975, NOV EL OPT SYST DES; SPALDING IJ, 1971, PHYSIS B, P401; SPARKS JE, 1972, MACHINE DESIGN   FEB; SPECK RP, 1980, MAR P SPIE DEV SEM M, V221; STERLING WM, 1979, AUG P IEEE C PATT RE, P93; STEWART R, 1980, FEB P SPIE OPT METR, V220; SUGIYAMA S, 1980, JUL P SPIE ADV LAS E, V247; SWING DM, 1975, MAY P SPIE SOLV QUAL, V60, P118; TAKAGI A, 1978, 13TH P INT C HIGH SP, P594; TAKAMATSE S, 1976, J TEXT MACH SOC JAPA, V29, P9; TANABE I, 1975, KODAK PUBLICATION G, V45, P91; TAYLOR RD, 1976, BDX6131187 BEND CORP; THISSEN FLA, 1973, 22873 PHIL RES TECH; THISSEN FLAM, 1977, PHILIPS TECH REV, V37, P77; THOMPSON WB, 1980, COMPUTER         MAY; TSUJI S, 1979, APR P SPIE IM APPL A, V182, P2; TSUJI S, 1978, 4TH P INT JOINT C PA, P1144; TUCKER BJ, 1977, NOV P SPIE EFF UT OP, V129, P90; TUCKER J, 1976, QUALITY          AUG, P10; ULLMANN JR, 1978, PATTERN RECOGNITION, P17; UNO T, 1978, 4TH P INT JOINT C PA, P1147; VANDAELE J, 1980, OPT ENG, V19, P240, DOI 10.1117/12.7972500; VANDAELE J, 1979, APR P SPIE IM APPL A, V182, P58; VANDERBURG GJ, 1978, 8TH P ANN AUT IM PAT; VERHAGEN CJD, 1977, SEP P SPIE AUT INSP, V130, P8; WANG SC, 1974, QUALITY          SEP; WATKINS LS, 1973, APPL OPTICS, V12, P1880, DOI 10.1364/AO.12.001880; WATKINS LS, 1973, WEST ELECT ENG, V27, P39; WEAVER JA, 1978, 4TH P INT JOINT C PA, P1148; WECKLER GP, 1975, MAY P SPIE SOLV QUAL, V60, P14; WERTHEIMER AL, 1977, NOV P SPIE EFF UT OP, V129, P49; WEST P, 1980, APR P SPIE MIN MICR, V230; WEST RN, 1978, OPT ACTA, V25, P1207, DOI 10.1080/713819733; WEST RN, 1977, METROL INSPECTIO JUL; WEY RA, 1975, MAY P SPIE SOLV QUAL, V60, P68; WILDER J, 1979, APR P SPIE IM APPL A, V182, P94; WILDER J, 1978, 8TH P EIA ANN AUT IM, P91; WILLIAMS RV, 1975, MAY P SPIE SOLV QUAL, P52; WIRICK MP, 1980, FEB P SPIE OPT METR, V220; WOLF WE, 1980, FEB P SPIE OPT METR, V220; WOOD N, 1975, QUALITY MANAGEME FEB; WRIGHT LW, 1967, 6TH P S NOND EV AER; YACHIDA M, 1980, COMPUTER, V13, P50, DOI 10.1109/MC.1980.1653621; 1979, LASER WEEKLY, V13, P5; PRODUCT SYSTEM PRODU; 1974, BUSINESS WEEK   0406; 1977, QUALITY          JUN, P12; 1978, IMSCD625398 LOCKH PA; 1977, COMPUT DESIGN    DEC, P42; 1975, OPT SPECTRA      JUL; 1979, LASER WEEKLY, V13, P3; 1978, OPT SPECTRA      AUG, P28; 1973, AUTOMATION       APR, P24; 1977, NIKKEI ELECTRON  AUG, P80; 1974, BUSINESS WEEK   1116; 1974, BUSINESS WEEK   0406; 1976, RETICON CAMERA SYSTE	288	214	224	2	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	6					557	573		10.1109/TPAMI.1982.4767309	http://dx.doi.org/10.1109/TPAMI.1982.4767309			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	PS237	22499630				2022-12-18	WOS:A1982PS23700001
J	Scheirer, WJ; Jain, LP; Boult, TE				Scheirer, Walter J.; Jain, Lalit P.; Boult, Terrance E.			Probability Models for Open Set Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Machine learning; support vector machines; open set recognition; statistical extreme value theory	SUPPORT	Real-world tasks in computer vision often touch upon open set recognition: multi-class recognition with incomplete knowledge of the world and many unknown inputs. Recent work on this problem has proposed a model incorporating an open space risk term to account for the space beyond the reasonable support of known classes. This paper extends the general idea of open space risk limiting classification to accommodate non-linear classifiers in a multi-class setting. We introduce a new open set recognition model called compact abating probability (CAP), where the probability of class membership decreases in value (abates) as points move from known data toward open space. We show that CAP models improve open set recognition for multiple algorithms. Leveraging the CAP formulation, we go on to describe the novel Weibull-calibrated SVM (W-SVM) algorithm, which combines the useful properties of statistical extreme value theory for score calibration with one-class and binary support vector machines. Our experiments show that the W-SVM is significantly better for open set object detection and OCR problems when compared to the state-of-the-art for the same tasks.	[Scheirer, Walter J.] Harvard Univ, Dept Mol & Cellular Biol, Sch Engn & Appl Sci, Cambridge, MA 02138 USA; [Scheirer, Walter J.] Harvard Univ, Ctr Brain Sci, Cambridge, MA 02138 USA; [Jain, Lalit P.; Boult, Terrance E.] Univ Colorado, Dept Comp Sci, Colorado Springs, CO 80918 USA	Harvard University; Harvard University; University of Colorado System; University of Colorado at Colorado Springs	Scheirer, WJ (corresponding author), Harvard Univ, Dept Mol & Cellular Biol, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.	wscheirer@fas.harvard.edu; ljain2@uccs.edu; tboult@vast.uccs.edu	Boult, Terrance E./AAT-2134-2021	Boult, Terrance E./0000-0001-5007-2529	ONR MURI [N00014-08-1-0638]; US National Science Foundation (NSF) [IIS-1320956]; Direct For Computer & Info Scie & Enginr [1320956] Funding Source: National Science Foundation	ONR MURI(MURIOffice of Naval Research); US National Science Foundation (NSF)(National Science Foundation (NSF)); Direct For Computer & Info Scie & Enginr(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This work was supported in part by ONR MURI N00014-08-1-0638 and US National Science Foundation (NSF) IIS-1320956.	Bartlett PL, 2008, J MACH LEARN RES, V9, P1823; Bouchard Guillaume, 2004, 16 IASC INT S COMP S, P721; Bravo Cristian, 2008, 2008 8th International Conference on Hybrid Intelligent Systems (HIS), P649, DOI 10.1109/HIS.2008.112; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Duan KB, 2005, LECT NOTES COMPUT SC, V3541, P278; Fragoso V, 2013, PROC CVPR IEEE, P2770, DOI 10.1109/CVPR.2013.357; FREY PW, 1991, MACH LEARN, V6, P161, DOI 10.1023/A:1022606404104; Griffin Gregory, 2007, CALTECH 256 OBJECT C; Henriques JF, 2013, IEEE I CONF COMP VIS, P2760, DOI 10.1109/ICCV.2013.343; Hofmann T, 2008, ANN STAT, V36, P1171, DOI 10.1214/009053607000000677; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Huang T.-K., 2005, LIBSVM ERRORCODE; Huang TK, 2006, J MACH LEARN RES, V7, P85; Kotz S., 2001, EXTREME VALUE DISTRI; Lasserre J.A., 2006, IEEE COMP SOC C COMP, P87, DOI DOI 10.1109/CVPR.2006.227; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Platt JC, 2000, ADV NEUR IN, P61; Rumsfeld D., 2002, DOD NEWS BRIEFING AD; Scheirer W, 2010, LECT NOTES COMPUT SC, V6313, P481; Scheirer WJ, 2013, IEEE T PATTERN ANAL, V35, P1757, DOI 10.1109/TPAMI.2012.256; Scheirer WJ, 2012, PROC CVPR IEEE, P2933, DOI 10.1109/CVPR.2012.6248021; Scheirer WJ, 2011, IEEE T PATTERN ANAL, V33, P1689, DOI 10.1109/TPAMI.2011.54; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Vapnik V. N., 1998, NATURE STAT LEARNING; Weiss Y, 2012, LECT NOTES COMPUT SC, V7576, P340, DOI 10.1007/978-3-642-33715-4_25; Zhang R., 2006, P BRIT MACH VIS C, P1209	31	213	218	3	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2014	36	11					2317	2324		10.1109/TPAMI.2014.2321392	http://dx.doi.org/10.1109/TPAMI.2014.2321392			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR6OI	26353070	Green Submitted			2022-12-18	WOS:000343702400016
J	Liu, L; Fieguth, PW				Liu, Li; Fieguth, Paul W.			Texture Classification from Random Features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Texture classification; random projections; sparse representation; compressed sensing; textons; image patches; bag of words	FACE RECOGNITION; SIGNAL RECOVERY; PROOF	Inspired by theories of sparse representation and compressed sensing, this paper presents a simple, novel, yet very powerful approach for texture classification based on random projection, suitable for large texture database applications. At the feature extraction stage, a small set of random features is extracted from local image patches. The random features are embedded into a bag-of-words model to perform texture classification; thus, learning and classification are carried out in a compressed domain. The proposed unconventional random feature extraction is simple, yet by leveraging the sparse nature of texture images, our approach outperforms traditional feature extraction methods which involve careful design and complex steps. We have conducted extensive experiments on each of the CUReT, the Brodatz, and the MSRC databases, comparing the proposed approach to four state-of-the-art texture classification methods: Patch, Patch-MRF, MR8, and LBP. We show that our approach leads to significant improvements in classification accuracy and reductions in feature dimensionality.	[Liu, Li] Natl Univ Def Technol, Sch Elect Sci & Engn, Remote Sensing Informat Proc Lab, Changsha 410073, Hunan, Peoples R China; [Fieguth, Paul W.] Univ Waterloo, Dept Syst Design Engn, Vis & Image Proc VIP Lab, Waterloo, ON N2L 3G1, Canada	National University of Defense Technology - China; University of Waterloo	Liu, L (corresponding author), Natl Univ Def Technol, Sch Elect Sci & Engn, Remote Sensing Informat Proc Lab, Room 436,47 Yanwachi, Changsha 410073, Hunan, Peoples R China.	dreamliu2010@gmail.com; pfieguth@uwaterloo.ca			NSERC Canada; Department of Systems Design Engineering; China Scholarship Council	NSERC Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)); Department of Systems Design Engineering; China Scholarship Council(China Scholarship Council)	The authors would like to thank NSERC Canada, the Department of Systems Design Engineering, and the China Scholarship Council.	Achlioptas D., 2001, P TWENTIETHACMSIGMOD, P274, DOI DOI 10.1145/375551.375608; Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Baraniuk R, 2008, CONSTR APPROX, V28, P253, DOI 10.1007/s00365-007-9003-x; Biau G, 2008, IEEE T INFORM THEORY, V54, P781, DOI 10.1109/TIT.2007.913516; Bingham E., 2001, P 7 ACM SIGKDD INT C, P245, DOI DOI 10.1145/502512.502546; BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; Cula OG, 2004, INT J COMPUT VISION, V59, P33, DOI 10.1023/B:VISI.0000020670.05764.55; Dasgupta S, 2003, RANDOM STRUCT ALGOR, V22, P60, DOI 10.1002/rsa.10073; Dasgupta S., 2000, P 16 C UNC ART INT, P143; Dasgupta S, 2009, IEEE T INFORM THEORY, V55, P3229, DOI 10.1109/TIT.2009.2021326; Davenport MA, 2010, IEEE J-STSP, V4, P445, DOI 10.1109/JSTSP.2009.2039178; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Duarte M.F., 2007, P INT C IM PROC; Duarte-Carvajalino JM, 2009, IEEE T IMAGE PROCESS, V18, P1395, DOI 10.1109/TIP.2009.2022459; Fern XZ, 2003, P 20 INT C MACH LEAR, P186; Goel N, 2005, PROC SPIE, V5779, P426, DOI 10.1117/12.605553; Graf S., 2000, FDN QUANTIZATION PRO; Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Haupt J, 2006, CONF REC ASILOMAR C, P1430; Hayman E, 2004, LECT NOTES COMPUT SC, V2034, P253; Heeger DJ, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC648; Johnson W. B., 1984, CONT MATH, V26, P189, DOI DOI 10.1090/CONM/026/737400; Julesz B., 1962, IRE T INFORM THEOR, V8, P84, DOI 10.1109/TIT.1962.1057698; Kaplan LM, 1999, IEEE T IMAGE PROCESS, V8, P1572, DOI 10.1109/83.799885; Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151; Lazebnik S, 2009, IEEE T PATTERN ANAL, V31, P1294, DOI 10.1109/TPAMI.2008.138; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Levina E., 2002, THESIS U CALIFORNIA; Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682; Linder T., 2001, PRINCIPLES NONPARAME; Maenpaa T., 2003, P SCAND C IM AN; Mairal J., 2008, P IEEE C COMP VIS PA; Mallat S., 1999, WAVELET TOUR SIGNAL; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5; Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Peyre G, 2009, J MATH IMAGING VIS, V34, P17, DOI 10.1007/s10851-008-0120-3; Pietikainen M, 2004, PATTERN RECOGN, V37, P313, DOI 10.1016/S0031-3203(03)00231-0; Qin XJ, 2005, IEEE I CONF COMP VIS, P128; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; Rauhut H, 2008, IEEE T INFORM THEORY, V54, P2210, DOI 10.1109/TIT.2008.920190; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Skretting K, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/52561; Tropp J.A., 2004, THESIS U TEXAS AUSTI; Tuceryan M., 1993, HDB PATTERN RECOGNIT, P235, DOI DOI 10.1142/9789814343138_0010; Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4; Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182; WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhang JG, 2002, PATTERN RECOGN, V35, P735, DOI 10.1016/S0031-3203(01)00074-7; Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420	61	213	236	0	72	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2012	34	3					574	586		10.1109/TPAMI.2011.145	http://dx.doi.org/10.1109/TPAMI.2011.145			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	880CH	21768653				2022-12-18	WOS:000299381600012
J	Liu, ZY; Sarkar, S				Liu, ZY; Sarkar, S			Improved gait recognition by gait dynamics normalization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						gait recognition; biometrics; LDA; gait shape; population HMM	PERCEPTION	Potential sources for gait biometrics can be seen to derive from two aspects: gait shape and gait dynamics. We show that improved gait recognition can be achieved after normalization of dynamics and focusing on the shape information. We normalize for gait dynamics using a generic walking model, as captured by a population Hidden Markov Model ( pHMM) defined for a set of individuals. The states of this pHMM represent gait stances over one gait cycle and the observations are the silhouettes of the corresponding gait stances. For each sequence, we first use Viterbi decoding of the gait dynamics to arrive at one dynamics- normalized, averaged, gait cycle of fixed length. The distance between two sequences is the distance between the two corresponding dynamics- normalized gait cycles, which we quantify by the sum of the distances between the corresponding gait stances. Distances between two silhouettes from the same generic gait stance are computed in the linear discriminant analysis space so as to maximize the discrimination between persons, while minimizing the variations of the same subject under different conditions. The distance computation is constructed so that it is invariant to dilations and erosions of the silhouettes. This helps us handle variations in silhouette shape that can occur with changing imaging conditions. We present results on three different, publicly available, data sets. First, we consider the HumanID Gait Challenge data set, which is the largest gait benchmarking data set that is available ( 122 subjects), exercising five different factors, i. e., viewpoint, shoe, surface, carrying condition, and time. We significantly improve the performance across the hard experiments involving surface change and briefcase carrying conditions. Second, we also show improved performance on the UMD gait data set that exercises time variations for 55 subjects. Third, on the CMU Mobo data set, we show results for matching across different walking speeds. It is worth noting that there was no separate training for the UMD and CMU data sets.	Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA	State University System of Florida; University of South Florida	Liu, ZY (corresponding author), Univ S Florida, Dept Comp Sci & Engn, 4202 E Fowler Ave,ENB 118, Tampa, FL 33620 USA.	zliu4@cse.usf.edu; sarkar@cse.usf.edu	Sarkar, Sudeep/ABD-7629-2021; Sarkar, Sudeep/A-8213-2009	Sarkar, Sudeep/0000-0001-7332-4207; Sarkar, Sudeep/0000-0001-7332-4207				Akaike H., 1973, 2 INT S INFORM THEOR, P267, DOI DOI 10.1007/978-1-4612-1694-0_15; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Boyd JE, 2004, COMPUT VIS IMAGE UND, V96, P35, DOI 10.1016/j.cviu.2004.04.004; Collins RT, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P366, DOI 10.1109/AFGR.2002.1004181; CUTTING JE, 1977, B PSYCHONOMIC SOC, V9, P353, DOI 10.3758/BF03337021; Gross R, 2001, CMURITR0118; Han J, 2004, PROC CVPR IEEE, P842; JOHNSON A, 2001, P 3 INT C AUD VID BA, P301; Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865; Kale A, 2003, LECT NOTES COMPUT SC, V2688, P706; Lee B, 2003, J MICROMECH MICROENG, V13, P663, DOI 10.1088/0960-1317/13/5/318; Lee CS, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P147; Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148; LEE L, 2003, THESIS MIT; Liu JX, 2004, ADSORPTION, V10, P205, DOI 10.1023/B:ADSO.0000046356.48581.1b; Liu YX, 2002, LECT NOTES COMPUT SC, V2351, P657; Liu ZY, 2005, IEEE T SYST MAN CY B, V35, P170, DOI 10.1109/TSMCB.2004.842251; Liu ZY, 2004, INT C PATT RECOG, P211, DOI 10.1109/ICPR.2004.1333741; Mowbray SD, 2003, LECT NOTES COMPUT SC, V2688, P566; Nixon MS, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P139, DOI 10.1109/AFGR.2004.1301521; NIYOGI S, 1994, P IEEE WORKSH NONR M, P24; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Rabiner L., 1993, FUNDAMENTALS SPEECH; Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39; Sundaresan A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P93; Tanawongsuwan R, 2004, PROC CVPR IEEE, P783; Tanawongsuwan R, 2003, LECT NOTES COMPUT SC, V2688, P715; Tolliver D, 2003, LECT NOTES COMPUT SC, V2688, P734; Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246; Wagg DK, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P11, DOI 10.1109/AFGR.2004.1301502; Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144; Zhao GY, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P23	32	213	220	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2006	28	6					863	876		10.1109/TPAMI.2006.122	http://dx.doi.org/10.1109/TPAMI.2006.122			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	031WB	16724582	Green Submitted			2022-12-18	WOS:000236734400002
J	Tappen, MF; Freeman, WT; Adelson, EH				Tappen, MF; Freeman, WT; Adelson, EH			Recovering intrinsic images from a single image	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; machine learning; reflectance; shading; boosting; belief propagation		Interpreting real-world images requires the ability distinguish the different characteristics of the scene that lead to its final appearance. Two of the most important of these characteristics are the shading and reflectance of each point in the scene. We present an algorithm that uses multiple cues to recover shading and reflectance intrinsic images from a single image. Using both color information and a classifier trained to recognize gray-scale patterns, given the lighting direction, each image derivative is classified as being caused by shading or a change in the surface's reflectance. The classifiers gather local evidence about the surface's form and color, which is then propagated using the Generalized Belief Propagation algorithm. The propagation step disambiguates areas of the image where the correct classification is not clear from local evidence. We use real- world images to demonstrate results and show how each component of the system affects the results.	MIT, Comp Sci & Artificial Intelligence Lab, Stata Ctr, Cambridge, MA 02139 USA; MIT, Dept Brain Cognit Sci, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT)	Tappen, MF (corresponding author), MIT, Comp Sci & Artificial Intelligence Lab, Stata Ctr, Blsg 32,32 Vassar St, Cambridge, MA 02139 USA.	mtappen@csail.mit.edu; billf@mit.edu; adelson@csail.mit.edu			NATIONAL EYE INSTITUTE [R01EY011005] Funding Source: NIH RePORTER; NEI NIH HHS [EY11005-04] Funding Source: Medline	NATIONAL EYE INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI)); NEI NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI))		Barrow H., 1978, COMPUT VIS SYST, V2, P2; BELL M, 2001, P INT C COMP VIS; BESAG J, 1975, J ROY STAT SOC D-STA, V24, P179, DOI 10.2307/2987782; Finlayson G., 2002, P 7 EUR C COMP VIS 4, P823; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; FREEMAN WT, 1998, ADV NEURAL INFORMATI; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; FUNT BV, 1992, LECT NOTES COMPUT SC, V588, P124; GIBSON JJ, 1966, SENSES CONSIDERED PE, pCH10; Heeger D.J., 1995, P 22 ANN C COMP GRAP, P229, DOI DOI 10.1145/218380.218446; HORN BKP, 1986, ROBOT VISION, pCH9; Lafferty John, 2001, P INT C MACH LEARN J; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; Leung T., 1999, P IEEE INT C COMP VI; Matsushita Y, 2003, PROC CVPR IEEE, P3; OPPENHEI.AV, 1968, IEEE T ACOUST SPEECH, VAU16, P437, DOI 10.1109/TAU.1968.1161990; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P153, DOI 10.1007/BF00127815; RUBIN JM, 1982, BIOL CYBERN, V45, P215, DOI 10.1007/BF00336194; Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444; Sinha P., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P156, DOI 10.1109/ICCV.1993.378224; Tieu K, 2000, PROC CVPR IEEE, P228, DOI 10.1109/CVPR.2000.855824; Weiss Y., 2001, P INT C COMP VIS; Yedidia JS, 2001, ADV NEUR IN, V13, P689	24	213	249	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2005	27	9					1459	1472		10.1109/TPAMI.2005.185	http://dx.doi.org/10.1109/TPAMI.2005.185			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	944XB	16173188	Green Published			2022-12-18	WOS:000230463300008
J	Can, A; Stewart, CV; Roysam, B; Tanenbaum, HL				Can, A; Stewart, CV; Roysam, B; Tanenbaum, HL			A feature-based, robust, hierarchical algorithm for registering pairs of images of the curved human retina	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						robust estimation; registration; transformation estimation; image mosaic; retinal imaging; feature extraction; feature refinement; multiscale methods; ophthalmic image processing; biomedical image processing	COMPUTER-SIMULATION; FUNDUS IMAGES; REGISTRATION; TRANSFORMATIONS; DEFORMATIONS; DESIGN	This paper describes a robust hierarchical algorithm for fully-automatic registration of a pair of images of the curved human retina photographed by a fundus microscope. Accurate registration is essential for mosaic synthesis, change detection, and design of computer-aided instrumentation. Central to the new algorithm is a 12-parameter interimage transformation derived by modeling the retina as a rigid quadratic surface with unknown parameters, imaged by an uncalibrated weak perspective camera. The parameters of this model are estimated by matching vascular landmarks extracted by an algorithm that recursively traces the blood vessel structure. The parameter estimation technique, which could be generalized to other applications, is a hierarchy of models and methods: an initial match set is pruned based on a zeroth order transformation estimated as the peak of a similarity-weighted histogram; a first order, affine transformation is estimated using the reduced match set and least-median of squares; and the final, second order, 12-parameter transformation is estimated using an M-estimator initialized from the first order estimate. This hierarchy makes the algorithm robust to unmatchable image features and mismatches between features caused by large interframe motions. Before final convergence of the M-estimator, feature positions are refined and the correspondence set is enhanced using normalized sum-of-squared differences matching of regions deformed by the emerging transformation. Experiments involving 3,000 image pairs (1, 024 x 1, 024 pixels) from 16 different healthy eyes were performed. Starting with as low as 20 percent overlap between images, the algorithm improves its success rate exponentially and has a negligible failure rate above 67 percent overlap. The experiments also quantify the reduction in errors as the model complexities increase. Final registration errors less than a pixel are routinely achieved. The speed, accuracy, and ability to handle small overlaps compare favorably with retinal image registration techniques published in the literature.	Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA; Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA; Ctr Sight, Albany, NY 12204 USA	Rensselaer Polytechnic Institute; Rensselaer Polytechnic Institute	Can, A (corresponding author), Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA.	alican@alum.rpi.edu; stewart@cs.rpi.edu; roysab@rpi.edu; how1@albany.net						BALDUF E, 1998, THESIS RENSSELAER PO; BEATON AE, 1974, TECHNOMETRICS, V16, P147, DOI 10.2307/1267936; Becker DE, 1996, CYTOMETRY, V25, P235, DOI 10.1002/(SICI)1097-0320(19961101)25:3<235::AID-CYTO4>3.0.CO;2-E; BECKER DE, 1998, IEEE T BIOMEDICAL EN, V45; BECKER DE, 1999, IMIA YB MED INFORMAT; BERGEN JR, 1992, P EUR C COMP VIS, P237; Berger JW, 1997, LECT NOTES COMPUT SC, V1205, P399, DOI 10.1007/BFb0029261; Berger JW, 1999, OPHTHALMIC SURG LAS, V30, P72; BERGER JW, 1999, OPHTHALMOLOGY, V106; Besl PJ., 1992, ROBOT TENTAT, V14, P239, DOI DOI 10.1109/34.121791; BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; Can A, 2002, IEEE T PATTERN ANAL, V24, P412, DOI 10.1109/34.990145; Can A, 1999, IEEE Trans Inf Technol Biomed, V3, P125, DOI 10.1109/4233.767088; CAN A, 1999, P IEEE C COMP VIS PA, P286; CAN A, 2000, THESIS RENSSELAER PO; Cham TJ, 1998, PROC CVPR IEEE, P442, DOI 10.1109/CVPR.1998.698643; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733; CIDECIYAN AV, 1995, IEEE ENG MED BIOL, V14, P52, DOI 10.1109/51.340749; Duncan JS, 2000, IEEE T PATTERN ANAL, V22, P85, DOI 10.1109/34.824822; FEDERMAN JL, 1988, RETINA VITREOUS; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gleicher M, 1997, PROC CVPR IEEE, P331, DOI 10.1109/CVPR.1997.609345; GOLDBAUM M, 1990, OPHTHALMOL CLIN N AM, V3, P447; GOLDBAUM MH, 1993, SPIE OPHTHALMIC TECH, V1877, P94; Hampel FR., 2011, WILEY SERIES PROBABI; HOLLAND PW, 1977, COMMUN STAT A-THEOR, V6, P813, DOI 10.1080/03610927708827533; IRANI M, 1994, INT J COMPUT VISION, V12, P5, DOI 10.1007/BF01420982; Jensen PK, 1999, ACTA OPHTHALMOL SCAN, V77, P526, DOI 10.1034/j.1600-0420.1999.770508.x; Kashiwase M, 2000, OPHTHALMOLOGY, V107, P790, DOI 10.1016/S0161-6420(99)00143-8; Lester H, 1999, PATTERN RECOGN, V32, P129, DOI 10.1016/S0031-3203(98)00095-8; Mahurkar AA, 1996, INVEST OPHTH VIS SCI, V37, P1675; MARKOW MS, 1993, IEEE T BIOMEDICAL EN; Matsopoulos G K, 1999, IEEE Trans Inf Technol Biomed, V3, P47, DOI 10.1109/4233.748975; Miller JV, 1996, PROC CVPR IEEE, P300, DOI 10.1109/CVPR.1996.517089; Neumann F, 1997, ADV ENG SOFTW, V28, P353, DOI 10.1016/S0965-9978(97)00021-5; ONUKI T, 1993, ANN BIOMED ENG, V21, P107, DOI 10.1007/BF02367606; Rayner K., 1992, EYE MOVEMENTS VISUAL; Ritter N, 1999, IEEE T MED IMAGING, V18, P404, DOI 10.1109/42.774168; Rousseeuw P. J., 1987, ROBUST REGRESSION OU; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; SAWHNEY H, 1998, P 5 EUR C COMP VIS, V2, P103; Sawhney HS, 1999, IEEE T PATTERN ANAL, V21, P235, DOI 10.1109/34.754589; Schmid C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P230, DOI 10.1109/ICCV.1998.710723; Shashua A, 1997, INT J COMPUT VISION, V23, P185, DOI 10.1023/A:1007962930529; Shen H, 2001, IEEE T INF TECHNOL B, V5, P77, DOI 10.1109/4233.908405; Shin DS, 1999, OPHTHALMOLOGY, V106, P1119, DOI 10.1016/S0161-6420(99)90257-9; Shum HY, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P953, DOI 10.1109/ICCV.1998.710831; Stewart CV, 1999, SIAM REV, V41, P513, DOI 10.1137/S0036144598345802; Szeliski R, 1996, INT J COMPUT VISION, V18, P171, DOI 10.1007/BF00055001; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; WEXLER Y, 1999, P IEEE C COMP VIS PA, V1, P333; Wright C H, 1997, J Biomed Opt, V2, P195, DOI 10.1117/12.268964; Zana F, 1999, IEEE T MED IMAGING, V18, P419, DOI 10.1109/42.774169; Zhang X, 1995, ELECTRON COMM JPN 3, V78, P1, DOI 10.1002/ecjc.4430780801	57	213	249	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2002	24	3					347	364		10.1109/34.990136	http://dx.doi.org/10.1109/34.990136			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	524WM					2022-12-18	WOS:000174035900005
J	Lee, L; Romano, R; Stein, G				Lee, L; Romano, R; Stein, G			Monitoring activities from multiple video streams: Establishing a common coordinate frame	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						video surveillance; multiple views; external camera calibration; planar motion; tracking	MOTION	monitoring of large sites requires coordination between multiple cameras. which in turn requires methods for relating events between distributed cameras. This paper tackles the problem of automatic external calibration of multiple cameras in an extended scene, that is, full recovery of their 3D relative positions and orientations. Because the cameras are placed far apart, brightness or proximity constraints cannot be used to match static features, so we instead apply planar geometric constraints to moving objects tracked throughout the scene. By robustly matching and fitting tracked objects to a planar model, we align the scene's ground plane across multiple views and decompose the planar alignment matrix to recover the 3D relative camera and ground plane positions. We demonstrate this technique in both a controlled lab setting where we test the effects of errors in the intrinsic camera parameters. and in an uncontrolled, outdoor setting. In the latter, we do not assume synchronized cameras and we show that enforcing geometric constraints enables us to align the tracking data in time. In spite of noise in the intrinsic camera parameters and in the image data. the system successfully transforms multiple views of the scene's ground plane to an overhead view and recovers the relative 3D camera and ground plane positions.	MIT, Artificial Intelligence Lab, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT)	Lee, L (corresponding author), MIT, Artificial Intelligence Lab, 545 Technol Sq,NE43-741, Cambridge, MA 02139 USA.	llee@ai.mit.edu; romano@ai.mit.edu; gideon@ai.mit.edu						AZARBAYEJANI A, 1996, 363 MIT MED LAB; Bradshaw KJ, 1997, IEEE T PATTERN ANAL, V19, P219, DOI 10.1109/34.584099; Cham TJ, 1998, PROC CVPR IEEE, P442, DOI 10.1109/CVPR.1998.698643; FAUGERAS OD, 1993, 3 DIMENSIONAL COMPUT, P206; Grimson WEL, 1998, PROC CVPR IEEE, P22, DOI 10.1109/CVPR.1998.698583; INTILLE SS, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P672, DOI 10.1109/ICCV.1995.466874; IRANI M, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P454, DOI 10.1109/CVPR.1994.323866; Murray DW, 1996, COMPUT VIS IMAGE UND, V63, P169, DOI 10.1006/cviu.1996.0012; Murray R. M., 1994, MATH INTRO ROBOTIC M; Stauffer C., 1999, P IEEE COMP SOC C CO, V2; STAUFFER C, 1999, IEEE T PATTERN ANAL; SULL S, 1991, P IEEE C COMP VIS PA; TSAI RY, 1982, IEEE T ACOUST SPEECH, V30, P525, DOI 10.1109/TASSP.1982.1163931; TSAI RY, 1982, 9479 IBM RC IBM WATS; WENG JY, 1991, IEEE T SIGNAL PROCES, V39, P2691, DOI 10.1109/78.107418; ZOGHLAMI I, 1997, P IEEE C COMP VIS PA, P421	16	213	228	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2000	22	8					758	767		10.1109/34.868678	http://dx.doi.org/10.1109/34.868678			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	354GN		Green Published, Green Submitted			2022-12-18	WOS:000089321500003
J	Wang, KY; He, R; Wang, L; Wang, W; Tan, TN				Wang, Kaiye; He, Ran; Wang, Liang; Wang, Wei; Tan, Tieniu			Joint Feature Selection and Subspace Learning for Cross-Modal Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Subspace learning; coupled feature selection; half-quadratic minimization; cross-modal retrieval	RECOGNITION; SIMILARITY	Cross-modal retrieval has recently drawn much attention due to the widespread existence of multimodal data. It takes one type of data as the query to retrieve relevant data objects of another type, and generally involves two basic problems: the measure of relevance and coupled feature selection. Most previous methods just focus on solving the first problem. In this paper, we aim to deal with both problems in a novel joint learning framework. To address the first problem, we learn projection matrices to map multimodal data into a common subspace, in which the similarity between different modalities of data can be measured. In the learning procedure, the l(21)-norm penalties are imposed on the projection matrices separately to solve the second problem, which selects relevant and discriminative features from different feature spaces simultaneously. A multimodal graph regularization term is further imposed on the projected data, which preserves the inter-modality and intra-modality similarity relationships. An iterative algorithm is presented to solve the proposed joint learning problem, along with its convergence analysis. Experimental results on cross-modal retrieval tasks demonstrate that the proposed method outperforms the state-of-the-art subspace approaches.	[Wang, Kaiye; He, Ran; Wang, Liang; Wang, Wei; Tan, Tieniu] Chinese Acad Sci CASIA, Inst Automat, Natl Lab Pattern Recognit, Ctr Res Intelligent Percept & Comp CRIPAC, Beijing 100190, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS	Wang, KY (corresponding author), Chinese Acad Sci CASIA, Inst Automat, Natl Lab Pattern Recognit, Ctr Res Intelligent Percept & Comp CRIPAC, Beijing 100190, Peoples R China.	kaiye.wang@nlpr.ia.ac.cn; rhe@nlpr.ia.ac.cn; wangliang@nlpr.ia.ac.cn; wangwei@nlpr.ia.ac.cn; tnt@nlpr.ia.ac.cn		Wang, Yunlong/0000-0002-3535-308X	National Basic Research Program of China [2012CB316305]; National Natural Science Foundation of China [61420106015, 61525306]	National Basic Research Program of China(National Basic Research Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work is jointly supported by National Basic Research Program of China (2012CB316305), and National Natural Science Foundation of China (61420106015,61525306). Liang Wang is the corresponding author of this paper.	Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0; Bekkerman R, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383223; Bengio Samy, 2010, ADV NEURAL INFORM PR, V1, P163, DOI [10.5555/2997189.2997208, DOI 10.5555/2997189.2997208]; Blei D.M., 2003, P 26 ANN INT ACM SIG, P127, DOI [10.1145/860435.860460, DOI 10.1145/860435.860460]; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928; Cai D., 2007, IEEE C COMP VIS ICCV, P1, DOI DOI 10.1109/ICCV.2007.4408856; Chen YM, 2012, IEEE IMAGE PROC, P1949, DOI 10.1109/ICIP.2012.6467268; Chua T.-S., 2009, P ACM INT C IM VID R, P1, DOI 10.1145/1646396.1646452; Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142; Ding G., 2014, P IEEE C COMP VIS PA, P4321; Frome Andrea, 2013, NEURIPS; Fu YW, 2014, IEEE T PATTERN ANAL, V36, P303, DOI 10.1109/TPAMI.2013.128; Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; He R, 2012, PROC CVPR IEEE, P2504, DOI 10.1109/CVPR.2012.6247966; He R, 2011, IEEE T PATTERN ANAL, V33, P1561, DOI 10.1109/TPAMI.2010.220; Hwang SJ, 2012, IEEE T PATTERN ANAL, V34, P1145, DOI 10.1109/TPAMI.2011.190; Jia Y., P ACM MULT, P675; Jia YQ, 2011, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2011.6126524; Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037; Li AN, 2011, IEEE I CONF COMP VIS, P1060, DOI 10.1109/ICCV.2011.6126352; Li D., 2003, P 11 ACM INT C MULTI, P604, DOI DOI 10.1145/957013.957143; Lin DH, 2006, LECT NOTES COMPUT SC, V3954, P13; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu XY, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P433; Lu Z., 2013, P 27 AAAI C ART INT, P640; Lu ZW, 2013, INT J COMPUT VISION, V103, P306, DOI 10.1007/s11263-012-0602-z; Mahadevan V., 2011, ADV NEURAL INFORM PR, P918; Mao Xiangbo, 2013, P 21 ACM INT C MULT, P897; Masci J, 2014, IEEE T PATTERN ANAL, V36, P824, DOI 10.1109/TPAMI.2013.225; Mignon A., 2012, P AS C COMP VIS, P1; Nie F., 2010, ADV NEURAL INFORM PR, V1, P1813, DOI DOI 10.1007/978-3-319-10690-8_12; Nikolova M, 2005, SIAM J SCI COMPUT, V27, P937, DOI 10.1137/030600862; Putthividhya D, 2010, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2010.5540000; Quadrianto N., 2011, P 28 INT C MACHINE L; Rasiwasia N, 2010, ACM MM, DOI DOI 10.1145/1873951.1873987; Rasiwasia N, 2007, IEEE T MULTIMEDIA, V9, P923, DOI 10.1109/TMM.2007.900138; Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923; Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350; Shen HF, 2010, IEEE INT CON MULTI, P980, DOI 10.1109/ICME.2010.5583900; Srivastava Nitish, 2012, ADV NEURAL INFORM PR, P2222, DOI DOI 10.1109/CVPR.2013.49; Sun L., 2008, ICML, P1024; Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349; Udupa R., 2010, P HLT NAACL, P492; Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261; Weinberger K., 2009, ADV NEURAL INFORM PR, P1737; Weston Jason, 2011, 22 INT JOINT C ART I; Wu F., 2013, P 21 ACM INT C MULT, P877, DOI DOI 10.1145/2502081.2502097; Wu F, 2012, INT J MULTIMED INF R, V1, P3, DOI 10.1007/s13735-012-0001-9; Wu W., 2010, MSRTR201086; Xu C, 2014, IEEE T PATTERN ANAL, V36, P1559, DOI 10.1109/TPAMI.2013.2296528; Yang YS, 2009, PROCEEDINGS OF 2009 CONFERENCE ON SYSTEMS SCIENCE, MANAGEMENT SCIENCE & SYSTEM DYNAMICS, VOL 8, P175, DOI 10.1145/1631272.1631298; Yu Z, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P395, DOI 10.1145/2600428.2609563; Zhai X., 2013, P AAAI C ART INT AAA; Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704; Zhen Y., 2012, ADV NEURAL INFORM PR, P1376, DOI [10.5555/2999134.2999288, DOI 10.5555/2999134.2999288]; Zhuang YT, 2008, IEEE T MULTIMEDIA, V10, P221, DOI 10.1109/TMM.2007.911822; Zhuang Yueting, 2013, 27 AAAI C ART INT, P1070	61	212	234	10	60	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2016	38	10					2010	2023		10.1109/TPAMI.2015.2505311	http://dx.doi.org/10.1109/TPAMI.2015.2505311			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DX2YV	26660704				2022-12-18	WOS:000384240600007
J	Hosang, J; Benenson, R; Dollar, P; Schiele, B				Hosang, Jan; Benenson, Rodrigo; Dollar, Piotr; Schiele, Bernt			What Makes for Effective Detection Proposals?	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; object detection; detection proposals	OBJECT DETECTION; SEGMENTATION	Current top performing object detectors employ detection proposals to guide the search for objects, thereby avoiding exhaustive sliding window search across images. Despite the popularity and widespread use of detection proposals, it is unclear which trade-offs are made when using them during object detection. We provide an in-depth analysis of twelve proposal methods along with four baselines regarding proposal repeatability, ground truth annotation recall on PASCAL, ImageNet, and MS COCO, and their impact on DPM, R-CNN, and Fast R-CNN detection performance. Our analysis shows that for object detection improving proposal localisation accuracy is as important as improving recall. We introduce a novel metric, the average recall (AR), which rewards both high recall and good localisation and correlates surprisingly well with detection performance. Our findings show common strengths and weaknesses of existing methods, and provide insights and metrics for selecting and tuning proposal methods.	[Hosang, Jan; Benenson, Rodrigo; Schiele, Bernt] Max Planck Inst Informat, D2, Saarbrucken, Saarland, Germany; [Dollar, Piotr] Facebook AI Res FAIR, Menlo Pk, CA USA	Max Planck Society; Facebook Inc	Hosang, J; Benenson, R; Schiele, B (corresponding author), Max Planck Inst Informat, D2, Saarbrucken, Saarland, Germany.; Dollar, P (corresponding author), Facebook AI Res FAIR, Menlo Pk, CA USA.	jhosang@mpi-inf.mpg.de; benenson@mpi-inf.mpg.de; pdollar@gmail.com; schiele@mpi-inf.mpg.de						Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Blaschko MB, 2013, LECT NOTES COMPUT SC, V7944, P408; Bourdev L, 2005, PROC CVPR IEEE, P236, DOI 10.1109/cvpr.2005.310; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; Carreira J, 2010, PROC CVPR IEEE, P3241, DOI 10.1109/CVPR.2010.5540063; Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333; Chavali N., 2015, ARXIV150505836; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Cinbis RG, 2013, IEEE I CONF COMP VIS, P2968, DOI 10.1109/ICCV.2013.369; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dollar P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715; Dollar P, 2012, LECT NOTES COMPUT SC, V7573, P645, DOI 10.1007/978-3-642-33709-3_46; Dollar P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231; Endres I, 2014, IEEE T PATTERN ANAL, V36, P222, DOI 10.1109/TPAMI.2013.122; Endres I, 2010, LECT NOTES COMPUT SC, V6315, P575, DOI 10.1007/978-3-642-15555-0_42; Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Feng J, 2011, IEEE I CONF COMP VIS, P1028, DOI 10.1109/ICCV.2011.6126348; Fragkiadaki K, 2015, PROC CVPR IEEE, P4083, DOI 10.1109/CVPR.2015.7299035; Girshick R., 2015, ICCV; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2013, IEEE I CONF COMP VIS, P3016, DOI 10.1109/ICCV.2013.375; Gu CH, 2009, PROC CVPR IEEE, P1030, DOI 10.1109/CVPRW.2009.5206727; Guillaumin M, 2014, INT J COMPUT VISION, V110, P328, DOI 10.1007/s11263-014-0713-9; Harzallah H, 2009, IEEE I CONF COMP VIS, P237, DOI 10.1109/ICCV.2009.5459257; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Hoiem Derek, 2012, ECCV, P340, DOI [10.1007/978-3-642-33712-3_25, DOI 10.1007/978-3-642-33712-3_25]; Hosang J., 2014, BMVC; Humayun A, 2014, PROC CVPR IEEE, P336, DOI 10.1109/CVPR.2014.50; Kim J, 2012, LECT NOTES COMPUT SC, V7578, P444, DOI 10.1007/978-3-642-33786-4_33; Krahenbuhl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47; Kuo W., 2015, ARXIV150502146; Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406; Lin T.Y., 2014, P EUR C COMP VIS 201; Malisiewicz T., 2007, P BRIT MACH VIS C; Manen S, 2013, IEEE I CONF COMP VIS, P2536, DOI 10.1109/ICCV.2013.315; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689; Pinheiro Pedro O., 2015, ADV NEURAL INFORM PR, V3, P5; Rahtu E, 2011, IEEE I CONF COMP VIS, P1052, DOI 10.1109/ICCV.2011.6126351; Rantalankila P, 2014, PROC CVPR IEEE, P2417, DOI 10.1109/CVPR.2014.310; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tang K, 2014, PROC CVPR IEEE, P1464, DOI 10.1109/CVPR.2014.190; Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055; Tuytelaars T, 2010, PROC CVPR IEEE, P2281, DOI 10.1109/CVPR.2010.5539911; Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456; Van den Bergh M, 2015, INT J COMPUT VISION, V111, P298, DOI 10.1007/s11263-014-0744-2; Van den Bergh M, 2013, IEEE I CONF COMP VIS, P377, DOI 10.1109/ICCV.2013.54; Vicente S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2217, DOI 10.1109/CVPR.2011.5995530; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang XY, 2013, IEEE I CONF COMP VIS, P17, DOI 10.1109/ICCV.2013.10; Zehnder P., 2008, P BRIT MACH VIS C; Zhang ZM, 2011, PROC CVPR IEEE, P1497, DOI 10.1109/CVPR.2011.5995411; Zhao Q., 2014, P BRIT MACH VIS C; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	63	212	234	6	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2016	38	4					814	830		10.1109/TPAMI.2015.2465908	http://dx.doi.org/10.1109/TPAMI.2015.2465908			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DH1MW		Green Submitted			2022-12-18	WOS:000372549700016
J	Liu, C; Sun, DQ				Liu, Ce; Sun, Deqing			On Bayesian Adaptive Video Super Resolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Super resolution; optical flow; blur kernel; noise level; aliasing	SUPERRESOLUTION; IMAGE; RECONSTRUCTION; CAMERA; LIMITS	Although multiframe super resolution has been extensively studied in past decades, super resolving real-world video sequences still remains challenging. In existing systems, either the motion models are oversimplified or important factors such as blur kernel and noise level are assumed to be known. Such models cannot capture the intrinsic characteristics that may differ from one sequence to another. In this paper, we propose a Bayesian approach to adaptive video super resolution via simultaneously estimating underlying motion, blur kernel, and noise level while reconstructing the original high-resolution frames. As a result, our system not only produces very promising super resolution results outperforming the state of the art, but also adapts to a variety of noise levels and blur kernels. To further analyze the effect of noise and blur kernel, we perform a two-step analysis using the Cramer-Rao bounds. We study how blur kernel and noise influence motion estimation with aliasing signals, how noise affects super resolution with perfect motion, and finally how blur kernel and noise influence super resolution with unknown motion. Our analysis results confirm empirical observations, in particular that an intermediate size blur kernel achieves the optimal image reconstruction results.	[Liu, Ce] Microsoft Res New England, Cambridge, MA 02142 USA; [Sun, Deqing] Harvard Univ, Pfister Grp, Cambridge, MA 02138 USA	Microsoft; Harvard University	Liu, C (corresponding author), Microsoft Res New England, 1 Mem Dr, Cambridge, MA 02142 USA.	celiu@microsoft.com; dqsun@seas.harvard.edu			Kitware; Nvidia; Google; Intel Science and Technology Center for Visual Computing; Office of Integrative Activities [1125087] Funding Source: National Science Foundation	Kitware; Nvidia; Google(Google Incorporated); Intel Science and Technology Center for Visual Computing; Office of Integrative Activities(National Science Foundation (NSF)NSF - Office of the Director (OD))	D. Sun would like to thank Dr. Lo-Bin Chang and Mr. Jianshu Chen for their help with the mathematical derivations of the performance bounds. He was supported by Kitware, Nvidia, Google, and the Intel Science and Technology Center for Visual Computing.	Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; Baker S., 1999, TECHNICAL REPORT; Bascle B., 1996, P EUR C COMP VIS; BILLINGS SA, 1989, MECH SYST SIGNAL PR, V3, P319, DOI 10.1016/0888-3270(89)90041-1; Brox T., 2004, P EUR C COMP VIS; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Clayton S., 2004, CRAMER RAO LOWER BOU; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; Fransens R, 2007, COMPUT VIS IMAGE UND, V106, P106, DOI 10.1016/j.cviu.2005.09.011; Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L; Joshi N., 2008, P IEEE C COMP VIS PA; Kay S. M., 1993, FUNDAMENTALS STAT SI; Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268; Levin A., 2009, P IEEE INT C COMP VI; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081; Liu C., 2009, PIXELS EXPLORING NEW; Liu C., 2010, P EUR C COMP VIS; Liu C., 2011, P IEEE C COMP VIS PA; Liu C, 2008, IEEE T PATTERN ANAL, V30, P299, DOI [10.1109/TPAMI.2007.1176, 10.1109/TPAMI.20071176]; Nguyen N., 1999, P AS C SIGN SYST COM; Oppenheim A.V., 1999, DISCRETE TIME SIGNAL; Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207; Robinson D, 2006, IEEE T IMAGE PROCESS, V15, P1413, DOI 10.1109/TIP.2006.871079; Roth S., 2007, THESIS BROWN U; Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6; Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915; Shan Q., 2008, ACM T GRAPHICS, V27; Sroubek F., 2008, Journal of Physics: Conference Series, V124, DOI 10.1088/1742-6596/124/1/012048; Su H, 2012, IEEE T IMAGE PROCESS, V21, P1782, DOI 10.1109/TIP.2011.2173204; Sun D., 2010, P IEEE C COMP VIS PA; Sun D., 2012, P EUR C COMP VIS; Tsai R.Y., 1984, ADV COMPUTER VISION; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7	39	212	234	2	61	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2014	36	2					346	360		10.1109/TPAMI.2013.127	http://dx.doi.org/10.1109/TPAMI.2013.127			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	278OL	24356354	Green Submitted			2022-12-18	WOS:000328899500011
J	Makinen, E; Raisamo, R				Makinen, Erno; Raisamo, Roope			Evaluation of gender classification methods with automatically detected and aligned faces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						classifier design and evaluation; computer vision; face and gesture classification; face detection; interactive systems; machine learning; vision I/O		We present a systematic study on gender classification with automatically detected and aligned faces. We experimented with 120 combinations of automatic face detection, face alignment, and gender classification. One of the findings was that the automatic face alignment methods did not increase the gender classification rates. However, manual alignment increased classification rates a little, which suggests that automatic alignment would be useful when the alignment methods are further improved. We also found that the gender classification methods performed almost equally well with different input image sizes. In any case, the best classification rate was achieved with a support vector machine. A neural network and Adaboost achieved almost as good classification rates as the support vector machine and could be used in applications where classification speed is considered more important than the maximum classification accuracy.	[Makinen, Erno; Raisamo, Roope] Univ Tampere, Dept Comp Sci, FIN-33014 Tampere, Finland	Tampere University	Makinen, E (corresponding author), Univ Tampere, Dept Comp Sci, FIN-33014 Tampere, Finland.	etm@cs.uta.fi; rr@cs.uta.fi	Raisamo, Roope/P-8398-2018	Raisamo, Roope/0000-0003-3276-7866				[Anonymous], 2005, 2005 IEEE COMP SOC C; Baluja S, 2007, INT J COMPUT VISION, V71, P111, DOI 10.1007/s11263-006-8910-9; CASTRILLONSANTA.M, 2003, P C ASS ESP INT ART; CASTRILLONSANTA.M, 2006, P 2 WORKSH MULT AUTH; CASTRILLONSANTA.MF, 2003, THESIS U PALMAS GRAN; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; COOTES E, 2001, P AS PAC C COMP HUM; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; JESORSKY O, 2001, P 3 INT C AUD VID BA, P90; Lian HC, 2006, LECT NOTES COMPUT SC, V3972, P202; MAKINEN E, 2002, P AS PAC C COMP HUM, P528; Moghaddam B., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P306, DOI 10.1109/AFGR.2000.840651; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; OpenCV, OP SOURC COMP VIS LI; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Rodriguez Y, 2006, IMAGE VISION COMPUT, V24, P882, DOI 10.1016/j.imavis.2006.02.012; Shakhnarovich G, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P16, DOI 10.1109/AFGR.2002.1004124; Stegmann MB, 2003, IEEE T MED IMAGING, V22, P1319, DOI 10.1109/TMI.2003.817780; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang T, 2003, PROC SPIE, V5286, P558, DOI 10.1117/12.539038; Wu B, 2003, P SOC PHOTO-OPT INS, V5286, P498, DOI 10.1117/12.539077; XIAO X, 2002, THESIS TSINGHUA U; Yang ZG, 2006, INT C PATT RECOG, P1099	26	212	220	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2008	30	3					541	547		10.1109/TPAMI.2007.70800	http://dx.doi.org/10.1109/TPAMI.2007.70800			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	250FT	18195447				2022-12-18	WOS:000252286100015
J	Torralba, A; Oliva, A				Torralba, A; Oliva, A			Depth estimation from image structure	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						depth; image statistics; scene structure; scene recognition; scale selection; monocular vision	NATURAL IMAGES; STATISTICS; SHAPE	In the absence of cues for absolute depth measurements as binocular disparity, motion, or defocus, the absolute distance between the observer and a scene cannot be measured. The interpretation of shading, edges, and junctions may provide a 3D model of the scene but it will not provide information about the actual "scale" of the space. One possible source of information for absolute depth estimation is the image size of known objects. However, object recognition, under unconstrained conditions, remains difficult and unreliable for current computational approaches. Here, we propose a source of information for absolute depth estimation based on the whole scene structure that does not rely on specific objects. We demonstrate that, by recognizing the properties of the structures present in the image, we can infer the scale of the scene and, therefore, its absolute mean depth. We illustrate the interest in computing the mean depth of the scene with application to scene recognition and object detection.	MIT, Artif Intelligence Lab, Cambridge, MA 02139 USA; Brigham & Womens Hosp, Ctr Ophthalm Res, Boston, MA 02115 USA	Massachusetts Institute of Technology (MIT); Harvard University; Brigham & Women's Hospital	Torralba, A (corresponding author), MIT, Artif Intelligence Lab, NE 43-743,200 Technol Sq, Cambridge, MA 02139 USA.	torralba@ai.mit.edu; oliva@search.bwh.harvard.edu						Baddeley R, 1997, COGNITIVE SCI, V21, P351, DOI 10.1207/s15516709cog2103_4; Barnard K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P408, DOI 10.1109/ICCV.2001.937654; BARROW HG, 1981, ARTIF INTELL, V17, P75, DOI 10.1016/0004-3702(81)90021-7; Bergen J.R., 1991, COMPUTATIONAL MODELS, P253; Carson C, 1997, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P42, DOI 10.1109/IVL.1997.629719; Coughlan J.M., 1999, P ICCV, V2, P941, DOI DOI 10.1109/ICCV.1999.790349; DEBONET JS, 1997, ADV NEURAL INFORMATI, V10, P866; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; GERSHNFELD N, 1999, NATURE MATH MODELING; GORKANI MM, 1994, INT C PATT RECOG, P459, DOI 10.1109/ICPR.1994.576325; HANCOCK PJB, 1992, NETWORK-COMP NEURAL, V3, P61, DOI 10.1088/0954-898X/3/1/008; Heeger DJ, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC648; Horn B.K.P., 1989, SHAPE SHADING; Jepson A., 1996, PERCEPTION BAYESIAN, P63; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; KELLER JM, 1987, IEEE T PATTERN ANAL, V9, P621, DOI 10.1109/TPAMI.1987.4767956; Lee AB, 2001, INT J COMPUT VISION, V41, P35, DOI 10.1023/A:1011109015675; LINDEBERG T, 1993, INT J COMPUT VISION, V11, P283, DOI 10.1007/BF01469346; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Liu F, 1996, IEEE T PATTERN ANAL, V18, P722, DOI 10.1109/34.506794; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; OLIVA A, 1999, P CHALLENGE IMAGE RE; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Palmer S., 1999, VISION SCI; Papoulis A., 2002, PROBABILITY RANDOM V; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591; Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983; ROGOWITZ BE, 1998, P SPIE C HUMAN VISIO; Ruderman DL, 1997, VISION RES, V37, P3385, DOI 10.1016/S0042-6989(97)00008-4; Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972; SHIMADA M, 2000, GEOMECH RES SER, V2, P1; Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193; SIMONCELLI EP, 1995, P 2 IEEE INT C IM PR; SUPER BJ, 1995, IEEE T PATTERN ANAL, V17, P333, DOI 10.1109/34.385983; Szummer M., 1998, P IEEE INT WORKSH CO; Torralba A, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P763, DOI 10.1109/ICCV.2001.937604; Torralba A. B., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1253, DOI 10.1109/ICCV.1999.790424; Vailaya A, 1998, PATTERN RECOGN, V31, P1921, DOI 10.1016/S0031-3203(98)00079-X; Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420	40	211	222	0	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2002	24	9					1226	1238		10.1109/TPAMI.2002.1033214	http://dx.doi.org/10.1109/TPAMI.2002.1033214			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	587KW					2022-12-18	WOS:000177640500006
J	LYVERS, EP; MITCHELL, OR; AKEY, ML; REEVES, AP				LYVERS, EP; MITCHELL, OR; AKEY, ML; REEVES, AP			SUBPIXEL MEASUREMENTS USING A MOMENT-BASED EDGE OPERATOR	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MAGNOVOX ELECTRO OPT SYST,DECIS SUPPORT SYST APPL CTR EXCELLENCE,FT WAYNE,IN 46808; UNIV TEXAS,DEPT ELECT ENGN,ARLINGTON,TX 76019; CORNELL UNIV,SCH ELECT ENGN,ITHACA,NY 14853	University of Texas System; University of Texas Arlington; Cornell University	LYVERS, EP (corresponding author), MIT,LINCOLN LAB,LEXINGTON,MA 02173, USA.							Duda R.O., 1973, J ROYAL STAT SOC SER; ENGLANDER A, 1987, SENSORS J MACHINE PE, V4, P9; FREI W, 1977, IEEE T COMPUT, V26, P988, DOI 10.1109/TC.1977.1674733; HUECKEL MH, 1974, J ACM, V21, P350, DOI 10.1145/321812.321830; HUECKEL MH, 1973, J ACM, V20, P634, DOI 10.1145/321784.321791; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; HUERTAS A, 1986, IEEE T PATTERN ANAL, V8, P651, DOI 10.1109/TPAMI.1986.4767838; IANNINO A, 1979, AUG P IEEE C PATT RE, P130; LYVERS EP, 1988, IEEE T PATTERN ANAL, V10, P927, DOI 10.1109/34.9114; MACHUCA R, 1981, IEEE T PATTERN ANAL, V3, P103, DOI 10.1109/TPAMI.1981.4767057; MACVICARWHELAN PJ, 1981, P SPIE, V281; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; PAPOULIS A, 1965, PROBABILITY RANDOM V, P65; PRATT WK, 1978, DIGITAL IMAGE PROCES, P498; Roberts L., 1965, MACHINE PERCEPTION 3; TABATABAI AJ, 1984, IEEE T PATTERN ANAL, V6, P188, DOI 10.1109/TPAMI.1984.4767502	16	211	289	3	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1989	11	12					1293	1309		10.1109/34.41367	http://dx.doi.org/10.1109/34.41367			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB716					2022-12-18	WOS:A1989CB71600005
J	Huang, C; Ai, HZ; Li, Y; Lao, SH				Huang, Chang; Ai, Haizhou; Li, Yuan; Lao, Shihong			High-performance rotation invariant multiview face detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern classification; AdaBoost; vector boosting; granular feature; rotation invariant; face detection		Rotation invariant multiview face detection (MVFD) aims to detect faces with arbitrary rotation-in-plane ( RIP) and rotation off-plane (ROP) angles in still images or video sequences. MVFD is crucial as the first step in automatic face processing for general applications since face images are seldom upright and frontal unless they are taken cooperatively. In this paper, we propose a series of innovative methods to construct a high-performance rotation invariant multiview face detector, including the Width-First-Search (WFS) tree detector structure, the Vector Boosting algorithm for learning vector-output strong classifiers, the domain-partition-based weak learning method, the sparse feature in granular space, and the heuristic search for sparse feature selection. As a result of that, our multiview face detector achieves low computational complexity, broad detection scope, and high detection accuracy on both standard testing sets and real-life images.	Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China; OMRON Corp, Sensing & Control Technol Lab, Kyoto 6190283, Japan	Tsinghua University; Omron Corporation	Huang, C (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.	huangc99@mails.tsinghua.edu.cn; ahz@mail.tsinghua.edu.cn; yuan-li@mails.tsinghua.edu.cn; lao@ari.ncl.omron.co.jp						ABRAMSON Y, 2005, P INT WORKSH AUT LEA; BALUJA S, 2004, P IEEE INT C IM PROC; Duffy N, 2002, MACH LEARN, V47, P153, DOI 10.1023/A:1013685603443; Fleuret F, 2001, INT J COMPUT VISION, V41, P85, DOI 10.1023/A:1011113216584; Freund Y, 2001, MACH LEARN, V43, P293, DOI 10.1023/A:1010852229904; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; HUANG C, 2005, P 10 IEEE INT C COMP; Huang C, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P401; JONES M, 2003, MERLTR200396; Kanade T., 1973, THESIS KYOTO U; Kotropoulos C, 1997, INT CONF ACOUST SPEE, P2537, DOI 10.1109/ICASSP.1997.595305; Li SZ, 2002, LECT NOTES COMPUT SC, V2353, P67; Li YM, 2004, IMAGE VISION COMPUT, V22, P413, DOI 10.1016/j.imavis.2003.12.005; Lienhart R, 2002, P IEEE INT C IM PROC; Liu C, 2003, PROC CVPR IEEE, P587; Mita Takeshi, 2005, P 10 IEEE INT C COMP; NILSSON NJ, 1998, ARTIF INTELL, P140; OSADCHY M, 2004, P NEUR INF PROC SYST; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Rowley HA, 1998, PROC CVPR IEEE, P38, DOI 10.1109/CVPR.1998.698585; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; SCHAPIRE RE, 1997, P 4 INT C MACH LEARN; Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895; Viola Paul, 2001, PROC CVPR IEEE; WANG P, 2005, P IEEE C COMP VIS PA; Wu B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P79; XIAO R, 2003, P 9 IEEE INT C COMP; YANG MH, 2002, IEEE T PATTERN ANAL, V24	29	209	230	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2007	29	4					671	686		10.1109/TPAMI.2007.1011	http://dx.doi.org/10.1109/TPAMI.2007.1011			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HJ	17299224				2022-12-18	WOS:000244855600015
J	Veeraraghavan, A; Roy-Chowdhury, AK; Chellappa, R				Veeraraghavan, A; Roy-Chowdhury, AK; Chellappa, R			Matching shape sequences in video with applications in human movement analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape; shape sequences; shape dynamics; comparison of shape sequences; gait recognition	RECOGNITION; DISCRIMINATION; REPRESENTATION; PERCEPTION; MOTION	We present an approach for comparing two sequences of deforming shapes using both parametric models and nonparametric methods. In our approach, Kendall's definition of shape is used for feature extraction. Since the shape feature rests on a non-Euclidean manifold, we propose parametric models like the autoregressive model and autoregressive moving average model on the tangent space and demonstrate the ability of these models to capture the nature of shape deformations using experiments on gait-based human recognition. The nonparametric model is based on Dynamic Time-Warping. We suggest a modification of the Dynamic time-warping algorithm to include the nature of the non-Euclidean space in which the shape deformations take place. We also show the efficacy of this algorithm by its application to gait-based human recognition. We exploit the shape deformations of a person's silhouette as a discriminating feature and provide recognition results using the nonparametric model. Our analysis leads to some interesting observations on the role of shape and kinematics in automated gait-based person authentication.	Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA; Univ Calif Riverside, Dept Elect Engn, Riverside, CA 92507 USA	University System of Maryland; University of Maryland College Park; University of California System; University of California Riverside	Veeraraghavan, A (corresponding author), Univ Maryland, Ctr Automat Res, 4417 AV Williams Bldg, College Pk, MD 20742 USA.	vashok@umiacs.umd.edu; amitrc@ee.ucr.edu; rama@umiacs.umd.edu	Chellappa, Rama/B-6573-2012; Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/AAV-8690-2020	Roy-Chowdhury, Amit/0000-0001-6690-9725				ARKIN E, 1986, IEEE T PATTERN ANAL, V27, P209; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BERTHILSSON R, 1998, STAT PATTERN RECOGNI, P677; Bissacco A, 2001, PROC CVPR IEEE, P52; BISSACCO A, 2004, P INT S MATH THEOR N; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; BOBICK A, 2003, P 4 INT C AUD VID BA; Bobick A. F., 2001, P C COMP VIS PATT RE; Bookstein FL., 1986, STAT SCI, V1, P181, DOI [DOI 10.1214/SS/1177013696, 10.1214/ss/1177013696]; Brockwell P., 1991, TIME SERIES THEORY M; CHEN CC, 1993, PATTERN RECOGN, V26, P683, DOI 10.1016/0031-3203(93)90121-C; Cock K. D., 2000, P INT S MATH THEOR N; Collins RT, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P366, DOI 10.1109/AFGR.2002.1004181; CUNADO D, 1994, P INT C AVBPA, P43; CUTTING JE, 1977, B PSYCHONOMIC SOC, V9, P353, DOI 10.3758/BF03337021; CUTTING JE, 1981, INTERSENSORY PERCEPT; DRYDEN I, 2000, P IMA WORKSH IM AN H; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; FORNERCORDERO A, IN PRESS J BIOMECHAN; Foster JP, 2003, PATTERN RECOGN LETT, V24, P2489, DOI 10.1016/S0167-8655(03)00094-1; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; Geiger D, 2003, IEEE T PATTERN ANAL, V25, P86, DOI 10.1109/TPAMI.2003.1159948; Golub G. H., 1996, MATRIX COMPUTATIONS; GOSHTASBY A, 1985, IEEE T PATTERN ANAL, V7, P738, DOI 10.1109/TPAMI.1985.4767734; HAN J, 2003, P WORKSH MULT US AUT, P181; Hoenkamp E., 1978, J HUMAN MOVEMENT STU, V4, P59; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378; KALE A, 2004, IEEE T IM PROC SEPT; KASHYAP RL, 1981, IEEE T INFORM THEORY, V27, P627, DOI 10.1109/TIT.1981.1056390; KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81; KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109; LEE L, 2003, P INT C COMP VIS; LIU C, 2004, P C COMP VIS PATT RE; Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2; MAUREL P, 2003, P 2 IEEE WORKSH VAR; MAZZARO C, 2002, P 1 INT S 3D DAT PRO; Mowbray SD, 2004, PROC CVPR IEEE, P895; MURRAY MP, 1964, J BONE JOINT SURG AM, V46, P335, DOI 10.2106/00004623-196446020-00009; NIYOGI S, 1994, 223 MIT MED LAB VIS; PARUI SK, 1986, PATTERN RECOGN LETT, V4, P201, DOI 10.1016/0167-8655(86)90020-6; PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; PHILLIPS J, 2002, P INT C PATT REC AUG; Prentice MJ, 1995, ANN STAT, V23, P1960; Proakis J., 2013, DIGIT SIGNAL PROCESS, V4th; Rabiner L., 1993, FUNDAMENTALS SPEECH; Rangarajan A, 1997, LECT NOTES COMPUT SC, V1230, P29; Soatto S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P439, DOI 10.1109/ICCV.2001.937658; Srivastava A, 2004, ADV APPL PROBAB, V36, P43, DOI 10.1239/aap/1077134463; SRIVASTAVA A, 2003, P 4 INT WORKSH EN MI; Tanawongsuwan R, 2004, PROC CVPR IEEE, P783; TOLLIVER D, 2003, P 4 INT C AUD VID BA; VANOVERSCHEE P, 1993, AUTOMATICA, V29, P649, DOI 10.1016/0005-1098(93)90061-W; VASWANI N, 2004, IEEE T IMAGE PROCESS; VEERARAGHAVAN A, 2004, P C COMP VIS PATT RE; VELTKAMP RC, 1999, UUCS199927, V27; Veres GV, 2004, PROC CVPR IEEE, P776; WANG L, 2002, P INT C IM PROC; Yezzi AJ, 2003, INT J COMPUT VISION, V53, P153, DOI 10.1023/A:1023048024042; [No title captured]	63	209	222	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2005	27	12					1896	1909		10.1109/TPAMI.2005.246	http://dx.doi.org/10.1109/TPAMI.2005.246			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	973ON	16355658				2022-12-18	WOS:000232532600005
J	Liu, CL; Jaeger, S; Nakagawa, M				Liu, CL; Jaeger, S; Nakagawa, M			Online recognition of Chinese characters: The state-of-the-art	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review						online Chinese character recognition; state-of-the-art; pattern representation; character classification; model learning; contextual processing; performance evaluation	CANDIDATE SELECTION; SET RECOGNITION; NORMALIZATION; ALGORITHM; MODEL; CLASSIFICATION; FEATURES; SYSTEM	Online handwriting recognition is gaining renewed interest owing to the increase of pen computing applications and new pen input devices. The recognition of Chinese characters is different from western handwriting recognition and poses a special challenge. To provide an overview of the technical status and inspire future research, this paper reviews the advances in online Chinese character recognition (OLCCR), with emphasis on the research works from the 1990s. Compared to the research in the 1980s, the research efforts in the 1990s aimed to further relax the constraints of handwriting, namely, the adherence to standard stroke orders and stroke numbers and the restriction of recognition to isolated characters only. The target of recognition has shifted from regular script to fluent script in order to better meet the requirements of practical applications. The research works are reviewed in terms of pattern representation, character classification, learning/adaptation, and contextual processing. We compare important results and discuss possible directions of future research.	Hitachi Ltd, Cent Res Lab, Kokubunji, Tokyo 1858601, Japan; Tokyo Univ Agr & Technol, Dept Comp Sci, Koganei, Tokyo 1848588, Japan	Hitachi Limited; Tokyo University of Agriculture & Technology	Liu, CL (corresponding author), Hitachi Ltd, Cent Res Lab, 1-280 Higashi Koigakubo, Kokubunji, Tokyo 1858601, Japan.	liucl@crl.hitachi.co.jp; stefan@hands.ei.tuat.ac.jp; nakagawa@cc.tuat.ac.jp	Nakagawa, Masaki/B-9966-2013	Nakagawa, Masaki/0000-0001-7872-156X				AKIYAMA K, PRMU2000210 IEICE; AKIYAMA K, 2000, PRMU99235 IEICE; BLOSTEIN D, 1995, GRAPHICS RECOGNITION, P107; CASEY RG, 1970, IBM J RES DEV, V14, P548, DOI 10.1147/rd.145.0548; Chan KF, 2001, PATTERN RECOGN, V34, P1671, DOI 10.1016/S0031-3203(00)00102-3; CHANDLER DE, 1992, MICROSC RES TECHNIQ, V22, P1, DOI 10.1002/jemt.1070220102; Chen J W, 1996, P 13 INT C PATT REC, V3, P220; CHEN JW, 1994, IMAGE VISION COMPUT, V12, P669, DOI 10.1016/0262-8856(94)90042-6; CHEN JW, 1996, ADV SYNTACTIC STRUCT, P351; CHEN KJ, 1988, INT J PATTERN RECOGN, V2, P139; Chen S, 1997, MOL ENDOCRINOL, V11, P3, DOI 10.1210/me.11.1.3; CHEN WT, 1994, PATTERN RECOGN, V27, P205, DOI 10.1016/0031-3203(94)90054-X; CHEN Z, 1996, P 13 INT C PATT REC, V3, P89; CHENG RH, 1994, P 4 INT WORKSH FRONT, P176; Cho SJ, 2001, PROC INT CONF DOC, P86, DOI 10.1109/ICDAR.2001.953760; Chou KS, 1997, PATTERN RECOGN, V30, P483, DOI 10.1016/S0031-3203(96)00090-8; CHOU KS, 1994, IEEE J SEL AREA COMM, V12, P1566, DOI 10.1109/49.339925; CHOU KS, 1994, P 4 INT WORKSH FRONT, P185; Chou TR, 1997, PATTERN RECOGN, V30, P903, DOI 10.1016/S0031-3203(96)00102-1; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; FAN KC, 1995, PATTERN RECOGN, V28, P303, DOI 10.1016/0031-3203(94)00110-8; FUJISAKI T, 1992, CHARACTER HANDWRITIN, P123; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Fukushima T, 2000, INT C PATT RECOG, P359, DOI 10.1109/ICPR.2000.906087; GUYON I, 1994, INT C PATT RECOG, P29, DOI 10.1109/ICPR.1994.576870; Hamanaka M., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P204, DOI 10.1109/ICDAR.1993.395748; HAMANAKA M, 2000, P 7 INT WORKSH FRONT, P23; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; HIDAI Y, 1986, P 8 INT C PATT REC, V2, P934; HILDEBRANDT TH, 1993, PATTERN RECOGN, V26, P205, DOI 10.1016/0031-3203(93)90030-Z; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716; HONG C, 1997, P INT C COMP PROC OR, P630; HSIEH AJ, 1995, PATTERN RECOGN, V28, P143, DOI 10.1016/0031-3203(94)00090-9; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; Iijima T., 1973, 1st International Joint Conference on Pattern Recognition, P50; ISHIGAKI K, 1988, P INT C COMP PROC CH, P141; ITOH M, 1995, OPT REV, V2, P135, DOI 10.1007/s10043-995-0135-6; IWAYAMA N, 2000, P 7 IWFHR, P469; Jaeger S, 2001, PROC INT CONF DOC, P566, DOI 10.1109/ICDAR.2001.953853; Jaeger S., 2003, International Journal on Document Analysis and Recognition, V6, P75, DOI 10.1007/s10032-003-0107-y; Jain AK, 2002, PATTERN RECOGN, V35, P2963, DOI 10.1016/S0031-3203(01)00240-0; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; Jianzhuang Liu, 1996, Proceedings of the 13th International Conference on Pattern Recognition, P259, DOI 10.1109/ICPR.1996.546950; Jing Zhen, 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P649, DOI 10.1109/ICDAR.1999.791871; KAWAMURA A, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P183, DOI 10.1109/ICPR.1992.201750; Kawatani T., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P98, DOI 10.1109/ICDAR.1995.598952; Kim HJ, 1996, PATTERN RECOGN LETT, V17, P1311, DOI 10.1016/0167-8655(96)00078-5; Kim HJ, 1997, PATTERN RECOGN, V30, P1489, DOI 10.1016/S0031-3203(96)00161-6; Kim IJ, 2003, IEEE T PATTERN ANAL, V25, P1422, DOI 10.1109/TPAMI.2003.1240117; Kimura F, 1997, PATTERN RECOGN, V30, P1329, DOI 10.1016/S0031-3203(96)00153-7; KIMURA F, 1987, IEEE T PATTERN ANAL, V9, P149, DOI 10.1109/TPAMI.1987.4767881; Kimura Y., 2001, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ84D-II, P509; Kitadai A, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P163, DOI 10.1109/IWFHR.2002.1030903; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kobayashi M., 2001, International Journal on Document Analysis and Recognition, V3, P181, DOI 10.1007/PL00013560; KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325; Komiya Y, 2001, IEICE T INF SYST, VE84D, P833; Kuo-Sen Chou, 1996, Proceedings of the 13th International Conference on Pattern Recognition, P84, DOI 10.1109/ICPR.1996.546799; Kuroda K, 1999, PATTERN RECOGN, V32, P1307, DOI 10.1016/S0031-3203(98)00161-7; LAAKSONEN J, 1999, ADV HANDWRITING RECO, P489; Lay SR, 1996, PATTERN RECOGN, V29, P1647, DOI 10.1016/0031-3203(96)00014-3; LECLERC F, 1994, INT J PATTERN RECOGN, V8, P3; LEE SW, 1994, PATTERN RECOGN, V27, P895, DOI 10.1016/0031-3203(94)90155-4; LI X, 1993, PATTERN RECOGN, V26, P1315, DOI 10.1016/0031-3203(93)90138-M; LIN CK, 1993, PATTERN RECOGN, V26, P259, DOI 10.1016/0031-3203(93)90034-T; LIN MY, 1988, P INT C COMP PROC CH, P131; LIN TZ, 1994, PATTERN RECOGN, V27, P1365, DOI 10.1016/0031-3203(94)90070-1; Liu C.-L., 1997, PROGR HANDWRITING RE, P161; Liu CL, 2000, IEEE T PATTERN ANAL, V22, P636, DOI 10.1109/34.862202; Liu CL, 2003, PROC INT CONF DOC, P524; Liu J, 1996, IEE P-VIS IMAGE SIGN, V143, P125, DOI 10.1049/ip-vis:19960326; Liu JZ, 2000, IEE P-VIS IMAGE SIGN, V147, P47, DOI 10.1049/ip-vis:20000103; Liu Y.-J., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P192, DOI 10.1109/ICDAR.1993.395751; Liu Y. J., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P808, DOI 10.1109/ICPR.1988.28366; Liu YW, 2001, CHINESE LAW GOV, V34, P3, DOI 10.2753/CLG0009-460934063; Lopresti D., 2000, P 7 INT WORKSH FRONT, P3; MA M, 1997, P 17 INT C COMP PROC, P107; Matic NP, 2002, INT C PATT RECOG, P435, DOI 10.1109/ICPR.2002.1047941; Matsumoto K, 2001, PROC INT CONF DOC, P496, DOI 10.1109/ICDAR.2001.953839; MATSUMOTO K, 2002, PRMU2001273; Muller S., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P289, DOI 10.1109/ICDAR.1999.791781; MURASE H, 1988, P 9 ICPR, P1143; MYERS CS, 1981, IEEE T ACOUST SPEECH, V29, P284, DOI 10.1109/TASSP.1981.1163527; Nakagawa M., 1996, Advances in Structural and Syntactical Pattern Recognition. 6th International Workshop, SSPR '96 Proceedings, P180; Nakagawa M, 1997, PROC INT CONF DOC, P376, DOI 10.1109/ICDAR.1997.619874; Nakagawa M., 1990, Journal of Information Processing, V13, P15; Nakagawa M., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P269, DOI 10.1109/ICPR.1996.546953; Nakagawa M., 1999, ADV HANDWRITING RECO, P578; NAKAGAWA M, 1995, P 4 INT WORKSH FRONT, P48; Nakai M, 2003, PROC INT CONF DOC, P514; Nakai M., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P491, DOI 10.1109/ICDAR.2001.953838; Nakajima T, 2002, ALIMENT PHARM THERAP, V16, P3, DOI 10.1046/j.1365-2036.16.s2.25.x; Nambu H, 1998, INT C PATT RECOG, P1145; Nillson N. J, 1980, PRINCIPLES ARTIFICIA; ODAKA K, 1982, T IECE D, V65, P679; OJA E, 1983, SUBSPACE METHOD PATT; Okamoto M., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P491, DOI 10.1109/ICDAR.1999.791832; Okamoto M, 1999, PATTERN RECOGN, V32, P1115, DOI 10.1016/S0031-3203(98)00153-8; OKAMOTO M, 1996, P 13 INT C PATTERN R, V4, P422; PAPADIMITRIOUS CH, 1982, COMBINATORIAL OPTIMA; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Ramer U, 1972, COMPUT GRAPH IMAGE P, V1, P244, DOI [DOI 10.1016/S0146-664X(72)80017-0, 10.1016/S0146-664X(72)80017-0]; ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188; Rowley HA, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P36, DOI 10.1109/IWFHR.2002.1030881; Russell G, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P233, DOI 10.1109/IWFHR.2002.1030915; SARKAR P, 2000, P ICPR 15 BARC SEPT, V2, P859; Schomaker L., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P293, DOI 10.1109/ICDAR.1999.791782; Senda S., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P184, DOI 10.1109/ICDAR.2001.953780; SENDA S, 1998, PRMU98138 IEICE; Shin JP, 2002, PATTERN RECOGN LETT, V23, P601, DOI 10.1016/S0167-8655(01)00136-2; SHIN JP, 1999, T IEICE JAPAN D, V82, P230; Subrahmonia J, 2000, INT C PATT RECOG, P60, DOI 10.1109/ICPR.2000.906018; SUEN CY, 1979, IEEE T PATTERN ANAL, V1, P164, DOI 10.1109/TPAMI.1979.4766902; TAI JW, 1992, CHARACTER HANDWRITIN, P199; Takahashi K, 1997, PROC INT CONF DOC, P369, DOI 10.1109/ICDAR.1997.619873; Takeuchi K., 2000, International Journal of Computer Processing of Oriental Languages, V13, P69, DOI 10.1142/S0219427900000089; Tanaka H., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P209, DOI 10.1109/ICDAR.1999.791761; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669; Tokuno J, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P78, DOI 10.1109/IWFHR.2002.1030888; TSAI WH, 1985, IEEE T PATTERN ANAL, V7, P453, DOI 10.1109/TPAMI.1985.4767684; TSAI WH, 1983, IEEE T SYST MAN CYB, V13, P48, DOI 10.1109/TSMC.1983.6313029; Tsay MK, 1999, IEICE T INF SYST, VE82D, P687; TSAY YT, 1993, IEEE T PATTERN ANAL, V15, P180, DOI 10.1109/34.192491; Tseng CC, 1999, J INF SCI ENG, V15, P451; TSUKUMO J, 1988, P 9 INT C PATT REC, P168; Umeda M, 1996, IEICE T INF SYST, VE79D, P401; VELEK O, 2000, P 8 INT WORKSH FRONT, P177; Vuori V., 2001, International Journal on Document Analysis and Recognition, V3, P150, DOI 10.1007/PL00013555; Wakahara T., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P1059, DOI 10.1109/ICDAR.1995.602091; WAKAHARA T, 1992, P IEEE, V80, P1181, DOI 10.1109/5.156478; Wakahara T, 1997, IEEE T PATTERN ANAL, V19, P1381, DOI 10.1109/34.643898; WAKAHARA T, 1988, P 9 INT C PATT REC N, P1133; Winston P.H., 1992, ARTIF INTELL; WONG AKC, 1990, IEEE T SYST MAN CYB, V20, P628, DOI 10.1109/21.57275; Wong PK, 1999, IEEE T SYST MAN CY B, V29, P286, DOI 10.1109/3477.752802; WU WY, 1993, CVGIP-GRAPH MODEL IM, V55, P79, DOI 10.1006/cgip.1993.1006; XIAO XH, 1997, P 17 INT C COMP PROC, P89; Xu RF, 2002, INT J PATTERN RECOGN, V16, P657, DOI 10.1142/S0218001402001964; YAMADA H, 1990, PATTERN RECOGN, V23, P1023, DOI 10.1016/0031-3203(90)90110-7; Yamasaki K., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P673, DOI 10.1109/ICDAR.1999.791877; Yasuda H., 1999, ADV HANDWRITING RECO, P19; YASUDA M, 1979, IEICE T D, V62, P217; YE PJ, 1984, P 7 INT C PATT REC, P1043; YHAP EF, 1981, IBM J RES DEV, V25, P187, DOI 10.1147/rd.252.0187; YOKOTA T, 2001, P HCI INT, P455; Zanibbi R, 2002, IEEE T PATTERN ANAL, V24, P1455, DOI 10.1109/TPAMI.2002.1046157; Zheng J, 1997, PROC INT CONF DOC, P621, DOI 10.1109/ICDAR.1997.620578	149	209	230	2	54	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2004	26	2					198	213						16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	762DA	15376895				2022-12-18	WOS:000187954300006
J	COHEN, FS; FAN, ZG; ATTALI, S				COHEN, FS; FAN, ZG; ATTALI, S			AUTOMATED INSPECTION OF TEXTILE FABRICS USING TEXTURAL MODELS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						FABRIC INSPECTION; GAUSSIAN MARKOV RANDOM FIELDS; GENERALIZED LIKELIHOOD RATIO TEST; MAXIMUM LIKELIHOOD ESTIMATES; SUFFICIENT STATISTICS		This correspondence is concerned with the problem of textile fabric inspection using the visual textural properties of the fabric. The problem here is to detect and locate the various kinds of defects that might be present in a given fabric sample based on an image of the fabric. Stochastic models are used to model the visual fabric texture. We use the Gaussian Markov Random Field (GMRF) to model the texture image of a nondefective fabric texture. The GMRF model is fully described by a compact set of parameters, and is a synthesis model. The inspection problem is cast as a statistical hypothesis testing problem on statistics derived from the model. The image of the fabric patch to be inspected is partitioned into nonoverlapping windows of size N x N, where each window is classified as defective or nondefective based on a likelihood ratio test of size alpha. This test requires the computation of the maximum likelihood estimates (MLE) of the model parameters in each window. This is somewhat computationally intensive and time consuming. To overcome this problem, the test is recast in terms of the sufficient statistics associated with the model parameters. The sufficient statistics is easily computable for any sample. Finally, we generalize the test when the model parameters of the fabric can not be obtained beforehand, and hence are assumed unknown.	XEROX CORP,WEBSTER RES CTR,WEBSTER,NY 14580; GIXI INGN INFORMAT SA,LES ULIS,FRANCE	Xerox	COHEN, FS (corresponding author), DREXEL UNIV,DEPT ELECT & COMP ENGN,PHILADELPHIA,PA 19118, USA.							BESAG J, 1975, BIOMETRIKA, V62; BESAG JE, 1974, J ROY STATIST SOC B, V36; BOLLE RM, 1986, IEEE T PATTERN ANAL, V8; CHELLAPPA R, 1985, IEEE T ACOUST SP AUG; CHIN R, 1982, NOV IEEE T PATT AN M, V4; COHEN FS, 1986, MARKOV RANDOM FIELDS; COHEN FS, 1987, IEEE T PATTERN ANAL, V9; CONNERS R, 1979, P IEEE C PRIP; CONNERS R, 1983, IEEE T PATTERN ANAL, V5; COOPER DB, 1974, IEEE T INFORM THEORY, V12; CRISTI R, 1988, APR P INT C AC SPEEC; CROSS R, 1983, IEEE PATTERN ANAL MA, V5; DERIN H, 1987, IEEE T PATTERN ANAL, V9; DON H, 1984, IEEE T SYST MAN CYBE, V14; FAN Z, 1988, IEEE T SYST CIRC JUN; FU S, 1979, COMPUT VISION GRAPHI, V9; Geman S., 1984, IEEE T PATTERN ANAL, V6; GIEBEL H, 1982, 6TH P IEEE INT C PAT, V2; Haralick RM, 1973, IEEE T SYST MAN CYBE, V3; Julesz B., 1962, IRE T INFORM THEORY, V8; KASHYAP RL, 1982, PATTERN RECOGNITION, V1; KASHYAP RL, 1983, IEEE T INFORM TH JAN; KNOLL A, 1985, AUTOMATIC FABRIC INS; KOSHIMIZU H, 1979, P SPIE IMAGING APPLI, V182; KUSE E, 1978, J SOC FIBER SCI TECH, V34; LEHMANN EL, 1959, TESTING STATISTICAL; PIETRZAK K, 1985, THESIS U RHODE ISLAN; RIMEY R, 1988, IEEE T ROBOTICS AUTO, V4; ROSENFELD A, 1970, 70116 U MARYL TECH R; TAKAMATSU S, 1976, J TEXTILE MACH SOC J, V29; THERRIEN C, 1983, COMPUT GRAPHICS IMAG, V22; TOMITA F, 1979, P IJCAI79; WOODS J, 1972, IEEE T INFORM THEORY, V18; ZACKS S, 1981, PARAMETRIC STATISTIC; ZUCKER SW, 1975, IEEE T COMPUT, V24	35	209	233	1	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1991	13	8					803	808		10.1109/34.85670	http://dx.doi.org/10.1109/34.85670			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GC642					2022-12-18	WOS:A1991GC64200005
J	Konishi, S; Yuille, AL; Coughlan, JM; Zhu, SC				Konishi, S; Yuille, AL; Coughlan, JM; Zhu, SC			Statistical edge detection: Learning and evaluating edge cues	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						edge detection; statistical learning; performance analysis; Bayesian inference	NATURAL IMAGES	We formulate edge detection as statistical inference. This statistical edge detection is data driven, unlike standard methods for edge detection which are model based. For any set of edge detection filters (implementing local edge cues), we use presegmented images to learn the probability distributions of filter responses conditioned on whether they are evaluated on or off an edge. Edge detection is formulated as a discrimination task specified by a likelihood ratio test on the filter responses. This approach emphasizes the necessity of modeling the image background (the off-edges). We represent the conditional probability distributions nonparametrically and illustrate them on two different data sets of 100 (Sowerby) and 50 (South Florida) images. Multiple edges cues, including chrominance and multiple-scale, are combined by using their joint distributions. Hence, this cue combination is optimal in the statistical sense. We evaluate the effectiveness of different visual cues using the Chernoff information and Receiver Operator Characteristic (ROC) curves. This shows that our approach gives quantitatively better results than the Canny edge detector when the image background contains significant clutter. In addition, it enables us to determine the effectiveness of different edge cues and gives quantitative measures for the advantages of multilevel processing, for the use of chrominance, and for the relative effectiveness of different detectors. Furthermore, we show that we can learn these conditional distributions on one data set and adapt them to the other with only slight degradation of performance without knowing the ground truth on the second data set. This shows that our results are not purely domain specific. We apply the same approach to the spatial grouping of edge cues and obtain analogies to nonmaximal suppression and hysteresis.	Smith Kettlewell Eye Res Inst, San Francisco, CA 94115 USA; Univ Calif Los Angeles, Dept Psychol & Stat, Los Angeles, CA 90095 USA; Ohio State Univ, Dept Comp & Informat Sci, Columbus, OH 43210 USA	The Smith-Kettlewell Eye Research Institute; University of California System; University of California Los Angeles; University System of Ohio; Ohio State University	Konishi, S (corresponding author), Smith Kettlewell Eye Res Inst, 2318 Fillmore St, San Francisco, CA 94115 USA.	konishi@ski.org; yuille@stat.ucla.edu; coughlan@ski.org; szhu@cis.ohio-state.edu		Yuille, Alan L./0000-0001-5207-9249				ATICK JJ, 1992, NEURAL COMPUT, V4, P196, DOI 10.1162/neco.1992.4.2.196; BALBOA R, 1997, THESIS U ALICANTE SP; BALBOA R, 2000, VISION RES; Balboa RM, 2000, NEURAL COMPUT, V12, P1485, DOI 10.1162/089976600300015231; Blake A., 1992, ACTIVE VISION; Bowyer K, 2001, COMPUT VIS IMAGE UND, V84, P77, DOI 10.1006/cviu.2001.0931; Bowyer K., 1998, EMPIRICAL EVALUATION; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; COUGHLAN JM, 1998, P COMP VIS PATT REC; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Green DM, 1988, SIGNAL DETECTION THE; Grzywacz NM, 2002, NEURAL COMPUT, V14, P543, DOI 10.1162/089976602317250898; HEITGER F, 1992, VISION RES, V32, P963, DOI 10.1016/0042-6989(92)90039-L; Kass M., 1987, International Journal of Computer Vision, V1, P321, DOI 10.1007/BF00133570; Knill DC, 1996, PERCEPTION BAYESIAN; KONISHI S, 2000, P COMP VIS PATT REC; KONISHI S, 2002, THESIS U CALIFORNIA; KONISHI S, 2002, P WORKSH GEN MOD BAS; KONISHI SM, 1999, P COMP VIS PATT REC; LEE AB, 2000, INT J COMPUTER V OCT; Marr D., 1982, VISION; Nitzberg M., 1993, FILTERING SEGMENTATI; Peng J, 1998, IEEE T PATTERN ANAL, V20, P139, DOI 10.1109/34.659932; Perona P., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P52, DOI 10.1109/ICCV.1990.139492; Ripley BD., 1996; RUDERMAN DL, 1994, PHYS REV LETT, V73, P814, DOI 10.1103/PhysRevLett.73.814; Shin M. C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P360, DOI 10.1109/CVPR.1999.786964; SIDENBLAT H, 2001, THESIS ROYAL I TECHN; Sullivan J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1068, DOI 10.1109/ICCV.1999.790391; Vapnik V.N, 1998, STAT LEARNING THEORY; Wainwright MJ, 2000, ADV NEUR IN, V12, P855; Yuille AL, 2000, IEEE T PATTERN ANAL, V22, P160, DOI 10.1109/34.825754; YUILLE AL, 2000, P INT SOC OPT ENG SP; ZHU S, 1997, NEURAL COMPUTATION, V9; Zhu SC, 1997, IEEE T PATTERN ANAL, V19, P1236, DOI 10.1109/34.632983; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	39	208	228	1	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2003	25	1					57	74		10.1109/TPAMI.2003.1159946	http://dx.doi.org/10.1109/TPAMI.2003.1159946			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	628NL					2022-12-18	WOS:000180002300005
J	GRANVILLE, V; KRIVANEK, M; RASSON, JP				GRANVILLE, V; KRIVANEK, M; RASSON, JP			SIMULATED ANNEALING - A PROOF OF CONVERGENCE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter							NOISE	We prove the convergence of the simulated annealing procedure when the decision to change the current configuration is blind of the cost of the new configuration. In case of filtering binary images, the proof easily generalizes to other procedures, including that of Metropolis. We show that a function Q associated with the algorithm must be chosen as large as possible to provide a fast rate of convergence. The worst case (Q constant) is associated with the ''blind'' algorithm. On the other hand, an appropriate Q taking sufficiently high values yields a better rate of convergence than that of Metropolis procedure.	CHARLES UNIV,DEPT COMP SCI,CS-11800 PRAGUE 1,CZECH REPUBLIC	Charles University Prague	GRANVILLE, V (corresponding author), FUNDP,DEPT MATH,REMPART VIERGE 8,B-5000 NAMUR,BELGIUM.							BESAG J, 1986, J R STAT SOC B, V48, P259; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; GELFAND SB, 1987, P ADV SCH CISM UDINE, P1; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GEMAN S, 1988, LECTURES NOTES MATH, V1427, P117; GIDAS B, 1985, J STAT PHYS, V39, P73, DOI 10.1007/BF01007975; GRANVILLE V, 1993, COMPUT STAT DATA AN, V15, P297, DOI 10.1016/0167-9473(93)90258-U; GRANVILLE V, 1992, STAT PROBABIL LETT, V14, P61, DOI 10.1016/0167-7152(92)90211-M; GRANVILLE V, 1991, IN PRESS 4TH P J SCI; GUYON X, 1985, CHAMPS STATIONNAIRES; HAJEK B, 1988, MATH OPER RES, V13, P311, DOI 10.1287/moor.13.2.311; JOHNSON ME, 1989, SIMULATED ANNEALING; LAARHOVEN V, 1987, SIMULATED ANNEALING; LAKSHMANAN S, 1989, IEEE T PATTERN ANAL, V11, P799, DOI 10.1109/34.31443; Varga RS., 1999, MATRIX ITERATIVE ANA	16	208	213	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1994	16	6					652	656		10.1109/34.295910	http://dx.doi.org/10.1109/34.295910			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NR972					2022-12-18	WOS:A1994NR97200010
J	Baydogan, MG; Runger, G; Tuv, E				Baydogan, Mustafa Gokce; Runger, George; Tuv, Eugene			A Bag-of-Features Framework to Classify Time Series	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Supervised learning; feature extraction; codebook	CLASSIFICATION; RECOGNITION; RETRIEVAL; MUSIC	Time series classification is an important task with many challenging applications. A nearest neighbor (NN) classifier with dynamic time warping (DTW) distance is a strong solution in this context. On the other hand, feature-based approaches have been proposed as both classifiers and to provide insight into the series, but these approaches have problems handling translations and dilations in local patterns. Considering these shortcomings, we present a framework to classify time series based on a bag-of-features representation (TSBF). Multiple subsequences selected from random locations and of random lengths are partitioned into shorter intervals to capture the local information. Consequently, features computed from these subsequences measure properties at different locations and dilations when viewed from the original series. This provides a feature-based approach that can handle warping (although differently from DTW). Moreover, a supervised learner (that handles mixed data types, different units, etc.) integrates location information into a compact codebook through class probability estimates. Additionally, relevant global features can easily supplement the codebook. TSBF is compared to NN classifiers and other alternatives (bag-of-words strategies, sparse spatial sample kernels, shapelets). Our experimental results show that TSBF provides better results than competitive methods on benchmark datasets from the UCR time series database.	[Baydogan, Mustafa Gokce] Secur & Def Syst Initiat, Tempe, AZ 85287 USA; [Runger, George] Arizona State Univ, Sch Comp Informat & Decis Syst Engn, Tempe, AZ 85281 USA; [Tuv, Eugene] Intel Corp, Log Technol Dev, Chandler, AZ 85226 USA	Arizona State University; Arizona State University-Tempe; Intel Corporation	Baydogan, MG (corresponding author), Secur & Def Syst Initiat, 781 E Terrace Rd, Tempe, AZ 85287 USA.	mbaydoga@asu.edu; runger@asu.edu	Baydogan, Mustafa Gokce/L-2736-2018	Baydogan, Mustafa Gokce/0000-0001-6324-6575	US Office of Naval Research [N00014-09-1-0656]	US Office of Naval Research(Office of Naval Research)	This research was partially supported by US Office of Naval Research grant no. N00014-09-1-0656.	Aucouturier JJ, 2007, J ACOUST SOC AM, V122, P881, DOI 10.1121/1.2750160; Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; Baydogan M. G., 2012, BAG OF FEATURES FRAM; Baydogan MG, 2012, THESIS ARIZONA STATE; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Briggs F, 2009, IEEE DATA MINING, P51, DOI 10.1109/ICDM.2009.65; Caruana R., 2008, P 25 INT C MACH LEAR, DOI DOI 10.1145/1390156.1390169; Casey M, 2008, IEEE T AUDIO SPEECH, V16, P1015, DOI 10.1109/TASL.2008.925883; Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Ding H, 2008, PROC VLDB ENDOW, V1, P1542; Dollar P, 2008, LECT NOTES COMPUT SC, V5303, P211, DOI 10.1007/978-3-540-88688-4_16; Eads D., 2005, P C NEUR INF PROC SY; Fergus R, 2003, PROC CVPR IEEE, P264; Fu TC, 2011, ENG APPL ARTIF INTEL, V24, P164, DOI 10.1016/j.engappai.2010.09.007; Fu ZY, 2011, PATTERN RECOGN LETT, V32, P1768, DOI 10.1016/j.patrec.2011.06.026; Geurts P., 2001, EUR C PRINC DAT MIN, P115, DOI DOI 10.1073/pnas.1311874111; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428; Jeong YS, 2011, PATTERN RECOGN, V44, P2231, DOI 10.1016/j.patcog.2010.09.022; Keogh E, 2003, DATA MIN KNOWL DISC, V7, P349, DOI 10.1023/A:1024988512476; Keogh E., 2011, UCR TIME SERIES CLAS; Kuksa P. P., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3320, DOI 10.1109/ICPR.2010.1159; Lewis D., P EUR C MACH LEARN, P4; Lin J, 2007, DATA MIN KNOWL DISC, V15, P107, DOI 10.1007/s10618-007-0064-z; Lin J, 2009, LECT NOTES COMPUT SC, V5566, P461, DOI 10.1007/978-3-642-02279-1_33; Lyon RF, 2010, NEURAL COMPUT, V22, P2390, DOI 10.1162/NECO_a_00011; Maron O., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P341; Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571; Moosmann F, 2008, IEEE T PATTERN ANAL, V30, P1632, DOI 10.1109/TPAMI.2007.70822; Mueen A., 2011, P 17 ACM SIGKDD INT, P1154, DOI [10.1145/2020408.2020587, DOI 10.1145/2020408.2020587]; Nanopoulos A, 2001, INFORMATION PROCESSING AND TECHNOLOGY, P49; Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490; Rahmani R, 2006, P 23 INT C MACH LEAR, P705, DOI DOI 10.1145/1143844.1143933; Ratanamahatana CA, 2004, SIAM PROC S, P11; Ratanamahatana CA, 2005, SIAM PROC S, P506; Raykar VC, 2008, P 25 INT C MACH LEAR, P808; Rodriguez J. J., 2001, Intelligent Data Analysis, V5, P245; Rodriguez J. J., 2004, P 2004 ACM S APPL CO, P548; Rodriguez JJ, 2005, KNOWL-BASED SYST, V18, P171, DOI 10.1016/j.knosys.2004.10.007; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Song YQ, 2005, IEEE IJCNN, P1142; Turnbull D, 2008, IEEE T AUDIO SPEECH, V16, P467, DOI 10.1109/TASL.2007.913750; Ueno K., 2007, P IEEE INT C DAT MIN, P623; Xing ZZ, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1297; Yamada Y., 2003, P 20 INT C MACH LEAR, P840; Ye LX, 2011, DATA MIN KNOWL DISC, V22, P149, DOI 10.1007/s10618-010-0179-5; Ye LX, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P947; Zhang Qi, 2002, P 19 INT C MACH LEAR, P682	50	207	215	2	79	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2013	35	11					2796	2802		10.1109/TPAMI.2013.72	http://dx.doi.org/10.1109/TPAMI.2013.72			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	223SU	24051736				2022-12-18	WOS:000324830900017
J	Schweighofer, G; Pinz, A				Schweighofer, Gerald; Pinz, Axel			Robust pose estimation from a planar target	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						camera pose ambiguity; pose tracking		In theory, the pose of a calibrated camera can be uniquely determined from a minimum of four coplanar but noncollinear points. In practice, there are many applications of camera pose tracking from planar targets and there is also a number of recent pose estimation algorithms which perform this task in real-time, but all of these algorithms suffer from pose ambiguities. This paper investigates the pose ambiguity for planar targets viewed by a perspective camera. We show that pose ambiguities - two distinct local minima of the according error function - exist even for cases with wide angle lenses and close range targets. We give a comprehensive interpretation of the two minima and derive an analytical solution that locates the second minimum. Based on this solution, we develop a new algorithm for unique and robust pose estimation from a planar target. In the experimental evaluation, this algorithm outperforms four state-of-the-art pose estimation algorithms.	Graz Univ Technol, Inst Elect Measurement & Measurement Signal Proc, A-8010 Graz, Austria	Graz University of Technology	Schweighofer, G (corresponding author), Graz Univ Technol, Inst Elect Measurement & Measurement Signal Proc, Kopernikusgasse 24-4, A-8010 Graz, Austria.	gerald.schweighofer@tugraz.at; axel.pinz@tugraz.at						ANSAR A, 2002, P EUR C COMP VIS, V4, P282; Araujo H, 1998, COMPUT VIS IMAGE UND, V70, P227, DOI 10.1006/cviu.1997.0632; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; HARRIS C, 1992, ACTIVE VISION, pCH16; Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809; KAWANO T, 2003, P 2 IEEE ACM INT S M; Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199; MALIK S, 2002, P C VIS INT; Moore R. E., 1996, METHOD APPL INTERVAL; Nister D, 2004, PROC CVPR IEEE, P652; Oberkampf D, 1996, COMPUT VIS IMAGE UND, V63, P495, DOI 10.1006/cviu.1996.0037; WROBEL B, 2001, CALIBRATION ORIENTAT, pCH2; Wunsch P., 1996, P 13 INT C PATT REC, V1, P78; Zettler M, 1998, IEEE T AUTOMAT CONTR, V43, P425, DOI 10.1109/9.661615; 2006, ARTOOLKIT PLUS	15	207	233	1	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2006	28	12					2024	2030		10.1109/TPAMI.2006.252	http://dx.doi.org/10.1109/TPAMI.2006.252			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	093UL	17108375				2022-12-18	WOS:000241195700011
J	Camastra, F; Verri, A				Camastra, F; Verri, A			A novel kernel method for clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						kernel methods; one class SVM; clustering algorithms; EM algorithm; K-means	EM ALGORITHM	Kernel Methods are algorithms that, by replacing the inner product with an appropriate positive definite function, implicitly perform a nonlinear mapping of the input data into a high-dimensional feature space. In this paper, we present a kernel method for clustering inspired by the classical K-Means algorithm in which each cluster is iteratively refined using a one-class Support Vector Machine. Our method, which can be easily implemented, compares favorably with respect to popular clustering algorithms, like K-Means, Neural Gas, and Self-Organizing Maps, on a synthetic data set and three UCI real data benchmarks ( IRIS data, Wisconsin breast cancer database, Spam database).	Univ Genoa, INFM, DISI, I-16146 Genoa, Italy	Consiglio Nazionale delle Ricerche (CNR); Istituto Nazionale per la Fisica della Materia (INFM-CNR); University of Genoa	Camastra, F (corresponding author), Univ Genoa, INFM, DISI, Via Dodecaneso 35, I-16146 Genoa, Italy.	camastra@ieee.org; verri@disi.unige.it		Camastra, Francesco/0000-0003-4439-7583				ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.1090/s0002-9947-1950-0051437-7; Bazaraa M.S., 1979, NONLINEAR PROGRAMMIN; Ben-Hur A., 2002, Journal of Machine Learning Research, V2, P125, DOI 10.1162/15324430260185565; Berg C., 1984, HARMONIC ANAL SEMIGR; Bishop, 1995, NEURAL NETWORKS PATT; Cristianini N., 2000, INTRO SUPPORT VECTOR; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Girolami M, 2002, IEEE T NEURAL NETWOR, V13, P780, DOI 10.1109/TNN.2002.1000150; Gray R. M., 1992, VECTOR QUANTIZATION; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Kohonen T., 1997, SELF ORG MAP; LLOYD SP, 1982, IEEE T COMMUN, V28, P84; MARTINETZ TM, 1993, IEEE T NEURAL NETWOR, V4, P558, DOI 10.1109/72.238311; MEILA M, 2003, 418 U WASH DEP STAT; Ng AY, 2002, ADV NEUR IN, V14, P849; Schlkopf B., 1999, ADV NEURAL INFORMATI, P526; Scholkopf B., 1996, 44 M PLANCK I BIOL K; Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2; Vapnik V.N, 1998, STAT LEARNING THEORY; WOLBERG WH, 1990, P NATL ACAD SCI USA, V87, P9193, DOI 10.1073/pnas.87.23.9193; WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060	23	207	240	2	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2005	27	5					801	U4		10.1109/TPAMI.2005.88	http://dx.doi.org/10.1109/TPAMI.2005.88			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	905LI	15875800				2022-12-18	WOS:000227569300012
J	Yan, CG; Gong, B; Wei, YX; Gao, Y				Yan, Chenggang; Gong, Biao; Wei, Yuxuan; Gao, Yue			Deep Multi-View Enhancement Hashing for Image Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image retrieval; Binary codes; Machine learning; Training; Feature extraction; Neural networks; Stability analysis; Multi-view hashing; multi-view enhancement; image retrieval	ITERATIVE QUANTIZATION; PROCRUSTEAN APPROACH; NEURAL-NETWORKS; BINARY-CODES; SCALE	Hashing is an efficient method for nearest neighbor search in large-scale data space by embedding high-dimensional feature descriptors into a similarity preserving Hamming space with a low dimension. However, large-scale high-speed retrieval through binary code has a certain degree of reduction in retrieval accuracy compared to traditional retrieval methods. We have noticed that multi-view methods can well preserve the diverse characteristics of data. Therefore, we try to introduce the multi-view deep neural network into the hash learning field, and design an efficient and innovative retrieval model, which has achieved a significant improvement in retrieval performance. In this paper, we propose a supervised multi-view hash model which can enhance the multi-view information through neural networks. This is a completely new hash learning method that combines multi-view and deep learning methods. The proposed method utilizes an effective view stability evaluation method to actively explore the relationship among views, which will affect the optimization direction of the entire network. We have also designed a variety of multi-data fusion methods in the Hamming space to preserve the advantages of both convolution and multi-view. In order to avoid excessive computing resources on the enhancement procedure during retrieval, we set up a separate structure called memory network which participates in training together. The proposed method is systematically evaluated on the CIFAR-10, NUS-WIDE and MS-COCO datasets, and the results show that our method significantly outperforms the state-of-the-art single-view and multi-view hashing methods.	[Yan, Chenggang; Gong, Biao] Hangzhou Dianzi Univ, Hangzhou 310018, Zhejiang, Peoples R China; [Yan, Chenggang] Shandong Univ, Sch Mech Elect & Informat Engn, Weihai 264209, Shandong, Peoples R China; [Wei, Yuxuan; Gao, Yue] Tsinghua Univ, Sch Software, KLISS, BNRist, Beijing 100084, Peoples R China	Hangzhou Dianzi University; Shandong University; Tsinghua University	Gao, Y (corresponding author), Tsinghua Univ, Sch Software, KLISS, BNRist, Beijing 100084, Peoples R China.	cgyan@hdu.edu.cn; a.biao.gong@gmail.com; weiyuxua19@mails.tsinghua.edu.cn; gaoyue@tsinghua.edu.cn		Gong, Biao/0000-0002-6156-0816	National Nature Science Foundation of China [61931008, 61671267, 61671196, 61701149, 61801157, 61971268, 61901145, 61901150, 61972123]; National Natural Science Major Foundation of Research Instrumentation of PR China [61427808]; Zhejiang Province Nature Science Foundation of China [LR17F030006, Q19F010030]; 111 Project [D17019]	National Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Natural Science Major Foundation of Research Instrumentation of PR China; Zhejiang Province Nature Science Foundation of China; 111 Project(Ministry of Education, China - 111 Project)	This work is supported by National Nature Science Foundation of China (61931008, 61671267, 61671196, 61701149, 61801157, 61971268, 61901145, 61901150, 61972123), National Natural Science Major Foundation of Research Instrumentation of PR China under Grants 61427808, Zhejiang Province Nature Science Foundation of China (LR17F030006,Q19F010030), 111 Project, No. D17019.	Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Banerjee SJ, 2015, SCI REP-UK, V5, DOI 10.1038/srep17271; Cao Y, 2018, PROC CVPR IEEE, P1229, DOI 10.1109/CVPR.2018.00134; Cao ZJ, 2017, IEEE I CONF COMP VIS, P5609, DOI 10.1109/ICCV.2017.598; Chen ZX, 2018, PROC CVPR IEEE, P6838, DOI 10.1109/CVPR.2018.00715; Chen ZX, 2018, PATTERN RECOGN, V75, P149, DOI 10.1016/j.patcog.2017.02.026; Chua T.-S., 2009, P ACM INT C IM VID R, P1, DOI 10.1145/1646396.1646452; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Gu W, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P159, DOI 10.1145/3323873.3325045; Hu MQ, 2019, IEEE T IMAGE PROCESS, V28, P2770, DOI 10.1109/TIP.2018.2890144; Jia K, 2019, IEEE T IMAGE PROCESS, V28, P5121, DOI 10.1109/TIP.2019.2912356; Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348; Kim S, 2013, INT CONF ACOUST SPEE, P3123, DOI 10.1109/ICASSP.2013.6638233; Krizhevsky Alex., 2009, LEARNING MULTIPLE LA, P6; Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466; Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu L, 2015, IEEE T IMAGE PROCESS, V24, P956, DOI 10.1109/TIP.2015.2390975; Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16; Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887; Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598; Shen FM, 2015, IEEE T IMAGE PROCESS, V24, P1839, DOI 10.1109/TIP.2015.2405340; Shen XB, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3178119; Shen XB, 2017, IEEE T CYBERNETICS, V47, P4275, DOI 10.1109/TCYB.2016.2606441; Shen XB, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P831, DOI 10.1145/2733373.2806342; Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Wang JD, 2018, IEEE T PATTERN ANAL, V40, P769, DOI 10.1109/TPAMI.2017.2699960; Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824; Xia RK, 2014, AAAI CONF ARTIF INTE, P2156; Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133; Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345; Yan CG, 2020, IEEE T MULTIMEDIA, V22, P3014, DOI 10.1109/TMM.2020.2967645; Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576; Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448; Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320; Zhang CH, 2017, IEEE T IMAGE PROCESS, V26, P2604, DOI 10.1109/TIP.2017.2675205; Zhang D, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P225; Zhang PC, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P173, DOI 10.1145/2600428.2609600; Zhen Y, 2016, IEEE T CYBERNETICS, V46, P27, DOI 10.1109/TCYB.2015.2392052; Zhu H, 2016, AAAI CONF ARTIF INTE, P2415; Zhu XF, 2021, IEEE T KNOWL DATA EN, V33, P2425, DOI 10.1109/TKDE.2019.2956530; Zhu XF, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2019.107175	50	206	209	10	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2021	43	4					1445	1451		10.1109/TPAMI.2020.2975798	http://dx.doi.org/10.1109/TPAMI.2020.2975798			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QT3YJ	32091992	Green Submitted			2022-12-18	WOS:000626525300024
J	Xu, C; Tao, DC; Xu, C				Xu, Chang; Tao, Dacheng; Xu, Chao			Large-Margin Multi-View Information Bottleneck	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-view learning; large-margin learning; information bottleneck		In this paper, we extend the theory of the information bottleneck (IB) to learning from examples represented by multi-view features. We formulate the problem as one of encoding a communication system with multiple senders, each of which represents one view of the data. Based on the precise components filtered out from multiple information sources through a "bottleneck", a margin maximization approach is then used to strengthen the discrimination of the encoder by improving the code distance within the frame of coding theory. The resulting algorithm therefore inherits all the merits of the IB principle and coding theory. It has two distinct advantages over existing algorithms, namely, that our method finds a tradeoff between the accuracy and complexity of the multi-view model, and that the encoded multi-view data retains sufficient discrimination for classification. We also derive the robustness and generalization error bound of the proposed algorithm, and reveal the specific properties of multi-view learning. First, the complementarity of multi-view features guarantees the robustness of the algorithm. Second, the consensus of multi-view features reduces the empirical Rademacher complexity of the objective function, enhances the accuracy of the solution, and improves the generalization error bound of the algorithm. The resulting objective function is solved efficiently using the alternating direction method. Experimental results on annotation, classification and recognition tasks demonstrate that the proposed algorithm is promising for practical applications.	[Xu, Chang; Xu, Chao] Peking Univ, Minist Educ, Key Lab Machine Percept, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China; [Tao, Dacheng] Univ Technol, Ctr Quantum Computat & Intelligent Syst, Ultimo, NSW 2007, Australia; [Tao, Dacheng] Univ Technol, Fac Engn & Informat Technol, Ultimo, NSW 2007, Australia	Peking University; University of Technology Sydney; University of Technology Sydney	Xu, C (corresponding author), Peking Univ, Minist Educ, Key Lab Machine Percept, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China.	changxu1989@gmail.com; dacheng.tao@uts.edu.au; xuchao@cis.pku.edu.cn	Xu, Chang/AAG-9337-2019	Xu, Chang/0000-0002-4756-0609	Australian Research Council [FT130101457, DP140102164]; NBRPC [2011CB302400]; NSFC [61121002, 61375026]; JCYJ [20120614152136201]	Australian Research Council(Australian Research Council); NBRPC(National Basic Research Program of China); NSFC(National Natural Science Foundation of China (NSFC)); JCYJ	The authors greatly thank the handling Associate Editor and all anonymous reviewers for their positive support and constructive comments for improving the quality of this paper. The work was supported in part by Australian Research Council Projects FT130101457 and DP140102164, NBRPC 2011CB302400, NSFC 61121002, 61375026, and JCYJ 20120614152136201.	Akaho S., 2006, CS0609071; Archambeau C., 2008, P ADV NEUR INF PROC; Bach F. R., 2005, 688 U CAL DEP STAT; Bartlett P. L., 2003, Journal of Machine Learning Research, V3, P463, DOI 10.1162/153244303321897690; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Chaudhuri K., 2009, PROC INT C MACHINE L, P129, DOI DOI 10.1145/1553374.1553391; Chen N, 2012, IEEE T PATTERN ANAL, V34, P2365, DOI 10.1109/TPAMI.2012.64; Chen Ning, 2010, P ADV NEUR INF PROC, P361; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI 10.1002/0471200611; Damianou A., 2012, ARXIV12064610; Diethe T., 2008, P WORKSH LEARN MULT; Diethe T, 2010, LECT NOTES ARTIF INT, V6321, P328, DOI 10.1007/978-3-642-15880-3_27; Eckstein J., 2011, FDN TRENDS MACH LEAR, V3, P1, DOI DOI 10.1561/2200000016; Farquhar J., 2005, P ADV NEUR INF PROC; Globerson A, 2003, Journal of Machine Learning Research, V3, P1307, DOI 10.1162/153244303322753689; Guillaumin M., 2010, P IEEE C COMP VIS PA; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; He BS, 2012, SIAM J NUMER ANAL, V50, P700, DOI 10.1137/110836936; Hussain Z., 2011, P INT C ART INT STAT; Jia Y., 2010, P ADV NEUR INF PROC; Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]; Kakade SM, 2007, LECT NOTES COMPUT SC, V4539, P82, DOI 10.1007/978-3-540-72927-3_8; Kuehne H., 2011, P INT C COMP VIS, DOI DOI 10.1109/ICCV.2011.6126543; Lin Z., 2010, 10095055; Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302; Lu Y., 2012, CORR; Luo Y, 2013, IEEE T NEUR NET LEAR, V24, P709, DOI 10.1109/TNNLS.2013.2238682; Memisevic R., 2006, P 23 INT C MACH LEAR; Memisevic R, 2012, IEEE T PATTERN ANAL, V34, P778, DOI 10.1109/TPAMI.2011.154; Morik K., 1999, P 16 INT C MACH LEAR; Nesterov Y, 2005, MATH PROGRAM, V103, P127, DOI 10.1007/s10107-004-0552-5; Nigam K., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P86, DOI 10.1145/354756.354805; Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491; Sen P, 2008, AI MAG, V29, P93, DOI 10.1609/aimag.v29i3.2157; Sindhwani V., 2005, P 22 INT C MACH LEAR, P824, DOI DOI 10.1145/1102351.1102455; Smola A. J., 2000, ADV LARGE MARGIN CLA; Song Y, 2012, PROC CVPR IEEE, P2120, DOI 10.1109/CVPR.2012.6247918; Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531; Suzuki T., 2010, P INT C ART INT STAT; Tishby Naftali, 2000, PHYSICS0004057 ARXIV; Torresani L., 2006, P ADV NEUR INF PROC; Wang XC, 2013, IEEE T IMAGE PROCESS, V22, P2646, DOI 10.1109/TIP.2013.2255300; Xie B, 2011, IEEE T SYST MAN CY B, V41, P1088, DOI 10.1109/TSMCB.2011.2106208; Xu C, 2013, P 5 INT C INT MULT C; Xu C., 2013, 13045634; Xu H, 2012, MACH LEARN, V86, P391, DOI 10.1007/s10994-011-5268-1; Ye G.-B., 2011, P INT C ART INT STAT; Yu J, 2012, IEEE T IMAGE PROCESS, V21, P4636, DOI 10.1109/TIP.2012.2207395; Zhang C., 2012, P INT C ART INT STAT; Zhu J., 2009, P 26 ANN INT C MACH	53	206	212	0	48	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2014	36	8					1559	1572		10.1109/TPAMI.2013.2296528	http://dx.doi.org/10.1109/TPAMI.2013.2296528			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9HN	26353338				2022-12-18	WOS:000340191900006
J	Sun, LA; Ji, SW; Ye, JP				Sun, Liang; Ji, Shuiwang; Ye, Jieping			Canonical Correlation Analysis for Multilabel Classification: A Least-Squares Formulation, Extensions, and Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Canonical correlation analysis; least squares; multilabel learning; partial least squares; regularization		Canonical Correlation Analysis (CCA) is a well-known technique for finding the correlations between two sets of multidimensional variables. It projects both sets of variables onto a lower-dimensional space in which they are maximally correlated. CCA is commonly applied for supervised dimensionality reduction in which the two sets of variables are derived from the data and the class labels, respectively. It is well-known that CCA can be formulated as a least-squares problem in the binary class case. However, the extension to the more general setting remains unclear. In this paper, we show that under a mild condition which tends to hold for high-dimensional data, CCA in the multilabel case can be formulated as a least-squares problem. Based on this equivalence relationship, efficient algorithms for solving least-squares problems can be applied to scale CCA to very large data sets. In addition, we propose several CCA extensions, including the sparse CCA formulation based on the 1-norm regularization. We further extend the least-squares formulation to partial least squares. In addition, we show that the CCA projection for one set of variables is independent of the regularization on the other set of multidimensional variables, providing new insights on the effect of regularization on CCA. We have conducted experiments using benchmark data sets. Experiments on multilabel data sets confirm the established equivalence relationships. Results also demonstrate the effectiveness and efficiency of the proposed CCA extensions.	[Sun, Liang] Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA; Arizona State Univ, Ctr Evolutionary Med & Informat, Biodesign Inst, Tempe, AZ 85287 USA	Arizona State University; Arizona State University-Tempe; Arizona State University; Arizona State University-Tempe	Sun, LA (corresponding author), Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA.	sun.liang@asu.edu; shuiwang.ji@asu.edu; jieping.ye@asu.edu	Sun, Liang/L-8630-2013	Ji, Shuiwang/0000-0002-4205-4563	US National Science Foundation (NSF) [IIS-0612069, IIS-0812551, IIS-0953662, NIH R01-HG002516, NGA HM1582-08-1-0016]; NATIONAL HUMAN GENOME RESEARCH INSTITUTE [R01HG002516] Funding Source: NIH RePORTER	US National Science Foundation (NSF)(National Science Foundation (NSF)); NATIONAL HUMAN GENOME RESEARCH INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Human Genome Research Institute (NHGRI))	This research was sponsored by the US National Science Foundation (NSF) IIS-0612069, IIS-0812551, IIS-0953662, NIH R01-HG002516, and NGA HM1582-08-1-0016.	Bach F.R., 2005, PROBABILISTIC INTERP; Bach FR, 2003, J MACH LEARN RES, V3, P1, DOI 10.1162/153244303768966085; Barker M, 2003, J CHEMOMETR, V17, P166, DOI 10.1002/cem.785; Bishop C.M, 2006, PATTERN RECOGN; Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009; DASPREMONT A, 2004, P ANN C NEUR INF PRO, V16, P41; Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Hardoon D., 2004, NEURAL COMPUTATION, V16; HARDOON D, 2006, THESIS U SOUTHAMPTON; Hardoon D. R., 2003, P 3 INT WORKSH CONT; HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Kazawa H., 2005, ADV NEURAL INFORM PR, V17, P649; Lai EC, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-7-r42; Liu J., 2009, SLEP SPARSE LEARNING; PAIGE CC, 1982, ACM T MATH SOFTWARE, V8, P43, DOI 10.1145/355984.355989; Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2; Saad Y, 1992, NUMERICAL METHODS LA; Scholkopf B., 2001, LEARNING KERNELS SUP; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Sriperumbudur B. K., 2007, P 24 INT C MACH LEAR, P831; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Vert J. P., 2003, ADV NEURAL INFORMATI, P1425; Watkins SD, 2005, FUNDAMENTALS MATRIX; Worsley KJ, 1997, NEUROIMAGE, V6, P305, DOI 10.1006/nimg.1997.0294; Yang Yiming, 1997, P 14 INT C MACHINE L, P412, DOI DOI 10.1016/J.ESWA.2008.05.026; Ye J., 2007, P 24 INT C MACH LEAR, P1087, DOI DOI 10.1145/1273496.1273633; Yu SP, 2006, IEEE T KNOWL DATA EN, V18, P1600, DOI 10.1109/TKDE.2006.194; ZHU J, 2003, P ANN C NEUR INF PRO, V15, P49	32	206	223	1	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2011	33	1					194	U204		10.1109/TPAMI.2010.160	http://dx.doi.org/10.1109/TPAMI.2010.160			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	681AC	20733223				2022-12-18	WOS:000284277600015
J	Gao, DS; Han, S; Vasconcelos, N				Gao, Dashan; Han, Sunhyoung; Vasconcelos, Nuno			Discriminant Saliency, the Detection of Suspicious Coincidences, and Applications to Visual Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual saliency; interest point detection; coincidence detection; visual recognition; object detection from cluttered scenes; infomax feature selection; saliency measures; natural image statistics	OBJECT RECOGNITION; ATTENTION; FEATURES; MODEL; COMPRESSION; TEXTURE; CONTEXT; SCALE	A discriminant formulation of top-down visual saliency, intrinsically connected to the recognition problem, is proposed. The new formulation is shown to be closely related to a number of classical principles for the organization of perceptual systems, including infomax, inference by detection of suspicious coincidences, classification with minimal uncertainty, and classification with minimum probability of error. The implementation of these principles with computational parsimony, by exploitation of the statistics of natural images, is investigated. It is shown that Barlow's principle of inference by the detection of suspicious coincidences enables computationally efficient saliency measures which are nearly optimal for classification. This principle is adopted for the solution of the two fundamental problems in discriminant saliency: feature selection and saliency detection. The resulting saliency detector is shown to have a number of interesting properties, and acts effectively as a focus of attention mechanism for the selection of interest points according to their relevance for visual recognition. Experimental evidence shows that the selected points have good performance with respect to 1) the ability to localize objects embedded in significant amounts of clutter, 2) the ability to capture information relevant for image classification, and 3) the richness of the set of visual attributes that can be considered salient.	[Gao, Dashan] Gen Elect Global Res, Visualizat & Comp Vis Lab, Niskayuna, NY 12309 USA; [Han, Sunhyoung; Vasconcelos, Nuno] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA	General Electric; University of California System; University of California San Diego	Gao, DS (corresponding author), Gen Elect Global Res, Visualizat & Comp Vis Lab, 1 Res Circle,KW C412, Niskayuna, NY 12309 USA.	gaoda@ge.com; s1han@ucsd.edu; nuno@ece.ucsd.edu		Vasconcelos, Nuno/0000-0002-9024-4302	US National Science Foundation (NSF) [IIS-0448609, CCF0830535]	US National Science Foundation (NSF)(National Science Foundation (NSF))	The authors would like to acknowledge Dr. Jianguo Zhang for suggestions on the implementation of the classifier of [13]. The work was partially funded by US National Science Foundation (NSF) award IIS-0448609 and NSF award CCF0830535. This work was performed while D. Gao was with the Department of Electrical and Computer Engineering, University of California, San Diego.	ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; Barlow H, 2001, NETWORK-COMP NEURAL, V12, P241, DOI 10.1088/0954-898X/12/3/301; Barlow H. B., 1985, Models of the visual cortex, P37; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; BINFORD TO, 1981, ARTIF INTELL, V17, P205, DOI 10.1016/0004-3702(81)90025-4; BOUVEYRON C, 2006, P IND C VIS GRAPH IM; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; Buccigrossi RW, 1999, IEEE T IMAGE PROCESS, V8, P1688, DOI 10.1109/83.806616; CHUM O, 2007, P IEEE C COMP VIS PA, V1, P1; Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822; Dorko G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P634; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Everingham M, 2009, PASCAL VISUAL OBJECT; Fergus R, 2005, IEEE I CONF COMP VIS, P1816; Fergus R., 2003, P IEEE C COMP VIS PA; Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144; FORSTNER W, 1994, P EUR C COMP VIS, P383; GAO D, 2007, P 3 INT WORKSH ATT P, P184; Gao DS, 2009, NEURAL COMPUT, V21, P239, DOI 10.1162/neco.2009.11-06-391; Gao D, 2008, J VISION, V8, DOI 10.1167/8.7.13; Gao DS, 2005, PROC CVPR IEEE, P282; HAN S, 2008, P IEEE INT C IM PROC; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Heidemann G, 2004, IEEE T PATTERN ANAL, V26, P817, DOI 10.1109/TPAMI.2004.29; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Huang J G, 1999, P 1999 IEEE COMP VIS, P541; Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jurie F., 2005, P INT C COMP VIS; Kadir T, 2004, LECT NOTES COMPUT SC, V3021, P228; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; KOCH C, 1985, HUM NEUROBIOL, V4, P219; Lazebnik S., 2006, P IEEE CS C COMP VIS; LINSKER R, 1988, COMPUTER, V21, P105, DOI 10.1109/2.36; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; MALLAT S, 1989, IEEE T PATTERN ANAL, V11, P7; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Mladenic D., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P234, DOI 10.1145/1008992.1009034; MODESTINO JW, 1977, NONPARAMETRIC METHOD, P29; Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490; Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009; Opelt A, 2006, IEEE T PATTERN ANAL, V28, P416, DOI 10.1109/TPAMI.2006.54; Palmer S.E., 1999, VISION SCI PHOTONS P; POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231; Quelhas P, 2007, IEEE T PATTERN ANAL, V29, P1575, DOI 10.1109/TPAMI.2007.1155; REISFELD D, 1995, INT J COMPUT VISION, V14, P119, DOI 10.1007/BF01418978; Sebe N, 2003, PATTERN RECOGN LETT, V24, P89, DOI 10.1016/S0167-8655(02)00192-7; SHARIFI K, 1995, IEEE T CIRC SYST VID, V5, P52, DOI 10.1109/76.350779; Shic F, 2007, INT J COMPUT VISION, V73, P159, DOI 10.1007/s11263-006-9784-6; Sivic J, 2005, IEEE I CONF COMP VIS, P370; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; TSOTSOS JK, 1995, ARTIF INTELL, V78, P507, DOI 10.1016/0004-3702(95)00025-9; Ullman S., 1988, P 2 INT C COMP VIS, P321, DOI DOI 10.1109/CCV.1988.590008; Vasconcelos M., 2006, P IEEE C COMP VIS PA, P1001; Vasconcelos M, 2009, IEEE T PATTERN ANAL, V31, P228, DOI 10.1109/TPAMI.2008.77; VASCONCELOS N, 2002, P ANN C NEUR INF PRO; VASCONCELOS N, 2002, P EUR C COMP VIS; VIDALNAQUET M, 2003, P IEEE INT C COMP VI; Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001; WOLFE JM, 1994, PSYCHON B REV, V1, P202, DOI 10.3758/BF03200774; Yamada K., 1995, P 17 ANN C COGN SCI, P55; Yarbus A. L., 1967, EYE MOVEMENTS VISION, P171; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4	67	206	226	2	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2009	31	6					989	1005		10.1109/TPAMI.2009.27	http://dx.doi.org/10.1109/TPAMI.2009.27			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431YF	19372605	Green Submitted			2022-12-18	WOS:000265100000003
J	Lee, J; Lee, D				Lee, J; Lee, D			An improved cluster labeling method for support vector clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						clustering; unsupervised learning method; support vector machines		The support vector clustering (SVC) algorithm is a recently emerged unsupervised learning method inspired by support vector machines. One key step involved in the SVC algorithm is the cluster assignment of each data point. A new cluster labeling method for SVC is developed based on some invariant topological properties of a trained kernel radius function. Benchmark results show that the proposed method outperforms previously reported labeling techniques.	Pohang Univ Sci & Technol, Dept Ind Engn, Informat Lab, Pohang 790784, Kyungbuk, South Korea	Pohang University of Science & Technology (POSTECH)	Lee, J (corresponding author), Pohang Univ Sci & Technol, Dept Ind Engn, Informat Lab, Pohang 790784, Kyungbuk, South Korea.	jaewookl@postech.ac.kr; woosuhan@postech.ac.kr	Lee, Jaewook/A-7355-2013; LEE, Daewon/GWZ-8418-2022; Lee, Jaewook/A-8862-2012	Lee, Jaewook/0000-0001-5720-8337; 				Ben-Hur A., 2002, Journal of Machine Learning Research, V2, P125, DOI 10.1162/15324430260185565; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; GEORGESCU B, 2003, P 9 INT C COMP VIS; Guckenheimer J., 1986, APPL MATH SCI, V42; Khalil H. K., 1992, NONLINEAR SYSTEMS; Lee J, 2004, IEEE T AUTOMAT CONTR, V49, P888, DOI 10.1109/TAC.2004.829603; LEE J, 1999, THESIS CORNELL U NEW; Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2; Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640; Yang JH, 2002, ICONIP'02: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING, P898	11	206	223	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2005	27	3					461	464		10.1109/TPAMI.2005.47	http://dx.doi.org/10.1109/TPAMI.2005.47			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	887IW	15747800				2022-12-18	WOS:000226300200014
J	Zhong, Y; Zhang, HJ; Jain, AK				Zhong, Y; Zhang, HJ; Jain, AK			Automatic caption localization in compressed video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						caption extraction; text location; texture; compressed video; segmentation; multimedia	TEXT; IMAGES; SEGMENTATION	We present a method to automatically localize captions in JPEG compressed images and the I-frames of MPEG compressed videos. Caption text regions are segmented from background images using their distinguishing texture characteristics. Unlike previously published methods which fully decompress the video sequence before extracting the text regions, this method locates candidate caption text regions directly in the DCT compressed domain using the intensity variation information encoded in the DCT domain. Therefore, only a very small amount of decoding is required. The proposed algorithm takes about 0.006 second to process a 240 x 350 image and achieves a recall rate of 99.17 percent while falsely accepting about 1.87 percent nontext DCT blocks on a variety of MPEG compressed videos containing more than 2,300 I-frames.	Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; Hewlett Packard Corp, Internet Syst & Applicat Lab, Palo Alto, CA 94040 USA; Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Carnegie Mellon University; Hewlett-Packard; Michigan State University	Zhong, Y (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.	zhongyu@cs.cmu.edu; hjzhang@hpl.hp.com; jain@cse.msu.edu						CHRISTEL M, 1994, P ACM MULT C OCT, P480; Gargi U, 1998, INT C PATT RECOG, P916, DOI 10.1109/ICPR.1998.711301; Hauptmann A. G., 1995, AAAI S COMP MOD INT; Jain A. K., 1992, Machine Vision and Applications, V5, P169, DOI 10.1007/BF02626996; Jain AK, 1998, PATTERN RECOGN, V31, P2055, DOI 10.1016/S0031-3203(98)00067-3; Jain AK, 1996, PATTERN RECOGN, V29, P743, DOI 10.1016/0031-3203(95)00131-X; Lee SW, 1996, IEEE T PATTERN ANAL, V18, P1045, DOI 10.1109/34.541415; LEGALL D, 1991, COMMUN ACM, V34, P46, DOI 10.1145/103085.103090; LIENHART R, 1996, P PRAKT INF, V4, P68; OHYA J, 1994, IEEE T PATTERN ANAL, V16, P214, DOI 10.1109/34.273729; Sethi I. K., 1995, Proceedings of the SPIE - The International Society for Optical Engineering, V2420, P329, DOI 10.1117/12.205299; Shen B, 1996, J VIS COMMUN IMAGE R, V7, P411, DOI 10.1006/jvci.1996.0035; Shim JC, 1998, INT C PATT RECOG, P618, DOI 10.1109/ICPR.1998.711219; SMITH MA, 1995, VIDEO SKIMMING CHARA; WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089; Wu V, 1997, ACM DIGITAL LIBRARIES '97, P3; YEO BL, 1995, SPIE DIGITAL VIDEO C; Zhang H., 1995, Multimedia Tools and Applications, V1, P89, DOI 10.1007/BF01261227; ZHANG H, 1994, P IS T SPIE S ELECTR, P140; ZHANG HJ, 1995, P ACM MULT 95 SAN FR, P15, DOI DOI 10.1145/217279.215068; ZHONG Y, 1995, PATTERN RECOGN, V28, P1523, DOI 10.1016/0031-3203(95)00030-4; [No title captured]	22	206	242	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2000	22	4					385	392		10.1109/34.845381	http://dx.doi.org/10.1109/34.845381			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	317WT					2022-12-18	WOS:000087250500008
J	Pittner, S; Kamarthi, SV				Pittner, S; Kamarthi, SV			Feature extraction from wavelet coefficients for pattern recognition tasks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						feature extraction; fast wavelet transform; signal interpretation	NEURAL NETWORKS; CLASSIFICATION	In this paper, a new efficient feature extraction method based on the fast wavelet transform is presented. This paper especially deals with the assessment of process parameters or states in a given application using the features extracted from the wavelet coefficients of measured process signals. Since the parameter assessment using all wavelet coefficients will often turn out to be tedious or leads to inaccurate results, a preprocessing routine that computes robust features correlated to the process parameters of interest is highly desirable. The method presented divides the matrix of computed wavelet coefficients into clusters equal to rowvectors. The rows that represent important frequency ranges (for signal interpretation) have a larger number of clusters than the rows that represent less important frequency ranges. The features of a process signal are eventually calculated by the euclidean norms of the clusters. The effectiveness of this new method has been verified on a flank wear estimation problem in turning processes and on a problem of recognizing different kinds of lung sounds for diagnosis of pulmonary diseases.	Northeastern Univ, Dept Mech Ind & Mgf Engn, Snell Engn Ctr 334, Boston, MA 02115 USA	Northeastern University	Pittner, S (corresponding author), Northeastern Univ, Dept Mech Ind & Mgf Engn, Snell Engn Ctr 334, Boston, MA 02115 USA.							Bishop, 1995, NEURAL NETWORKS PATT; Chui C.K., 1992, INTRO WAVELETS; DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705; Daubechies I., 1992, 10 LECT WAVELETS, DOI [10.1137/1.9781611970104.ch1, DOI 10.1137/1.9781611970104.CH1]; FU KS, 1976, DIGITAL PATTERN RECO; Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891; KALAYCI T, 1995, IEEE ENG MED BIOL, V14, P160, DOI 10.1109/51.376754; Kamarthi SV, 1997, MECH SYST SIGNAL PR, V11, P791, DOI 10.1006/mssp.1997.0106; KAMARTHI SV, IN PRESS J ENG IND; LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679; Lippmann R. P., 1988, Computer Architecture News, V16, P7, DOI [10.1109/MASSP.1987.1165576, 10.1145/44571.44572]; Livens S., 1995, Computer Analysis of Images and Patterns. 6th International Conference, CAIP'95. Proceedings, P538; Looney C.G., 1997, PATTERN RECOGN; Mallet Y, 1997, IEEE T PATTERN ANAL, V19, P1058, DOI 10.1109/34.625106; Mitrinovic, 1970, ANAL INEQUALITIES, V1; NICOLAS JM, 1990, REV GEN ELECTR, V5, P43; PETROSIAN A, 1995, P SOC PHOTO-OPT INS, V2569, P189, DOI 10.1117/12.217574; Pittner S, 1998, J INTELL MANUF, V9, P315, DOI 10.1023/A:1008970608121; PITTNER S, 1997, INTELLIGENT ENG SYST, V7, P561; PITTNER S, 1998, INTELLIGENT ENG SYST, V8, P479; PITTNER S, 1994, THESIS VIENNA U TECH; Ripley BD., 1996; Schalkoff R, 1992, PATTERN RECOGN; Sen P. K., 1993, LARGE SAMPLE METHODS; TANSEL IN, 1995, INT J MACH TOOL MANU, V35, P1137; TANSEL IN, 1993, INT J MACH TOOL MANU, V33, P559, DOI 10.1016/0890-6955(93)90092-9; Tou J.T., 1981, PATTERN RECOGNITION; Wu Y, 1996, MECH SYST SIGNAL PR, V10, P29, DOI 10.1006/mssp.1996.0003	28	206	222	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1999	21	1					83	88		10.1109/34.745739	http://dx.doi.org/10.1109/34.745739			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	163DZ					2022-12-18	WOS:000078388900012
J	COHEN, FS; FAN, ZG; PATEL, MA				COHEN, FS; FAN, ZG; PATEL, MA			CLASSIFICATION OF ROTATED AND SCALED TEXTURED IMAGES USING GAUSSIAN MARKOV RANDOM FIELD MODELS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CRAMER-RAO BOUND; FISHER INFORMATION MATRIX; MAXIMUM LIKELIHOOD ESTIMATION; ROTATION; SCALE; STATIONARY GAUSSIAN MARKOV RANDOM FIELDS; TEXTURE; 2-D DFT	SPATIAL-INTERACTION	This correspondence concerns the problem of classifying a test textured image that is obtained from one of C possible parent texture classes, after possibly applying unknown rotation and scale changes to the parent texture. The training texture images (parent classes) are modeled by Gaussian Markov random fields (GMRF's). To classify a rotated and scaled test texture, we incorporate the rotation and scale changes in the texture model through an appropriate transformation of the power spectral density of the GMRF. For the rotated and scaled image, a bona fide likelihood function that shows the explicit dependence of the likelihood function on the GMRF parameters, as well as on the rotation and scale parameters, is derived. Although, in general, the scaled and/or rotated texture does not correspond to a finite-order GMRF, we are able nonetheless to write down a likelihood function for the image data. The likelihood function of the discrete Fourier transform of the image data corresponds to that of a white nonstationary Gaussian random field, with the variance at each pixel (i,j) being a known function of the rotation, the scale, the GMRF model parameters, and (i,j). The variance is an explicit function of the appropriately sampled power spectral density of the GMRF. The estimation of the rotation and scale parameters is performed in the frequency domain by maximizing the likelihood function associated with the discrete Fourier transform of the image data. Cramer-Rao error bounds on the scale and rotation estimates are easily computed. A modified Bayes decision rule is used to classify a given test image into one of C possible texture classes. The classification power of the method is demonstrated through experimental results on natural textures from the Brodatz album.	XEROX CORP, WEBSTER RES CTR, WEBSTER, NY 14580 USA	Xerox	COHEN, FS (corresponding author), DREXEL UNIV, DEPT ELECT & COMP ENGN, PHILADELPHIA, PA 19104 USA.							BAJCSY R, 1973, 3RD P INT JOINT C AR, P572; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1975, BIOMETRIKA, V62; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; CHIN RT, 1982, IEEE T PATTERN ANAL, V4, P557, DOI 10.1109/TPAMI.1982.4767309; CONNERS R, 1979, P IEEE C PATTERN REC; CONNERS RW, 1980, IEEE T PATTERN ANAL, V2, P204, DOI 10.1109/TPAMI.1980.4767008; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P251, DOI 10.1109/TPAMI.1979.4766921; Davis P. J., 1979, CIRCULANT MATRICES; Galloway MM., 1975, COMPUT GRAPHICS IMAG, V4, DOI DOI 10.1016/S0146-664X(75)80008-6; GOUTSIAS J, 1988, IEEE T INFORM THEORY, V34, P551, DOI 10.1109/18.6036; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; Jain A. K., 1989, FUNDAMENTALS DIGITAL; Julesz B., 1962, IRE T INFORM THEOR, V8, P84, DOI 10.1109/TIT.1962.1057698; Kashyap RL, 1982, PATTERN RECOGN LETT, V1, P43, DOI 10.1016/0167-8655(82)90050-2; KASHYAP RL, 1986, IEEE T PATTERN ANAL, V8, P472, DOI 10.1109/TPAMI.1986.4767811; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; LAKSHMANAN S, 1989, IEEE T PATTERN ANAL, V11, P799, DOI 10.1109/34.31443; LU SY, 1979, COMPUT VISION GRAPH, V9, P234, DOI 10.1016/0146-664X(79)90039-X; Papoulis A., 2002, PROBABILITY RANDOM V; ROSENFELD A, 1970, TR70116 U MAR; TOMITA F, 1979, P IJCAI 79; VICKERS AL, 1982, IEEE T PATTERN ANAL, V4, P61, DOI 10.1109/TPAMI.1982.4767197; WOODS JW, 1972, IEEE T INFORM THEORY, V18, P232, DOI 10.1109/TIT.1972.1054786; ZACKS S, 1981, PARAMETRIC STATISTIC; ZUCKER SW, 1975, IEEE T COMPUT, V24, P1228, DOI 10.1109/T-C.1975.224169	27	206	212	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1991	13	2					192	202		10.1109/34.67648	http://dx.doi.org/10.1109/34.67648			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EY699					2022-12-18	WOS:A1991EY69900008
J	MURRAY, D; BASU, A				MURRAY, D; BASU, A			MOTION TRACKING WITH AN ACTIVE CAMERA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article							OPTICAL-FLOW; IMAGE	This work describes a method for real-time motion detection using an active camera mounted on a pan/tilt platform. Image mapping is used to align images of different viewpoints so that static camera motion detection can be applied. In the presence of camera position noise, the image mapping is inexact and compensation techniques fail. The use of morphological filtering of motion images is explored to desensitize the detection algorithm to inaccuracies in background compensation. Two motion detection techniques are examined, and experiments to verify the methods are presented. The system successfully extracts moving edges from dynamic images even when the pan/tilt angles between successive frames are as large as 3-degrees.	MACDONALD DETWILER,RICHMOND V6U 2J3,BC,CANADA; UNIV ALBERTA,DEPT COMP SCI,EDMONTON T6G 2H1,AB,CANADA; TELECOMMUN RES LABS,EDMONTON T5K 2P7,AB,CANADA	University of Alberta; University of Alberta								ALLEN P, 1990, CUCS03590 COL U PITT; ALOIMONOS J, 1988, INT J COMPUT VISION, V2, P333; Aloimonos Y., 1990, P DARPA IMAGE UNDERS, P816; BAJCSY R, 1988, P IEEE, V76, P996, DOI 10.1109/5.5968; Ballard D.H., 1982, COMPUTER VISION; BHANU B, 1990, INT J ROBOT RES, V9, P74; BRAY AJ, 1990, IMAGE VISION COMPUT, V8, P4, DOI 10.1016/0262-8856(90)90049-B; Brooks R., 1984, MODEL BASED COMPUTER; Duncan J. H., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P374, DOI 10.1109/CCV.1988.590014; FERMULLER C, 1992, BIOL CYBERN, V67, P259, DOI 10.1007/BF00204399; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; KANATANI KI, 1987, COMPUT VISION GRAPH, V39, P328, DOI 10.1016/S0734-189X(87)80185-8; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; MARAGOS P, 1987, OPT ENG, V26, P623, DOI 10.1117/12.7974127; Nelson R. C., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P173, DOI 10.1109/CVPR.1991.139683; Picton P. D., 1989, Third International Conference on Image Processing and its Applications (Conf. Publ. No.307), P389; PRAZDNY K, 1981, COMPUT VISION GRAPH, V17, P238, DOI 10.1016/0146-664X(81)90004-6; ROACH JW, 1979, IEEE T PATTERN ANAL, V1, P127, DOI 10.1109/TPAMI.1979.4766898; SCHALKOFF RJ, 1982, IEEE T PATTERN ANAL, V4, P2, DOI 10.1109/TPAMI.1982.4767188; SCHUNCK BG, 1986, COMPUT VISION GRAPH, V35, P20, DOI 10.1016/0734-189X(86)90124-6; STEPHENS RS, 1990, IMAGE VISION COMPUT, V8, P91, DOI 10.1016/0262-8856(90)90062-A; ULLMAN S, 1981, COMPUTER, V14, P57, DOI 10.1109/C-M.1981.220564; WILCOX B, 1987, SPIE, V754; [No title captured]	25	205	217	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1994	16	5					449	459		10.1109/34.291452	http://dx.doi.org/10.1109/34.291452			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NP141		Green Submitted			2022-12-18	WOS:A1994NP14100001
J	Shotton, J; Blake, A; Cipolla, R				Shotton, Jamie; Blake, Andrew; Cipolla, Roberto			Multiscale categorical object recognition using contour fragments	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						edge and feature detection; feature representation; size and shape; object recognition; computer vision; machine learning	TRACKING; TEXTURE	Psychophysical studies [9], [17] show that we can recognize objects using fragments of outline contour alone. This paper proposes a new automatic visual recognition system based only on local contour features, capable of localizing objects in space and scale. The system first builds a class-specific codebook of local fragments of contour using a novel formulation of chamfer matching. These local fragments allow recognition that is robust to within-class variation, pose changes, and articulation. Boosting combines these fragments into a cascaded sliding-window classifier, and mean shift is used to select strong responses as a final set of detection. We show how learning can be performed iteratively on both training and test sets to bootstrap an improved classifier. We compare with other methods based on contour and local descriptors in our detailed evaluation over 17 challenging categories and obtain highly competitive results. The results confirm that contour is indeed a powerful cue for multiscale and multiclass visual object recognition.	[Shotton, Jamie] Toshiba Co Ltd, R&D Ctr, Saiwai Ku, Kawasaki 2128582, Japan; [Blake, Andrew] Microsoft Res, Cambridge CB3 0FB, England; [Cipolla, Roberto] Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England	Toshiba Corporation; Microsoft; University of Cambridge	Shotton, J (corresponding author), Toshiba Co Ltd, R&D Ctr, Saiwai Ku, 1 Komukai Toshiba Cho, Kawasaki 2128582, Japan.	jamie@shotton.org	Arandjelović, Ognjen/V-5255-2019	Arandjelović, Ognjen/0000-0002-9314-194X; Cipolla, Roberto/0000-0002-8999-2151				AGARWAL S, 2002, P EUR C COMP VIS MAY, V13, P113; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Barrow HG, 1977, P 5 INT JOINT C ART; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Berg AC, 2005, PROC CVPR IEEE, P26; BIEDERMAN I, 1988, COGNITIVE PSYCHOL, V20, P38, DOI 10.1016/0010-0285(88)90024-2; BORENSTEIN E, 2004, P IEEE WORKSH PERC O, V4, P46; Boykov Y.Y., 2001, ICCV, V1, P105, DOI DOI 10.1109/ICCV.2001.937505; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Carmichael O, 2004, IEEE T PATTERN ANAL, V26, P1537, DOI 10.1109/TPAMI.2004.128; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; CSURKA G, 2004, P EUR C COMP VIS INT; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; De Winter J, 2004, BEHAV RES METH INS C, V36, P604, DOI 10.3758/BF03206541; DOLLAR P, 2006, P IEEE C COMP VIS PA, V2, P1964, DOI DOI 10.1109/CVPR.2006.298; FELZENSZWALB P. F., 2004, DISTANCE TRANSFORMS, P6; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Felzenszwalb PF, 2001, PROC CVPR IEEE, P1056; Fergus R, 2004, LECT NOTES COMPUT SC, V3021, P242; Fergus R, 2003, PROC CVPR IEEE, P264; Ferrari V, 2006, LECT NOTES COMPUT SC, V3953, P14, DOI 10.1007/11744078_2; FERRARI V, 2007, IEEE T PATTERN ANAL, V29; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Gavrila DM, 1998, INT C PATT RECOG, P439, DOI 10.1109/ICPR.1998.711175; GAVRILA DM, 2000, P EUR C COMP VIS, P37; HUTTENLOCHER DP, 1992, TR921321 U DEC DEP C; Kumar M. P., 2004, P BRIT MACH VIS C; Kumar MP, 2005, PROC CVPR IEEE, P18; Leibe B, 2004, LECT NOTES COMPUT SC, V3175, P145; Leibe B, 2005, PROC CVPR IEEE, P878; LEIBE B, 2003, P BRIT MACH VIS C, V2, P264; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Marr D., 1982, VISION COMPUTATIONAL; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Mikolajczyk K., 2003, BRIT MACH VIS C BMVC, V2, P779; Nelson RC, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P614, DOI 10.1109/ICCV.1998.710781; Olson CF, 1997, IEEE T IMAGE PROCESS, V6, P103, DOI 10.1109/83.552100; OPELT A, 2006, P IEEE C COMP VIS PA, V1, P3; Opelt A, 2006, LECT NOTES COMPUT SC, V3952, P575; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Shotton J, 2005, IEEE I CONF COMP VIS, P503; SHOTTON J, 2007, THESIS U CAMBRIDGE; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Stenger B, 2006, IEEE T PATTERN ANAL, V28, P1372, DOI 10.1109/TPAMI.2006.189; Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055; Toyama K, 2002, INT J COMPUT VISION, V48, P9, DOI 10.1023/A:1014899027014; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Winn J., 2006, CVPR; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; ZHENG S, 2007, P IEEE C COMP VIS PA; Zhu X., 2002, CMUCALD02107 CARN ME; [No title captured]	53	204	229	0	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2008	30	7					1270	1281		10.1109/TPAMI.2007.70772	http://dx.doi.org/10.1109/TPAMI.2007.70772			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	307CA	18550908				2022-12-18	WOS:000256294100012
J	Ye, JP; Li, Q				Ye, JP; Li, Q			A two-stage linear discriminant analysis via QR-decomposition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						linear discriminant analysis; dimension reduction; QR decomposition; classification	DIMENSIONALITY REDUCTION; CLASSIFICATION; ALGORITHM; EIGENFACES; CRITERION	Linear Discriminant Analysis (LDA) is a well-known method for feature extraction and dimension reduction. It has been used widely in many applications involving high-dimensional data, such as image and text classification. An intrinsic limitation of classical LDA is the so-called singularity problems; that is, it fails when all scatter matrices are singular. Many LDA extensions were proposed in the past to overcome the singularity problems. Among these extensions, PCA+LDA, a two-stage method, received relatively more attention. In PCA+LDA, the LDA stage is preceded by an intermediate dimension reduction stage using Principal Component Analysis (PCA). Most previous LDA extensions are computationally expensive, and not scalable, due to the use of Singular Value Decomposition or Generalized Singular Value Decomposition. In this paper, we propose a two-stage LDA method, namely LDA/QR, which aims to overcome the singularity problems of classical LDA, while achieving efficiency and scalability simultaneously. The key difference between LDA/QR and PCA+LDA lies in the first stage, where LDA/QR applies QR decomposition to a small matrix involving the class centroids, while PCA+LDA applies PCA to the total scatter matrix involving all training data points. We further justify the proposed algorithm by showing the relationship among LDA/QR and previous LDA methods. Extensive experiments on face images and text documents are presented to show the effectiveness of the proposed algorithm.	Univ Minnesota Twin Cities, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA; Univ Delaware, Dept Comp & Informat Sci, Newark, DE 19716 USA	University of Minnesota System; University of Minnesota Twin Cities; University of Delaware	Ye, JP (corresponding author), Univ Minnesota Twin Cities, Dept Comp Sci & Engn, 4-192 EE CSCI Bldg,200 Union St SE, Minneapolis, MN 55455 USA.	jieping@cs.umn.edu; qili@cis.udel.edu						Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Cevikalp H, 2005, IEEE T PATTERN ANAL, V27, P4, DOI 10.1109/TPAMI.2005.9; Chakrabarti S, 2003, VLDB J, V12, P170, DOI 10.1007/s00778-003-0098-9; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; De la Torre F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P362, DOI 10.1109/ICCV.2001.937541; Duda R.O., 2000, PATTERN CLASSIFICATI; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Fukunaga K., 1990, INTRO STAT PATTERN C; Golub G. H., 2012, MATRIX COMPUTATIONS; Howland P, 2003, SIAM J MATRIX ANAL A, V25, P165, DOI 10.1137/S0895479801393666; Hwang WS, 2000, IEEE T PATTERN ANAL, V22, P1277, DOI 10.1109/34.888712; Jin H, 2003, PROC INT CONF DATA, P87, DOI 10.1109/ICDE.2003.1260784; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Kanth KVR, 1999, COMPUT VIS IMAGE UND, V75, P59, DOI 10.1006/cviu.1999.0762; KRZANOWSKI WJ, 1995, J R STAT SOC C-APPL, V44, P101, DOI 10.2307/2986198; Kumar S, 2002, PATTERN ANAL APPL, V5, P210, DOI 10.1007/s100440200019; Lewis DD, 1999, REUTERS 21578 TEXT C; Liu CJ, 1998, INT C PATT RECOG, P1368, DOI 10.1109/ICPR.1998.711956; Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629; Martin H, 1933, J AGR SCI, V23, P228, DOI 10.1017/S0021859600053028; Martinez, 1998, 24 CVC; Porter MF, 2006, PROGRAM-ELECTRON LIB, V40, P211, DOI 10.1108/eb046814; Raudys S, 1998, PATTERN RECOGN LETT, V19, P385, DOI 10.1016/S0167-8655(98)00016-6; Salton G., 1989, AUTOMATIC TEXT PROCE; Schokopf B., 2002, LEARNING KERNELS SUP; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; *TREC, 1999, P TEXT RETR C; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; VANLOAN CF, 1976, SIAM J NUMER ANAL, V13, P76, DOI 10.1137/0713009; Ye JP, 2004, IEEE T PATTERN ANAL, V26, P982, DOI 10.1109/TPAMI.2004.37; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X; Zhao Y, 2004, MACH LEARN, V55, P311, DOI 10.1023/B:MACH.0000027785.44527.d6	34	204	220	1	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2005	27	6					929	941		10.1109/TPAMI.2005.110	http://dx.doi.org/10.1109/TPAMI.2005.110			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	915TR	15943424				2022-12-18	WOS:000228334700008
J	Messmer, BT; Bunke, H				Messmer, BT; Bunke, H			A new algorithm for error-tolerant subgraph isomorphism detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						graphs; subgraph isomorphism; graph matching; error-correcting graph matching; search; graph algorithms; graph decomposition	DISTANCE MEASURE; RECOGNITION; GRAPHS	In this paper, we propose a new algorithm for error-correcting subgraph isomorphism detection from a set of model graphs to an unknown input graph. The algorithm is based on a compact representation of the model graphs. This representation is derived from the set of model graphs in an off-line preprocessing step. The main advantage of the proposed representation is that common subgraphs of different model graphs are represented only once. Therefore, at run time, given an unknown input graph, the computational effort of matching the common subgraphs for each model graph onto the input graph is done only once. Consequently, the new algorithm is only sublinearly dependent on the number of model graphs. Furthermore, the new algorithm can be combined with a future cost estimation method that greatly improves its run-time performance.	Swisscom AG, Corp Technol, CH-3000 Bern, Switzerland; Univ Bern, Inst Informat & Angew Math, CH-3012 Bern, Switzerland	University of Bern	Messmer, BT (corresponding author), Swisscom AG, Corp Technol, Ostermundigenstr 93, CH-3000 Bern, Switzerland.	Bruno.Messmer@swisscom.com; bunke@iam.unibe.ch						[Anonymous], 1980, PRINCIPLES ARTIFICIA; BENARIE J, 1987, COMPUT VISION GRAPH, V37, P345, DOI 10.1016/0734-189X(87)90042-9; Bunke H, 1983, PATTERN RECOGN LETT, V1, P245, DOI 10.1016/0167-8655(83)90033-8; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; COSTA M, 1995, LECT NOTES COMPUTER, V974; ESHERA MA, 1984, IEEE T SYST MAN CYB, V14, P398, DOI 10.1109/TSMC.1984.6313232; FENG J, 1994, PATTERN RECOGN, V4, P177; FORGY CL, 1982, ARTIF INTELL, V19, P17, DOI 10.1016/0004-3702(82)90020-0; Garey M.R., 1979, COMPUTERS INTRACTABI; KITTLER J, 1992, ADV STRUCTURAL SYNTA, P471; LEE HS, 1992, ARTIF INTELL, P255; LEE JP, 1990, EYE, V4, P1; LU SW, 1991, PATTERN RECOGN, V24, P617, DOI 10.1016/0031-3203(91)90029-5; Messmer BT, 1995, THESIS U BERN SWITZE; MESSMER BT, 1996, LECT NOTES COMPUTER, V1072, P123; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175; SENGUPTA K, 1995, IEEE T PATTERN ANAL, V17; SEONG DS, 1993, IEEE T SYST MAN CYB, V23, P1399, DOI 10.1109/21.260671; SHAPIRO LG, 1982, IEEE T PATTERN ANAL, V4, P595, DOI 10.1109/TPAMI.1982.4767312; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144; Sossa H., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P811, DOI 10.1109/CVPR.1992.223252; TSAI WH, 1979, IEEE T SYST MAN CYB, V9, P757, DOI 10.1109/TSMC.1979.4310127; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; WONG AKC, 1990, IEEE T SYST MAN CYB, V20, P628, DOI 10.1109/21.57275; Wong E, 1990, SYNTACTIC STRUCTURAL, P381; XU L, 1990, LECT NOTES COMPUT SC, V412, P151	26	204	213	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1998	20	5					493	504		10.1109/34.682179	http://dx.doi.org/10.1109/34.682179			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZR253					2022-12-18	WOS:000073955600005
J	DelBimbo, A; Pala, P				DelBimbo, A; Pala, P			Visual image retrieval by elastic matching of user sketches	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image database; image retrieval by sketch; shape similarity-based retrieval; elastic matching	DATA MANAGEMENT	Effective image retrieval by content from database requires that visual image properties are used instead of textual labels to properly index and recover pictorial data. Retrieval by shape similarity, given a user-sketched template is particularly challenging, owing to the difficulty to derive a similarity measure that closely conforms to the common perception of similarity by humans. In this paper, we present a technique which is based on elastic matching of sketched templates over the shapes in the images to evaluate similarity ranks. The degree of matching achieved and the elastic deformation energy spent by the sketch to achieve such a match are used to derive a measure of similarity between the sketch and the images in the database and to rank images to be displayed. The elastic matching is integrated with arrangements to provide scale invariance and take into account spatial relationships between objects in multi-object queries. Examples from a prototype system are expounded with considerations about the effectiveness of the approach and comparative performance analysis.			DelBimbo, A (corresponding author), UNIV FLORENCE, DIPARTIMENTO SISTEMI & INFORMAT, I-50139 FLORENCE, ITALY.			PALA, PIETRO/0000-0001-5670-3774; DEL BIMBO, ALBERTO/0000-0002-1052-8322				ANSELONE PM, 1968, NUMER MATH, V12, P66, DOI 10.1007/BF02170998; BINAGHI E, 1992, IFIP T A, V7; CHANG SK, 1988, IEEE T SOFTWARE ENG, V14, P681, DOI 10.1109/32.6147; CHANG SK, 1987, IEEE T PATTERN ANAL, V9, P413, DOI 10.1109/TPAMI.1987.4767923; DELBIMBO A, 1993, IEEE T SOFTWARE ENG, V19, P997, DOI 10.1109/32.245741; DELBIMBO A, 1994, J VISUAL LANGUAGES C, V5; DELBIMBO A, 1994, P IEEE VL 94 INT S V; DURBIN R, 1987, NATURE, V326, P689, DOI 10.1038/326689a0; FALOUTSOS C, 1993, 9453 IBM RES DIV ALM; GROSKY WI, 1990, COMPUT VISION GRAPH, V52, P416, DOI 10.1016/0734-189X(90)90085-A; HIRATA K, LECT NOTES COMPUTER, V580; JACOBS C, 1995, P SIGGRAPH 95; JUNGERT E, 1992, LECT NOTES COMPUTER; KANKANHALLI A, 1994, IEEE P INT C AUT ROB; LEE S, 1989, PATTERN RECOGNITION, V22; LEE SY, 1992, J VISUAL LANG COMPUT, V3, P373; LEE SY, 1992, PATTERN RECOGNITION, V25; MEHROTRA R, 1995, COMPUTER, V28, P57, DOI 10.1109/2.410154; NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173; OHLSSONO M, 1992, 9228 LU TP U LUND DE; PICARD RW, 1994, P IEEE C AC SPEECH S; PICARD RW, 1995, 360 MIT MED LAB PERC; SWAIN MJ, 1991, INT J COMPUTER VISIO, V7; TANIMOTO SL, 1976, PATTERN RECOGNITION; TIHONOV AN, 1963, SOV MATH DOKL, V4, P1624; YOUILLE AL, 1991, P INT JOINT C NEUR N; [No title captured]	27	204	215	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1997	19	2					121	132		10.1109/34.574790	http://dx.doi.org/10.1109/34.574790			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WK728					2022-12-18	WOS:A1997WK72800003
J	Jackway, PT; Deriche, M				Jackway, PT; Deriche, M			Scale-space properties of the multiscale morphological dilation erosion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						scale-space filtering; multiscale morphology; signal analysis; monotonic property; scale-space fingerprints	MATHEMATICAL MORPHOLOGY; ZERO-CROSSINGS; EDGE-DETECTION; FILTERS	A multiscale morphological dilation-erosion smoothing operation and its associated scale-space expansion for multidimensional signals are proposed. Properties of this smoothing operation are developed and, in particular a scale-space monotonic property for signal extrema is demonstrated. Scale-space fingerprints from this approach have advantages over Gaussian scale-space fingerprints in that they are defined for negative values of the scale parameter; have monotonic properties in two and higher dimensions, do not cause features to be shifted by the smoothing, and allow efficient computation. The application of reduced multiscale dilation-erosion fingerprints to the surface matching of terrain is demonstrated.	QUEENSLAND UNIV TECHNOL, SCH MATH, BRISBANE, QLD 4001, AUSTRALIA; QUEENSLAND UNIV TECHNOL, SIGNAL PROC RES CTR, BRISBANE, QLD 4001, AUSTRALIA; QUEENSLAND UNIV TECHNOL, SCH ELECT ELECTR & SYST ENGN, BRISBANE, QLD 4001, AUSTRALIA	Queensland University of Technology (QUT); Queensland University of Technology (QUT); Queensland University of Technology (QUT)	Jackway, PT (corresponding author), UNIV QUEENSLAND, DEPT ELECT & COMP ENGN, BRISBANE, QLD 4072, AUSTRALIA.		Jackway, Paul T/A-3636-2009; Deriche, Mohamed/A-9871-2008	Jackway, Paul T/0000-0002-5848-4832; Deriche, Mohamed/0000-0002-5287-1874				BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; BANGHAM JA, 1993, IEEE T SIGNAL PROCES, V41, P31, DOI 10.1109/TSP.1993.193125; Bartle R.G., 1964, ELEMENTS REAL ANAL, VVolume 2; CHEN MH, 1989, IEEE T PATTERN ANAL, V11, P694, DOI 10.1109/34.192464; DePree J, 1988, INTRO REAL ANAL; Dougherty E. R., 1992, Journal of Mathematical Imaging and Vision, V1, P7, DOI 10.1007/BF00135222; DUCHATEAU P, 1986, SCHAUMS OUTLINE SERI; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; HEIJMANS HJAM, 1990, COMPUT VISION GRAPH, V50, P245, DOI 10.1016/0734-189X(90)90148-O; HUMMEL R, 1989, IEEE T ACOUST SPEECH, V37, P2111, DOI 10.1109/29.45555; JACKWAY PT, 1995, J VIS COMMUN IMAGE R, V6, P189, DOI 10.1006/jvci.1995.1017; JACKWAY PT, 1995, THESIS QUEENSLAND U; JACKWAY PT, 1994, 1994 P IEEE INT C AC, pV5; JACKWAY PT, 1993, DEC P DICTA 93 DIG I, P382; JACKWAY PT, 1992, 11TH P IAPR INT C PA, pC252; JANG BK, 1991, 25TH P ANN C INF SCI, P1; LIFSHITZ LM, 1990, IEEE T PATTERN ANAL, V12, P529, DOI 10.1109/34.56189; LINDEBERG T, 1990, IEEE T PATTERN ANAL, V12, P234, DOI 10.1109/34.49051; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; MARAGOS P, 1987, IEEE T ACOUST SPEECH, V35, P1170, DOI 10.1109/TASSP.1987.1165254; MARAGOS P, 1987, IEEE T ACOUST SPEECH, V35, P1153, DOI 10.1109/TASSP.1987.1165259; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MARR D, 1979, J OPT SOC AM, V69, P914, DOI 10.1364/JOSA.69.000914; Marr D., 1982, VISION; Matheron G., 1975, RANDOM SETS INTEGRAL; Morel J.M., 1994, ACTA NUMER, V3, P1, DOI 10.1017/S0962492900002415; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Protter M.H., 1984, MAXIMUM PRINCIPLE DI, DOI 10.1007/978-1-4612-5282-5; Rivest J.-F., 1992, Journal of Visual Communication and Image Representation, V3, P137, DOI 10.1016/1047-3203(92)90011-H; ROMENY BMT, 1991, 12TH P INT C IM PROC, P239; Serra J, 1982, IMAGE ANAL MATH MORP; Serra J, 1988, IMAGE ANAL MATH MORP; STANSFIELD JL, 1980, MIT AI601 MEM; STERNBERG SR, 1986, COMPUT VISION GRAPH, V35, P333, DOI 10.1016/0734-189X(86)90004-6; VANDENBOOMGAARD R, 1994, IEEE T PATTERN ANAL, V16, P1101, DOI 10.1109/34.334389; VANDENBOOMGAARD R, 1992, THESIS U AMSTERDAM; WILSON R, 1984, IEEE T PATTERN ANAL, V6, P758, DOI 10.1109/TPAMI.1984.4767599; Witkin A. P., 1984, IMAGE UNDERSTANDING, P79; WITKIN AP, 1983, AUG P INT JOINT C AR, P1019; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]	42	204	210	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1996	18	1					38	51		10.1109/34.476009	http://dx.doi.org/10.1109/34.476009			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TP315					2022-12-18	WOS:A1996TP31500004
J	KUHN, R; DEMORI, R				KUHN, R; DEMORI, R			A CACHE-BASED NATURAL-LANGUAGE MODEL FOR SPEECH RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									CTR RECH INFORMAT MONTREAL INC,MONTREAL,QUEBEC,CANADA		KUHN, R (corresponding author), MCGILL UNIV,SCH COMP SCI,MONTREAL H3A 2A7,QUEBEC,CANADA.							DEROUAULT AM, 1986, IEEE T PATTERN ANAL, V8, P742, DOI 10.1109/TPAMI.1986.4767855; DEROUAULT AM, 1984, 7TH P INT C PATT REC, V2, P1373; JELINEK F, 1985, P IEEE, V73, P1616, DOI 10.1109/PROC.1985.13343; JELINEK F, 1983, IEEE T PATTERNS ANAL, V5, P179; JELINEK F, 1981, PATTERN RECOGN, P381; JOHANSSON S, 1985, COMPUT HUMANITIES, V19, P23, DOI 10.1007/BF02259615; Johansson S., 1986, TAGGED LOB CORPUS US; Johansson S., 1985, ITL REV APPL LINGUIS, V67-68, P117; KATZ S, IN PRESS RECURSIVE M; MUCKSTEIN EM, 1981, IBM RC751638450 RES; NADAS A, 1984, IEEE T ACOUST SPEECH, V32, P859, DOI 10.1109/TASSP.1984.1164378; Peterson J. L., 1983, OPERATING SYSTEM CON; Rabiner L. R., 1986, IEEE ASSP MAGAZI JAN, P4	13	204	213	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1990	12	6					570	583		10.1109/34.56193	http://dx.doi.org/10.1109/34.56193			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE003		Green Submitted			2022-12-18	WOS:A1990DE00300006
J	Shi, BG; Yang, MK; Wang, XG; Lyu, PY; Yao, C; Bai, X				Shi, Baoguang; Yang, Mingkun; Wang, Xinggang; Lyu, Pengyuan; Yao, Cong; Bai, Xiang			ASTER: An Attentional Scene Text Recognizer with Flexible Rectification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Scene text recognition; thin-plate spline; image transformation; sequence-to-sequence learning	LOCALIZATION	A challenging aspect of scene text recognition is to handle text with distortions or irregular layout. In particular, perspective text and curved text are common in natural scenes and are difficult to recognize. In this work, we introduce ASTER, an end-to-end neural network model that comprises a rectification network and a recognition network. The rectification network adaptively transforms an input image into a new one, rectifying the text in it. It is powered by a flexible Thin-Plate Spline transformation which handles a variety of text irregularities and is trained without human annotations. The recognition network is an attentional sequence-to-sequence model that predicts a character sequence directly from the rectified image. The whole model is trained end to end, requiring only images and their groundtruth text. Through extensive experiments, we verify the effectiveness of the rectification and demonstrate the state-of-the-art recognition performance of ASTER. Furthermore, we demonstrate that ASTER is a powerful component in end-to-end recognition systems, for its ability to enhance the detector.	[Shi, Baoguang; Yang, Mingkun; Wang, Xinggang; Lyu, Pengyuan; Bai, Xiang] Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Hubei, Peoples R China; [Yao, Cong] Megvii Face Inc, Beijing 100190, Peoples R China	Huazhong University of Science & Technology	Bai, X (corresponding author), Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430074, Hubei, Peoples R China.	shibaoguang@gmail.com; yangmingkun@hust.edu.cn; wxghust@gmail.com; lvpyuan@gmail.com; yaocong2010@gmail.com; xbai@mail.hust.edu.cn	Wang, Xinggang/W-4374-2019	Wang, Xinggang/0000-0001-6732-7823; Yang, Mingkun/0000-0002-6078-6100; Bai, Xiang/0000-0002-3449-5940	National Key R&D Program of China [2018YFB1004600]; NSFC [61733007, 61573160]; National Program for Support of Top-notch Young Professionals; Program for HUST Academic Frontier Youth Team	National Key R&D Program of China; NSFC(National Natural Science Foundation of China (NSFC)); National Program for Support of Top-notch Young Professionals; Program for HUST Academic Frontier Youth Team	This work was supported by National Key R&D Program of China No. 2018YFB1004600, NSFC 61733007, NSFC 61573160, the National Program for Support of Top-notch Young Professionals, and the Program for HUST Academic Frontier Youth Team.	Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Almazan J, 2014, IEEE T PATTERN ANAL, V36, P2552, DOI 10.1109/TPAMI.2014.2339814; Bartz C., 2017, ARXIV170708831; Bartz C, 2018, AAAI CONF ARTIF INTE, P6674; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bengio Y., 2014, ARXIV14061078; Bissacco A, 2013, IEEE I CONF COMP VIS, P785, DOI 10.1109/ICCV.2013.102; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Busta M, 2017, IEEE I CONF COMP VIS, P2223, DOI 10.1109/ICCV.2017.242; Casey RG, 1996, IEEE T PATTERN ANAL, V18, P690, DOI 10.1109/34.506792; Cheng ZZ, 2017, IEEE I CONF COMP VIS, P5086, DOI 10.1109/ICCV.2017.543; Chorowski I. K., 2015, ADV NEURAL INFORM PR, V28, P577, DOI DOI 10.1016/0167-739X(94)90007-8; Dzmitry Bahdanau, 2016, Arxiv, DOI arXiv:1409.0473; Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041; Gehring J., 2017, P ICML; Gordo A, 2015, PROC CVPR IEEE, P2956, DOI 10.1109/CVPR.2015.7298914; Graves A., 2006, P 23 INT C MACH LEAR, P369; Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137; Gupta A, 2016, PROC CVPR IEEE, P2315, DOI 10.1109/CVPR.2016.254; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; He P, 2016, AAAI CONF ARTIF INTE, P3501; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Huang C, 2017, 2017 EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), P334, DOI 10.1109/ICICIP.2017.8113966; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Jaderberg M, 2015, ICLR; Jaderberg M., 2014, P NIPS DEEP LEARN WO; Jaderberg M., 2015, ADV NEURAL INFORM PR, P2017, DOI DOI 10.1038/NBT.3343; Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z; Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34; Jagannathan L., 2005, P 1 INT WORKSH CAM B, P148; Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942; Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee CY, 2016, PROC CVPR IEEE, P2231, DOI 10.1109/CVPR.2016.245; Lee CY, 2014, PROC CVPR IEEE, P4050, DOI 10.1109/CVPR.2014.516; Li H, 2017, IEEE I CONF COMP VIS, P5248, DOI 10.1109/ICCV.2017.560; Liao MH, 2017, AAAI CONF ARTIF INTE, P4161; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lu SJ, 2006, INT C PATT RECOG, P971; Lu SJ, 2005, IMAGE VISION COMPUT, V23, P541, DOI 10.1016/j.imavis.2005.01.003; Lucas S. M., 2005, International Journal on Document Analysis and Recognition, V7, P105, DOI 10.1007/s10032-004-0134-3; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; Mishra A., 2012, P IEEE C COMP VIS PA; Mishra A, 2016, COMPUT VIS IMAGE UND, V145, P30, DOI 10.1016/j.cviu.2016.01.002; Neumann L, 2016, IEEE T PATTERN ANAL, V38, P1872, DOI 10.1109/TPAMI.2015.2496234; Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097; Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Risnumawan A, 2014, EXPERT SYST APPL, V41, P8027, DOI 10.1016/j.eswa.2014.07.008; Rodriguez-Serrano JA, 2015, INT J COMPUT VISION, V113, P193, DOI 10.1007/s11263-014-0793-6; Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371; Shi BG, 2016, PROC CVPR IEEE, P4168, DOI 10.1109/CVPR.2016.452; Su B, 2014, INT C INTEL HUM MACH, P300, DOI 10.1109/IHMSC.2014.80; Su BL, 2017, PATTERN RECOGN, V63, P397, DOI 10.1016/j.patcog.2016.10.016; Sutskever I., 2014, ARXIV14093215, DOI DOI 10.1007/S10107-014-0839-0; Phan TQ, 2013, IEEE I CONF COMP VIS, P569, DOI 10.1109/ICCV.2013.76; Wang JF, 2017, ADV NEUR IN, V30; Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402; Wang K, 2010, LECT NOTES COMPUT SC, V6311, P591, DOI 10.1007/978-3-642-15549-9_43; Wang T, 2012, INT C PATT RECOG, P3304; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Weinman JJ, 2014, IEEE T PATTERN ANAL, V36, P375, DOI 10.1109/TPAMI.2013.126; Yang XP, 2017, DESTECH TRANS COMP, P328; Yao C, 2014, IEEE T IMAGE PROCESS, V23, P4737, DOI 10.1109/TIP.2014.2353813; Yao C, 2014, PROC CVPR IEEE, P4042, DOI 10.1109/CVPR.2014.515; Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787; Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765; Zeiler Matthew D, 2012, ARXIV12125701; Zhang Z, 2015, PROC CVPR IEEE, P2558, DOI 10.1109/CVPR.2015.7298871; Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283; Zhu YY, 2016, FRONT COMPUT SCI-CHI, V10, P19, DOI 10.1007/s11704-015-4488-0	72	203	217	4	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2019	41	9					2035	2048		10.1109/TPAMI.2018.2848939	http://dx.doi.org/10.1109/TPAMI.2018.2848939			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IP9BY	29994467				2022-12-18	WOS:000480343900001
J	Pritch, Y; Rav-Acha, A; Peleg, S				Pritch, Yael; Rav-Acha, Alex; Peleg, Shmuel			Nonchronological video synopsis and indexing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						video summary; video indexing; video surveillance		The amount of captured video is growing with the increased numbers of video cameras, especially the increase of millions of surveillance cameras that operate 24 hours/day. Since video browsing and retrieval is time consuming, most captured video is never watched or examined. Video synopsis is an effective tool for browsing and indexing of such a video. It provides a short video representation, while preserving the essential activities of the original video. The activity in the video is condensed into a shorter period by simultaneously showing multiple activities, even when they originally occurred at different times. The synopsis video is also an index of the original video by pointing to the original time of each activity. Video synopsis can be applied to create a synopsis of endless video streams, as generated by webcams and by surveillance cameras. It can address queries like "Show in one minute the synopsis of this camera broadcast during the past day." This process includes two major phases: 1) an online conversion of the endless video stream into a database of objects and activities ( rather than frames) and 2) a response phase, generating the video synopsis as a response to the user's query.	[Pritch, Yael; Peleg, Shmuel] Hebrew Univ Jerusalem, Sch Engn & Comp Sci, IL-91904 Jerusalem, Israel; [Rav-Acha, Alex] Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel	Hebrew University of Jerusalem; Weizmann Institute of Science	Pritch, Y (corresponding author), Hebrew Univ Jerusalem, Sch Engn & Comp Sci, IL-91904 Jerusalem, Israel.	yaelpri@cs.huji.ac.il; ravacha@gmail.com; peleg@mail.huji.ac.il	Peleg, Shmuel/B-7454-2011	Peleg, Shmuel/0000-0002-4468-2619	Israel Science Foundation; Israeli Ministry of Science; Google	Israel Science Foundation(Israel Science Foundation); Israeli Ministry of Science(Ministry of Science, Technology and Space (MOST), Israel); Google(Google Incorporated)	This research was supported by the Israel Science Foundation, by the Israeli Ministry of Science, and by Google.	Agarwala A, 2005, ACM T GRAPHIC, V24, P821, DOI 10.1145/1073204.1073268; Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718; AGARWALA A, 2007, P ACM SIGGRAPH 07; [Anonymous], 2001, HPL2001191; ASSA J, 2005, P ACM SIGGRAPH, P667; Boiman O, 2005, IEEE I CONF COMP VIS, P462; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Brostow G. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P8, DOI 10.1109/ICCV.1999.791190; Cohen S, 2005, IEEE I CONF COMP VIS, P1034; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Ferman AM, 1997, P SOC PHOTO-OPT INS, V3229, P23, DOI 10.1117/12.290352; Irani M, 1996, SIGNAL PROCESS-IMAGE, V8, P327, DOI 10.1016/0923-5965(95)00055-0; KANG HW, 2006, P IEEE C COMP VIS PA, P1331; KIM C, 2000, ACM MULTIMEDIA, P303; KOLMOGOROV V, 2002, P EUR C COMP VIS ECC, P65; Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410; NAM J, 1999, P IEEE 3 WORKSH MULT, P117; Oh J, 2004, VIDEO DATA MANAGEMEN, P321; OREN M, 1997, P IM UND WORKSH, P207; Pal C, 2005, PROC CVPR IEEE, P1192; PATIL R, 2004, P IEEE RSJ INT C INT, V1, P1323; Perez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269; Petrovic N, 2005, MULTIMED TOOLS APPL, V26, P327, DOI 10.1007/s11042-005-0895-9; Pope A, 1998, CONF REC ASILOMAR C, P915, DOI 10.1109/ACSSC.1998.751015; PRITCH Y, 2007, P INT C COMP VIS OCT; Rav-Acha A., P 2006 IEEE COMP SOC, P435; Rav-Acha A, 2007, IEEE T PATTERN ANAL, V29, P1789, DOI 10.1109/TPAMI.2007.1091; Rother C, 2006, ACM T GRAPHIC, V25, P847, DOI 10.1145/1141911.1141965; Schodl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012; SMITH AM, 1998, P INT WORKSH CONT BA, P61; Stefanidis A, 2000, 11TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATION, PROCEEDINGS, P906, DOI 10.1109/DEXA.2000.875134; Sun J, 2006, LECT NOTES COMPUT SC, V3952, P628; Yeung MM, 1997, IEEE T CIRC SYST VID, V7, P771, DOI 10.1109/76.633496; Zhong H, 2004, PROC CVPR IEEE, P819; Zhu LD, 2004, SENSOR ACTUAT B-CHEM, V98, P115, DOI 10.1016/S0925-4005(03)00640-3	35	203	218	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2008	30	11					1971	1984		10.1109/TPAMI.2008.29	http://dx.doi.org/10.1109/TPAMI.2008.29			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	347AC	18787245				2022-12-18	WOS:000259110000010
J	Hassouna, MS; Farag, AA				Hassouna, M. Sabry; Farag, Aly A.			Multistencils fast marching methods: A highly accurate solution to the eikonal equation on Cartesian domains	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multistencils fast marching methods; monotonically advancing fronts; fast marching methods; level set methods; Eikonal equation	FINITE-DIFFERENCE CALCULATION; HAMILTON-JACOBI EQUATIONS; LEVEL SET METHOD; ALGORITHMS; SHAPE	A wide range of computer vision applications require an accurate solution of a particular Hamilton-Jacobi (HJ) equation known as the Eikonal equation. In this paper, we propose an improved version of the fast marching method (FMM) that is highly accurate for both 2D and 3D Cartesian domains. The new method is called multistencils fast marching (MSFM), which computes the solution at each grid point by solving the Eikonal equation along several stencils and then picks the solution that satisfies the upwind condition. The stencils are centered at each grid point and cover its entire nearest neighbors. In 2D space, two stencils cover 8-neighbors of the point, whereas in 3D space, six stencils cover its 26-neighbors. For those stencils that are not aligned with the natural coordinate system, the Eikonal equation is derived using directional derivatives and then solved using higher order finite difference schemes. The accuracy of the proposed method over the state-of-the-art FMM-based techniques has been demonstrated through comprehensive numerical experiments.	Univ Louisville, Dept Elect & Comp Engn, Comp Vis & Image Proc Lab, Louisville, KY 40292 USA	University of Louisville	Hassouna, MS (corresponding author), Univ Louisville, Dept Elect & Comp Engn, Comp Vis & Image Proc Lab, Room 412, Louisville, KY 40292 USA.	msabry@cvip.uofl.edu; aly.farag@louisville.edu						Abd El Munim HE, 2005, IEEE I CONF COMP VIS, P930; ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098; Bouix S, 2003, PROC CVPR IEEE, P449; Cao ZJ, 2003, PROC SPIE, V5032, P325, DOI 10.1117/12.480306; CERVENY V, 1985, J GEOPHYS-Z GEOPHYS, V58, P2; Chen S, 1997, J COMPUT PHYS, V135, P8, DOI 10.1006/jcph.1997.5721; Chopp DL, 2001, SIAM J SCI COMPUT, V23, P230, DOI 10.1137/S106482750037617X; Danielsson PE, 2003, LECT NOTES COMPUT SC, V2749, P1154; Deschamps T, 2002, INT C PATT RECOG, P731, DOI 10.1109/ICPR.2002.1044862; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]; Godunov S.K., 1959, MATEMATICHESKII SBOR, V47, P271; Gremaud PA, 2006, SIAM J SCI COMPUT, V27, P1803, DOI 10.1137/040605655; Hassouna M. S., 2006, P IEEE C COMP VIS PA, P355; Hassouna MS, 2005, PROC CVPR IEEE, P458; HASSOUNA MS, 2005, P IEEE INT C IM PROC, P473; Kao CY, 2005, SIAM J NUMER ANAL, V42, P2612, DOI 10.1137/S0036142902419600; Kao CY, 2004, J COMPUT PHYS, V196, P367, DOI 10.1016/j.jcp.2003.11.007; Kim S, 2001, SIAM J SCI COMPUT, V22, P2178, DOI 10.1137/S1064827500367130; KIM S, 1999, SOC EXPLORATION GEOP, P1747; KIMMEL R, 1995, COMPUT VIS IMAGE UND, V62, P382, DOI 10.1006/cviu.1995.1062; Kimmel R, 2001, J MATH IMAGING VIS, V14, P237, DOI 10.1023/A:1011234012449; KIMMEL R, 1993, COMPUT AIDED DESIGN, V25, P154, DOI 10.1016/0010-4485(93)90040-U; Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; PODVIN P, 1991, GEOPHYS J INT, V105, P271, DOI 10.1111/j.1365-246X.1991.tb03461.x; QIAN J, 2002, IN PRESS J SCI COMPU; QIAN J, IN PRESS SIAM J NUME; Sethian JA, 2000, P NATL ACAD SCI USA, V97, P5699, DOI 10.1073/pnas.090060097; Sethian JA, 2003, SIAM J NUMER ANAL, V41, P325, DOI 10.1137/S0036142901392742; SETHIAN JA, 1999, LEVEL SETS METHODS F; Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596; Tsai YHR, 2003, SIAM J NUMER ANAL, V41, P673, DOI 10.1137/S0036142901396533; TSITSIKLIS JN, 1995, IEEE T AUTOMAT CONTR, V40, P1528, DOI 10.1109/9.412624; VANTRIER J, 1991, GEOPHYSICS, V56, P812, DOI 10.1190/1.1443099; VIDALE JE, 1990, GEOPHYSICS, V55, P521, DOI 10.1190/1.1442863; Yatziv L, 2006, J COMPUT PHYS, V212, P393, DOI 10.1016/j.jcp.2005.08.005; ZHANG Y, IN PRESS J SCI COMPU; Zhao HK, 2005, MATH COMPUT, V74, P603	38	203	211	2	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2007	29	9					1563	1574		10.1109/TPAMI.2007.1154	http://dx.doi.org/10.1109/TPAMI.2007.1154			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	189CD	17627044				2022-12-18	WOS:000247965600006
J	Cappelli, R; Maio, D; Maltoni, D; Wayman, JL; Jain, AK				Cappelli, R; Maio, D; Maltoni, D; Wayman, JL; Jain, AK			Performance evaluation of fingerprint verification systems	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						biometric systems; fingerprint verification; performance evaluation; technology evaluation; FVC		This paper is concerned with the performance evaluation of fingerprint verification systems. After an initial classification of biometric testing initiatives, we explore both the theoretical and practical issues related to performance evaluation by presenting the outcome of the recent Fingerprint Verification Competition (FVC2004). FVC2004 was organized by the authors of this work for the purpose of assessing the state-of-the-art in this challenging pattern recognition application and making available a new common benchmark for an unambiguous comparison of fingerprint-based biometric systems. FVC2004 is an independent, strongly supervised evaluation performed at the evaluators' site on evaluators' hardware. This allowed the test to be completely controlled and the computation times of different algorithms to be fairly compared. The experience and feedback received from previous, similar competitions (FVC2000 and FVC2002) allowed us to improve the organization and methodology of FVC2004 and to capture the attention of a significantly higher number of academic and commercial organizations (67 algorithms were submitted for FVC2004). A new, "Light" competition category was included to estimate the loss of matching performance caused by imposing computational constraints. This paper discusses data collection and testing protocols, and includes a detailed analysis of the results. We introduce a simple but effective method for comparing algorithms at the score level, allowing us to isolate difficult cases (images) and to study error correlations and algorithm "fusion." The huge amount of information obtained, including a structured classification of the submitted algorithms on the basis of their features, makes it possible to better understand how current fingerprint recognition systems work and to delineate useful research directions for the future.	Univ Bologna, DEIS, Biomet Syst Lab, I-47023 Cesena, Italy; San Jose State Univ, Biometr Res Ctr, Off Grad Studies & Res, San Jose, CA 95192 USA; Michigan State Univ, Pattern Recognit & Image Proc Lab, E Lansing, MI 48824 USA	University of Bologna; California State University System; San Jose State University; Michigan State University	Cappelli, R (corresponding author), Univ Bologna, DEIS, Biomet Syst Lab, Via Sacchi 3, I-47023 Cesena, Italy.	cappelli@csr.unibo.it; maio@csr.unibo.it; maltoni@csr.unibo.it; jlwayman@aol.com; jain@cse.msu.edu		Cappelli, Raffaele/0000-0003-3054-9363				[Anonymous], 2000, FINGERPRINT VERIFICA; [Anonymous], 2004, FINGERPRINT VERIFICA; [Anonymous], 2002, FINGERPRINT VERIFICA; Bester-Roga M, 2002, J SOLUTION CHEM, V31, P1, DOI 10.1023/A:1014805417286; Blackburn D. M., 2001, FACIAL RECOGNITION V; Cappelli R, 2002, INT C PATT RECOG, P744, DOI 10.1109/ICPR.2002.1048096; Cappelli R, 2000, INT C PATT RECOG, P471, DOI 10.1109/ICPR.2000.903586; CAPPELLI R, 2001, P 2 INT C ADV PATT R, P369; Cappelli R, 2003, HDB FINGERPRINT RECO; DITYAN Y, 2004, P INT C BIOM AUTH JU, P16; Doddington G., 1998, INT C SPOKEN LANGUAG, P1351; FIERREZAGUILAR J, 2005, P 13 INT C IM AN PRO; *ISO IEC, 2004, ISOIECJTC1SC37WG3; Jain A, 2002, INT CONF ACOUST SPEE, P4064; Jain AK, 1999, PATTERN RECOGN LETT, V20, P1371, DOI 10.1016/S0167-8655(99)00108-7; Maio D, 2004, LECT NOTES COMPUT SC, V3072, P1; Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144; Maio D, 2002, IEEE T PATTERN ANAL, V24, P402, DOI 10.1109/34.990140; MANSFIELD A, 2001, BIOMETRIC PRODUCT TE; MARTIN A, 2004, BIOMETRIC SYSTEMS TE; Matas J, 2000, INT C PATT RECOG, P858; MESSER K, 2004, P 1 INT C BIOM AUTH, P8; PANETAL SB, 2003, IEEE T CONSUM ELECTR, V49, P453; PANKANTI S, 2002, P 16 INT C PATT REC; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Phillips PJ, 2000, COMPUTER, V33, P56, DOI 10.1109/2.820040; PHILLIPS PJ, 2002, FACIAL RECOGNITION V; Prabhakar S., 2003, HDB FINGERPRINT RECO; Sanchez-Reillo R, 2002, IEEE AERO EL SYS MAG, V17, P12, DOI 10.1109/MAES.2002.1039788; Wilson C, 2004, 7123 NISTIR	30	203	212	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2006	28	1					3	18		10.1109/TPAMI.2006.20	http://dx.doi.org/10.1109/TPAMI.2006.20			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	982OR	16402615	Green Submitted			2022-12-18	WOS:000233172000001
J	Cai, Q; Aggarwal, JK				Cai, Q; Aggarwal, JK			Tracking human motion in structured environments using a distributed-camera system	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						tracking; human modeling; motion estimation; multiple perspectives; Bayesian classification; end-to-end vision systems		This paper presents a comprehensive framework for tracking coarse human models from sequences of synchronized monocular grayscale images in multiple camera coordinates. It demonstrates the feasibility of an end-to-end person tracking system using a unique combination of motion analysis on 3D geometry in different camera coordinates and other existing techniques in motion detection, segmentation, and pattern recognition. The system starts with tracking from a single camera view. When the system predicts that the active camera will no longer have a good view of the subject of interest, tracking will be switched to anomer camera which provides a better view and requires the least switching to continue tracking. The nonrigidity of the human body is addressed by matching points of the middle line of the human image, spatially and temporally, using Bayesian classification schemes. Multivariate normal distributions are employed to model class-conditional densities of the features for tracking, such as location, intensity, and geometric features. Limited degrees of occlusion are tolerated within the system. Experimental results using a prototype system are presented and the performance of the algorithm is evaluated to demonstrate its feasibility for real time applications.	Realnetworks Inc, Consulting Grp, Seattle, WA 98121 USA; Univ Texas, Dept Elect & Comp Engn, Austin, TX 78712 USA	University of Texas System; University of Texas Austin	Cai, Q (corresponding author), Realnetworks Inc, Consulting Grp, 2601 Elliott Ave, Seattle, WA 98121 USA.							Cai Q., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P215, DOI 10.1109/ICIP.1995.529584; Cai Q., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P68, DOI 10.1109/ICPR.1996.546796; CAI Q, 1998, P INT C COMP VIS BOM; CAI Q, 1997, THESIS U TEXAS AUSTI; CHANG YL, 1993, PATTERN RECOGN, V26, P75, DOI 10.1016/0031-3203(93)90089-F; KANATANI K, 1988, COMPUT VISION GRAPH, V41, P28, DOI 10.1016/0734-189X(88)90115-6; Kelly P. H, 1995, P ACM C MULT, P201; Pingali S., 1996, Proceeding. Third IEEE Workshop on Applications of Computer Vision. WACV'96 (Cat. No.96TB100084), P33, DOI 10.1109/ACV.1996.571994; Polana R., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P77, DOI 10.1109/MNRAO.1994.346251; Sato K., 1994, Proceedings of the 1994 Second CAD-Based Vision Workshop (Cat. No.94TH0595-9), P291, DOI 10.1109/CADVIS.1994.284490	10	203	217	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1999	21	11					1241	1247		10.1109/34.809119	http://dx.doi.org/10.1109/34.809119			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	259YG					2022-12-18	WOS:000083921100015
J	Bhat, DN; Nayar, SK				Bhat, DN; Nayar, SK			Ordinal measures for image correspondence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image matching; stereo; ordinal measures; correlation; correspondence		We present ordinal measures of association for image correspondence in the context of stereo. Linear correspondence measures like correlation and the sum of squared difference between intensity distributions are known to be fragile. Ordinal measures which are based on relative ordering of intensity values in windows-rank permutations-have demonstrable robustness. By using distance metrics between two rank permutations, ordinal measures are defined. These measures are independent of absolute intensity scale and invariant to monotone transformations of intensity values like gamma variation between images. We have developed simple algorithms for their efficient implementation. Experiments suggest the superiority of ordinal measures over existing techniques under nonideal conditions. These measures serve as a general tool for image matching that are applicable to other vision problems such as motion estimation and texture-based image retrieval.	LG Elect Res Ctr Amer, Princeton, NJ 08550 USA; Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Columbia University	Bhat, DN (corresponding author), LG Elect Res Ctr Amer, 40 Washington Rd, Princeton, NJ 08550 USA.							BHAT DN, 1996, CUCS00996; Black M, 1992, THESIS YALE U; Conover WJ, 1980, PRACTICAL NONPARAMET; GEIGER D, 1992, P EUR C COMP VIS, P423; GIDEON RA, 1987, J AM STAT ASSOC, V82, P656; Kendall M.G., 1990, RANK CORRELATION MET, V5th; Kories R., 1986, Proceedings of the Workshop on Motion: Representation and Analysis (Cat. No.86CH2322-6), P101; OKUTOMI M, 1992, INT J COMPUT VISION, V7, P1499; QUAM L, 1984, P IMAGE UNDERSTANDIN, P149; [No title captured]	10	203	253	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1998	20	4					415	423		10.1109/34.677275	http://dx.doi.org/10.1109/34.677275			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZP214					2022-12-18	WOS:000073729200008
J	Wilson, RC; Hancock, ER				Wilson, RC; Hancock, ER			Structural matching by discrete relaxation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						structural graph matching; discrete relaxation; energy minimization; Bayesian; graph edit; clutter; MAP estimation; SAR images; infrared images	PATTERN-RECOGNITION; RELATIONAL GRAPHS; COMPUTER VISION; IMAGES	This paper describes a Bayesian framework for performing relational graph matching by discrete relaxation. Our basic aim is to draw on this framework to provide a comparative evaluation of a number of contrasting approaches to relational matching. Broadly speaking there are two main aspects to this study. Firstly we locus on the issue of how relational inexactness may be quantified. We illustrate that several popular relational distance measures can be recovered as specific limiting cases of the Bayesian consistency measure. The second aspect of our comparison concerns the way in which structural inexactness is controlled. We investigate three different realizations ai the matching process which draw on contrasting control models. The main conclusion of our study is that the active process of graph-editing outperforms the alternatives in terms of its ability to effectively control a large population of contaminating clutter.			Wilson, RC (corresponding author), UNIV YORK, DEPT COMP SCI, YORK YO1 5DD, N YORKSHIRE, ENGLAND.		Hancock, Edwin/N-7548-2019; Hancock, Edwin R/C-6071-2008	Hancock, Edwin/0000-0003-4496-2028; Hancock, Edwin R/0000-0003-4496-2028				Barrow H. G., 1971, Machine Intelligence Volume 6, P377; Barrow H. G., 1976, Information Processing Letters, V4, P83, DOI 10.1016/0020-0190(76)90049-1; BOYER KL, 1988, IEEE T PATTERN ANAL, V10, P144, DOI 10.1109/34.3880; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; Christmas WJ, 1996, IMAGE VISION COMPUT, V14, P617, DOI 10.1016/0262-8856(96)01093-1; DICKINSON SJ, 1992, IEEE T PATTERN ANAL, V14, P174, DOI 10.1109/34.121788; FAUGERAS OD, 1981, IEEE T PATTERN ANAL, V3, P633, DOI 10.1109/TPAMI.1981.4767164; Finch AM, 1997, PATTERN RECOGN, V30, P123, DOI 10.1016/S0031-3203(96)00060-X; FLYNN PJ, 1991, IEEE T PATTERN ANAL, V13, P114, DOI 10.1109/34.67642; FOGEL DB, 1994, IEEE T NEURAL NETWOR, V5, P3, DOI 10.1109/72.265956; GARDNER E, 1986, J PHYS A-MATH GEN, V19, P1047, DOI 10.1088/0305-4470/19/16/017; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GLOVER F, 1994, DISCRETE APPL MATH, V49, P231, DOI 10.1016/0166-218X(94)90211-9; GLOVER F, 1995, DISCRETE APPL MATH, V49, P111; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Hancock E. R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P300, DOI 10.1109/CVPR.1993.340965; HANCOCK ER, 1990, PATTERN RECOGN, V23, P711, DOI 10.1016/0031-3203(90)90094-2; HANCOCK ER, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P341, DOI 10.1109/ICNN.1993.298580; HORAUD R, 1989, IEEE T PATTERN ANAL, V11, P1168, DOI 10.1109/34.42855; KIM WY, 1991, IEEE T PATTERN ANAL, V13, P224, DOI 10.1109/34.75511; MESSMER BT, 1994, SHAPE STRUCTURE PATT, P231; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175; SENGUPTA K, 1995, IEEE T PATTERN ANAL, V17, P321, DOI 10.1109/34.385984; SHAPIRO LG, 1985, IEEE T PATTERN ANAL, V7, P90, DOI 10.1109/TPAMI.1985.4767621; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144; Simic PD, 1991, NEURAL COMPUT, V3, P268, DOI 10.1162/neco.1991.3.2.268; SUGANTHAN PN, 1995, PATTERN RECOGN, V28, P997, DOI 10.1016/0031-3203(94)00166-J; WILLIAMS ML, IN PRESS LECT NOTES; Wilson RC, 1996, PATTERN RECOGN LETT, V17, P263, DOI 10.1016/0167-8655(95)00115-8; WILSON RC, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P450, DOI 10.1109/ICCV.1995.466905; WILSON RC, 1995, IMAGE VISION COMPUT, V13, P411, DOI 10.1016/0262-8856(95)99728-J; WONG AKC, 1985, IEEE T PATTERN ANAL, V7, P599, DOI 10.1109/TPAMI.1985.4767707; YANG D, 1994, P 12 INT C PATT REC, V2, P219	35	203	205	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1997	19	6					634	648		10.1109/34.601251	http://dx.doi.org/10.1109/34.601251			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XG302		Green Accepted, Green Published			2022-12-18	WOS:A1997XG30200008
J	METAXAS, D; TERZOPOULOS, D				METAXAS, D; TERZOPOULOS, D			SHAPE AND NONRIGID MOTION ESTIMATION THROUGH PHYSICS-BASED SYNTHESIS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ANALYSIS BY SYNTHESIS; COMPUTER VISION; CONSTRAINTS; DEFORMABLE MODELS; KALMAN FILTERING; NONRIGID MOTION ESTIMATION; PHYSICS-BASED MODELING	GLOBAL DEFORMATIONS; SUPERQUADRICS; RECOVERY; IMAGES; MODELS	This paper presents a physics-based framework for 3-D shape and nonrigid motion estimation aimed at real-time computer vision. The framework features dynamic models that incorporate the mechanical principles of rigid and nonrigid bodies into conventional geometric primitives. Through the efficient numerical simulation of Lagrange equations of motion, the models can synthesize physically correct behaviors in response to applied forces and imposed constraints. We exploit the shape and motion synthesis capabilities of our models for the purposes of visual estimation. Applying continuous nonlinear Kalman filtering theory, we construct a recursive shape and motion estimator that employs the Lagrange equations as a system model. We interpret the continuous Kalman filter physically: The system model continually synthesizes nonrigid motion in response to generalized forces that arise from the inconsistency between the incoming observations and the estimated model state. The observation forces also account formally for instantaneous uncertainties and incomplete information. A Riccati procedure updates a covariance matrix that transforms the forces in accordance with the system dynamics and prior observation history. The transformed forces modify the translational, rotational, and deformational state variables of the system model to reduce inconsistency, thus producing nonstationary shape and motion estimates from the time-varying visual data. We demonstrate the dynamic estimator in experiments involving model fitting and tracking of articulated and flexible objects from noisy 3-D data.	UNIV TORONTO, DEPT COMP SCI, TORONTO M5S 1A4, ONTARIO, CANADA	University of Toronto	METAXAS, D (corresponding author), UNIV PENN, DEPT COMP & INFORMAT SCI, PHILADELPHIA, PA 19104 USA.							Barr A. H., 1984, Computers & Graphics, V18, P21; Barzel R., 1988, Computer Graphics, V22, P179, DOI 10.1145/378456.378509; BAUMGARTE J, 1972, COMPUTER METHODS APP, V1, P1, DOI DOI 10.1016/0045-7825(72)90018-7; Blake A., 1992, ACTIVE VISION; BROIDA TJ, 1990, IEEE T AERO ELEC SYS, V26, P639, DOI 10.1109/7.55557; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; CHEN CW, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P456; DERICHE R, 1990, IMAGE VISION COMPUT, V8, P261, DOI 10.1016/0262-8856(90)80002-B; Dickmanns E.D., 1988, MACH VISION APPL, V1, P241; DICKMANNS ED, 1988, MACH VISION APPL, V1, P223; DUNCAN JS, 1991, IEEE COMPUT VISION P, P318; Gelb A., 1974, APPL OPTIMAL ESTIMAT; Goldgof D. B., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P375, DOI 10.1109/CVPR.1988.196262; HEEL J, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P292; HUANG TS, 1990, 10TH P INT C PATT RE, P361; Kardestuncer Hayrettin, 1987, FINITE ELEMENT HDB; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032; METAXAS D, 1992, THESIS U TORONTO TOR; METAXAS D, 1992, JUL P COMP GRAPH ACM, V26, P309; METAXAS D, 1991, JUN IEEE C COMP VIS, P337; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P730, DOI 10.1109/34.85661; Shabana A. A, 1989, DYNAMICS MULTIBODY S; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; SZELISKI R, 1991, JUL P SPIE INT SOC O, V1570, P140; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; TERZOPOULOS D, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P606; WANG YF, 1992, IEEE T PATTERN ANAL, V14, P572, DOI 10.1109/34.134061; Wittenburg J., 1977, DYNAMICS SYSTEMS RIG	30	203	211	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1993	15	6					580	591		10.1109/34.216727	http://dx.doi.org/10.1109/34.216727			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LF257		Green Published			2022-12-18	WOS:A1993LF25700006
J	Couprie, C; Grady, L; Najman, L; Talbot, H				Couprie, Camille; Grady, Leo; Najman, Laurent; Talbot, Hugues			Power Watershed: A Unifying Graph-Based Optimization Framework	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Combinatorial optimization; image segmentation; graph cuts; random walker; shortest paths; optimal spanning forests; Markov random fields	IMAGE; SEGMENTATION; ALGORITHM; RECONSTRUCTION; RESTORATION; MINIMUM; MAXIMUM; TREE	In this work, we extend a common framework for graph-based image segmentation that includes the graph cuts, random walker, and shortest path optimization algorithms. Viewing an image as a weighted graph, these algorithms can be expressed by means of a common energy function with differing choices of a parameter q acting as an exponent on the differences between neighboring nodes. Introducing a new parameter p that fixes a power for the edge weights allows us to also include the optimal spanning forest algorithm for watershed in this same framework. We then propose a new family of segmentation algorithms that fixes p to produce an optimal spanning forest but varies the power q beyond the usual watershed algorithm, which we term the power watershed. In particular, when q = 2, the power watershed leads to a multilabel, scale and contrast invariant, unique global optimum obtained in practice in quasi-linear time. Placing the watershed algorithm in this energy minimization framework also opens new possibilities for using unary terms in traditional watershed segmentation and using watershed to optimize more general models of use in applications beyond image segmentation.	[Couprie, Camille; Najman, Laurent; Talbot, Hugues] Univ Paris Est, Lab Informat Gaspard Monge, Equipe A3SI, ESIEE Paris, F-93160 Noisy Le Grand, France; [Grady, Leo] Siemens Corp Res, Dept Imaging & Visualizat, Princeton, NJ 08540 USA	Universite Gustave-Eiffel; ESIEE Paris; Siemens AG	Couprie, C (corresponding author), Univ Paris Est, Lab Informat Gaspard Monge, Equipe A3SI, ESIEE Paris, 2 Blvd Blaise Pascal,Cite DESCARTES BP 99, F-93160 Noisy Le Grand, France.	C.Couprie@esiee.fr; Leo.Grady@siemens.com; L.Najman@esiee.fr; H.Talbot@esiee.fr	Najman, Laurent/AAB-4212-2020; couprie, camille/H-4092-2014	Najman, Laurent/0000-0002-6190-0235; 				Allene, 2007, MATH MORPHOLOGY ITS, V1, P253; ALLENE C, 2009, IMAGE VISION COMPUTI; Alvino C, 2007, INT J COMPUT MATH, V84, P1309, DOI 10.1080/00207160701324249; Anandkumar A, 2007, INT CONF ACOUST SPEE, P829; ANGULO J, 2007, P 8 INT S MATH MORPH, P265; Appleton B, 2006, IEEE T PATTERN ANAL, V28, P106, DOI 10.1109/TPAMI.2006.12; Arbelaez PA, 2006, INT J COMPUT VISION, V69, P119, DOI 10.1007/s11263-006-6857-5; Audigier R, 2007, J MATH IMAGING VIS, V27, P157, DOI 10.1007/s10851-007-0780-4; Bai XF, 2007, IEEE IC COMP COM NET, P1; Bertrand G, 2005, J MATH IMAGING VIS, V22, P217, DOI 10.1007/s10851-005-4891-5; Beucher S., 1993, MATH MORPHOLOGY IMAG, P433, DOI DOI 10.1201/9781482277234-12; Bieniek A, 2000, PATTERN RECOGN, V33, P907, DOI 10.1016/S0031-3203(99)00154-5; Blake A, 2004, LECT NOTES COMPUT SC, V3021, P428; Bournan C, 1993, IEEE T IMAGE PROCESS, V2, P296, DOI 10.1109/83.236536; Boykov Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P26; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Breen EJ, 1996, COMPUT VIS IMAGE UND, V64, P377, DOI 10.1006/cviu.1996.0066; Chazelle B, 2000, J ACM, V47, P1028, DOI 10.1145/355541.355562; Cohen LD, 1997, INT J COMPUT VISION, V24, P57, DOI 10.1023/A:1007922224810; Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7426, DOI 10.1073/pnas.0500334102; Couprie C, 2010, IEEE IMAGE PROC, P4153, DOI 10.1109/ICIP.2010.5653896; Couprie C, 2009, IEEE I CONF COMP VIS, P731, DOI 10.1109/ICCV.2009.5459284; Couprie M, 2005, J MATH IMAGING VIS, V22, P231, DOI 10.1007/s10851-005-4892-4; COUSTY J, 2007, P 7 INT S MATH MORPH, V1, P301; Cousty J, 2009, IEEE T PATTERN ANAL, V31, P1362, DOI 10.1109/TPAMI.2008.173; Cousty J, 2010, IEEE T PATTERN ANAL, V32, P925, DOI 10.1109/TPAMI.2009.71; Criminisi A, 2008, LECT NOTES COMPUT SC, V5302, P99, DOI 10.1007/978-3-540-88682-2_9; DUCHENNE O, 2008, P IEEE CS C COMP VIS; Falcao AX, 1998, GRAPH MODEL IM PROC, V60, P233, DOI 10.1006/gmip.1998.0475; Falcao AX, 2004, IEEE T PATTERN ANAL, V26, P19, DOI 10.1109/TPAMI.2004.1261076; GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GEMAN S, 1987, P 46 SESS INT STAT I, V52, P4; GERAUD T, 2010, MATH MORPHOLOGY THEO, P345; Grady L., 2008, P EUR C COMP VIS, P252; GRADY L, 2008, P IEEE CS C COMP VIS; Grady L.J., 2010, DISCRETE CALCULUS AP; Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233; Grady L, 2010, IEEE T PATTERN ANAL, V32, P321, DOI 10.1109/TPAMI.2008.289; GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x; Guigues L, 2006, INT J COMPUT VISION, V68, P289, DOI 10.1007/s11263-005-6299-0; GUILLATAUD P, 1992, THESIS U BORDEAUX 1; HANUSSE P, 1992, P 8 RFIA, V2, P577; KAUFHOLD JP, 2000, THESIS BOSTON U; KOHLI P, 2007, P IEEE CS C COMP VIS; KOHLI P, 2008, P IEEE CS C COMP VIS; KRAJSEK K, 2010, P IEEE C COMP VIS PA; Kruskal J. B., 1956, P AM MATH SOC, V7, P48, DOI [DOI 10.1090/S0002-9939-1956-0078686-7, 10.2307/2033241]; LEMPITSKY VS, 2008, P IEEE CS C COMP VIS; Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177; LEVITAN E, 1987, IEEE T MED IMAGING, V6, P185, DOI 10.1109/TMI.1987.4307826; Li YP, 2008, LECT NOTES COMPUT SC, V5303, P379; Matas P, 2008, LECT NOTES COMPUT SC, V5259, P230, DOI 10.1007/978-3-540-88458-3_21; Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M; MEYER F, 2010, MATH MORPHOLOGY THEO, P255; MICHAEL HS, 2003, P IEEE INT C COMP VI, P840; Mortensen EN, 1998, GRAPH MODEL IM PROC, V60, P349, DOI 10.1006/gmip.1998.0480; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; NAJMAN L, 1994, SIGNAL PROCESS, V38, P99, DOI 10.1016/0165-1684(94)90059-0; Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254; NAJMAN L, 2009, P 9 INT S MATH MORPH, P181; Najman L, 2010, MATH MORPHOLOGY THEO; NAJMAN L, 2010, ABS10021887 CORR; Najman L, 2006, IEEE T IMAGE PROCESS, V15, P3531, DOI 10.1109/TIP.2006.877518; PRIM RC, 1957, AT&T TECH J, V36, P1389, DOI 10.1002/j.1538-7305.1957.tb01515.x; Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187; ROTHER C, 2004, P ACM SIGGRAPH, P309; Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500; SAMUEL KGG, 2009, P IEEE C COMP VIS PA; SCHMIDT U, 2010, P IEEE C COMP VIS PA; SHEN R, 2008, P INT C PATT REC; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; SINGARAJU D, 2009, P IEEE CS C COMP VIS; SINGARAJU D, 2010, ADV MARKOV RANDOM FI; SINOP AK, 2007, P IEEE INT C COMP VI; STRANG G, 1982, P US JAP SEM NONL PA, P273; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; Tappen M. F., 2007, P IEEE C COMP VIS PA, P1; TARJAN RE, 1975, J ACM, V22, P215, DOI 10.1145/321879.321884; UNGER M, 2008, P BRIT MACH VIS C; VICENTE S, 2008, P IEEE CS C COMP VIS; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222; Wilkinson MHF, 2008, IEEE T PATTERN ANAL, V30, P1800, DOI 10.1109/TPAMI.2007.70836; Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005; Yang L, 2004, INT C PATT RECOG, P303, DOI 10.1109/ICPR.2004.1334180	88	202	209	0	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2011	33	7					1384	1399		10.1109/TPAMI.2010.200	http://dx.doi.org/10.1109/TPAMI.2010.200			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	763QE	21079274	Green Submitted			2022-12-18	WOS:000290574000008
J	Mallapragada, PK; Jin, R; Jain, AK; Liu, Y				Mallapragada, Pavan Kumar; Jin, Rong; Jain, Anil K.; Liu, Yi			SemiBoost: Boosting for Semi-Supervised Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Machine learning; semi-supervised learning; semi-supervised improvement; manifold assumption; cluster assumption; boosting		Semi-supervised learning has attracted a significant amount of attention in pattern recognition and machine learning. Most previous studies have focused on designing special algorithms to effectively exploit the unlabeled data in conjunction with labeled data. Our goal is to improve the classification accuracy of any given supervised learning algorithm by using the available unlabeled examples. We call this as the Semi-supervised improvement problem, to distinguish the proposed approach from the existing approaches. We design a metasemi-supervised learning algorithm that wraps around the underlying supervised algorithm and improves its performance using unlabeled data. This problem is particularly important when we need to train a supervised learning algorithm with a limited number of labeled examples and a multitude of unlabeled examples. We present a boosting framework for semi-supervised learning, termed as SemiBoost. The key advantages of the proposed semi-supervised learning approach are: 1) performance improvement of any supervised learning algorithm with a multitude of unlabeled data, 2) efficient computation by the iterative boosting algorithm, and 3) exploiting both manifold and cluster assumption in training classification models. An empirical study on 16 different data sets and text categorization demonstrates that the proposed framework improves the performance of several commonly used supervised learning algorithms, given a large number of unlabeled examples. We also show that the performance of the proposed algorithm, SemiBoost, is comparable to the state-of-the-art semi-supervised learning algorithms.	[Mallapragada, Pavan Kumar; Jin, Rong; Jain, Anil K.; Liu, Yi] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48823 USA	Michigan State University	Mallapragada, PK (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, 3115 Engn Bldg, E Lansing, MI 48823 USA.	pavanm@cse.msu.edu; rongjin@cse.msu.edu; jain@cse.msu.edu; liuyiyi@gmail.com			US Office of Naval Research [N000140710225]; US National Science Foundation [IIS-0643494]	US Office of Naval Research(Office of Naval Research); US National Science Foundation(National Science Foundation (NSF))	The authors thank the anonymous reviewers for their valuable comments. The research was partially supported by US Office of Naval Research grant no. N000140710225 and US National Science Foundation grant no. IIS-0643494.	BELKIN M, 2004, T200406 U CHIC DEP C; Bengio Y., 2006, SEMISUPERVISED LEARN, P193, DOI [10.7551/mitpress/9780262033589.003.0011, DOI 10.7551/MITPRESS/9780262033589.003.0011]; Bennett K.P., 2002, P 8 ACM SIGKDD INT C, P289; Bennett KP, 1999, ADV NEUR IN, V11, P368; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Blum A., 2001, P INT C MACH LEARN I, P19, DOI DOI 10.1184/R1/6606860.V1; BUC FD, 2002, P NEUR INF PROC SYST, P553; Chapelle O., 2006, IEEE T NEURAL NETW, V20, P542; Chapelle O, 2005, P 10 INT WORKSH ART, V2005, P57; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Freund Y, 1996, P 13 INT C MACH LEAR, P148, DOI DOI 10.5555/3091696.3091715; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Fung G, 2001, OPTIM METHOD SOFTW, V15, P29, DOI 10.1080/10556780108805809; JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; Joachims T., 2003, P 20 INT C MACH LEAR, P290, DOI DOI 10.1145/2612669.2612699; LAWRENCE ND, 2005, P ADV NEUR INF PROC, P753; Lu XG, 2004, P SOC PHOTO-OPT INS, V5404, P114, DOI 10.1117/12.542847; MALLAPRAGADA PK, 2007, MSUCSE07197; Mason L, 2000, ADV NEUR IN, V12, P512; MILLER DJ, 1996, P ANN C NEUR INF PRO, P571; Minka T, 1998, EXPECTATION MAXIMIZA; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Platt JC, 2000, ADV NEUR IN, V12, P547; Reyzin L., 2006, PROC 23 INT C MACH L, P753, DOI DOI 10.1145/1143844.1143939; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; Rosenberg C, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P29; SCUDDER HJ, 1965, IEEE T INFORM THEORY, V11, P363, DOI 10.1109/tit.1965.1053799; SZUMMER M, 2001, NIPS, P945; VURAL V, OPTIMIZATIO IN PRESS; Witten I.H., 2005, P DATA MINING LAS VE, P4; ZHOU D, 2005, P 22 INT C MACH LEAR, P1036; Zhu X., 2003, INT C MACH LEARN; Zhu X, 2002, LEARNING LABELED UNL	34	202	228	3	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2009	31	11					2000	2014		10.1109/TPAMI.2008.235	http://dx.doi.org/10.1109/TPAMI.2008.235			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	493VV	19762927	Green Submitted			2022-12-18	WOS:000269767600006
J	Kim, TK; Kittler, J				Kim, TK; Kittler, J			Locally linear discriminant analysis for multimodally distributed classes for face recognition with a single model image	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						linear discriminant analysis; generalized discriminant analysis; support vector machine; dimensionality reduction; face recognition; feature extraction; pose invariance; subspace representation		We present a novel method of nonlinear discriminant analysis involving a set of locally linear transformations called "Locally Linear Discriminant Analysis (LLDA)." The underlying idea is that global nonlinear data structures are locally linear and local structures can be linearly aligned. Input vectors are projected into each local feature space by linear transformations found to yield locally linearly transformed classes that maximize the between-class covariance while minimizing the within-class covariance. In face recognition, linear discriminant analysis (LDA) has been widely adopted owing to its efficiency, but it does not capture nonlinear manifolds of faces which exhibit pose variations. Conventional nonlinear classification methods based on kernels such as generalized discriminant analysis (GDA) and support vector machine (SVM) have been developed to overcome the shortcomings of the linear method, but they have the drawback of high computational cost of classification and overfitting. Our method is for multiclass nonlinear discrimination and it is computationally highly efficient as compared to GDA. The method does not suffer from overfitting by virtue of the linear base structure of the solution. A novel gradient-based learning algorithm is proposed for finding the optimal set of local linear bases. The optimization does not exhibit a local-maxima problem. The transformation functions facilitate robust face recognition in a low-dimensional subspace, under pose variations, using a single model image. The classification results are given for both synthetic and real face data.	Samsung Adv Inst Technol, Comp Lab, Yongin 449712, Kyungki Do, South Korea; Univ Surrey, Ctr Vis Speech & Signal Proc, Surrey GU2 7XH, England	Samsung; University of Surrey	Kim, TK (corresponding author), Samsung Adv Inst Technol, Comp Lab, San 14-1, Yongin 449712, Kyungki Do, South Korea.	ktk22@hanmail.net; j.kittler@eim.surrey.ac.uk						Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; BLACKBURN DM, 2000, FACIAL RECOGNITION V; BLANZ V, 2002, IEEE C AUT FAC GEST, P192; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Gong SG, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P265, DOI 10.1109/AFGR.1996.557275; GRAHAM DB, 1998, P BRIT MACHINE VISIO, P64; Gross R, 2004, IEEE T PATTERN ANAL, V26, P449, DOI 10.1109/TPAMI.2004.1265861; He XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P385, DOI 10.1109/ICCV.2003.1238370; HEISELE B, 2001, P 8 IEEE INT C COMP, V2, P688; Hyvarinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71; Kee S., 2003, P BRIT MACHINE VISIO, P123; Kim HC, 2002, INT C PATT RECOG, P486, DOI 10.1109/ICPR.2002.1048344; KIM TK, 2003, P COMPUTER VISION PA, V1, P579; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Lee DD, 2001, ADV NEUR IN, V13, P556; LI Y, 2001, P IEEE C COMP VIS PA, V2, P258; Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121; Okada K, 2001, PROC CVPR IEEE, P761; OKADA T, 1985, PATTERN RECOGN, V18, P139, DOI 10.1016/0031-3203(85)90037-8; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814; PHILLIPS PJ, 2003, FRVT 2002 EVALUATION; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Sun M, 2002, P ANN INT IEEE EMBS, P2027; Tae-Kyun Kim, 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P507; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Vetter T, 1997, IEEE T PATTERN ANAL, V19, P733, DOI 10.1109/34.598230; Yang MH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P215; Zhao MH, 1998, ENG ANAL BOUND ELEM, V21, P169, DOI 10.1016/S0955-7997(98)00033-2; Zhao WY, 2000, INT C PATT RECOG, P818, DOI 10.1109/ICPR.2000.906201	34	202	217	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2005	27	3					318	327		10.1109/TPAMI.2005.58	http://dx.doi.org/10.1109/TPAMI.2005.58			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	887IW	15747788				2022-12-18	WOS:000226300200002
J	NITZBERG, M; SHIOTA, T				NITZBERG, M; SHIOTA, T			NONLINEAR IMAGE FILTERING WITH EDGE AND CORNER ENHANCEMENT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						ADAPTIVE FILTERING; CORNER DETECTION; CORNER ENHANCEMENT; EDGE ENHANCEMENT; NONLINEAR DIFFUSION; NONLINEAR FILTERING; T-JUNCTION		We describe a method of nonlinear image filtering for noise reduction and edge enhancement using anisotropic diffusion. The method is designed to enhance not only edges but corners and T junctions as well. As in the recent work of Perona and Malik [1], the method roughly corresponds to a nonlinear diffusion process with backward heat flow across the strong edges. Such a process is ill posed, making the results depend strongly on how the algorithm differs from the diffusion process. We study two ways of modifying the equations using simulations on a variable grid.	KYOTO UNIV,MATH SCI RES INST,KYOTO 606,JAPAN	Kyoto University	NITZBERG, M (corresponding author), HARVARD UNIV,DIV APPL SCI,CAMBRIDGE,MA 02138, USA.							Flannery B.P., 1988, NUMERICAL RECIPES C; GRAHAM RE, 1962, IRE T INF THEORY, V9, P129; KANIZSA G, 1979, ORG VISION, pCH1; KELLMAN PJ, IN PRESS VISUAL INTE; KITCHEN L, 1980, TR887 U MAR COMP SCI; LEV A, 1977, IEEE T SYST MAN CYB, V7, P435, DOI 10.1109/TSMC.1977.4309740; NAGAO M, 1979, COMPUT VISION GRAPH, V9, P394, DOI 10.1016/0146-664X(79)90102-3; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; NAKAYAMA K, IN PRESS P COLD SPRI, V55; NEWMAN TG, 1973, IEEE T COMPUT, VC 22, P869, DOI 10.1109/TC.1973.5009186; NITZBERG M, 1990 P ICCV; NITZBERG M, 1991, THESIS HARVARD U CAM; NITZBERG M, 1990, 902 HARV U HARV ROB; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; VONDERHEYDT R, 1984, SCIENCE, V224, P1260, DOI 10.1126/science.6539501	15	202	220	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1992	14	8					826	833		10.1109/34.149593	http://dx.doi.org/10.1109/34.149593			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JG613					2022-12-18	WOS:A1992JG61300003
J	Xu, H; Ma, JY; Jiang, JJ; Guo, XJ; Ling, HB				Xu, Han; Ma, Jiayi; Jiang, Junjun; Guo, Xiaojie; Ling, Haibin			U2Fusion: A Unified Unsupervised Image Fusion Network	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image fusion; unified model; unsupervised learning; continual learning	MULTI-FOCUS IMAGE; FRAMEWORK	This study proposes a novel unified and unsupervised end-to-end image fusion network, termed as U2Fusion, which is capable of solving different fusion problems, including multi-modal, multi-exposure, and multi-focus cases. Using feature extraction and information measurement, U2Fusion automatically estimates the importance of corresponding source images and comes up with adaptive information preservation degrees. Hence, different fusion tasks are unified in the same framework. Based on the adaptive degrees, a network is trained to preserve the adaptive similarity between the fusion result and source images. Therefore, the stumbling blocks in applying deep learning for image fusion, e.g., the requirement of ground-truth and specifically designed metrics, are greatly mitigated. By avoiding the loss of previous fusion capabilities when training a single model for different tasks sequentially, we obtain a unified model that is applicable to multiple fusion tasks. Moreover, a new aligned infrared and visible image dataset, RoadScene (available at https://github.com/hanna-xu/RoadScene), is released to provide a new option for benchmark evaluation. Qualitative and quantitative experimental results on three typical image fusion tasks validate the effectiveness and universality of U2Fusion. Our code is publicly available at https://github.com/hanna-xu/U2Fusion.	[Xu, Han; Ma, Jiayi] Wuhan Univ, Elect Informat Sch, Wuhan 430072, Peoples R China; [Jiang, Junjun] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China; [Guo, Xiaojie] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China; [Ling, Haibin] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA	Wuhan University; Harbin Institute of Technology; Tianjin University; State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	Ma, JY (corresponding author), Wuhan Univ, Elect Informat Sch, Wuhan 430072, Peoples R China.	xu_han@whu.edu.cn; jyma2010@gmail.com; jiangjunjun@hit.edu.cn; xj.max.guo@gmail.com; haibin.ling@gmail.com	Guo, Xiaojie/AAC-3114-2022	Xu, Han/0000-0002-6291-2924; Ma, Jiayi/0000-0003-3264-3265	National Natural Science Foundation of China [61773295, 61971165, 61772512]; Natural Science Foundation of Hubei Province [2019CFA037]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Hubei Province(Natural Science Foundation of Hubei Province)	This work was supported by the National Natural Science Foundation of China under Grants 61773295, 61971165 and 61772512, and the Natural Science Foundation of Hubei Province under Grant no. 2019CFA037.This work was supported by the National Natural Science Foundation of China under Grants 61773295, 61971165 and 61772512, and the Natural Science Foundation of Hubei Province under Grant no. 2019CFA037.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Aslantas V, 2015, AEU-INT J ELECTRON C, V69, P160, DOI 10.1016/j.aeue.2015.09.004; Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218; Cao L, 2015, IEEE SIGNAL PROC LET, V22, P220, DOI 10.1109/LSP.2014.2354534; Das S, 2013, IEEE T BIO-MED ENG, V60, P3347, DOI 10.1109/TBME.2013.2282461; Eichel J. A., 2015, ARXIV151002055; Guo XP, 2019, IEEE T MULTIMEDIA, V21, P1982, DOI 10.1109/TMM.2019.2895292; Han Y, 2013, INFORM FUSION, V14, P127, DOI 10.1016/j.inffus.2011.08.002; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114; Lee SW, 2017, ADV NEUR IN, V30; Li H, 2019, IEEE T IMAGE PROCESS, V28, P2614, DOI 10.1109/TIP.2018.2887342; Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004; Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222; Li ZZ, 2018, IEEE T PATTERN ANAL, V40, P2935, DOI 10.1109/TPAMI.2017.2773081; Liu Y, 2018, INFORM FUSION, V42, P158, DOI 10.1016/j.inffus.2017.10.007; Liu Y, 2017, 2017 20TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1070; Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001; Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776; Liu Y, 2015, J VIS COMMUN IMAGE R, V31, P208, DOI 10.1016/j.jvcir.2015.06.021; Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004; Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109; Ma B, 2019, ARXIV PREPRINT ARXIV; Ma JY, 2020, IEEE T IMAGE PROCESS, V29, P4980, DOI 10.1109/TIP.2020.2977573; Ma JY, 2020, INFORM FUSION, V54, P85, DOI 10.1016/j.inffus.2019.07.005; Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004; Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004; Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001; Ma KD, 2018, IEEE T COMPUT IMAG, V4, P60, DOI 10.1109/TCI.2017.2786138; Mai GC, 2019, IEEE T PATTERN ANAL, V41, P1188, DOI 10.1109/TPAMI.2018.2827389; Paul S, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501231; Prabhakar KR, 2017, IEEE I CONF COMP VIS, P4724, DOI 10.1109/ICCV.2017.505; Qi YK, 2019, IEEE T PATTERN ANAL, V41, P1116, DOI 10.1109/TPAMI.2018.2828817; Qiu XH, 2019, SIGNAL PROCESS-IMAGE, V72, P35, DOI 10.1016/j.image.2018.12.004; Sugianto N., 2019, P IEEE INT C ADV VID, P1; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929; Xia R, 2017, IEEE T AFFECT COMPUT, V8, P3, DOI 10.1109/TAFFC.2015.2512598; Xu H, 2020, AAAI CONF ARTIF INTE, V34, P12484; Xu H, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3954; Yang Y, 2018, IEEE SIGNAL PROC LET, V25, P1885, DOI 10.1109/LSP.2018.2877893; Yin M, 2019, IEEE T INSTRUM MEAS, V68, P49, DOI 10.1109/TIM.2018.2838778; Zenke F, 2017, PR MACH LEARN RES, V70; Zhang H, 2018, IEEE COMPUT SOC CONF, P1015, DOI 10.1109/CVPRW.2018.00135; Zhang Q, 2018, INFORM FUSION, V40, P57, DOI 10.1016/j.inffus.2017.05.006; Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93; Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011; Zhou ZQ, 2016, INFORM FUSION, V30, P15, DOI 10.1016/j.inffus.2015.11.003; Zhu ZQ, 2019, IEEE ACCESS, V7, P20811, DOI 10.1109/ACCESS.2019.2898111	50	201	205	127	263	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					502	518		10.1109/TPAMI.2020.3012548	http://dx.doi.org/10.1109/TPAMI.2020.3012548			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	32750838				2022-12-18	WOS:000728561300036
J	Lisanti, G; Masi, I; Bagdanov, AD; Del Bimbo, A				Lisanti, Giuseppe; Masi, Iacopo; Bagdanov, Andrew D.; Del Bimbo, Alberto			Person Re-Identification by Iterative Re-Weighted Sparse Ranking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Person re-identification; video surveillance; sparse methods	PEDESTRIAN RECOGNITION	In this paper we introduce a method for person re-identification based on discriminative, sparse basis expansions of targets in terms of a labeled gallery of known individuals. We propose an iterative extension to sparse discriminative classifiers capable of ranking many candidate targets. The approach makes use of soft-and hard-re-weighting to redistribute energy among the most relevant contributing elements and to ensure that the best candidates are ranked at each iteration. Our approach also leverages a novel visual descriptor which we show to be discriminative while remaining robust to pose and illumination variations. An extensive comparative evaluation is given demonstrating that our approach achieves state-of-the-art performance on single-and multi-shot person re-identification scenarios on the VIPeR, i-LIDS, ETHZ, and CAVIAR4REID datasets. The combination of our descriptor and iterative sparse basis expansion improves state-of-the-art rank-1 performance by six percentage points on VIPeR and by 20 on CAVIAR4REID compared to other methods with a single gallery image per person. With multiple gallery and probe images per person our approach improves by 17 percentage points the state-of-the-art on i-LIDS and by 72 on CAVIAR4REID at rank-1. The approach is also quite efficient, capable of single-shot person re-identification over galleries containing hundreds of individuals at about 30 re-identifications per second.	[Lisanti, Giuseppe; Masi, Iacopo; Del Bimbo, Alberto] Univ Florence, MICC, I-50134 Florence, Italy; [Bagdanov, Andrew D.] Comp Vis Ctr, Barcelona, Spain; [Bagdanov, Andrew D.] Univ Florence, Media Integrat & Commun Ctr, Res Unit, I-50134 Florence, Italy	University of Florence; Centre de Visio per Computador (CVC); University of Florence	Lisanti, G (corresponding author), Univ Florence, MICC, I-50134 Florence, Italy.	giuseppe.lisanti@unifi.it; iacopo.masi@unifi.it; bagdanov@cvc.uab.es; alberto.delbimbo@unifi.it	Lisanti, Giuseppe/AAG-8699-2020	Lisanti, Giuseppe/0000-0002-0785-9972	Thales Italia; AQUIS-CH Fellowship (POR-CRO-FSE / UNIFI_FSE); Ramon y Cajal Fellowship [RYC-2012-11776]	Thales Italia(Thales Group); AQUIS-CH Fellowship (POR-CRO-FSE / UNIFI_FSE); Ramon y Cajal Fellowship(Spanish Government)	This work was partially supported by Thales Italia. G. Lisanti acknowledges the support of the AQUIS-CH Fellowship (POR-CRO-FSE 2007-2013/ UNIFI_FSE2012), and A. D. Bagdanov the support of a Ramon y Cajal Fellowship (RYC-2012-11776).	[Anonymous], 2007, P IEEE INT WORKSH PE; Avraham Tamar, 2012, Computer Vision - ECCV 2012. Proceedings of Workshops and Demonstrations, P381, DOI 10.1007/978-3-642-33863-2_38; Bak S., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P179, DOI 10.1109/AVSS.2011.6027316; Bak S., 2010, P 7 IEEE INT C ADV V, P179; Bak S, 2012, LECT NOTES COMPUT SC, V7574, P806, DOI 10.1007/978-3-642-33712-3_58; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Bazzani Loris, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1413, DOI 10.1109/ICPR.2010.349; Bazzani L, 2012, PATTERN RECOGN LETT, V33, P898, DOI 10.1016/j.patrec.2011.11.016; Candes EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x; Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68; Cinbis RG, 2012, PROC CVPR IEEE, P2184, DOI 10.1109/CVPR.2012.6247926; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dikmen M, 2011, LECT NOTES COMPUT SC, V6495, P501, DOI 10.1007/978-3-642-19282-1_40; Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067; Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Gandhi T., 2006, P IEEE INT C VID SIG, P78, DOI DOI 10.1109/AVSS.2006.90; Gheissari N., 2006, P IEEE C COMP VIS PA, V2, P1528, DOI DOI 10.1109/CVPR.2006.223; Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21; Hirzer M, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P203, DOI 10.1109/AVSS.2012.55; Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56; Jojic N, 2009, PROC CVPR IEEE, P2044, DOI 10.1109/CVPRW.2009.5206581; Kostinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939; Liu YG, 2011, IEEE T NEURAL NETWOR, V22, P1256, DOI 10.1109/TNN.2011.2153210; Mairal J, 2010, J MACH LEARN RES, V11, P19; Prosser B.J., 2010, BRIT MACH VIS C AB B, P1, DOI DOI 10.5244/C.24.21; Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Wu Y, 2012, LECT NOTES COMPUT SC, V7574, P497, DOI 10.1007/978-3-642-33712-3_36; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138; Zheng WS, 2012, PROC CVPR IEEE, P2650, DOI 10.1109/CVPR.2012.6247985; Zheng Wei-Shi, 2009, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.23.23	33	201	213	3	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2015	37	8					1629	1642		10.1109/TPAMI.2014.2369055	http://dx.doi.org/10.1109/TPAMI.2014.2369055			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CM3ON	26353000	Green Submitted			2022-12-18	WOS:000357591900008
J	Kumar, N; Berg, AC; Belhumeur, PN; Nayar, SK				Kumar, Neeraj; Berg, Alexander C.; Belhumeur, Peter N.; Nayar, Shree K.			Describable Visual Attributes for Face Verification and Image Search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; attribute classification; feature selection; classifier training; content-based image retrieval; image search	RECOGNITION; HUMANS	We introduce the use of describable visual attributes for face verification and image search. Describable visual attributes are labels that can be given to an image to describe its appearance. This paper focuses on images of faces and the attributes used to describe them, although the concepts also apply to other domains. Examples of face attributes include gender, age, jaw shape, nose size, etc. The advantages of an attribute-based representation for vision tasks are manifold: They can be composed to create descriptions at various levels of specificity; they are generalizable, as they can be learned once and then applied to recognize new objects or categories without any further training; and they are efficient, possibly requiring exponentially fewer attributes (and training data) than explicitly naming each category. We show how one can create and label large data sets of real-world images to train classifiers which measure the presence, absence, or degree to which an attribute is expressed in images. These classifiers can then automatically label new images. We demonstrate the current effectiveness-and explore the future potential-of using attributes for face verification and image search via human and computational experiments. Finally, we introduce two new face data sets, named FaceTracer and PubFig, with labeled attributes and identities, respectively.	[Kumar, Neeraj; Belhumeur, Peter N.; Nayar, Shree K.] Columbia Univ, Dept Comp Sci, New York, NY 10027 USA; [Berg, Alexander C.] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA	Columbia University; State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	Kumar, N (corresponding author), Columbia Univ, Dept Comp Sci, Room 450,500 W 120th St, New York, NY 10027 USA.	neeraj@cs.columbia.edu; aberg@cs.stonybrook.edu; belhumeur@cs.columbia.edu; nayar@cs.columbia.edu			US Office of Naval Research [N00014-08-1-0638]; IARPA [DA 911NF-10-2-0011]	US Office of Naval Research(Office of Naval Research); IARPA	The authors would like to thank Pietro Perona for suggesting the human attribute labels experiment described in Section 5.4. They are also grateful to the anonymous reviewers for their excellent suggestions. This work was supported in part by US Office of Naval Research Award N00014-08-1-0638 and IARPA DA 911NF-10-2-0011.	Baluja S, 2007, INT J COMPUT VISION, V71, P111, DOI 10.1007/s11263-006-8910-9; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Berg T.L., 2004, P IEEE CS C COMP VIS; Blanz V., 2002, P IEEE INT C AUT FAC; Bruce V, 1999, J EXP PSYCHOL-APPL, V5, P339, DOI 10.1037/1076-898X.5.4.339; Castillo C., 2007, P IEEE C COMP VIS PA; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; CHEN H, 2000, P IEEE C COMP VIS PA; COOTES T, 2000, P IEEE INT C AUT FAC; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; COTTRELL GW, 1990, P 1990 C ADV NEUR PR, P564; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Datta Ritendra, 2005, P MIR, P253; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Everingham M., 2012, PASCAL VISUAL OBJECT; Everingham M., 2006, BMVC, DOI DOI 10.5244/C.20.92; Farhadi Ali, 2009, CVPR; Ferencz A, 2008, INT J COMPUT VISION, V77, P3, DOI 10.1007/s11263-007-0093-5; FERRARI V, 2007, P ADV NEUR INF PROC; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; GOLOMB B, 1990, P 1990 C ADV NEUR IN, P572; GROSS R, 2001, P WORKSH EMP EV METH; Hua G, 2009, IEEE I CONF COMP VIS, P2082, DOI 10.1109/ICCV.2009.5459457; Huang G. B., 2008, P FAC REAL LIF IM WO; Huang Gary B., 2007, 0749 U MASS, P7; Huang GB, 2007, 07 UMASS TR; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; Kumar N., 2008, P EUR C COMP VIS; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005; LING H, 2007, P IEEE INT C COMP VI; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244; Nister David, 2006, CVPR, P2161, DOI DOI 10.1109/CVPR.2006.264; NOWAK E, 2007, P IEEE C COMP VIS PA; Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490; O'Toole AJ, 2007, IEEE T PATTERN ANAL, V29, P1642, DOI 10.1109/TPAMI.2007.1107; *OMR, 2010, OKAO VIS; PALATUCCI M, 2009, P C ADV NEUR INF PRO; Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143; PENTLAND A, 1994, P IEEE CS C COMP VIS; PHILLIPS P, 2006, P IEEE C AUT FAC GES; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; PHILLIPS PJ, 2005, P IEEE CS C COMP VIS; Pinto N., 2009, P IEEE C COMP VIS PA; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300; Shakhnarovich G., 2002, P IEEE INT C AUT FAC; Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130; Sinha P, 1996, NATURE, V384, P404, DOI 10.1038/384404a0; Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Taigman Y., 2009, P BRIT MACH VIS C; TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586; Viola P., 2001, IEEE COMP SOC C COMP; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; Wolf L., 2009, P AS C COMP VIS; Wolf L., 2008, P FACES REAL LIFE IM; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	62	201	221	1	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2011	33	10					1962	1977		10.1109/TPAMI.2011.48	http://dx.doi.org/10.1109/TPAMI.2011.48			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	808HQ					2022-12-18	WOS:000293969000005
J	Chiuso, A; Favaro, P; Jin, HL; Soatto, S				Chiuso, A; Favaro, P; Jin, HL; Soatto, S			Structure from motion causally integrated over time	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						structure from motion; real-time vision; shape; geometry	3-DIMENSIONAL MOTION; LONG SEQUENCE; SHAPE	We describe an algorithm for reconstructing three-dimensional structure and motion causally, in real time from monocular sequences of images. We prove that the algorithm is minimal and stable, in the sense that the estimation error remains bounded with probability one throughout a sequence of arbitrary length. We discuss a scheme for handling occlusions (point features appearing and disappearing) and drift in the scale factor. These issues are crucial for the algorithm to operate in real time on real scenes. We describe in detail the implementation of the algorithm, which runs on a personal computer and has been made available to the community. We report the performance of our implementation on a few representative long sequences of real and synthetic images. The algorithm, which has been tested extensively over the course of the past few years, exhibits honest performance when the scene contains at least 20-40 points with high contrast, when the relative motion is "slow" compared to the sampling frequency of the frame grabber (30Hz), and the lens aperture is "large enough" (typically more than 30degrees of visual field).	Univ Padua, Dipartimento Elettr & Informat, I-35131 Padua, Italy; Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA	University of Padua; University of California System; University of California Los Angeles	Chiuso, A (corresponding author), Univ Padua, Dipartimento Elettr & Informat, Via Gradenigo 6-A, I-35131 Padua, Italy.	chiuso@dei.unipd.it; favaro@cs.ucla.edu; hljin@ee.wustl.edu; soatto@ucla.edu		CHIUSO, ALESSANDRO/0000-0002-4410-6101				ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; Anderson B. D. O., 1979, OPTIMAL FILTERING; AZARBAYEJANI A, 1995, IEEE T PATTERN ANAL, V17, P562, DOI 10.1109/34.387503; Bartlett M., 1956, INTRO STOCHASTIC PRO; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; Chiuso A, 2000, INT J COMPUT VISION, V39, P195, DOI 10.1023/A:1026563712076; CHIUSO A, 1999, 9903 ESSRL; CUI N, 1994, CVGIP-IMAG UNDERSTAN, V59, P154, DOI 10.1006/ciun.1994.1010; DAYAWANSA WP, 1995, SYST CONTROL LETT, V25, P159, DOI 10.1016/0167-6911(94)00064-3; Dickmanns E.D., 1988, MACH VISION APPL, V1, P241; Faugeras Olivier, 1993, 3 DIMENSIONAL VISION, P2; FERMULLER C, 1992, BIOL CYBERN, V67, P259, DOI 10.1007/BF00204399; Gennery D B, 1982, P AAAI 2 NAT C ART I, P13; HEEL J, 1990, ROBOTICS AUTONOMOUS, V6; HU XP, 1993, IMAGE VISION COMPUT, V11, P549, DOI 10.1016/0262-8856(93)90021-8; Jazwinski A.H., 1970, STOCHASTIC PROCESSES; JEPSON A, 1991, TR9035 RBCV U TOR CS; JIN H, 2000, P IEEE C COMP VIS PA; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; KUMAR R, 1994, P IM UND WORKSH; Lucas Bruce, 1981, IJCAI; MATTHIES L, 1989, INT J COMPUT VISION, P2989; MCLAUCHLAN P, 1994, P EUR C COMP VIS MAY; MCLAUCHLAN PF, 1999, IEEE WORKSH MULT VIE; Oliensis J, 2000, IEEE T PATTERN ANAL, V22, P685, DOI 10.1109/34.865186; OLIENSIS J, 1992, P DARPA IM UND WORKS; OLIENSIS J, 1996, P IEEE C COMP VIS PA; PHILIP J, 1991, IEEE T PATTERN ANAL, V13, P61, DOI 10.1109/34.67631; POELMAN C, 1994, P EUR C COMP VIS; Reif K, 1999, IEEE T AUTOMAT CONTR, V44, P714, DOI 10.1109/9.754809; SAWHNEY HS, 1994, P INT C PATT REC JUN; SHAPIRO L, 1994, P EUR C COMP VIS; Soatto S, 1997, AUTOMATICA, V33, P1287, DOI 10.1016/S0005-1098(97)00048-4; Soatto S, 1998, IEEE T PATTERN ANAL, V20, P933, DOI 10.1109/34.713360; SOATTO S, 1994, IEEE DECIS CONTR P, P3235, DOI 10.1109/CDC.1994.411638; SPETSAKIS M, 1991, INT J COMPUT VISION, V6, P245, DOI 10.1007/BF00115698; SZELISKI R, 1994, J VISUAL COMM IMAGE; TAALEBINEZHAAD MA, 1992, IEEE T PATTERN ANAL, V14, P847, DOI 10.1109/34.149584; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074; ZHANG ZY, 1992, INT J COMPUT VISION, V7, P211, DOI 10.1007/BF00126394	41	201	213	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2002	24	4					523	535		10.1109/34.993559	http://dx.doi.org/10.1109/34.993559			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	534FM					2022-12-18	WOS:000174574100008
J	Chen, CS; Hung, YP; Cheng, JB				Chen, CS; Hung, YP; Cheng, JB			RANSAC-based DARCES: A new approach to fast automatic registration of partially overlapping range images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; range data; range image; registration; 3D imaging	OBJECT RECOGNITION	In this paper, we propose a new method, the RANSAC-based DARCES method, which can solve the partially overlapping 3D registration problem without any initial estimation. For the noiseless case, the basic algorithm of our method can guarantee that the solution it finds is the true one, and its time complexity can be shown to be relatively low. An extra characteristic is that our method can be used even for the case that there are no local features in the 3D data sets.	Acad Sinica, Inst Informat Sci, Taipei, Taiwan	Academia Sinica - Taiwan	Chen, CS (corresponding author), Acad Sinica, Inst Informat Sci, Taipei, Taiwan.	song@iis.sinica.edu.tw; hung@iis.sinica.edu.tw						BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BLAIS G, 1995, IEEE T PATTERN ANAL, V17, P820, DOI 10.1109/34.400574; Chen CS, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P242, DOI 10.1109/ICCV.1998.710725; Chen CS, 1997, IMAGE VISION COMPUT, V15, P445, DOI 10.1016/S0262-8856(96)01148-1; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Chua CS, 1996, INT J COMPUT VISION, V17, P77, DOI 10.1007/BF00127819; Dorai C, 1998, IEEE T PATTERN ANAL, V20, P83, DOI 10.1109/34.655652; HIGUCHI K, 1995, GRAPH MODEL IM PROC, V57, P315, DOI 10.1006/gmip.1995.1028; STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785; Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241	10	201	231	1	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1999	21	11					1229	1234		10.1109/34.809117	http://dx.doi.org/10.1109/34.809117			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	259YG					2022-12-18	WOS:000083921100013
J	WEI, GQ; DEMA, S				WEI, GQ; DEMA, S			IMPLICIT AND EXPLICIT CAMERA CALIBRATION - THEORY AND EXPERIMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						PROJECTIVE MAPPING; BACK-PROJECTION; PROJECTION; IMPLICIT DISTORTION COMPENSATION; PERSPECTIVITY CONDITIONS; PROJECTIVE INVARIANTS; EXPLICIT DISTORTION CORRECTION		By implicit camera calibration, we mean the process of calibrating a camera without explicitly computing its physical parameters. Implicit calibration can be used for both three-dimensional (3-D) measurement and generation of image coordinates. In this paper, we present a new implicit model based on the generalized projective mappings between the image plane and two calibration planes. The back-projection and projection processes are modelled separately to ease the computation of distorted image coordinates from known world points. A set of constraints of perspectivity is derived to relate the transformation parameters of the two calibration planes. Under the assumption of the radial distortion model, we present a computationally efficient method for explicitly correcting the distortion of image coordinates in frame buffer without involving the computation of camera position and orientation. By combining with any linear calibration techniques, this method makes explicit the camera physical parameters. Extensive experimental comparison of our methods with the classic photogrammetric method and Tsai's method in the aspects of 3-D measurement (both absolute and relative errors), the prediction of image coordinates, and the effect of the number of calibration points, is made using real images from 15 different depth values.	CHINESE ACAD SCI, INST AUTOMAT, NATL LAB PATTERN RECOGNIT, BEIJING 100080, PEOPLES R CHINA	Chinese Academy of Sciences; Institute of Automation, CAS	WEI, GQ (corresponding author), GERMAN AEROSP RES ESTAB, INST ROBOT & SYST DYNAM, D-82230 OBERPFAFFENHOFEN, GERMANY.							Abdel-Aziz Y, 1971, S CLOS RANG PHOT, P1; ATKINSON KB, 1980, DEV CLOSE RANGE PHOT; COXETER HSM, 1987, PROJECTIVE GEOMETRY, P35; FAIG W, 1975, PHOTOGRAMM ENG REM S, V41, P1479; Faugeras O. D., 1987, Proceedings of the International Workshop on Industrial Applications of Machine Vision and Machine Intelligence. Seiken Symposium (Cat. no. 87TH0166-9), P240; Faugeras O. D., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P15; GANAPATHY S, 1984, P INT C ROBOTICS, P130; GARNER LE, 1981, OUTLINE PROJECTIVE G, P51; GREMBAN K, 1988, ICRA, P562; Grosky W. I., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P511; IZAQUIRE A, 1985, P IEEE INT C ROB AUT, P74; Kanatani Kenichi, 1990, GROUP THEORETICAL ME, P4; LAMDAN Y, 1988, APR P IEEE INT C ROB, P1407; LENZ RK, 1988, IEEE T PATTERN ANAL, V10, P713, DOI 10.1109/34.6781; MARTINS HA, 1981, COMPUT VISION GRAPH, V17, P173, DOI 10.1016/0146-664X(81)90024-1; MOHR R, 1991, JUN P IEEE C COMP VI, P139; PENNA MA, 1991, IEEE T PATTERN ANAL, V13, P1240, DOI 10.1109/34.107007; SHEN J, 1986, JUN P IEEE C COMP VI, P104; Tsai R.Y., 1986, P IEEE C COMP VIS PA, P364; Wei G.-Q., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P133, DOI 10.1109/CVPR.1991.139675; WEI GQ, 1993, FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION : PROCEEDINGS, P439; WEI GQ, 1988, P INT C COMPUT AIDED, P331; WEI GQ, 1992, IMPLICIT EXPLICIT CA; Weng J., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P246, DOI 10.1109/ICPR.1990.118105; WONG KW, 1975, PHOTOGRAMM ENG REM S, V41, P1355; YAKIMOVSKY Y, 1978, COMPUT VISION GRAPH, V7, P195, DOI 10.1016/0146-664X(78)90112-0	26	201	257	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1994	16	5					469	480		10.1109/34.291450	http://dx.doi.org/10.1109/34.291450			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NP141					2022-12-18	WOS:A1994NP14100003
J	RATTARANGSI, A; CHIN, RT				RATTARANGSI, A; CHIN, RT			SCALE-BASED DETECTION OF CORNERS OF PLANAR CURVES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CORNER DETECTION; CURVATURE SCALE SPACE; DIGITAL CURVES; DOMINANT POINT DETECTION; GAUSSIAN SMOOTHING; MULTIRESOLUTION PROCESSING; SCALE SPACE FILTERING	DOMINANT POINTS; DIGITAL CURVES; EDGE MODELS; CURVATURE	A technique for detecting and localizing corners of planar curves is proposed. The technique is based on Gaussian scale space, which consists of the maxima of absolute curvature of the boundary function presented at all scales. The scale space of isolated simple and double corners is first analyzed to investigate the behavior of scale space due to smoothing and interactions between two adjacent corners. The analysis shows that the resulting scale space contains line patterns that either persist, terminate, or merge with a neighboring line. Next, the scale space is transformed into a tree that provides simple but concise representation of corners at multiple scales. Finally, a multiple-scale corner detection scheme is developed using a coarse-to-fine tree parsing technique. The parsing scheme is based on a stability criterion that states that the presence of a corner must concur with a curvature maximum observable at a majority of scales. Experiments were performed to show that the scale space corner detector is reliable for objects with multiple-size features and noisy boundaries and compares favorably with other corner detectors tested.	UNIV WISCONSIN, DEPT ELECT & COMP ENGN, MADISON, WI 53706 USA	University of Wisconsin System; University of Wisconsin Madison			Chin, Roland Tai Hong/E-9856-2010					ANDERSON IM, 1984, IEEE T PATTERN ANAL, V6, P27, DOI 10.1109/TPAMI.1984.4767472; ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; CLARK JJ, 1988, IEEE T PATTERN ANAL, V10, P720, DOI 10.1109/34.6782; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; Langridge D., 1972, FRONTIERS PATTERN RE, P347; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MEER P, 1988, PATTERN RECOGN, V21, P217, DOI 10.1016/0031-3203(88)90056-8; MEER P, 1987, IEEE T PATTERN ANAL, V9, P512, DOI 10.1109/TPAMI.1987.4767939; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; PIECH MA, 1988, COMPUT VISION GRAPH, V42, P381, DOI 10.1016/S0734-189X(88)80046-X; ROSENFELD A, 1975, IEEE T COMPUT, V24, P940, DOI 10.1109/T-C.1975.224342; ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188; SAINTMARC P, 1988, P IM UND, V2, P1100; SANKAR PV, 1978, COMPUT VISION GRAPH, V7, P403, DOI 10.1016/S0146-664X(78)80006-9; SHAH M, 1986, COMPUT VISION GRAPH, V34, P321, DOI 10.1016/S0734-189X(86)80046-9; TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]	22	201	222	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1992	14	4					430	449		10.1109/34.126805	http://dx.doi.org/10.1109/34.126805			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HL193					2022-12-18	WOS:A1992HL19300003
J	Shekhar, S; Patel, VM; Nasrabadi, NM; Chellappa, R				Shekhar, Sumit; Patel, Vishal M.; Nasrabadi, Nasser M.; Chellappa, Rama			Joint Sparse Representation for Robust Multimodal Biometrics Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multimodal biometrics; feature fusion; sparse representation	FACE RECOGNITION; COMPUTER VISION; REGRESSION; ALGORITHMS; SELECTION; FUSION	Traditional biometric recognition systems rely on a single biometric signature for authentication. While the advantage of using multiple sources of information for establishing the identity has been widely recognized, computational models for multimodal biometrics recognition have only recently received attention. We propose a multimodal sparse representation method, which represents the test data by a sparse linear combination of training data, while constraining the observations from different modalities of the test subject to share their sparse representations. Thus, we simultaneously take into account correlations as well as coupling information among biometric modalities. A multimodal quality measure is also proposed to weigh each modality as it gets fused. Furthermore, we also kernelize the algorithm to handle nonlinearity in data. The optimization problem is solved using an efficient alternative direction method. Various experiments show that the proposed method compares favorably with competing fusion-based methods.	[Shekhar, Sumit; Patel, Vishal M.; Chellappa, Rama] Univ Maryland, UMIACS, Dept Elect & Comp Engn, College Pk, MD 20742 USA; [Shekhar, Sumit; Patel, Vishal M.; Chellappa, Rama] Univ Maryland, UMIACS, Ctr Automat Res, College Pk, MD 20742 USA; [Nasrabadi, Nasser M.] US Army Res Lab, Adelphi, MD 20783 USA	University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park; United States Department of Defense; United States Army; US Army Research, Development & Engineering Command (RDECOM); US Army Research Laboratory (ARL)	Shekhar, S (corresponding author), Univ Maryland, UMIACS, Dept Elect & Comp Engn, College Pk, MD 20742 USA.	sshekha@umiacs.umd.edu; pvishalm@umiacs.umd.edu; nasser.m.nasrabadi@us.army.mil; rama@umiacs.umd.edu	Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/B-6573-2012; Chellappa, Rama/AAJ-1504-2020		MURI grant from the US Army Research Office [W911NF-09-1-0383]	MURI grant from the US Army Research Office	The work of Sumit Shekhar, Vishnal M. Patel, and Rama Chellappa was partially supported by a MURI grant from the US Army Research Office under the Grant W911NF-09-1-0383.	Afonso MV, 2011, IEEE T IMAGE PROCESS, V20, P681, DOI 10.1109/TIP.2010.2076294; Bolle RM, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P15, DOI 10.1109/AUTOID.2005.48; Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Cheng B, 2011, IEEE I CONF COMP VIS, P2439, DOI 10.1109/ICCV.2011.6126528; Chikkerur S, 2004, LECT NOTES COMPUT SC, V3072, P344; Crihalmeanu S., 2007, TECHNICAL REPORT; Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350; Diethe T, 2010, LECT NOTES ARTIF INT, V6321, P328, DOI 10.1007/978-3-642-15880-3_27; Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1; Elhamifar E., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1873, DOI 10.1109/CVPR.2011.5995664; Farquhar J., 2006, P ADV NEUR INF PROC; Gonen M, 2011, J MACH LEARN RES, V12, P2211; Jain AK, 2000, IEEE T IMAGE PROCESS, V9, P846, DOI 10.1109/83.841531; Kakade SM, 2007, LECT NOTES COMPUT SC, V4539, P82, DOI 10.1007/978-3-540-72927-3_8; Kim SJ, 2006, P 23 INT C MACH LEAR, P465, DOI DOI 10.1145/1143844.1143903; Klausner A, 2007, 2007 FIRST ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P63; Krishnapuram B, 2005, IEEE T PATTERN ANAL, V27, P957, DOI 10.1109/TPAMI.2005.127; Krishnasamy P., 2011, P 2011 INT JOINT C B, P1; Li H., 2012, ADV TOPICS BIOMETRIC; Martnez A., 1998, AR FACE DATABASE; Masek L., 2003, TECHNICAL REPORT; Meier L, 2008, J R STAT SOC B, V70, P53, DOI 10.1111/j.1467-9868.2007.00627.x; Moorhouse A., 2009, AUDIO T IRE PROFESSI, P1; Nagesh P, 2009, PROC CVPR IEEE, P1518, DOI 10.1109/CVPRW.2009.5206657; Nam H., 2011, INF FUS FUSION 2011, P1; Nandakumar K, 2008, IEEE T PATTERN ANAL, V30, P342, DOI 10.1109/TPAMI.2007.70796; Park U, 2011, IEEE T INF FOREN SEC, V6, P96, DOI 10.1109/TIFS.2010.2096810; Patel VM, 2012, IEEE T INF FOREN SEC, V7, P954, DOI 10.1109/TIFS.2012.2189205; Patel VM, 2011, 2011 FIRST ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P325, DOI 10.1109/ACPR.2011.6166711; Patel VM, 2010, I C CONT AUTOMAT ROB, P1, DOI 10.1109/ICARCV.2010.5707955; Pillai JK, 2011, IEEE T PATTERN ANAL, V33, P1877, DOI 10.1109/TPAMI.2011.34; Pundlik Shrinivas J., 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563108; Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491; Rattani A., 2007, 2007 1 IEEE INT C BI, P1, DOI DOI 10.1109/BTAS.2007.4401919; Ross A, 2005, PROC SPIE, V5779, P196, DOI 10.1117/12.606093; Ross Arun, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P1221; Ross A.A., 2006, HDB MULTIBIOMETRICS; Shekhar S., 2012, P ECCV WORKSH INF FU; Sindhwani V., 2008, INT C MACH LEARN, V307, P976, DOI DOI 10.1145/1390156.1390279; Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yang JF, 2011, SIAM J SCI COMPUT, V33, P250, DOI 10.1137/090777761; Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286; Yuan M, 2006, J R STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Yuan XT, 2010, PROC CVPR IEEE, P3493, DOI 10.1109/CVPR.2010.5539967; Zhang HC, 2011, IEEE I CONF COMP VIS, P595, DOI [10.1109/ICCV.2011.6126293, 10.1109/APAP.2011.6180470]; Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989; Zhou XL, 2006, INT C PATT RECOG, P529	53	200	212	4	96	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2014	36	1					113	126		10.1109/TPAMI.2013.109	http://dx.doi.org/10.1109/TPAMI.2013.109			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	265PV	24231870				2022-12-18	WOS:000327965100010
J	Kovacs-Vajna, ZM				Kovacs-Vajna, ZM			A fingerprint verification system based on triangular matching and dynamic time warping	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fingerprint; fingerprint verification; dynamic time warping; triangular matching; NIST sdb 4	IMAGES	An effective fingerprint verification system is presented. It assumes that an existing reference fingerprint image must validate the identity of a person by means of a Lest fingerprint image acquired online and in real-time using minutiae matching. The matching system consists of two main blocks: The first allows for the extraction of essential information from the reference image offline, the second performs the matching itself online. The information is obtained from the reference image by filtering and careful minutiae extraction procedures. The fingerprint identification is based on triangular matching to cope with the strong deformation of fingerprint images due to static friction or finger rolling. The matching is finally validated by Dynamic Time Warping. Results reported on the NIST Special Database 4 reference set, featuring 85 percent correct verification (15 percent false negative) and 0.05 percent false positive, demonstrate the effectiveness of the verification technique.	Univ Brescia, DEA, I-25123 Brescia, Italy	University of Brescia	Kovacs-Vajna, ZM (corresponding author), Univ Brescia, DEA, Via Branze 38, I-25123 Brescia, Italy.		Kovacs-Vajna, Zsolt M/AGY-9331-2022	Kovacs-Vajna, Zsolt M/0000-0003-4460-7683				CANDELA G, 1995, PCASYS PATTERN LEVEL; COETZEE L, 1993, PATTERN RECOGN, V26, P1441, DOI 10.1016/0031-3203(93)90151-L; Farina A, 1999, PATTERN RECOGN, V32, P877, DOI 10.1016/S0031-3203(98)00107-1; *FED BUR INV, 1988, SCI FING CLASS US; GERMAIN RS, 1998, BIOMETRICS PERSONAL, P311; Hong L., 1998, IEEE T PATTERN ANAL, V20; Jain Anil, 1997, IEEE T PATTERN ANAL, V19; KOVACSVAJNA ZM, 1998, Patent No. 123956; KRAMER A, 1994, P IEEE IEDM 1994, P449; *NAT I STAND TECHN, 1992, 8 BIT GRAY SCAL IM F; Rabiner L., 1993, FUNDAMENTALS SPEECH; Tartagni M., 1997, P 1997 IEEE INT SOL, P200; UMEYAMA S, 1993, IEEE T PATTERN ANAL, V15; YAHAGI H, 1990, P 1990 SOUTH, V1, P343	14	200	225	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2000	22	11					1266	1276		10.1109/34.888711	http://dx.doi.org/10.1109/34.888711			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	374QE					2022-12-18	WOS:000165355200005
J	Chesnaud, C; Refregier, P; Boulet, V				Chesnaud, C; Refregier, P; Boulet, V			Statistical region snake-based segmentation adapted to different physical noise models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image processing; statistical theory of estimation; segmentation; active contour	ACTIVE SHAPE MODELS; DEFORMABLE MODELS; IMAGES; TARGET; CONTOURS	Algorithms for object segmentation are crucial in many image processing applications. During past years, active contour models (snakes) have been widely used for finding the contours of objects. This segmentation strategy is classically edge-based in the sense that the snake is driven to fit the maximum of an edge map of the scene. In this paper, we propose a region snake approach and we determine fast algorithms for the segmentation of an object in an image. The algorithms developed in a Maximum Likelihood approach are based on the calculation of the statistics of the inner and the outer regions (defined by the snake). It has thus been possible to develop optimal algorithms adapted to the random fields which describe the gray levels in the input image if we assume that their probability density function family are known. We demonstrate that this approach is still efficient when no boundary's edge exists in the image. We also show that one can obtain fast algorithms by transforming the summations over a region, for the calculation of the statistics, into summations along the boundary of the region. Finally, we will provide numerical simulation results for different physical situations in order to illustrate the efficiency of this approach.	Domaine Univ St Jerome, Signal & Image Lab, Ecole Natl Super Phys Marseille, F-13397 Marseille 20, France; Thomson CSF Optronique, F-78283 Guyancourt, France	UDICE-French Research Universities; Aix-Marseille Universite; Thales Group	Chesnaud, C (corresponding author), Domaine Univ St Jerome, Signal & Image Lab, Ecole Natl Super Phys Marseille, F-13397 Marseille 20, France.	refregie@enspm009.u-3mrs.fr						AMIT Y, 1991, J AM STAT ASSOC, V86, P376, DOI 10.2307/2290581; Azzalini A., 1996, STAT INFERENCE BASED; BOVIK AC, 1988, IEEE T ACOUST SPEECH, V36, P1618, DOI 10.1109/29.7550; CASSELLES R, 1995, P INT C COMPUTER VIS, V1, P694; Chesnaud C, 1998, OPT LETT, V23, P488, DOI 10.1364/OL.23.000488; CHESNAUD C, 1999, PSIP 99, P3; COOTES TF, 1994, IMAGE VISION COMPUT, V12, P355, DOI 10.1016/0262-8856(94)90060-4; DEFIGUEIREDO MT, 1992, IEEE T MED IMAGING, V11, P416, DOI 10.1109/42.158946; Dias JMB, 1996, IEEE T MED IMAGING, V15, P25, DOI 10.1109/42.481438; FIGUEIREDO MAT, 1997, ENERGY MINIMIZATION; Germain O, 1996, OPT LETT, V21, P1845, DOI 10.1364/OL.21.001845; GERMAIN O, 1998, P EUR C IM SIGN PROC, P111; Goodman J. W., 1975, STAT PROPERTIES LASE, P9; GREG IC, 1995, IEEE T IMAGE PROCESS, V4, P1407; Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KERVRANN C, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P724, DOI 10.1109/CVPR.1994.323887; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; Oliver CJ, 1995, P SOC PHOTO-OPT INS, V2584, P152, DOI 10.1117/12.227124; Refregier P, 1997, OPT COMMUN, V137, P382, DOI 10.1016/S0030-4018(96)00782-1; Reno AL, 1998, P SOC PHOTO-OPT INS, V3371, P322, DOI 10.1117/12.323852; ROBERT CP, 1996, BAYESIAN CHOICE DECI; RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153; SLOCUMB BJ, 1990, ACQUISITION TRACKING, V4, P165; STORVIK G, 1994, IEEE T PATTERN ANAL, V16, P976, DOI 10.1109/34.329011; WILLIAMS DJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P14, DOI 10.1016/1049-9660(92)90003-L; Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186	30	200	207	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1999	21	11					1145	1157		10.1109/34.809108	http://dx.doi.org/10.1109/34.809108			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	259YG					2022-12-18	WOS:000083921100004
J	Hospedales, T; Antoniou, A; Micaelli, P; Storkey, A				Hospedales, Timothy; Antoniou, Antreas; Micaelli, Paul; Storkey, Amos			Meta-Learning in Neural Networks: A Survey	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Optimization; Training; Machine learning algorithms; Predictive models; Neural networks; Deep learning; Meta-learning; learning-to-learn; few-shot learning; transfer learning; neural architecture search	SEARCH; ALGORITHM; MEMORY	The field of meta-learning, or learning-to-learn, has seen a dramatic rise in interest in recent years. Contrary to conventional approaches to AI where tasks are solved from scratch using a fixed learning algorithm, meta-learning aims to improve the learning algorithm itself, given the experience of multiple learning episodes. This paradigm provides an opportunity to tackle many conventional challenges of deep learning, including data and computation bottlenecks, as well as generalization. This survey describes the contemporary meta-learning landscape. We first discuss definitions of meta-learning and position it with respect to related fields, such as transfer learning and hyperparameter optimization. We then propose a new taxonomy that provides a more comprehensive breakdown of the space of meta-learning methods today. We survey promising applications and successes of meta-learning such as few-shot learning and reinforcement learning. Finally, we discuss outstanding challenges and promising areas for future research.	[Hospedales, Timothy] Samsung AI Ctr, Cambridge CB1 2JD, England; [Hospedales, Timothy; Antoniou, Antreas; Micaelli, Paul] Univ Edinburgh, Edinburgh EH8 9AB, Midlothian, Scotland; [Storkey, Amos] Univ Edinburgh, Sch Informat, Machine Learning & AI, Edinburgh EH8 9AB, Midlothian, Scotland	University of Edinburgh; University of Edinburgh	Hospedales, T (corresponding author), Samsung AI Ctr, Cambridge CB1 2JD, England.	t.hospedales@ed.ac.uk; a.antoniou@ed.ac.uk; paul.micaelli@ed.ac.uk; a.storkey@ed.ac.uk			Engineering and Physical Sciences Research Council of the U.K. (EPSRC) [EP/S000631/1]; U.K. MOD University Defence Research Collaboration (UDRC) in Signal Processing; EPSRC [EP/R026173/1]	Engineering and Physical Sciences Research Council of the U.K. (EPSRC)(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); U.K. MOD University Defence Research Collaboration (UDRC) in Signal Processing; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The work of Timothy Hospedales was supported in part by the Engineering and Physical Sciences Research Council of the U.K. (EPSRC) under Grant EP/S000631/1, in part by the U.K. MOD University Defence Research Collaboration (UDRC) in Signal Processing, and in part by the EPSRC under Grant EP/R026173/1.	Al-Shedivat Maruan, 2018, P INT C LEARN REPR I; Alec Radford, 2017, Arxiv, DOI arXiv:1707.06347; Alet F., 2018, CORL, V87, P856; Alet F., 2019, PROC 33 INT C NEURAL, P1; Alet F., 2020, ICLR; Alex Nichol, 2018, Arxiv, DOI arXiv:1803.02999; Alexandre Lacoste, 2020, Arxiv, DOI arXiv:1905.12131; Alexei A. Efros, 2020, Arxiv, DOI arXiv:1811.10959; Fallah A, 2020, Arxiv, DOI arXiv:2002.05135; Allen KR, 2019, PR MACH LEARN RES, V97; Altae-Tran H, 2017, ACS CENTRAL SCI, V3, P283, DOI 10.1021/acscentsci.6b00367; Amos Storkey, 2019, Arxiv, DOI arXiv:1902.09884; Amos Storkey, 2020, Arxiv, DOI arXiv:2004.11967; Andrychowicz M, 2020, INT J ROBOT RES, V39, P3, DOI 10.1177/0278364919887447; [Anonymous], 2016, P 25 INT JOINT C ART; [Anonymous], 2019, PROC 33 INT C NEURAL; Antoniou A., 2019, PROC INT C NEURAL IN; Antoniou Antreas, 2018, ARXIV181009502; Artem Molchanov, 2019, Arxiv, DOI arXiv:1910.01727; Ba J., 2017, P 3 INT C LEARN REPR; Bachman P, 2017, PR MACH LEARN RES, V70; Bakhtin A, 2019, ADV NEUR IN, V32; Balaji Y, 2018, ADV NEUR IN, V31; Bao Yujia, 2020, INT C LEARN REPR; Barret Zoph, 2017, Arxiv, DOI arXiv:1710.05941; Baxter J, 1998, LEARNING TO LEARN, P71; Baydin A. G., 2018, PROC INT C LEARN REP, P1; Bayer J, 2009, LECT NOTES COMPUT SC, V5769, P755, DOI 10.1007/978-3-642-04277-5_76; Bechtle S., 2020, PROC INT C PATTERN R; Bello I, 2017, PR MACH LEARN RES, V70; Ben Poole, 2020, Arxiv, DOI arXiv:2009.11243; BENGIO S, 1995, NEURAL PROCESS LETT, V2, P26, DOI 10.1007/BF02279935; Bengio Y., 1991, IJCNN-91-Seattle: International Joint Conference on Neural Networks (Cat. No.91CH3049-4), DOI 10.1109/IJCNN.1991.155621; Bengio Yoshua., 2009, P 26 ANN INT C MACHI, P41, DOI 10.1145/ 1553374.1553380; Bergstra J, 2012, J MACH LEARN RES, V13, P281; Bertinetto Luca, 2019, INT C LEARN REPR, P2; Bharadhwaj H., 2019, P 2019 INT JOINT C N, P1; BIGGS JB, 1985, BRIT J EDUC PSYCHOL, V55, P185, DOI 10.1111/j.2044-8279.1985.tb02625.x; Bishay Mina, 2019, ARXIV190709021; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bohdal Ondrej, 2020, ARXIV200608572; Boney A. I. Rinu, 2018, P INT C LEARN REPR, P1; Gao BY, 2021, Arxiv, DOI arXiv:2103.00243; Cao Y, 2019, 2019 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXHIBITION (OFC); Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Charles Blundell, 2017, Arxiv, DOI arXiv:1611.05763; Chen S., 2019, PROC INT C NEURAL IN, P1; Chen YT, 2017, PR MACH LEARN RES, V70; Chen Z, 2018, SYNTHESIS LECT ARTIF, V12, P1, DOI [10.2200/S00737ED1V01Y201610AIM033, DOI 10.2200/S00737ED1V01Y201610AIM033]; Chengxiang Yin, 2020, Arxiv, DOI arXiv:1806.03316; Chuan-Sheng Foo, 2020, Arxiv, DOI arXiv:1912.10364; Clavera I., 2019, ICLR; Cobbe K, 2019, PR MACH LEARN RES, V97; Coskun Huseyin, 2021, IEEE Trans Pattern Anal Mach Intell, VPP, DOI 10.1109/TPAMI.2021.3058606; Csurka G, 2017, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-3-319-58347-1; Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020; Daejoong Kim, 2018, Arxiv, DOI arXiv:1806.06928; Dai B, 2018, PR MACH LEARN RES, V80; De Freitas N., 2016, ADV NEURAL INFORM PR, P3981; de Vries Terrance, 2019, IEEE C COMP VIS PATT, P52; Denevi G, 2018, ADV NEUR IN, V31; Denevi Giulia, 2019, ADV NEURAL INFORM PR, V32, P1; Devlin J., 2018, P 2019 C N AM CHAPTE, P4171, DOI DOI 10.18653/V1/N19-1423DIEZPF; Devlin J., 2017, PROC 31 C NEURAL INF, P1; Dexiong Chen, 2019, Arxiv, DOI arXiv:1908.10059; Doersch C, 2017, IEEE I CONF COMP VIS, P2070, DOI 10.1109/ICCV.2017.226; Dong Nanqing, 2018, BMVC; Duan Y, 2017, ADV NEUR IN, V30; Edwards Harrison, 2016, ICLR; ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4; Elsken T., 2019, PROC C COMPUT VIS PA, P12365; Elsken T, 2019, J MACH LEARN RES, V20; Eslami SMA, 2018, SCIENCE, V360, P1204, DOI 10.1126/science.aar6170; Fakoor R., 2020, ARXIV PREPRINT ARXIV; Fan Y., 2018, ARXIV PREPRINT ARXIV; Fei Chen, 2017, Arxiv, DOI arXiv:1707.09835; Fernando C. T., 2018, 180607917 ARXIV; Fernando Chrisantha, 2017, ARXIV; Finn C., 2018, P 32 C INT NEUR INF, P9537; Finn C, 2019, PR MACH LEARN RES, V97; Finn C, 2017, PR MACH LEARN RES, V70; Finn Chelsea, 2018, INT C LEARN REPR; Flennerhag S., 2019, PROC INT C LEARN REP, P1; Flennerhag Sebastian, 2020, INT C LEARN REPR; Flood Sung, 2017, Arxiv, DOI arXiv:1706.09529; Franceschi L, 2018, PR MACH LEARN RES, V80; Franceschi L, 2017, PR MACH LEARN RES, V70; Garcia V., 2018, ICLR; Garcia-Bastidas FA, 2020, PLANT DIS, V104, P994, DOI 10.1094/PDIS-09-19-1922-PDN; Garg V., 2018, PROC INT C NEURAL IN; Garnelo M, 2018, PR MACH LEARN RES, V80; Ghasemi S, 2020, PHARMACOGENOMICS J, V20, P367, DOI 10.1038/s41397-019-0138-5; Gidaris S, 2018, PROC CVPR IEEE, P4367, DOI 10.1109/CVPR.2018.00459; Goldblum M, 2020, ADV NEUR IN, V33; Gonzalez S, 2020, IEEE C EVOL COMPUTAT; Goodfellow I. J., 2015, INT C LEARN REPR ICL; Gordon J., 2019, P 7 INT C LEARN REPR, P3915; Grant Erin, 2018, INT C LEARN REPR; Greg Brockman, 2016, Arxiv, DOI arXiv:1606.01540; Gui L.-Y., 2018, PROC EUR C COMPUT VI, P1; Gui LY, 2018, LECT NOTES COMPUT SC, V11212, P441, DOI 10.1007/978-3-030-01237-3_27; Guo YH, 2020, PEER PEER NETW APPL, V13, P1442, DOI 10.1007/s12083-020-00896-4; Gupta A., 2018, P 32 INT C NEUR INF, P5307; Ha David, 2016, ARXIV160909106; Haarnoja T, 2018, PR MACH LEARN RES, V80; Hae Beom Lee, 2020, Arxiv, DOI arXiv:2002.12017; HARLOW HF, 1949, PSYCHOL REV, V56, P51, DOI 10.1037/h0062474; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Heskes Tom, 2000, P INT C MACH LEARN; Pham H, 2020, Arxiv, DOI arXiv:2003.10580; Himanshu Asnani, 2019, Arxiv, DOI arXiv:1903.02268; Hochreiter Sepp, 2001, INT C ART NEUR NETW, P87, DOI [10.1007/3-540-44668-0, DOI 10.1007/3-540-44668-0]; Hou RB, 2019, ADV NEUR IN, V32; Houthooft R., 2018, PROC 32 C NEURAL INF; Hsu J.-Y., 2019, PROC INT C ACOUST SP; Hsu K., 2019, UNSUPERVISED LEARNIN; Huang C, 2019, PR MACH LEARN RES, V97; Hutter F., 2019, AUTOMATIC MACHINE LE; Ilya Sutskever, 2017, Arxiv, DOI arXiv:1703.03864; Ilya Sutskever, 2016, Arxiv, DOI arXiv:1611.02779; Jabri A, 2019, ADV NEUR IN, V32; Jaderberg M, 2019, SCIENCE, V364, P859, DOI 10.1126/science.aau6249; Jaderberg Max, 2017, ICLR; Javed K, 2019, ADV NEUR IN, V32; Joaquin Vanschoren, 2018, Arxiv, DOI arXiv:1810.03548; Kang BY, 2019, IEEE I CONF COMP VIS, P8419, DOI 10.1109/ICCV.2019.00851; Kang Z., 2011, P INT C MACH LEARN, V2, P4; Kar A, 2019, IEEE I CONF COMP VIS, P4550, DOI 10.1109/ICCV.2019.00465; Khodadadeh S, 2019, ADV NEUR IN, V32; Kirsch L., 2020, PROC INT C LEARN REP; Klejch O, 2018, INTERSPEECH, P867, DOI 10.21437/Interspeech.2018-1244; Koch G., 2015, PROC 32 INT C MACH L; Konyushkova K., 2017, PROC INT C NEURAL IN, P1; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Kroemer O, 2021, J MACH LEARN RES, V22; Kunkun Pang, 2018, Arxiv, DOI arXiv:1806.04798; Lee H., 2020, PROC INT C LEARN REP; LEE HB, 2020, PROC INT C LEARN REP, P1, DOI DOI 10.1109/GCWKSHPS50303.2020.9367572; Lee J., 2019, PROC INT C LEARN REP; Lee J, 2019, PR MACH LEARN RES, V97; Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091; Lee Y, 2018, PR MACH LEARN RES, V80; Lemke C, 2015, ARTIF INTELL REV, V44, P117, DOI 10.1007/s10462-013-9406-y; Li D., 2020, P EUR C COMP VIS, P382; Li D., 2018, PROC 32 ASS ADV ARTI; Li D, 2017, IEEE I CONF COMP VIS, P5543, DOI 10.1109/ICCV.2017.591; Li JN, 2019, PROC CVPR IEEE, P5046, DOI 10.1109/CVPR.2019.00519; Li K., 2017, PROC INT C LEARN REP; Li XZ, 2019, ADV NEUR IN, V32; Li Y., 2020, PROC EUR C COMPUT VI, P1; Li YJ, 2019, PR MACH LEARN RES, V97; Liang D, 2020, 2020 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXPOSITION (OFC); Lin X, 2019, ADV NEUR IN, V32; Liu H., 2019, PROC INT C LEARN REP; Liu H, 2019, PR MACH LEARN RES, V97; Liu S, 2019, ADV NEUR IN, V32; Liu Y. -C., 2019, PROC INT C LEARN REP; Liu ZC, 2019, IEEE I CONF COMP VIS, P3295, DOI [10.1109/ICCV.2019.00339, 10.1109/ICCV.2019.00339D\]; Lorraine J, 2020, PR MACH LEARN RES, V108, P1540; Loshchilov I., 2016, ARXIV; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu J, 2018, PR MACH LEARN RES, V80; Machado MC, 2018, J ARTIF INTELL RES, V61, P523, DOI 10.1613/jair.5699; Maclaurin D, 2015, PR MACH LEARN RES, V37, P2113; Madotto A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5454; Maicas G, 2018, LECT NOTES COMPUT SC, V11070, P546, DOI 10.1007/978-3-030-00928-1_62; Marcus G., 2018, ARXIV; Meier F, 2018, IEEE INT CONF ROBOT, P2425; Metter DM, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.4337; Metz L, 2019, PR MACH LEARN RES, V97; Metz Luke, 2019, INT C LEARN REPR; Micaelli P., 2020, ARXIV; Miconi T., 2019, PROC INT C LEARN REP; Miconi T, 2018, PR MACH LEARN RES, V80; Mirikharaji Z., 2019, ARXIV; Mishra N., 2018, PROC INT C LEARN REP; Muandet K., 2013, INT C MACH LEARN, P10; Munkhdalai T, 2017, PR MACH LEARN RES, V70; Nakul Verma, 2019, Arxiv, DOI arXiv:1910.14134; Nguyen B. D., 2019, PROC MED IMAGE COMPU; O'Shea T, 2017, IEEE T COGN COMMUN, V3, P563, DOI 10.1109/TCCN.2017.2758370; Oreshkin BN, 2018, ADV NEUR IN, V31; Pakman A., 2019, PROC 37 INT C MACH L, P7455; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012; Park E, 2019, ADV NEUR IN, V32; Patacchiola M., 2020, PROC INT C NEURAL IN; Pedregosa F, 2016, PR MACH LEARN RES, V48; Perez-Rua Juan-Manuel, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13843, DOI 10.1109/CVPR42600.2020.01386; Qiao SY, 2018, PROC CVPR IEEE, P7229, DOI 10.1109/CVPR.2018.00755; Rae JW, 2019, PR MACH LEARN RES, V97; Raghu Aniruddh, 2020, ICLR; Rajeswaran A, 2019, ADV NEUR IN, V32; Rakelly K, 2019, PR MACH LEARN RES, V97; Rakelly Kate, 2018, ARXIV180607373; Ravi Sachin, 2019, INT C LEARN REPR; Ravi Sachin, 2017, INT C LEARN REPR, V2, P5; Real E, 2019, AAAI CONF ARTIF INTE, P4780; Reed Scott, 2018, ICLR; Ren M., 2019, PROC 33 INT C NEURAL, P1; Ren M., 2018, ICLR; Ren MY, 2018, PR MACH LEARN RES, V80; Ritter S, 2018, PR MACH LEARN RES, V80; Rothfuss J., 2019, INT C LEARN REPR; Ruiz N., 2018, ARXIV, P1; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Russell C., 2019, PROC INT C NEURAL IN, P1; Rusu Andrei A, 2019, ICLR; Santoro A, 2016, PR MACH LEARN RES, V48; Schmidhuber J, 1997, MACH LEARN, V28, P105, DOI 10.1023/A:1007383707642; SCHMIDHUBER J, 1991, FROM ANIMALS TO ANIMATS, P222; SCHMIDHUBER J, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P407, DOI 10.1109/ICNN.1993.298591; Schmidhuber J., 1997, TRIDSIA3597; Schmidhuber J, 1987, THESIS; Schmidhuber J., 1996, SIMPLE PRINCIPLES ME; SCHRIER A M, 1984, Primates, V25, P95, DOI 10.1007/BF02382299; Schweighofer N, 2003, NEURAL NETWORKS, V16, P5, DOI 10.1016/S0893-6080(02)00228-9; Settles B., 2012, SYNTH LECT ARTIF INT, V6, P1; Shaban A, 2019, PR MACH LEARN RES, V89; Shaban Amirreza, 2017, ARXIV170903410, DOI 10.5244/C.31.167; Shahriari B, 2016, P IEEE, V104, P148, DOI 10.1109/JPROC.2015.2494218; Shaw A., 2019, PROC 33 INT C NEURAL; Shen FL, 2018, PROC CVPR IEEE, P8061, DOI 10.1109/CVPR.2018.00841; Shu J, 2019, ADV NEUR IN, V32; Si X., 2018, PROC SEG TECH PROGRA, P1; Sigaud O, 2019, NEURAL NETWORKS, V113, P28, DOI 10.1016/j.neunet.2019.01.011; Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961; Sinha A, 2018, IEEE T EVOLUT COMPUT, V22, P276, DOI 10.1109/TEVC.2017.2712906; Sinitsin A., 2020, PROC INT C LEARN REP, P1; Snell J., 2017, PROC 31 C NEURAL INF; Song X., 2020, P INT C LEARN REPR; Stackelberg H., 1952, THEORY MARKET EC; Stadie B. C., 2018, PROC 36 INT C NEURAL; Stanley KO, 2019, NAT MACH INTELL, V1, P24, DOI 10.1038/s42256-018-0006-z; Storck J., 1995, ICANN '95. International Conference on Artificial Neural Networks. Neuronimes '95 Scientific Conference, P159; Stulp F., 2013, PALADYN J BEHAV ROBO, V4, P49, DOI DOI 10.2478/PJBR-2013-0003; Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97; Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049; Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131; Thrun S, 1998, LEARNING TO LEARN, P181; Thrun S, 1998, LEARNING TO LEARN, P3; Yu TH, 2019, Arxiv, DOI arXiv:1910.10897; Tremblay J, 2018, IEEE COMPUT SOC CONF, P1082, DOI 10.1109/CVPRW.2018.00143; Triantafillou E., 2020, PROC INT C LEARN REP; Tseng Hung-Yu, 2020, INT C LEARN REPR, P2; Vartak Manasi, 2017, P 31 INT C NEUR INF; Veeriah V., 2019, PROC INT C NEURAL IN; Vilalta R, 2002, ARTIF INTELL REV, V18, P77, DOI 10.1023/A:1019956318069; Vinyals O., 2016, ADV NEURAL INFORM PR, P3637, DOI [10.48550/arXiv.1606.04080, DOI 10.5555/3157382.3157504]; Volpi R., 2019, PROC INT C COMPUT VI, P33; Vuorio R., 2019, PROC 33 INT C NEURAL; Wang TC, 2019, ADV NEUR IN, V32; Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252; Wichrowska O, 2017, PR MACH LEARN RES, V70; Wiering M, 1998, FROM ANIM ANIMAT, P223; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696; Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270; Winate GI, 2020, INTERSPEECH, P1276, DOI 10.21437/Interspeech.2020-45; Wu Y, 2021, IEEE T SYST MAN CY-S, V51, P326, DOI 10.1109/TSMC.2018.2871100; Xie Sirui, 2019, ICLR, V1, P13; Xie Y., 2019, PROC INT C NEURAL IN; Xu T., 2018, P 35 INT C MACHINE L, P5463; Xu ZW, 2018, ADV NEUR IN, V31, DOI 10.1142/S0192415X1850074X; Yang Y., 2015, ICLR; Yang Y., 2017, PROC INT C LEARN REP; Yang YX, 2019, AAMAS '19: PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, P323; Yao HX, 2019, PR MACH LEARN RES, V97; Yao Huaxiu, 2020, AUTOMATED RELATIONAL, DOI [10.1101/2001.00745, DOI 10.1101/2001.00745]; Yin H, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE-RCAR 2020), P1; Yin M., 2020, PROC INT C LEARN REP; Ying C, 2019, PR MACH LEARN RES, V97; Yoon SW, 2019, PR MACH LEARN RES, V97; Yosinski J, 2014, ADV NEUR IN, V27; Young K, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4185; Younger AS, 2001, IEEE IJCNN, P2001, DOI 10.1109/IJCNN.2001.938471; Yu T., 2020, PROC INT C NEURAL IN; Zaheer M, 2017, ADV NEUR IN, V30; Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955; Zela A., 2020, PROC ICLR 2020; Zhang C, 2019, AAAI CONF ARTIF INTE, P5741; Zhao B., 2021, PROC INT C LEARN REP; Zheng ZY, 2018, ADV NEUR IN, V31; Zhou W., 2020, ADV NEURAL INFORM PR, V33; Zoph B., 2017, P1; Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907	300	199	203	112	164	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					5149	5169		10.1109/TPAMI.2021.3079209	http://dx.doi.org/10.1109/TPAMI.2021.3079209			21	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33974543	Green Submitted, hybrid			2022-12-18	WOS:000836666600049
J	Bai, X; Yang, XW; Latecki, LJ; Liu, WY; Tu, ZW				Bai, Xiang; Yang, Xingwei; Latecki, Longin Jan; Liu, Wenyu; Tu, Zhuowen			Learning Context-Sensitive Shape Similarity by Graph Transduction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape similarity; shape retrieval; shape classification; shape clustering; graph transduction	IMAGE RETRIEVAL; NONRIGID SHAPES; REPRESENTATION; DESCRIPTORS	Shape similarity and shape retrieval are very important topics in computer vision. The recent progress in this domain has been mostly driven by designing smart shape descriptors for providing better similarity measure between pairs of shapes. In this paper, we provide a new perspective to this problem by considering the existing shapes as a group, and study their similarity measures to the query shape in a graph structure. Our method is general and can be built on top of any existing shape similarity measure. For a given similarity measure, a new similarity is learned through graph transduction. The new similarity is learned iteratively so that the neighbors of a given shape influence its final similarity to the query. The basic idea here is related to PageRank ranking, which forms a foundation of Google Web search. The presented experimental results demonstrate that the proposed approach yields significant improvements over the state-of-art shape matching algorithms. We obtained a retrieval rate of 91.61 percent on the MPEG-7 data set, which is the highest ever reported in the literature. Moreover, the learned similarity by the proposed method also achieves promising improvements on both shape classification and shape clustering.	[Bai, Xiang; Liu, Wenyu] Huazhong Univ Sci & Technol, Dept Elect & Informat Engn, Wuhan 430074, Hubei, Peoples R China; [Yang, Xingwei; Latecki, Longin Jan] Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA; [Tu, Zhuowen] Univ Calif Los Angeles, Lab Neuro Imaging, Dept Neurol, Los Angeles, CA 90095 USA; [Bai, Xiang] Temple Univ, Dept Comp Sci & Informat, Philadelphia, PA 19122 USA; [Tu, Zhuowen] Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA; [Tu, Zhuowen] Univ Calif Los Angeles, Bioengn Interdept Program, Los Angeles, CA 90095 USA; [Tu, Zhuowen] Univ Calif Los Angeles, Bioinformat Program, Los Angeles, CA 90095 USA	Huazhong University of Science & Technology; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University; University of California System; University of California Los Angeles; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University; University of California System; University of California Los Angeles; University of California System; University of California Los Angeles; University of California System; University of California Los Angeles	Bai, X (corresponding author), Huazhong Univ Sci & Technol, Dept Elect & Informat Engn, 1037 Luoyu Rd, Wuhan 430074, Hubei, Peoples R China.	xiang.bai@gmail.com; xingwei.yang@temple.edu; latecki@temple.edu; liuwy@hust.edu.cn; zhuowen.tu@loni.ucla.edu	Liu, Wenyu/AAG-1426-2019	Liu, Wenyu/0000-0002-4582-7488; Latecki, Longin Jan/0000-0002-5102-8244	US National Science Foundation [IIS-0812118]; US Department of Energy [DE-FG52-06NA27508]; National Science Foundation of China [60873127, 60903096]; PhD Programs Foundation of the Ministry of Education of China [20070487028]; US National Institutes of Health [U54 RR021813]; US Office of Naval Research [N000140910099]; MSRA; NATIONAL CENTER FOR RESEARCH RESOURCES [U54RR021813] Funding Source: NIH RePORTER	US National Science Foundation(National Science Foundation (NSF)); US Department of Energy(United States Department of Energy (DOE)); National Science Foundation of China(National Natural Science Foundation of China (NSFC)); PhD Programs Foundation of the Ministry of Education of China(Ministry of Education, China); US National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); US Office of Naval Research(Office of Naval Research); MSRA; NATIONAL CENTER FOR RESEARCH RESOURCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR))	The authors would like to thank H. Ling for proving us his software for IDSC and the Swedish leaf database. The authors would also like to thank Eamonn Keogh for providing them the Face (all) data set. They also want to thank B. B. Kimia for proving his shape databases on the Internet. This work is supported in part by US National Science Foundation Grant No. IIS-0812118, US Department of Energy Grant No. DE-FG52-06NA27508, National Science Foundation of China Grant No. 60873127, and a grant from the PhD Programs Foundation of the Ministry of Education of China (No. 20070487028). This project is also in part supported by US National Institutes of Health Grant U54 RR021813 entitled Center for Computational Biology. This project is also supported in part by the US Office of Naval Research N000140910099 and National Science Foundation of China Grant 60903096. One of the authors (Xiang Bai) is supported by the MSRA Fellowship. The code and data used in this paper are available for free download at http://happyyxw.googlepages.com/democodeeccv.	Adamek T, 2004, IEEE T CIRC SYST VID, V14, P742, DOI 10.1109/TCSVT.2004.826776; Alajlan N, 2008, IEEE T PATTERN ANAL, V30, P1003, DOI 10.1109/TPAMI.2008.37; Athitsos V., 2004, P IEEE CS C COMP VIS; Attalla E, 2005, PATTERN RECOGN, V38, P2229, DOI 10.1016/j.patcog.2005.02.009; Bai X, 2008, IEEE T PATTERN ANAL, V30, P1282, DOI 10.1109/TPAMI.2007.70769; BARHILLEL A, 2003, P 20 INT C MACH LEAR, P11; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; BREFELD U, 2005, P EUR C MACH LEARN; Daliri MR, 2008, PATTERN RECOGN, V41, P1782, DOI 10.1016/j.patcog.2007.10.020; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Fan X, 2005, IEEE I CONF COMP VIS, P302; FELZENSZWALB PF, 2007, P IEEE CS C COMP VIS; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Ghosh A, 2005, IEEE T PATTERN ANAL, V27, P1793, DOI 10.1109/TPAMI.2005.225; Gorelick L, 2006, IEEE T PATTERN ANAL, V28, P1991, DOI 10.1109/TPAMI.2006.253; Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P729, DOI 10.1109/TIP.2003.814250; Hein M., 2006, ADV NEURAL INFORM PR; Hertz T, 2004, PROC CVPR IEEE, P570; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; Keogh E., UCR TIME SERIES CLAS; Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802; Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850; Lawrence N. D., 2004, ADV NEURAL INFORM PR; LEIBE B, 2003, P IEEE CS C COMP VIS; Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41; McNeill G., 2006, P IEEE CS C COMP VIS; MCNEILL G, 2005, P INT JOINT C ART IN; MOKHTARIAN F, 1997, IMAGE DATABASES MULT, P51, DOI DOI 10.1142/9789812797988_; Mokhtarian F., 2003, CURVATURE SCALE SPAC; Page L., 1999, TECHNICAL REPORT 199; PETER A, 2008, P IEEE CS C COMP VIS; Ratanamahatana CA, 2005, SIAM PROC S, P506; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; Shokoufandeh A, 2005, IEEE T PATTERN ANAL, V27, P1125, DOI 10.1109/TPAMI.2005.142; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; Soderkvist O, 2001, THESIS LINKOPING U; Srivastava A, 2005, IEEE T PATTERN ANAL, V27, P590, DOI 10.1109/TPAMI.2005.86; Super B.J., 2004, P IEEE WORKSH LEARN; Super BJ, 2006, INT J PATTERN RECOGN, V20, P1117, DOI 10.1142/S0218001406005174; Tu ZW, 2004, LECT NOTES COMPUT SC, V3023, P195; Vleugels J, 2002, PATTERN RECOGN, V35, P69, DOI 10.1016/S0031-3203(00)00120-5; WANG F, 2006, P IEEE CS C COMP VIS; WANG J, 2008, P IEEE CS C COMP VIS; Xie J, 2008, PATTERN RECOGN, V41, P1756, DOI 10.1016/j.patcog.2007.11.005; Xing E., 2002, ADV NEURAL INFORM PR, V15, P505, DOI DOI 10.5555/2968618.2968683; YANG X, 2008, P EUR C COMP VIS; Yu J, 2008, IEEE T PATTERN ANAL, V30, P451, DOI 10.1109/TPAMI.2007.70714; Zelnik-Manor L, 2004, ADV NEURAL INFORM PR; ZHOU D, 2003, ADV INFORM PROCESSIN; Zhou D., 2003, ADV NEURAL INFORM PR; ZHU X, 2005, CMULTI05192; Zhu X., 2003, ICML	54	199	220	1	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2010	32	5					861	874		10.1109/TPAMI.2009.85	http://dx.doi.org/10.1109/TPAMI.2009.85			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	569AW	20299710	Green Submitted			2022-12-18	WOS:000275569300007
J	Grossberg, MD; Nayar, SK				Grossberg, MD; Nayar, SK			Determining the camera response from images: What is knowable?	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	7th European Conference on Computer Vision (ECCV 2002)	MAY 28-31, 2002	COPENHAGEN, DENMARK	IT Univ Copenhagen, Univ Copenhagen, Lund Univ		calibration; histogram; response function; ambiguities; illumination; radiometry; comparagram; dynamic range; intensity mapping; histogram specification; comparametric	SHAPE	An image acquired by a camera consists of measured intensity values which are related to scene radiance by a function called the camera response function. Knowledge of this response is necessary for computer vision algorithms which depend on scene radiance. One way the response has been determined is by establishing a mapping of intensity values between images taken with different exposures. We call this mapping the intensity mapping function. In this paper, we address two basic questions. What information from a pair of images taken at different exposures is needed to determine the intensity mapping function? Given this function, can the response of the camera and the exposures of the images be determined? We completely determine the ambiguities associated with the recovery of the response and the ratios of the exposures. We show all methods that have been used to recover the response break these ambiguities by making assumptions on the exposures or on the form of the response. We also show when the ratio of exposures can be recovered directly from the intensity mapping, without recovering the response. We show that the intensity mapping between images is determined solely by the intensity histograms of the images. We describe how this allows determination of the intensity mapping between images without registration. This makes it possible to determine the intensity mapping in sequences with some motion of both the camera and objects in the scene.	Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Columbia University	Grossberg, MD (corresponding author), Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.	mdog@cs.columbia.edu; mayar@cs.columbia.edu						ASADA N, 1996, P INT C PATT REC, VA, P189; Barros AF, 2002, INT CONF ACOUST SPEE, P3345; Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484; Candocia FM, 2002, INT CONF ACOUST SPEE, P3237; Chang YC, 1996, IEEE T IMAGE PROCESS, V5, P1414, DOI 10.1109/83.536890; Debevec P., 1997, P ACM SIGGRAPH 1997, DOI [DOI 10.1145/258734.258884, 10.1145/258734.258884]; DROR R, 2002, COMMUNICATION; EBEVEV PE, 1998, P ACM SIGGRAPH, P189; Farid H, 2001, IEEE T IMAGE PROCESS, V10, P1428, DOI 10.1109/83.951529; GROSSBERG MD, 2002, P EUR C COMP VIS, V4, P189; Hardy G. H, 1975, INTRO THEORY NUMBERS, V4th; Horn B., 1986, ROBOT VISION, P1; JA AK, 1989, FUNDAMENTALS DIGITAL; MALONEY LT, 1986, J OPT SOC AM A, V3, P29, DOI 10.1364/JOSAA.3.000029; Mann S, 1997, IEEE T IMAGE PROCESS, V6, P1281, DOI 10.1109/83.623191; Mann S, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P193, DOI 10.1109/ICIP.1996.560417; MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442; Mann S, 2000, IEEE T IMAGE PROCESS, V9, P1389, DOI 10.1109/83.855434; MANN S, 2001, P CS C COMP VIS PATT; MARSCHNER SE, 1998, THESIS STANFORD U CA; MATSUNAGA T, 1999, P CS C COMP VIS PATT, V2, P374; NAYAR SK, 1991, INT J COMPUT VISION, V6, P173, DOI 10.1007/BF00115695; Nicodemus FE, 1977, NBS MONOGRAPH, V160; Schechner YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P17, DOI 10.1109/ICCV.2001.937494; Stewart J., 2016, CALCULUS, VEighth; Tsin Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P480, DOI 10.1109/ICCV.2001.937555; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284	27	199	219	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2003	25	11					1455	1467		10.1109/TPAMI.2003.1240119	http://dx.doi.org/10.1109/TPAMI.2003.1240119			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	733NG					2022-12-18	WOS:000186006800010
J	Gokcay, E; Principe, JC				Gokcay, E; Principe, JC			Information theoretic clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						information theory; clustering; MRI segmentation; entropy; optimization		Clustering is one of the important topics in pattern recognition. Since only the structure of the data dictates the grouping (unsupervised learning), information theory is an obvious criteria to establish the clustering rule. This paper describes a novel valley seeking clustering algorithm using an information theoretic measure to estimate the cost of partitioning the data set The information theoretic criteria developed here evolved from a Renyi's entropy estimator that was proposed recently and has been successfully applied to other machine learning applications. An improved version of the k-change algorithm is used in optimization because of the stepwise nature of the cost function and existence of local minima. Even when applied to nonlinearly separable data, the new algorithm performs well, and was able to find nonlinear boundaries between clusters. The algorithm is also applied to the segmentation of magnetic resonance imaging data (MRI) with very promising results.	Salk Inst Biol Studies, Computat Neurobiol Lab, La Jolla, CA 92037 USA; Univ Florida, Elect & Comp Engn Dept, Gainesville, FL 32611 USA	Salk Institute; State University System of Florida; University of Florida	Gokcay, E (corresponding author), Salk Inst Biol Studies, Computat Neurobiol Lab, 10010 N Torrey Pines Rd, La Jolla, CA 92037 USA.	erhan@salk.edu; principe@cnel.ufl.edu	principe, jose/N-8099-2014					ASHTARI M, 1990, INVEST RADIOL, V25, P798, DOI 10.1097/00004424-199007000-00009; BEZDEK JC, 1993, MED PHYS, V20, P1033, DOI 10.1118/1.597000; Bhattacharyya A., 1943, BULL CALCUTTA MATH S, V35, P99; Bishop, 1995, NEURAL NETWORKS PATT; BUCHBINDER BR, 1991, SOC MAGNETIC RESONAN, V1; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; CARPENTER GA, 1987, APPL OPTICS, V26, P4919, DOI 10.1364/AO.26.004919; CHARIKAR M, 1997, P 29 ANN ACM S THEOR, P626, DOI DOI 10.1145/258533.258657; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Duda R.O., 1973, J ROYAL STAT SOC SER; FUJUNAGA K, 1990, INTRO STAT PATTERN R; GERSHO A, 1982, IEEE T INFORM THEORY, V28, P157, DOI 10.1109/TIT.1982.1056457; GOKCAY E, 2000, IEEE INT C AC SPEECH; Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229; GRAY RM, 1990, ENTROPY INFORMATION; GROSSBERG S, 1976, BIOL CYBERN, V23, P121, DOI 10.1007/BF00344744; HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7; Hartigan J.A., 1975, CLUSTERING ALGORITHM; HAYKIN S, 1994, NEURAL NETWORKS; Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806; JACK CR, 1990, RADIOLOGY, V176, P205, DOI 10.1148/radiology.176.1.2353093; JACKSON EF, 1993, J COMPUT ASSIST TOMO, V17, P200, DOI 10.1097/00004728-199303000-00007; Kapur J., 1992, ENTROPY OPTIMIZATION; KATO N, 1996, P 1996 IEEE INT C SY, V1, P432; Kazakos D., 1990, DETECTION ESTIMATION; KIDO K, 1978, IEEE INT C AC SPEECH, P735; KULLBACK S, 1959, INFORMATION THEORY S; LE K, 1997, P IEEE C DEC CONTR, V5, P4490; Lippmann RP, 1989, NEURAL COMPUT, V1, P1, DOI 10.1162/neco.1989.1.1.1; McLachlan G.J., 1988, MIXTURE MODELS INFER, V38; McLachlan GJ., 1996, WILEY SERIES PROBABI; MORGAN N, 1997, IEEE SIGNAL PROCESSI, V14, P46; Navarro A, 1997, P SOC PHOTO-OPT INS, V3027, P31, DOI 10.1117/12.270077; PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J; PAPOULIS A, 1965, ROBABILITY RANDOM VA; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Principe J.C., 1997, NEURAL ADAPTIVE SYST; PRINCIPE JC, 2000, UNSUPERVISED ADAPTIV; PRINCIPE JC, 1997, IEEE INT C NEURAL NE, V4, P2085; Radova V, 1997, INT CONF ACOUST SPEE, P1135, DOI 10.1109/ICASSP.1997.596142; Reiss AL, 1996, BRAIN, V119, P1763, DOI 10.1093/brain/119.5.1763; Renyi A, 1961, PROC 4 BERKELEY SYMP, V1, P547; Roberts SJ, 1998, IEEE T PATTERN ANAL, V20, P1133, DOI 10.1109/34.730550; RUMELHART DE, 1985, COGNITIVE SCI, V9, P75, DOI 10.1207/s15516709cog0901_5; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; Shannon CE, 1962, MATH THEORY COMMUNIC; SHIMOJI S, 1994, IEEE INT C NEUR NETW, P2423; Watanabe S, 1985, PATTERN RECOGNITION; Xu DX, 1998, NEURAL NETWORKS FOR SIGNAL PROCESSING VIII, P155, DOI 10.1109/NNSP.1998.710645	51	199	209	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2002	24	2					158	171		10.1109/34.982897	http://dx.doi.org/10.1109/34.982897			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	516DC		Green Submitted			2022-12-18	WOS:000173535700002
J	BOZINOVIC, RM; SRIHARI, SN				BOZINOVIC, RM; SRIHARI, SN			OFF-LINE CURSIVE SCRIPT WORD RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									SUNY BUFFALO,DEPT COMP SCI,BUFFALO,NY 14260	State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	BOZINOVIC, RM (corresponding author), MIHAJLO PUPIN INST,DEPT COMP SYST,BELGRADE,YUGOSLAVIA.		Srihari, Sargur N/E-8100-2011					BADIE K, 1982, 6TH P INT C PATT REC, P28; Bahl L., 1975, IEEE T INFORM THEORY, V21; BERTHOD M, 1980, 5TH P INT C PATT REC, P723; BOUMA H, 1971, VISION RES, V11, P459, DOI 10.1016/0042-6989(71)90087-3; BOZINOVIC R, 1982, IEEE T PATTERN ANAL, V4, P655, DOI 10.1109/TPAMI.1982.4767321; BOZINOVIC R, 1985, TR8513 STAT U NEW YO; BROWN MK, 1981, THESIS U MICHIGAN; BUNEMAN OP, 1969, MACH INTELL, V4, P383; BURR DJ, 1983, IEEE T PATTERN ANAL, V5, P554, DOI 10.1109/TPAMI.1983.4767435; BURR DJ, 1982, 6TH P INT C PATT REC, P1027; Carroll JohnB., 1967, COMPUTATIONAL ANAL P; DUTTA AK, 1974, IEEE T COMPUT, VC 23, P536, DOI 10.1109/T-C.1974.223978; EARNEST LD, 1962, INFORMATION PROCESSI; ECCLES MJ, 1977, PATTERN RECOGN, V9, P31, DOI 10.1016/0031-3203(77)90028-0; EDEN M, 1961, P S APPL MATH, V12, P83; EHRICH RW, 1975, IEEE T COMPUT, VC 24, P182, DOI 10.1109/T-C.1975.224184; FARAG RFH, 1979, IEEE T COMPUT, V28, P172, DOI 10.1109/TC.1979.1675310; FREEMAN H, 1962, P NATL ELECT C, V18, P312; FRISHKOPF LS, 1961, INFORMATION THEORY; HABER RN, 1981, VISIBLE LANG, V15, P147; HAYES K, 1979, TR783 U MAR; HULL JJ, 1986, JUN P IEEE C COMP VI, P156; Jelinek F., 1969, IBM Journal of Research and Development, V13, P675, DOI 10.1147/rd.136.0675; MERMELSTEIN P, 1964, INFORM CONTROL, V7, P255, DOI 10.1016/S0019-9958(64)90142-1; Minsky M., 1969, PERCEPTRONS; SAYRE KM, 1973, PATTERN RECOGN, V5, P213, DOI 10.1016/0031-3203(73)90044-7; SRIHARI S, 1984, COMPUTER TEXT RECOGN; SRIHARI SN, 1987, ARTIF INTELL, V33, P217, DOI 10.1016/0004-3702(87)90035-X; SRIHARI SN, 1983, ACM T OFFIC INFORM S, V1, P58; Tappert C. C., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P1004; TAPPERT CC, 1982, IBM J RES DEV, V26, P765, DOI 10.1147/rd.266.0765; TAYLOR I, 1983, PSYCHOL READ, P183; ZACHOPOULOS G, 1984, THESIS STATE U NEW Y	33	199	214	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1989	11	1					68	83		10.1109/34.23114	http://dx.doi.org/10.1109/34.23114			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	R4474					2022-12-18	WOS:A1989R447400006
J	Yang, J; Luo, L; Qian, JJ; Tai, Y; Zhang, FL; Xu, Y				Yang, Jian; Luo, Lei; Qian, Jianjun; Tai, Ying; Zhang, Fanlong; Xu, Yong			Nuclear Norm Based Matrix Regression with Applications to Face Recognition with Occlusion and Illumination Changes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Nuclear norm; robust regression; sparse representation; alternating direction method of multipliers (ADMM); face recognition	SPARSE; REPRESENTATION; MINIMIZATION; ALGORITHMS; FILTER	Recently, regression analysis has become a popular tool for face recognition. Most existing regression methods use the one-dimensional, pixel-based error model, which characterizes the representation error individually, pixel by pixel, and thus neglects the two-dimensional structure of the error image. We observe that occlusion and illumination changes generally lead, approximately, to a low-rank error image. In order to make use of this low-rank structural information, this paper presents a two-dimensional image-matrix-based error model, namely, nuclear norm based matrix regression (NMR), for face representation and classification. NMR uses the minimal nuclear norm of representation error image as a criterion, and the alternating direction method of multipliers (ADMM) to calculate the regression coefficients. We further develop a fast ADMM algorithm to solve the approximate NMR model and show it has a quadratic rate of convergence. We experiment using five popular face image databases: the Extended Yale B, AR, EURECOM, Multi-PIE and FRGC. Experimental results demonstrate the performance advantage of NMR over the state-of-the-art regression-based methods for face recognition in the presence of occlusion and illumination variations.	[Yang, Jian; Luo, Lei; Qian, Jianjun; Tai, Ying; Zhang, Fanlong] Nanjing Univ Sci & Technol, Sch Engn & Comp Sci, Nanjing 210094, Jiangsu, Peoples R China; [Xu, Yong] Harbin Inst Technol, Shenzhen Grad Sch, Shenzhen, Peoples R China	Nanjing University of Science & Technology; Harbin Institute of Technology; University Town of Shenzhen	Yang, J (corresponding author), Nanjing Univ Sci & Technol, Sch Engn & Comp Sci, Nanjing 210094, Jiangsu, Peoples R China.	csjyang@njust.edu.cn; zzdxpyy3001@163.com; csjqian@njust.edu.cn; tyshiwo@gmail.com; csfzhang@126.com; laterfall@hitsz.edu.cn	Tai, Ying/AID-2000-2022	Tai, Ying/0000-0002-4665-6852	National Science Fund of China [91420201, 61472187, 61502235, 61233011, 61373063]; 973 Program [2014CB349303]; Program for Changjiang Scholars and Innovative Research Team in University	National Science Fund of China(National Natural Science Foundation of China (NSFC)); 973 Program(National Basic Research Program of China); Program for Changjiang Scholars and Innovative Research Team in University(Program for Changjiang Scholars & Innovative Research Team in University (PCSIRT))	The authors would like to thank the editor and the anonymous reviewers for their critical and constructive comments and suggestions. This work was supported by the National Science Fund of China under Grant Nos. 91420201, 61472187, 61502235, 61233011 and 61373063, the 973 Program No. 2014CB349303, and Program for Changjiang Scholars and Innovative Research Team in University. J. Yang is the corresponding author. Jian Yang, Lei Luo, and Jianjun Qian are co-first authors.	[Anonymous], 2013, ARXIV10095055V3; Benavente R, 1998, 24 COMP VIS CTR; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes E, 2012, COMMUN ACM, V55, P111, DOI 10.1145/2184319.2184343; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Candes EJ, 2010, IEEE T INFORM THEORY, V56, P2053, DOI 10.1109/TIT.2010.2044061; Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644, DOI 10.1109/TPAMI.2002.1114855; Deng W., 2012, 1252 UCLA CAM, P12; Esser E, 2009, APPL LAGRANGIAN BASE; Fazel M, 2001, P AMER CONTR CONF, P4734, DOI 10.1109/ACC.2001.945730; Fazel M., 2002, MATRIX RANK MINIMIZA; Gabay D., 1976, Computers & Mathematics with Applications, V2, P17, DOI 10.1016/0898-1221(76)90003-1; Goldstein T, 2014, SIAM J IMAGING SCI, V7, P1588, DOI 10.1137/120896219; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Hansson A., 2012, ARXIV12070023; He BS, 2015, NUMER MATH, V130, P567, DOI 10.1007/s00211-014-0673-6; He BS, 1998, OPER RES LETT, V23, P151, DOI 10.1016/S0167-6377(98)00044-3; He R, 2014, IEEE T PATTERN ANAL, V36, P261, DOI 10.1109/TPAMI.2013.102; He R, 2011, NEURAL COMPUT, V23, P2074, DOI 10.1162/NECO_a_00155; He R, 2011, IEEE T PATTERN ANAL, V33, P1561, DOI 10.1109/TPAMI.2010.220; HOLLAND PW, 1977, COMMUN STAT A-THEOR, V6, P813, DOI 10.1080/03610927708827533; Huang J., 2009, P INT C MACH LEARN; Jenatton R., 2010, INT C ARTIFICIAL INT; Jenatton R, 2011, J MACH LEARN RES, V12, P2777; Jia K, 2012, LECT NOTES COMPUT SC, V7575, P331, DOI 10.1007/978-3-642-33765-9_24; Kavukcuoglu K, 2009, PROC CVPR IEEE, P1605, DOI 10.1109/CVPRW.2009.5206545; Kontogiorgis S, 1998, MATH PROGRAM, V83, P29, DOI 10.1007/BF02680549; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Li XX, 2013, IEEE T IMAGE PROCESS, V22, P1889, DOI 10.1109/TIP.2013.2237920; LIONS PL, 1979, SIAM J NUMER ANAL, V16, P964, DOI 10.1137/0716071; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu Z, 2009, SIAM J MATRIX ANAL A, V31, P1235, DOI 10.1137/090755436; Luo L, 2014, INT C PATT RECOG, P1834, DOI 10.1109/ICPR.2014.321; Mairal J., 2011, SPIE WAVELETS SPARSI, VXIV, P8138; Min R, 2014, IEEE T SYST MAN CY-S, V44, P1534, DOI 10.1109/TSMC.2014.2331215; Naseem I, 2012, PATTERN RECOGN, V45, P104, DOI 10.1016/j.patcog.2011.07.003; Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128; Nesterov Y., 1983, SOV MATH DOKL, V27, P372; Peng YG, 2010, PROC CVPR IEEE, P763, DOI 10.1109/CVPR.2010.5540138; Phillips PJ, 2005, PROC CVPR IEEE, P947; Ran He, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2889, DOI 10.1109/CVPR.2011.5995328; Recht B, 2008, IEEE DECIS CONTR P, P3065, DOI 10.1109/CDC.2008.4739332; Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835; Rigamonti R, 2011, PROC CVPR IEEE, P1545, DOI 10.1109/CVPR.2011.5995313; Savvides M, 2004, PROC CVPR IEEE, P834; Shi QF, 2011, PROC CVPR IEEE, P553, DOI 10.1109/CVPR.2011.5995556; Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112; Wright J., 2009, P ADV NEUR INF PROC, V58, P289; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yang J., 2014, 140520141207 ARXIV, V1405, P1207; Yang J, 2007, IEEE T INF FOREN SEC, V2, P781, DOI 10.1109/TIFS.2007.910239; Yang J, 2012, PATTERN RECOGN, V45, P1104, DOI 10.1016/j.patcog.2011.08.022; Yang M, 2012, LECT NOTES COMPUT SC, V7572, P850, DOI 10.1007/978-3-642-33718-5_61; Yang M, 2013, IEEE T IMAGE PROCESS, V22, P1753, DOI 10.1109/TIP.2012.2235849; Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393; Yuan XM, 2013, PAC J OPTIM, V9, P167; Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277; Zhou Q, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 3, PROCEEDINGS, P241, DOI 10.1109/ICNC.2008.139; Zhou ZH, 2009, IEEE I CONF COMP VIS, P1050, DOI 10.1109/ICCV.2009.5459383	64	198	209	9	117	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2017	39	1					156	171		10.1109/TPAMI.2016.2535218	http://dx.doi.org/10.1109/TPAMI.2016.2535218			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EF6DP	26930675	Green Submitted			2022-12-18	WOS:000390421300014
J	Veenman, CJ; Reinders, MJT; Backer, E				Veenman, CJ; Reinders, MJT; Backer, E			Resolving motion correspondence for densely moving points	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion correspondence; feature point tracking; target tracking; algorithms	MULTITARGET TRACKING; MULTIPLE TARGETS; DATA ASSOCIATION; ALGORITHM; IMPLEMENTATION; TRAJECTORIES	This paper studies the motion correspondence problem for which a diversity of qualitative and statistical solutions exist. We concentrate on qualitative modeling, especially in situations where assignment conflicts arise either because multiple features compete for one detected point or because multiple detected points fit a single feature point. We leave out the possibility of point track initiation and termination because that principally conflicts with allowing for temporary point occlusion. We introduce individual, combined, and global motion models and fit existing qualitative solutions in this framework. Additionally, we present a new efficient tracking algorithm that satisfies these-possibly constrained-models in a greedy matching sense, including an effective way to handle detection errors and occlusion. The performance evaluation shows that the proposed algorithm outperforms existing greedy matching algorithms. Finally, we describe an extension to the tracker that enables automatic initialization of the point tracks. Several experiments show that the extended algorithm is efficient, hardly sensitive its few parameters, and qualitatively better than other algorithms, including the presumed optimal statistical multiple hypothesis tracker.	Delft Univ Technol, Fac Informat Technol & Syst, Dept Mediamat, NL-2600 GA Delft, Netherlands	Delft University of Technology	Veenman, CJ (corresponding author), Delft Univ Technol, Fac Informat Technol & Syst, Dept Mediamat, POB 5031, NL-2600 GA Delft, Netherlands.							Chetverikov D, 1999, COMPUTING, V62, P321, DOI 10.1007/s006070050027; Cox IJ, 1996, IEEE T PATTERN ANAL, V18, P138, DOI 10.1109/34.481539; COX IJ, 1993, INT J COMPUT VISION, V10, P53, DOI 10.1007/BF01440847; Cox IJ, 1997, IEEE T AERO ELEC SYS, V33, P295, DOI 10.1109/7.570789; COX IJ, 1995, IEEE T AERO ELEC SYS, V32, P486; Danchicka R., 1993, IEEE T AERO ELEC SYS, V29, P555; Deb S, 1997, IEEE T AERO ELEC SYS, V33, P523, DOI 10.1109/7.575891; DEB S, 1992, P IEEE INT C SYST MA, P249; FORTMANN TE, 1983, IEEE J OCEANIC ENG, V8, P173, DOI 10.1109/JOE.1983.1145560; Hodges KI, 1999, MON WEATHER REV, V127, P1362, DOI 10.1175/1520-0493(1999)127<1362:ACFFT>2.0.CO;2; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HWANG VSS, 1989, PATTERN RECOGN, V22, P247, DOI 10.1016/0031-3203(89)90073-3; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Mehrotra R, 1998, PATTERN RECOGN, V31, P23, DOI 10.1016/S0031-3203(97)00030-7; Miller ML, 1997, IEEE T AERO ELEC SYS, V33, P851, DOI 10.1109/7.599256; NAGARAJAN V, 1987, IEE PROC-F, V134, P113, DOI 10.1049/ip-f-1.1987.0019; POORE A, 1995, PARTITIONING DATA SE, P169; POORE AB, 1999, P 2 INT C INF FUS, V2, P1037; RANGARAJAN K, 1991, CVGIP-IMAG UNDERSTAN, V54, P56, DOI 10.1016/1049-9660(91)90075-Z; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; SALAH K, 1990, INT J MINI MICROCOMP, V12, P97; SETHI IK, 1987, IEEE T PATTERN ANAL, V9, P56, DOI 10.1109/TPAMI.1987.4767872; Shea PJ, 1998, P SOC PHOTO-OPT INS, V3373, P428, DOI 10.1117/12.324636; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; VEENMAN CJ, 1998, P IEEE INT C IM PROC, V3, P653; Verestoy J, 2000, P WORKSH EV VAL COMP, P183	27	198	213	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2001	23	1					54	72		10.1109/34.899946	http://dx.doi.org/10.1109/34.899946			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	390VA		Green Submitted			2022-12-18	WOS:000166316700005
J	Zhu, SC; Mumford, D				Zhu, SC; Mumford, D			Prior learning and Gibbs reaction-diffusion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						visual learning; Gibbs distribution; reaction-diffusion; anisotropic diffusion; texture synthesis; clutter modeling; image restoration	SURFACE RECONSTRUCTION; IMAGE SEGMENTATION; SPACE; RESTORATION; EDGE	This article addresses two important themes in early visual computation: First, it presents a novel theory for learning the universal statistics of natural images-a prior model for typical cluttered scenes of the world-from a set of natural images, and, second, it proposes a general framework of designing reaction-diffusion equations for image processing. We start by studying the statistics of natural images including the scale invariant properties, then generic prior models were learned to duplicate the observed statistics, based on the minimax entropy theory studied in two previous papers. The resulting Gibbs distributions have potentials of the form U(I; Lambda, S) = Sigma(alpha=1)(k) Sigma((x,y))(lambda(alpha))((F-(alpha)*I)(x,y)) with S = (F-(1), F-(2), ..., F-(K)} being a set of filters and Lambda = {lambda((1))(),lambda((2))(). (),..., lambda((K))()} the potential functions. The learned Gibbs distributions confirm and improve the form of existing prior models such as line-process, but, in contrast to all previous models, inverted potentials (i.e., lambda(x) decreasing as a function of \x\) were found to be necessary. We find that the partial differential equations given by gradient descent on U(I; Lambda, S) are essentially reaction-diffusion equations, where the usual energy terms produce anisotropic diffusion, while the inverted energy terms produce reaction associated with pattern formation, enhancing preferred image features. We illustrate how these models can be used for texture pattern rendering, denoising, image enhancement, and clutter removal by careful choice of both prior and data models of this type, incorporating the appropriate features.	BROWN UNIV,DIV APPL MATH,PROVIDENCE,RI 02912	Brown University	Zhu, SC (corresponding author), STANFORD UNIV,DEPT COMP SCI,STANFORD,CA 94305, USA.							Berger A. L., 1996, COMPUTATIONAL LINGUI, V22; BLACK M, IN PRESS IEEE T IMAG; BLACK MJ, 1996, INT J COMPUTER VISIO, V19; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; FIELD D, 1987, J OPTICAL SOC AM, V4; GABOR D, 1946, IEE P, V93; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; GEIGER D, 1991, INT J COMPUT VISION, V6, P227, DOI 10.1007/BF00115697; GELFAND SB, 1993, MARKOV RANDOM FIELDS; GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GEMAN S, 1986, SIAM J CONTROL OPTIM, V24; GIDAS B, 1989, IEEE T PATTERN ANAL, V11; Grindrod P., 1996, THEORY APPL REACTION; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; MARROGUIN J, 1987, J AM STAT ASS, V82; MEER P, 1991, INT J COMPUTER VISIO, V6; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; MURRAY JD, 1981, J THEOR BIOL, V88, P161, DOI 10.1016/0022-5193(81)90334-9; Niessen WJ, 1997, INT J COMPUT VISION, V21, P187, DOI 10.1023/A:1007995731951; NITZBERG M, 1992, IEEE T PATTERN ANAL, V14, P826, DOI 10.1109/34.149593; OLSHAUSEN BA, 1995, P WORKSH INF THEOR B; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; RUDERMAN DL, 1994, PHYS REV LETT, V73, P814, DOI 10.1103/PhysRevLett.73.814; SHERSTINSKY A, 1996, IEEE T IMAGE PROCESS, V5; SWINDALE NV, 1980, PROC R SOC SER B-BIO, V208, P243, DOI 10.1098/rspb.1980.0051; TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8; Tikhonov A., 1977, SOLUTIONS ILL POSED; TURING AM, 1952, PHILOS T ROY SOC B, V237, P37, DOI 10.1098/rstb.1952.0012; TURK G, 1991, COMPUTER GRAPHICS, V25; WATSON AB, 1987, J OPTICAL SOC AM A, V4; WILSON KG, 1975, REV MOD PHYS, V47, P773, DOI 10.1103/RevModPhys.47.773; WINKLER G., 1995, IMAGE ANAL RANDOM FI; Witkin A., 1991, COMPUTER GRAPHICS, V25; ZHU S, 1997, NEURAL COMPUTATION, V9; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343; ZHU SC, 1996, P CVPR; ZHU SC, TR9605 HARV ROB LAB	42	198	207	1	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1997	19	11					1236	1250						15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YG585		Green Published			2022-12-18	WOS:A1997YG58500005
J	Qi, XB; Xiao, R; Li, CG; Qiao, Y; Guo, J; Tang, XO				Qi, Xianbiao; Xiao, Rong; Li, Chun-Guang; Qiao, Yu; Guo, Jun; Tang, Xiaoou			Pairwise Rotation Invariant Co-Occurrence Local Binary Pattern	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Co-occurrence LBPs; rotation invariance; texture classification; material recognition; flower recognition; leaf recognition; food recognition; scene recognition	TEXTURE CLASSIFICATION; FACE RECOGNITION; REPRESENTATION; EXTRACTION; FEATURES; SCENE; SHAPE	Designing effective features is a fundamental problem in computer vision. However, it is usually difficult to achieve a great tradeoff between discriminative power and robustness. Previous works shown that spatial co-occurrence can boost the discriminative power of features. However the current existing co-occurrence features are taking few considerations to the robustness and hence suffering from sensitivity to geometric and photometric variations. In this work, we study the Transform Invariance (TI) of co-occurrence features. Concretely we formally introduce a Pairwise Transform Invariance (PTI) principle, and then propose a novel Pairwise Rotation Invariant Co-occurrence Local Binary Pattern (PRICoLBP) feature, and further extend it to incorporate multi-scale, multi-orientation, and multi-channel information. Different from other LBP variants, PRICoLBP can not only capture the spatial context co-occurrence information effectively, but also possess rotation invariance. We evaluate PRICoLBP comprehensively on nine benchmark data sets from five different perspectives, e.g., encoding strategy, rotation invariance, the number of templates, speed, and discriminative power compared to other LBP variants. Furthermore we apply PRICoLBP to six different but related applications-texture, material, flower, leaf, food, and scene classification, and demonstrate that PRICoLBP is efficient, effective, and of a well-balanced tradeoff between the discriminative power and robustness.	[Qi, Xianbiao; Li, Chun-Guang; Guo, Jun] Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing 100876, Peoples R China; [Xiao, Rong] Microsoft Corp, Redmond, WA 98052 USA; [Qiao, Yu; Tang, Xiaoou] Chinese Acad Sci, Shenzhen Key Lab Comp Vis & Pattern Recognit, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China	Beijing University of Posts & Telecommunications; Microsoft; Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS	Qi, XB (corresponding author), Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing 100876, Peoples R China.	qixianbiao@gmail.com; rxiao@microsoft.com; lichunguang@bupt.edu.cn; yu.qiao@siat.ac.cn; guojun@bupt.edu.cn; xtang@ie.cuhk.edu.hk	Qiao, Yu/ABD-5787-2021		Natural Science Foundation of China (NSFC) [61175011, 61273217, 61171193]; 111 Project [B08004]; NSFC [91320101]; Shenzhen Basic Research Program [JC201005270350A, JCYJ20120903092050890, JCYJ20120617114614438]; CAS	Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); 111 Project(Ministry of Education, China - 111 Project); NSFC(National Natural Science Foundation of China (NSFC)); Shenzhen Basic Research Program; CAS(Chinese Academy of Sciences)	The authors would like to thank the anonymous reviewers for constructive comments. We also want to thank Dr. Guoying Zhao for giving some useful comments. X. Qi, C.-G. Li, and J. Guo are supported by the Natural Science Foundation of China (NSFC) under Grant nos. 61175011, 61273217, and 61171193, and the 111 Project under Grant no. B08004. Y. Qiao and X. Tang are supported by NSFC (91320101), Shenzhen Basic Research Program (JC201005270350A, JCYJ20120903092050890, JCYJ20120617114614438), 100 Talents Programme of CAS.	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Ahonen T, 2009, LECT NOTES COMPUT SC, V5575, P61, DOI 10.1007/978-3-642-02230-2_7; Bo L., 2009, P ADV NEUR INF PROC, V1730, P1731; Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598; Brodatz P., 1999, TEXTURES PHOTOGRAPHI; Caputo B, 2010, IMAGE VISION COMPUT, V28, P150, DOI 10.1016/j.imavis.2009.05.005; Chai Y., 2011, THESIS SWISS FEDERAL; Chai YN, 2012, LECT NOTES COMPUT SC, V7572, P794, DOI 10.1007/978-3-642-33718-5_57; Chai YN, 2011, IEEE I CONF COMP VIS, P2579, DOI 10.1109/ICCV.2011.6126546; Chang P., 1999, P IEEE C COMP VIS PA; Chen M, 2009, IEEE IMAGE PROC, P289, DOI 10.1109/ICIP.2009.5413511; Chum O, 2010, PROC CVPR IEEE, P3416, DOI 10.1109/CVPR.2010.5539997; Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Felzenszwalb P.F., 2007, P 2007 IEEE C COMP V, P1, DOI [DOI 10.1109/CVPR.2007.383018, 10.1109/CVPR.2007.383018]; Fox D, 2010, ADV NEURAL INFORM PR, P244; Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957; Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Hayman E, 2004, LECT NOTES COMPUT SC, V2034, P253; Hobson P., 2013, P IEEE 20 INT C IM P; Hu DN, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.48; Huu-Giao Nguyen, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2945, DOI 10.1109/CVPR.2011.5995340; Ito S, 2010, LECT NOTES COMPUT SC, V6312, P209, DOI 10.1007/978-3-642-15552-9_16; Kanan C, 2010, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2010.5539947; Kwitt Roland, 2012, Computer Vision - ECCV 2012. Proceedings of the 12th European Conference on Computer Vision, P359, DOI 10.1007/978-3-642-33765-9_26; Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Li WB, 2012, LECT NOTES COMPUT SC, V7575, P345, DOI 10.1007/978-3-642-33765-9_25; Liao ZC, 2013, PROC CVPR IEEE, P963, DOI 10.1109/CVPR.2013.129; Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41; Liu C, 2010, PROC CVPR IEEE, P239, DOI 10.1109/ICCET.2010.5485248; Liu L, 2012, IEEE T PATTERN ANAL, V34, P574, DOI 10.1109/TPAMI.2011.145; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Ni BB, 2012, PROC CVPR IEEE, P3514, DOI 10.1109/CVPR.2012.6248094; Nilsback M.-E., 2009, THESIS U OXFORD OXFO; Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47; Nosaka R, 2011, LECT NOTES COMPUT SC, V7088, P82, DOI 10.1007/978-3-642-25346-1_8; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Orban GA, 2008, PHYSIOL REV, V88, P59, DOI 10.1152/physrev.00008.2007; Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383; Parizi SN, 2012, PROC CVPR IEEE, P2775, DOI 10.1109/CVPR.2012.6248001; Qi XB, 2012, LECT NOTES COMPUT SC, V7577, P158, DOI 10.1007/978-3-642-33783-3_12; Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537; Rasiwasia N, 2009, PROC CVPR IEEE, P1889, DOI 10.1109/CVPRW.2009.5206826; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Sadeghi F, 2012, LECT NOTES COMPUT SC, V7576, P228, DOI 10.1007/978-3-642-33715-4_17; Sharan L, 2010, J VISION, V9, P784; Sharan L, 2013, INT J COMPUT VISION, V103, P348, DOI 10.1007/s11263-013-0609-0; SODERKVIST OJO, 2001, THESIS LINKOPING U L; Su H., 2010, ADV NEURAL PROCESSIN, V1, P1378; Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168; van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132; Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4; Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182; Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153; Vedaldi Andrea, 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249; Vu N.-S., 2011, P INT JOINT C BIOM, P1; Vu NS, 2010, LECT NOTES COMPUT SC, V6311, P313; Wang LW, 2012, PROC CVPR IEEE, P2767, DOI 10.1109/CVPR.2012.6248000; Wang ZL, 2013, IEEE T IMAGE PROCESS, V22, P537, DOI 10.1109/TIP.2012.2218826; Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Yang S, 2010, PROC CVPR IEEE, P2249, DOI 10.1109/CVPR.2010.5539907; Yang Y, 2011, IEEE I CONF COMP VIS, P1465, DOI 10.1109/ICCV.2011.6126403; Yuan JS, 2011, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2011.5995476; Yuan XT, 2010, PROC CVPR IEEE, P3493, DOI 10.1109/CVPR.2010.5539967; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhang SW, 2013, PATTERN RECOGN, V46, P1891, DOI 10.1016/j.patcog.2013.01.015; Zhang YM, 2011, PROC CVPR IEEE, P809, DOI 10.1109/CVPR.2011.5995528; Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110; Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739; Zhu J., 2010, P ADV NEUR INF PROC, P2586	74	197	212	5	76	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2014	36	11					2199	2213		10.1109/TPAMI.2014.2316826	http://dx.doi.org/10.1109/TPAMI.2014.2316826			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR6OI	26353061				2022-12-18	WOS:000343702400007
J	Grangier, D; Bengio, S				Grangier, David; Bengio, Samy			A discriminative kernel-based model to rank images from text queries	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image retrieval; ranking; discriminative learning; kernel-based classifier; large margin		This paper introduces a discriminative model for the retrieval of images from text queries. Our approach formalizes the retrieval task as a ranking problem and introduces a learning procedure optimizing a criterion related to the ranking performance. The proposed model hence addresses the retrieval problem directly and does not rely on an intermediate image annotation task, which contrasts with previous research. Moreover, our learning procedure builds upon recent work on the online learning of kernel-based classifiers. This yields an efficient scalable algorithm, which can benefit from recent kernels developed for image comparison. The experiments performed over stock photography data show the advantage of our discriminative ranking approach over state-of-the-art alternatives (for example, our model yields 26.3 percent average precision over the Corel data set, which should be compared to 22.0 percent for the best alternative model evaluated). Further analysis of the results shows that our model is especially advantageous over difficult queries such as queries with few relevant pictures or multiple-word queries.	[Grangier, David] IDIAP Res Inst, Ctr Parc, CH-1920 Martigny, Switzerland; [Bengio, Samy] Google Inc, Mountain View, CA 94043 USA	Google Incorporated	Grangier, D (corresponding author), IDIAP Res Inst, Ctr Parc, Av Pres Beudin 20,Case Postale 592, CH-1920 Martigny, Switzerland.	grangier@idiap.ch; bengio@google.com		Grangier, David/0000-0002-8847-9532				AMIR A, 2005, P TREC VID WORKSH; Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463; BARNARD K, 2001, P INT C COMP VIS ICC; BARNARD K, 2003, J MACHINE LEARNING R, V3; Blei D, 2003, J MACHINE LEARNING R, V3; BOUGHORBEL S, 2004, P BRIT MACH VIS C; BRINKER K, 2005, P NIPS WORKSH LEARN; Burges C., 2005, P INT C MACH LEARN I; CARNEIRO G, 2005, P C COMP VIS PATT RE; CHANG SF, 2006, P TREC VID WORKSH; Collobert R., 2004, ICML, V04; Crammer K., 2006, J MACHINE LEARNING R, V7; DUYGULU P., 2002, P EUR C COMP VIS ECC; EICHHORN J, 2004, 137 MAX PLANCK I; FENG SL, 2004, P C COMP VIS PATT RE; GRANGIER D, 2005, P NIPS WORKSH LEARN; GRANGIER FMD, 2006, P INT C AD MULT RETR; Grauman K., 2005, P INT C COMP VIS ICC; Herbrich R., 2000, ADV LARGE MARGIN CLA; Hofmann Thomas, 2001, MACHINE LEARNING, V42; JEBARA T, 2003, P C LEARN THEOR; JEON J, 2003, P ACM SPEC INT GROUP; JEON J, 2004, P INT C IM VID RETR; Joachims T., 1998, MAKING LARGE SCALE S; JOACHIMS T, 2002, P INT C KNOWL DISC D; Joachims T., 2005, P INT C MACH LEARN I; Kondor R, 2003, P INT C MACH LEARN I; LAVRENKO V, 2002, P ACM SPEC INT GROUP; Lowe D.G., 2004, INT J COMPUTER VISIO, V60; LYU S, 2005, P EUR C MACH LEARN E; Monay F., 2004, P ACM INT C MULT; MUELLER H, 2002, P INT C IM VID RETR; NAPHADE MR, 2004, J VISUAL COMM IMAGE, V15; Ojala T., 2002, T PATTERN ANAL MACHI, V24; PAN JY, 2004, P INT C MULT EXP ICM; Quelhas P, 2005, IEEE I CONF COMP VIS, P883; RAKOTOMAMONJY A, 2004, P EUR C ART INT WORK; RICE J, 1995, RICE MATH STAT DATA; Sivic J., 2005, P INT C COMP VIS ICC; SMEATON AF, 2006, P ACM WORKSH MULT IN; Szummer M., 1998, P WORKSH CONT BAS AC; TAKALA V, 2005, P SCAND C IM AN SCIA; TIEU K, 2004, INT J COMPUTER VISIO, V56; VAILAYA A, 1998, P WORKSH CONT BAS AC; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; VOGEL J, 2004, P INT C IM VID RETR; VOORHEES EM, 2001, P ACM ACM SPEC INT G; WALLRAVEN C, 2003, P INT C COMP VIS ICC	48	197	221	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2008	30	8					1371	1384		10.1109/TPAMI.2007.70791	http://dx.doi.org/10.1109/TPAMI.2007.70791			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	312OC	18566492				2022-12-18	WOS:000256679700005
J	Brand, M; Kettnaker, V				Brand, M; Kettnaker, V			Discovery and segmentation of activities in video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						video activity monitoring; hidden Markov models; hidden state; parameter estimation; entropy minimization	MARKOV-CHAINS; MODELS	Hidden Markov models (HMMs) have become the workhorses of the monitoring and event recognition literature because they bring to time-series analysts the utility of density estimation and the convenience of dynamic time warping. Once trained. the internals of these models are considered opaque; there is no effort to interpret the hidden states. We show that by minimizing the entropy of the joint distribution, an HMM's internal state machine can be made to organize observed activity into meaningful states. This has uses in video monitoring and annotation, low bit-rate coding of scene activity. and detection of anomalous behavior. We demonstrate with models of office activity and outdoor traffic, showing how the framework learns principal modes of activity and patterns of activity change. We then show how this framework can be adapted to infer hidden state from extremely ambiguous images. In particular, inferring 3D body orientation and pose from sequences of low-resolution silhouettes.	Mitsubishi Elect Res Labs, Cambridge, MA 02139 USA; Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA	Rensselaer Polytechnic Institute	Brand, M (corresponding author), Mitsubishi Elect Res Labs, 201 Braodway, Cambridge, MA 02139 USA.		Kettnaker, Vera/AAB-4384-2020	Kettnaker, Vera/0000-0003-0967-0214				[Anonymous], 1998, STAT METHODS SPEECH; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; BENGIO Y, 1995, ADV NEURAL INFORMATI, V7, P553; Brand M, 1999, NEURAL COMPUT, V11, P1155, DOI 10.1162/089976699300016395; BRAND M, 1999, P INT C COMP VIS; BRAND M, 2000, P INT C MACH LEARN; BRAND M, 1999, ARTIFICIAL INTELLIGE; Grimson WEL, 1998, PROC CVPR IEEE, P22, DOI 10.1109/CVPR.1998.698583; JUANG BH, 1986, IEEE T INFORM THEORY, V32, P307, DOI 10.1109/TIT.1986.1057145; LIPORACE LA, 1982, IEEE T INFORM THEORY, V28, P729, DOI 10.1109/TIT.1982.1056544; PENTLAND A, 1997, P INT C AUT FAC GEST; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rissanen Jorma, 1989, STOCHASTIC COMPLEXIT; STRAT T, 1998, P DARPA IM UND WORKS; VITANYI P, 1996, ISIS INFORMATION STA, P282; WALLACE CS, 1987, J ROY STAT SOC B MET, V49, P240; WREN C, 1995, P SPIE, V2615; YACHIDA M, 1998, P INT C AUT FAC GEST	18	197	213	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2000	22	8					844	851		10.1109/34.868685	http://dx.doi.org/10.1109/34.868685			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	354GN					2022-12-18	WOS:000089321500010
J	Cappelli, R; Lumini, A; Maio, D; Maltoni, D				Cappelli, R; Lumini, A; Maio, D; Maltoni, D			Fingerprint classification by directional image partitioning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fingerprint classification; directional image; partitioning algorithms; continuous classification; biometric systems	MAPS	In this work, we introduce a new approach to automatic fingerprint classification. The directional Image is partitioned into "homogeneous" connected regions according to the fingerprint topology, thus giving a synthetic representation which can be exploited as a basis for the classification. A set of dynamic masks, together with an optimization criterion, are used to guide the partitioning. The adaptation of the masks produces a numerical vector representing each fingerprint as a multidimensional point, which can be conceived as a continuous classification. Different search strategies are discussed to efficiently retrieve fingerprints both with continuous and exclusive classification. Experimental results have been given for the most commonly used fingerprint databases and the new method has been compared with other approaches known in the literature: As to fingerprint retrieval based on continuous classification, our method gives the best performance and exhibits a very high robustness.	Univ Bologna, Corso Laurea Sci Informaz, I-47023 Cesena, Italy; Univ Bologna, DEIS, CNR, CSITE, I-40136 Bologna, Italy	University of Bologna; Consiglio Nazionale delle Ricerche (CNR); University of Bologna	Cappelli, R (corresponding author), Univ Bologna, Corso Laurea Sci Informaz, Via Sacchi 3, I-47023 Cesena, Italy.		Lumini, Alessandra/B-6100-2013; Lumini, Alessandra/AAF-2975-2020	Lumini, Alessandra/0000-0003-0290-7354; Lumini, Alessandra/0000-0003-0290-7354; Cappelli, Raffaele/0000-0003-3054-9363				Bowen J., 1992, P IEE C NEUR NETW IM; Bunke H, 1983, PATTERN RECOGN LETT, V1, P245, DOI 10.1016/0167-8655(83)90033-8; CANDELA GT, 1995, 5647 NIST NISTIR; CANDELA GT, 1993, 5163 NIST NISTIR; Chong MMS, 1997, PATTERN RECOGN, V30, P1475, DOI 10.1016/S0031-3203(96)00178-1; DONAHUE MJ, 1993, CVGIP-IMAG UNDERSTAN, V57, P185, DOI 10.1006/ciun.1993.1012; Galton Francis, 1892, FINGER PRINTS; Henry ER., 1900, CLASSIFICATION USES; HUGHES PA, 1991, P 2 INT C NEUR NETW, P79; JAIN AK, 1989, FUNDAMENTALS DIGITAL, P163; Jolliffe I.T., 1986, PRINCIPLE COMPONENT; KAMIJO M, 1993, P 3 INT C NEUR NETW, P1932; Karu K, 1996, PATTERN RECOGN, V29, P389, DOI 10.1016/0031-3203(95)00106-9; KAWAGOE M, 1984, PATTERN RECOGN, V17, P295, DOI 10.1016/0031-3203(84)90079-7; Lee H. C., 1991, ADV FINGERPRINT TECH; Lumini A, 1997, PATTERN RECOGN LETT, V18, P1027, DOI 10.1016/S0167-8655(97)00127-X; MAIO D, 1995, PATTERN RECOGN LETT, V16, P89, DOI 10.1016/0167-8655(94)00069-F; Maio D, 1996, IEEE T PATTERN ANAL, V18, P1080, DOI 10.1109/34.544077; MAIO D, 1996, P 13 ICPR AUG VIENN; MOAYER B, 1975, PATTERN RECOGN, V7, P1, DOI 10.1016/0031-3203(75)90011-4; MOSCINSKA K, 1993, P 3 INT C NEUR NETW, P229; RAO CVK, 1980, IEEE T PATTERN ANAL, V2, P223; Senior A., 1997, P 31 AS C SIGN SYST, P306; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; SRINIVASAN VS, 1992, PATTERN RECOGN, V25, P139, DOI 10.1016/0031-3203(92)90096-2; STOCK RM, 1969, XM2478X1 CAL, P13; WATSON C, 1992, NIST SPECIAL DATABAS, V4; WATSON CI, 1993, NIST SPECIAL DATABAS, V14	28	197	226	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1999	21	5					402	421		10.1109/34.765653	http://dx.doi.org/10.1109/34.765653			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	194LK		Green Published			2022-12-18	WOS:000080194900003
J	KASHYAP, RL				KASHYAP, RL			OPTIMAL CHOICE OF AR AND MA PARTS IN AUTOREGRESSIVE MOVING AVERAGE MODELS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											KASHYAP, RL (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.							AKAIKE H, 1979, BIOMETRIKA, V66, P237, DOI 10.1093/biomet/66.2.237; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; BOX AEP, 1976, TIME SERIES ANAL; DEGUCHI K, 1978, IEEE T INFORM THEORY, V27, P738; DELP EJ, 1979, PATTERN RECOGN, V11, P313, DOI 10.1016/0031-3203(79)90041-4; Erdelyi A., 1956, ASYMPTOTIC EXPANSION; FINE TL, 1979, IEEE T AUTOMAT CONTR, V24; GUEGUEN C, 1980, ONR36 COL STAT U DEP; HANNAN EJ, 1980, ANN STAT, V8, P1071, DOI 10.1214/aos/1176345144; Kashyap R.L., 1976, DYNAMIC STOCHASTIC M; KASHYAP RL, 1978, IEEE T INFORM THEORY, V24, P281, DOI 10.1109/TIT.1978.1055893; KASHYAP RL, 1980, IEEE T AUTOMAT CONTR, V25, P996, DOI 10.1109/TAC.1980.1102471; KASHYAP RL, 1981, IEEE T INFORM THEORY, V27, P627, DOI 10.1109/TIT.1981.1056390; KASHYAP RL, 1977, IEEE T AUTOMAT CONTR, V22, P715, DOI 10.1109/TAC.1977.1101594; KASHYAP RL, 1982, JAN P IFAC S THEOR A; Makhoul J., 1975, P IEEE, V63; McCormick B. H., 1974, International Journal of Computer & Information Sciences, V3, P329, DOI 10.1007/BF00978978; RAO CR, 1965, LINEAR STATISTICAL I; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SHIBATA R, 1976, BIOMETRIKA, V63, P117; [No title captured]	22	197	199	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	2					99	104		10.1109/TPAMI.1982.4767213	http://dx.doi.org/10.1109/TPAMI.1982.4767213			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NE957	21869012				2022-12-18	WOS:A1982NE95700002
J	IKEUCHI, K				IKEUCHI, K			DETERMINING SURFACE ORIENTATIONS OF SPECULAR SURFACES BY USING THE PHOTOMETRIC STEREO METHOD	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											IKEUCHI, K (corresponding author), MINIST INT TRADE & IND,COMP VIS SECT,ELECTROTECH LAB,TOKYO,JAPAN.							Do Carmo M.P., 2016, DIFFERENTIAL GEOMETR, Vsecond; ERWAY DM, 1978, THESIS MASSACHUSETTS; GRIMSON WEL, 1979, P IMAGE UNDERSTANDIN; Horn B.K.P., 1975, PSYCHOL COMPUTER VIS; HORN BKP, 1979, APPL OPT, V18; HORN BKP, 1977, ARTIFICIAL INTELL, V8; IKEUCHI K, 1980, ARTIFICIAL INTELL LA, V566; LAND E, 1971, J OPT SOC AM, V61; MARR D, 1976, ARTIFICIAL INTELL LA, V364; NICODEMUS FE, 1977, NBS US DEP COMMERCE, V160; Woodham R.J., 1978, P SPIE, V155	11	197	205	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	6					661	669		10.1109/TPAMI.1981.4767167	http://dx.doi.org/10.1109/TPAMI.1981.4767167			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	MR996	21868986				2022-12-18	WOS:A1981MR99600006
J	Chen, QF; Li, DZY; Tang, CK				Chen, Qifeng; Li, Dingzeyu; Tang, Chi-Keung			KNN Matting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Natural image matting; layer extraction	IMAGE	This paper proposes to apply the nonlocal principle to general alpha matting for the simultaneous extraction of multiple image layers; each layer may have disjoint as well as coherent segments typical of foreground mattes in natural image matting. The estimated alphas also satisfy the summation constraint. As in nonlocal matting, our approach does not assume the local color-line model and does not require sophisticated sampling or learning strategies. On the other hand, our matting method generalizes well to any color or feature space in any dimension, any number of alphas and layers at a pixel beyond two, and comes with an arguably simpler implementation, which we have made publicly available. Our matting technique, aptly called KNN matting, capitalizes on the nonlocal principle by using K nearest neighbors (KNN) in matching nonlocal neighborhoods, and contributes a simple and fast algorithm that produces competitive results with sparse user markups. KNN matting has a closed-form solution that can leverage the preconditioned conjugate gradient method to produce an efficient implementation. Experimental evaluation on benchmark datasets indicates that our matting results are comparable to or of higher quality than state-of-the-art methods requiring more involved implementation. In this paper, we take the nonlocal principle beyond alpha estimation and extract overlapping image layers using the same Laplacian framework. Given the alpha value, our closed form solution can be elegantly generalized to solve the multilayer extraction problem. We perform qualitative and quantitative comparisons to demonstrate the accuracy of the extracted image layers.	[Chen, Qifeng] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA; [Li, Dingzeyu] Columbia Univ, Dept Comp Sci, New York, NY 10027 USA; [Tang, Chi-Keung] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China	Stanford University; Columbia University; Hong Kong University of Science & Technology	Chen, QF (corresponding author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.	cqf@stanford.edu; dli@cs.columbia.edu; cktang@cse.ust.hk	Li, Dingzeyu/AAM-9159-2020	Chen, Qifeng/0000-0003-2199-3948	Research Grant Council of Hong Kong Special Administrative Region [619112]	Research Grant Council of Hong Kong Special Administrative Region(Hong Kong Research Grants Council)	This research was supported by the Research Grant Council of Hong Kong Special Administrative Region under grant number 619112.	Barrett R., 1994, TEMPLATES SOLUTION L; Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1; Chen QF, 2012, PROC CVPR IEEE, P869, DOI 10.1109/CVPR.2012.6247760; Chuang YY, 2001, PROC CVPR IEEE, P264; Cohen M. F., 2007, P IEEE C COMP VIS PA; Cole F. H., 2002, THESIS HARVARD COLL; Gastal ESL, 2010, COMPUT GRAPH FORUM, V29, P575, DOI 10.1111/j.1467-8659.2009.01627.x; Goldman DB, 2010, IEEE T PATTERN ANAL, V32, P1060, DOI 10.1109/TPAMI.2009.102; Guan Y, 2006, COMPUT GRAPH FORUM, V25, P567, DOI 10.1111/j.1467-8659.2006.00976.x; He KM, 2010, PROC CVPR IEEE, P2165, DOI 10.1109/CVPR.2010.5539896; Kaiming He, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2049, DOI 10.1109/CVPR.2011.5995495; Lawrence J, 2006, ACM T GRAPHIC, V25, P735, DOI 10.1145/1141911.1141949; Lee P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2193, DOI 10.1109/CVPR.2011.5995665; Lepage D, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024178; Levin A, 2008, IEEE T PATTERN ANAL, V30, P1699, DOI 10.1109/TPAMI.2008.168; Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177; Lin HT, 2011, IEEE T PATTERN ANAL, V33, P2329, DOI 10.1109/TPAMI.2011.93; McCool MD, 2001, COMP GRAPH, P171, DOI 10.1145/383259.383276; Rhemann C., 2008, P BRIT MACH VIS C, P1, DOI DOI 10.5244/C.22.115; Rhemann C, 2010, PROC CVPR IEEE, P2149, DOI 10.1109/CVPR.2010.5539894; Rhemann C, 2009, PROC CVPR IEEE, P1826, DOI 10.1109/CVPRW.2009.5206503; Shahrian E, 2012, PROC CVPR IEEE, P718, DOI 10.1109/CVPR.2012.6247741; Singaraju D, 2011, IEEE T PATTERN ANAL, V33, P1295, DOI 10.1109/TPAMI.2010.206; Smith A. R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P259, DOI 10.1145/237170.237263; Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Wang J, 2005, IEEE I CONF COMP VIS, P936; Zhang ZP, 2012, IEEE IMAGE PROC, P2109, DOI 10.1109/ICIP.2012.6467308; Zheng YJ, 2009, IEEE I CONF COMP VIS, P889, DOI 10.1109/ICCV.2009.5459326	30	196	284	2	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2013	35	9					2175	2188		10.1109/TPAMI.2013.18	http://dx.doi.org/10.1109/TPAMI.2013.18			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	186GB	23868778				2022-12-18	WOS:000322029000010
J	Kuncheva, LI; Vetrov, DP				Kuncheva, Ludmila I.; Vetrov, Dmitry P.			Evaluation of stability of k-means cluster ensembles with respect to random initialization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						clustering; cluster ensembles; stability and diversity; cluster validity	ALGORITHMS	Many clustering algorithms, including cluster ensembles, rely on a random component. Stability of the results across different runs is considered to be an asset of the algorithm. The cluster ensembles considered here are based on k-means clusterers. Each clusterer is assigned a random target number of clusters, k and is started from a random initialization. Here, we use 10 artificial and 10 real data sets to study ensemble stability with respect to random k, and random initialization. The data sets were chosen to have a small number of clusters (two to seven) and a moderate number of data points (up to a few hundred). Pairwise stability is defined as the adjusted Rand index between pairs of clusterers in the ensemble, averaged across all pairs. Nonpairwise stability is defined as the entropy of the consensus matrix of the ensemble. An experimental comparison with the stability of the standard k-means algorithm was carried out for k from 2 to 20. The results revealed that ensembles are generally more stable, markedly so for larger k. To establish whether stability can serve as a cluster validity index, we first looked at the relationship between stability and accuracy with respect to the number of clusters, k. We found that such a relationship strongly depends on the data set, varying from almost perfect positive correlation (0.97, for the glass data) to almost perfect negative correlation (-0.93, for the crabs data). We propose a new combined stability index to be the sum of the pairwise individual and ensemble stabilities. This index was found to correlate better with the ensemble accuracy. Following the hypothesis that a point of stability of a clustering algorithm corresponds to a structure found in the data, we used the stability measures to pick the number of clusters. The combined stability index gave best results.	Univ Wales, Sch Informat, Bangor LL57 1UT, Gwynedd, Wales; Russian Acad Sci, Dorodnicyn Comp Ctr, Moscow 119991, Russia	Bangor University; Federal Research Center "Computer Science & Control" of RAS; Russian Academy of Sciences; Dorodnitsyn Computing Centre, RAS	Kuncheva, LI (corresponding author), Univ Wales, Sch Informat, Bangor LL57 1UT, Gwynedd, Wales.	l.i.kuncheva@bangor.ac.uk; vetrovd@yandex.ru	Vetrov, Dmitry/H-4870-2015; Kuncheva, Ludmila/J-4357-2014	Vetrov, Dmitry/0000-0001-6863-9028; Kuncheva, Ludmila/0000-0002-0415-6964				Ayad H., 2003, P 4 INT WORKSH MULT; Ben-Hur Asa, 2002, Pac Symp Biocomput, P6; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Duda R.O., 1973, J ROYAL STAT SOC SER; Dudoit S, 2003, BIOINFORMATICS, V19, P1090, DOI 10.1093/bioinformatics/btg038; Elisseeff A, 2005, J MACH LEARN RES, V6, P55; Fern X.Z., 2003, P 20 INT C MACH LEAR, P186; Fischer B, 2003, IEEE T PATTERN ANAL, V25, P1411, DOI 10.1109/TPAMI.2003.1240115; FRED A, 2003, P IEEE CS C COMP VIS; FRED A, 2001, P 2 INT WORKSH MULT; Fred ALN, 2005, IEEE T PATTERN ANAL, V27, P835, DOI 10.1109/TPAMI.2005.113; Fred ALN, 2002, INT C PATT RECOG, P276, DOI 10.1109/ICPR.2002.1047450; Ghosh J., 2002, P 3 INT WORKSH MULT; Gordon AD, 1999, CLASSIFICATION; GREENE D, 2004, TCDCS200412 DEPT COM; HADJITODOROV ST, 2005, INFORM FUSION; HU X, 2004, P 2 AS PAC BIOINF C; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; KUNCHEVA LI, 2004, P IEEE INT C SYST MA; Lange T, 2004, NEURAL COMPUT, V16, P1299, DOI 10.1162/089976604773717621; Law M. H, 2003, MSUCSE035; Levine E, 2001, NEURAL COMPUT, V13, P2573, DOI 10.1162/089976601753196030; Maulik U, 2002, IEEE T PATTERN ANAL, V24, P1650, DOI 10.1109/TPAMI.2002.1114856; MINAEI B, 2004, P INT C INF TECHN CO; Monti S, 2003, MACH LEARN, V52, P91, DOI 10.1023/A:1023949509487; MUFTI B.G., 2005, P INT S APPL STOCH M, P404; Newman C. B. D., 1998, UCI REPOSITORY MACHI; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Ripley BD., 1996; Roth V, 2002, COMPSTAT 2002: PROCEEDINGS IN COMPUTATIONAL STATISTICS, P123; Strehl A., 2003, Journal of Machine Learning Research, V3, P583, DOI 10.1162/153244303321897735; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; Topchy A, 2004, SIAM PROC S, P379; Topchy A, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P331; VILARINO F, 2005, PATTERN RECOGNITION; WEINGESSEL A, 2003, ENSAMBLE METHOD CLUS	37	196	211	0	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2006	28	11					1798	1808		10.1109/TPAMI.2006.226	http://dx.doi.org/10.1109/TPAMI.2006.226			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	083GC	17063684				2022-12-18	WOS:000240443400007
J	Wang, Q; Chen, ML; Nie, FP; Li, XL				Wang, Qi; Chen, Mulin; Nie, Feiping; Li, Xuelong			Detecting Coherent Groups in Crowd Scenes by Multiview Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Clustering methods; Optical imaging; Electronic mail; Videos; Computer science; Correlation; Crowd analysis; group detection; context descriptor; multiview clustering; graph clustering	TRACKING	Detecting coherent groups is fundamentally important for crowd behavior analysis. In the past few decades, plenty of works have been conducted on this topic, but most of them have limitations due to the insufficient utilization of crowd properties and the arbitrary processing of individuals. In this study, a Multiview-based Parameter Free framework (MPF) is proposed. Based on the L1-norm and L2-norm, we design two versions of the multiview clustering method, which is the main part of the proposed framework. This paper presents the contributions on three aspects: (1) a new structural context descriptor is designed to characterize the structural properties of individuals in crowd scenes; (2) a self-weighted multiview clustering method is proposed to cluster feature points by incorporating their orientation and context similarities; and (3) a novel framework is introduced for group detection, which is able to determine the group number automatically without any parameter or threshold to be tuned. The effectiveness of the proposed framework is evaluated on real-world crowd videos, and the experimental results show its promising performance on group detection. In addition, the proposed multiview clustering method is also evaluated on a synthetic dataset and several standard benchmarks, and its superiority over the state-of-the-art competitors is demonstrated.	[Wang, Qi; Chen, Mulin; Nie, Feiping; Li, Xuelong] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China; [Wang, Qi; Chen, Mulin; Nie, Feiping; Li, Xuelong] Northwestern Polytech Univ, Ctr Opt Imagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China	Northwestern Polytechnical University; Northwestern Polytechnical University	Wang, Q (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.; Wang, Q (corresponding author), Northwestern Polytech Univ, Ctr Opt Imagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China.	crabwq@gmail.com; chenmulin@mail.nwpu.edu.cn; feipingnie@gmail.com; xuelong_li@ieee.org	Li, Xuelong/ABF-3381-2020	Wang, Qi/0000-0002-7028-4956; Nie, Feiping/0000-0002-0871-6519	National Key R&D Program of China [2017YFB1002202]; National Natural Science Foundation of China [61773316]	National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the National Key R&D Program of China under Grant 2017YFB1002202, and the National Natural Science Foundation of China under Grant 61773316.	Ali S, 2007, PROC CVPR IEEE, P65; [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.109; Ballerini M, 2008, P NATL ACAD SCI USA, V105, P1232, DOI 10.1073/pnas.0711437105; Chen ML, 2017, INT CONF ACOUST SPEE, P1378, DOI 10.1109/ICASSP.2017.7952382; Fang JW, 2014, IEEE T CIRC SYST VID, V24, P854, DOI 10.1109/TCSVT.2013.2283646; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Ge WN, 2012, IEEE T PATTERN ANAL, V34, P1003, DOI 10.1109/TPAMI.2011.176; Hu M, 2008, INT C PATT RECOG, P9; KULLBACK S, 1968, IEEE T INFORM THEORY, V14, P765, DOI 10.1109/TIT.1968.1054195; Kumar D, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1413; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Li M., 2016, IJCAI, P1704; Li XL, 2017, AAAI CONF ARTIF INTE, P4147; Li YQ, 2015, AAAI CONF ARTIF INTE, P2750; Lin WY, 2016, IEEE T IMAGE PROCESS, V25, P1674, DOI 10.1109/TIP.2016.2531281; Liu XB, 2016, AAAI CONF ARTIF INTE, P3553; Liu XW, 2017, AAAI CONF ARTIF INTE, P2266; Liu XW, 2016, AAAI CONF ARTIF INTE, P1888; Mazzon R, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P202, DOI 10.1109/AVSS.2013.6636640; Mehran R, 2010, LECT NOTES COMPUT SC, V6313, P439; Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641; Nie F., 2016, IJCAI, P1881; Nie F., 2010, ADV NEURAL INFORM PR, V2, P1813; Nie FP, 2016, AAAI CONF ARTIF INTE, P1969; Nie FP, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P977, DOI 10.1145/2623330.2623726; Nie FP, 2011, IEEE T NEURAL NETWOR, V22, P1796, DOI 10.1109/TNN.2011.2162000; Rabaud V., 2006, PROC IEEE COMPUT SOC, V1, P705, DOI DOI 10.1109/CVPR.2006.92; Ryan D., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P218, DOI 10.1109/AVSS.2010.30; Shao J, 2014, PROC CVPR IEEE, P2227, DOI 10.1109/CVPR.2014.285; Solera F, 2016, IEEE T PATTERN ANAL, V38, P995, DOI 10.1109/TPAMI.2015.2470658; Tarjan R., 1972, SIAM Journal on Computing, V1, P146, DOI 10.1137/0201010; van Breukelen M, 1998, KYBERNETIKA, V34, P381; Wahid A, 2015, IEEE C EVOL COMPUTAT, P1696, DOI 10.1109/CEC.2015.7257091; Wang Q, 2017, AAAI CONF ARTIF INTE, P4292; Wang Q, 2014, NEUROCOMPUTING, V131, P227, DOI 10.1016/j.neucom.2013.10.021; Wang YH, 2016, IEEE INT SYM MULTIM, P14, DOI [10.1109/ISM.2016.64, 10.1109/ISM.2016.0013]; Winn J, 2005, IEEE I CONF COMP VIS, P756; Wu S, 2012, IEEE T SYST MAN CY B, V42, P1443, DOI 10.1109/TSMCB.2012.2192267; Wu YP, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P361, DOI 10.1145/2733373.2806227; Xia RK, 2014, AAAI CONF ARTIF INTE, P2149; Xia TA, 2010, IEEE T SYST MAN CY B, V40, P1438, DOI 10.1109/TSMCB.2009.2039566; Xiao Cai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1977, DOI 10.1109/CVPR.2011.5995740; Yi S, 2016, IEEE T IMAGE PROCESS, V25, P4354, DOI 10.1109/TIP.2016.2590322; Yi S, 2014, PROC CVPR IEEE, P2219, DOI 10.1109/CVPR.2014.284; Yuan Y, 2015, IEEE T CYBERNETICS, V45, P562, DOI 10.1109/TCYB.2014.2330853; Zhang CQ, 2015, IEEE I CONF COMP VIS, P1582, DOI 10.1109/ICCV.2015.185; Zhang YH, 2017, IEEE T CIRC SYST VID, V27, P635, DOI 10.1109/TCSVT.2016.2593609; Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70; Zhou BL, 2012, LECT NOTES COMPUT SC, V7573, P857, DOI 10.1007/978-3-642-33709-3_61; Zhou BL, 2014, IEEE T PATTERN ANAL, V36, P1586, DOI 10.1109/TPAMI.2014.2300484; Zhu F, 2014, LECT NOTES COMPUT SC, V8694, P139, DOI 10.1007/978-3-319-10599-4_10	51	195	200	12	79	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2020	42	1					46	58		10.1109/TPAMI.2018.2875002	http://dx.doi.org/10.1109/TPAMI.2018.2875002			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JV3VQ	30307858				2022-12-18	WOS:000502294300004
J	Cinbis, RG; Verbeek, J; Schmid, C				Cinbis, Ramazan Gokberk; Verbeek, Jakob; Schmid, Cordelia			Weakly Supervised Object Localization with Multi-Fold Multiple Instance Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Weakly supervised learning; object detection		Object category localization is a challenging problem in computer vision. Standard supervised training requires bounding box annotations of object instances. This time-consuming annotation process is sidestepped in weakly supervised learning. In this case, the supervised information is restricted to binary labels that indicate the absence/presence of object instances in the image, without their locations. We follow a multiple-instance learning approach that iteratively trains the detector and infers the object locations in the positive training images. Our main contribution is a multi-fold multiple instance learning procedure, which prevents training from prematurely locking onto erroneous object locations. This procedure is particularly important when using high-dimensional representations, such as Fisher vectors and convolutional neural network features. We also propose a window refinement method, which improves the localization accuracy by incorporating an objectness prior. We present a detailed experimental evaluation using the PASCALVOC 2007 dataset, which verifies the effectiveness of our approach.	[Cinbis, Ramazan Gokberk] Bilkent Univ, Dept Comp Engn, Ankara, Turkey; [Verbeek, Jakob; Schmid, Cordelia] Univ Grenoble Alpes, LEAR Team, Inria Grenoble Rhone Alpes, Lab Jean Kuntzmann,CNRS, Grenoble, France	Ihsan Dogramaci Bilkent University; UDICE-French Research Universities; Communaute Universite Grenoble Alpes; Institut National Polytechnique de Grenoble; Universite Grenoble Alpes (UGA); Centre National de la Recherche Scientifique (CNRS); Inria	Cinbis, RG (corresponding author), Bilkent Univ, Dept Comp Engn, Ankara, Turkey.	gcinbis@cs.bilkent.edu.tr; Jakob.Verbeek@inria.fr; cordelia.schmid@inria.fr	Cinbis, Ramazan Gokberk/AAQ-6929-2020	Cinbis, Ramazan Gokberk/0000-0003-0962-7101	European integrated project AXES; ERC advanced grant ALLEGRO	European integrated project AXES; ERC advanced grant ALLEGRO	This work was supported by the European integrated project AXES and the ERC advanced grant ALLEGRO. Most of this work was done when R. G. Cinbis was with LEAR team, Inria Grenoble Rhone-Alpes, Laboratoire Jean Kuntzmann, CNRS, University Grenoble Alpes, France.	Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226; Alted F, 2010, COMPUT SCI ENG, V12, P68, DOI 10.1109/MCSE.2010.51; Bagon S, 2010, PROC CVPR IEEE, P33, DOI 10.1109/CVPR.2010.5540233; Bengio Yoshua., 2009, P 26 ANN INT C MACHI, P41, DOI 10.1145/ 1553374.1553380; Berg TL, 2004, PROC CVPR IEEE, P848; Bilen H, 2014, P BRIT MACH VIS C, P112; Bilen H, 2014, INT J COMPUT VISION, V106, P237, DOI 10.1007/s11263-013-0646-8; Blaschko M., 2010, ADV NEURAL INFORM PR; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Cho M, 2015, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2015.7298724; Chum O., 2007, P IEEE C COMP VIS PA, P1; Cinbis RG, 2014, PROC CVPR IEEE, P2409, DOI 10.1109/CVPR.2014.309; Cinbis RG, 2013, IEEE I CONF COMP VIS, P2968, DOI 10.1109/ICCV.2013.369; Crandall DJ, 2006, LECT NOTES COMPUT SC, V3951, P16; Csurka Gabriella, 2004, P ECCV INT WORKSH ST; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deselaers T., 2012, IJCV, V100, P257; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Everingham M, 2009, IMAGE VISION COMPUT, V27, P545, DOI 10.1016/j.imavis.2008.04.018; Girshick RB, 2012, DISCRIMINATIVELY TRA; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Gu CH, 2012, LECT NOTES COMPUT SC, V7575, P445, DOI 10.1007/978-3-642-33765-9_32; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jia Y., P ACM MULT, P675; Kim G., 2009, P ADV NEUR INF PROC, P4; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar M., 2010, NIPS, P1189, DOI DOI 10.5555/2997189.2997322; Lampert CH, 2009, IEEE T PATTERN ANAL, V31, P2129, DOI 10.1109/TPAMI.2009.144; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Nguyen MH, 2009, IEEE I CONF COMP VIS, P1925, DOI 10.1109/ICCV.2009.5459426; Nesterov Y, 2005, MATH PROGRAM, V103, P127, DOI 10.1007/s10107-004-0552-5; Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383; Parkhi OM, 2011, IEEE I CONF COMP VIS, P1427, DOI 10.1109/ICCV.2011.6126398; Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065; Russakovsky O, 2012, LECT NOTES COMPUT SC, V7573, P1, DOI 10.1007/978-3-642-33709-3_1; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Shi ZY, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.78; Shi Z, 2013, IEEE I CONF COMP VIS, P2984, DOI 10.1109/ICCV.2013.371; Singh S, 2012, LECT NOTES COMPUT SC, V7573, P73, DOI 10.1007/978-3-642-33709-3_6; Siva P, 2013, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2013.416; Siva P, 2012, LECT NOTES COMPUT SC, V7574, P594, DOI 10.1007/978-3-642-33712-3_43; Siva P, 2011, IEEE I CONF COMP VIS, P343, DOI 10.1109/ICCV.2011.6126261; Song HO., 2014, ADV NEURAL INFORM PR, V2, P1637; Song HO, 2014, PR MACH LEARN RES, V32, P1611; Song Z, 2011, PROC CVPR IEEE, P1585, DOI 10.1109/CVPR.2011.5995330; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; van de Sande KEA, 2014, PROC CVPR IEEE, P2377, DOI 10.1109/CVPR.2014.304; Verbeek J., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383098; Vijayanarasimhan S, 2011, PROC CVPR IEEE, P1449, DOI 10.1109/CVPR.2011.5995430; Wang C, 2014, LECT NOTES COMPUT SC, V8694, P431, DOI 10.1007/978-3-319-10599-4_28; WANG JJ, 2010, PROC CVPR IEEE, P3360, DOI DOI 10.1109/CVPR.2010.5540018; Wang XY, 2013, IEEE I CONF COMP VIS, P17, DOI 10.1109/ICCV.2013.10; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	56	195	204	5	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2017	39	1					189	203		10.1109/TPAMI.2016.2535231	http://dx.doi.org/10.1109/TPAMI.2016.2535231			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EF6DP	26930676	Green Submitted, Green Published			2022-12-18	WOS:000390421300016
J	Han, H; Otto, C; Liu, XM; Jain, AK				Han, Hu; Otto, Charles; Liu, Xiaoming; Jain, Anil K.			Demographic Estimation from Face Images: Human vs. Machine Performance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Demographic estimation; demographic informative feature; quality assessment; hierarchical approach; crowdsourcing; human vs. machine	HUMAN AGE ESTIMATION; GENDER CLASSIFICATION; OBJECT RECOGNITION; FEATURES; SIMULATION; COLOR; POSE	Demographic estimation entails automatic estimation of age, gender and race of a person from his face image, which has many potential applications ranging from forensics to social media. Automatic demographic estimation, particularly age estimation, remains a challenging problem because persons belonging to the same demographic group can be vastly different in their facial appearances due to intrinsic and extrinsic factors. In this paper, we present a generic framework for automatic demographic (age, gender and race) estimation. Given a face image, we first extract demographic informative features via a boosting algorithm, and then employ a hierarchical approach consisting of between-group classification, and within-group regression. Quality assessment is also developed to identify low-quality face images that are difficult to obtain reliable demographic estimates. Experimental results on a diverse set of face image databases, FG-NET (1K images), FERET (3K images), MORPH II (75K images), PCSO (100K images), and a subset of LFW (4K images), show that the proposed approach has superior performance compared to the state of the art. Finally, we use crowdsourcing to study the human perception ability of estimating demographics from face images. A side-by-side comparison of the demographic estimates from crowdsourced data and the proposed algorithm provides a number of insights into this challenging problem.	[Han, Hu; Otto, Charles; Liu, Xiaoming; Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Michigan State University	Han, H (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.	hhan@cse.msu.edu; ottochar@cse.msu.edu; liuxm@cse.msu.edu; jain@cse.msu.edu		Han, Hu/0000-0001-6010-1792; liu, xiaoming/0000-0003-3215-8753				Ballihi L, 2012, IEEE T INF FOREN SEC, V7, P1766, DOI 10.1109/TIFS.2012.2209876; Baluja S, 2007, INT J COMPUT VISION, V71, P111, DOI 10.1007/s11263-006-8910-9; Bekios-Calfa J, 2011, IEEE T PATTERN ANAL, V33, P858, DOI 10.1109/TPAMI.2010.208; Best-Rowden L., 2014, P INT JOINT C BIOM C; BROWN E, 1993, PERCEPTION, V22, P829, DOI 10.1068/p220829; BRUNELLI R, 1995, P DARPA IM UND WORKS, P311; BURT DM, 1995, P ROY SOC B-BIOL SCI, V259, P137, DOI 10.1098/rspb.1995.0021; Chang KY, 2011, PROC CVPR IEEE, P585, DOI 10.1109/CVPR.2011.5995437; Chao WL, 2013, PATTERN RECOGN, V46, P628, DOI 10.1016/j.patcog.2012.09.011; Chen C., 2013, P SPIE; Chhaya N., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P466, DOI 10.1109/ICB.2012.6199794; Choi SE, 2011, PATTERN RECOGN, V44, P1262, DOI 10.1016/j.patcog.2010.12.005; Cognitec Systems GmbH, 2010, FACEVACS SOFTW DEV; Cootes T. F., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P484, DOI 10.1007/BFb0054760; COTTRELL GW, 1990, P 1990 C ADV NEUR IN, V3, P564; Dong YH, 2012, INT J PROD RES, V50, P2681, DOI 10.1080/00207543.2011.579637; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847; Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36; Gao, 2008, P 8 IEEE INT C AUT F, P1; Gao W, 2009, LECT NOTES COMPUT SC, V5558, P169, DOI 10.1007/978-3-642-01793-3_18; Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733; Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51; Grother P, 2007, IEEE T PATTERN ANAL, V29, P531, DOI 10.1109/TPAMI.2007.1019; Guo GD, 2011, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2011.5995404; Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681; Gutta S, 2000, IEEE T NEURAL NETWOR, V11, P948, DOI 10.1109/72.857774; Hadid A, 2013, NEUROCOMPUTING, V100, P197, DOI 10.1016/j.neucom.2011.10.040; Han Hu, 2013, P 2013 INT C BIOM IC, P1, DOI DOI 10.1109/ICB.2013.6613022; Hayashi J, 2002, INT C PATT RECOG, P405, DOI 10.1109/ICPR.2002.1044736; Huang G. B., 2007, 0749 U MASS SCH COMP; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837; Jain A. K., 2011, HDB FACE RECOGNITION, V1; Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48; Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549; Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Lu JW, 2013, IEEE T HUM-MACH SYST, V43, P249, DOI 10.1109/TSMCC.2012.2192727; Luu K., 2011, IJCB, P1; Maekinen E, 2008, PATTERN RECOGN LETT, V29, P1544, DOI 10.1016/j.patrec.2008.03.016; MAY KO, 1952, ECONOMETRICA, V20, P680, DOI DOI 10.2307/1907651; Meyers E, 2008, INT J COMPUT VISION, V76, P93, DOI 10.1007/s11263-007-0058-8; Moghaddam B., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P306, DOI 10.1109/AFGR.2000.840651; Mozaffari Saeed, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1192, DOI 10.1109/ICPR.2010.297; Mutch J, 2008, INT J COMPUT VISION, V80, P45, DOI 10.1007/s11263-007-0118-0; Phillips PJ, 2014, IMAGE VISION COMPUT, V32, P74, DOI 10.1016/j.imavis.2013.12.002; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Ramanathan N., 2006, P IEEE COMP SOC C CO, P387, DOI DOI 10.1109/CVPR.2006.187; Rhodes MG, 2009, APPL COGNITIVE PSYCH, V23, P1, DOI 10.1002/acp.1442; Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819; Saatci Y, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P393; Scheirer WJ, 2012, PROC CVPR IEEE, P2933, DOI 10.1109/CVPR.2012.6248021; SEMAJ LT, 1981, J NEGRO EDUC, V50, P41, DOI 10.2307/2294732; Serre T, 2005, PROC CVPR IEEE, P994; Tabassi E., 2004, NISTIR7151 NIST, V5; Tapia JE, 2013, IEEE T INF FOREN SEC, V8, P488, DOI 10.1109/TIFS.2013.2242063; Tariq U, 2009, IEEE IMAGE PROC, P2441, DOI 10.1109/ICIP.2009.5414117; Thukral P, 2012, INT CONF ACOUST SPEE, P1529, DOI 10.1109/ICASSP.2012.6288182; Tsukahara K, 2007, J DERMATOL SCI, V47, P19, DOI 10.1016/j.jdermsci.2007.03.007; Vapnik V.N, 1998, STAT LEARNING THEORY; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Voelkle MC, 2012, PSYCHOL AGING, V27, P265, DOI 10.1037/a0025065; Wang JW, 2013, 2013 IEEE 10TH INTERNATIONAL CONFERENCE ON AND 10TH INTERNATIONAL CONFERENCE ON AUTONOMIC AND TRUSTED COMPUTING (UIC/ATC) UBIQUITOUS INTELLIGENCE AND COMPUTING, P17, DOI 10.1109/UIC-ATC.2013.19; Wang Y, 2010, MODELLING SIMULATION, P1; Wu B, 2003, LECT NOTES COMPUT SC, V2688, P104; Wu J, 2010, IMAGE VISION COMPUT, V28, P1039, DOI 10.1016/j.imavis.2009.09.003; Wu T, 2012, IEEE T INF FOREN SEC, V7, P1780, DOI 10.1109/TIFS.2012.2213812; Yang ZG, 2007, LECT NOTES COMPUT SC, V4642, P464; Zhang G, 2011, INT JOINT C BIOM IEE, P1, DOI [10.1109/IJCB.2011.6117590., DOI 10.1109/IJCB.2011.6117590]; Zhao L, 2011, VISION RES, V51, P2462, DOI 10.1016/j.visres.2011.10.001	71	195	199	1	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2015	37	6					1148	1161		10.1109/TPAMI.2014.2362759	http://dx.doi.org/10.1109/TPAMI.2014.2362759			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	CH9SR	26357339	Green Submitted			2022-12-18	WOS:000354377100003
J	Wang, Y; Hu, JK; Phillips, D				Wang, Yi; Hu, Jiankun; Phillips, Damien			A fingerprint orientation model based on 2D Fourier expansion (FOMFE) and its application to singular-point detection and fingerprint indexing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fingerprint orientation; Fourier expansion; singular points; fingerprint indexing; fingerprint authentication	COMPUTATION; FIELDS	In this paper, we have proposed a fingerprint orientation model based on 2D Fourier expansions (FOMFE) in the phase plane. The FOMFE does not require prior knowledge of singular points (SPs). It is able to describe the overall ridge topology seamlessly, including the SP regions, even for noisy fingerprints. Our statistical experiments on a public database show that the proposed FOMFE can significantly improve the accuracy of fingerprint feature extraction and thus that of fingerprint matching. Moreover, the FOMFE has a low-computational cost and can work very efficiently on large fingerprint databases. The FOMFE provides a comprehensive description for orientation features, which has enabled its beneficial use in feature-related applications such as fingerprint indexing. Unlike most indexing schemes using raw orientation data, we exploit FOMFE model coefficients to generate the feature vector. Our indexing experiments show remarkable results using different fingerprint databases.	RMIT Univ, Sch Comp Sci & IT, Melbourne, Vic 3001, Australia	Royal Melbourne Institute of Technology (RMIT)	Wang, Y (corresponding author), RMIT Univ, Sch Comp Sci & IT, City Campus,Room 11,Lvl 9,Bldg 10, Melbourne, Vic 3001, Australia.	yi.wang@computer.org; jiankun@cs.rmit.edu.au; damphil@gmail.com	Wang, Yi Alice/L-8254-2016; Hu, Jiankun/D-9856-2012	Wang, Yi Alice/0000-0002-8448-8570; Hu, Jiankun/0000-0003-0230-1432				Bazen AM, 2002, IEEE T PATTERN ANAL, V24, P905, DOI 10.1109/TPAMI.2002.1017618; Boer J., 2001, P WORKSH CIRC SYST S, P58; Cappelli R, 2001, IEEE T PATTERN ANAL, V23, P977, DOI 10.1109/34.955111; Dass SC, 2004, IEEE T IMAGE PROCESS, V13, P1358, DOI 10.1109/TIP.2004.834659; Dym H., 1972, FOURIER SERIES INTEG; Ford R. M., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P644, DOI 10.1109/CVPR.1993.341047; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Golub Gene H., 2013, MATRIX COMPUTATION, V3; JAIN A, 2006, IEEE SPECTRUM, P14; Jain AK, 2004, INT C PATT RECOG, P935, DOI 10.1109/ICPR.2004.1334413; Kamei T, 1998, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.1998.698714; KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0; KAWAGOE M, 1984, PATTERN RECOGN, V17, P295, DOI 10.1016/0031-3203(84)90079-7; Lumini A, 1997, PATTERN RECOGN LETT, V18, P1027, DOI 10.1016/S0167-8655(97)00127-X; Morse P.M., 1953, METHODS THEORETICAL; Pankanti S, 2002, IEEE T PATTERN ANAL, V24, P1010, DOI 10.1109/TPAMI.2002.1023799; Perko L., 2006, DIFFER EQUAT DYN SYS; Prabhakar S., 2003, HDB FINGERPRINT RECO; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; RAO AR, 1992, IEEE T PATTERN ANAL, V14, P693, DOI 10.1109/34.142908; SHERLOCK BG, 1994, IEE P-VIS IMAGE SIGN, V141, P87, DOI 10.1049/ip-vis:19949924; SHERLOCK BG, 1993, PATTERN RECOGN, V26, P1047, DOI 10.1016/0031-3203(93)90006-I; SHU C, 2001, IEEE T PATTERN ANAL, V40; Vizcaya PR, 1996, PATTERN RECOGN, V29, P1221, DOI 10.1016/0031-3203(95)00154-9; WATSON C, 2001, USERS GUIDE NIST FIN, V2; WATSON CI, 1993, 14 NIST; Wilson C. L., 1994, Journal of Artificial Neural Networks, V1, P203; WU N, 2004, P INT C IM PROC OCT, V2, P885; YAU W, 2004, IEE P CONTR AUT ROB, V2, P1262; Zhou J, 2004, PATTERN RECOGN, V37, P389, DOI 10.1016/S0031-3203(03)00186-9; Zhou J, 2004, IEEE T IMAGE PROCESS, V13, P821, DOI 10.1109/TIP.2003.822608; [No title captured]	32	195	209	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2007	29	4					573	585		10.1109/TPAMI.2007.1003	http://dx.doi.org/10.1109/TPAMI.2007.1003			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HJ	17299215				2022-12-18	WOS:000244855600006
J	Awate, SP; Whitaker, RT				Awate, SP; Whitaker, RT			Unsupervised, information-theoretic, adaptive image filtering for image restoration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						filtering; restoration; nonparametric statistics; information theory	MEAN SHIFT; DIFFUSION; SCALE; RELAXATION; SHRINKAGE; MODEL	Image restoration is an important and widely studied problem in computer vision and image processing. Various image filtering strategies have been effective, but invariably make strong assumptions about the properties of the signal and/or degradation. Hence, these methods lack the generality to be easily applied to new applications or diverse image collections. This paper describes a novel unsupervised, information-theoretic, adaptive filter (UINTA) that improves the predictability of pixel intensities from their neighborhoods by decreasing their joint entropy. In this way, UINTA automatically discovers the statistical properties of the signal and can thereby restore a wide spectrum of images. The paper describes the formulation to minimize the joint entropy measure and presents several important practical considerations in estimating neighborhood statistics. It presents a series of results on both real and synthetic data along with comparisons with current state-of-the-art techniques, including novel applications to medical image processing.	Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA	Utah System of Higher Education; University of Utah	Awate, SP (corresponding author), Univ Utah, Sch Comp, 3190 Merril Engn Bldg,50 S Cent Campus Dr, Salt Lake City, UT 84112 USA.	suyash@cs.utah.edu; whitaker@cs.utah.edu		awate, suyash/0000-0002-4945-9539				ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098; Awate SP, 2005, PROC CVPR IEEE, P44; AWATE SP, 2005, P INT C INF PROC MED; Barash D, 2004, IMAGE VISION COMPUT, V22, P73, DOI 10.1016/j.imavis.2003.08.005; Chan T. F., 2003, NOT AM MATH SOC, V50, P14; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; De Bonet JS, 1998, ADV NEUR IN, V10, P773; DESILVA V, 2004, P S POINT BAS GRAPH; DOUGHERTY ER, 1998, RANDOM PROCESSES IMA; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; EVERETT M, 2001, REPTILES; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Haykin S., 2000, UNSUPERVISED ADAPTIV; Huang J G, 1999, P 1999 IEEE COMP VIS, P541; Hyvarinen A, 1999, NEURAL COMPUT, V11, P1739, DOI 10.1162/089976699300016214; Lee AB, 2003, INT J COMPUT VISION, V54, P83, DOI 10.1023/A:1023705401078; Miller JV, 1996, PROC CVPR IEEE, P300, DOI 10.1109/CVPR.1996.517089; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; NORDSTROM KN, 1990, IMAGE VISION COMPUT, V8, P318, DOI 10.1016/0262-8856(90)80008-H; Osher S, 2003, LEVEL SET METHODS DY; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Pizurica A, 2002, IEEE T IMAGE PROCESS, V11, P545, DOI 10.1109/TIP.2002.1006401; Popat K, 1997, IEEE T IMAGE PROCESS, V6, P268, DOI 10.1109/83.551697; Portilla J, 2004, IEEE IMAGE PROC, P1217; Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640; Romeny B.M., 1994, GEOMETRY DRIVEN DIFF; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Scott D. W., 1992, MULTIVARIATE DENSITY, DOI 10.1002/9780470316849; Sendur L, 2002, IEEE T SIGNAL PROCES, V50, P2744, DOI 10.1109/TSP.2002.804091; Sethian J. A., 1999, LEVEL SET METHODS FA; SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; SNYDER W, 1995, IEEE T PATTERN ANAL, V17, P620, DOI 10.1109/34.387509; STARCK J, 2000, IEEE T IMAGE PROCESS, V11; TASDIZEN T, 2003, ACM T GRAPHICS; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106; VIOLA P, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P16, DOI 10.1109/ICCV.1995.466930; WEI LY, 2002, TR200201 STANF U COM; Weickert J, 1999, INT J COMPUT VISION, V31, P111, DOI 10.1023/A:1008009714131; Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1; WEISSMAN T, 2003, HPL200329	47	195	204	2	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2006	28	3					364	376		10.1109/TPAMI.2006.64	http://dx.doi.org/10.1109/TPAMI.2006.64			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	001FB	16526423				2022-12-18	WOS:000234517900003
J	Domeniconi, C; Peng, J; Gunopulos, D				Domeniconi, C; Peng, J; Gunopulos, D			Locally adaptive metric nearest-neighbor classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Chi-squared distance; classification; feature relevance; nearest neighbors	REGRESSION	Nearest-neighbor classification assumes locally constant class conditional probabilities. This assumption becomes invalid in high dimensions with finite samples due to the curse of dimensionality. Severe bias can be introduced under these conditions when using the nearest-neighbor rule. We propose a locally adaptive nearest-neighbor classification method to try to minimize bias. We use a Chi-squared distance analysis to compute a flexible metric for producing neighborhoods that are highly adaptive to query locations. Neighborhoods are elongated along less relevant feature dimensions and constricted along most influential ones. As a result, the class conditional probabilities are smoother in the modified neighborhoods, whereby better classification performance can e achieved. The efficacy of our method is validated and compared against other techniques using both simulated and real-world data.	Univ Calif Riverside, Comp Sci Dept, Riverside, CA 92521 USA; Tulane Univ, Elect Engn & Comp Sci Dept, New Orleans, LA 70118 USA	University of California System; University of California Riverside; Tulane University	Domeniconi, C (corresponding author), Univ Calif Riverside, Comp Sci Dept, Surge Bldg, Riverside, CA 92521 USA.			Gunopulos, Dimitrios/0000-0001-6339-1879				Atkeson CG, 1997, ARTIF INTELL REV, V11, P11, DOI 10.1023/A:1006559212014; Bellman R., 1961, ADAPTIVE CONTROL PRO; BOTTOU L, 1992, NEURAL COMPUT, V4, P888, DOI 10.1162/neco.1992.4.6.888; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282; Duda R.O., 1973, J ROYAL STAT SOC SER; Friedman J. H., 1994, FLEXIBLE METRIC NEAR; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; Mclachlan GJ., 2005, DISCRIMINANT ANAL ST; MYLES JP, 1990, PATTERN RECOGN, V23, P1291, DOI 10.1016/0031-3203(90)90123-3; Quinlan J., 2014, C4 5 PROGRAMS MACHIN, DOI DOI 10.1007/BF00993309; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; [No title captured]	15	195	202	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2002	24	9					1281	1285		10.1109/TPAMI.2002.1033219	http://dx.doi.org/10.1109/TPAMI.2002.1033219			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	587KW					2022-12-18	WOS:000177640500011
J	Liao, SX; Pawlak, M				Liao, SX; Pawlak, M			On the accuracy of Zernike moments for image analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Zernike moments; geometric error; lattice points; circle problem; image reconstruction	RECOGNITION	In this paper, we give a detailed analysis of the accuracy of Zernike moments in terms of their discretization errors and the reconstruction power. It is found that there is an inherent limitation in the precision of computing the Zernike moments due to the geometric nature of a circular domain. This is explained by relating the accuracy issue to a celebrated problem in analytic number theory of evaluating the lattice points within a circle.	Univ Winnipeg, Dept Business Comp, Winnipeg, MB R3B 2E9, Canada; Univ Manitoba, Dept Elect & Comp Engn, Winnipeg, MB R3T 5V6, Canada	University of Winnipeg; University of Manitoba	Liao, SX (corresponding author), Univ Winnipeg, Dept Business Comp, 515 Portage Ave, Winnipeg, MB R3B 2E9, Canada.			Pawlak, Miroslaw/0000-0003-2627-108X				Bailey RR, 1996, IEEE T PATTERN ANAL, V18, P389, DOI 10.1109/34.491620; BHATIA AB, 1954, P CAMB PHILOS SOC, V50, P40, DOI 10.1017/S0305004100029066; ENGELS H, 1980, NUMERICAL QUADRATURE; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; HUXLEY MN, 1990, P LOND MATH SOC, V60, P471; IWANIEC H, 1988, J NUMBER THEORY, V29, P60, DOI 10.1016/0022-314X(88)90093-5; KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109; Liao S.X., 1993, THESIS U MANITOBA; Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554; MUKUNDAN R, 1995, PATTERN RECOGN, V28, P1433, DOI 10.1016/0031-3203(95)00011-N; PAWLAK M, 1992, IEEE T INFORM THEORY, V38, P1698, DOI 10.1109/18.165444; PROKOP RJ, 1992, CVGIP-GRAPH MODEL IM, V54, P438, DOI 10.1016/1049-9652(92)90027-U; Sansone G., 1991, ORTHOGONAL FUNCTIONS; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913; TEH CH, 1986, COMPUT VISION GRAPH, V33, P318, DOI 10.1016/0734-189X(86)90180-5; Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2; Zernike F, 1934, PHYSICA, V1, P689	18	195	214	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1998	20	12					1358	1364		10.1109/34.735809	http://dx.doi.org/10.1109/34.735809			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	147QV					2022-12-18	WOS:000077578300008
J	STOCKMAN, G; KOPSTEIN, S; BENETT, S				STOCKMAN, G; KOPSTEIN, S; BENETT, S			MATCHING IMAGES TO MODELS FOR REGISTRATION AND OBJECT DETECTION VIA CLUSTERING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MITRE CORP,DIV METREK,MCLEAN,VA 22124; LNK CORP,COLL PK,MD 20740; AMER MANAGEMENT SYSTEMS,ARLINGTON,VA 22209	MITRE Corporation	STOCKMAN, G (corresponding author), AMERICAN UNIV,DEPT MATH STAT & COMP SCI,WASHINGTON,DC 20016, USA.							ANDRUS J, 1975, IEEE T COMPUT, V24, P936; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2; BARROW HG, 1977, 5TH P INT JOINT C AR; Duda RO, 1973, PATTERN RECOGNITION; HORN BKP, 1978, COMMUN ACM, V21, P914, DOI 10.1145/359642.359647; Pavlidis T., 1977, STRUCTURAL PATTERN R; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; PERSOON E, 1978, PHILIPS TECH REV, V30, P356; SAVOL AM, 1978, MAY P IEEE C PATT RE; STOCKMAN G, 1980, PB80178817; STOCKMAN G, AMRLTR78117 WRIGHT P; VANWIE P, 1977, IEEE T GEOSCI ELECTR, V15	12	195	217	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	3					229	241		10.1109/TPAMI.1982.4767240	http://dx.doi.org/10.1109/TPAMI.1982.4767240			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NN069	21869030				2022-12-18	WOS:A1982NN06900001
J	Lampert, CH; Blaschko, MB; Hofmann, T				Lampert, Christoph H.; Blaschko, Matthew B.; Hofmann, Thomas			Efficient Subwindow Search: A Branch and Bound Framework for Object Localization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object localization; sliding window; global optimization; branch and bound	HISTOGRAMS; ALGORITHMS; IMAGES	Most successful object recognition systems rely on binary classification, deciding only if an object is present or not, but not providing information on the actual object location. To estimate the object's location, one can take a sliding window approach, but this strongly increases the computational cost because the classifier or similarity function has to be evaluated over a large set of candidate subwindows. In this paper, we propose a simple yet powerful branch and bound scheme that allows efficient maximization of a large class of quality functions over all possible subimages. It converges to a globally optimal solution typically in linear or even sublinear time, in contrast to the quadratic scaling of exhaustive or sliding window search. We show how our method is applicable to different object detection and image retrieval scenarios. The achieved speedup allows the use of classifiers for localization that formerly were considered too slow for this task, such as SVMs with a spatial pyramid kernel or nearest-neighbor classifiers based on the chi(2) distance. We demonstrate state-of-the-art localization performance of the resulting systems on the UIUC Cars data set, the PASCAL VOC 2006 data set, and in the PASCAL VOC 2007 competition.	[Lampert, Christoph H.] Max Planck Inst Biol Cybernet, D-72076 Tubingen, Germany; [Blaschko, Matthew B.] Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England; [Hofmann, Thomas] Google Inc, CH-8002 Zurich, Switzerland	Max Planck Society; University of Oxford; Google Incorporated	Lampert, CH (corresponding author), Max Planck Inst Biol Cybernet, Spemannstr 38, D-72076 Tubingen, Germany.	christoph.lampert@tuebingen.mpg.de; blaschko@robots.ox.ac.uk; thofmann@google.com	; Lampert, Christoph H./J-2931-2014	Blaschko, Matthew/0000-0002-2640-181X; Lampert, Christoph H./0000-0001-8622-7887	EU [IST 027978, EST 504321]	EU(European Commission)	This work was funded in part by the EU projects CLASS, IST 027978, and PerAct, EST 504321. The authors would like to thank Marcin Marszalek for sharing the confidence scores of his PASCAL VOC 2007 classifier with them.	Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108; Barla A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P513; Bay H., 2006, EUR C COMP VIS ECCV, P404, DOI [10.1007/11744023_32, DOI 10.1007/11744023_32]; Blaschko M.B., 2008, P EUR C COMP VIS; Boughorbel S., 2005, P IEEE INT C IM PROC, V3; Breuel T. M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P445, DOI 10.1109/CVPR.1992.223152; Breuel TM, 2003, PATTERN RECOGN LETT, V24, P1375, DOI 10.1016/S0167-8655(02)00378-1; CHANG NS, 1980, IEEE T SOFTWARE ENG, V6, P519, DOI 10.1109/TSE.1980.230801; Chum 0., 2007, P IEEE C COMP VIS PA; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; DARRELL T., 2009, P IEEE C COMP VIS PA; Everingham M., 2006, PASCAL VISUAL OBJECT; Fergus R, 2003, PROC CVPR IEEE, P264; Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144; FOX BL, 1978, EUR J OPER RES, V2, P191, DOI 10.1016/0377-2217(78)90092-9; Fritz M, 2005, IEEE I CONF COMP VIS, P1363; GENDRON B, 1994, OPER RES, V42, P1042, DOI 10.1287/opre.42.6.1042; Grauman K, 2007, J MACH LEARN RES, V8, P725; Hagedoorn M, 1999, INT J COMPUT VISION, V31, P203, DOI 10.1023/A:1008022116857; Hickey T, 2001, J ACM, V48, P1038, DOI 10.1145/502102.502106; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Jurie F, 1999, COMPUT VIS IMAGE UND, V73, P357, DOI 10.1006/cviu.1998.0735; LAMPERT C. H., 2008, P IEEE C COMP VIS PA; Laptev I, 2009, IMAGE VISION COMPUT, V27, P535, DOI 10.1016/j.imavis.2008.08.010; LAWLER EL, 1966, OPER RES, V14, P699, DOI 10.1287/opre.14.4.699; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Maji S., 2008, P IEEE C COMP VIS PA; Moore R. E., 1996, METHOD APPL INTERVAL; Mount DM, 1999, PATTERN RECOGN, V32, P17, DOI 10.1016/S0031-3203(98)00086-7; Mutch J, 2006, P IEEE C COMP VIS PA, P11, DOI [10.1109/CVPR.2006.200, DOI 10.1109/CVPR.2006.200]; Olson CF, 2001, PATTERN RECOGN, V34, P1247, DOI 10.1016/S0031-3203(00)00064-9; Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188; Rowley HA, 1996, ADV NEUR IN, V8, P875; Schaffalitzky F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P636, DOI 10.1109/ICCV.2001.937686; SCHIELE B, 1996, P 4 EUR C COMP VIS, V1, P610; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; VIITANIEMI V, 2006, P INT C ART NEUR NET, V2, P35; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb	41	194	212	0	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2009	31	12					2129	2142		10.1109/TPAMI.2009.144	http://dx.doi.org/10.1109/TPAMI.2009.144			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	511BY	19834136				2022-12-18	WOS:000271140100003
J	Cremers, D				Cremers, Daniel			Dynamical statistical shape priors for level set-based tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						variational methods; statistical shape models; autoregressive models; level sets; tracking	ACTIVE CONTOURS; MODEL	In recent years, researchers have proposed introducing statistical shape knowledge into level set- based segmentation methods in order to cope with insufficient low- level information. While these priors were shown to drastically improve the segmentation of familiar objects, so far the focus has been on statistical shape priors which are static in time. Yet, in the context of tracking deformable objects, it is clear that certain silhouettes ( such as those of a walking person) may become more or less likely over time. In this paper, we tackle the challenge of learning dynamical statistical models for implicitly represented shapes. We show how these can be integrated as dynamical shape priors in a Bayesian framework for level set- based image sequence segmentation. We assess the effect of such shape priors " with memory" on the tracking of familiar deformable objects in the presence of noise and occlusion. We show comparisons between dynamical and static shape priors, between models of pure deformation and joint models of deformation and transformation, and we quantitatively evaluate the segmentation accuracy as a function of the noise level and of the camera frame rate. Our experiments demonstrate that level set- based segmentation and tracking can be strongly improved by exploiting the temporal correlations among consecutive silhouettes which characterize deforming shapes.	Univ Bonn, Dept Comp Sci, D-53117 Bonn, Germany	University of Bonn	Cremers, D (corresponding author), Univ Bonn, Dept Comp Sci, Roemerstr 164, D-53117 Bonn, Germany.	dcremers@cs.uni-bonn.de						AKAIKE H, 1971, ANN I STAT MATH, V23, P163, DOI 10.1007/BF02479221; Blake A, 1998, PHILOS T R SOC A, V356, P1283, DOI 10.1098/rsta.1998.0222; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; CASELLES V, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P694, DOI 10.1109/ICCV.1995.466871; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Chen YM, 2002, INT J COMPUT VISION, V50, P315, DOI 10.1023/A:1020878408985; Cremers D, 2006, INT J COMPUT VISION, V66, P67, DOI 10.1007/s11263-005-3676-z; Cremers D, 2005, LECT NOTES COMPUT SC, V3752, P210; CREMERS D, 2006, INT J COMPUTER VISIO; CREMERS D, IN PRESS INT J COMPU; CREMERS D, 2002, P EUR C COMP VIS MAY; DERVIEUX A, 1979, SPRINGER LECT NOTES, V771, P145; Goldenberg R, 2005, PATTERN RECOGN, V38, P1033, DOI 10.1016/j.patcog.2004.11.024; KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855; Kolman Ada, 2004, Curr Opin Investig Drugs, V5, P657; LEVENTON ME, 2000, PROC CVPR IEEE, P316, DOI DOI 10.1109/CVPR.2000.855835; Ljung L., 1999, SYSTEM IDENTIFICATIO, V2nd; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; MOELICH M, 2003, 0314 U CAL LOS ANG C; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; PAPOULIS A, 1984, PRIBABILITY RANDOM V; Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068; Rathi Y, 2005, PROC CVPR IEEE, P2; RIKLINRAVIV T, 2004, P EUR C COMP VIS; Rousson M, 2005, LECT NOTES COMPUT SC, V3750, P757, DOI 10.1007/11566489_93; Rousson M, 2004, LECT NOTES COMPUT SC, V3216, P209; ROUSSON M, 2002, P EUR C COMP VIS; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Tsai A, 2001, PROC CVPR IEEE, P463; Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	34	194	204	0	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2006	28	8					1262	1273		10.1109/TPAMI.2006.161	http://dx.doi.org/10.1109/TPAMI.2006.161			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	051LK	16886862				2022-12-18	WOS:000238162400008
J	Opelt, A; Pinz, A; Fussenegger, M; Auer, P				Opelt, A; Pinz, A; Fussenegger, M; Auer, P			Generic object recognition with boosting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						boosting; object categorization; object localization	INVARIANTS	This paper explores the power and the limitations of weakly supervised categorization. We present a complete framework that starts with the extraction of various local regions of either discontinuity or homogeneity. A variety of local descriptors can be applied to form a set of feature vectors for each local region. Boosting is used to learn a subset of such feature vectors (weak hypotheses) and to combine them into one final hypothesis for each visual category. This combination of individual extractors and descriptors leads to recognition rates that are superior to other approaches which use only one specific extractor/descriptor setting. To explore the limitation of our system, we had to set up new, highly complex image databases that show the objects of interest at varying scales and poses, in cluttered background, and under considerable occlusion. We obtain classification results up to 81 percent ROC-equal error rate on the most complex of our databases. Our approach outperforms all comparable solutions on common databases.	Graz Univ Technol, Inst Elect Measurement & Measurement Signal Proc, A-8010 Graz, Austria; Univ Leoben, Inst Comp Sci, A-8700 Leoben, Austria	Graz University of Technology; University of Leoben	Opelt, A (corresponding author), Graz Univ Technol, Inst Elect Measurement & Measurement Signal Proc, Schiesstattg 14b, A-8010 Graz, Austria.	opelt@tugraz.at; pinz@tugraz.at; fussenegger@tugraz.at; auer@unileoben.ac.at	Auer, Peter/AAC-1314-2019	Auer, Peter/0000-0001-8385-9635				AGARWAL S, 2002, P ECCV, P113; Barnard K, 2003, PROC CVPR IEEE, P675; Carbonetto P, 2004, LECT NOTES COMPUT SC, V3021, P350; Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Dorko G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P634; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Fergus R, 2004, LECT NOTES COMPUT SC, V3021, P242; Fergus R, 2003, PROC CVPR IEEE, P264; FERRARI V, 2004, P EUR C COMP VIS, P40; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; FUSSENEGGER M, 2004, P INT C PATT REC; Gonzalez R., 2001, DIGITAL IMAGE PROCES, V2; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; Harris C. G., 1988, P 4 ALV VIS C, V15, P10, DOI [10.5244/C.2.23, DOI 10.5244/C.2.23]; Laganiere R, 1998, PATTERN RECOGN, V31, P1643, DOI 10.1016/S0031-3203(98)00017-X; LECUN Y, 2004, P C COMP VIS PATT RE; LEIBE B, 2004, P EUR C COMP VIS WOR; Leung TK, 1998, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.1998.698677; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Maass W, 1998, INFORM COMPUT, V141, P66, DOI 10.1006/inco.1997.2686; MAITRA S, 1979, P IEEE, P679; Mikolajczyk K, 2003, PROC CVPR IEEE, P257; Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561; MIKOLAJCZYK K, 2002, P EUR C COMP VIS, P128; Nelson RC, 2000, INT C PATT RECOG, P1, DOI 10.1109/ICPR.2000.905264; Opelt A, 2004, LECT NOTES COMPUT SC, V3022, P71; OPELT A, 2003, THESIS GRAZ U TECHNO; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; SCHMID C, 2004, INT J COMPUT VISION, V37, P151; Schneiderman H, 2004, INT J COMPUT VISION, V56, P151, DOI 10.1023/B:VISI.0000011202.85607.00; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shilat E, 1997, PROC CVPR IEEE, P976, DOI 10.1109/CVPR.1997.609446; THRUESON J, 2004, P EUR C COMP VIS, P518; Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wallraven C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P257; Weber M., 2000, P EUR C COMP VIS; WUERTZ RP, 1997, P INT C ART NEUR NET, P901	41	194	205	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2006	28	3					416	431		10.1109/TPAMI.2006.54	http://dx.doi.org/10.1109/TPAMI.2006.54			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	001FB	16526427				2022-12-18	WOS:000234517900007
J	McCowan, I; Gatica-Perez, D; Bengio, S; Lathoud, G; Barnard, M; Zhang, D				McCowan, I; Gatica-Perez, D; Bengio, S; Lathoud, G; Barnard, M; Zhang, D			Automatic analysis of multimodal group actions in meetings	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						statistical models; multimedia applications and numerical signal processing; computer conferencing; asynchronous interaction		This paper investigates the recognition of group actions in meetings. A framework is employed in which group actions result from the interactions of the individual participants. The group actions are modeled using different HMM-based approaches, where the observations are provided by a set of audiovisual features monitoring the actions of individuals. Experiments demonstrate the importance of taking interactions into account in modeling the group actions. It is also shown that the visual modality contains useful information, even for predominantly audio-based events, motivating a multimodal approach to meeting analysis.	IDIAP Res Inst, CH-1920 Martigny, Switzerland		McCowan, I (corresponding author), IDIAP Res Inst, Rue Simplon 4,CP 592, CH-1920 Martigny, Switzerland.	mccowan@idiap.ch; gatica@idiap.ch; bengio@idiap.ch; lathoud@idiap.ch; barnard@idiap.ch; zhang@idiap.ch						Bales R.F., 1979, SYMLOG SYSTEM MULTIP; Bales R.F., 1950, INTERACTION PROCESS; BENGIO S, 2003, ADV NEURAL INFORMATI, V15; BOBICK A, 1999, PRESENCE TELEOPERATO, V8; Boreczky JS, 1998, INT CONF ACOUST SPEE, P3741, DOI 10.1109/ICASSP.1998.679697; Brand M., 1996, 405 MIT MED LAB VIS; BRAND M, 1997, P IEEE; COLLOBERT R, 2002, 46 IDIARPRR; CUTLER R, 2002, P ACM MULTIMEDIA C; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; DEPAULO BM, 1978, J PERS SOC PSYCHOL, V36, P313; DiBiase JH, 2001, DIGITAL SIGNAL PROC, P157; DiBiase JH., 2000, HIGH ACCURACY LOW LA; DIELMANN A, 2004, P IEEE INT C ACO MAY; Dupont S, 2000, IEEE T MULTIMEDIA, V2, P141, DOI 10.1109/6046.865479; Eickeler S, 1999, INT CONF ACOUST SPEE, P2997, DOI 10.1109/ICASSP.1999.757471; Fay N, 2000, PSYCHOL SCI, V11, P481, DOI 10.1111/1467-9280.00292; FORSYTH D, 2003, MEASUREMENT SOCIAL P; GATICAPEREZ D, 2003, P INT C IMAGE PROCES; GATICAPEREZ D, 2003, P WOMTEC         SEP; HILLARD D, 2003, P HUMAN LANGUAGE MAY; HONGENG S, 2001, P IEEE INT C COM JUL; HOZJAN V, 2003, P EUR            SEP; *IDIAP, 2004, IDIAP DAT DISTR; JEBARA T, 1999, P INT C VISION S JAN; JOHNSON N, 1998, P IEEE INT C COM JUN; Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198; KENNEDY L, 2003, P AUT SPEECH REC DEC; KRAUSS RM, 1977, J PERS SOC PSYCHOL, V35, P523, DOI 10.1037/0022-3514.35.7.523; Kubala F, 1999, ACM COMPUT SURV, V31, pU49; KWON O, 2003, P EUR            SEP; LATHOUD G, 2003, P EUROSPEECH 200 SEP; MARKEL JD, 1972, IEEE T ACOUST SPEECH, VAU20, P367, DOI 10.1109/TAU.1972.1162410; MCCOWAN I, 2003, P INT C ACOUSTIC APR; McGrath J. E., 1984, GROUPS INTERACTION P; MCGRATH JE, 1982, ANNU REV PSYCHOL, V33, P195, DOI 10.1146/annurev.ps.33.020182.001211; MOORE D, 2002, 0207 IDIAP; MOORE D, 2003, P INT C ACOUSTIC APR; MORGAN N, 1998, P 1998 IEEE INT C AC; MORGAN N, 2001, P HUMAN LANGUAGE MAR; MORRIS A, 2001, SPEECH COMM; MOTA S, 2003, P CVPR WORKSH CO JUN; NOVICK D, 1996, P 1996 INT C SPOK LA; OLIVER N, 2002, P INT C MULTIMOD OCT; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; PADILHA E, 2002, EDILOG; PARKER KCH, 1988, J PERS SOC PSYCHOL, V54, P965, DOI 10.1037/0022-3514.54.6.965; Potamianos G., 2004, ISSUES VISUAL AUDIO; Rabiner L., 1993, FUNDAMENTALS SPEECH; RENALS S, 2003, P INT C ACOUSTICS SP; STARNER T, 1995, P INT WORKSHOP AUTOM; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010; WAIBEL A, 2001, P INT C ACOUSTIC MAY; WAIBEL A, 2003, P INT C ACOUSTICS SP; WARD K, 1995, 95011 CSE OR GRAD I; WREDE B, 2003, P EUR            SEP; WREDE B, 2003, P AUT SPEECH REC DEC; XIE L, 2002, P IEEE INT C ACOUSTI; ZHANG D, 2004, P IEEE CVPR WORKSH E; ZOBL M, 2003, P ICVS WORKSH PERF E; 2004, MERRIAMWEBSTER ONLIN	62	194	202	1	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2005	27	3					305	317		10.1109/TPAMI.2005.49	http://dx.doi.org/10.1109/TPAMI.2005.49			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	887IW	15747787	Green Submitted			2022-12-18	WOS:000226300200001
J	WOLFF, LB				WOLFF, LB			POLARIZATION-BASED MATERIAL CLASSIFICATION FROM SPECULAR REFLECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											WOLFF, LB (corresponding author), COLUMBIA UNIV,DEPT COMP SCI,NEW YORK,NY 10027, USA.							Beckmann Petr, 1987, SCATTERING ELECTROMA, P4; Born M.A.X., 1980, PRINCIPLES OPTICS, VSixth, P1, DOI 10.1016/B978-0-08-026482-0.50008-6; Brindley G. S., 1970, PHYSL RETINA VISUAL, V2nd; Cook R. L., 1981, Computer Graphics, V15, P307, DOI 10.1145/965161.806819; Grainger J. F., 1971, POLARIZED LIGHT OPTI; GRAY DE, 1972, AM I PHYSICS HDB; HEALEY G, 1989, J OPT SOC AM A, V6, P920, DOI 10.1364/JOSAA.6.000920; HEALEY G, COMMUNICATION; HEALEY G, 1988, APR P DARPA IMAGE UN; HEALEY G, 1988, APR P DARAP IM UND W, P1140; HEALEY G, 1988, APR P SPIE C OPT EL; KLINKER G, 1987, 1ST P INT C COMP VIS, P145; KLINKER GJ, 1988, THESIS CARNEGIEMELLO; KOSHIKAWA K, 1979, 6TH P INT JOINT C AR, P493; KOSHIKAWA K, 1987, ADV ROBOTICS, V2; MARION H, 1980, CLASSICAL ELECTROMAG; PORTER GB, 1981, P SOC PHOTO-OPT INST, V281, P176, DOI 10.1117/12.965745; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; Siegel R., 1981, THERMAL RAD HEAT TRA; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; TROWBRIDGE TS, 1975, J OPT SOC AM, V65, P531, DOI 10.1364/JOSA.65.000531; WOLFF LB, 1989, JUN P IEEE C COMP VI, P363; WOLFF LB, 1987, NOV P OPT ILL IM SEN, V850, P110; WOLFF LB, 1989, NOV P OPT ILL IM SEN, V1194, P287; WOLFF LB, THESIS COLUMBIA U; WOLFF LB, 1989, MAY P DARPA IM UND W, P232	26	194	216	2	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1990	12	11					1059	1071		10.1109/34.61705	http://dx.doi.org/10.1109/34.61705			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EH557					2022-12-18	WOS:A1990EH55700003
J	Drira, H; Ben Amor, B; Srivastava, A; Daoudi, M; Slama, R				Drira, Hassen; Ben Amor, Boulbaba; Srivastava, Anuj; Daoudi, Mohamed; Slama, Rim			3D Face Recognition under Expressions, Occlusions, and Pose Variations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D face recognition; shape analysis; biometrics; quality control; data restoration		We propose a novel geometric framework for analyzing 3D faces, with the specific goals of comparing, matching, and averaging their shapes. Here we represent facial surfaces by radial curves emanating from the nose tips and use elastic shape analysis of these curves to develop a Riemannian framework for analyzing shapes of full facial surfaces. This representation, along with the elastic Riemannian metric, seems natural for measuring facial deformations and is robust to challenges such as large facial expressions (especially those with open mouths), large pose variations, missing parts, and partial occlusions due to glasses, hair, and so on. This framework is shown to be promising from both-empirical and theoretical-perspectives. In terms of the empirical evaluation, our results match or improve upon the state-of-the-art methods on three prominent databases: FRGCv2, GavabDB, and Bosphorus, each posing a different type of challenge. From a theoretical perspective, this framework allows for formal statistical inferences, such as the estimation of missing facial parts using PCA on tangent spaces and computing average shapes.	[Drira, Hassen; Ben Amor, Boulbaba; Daoudi, Mohamed] TELECOM Lille 1, Inst Mines Telecom, LIFL, UMR CNRS 8022, F-59653 Villeneuve Dascq, France; [Srivastava, Anuj] Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA; [Slama, Rim] Univ Lille 1, Telecom Lille 1, LIFL, UMR CNRS 8022, F-59653 Villeneuve Dascq, France	IMT - Institut Mines-Telecom; IMT Nord Europe; Universite de Lille - ISITE; Universite de Lille; State University System of Florida; Florida State University; Universite de Lille - ISITE; Universite de Lille	Drira, H (corresponding author), TELECOM Lille 1, Inst Mines Telecom, LIFL, UMR CNRS 8022, Rue G Marconi,BP 20145, F-59653 Villeneuve Dascq, France.	hassen.drira@telecom-lille1.eu	Ben Amor, Boulbaba/K-7066-2018; Drira, Hassen/AAG-9736-2020; Srivastava, Anuj/L-4705-2019; Daoudi, Mohammed/H-5935-2013	Ben Amor, Boulbaba/0000-0002-4176-9305; Drira, Hassen/0000-0003-1052-4353; Daoudi, Mohammed/0000-0003-4219-7860; Srivastava, Anuj/0000-0001-7406-0338	French research agency ANR [ANR 2010 INTB 0301 01, FAR3D ANR-07-SESU-04]; US National Science Foundation [DMS 0915003, DMS 1208959]	French research agency ANR(French National Research Agency (ANR)); US National Science Foundation(National Science Foundation (NSF))	This work was supported by the French research agency ANR through the 3D Face Analyzer project under the contract ANR 2010 INTB 0301 01 and the project FAR3D ANR-07-SESU-04. It was also partially supported by US National Science Foundation grants DMS 0915003 and DMS 1208959 grants to Anuj Srivastava. This paper was presented in part at BMVC 2010 [7].	Alyuz N., 2008, P 2 IEEE INT C BIOM; Berretti S, 2010, IEEE T PATTERN ANAL, V32, P2162, DOI 10.1109/TPAMI.2010.43; Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005; Bronstein AM, 2007, IEEE T IMAGE PROCESS, V16, P188, DOI 10.1109/TIP.2006.884940; Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y; Chen, 2010, P IEEE INT C BIOM TH, P1; Colombo A, 2011, J MATH IMAGING VIS, V40, P105, DOI 10.1007/s10851-010-0252-0; Diaz F. J., 2005, P INT S IM SIGN PROC; Drira H, 2010, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.24.90; Drira H, 2009, IEEE I CONF COMP VIS, P2050, DOI 10.1109/ICCV.2009.5459451; Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287; Gordon G., 1992, CVPR, P108; GUPTA S, 2007, P IEEE C COMP VIS PA; Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017; KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502; Lee Y, 2005, LECT NOTES COMPUT SC, V3546, P909; Lu XG, 2008, IEEE T PATTERN ANAL, V30, P1346, DOI 10.1109/TPAMI.2007.70784; Mahoor MH, 2009, PATTERN RECOGN, V42, P445, DOI 10.1016/j.patcog.2008.08.012; McKeon R, 2010, P 4 IEEE INT C BIOM, P1; Moorthy A. K., 2010, 2010 4 IEEE INT C BI, P1, DOI DOI 10.1109/BTAS.2010.5634494; Moreno A.B., 2004, WORKSH BIOM INT, V275, P77; Mousavi MH, 2008, 7TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE IN CONJUNCTION WITH 2ND IEEE/ACIS INTERNATIONAL WORKSHOP ON E-ACTIVITY, PROCEEDINGS, P208, DOI 10.1109/ICIS.2008.77; Mpiperis I, 2007, IEEE T INF FOREN SEC, V2, P537, DOI 10.1109/TIFS.2007.902326; Passalis G, 2011, IEEE T PATTERN ANAL, V33, P1938, DOI 10.1109/TPAMI.2011.49; Queirolo CC, 2010, IEEE T PATTERN ANAL, V32, P206, DOI 10.1109/TPAMI.2009.14; Samir C, 2006, IEEE T PATTERN ANAL, V28, P1858, DOI 10.1109/TPAMI.2006.235; Samir C, 2009, INT J COMPUT VISION, V82, P80, DOI 10.1007/s11263-008-0187-8; Spreeuwers L, 2011, INT J COMPUT VISION, V93, P389, DOI 10.1007/s11263-011-0426-2; Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184; ter Haar FB, 2010, COMPUT GRAPH-UK, V34, P231, DOI 10.1016/j.cag.2010.03.010; Wang YM, 2010, IEEE T PATTERN ANAL, V32, P1858, DOI 10.1109/TPAMI.2009.200; Xiaoxing Li, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2575, DOI 10.1109/CVPRW.2009.5206613; Younes L, 2008, REND LINCEI-MAT APPL, V19, P25	33	193	208	3	65	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2013	35	9					2270	2283		10.1109/TPAMI.2013.48	http://dx.doi.org/10.1109/TPAMI.2013.48			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	186GB	23868784	Green Submitted			2022-12-18	WOS:000322029000016
J	van de Weijer, J; Gevers, T; Bagdanov, AD				van de Weijer, J; Gevers, T; Bagdanov, AD			Boosting color saliency in image feature detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image saliency; feature detection; image statistics; color imaging		The aim of salient feature detection is to find distinctive local events in images. Salient features are generally determined from the local differential structure of images. They focus on the shape-saliency of the local neighborhood. The majority of these detectors are luminance-based, which has the disadvantage that the distinctiveness of the local color information is completely ignored in determining salient image features. To fully exploit the possibilities of salient point detection in color images, color distinctiveness should be taken into account in addition to shape distinctiveness. In this paper, color distinctiveness is explicitly incorporated into the design of saliency detection. The algorithm, called color saliency boosting, is based on an analysis of the statistics of color image derivatives. Color saliency boosting is designed as a generic method easily adaptable to existing feature detectors. Results show that substantial improvements in information content are acquired by targeting color salient features.	INRIA, GRAVIR, Lear Grp, F-38330 Montbonnot St Martin, France; Univ Amsterdam, Fac Sci, ISLA Grp, NL-1098 SJ Amsterdam, Netherlands; Univ Florence, Dipartimento Sistemi & Informat, I-50139 Florence, Italy	Inria; University of Amsterdam; University of Florence	van de Weijer, J (corresponding author), INRIA, GRAVIR, Lear Grp, 655 Ave Europe, F-38330 Montbonnot St Martin, France.	joost.van-de-weijer@inrialpes.fr; gevers@science.uva.nl; bagdanov@gmail.com	van de Weijer, Joost/A-1643-2009; Bagdanov, Andrew/K-3932-2014	van de Weijer, Joost/0000-0002-9656-9706; Bagdanov, Andrew/0000-0001-6408-7043				Fergus R, 2003, PROC CVPR IEEE, P264; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Heidemann G, 2004, IEEE T PATTERN ANAL, V26, P817, DOI 10.1109/TPAMI.2004.29; Lee MS, 1999, COMPUT VIS IMAGE UND, V76, P54, DOI 10.1006/cviu.1999.0787; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Montesinos P, 1998, INT C PATT RECOG, P838, DOI 10.1109/ICPR.1998.711280; REISFELD D, 1995, INT J COMPUT VISION, V14, P119, DOI 10.1007/BF01418978; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Sebe N, 2003, IMAGE VISION COMPUT, V21, P1087, DOI 10.1016/j.imavis.2003.08.012; Van Gool L, 2001, COMPUT IMAGING VIS, V22, P21; Williams F., 1996, DRUG DELIV, V3, P81, DOI 10.3109/10717549609031177	12	193	201	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2006	28	1					150	156		10.1109/TPAMI.2006.3	http://dx.doi.org/10.1109/TPAMI.2006.3			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	982OR	16402628	Green Submitted			2022-12-18	WOS:000233172000014
J	Jafari-Khouzani, K; Soltanian-Zadeh, H				Jafari-Khouzani, K; Soltanian-Zadeh, H			Radon transform orientation estimation for rotation invariant texture analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						texture classification; Radon transform; wavelet transform; rotation invariance	HIDDEN MARKOV MODEL; GRAY-SCALE; CLASSIFICATION; DECOMPOSITION; FEATURES	This paper presents a new approach to rotation invariant texture classification. The proposed approach benefits from the fact that most of the texture patterns either have directionality (anisotropic textures) or are not with a specific direction (isotropic textures). The wavelet energy features of the directional textures change significantly when the image is rotated. However, for the isotropic images, the wavelet features are not sensitive to rotation. Therefore, for the directional textures, it is essential to calculate the wavelet features along a specific direction. In the proposed approach, the Radon transform is first employed to detect the principal direction of the texture. Then, the texture is rotated to place its principal direction at 0 degrees. A wavelet transform is applied to the rotated image to extract texture features. This approach provides a features space with small intraclass variability and, therefore, good separation between different classes. The performance of the method is evaluated using three texture sets. Experimental results show the superiority of the proposed approach compared with some existing methods.	Henry Ford Hlth Syst, Radiol Image Anal Lab, Detroit, MI 48202 USA; Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA; Univ Tehran, Dept Elect & Comp Engn, Control & Intelligent Proc Ctr Excellence, Tehran, Iran	Henry Ford Health System; Henry Ford Hospital; Wayne State University; University of Tehran	Jafari-Khouzani, K (corresponding author), Henry Ford Hlth Syst, Radiol Image Anal Lab, 1 Ford Pl,2F Box 82, Detroit, MI 48202 USA.	kjafari@rad.hfh.edu; hamids@rad.hfh.edu	Soltanian-Zadeh, Hamid/K-2903-2016; Soltanian-Zadeh, Hamid/AAD-7027-2022	Soltanian-Zadeh, Hamid/0000-0002-7302-6856; Soltanian-Zadeh, Hamid/0000-0002-7302-6856	NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [R01EB002450] Funding Source: NIH RePORTER; NIBIB NIH HHS [R01 EB002450, R01 EB002450-02] Funding Source: Medline	NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NIBIB NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB))		BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668; Bracewell RN., 1995, 2 DIMENSIONAL IMAGIN; Brodatz P., 1966, TEXTURE PHOTOGRAPHIC; Campisi P, 2004, IEEE T IMAGE PROCESS, V13, P782, DOI 10.1109/TIP.2003.822607; Chandra DVS, 1998, IEEE T AERO ELEC SYS, V34, P1009, DOI 10.1109/7.705915; Charalampidis D, 2002, IEEE T IMAGE PROCESS, V11, P825, DOI 10.1109/TIP.2002.801117; CHEN JL, 1994, IEEE T PATTERN ANAL, V16, P208, DOI 10.1109/34.273730; Do MN, 2002, IEEE T MULTIMEDIA, V4, P517, DOI 10.1109/TMM.2002.802019; Haley GM, 1999, IEEE T IMAGE PROCESS, V8, P255, DOI 10.1109/83.743859; JAFARIKHOUZANI K, 2005, TR0105 H FORD HLTH S; JAFARIKHOUZANI K, 2005, UNPUB IEEE T IMAGE P; Manthalkar R, 2003, PATTERN RECOGN LETT, V24, P2455, DOI 10.1016/S0167-8655(03)00090-4; MESTER R, 2000, P 10 EUR SIGN PROC C, V2, P921; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; OJALA T, 2002, P 16 INT C PATT REC, P701; Pun CM, 2003, IEEE T PATTERN ANAL, V25, P590, DOI 10.1109/TPAMI.2003.1195993; Wu WR, 1996, IEEE T IMAGE PROCESS, V5, P1423, DOI 10.1109/83.536891	17	193	213	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2005	27	6					1004	1008		10.1109/TPAMI.2005.126	http://dx.doi.org/10.1109/TPAMI.2005.126			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	915TR	15945146	Green Accepted			2022-12-18	WOS:000228334700016
J	Roberts, SJ; Husmeier, D; Rezek, I; Penny, W				Roberts, SJ; Husmeier, D; Rezek, I; Penny, W			Bayesian approaches to Gaussian mixture modeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						cluster analysis; unsupervised learning; Bayesian methods; Gaussian mixture models		A Bayesian-based methodology is presented which automatically penalizes overcomplex models being fitted to unknown data. We show that, with a Gaussian mixture model, the approach is able to select an "optimal" number of components in the model and so partition data sets. The performance of the Bayesian method is compared to other methods of optimal model selection and found to give good results. The methods are tested on synthetic and real data sets.	Univ London Sch Pharm, Dept Elect & Elect Engn, London, England	University of London; University College London; University of London School of Pharmacy	Roberts, SJ (corresponding author), Univ London Sch Pharm, Dept Elect & Elect Engn, London, England.			Husmeier, Dirk/0000-0003-1673-7413; Penny, William/0000-0001-9064-1191				Anderson E., 1935, B AM IRIS SOC, V59, P2; Artin M., 1988, SPHERE PACKINGS LATT; BAXTER R, 1994, 207 MON U DEP COMP S; Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; Bishop, 1995, NEURAL NETWORKS PATT; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; HALL P, 1985, J ROY STAT SOC B MET, V47, P155; HAND DJ, 1994, KERNEL DISCRIMINANT; Harvey A. C., 1981, ECONOMETRIC ANAL TIM; HUSMEIER D, 1997, THESIS U LONDON; JEFFREYS H., 1939, THEORY PROBABILITY; LEE JAN, 1992, IEEE ANN HIST COMPUT, V14, P4; Oliver J., 1996, P 13 INT C MACH LEAR, P364; OLIVER JJ, 1994, 206 TR MON U CLAYT D; ORUANAIDTH JJK, 1996, NUMERICAL BAYESIAN M; REZEK IA, 1998, IEEE T BIOMEDICAL EN, V44; Richardson S, 1997, J ROY STAT SOC B MET, V59, P731, DOI 10.1111/1467-9868.00095; Ripley BD., 1996; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Roberts SJ, 1997, PATTERN RECOGN, V30, P261, DOI 10.1016/S0031-3203(96)00079-9; Silverman B. W., 1986, DENSITY ESTIMATION S; TITTERINGTON DM, 1985, STAT ANAL FINITE MIX; WALLACE CS, 1987, J ROY STAT SOC B MET, V49, P240; Wand M.P., 1995, MONOGRAPHS STAT APPL	26	193	202	4	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1998	20	11					1133	1142		10.1109/34.730550	http://dx.doi.org/10.1109/34.730550			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	138TX					2022-12-18	WOS:000076990100002
J	BROIDA, TJ; CHELLAPPA, R				BROIDA, TJ; CHELLAPPA, R			ESTIMATION OF OBJECT MOTION PARAMETERS FROM NOISY IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									HUGHES AIRCRAFT CO,RADAR SYST GRP,LOS ANGELES,CA 90009	Hughes Aircraft Company	BROIDA, TJ (corresponding author), UNIV SO CALIF,INST SIGNAL & IMAGE PROC,DEPT ELECT ENGN SYST,LOS ANGELES,CA 90089, USA.		Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/B-6573-2012					Anderson B. D. O., 1979, OPTIMAL FILTERING; BALAKRISHNAN AV, 1984, KALMAN FILTERING THE; BALLARD DH, 1983, COMPUT VISION GRAPH, V22, P95, DOI 10.1016/0734-189X(83)90097-X; Edmund Taylor Whittaker, 1959, TREATISE ANAL DYNAMI; FANG JQ, 1984, IEEE T PATTERN ANAL, V6, P545, DOI 10.1109/TPAMI.1984.4767569; Gelb A., 1974, APPL OPTIMAL ESTIMAT; Greenwood D.T., 1965, PRINCIPLES DYNAMICS; Jazwinski A.H., 1970, STOCHASTIC PROCESSES; LEGTERS GR, 1982, IEEE T PATTERN ANAL, V4, P583, DOI 10.1109/TPAMI.1982.4767311; Maybeck P. S., 1982, STOCHASTIC MODELS ES, V2; Maybeck P. S., 1982, STOCHASTIC MODELS ES; MEIRI AZ, 1980, IEEE T PATTERN ANAL, V2, P582, DOI 10.1109/TPAMI.1980.6447706; RAO CR, 1973, LINEAR STATISTICAL I; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; TSAI RY, 1984, IEEE T ACOUST SPEECH, V32, P213, DOI 10.1109/TASSP.1984.1164313	16	193	206	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1986	8	1					90	99		10.1109/TPAMI.1986.4767755	http://dx.doi.org/10.1109/TPAMI.1986.4767755			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AWT86	21869326				2022-12-18	WOS:A1986AWT8600010
J	Lu, CY; Feng, JS; Lin, ZC; Mei, T; Yan, SC				Lu, Canyi; Feng, Jiashi; Lin, Zhouchen; Mei, Tao; Yan, Shuicheng			Subspace Clustering by Block Diagonal Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Subspace clustering; spectral clustering; block diagonal regularizer; block diagonal representation; nonconvex optimization; convergence analysis	GENERAL FRAMEWORK; SEGMENTATION; GRAPH	This paper studies the subspace clustering problem. Given some data points approximately drawn from a union of subspaces, the goal is to group these data points into their underlying subspaces. Many subspace clustering methods have been proposed and among which sparse subspace clustering and low-rank representation are two representative ones. Despite the different motivations, we observe that many existing methods own the common block diagonal property, which possibly leads to correct clustering, yet with their proofs given case by case. In this work, we consider a general formulation and provide a unified theoretical guarantee of the block diagonal property. The block diagonal property of many existing methods falls into our special case. Second, we observe that many existing methods approximate the block diagonal representation matrix by using different structure priors, e.g., sparsity and low-rankness, which are indirect. We propose the first block diagonal matrix induced regularizer for directly pursuing the block diagonal matrix. With this regularizer, we solve the subspace clustering problem by Block Diagonal Representation (BDR), which uses the block diagonal structure prior. The BDR model is nonconvex and we propose an alternating minimization solver and prove its convergence. Experiments on real datasets demonstrate the effectiveness of BDR.	[Lu, Canyi; Feng, Jiashi; Yan, Shuicheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119077, Singapore; [Lin, Zhouchen] Peking Univ, Sch EECS, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China; [Lin, Zhouchen] Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Shanghai 200240, Peoples R China; [Mei, Tao] Microsoft Res Asia, Beijing 100080, Peoples R China	National University of Singapore; Peking University; Shanghai Jiao Tong University; Microsoft; Microsoft Research Asia	Lin, ZC (corresponding author), Peking Univ, Sch EECS, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China.; Lin, ZC (corresponding author), Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Shanghai 200240, Peoples R China.	canyilu@gmail.com; elefjia@nus.edu.sg; zlin@pku.edu.cn; tmei@microsoft.com; eleyans@nus.edu.sg	Mei, Tao/GQZ-0596-2022; Feng, Jiashi/AGX-6209-2022; Yan, Shuicheng/HCI-1431-2022	Mei, Tao/0000-0002-5990-7307; 	National University of Singapore [R-263-000-C08-133]; Ministry of Education of Singapore [R-263-000-C21-112]; National Basic Research Program of China (973 Program) [2015CB352502]; National Natural Science Foundation (NSF) of China [61625301, 61731018]; Qualcomm; Microsoft Research Asia	National University of Singapore(National University of Singapore); Ministry of Education of Singapore(Ministry of Education, Singapore); National Basic Research Program of China (973 Program)(National Basic Research Program of China); National Natural Science Foundation (NSF) of China(National Natural Science Foundation of China (NSFC)); Qualcomm; Microsoft Research Asia(Microsoft)	J. Feng is partially supported by National University of Singapore startup grant R-263-000-C08-133 and Ministry of Education of Singapore AcRF Tier One grant R-263-000-C21-112. Z. Lin was supported by National Basic Research Program of China (973 Program) (grant no. 2015CB352502), National Natural Science Foundation (NSF) of China (grant nos. 61625301 and 61731018), Qualcomm, and Microsoft Research Asia.	Bako L, 2011, AUTOMATICA, V47, P668, DOI 10.1016/j.automatica.2011.01.036; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Bradley PS, 2000, J GLOBAL OPTIM, V16, P23, DOI 10.1023/A:1008324625522; Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21; Chen GL, 2009, INT J COMPUT VISION, V81, P317, DOI 10.1007/s11263-008-0178-9; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; Dattorro J., 2016, CONVEX OPTIMIZATION; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Feng JS, 2014, PROC CVPR IEEE, P3818, DOI 10.1109/CVPR.2014.482; Gear CW, 1998, INT J COMPUT VISION, V29, P133, DOI 10.1023/A:1008026310903; Hastie T, 1998, STAT SCI, V13, P54; Hu H, 2014, PROC CVPR IEEE, P3834, DOI 10.1109/CVPR.2014.484; Kanatani K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P586, DOI 10.1109/ICCV.2001.937679; Lai HJ, 2014, LECT NOTES COMPUT SC, V8690, P617, DOI 10.1007/978-3-319-10605-2_40; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Li CG, 2015, PROC CVPR IEEE, P277, DOI 10.1109/CVPR.2015.7298624; Liu G., 2010, P 27 INT C MACHINE L, P663, DOI DOI 10.1109/ICDMW.2010.64; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu GC, 2011, IEEE I CONF COMP VIS, P1615, DOI 10.1109/ICCV.2011.6126422; Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26; Lu CY, 2018, IEEE T PATTERN ANAL, V40, P527, DOI 10.1109/TPAMI.2017.2689021; Lu CY, 2016, IEEE T IMAGE PROCESS, V25, P829, DOI 10.1109/TIP.2015.2511584; Lu CY, 2013, IEEE I CONF COMP VIS, P1801, DOI 10.1109/ICCV.2013.226; Lu CY, 2013, IEEE I CONF COMP VIS, P1345, DOI 10.1109/ICCV.2013.170; Luo DJ, 2011, LECT NOTES ARTIF INT, V6912, P405, DOI 10.1007/978-3-642-23783-6_26; Ma Y, 2008, SIAM REV, V50, P413, DOI 10.1137/060655523; Nasihatkon B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2137, DOI 10.1109/CVPR.2011.5995679; Ng AY, 2002, ADV NEUR IN, V14, P849; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Soltanolkotabi M, 2012, ANN STAT, V40, P2195, DOI 10.1214/12-AOS1034; Tron R, 2007, PROC CVPR IEEE, P41, DOI 10.1109/cvpr.2007.382974; Tseng P, 2000, J OPTIMIZ THEORY APP, V105, P249, DOI 10.1023/A:1004678431677; Vidal R, 2005, IEEE T PATTERN ANAL, V27, P1945, DOI 10.1109/TPAMI.2005.244; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wang S., 2011, P 25 AAAI C ARTIFICI, P519; Yan JY, 2006, LECT NOTES COMPUT SC, V3954, P94; You C, 2016, PROC CVPR IEEE, P3918, DOI 10.1109/CVPR.2016.425; You C, 2016, PROC CVPR IEEE, P3928, DOI 10.1109/CVPR.2016.426; Zhang A., 2012, P 28 C UNCERTAINTY A, P944; Zhu X., 2009, SYNTHESIS LECT ARTIF, V3, P1, DOI [10.2200/S00196ED1V01Y200906AIM006, DOI 10.2200/S00196ED1V01Y200906AIM006]	43	192	205	8	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2019	41	2					487	501		10.1109/TPAMI.2018.2794348	http://dx.doi.org/10.1109/TPAMI.2018.2794348			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HI0RN	29994558	Green Submitted			2022-12-18	WOS:000456150600016
J	Pont-Tuset, J; Marques, F				Pont-Tuset, Jordi; Marques, Ferran			Supervised Evaluation of Image Segmentation and Object Proposal Techniques	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	27th IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 23-28, 2014	Columbus, OH	Comp Vis Fdn, IEEE, IEEE Comp Soc		Image segmentation; object proposals; supervised evaluation; meta-measures		This paper tackles the supervised evaluation of image segmentation and object proposal algorithms. It surveys, structures, and deduplicates the measures used to compare both segmentation results and object proposals with a ground truth database; and proposes a new measure: the precision-recall for objects and parts. To compare the quality of these measures, eight state-of-the-art object proposal techniques are analyzed and two quantitative meta-measures involving nine state of the art segmentation methods are presented. The meta-measures consist in assuming some plausible hypotheses about the results and assessing how well each measure reflects these hypotheses. As a conclusion of the performed experiments, this paper proposes the tandem of precision-recall curves for boundaries and for objects-and-parts as the tool of choice for the supervised evaluation of image segmentation. We make the datasets and code of all the measures publicly available.	[Pont-Tuset, Jordi; Marques, Ferran] Univ Politecn Cataluna, Signal Theory & Commun, BarcelonaTech, Barcelona, Spain	Universitat Politecnica de Catalunya	Pont-Tuset, J (corresponding author), Univ Politecn Cataluna, Signal Theory & Commun, BarcelonaTech, Barcelona, Spain.	jordi.pont@upc.edu; ferran.marques@upc.edu		Marques, Ferran/0000-0001-8311-1168				Achanta R., 2010, SLIC SUPERPIXELS; Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Arbelaez P, 2012, PROC CVPR IEEE, P3378, DOI 10.1109/CVPR.2012.6248077; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/cvpr.2008.4587586; Cardoso JS, 2005, IEEE T IMAGE PROCESS, V14, P1773, DOI 10.1109/TIP.2005.854491; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; CZEKANOWSKI J, 1913, PRACE TOWARZYSTWA NA, V5; DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409; Dongen S., 2000, INSR0012 CWI; Endres I, 2014, IEEE T PATTERN ANAL, V36, P222, DOI 10.1109/TPAMI.2013.122; Estrada FJ, 2009, INT J COMPUT VISION, V85, P167, DOI 10.1007/s11263-009-0251-z; Everingham M., 2006, P EUR C COMP VIS, P255; Everingham M., 2010, PASCAL VISUAL OBJECT; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Ge F., 2006, IEEE COMP SOC C COMP, V1, P1146, DOI DOI 10.1109/CVRR.2006.147; Ge F., 2007, ELECT IMAGING, V16; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Gu CH, 2009, PROC CVPR IEEE, P1030, DOI 10.1109/CVPRW.2009.5206727; Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20; Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25; Hoover A, 1996, IEEE T PATTERN ANAL, V18, P673, DOI 10.1109/34.506791; Huang Q, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC53; Humayun A, 2014, PROC CVPR IEEE, P336, DOI 10.1109/CVPR.2014.50; Ion A, 2011, IEEE I CONF COMP VIS, P2110, DOI 10.1109/ICCV.2011.6126486; Jaccard P, 1901, B SOC VAUDOISE SCI N, V37, P241; Jiang XY, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/35909; Kanungo T., 1994, 9754 RJ IBM RES DIV; Krahenbuhl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47; Leal-Taixe L., 2015, ARXIV150401942; Levinshtein A, 2010, LECT NOTES COMPUT SC, V6312, P480, DOI 10.1007/978-3-642-15552-9_35; Li FX, 2010, PROC CVPR IEEE, P1712, DOI 10.1109/CVPR.2010.5539839; Liu G, 2000, PROC CVPR IEEE, P26, DOI 10.1109/CVPR.2000.855794; Malisiewicz T., 2007, P BRIT MACH VIS C UK, DOI 10.5244/C.21.55; Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Martin D.R., 2003, THESIS; McGuinness K, 2010, PATTERN RECOGN, V43, P434, DOI 10.1016/j.patcog.2009.03.008; Meila M., 2005, PROC INT C MACHINE L, P577, DOI DOI 10.1145/1102351.1102424; Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254; Nowozin S, 2010, LECT NOTES COMPUT SC, V6316, P98, DOI 10.1007/978-3-642-15567-3_8; Pont-Tuset J., 2014, THESIS; Pont-Tuset J., 2013, SEISM SUPERVISED EVA; Pont-Tuset J, 2013, PROC CVPR IEEE, P2131, DOI 10.1109/CVPR.2013.277; Pont-Tuset J, 2012, LECT NOTES COMPUT SC, V7575, P814, DOI 10.1007/978-3-642-33765-9_58; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Rantalankila P, 2014, PROC CVPR IEEE, P2417, DOI 10.1109/CVPR.2014.310; Ren ZL, 2013, PROC CVPR IEEE, P2011, DOI 10.1109/CVPR.2013.262; Russell B. C., 2006, P IEEE C COMP VIS PA, V2, P1605; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Smith K., 2005, COMP VIS PATT REC WO, P36, DOI DOI 10.1109/CVPR.2005.453; Sorensen T., 1948, BIOL SKRIFTER, V5, P297; Suinesiaputra Avail, 2012, Statistical Atlases and Computational Models of the Heart. Imaging and Modelling Challenges. Second International Workshop, STACOM 2011 Held in Conjunction with MICCAI 2011. Revised Selected Papers, P88, DOI 10.1007/978-3-642-28326-0_9; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046; Veltkamp RC, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P188, DOI 10.1109/SMA.2001.923389; Vilaplana V, 2008, IEEE T IMAGE PROCESS, V17, P2201, DOI 10.1109/TIP.2008.2002841; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Zou KH, 2004, ACAD RADIOL, V11, P178, DOI 10.1016/S1076-6332(03)00671-8	65	192	204	1	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2016	38	7							1465	10.1109/TPAMI.2015.2481406	http://dx.doi.org/10.1109/TPAMI.2015.2481406			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	DO6MH	26415155	Green Published			2022-12-18	WOS:000377897100015
J	Ye, JP; Janardan, R; Park, CH; Park, H				Ye, JP; Janardan, R; Park, CH; Park, H			An optimization criterion for generalized discriminant analysis on undersampled problems	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						classification; clustering; dimension reduction; generalized singular value decomposition; linear discriminant analysis; text mining	SINGULAR-VALUE DECOMPOSITION; RETRIEVAL; CLASSIFICATION; RECOGNITION	An optimization criterion is presented for discriminant analysis. The criterion extends the optimization criteria of the classical Linear Discriminant Analysis (LDA) through the use of the pseudoinverse when the scatter matrices are singular. It is applicable regardless of the relative sizes of the data dimension and sample size, overcoming a limitation of classical LDA. The optimization problem can be solved analytically by applying the Generalized Singular Value Decomposition (GSVD) technique. The pseudoinverse has been suggested and used for undersampled problems in the past, where the data dimension exceeds the number of data points. The criterion proposed in this paper provides a theoretical justification for this procedure. An approximation algorithm for the GSVD-based approach is also presented. It reduces the computational complexity by finding subclusters of each cluster and uses their centroids to capture the structure of each cluster. This reduced problem yields much smaller matrices to which the GSVD can be applied efficiently. Experiments on text data, with up to 7,000 dimensions, show that the approximation algorithm produces results that are close to those produced by the exact algorithm.	Univ Minnesota Twin Cities, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA	University of Minnesota System; University of Minnesota Twin Cities	Ye, JP (corresponding author), Univ Minnesota Twin Cities, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.	jieping@cs.umn.edu; janardan@cs.umn.edu; chpark@cs.umn.edu; hpark@cs.umn.edu						Baldi P, 2002, DNA MICROARRAYS GENE; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Berry MW, 1995, SIAM REV, V37, P573, DOI 10.1137/1037127; Dai DQ, 2003, PATTERN RECOGN, V36, P845, DOI 10.1016/S0031-3203(02)00092-4; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971; Duda R.O., 2000, PATTERN CLASSIFICATI; DUIN RPW, 1995, SCIA 95 P 9 SCAND C, V2, P957; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Golub Gene H., 2013, MATRIX COMPUTATION, V3; GOWER JC, 1966, BIOMETRIKA, V53, P325, DOI 10.2307/2333639; Howland P, 2003, SIAM J MATRIX ANAL A, V25, P165, DOI 10.1137/S0895479801393666; HOWLAND P, P 4 SIAM INT C DAT M; HOWLANDP, IEEE T PATTERN ANAL; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; KOWALSKI G, 1997, INFORMATION RETRIEVA; KRZANOWSKI WJ, 1995, J R STAT SOC C-APPL, V44, P101, DOI 10.2307/2986198; Lewis DD, 1999, REUTERS 21578 TEXT C; MEHAY A, 2002, APPL SPECTROSC, V15, P219; PAIGE CC, 1981, SIAM J NUMER ANAL, V18, P398, DOI 10.1137/0718026; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Raudys S, 1998, PATTERN RECOGN LETT, V19, P385, DOI 10.1016/S0167-8655(98)00016-6; SALTON G, 1983, INTRO MODERN INFORMA; Salton G., 1989, AUTOMATIC TEXT PROCE; Skurichina M., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P891, DOI 10.1109/ICPR.1996.547204; Skurichina M, 1999, PATTERN ANAL APPL, V2, P44, DOI 10.1007/s100440050013; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; TIAN Q, 1986, OPT ENG, V25, P834, DOI 10.1117/12.7973916; *TREC, 1999, P TEXT RETR C; VANLOAN CF, 1976, SIAM J NUMER ANAL, V13, P76, DOI 10.1137/0713009; ZHAO Y, 2001, TR01040 U MINN DEP C; Zhou XS, 2001, PROC CVPR IEEE, P11	33	192	196	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2004	26	8					982	994		10.1109/TPAMI.2004.37	http://dx.doi.org/10.1109/TPAMI.2004.37			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	827BE	15641729				2022-12-18	WOS:000221872400003
J	THOMPSON, AM; BROWN, JC; KAY, JW; TITTERINGTON, DM				THOMPSON, AM; BROWN, JC; KAY, JW; TITTERINGTON, DM			A STUDY OF METHODS OF CHOOSING THE SMOOTHING PARAMETER IN IMAGE-RESTORATION BY REGULARIZATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CROSS-VALIDATION; ILL-POSED PROBLEMS; IMAGE RESTORATION; REGULARIZATION; SMOOTHING	COMPUTATIONAL VISION; COMMON STRUCTURE; REGRESSION; INVERSION	The method of regularization is portrayed as providing a compromise between fidelity to the data and smoothness, with the tradeoff being determined by a scalar smoothing parameter. Various ways of choosing this parameter are discussed in the case of quadratic regularization criteria. They are compared algebraically and their statistical properties are assessed, comparatively, from the results of an extensive simulation study based on simple images.	UNIV GLASGOW,DEPT STAT,GLASGOW G12 2QW,SCOTLAND	University of Glasgow	THOMPSON, AM (corresponding author), UNIV GLASGOW,DEPT PHYS & ASTRON,GLASGOW G12 2QW,SCOTLAND.							ANDERSON TW, 1971, STATISTICAL ANAL TIM; Craig I. J. D., 1986, INVERSE PROBLEMS AST; CRAIG IJD, 1985, ASTRON ASTROPHYS, V149, P171; GASSER T, 1986, BIOMETRIKA, V73, P625; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; GRAY RM, 1972, IEEE T INFORM THEORY, V18, P725, DOI 10.1109/TIT.1972.1054741; GRIMSON WEL, 1983, COMPUT VISION GRAPH, V21, P215; GROETSCH CW, 1984, 105 RES NOT MATH; GULL SF, 1984, IEE PROC-F, V131, P646, DOI 10.1049/ip-f-1.1984.0099; HALL P, 1986, J ROY STAT SOC B MET, V48, P330; HALL P, 1987, J ROY STAT SOC B MET, V49, P184; HARDLE W, 1988, J AM STAT ASSOC, V83, P86, DOI 10.2307/2288922; JAIN AK, 1978, IEEE T ACOUST SPEECH, V26, P121, DOI 10.1109/TASSP.1978.1163064; JOHNSON NL, 1970, DISTRIBUTIONS STATIS, V2; KAY JW, 1988, SPRINGER LECT NOTES, V301, P587; MACKINNON AL, 1985, SOL PHYS, V99, P231, DOI 10.1007/BF00157310; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; PHILIP J, 1987, INVERSE PROBL, V3, P309, DOI 10.1088/0266-5611/3/2/013; PHILLIPS DL, 1962, J ACM, V9, P84, DOI 10.1145/321105.321114; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; Rice J., 1986, CONT MATH, V59, P137; SHARAYHA B, 1989, IEEE T PAMI, V11, P600; Thompson A., 1989, J STATIST COMPUT SIM, V33, P199; THOMPSON AM, 1988, MAXIMUM ENTROPY BAYE, P497; Tikhonov A., 1977, SOLUTIONS ILL POSED; TITTERINGTON DM, 1985, INT STAT REV, V53, P141, DOI 10.2307/1402932; TITTERINGTON DM, 1985, ASTRON ASTROPHYS, V144, P381; TITTERINGTON DM, 1986, STATIST SCI, V1, P519; WAHBA G, 1983, J ROY STAT SOC B MET, V45, P133; WAHBA G, 1985, COMMUN STAT, V4, P1; Wahba S. S., 1982, STAT DECISION THEORY, P383; YASUMOTO Y, 1986, IEEE T PATTERN ANAL, V8, P464, DOI 10.1109/TPAMI.1986.4767810	32	192	195	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1991	13	4					326	339		10.1109/34.88568	http://dx.doi.org/10.1109/34.88568			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL566					2022-12-18	WOS:A1991FL56600003
J	Shivakumara, P; Phan, TQ; Tan, CL				Shivakumara, Palaiahnakote; Phan, Trung Quy; Tan, Chew Lim			A Laplacian Approach to Multi-Oriented Text Detection in Video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Connected component analysis; frequency domain processing; text detection; text orientation	IMAGES	In this paper, we propose a method based on the Laplacian in the frequency domain for video text detection. Unlike many other approaches which assume that text is horizontally-oriented, our method is able to handle text of arbitrary orientation. The input image is first filtered with Fourier-Laplacian. K-means clustering is then used to identify candidate text regions based on the maximum difference. The skeleton of each connected component helps to separate the different text strings from each other. Finally, text string straightness and edge density are used for false positive elimination. Experimental results show that the proposed method is able to handle graphics text and scene text of both horizontal and nonhorizontal orientation.	[Shivakumara, Palaiahnakote; Phan, Trung Quy; Tan, Chew Lim] Natl Univ Singapore, Dept Comp Sci, Sch Comp, Singapore 117417, Singapore	National University of Singapore	Shivakumara, P (corresponding author), Natl Univ Singapore, Dept Comp Sci, Sch Comp, Comp 1,13 Comp Dr, Singapore 117417, Singapore.	shiva@comp.nus.edu.sg; phanquyt@comp.nus.edu.sg; tancl@comp.nus.edu.sg	Palaiahnakote, Shivakumara/B-6261-2013		MDA [R252-000-325-279]; A*STAR [R252-000-402-305]	MDA(Muscular Dystrophy Association); A*STAR(Agency for Science Technology & Research (A*STAR))	This research was supported in part by MDA grant R252-000-325-279 and A*STAR grant R252-000-402-305. The authors thank the anonymous reviewers for their constructive comments, which helped to improve the paper.	Bhattacharya Ujjwal, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P171, DOI 10.1109/ICDAR.2009.178; Cai M, 2002, IEEE IMAGE PROC, P117; Chen DT, 2004, SIGNAL PROCESS-IMAGE, V19, P205, DOI 10.1016/S0923-5965(03)00075-4; Chen XL, 2004, IEEE T IMAGE PROCESS, V13, P87, DOI 10.1109/TIP.2003.819223; Crandall D., 2003, International Journal on Document Analysis and Recognition, V5, P138, DOI 10.1007/s10032-002-0091-7; GONZALEZ RC, 2002, DIGITAL IMAGE PROCES, P167; Hua XS, 2004, IEEE T CIRC SYST VID, V14, P498, DOI 10.1109/TCSVT.2004.825538; Jung K, 2004, PATTERN RECOGN, V37, P977, DOI 10.1016/j.patcog.2003.10.012; Jung K, 2001, PATTERN RECOGN LETT, V22, P1503, DOI 10.1016/S0167-8655(01)00096-4; Kim KI, 2003, IEEE T PATTERN ANAL, V25, P1631, DOI 10.1109/TPAMI.2003.1251157; Lee CW, 2003, PATTERN RECOGN LETT, V24, P2607, DOI 10.1016/S0167-8655(03)00105-3; Lienhart R, 2002, IEEE T CIRC SYST VID, V12, P256, DOI 10.1109/76.999203; Liu CM, 2005, PROC INT CONF DOC, P610; LUCAS SM, 2005, P INT C DOC AN REC, V1, P8084; Lyu MR, 2005, IEEE T CIRC SYST VID, V15, P243, DOI 10.1109/TCSVT.2004.841653; Mariano VY, 2000, INT C PATT RECOG, P539, DOI 10.1109/ICPR.2000.902976; Roy Partha Pratim, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P11, DOI 10.1109/ICDAR.2009.124; Roy PP, 2008, INT C PATT RECOG, P773; Sobottka K., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P57, DOI 10.1109/ICDAR.1999.791724; Tang X, 2002, IEEE T NEURAL NETWOR, V13, P961, DOI 10.1109/TNN.2002.1021896; Trung Quy Phan, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P66, DOI 10.1109/ICDAR.2009.153; Wang F, 2008, PATTERN RECOGN, V41, P3257, DOI 10.1016/j.patcog.2008.03.024; Wong EK, 2003, PATTERN RECOGN, V36, P1397, DOI 10.1016/S0031-3203(02)00230-3; Ye QX, 2005, IMAGE VISION COMPUT, V23, P565, DOI 10.1016/j.imavis.2005.01.004; Zhang J, 2008, PROCEEDINGS OF THE 8TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, P5, DOI 10.1109/DAS.2008.49; ZHONG Y, 1995, P 3 INT C DOC AN REC, P146	26	191	206	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2011	33	2					412	419		10.1109/TPAMI.2010.166	http://dx.doi.org/10.1109/TPAMI.2010.166			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	694QR	20733217				2022-12-18	WOS:000285313200016
J	Kim, KI; Franz, MO; Scholkopf, B				Kim, KI; Franz, MO; Scholkopf, B			Iterative kernel principal component analysis for image modeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						principal component analysis; kernel methods; image models; image enhancement; unsupervised learning	NATURAL IMAGES; COMPRESSION	In recent years, Kernel Principal Component Analysis ( KPCA) has been suggested for various image processing tasks requiring an image model such as, e.g., denoising or compression. The original form of KPCA, however, can be only applied to strongly restricted image classes due to the limited number of training examples that can be processed. We therefore propose a new iterative method for performing KPCA, the Kernel Hebbian Algorithm which iteratively estimates the Kernel Principal Components with only linear order memory complexity. In our experiments, we compute models for complex image classes such as faces and natural images which require a large number of training examples. The resulting image models are tested in single-frame super-resolution and denoising applications. The KPCA model is not specifically tailored to these tasks; in fact, the same model can be used in super-resolution with variable input resolution, or denoising with unknown noise characteristics. In spite of this, both super-resolution and denoising performance are comparable to existing methods.	Korea Adv Inst Sci & Technol, Dept Comp Sci, AI Lab, Taejon 305701, South Korea; Max Planck Inst Biol Cybernet, D-72076 Tubingen, Germany	Korea Advanced Institute of Science & Technology (KAIST); Max Planck Society	Kim, KI (corresponding author), Korea Adv Inst Sci & Technol, Dept Comp Sci, AI Lab, 373-1 Taejon, Taejon 305701, South Korea.	kimki@tuebingen.mpg.de; mof@tuebingen.mpg.de; bs@tuebingen.mpg.de	Schölkopf, Bernhard/A-7570-2013	Schölkopf, Bernhard/0000-0002-8177-0925; Franz, Matthias/0000-0003-3789-8849				Akkarakaran S, 1999, P SOC PHOTO-OPT INS, V3813, P346, DOI 10.1117/12.366792; BADDELEY RJ, 1991, P ROY SOC B-BIOL SCI, V246, P219, DOI 10.1098/rspb.1991.0147; Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Buccigrossi RW, 1999, IEEE T IMAGE PROCESS, V8, P1688, DOI 10.1109/83.806616; BURGES CJC, 1996, P 13 INT C MACH LEAR, P71; CHAPELLE O, 2000, ADV NEURAL INFORMATI, V12; Chen ATL, 1998, GENET MED, V1, P67, DOI 10.1097/00125817-199811000-00026; CHOI H, 1999, P IEEE INT C IM PROC, P595; CRISTIANINI N, 2002, ADV NEURAL INFORMATI, V14; FIELD DJ, 1994, NEURAL COMPUT, V6, P559, DOI 10.1162/neco.1994.6.4.559; Franz MO, 2004, MACHINE LEARNING FOR SIGNAL PROCESSING XIV, P735; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Girosi F, 1998, NEURAL COMPUT, V10, P1455, DOI 10.1162/089976698300017269; Gonzalez R C, 1992, DIGITAL IMAGE PROCES; Grenander U, 2001, IEEE T PATTERN ANAL, V23, P424, DOI 10.1109/34.917579; HAM J, 2003, 110 M PLANCK I BIOL; HANGCOCK PJB, 1992, NETWORK, V3, P61; HAYK S, 1999, NEURAL NETWORKS COMP; Herbrich R., 2001, LEARNING KERNEL CLAS; HURRI J, 1996, P IEEE 1996 NORD C S; Kim SH, 2003, WASH QUART, V26, P109; KWOK JT, 2004, ADV NEURAL INFORMATI; Kwok JTY, 2004, IEEE T NEURAL NETWOR, V15, P1517, DOI 10.1109/TNN.2004.837781; Lee AB, 2001, INT J COMPUT VISION, V41, P35, DOI 10.1023/A:1011109015675; Malina H Z, 2001, BMC Physiol, V1, P7, DOI 10.1186/1472-6793-1-7; Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121; Mika S, 1999, ADV NEUR IN, V11, P536; Munson DC, 1996, IEEE T IMAGE PROCESS, V5, P1; OJA E, 1992, NEURAL NETWORKS, V5, P927, DOI 10.1016/S0893-6080(05)80089-9; OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; PIZURICA A, IN PRESS IEEE T IMAG; POGGIO T, 1990, P IM UND WORKSH, P597; Romdhani S, 1999, P 10 BRIT MACH VIS C, P483, DOI [10.5244/C.13.48, DOI 10.5244/C.13.48]; Ruderman DL, 1997, VISION RES, V37, P3385, DOI 10.1016/S0042-6989(97)00008-4; SANGER TD, 1989, NEURAL NETWORKS, V2, P459, DOI 10.1016/0893-6080(89)90044-0; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SCHOLKOPV B, 2002, LEARNING KERNELS; Simoncelli E.P., 1999, BAYESIAN INFERENCE W, V141, P291, DOI DOI 10.1007/978-1-4612-0567-8; Steinwart I, 2002, J MACH LEARN RES, V2, P67, DOI 10.1162/153244302760185252; TURK A, 1991, P CVPQ 91, P586; TWINING CJ, 2001, P BRIT MACH VIS C, P23; Vapnik V, 2000, ADV NEUR IN, P261; von Luxburg U, 2004, J MACH LEARN RES, V5, P293; Yoshizawa S., 2001, International Journal of Applied Mathematics and Computer Science, V11, P223; Zhu SC, 1997, IEEE T PATTERN ANAL, V19, P1236, DOI 10.1109/34.632983	51	191	210	0	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2005	27	9					1351	1366						16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	944XB	16173181				2022-12-18	WOS:000230463300001
J	SUBBARAO, M; CHOI, T				SUBBARAO, M; CHOI, T			ACCURATE RECOVERY OF 3-DIMENSIONAL SHAPE FROM IMAGE FOCUS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						SHAPE-FROM-FOCUS; FOCUSED IMAGE SURFACE; PARAXIAL-GEOMETRIC OPTICS; FOCUS MEASURE; CAMERA PARAMETERS; SHAPE RECOVERY; FOCUSED IMAGE RECONSTRUCTION		A new Shape-from-focus method is described which is based on a new concept named Focused Image Surface (FIS). PIS of an object is defined as the surface formed by the set of points at which the object points are focused by a camera lens. According to paraxial-geometric optics, there is a one-to-one correspondence between the shape of an object and the shape of its FIS. Therefore, the problem of shape recovery can be posed as the problem of determining the shape of the PIS. From the shape of FIS the shape of the object is easily obtained. In this paper the shape of the FIS is determined by searching for a shape which maximizes a focus measure. In contrast to previous literature where the focus measure is computed over the planar image detector of the camera, here the focus measure is computed over the PIS. This results in more accurate shape recovery than the traditional methods. Also, using FIS, a more accurate focused image can be reconstructed from a sequence of images than is possible with traditional methods. The new method has been implemented on an actual camera system, and the results of shape recovery and focused image reconstruction are presented.	HYUNDAI ELECTR AMER,ENGLEWOOD CLIFFS,NJ 07632		SUBBARAO, M (corresponding author), SUNY STONY BROOK,DEPT ELECT ENGN,COMP VIS LAB,STONY BROOK,NY 11794, USA.							ENNS J, 1993, IEEE T PATTERN ANAL, V15, P97; Gaskill J.D., 1978, LINEAR SYSTEMS FOURI; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1968, MIT160 ART INT MEM; KROTKOV E, 1987, INT J COMPUT VISION, V1, P223, DOI 10.1007/BF00127822; LIGTHART G, 1982, IEEE P INT C PATT RE, P597; LU MC, 1993, THESIS STATE U NEW Y; NAYAR SK, 1992, JUN P IEEE COMP SOC, P302; PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940; SCHLAG JF, 1983, CMURITR8314 CARN MEL; Subbarao M., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P149, DOI 10.1109/CCV.1988.589986; SUBBARAO M, 1993, OPT ENG, V32, P2824, DOI 10.1117/12.147706; SUBBARAO M, 1992, 1992 P IEEE COMP SOC, P773; SUBBARAO M, 1992, SPIE C P, V1822, P159	14	191	206	2	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1995	17	3					266	274		10.1109/34.368191	http://dx.doi.org/10.1109/34.368191			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QM090					2022-12-18	WOS:A1995QM09000004
J	DUNN, D; HIGGINS, WE; WAKELEY, J				DUNN, D; HIGGINS, WE; WAKELEY, J			TEXTURE SEGMENTATION USING 2-D GABOR ELEMENTARY-FUNCTIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						TEXTURE SEGMENTATION; TEXTURE DISCRIMINATION; COMPUTER VISION; GABOR FUNCTIONS; IMAGE SEGMENTATION	LOCALIZED SPATIAL FILTERS; VISUAL-CORTEX; DISCRIMINATION; VISION; FREQUENCY; CELLS; CHANNELS; SIGNALS; FIELDS; SPACE	Many texture-segmentation schemes use an elaborate bank of filters to decompose a textured image into a joint space/spatial-frequency representation. Although these schemes show promise, and although some analytical work work has been done, the relationship between texture differences and the filter configurations required to distinguish them remain largely unknown. This paper examines the issue of designing individual filters. Using a 2-D texture model, we show analytically that applying a properly configured bandpass filter to a textured image produces distinct output discontinuities at texture boundaries; the analysis is based on Gabor elementary functions, but it is the bandpass nature of the filter that is essential. Depending on the type of texture difference, these discontinuities form one of four characteristic signatures: a step, ridge, valley, or a step change in average local output variation. Accompanying experimental evidence indicates that these signatures are useful for segmenting an image. The analysis indicates those texture characteristics that are responsible for each signature type. Detailed criteria are provided for designing filters that can produce quality output signatures. We also illustrate occasions when asymmetric filters are beneficial, an issue not previously addressed.	PENN STATE UNIV,DEPT ELECT & COMP ENGN,UNIV PK,PA 16802; PENN STATE UNIV,APPL RES LAB,UNIV PK,PA 16802	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University	DUNN, D (corresponding author), PENN STATE UNIV,DEPT COMP SCI & ENGN,UNIV PK,PA 16802, USA.							BECK J, 1987, COMPUT VISION GRAPH, V37, P299, DOI 10.1016/S0734-189X(87)80006-3; BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384; BOVIK AC, 1991, IEEE T SIGNAL PROCES, V39, P2025, DOI 10.1109/78.134435; BRACEWELL RN, 1978, FOURIER TRANSFORM IT; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; CAELLI T, 1985, Spatial Vision, V1, P19, DOI 10.1163/156856885X00044; CAMPBELL FW, 1968, J PHYSIOL-LONDON, V197, P551, DOI 10.1113/jphysiol.1968.sp008574; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CLARK M, 1989, PATTERN RECOGN, V22, P707, DOI 10.1016/0031-3203(89)90007-1; CONNERS RW, 1980, IEEE T PATTERN ANAL, V2, P204, DOI 10.1109/TPAMI.1980.4767008; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DAUGMAN JG, 1984, VISION RES, V24, P891, DOI 10.1016/0042-6989(84)90065-8; DEVALOIS RL, 1982, RECOGNITION PATTERN; DUBUF JMH, 1991, SIGNAL PROCESS, V23, P227, DOI 10.1016/0165-1684(91)90002-Z; DUNN D, 1992, IEEE T ACOUST SPEECH, V3, P65; DUNN D, 1991, SPIE P VISUAL COMMUN, V1606, P541; DUNN D, 1992, THESIS PENNSYLVANIA; DUNN DF, 1993, IEEE INT C AC SPEECH, V5, P37; FARROKHNIA F, 1991, IEEE C CVPR; FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594; FRANCOS JM, 1991, P INT C ACOUSTICS SP, P2669; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; GAGALOWICZ A, 1981, IEEE T PATTERN ANAL, V3, P520, DOI 10.1109/TPAMI.1981.4767145; Hawkins JK, 1970, PICTURE PROCESSING P, P347; IWAMA K, 1989, J EXPT THEOR ARTIF I, V2, P113; JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S; JULESZ B, 1986, BIOL CYBERN, V54, P245, DOI 10.1007/BF00318420; JULESZ B, COMMUNICATION; JULESZ B, 1962, IRE T INF THEORY, V8, P92; Julesz B., 1962, IRE T INFORM THEOR, V8, P84, DOI 10.1109/TIT.1962.1057698; KROSE BJA, 1987, BIOL CYBERN, V55, P289, DOI 10.1007/BF02281975; Kube P., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P100, DOI 10.1109/CVPR.1988.196221; KULIKOWSKI JJ, 1982, BIOL CYBERN, V43, P187, DOI 10.1007/BF00319978; MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923; MANJUNATH B, 1991, IEEE C CVPR; MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297; OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591; POLLEN DA, 1982, VISION RES, V22, P101, DOI 10.1016/0042-6989(82)90172-9; PORAT M, 1988, IEEE T PATTERN ANAL, V10, P452, DOI 10.1109/34.3910; PORAT M, 1989, IEEE T BIO-MED ENG, V36, P115, DOI 10.1109/10.16457; Pratt W, 1991, DIGITAL IMAGE PROCES; RAO A, 1990, TAXONOMY TEXTURE DES; REARICK TC, 1985, IEEE C COMP VISION P, P312; REED T, 1990, IEEE T PATTERN ANAL, V12; RENTSCHLER I, 1988, VISION RES, V28, P279, DOI 10.1016/0042-6989(88)90156-3; SKLANSKY J, 1978, IEEE T SYST MAN CYB, V8, P237, DOI 10.1109/TSMC.1978.4309944; Super B. J., 1991, Journal of Visual Communication and Image Representation, V2, P114, DOI 10.1016/1047-3203(91)90002-W; SUPER BJ, 1991, P SOC PHOTO-OPT INS, V1606, P574, DOI 10.1117/12.50344; TURNER MR, 1986, BIOL CYBERN, V55, P71; VOORHEES H, 1988, NATURE, V333, P364, DOI 10.1038/333364a0; YOUNG RA, 1987, GMR4920 GEN MOT RES	52	191	210	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1994	16	2					130	149		10.1109/34.273736	http://dx.doi.org/10.1109/34.273736			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NA631					2022-12-18	WOS:A1994NA63100002
J	Zhang, YL; Tian, YP; Kong, Y; Zhong, BN; Fu, Y				Zhang, Yulun; Tian, Yapeng; Kong, Yu; Zhong, Bineng; Fu, Yun			Residual Dense Network for Image Restoration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Image restoration; Training; Task analysis; Image coding; Image denoising; Residual dense network; hierarchical features; image restoration; image super-resolution; image denoising; compression artifact reduction; image deblurring	SPARSE; SUPERRESOLUTION; REPRESENTATIONS	Recently, deep convolutional neural network (CNN) has achieved great success for image restoration (IR) and provided hierarchical features at the same time. However, most deep CNN based IR models do not make full use of the hierarchical features from the original low-quality images; thereby, resulting in relatively-low performance. In this work, we propose a novel and efficient residual dense network (RDN) to address this problem in IR, by making a better tradeoff between efficiency and effectiveness in exploiting the hierarchical features from all the convolutional layers. Specifically, we propose residual dense block (RDB) to extract abundant local features via densely connected convolutional layers. RDB further allows direct connections from the state of preceding RDB to all the layers of current RDB, leading to a contiguous memory mechanism. To adaptively learn more effective features from preceding and current local features and stabilize the training of wider network, we proposed local feature fusion in RDB. After fully obtaining dense local features, we use global feature fusion to jointly and adaptively learn global hierarchical features in a holistic way. We demonstrate the effectiveness of RDN with several representative IR applications, single image super-resolution, Gaussian image denoising, image compression artifact reduction, and image deblurring. Experiments on benchmark and real-world datasets show that our RDN achieves favorable performance against state-of-the-art methods for each IR task quantitatively and visually.	[Zhang, Yulun] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA; [Tian, Yapeng] Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA; [Kong, Yu] Thomas Golisano Coll Comp & Informat Sci, Rochester Inst Technol, Rochester, NY 14623 USA; [Zhong, Bineng] Huaqiao Univ, Sch Comp Sci & Technol, Xiamen 361021, Peoples R China; [Fu, Yun] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA; [Fu, Yun] Northeastern Univ, Khoury Coll, Boston, MA 02115 USA	Northeastern University; University of Rochester; Rochester Institute of Technology; Huaqiao University; Northeastern University; Northeastern University	Zhang, YL (corresponding author), Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.	yulun100@gmail.com; yapengtian@rochester.edu; yu.kong@rit.edu; bnzhong@hqu.edu.cn; yunfu@ece.neu.edu		Fu, Yun/0000-0002-5098-2853	U.S. Army Research Office Award [W911NF-17-1-0367]	U.S. Army Research Office Award	This work was supported in part by the U.S. Army Research Office Award W911NF-17-1-0367.	Ancuti C, 2018, IEEE COMPUT SOC CONF, P1004, DOI 10.1109/CVPRW.2018.00134; [Anonymous], 2018, ARXIV PREPRINT ARXIV; Ba J., 2017, P 3 INT C LEARN REPR; Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135; Blau Y, 2019, LECT NOTES COMPUT SC, V11133, P334, DOI 10.1007/978-3-030-11021-5_21; Chen GY, 2015, IEEE I CONF COMP VIS, P477, DOI 10.1109/ICCV.2015.62; Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743; Dabov K, 2007, IEEE IMAGE PROC, P313, DOI 10.1109/icip.2007.4378954; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25; Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Dong WS, 2019, IEEE T PATTERN ANAL, V41, P2305, DOI 10.1109/TPAMI.2018.2873610; Dong WS, 2015, INT J COMPUT VISION, V114, P217, DOI 10.1007/s11263-015-0808-y; Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Glorot X., 2011, P 14 INT C ART INT S, P315; Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jancsary J, 2012, LECT NOTES COMPUT SC, V7578, P112, DOI 10.1007/978-3-642-33786-4_9; Karras Tero, 2018, INT C LEARN REPR; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304; Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618; Lebrun M, 2015, IMAGE PROCESS ON LIN, V5, P1, DOI 10.5201/ipol.2015.125; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562; Levin A, 2012, LECT NOTES COMPUT SC, V7576, P73, DOI 10.1007/978-3-642-33715-4_6; Li KP, 2018, PROC CVPR IEEE, P9215, DOI 10.1109/CVPR.2018.00960; Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151; Liu PJ, 2018, IEEE COMPUT SOC CONF, P886, DOI 10.1109/CVPRW.2018.00121; Mao XJ, 2016, ADV NEUR IN, V29; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z; Peleg T, 2014, IEEE T IMAGE PROCESS, V23, P2569, DOI 10.1109/TIP.2014.2305844; Plotz Tobias, 2018, ADV NEURAL INFORM PR, V31, P1087; Schulter S, 2015, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2015.7299003; Sheikh H., 2005, LIVE IMAGE QUALITY A; Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207; Shi WZ, 2013, LECT NOTES COMPUT SC, V8151, P9, DOI 10.1007/978-3-642-40760-4_2; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486; Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298; Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149; Timofte R, 2016, PROC CVPR IEEE, P1865, DOI 10.1109/CVPR.2016.206; Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8; Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241; Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50; Xu J, 2017, IEEE I CONF COMP VIS, P1105, DOI 10.1109/ICCV.2017.125; Yu K, 2018, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR.2018.00259; Zeyde Roman, 2010, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47; Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407; Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337; Zhang H, 2018, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2018.00079; Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344; Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891; Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300; Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206; Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977; Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407; Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI [10.1007/978-3-030-01234-2_18, 10.1007/978-3-030-01240-3_22]; Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262; Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423	75	190	197	53	197	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2021	43	7					2480	2495		10.1109/TPAMI.2020.2968521	http://dx.doi.org/10.1109/TPAMI.2020.2968521			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL3FK	31985406	Green Submitted			2022-12-18	WOS:000692540900022
J	Bucak, SS; Jin, R; Jain, AK				Bucak, Serhat S.; Jin, Rong; Jain, Anil K.			Multiple Kernel Learning for Visual Object Recognition: A Review	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review						Multiple kernel learning; support vector machine; visual object recognition; convex optimization	CLASSIFICATION; SCALE; ALGORITHMS; FEATURES; TEXTURE; SHAPE	Multiple kernel learning (MKL) is a principled approach for selecting and combining kernels for a given recognition task. A number of studies have shown that MKL is a useful tool for object recognition, where each image is represented by multiple sets of features and MKL is applied to combine different feature sets. We review the state-of-the-art for MKL, including different formulations and algorithms for solving the related optimization problems, with the focus on their applications to object recognition. One dilemma faced by practitioners interested in using MKL for object recognition is that different studies often provide conflicting results about the effectiveness and efficiency of MKL. To resolve this, we conduct extensive experiments on standard datasets to evaluate various approaches to MKL for object recognition. We argue that the seemingly contradictory conclusions offered by studies are due to different experimental setups. The conclusions of our study are: (i) given a sufficient number of training examples and feature/kernel types, MKL is more effective for object recognition than simple kernel combination (e.g., choosing the best performing kernel or average of kernels); and (ii) among the various approaches proposed for MKL, the sequential minimal optimization, semi-infinite programming, and level method based ones are computationally most efficient.	[Bucak, Serhat S.; Jin, Rong; Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA; [Jain, Anil K.] Korea Univ, Dept Brain & Cognit Engn, Seoul, South Korea	Michigan State University; Korea University	Bucak, SS (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.	bucakser@cse.msu.edu; rongjin@cse.msu.edu; jain@cse.msu.edu	Jeong, Yongwook/N-7413-2016		US National Science Foundation [IIS-0643494]; U.S. Army Research (ARO) [W911NF-08-010403]; Office of Naval Research [ONR N00014-09-1-0663]	US National Science Foundation(National Science Foundation (NSF)); U.S. Army Research (ARO); Office of Naval Research(Office of Naval Research)	The authors would like to thank Z. Xu and P. Gehler for sharing their codes and data. This work was supported in part by the US National Science Foundation (IIS-0643494), and in part by the U.S. Army Research (ARO Award W911NF-08-010403) and the Office of Naval Research (ONR N00014-09-1-0663). Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of NFS, ARO, and ONR.	Aflalo J, 2011, J MACH LEARN RES, V12, P565; [Anonymous], 2010, ADV NEURAL INFORM PR; [Anonymous], 2006, ADV NEURAL INFORM PR; Bach F., 2005, P NIPS; Bach F., 2009, P NIPS; Bach F. R., 2004, P 21 ICML NEW YORK N; Bach FR, 2008, J MACH LEARN RES, V9, P1179; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Berg AC, 2001, PROC CVPR IEEE, P607; Bucak S., 2010, ADV NEURAL INFORM PR, P325; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chapelle O., 2003, ADV NEURAL INFORM PR; Chatfield K., 2011, P BMVC; Chen Q., 2010, P PASCAL VIS OBJ CLA; Cortes, 2009, NEURAL INF PROCESS S; Cortes C., 2010, P 27 ICML HAIF ISR; Cortes C., 2009, P C UNC ART INT; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Damoulas T, 2008, BIOINFORMATICS, V24, P1264, DOI 10.1093/bioinformatics/btn112; Dickinson S., 2009, OBJECT CATEGORIZATIO, P1; Do H, 2009, LECT NOTES ARTIF INT, V5781, P330; Everingham M., PASCAL VISUAL OBJECT; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Gehler P. V., 2009, P ICCV; Gehler P. V., 2009, P IEEE CVPR; Gonen M., 2008, P 25 ICML NEW YORK N; Gonen M, 2011, J MACH LEARN RES, V12, P2211; Grant M., 2013, CVX MATLAB SOFTWARE; Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Harzallah H, 2009, IEEE I CONF COMP VIS, P237, DOI 10.1109/ICCV.2009.5459257; Hertz T., 2006, THESIS HEBREW U JERU; Hoi S. C. H., 2008, P INT C MACH LEARN, P400, DOI DOI 10.1145/1390156.1390207; Hussain Z., 2011, ABS11066258 CORR; Ji S., 2009, P NIPS; Jie L., 2010, IEEE COMP SOC C COMP, P43; Jin R, 2010, LECT NOTES ARTIF INT, V6331, P390; Kloft M, 2011, J MACH LEARN RES, V12, P953; Kloft M, 2010, LECT NOTES ARTIF INT, V6322, P66, DOI 10.1007/978-3-642-15883-4_5; Kondor R.I., 2002, P 19 INT C MACHINE L, P315; Kowalski M., 2009, P 26 ANN INT C MACH, P545; Kulis B., 2006, P 23 INT C MACH LEAR, P505; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Lewis D. P., 2006, P 23 INT C MACH LEAR, P553, DOI DOI 10.1145/1143844.1143914; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Li FX, 2010, PROC CVPR IEEE, P1712, DOI 10.1109/CVPR.2010.5539839; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491, DOI 10.1109/TKDE.2005.66; Longworth C, 2008, INT CONF ACOUST SPEE, P1581, DOI 10.1109/ICASSP.2008.4517926; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Marius K., 2009, NIPS, P997; Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561; Nakajima S., 2009, IBIS2009; Nath J. Saketha, 2009, P NIPS; Nesterov Y., 2004, APPL OPTIM; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Oliveira GL, 2012, IEEE INT CONF ROBOT, P2592, DOI 10.1109/ICRA.2012.6224785; Perronnin F., 2010, P 11 ECCV HER GREEC; Perronnin F, 2010, PROC CVPR IEEE, P2297, DOI 10.1109/CVPR.2010.5539914; Person P. V. G., 2008, TR178 M PLANCK I BIO; Pinto N, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.0040027; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Ponce J, 2006, LECT NOTES COMPUT SC, V4170, P29; Rakotomamonjy A., 2007, P 24 ICML CORV OR US; Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491; Ren JT, 2010, LECT NOTES ARTIF INT, V6441, P63, DOI 10.1007/978-3-642-17313-4_7; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; Scholkopf B., 2001, LEARNING KERNELS SUP; Shechtman E., 2007, P CVPR, P607; Sindhwani V., 2011, P NIPS, P414; Song Z, 2011, PROC CVPR IEEE, P1585, DOI 10.1109/CVPR.2011.5995330; Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531; Sun Z., 2010, P ADV NEUR INF PROC, V23, P2361; Tahir M. A., 2008, P PASCAL VIS OBJ CLA; Tang L., 2009, P IJCAI; Tomioka R., 2009, P NIPS WORKSH UND MU; Tuzel O, 2007, PROC CVPR IEEE, P1736; van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334; Varma M., 2009, P 26 ANN INT C MACH, P1065; Varma M., 2007, P 11 IEEE ICCV RIO J; Vedaldi A., 2009, P 12 ICCV KYOT JAP; Wang Z, 2008, IEEE T PATTERN ANAL, V30, P348, DOI 10.1109/TPAMI.2007.70786; Xu Z., 2010, P AAAI ART INT; Xu Z., 2010, P 27 ICML HAIF ISR; Xu Z, 2009, ADV NEURAL INFORM PR, P1825; Yan F., 2009, P INT WORKSH CBMI; Yan F, 2010, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2010.5539916; Yang J., 2009, P 12 ICCV KYOT JAP; Yang JJ, 2010, EURASIP J IMAGE VIDE, DOI 10.1155/2010/461450; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhuang J., 2009, P 26 ICML MONTR QC C; Zien A., 2007, P 24 ICML CORV OR US	95	190	203	3	134	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2014	36	7					1354	1369		10.1109/TPAMI.2013.212	http://dx.doi.org/10.1109/TPAMI.2013.212			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AK1WS	26353308				2022-12-18	WOS:000338209900006
J	Shotton, J; Girshick, R; Fitzgibbon, A; Sharp, T; Cook, M; Finocchio, M; Moore, R; Kohli, P; Criminisi, A; Kipman, A; Blake, A				Shotton, Jamie; Girshick, Ross; Fitzgibbon, Andrew; Sharp, Toby; Cook, Mat; Finocchio, Mark; Moore, Richard; Kohli, Pushmeet; Criminisi, Antonio; Kipman, Alex; Blake, Andrew			Efficient Human Pose Estimation from Single Depth Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; machine learning; pixel classification; depth cues; range data; games	RECOGNITION	We describe two new approaches to human pose estimation. Both can quickly and accurately predict the 3D positions of body joints from a single depth image without using any temporal information. The key to both approaches is the use of a large, realistic, and highly varied synthetic set of training images. This allows us to learn models that are largely invariant to factors such as pose, body shape, field-of-view cropping, and clothing. Our first approach employs an intermediate body parts representation, designed so that an accurate per-pixel classification of the parts will localize the joints of the body. The second approach instead directly regresses the positions of body joints. By using simple depth pixel comparison features and parallelizable decision forests, both approaches can run super-real time on consumer hardware. Our evaluation investigates many aspects of our methods, and compares the approaches to each other and to the state of the art. Results on silhouettes suggest broader applicability to other imaging modalities.	[Shotton, Jamie; Sharp, Toby] Microsoft Res, Machine Learning & Percept Grp, Cambridge CB3 0FB, England; [Shotton, Jamie; Fitzgibbon, Andrew; Sharp, Toby; Cook, Mat; Kohli, Pushmeet; Criminisi, Antonio; Blake, Andrew] Microsoft Res, Cambridge CB3 0FB, England; [Girshick, Ross] Univ Calif Berkeley, EERES COENG Engn Res, Berkeley, CA 94720 USA; [Finocchio, Mark; Kipman, Alex] Microsoft Corp, Redmond, WA 98052 USA	Microsoft; Microsoft; University of California System; University of California Berkeley; Microsoft	Shotton, J (corresponding author), Microsoft Res, Machine Learning & Percept Grp, 7 JJ Thomson Ave, Cambridge CB3 0FB, England.	jamiesho@microsoft.com; ross.girshick@gmail.com; awf@microsoft.com; tsharp@microsoft.com; a-macook@microsoft.com; markfi@microsoft.com; richard.moore@stericsson.com; pkohli@microsoft.com; antcrim@microsoft.com; akipman@microsoft.com; ablake@microsoft.com						Agarwal A., 2004, P IEEE C COMP VIS PA; Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Anguelov D., 2005, P IEEE C COMP VIS PA; [Anonymous], KIN; [Anonymous], 2013, CMU MOC DAT; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Bregler C., 1998, P IEEE C COMP VIS PA; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Brubaker MA, 2010, INT J COMPUT VISION, V87, P140, DOI 10.1007/s11263-009-0274-5; Cipoll Roberto, 2008, PROC CVPR IEEE, P1; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Criminisi A., 2010, P INT MICCAI C MED C; Criminisil A, 2011, FOUND TRENDS COMPUT, V7, P81, DOI [10.1561/0600000035, 10.1501/0000000035]; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Fergus R, 2003, PROC CVPR IEEE, P264; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Gall J, 2009, PROC CVPR IEEE, P1746, DOI 10.1109/CVPRW.2009.5206755; Ganapathi V, 2010, P IEEE C COMP VIS PA; Gavrila D., 2000, P EUR C COMP VIS JUN; Girshick R., 2011, P IEEE INT C COMP VI; GONZALEZ TF, 1985, THEOR COMPUT SCI, V38, P293, DOI 10.1016/0304-3975(85)90224-5; Grest D., 2005, P 27 DAGM C PATT REC; Hastie T, 2009, ELEMENTS STAT LEARNI; Ioffe S, 2001, INT J COMPUT VISION, V43, P45, DOI 10.1023/A:1011179004708; Kalogerakis E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778839; Kanaujia A., 2007, P IEEE C COMP VIS PA, P1; Knoop S., 2006, P IEEE INT C ROB AUT; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Lepetit V, 2005, PROC CVPR IEEE, P775; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; Montillo A., 2011, P 22 INT C INF PROC; Moosmann F., 2006, NIPS, P985; Mori G., 2003, P IEEE INT C COMP VI; Muller J., 2010, P 1 ACM INT WORKSH A; Navaratnam R., 2007, P IEEE INT C COMP VI; Ning H., 2008, P IEEE C COMP VIS PA; Nowozin Sebastian, 2012, ICML 2012; Okada R., 2008, P 10 EUR C COMP VIS; Plagemann C., 2010, P IEEE INT C ROB AUT; Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; Ramanan D., 2003, P IEEE C COMP VIS PA; Rogez G, 2008, PROC CVPR IEEE, P2142; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; SHARP T, 2008, P EUR C COMP VIS; Shepherd B., 1983, P 8 INT JOINT C ART; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Siddiqui M., 2010, P IEEE C COMP VIS PA; Sidenbladh H., 2002, P 7 EUR C COMP VIS; Sigal L, 2004, PROC CVPR IEEE, P421; Tu Z., 2008, IEEE C COMP VIS PATT, P1; Urtasun R, 2008, PROC CVPR IEEE, P149; VITTER JS, 1985, ACM T MATH SOFTWARE, V11, P37, DOI 10.1145/3147.3165; Wang R., 2009, P ACM SIGGRAPH; Winn J., 2006, P IEEE C COMP VIS PA; Zhu Y., 2007, P 8 AS C COMP VIS	58	190	208	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2013	35	12					2821	2840		10.1109/TPAMI.2012.241	http://dx.doi.org/10.1109/TPAMI.2012.241			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	245YV	24136424				2022-12-18	WOS:000326502200002
J	Khan, SM; Shah, M				Khan, Saad M.; Shah, Mubarak			Tracking Multiple Occluding People by Localizing on Multiple Scene Planes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Tracking; sensor fusion; graph-theoretic methods		Occlusion and lack of visibility in crowded and cluttered scenes make it difficult to track individual people correctly and consistently, particularly in a single view. We present a multiview approach to solve this problem. In our approach, we neither detect nor track objects from any single camera or camera pair; rather, evidence is gathered from all of the cameras into a synergistic framework and detection and tracking results are propagated back to each view. Unlike other multiview approaches that require fully calibrated views, our approach is purely image-based and uses only 2D constructs. To this end, we develop a planar homographic occupancy constraint that fuses foreground likelihood information from multiple views to resolve occlusions and localize people on a reference scene plane. For greater robustness, this process is extended to multiple planes parallel to the reference plane in the framework of plane to plane homologies. Our fusion methodology also models scene clutter using the Schmieder and Weathersby clutter measure, which acts as a confidence prior, to assign higher fusion weight to views with lesser clutter. Detection and tracking are performed simultaneously by graph cuts segmentation of tracks in the space-time occupancy likelihood data. Experimental results with detailed qualitative and quantitative analysis are demonstrated in challenging multiview crowded scenes.	[Khan, Saad M.; Shah, Mubarak] Univ Cent Florida, Dept Elect Engn & Comp Sci, Orlando, FL 32816 USA	State University System of Florida; University of Central Florida	Khan, SM (corresponding author), Univ Cent Florida, Dept Elect Engn & Comp Sci, Orlando, FL 32816 USA.	skhan@sarnoff.com; shah@eecs.ucf.edu		Shah, Mubarak/0000-0001-6172-5572	US Government VACE program	US Government VACE program	The authors would like to thank Pavel Babenko for help in the GPU implementation. This research was funded in part by the US Government VACE program.	AZARBAYEJANI A, 1996, P 13 INT C PATT REC; Berclaz J., 2006, P IEEE C COMP VIS PA; BOUKOV Y, 2001, P 8 IEEE INT C COMP; BOYKOV Y, 2001, IEEE T PATTERN ANAL, V23; BROSTOW GJ, 2006, P IEEE C COMP VIS PA; CAI Q, 1998, P 6 IEEE INT C COMP; Chang T.-H., 2001, P IEEE WORKSH MULT T; CRIMINISI A, 1989, INT J COMPUTER VISIO; DARRELL T, 2001, P 8 IEEE INT C COMP; DOCKSTADER SL, 2001, P IEEE WORKSH MULT T; Elfes A., 1989, THESIS; Franco J., 2005, P 10 IEEE INT C COMP; Freedman D., 2005, P IEEE C COMP VIS PA; Gibson J., 1979, ECOLOGICAL APPROACH; Han M., 2004, P IEEE C COMP VIS PA; HARITAOGLU I, 2000, IEEE T PATTERN ANAL, V22; Hartley R., 2002, MULTIPLE VIEW GEOMET; Hu W., 2006, IEEE T PATTERN ANAL, V29; Huang Y., 2005, P IEEE C COMP VIS PA; ISARD M, 2001, P IEEE C COMP VIS PA; Jain R., 1995, P IEEE INT C MULT CO; JOJIC N, 2001, P IEEE C COMP VIS PA; KANG J, 2003, P IEEE C COMP VIS PA; KELLY P, 1995, P 3 ACM INT C MULT; Khan S., 2003, IEEE T PATTERN ANAL, V23; khan s.m., 2006, P 9 EUR C COMP VIS; KHAN Z, 2004, P 8 EUR C COMP VIS; Kim K., 2006, P 9 EUR C COMP VIS; KORNPROBST P, 2000, P IEEE C COMP VIS PA; KRUMM J, 2000, P 3 IEEE INT WORKSH; LOWE DG, 2004, INT J COMPUTER VISIO; LV F, 2002, P 16 INT C PATT REC; MacCormick J., 2000, INT J COMPUTER VISIO; Marr D., 1982, VISION COMPUTATIONAL; McKenna S. J., 2000, COMPUTER VISION IMAG; MITTAL A, 2002, INT J COMPUTER VISIO; Nakazawa A., 1998, P 14 INT C PATT REC; Neisser U., 1976, COGNITION REALITY PR; OKUMA K, 2004, P 8 EUR C COMP VIS; Orwell J., 1999, P IEEE INT C IM PROC; PARK S, 2006, P IEEE INT C INT SEC; PARK S, 2006, P 4 ACM INT WORKSH V; PERERA AGA, 2006, P IEEE C COMP VIS PA; POORE A, 1995, P DIMACS WORKSH; Reid D., 1979, IEEE T AUTOMATIC CON; ROSALES R, 1999, P IEEE C COMP VIS PA; Rother C., 2002, P 13 BRIT MACH VIS C; ROTMAN S, 1994, IEEE T AEROSPACE ELE; SATO K, 1994, P 2 IEEE CAD BAS VIS; SCHMIEDER D, 1983, IEEE T AEROSPACE ELE; SENIOR A, 2001, P 2 IEEE WORKSH PERF; SETHI IK, 1987, IEEE T PATTERN ANAL, V9; SIDENBLADH H, 2000, P 6 EUR C COMP VIS E; Stauffer C., 1999, P IEEE COMP SOC C CO, V2; TAO H, 2002, IEEE T PATTERN ANAL, V24; Thrun S., 2003, J AUTONOMOUS ROBOTS; Wren Christopher Richard, 1997, IEEE T PATTERN ANAL, V19; WU Y, 2003, P IEEE C COMP VIS PA; YANG DB, 2003, P 9 IEEE INT C COMP; YILMAZ A, 2006, ACM J COMPUTING SURV; YILMAZ A, 2004, IEEE T PATTERN ANAL, V26; ZHAO T, 2004, IEEE T PATTERN ANAL, V26; ZHAO T, 2004, P IEEE C COMP VIS PA	63	190	210	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2009	31	3					505	519		10.1109/TPAMI.2008.102	http://dx.doi.org/10.1109/TPAMI.2008.102			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	394VO	19147878				2022-12-18	WOS:000262480200009
J	HOFF, W; AHUJA, N				HOFF, W; AHUJA, N			SURFACES FROM STEREO - INTEGRATING FEATURE MATCHING, DISPARITY ESTIMATION, AND CONTOUR-DETECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV ILLINOIS, DEPT ELECT & COMP ENGN, URBANA, IL 61801 USA; UNIV ILLINOIS, COORDINATED SCI LAB, URBANA, IL 61801 USA	University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign	HOFF, W (corresponding author), MARTIN MARIETTA ASTRONAUT GRP, POB 179, DENVER, CO 80201 USA.							AYACHE N, 1985, JUN P COMP VIS PATT, P662; BAKER HH, 1981, AUG P INT JOINT C AR, P631; BARNARD ST, 1982, ACM COMPUT SURV, V14, P195; BOULT TE, 1988, JUN P IEEE C COMP VI, P177; BOYER KL, 1988, IEEE T PATTERN ANAL, V10, P144, DOI 10.1109/34.3880; BRADY M, 1982, PATTERN RECOGNITION; BRODATZ P, 1956, TEXTURES PHOTOGRAPHI; CLARK JJ, 1986, COMPUT VISION GRAPH, V35, P1, DOI 10.1016/0734-189X(86)90123-4; Duda R.O., 1973, J ROYAL STAT SOC SER; EASTMAN RD, 1987, COMPUT VISION GRAPH, V39, P73, DOI 10.1016/S0734-189X(87)80203-7; GILLAM B, 1984, PERCEPT PSYCHOPHYS, V36, P559, DOI 10.3758/BF03207516; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; GRIMSON WEL, 1981, IMAGES SURFACES; HOFF W, 1985, DEC P DARPA IM UND W, P98; HOFF W, 1987, 1ST P INT C COMP VIS, P284; HOFF WA, 1985, 4TH P SCAND C IM AN, P761; JULESZ B, 1971, F CYCLOPEAN PERCEPTI; Leclerc Y., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P46; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Marr D., 1982, VISION; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; MAYHEW JEW, 1980, PERCEPTION, V9, P69, DOI 10.1068/p090069; MEDIONI G, 1985, COMPUT VISION GRAPH, V31, P2, DOI 10.1016/S0734-189X(85)80073-6; Morevec H.P., 1977, INT JOINT C ART INT, V2, P584; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; Olsen S. J., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P1038; RICHARDS W, 1977, VISION RES, V17, P967, DOI 10.1016/0042-6989(77)90072-4; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; [No title captured]	30	190	215	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1989	11	2					121	136		10.1109/34.16709	http://dx.doi.org/10.1109/34.16709			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	R9989					2022-12-18	WOS:A1989R998900002
J	DAVIS, LS; JOHNS, SA; AGGARWAL, JK				DAVIS, LS; JOHNS, SA; AGGARWAL, JK			TEXTURE ANALYSIS USING GENERALIZED CO-OCCURRENCE MATRICES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV TEXAS,DEPT ELECT ENGN,AUSTIN,TX 78712; ABBOTT LABS,DALLAS,TX	University of Texas System; University of Texas Austin; Abbott Laboratories	DAVIS, LS (corresponding author), UNIV TEXAS,DEPT COMP SCI,AUSTIN,TX 78712, USA.							CHEN P, 1978, IEEE WORKSHOP PATTER; HANSON A, 1975, TR75C3 COMP INF SCI; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; KIRSCH R, 1971, COMPUT BIOMED RES, V4; MALESON JT, 1977, P DARPA IM UNDERST W, P19; MARR D, UNPUBLISHED; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; ZUCKER SW, 1975, IEEE T COMPUT, V24, P1228, DOI 10.1109/T-C.1975.224169	8	190	194	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	3					251	259		10.1109/TPAMI.1979.4766921	http://dx.doi.org/10.1109/TPAMI.1979.4766921			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC301	21868856				2022-12-18	WOS:A1979HC30100003
J	Kim, TK; Cipolla, R				Kim, Tae-Kyun; Cipolla, Roberto			Canonical Correlation Analysis of Video Volume Tensors for Action Categorization and Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action categorization; gesture recognition; canonical correlation analysis; tensor; action detection; incremental subspace learning; spatiotemporal pattern classification	RECOGNITION	This paper addresses a spatiotemporal pattern recognition problem. The main purpose of this study is to find a right representation and matching of action video volumes for categorization. A novel method is proposed to measure video-to-video volume similarity by extending Canonical Correlation Analysis (CCA), a principled tool to inspect linear relations between two sets of vectors, to that of two multiway data arrays ( or tensors). The proposed method analyzes video volumes as inputs avoiding the difficult problem of explicit motion estimation required in traditional methods and provides a way of spatiotemporal pattern matching that is robust to intraclass variations of actions. The proposed matching is demonstrated for action classification by a simple Nearest Neighbor classifier. We, moreover, propose an automatic action detection method, which performs 3D window search over an input video with action exemplars. The search is speeded up by dynamic learning of subspaces in the proposed CCA. Experiments on a public action data set (KTH) and a self-recorded hand gesture data showed that the proposed method is significantly better than various state-of-the-art methods with respect to accuracy. Our method has low time complexity and does not require any major tuning parameters.	[Kim, Tae-Kyun] Univ Cambridge, Sidney Sussex Coll, Cambridge CB2 3HU, England; [Cipolla, Roberto] Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England	University of Cambridge; University of Cambridge	Kim, TK (corresponding author), Univ Cambridge, Sidney Sussex Coll, Cambridge CB2 3HU, England.	tkk22@cam.ac.uk; cipolla@cam.ac.uk	Arandjelović, Ognjen/V-5255-2019	Arandjelović, Ognjen/0000-0002-9314-194X; Cipolla, Roberto/0000-0002-8999-2151	Sidney Sussex College, University of Cambridge; Toshiba Cambridge Studentship	Sidney Sussex College, University of Cambridge(University of Cambridge); Toshiba Cambridge Studentship	The work of Tae-Kyun Kim was supported by a research fellowship from Sidney Sussex College, University of Cambridge and by a Toshiba Cambridge Studentship. The authors are grateful to the anonymous reviewers for their constructive comments, Kil-Rye Lee for her help in the database annotation, Navid Mavaddat and Bjorn Stenger for their help in proofreading this work, and Shu-Fai Wong for his effort in the conference version.	Bach F. R., 2005, 688 TR U CAL DEP STA; BAUCKHAGE C, 2006, P IEEE C COMP VIS PA; BISSACCO A, 2001, P IEEE INT C COMP VI, P401; BJORCK A, 1973, MATH COMPUT, V27, P579, DOI 10.2307/2005662; BLACK MJ, 1999, P INT C CVPR, P1326; Blank M, 2005, IEEE I CONF COMP VIS, P1395; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; EFROS AA, 2003, P 9 IEEE INT C COMP; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Hall P, 2000, IEEE T PATTERN ANAL, V22, P1042, DOI 10.1109/34.877525; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; HARSHMAN R, 2006, 34 ANN M STAT SOC CA; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Ke Y, 2005, IEEE I CONF COMP VIS, P166; Kim T.-K., 2007, P IEEE C COMP VIS PA; Kim TK, 2007, LECT NOTES COMPUT SC, V4843, P335; Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MARTIN CDM, 2004, P TENS DEC WORKSH; Niebles J.C., 2007, P IEEE C COMP VIS PA; Niebles J. C., 2006, P BRIT MACH VIS C; Parameswaran V, 2005, COMPUT VIS IMAGE UND, V98, P295, DOI 10.1016/j.cviu.2004.09.002; Ramanan D., 2004, P ADV NEUR INF PROC; Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748; Saisan P, 2001, PROC CVPR IEEE, P58; SAVARESE S, 2007, 2D 3D SPATIAL REASON; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Shechtman E, 2005, PROC CVPR IEEE, P405; Skocaj D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1494; Vasilescu MAO, 2002, INT C PATT RECOG, P456, DOI 10.1109/ICPR.2002.1047975; VASILESCU MAO, 2002, P 7 EUR C COMP VIS; Vaswani N, 2005, IEEE T IMAGE PROCESS, V14, P1603, DOI 10.1109/TIP.2005.852197; Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246; VEERARAGHAVAN A, 2006, P IEEE C COMP VIS PA; WANG H, 2006, P IEEE C COMP VIS PA; WANG S, 2006, P IEEE C COMP VIS PA; WOLF L, 2003, P IEEE C COMP VIS PA; Wolf L., 2007, P IEEE C COMP VIS PA; Wong S., 2007, P IEEE C COMP VIS PA; WONG SF, 2005, P BRIT MACH VIS C, P379; Yamaguchi O, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P318, DOI 10.1109/AFGR.1998.670968; YAN S, 2005, P IEEE C COMP VIS PA; Yimaz A, 2006, COMPUT VIS IMAGE UND, V104, P221, DOI 10.1016/j.cviu.2006.07.012	45	189	195	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2009	31	8					1415	1428		10.1109/TPAMI.2008.167	http://dx.doi.org/10.1109/TPAMI.2008.167			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	458UN	19542576				2022-12-18	WOS:000267050600006
J	Learned-Miller, EG				Learned-Miller, EG			Data driven image models through continuous joint alignment	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						alignment; artifact removal; bias removal; congealing; clustering; correspondence; density estimation; entropy; maximum likelihood; medical imaging; magnetic resonance imaging; nonparametric statistics; registration; unsupervised learning		This paper presents a family of techniques that we call congealing for modeling image classes from data. The idea is to start with a set of images and make them appear as similar as possible by removing variability along the known axes of variation. This technique can be used to eliminate "nuisance" variables such as affine deformations from handwritten digits or unwanted bias fields from magnetic resonance images. In addition to separating and modeling the latent images-i.e., the images without the nuisance variables-we can model the nuisance variables themselves, leading to factorized generative image models. When nuisance variable distributions are shared between classes, one can share the knowledge learned in one task with another task, leading to efficient learning. We demonstrate this process by building a handwritten digit classifier from just a single example of each class. In addition to applications in handwritten character recognition, we describe in detail the application of bias removal from magnetic resonance images. Unlike previous methods, we use a separate, nonparametric model for the intensity values at each pixel. This allows us to leverage the data from the MR images of different patients to remove bias from each other. Only very weak assumptions are made about the distributions of intensity values in the images. In addition to the digit and MR applications, we discuss a number of other uses of congealing and describe experiments about the robustness and consistency of the method.	Univ Massachusetts, Dept Comp Sci, Amherst, MA 01003 USA	University of Massachusetts System; University of Massachusetts Amherst	Learned-Miller, EG (corresponding author), Univ Massachusetts, Dept Comp Sci, 140 Governors Dr, Amherst, MA 01003 USA.	elm@cs.umass.edu			NATIONAL CENTER FOR RESEARCH RESOURCES [P41RR013218] Funding Source: NIH RePORTER; NCRR NIH HHS [P41 RR013218, P41 RR13218] Funding Source: Medline	NATIONAL CENTER FOR RESEARCH RESOURCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR)); NCRR NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR))		Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; Fan A., 2003, THESIS MIT; Frey BJ, 2003, IEEE T PATTERN ANAL, V25, P1, DOI 10.1109/TPAMI.2003.1159942; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; MILLER E, 2002, THESIS MIT; MILLER E, 2000, P IEEE COMP VIS PATT; Miller E G L, 2003, J MACHINE LEARNING R, V4, P1271; MILLER EG, 2003, P IEEE COMP VIS PATT; Revow M, 1996, IEEE T PATTERN ANAL, V18, P592, DOI 10.1109/34.506410; VASICEK O, 1976, J R STAT SOC B, V38, P54; VIOLA P, 1995, THESIS MIT; VIOLA P, 1997, INT J COMPUTER VISIO; Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747	15	189	193	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2006	28	2					236	250		10.1109/TPAMI.2006.34	http://dx.doi.org/10.1109/TPAMI.2006.34			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	991OY	16468620	Green Submitted			2022-12-18	WOS:000233824500006
J	Feraud, R; Bernier, OJ; Viallet, JE; Collobert, M				Feraud, R; Bernier, OJ; Viallet, JE; Collobert, M			A fast and accurate face detector based on neural networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						combination of models; face detection; generative models; machine learning; neural networks; projection	PRINCIPAL COMPONENT ANALYSIS	Detecting faces in images with complex backgrounds is a difficult task. Our approach, which obtains state of the art results, is based on a new neural network model: the Constrained Generative Model (CGM). Generative, since the goal of the learning process is to evaluate the probability that the model has generated the input data, and constrained since some counterexamples are used to increase the quality of the estimation performed by the model. To detect side view faces and to decrease the number of false alarms, a conditional mixture of networks is used. To decrease the computational time cost, a fast search algorithm is proposed. The level of performance reached, in terms of detection accuracy and processing time, allows to apply this detector to a real world application: the indexation of images and videos.	France Telecom, R&D DLT DLI, Technopole Anticipa, F-22307 Lannion, France	Orange SA	Feraud, R (corresponding author), France Telecom, R&D DLT DLI, Technopole Anticipa, 2 Ave Pierre Marzin, F-22307 Lannion, France.	raphael.feraud@francetelecom.fr; olivier.bernier@francetelecom.fr; jeanemmanuel.viallet@francetelecom.fr; michel.collobert@francetelecom.fr						BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2; BARON RJ, 1981, INT J MAN MACH STUD, V15, P137, DOI 10.1016/S0020-7373(81)80001-6; BENYACOUB S, 1997, FAST OBJECT DETECTIO; Beymer D. J., 1993, FACE RECOGNITION VAR; BOUATTOUR H, 1992, ARTIFICIAL NEURAL NETWORKS, 2, VOLS 1 AND 2, P1595; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; COLLOBERT M, 1996, P 2 INT C AUT FAC GE; Colmenarez A. J., 1998, FACE DETECTION RECOG, P174; COTTRELL GW, 1988, SPIE VISUAL COMMUNIC, V101, P1070; DUCHNOWSKI P, 1995, P INT C AC SPEECH SI; FERAUD R, 1997, NEURAL INFORMATION P, V10; FERAUD R, 1998, FACE RECOGNITION THE, V163, P424; Fleming M. K., 1990, IJCNN International Joint Conference on Neural Networks (Cat. No.90CH2879-5), P65, DOI 10.1109/IJCNN.1990.137696; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Golomb BA, 1991, ADV NEURAL INFORMATI, V1, P572; Hoogenboom R, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P334, DOI 10.1109/AFGR.1996.557287; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Huang J, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P248, DOI 10.1109/AFGR.1996.557272; HUNKE HM, 1994, CS94155 CMU; Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79; KANADE T, 1973, PICTURE PROCESSING C; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; MAIO D, 1998, FAST FACE LOCATION C; Manjunath B. S., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P373, DOI 10.1109/CVPR.1992.223162; MOGHADDAM B, 1995, P 5 INT C COMP VIS J; OBERNIER O, 1998, P INT C IM PROC; Osuna E, 1997, COMPUTER VISION PATT; Papageorgiou C., 1998, P INT C COMP VIS; ROWLEY H, 1995, NEURAL INFORMATION P, V8; Rowley H.A., 1998, IEEE T PATTERN ANAL; SEGUIER R, 1995, P 7 PROT PATT REC; Sung K.-K., 1994, EXAMPLE BASED LEARNI; SWAIN MJ, 1997, COMPUTER VISION PATT; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; VAILLANT R, 1994, IEE P VISUAL IMAGE S, V141, P572; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; VIENNET E, 1992, ARTIFICIAL NEURAL NETWORKS, 2, VOLS 1 AND 2, P1599; Yow KC, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P295, DOI 10.1109/AFGR.1996.557280; Yuille A. L., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P104, DOI 10.1109/CVPR.1989.37836; 1986, PRINCIPAL COMPONENT	40	189	239	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2001	23	1					42	53		10.1109/34.899945	http://dx.doi.org/10.1109/34.899945			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	390VA					2022-12-18	WOS:000166316700004
J	SAMET, H; TAMMINEN, M				SAMET, H; TAMMINEN, M			EFFICIENT COMPONENT LABELING OF IMAGES OF ARBITRARY DIMENSION REPRESENTED BY LINEAR BINTREES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									HELSINKI UNIV TECHNOL,INFORMAT PROC SCI LAB,SF-02150 ESPOO 15,FINLAND	Aalto University	SAMET, H (corresponding author), UNIV MARYLAND,DEPT COMP SCI,COLLEGE PK,MD 20742, USA.							DYER CR, 1980, COMPUT VISION GRAPH, V13, P270, DOI 10.1016/0146-664X(80)90050-7; GARGANTINI I, 1982, COMMUN ACM, V25, P905, DOI 10.1145/358728.358741; HUNTER GM, 1978, THESIS PRINCETON U P; JACKINS CL, 1983, IEEE T PATTERN ANAL, V5, P533, DOI 10.1109/TPAMI.1983.4767433; JACKINS CL, 1980, COMPUT VISION GRAPH, V14, P249, DOI 10.1016/0146-664X(80)90055-6; KAWAGUCHI E, 1980, IEEE T PATTERN ANAL, V2, P27, DOI 10.1109/TPAMI.1980.4766967; KLINGER A, 1971, OPTIMIZING METHODS S, P303; LUMIA R, 1983, COMPUT VISION GRAPH, V23, P207, DOI 10.1016/0734-189X(83)90113-5; MEAGHER D, 1982, COMPUT VISION GRAPH, V19, P129, DOI 10.1016/0146-664X(82)90104-6; Minsky M., 1969, PERCEPTRONS INTRO CO, DOI 10.7551/mitpress/11301.001.0001; ROSENFEL.A, 1966, J ACM, V13, P471; SAMET H, 1981, J ACM, V28, P487, DOI 10.1145/322261.322267; Samet H., 1985, IEEE T PATTERN ANAL, V7; SAMET H, TR1237 U MAR COMP SC; SAMET H, 1986, JUN P COMP VIS PATT, P312; TAMMINEN M, 1984, COMMUN ACM, V27, P248, DOI 10.1145/357994.358026; TAMMINEN M, 1984, JUL P SIGGRAPH 84 C, P43; TARJAN RE, 1984, J ACM, V31, P245, DOI 10.1145/62.2160; TARJAN RE, 1975, J ACM, V22, P215, DOI 10.1145/321879.321884; YAU MM, 1983, COMMUN ACM, V26, P504, DOI 10.1145/358150.358158; [No title captured], DOI DOI 10.1145/356924.356930	21	189	204	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1988	10	4					579	586		10.1109/34.3918	http://dx.doi.org/10.1109/34.3918			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	P1493					2022-12-18	WOS:A1988P149300011
J	Yang, Y; Sun, J; Li, HB; Xu, ZB				Yang, Yan; Sun, Jian; Li, Huibin; Xu, Zongben			ADMM-CSNet: A Deep Learning Approach for Image Compressive Sensing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image reconstruction; Transforms; Imaging; Task analysis; Computer architecture; Data models; Compressive sensing; deep learning; MR imaging; ADMM; ADMM-CSNet	GENERATIVE ADVERSARIAL NETWORKS; SIGNAL RECOVERY; THRESHOLDING ALGORITHM; SPARSE REPRESENTATION; MRI RECONSTRUCTION; INVERSE PROBLEMS; LOW-RANK; CNN	Compressive sensing (CS) is an effective technique for reconstructing image from a small amount of sampled data. It has been widely applied in medical imaging, remote sensing, image compression, etc. In this paper, we propose two versions of a novel deep learning architecture, dubbed as ADMM-CSNet, by combining the traditional model-based CS method and data-driven deep learning method for image reconstruction from sparsely sampled measurements. We first consider a generalized CS model for image reconstruction with undetermined regularizations in undetermined transform domains, and then two efficient solvers using Alternating Direction Method of Multipliers (ADMM) algorithm for optimizing the model are proposed. We further unroll and generalize the ADMM algorithm to be two deep architectures, in which all parameters of the CS model and the ADMM algorithm are discriminatively learned by end-to-end training. For both applications of fast CS complex-valued MR imaging and CS imaging of real-valued natural images, the proposed ADMM-CSNet achieved favorable reconstruction accuracy in fast computational speed compared with the traditional and the other deep learning methods.	[Yang, Yan; Sun, Jian; Li, Huibin; Xu, Zongben] Xi An Jiao Tong Univ, Sch Math & Stat, Inst Informat & Syst Sci, Xian 710049, Shaanxi, Peoples R China	Xi'an Jiaotong University	Sun, J (corresponding author), Xi An Jiao Tong Univ, Sch Math & Stat, Inst Informat & Syst Sci, Xian 710049, Shaanxi, Peoples R China.	yangyan92@stu.xjtu.edu.cn; jiansun@mail.xjtu.edu.cn; huibinli@mail.xjtu.edu.cn; zbxu@mail.xjtu.edu.cn		Sun, Jian/0000-0001-7206-0641	National Natural Science Foundation of China [11622106, 11690011, 61721002, 61472313]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work is supported by National Natural Science Foundation of China under Grants 11622106, 11690011, 61721002, 61472313. The authors would like to thank Prof. Dong Liang at Shenzhen Institutes ofAdvanced Technology for providing the brainMRI data used in the experiments.	Adler J, 2018, IEEE T MED IMAGING, V37, P1322, DOI 10.1109/TMI.2018.2799231; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], [No title captured]; [Anonymous], 2016, ADV NEUR IN; [Anonymous], 2010, P INT C MACH LEARN; [Anonymous], [No title captured]; Bajwa WU, 2007, 2007 IEEE/SP 14TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING, VOLS 1 AND 2, P294, DOI 10.1109/SSP.2007.4301266; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bernstein MA, 2001, J MAGN RESON IMAGING, V14, P270, DOI 10.1002/jmri.1183; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; BYRD RH, 1995, SIAM J SCI COMPUT, V16, P1190, DOI 10.1137/0916069; Candes EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Candes EJ, 2015, APPL COMPUT HARMON A, V39, P277, DOI 10.1016/j.acha.2014.09.004; Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1; Chen H, 2017, IEEE T MED IMAGING, V36, P2524, DOI 10.1109/TMI.2017.2715284; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Do TT, 2012, IEEE T SIGNAL PROCES, V60, P139, DOI 10.1109/TSP.2011.2170977; Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100; Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730; Eksioglu EM, 2016, J MATH IMAGING VIS, V56, P430, DOI 10.1007/s10851-016-0647-7; Gupta H, 2018, IEEE T MED IMAGING, V37, P1440, DOI 10.1109/TMI.2018.2832656; Hammernik K, 2018, MAGN RESON MED, V79, P3055, DOI 10.1002/mrm.26977; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; He LH, 2009, IEEE T SIGNAL PROCES, V57, P3488, DOI 10.1109/TSP.2009.2022003; Hitomi Y, 2011, IEEE I CONF COMP VIS, P287, DOI 10.1109/ICCV.2011.6126254; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Iliadis M, 2018, DIGIT SIGNAL PROCESS, V72, P9, DOI 10.1016/j.dsp.2017.09.010; Jia Y., 2014, P 22 ACM INT C MULT, P675; Jiang H, 2012, INVERSE PROBL IMAG, V6, P201, DOI 10.3934/ipi.2012.6.201; Jin KH, 2017, IEEE T IMAGE PROCESS, V26, P4509, DOI 10.1109/TIP.2017.2713099; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kulkarni K, 2016, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2016.55; Lai ZY, 2016, MED IMAGE ANAL, V27, P93, DOI 10.1016/j.media.2015.05.012; Lee D, 2017, I S BIOMED IMAGING, P15, DOI 10.1109/ISBI.2017.7950457; Li C., 2009, CAAM REPORT; Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391; Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828; Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452; Mardani M, 2019, IEEE T MED IMAGING, V38, P167, DOI 10.1109/TMI.2018.2858752; Metzler CA, 2017, ADV NEUR IN, V30; Metzler CA, 2016, IEEE T INFORM THEORY, V62, P5117, DOI 10.1109/TIT.2016.2556683; Mousavi A, 2017, INT CONF ACOUST SPEE, P2272, DOI 10.1109/ICASSP.2017.7952561; Mousavi A, 2015, ANN ALLERTON CONF, P1336, DOI 10.1109/ALLERTON.2015.7447163; Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002; Peng X, 2015, MAGN RESON MED, V73, P1490, DOI 10.1002/mrm.25272; Pfister L, 2015, PROC SPIE, V9597, DOI 10.1117/12.2188663; Qu XB, 2014, MED IMAGE ANAL, V18, P843, DOI 10.1016/j.media.2013.09.007; Qu XB, 2012, MAGN RESON IMAGING, V30, P964, DOI 10.1016/j.mri.2012.02.019; Ravishankar S, 2017, IEEE T MED IMAGING, V36, P1116, DOI 10.1109/TMI.2017.2650960; Ravishankar S, 2011, IEEE T MED IMAGING, V30, P1028, DOI 10.1109/TMI.2010.2090538; Schlemper J, 2017, LECT NOTES COMPUT SC, V10265, P647, DOI 10.1007/978-3-319-59050-9_51; Schmidt U, 2014, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2014.349; Sun JC, 2011, IEEE INT C BIO BIO W, P274, DOI 10.1109/BIBMW.2011.6112387; Wang SS, 2016, I S BIOMED IMAGING, P514, DOI 10.1109/ISBI.2016.7493320; Wang SY, 2016, INT J DISTRIB SENS N, DOI 10.1155/2016/3159805; Wang Y, 2019, J SCI COMPUT, V78, P29, DOI 10.1007/s10915-018-0757-z; Wang ZY, 2016, AAAI CONF ARTIF INTE, P2194; Wolterink JM, 2017, IEEE T MED IMAGING, V36, P2536, DOI 10.1109/TMI.2017.2708987; Xin B, 2016, ADV NEUR IN, V29; Yang G, 2018, IEEE T MED IMAGING, V37, P1310, DOI 10.1109/TMI.2017.2785879; Yang JF, 2010, IEEE J-STSP, V4, P288, DOI 10.1109/JSTSP.2010.2042333; Zhan ZF, 2016, IEEE T BIO-MED ENG, V63, P1850, DOI 10.1109/TBME.2015.2503756; Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206; Zhu L, 2018, INVEST RADIOL, V53, P150, DOI 10.1097/RLI.0000000000000421; Zibulevsky M, 2010, IEEE SIGNAL PROC MAG, V27, P76, DOI 10.1109/MSP.2010.936023	70	188	200	53	271	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2020	42	3					521	538		10.1109/TPAMI.2018.2883941	http://dx.doi.org/10.1109/TPAMI.2018.2883941			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LC5KN	30507495				2022-12-18	WOS:000525365300001
J	He, R; Zheng, WS; Tan, TN; Sun, ZA				He, Ran; Zheng, Wei-Shi; Tan, Tieniu; Sun, Zhenan			Half-Quadratic-Based Iterative Minimization for Robust Sparse Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						l(1)-minimization; half-quadratic optimization; sparse representation; M-estimator; correntropy	FACE RECOGNITION; SIGNAL RECOVERY; IMAGE; RECONSTRUCTION; CORRENTROPY; ALGORITHMS; CRITERIA; LASSO	Robust sparse representation has shown significant potential in solving challenging problems in computer vision such as biometrics and visual surveillance. Although several robust sparse models have been proposed and promising results have been obtained, they are either for error correction or for error detection, and learning a general framework that systematically unifies these two aspects and explores their relation is still an open problem. In this paper, we develop a half-quadratic ( HQ) framework to solve the robust sparse representation problem. By defining different kinds of half-quadratic functions, the proposed HQ framework is applicable to performing both error correction and error detection. More specifically, by using the additive form of HQ, we propose an l(1)-regularized error correction method by iteratively recovering corrupted data from errors incurred by noises and outliers; by using the multiplicative form of HQ, we propose an l(1)-regularized error detection method by learning from uncorrupted data iteratively. We also show that the l(1)-regularization solved by soft-thresholding function has a dual relationship to Huber M-estimator, which theoretically guarantees the performance of robust sparse representation in terms of M-estimation. Experiments on robust face recognition under severe occlusion and corruption validate our framework and findings.	[He, Ran; Tan, Tieniu; Sun, Zhenan] Chinese Acad Sci, Ctr Res Intelligent Percept & Comp CRIPAC, Beijing 100190, Peoples R China; [He, Ran; Tan, Tieniu; Sun, Zhenan] Chinese Acad Sci, NLPR, Inst Automat, Beijing 100190, Peoples R China; [Zheng, Wei-Shi] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510260, Guangdong, Peoples R China	Chinese Academy of Sciences; Chinese Academy of Sciences; Institute of Automation, CAS; Sun Yat Sen University	He, R (corresponding author), Chinese Acad Sci, Ctr Res Intelligent Percept & Comp CRIPAC, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.	rhe@nlpr.ia.ac.cn; wszheng@ieee.org; tnt@nlpr.ia.ac.cn; znsun@nlpr.ia.ac.cn	Zheng, Wei-Shi/J-7661-2016	Zheng, Wei-Shi/0000-0001-8327-0003; Wang, Yunlong/0000-0002-3535-308X	National Basic Research Program of China [2012CB316300]; National Natural Science Foundation of China; Chinese Academy of Sciences [XDA06030300]	National Basic Research Program of China(National Basic Research Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Chinese Academy of Sciences(Chinese Academy of Sciences)	The authors would like to greatly thank the associate editor and the reviewers for their valuable comments and advice, and Prof. Liang Wang, Dr. Xiao-Tong Yuan, and Mr. Bo Dai for helping to revise the paper. This work was funded by the National Basic Research Program of China (grant no. 2012CB316300), National Natural Science Foundation of China, and the Strategic Priority Research Program of the Chinese Academy of Sciences (grant no. XDA06030300).	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Allain M, 2006, IEEE T IMAGE PROCESS, V15, P1130, DOI 10.1109/TIP.2005.864173; Bajwa W, 2006, P INT C INF PROC SEN; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319; Boyd S, 2004, CONVEX OPTIMIZATION; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Candes EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x; Champagnat F, 2004, IEEE SIGNAL PROC LET, V11, P709, DOI 10.1109/LSP.2004.833511; Chartrand R, 2008, INT CONF ACOUST SPEE, P3869, DOI 10.1109/ICASSP.2008.4518498; Chartrand R, 2007, IEEE SIGNAL PROC LET, V14, P707, DOI 10.1109/LSP.2007.898300; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S1064827596304010; Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764; Combettes P.L., 2007, SIAM J OPTIMIZ, V18, P1531; Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Daubechies I, 2010, COMMUN PUR APPL MATH, V63, P1, DOI 10.1002/cpa.20303; Davis G, 1997, CONSTR APPROX, V13, P57, DOI 10.1007/BF02678430; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; Donoghue D, 2006, NY TIMES BK REV, P16; Donoho D, 2009, PHILOS T R SOC A, V367, P4273, DOI 10.1098/rsta.2009.0152; Donoho DL, 2008, IEEE T INFORM THEORY, V54, P4789, DOI 10.1109/TIT.2008.929958; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Fadili M., 2006, ASTRONOMICAL DATA AN; Fidler S, 2006, IEEE T PATTERN ANAL, V28, P337, DOI 10.1109/TPAMI.2006.46; Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281; Fornasier M., 2010, RADON SERIES COMPUTA, P1; GEMAN D, 1995, IEEE T IMAGE PROCESS, V4, P932, DOI 10.1109/83.392335; GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; He R., P IEEE C COMP VIS PA, P2504; He R, 2011, NEURAL COMPUT, V23, P2074, DOI 10.1162/NECO_a_00155; He R, 2011, IEEE T PATTERN ANAL, V33, P1561, DOI 10.1109/TPAMI.2010.220; Hellier P., 2000, P IEEE C COMP VIS PA; Idier J, 2001, IEEE T IMAGE PROCESS, V10, P1001, DOI 10.1109/83.931094; Jenatton Rodolphe, 2010, P 13 INT C ART INT S, P366; Jia HJ, 2009, PROC CVPR IEEE, P136, DOI 10.1109/CVPRW.2009.5206862; Lee H, 2016, ADV NEURAL INFORM PR, V19; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Li SZ, 1998, PROC CVPR IEEE, P839, DOI 10.1109/CVPR.1998.698702; Li XX, 2013, IEEE T IMAGE PROCESS, V22, P1889, DOI 10.1109/TIP.2013.2237920; Liu WF, 2007, IEEE T SIGNAL PROCES, V55, P5286, DOI 10.1109/TSP.2007.896065; Mairal J, 2008, MULTISCALE MODEL SIM, V7, P214, DOI 10.1137/070697653; Martinez A. M., 1998, TECHNICAL REPORT; Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128; Nguyen NH, 2013, IEEE T INFORM THEORY, V59, P2036, DOI 10.1109/TIT.2012.2232347; Nguyen NH, 2013, IEEE T INFORM THEORY, V59, P2017, DOI 10.1109/TIT.2013.2240435; Nikolova M, 2005, SIAM J SCI COMPUT, V27, P937, DOI 10.1137/030600862; Nowak RD, 2001, CONF REC ASILOMAR C, P371, DOI 10.1109/ACSSC.2001.986953; Plumbley MD, 2006, LECT NOTES COMPUT SC, V3889, P206; Principe J., 2000, UNSUPERVISED ADAPTIV, V1; Ragheb T., 2007, 50 MIDW S CIRC SYST, P325; Ran He, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2889, DOI 10.1109/CVPR.2011.5995328; Seth S, 2008, INT CONF ACOUST SPEE, P3845, DOI 10.1109/ICASSP.2008.4518492; Shi QF, 2011, PROC CVPR IEEE, P553, DOI 10.1109/CVPR.2011.5995556; Sun X., 2001, MATRIX PERTURBATION; Takhar D, 2006, PROC SPIE, V6065, DOI 10.1117/12.659602; Vaiter S, 2013, IEEE T INFORM THEORY, V59, P2001, DOI 10.1109/TIT.2012.2233859; Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112; Wakin MB, 2006, IEEE IMAGE PROC, P1273, DOI 10.1109/ICIP.2006.312577; Wright J, 2010, IEEE T INFORM THEORY, V56, P3540, DOI 10.1109/TIT.2010.2048473; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Wright S., 2008, P IEEE C AC SPEECH S; Yang A.Y., 2010, P INT C IM PROC; Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393; Yin WT, 2008, SIAM J IMAGING SCI, V1, P143, DOI 10.1137/070703983; Yuan X., 2009, P 26 ANN INT C MACH, P1193; Yuan X., 2007, P IEEE INT C COMP VI; Zhang L., 2011, P IEEE INT C COMP VI; Zhang T., 2008, P NEUR INF PROC SYST, P16; Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2; Zou H, 2006, J AM STAT ASSOC, V101, P1418, DOI 10.1198/016214506000000735	76	188	201	4	67	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2014	36	2					261	275		10.1109/TPAMI.2013.102	http://dx.doi.org/10.1109/TPAMI.2013.102			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	278OL	24356348				2022-12-18	WOS:000328899500005
J	Hoffbeck, JP; Landgrebe, DA				Hoffbeck, JP; Landgrebe, DA			Covariance matrix estimation and classification with limited training data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						covariance matrix; estimation; leave-one-out method; cross validation; classification; high dimensional data		A new covariance matrix estimator useful for designing classifiers with limited training data is developed. In experiments, this estimator achieved higher classification accuracy than the sample covariance matrix and common covariance matrix estimates. In about half of the experiments, it achieved higher accuracy than regularized discriminant analysis, but required much less computation.	PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907	Purdue University System; Purdue University; Purdue University West Lafayette Campus	Hoffbeck, JP (corresponding author), AT&T BELL LABS,67 WHIPPANY RD,WHIPPANY,NJ 07981, USA.							Anderson T. W., 1984, INTRO MULTIVARIATE S, P209; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; FUKUNAGA K, 1990, INTRO STAT PATTERN R, P38; Golub GH, 1989, MATRIX COMPUTATIONS, P51; HOFFBECK JP, THESIS PURDUE U W LA, P55; Sorenson H. W., 1980, PARAMETER ESTIMATION, P183	6	188	195	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1996	18	7					763	767		10.1109/34.506799	http://dx.doi.org/10.1109/34.506799			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UZ457					2022-12-18	WOS:A1996UZ45700009
J	Long, MS; Cao, Y; Cao, ZJ; Wang, JM; Jordan, M				Long, Mingsheng; Cao, Yue; Cao, Zhangjie; Wang, Jianmin; Jordan, Michael			Transferable Representation Learning with Deep Adaptation Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Kernel; Adaptation models; Convolutional neural networks; Gallium nitride; Testing; Domain adaptation; deep learning; convolutional neural network; two-sample test; multiple kernel learning	KERNEL	Domain adaptation studies learning algorithms that generalize across source domains and target domains that exhibit different distributions. Recent studies reveal that deep neural networks can learn transferable features that generalize well to similar novel tasks. However, as deep features eventually transition from general to specific along the network, feature transferability drops significantly in higher task-specific layers with increasing domain discrepancy. To formally reduce the effects of this discrepancy and enhance feature transferability in task-specific layers, we develop a novel framework for deep adaptation networks that extends deep convolutional neural networks to domain adaptation problems. The framework embeds the deep features of all task-specific layers into reproducing kernel Hilbert spaces (RKHSs) and optimally matches different domain distributions. The deep features are made more transferable by exploiting low-density separation of target-unlabeled data in very deep architectures, while the domain discrepancy is further reduced via the use of multiple kernel learning that enhances the statistical power of kernel embedding matching. The overall framework is cast in a minimax game setting. Extensive empirical evidence shows that the proposed networks yield state-of-the-art results on standard visual domain-adaptation benchmarks.	[Long, Mingsheng; Cao, Yue; Cao, Zhangjie; Wang, Jianmin] Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China; [Jordan, Michael] Univ Calif Berkeley, Dept EECS, Dept Stat, Berkeley, CA 94720 USA	Tsinghua University; University of California System; University of California Berkeley	Wang, JM (corresponding author), Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.	mingsheng@tsinghua.edu.cn; yue-cao14@mails.tsinghua.edu.cn; caozj14@mails.tsinghua.edu.cn; jimwang@tsinghua.edu.cn; jordan@berkeley.edu	wang, jian/GVS-0711-2022; Jordan, Michael I/C-5253-2013	Jordan, Michael/0000-0001-8935-817X	National Key R&D Program of China [2016YFB1000701]; National Natural Science Foundation of China [61772299, 71690231, 61502265]; DARPA Program on Lifelong Learning Machines	National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); DARPA Program on Lifelong Learning Machines	This work was supported by National Key R&D Program of China (No. 2016YFB1000701), the National Natural Science Foundation of China (No. 61772299, 71690231, 61502265) and the DARPA Program on Lifelong Learning Machines.	Ajakan H., 2014, P NIPS WORKSH TRANSF; [Anonymous], [No title captured]; Ben-David S., 2007, ADV NEURAL INFORM PR, V19, P137; Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18; Chapelle O., 2006, IEEE T NEURAL NETWOR, V20, P542; Chwialkowski K.P., 2015, P 28 INT C NEUR INF, P1981; Collobert R, 2011, J MACH LEARN RES, V12, P2493; Donahue J, 2014, PR MACH LEARN RES, V32; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114; Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368; Fukumizu K., 2009, ADV NEURAL INFORM PR, P1750; Ganin Y, 2016, J MACH LEARN RES, V17; Ganin Yaroslav, 2015, ICML; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Glorot Xavier, 2011, P 28 INT C MACH LEAR, P513, DOI DOI 10.1177/1753193411430810; Gong B., 2013, INT CONF COMPUTAT; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Grandvalet Yves, 2004, NIPS, P529; Gretton A, 2012, ADV NEURAL INF PROCE; Gretton A, 2012, J MACH LEARN RES, V13, P723; Griffin Gregory, 2007, CALTECH 256 OBJECT C; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Hinton GE, 2012, IMPROVING NEURAL NET, DOI DOI 10.9774/GLEAF.978-1-909493-38-4_2; Hoffman Judy, 2014, NIPS; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jitkrittum W., 2016, ADV NEURAL INFORM PR, P181; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167; Liu Ming-Yu, 2016, ADV NEURAL INFORM PR, P2; Long MH, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON SOCIAL SCIENCE (ICSS 2015), P92; Long MS, 2017, PR MACH LEARN RES, V70; Long MS, 2015, IEEE T KNOWL DATA EN, V27, P1519, DOI 10.1109/TKDE.2014.2373376; Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274; Luo Z., 2017, P NIPS, P165; Ngiam Jiquan, 2011, ICML, DOI DOI 10.5555/3104482.3104569; Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Sejdinovic D, 2013, ANN STAT, V41, P2263, DOI 10.1214/13-AOS1140; Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241; Sugiyama M, 2007, J MACH LEARN RES, V8, P985; Sun BC, 2016, AAAI CONF ARTIF INTE, P2058; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Tzeng E., 2014, ARXIV PREPRINT ARXIV; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463; Wang XZ, 2014, ADV NEUR IN, V27; YOSINSKI J, 2014, ADV NEURAL INFORM PR, P3320, DOI DOI 10.1109/IJCNN.2016.7727519; Zhang L, 2013, PROCEEDINGS OF 2013 CHINA INTERNATIONAL CONFERENCE ON INSURANCE AND RISK MANAGEMENT, P819	56	187	197	34	172	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2019	41	12					3071	3085		10.1109/TPAMI.2018.2868685	http://dx.doi.org/10.1109/TPAMI.2018.2868685			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JQ0XI	30188813				2022-12-18	WOS:000498677600019
J	Ghifary, M; Balduzzi, D; Kleijn, WB; Zhang, MJ				Ghifary, Muhammad; Balduzzi, David; Kleijn, W. Bastiaan; Zhang, Mengjie			Scatter Component Analysis: A Unified Framework for Domain Adaptation and Domain Generalization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Domain adaptation; domain generalization; feature learning; kernel methods; scatter; object recognition	KERNEL; RECOGNITION; DATABASE	This paper addresses classification tasks on a particular target domain in which labeled training data are only available from source domains different from (but related to) the target. Two closely related frameworks, domain adaptation and domain generalization, are concerned with such tasks, where the only difference between those frameworks is the availability of the unlabeled target data: domain adaptation can leverage unlabeled target information, while domain generalization cannot. We propose Scatter Component Analyis (SCA), a fast representation learning algorithm that can be applied to both domain adaptation and domain generalization. SCA is based on a simple geometrical measure, i.e., scatter, which operates on reproducing kernel Hilbert space. SCA finds a representation that trades between maximizing the separability of classes, minimizing the mismatch between domains, and maximizing the separability of data; each of which is quantified through scatter. The optimization problem of SCA can be reduced to a generalized eigenvalue problem, which results in a fast and exact solution. Comprehensive experiments on benchmark cross-domain object recognition datasets verify that SCA performs much faster than several state-of-the-art algorithms and also provides state-ofthe- art classification accuracy in both domain adaptation and domain generalization. We also show that scatter can be used to establish a theoretical generalization bound in the case of domain adaptation.	[Ghifary, Muhammad; Kleijn, W. Bastiaan; Zhang, Mengjie] Victoria Univ Wellington, Sch Engn & Comp Sci, Wellington 6140, New Zealand; [Balduzzi, David] Victoria Univ Wellington, Sch Math & Stat, Wellington 6140, New Zealand	Victoria University Wellington; Victoria University Wellington	Ghifary, M (corresponding author), Victoria Univ Wellington, Sch Engn & Comp Sci, Wellington 6140, New Zealand.	muhammad.ghifary@ecs.vuw.ac.nz; david.balduzzi@vuw.ac.nz; bastiaan.kleijn@ecs.vuw.ac.nz; mengjie.zhang@ecs.vuw.ac.nz	Zhang, Mengjie/AAT-8675-2021	Kleijn, W./0000-0002-1973-3920				[Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; [Anonymous], P ICML WORKSH CHALL; [Anonymous], 2007, P 15 ACM INT C MULTI; [Anonymous], [No title captured]; Baktashmotlagh M, 2014, PROC CVPR IEEE, P2481, DOI 10.1109/CVPR.2014.318; Baktashmotlagh M, 2013, IEEE I CONF COMP VIS, P769, DOI 10.1109/ICCV.2013.100; Bartlett P. L., 2003, Journal of Machine Learning Research, V3, P463, DOI 10.1162/153244303321897690; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Ben-David Shai, 2007, NEURIPS, P7; Blanchard Gilles, 2011, NIPS, V24, P3; Blitzer J., 2006, P 2006 C EMP METH NA, P120, DOI DOI 10.3115/1610075.1610094; Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401; Chen Minmin, 2012, P 29 INT C MACH LEAR, P767, DOI DOI 10.1007/S11222-007-9033-Z; Cortes C, 2014, THEOR COMPUT SCI, V519, P103, DOI 10.1016/j.tcs.2013.09.027; Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346; Daume H, 2007, P 45 ANN M ASS COMP, V45, P256; Donahue J, 2014, PR MACH LEARN RES, V32; Duan Lixin, 2012, IEEE Trans Neural Netw Learn Syst, V23, P504, DOI 10.1109/TNNLS.2011.2178556; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fang C, 2013, IEEE I CONF COMP VIS, P1657, DOI 10.1109/ICCV.2013.208; Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Ganin Y, 2015, PR MACH LEARN RES, V37, P1180; Geng B, 2011, IEEE T IMAGE PROCESS, V20, P2980, DOI 10.1109/TIP.2011.2134107; Ghifary M, 2015, IEEE I CONF COMP VIS, P2551, DOI 10.1109/ICCV.2015.293; Ghifary M, 2014, LECT NOTES ARTIF INT, V8862, P898, DOI 10.1007/978-3-319-13560-1_76; Glorot Xavier, 2011, P 28 INT C MACH LEAR, P513, DOI DOI 10.1177/1753193411430810; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Gretton A, 2012, J MACH LEARN RES, V13, P723; Griffin G., 2007, 120 CAL I TECHN; Hoffman J., 2013, P INT C LEARN REPR; Hoffman J, 2014, PROC CVPR IEEE, P867, DOI 10.1109/CVPR.2014.116; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; Jiang J., 2008, LIT SURVEY DOMAIN AD; Khosla A, 2012, LECT NOTES COMPUT SC, V7572, P158, DOI 10.1007/978-3-642-33718-5_12; Kifer Daniel, 2004, VLDB, DOI DOI 10.1016/B978-012088469-8/50019-X; Kim M, 2011, IEEE T PATTERN ANAL, V33, P657, DOI 10.1109/TPAMI.2010.111; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Krizhevsky Alex., 2009, LEARNING MULTIPLE LA, P6; Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167; Long M., 2015, P 32 INT C MACH LEAR, V1, P97; Long MS, 2014, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2014.183; Long MS, 2013, PROC CVPR IEEE, P407, DOI 10.1109/CVPR.2013.59; Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229; Micchelli CA, 2006, J MACH LEARN RES, V7, P2651; Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121; Muandet Krikamol, 2013, ICML; Niu L, 2016, INT J COMPUT VISION, V118, P130, DOI 10.1007/s11263-015-0862-5; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Pan SJ, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1187; Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P53, DOI 10.1109/MSP.2014.2347059; Ponce J, 2006, LECT NOTES COMPUT SC, V4170, P29; Rahimi A., 2007, ADV NEURAL INFORM PR, P3; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Sha, 2013, P INT C MACH LEARN; Shekhar S, 2013, PROC CVPR IEEE, P361, DOI 10.1109/CVPR.2013.53; Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4; Simonyan Karen, 2015, INT C LEARN REPR; Smola, 2007, ADV NEURAL INFORM PR, P513, DOI DOI 10.5555/2188385.2188410; Sriperumbudur BK, 2010, J MACH LEARN RES, V11, P1517; Steinwart I, 2002, J MACH LEARN RES, V2, P67, DOI 10.1162/153244302760185252; Sun B, 2014, P BRIT MACH VIS C; Sun BC, 2016, AAAI CONF ARTIF INTE, P2058; Sutskever I., 2014, P ADV INT C NEUR INF, P3104; Tommasi T, 2013, IEEE I CONF COMP VIS, P897, DOI 10.1109/ICCV.2013.116; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; van Gestel T, 2004, MACH LEARN, V54, P5, DOI 10.1023/B:MACH.0000008082.80494.e0; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013; Winn J, 2005, IEEE I CONF COMP VIS, P1800; Xu Z, 2014, LECT NOTES COMPUT SC, V8691, P628, DOI 10.1007/978-3-319-10578-9_41; [No title captured]	83	187	191	15	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2017	39	7					1414	1430		10.1109/TPAMI.2016.2599532	http://dx.doi.org/10.1109/TPAMI.2016.2599532			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EW8BZ	28113617	Green Submitted			2022-12-18	WOS:000402744400011
J	Heo, YS; Lee, KM; Lee, SU				Heo, Yong Seok; Lee, Kyoung Mu; Lee, Sang Uk			Robust Stereo Matching Using Adaptive Normalized Cross-Correlation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo matching; color; radiometric variation; illumination; camera exposure; gamma correction	ENERGY MINIMIZATION; COLOR; RETINEX	A majority of the existing stereo matching algorithms assume that the corresponding color values are similar to each other. However, it is not so in practice as image color values are often affected by various radiometric factors such as illumination direction, illuminant color, and imaging device changes. For this reason, the raw color recorded by a camera should not be relied on completely, and the assumption of color consistency does not hold good between stereo images in real scenes. Therefore, the performance of most conventional stereo matching algorithms can be severely degraded under the radiometric variations. In this paper, we present a new stereo matching measure that is insensitive to radiometric variations between left and right images. Unlike most stereo matching measures, we use the color formation model explicitly in our framework and propose a new measure, called the Adaptive Normalized Cross-Correlation (ANCC), for a robust and accurate correspondence measure. The advantage of our method is that it is robust to lighting geometry, illuminant color, and camera parameter changes between left and right images, and does not suffer from the fattening effect unlike conventional Normalized Cross-Correlation (NCC). Experimental results show that our method outperforms other state-of-the-art stereo methods under severely different radiometric conditions between stereo images.	[Heo, Yong Seok; Lee, Kyoung Mu; Lee, Sang Uk] Seoul Natl Univ, Dept Elect Engn & Comp Sci, Automat & Syst Res Inst, Seoul 151744, South Korea	Seoul National University (SNU)	Heo, YS (corresponding author), Seoul Natl Univ, Dept Elect Engn & Comp Sci, Automat & Syst Res Inst, 599 Gwanak Ro, Seoul 151744, South Korea.	hys@diehard.snu.ac.kr; kyoungmu@snu.ac.kr; sanguk@ipl.snu.ac.kr	Heo, Yong Seok/AAD-8816-2021; Lee, Kyoung Mu/AAC-4063-2020	Lee, Kyoung Mu/0000-0001-7210-1036	Defense Acquisition Program Administration and Agency for Defense Development, Korea, through the Image Information Research Center Technology [UD070007AD]; Ministry of Information and Communication	Defense Acquisition Program Administration and Agency for Defense Development, Korea, through the Image Information Research Center Technology; Ministry of Information and Communication	The authors would like to thank the anonymous reviewers for their constructive comments. This research was supported in part by the Defense Acquisition Program Administration and Agency for Defense Development, Korea, through the Image Information Research Center & Technology under the contract UD070007AD, and in part by the ITRC program of the Ministry of Information and Communication.	BERWICK D, 1998, P IEEE INT C COMP VI; Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; BRAINARD DH, 1986, J OPT SOC AM A, V3, P1651, DOI 10.1364/JOSAA.3.001651; CHONG HY, 2007, P IEEE INT C COMP VI; Debevec P. E., 1997, P ACM SIGGRAPH; EBNER M, 2004, P EUR C COMP VIS; Egnal Geoffrey, 2000, MUTUAL INFORM STEREO; FAUGERAS O, 1993, RR2013 INRIA; Finayson GD, 2001, IEEE T PATTERN ANAL, V23, P1209, DOI 10.1109/34.969113; Finlayson G, 2003, PATTERN RECOGN LETT, V24, P1679, DOI 10.1016/S0167-8655(02)00324-0; Finlayson G.D., 2002, P EUR C COMP VIS; Finlayson G. D., 1993, P IEEE INT C COMP VI; FINLAYSON GD, 1994, J OPT SOC AM A, V11, P1553, DOI 10.1364/JOSAA.11.001553; Finlayson GD, 2001, J OPT SOC AM A, V18, P253, DOI 10.1364/JOSAA.18.000253; FINLAYSON GD, 1998, P EUR C COMP VIS; FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770; FUNT B, 2000, P 8 COL IM C COL SCI; FUNT B, 1998, P EUR C COMP VIS; Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559; Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3; Gevers T, 2004, IEEE T PATTERN ANAL, V26, P113, DOI 10.1109/TPAMI.2004.1261083; Goesele M., 2007, P IEEE INT C COMP VI; Grossberg MD, 2004, IEEE T PATTERN ANAL, V26, P1272, DOI 10.1109/TPAMI.2004.88; Heo Y. S., 2008, P IEEE C COMP VIS PA; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; Hirschmuller H, 2002, INT J COMPUT VISION, V47, P229, DOI 10.1023/A:1014554110407; Hirschmuller H., 2007, P IEEE C COMP VIS PA; Hunt R. W. G., 1995, REPROD COLOR; Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272; Kim J., 2003, P IEEE INT C COMP VI; Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998; KLINKER GJ, 1990, INT J COMPUT VISION, V4, P7, DOI 10.1007/BF00137441; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; MELTZER T, 2005, P IEEE INT C COMP VI; MITSUNAGA T, 1999, P IEEE C COMP VIS PA; Negahdaripour S, 1998, IEEE T PATTERN ANAL, V20, P961, DOI 10.1109/34.713362; Ogale A. S., 2004, P IEEE INT C ROB AUT; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; TAN R, 2003, P IEEE INT C COMP VI; Tomasi C., 1998, 6 INT C COMP VIS, P839; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; Wang L, 2007, IEEE T PATTERN ANAL, V29, P1616, DOI [10.1109/TPAMI.2007.1171, 10.1109/TPAM1.2007.1171]; Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70; Zabih R., 1994, P EUR C COMP VIS; Zhang J, 2006, P IEEE C COMP VIS PA; Zickler T, 2008, INT J COMPUT VISION, V79, P13, DOI 10.1007/s11I263-007-0087-3	51	187	198	0	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2011	33	4					807	822		10.1109/TPAMI.2010.136	http://dx.doi.org/10.1109/TPAMI.2010.136			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	721QT	20660949	Green Submitted			2022-12-18	WOS:000287370400012
J	Zhang, GF; Jia, JY; Wong, TT; Bao, HJ				Zhang, Guofeng; Jia, Jiaya; Wong, Tien-Tsin; Bao, Hujun			Consistent Depth Maps Recovery from a Video Sequence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Consistent depth maps recovery; multiview stereo; bundle optimization; space-time fusion	STEREO	This paper presents a novel method for recovering consistent depth maps from a video sequence. We propose a bundle optimization framework to address the major difficulties in stereo reconstruction, such as dealing with image noise, occlusions, and outliers. Different from the typical multiview stereo methods, our approach not only imposes the photo-consistency constraint, but also explicitly associates the geometric coherence with multiple frames in a statistical way. It thus can naturally maintain the temporal coherence of the recovered dense depth maps without oversmoothing. To make the inference tractable, we introduce an iterative optimization scheme by first initializing the disparity maps using a segmentation prior and then refining the disparities by means of bundle optimization. Instead of defining the visibility parameters, our method implicitly models the reconstruction noise as well as the probabilistic visibility. After bundle optimization, we introduce an efficient space-time fusion algorithm to further reduce the reconstruction noise. Our automatic depth recovery is evaluated using a variety of challenging video examples.	[Zhang, Guofeng; Bao, Hujun] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China; [Jia, Jiaya; Wong, Tien-Tsin] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China	Zhejiang University; Chinese University of Hong Kong	Zhang, GF (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Zijingang Campus, Hangzhou 310058, Zhejiang, Peoples R China.	zhangguofeng@cad.zju.edu.cn; leojia@cse.cuhk.edu.hk; ttwong@cse.cuhk.edu.hk; bao@cad.zju.edu.cn	Jia, Jiaya/I-3251-2012					Alvarez L, 2007, INT J COMPUT VISION, V75, P371, DOI 10.1007/s11263-007-0041-4; BHAT P, 2007, RENDERING TECHNIQUES, P327; Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; BRADLEY D, 2008, P IEEE CS C COMP VIS; Collins RT, 1996, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.1996.517097; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Deng Y, 2005, IEEE I CONF COMP VIS, P1316; Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183; Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4; Fua P., 1993, Machine Vision and Applications, V6, P35, DOI 10.1007/BF01212430; FURUKAWA Y, 2008, P IEEE CS C COMP VIS; GALLUP D, 2007, P IEEE CS C COMP VIS; Gargallo P, 2005, PROC CVPR IEEE, P885; Goesele M., 2007, P IEEE INT C COMP VI; Hartley R., 2004, ROBOTICA; HERNANDEZ C, 2007, P IEEE CS C COMP VIS; Kang SB, 2004, INT J COMPUT VISION, V58, P139, DOI 10.1023/B:VISI.0000015917.35451.df; Kang SB, 2001, PROC CVPR IEEE, P103; Klaus A, 2006, INT C PATT RECOG, P15; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; Larsen ES, 2007, IEEE I CONF COMP VIS, P1440; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; LI G, 2006, P IEEE CS C COMP VIS, V2, P2355; MERRELL P, 2007, P IEEE INT C COMP VI; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a; PROESMANS M, 1994, P 3 EUR C COMP VIS, V2, P295; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Seitz S., 2006, P CVPR 06 IE COMP SO, V1, P519, DOI DOI 10.1109/CVPR.2006.19; Seitz SM, 1999, INT J COMPUT VISION, V35, P151, DOI 10.1023/A:1008176507526; Strecha C, 2004, PROC CVPR IEEE, P552; Strecha C, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P416, DOI 10.1109/TDPVT.2002.1024097; STRECHA C, 2008, P IEEE CS C COMP VIS; STRECHA C, 2006, P IEEE C COMP VIS PA, V2, P2394; Sun J, 2005, PROC CVPR IEEE, P399; Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509; TAGUCHI Y, 2008, P IEEE CS C COMP VIS; Tao H, 2001, PROC CVPR IEEE, P118; Tao H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P532, DOI 10.1109/ICCV.2001.937562; Tappen MF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P900; TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8; Vogiatzis G, 2005, PROC CVPR IEEE, P391; WOODFORDY OJ, 2008, P IEEE CS C COMP VIS; Yang Q., 2006, P IEEE C COMP VIS PA, P2347; Zach C., 2007, P IEEE INT C COMP VI, P1; Zaharescu A, 2007, LECT NOTES COMPUT SC, V4844, P166; ZHANG G, 2007, P IEEE CS C COMP VIS; Zhou CX, 2003, PROC CVPR IEEE, P351; Zitnick CL, 2007, INT J COMPUT VISION, V75, P49, DOI 10.1007/s11263-006-0018-8	51	187	222	0	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2009	31	6					974	988		10.1109/TPAMI.2009.52	http://dx.doi.org/10.1109/TPAMI.2009.52			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431YF	19372604	Green Submitted			2022-12-18	WOS:000265100000002
J	Nene, SA; Nayar, SK				Nene, SA; Nayar, SK			A simple algorithm for nearest neighbor search in high dimensions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern classification; nearest neighbor; searching by slicing; benchmarks; object recognition; visual correspondence; hardware architecture	VORONOI DIAGRAMS; TREES	The problem of finding the closest point in high-dimensional spaces is common in pattern recognition. Unfortunately, the complexity of most existing search algorithms, such as k-d tree and R-tree, grows exponentially with dimension, making them impractical for dimensionality above 15. In nearly all applications, the closest point is of interest only if it lies within a user-specified distance E. We present a simple and practical algorithm to efficiently search for the nearest neighbor within Euclidean distance E. The use of projection search combined with a novel data structure dramatically improves performance in high dimensions. A complexity analysis is presented which helps to automatically determine epsilon in structured problems. A comprehensive set of benchmarks clearly shows the superiority of the proposed algorithm for a Variety of structured and unstructured search problems. Object recognition is demonstrated as an example application. The simplicity of the algorithm makes it possible to construct an inexpensive hardware search engine which can be 100 times faster than its software equivalent. A C++ implementation of our algorithm is available upon request to search@cs.columbia.edu/CAVE/.			Nene, SA (corresponding author), COLUMBIA UNIV, DEPT COMP SCI, NEW YORK, NY 10027 USA.							Aho AV, 1974, DESIGN ANAL COMPUTER; ARYA S, 1995, CSTR3490 U MAR; BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93605.98741; BENTLEY JL, 1980, COMMUN ACM, V23, P214, DOI 10.1145/358841.358850; BENTLEY JL, 1980, ACM T MATH SOFTWARE, V6, P563, DOI 10.1145/355921.355927; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BENTLEY JL, 1979, IEEE T SOFTWARE ENG, V5, P333, DOI 10.1109/TSE.1979.234200; Califano A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P28, DOI 10.1109/CVPR.1991.139656; CLARKSON KL, 1988, SIAM J COMPUT, V17, P830, DOI 10.1137/0217052; Dobkin D., 1976, SIAM Journal on Computing, V5, P181, DOI 10.1137/0205015; Edelsbrunner H., 1987, ALGORITHMS COMBINATO; FARAGO A, 1993, IEEE T PATTERN ANAL, V15, P957, DOI 10.1109/34.232083; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; FRIEDMAN JH, 1975, IEEE T COMPUT, V24, P1000, DOI 10.1109/T-C.1975.224110; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; GARGANTINI I, 1982, COMMUN ACM, V25, P905, DOI 10.1145/358728.358741; Guttman A., 1984, ACM SIGMOD RECORD, V14, P47, DOI [DOI 10.1145/602259.602266, 10.1145/971697.602266]; HOROWITZ E, 1987, FUNDAMENTALS DATA ST; KLEE V, 1980, ARCH MATH, V34, P75, DOI 10.1007/BF01224932; Knuth D., 1973, ART COMPUTER PROGRAM, V3; LOMET DB, 1990, ACM T DATABASE SYST, V15, P625, DOI 10.1145/99935.99949; MICO ML, 1994, PATTERN RECOGN LETT, V15, P9, DOI 10.1016/0167-8655(94)90095-7; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Nayar SK, 1996, PROC CVPR IEEE, P471, DOI 10.1109/CVPR.1996.517114; NAYAR SK, 1994, P IEEE INT C ROB AUT; NAYAR SK, 1996, P IEEE INT C ROB AUT; NENE SA, CUCS01994; NENE SA, 1994, P ARPA IM UND WORKSH; NETRAVALI AN, 1995, DIGITAL PICTURES REP; PETRAKIS EGM, 1994, CSTR3388 U MAR DEP C; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Robinson J. J., 1981, Paper, 32nd Annual Meeting of the European Association for Animal Production; ROUSSOPOULOS N, 1985, P ACM SIGMOD     MAY; Sellis T., 1987, Proceedings of the Thirteenth International Conference on Very Large Data Bases: 1987 13th VLDB, P507; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061; VILAR JM, 1996, INFORMATION PROCESSI; WOLFSON HJ, 1990, P 1 EUR C COMP VIS, P526; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311; YUNCK TP, 1976, IEEE T SYST MAN CYB, V6, P678, DOI 10.1109/TSMC.1976.4309418	41	187	233	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1997	19	9					989	1003		10.1109/34.615448	http://dx.doi.org/10.1109/34.615448			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XX985		Green Published			2022-12-18	WOS:A1997XX98500005
J	UNSER, M; EDEN, M				UNSER, M; EDEN, M			MULTIRESOLUTION FEATURE-EXTRACTION AND SELECTION FOR TEXTURE SEGMENTATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											UNSER, M (corresponding author), NIH,DIV RES SERV,BIOMED ENGN & INSTRUMENTAT BRANCH,BETHESDA,MD 20892, USA.		Unser, Michael/A-1550-2008					ADE F, 1983, SIGNAL PROCESS, V5, P451, DOI 10.1016/0165-1684(83)90008-7; BLANTZ WE, 1987, JUN P INT C COMP VIS, P439; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; Bryan JG, 1951, HARVARD EDUC REV, V21, P90; BURT PJ, 1983, COMPUT VISION GRAPH, V21, P368, DOI 10.1016/S0734-189X(83)80049-8; CHEN PC, 1980, COMPUT VISION GRAPH, V12, P153, DOI 10.1016/0146-664X(80)90009-X; CHEN PC, 1979, COMPUT VISION GRAPH, V10, P172, DOI 10.1016/0146-664X(79)90049-2; COLEMAN GB, 1979, P IEEE, V67, P773, DOI 10.1109/PROC.1979.11327; Duda R.O., 1973, J ROYAL STAT SOC SER; FAUGERAS OD, 1978, NOV P INT JOINT C PA, P549; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; GRANLUND GH, 1980, 5TH P INT C PATT REC, P776; GRINAKER S, 1980, 5TH P INT C PATTERN, V1, P776; HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Hubel D. H., 1979, Scientific American, V241, P130; JULESZ B, 1983, AT&T TECH J, V62, P1619; KENDALL MG, 1977, ADV THEORY STATISTIC, V1; Laws K. I., 1980, 940 U SO CAL IM PROC; PERKINS WA, 1980, IEEE T PATTERN ANAL, V2, P8, DOI 10.1109/TPAMI.1980.4766965; PETERSON DW, 1966, IEEE T INFORM THEORY, V12, P380, DOI 10.1109/TIT.1966.1053913; PIETIKAINEN M, 1983, IEEE T SYST MAN CYB, V13, P421, DOI 10.1109/TSMC.1983.6313175; PIETIKAINEN M, 1981, IEEE T SYST MAN CYB, V11, P822; SKLANSKY J, 1973, PATTERN RECOGN, P146; UNSER M, 1986, SIGNAL PROCESS, V11, P61, DOI 10.1016/0165-1684(86)90095-2; UNSER M, 1984, THESIS SWISS FED I T; WATANABE S, 1965, 4TH T PRAG C INF THE, P635; WERMSER D, 1984, 7TH P INT C PATT REC; WERMSER D, 1982, 6TH P INT PATT REC M, P1078; WESKA JS, 1978, COMPUT GRAPHICS IMAG, V7, P259; Zucker S. W., 1976, Computer Graphics and Image Processing, V5, P382, DOI 10.1016/S0146-664X(76)80014-7	33	187	189	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1989	11	7					717	728		10.1109/34.192466	http://dx.doi.org/10.1109/34.192466			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AB815		Green Submitted			2022-12-18	WOS:A1989AB81500005
J	Xiang, T; Gong, SG				Xiang, Tao; Gong, Shaogang			Video behavior profiling for anomaly detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						behavior profiling; anomaly detection; dynamic scene modeling; spectral clustering; feature selection; Dynamic Bayesian Networks	FEATURE-SELECTION; MODELS	This paper aims to address the problem of modeling video behavior captured in surveillance videos for the applications of online normal behavior recognition and anomaly detection. A novel framework is developed for automatic behavior profiling and online anomaly sampling/detection without any manual labeling of the training data set. The framework consists of the following key components: 1) Acompact and effective behavior representation method is developed based on discrete-scene event detection. The similarity between behavior patterns are measured based on modeling each pattern using a Dynamic Bayesian Network (DBN). 2) The natural grouping of behavior patterns is discovered through a novel spectral clustering algorithm with unsupervised model selection and feature selection on the eigenvectors of a normalized affinity matrix. 3) A composite generative behavior model is constructed that is capable of generalizing from a small training set to accommodate variations in unseen normal behavior patterns. 4) A runtime accumulative anomaly measure is introduced to detect abnormal behavior, whereas normal behavior patterns are recognized when sufficient visual evidence has become available based on an online Likelihood Ratio Test (LRT) method. This ensures robust and reliable anomaly detection and normal behavior recognition at the shortest possible time. The effectiveness and robustness of our approach is demonstrated through experiments using noisy and sparse data sets collected from both indoor and outdoor surveillance scenarios. In particular, it is shown that a behavior model trained using an unlabeled data set is superior to those trained using the same but labeled data set in detecting anomaly from an unseen video. The experiments also suggest that our online LRT-based behavior recognition approach is advantageous over the commonly used Maximum Likelihood (ML) method in differentiating ambiguities among different behavior classes observed online.	[Xiang, Tao; Gong, Shaogang] Queen Mary Univ London, Dept Comp Sci, London E1 4NS, England	University of London; Queen Mary University London	Xiang, T (corresponding author), Queen Mary Univ London, Dept Comp Sci, Mile End Rd, London E1 4NS, England.	txiang@dcs.qmul.ac.uk; sgg@dcs.qmul.ac.uk			Engineering and Physical Sciences Research Council [GR/S63687/01] Funding Source: researchfish	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147; Boiman O, 2005, IEEE I CONF COMP VIS, P462; Dee H. M., 2004, BRIT MACH VIS C, P477; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Duong TV, 2005, PROC CVPR IEEE, P838; Dy JG, 2003, IEEE T PATTERN ANAL, V25, P373, DOI 10.1109/TPAMI.2003.1182100; Ghahramani Z, 1998, LECT NOTES ARTIF INT, V1387, P168, DOI 10.1007/BFb0053999; Gong SG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P742, DOI 10.1109/ICCV.2003.1238423; Hamid R, 2005, PROC CVPR IEEE, P1031; Higgins A., 1991, Digital Signal Processing, V1, P89, DOI 10.1016/1051-2004(91)90098-6; Kruskal J., 1983, SYMMETRIC TIME WARPI; Law MHC, 2004, IEEE T PATTERN ANAL, V26, P1154, DOI 10.1109/TPAMI.2004.71; Morris RJ, 2000, INT J COMPUT VISION, V37, P209, DOI 10.1023/A:1008159822101; Ng AY, 2002, ADV NEUR IN, V14, P849; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; PANUCCIO A, 2002, P JOINT IAPR INT WOR, P734; Porikli F., 2004, PROC C COMPUT VIS PA, P114; PORIKLI F, 2002, P 6 IEEE INT WORKSH; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Roberts SJ, 1998, IEEE T PATTERN ANAL, V20, P1133, DOI 10.1109/34.730550; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SHAN Y, 2004, P AS C COMP VIS; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P975, DOI 10.1109/ICCV.1999.790354; WILPON JG, 1990, IEEE T ACOUST SPEECH, V38, P1870, DOI 10.1109/29.103088; Xiang T, 2005, IEEE I CONF COMP VIS, P1238; XIANG T, 2004, P BRIT MACH VIS C, P177; Xiang T, 2002, P BRIT MACH VIS C, P233; Yu SX, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P313, DOI 10.1109/iccv.2003.1238361; Zelnik-Manor L, 2004, ADV NEURAL INFORM PR; ZELNIKMANOR L, 2001, P IEEE C COMP VIS PA; Zhang D, 2005, PROC CVPR IEEE, P611; Zhong H, 2004, PROC CVPR IEEE, P819	34	185	195	2	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2008	30	5					893	908		10.1109/TPAMI.2007.70731	http://dx.doi.org/10.1109/TPAMI.2007.70731			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	272SI	18369257				2022-12-18	WOS:000253879700011
J	Law, MHC; Jain, AK				Law, MHC; Jain, AK			Incremental nonlinear dimensionality reduction by manifold learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						incremental learning; dimensionality reduction; ISOMAP; manifold learning; unsupervised learning	COMPONENT ANALYSIS; NEURAL-NETWORKS; PRINCIPAL	Understanding the structure of multidimensional patterns, especially in unsupervised cases, is of fundamental importance in data mining, pattern recognition, and machine learning. Several algorithms have been proposed to analyze the structure of high-dimensional data based on the notion of manifold learning. These algorithms have been used to extract the intrinsic characteristics of different types of high-dimensional data by performing nonlinear dimensionality reduction. Most of these algorithms operate in a '' batch '' modeand cannot be efficiently applied when data are collected sequentially. In this paper, we describe an incremental version of ISOMAP, one of the key manifold learning algorithms. Our experiments on synthetic data as well as real world images demonstrate that our modified algorithm can maintain an accurate low-dimensional representation of the data in an efficient manner.	Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Michigan State University	Law, MHC (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, 3115 Engn Bldg, E Lansing, MI 48824 USA.	lawhiu@cse.msu.edu; jain@cse.msu.edu						BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bengio Y, 2004, ADV NEURAL INFORM PR, V16; Bernstein M., 2000, GRAPH APPROXIMATIONS; BEYGELZIMER A, 2005, COVER TREES NEAREST; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Brand  M., 2003, ADV NEURAL INFORM PR, P961, DOI DOI 10.1109/34.682189; BRUN A, 2003, P 9 INT C AID SYST T, V2809; Bruske J, 1998, IEEE T PATTERN ANAL, V20, P572, DOI 10.1109/34.682189; Camastra F, 2002, IEEE T PATTERN ANAL, V24, P1404, DOI 10.1109/TPAMI.2002.1039212; Chang Y, 2004, PROC CVPR IEEE, P520; Costa JA, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P988; Cox T.F., 2001, MULTIDIMENSIONAL SCA, V2nd; DeMers D., 1993, ADV NEURAL INFORM PR, P580; Demetrescu C, 2004, J ACM, V51, P968, DOI 10.1145/1039488.1039492; DESILVA V, 2003, ADV NEURAL INFORM PR, V15, P705; Donoho DL, 2002, 200227 STANF U DEP S; DUDA RO, 2001, PATTERN CLASSIFICAT; Elgamal EA, 2004, CHILD NERV SYST, V20, P489, DOI 10.1007/s00381-003-0891-1; Elgammal A, 2004, PROC CVPR IEEE, P681; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Hadid A, 2002, INT C PATT RECOG, P111, DOI 10.1109/ICPR.2002.1044625; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; Hinton GE, 1997, IEEE T NEURAL NETWOR, V8, P65, DOI 10.1109/72.554192; Jenkins O., 2004, P 21 INT C MACH LEAR; Kegl B, 2000, IEEE T PATTERN ANAL, V22, P281, DOI 10.1109/34.841759; Kegl B, 2003, ADV NEURAL INFORM PR, V15; Kohonen T, 2001, SELF ORG MAPS, Vthird, DOI DOI 10.1007/978-3-642-56927-2; Law MHC, 2004, SIAM PROC S, P33; Levina E., 2005, ADV NEURAL INFORM PR, V17; Li S.Z., 2001, P IEEE ICCV WORKSH R; Lu XG, 2004, P SOC PHOTO-OPT INS, V5404, P114, DOI 10.1117/12.542847; MAO JC, 1995, IEEE T NEURAL NETWOR, V6, P296, DOI 10.1109/72.363467; MARTINEZ A, 1998, 24 U AL BIRM COMP VI; Narvaez P, 2001, IEEE ACM T NETWORK, V9, P706, DOI 10.1109/90.974525; Narvaez P, 2000, IEEE ACM T NETWORK, V8, P734, DOI 10.1109/90.893870; Niskanen M, 2003, PROC SPIE, V5132, P178, DOI 10.1117/12.514959; PETTIS KW, 1979, IEEE T PATTERN ANAL, V1, P25, DOI 10.1109/TPAMI.1979.4766873; Roweis S, 2002, ADV NEUR IN, V14, P889; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Simard PY, 2003, PROC INT CONF DOC, P958; SJOSTROM E, 1996, THESIS; Smola AJ, 2001, J MACH LEARN RES, V1, P179, DOI 10.1162/15324430152748227; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tibshirani R., 1992, Statistics and Computing, V2, P183, DOI 10.1007/BF01889678; Verbeek JJ, 2002, LECT NOTES COMPUT SC, V2415, P914; Weinberger KQ, 2004, PROC CVPR IEEE, P988; Weng JY, 2003, IEEE T PATTERN ANAL, V25, P1034, DOI 10.1109/TPAMI.2003.1217609; Yang MH, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P117; Zha H., 2003, P 20 INT C MACH LEAR; Zhang J., 2004, P 6 INT C AUT FAC GE	53	185	215	1	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2006	28	3					377	391		10.1109/TPAMI.2006.56	http://dx.doi.org/10.1109/TPAMI.2006.56			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	001FB	16526424				2022-12-18	WOS:000234517900004
J	Peterfreund, N				Peterfreund, N			Robust tracking of position and velocity with Kalman snakes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						active contour; Kalman snakes; optical-flow robust tracking	OPTICAL-FLOW; OBJECTS; MODEL	A new Kalman-filter based active contour model is proposed for tracking of nonrigid objects in combined spatio-velocity space. The model employs measurements of gradient-based image potential and of optical-flow along the contour as system measurements. In order to improve robustness to image clutter and to occlusions an optical-flow based detection mechanism is proposed. The method detects and rejects spurious measurements which are not consistent with previous estimation of image motion.	Oak Ridge Natl Lab, Ctr Engn Syst Adv Res, Oak Ridge, TN 37831 USA	United States Department of Energy (DOE); Oak Ridge National Laboratory	Peterfreund, N (corresponding author), Oak Ridge Natl Lab, Ctr Engn Syst Adv Res, POB 2008, Oak Ridge, TN 37831 USA.	v4p@mars.epm.ornl.gov						Amini A. A., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P251; Bar-Shalom Y., 1988, TRACKING DATA ASS; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BASCLE B, 1993, P SPIE GEOM METH COM, V2, P282; BASLE B, 1993, P 4 INT C COMP VIS, P421; BLAKE A, 1994, P COMP GRAPH SIGGRAP, P71; COOTES TF, 1993, P 4 INT C COMP VIS, P242; Curwen R, 1992, ACTIVE VISION, P39; GENNERY DB, 1992, INT J COMPUT VISION, V7, P243, DOI 10.1007/BF00126395; Grewal M, 1993, KALMAN FILTERING THE; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; ISARD M, 1996, P EUR C COMP VIS, P343; Johan K., 1995, ADAPTIVE CONTROL; Jolly MPD, 1996, IEEE T PATTERN ANAL, V18, P293, DOI 10.1109/34.485557; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LEYMARIE F, 1993, IEEE T PATTERN ANAL, V15, P617, DOI 10.1109/34.216733; LOWE DG, 1992, INT J COMPUT VISION, V8, P113, DOI 10.1007/BF00127170; LUETTGEN MR, 1994, IEEE T IMAGE PROCESS, V3, P41, DOI 10.1109/83.265979; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; PETERFREUND N, 1997, P IEEE NONR ART MOT; Terzopoulos D., 1992, ACTIVE VISION, P3; Willems J. L., 1970, STABILITY THEORY DYN	22	185	205	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1999	21	6					564	569		10.1109/34.771328	http://dx.doi.org/10.1109/34.771328			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	205KD					2022-12-18	WOS:000080819100008
J	KONRAD, J; DUBOIS, E				KONRAD, J; DUBOIS, E			BAYESIAN-ESTIMATION OF MOTION VECTOR-FIELDS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						BAYESIAN ESTIMATION; MARKOV RANDOM FIELDS; MOTION ESTIMATION; MOTION MODELING; OPTICAL FLOW; SIMULATED ANNEALING; STOCHASTIC RELAXATION; 2-D MOTION	STATISTICAL-ANALYSIS; IMAGE SEQUENCES; VISUAL-MOTION; OPTICAL-FLOW; SEGMENTATION; OPTIMIZATION; SYSTEMS	This paper presents a new approach to the estimation of 2-D motion vector fields from time-varying images. The approach is stochastic both in its formulation and in the solution method. The formulation involves the specification of a deterministic structural model along with stochastic observation and motion field models. Two motion models are proposed: a globally smooth model based on vector Markov random fields and a piecewise smooth model derived from coupled vector-binary Markov random fields. Two estimation criteria are studied. In the maximum a posteriori probability (MAP) estimation, the a posteriori probability of motion given data is maximized, whereas in the minimum expected cost (MEC) estimation, the expectation of a certain cost function is minimized. The MAP estimation is performed via simulated annealing, whereas the MEC algorithm performs iteration-wise averaging. Both algorithms generate sample fields by means of stochastic relaxation implemented via the Gibbs sampler. Two versions are developed: one for a discrete state space and the other for a continuous state space. The MAP estimation is incorporated into a hierarchical environment to deal efficiently with large displacements. Numerous experimental results of application of these algorithms to natural and computer-generated images with natural and synthetic motion are shown.			KONRAD, J (corresponding author), INST NATL RECH SCI TELECOMMUN, VERDUN H3E 1H6, QUEBEC, CANADA.							ANANDAN P, 1987, THESIS U MASS; BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1986, J R STAT SOC B, V48, P259; Bouthemy P., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P1651, DOI 10.1109/ICASSP.1989.266763; BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; DUBOIS E, 1985, P IEEE, V73, P502, DOI 10.1109/PROC.1985.13182; ENKELMANN W, 1988, COMPUT VISION GRAPH, V43, P150, DOI 10.1016/0734-189X(88)90059-X; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GENNERT M, 1987, MIT975 ART INT LAB T; GLAZER F, 1987, THESIS U MASS; Hassner M., 1981, IMAGE MODELING, P185; HEITZ F, 1990, INT CONF ACOUST SPEE, P2305, DOI 10.1109/ICASSP.1990.116039; HEITZ F, 1990, JUN P IEEE INT C PAT, P378; HILDRETH EC, 1984, ARTIF INTELL, V23, P309, DOI 10.1016/0004-3702(84)90018-3; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HUTCHINSON J, 1988, COMPUTER, V21, P52, DOI 10.1109/2.31; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Konrad J., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P1072, DOI 10.1109/ICASSP.1988.196780; KONRAD J, 1991, IMAGE VISION COMPUT, V9, P215, DOI 10.1016/0262-8856(91)90026-L; KONRAD J, 1989, THESIS MCGILL U MONT; KONRAD J, 1988, DEC P IEEE INT C COM, P354; KONRAD J, 1989, P C VISION INTERFACE, P51; KONRAD J, 1988, INRS26 TEL TECH REP; MARROQUIN JL, 1985, THESIS MIT CAMBRIDGE; MARTINEZ D, 1986, THESIS MIT CAMBRIDGE; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; MURRAY DW, 1987, IEEE T PATTERN ANAL, V9, P220, DOI 10.1109/TPAMI.1987.4767896; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; ROSS SM, 1970, APPLIED PROBABILITY; SCHUNCK BG, 1983, THESIS MIT CAMBRIDGE; TRETIAK O, 1984, JUL P IEEE INT C PAT, P16; WOODS JW, 1972, IEEE T INFORM THEORY, V18, P232, DOI 10.1109/TIT.1972.1054786	35	185	196	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1992	14	9					910	927		10.1109/34.161350	http://dx.doi.org/10.1109/34.161350			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JL924		Green Submitted			2022-12-18	WOS:A1992JL92400004
J	JAIN, AK				JAIN, AK			SINUSOIDAL FAMILY OF UNITARY TRANSFORMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV CALIF DAVIS,DEPT ELECT ENGN,DAVIS,CA 95616	University of California System; University of California Davis								AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784; Ahmed N., 1975, ORTHOGONAL TRANSFORM, P86; Bellman R., 1970, INTRO MATRIX ANAL, V2nd; Brigham E. O., 1974, FAST FOURIER TRANSFO; CHEN WC, 1976, JUN P INT COMM C; COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354; FINO BJ, 1977, SIAM J COMPUT, V6; GRAY RM, 1972, IEEE T INFORM THEORY, V18, P725, DOI 10.1109/TIT.1972.1054741; GRAY RM, 1971, SUSEL71032 STANF U T; HAMIDI M, 1976, IEEE T ACOUST SPEECH, V24, P428, DOI 10.1109/TASSP.1976.1162839; JAIN AC, UNPUBLISHED; JAIN AK, 1976, IEEE T COMMUN, V24, P1023, DOI 10.1109/TCOM.1976.1093409; JAIN AK, 1978, IEEE T ACOUST SPEECH, V26, P121, DOI 10.1109/TASSP.1978.1163064; JAIN AK, 1977, IEEE T COMPUT, V25, P1061; JAIN AK, 1976, NOV P NAT TEL COMM C; JAIN AK, 1976, NAS831434 CONTR; JAIN AK, 1976, IMAGE SCI MATHEMATIC, P201; MEIRI AZ, 1976, 1976 P SPIE C IM PRO; PEARL J, 1975, IEEE T ACOUST SPEECH, V23, P547, DOI 10.1109/TASSP.1975.1162736; PRATT WK, 1977, IMAGE PROCESSING; RABINER LR, 1969, IEEE T ACOUST SPEECH, VAU17, P86, DOI 10.1109/TAU.1969.1162034; RAY WD, 1970, IEEE T INFORM THEORY, V16, P663, DOI 10.1109/TIT.1970.1054565; WHITEHOUSE HJ, 1975, SIGNAL PROCESSING US; YEMINI Y, 1975, UCLAENG7566 U CAL SC	24	185	202	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	4					356	365		10.1109/TPAMI.1979.4766944	http://dx.doi.org/10.1109/TPAMI.1979.4766944			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HV227	21868870				2022-12-18	WOS:A1979HV22700004
J	Wang, WG; Shen, JB; Ling, HB				Wang, Wenguan; Shen, Jianbing; Ling, Haibin			A Deep Network Solution for Attention and Aesthetics Aware Photo Cropping	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Photo cropping; attention box prediction; aesthetics assessment; deep learning	VISUAL-ATTENTION	We study the problem of photo cropping, which aims to find a cropping window of an input image to preserve as much as possible its important parts while being aesthetically pleasant. Seeking a deep learning-based solution, we design a neural network that has two branches for attention box prediction (ABP) and aesthetics assessment (AA), respectively. Given the input image, the ABP network predicts an attention bounding box as an initial minimum cropping window, around which a set of cropping candidates are generated with little loss of important information. Then, the AA network is employed to select the final cropping window with the best aesthetic quality among the candidates. The two sub-networks are designed to share the same full-image convolutional feature map, and thus are computationally efficient. By leveraging attention prediction and aesthetics assessment, the cropping model produces high-quality cropping results, even with the limited availability of training data for photo cropping. The experimental results on benchmark datasets clearly validate the effectiveness of the proposed approach. In addition, our approach runs at 5 fps, outperforming most previous solutions. The code and results are available at: https://github.com/shenjianbing/DeepCropping.	[Wang, Wenguan; Shen, Jianbing] Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China; [Shen, Jianbing] Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates; [Ling, Haibin] Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA	Beijing Institute of Technology; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University	Wang, WG (corresponding author), Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.	wenguanwang.ai@gmail.com; shenjianbing@bit.edu.cn; hbling@temple.edu	Shen, Jianbing/U-8796-2019; Wang, Wenguan/AAA-5782-2022	Wang, Wenguan/0000-0002-0802-9567; Shen, Jianbing/0000-0002-4109-8353; Ling, Haibin/0000-0003-4094-8413	Beijing Natural Science Foundation [4182056]; National Basic Research Program of China [2013CB328805]; Fok Ying-Tong Education Foundation for Young Teachers; US NSF [1618398, 1449860, 1350521]	Beijing Natural Science Foundation(Beijing Natural Science Foundation); National Basic Research Program of China(National Basic Research Program of China); Fok Ying-Tong Education Foundation for Young Teachers; US NSF(National Science Foundation (NSF))	This work was supported in part by the Beijing Natural Science Foundation under Grant 4182056, the National Basic Research Program of China under grant 2013CB328805, and the Fok Ying-Tong Education Foundation for Young Teachers. Specialized Fund for Joint Building Program of Beijing Municipal Education Commission. Ling was supported in part by US NSF Grants 1618398, 1449860 and 1350521.	Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2006, NIPS; Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89; Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30; Borji Ali, 2012, CVPR; Carrasco M, 2011, VISION RES, V51, P1484, DOI 10.1016/j.visres.2011.04.012; Chen JS, 2016, PROC CVPR IEEE, P507, DOI 10.1109/CVPR.2016.61; Chen YL, 2017, IEEE WINT CONF APPL, P226, DOI 10.1109/WACV.2017.32; Cheng B., 2010, P 18 ACM INT C MULTI, P291; Cong RM, 2018, IEEE T IMAGE PROCESS, V27, P568, DOI 10.1109/TIP.2017.2763819; Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23; Deng YB, 2017, IEEE SIGNAL PROC MAG, V34, P80, DOI 10.1109/MSP.2017.2696576; Dhar S, 2011, PROC CVPR IEEE, P1657, DOI 10.1109/CVPR.2011.5995467; Donahue J, 2014, PR MACH LEARN RES, V32; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fang C, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1105, DOI 10.1145/2647868.2654979; Gao D, 2008, ADV NEURAL INFORM PR, P497; Gao D., 2005, ADV NEURAL INFORM PR, P481; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; JIANG M, 2015, PROC CVPR IEEE, P1072, DOI DOI 10.1109/CVPR.2015.7298710; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Ke Yan, 2006, 2006 IEEE COMPUTER S, V1, P419, DOI DOI 10.1109/CVPR.2006.303; Kingma D.P, P 3 INT C LEARNING R; Kong S, 2016, LECT NOTES COMPUT SC, V9905, P662, DOI 10.1007/978-3-319-46448-0_40; Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633; Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047; Lu X, 2015, IEEE I CONF COMP VIS, P990, DOI 10.1109/ICCV.2015.119; Lu X, 2015, IEEE T MULTIMEDIA, V17, P2021, DOI 10.1109/TMM.2015.2477040; Lu X, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P457, DOI 10.1145/2647868.2654927; Luo W, 2011, IEEE I CONF COMP VIS, P2206, DOI 10.1109/ICCV.2011.6126498; Lv CG, 2009, ADV INTEL SYS RES, P681; Mai L, 2016, PROC CVPR IEEE, P497, DOI 10.1109/CVPR.2016.60; Marchesotti L, 2011, IEEE I CONF COMP VIS, P1784, DOI 10.1109/ICCV.2011.6126444; Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467; Mishra AK, 2012, IEEE T PATTERN ANAL, V34, P639, DOI 10.1109/TPAMI.2011.171; MURRAY N, 2012, PROC CVPR IEEE, P2408; Nishiyama M, 2009, P 17 ACM INT C MULTI, P669; Nishiyama M, 2011, PROC CVPR IEEE, P33, DOI 10.1109/CVPR.2011.5995539; Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71; Park J, 2012, IEEE IMAGE PROC, P2741, DOI 10.1109/ICIP.2012.6467466; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Shen JB, 2016, IEEE T IMAGE PROCESS, V25, P5933, DOI 10.1109/TIP.2016.2616302; Su Hsiao-Hang, 2011, P 19 ACM INT C MULTI, P1213; Suh B, 2003, P 16 ANN ACM S USER, P95, DOI [10.1145/964696.964707, DOI 10.1145/964696.964707]; Sun J, 2013, INT J COMPUT VISION, V104, P135, DOI 10.1007/s11263-013-0618-z; Tang HX, 2014, PROC CVPR IEEE, P2877, DOI 10.1109/CVPR.2014.368; Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358; Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941; Wang WG, 2018, IEEE T CIRC SYST VID, V28, P1727, DOI 10.1109/TCSVT.2017.2701279; Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612; Wang WG, 2017, IEEE I CONF COMP VIS, P2205, DOI 10.1109/ICCV.2017.240; Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005; Wang WG, 2017, IEEE T VIS COMPUT GR, V23, P2014, DOI 10.1109/TVCG.2016.2600594; Wang WG, 2016, IEEE T IMAGE PROCESS, V25, P5025, DOI 10.1109/TIP.2016.2601784; Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013; Wang WQ, 2018, PROC CVPR IEEE, P9329, DOI 10.1109/CVPR.2018.00972; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961; Yan JZ, 2013, PROC CVPR IEEE, P971, DOI 10.1109/CVPR.2013.130; Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844; Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32; Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226	72	184	184	5	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2019	41	7					1531	1544		10.1109/TPAMI.2018.2840724	http://dx.doi.org/10.1109/TPAMI.2018.2840724			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IC4XW	29993710				2022-12-18	WOS:000470972300001
J	Geng, B; Tao, DC; Xu, C; Yang, LJ; Hua, XS				Geng, Bo; Tao, Dacheng; Xu, Chao; Yang, Linjun; Hua, Xian-Sheng			Ensemble Manifold Regularization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Manifold learning; semi-supervised learning; ensemble manifold regularization	CLASSIFICATION	We propose an automatic approximation of the intrinsic manifold for general semi-supervised learning (SSL) problems. Unfortunately, it is not trivial to define an optimization function to obtain optimal hyperparameters. Usually, cross validation is applied, but it does not necessarily scale up. Other problems derive from the suboptimality incurred by discrete grid search and the overfitting. Therefore, we develop an ensemble manifold regularization (EMR) framework to approximate the intrinsic manifold by combining several initial guesses. Algorithmically, we designed EMR carefully so it 1) learns both the composite manifold and the semi-supervised learner jointly, 2) is fully automatic for learning the intrinsic manifold hyperparameters implicitly, 3) is conditionally optimal for intrinsic manifold approximation under a mild and reasonable assumption, and 4) is scalable for a large number of candidate manifold hyperparameters, from both time and space perspectives. Furthermore, we prove the convergence property of EMR to the deterministic matrix at rate root-n. Extensive experiments over both synthetic and real data sets demonstrate the effectiveness of the proposed framework.	[Geng, Bo; Xu, Chao] Peking Univ, Minist Educ, Key Lab Machine Percept, Beijing 100871, Peoples R China; [Tao, Dacheng] Univ Technol, Fac Engn & Informat Technol, Ctr Quantum Computat & Intelligent Syst, Broadway, NSW 2007, Australia; [Yang, Linjun] Microsoft Res Asia, Beijing 100190, Peoples R China; [Hua, Xian-Sheng] Microsoft Corp, Redmond, WA 98052 USA	Peking University; University of Technology Sydney; Microsoft; Microsoft Research Asia; Microsoft	Geng, B (corresponding author), Peking Univ, Minist Educ, Key Lab Machine Percept, Beijing 100871, Peoples R China.	bogeng@pku.edu.cn; dacheng.tao@uts.edu.au; xuchao@cis.pku.edu.cn; linjuny@microsoft.com; xshua@microsoft.com	Tao, Dacheng/A-5449-2012		Australian ARC [ARC DP-120103730]; Chinese NBRPC [2011CB302400]; NSFC [60975014, 61121002]; NSB [4102024]	Australian ARC; Chinese NBRPC; NSFC(National Natural Science Foundation of China (NSFC)); NSB	This work is partially supported by the Australian ARC discovery project (ARC DP-120103730), Chinese NBRPC 2011CB302400, NSFC 60975014, 61121002, and NSB 4102024.	Argyriou A., 2005, ADV NEURAL INF PROC, P67; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Belkin M., 2002, P NEUR INF PROC SYST; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Bennett KP, 1999, ADV NEUR IN, V11, P368; Bezdek J. C., 2003, Neural, Parallel & Scientific Computations, V11, P351; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Chapelle O., 2001, P ADV NEUR INF PROC, V15; Chapelle O., 2006, IEEE T NEURAL NETWOR, V20, P542; Chapelle O, 2008, J MACH LEARN RES, V9, P203; He X., 2004, P ADV NEUR INF PROC, V18; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Keerthi S., 2007, P ADV NEUR INF PROC, V19; Kohavi R., 1995, INT JOINT C ART INT, V14, P1137, DOI DOI 10.1067/MOD.2000.109031; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; ROSENBERG S, 1997, LAPLACIAN RIEMMANNIA; Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40; Sindhwani V., 2006, P 23 INT C MACH LEAR, V23, P841, DOI DOI 10.1145/1143844.1143950; Sindhwani V., 2005, P 22 INT C MACH LEAR, P824; Smola A., 2003, P C LEARN THEOR KERN; Tong S., 2000, P 17 INT C MACH LEAR, P999; Vapnik VN, 1998, STAT LEARNING THEORY, DOI DOI 10.1007/978-1-4419-1428-6_5864; Yarowsky David, 1995, ACL, P2, DOI [10.3115/981658.981684, DOI 10.3115/981658.981684]; Zhou DY, 2004, ADV NEUR IN, V16, P321; Zhu X., 2003, INT C MACH LEARN	28	184	189	3	60	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2012	34	6					1227	1233		10.1109/TPAMI.2012.57	http://dx.doi.org/10.1109/TPAMI.2012.57			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	927OE	22371429				2022-12-18	WOS:000302916600015
J	Pillai, JK; Patel, VM; Chellappa, R; Ratha, NK				Pillai, Jaishanker K.; Patel, Vishal M.; Chellappa, Rama; Ratha, Nalini K.			Secure and Robust Iris Recognition Using Random Projections and Sparse Representations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Iris recognition; cancelability; secure biometrics; random projections; sparse representations	SIGNAL RECOVERY; UNCERTAINTY PRINCIPLES; BASIS PURSUIT; BIOMETRICS	Noncontact biometrics such as face and iris have additional benefits over contact-based biometrics such as fingerprint and hand geometry. However, three important challenges need to be addressed in a noncontact biometrics-based authentication system: ability to handle unconstrained acquisition, robust and accurate matching, and privacy enhancement without compromising security. In this paper, we propose a unified framework based on random projections and sparse representations, that can simultaneously address all three issues mentioned above in relation to iris biometrics. Our proposed quality measure can handle segmentation errors and a wide variety of possible artifacts during iris acquisition. We demonstrate how the proposed approach can be easily extended to handle alignment variations and recognition from iris videos, resulting in a robust and accurate system. The proposed approach includes enhancements to privacy and security by providing ways to create cancelable iris templates. Results on public data sets show significant benefits of the proposed approach.	[Pillai, Jaishanker K.; Chellappa, Rama] Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA; [Pillai, Jaishanker K.; Chellappa, Rama] Univ Maryland, Ctr Automat Res CfAR, College Pk, MD 20742 USA; [Patel, Vishal M.] Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA; [Ratha, Nalini K.] IBM Res Corp, Hawthorne, NY 10532 USA	University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park; International Business Machines (IBM)	Pillai, JK (corresponding author), Univ Maryland, Dept Elect & Comp Engn, AV Williams Bldg, College Pk, MD 20742 USA.	jsp@umiacs.umd.edu; pvishalm@gmail.com; rama@umiacs.umd.edu; ratha@us.ibm.com	Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/B-6573-2012; Ratha, Nalini/AAR-6235-2020		MURI from the US Office of Naval Research [N00014-08-1-0638]	MURI from the US Office of Naval Research	The work of J.K. Pillai, V. M. Patel, and R. Chellappa was supported by MURI from the US Office of Naval Research under the Grant N00014-08-1-0638.	Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718; BLANCHARD JD, RESTRICTED IN PRESS; Bolle RM, 2002, PATTERN RECOGN, V35, P2727, DOI 10.1016/S0031-3203(01)00247-3; Bowyer K. W., 2010, ND IRIS 0405 IRIS IM; Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Chen Y, 2006, LECT NOTES COMPUT SC, V3832, P373; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; Daugman J, 2006, P IEEE, V94, P1927, DOI 10.1109/JPROC.2006.884092; Davida GI, 1998, 1998 IEEE SYMPOSIUM ON SECURITY AND PRIVACY - PROCEEDINGS, P148, DOI 10.1109/SECPRI.1998.674831; Donoho DL, 2006, DISCRETE COMPUT GEOM, V35, P617, DOI 10.1007/s00454-005-1220-0; Donoho DL, 2006, SIGNAL PROCESS, V86, P511, DOI 10.1016/j.sigpro.2005.05.027; Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265; DU Y, 2006, P SPIE C BIOM TECHN; Hao F, 2006, IEEE T COMPUT, V55, P1081, DOI 10.1109/TC.2006.138; HOLLINGWSORTH KP, 2009, P 3 INT C ADV BIOM; Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416; Juels A, 1999, 6TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P28, DOI 10.1145/319709.319714; KALKA ND, 2006, P SPIE C BIOM TECHN, P6202; KANADE S, 2009, P IEEE C COMP VIS PA; KRICHEN E, 2005, P INT C AUD VID BAS, P23; Liu CQ, 2006, INT C PATT RECOG, P489; Ma L, 2004, IEEE T IMAGE PROCESS, V13, P739, DOI 10.1109/TIP.2004.827237; Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145; Masek L., 2003, MATLAB SOURCE CODE B; Monro D. M, 2007, P IEEE WORKSH SIGN P, P1; Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002; Newton EM, 2009, IEEE T SYST MAN CY A, V39, P4, DOI 10.1109/TSMCA.2008.2008210; Phillips PJ, 1998, IEEE T IMAGE PROCESS, V7, P1150, DOI 10.1109/83.704308; PHILLIPS PJ, 2006, P NRECA C FAC; Phillips PJ, 2009, P 3 INT ASS PATT REC; Pillai J.K., 2010, P IEEE INT C AC SPEE; PILLAI JK, 2009, P 3 IEEE INT C BIOM; Proenca H, 2006, IEE P-VIS IMAGE SIGN, V153, P199, DOI 10.1049/ip-vis:20050213; Proenca H, 2006, INT C PATT RECOG, P405; Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614; Rauhut H, 2008, IEEE T INFORM THEORY, V54, P2210, DOI 10.1109/TIT.2008.920190; ROY K, 2006, P INT C BIOM JAN, P486; Schmid NA, 2006, IEEE T INF FOREN SEC, V1, P154, DOI 10.1109/TIFS.2006.873603; Teoh ABJ, 2006, IEEE T PATTERN ANAL, V28, P1892, DOI 10.1109/TPAMI.2006.250; Teoh ABJ, 2007, IEEE T SYST MAN CY B, V37, P1096, DOI 10.1109/TSMCB.2007.903538; Thornton J, 2007, IEEE T PATTERN ANAL, V29, P596, DOI 10.1109/TPAMI.2007.1006; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; van den Berg E, 2008, SIAM J SCI COMPUT, V31, P890, DOI 10.1137/080714488; Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yang A., 2010, UCBEECS201013; Zhu XD, 2004, FOURTH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY, PROCEEDINGS, P24; Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zuo J., 2008, P 19 INT C PATT REC, P1	52	184	194	2	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2011	33	9					1877	1893		10.1109/TPAMI.2011.34	http://dx.doi.org/10.1109/TPAMI.2011.34			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	792JN	21339529	Green Submitted			2022-12-18	WOS:000292740000013
J	Jain, AK; Feng, JJ				Jain, Anil K.; Feng, Jianjiang			Latent Palmprint Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Palmprint; forensics; latents; minutiae; MinutiaCode; matching; region growing	FINGERPRINT; ALGORITHM	The evidential value of palmprints in forensic applications is clear as about 30 percent of the latents recovered from crime scenes are from palms. While biometric systems for palmprint-based personal authentication in access control type of applications have been developed, they mostly deal with low-resolution (about 100 ppi) palmprints and only perform full-to-full palmprint matching. We propose a latent-to-full palmprint matching system that is needed in forensic applications. Our system deals with palmprints captured at 500 ppi (the current standard in forensic applications) or higher resolution and uses minutiae as features to be compatible with the methodology used by latent experts. Latent palmprint matching is a challenging problem because latent prints lifted at crime scenes are of poor image quality, cover only a small area of the palm, and have a complex background. Other difficulties include a large number of minutiae in full prints (about 10 times as many as fingerprints), and the presence of many creases in latents and full prints. A robust algorithm to reliably estimate the local ridge direction and frequency in palmprints is developed. This facilitates the extraction of ridge and minutiae features even in poor quality palmprints. A fixed-length minutia descriptor, MinutiaCode, is utilized to capture distinctive information around each minutia and an alignment-based minutiae matching algorithm is used to match two palmprints. Two sets of partial palmprints (150 live-scan partial palmprints and 100 latent palmprints) are matched to a background database of 10,200 full palmprints to test the proposed system. Despite the inherent difficulty of latent-to-full palmprint matching, rank-1 recognition rates of 78.7 and 69 percent, respectively, were achieved in searching live-scan partial palmprints and latent palmprints against the background database.	[Jain, Anil K.; Feng, Jianjiang] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Michigan State University	Jain, AK (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, 3115 Engn Bldg, E Lansing, MI 48824 USA.	jain@cse.msu.edu; jfeng@cse.msu.edu	Feng, Jianjiang/I-3386-2012		US Army Research Office [W911NF-061-0418]; National Institute of Justice [2007-RG-CXK183]; US National Science Foundation IUC on Identification Technology Research (CITeR)	US Army Research Office; National Institute of Justice(US National Institute of Justice); US National Science Foundation IUC on Identification Technology Research (CITeR)(National Science Foundation (NSF))	The authors would like to thank Karthik Nandakumar, Abhishek Nagar, and the anonymous reviewers for their valuable comments. The authors would also like to thank Meltem Demirkus for collecting live- scan palmprints. The latent and full palmprint databases used in our experiments were provided by Lt. Gregoire Michaud and Sgt. Scott Hrcka of the Forensic Science Division of the Michigan State Police and Austin Hicklin of Noblis. This work was supported by US Army Research Office grant W911NF-061-0418, US National Institute of Justice grant 2007-RG-CXK183, and a grant from the US National Science Foundation IUC on Identification Technology Research (CITeR).	Ashbaugh D.R, 1999, CRC SER PR CRIM; Bazen A. M., 2000, P WORKSH CIRC SYST S, P205; Chen XJ, 2006, IEEE T IMAGE PROCESS, V15, P767, DOI 10.1109/TIP.2005.860597; Cummins H, 1961, FINGER PRINTS PALMS; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DEWAN SK, 2003, NY TIMES         NOV; Feng JJ, 2008, PATTERN RECOGN, V41, P342, DOI 10.1016/j.patcog.2007.04.016; Funada J, 1998, INT C PATT RECOG, P1849, DOI 10.1109/ICPR.1998.712091; GALTON F, 1965, FINGERPRINTS; Germain RS, 1997, IEEE COMPUT SCI ENG, V4, P42, DOI 10.1109/99.641608; Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565; Jain A, 2002, INT CONF ACOUST SPEE, P4064; Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996; Jain AK, 2008, LATENT PALMPRINT MAT; JAIN AK, 2008, P CVPR WORKSH BIOM J; Jiang XD, 2000, INT C PATT RECOG, P1038, DOI 10.1109/ICPR.2000.906252; Komarinski P. D., 2004, AUTOMATED FINGERPRIN; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Neurotechnology Inc, 2009, VERIFINGER; *NGI, 2008, FBIS NEXT GEN ID; *NIST, 2009, NIST SPEC DAT, V27; *NIST, NIST MIN INT EXCH TE; *NSTC SUBCOMM BIOM, 2009, PALM PRINT REC; Prabhakar S., 2003, HDB FINGERPRINT RECO; Rowe RK, 2007, 2007 BIOMETRICS SYMPOSIUM, P18; *RSMITH ASS INC, 2009, DEM PALM PRINTS; Sun ZN, 2005, PROC CVPR IEEE, P279; Tico M, 2003, IEEE T PATTERN ANAL, V25, P1009, DOI 10.1109/TPAMI.2003.1217604; Wang Y, 2007, IEEE T PATTERN ANAL, V29, P573, DOI 10.1109/TPAMI.2007.1003; WILSON C, 2003, 7123 NISTIR; Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981; Zhou J, 2004, IEEE T IMAGE PROCESS, V13, P821, DOI 10.1109/TIP.2003.822608; 2007, EVALUATION LATENT FI; 2009, FVC2006 4 INT FING V	34	184	196	4	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2009	31	6					1032	1047		10.1109/TPAMI.2008.242	http://dx.doi.org/10.1109/TPAMI.2008.242			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431YF	19372608	Green Submitted			2022-12-18	WOS:000265100000006
J	Mensink, T; Verbeek, J; Perronnin, F; Csurka, G				Mensink, Thomas; Verbeek, Jakob; Perronnin, Florent; Csurka, Gabriela			Distance-Based Image Classification: Generalizing to New Classes at Near-Zero Cost	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Metric learning; k-nearest neighbors classification; nearest class mean classification; large scale image classification; transfer learning; zero-shot learning; image retrieval		We study large-scale image classification methods that can incorporate new classes and training images continuously over time at negligible cost. To this end, we consider two distance-based classifiers, the k-nearest neighbor (k-NN) and nearest class mean (NCM) classifiers, and introduce a new metric learning approach for the latter. We also introduce an extension of the NCM classifier to allow for richer class representations. Experiments on the ImageNet 2010 challenge dataset, which contains over 10(6) training images of 1,000 classes, show that, surprisingly, the NCM classifier compares favorably to the more flexible k-NN classifier. Moreover, the NCM performance is comparable to that of linear SVMs which obtain current state-of-the-art performance. Experimentally, we study the generalization performance to classes that were not used to learn the metrics. Using a metric learned on 1,000 classes, we show results for the ImageNet-10K dataset which contains 10,000 classes, and obtain performance that is competitive with the current state-of-the-art while being orders of magnitude faster. Furthermore, we show how a zero-shot class prior based on the ImageNet hierarchy can improve performance when few training images are available.	[Mensink, Thomas] Univ Amsterdam, ISLA Lab, NL-1098 XH Amsterdam, Netherlands; [Verbeek, Jakob] INRIA Grenoble, LEAR Team, F-38330 Montbonnot St Martin, France; [Perronnin, Florent; Csurka, Gabriela] Xerox Res Ctr Europe Grenoble, F-38240 Meylan, France	University of Amsterdam	Mensink, T (corresponding author), Univ Amsterdam, ISLA Lab, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands.	thomas.mensink@uva.nl; jakob.verbeek@inria.fr; florent.perronnin@xrce.xerox.com; gabriela.csurka@xrce.xerox.com		Mensink, Thomas/0000-0002-5730-713X				Bai B, 2010, INFORM RETRIEVAL, V13, P291, DOI 10.1007/s10791-009-9117-9; Bengio S., 2011, P C NEUR INF PROC SY; Boiman O., 2008, P IEEE C COMP VIS PA; Bottou L., 2010, P 19 INT C COMP STAT; Boyd S, 2004, CONVEX OPTIMIZATION; Chai J, 2010, SIGNAL PROCESS, V90, P236, DOI 10.1016/j.sigpro.2009.06.015; Chechik G, 2010, J MACH LEARN RES, V11, P1109; Clinchant S., 2007, IMAGEVAL WORKSH CVIR; Csurka G., 2004, P INT WORKSH STAT LE; Deng J., 2010, P 11 EUR C COMP VIS; Deng J., 2009, 2009 IEEE C COMP VIS, P248, DOI [DOI 10.1109/CVPR.2009.5206848, 10.1109/CVPR.2009.5206848]; Gao T., 2011, P IEEE INT C COMP VI; Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278; Globerson A., 2006, P C NEUR INF PROC SY; Goldberger J., 2005, P C NEUR INF PROC SY; Gordo A., 2012, P IEEE C COMP VIS PA; Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541; Guillaumin M., 2009, P IEEE INT C COMP VI; Jegou H, 2008, P 10 EUR C COMP VIS; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Kostinger Martin, 2012, P IEEE C COMP VIS PA; Lampert C. H., 2009, P IEEE C COMP VIS PA; Larochelle H., 2008, P AAAI C ART INT; Le Q., 2012, P INT C MACH LEARN; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Lin Y., 2011, P IEEE C COMP VIS PA; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucchi A., 2012, P 12 EUR C COMP VIS; Mensink T., 2012, P 12 EUR C COMP VIS; Mensink T., 2012, RR8077 INRIA; Nister D., 2006, P 2006 IEEE COMP SOC; NOWAK E, 2007, P IEEE C COMP VIS PA; Parameswaran S., 2010, P C NEUR INF PROC SY; Perronnin F., 2010, P 11 EUR C COMP VIS; Perronnin F., 2012, P IEEE C COMP VIS PA; Rohrbach M., 2011, P IEEE C COMP VIS PA; Saenko K., 2010, P 11 EUR C COMP VIS; Sanchez J., 2011, P IEEE C COMP VIS PA; Tommasi T, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.87; Veenman CJ, 2005, IEEE T PATTERN ANAL, V27, P1496, DOI 10.1109/TPAMI.2005.182; Wang Z., 2010, P 11 EUR C COMP VIS; Webb A.R., 2003, STAT PATTERN RECOGNI; Weinberger K., 2009, P C NEUR INF PROC SY; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Weston Jason, 2011, 22 INT JOINT C ART I; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhou X., 2008, P 16 ACM INT C MULT	48	183	195	2	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2013	35	11					2624	2637		10.1109/TPAMI.2013.83	http://dx.doi.org/10.1109/TPAMI.2013.83			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	223SU	24051724	Green Submitted			2022-12-18	WOS:000324830900005
J	Moosmann, F; Nowak, E; Jurie, F				Moosmann, Frank; Nowak, Eric; Jurie, Frederic			Randomized clustering forests for image classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						randomized trees; image classification; object recognition; similarity measure		This paper introduces three new contributions to the problems of image classification and image search. First, we propose a new image patch quantization algorithm. Other competitive approaches require a large code book and the sampling of many local regions for accurate image description, at the expense of a prohibitive processing time. We introduce Extremely Randomized Clustering Forests-ensembles of randomly created clustering trees-that are more accurate, much faster to train and test, and more robust to background clutter compared to state-of-the-art methods. Second, we propose an efficient image classification method that combines ERC-Forests and saliency maps very closely with image information sampling. For a given image, a classifier builds a saliency map online, which it uses for classification. We demonstrate speed and accuracy improvement in several state-of-the-art image classification tasks. Finally, we show that our ERC-Forests are used very successfully for learning distances between images of never-seen objects. Our algorithm learns the characteristic differences between local descriptors sampled from pairs of the "same" or "different" objects, quantizes these differences with ERC-Forests, and computes the similarity from this quantization. We show significant improvement over state-of-the-art competitive approaches.	[Moosmann, Frank] Univ Karlsruhe, Inst Mess & Regelungstech, D-76131 Karlsruhe, Germany; [Nowak, Eric] LEAR Group INRIA, F-38334 Saint Ismier, France; [Jurie, Frederic] Univ Caen, F-14032 Caen, France; [Jurie, Frederic] LEAR Grp, F-14032 Caen, France	Helmholtz Association; Karlsruhe Institute of Technology; Universite de Caen Normandie	Moosmann, F (corresponding author), Univ Karlsruhe, Inst Mess & Regelungstech, Engler Bunte Ring 21, D-76131 Karlsruhe, Germany.	moosmann@mrt.uka.de; eric.nowak@inrialpes.fr; frederic.jurie@unicaen.fr						AMIT Y, 1997, JOINT INDUCTION SHAP; AVRAHAM T, 2004, P 8 EUR C COMP VIS; Bar-Hillel AB, 2005, J MACH LEARN RES, V6, P937; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Berg TL, 2004, PROC CVPR IEEE, P848; BEYER K, 1999, P 7 INT C DAT THEOR, P217; Blockeel H., 1998, P 15 INT C MACH LEAR, P55; BONAIUTO J, 2005, P 3 INT WORKSH ATT P; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; EVERINGHAM M, 2006, P 1 PASCAL CHALL WOR; Ferencz A, 2005, IEEE I CONF COMP VIS, P286; FERENCZ AD, 2005, P ANN C NEUR INF PRO, P425; Fergus R, 2005, IEEE I CONF COMP VIS, P1816; Fitzpatrick JJ, 2003, APPL NURS RES, V16, P1, DOI 10.1053/apnr.2003.50006; FLEURET F, 2005, P ANN C NEUR INF PRO, P371; FRITZ G, 2004, P WORKSH EARL COGN V; FROME A, 2006, P ANN C NEUR INF PRO; GEURTS P, 2006, MACHINE LEARNING J, V63; GLOBERSON A, 2005, P ANN C NEUR INF PRO; GOLDBERGER J, 2004, P ANN C NEUR INF PRO; HALL D, 2002, P 13 BRIT MACH VIS C; HARRIS C, 1988, P 40 ALV VIS C; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jain V., 2006, P BRIT MACH VIS C BM, V1, P357; Jurie F, 2004, PROC CVPR IEEE, P90; Jurie F., 2005, P 10 IEEE INT C COMP; KADIR T, 2001, INT J COMPUTER VISIO, V45; LEIBE B, 2003, P 14 BRIT MACH VIS C; Lepetit V, 2005, PROC CVPR IEEE, P775; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Liu B., 2000, P 9 INT C INF KNOWL, P20; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; LOWE DG, 1995, NEURAL COMPUT, V7, P72, DOI 10.1162/neco.1995.7.1.72; Maree R, 2005, PROC CVPR IEEE, P34; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Miller EG, 2000, PROC CVPR IEEE, P464, DOI 10.1109/CVPR.2000.855856; NAVALPAKKAM V, 2003, P 1 INT WORKSH ATT P; NISTER D, 2006, P IEEE INT C COMP VI; NOWAK E, 2006, P 9 EUR C COMP VIS; OBDRZLEK S, 2005, P 16 BRIT MACH VIS C; OPELT A, 2005, P 14 SCAND C IM AN; PERRONNIN F, 2006, P 9 EUR C COMP VIS; Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446; Sebe N, 2003, PATTERN RECOGN LETT, V24, P89, DOI 10.1016/S0167-8655(02)00192-7; SERRE T, 2002, P 13 BRIT MACH VIS C; SHAFT U, 1998, 1388 TR U WISC DEP C; Shalev-Shwartz S., 2004, P 21 INT C MACH LEAR, DOI 10.1145/1015330.1015376.94.; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; STOLLNITZ EJ, 1995, IEEE COMPUT GRAPH, V15, P76, DOI 10.1109/38.376616; Vidal-Naquet M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P281; WALKER KN, 1998, P 13 BRIT MACH VIS C; WALTHER D, 2004, P 8 EUR C COMP VIS; WEINBERGER K, 2006, P ANN C NEUR INF PRO; Winn J, 2005, IEEE I CONF COMP VIS, P1800; XING EP, 2002, P ANN C NEUR INF PRO; YE Y, 1995, P IEEE INT S COMP VI; Zaharescu A, 2004, P INT WORKSH ATT PER, P133; ZHANG J, 2006, INT J COMP VIS	61	183	211	0	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2008	30	9					1632	1646		10.1109/TPAMI.2007.70822	http://dx.doi.org/10.1109/TPAMI.2007.70822			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	324FZ	18617720	Green Submitted			2022-12-18	WOS:000257504400010
J	Favaro, P; Soatto, S				Favaro, P; Soatto, S			A geometric approach to shape from defocus	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape from defocus; depth from defocus; blind deconvolution; image processing; deblurring; shape; 3D reconstruction; shape estimation; image restoration; learning subspaces	DEPTH; EDGE	We introduce a novel approach to shape from defocus, i.e., the problem of inferring the three-dimensional (3D) geometry of a scene from a collection of defocused images. Typically, in shape from defocus, the task of extracting geometry also requires deblurring the given images. A common approach to bypass this task relies on approximating the scene locally by a plane parallel to the image (the so-called equifocal assumption). We show that this approximation is indeed not necessary, as one can estimate 3D geometry while avoiding deblurring without strong assumptions on the scene. Solving the problem of shape from defocus requires modeling how light interacts with the optics before reaching the imaging surface. This interaction is described by the so-called point spread function (PSF). When the form of the PSF is known, we propose an optimal method to infer 3D geometry from defocused images that involves computing orthogonal operators which are regularized via functional singular value decomposition. When the form of the PSF is unknown, we propose a simple and efficient method that first learns a set of projection operators from blurred images and then uses these operators to estimate the 3D geometry of the scene from novel blurred images. Our experiments on both real and synthetic images show that the performance of the algorithm is relatively insensitive to the form of the PSF. Our general approach is to minimize the Euclidean norm of the difference between the estimated images and the observed images. The method is geometric in that we reduce the minimization to performing projections onto linear subspaces, by using inner product structures on both infinite and finite-dimensional Hilbert spaces. Both proposed algorithms involve only simple matrix-vector multiplications which can be implemented in real-time.	Univ Cambridge, Dept Elect Engn, Cambridge, England; Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA	University of Cambridge; University of California System; University of California Los Angeles	Favaro, P (corresponding author), Univ Cambridge, Dept Elect Engn, Cambridge, England.	favaro@cs.ucla.edu; soatto@ucla.edu						Asada N, 1998, INT J COMPUT VISION, V26, P153, DOI 10.1023/A:1007996810301; Bertero Mario, 2020, INTRO INVERSE PROBLE, P2; Bhasin SS, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P488, DOI 10.1109/ICCV.2001.937556; Born M., 1980, PRINCIPLES OPTICS, P180; Chaudhuri S., 1999, DEPTH DEFOCUS REAL A; ENS J, 1993, IEEE T PATTERN ANAL, V15, P97, DOI 10.1109/34.192482; Faugeras Olivier, 1993, 3 DIMENSIONAL VISION, P2; Favaro P, 2003, INT J COMPUT VISION, V52, P25, DOI 10.1023/A:1022366408068; Favaro P, 2000, LECT NOTES COMPUT SC, V1842, P755; Favaro P., 2003, P IEEE C COMP VIS PA; FAVARO P, 2002, P EUR C COMP VIS, V2, P735; Forsyth DA, 2002, PRENT HALL PROF TECH; Girod B., 1989, SPIE, V1194, P209; GOKSTORP M, 1994, P INT C PATT REC, pA153; GOLUB GH, 1973, SIAM J NUMER ANAL, V10, P413, DOI 10.1137/0710036; Luenberger DG, 1968, OPTIMIZATION VECTOR; Ma Y., 2003, INVITATION 3D VISION; Marshall JA, 1996, J OPT SOC AM A, V13, P681, DOI 10.1364/JOSAA.13.000681; Nair H. N., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P309, DOI 10.1109/CVPR.1992.223258; Nayar S., 1990, IEEE INT C ROB AUT, DOI DOI 10.1109/ROBOT.1990.125976; Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306; Nayar SK, 1996, IEEE T PATTERN ANAL, V18, P1186, DOI 10.1109/34.546256; NOGUCHI M, 1994, INT C PATT RECOG, P147, DOI 10.1109/ICPR.1994.576247; PENTLAND A, 1994, J OPT SOC AM A, V11, P2925, DOI 10.1364/JOSAA.11.002925; PENTLAND A, 1989, COMPUTER VISION PATT, P256; PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940; Rajagopalan AN, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1047, DOI 10.1109/ICCV.1998.710846; Rajagopalan AN, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC636; RAJAGOPALAN AN, 1997, COMPUTER VISION PATT, P219; SCHECHNER Y, 1993, P INT C COMP VIS, P843; SCHNEIDER G, 1994, IEEE IMAGE PROC, P116, DOI 10.1109/ICIP.1994.413542; Soatto S, 2000, PROC CVPR IEEE, P10, DOI 10.1109/CVPR.2000.854725; SUBBARAO M, 1994, INT J COMPUT VISION, V13, P271, DOI 10.1007/BF02028349; SUBBARAO M, 1988, CVPR, P498; Watanabe M, 1998, INT J COMPUT VISION, V27, P203, DOI 10.1023/A:1007905828438; WATANABE M, 1996, CVPR 96, P431; Xiong Y., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P68, DOI 10.1109/CVPR.1993.340977; XIONG Y, 1995, P INT C INT ROB SYST, P108; YENFU L, 1998, UNIFIED APPROACH IMA; Ziou D, 2001, COMPUT VIS IMAGE UND, V81, P143, DOI 10.1006/cviu.2000.0899	41	183	213	6	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2005	27	3					406	417		10.1109/TPAMI.2005.43	http://dx.doi.org/10.1109/TPAMI.2005.43			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	887IW	15747795				2022-12-18	WOS:000226300200009
J	Yap, PT; Jiang, XD; Kot, AC				Yap, Pew-Thian; Jiang, Xudong; Kot, Alex Chichung			Two-Dimensional Polar Harmonic Transforms for Invariant Image Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Polar harmonic transforms; harmonic kernels; rotation invariance; Zernike moments; pseudo-Zernike moments; orthogonal moments	ZERNIKE MOMENTS; RECOGNITION	This paper introduces a set of 2D transforms, based on a set of orthogonal projection bases, to generate a set of features which are invariant to rotation. We call these transforms Polar Harmonic Transforms (PHTs). Unlike the well-known Zernike and pseudo-Zernike moments, the kernel computation of PHTs is extremely simple and has no numerical stability issue whatsoever. This implies that PHTs encompass the orthogonality and invariance advantages of Zernike and pseudo-Zernike moments, but are free from their inherent limitations. This also means that PHTs are well suited for application where maximal discriminant information is needed. Furthermore, PHTs make available a large set of features for further feature selection in the process of seeking for the best discriminative or representative features for a particular application.	[Yap, Pew-Thian; Jiang, Xudong; Kot, Alex Chichung] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Yap, PT (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.	ptyap@med.unc.edu; exdjiang@ntu.edu.sg; eackot@ntu.edu.sg	Yap, Pew-Thian/G-3292-2012; Jiang, Xudong/B-1555-2008	Jiang, Xudong/0000-0002-9104-2315	Singapore A*Star SERC [0621300056]	Singapore A*Star SERC(Agency for Science Technology & Research (A*STAR))	This work was supported by Singapore A*Star SERC Research Grant No: 0621300056. This work was performed when Pew-Thian Yap was with the Nanyang Technological University.	ABUMOSTAFA YS, 1985, IEEE T PATTERN ANAL, V7, P46, DOI 10.1109/TPAMI.1985.4767617; ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698, DOI 10.1109/TPAMI.1984.4767594; Al-Rawi M, 2008, J REAL-TIME IMAGE PR, V3, P89, DOI 10.1007/s11554-007-0069-2; BHATIA AB, 1954, P CAMB PHILOS SOC, V50, P40, DOI 10.1017/S0305004100029066; Canterakis N., 1999, P SCANDINAVIAN C IMA, P85; Chong CW, 2003, PATTERN RECOGN, V36, P731, DOI 10.1016/S0031-3203(02)00091-2; Coatrieux JL, 2008, IEEE ENG MED BIOL, V27, P81, DOI [10.1109/MEMB.2007.911462, 10.1109/MEMB.20O7.911462]; Flusser J, 2003, LECT NOTES COMPUT SC, V2756, P41; Foon NH, 2004, I C COMP GRAPH IM VI, P65; FREUND Y, 1997, P EUR C COMP LEARN T, P23; Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279; GHOSAL S, 1994, IEEE T IMAGE PROCESS, V3, P14, DOI 10.1109/83.265977; ISKANDAR B, 2001, IEEE T ENG MANAGE, V48, P1; JACKSON D, 1941, FOURIER SERIES ORTHO, pCH7; Kan C, 2002, PATTERN RECOGN, V35, P143, DOI 10.1016/S0031-3203(00)00179-5; Kim HS, 2003, IEEE T CIRC SYST VID, V13, P766, DOI 10.1109/TCSVT.2003.815955; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Liao SX, 1998, IEEE T PATTERN ANAL, V20, P1358, DOI 10.1109/34.735809; LO CH, 1989, IEEE T PATTERN ANAL, V11, P1053, DOI 10.1109/34.42836; Mukundan R., 1998, MOMENT FUNCTIONS IMA; Novotni M., 2003, P 8 ACM S SOL MOD AP; Ren HP, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 3, PROCEEDINGS, P307, DOI 10.1109/FSKD.2007.213; SCHAPIRE RE, 1997, P 14 INT C MACH LEAR, P322; SHENG Y, 1986, J OPT SOC AM A, V3, P885, DOI 10.1364/JOSAA.3.000885; SHENG YL, 1994, J OPT SOC AM A, V11, P1748, DOI 10.1364/JOSAA.11.001748; Shu HZ, 2008, IEEE ENG MED BIOL, V27, P89, DOI 10.1109/MEMB.2008.918690; Shu HZ, 2007, IEEE ENG MED BIOL, V26, P70, DOI 10.1109/EMB.2007.906026; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913; Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109; Wang LZ, 1998, IEEE T IMAGE PROCESS, V7, P196, DOI 10.1109/83.660996; YAP PT, 2008, P INT C PATT REC, P1	32	182	197	1	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2010	32	7					1259	1270		10.1109/TPAMI.2009.119	http://dx.doi.org/10.1109/TPAMI.2009.119			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	595YC	20489228				2022-12-18	WOS:000277649100008
J	Yang, GH; Stewart, CV; Sofka, M; Tsai, CL				Yang, Gehua; Stewart, Charles V.; Sofka, Michal; Tsai, Chia-Ling			Registration of challenging image pairs: Initialization, estimation, and decision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image registration; feature extraction; iterative closest point; radial lens distortion; decision criteria; keypoint	MUTUAL-INFORMATION; ROBUST; MAXIMIZATION; SCALE; ALGORITHM; ALIGNMENT	Our goal is an automated 2D-image-pair registration algorithm capable of aligning images taken of a wide variety of natural and man-made scenes as well as many medical images. The algorithm should handle low overlap, substantial orientation and scale differences, large illumination variations, and physical changes in the scene. An important component of this is the ability to automatically reject pairs that have no overlap or have too many differences to be aligned well. We propose a complete algorithm including techniques for initialization, for estimating transformation parameters, and for automatically deciding if an estimate is correct. Keypoints extracted and matched between images are used to generate initial similarity transform estimates, each accurate over a small region. These initial estimates are rank-ordered and tested individually in succession. Each estimate is refined using the Dual-Bootstrap ICP algorithm, driven by matching of multiscale features. A three-part decision criteria, combining measurements of alignment accuracy, stability in the estimate, and consistency in the constraints, determines whether the refined transformation estimate is accepted as correct. Experimental results on a data set of 22 challenging image pairs show that the algorithm effectively aligns 19 of the 22 pairs and rejects 99.8 percent of the misalignments that occur when all possible pairs are tried. The algorithm substantially out-performs algorithms based on keypoint matching alone.	Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA; Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Min Hsiung Chia Yi, Taiwan	Rensselaer Polytechnic Institute; National Chung Cheng University	Yang, GH (corresponding author), Rensselaer Polytech Inst, Dept Comp Sci, 110 8th St, Troy, NY 12180 USA.	yangg2@cs.rpi.edu; stewart@cs.rpi.edu; sofka@cs.rpi.edu; tsaic@cs.ccu.edu.tw						[Anonymous], 2004, EMERGING TOPICS COMP; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Belongie S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P675, DOI 10.1109/ICCV.1998.710790; BERGEN JR, 1992, P EUR C COMP VIS, P237; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; Brown M, 2005, PROC CVPR IEEE, P510; Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218; Bubna K, 2000, COMPUT VIS IMAGE UND, V80, P215, DOI 10.1006/cviu.2000.0871; Burnham K.P., 2002, MODEL SELECTION MULT, V2nd edn, DOI DOI 10.1007/B97636; Can A, 2002, IEEE T PATTERN ANAL, V24, P347, DOI 10.1109/34.990136; Champleboux G., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P83, DOI 10.1109/CVPR.1992.223223; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Chui H, 2004, IEEE T PATTERN ANAL, V26, P160, DOI 10.1109/TPAMI.2004.1262178; Dufournaud YE, 2004, COMPUT VIS IMAGE UND, V93, P175, DOI 10.1016/j.cviu.2003.07.003; Fergus R, 2003, PROC CVPR IEEE, P264; FERRARI V, 2004, P 8 EUR C COMP VIS; FRANSENS R, 2004, P THEOR APPL KNOW DR; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; GOOL LV, 1996, P 4 EUR C COMP VIS; Granger S, 2002, LECT NOTES COMPUT SC, V2353, P418; GRIMSON WEL, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P430, DOI 10.1109/CVPR.1994.323862; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Hill DLG, 2001, PHYS MED BIOL, V46, pR1, DOI 10.1088/0031-9155/46/3/201; HOLLAND PW, 1977, COMMUN STAT A-THEOR, V6, P813, DOI 10.1080/03610927708827533; Irani M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P959, DOI 10.1109/ICCV.1998.710832; KADIR T, 2004, P 8 EUR C COMP VIS; Kanatani K., 1996, STAT OPTIMIZATION GE; Lindeberg T., 1994, SCALE SPACE THEORY C; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Luo B, 2002, IMAGE VISION COMPUT, V20, P377, DOI 10.1016/S0262-8856(02)00010-0; Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; MILLER JV, 1997, THESIS RENSSELAER PO; Pluim JPW, 2000, IEEE T MED IMAGING, V19, P809, DOI 10.1109/42.876307; Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867; SAWHNEY H, 1998, P 5 EUR C COMP VIS, V2, P103; Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414; Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446; SHAN Y, 2005, P IEEE C COMP VIS PA; Shen DG, 2002, IEEE T MED IMAGING, V21, P1421, DOI 10.1109/TMI.2002.803111; STEELE KL, 2005, P IEEE C COMP VIS PA; Stewart CV, 1999, SIAM REV, V41, P513, DOI 10.1137/S0036144598345802; Stewart CV, 2003, IEEE T MED IMAGING, V22, P1379, DOI 10.1109/TMI.2003.819276; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Torr PHS, 1997, PROC CVPR IEEE, P47, DOI 10.1109/CVPR.1997.609296; Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	53	182	199	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2007	29	11					1973	1989		10.1109/TPAMI.2007.1116	http://dx.doi.org/10.1109/TPAMI.2007.1116			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	208UE	17848778	Green Submitted			2022-12-18	WOS:000249343900008
J	Gavrila, DM				Gavrila, Dariu M.			A Bayesian, exemplar-based approach to hierarchical shape matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						hierarchical shape matching; chamfer distance; Bayesian models	RECOGNITION; TRACKING; IMAGES	This paper presents a novel probabilistic approach to hierarchical, exemplar-based shape matching. No feature correspondence is needed among exemplars, just a suitable pairwise similarity measure. The approach uses a template tree to efficiently represent and match the variety of shape exemplars. The tree is generated offline by a bottom-up clustering approach using stochastic optimization. Online matching involves a simultaneous coarse-to-fine approach over the template tree and over the transformation parameters. The main contribution of this paper is a Bayesian model to estimate the a posteriori probability of the object class, after a certain match at a node of the tree. This model takes into account object scale and saliency and allows for a principled setting of the matching thresholds such that unpromising paths in the tree traversal process are eliminated early on. The proposed approach was tested in a variety of application domains. Here, results are presented on one of the more challenging domains: real-time pedestrian detection from a moving vehicle. A significant speed-up is obtained when comparing the proposed probabilistic matching approach with a manually tuned nonprobabilistic variant, both utilizing the same template tree structure.	DaimlerChrysler R&D, Machine Percept Dept, D-89081 Ulm, Germany; Univ Amsterdam, Intelligent Syst Lab, Fac Sci, NL-1098 SJ Amsterdam, Netherlands	Daimler AG; University of Amsterdam	Gavrila, DM (corresponding author), DaimlerChrysler R&D, Machine Percept Dept, Wilhelm Runge St 11, D-89081 Ulm, Germany.	dariu.gavrila@DaimlerChrysler.com						Amit Y, 2004, IEEE T PATTERN ANAL, V26, P1606, DOI 10.1109/TPAMI.2004.111; Barrow HG, 1977, P 5 INT JOINT C ART; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Duta N, 2001, IEEE T PATTERN ANAL, V23, P433, DOI 10.1109/34.922703; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; Gavrila D. M., 2001, Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191), P369; Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7; GAVRILA DM, 1999, P IEEE INT C COMP VI, P87, DOI DOI 10.1109/ICCV.1999.791202; Gdalyahu Y, 1999, IEEE T PATTERN ANAL, V21, P1312, DOI 10.1109/34.817410; GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x; HEAP T, 1997, P BRIT MACH VIS C; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; LIEBE B, 2005, P C COMP VIS PATT RE, P878; *MATHWORKS MATL, 2005, FUNCT KSDENS; Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571; Olson CF, 1997, IEEE T IMAGE PROCESS, V6, P103, DOI 10.1109/83.552100; OLSON CF, 1998, P C COMP VIS PATT RE; PAGLIERONI DW, 1994, IEEE T PATTERN ANAL, V16, P740, DOI 10.1109/34.297956; RUCKLIDGE WJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P457, DOI 10.1109/ICCV.1995.466904; Srivastava A, 2005, IEEE T PATTERN ANAL, V27, P590, DOI 10.1109/TPAMI.2005.86; Stenger B, 2006, IEEE T PATTERN ANAL, V28, P1372, DOI 10.1109/TPAMI.2006.189; Toyama K, 2002, INT J COMPUT VISION, V48, P9, DOI 10.1023/A:1014899027014; Yang MS, 2004, IEEE T PATTERN ANAL, V26, P434, DOI 10.1109/TPAMI.2004.1265860; Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008	30	182	202	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2007	29	8					1408	1421		10.1109/TPAMI.2007.1062	http://dx.doi.org/10.1109/TPAMI.2007.1062			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	177XT	17568144	Green Submitted			2022-12-18	WOS:000247186500009
J	Hertzmann, A; Seitz, SM				Hertzmann, A; Seitz, SM			Example-based photometric stereo: Shape reconstruction with general, varying BRDFs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						photometric stereo; shape reconstruction; shape-from-shading; bidirectional reflectance distribution function (BRDF); specular materials; clustering materials	SPECULAR SURFACES; REFLECTANCE; ALGORITHM	This paper presents a technique for computing the geometry of objects with general reflectance properties from images. For surfaces with varying material properties, a full segmentation into different material types is also computed. It is assumed that the camera viewpoint is fixed, but the illumination varies over the input sequence. It is also assumed that one or more example objects with similar materials and known geometry are imaged under the same illumination conditions. Unlike most previous work in shape reconstruction, this technique can handle objects with arbitrary and spatially-varying BRDFs. Furthermore, the approach works for arbitrary distant and unknown lighting environments. Finally, almost no calibration is needed, making the approach exceptionally simple to apply.	Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada; Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA	University of Toronto; University of Washington; University of Washington Seattle	Hertzmann, A (corresponding author), Univ Toronto, Dept Comp Sci, 10 Kings Coll Rd,Room 3302, Toronto, ON M5S 3G4, Canada.	hertzman@dgp.toronto.edu; seitz@cs.washington.edu		Hertzmann, Aaron/0000-0001-9667-0292				Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Bajcsy R., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P785, DOI 10.1109/ICPR.1990.118217; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Basri R, 2001, PROC CVPR IEEE, P374; Beis JS, 1999, IEEE T PATTERN ANAL, V21, P1000, DOI 10.1109/34.799907; Chen WC, 2002, ACM T GRAPHIC, V21, P447, DOI 10.1145/566570.566601; COLEMAN EN, 1982, COMPUT VISION GRAPH, V18, P309, DOI 10.1016/0146-664X(82)90001-6; Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778; Debevec P., 1997, P ACM SIGGRAPH 1997, DOI [DOI 10.1145/258734.258884, 10.1145/258734.258884]; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; GEORGHIADES AS, 2003, P EUR WORKSH REND, P230; HEALEY G, 1992, IEEE T SYST MAN CYB, V22, P64, DOI 10.1109/21.141311; Hertzmann A, 2003, PROC CVPR IEEE, P533; Horn B., 1986, ROBOT VISION, P1; IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167; KLINKER GJ, 1990, INT J COMPUT VISION, V4, P7, DOI 10.1007/BF00137441; KRIEGMAN DJ, 2003, P EUR C COMP VIS OCT, P1411; Lensch HPA, 2003, ACM T GRAPHIC, V22, P234, DOI 10.1145/636886.636891; Lu R, 1998, APPL OPTICS, V37, P5974, DOI 10.1364/AO.37.005974; Matusik W, 2003, ACM T GRAPHIC, V22, P759, DOI 10.1145/882262.882343; MATUSIK W, 2003, P 14 EUR WORKSH REND, P241; NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P418, DOI 10.1109/70.59367; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; Pelleg D., 2000, P 17 INT C MACH LEAR, DOI DOI 10.1038/S41598-021-86770-6; Ramantoorthi R, 2002, ACM T GRAPHIC, V21, P517, DOI 10.1145/566570.566611; Silver William M, 1980, THESIS MIT; SMITH AR, 1996, P SIGGRAPH 96, P259; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; Treuille A, 2004, LECT NOTES COMPUT SC, V3022, P457; Tu P, 2003, PROC CVPR IEEE, P541; Wolff L.B., 1992, PHYS BASED VISION PR; Wood DN, 2000, COMP GRAPH, P287, DOI 10.1145/344779.344925; WOODHAM RJ, 1994, J OPT SOC AM A, V11, P3050, DOI 10.1364/JOSAA.11.003050; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; WOODHAM RJ, 1978, AITR457 MIT ART INT; Zickler TE, 2003, PROC CVPR IEEE, P548; Zickler TE, 2002, INT J COMPUT VISION, V49, P215, DOI 10.1023/A:1020149707513	38	182	198	1	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2005	27	8					1254	1264		10.1109/TPAMI.2005.158	http://dx.doi.org/10.1109/TPAMI.2005.158			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	934HW	16119264	Green Submitted			2022-12-18	WOS:000229700900006
J	Vacchetti, L; Lepetit, V; Fua, P				Vacchetti, L; Lepetit, V; Fua, P			Stable real-time 3D tracking using online and offline information	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; real-time systems; tracking	MOTION; INTEGRATION; MODELS	We propose an efficient real-time solution for tracking rigid objects in 3D using a single camera that can handle large camera displacements, drastic aspect changes, and partial occlusions. While commercial products are already available for offline camera registration, robust online tracking remains an open issue because many real-time algorithms described in the literature still lack robustness and are prone to drift and jitter. To address these problems, we have formulated the tracking problem in terms of local bundle adjustment and have developed a method for establishing image correspondences that can equally well handle short and wide-baseline matching. We then can merge the information from preceding frames with that provided by a very limited number of keyframes created during a training stage, which results in a real-time tracker that does not jitter or drift and can deal with significant aspect changes.	Swiss Fed Inst Technol, Comp Vis Lab, EPFL, CH-1015 Lausanne, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Vacchetti, L (corresponding author), Swiss Fed Inst Technol, Comp Vis Lab, EPFL, CH-1015 Lausanne, Switzerland.	luca.vacchetti@epfl.ch; vincent.lepetit@epfl.ch; pascal.fua@epfl.ch	Fua, Pascal/H-3928-2011	Fua, Pascal/0000-0002-6702-9970				AZARBAYEJANI A, 1995, IEEE T PATTERN ANAL, V17, P562, DOI 10.1109/34.387503; Beardsley PA, 1997, INT J COMPUT VISION, V23, P235, DOI 10.1023/A:1007923216416; CASCIA ML, 2000, IEEE T PATTERN ANAL, V22; Chia K. W, 2002, P INT S MIX AUGM REA; Chris H., 1988, P 4 ALVEY VISION C, P189; DeCarlo D, 1996, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.1996.517079; Drummond T, 2002, IEEE T PATTERN ANAL, V24, P932, DOI 10.1109/TPAMI.2002.1017620; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; FITZGIBBON AW, 1998, P EUR C COMP VIS, P311; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Huber P., 1981, ROBUST STAT; Jurie F, 2002, IEEE T PATTERN ANAL, V24, P996, DOI 10.1109/TPAMI.2002.1017625; LEPETIT V, 2003, P INT S MIX AUGM REA; LOWE D, 2004, IN PRESS P INT COMP; LOWE DG, 1992, INT J COMPUT VISION, V8, P113, DOI 10.1007/BF00127170; Marchand E., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P262, DOI 10.1109/ICCV.1999.791229; Neumann U, 1999, IEEE T MULTIMEDIA, V1, P53, DOI 10.1109/6046.748171; NISTER D, 2003, P C COMP VIS PATT RE; POLLEFEYS M, 1998, P INT C COMP VIS; RAVELA S, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 1, P174, DOI 10.1109/IROS.1995.525793; SHAN Y, 2001, P INT C COMP VIS JUL; Simon G, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P120, DOI 10.1109/ISAR.2000.880935; SIMON G, 1998, P INT WORKSH AUGM RE; Vacchetti L., 2003, P C COMP VIS PATT RE	25	182	209	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2004	26	10					1385	1391		10.1109/TPAMI.2004.92	http://dx.doi.org/10.1109/TPAMI.2004.92			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	844EM	15641726	Green Submitted			2022-12-18	WOS:000223140200014
J	Wang, S; Siskind, JM				Wang, S; Siskind, JM			Image segmentation with ratio cut	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						graph partitioning algorithms; cut ratio; cycle ratio; perfect matching; perceptual organization; edge detection; image segmentation; machine vision	NORMALIZED CUTS	This paper proposes anew cost function, cut ratio, for segmenting images using graph-based methods. The cut ratio is defined as the ratio of the corresponding sums of two different weights of edges along the cut boundary and models the mean affinity between the segments separated by the boundary per unit boundary length. This new cost function allows the image perimeter to be segmented, guarantees that the segments produced by bipartitioning are connected, and does not introduce a size, shape, smoothness, or boundary-length bias. The latter allows it to produce segmentations where boundaries are aligned with image edges. Furthermore, the cut-ratio cost function allows efficient iterated region-based segmentation as well as pixel-based segmentation. These properties may be useful for some image-segmentation applications. While the problem of finding a minimum ratio cut in an arbitrary graph is NP-hard, one can find a minimum ratio cut in the connected planar graphs that arise during image segmentation in polynomial time. While the cut ratio, alone, is not sufficient as a baseline method for image segmentation, it forms a good basis for an extended method of image segmentation when combined with a small number of standard techniques. We present an implemented algorithm for finding a minimum ratio cut, prove its correctness, discuss its application to image segmentation, and present the results of segmenting a number of medical and natural images using our techniques.	Univ S Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA; Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA	University of South Carolina; University of South Carolina System; University of South Carolina Columbia; Purdue University System; Purdue University; Purdue University West Lafayette Campus	Wang, S (corresponding author), Univ S Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA.	songwang@cse.sc.edu; qobi@purdue.edu		Wang, Song/0000-0003-4152-5295				Ahuja R. K., 1993, NETWORK FLOWS THEORY; Aumann Y, 1998, SIAM J COMPUT, V27, P291, DOI 10.1137/S0097539794285983; Cox I. J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P557, DOI 10.1109/ICPR.1996.546886; EDMONDS J, 1965, CANADIAN J MATH, V17, P449, DOI 10.4153/CJM-1965-045-4; EDMONDS J, 1965, J RES NATL BUR STAND, VB 69, P125, DOI 10.6028/jres.069B.013; Jermyn I. H., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P904, DOI 10.1109/ICCV.1999.790318; Jermyn IH, 2001, IEEE T PATTERN ANAL, V23, P1075, DOI 10.1109/34.954599; KARP RM, 1978, DISCRETE MATH, V23, P309, DOI 10.1016/0012-365X(78)90011-0; Malishevskii AS, 2001, PHYS SOLID STATE+, V43, P1, DOI 10.1134/1.1340176; MEHLHORN K, 1999, LEDA PLATFORM COMBIN; Sarkar S, 2000, IEEE T PATTERN ANAL, V22, P504, DOI 10.1109/34.857006; SHARON E, 2000, P IEEE CS C COMP VIS; SHARON E, 2001, P IEEE CS C COMP VIS; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shi JB, 1997, PROC CVPR IEEE, P731, DOI 10.1109/CVPR.1997.609407; SOUNDARARAJAN P, 2001, P 3 WORKSH PERC ORG; TAL D, 2000, NORMALIZED CUTS SOFT; Veksler O, 2000, PROC CVPR IEEE, P339, DOI 10.1109/CVPR.2000.855838; Wang S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P517, DOI 10.1109/ICCV.2001.937560; WANG S, 2002, TRECE0207 PURD U; WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673; [No title captured]; [No title captured]	23	182	219	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2003	25	6					675	690						16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	680DP		Green Submitted, Green Published			2022-12-18	WOS:000182961300004
J	KIMMEL, R; AMIR, A; BRUCKSTEIN, AM				KIMMEL, R; AMIR, A; BRUCKSTEIN, AM			FINDING SHORTEST PATHS ON SURFACES USING LEVEL SETS PROPAGATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CURVE EVOLUTION; EQUAL DISTANCE CONTOURS; GEODESIC PATH; NUMERICAL ALGORITHMS; MINIMAL GEODESICS	CURVATURE; EVOLUTION; FRONTS	We present a nerv algorithm for determining minimal length paths between two regions on a three dimensional surface, The numerical implementation is based on finding equal geodesic distance contours from a given area, These contours are calculated as zero sets of a bivariate function designed to evolve so as to track the equal distance curves on the given surface, The algorithm produces all paths of minimal length between the source and destination areas on the surface given as height values on a rectangular grid.	TECHNION ISRAEL INST TECHNOL,DEPT COMP SCI,IL-32000 HAIFA,ISRAEL	Technion Israel Institute of Technology	KIMMEL, R (corresponding author), TECHNION ISRAEL INST TECHNOL,DEPT ELECT ENGN,IL-32000 HAIFA,ISRAEL.							CHOPP DL, 1992, UCLA9223 DEP MATH RE; Do Carmo M.P., 2016, DIFFERENTIAL GEOMETR, Vsecond; Epstein C L, 1987, WAVE MOTION THEORY M; KIMMEL R, 1993, COMPUT AIDED DESIGN, V25, P154, DOI 10.1016/0010-4485(93)90040-U; KIMMEL R, 1993, CIS9301 TECHN REP; KIMMEL R, 1994, IN PRESS J MATH IMAG; KIMMEL R, 1992, CIS9209 TECHN REP; KIMMEL R, 1995, INT J COMP MATH APP, V29, P49; KIRYATI N, 1993, PATTERN RECOGN, V26, P1623, DOI 10.1016/0031-3203(93)90018-R; MITCHELL JSB, 1987, INT J INTELL SYST, V2, P129, DOI 10.1002/int.4550020204; MULDER W, 1992, J COMPUT PHYS, V100, P209, DOI 10.1016/0021-9991(92)90229-R; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; OSHER S, 1991, SIAM J NUMER ANAL, V28, P907, DOI 10.1137/0728049; OSHER S, 1990, SIAM J NUMER ANAL, V27, P919, DOI 10.1137/0727053; SAPIRO G, 1993, PATTERN RECOGN, V26, P1363, DOI 10.1016/0031-3203(93)90142-J; SETHIAN JA, 1985, COMMUN MATH PHYS, V101, P487, DOI 10.1007/BF01210742; SETHIAN JA, 1989, J DIFFER GEOM, V33, P131	17	182	197	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1995	17	6					635	640		10.1109/34.387512	http://dx.doi.org/10.1109/34.387512			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QZ940					2022-12-18	WOS:A1995QZ94000010
J	Sun, ZN; Tan, TN				Sun, Zhenan; Tan, Tieniu			Ordinal Measures for Iris Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Biometrics; feature representation; iris recognition; multilobe differential filter; ordinal measures	VISION; IMAGES; CORTEX	Images of a human iris contain rich texture information useful for identity authentication. A key and still open issue in iris recognition is how best to represent such textural information using a compact set of features (iris features). In this paper, we propose using ordinal measures for iris feature representation with the objective of characterizing qualitative relationships between iris regions rather than precise measurements of iris image structures. Such a representation may lose some image-specific information, but it achieves a good trade-off between distinctiveness and robustness. We show that ordinal measures are intrinsic features of iris patterns and largely invariant to illumination changes. Moreover, compactness and low computational complexity of ordinal measures enable highly efficient iris recognition. Ordinal measures are a general concept useful for image analysis and many variants can be derived for ordinal feature extraction. In this paper, we develop multilobe differential filters to compute ordinal measures with flexible intralobe and interlobe parameters such as location, scale, orientation, and distance. Experimental results on three public iris image databases demonstrate the effectiveness of the proposed ordinal feature models.	[Sun, Zhenan; Tan, Tieniu] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Ctr Biometr & Secur Res, Beijing 100190, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS	Sun, ZN (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Ctr Biometr & Secur Res, 95 Zhongguancun E Rd,POB 2728, Beijing 100190, Peoples R China.	znsun@nlpr.ia.ac.cn; tnt@nlpr.ia.ac.cn		Wang, Yunlong/0000-0002-3535-308X	National Basic Research Program of China [2004CB318110]; Natural Science Foundation of China [60736018, 60702024]; Hi-Tech Research and Development Program of China [2006AA01Z193, 2007AA01Z162]	National Basic Research Program of China(National Basic Research Program of China); Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Hi-Tech Research and Development Program of China(National High Technology Research and Development Program of China)	The authors are grateful to the anonymous reviewers for their constructive comments and suggestions. They would like to thank the University of Bath and NIST for sharing their iris image databases with us. This work was supported in part by the National Basic Research Program of China (Grant No. 2004CB318110), the Natural Science Foundation of China (Grant No. 60736018, 60702024), and the Hi-Tech Research and Development Program of China (Grant No. 2006AA01Z193, 2007AA01Z162). The work described in this paper has been filed for patents.	[Anonymous], 2009, CASIA IRIS IMAGE DAT; [Anonymous], 2005, 197946 ISOIEC; BALAS B, 2005, 246 CBCL MIT; Balas BJ, 2003, 229 CBCL MIT; Bhat DN, 1998, IEEE T PATTERN ANAL, V20, P415, DOI 10.1109/34.677275; Boles WW, 1998, IEEE T SIGNAL PROCES, V46, P1185, DOI 10.1109/78.668573; Bolle RM, 2004, COMPUT VIS IMAGE UND, V93, P1, DOI 10.1016/j.cviu.2003.08.002; Cui JL, 2004, LECT NOTES COMPUT SC, V3072, P442; Daugman J, 2001, INT J COMPUT VISION, V45, P25, DOI 10.1023/A:1012365806338; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; DEANGELIS GC, 1993, J NEUROPHYSIOL, V69, P1091, DOI 10.1152/jn.1993.69.4.1091; Huang J., 2004, P 6 AS C COMP VIS, VII, P954; IBG: International biometric group, 2005, INT BIOM GROUP IND T; *IR, 2009, IR CHALL EV; Kendall M.G., 1990, RANK CORRELATION MET, V5th; Lim S, 2001, ETRI J, V23, P61, DOI 10.4218/etrij.01.0101.0203; Lipson P, 1997, PROC CVPR IEEE, P1007, DOI 10.1109/CVPR.1997.609453; Ma L, 2004, IEEE T IMAGE PROCESS, V13, P739, DOI 10.1109/TIP.2004.827237; Ma L, 2004, PATTERN RECOGN, V37, P1287, DOI 10.1016/j.patcog.2004.02.001; Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145; Macmillan NA., 2005, DETECTION THEORY USE, VSecond; Monro DM, 2007, IEEE T PATTERN ANAL, V29, P586, DOI 10.1109/TPAMI.2007.1002; NOH S, 2003, P 4 INT C AUD VID BA, P838; PARK C, 2003, P 4 INT C AUD VID BA, P224; Partio M, 2004, IEEE IMAGE PROC, P1537; Phillips PJ, 2007, IEEE T PATTERN ANAL, V29, P1869, DOI [10.1109/TPAMI.2007.1137., 10.1109/TPAMI.2007.1137]; SADR J, 2002, ADV NEURAL INFORM PR; Sanchez-Avila C, 2005, PATTERN RECOGN, V38, P231, DOI 10.1016/j.patcog.2004.07.004; Sinha P, 2002, LECT NOTES COMPUT SC, V2525, P249; SINHA P, 1995, THESIS MIT, P141; SMERALDI F, 2003, RR030901 U LOND DEP; STEVENS SS, 1946, SCIENCE, V103, P677, DOI 10.1126/science.103.2684.677; Sun ZN, 2004, LECT NOTES COMPUT SC, V3338, P67; Sun ZN, 2004, INT C PATT RECOG, P783, DOI 10.1109/ICPR.2004.1334375; Sun ZN, 2004, LECT NOTES COMPUT SC, V3087, P270; THORESZ KJ, 2002, THESIS MIT; Thornton J, 2007, IEEE T PATTERN ANAL, V29, P596, DOI 10.1109/TPAMI.2007.1006; Tisse C., 2002, P VIS INT, P294; *U BATH, U BATH IR IM DAT; Van Rullen R, 2001, NEURAL COMPUT, V13, P1255, DOI 10.1162/08997660152002852; Wildes RP, 1996, MACH VISION APPL, V9, P1, DOI 10.1007/BF01246633; Young RA, 2001, SPATIAL VISION, V14, P261, DOI 10.1163/156856801753253582	42	181	196	0	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2009	31	12					2211	2226		10.1109/TPAMI.2008.240	http://dx.doi.org/10.1109/TPAMI.2008.240			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	511BY	19834142				2022-12-18	WOS:000271140100009
J	Whitehill, J; Littlewort, G; Fasel, I; Bartlett, M; Movellan, J				Whitehill, Jacob; Littlewort, Gwen; Fasel, Ian; Bartlett, Marian; Movellan, Javier			Toward Practical Smile Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face and gesture recognition; machine learning; computer vision	FACIAL EXPRESSION RECOGNITION; SEQUENCES	Machine learning approaches have produced some of the highest reported performances for facial expression recognition. However, to date, nearly all automatic facial expression recognition research has focused on optimizing performance on a few databases that were collected under controlled lighting conditions on a relatively small number of subjects. This paper explores whether current machine learning methods can be used to develop an expression recognition system that operates reliably in more realistic conditions. We explore the necessary characteristics of the training data set, image registration, feature representation, and machine learning algorithms. A new database, GENKI, is presented which contains pictures, photographed by the subjects themselves, from thousands of different people in many different real-world imaging conditions. Results suggest that human-level expression recognition accuracy in real-life illumination conditions is achievable with machine learning technology. However, the data sets currently used in the automatic expression recognition literature to evaluate progress may be overly constrained and could potentially lead research into locally optimal algorithmic solutions.	[Whitehill, Jacob; Littlewort, Gwen; Bartlett, Marian; Movellan, Javier] Univ Calif San Diego, Machine Percept Lab, La Jolla, CA 92093 USA; [Fasel, Ian] Univ Arizona, Dept Comp Sci, Tucson, AZ 85721 USA	University of California System; University of California San Diego; University of Arizona	Whitehill, J (corresponding author), Univ Calif San Diego, Machine Percept Lab, Atkinson Hall CALIT2,6100,9500 Gilman Dr,Mail Cod, La Jolla, CA 92093 USA.	jake@mplab.ucsd.edu; gwen@mplab.ucsd.edu; ianfasel@cs.arizona.edu; marni@salk.edu; movellan@mplab.ucsd.edu			US National Science Foundation (NSF) [0808767]; UC [10202]	US National Science Foundation (NSF)(National Science Foundation (NSF)); UC	This work was supported by US National Science Foundation (NSF) IIS INT2-Large 0808767 grant and by UC Discovery Grant 10202.	Bartlett JG, 2006, J PHYS CONF SER, V39, P1, DOI 10.1088/1742-6596/39/1/001; BARTLETT M, 2006, P AUT FAC GEST REC; Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X; COHN JF, 2004, INT J WAVELETS MULTI, V2, P1; Cortes C., 2004, P ADV NEUR INF PROC; Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905; Ekman P., 1975, PICTURES FACIAL AFFE; Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3; Fasel I, 2005, COMPUT VIS IMAGE UND, V98, P182, DOI 10.1016/j.cviu.2004.07.014; FENWICK I, 1991, J ADVERTISING RES, V31, P23; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; HEUSCH G, 2006, P 7 INT C AUT FAC GE; Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611; Kapoor  A., 2003, IEEE INT WORKSH AN M; Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954; LEVI K, 2004, P 2004 IEEE C COMP V; Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Movellan J.R., 2005, TUTORIAL GABOR FILTE; O'Toole AJ, 2005, IEEE T PATTERN ANAL, V27, P812, DOI 10.1109/TPAMI.2005.90; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931; Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976; Pantic M., 2005, P IEEE INT C MULT EX; PNEVMATIKAKIS A, 2006, P 3 INT FED INF PROC; SEBE N, 2004, P IEEE INT C MULT EX; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; TIAN Y, 2003, HDB FACE RECOGNITION; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang YB, 2004, INT C PATT RECOG, P926, DOI 10.1109/ICPR.2004.1334680; WEN Z, 2003, P IEEE INT C COMP VI; YANG P, 2005, P IEEE C COMP VIS PA; Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52; Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93; Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110; ZHU Z, 2006, P IEEE CS C COMP VIS	40	181	190	0	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2009	31	11					2106	2111		10.1109/TPAMI.2009.42	http://dx.doi.org/10.1109/TPAMI.2009.42			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	493VV	19762937				2022-12-18	WOS:000269767600016
J	Miyazawa, K; Ito, K; Aoki, T; Kobayashi, K; Nakajima, H				Miyazawa, Kazuyuki; Ito, Koichi; Aoki, Takafumi; Kobayashi, Koji; Nakajima, Hiroshi			An effective approach for iris recognition using phase-based image matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition	JUN 17-22, 2007	Minneapolis, MN	IEEE, hp invent, INI-GraphicsNet, VIOSO		phase-based image matching; phase-only correlation; phase-only matched filtering; biometrics; iris recognition	ALGORITHM	This paper presents an efficient algorithm for iris recognition using phase-based image matching - an image matching technique using phase components in 2D Discrete Fourier Transforms (DFTs) of given images. Experimental evaluation using the CASIA iris image databases (versions 1.0 and 2.0) and Iris Challenge Evaluation (ICE) 2005 database clearly demonstrates that the use of phase components of iris images makes it possible to achieve highly accurate iris recognition with a simple matching algorithm. This paper also discusses the major implementation issues of our algorithm. In order to reduce the size of iris data and to prevent the visibility of iris images, we introduce the idea of 2D Fourier Phase Code (FPC) for representing iris information. The 2D FPC is particularly useful for implementing compact iris recognition devices using state-of-the-art Digital Signal Processing (DSP) technology.	[Miyazawa, Kazuyuki; Ito, Koichi; Aoki, Takafumi] Tohoku Univ, Grad Sch Informat Sci, Aoba Ku, Sendai, Miyagi 9808579, Japan; [Kobayashi, Koji; Nakajima, Hiroshi] Yamatake Corp, Fujisawa, Kanagawa 2518522, Japan	Tohoku University	Miyazawa, K (corresponding author), Tohoku Univ, Grad Sch Informat Sci, Aoba Ku, Aoba 6-6-05, Sendai, Miyagi 9808579, Japan.	miyazawa@aoki.ecei.tohoku.ac.jp; ito@aoki.ecei.tohoku.ac.jp; aoki@ecei.tohoku.ac.jp; kobayashi-koji@jp.yamatake.com; nakajima-hiroshi-1@jp.yamatake.com	Miyazawa, Kazuyuki/AAO-6925-2020; Ito, Koichi/ABC-3254-2020	Ito, Koichi/0000-0001-7431-7105				[Anonymous], 2008, CASIA IR IM DAT; Boles WW, 1998, IEEE T SIGNAL PROCES, V46, P1185, DOI 10.1109/78.668573; Bolle RM, 2004, COMPUT VIS IMAGE UND, V93, P1, DOI 10.1016/j.cviu.2003.08.002; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; Gonzalez R.C., 2006, DIGITAL IMAGE PROCES; Ito K, 2006, LECT NOTES COMPUT SC, V3832, P316; Ito K, 2004, IEICE T FUND ELECTR, VE87A, P682; Ito K., 2005, P INT C IM PROC, VII, P33; Ito K, 2006, IEEE IMAGE PROC, P2669, DOI 10.1109/ICIP.2006.313059; Jain A., 1999, BIOMETRICS PERSONAL; Kuglin C. D., 1975, Proceedings of the 1975 International Conference on Cybernetics and Society, P163; Kumar BV., 2005, CORRELATION PATTERN, DOI 10.1017/CBO9780511541087; Kumar BVKV, 2002, IEEE IMAGE PROC, P53; Kumar BVKV, 2003, LECT NOTES COMPUT SC, V2688, P697; Ma L, 2004, IEEE T IMAGE PROCESS, V13, P739, DOI 10.1109/TIP.2004.827237; Masek L., 2003, MATLAB SOURCE CODE B; Miyazawa K, 2005, IEEE IMAGE PROC, P2001; Miyazawa K, 2006, LECT NOTES COMPUT SC, V3832, P356; Nakajima H, 2006, LECT NOTES COMPUT SC, V3832, P326; *NAT I STAND TECHN, 2008, ICE 2005 RES; *NAT I STAND TECHN, 2008, IR CHALL EV ICE; Sun ZN, 2006, LECT NOTES COMPUT SC, V3832, P366; Takita K, 2004, IEICE T FUND ELECTR, VE87A, P1913; Takita K, 2003, IEICE T FUND ELECTR, VE86A, P1925; Tisse C., 2002, P VIS INT, P294; *TOH U GRAD SCH IN, 2008, PROD US PHAS BAS IM; Venkataramani K, 2004, OPT ENG, V43, P1820, DOI 10.1117/1.1765666; Wayman J. L., 2005, BIOMETRIC SYSTEMS; Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669	30	181	190	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2008	30	10					1741	1756		10.1109/TPAMI.2007.70833	http://dx.doi.org/10.1109/TPAMI.2007.70833			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	336DQ	18703828				2022-12-18	WOS:000258344900006
J	Srivastava, A; Joshi, SH; Mio, W; Liu, XW				Srivastava, A; Joshi, SH; Mio, W; Liu, XW			Statistical shape analysis: Clustering, learning, and testing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape analysis; shape statistics; shape learning; shape testing; shape retrieval; shape clustering		Using a differential-geometric treatment of planar shapes, we present tools for: 1) hierarchical clustering of imaged objects according to the shapes of their boundaries, 2) learning of probability models for clusters of shapes, and 3) testing of newly observed shapes under competing probability models. Clustering at any level of hierarchy is performed using a mimimum variance type criterion criterion and a Markov process. Statistical means of clusters provide shapes to be clustered at the next higher level, thus building a hierarchy of shapes. Using finite-dimensional approximations of spaces tangent to the shape space at sample means, we ( implicitly) impose probability models on the shape space, and results are illustrated via random sampling and classification ( hypothesis testing). Together, hierarchical clustering and hypothesis testing provide an efficient framework for shape retrieval. Examples are presented using shapes and images from ETH, Surrey, and AMCOM databases.	Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA; Florida State Univ, Dept Elect Engn, Tallahassee, FL 32306 USA; Florida State Univ, Dept Math, Tallahassee, FL 32306 USA; Florida State Univ, Dept Comp Sci, Tallahassee, FL 32306 USA	State University System of Florida; Florida State University; State University System of Florida; Florida State University; State University System of Florida; Florida State University; State University System of Florida; Florida State University	Srivastava, A (corresponding author), Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA.	anuj@stat.fsu.edu; joshi@eng.fsu.edu; mio@math.fsu.edu; liux@cs.fsu.edu	Srivastava, Anuj/F-7417-2011; Srivastava, Anuj/L-4705-2019; Joshi, Sudhanshu/L-2284-2019	Joshi, Sudhanshu/0000-0003-4748-5001				Davies RH, 2003, IMAGE VISION COMPUT, V21, P1171, DOI 10.1016/j.imavis.2003.09.003; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Duta N, 2001, IEEE T PATTERN ANAL, V23, P433, DOI 10.1109/34.922703; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Grenander U, 2001, IEEE T PATTERN ANAL, V23, P424, DOI 10.1109/34.917579; Grenander U, 1998, Q APPL MATH, V56, P617, DOI 10.1090/qam/1668732; Grenander U., 1993, GEN PATTERN THEORY; Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806; HOLBOTH A, 2002, SCANDINAVIAN J STAT, V29, P355; Hyvarinen A, 1999, IEEE T NEURAL NETWOR, V10, P626, DOI 10.1109/72.761722; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502; Kent JT, 2001, BIOMETRIKA, V88, P469, DOI 10.1093/biomet/88.2.469; Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333; LE HL, 1993, ANN STAT, V21, P1225, DOI 10.1214/aos/1176349259; Mallat S., 1989, IEEE PAMI, V11, P674; MIO W, 2004, P IEEE COMP VIS PATT; MIO W, 2004, P EUR C COMP VIS 4, P62; MOKHTARIAN F, 1995, IEEE T PATTERN ANAL, V17, P539, DOI 10.1109/34.391387; Robert C. P., 1999, MONTE CARLO STAT MET; Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788; Small C.G., 1996, STAT THEORY SHAPE	23	181	186	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2005	27	4					590	602		10.1109/TPAMI.2005.86	http://dx.doi.org/10.1109/TPAMI.2005.86			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	895FG	15794163				2022-12-18	WOS:000226845700009
J	Jain, AK; Uludag, U				Jain, AK; Uludag, U			Hiding biometric data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						biometrics; data hiding; face; fingerprint; minutiae; steganography; watermarking	WATERMARKING; SYSTEM	With the wide spread utilization of biometric identification systems, establishing the authenticity of biometric data itself has emerged as an important research issue. The fact that biometric data is not replaceable and is not secret, combined with the existence of several types of attacks that are possible in a biometric system, make the issue of security/integrity of biometric data extremely critical. We introduce two applications of an amplitude modulation-based watermarking method, in which we hide a user's biometric data in a variety of images. This method has the ability to increase the security of both the hidden biometric data (e.g., eigen-face coefficients) and host images (e.g., fingerprints) Image adaptive data embedding methods used in our scheme lead to low visibility of the embedded signal. Feature analysis of host images guarantees high verification accuracy on watermarked (e.g., fingerprint) images.	Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Michigan State University	Jain, AK (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, 3115 Engn Bldg, E Lansing, MI 48824 USA.	jain@cse.msu.edu; uludagum@cse.msu.edu						Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2; Cappelli R, 2000, INT C PATT RECOG, P471, DOI 10.1109/ICPR.2000.903586; Gunsel B, 2002, PATTERN RECOGN, V35, P2739, DOI 10.1016/S0031-3203(01)00250-3; Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066; Jain A., 1999, BIOMETRICS PERSONAL; Jain AK, 1997, P IEEE, V85, P1365, DOI 10.1109/5.628674; JAIN S, 2000, P IND C COMP VIS GRA, P139; Janbandhu P. K., 2001, Information Management & Computer Security, V9, P205, DOI 10.1108/09685220110408022; Kutter M, 1997, P SOC PHOTO-OPT INS, V3022, P518, DOI 10.1117/12.263442; Pankanti S, 1999, P SOC PHOTO-OPT INS, V3657, P66, DOI 10.1117/12.344704; RAHTA NK, 1999, P IEEE WORKSH AUT ID, P70; RATHA NK, 2001, P 3 INT C AUD VID BA, P223; RATHA NK, 2000, P ACM MULT 2000 WORK, P127; Schneier B, 1999, COMMUN ACM, V42, P136, DOI 10.1145/310930.310988; Schneier B., 1996, APPL CRYPTOGRAPHY; EVALUATION FACE RECO	16	181	189	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2003	25	11					1494	1498		10.1109/TPAMI.2003.1240122	http://dx.doi.org/10.1109/TPAMI.2003.1240122			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	733NG					2022-12-18	WOS:000186006800013
J	Pun, CM; Lee, MC				Pun, CM; Lee, MC			Log-polar wavelet energy signatures for rotation and scale invariant texture classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						rotation and scale invariance; texture classification; shift invariant wavelet packet transform; log-polar transform	SEGMENTATION	Classification of texture images, especially those with different orientation and scale changes, is a challenging and important problem in image analysis and classification. This paper proposes an effective scheme for rotation and scale invariant texture classification using log-polar wavelet signatures. The rotation and scale invariant feature extraction for a given image involves applying a log-polar transform to eliminate the rotation and scale effects, but at same time produce a row shifted log-polar image, which is then passed to an adaptive row shift invariant wavelet packet transform to eliminate the row shift effects. So, the output wavelet coefficients are rotation and scale invariant. The adaptive row shift invariant wavelet packet transform is quite efficient with only O(n . log n) complexity. A feature vector of the most dominant log-polar wavelet energy signatures extracted from each subband of wavelet coefficients is constructed for rotation and scale invariant texture classification. In the experiments, we employed a Mahalanobis classifier to classify a set of 25 distinct natural textures selected from the Brodatz album. The experimental results, based on different testing data sets for images with different orientations and scales, show that the proposed classification scheme using log-polar wavelet signatures outperforms two other texture classification methods, its overall accuracy rate for joint rotation and scale invariance being 90.8 percent, demonstrating that the extracted energy signatures are effective rotation and scale invariant features. Concerning its robustness to noise, the classification scheme also performs better than the other methods.	Univ Macau, Fac Sci & Technol, Macau, Peoples R China; Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China	University of Macau; Chinese University of Hong Kong	Pun, CM (corresponding author), Univ Macau, Fac Sci & Technol, Macau, Peoples R China.	cmpun@umac.mo; mclee@cse.cuhk.edu.hk	Pun, Chi Man/GRJ-3703-2022	Pun, Chi-Man/0000-0003-1788-3746				BEYLKIN G, 1992, SIAM J NUMER ANAL, V29, P1716, DOI 10.1137/0729097; BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384; Brodatz P., 1966, TEXTURE PHOTOGRAPHIC; Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353; CHEN JL, 1994, IEEE T PATTERN ANAL, V16, P208, DOI 10.1109/34.273730; COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P192, DOI 10.1109/34.67648; Cohen I, 1997, SIGNAL PROCESS, V57, P251, DOI 10.1016/S0165-1684(97)00007-8; Coifman R. R., 1995, TRANSLATION INVARIAN, P125, DOI [DOI 10.1007/978-1-4612-2544-7_9, 10.1007/978-1-4612-2544-7]; COIFMAN RR, 1992, IEEE T INFORM THEORY, V38, P713, DOI 10.1109/18.119732; CONNERS RW, 1980, IEEE T PATTERN ANAL, V2, P204, DOI 10.1109/TPAMI.1980.4767008; DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705; Daubechies I., 1992, CBMS NSF REGIONAL C; Fountain SR, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P197, DOI 10.1109/ICIP.1997.632053; FOUNTAIN SR, 1998, P 9 BRIT MACH VIS C, P266; HAYLEY GM, 1994, P IEEE ICIP95, P262; HAYLEY GM, 1999, IEEE T IMAGE PROCESS, V8; KASHYAP RL, 1986, IEEE T PATTERN ANAL, V8, P472, DOI 10.1109/TPAMI.1986.4767811; Kim ND, 2000, IEEE T SYST MAN CY A, V30, P847, DOI 10.1109/3468.895915; LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679; LEUNG M, 1991, P INT C AC SPEECH SI, P461; LIANG J, 1996, IEEE T SIGNAL PROCES, V44; MALLAT S, 1989, IEEE T PATTERN ANAL, V11, P7; PESQUET JC, 1996, IEEE T SIGNAL PROCES, V44; PORTER R, 1997, IEE P VISION IMAGE S, V144; Schalkoff R, 1992, PATTERN RECOGN; TEUNER A, 1995, IEEE T IMAGE PROCESS, V4, P863, DOI 10.1109/83.388091; Tuceryan M., 1993, HDB PATTERN RECOGNIT, P235, DOI DOI 10.1142/9789814343138_0010; UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936; Wu WR, 1996, IEEE T IMAGE PROCESS, V5, P1423, DOI 10.1109/83.536891; YOU J, 1993, PATTERN RECOGN, V26, P245, DOI 10.1016/0031-3203(93)90033-S	30	181	223	0	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2003	25	5					590	603		10.1109/TPAMI.2003.1195993	http://dx.doi.org/10.1109/TPAMI.2003.1195993			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	669FY					2022-12-18	WOS:000182342300005
J	KEARNEY, JK; THOMPSON, WB; BOLEY, DL				KEARNEY, JK; THOMPSON, WB; BOLEY, DL			OPTICAL-FLOW ESTIMATION - AN ERROR ANALYSIS OF GRADIENT-BASED METHODS WITH LOCAL OPTIMIZATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MINNESOTA,DEPT COMP SCI,MINNEAPOLIS,MN 55455	University of Minnesota System; University of Minnesota Twin Cities	KEARNEY, JK (corresponding author), CORNELL UNIV,DEPT COMP SCI,ITHACA,NY 14853, USA.							BARNARD ST, 1979, THESIS U MINNESOTA; CAFFORIO C, 1976, IEEE T INFORM THEORY, V22, P573, DOI 10.1109/TIT.1976.1055602; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; HILDRETH EC, 1984, ARTIF INTELL, V23, P309, DOI 10.1016/0004-3702(84)90018-3; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Kearney J. K., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P376; KEARNEY JK, 1983, THESIS U MINNESOTA; KEARNEY JK, 1986, MOTION UNDERSTANDING; KITCHEN L, 1980, TR887 U MAR COMP SCI; Limb J. O., 1975, Computer Graphics and Image Processing, V4, P311, DOI 10.1016/0146-664X(75)90001-5; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; LUCAS B, 1981, 5TH INT JOINT C ART, P674; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; NETRAVALI AN, 1979, BELL SYST TECH J, V58; PAQUIN R, 1983, COMPUT VISION GRAPH, V21, P205, DOI 10.1016/S0734-189X(83)80037-1; SCHALKOFF RJ, 1979, THESIS U VIRGINIA; SCHALKOFF RJ, 1982, IEEE T PATTERN ANAL, V2, P2; SCHUNCK BG, 1981, AUG P IEEE C PATT RE, P205; Stewart G., 1973, INTRO MATRIX COMPUTA; THOMPSON WB, 1981, COMPUTER, V14; WAXMAN AM, 1985, INT J ROBOT RES, V4, P95, DOI 10.1177/027836498500400307; Westlake J. R., 1968, BIOMETRICS, V24, P33	23	181	187	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1987	9	2					229	244		10.1109/TPAMI.1987.4767897	http://dx.doi.org/10.1109/TPAMI.1987.4767897			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	G1633	21869393	Green Submitted			2022-12-18	WOS:A1987G163300004
J	Karpathy, A; Li, FF				Karpathy, Andrej; Li Fei-Fei			Deep Visual-Semantic Alignments for Generating Image Descriptions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image captioning; deep neural networks; visual-semantic embeddings; recurrent neural network; language model		We present a model that generates natural language descriptions of images and their regions. Our approach leverages datasets of images and their sentence descriptions to learn about the inter-modal correspondences between language and visual data. Our alignment model is based on a novel combination of Convolutional Neural Networks over image regions, bidirectional Recurrent Neural Networks (RNN) over sentences, and a structured objective that aligns the two modalities through a multimodal embedding. We then describe a Multimodal Recurrent Neural Network architecture that uses the inferred alignments to learn to generate novel descriptions of image regions. We demonstrate that our alignment model produces state of the art results in retrieval experiments on Flickr8K, Flickr30K and MSCOCO datasets. We then show that the generated descriptions outperform retrieval baselines on both full images and on a new dataset of region-level annotations. Finally, we conduct large-scale analysis of our RNN language model on the Visual Genome dataset of 4.1 million captions and highlight the differences between image and region-level caption statistics.	[Karpathy, Andrej; Li Fei-Fei] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA	Stanford University	Karpathy, A (corresponding author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.	karpathy@cs.stanford.edu; feifeili@cs.stanford.edu			NVIDIA Corporation; ONR MURI grant; US National Science Foundation [ISS-1115313]	NVIDIA Corporation; ONR MURI grant; US National Science Foundation(National Science Foundation (NSF))	We thank Justin Johnson and Jon Krause for helpful comments and discussions. We gratefully acknowledge the support of NVIDIA Corporation with the donation of the GPUs used for this research. We would also like to thank the maintainers of Torch 7, and especially Soumith Chintala for his support. This research is partially supported by an ONR MURI grant, and US National Science Foundation ISS-1115313.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Barbu A., 2012, ARXIV12042742, P102; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Bengio Y, 2006, STUD FUZZ SOFT COMP, V194, P137; Bengio Y, 2001, ADV NEUR IN, V13, P932; Berg TL, 2004, PROC CVPR IEEE, P848; Chen X., 2014, ARXIV14115654; Chen X, 2015, CORR, V1504, P325; Chen X., 2014, CORR; Collobert R., 2011, P BIG LEARN ADV NEUR, P1681; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Denkowski M., 2014, P 9 WORKSH STAT MATH, P67; Devlin J., 2015, ARXIV150504467; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Elliott Desmond, 2013, P 2013 C EMP METH NA, P1292; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754; Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2; Fei-Fei L, 2007, J VISION, V7, DOI 10.1167/7.1.10; Fidler S, 2013, PROC CVPR IEEE, P1995, DOI 10.1109/CVPR.2013.260; Frome Andrea, 2013, NEURIPS; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211; Gupta A., 2012, NEURAL INFORM PROCES; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Jia YQ, 2011, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2011.6126524; Kiros R, 2014, PR MACH LEARN RES, V32, P595; Kong C, 2014, PROC CVPR IEEE, P3558, DOI 10.1109/CVPR.2014.455; Krishna R., 2016, VISUAL GENOME CONNEC; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kuznetsova P., 2012, P 50 ANN M ASS COMPU, V1, P359; Kuznetsova Polina, 2014, T ASSOC COMPUT LING, V2, P351, DOI DOI 10.1162/TACL_A_00188; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718; Li LJ, 2007, LECT NOTES ARTIF INT, V4456, P1; Li S., 2011, P 15 C COMPUTATIONAL, P220; Lin DH, 2014, PROC CVPR IEEE, P2657, DOI 10.1109/CVPR.2014.340; Mao J., 2014, EXPLAIN IMAGES MULTI; Matuszek Cynthia, 2012, P 29 INT C MACH LEAR, P1671; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Mikolov Tomas., 2013, ADV NEURAL INFORM PR, P3111, DOI DOI 10.1162/JMLR.2003.3.4-5.951; Mitchell Margaret, 2012, EACL; Ordonez Vicente, 2011, ADV NEURAL INFORM PR, P1143; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pennington Jeffrey., 2014, P 2014 C EMP METH NA, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; SOCHER R, 2010, PROC CVPR IEEE, P966, DOI DOI 10.1109/CVPR.2010.5540112; Socher R., 2014, J T ASS COMPUT LINGU, V2, P207, DOI DOI 10.1162/TACL_A_00177; Sutskever Ilya, 2011, P 28 INT C MACH LEAR; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26; VEDANTAM R, 2015, PROC CVPR IEEE, P4566, DOI DOI 10.1109/CVPR.2015.7299087; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010; Weinberger KQ, 2014, ADV NEURAL INFORM PR, P1889; Yao BZ, 2010, P IEEE, V98, P1485, DOI 10.1109/JPROC.2010.2050411; Yatskar M., 2014, JOINT C LEX COMP SEM; Young P., 2014, P TACL, V2, P67, DOI 10.1162/tacl_a_00166; Zhang W., 1999, STATE SPACE SEARCH A; Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11; Zitnick CL, 2013, IEEE I CONF COMP VIS, P1681, DOI 10.1109/ICCV.2013.211	66	180	206	12	163	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2017	39	4					664	676		10.1109/TPAMI.2016.2598339	http://dx.doi.org/10.1109/TPAMI.2016.2598339			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EP9UD	27514036	Green Submitted			2022-12-18	WOS:000397717600005
J	Jenssen, R				Jenssen, Robert			Kernel Entropy Component Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Spectral data transformation; Renyi entropy; Parzen windowing; kernel PCA; clustering; pattern denoising	DIMENSIONALITY REDUCTION; PCA	We introduce kernel entropy component analysis (kernel ECA) as a new method for data transformation and dimensionality reduction. Kernel ECA reveals structure relating to the Renyi entropy of the input space data set, estimated via a kernel matrix using Parzen windowing. This is achieved by projections onto a subset of entropy preserving kernel principal component analysis (kernel PCA) axes. This subset does not need, in general, to correspond to the top eigenvalues of the kernel matrix, in contrast to the dimensionality reduction using kernel PCA. We show that kernel ECA may produce strikingly different transformed data sets compared to kernel PCA, with a distinct angle-based structure. A new spectral clustering algorithm utilizing this structure is developed with positive results. Furthermore, kernel ECA is shown to be an useful alternative for pattern denoising.	Univ Tromso, Dept Phys & Technol, N-9037 Tromso, Norway	UiT The Arctic University of Tromso	Jenssen, R (corresponding author), Univ Tromso, Dept Phys & Technol, N-9037 Tromso, Norway.	robert.jenssen@uit.no						Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Braun ML, 2008, J MACH LEARN RES, V9, P1875; Burges CJC, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P59, DOI 10.1007/0-387-25465-X_4; Duda R.O., 2001, PATTERN CLASSIFICATI; Girolami M, 2002, NEURAL COMPUT, V14, P669, DOI 10.1162/089976602317250942; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; JENSSEN R, 2009, P SCAND C IM AN JUN; Jenssen R., 2007, ADV NEURAL INFORM PR, P633; Jenssen R, 2008, NEUROCOMPUTING, V72, P23, DOI 10.1016/j.neucom.2008.03.017; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Kwok JTY, 2004, IEEE T NEURAL NETWOR, V15, P1517, DOI 10.1109/TNN.2004.837781; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Mika S, 1999, ADV NEUR IN, V11, P536; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; MURPHY R, 1994, UCI REPOSITORY MACHI; Ng AY, 2002, ADV NEUR IN, V14, P849; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Renyi A., 1976, SELECTED PAPERS A RE, V2, P565; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SAUL LK, 2005, SEMISUPERVISED LEARN, pCH1; Scholkopf B, 1999, IEEE T NEURAL NETWOR, V10, P1000, DOI 10.1109/72.788641; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Silverman B. W, 1986, DENSITY ESTIMATION S, DOI 10.1201/9781315140919; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Theodoridis S., 2008, PATTERN RECOGN; Weinberger KQ, 2006, INT J COMPUT VISION, V70, P77, DOI 10.1007/s11263-005-4939-z; Williams CKI, 2002, MACH LEARN, V46, P11, DOI 10.1023/A:1012485807823; Zha HY, 2002, ADV NEUR IN, V14, P1057	31	180	229	0	59	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2010	32	5					847	860		10.1109/TPAMI.2009.100	http://dx.doi.org/10.1109/TPAMI.2009.100			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	569AW	20299709				2022-12-18	WOS:000275569300006
J	Escalera, S; Pujol, O; Radeva, P				Escalera, Sergio; Pujol, Oriol; Radeva, Petia			On the Decoding Process in Ternary Error-Correcting Output Codes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Error-correcting output codes; decoding; multiclass classification; embedding of dichotomizers		A common way to model multiclass classification problems is to design a set of binary classifiers and to combine them. Error-Correcting Output Codes (ECOC) represent a successful framework to deal with these type of problems. Recent works in the ECOC framework showed significant performance improvements by means of new problem-dependent designs based on the ternary ECOC framework. The ternary framework contains a larger set of binary problems because of the use of a "do not care" symbol that allows us to ignore some classes by a given classifier. However, there are no proper studies that analyze the effect of the new symbol at the decoding step. In this paper, we present a taxonomy that embeds all binary and ternary ECOC decoding strategies into four groups. We show that the zero symbol introduces two kinds of biases that require redefinition of the decoding design. A new type of decoding measure is proposed, and two novel decoding strategies are defined. We evaluate the state-of-the-art coding and decoding strategies over a set of UCI Machine Learning Repository data sets and into a real traffic sign categorization problem. The experimental results show that, following the new decoding strategies, the performance of the ECOC design is significantly improved.	[Escalera, Sergio; Pujol, Oriol; Radeva, Petia] Univ Autonoma Barcelona, Dept Matemat Aplicada & Anal, Barcelona 08007, Spain; [Escalera, Sergio; Pujol, Oriol; Radeva, Petia] Univ Autonoma Barcelona, Comp Vis Ctr, Barcelona 08007, Spain	Autonomous University of Barcelona; Autonomous University of Barcelona; Centre de Visio per Computador (CVC)	Escalera, S (corresponding author), Univ Autonoma Barcelona, Dept Matemat Aplicada & Anal, Gran Via Corts 585, Barcelona 08007, Spain.	sergio@maia.ub.es; oriol@maia.ub.es; petia@maia.ub.es	Pujol, Oriol/F-7146-2016; Escalera, Sergio/L-2998-2015; Radeva, Petia/I-3385-2015	Pujol, Oriol/0000-0001-7573-009X; Escalera, Sergio/0000-0003-0617-8873; Radeva, Petia/0000-0003-0047-5172	CONSOLIDER-INGENIO [CSD 2007-00018];  [TIN2006-15308-C02];  [FIS PI061290]	CONSOLIDER-INGENIO(Ministry of Science and Innovation, Spain (MICINN)Spanish Government); ; 	This work has been supported in part by projects TIN2006-15308-C02, FIS PI061290, and CONSOLIDER-INGENIO CSD 2007-00018.	Allwein E. L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; Asuncion A, 2007, UCI MACHINE LEARNING; CASACUBERTA J, 2004, P C INT SOC PHOT REM; DEKEL O, 2002, P C NEUR INF PROC SY, V15; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich TG, 1994, J ARTIF INTELL RES, V2, P263; Escalera S, 2007, PATTERN RECOGN LETT, V28, P1759, DOI 10.1016/j.patrec.2007.05.007; Eun Bae Kong, 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P313; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Ghani R, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P597, DOI 10.1109/ICDM.2001.989574; Hastie T, 1998, ANN STAT, V26, P451; Ishii N, 2005, THIRD ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGMENT AND APPLICATIONS, PROCEEDINGS, P240; KIKUCHI T, 2003, P C ART NEUR NETW PA; Kittler J, 2001, PROC CVPR IEEE, P755; Nilsson N., 1965, LEARNING MACHINES; Passerini A, 2004, IEEE T NEURAL NETWOR, V15, P45, DOI 10.1109/TNN.2003.820841; Pujol O, 2006, IEEE T PATTERN ANAL, V28, P1007, DOI 10.1109/TPAMI.2006.116; PUJOL O, PATTERN REC IN PRESS; RICCI F, 1998, P 10 EUR C MACH LEAR, P280; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Smith RS, 2005, LECT NOTES COMPUT SC, V3541, P53; Utschick W, 2001, NEURAL COMPUT, V13, P1065, DOI 10.1162/08997660151134334; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Windeatt T., 2003, Information Fusion, V4, P11, DOI 10.1016/S1566-2535(02)00101-X; WINDEATT T, 2003, P INT C VIS INF ENG, P165; Zhou J, 2005, PROC INT CONF DOC, P484; ZHU J, 2005, MULTICLASS ADABOOST; OSU SVM TOOLBOX	30	180	187	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2010	32	1					120	134		10.1109/TPAMI.2008.266	http://dx.doi.org/10.1109/TPAMI.2008.266			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	520FQ	19926903				2022-12-18	WOS:000271826700010
J	Chen, H; Bhanu, B				Chen, Hui; Bhanu, Bir			Human ear recognition in 3D	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D ear biometrics; 3D ear identification; 3D ear verification; range and color images; surface matching	REGISTRATION; REPRESENTATION; IMAGES; COLOR	Human ear is a new class of relatively stable biometrics that has drawn researchers' attention recently. In this paper, we propose a complete human recognition system using 3D ear biometrics. The system consists of 3D ear detection, 3D ear identification, and 3D ear verification. For ear detection, we propose a new approach which uses a single reference 3D ear shape model and locates the ear helix and the antihelix parts in registered 2D color and 3D range images. For ear identification and verification using range images, two new representations are proposed. These include the ear helix/antihelix representation obtained from the detection algorithm and the local surface patch (LSP) representation computed at feature points. A local surface descriptor is characterized by a centroid, a local surface type, and a 2D histogram. The 2D histogram shows the frequency of occurrence of shape index values versus the angles between the normal of reference feature point and that of its neighbors. Both shape representations are used to estimate the initial rigid transformation between a gallery-probe pair. This transformation is applied to selected locations of ears in the gallery set and a modified Iterative Closest Point (ICP) algorithm is used to iteratively refine the transformation to bring the gallery ear and probe ear into the best alignment in the sense of the least root mean square error. The experimental results on the UCR data set of 155 subjects with 902 images under pose variations and the University of Notre Dame data set of 302 subjects with time-lapse gallery-probe pairs are presented to compare and demonstrate the effectiveness of the proposed algorithms and the system.	Univ Calif Riverside, Ctr Res Intelligent Syst, Riverside, CA 92521 USA	University of California System; University of California Riverside	Chen, H (corresponding author), Univ Calif Riverside, Ctr Res Intelligent Syst, Riverside, CA 92521 USA.	hchen@cris.ucr.edu; bhanu@cris.ucr.edu		Bhanu, Bir/0000-0001-8971-6416				BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bhanu B, 2003, P WORKSH MULT US AUT, P91; Boehnen C, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P135; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; BRONSTEIN A, 2003, P AUD VID BAS BIOM P, P62; Burge M, 2000, INT C PATT RECOG, P822, DOI 10.1109/ICPR.2000.906202; Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889; Chang K, 2003, IEEE T PATTERN ANAL, V25, P1160, DOI 10.1109/TPAMI.2003.1227990; Chang KI, 2005, IEEE T PATTERN ANAL, V27, P619, DOI 10.1109/TPAMI.2005.70; Chen CS, 1999, IEEE T PATTERN ANAL, V21, P1229, DOI 10.1109/34.809117; Chen H, 2005, LECT NOTES COMPUT SC, V3546, P748; Chen H, 2004, INT C PATT RECOG, P574, DOI 10.1109/ICPR.2004.1334594; Chen H., 2005, P IEEE C COMP VIS PA; CHEN H, 2005, P 7 IEEE WORKSH APPL, V1, P123; CHEN H, 2007, SUPPLEMENTAL MAT ACC; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Chin-Seng Chua, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P233, DOI 10.1109/AFGR.2000.840640; Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113; Flynn P. J., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P110, DOI 10.1109/CVPR.1989.37837; Gordon G. G., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P808, DOI 10.1109/CVPR.1992.223253; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; Hurley DJ, 2005, COMPUT VIS IMAGE UND, V98, P491, DOI 10.1016/j.cviu.2004.11.001; Iannarelli A., 1989, EAR IDENTIFICATION; Jain A., 1999, BIOMETRICS PERSONAL; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KIM J, 2005, P IEEE C COMP VIS PA, V1, P196; Kim SH, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P76, DOI 10.1109/AFGR.1998.670928; KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F; Kotropoulos CL, 2000, IEEE T MULTIMEDIA, V2, P14, DOI 10.1109/6046.825791; Lee J. C., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P722, DOI 10.1109/ICCV.1990.139627; Lu XG, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P156; Lu XG, 2004, INT C PATT RECOG, P362, DOI 10.1109/ICPR.2004.1334127; Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972; Shen WC, 1997, P IEEE, V85, P1464, DOI 10.1109/5.628719; Tsalakanidou F, 2005, IEEE T IMAGE PROCESS, V14, P152, DOI 10.1109/TIP.2004.840714; Wang R, 2007, PATTERN RECOGN LETT, V28, P40, DOI 10.1016/j.patrec.2006.06.015; Wang S, 2004, PROC CVPR IEEE, P143; Yan P, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P213; Yan P, 2005, PROC SPIE, V5779, P282, DOI 10.1117/12.603154; Yan P, 2005, LECT NOTES COMPUT SC, V3546, P503; Yan P., 2006, P 3 INT S 3D DAT PRO, P213; YAN P., 2005, P IEEE C COMP VIS PA; Yan P, 2006, THESIS U NOTRE DAME	47	180	201	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2007	29	4					718	737		10.1109/TPAMI.2007.1005	http://dx.doi.org/10.1109/TPAMI.2007.1005			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HJ	17299227				2022-12-18	WOS:000244855600018
J	Franti, P; Virmajoki, O; Hautamaki, V				Franti, Pasi; Virmajoki, Olli; Hautamaki, Ville			Fast agglomerative clustering using a k-nearest neighbor graph	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						clustering; agglomeration; nearest neighbor; vector quantization; PNN	VECTOR QUANTIZATION; ALGORITHM	We propose a fast agglomerative clustering method using an approximate nearest neighbor graph for reducing the number of distance calculations. The time complexity of the algorithm is improved from Od(tau N-2) to Od (tau N logN) at the cost of a slight increase in distortion; here, tau denotes the number of nearest neighbor updates required at each iteration. According to the experiments, a relatively small neighborhood size is sufficient to maintain the quality close to that of the full search.	Univ Joensuu, Dept Comp Sci, Speech & Image Proc Unit, FIN-80101 Joensuu, Finland	University of Eastern Finland	Franti, P (corresponding author), Univ Joensuu, Dept Comp Sci, Speech & Image Proc Unit, POB 111, FIN-80101 Joensuu, Finland.	franti@cs.joensuu.fi; ovirma@cs.joensuu.fi; villeh@cs.joensuu.fi		Hautamaki, Ville/0000-0002-5885-0003				Bandyopadhyay S, 2004, PATTERN RECOGN, V37, P33, DOI 10.1016/S0031-3203(03)00235-8; Conway J. H., 1998, SPHERE PACKINGS LATT; CORMEN TH, 1998, INTRO ALGORITHMS; EQUITZ WH, 1989, IEEE T ACOUST SPEECH, V37, P1568, DOI 10.1109/29.35395; Franti P, 2000, IEEE T IMAGE PROCESS, V9, P773, DOI 10.1109/83.841516; Franti P, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P525, DOI 10.1109/ICDM.2003.1250968; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; GOVER JC, 1969, APPL STAT, V18, P54; HAREL D, 2001, P 7 ACM SIGKDD INT C, P281; Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637; Kaukoranta T, 2000, IEEE T IMAGE PROCESS, V9, P1337, DOI 10.1109/83.855429; Kaukoranta T, 1999, OPT ENG, V38, P1862, DOI 10.1117/1.602251; Kotz S, 1985, ENCY STAT SCI, V6; KURITA T, 1991, PATTERN RECOGN, V24, P205, DOI 10.1016/0031-3203(91)90062-A; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; Miller RA, 1997, CLIN MICROBIOL REV, V10, P1; RA SW, 1993, IEEE T CIRCUITS-II, V40, P576, DOI 10.1109/82.257335; Shanbehzadeh J, 1997, IEEE T IMAGE PROCESS, V6, P614, DOI 10.1109/83.563327; SNEATH PHA, 1957, J GEN MICROBIOL, V17, P201, DOI 10.1099/00221287-17-1-201; SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061; Virmajoki O, 2004, INT C PATT RECOG, P264, DOI 10.1109/ICPR.2004.1334103; Virmajoki O, 2003, J ELECTRON IMAGING, V12, P648, DOI 10.1117/1.1604396; Virmajoki O, 2001, OPT ENG, V40, P2495, DOI 10.1117/1.1412423; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; Zhang T, 1997, DATA MIN KNOWL DISC, V1, P141, DOI 10.1023/A:1009783824328	25	180	193	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2006	28	11					1875	1881		10.1109/TPAMI.2006.227	http://dx.doi.org/10.1109/TPAMI.2006.227			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	083GC	17063692				2022-12-18	WOS:000240443400015
J	Levin, A; Weiss, Y				Levin, Anat; Weiss, Yair			User assisted separation of reflections from a single image using a sparsity prior	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						transparency; image statistics; low-level vision; interactive image editing		When we take a picture through transparent glass, the image we obtain is often a linear superposition of two images: The image of the scene beyond the glass plus the image of the scene reflected by the glass. Decomposing the single input image into two images is a massively ill-posed problem: In the absence of additional knowledge about the scene being viewed, there are an infinite number of valid decompositions. In this paper, we focus on an easier problem: user assisted separation in which the user interactively labels a small number of gradients as belonging to one of the layers. Even given labels on part of the gradients, the problem is still ill-posed and additional prior knowledge is needed. Following recent results on the statistics of natural images, we use a sparsity prior over derivative filters. This sparsity prior is optimized using the iterative reweighted least squares (IRLS) approach. Our results show that using a prior derived from the statistics of natural images gives a far superior performance compared to a Gaussian prior and it enables good separations from a modest number of labeled gradients.	Hebrew Univ Jerusalem, Sch Engn & Comp Sci, IL-91904 Jerusalem, Israel	Hebrew University of Jerusalem	Levin, A (corresponding author), Hebrew Univ Jerusalem, Sch Engn & Comp Sci, IL-91904 Jerusalem, Israel.	alevin@cs.huji.ac.il; yweiss@cs.huji.ac.il		Levin, Anat/0000-0002-9849-9043				Agrawal A, 2005, ACM T GRAPHIC, V24, P828, DOI 10.1145/1073204.1073269; [Anonymous], 2004, EMERGING TOPICS COMP; Farid H, 1999, J OPT SOC AM A, V16, P2136, DOI 10.1364/JOSAA.16.002136; Finlayson G.D., 2002, P EUR C COMP VIS; Irani M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P216, DOI 10.1109/CVPR.1992.223272; LEVIN A, 2004, P EUR C COMP VIS MAY; LEVIN A, 2002, ADV NEURAL INFORM PR, V15; MALIK J, 2000, PERCEPTUAL ORG ARTIF; Mallat S., 1989, IEEE PAMI, V11, P674; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Roth S., 2005, P C COMP VIS PATT RE; SAREL B, 2004, P EUR C COMP VIS MAY; SAREL B, 2005, P INT C COMP VIS; SHECHNER Y, 1999, P ICCV, P814; Simoncelli E, 1997, P 31 AS C SIGN SYST, P673; SIMONCELLI EP, 1999, WAVELET BASED MODELS; SZELIKSI R, 2000, P C COMP VIS PATT RE; TAPPEN M, 2002, ADV NEURAL INFORM PR, V15; Tsin Y, 2003, PROC CVPR IEEE, P702; Wainwright MJ, 2000, IEEE IMAGE PROC, P260, DOI 10.1109/ICIP.2000.900944; Weiss Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P68, DOI 10.1109/ICCV.2001.937606; ZIBULEVSKY M, 2001, ADV NEURAL INFORM PR, V14	23	179	190	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2007	29	9					1647	U1		10.1109/TPAMI.2007.1106	http://dx.doi.org/10.1109/TPAMI.2007.1106			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	189CD	17627051				2022-12-18	WOS:000247965600013
J	Sawhney, HS; Ayer, S				Sawhney, HS; Ayer, S			Compact representations of videos through dominant and multiple motion estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						compact video representations; video motion analysis; video mosaics; video indexing; layered motion representations; motion segmentation; robust estimation; mixture models; expectation-maximization (EM) algorithm	OPTICAL-FLOW	An explosion of on-line image and video data in digital form is already well underway. With the exponential rise in interactive information exploration and dissemination through the World-Wide Web (WWW), the major inhibitors of rapid access to on-line video data are costs and management of capture and storage, lack of real-time delivery, and nonavailability of content-based intelligent search and indexing techniques. The solutions for capture, storage, and delivery may be on the horizon or a little beyond. However, even with rapid delivery, the lack of efficient authoring and querying tools for visual content-based indexing may still inhibit as widespread a use of video information as that of text and traditional tabular data is currently. In order to be able to nonlinearly browse and index into videos through visual content, it is necessary to develop authoring tools that can automatically separate moving objects and significant components of the scene, and represent these in a compact form. Given that video data comes ill torrents-almost a megabyte every 30th of a second-it will be highly inefficient to search for objects and scenes in every frame of a video. In this paper, we present techniques to automatically derive compact representations of scenes and objects from the motion information. Image motion is a significant cue in Videos for the separation of scenes into their significant components and for the separation of moving objects. Motion analysis is useful in capturing the visual content of videos for indexing and browsing in two different ways. First, separation of the static scene from moving objects can be accomplished by employing dominant 2D/3D motion estimation methods. Alternatively, if the goal is to be able to represent the fixed scene too as a composition of significant structures and objects, then simultaneous multiple motion methods might be more appropriate. in either case, view-based summarized representations of the scene can be created by video compositing/mosaicing based on the estimated motions. We present robust algorithms for both kinds of representations: 1) dominant motion estimation based techniques which exploit a fairly common occurrence in Videos that a mostly fixed background (scene) is imaged with or without independently moving objects, and 2) simultaneous multiple motion estimation and representation of motion video using layered representations. Ample examples of the, representations achieved by each method are included in the paper.	SWISS FED INST TECHNOL, SIGNAL PROC LAB, CH-1015 LAUSANNE, SWITZERLAND	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Sawhney, HS (corresponding author), DAVID SARNOFF RES CTR, IMAGE INFORMAT RES GRP, CN5300, PRINCETON, NJ 08543 USA.							ADELSON EH, 1990, P AAAI WORKSH QUAL V; ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; ASHLEY J, 1995, IMAGE VIDEO STORAGE, V2420; AYER S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P777, DOI 10.1109/ICCV.1995.466859; AYER S, 1995, THESIS EPFL LAUSANNE; AYER S, 1994, P ECCV STOCKH MAY; BERGEN JR, 1992, 2ND P EUR C COMP VIS, P237; BLACK M, 1993, ROBUST ESTIMATION MU; BOBER M, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P947, DOI 10.1109/CVPR.1994.323931; DARRELL T, 1995, IEEE T PATTERN ANAL, V17, P474, DOI 10.1109/34.391395; FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146; Hampel FR., 2011, WILEY SERIES PROBABI; Hanna K. J., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P156, DOI 10.1109/WVM.1991.212812; HARTLEY RI, 1993, P JOINT EUR US WORKS; HASHIHARA H, 1991, SCENE RETRIEVAL METH; HASSELBLAD V, 1966, TECHNOMETRICS, V8, P431, DOI 10.2307/1266689; HIRATA K, 1993, NEC RES DEV, V34, P263; HSU S, 1994, INT C PATT RECOG, P743, DOI 10.1109/ICPR.1994.576427; IRANI M, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P605, DOI 10.1109/ICCV.1995.466883; IRANI M, 1992, 2ND P EUR C COMP VIS, P282; Jepson A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P760, DOI 10.1109/CVPR.1993.341161; KUMAR R, 1994, INT C PATT RECOG, P685, DOI 10.1109/ICPR.1994.576402; KUMAR R, 1995, P IEEE WORKSH REPR V; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; Li G., 1985, EXPLORING DATA TABLE; MACLEAN WJ, 1994, P BMVC; MANN S, 1994, P ICIP; McLachlan G.J., 1988, MIXTURE MODELS INFER, V38; NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173; OBODEZ JM, 1994, P 7 EUSIPCO EUR C SI, P411; ODOBEZ JM, 1994, IEEE IMAGE PROC, P257, DOI 10.1109/ICIP.1994.413571; PENTLAND A, 1994, P STOR RETR IM VID D; RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; SAWHNEY H, 1994, P INT C PATT REC, pA403; Sawhney H. S., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), P583, DOI 10.1109/ICCV.1995.466886; SHASHUA A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P483, DOI 10.1109/CVPR.1994.323870; Szeliski R., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P44, DOI 10.1109/ACV.1994.341287; SZELISKI R, 1995, P IEEE WORKSH REPR V; TEODOSIO LA, 1993, P ACM INT C MULT; TONOMURA Y, 1993, P INTERCHI 93, P131; Wang J. Y. A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P361, DOI 10.1109/CVPR.1993.341105; Wild C.J., 1989, NONLINEAR REGRESSION	43	179	197	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1996	18	8					814	830		10.1109/34.531801	http://dx.doi.org/10.1109/34.531801			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VE318		Green Submitted			2022-12-18	WOS:A1996VE31800005
J	PENTLAND, A; HOROWITZ, B				PENTLAND, A; HOROWITZ, B			RECOVERY OF NONRIGID MOTION AND STRUCTURE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						DEFORMABLE MODELS; FINITE ELEMENT METHOD; KALMAN FILTERING; MODAL ANALYSIS; MOTION PROCESSING; NONRIGID MOTION; PHYSICALLY BASED MODELING; SHAPE REPRESENTATION; 3-D SHAPE RECOVERY; 3-D TRACKING	MODELS	The elastic properties of real materials provide constraint on the types of nonrigid motion that can occur, and thus allow overconstrained estimates of 3-D nonrigid motion from optical flow data. We show that by modeling and simulating the physics of nonrigid motion we can obtain good estimates of both object shape and velocity. Examples using grey scale and X-ray imagery are presented, including an example of tracking a complex articulated figure.			PENTLAND, A (corresponding author), MIT,MEDIA LAB,VIS & MODELING GRP,CAMBRIDGE,MA 02139, USA.							Aoki M., 1989, OPTIMIZATION STOCHAS, V2; AYACHE N, 1989, IEEE T ROBOTIC AUTOM, V5, P804, DOI 10.1109/70.88101; Bathe Klaus Jurgen., 1982, J PRESS VESSEL TECHN; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; ESSA I, 1990, THESIS MIT CAMBRIDGE; FAUGERAS OD, 1986, APR P IEEE C ROB AUT; FRIEDLAND B, 1966, CONTROL SYSTEM DESIG; Kalman R.E., 1961, J BASIC ENG-T ASME, V83, P95, DOI [10.1115/1.3658902, DOI 10.1115/1.3658902]; Kalman RE., 1960, J BASIC ENG-T ASME, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; Pentland A., 1990, Computer Graphics, V24, P143, DOI 10.1145/91394.91444; Pentland A., 1989, Computer Graphics, V23, P215, DOI 10.1145/74334.74355; PENTLAND A, 1989, AUG P INT JOINT C AR; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P107, DOI 10.1007/BF00127812; SEGERLIND LJ, 1984, APPLIED FINITE ELEME; SUBBARAO M, 1989, IEEE T PATTERN ANAL, V11, P266, DOI 10.1109/34.21796; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; TERZOPOULOS D, 1987, INT J COMPUT VISION, V1, P211, DOI 10.1007/BF00127821; ULLMAN S, 1984, PERCEPTION, V13, P255, DOI 10.1068/p130255; WERKHOVEN P, 1990, IEEE T PATTERN ANAL, V12, P658, DOI 10.1109/34.56208	20	178	187	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1991	13	7					730	742		10.1109/34.85661	http://dx.doi.org/10.1109/34.85661			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GA139					2022-12-18	WOS:A1991GA13900009
J	MURRAY, DW; BUXTON, BF				MURRAY, DW; BUXTON, BF			SCENE SEGMENTATION FROM VISUAL-MOTION USING GLOBAL OPTIMIZATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											MURRAY, DW (corresponding author), GEC RES LTD,LONG RANGE RES LAB,HIRST RES CTR,E LANE,WEMBLEY HA9 7PP,ENGLAND.							ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; Buxton B. F., 1984, Image and Vision Computing, V2, P59, DOI 10.1016/0262-8856(84)90001-5; BUXTON BF, 1985, COMPUT PHYS COMMUN, V37, P273, DOI 10.1016/0010-4655(85)90162-6; BUXTON BF, 1985, IMAGE VISION COMPUT, V3, P163, DOI 10.1016/0262-8856(85)90003-4; BUXTON BF, 1983, PROC R SOC SER B-BIO, V218, P27, DOI 10.1098/rspb.1983.0024; BUXTON BF, 1984, 6TH P EUR C ART INT, P631; CLOCKSIN WF, 1980, PERCEPTION, V9, P253, DOI 10.1068/p090253; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HADANI I, 1980, J OPT SOC AM, V70, P60, DOI 10.1364/JOSA.70.000060; HILDRETH EC, 1984, ARTIF INTELL, V23, P309, DOI 10.1016/0004-3702(84)90018-3; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378; Kearney J. K., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P376; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; LAWTON DT, 1983, COMPUT VISION GRAPH, V22, P116, DOI 10.1016/0734-189X(83)90098-1; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LONGUETHIGGINS HC, 1984, PROC R SOC SER B-BIO, V223, P165, DOI 10.1098/rspb.1984.0088; MARROQUIN JL, 1984, MIT AI792 AI LAB MEM; METROPOLIS N, 1986, IMAGE VISION COMPUT, V4, P133; Murray D. W., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P382; MURRAY DW, 1986, PATTERN RECOGN LETT, V4, P87, DOI 10.1016/0167-8655(86)90028-0; MURRAY DW, 1986, IMAGE VISION COMPUT, V4, P133, DOI 10.1016/0262-8856(86)90056-9; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; NEUMANN B, 1980, P PATTERN RECOGNITIO; PAQUIN R, 1983, COMPUT VISION GRAPH, V21, P205, DOI 10.1016/S0734-189X(83)80037-1; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; POGGIO T, 1984, MIT AI773 AI LAB MEM; Proffitt D. R., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P232; SCHUNCK BG, 1984, APR P WORKSH COMP VI, P58; THOMPSON WB, 1980, IEEE T PATTERN ANAL, V2, P543, DOI 10.1109/TPAMI.1980.6447701; THOMPSON WB, 1981, COMPUTER, V14, P20, DOI 10.1109/C-M.1981.220559; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WALLACH H, 1953, J EXP PSYCHOL, V45, P205, DOI 10.1037/h0056880; WAXMAN AM, 1985, INT J ROBOT RES, V4, P72, DOI 10.1177/027836498500400306; WAXMAN AM, 1985, INT J ROBOT RES, V4, P95, DOI 10.1177/027836498500400307	39	178	190	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1987	9	2					220	228		10.1109/TPAMI.1987.4767896	http://dx.doi.org/10.1109/TPAMI.1987.4767896			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	G1633	21869392				2022-12-18	WOS:A1987G163300003
J	WONG, AKC; YOU, M				WONG, AKC; YOU, M			ENTROPY AND DISTANCE OF RANDOM GRAPHS WITH APPLICATION TO STRUCTURAL PATTERN-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											WONG, AKC (corresponding author), UNIV WATERLOO,DEPT SYST DESIGN ENGN,PATTERN ANAL & MACHINE INTELLIGENCE LAB,WATERLOO N2L 3G1,ONTARIO,CANADA.							ACZEL J, 1975, MEASURES INFORMATION; Berge C., 1973, GRAPHS HYPERGRAPHS; Fu K. S., 1980, Pictorial information systems, P104; GHAHRAMAN DE, 1980, IEEE T SYST MAN CYB, V10, P189; GHAHRAMAN DE, 1980, IEEE T SYST MAN CYB, V10, P181, DOI 10.1109/TSMC.1980.4308468; IMPEDOVO S, 1982, 1982 P INT C PATT RE, V1, P40; KALBFLEISCH JG, PROBABILITY STATISTI, V2; MASUMI AE, 1973, THESIS U ILLINOIS UR; NIEMANN H, 1980, 1980 P INT C PATT RE, P213; PAVLIDIS T, 1972, PATTERN RECOGN, V4, P5, DOI 10.1016/0031-3203(72)90016-7; Pavlidis T., 1980, Pictorial information systems, P86; Pavlidis T., 1977, STRUCTURAL PATTERN R; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144; SHAW AC, 1970, J ACM, V17, P453, DOI 10.1145/321592.321598; SHAW AC, 1969, INFORM CONTROL, V14, P9, DOI 10.1016/S0019-9958(69)90017-5; SHAW AC, 1972, FRONTIERS PATTERN RE, P491; TSAI WH, 1983, IEEE T SYST MAN CYB, V13, P48, DOI 10.1109/TSMC.1983.6313029; TSAI WH, 1979, IEEE T SYST MAN CYB, V9, P757, DOI 10.1109/TSMC.1979.4310127; WONG AKC, 1980, IEEE T PATTERN ANAL, V2, P341, DOI 10.1109/TPAMI.1980.4767033; WONG AKC, 1978, LARGE ENGINEERING SY, V2, P37; YOU M, 1983, THESIS U WATERLOO WA	22	178	180	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	5					599	609		10.1109/TPAMI.1985.4767707	http://dx.doi.org/10.1109/TPAMI.1985.4767707			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	AQH94	21869297				2022-12-18	WOS:A1985AQH9400011
J	Dong, WS; Wang, PY; Yin, WT; Shi, GM; Wu, FF; Lu, XT				Dong, Weisheng; Wang, Peiyao; Yin, Wotao; Shi, Guangming; Wu, Fangfang; Lu, Xiaotong			Denoising Prior Driven Deep Neural Network for Image Restoration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						denoising-based image restoration; deep neural network; denoising prior; image restoration	SPARSE REPRESENTATION; REGULARIZATION	Deep neural networks (DNNs) have shown very promising results for various image restoration (IR) tasks. However, the design of network architectures remains a major challenging for achieving further improvements. While most existing DNN-based methods solve the IR problems by directly mapping low quality images to desirable high-quality images, the observation models characterizing the image degradation processes have been largely ignored. In this paper, we first propose a denoising-based IR algorithm, whose iterative steps can be computed efficiently. Then, the iterative process is unfolded into a deep neural network, which is composed of multiple denoisers modules interleaved with back-projection (BP) modules that ensure the observation consistencies. A convolutional neural network (CNN) based denoiser that can exploit the multi-scale redundancies of natural images is proposed. As such, the proposed network not only exploits the powerful denoising ability of DNNs, but also leverages the prior of the observation model. Through end-to-end training, both the denoisers and the BP modules can be jointly optimized. Experimental results on several IR tasks, e.g., image denoisig, super-resolution and deblurring show that the proposed method can lead to very competitive and often state-of-the-art results on several IR tasks, including image denoising, deblurring, and super-resolution.	[Dong, Weisheng] Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Shaanxi, Peoples R China; [Dong, Weisheng; Wang, Peiyao; Shi, Guangming; Wu, Fangfang; Lu, Xiaotong] Xidian Univ, Sch Artificial Intelligence, Xian 710071, Shaanxi, Peoples R China; [Yin, Wotao] Univ Calif Los Angeles, Dept Math, Los Angeles, CA 90095 USA	Xidian University; Xidian University; University of California System; University of California Los Angeles	Dong, WS (corresponding author), Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Shaanxi, Peoples R China.; Dong, WS (corresponding author), Xidian Univ, Sch Artificial Intelligence, Xian 710071, Shaanxi, Peoples R China.	wsdong@mail.xidian.edu.cn; peiyw_xdxs@163.com; wotaoyin@math.ucla.edu; gmshi@xidian.edu.cn; ffwu1116@163.com; dmptcode@163.com	Yin, Wotao/A-5472-2011	Yin, Wotao/0000-0001-6697-9731	Natural Science Foundation of China [61622210, 61471281, 61632019, 61836008, 61621005, 61390512]	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by the Natural Science Foundation of China under Grant 61622210, Grant 61471281, Grant 61632019, Grant 61836008, Grant 61621005, and Grant 61390512.	Alain G, 2014, J MACH LEARN RES, V15, P3563; [Anonymous], 2018, ARXIV180902165; [Anonymous], 2010, P INT C MACH LEARN; Ba J., 2017, P 3 INT C LEARN REPR; Bigdeli S. A., 2017, ARXIV170309964V1; Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319; Bolte J, 2007, SIAM J OPTIMIZ, V17, P1205, DOI 10.1137/050644641; Brifman A, 2016, IEEE IMAGE PROC, P1404, DOI 10.1109/ICIP.2016.7532589; Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38; Burger HC, 2012, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2012.6247952; Chan SH, 2017, IEEE T COMPUT IMAG, V3, P84, DOI 10.1109/TCI.2016.2629286; Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Danielyan A, 2012, IEEE T IMAGE PROCESS, V21, P1715, DOI 10.1109/TIP.2011.2176954; Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Dong WS, 2015, INT J COMPUT VISION, V114, P217, DOI 10.1007/s11263-015-0808-y; Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847; Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729; Dong WS, 2011, PROC CVPR IEEE, P457, DOI 10.1109/CVPR.2011.5995478; Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747; Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P3194, DOI 10.1109/TIP.2012.2190080; Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366; Han W., P IEEE C COMP VIS PA; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kim Y, 2017, PROC CVPR IEEE, P284, DOI 10.1109/CVPR.2017.38; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Lee J. D., ARXIV171007406; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151; Liu L., 2018, ARXIV180110324V1; Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032; Liu L, 2012, IEEE T PATTERN ANAL, V34, P574, DOI 10.1109/TPAMI.2011.145; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828; Marquina A, 2008, J SCI COMPUT, V37, P367, DOI 10.1007/s10915-008-9214-8; Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412; Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Romano Y, 2017, SIAM J IMAGING SCI, V10, P1804, DOI 10.1137/16M1102884; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6; Schmidt U, 2014, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2014.349; Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486; Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298; Teodoro AM, 2016, IEEE IMAGE PROC, P3518, DOI 10.1109/ICIP.2016.7533014; Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8; Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514; Venkatakrishnan S, 2013, IEEE GLOB CONF SIG, P945, DOI 10.1109/GlobalSIP.2013.6737048; Wang Y, 2019, J SCI COMPUT, V78, P29, DOI 10.1007/s10915-018-0757-z; Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50; Xin B, 2016, ADV NEUR IN, V29; Xu L., 2014, INT C NEUR INF PROC, V27, P1790; Xu YY, 2013, SIAM J IMAGING SCI, V6, P1758, DOI 10.1137/120887795; Yang J, 2008, PROC CVPR IEEE, P173; Yang Y, 2016, ADV NEUR IN, V29; Yu GS, 2012, IEEE T IMAGE PROCESS, V21, P2481, DOI 10.1109/TIP.2011.2176743; Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300; Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206; Zhang YB, 2018, IEEE T IMAGE PROCESS, V27, P3150, DOI 10.1109/TIP.2018.2812081; Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278	67	177	180	25	156	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2019	41	10					2305	2318		10.1109/TPAMI.2018.2873610	http://dx.doi.org/10.1109/TPAMI.2018.2873610			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD1VC	30295612	Green Submitted			2022-12-18	WOS:000489763000003
J	Irani, M; Anandan, P				Irani, M; Anandan, P			A unified approach to moving object detection in 2D and 3D scenes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						moving object detection; rigidity constraints; multiframe analysis; planar-parallax; parallax geometry; layers	OPTICAL-FLOW; IMAGE MOTION	The detection of moving objects is important in many tasks. Previous approaches to this problem can be broadly divided into two classes: 2D algorithms which apply when the scene can be approximated by a flat surface and/or when the camera is only undergoing rotations and zooms, and 3D algorithms which work well only when significant depth variations are present in the scene and the camera is translating. In this paper, we describe a unified approach to handling moving-object detection in both 2D and 3D scenes, with a strategy to gracefully bridge the gap between those two extremes. Our approach is based on a stratification of the moving object-detection problem into scenarios which gradually increase in their complexity. We present a set of techniques that match the above stratification. These techniques progressively increase in their complexity, ranging from 2D techniques to more complex 3D techniques. Moreover, the computations required for the solution to the problem at one complexity level become the initial processing step for the solution at the next complexity level. We illustrate these techniques using examples from real-image sequences.	Weizmann Inst Sci, Dept Appl Math & Comp Sci, IL-76100 Rehovot, Israel; Microsoft Corp, Redmond, WA 98052 USA; Sarnoff Corp, Princeton, NJ USA	Weizmann Institute of Science; Microsoft; Sarnoff Corporation	Irani, M (corresponding author), Weizmann Inst Sci, Dept Appl Math & Comp Sci, IL-76100 Rehovot, Israel.							ADELSON EH, 1991, 181 MIT MED LAB VIS; ADIV G, 1989, IEEE T PATTERN ANAL, V11, P477, DOI 10.1109/34.24780; ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; Aloimonos Y, 1993, ACTIVE PERCEPTION; AYER S, 1995, ICCV, P777; BERGEN JR, 1992, IEEE T PATTERN ANAL, V14, P886, DOI 10.1109/34.161348; BERGEN JR, 1992, EUR C COMP VIS, P237; BURT PJ, 1991, IEEE WORKSH VIS MOT, P187; Costeira J., 1995, ICCV, P1071; DARREL T, 1991, IEEE WORKSH VIS MOT, P173; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; IRANI M, 1994, INT J COMPUT VISION, V12, P5, DOI 10.1007/BF01420982; Irani M, 1997, IEEE T PATTERN ANAL, V19, P268, DOI 10.1109/34.584105; IRANI M, 1996, EUR C COMP VIS CAMBR; IRANI M, 1996, 13 INT C PATT REC VI, P712; Ju SX, 1996, PROC CVPR IEEE, P307, DOI 10.1109/CVPR.1996.517090; KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371; KUMAR R, 1995, WORKSH REPR VIS SCEN; KUMAR R, 1994, P 12 ICPR; KUMAR R, 1994, DARPA IU WORKSH MONT; LAWN JM, 1994, EUR C COMP VIS MAY, P205; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; LONGUETHIGGINS HC, 1984, PROC R SOC SER B-BIO, V223, P165, DOI 10.1098/rspb.1984.0088; MEYER F, 1992, EUR C COMP VIS SANT, P476; RIEGER JH, 1985, J OPT SOC AM A, V2, P354, DOI 10.1364/JOSAA.2.000354; SAWHNEY H, 1994, IEEE C COMP VIS PATT; SHASHUA A, 1994, IEEE C COMP VIS PATT, P483; SHIZAWA M, 1991, IEEE WORKSH VIS MOT, P164; THOMPSON WB, 1990, INT J COMPUT VISION, V4, P29; TORR PHS, 1995, ICCV, P1037; TORR PHS, 1994, ECCV, P328; VEMURI BC, 1997, P 15 INT C INF PROC, P465; WANG J, 1993, IEEE C COMP VIS PATT, P361	33	177	190	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1998	20	6					577	589		10.1109/34.683770	http://dx.doi.org/10.1109/34.683770			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZV807		Green Submitted			2022-12-18	WOS:000074343300001
J	VERRI, A; POGGIO, T				VERRI, A; POGGIO, T			MOTION FIELD AND OPTICAL-FLOW - QUALITATIVE PROPERTIES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MIT,ARTIFICIAL INTELLIGENCE LAB,CAMBRIDGE,MA 02139	Massachusetts Institute of Technology (MIT)								BARLOW HB, 1965, J PHYSIOL-LONDON, V178, P477, DOI 10.1113/jphysiol.1965.sp007638; Born M.A.X., 1980, PRINCIPLES OPTICS, VSixth, P1, DOI 10.1016/B978-0-08-026482-0.50008-6; BURT P, 1981, PSYCHOL REV, V88, P171, DOI 10.1037/0033-295X.88.2.171; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; HASSENSTEIN B, 1956, Z NATURFORSCH PT B, V11, P513; Hildreth E., 1984, MEASUREMENT VISUAL M; HILDRETH EC, 1984, PROC R SOC SER B-BIO, V221, P189, DOI 10.1098/rspb.1984.0030; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1979, APPL OPTICS, V18, P1770, DOI 10.1364/AO.18.001770; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; KANATANI K, 1985, P DARPA IMAGE UNDERS, P107; MARR D, 1981, PROC R SOC SER B-BIO, V211, P151, DOI 10.1098/rspb.1981.0001; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NAGEL HH, 1ST P C IM TRAITM SY; Peixoto MM., 1962, TOPOLOGY, V1, P101, DOI 10.1016/0040-9383(65)90018-2; PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839; POGGIO T, 1973, KYBERNETIK, V13, P223, DOI 10.1007/BF00274887; TORRE V, 1978, PROC R SOC SER B-BIO, V202, P409, DOI 10.1098/rspb.1978.0075; URAS S, 1988, BIOL CYBERN, V60, P79, DOI 10.1007/BF00202895; VANSANTEN JPH, 1984, J OPT SOC AM A, V1, P451, DOI 10.1364/JOSAA.1.000451; VERRI A, 1987, 1ST P ICCV LOND; VERRI A, 1989, IN PRESS J OPT SOC A; W Hirsch M., 1989, DIFF EQUAT+; WAXMAN AM, IN PRESS ADV COMPUTE	25	177	185	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1989	11	5					490	498		10.1109/34.24781	http://dx.doi.org/10.1109/34.24781			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	U3604					2022-12-18	WOS:A1989U360400004
J	ARCELLI, C; DIBAJA, GS				ARCELLI, C; DIBAJA, GS			A WIDTH-INDEPENDENT FAST THINNING ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											ARCELLI, C (corresponding author), CNR,IST CIBERNET,I-80072 ARCO FELICE,ITALY.							ARCELLI C, 1981, PATTERN RECOGN, V13, P225, DOI 10.1016/0031-3203(81)90099-6; ARCELLI C, 1981, COMPUT VISION GRAPH, V17, P130, DOI 10.1016/0146-664X(81)90021-6; CORDELLA LP, 1983, 3RD P SCAND C IM AN, P73; DAVIS LS, 1979, COMPUT VISION GRAPH, V11, P49, DOI 10.1016/0146-664X(79)90076-5; Hilditch C J, 1983, IMAGE VISION COMPUT, V1, P115, DOI DOI 10.1016/0262-8856(83)90063-X; PAVLIDIS T, 1980, COMPUT VISION GRAPH, V13, P142, DOI 10.1016/S0146-664X(80)80037-2; PAVLIDIS T, 1982, COMPUT VISION GRAPH, V20, P133, DOI 10.1016/0146-664X(82)90041-7; PAVLIDIS T, 1982, ALGORITHMS GRAPHICS, pCH9; ROSENFEL.A, 1966, J ACM, V13, P471; ROSENFELD A, 1969, PRIC EAWSCON CONVENT, P264; RUTOVITZ D, 1966, J R STAT SOC SER A-G, V129, P504, DOI 10.2307/2982255; SUZUKI S, 1982, 6TH P INT C PATT REC, P732; TAMURA H, 1978, 4TH P INT JOINT C PA, P715; TORIWAKI J, 1981, PROGR PATTERN RECOGN, V1, P187; WAHL FM, 1983, COMPUT VISION GRAPH, V23, P218, DOI 10.1016/0734-189X(83)90114-7; Yokoi S., 1975, COMPUT GRAPHICS IMAG, V4, P63, DOI DOI 10.1016/0146-664X(75)90022-2	16	177	179	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	4					463	474		10.1109/TPAMI.1985.4767685	http://dx.doi.org/10.1109/TPAMI.1985.4767685			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ALB69	21869284				2022-12-18	WOS:A1985ALB6900010
J	Perez-Carrasco, JA; Zhao, B; Serrano, C; Acha, B; Serrano-Gotarredona, T; Chen, SC; Linares-Barranco, B				Antonio Perez-Carrasco, Jose; Zhao, Bo; Serrano, Carmen; Acha, Begona; Serrano-Gotarredona, Teresa; Chen, Shouchun; Linares-Barranco, Bernabe			Mapping from Frame-Driven to Frame-Free Event-Driven Vision Systems by Low-Rate Rate Coding and Coincidence Processing-Application to Feedforward ConvNets	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; convolutional neural networks; object recognition; spiking neural networks; event-driven neural networks; bioinspired vision; high speed vision	OPTIC-NERVE SIGNALS; ON-CHIP; FACE DETECTION; RETINA; LATENCY	Event-driven visual sensors have attracted interest from a number of different research communities. They provide visual information in quite a different way from conventional video systems consisting of sequences of still images rendered at a given "frame rate." Event-driven vision sensors take inspiration from biology. Each pixel sends out an event (spike) when it senses something meaningful is happening, without any notion of a frame. A special type of event-driven sensor is the so-called dynamic vision sensor (DVS) where each pixel computes relative changes of light or "temporal contrast." The sensor output consists of a continuous flow of pixel events that represent the moving objects in the scene. Pixel events become available with microsecond delays with respect to "reality." These events can be processed "as they flow" by a cascade of event (convolution) processors. As a result, input and output event flows are practically coincident in time, and objects can be recognized as soon as the sensor provides enough meaningful events. In this paper, we present a methodology for mapping from a properly trained neural network in a conventional frame-driven representation to an event-driven representation. The method is illustrated by studying event-driven convolutional neural networks (ConvNet) trained to recognize rotating human silhouettes or high speed poker card symbols. The event-driven ConvNet is fed with recordings obtained from a real DVS camera. The event-driven ConvNet is simulated with a dedicated event-driven simulator and consists of a number of event-driven processing modules, the characteristics of which are obtained from individually manufactured hardware modules.	[Antonio Perez-Carrasco, Jose; Serrano, Carmen; Acha, Begona] Univ Seville, Dept Teoria Senal & Comunicac, Escuela Super Ingn, Seville 41092, Spain; [Zhao, Bo; Chen, Shouchun] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; [Serrano-Gotarredona, Teresa; Linares-Barranco, Bernabe] Inst Microelect Sevilla IMSE CNM CSIC, Seville 41092, Spain	University of Sevilla; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Instituto de Microelectronica de Sevilla (IMS-CNM)	Perez-Carrasco, JA (corresponding author), Univ Seville, Dept Teoria Senal & Comunicac, Escuela Super Ingn, Camino Descubrimientos S-N, Seville 41092, Spain.	bernabe@imse-cnm.csic.es	linares-barranco, bernabe/H-6886-2012; chen, shoushun/A-5132-2011; Pérez-Carrasco, José Antonio/J-4990-2018; Serrano, Carmen/I-1641-2015; Acha, Begoña/I-1816-2015; serrano-gotarredona, teresa/H-5263-2011	linares-barranco, bernabe/0000-0002-1813-4889; chen, shoushun/0000-0002-5451-0028; Pérez-Carrasco, José Antonio/0000-0002-9511-2499; Serrano, Carmen/0000-0003-3008-6231; Acha, Begoña/0000-0001-7838-5746; Serrano Gotarredona, Maria Teresa/0000-0001-5714-2526	European CHIST-ERA Grant PNEUMA; Spanish MICINN [PRI-PIMCHI-2011-0768]; European Regional Development Fund [TEC2009-10639-C04-01]; Andalucian [TIC609]	European CHIST-ERA Grant PNEUMA; Spanish MICINN(Ministry of Science and Innovation, Spain (MICINN)Spanish Government); European Regional Development Fund(European Commission); Andalucian	This work was supported by European CHIST-ERA Grant PNEUMA funded by Spanish MICINN (PRI-PIMCHI-2011-0768), Spanish grant (with support from the European Regional Development Fund) TEC2009-10639-C04-01 (VULCANO), and Andalucian Grant TIC609 (NANONEURO).	Lenero-Bardallo JA, 2010, IEEE T CIRCUITS-I, V57, P2632, DOI 10.1109/TCSI.2010.2046971; Azadmehr M, 2005, IEEE INT SYMP CIRC S, P2751; Bohte SM, 2002, NEUROCOMPUTING, V48, P17, DOI 10.1016/S0925-2312(01)00658-0; Booij O, 2005, INFORM PROCESS LETT, V95, P552, DOI 10.1016/j.ipl.2005.05.023; Camunas-Mesa L, 2010, IEEE INT SYMP CIRC S, P249, DOI 10.1109/ISCAS.2010.5537918; Camunas-Mesa L, 2012, IEEE J SOLID-ST CIRC, V47, P504, DOI 10.1109/JSSC.2011.2167409; Camunas-Mesa L, 2011, IEEE T CIRCUITS-I, V58, P777, DOI 10.1109/TCSI.2010.2078851; Chellapilla K., 2006, P DOCUMENT RECOGNITI, V13, P6067; Chen SS, 2007, IEEE T VLSI SYST, V15, P346, DOI 10.1109/TVLSI.2007.893624; Chicca E, 2007, IEEE T CIRCUITS-I, V54, P981, DOI 10.1109/TCSI.2007.893509; Costas-Santos J, 2007, IEEE T CIRCUITS-I, V54, P1444, DOI 10.1109/TCSI.2007.900179; Culurciello E, 2003, IEEE J SOLID-ST CIRC, V38, P281, DOI 10.1109/JSSC.2002.807412; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Delbruck T, 2007, IEEE INT SYMP CIRC S, P845, DOI 10.1109/ISCAS.2007.378038; Delbruck T, 2010, IEEE INT SYMP CIRC S, P2426, DOI 10.1109/ISCAS.2010.5537149; Farabet C., 2012, P SNOWB LEARN WORKSH; Farabet C., 2011, P EMB COMP VIS WORKS; Farabet C, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00032; Farabet C, 2010, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2010.5537908; Frome A., 2009, P IEEE INT C COMP VI; Furber SB, 2013, IEEE T COMPUT, V62, P2454, DOI 10.1109/TC.2012.142; Gerstner W., 2002, SPIKING NEURON MODEL; Gomez-Rodriguez F, 2006, IEEE INT SYMP CIRC S, P3253, DOI 10.1109/ISCAS.2006.1693319; Higgins CM, 2002, IEEE SENS J, V2, P508, DOI 10.1109/JSEN.2002.807304; Indiveri G., 2002, P C ADV NEUR INF PRO, V15, P1091; Joshi S., 2010, P INT WORKSH CELL NA; Kramer J, 1997, IEEE T CIRCUITS-II, V44, P86, DOI 10.1109/82.554431; Kramer J, 2002, IEEE T CIRCUITS-II, V49, P612, DOI 10.1109/TCSII.2002.807270; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lichtsteiner P., 2006, P IEEE INT SOL STAT; Lichtsteiner P, 2008, IEEE J SOLID-ST CIRC, V43, P566, DOI 10.1109/JSSC.2007.914337; Masquelier T, 2009, NEURAL COMPUT, V21, P1259, DOI 10.1162/neco.2008.06-08-804; Nasse F, 2009, LECT NOTES COMPUT SC, V5702, P83, DOI 10.1007/978-3-642-03767-2_10; Osadchy M, 2007, J MACH LEARN RES, V8, P1197; Painkras E, 2013, IEEE J SOLID-ST CIRC, V48, P1943, DOI 10.1109/JSSC.2013.2259038; Ponulak F, 2010, NEURAL COMPUT, V22, P467, DOI 10.1162/neco.2009.11-08-901; Posch Christoph, 2010, 2010 IEEE International Solid-State Circuits Conference (ISSCC), P400, DOI 10.1109/ISSCC.2010.5433973; Poulton J, 2007, IEEE J SOLID-ST CIRC, V42, P2745, DOI 10.1109/JSSC.2007.908692; Serrano-Gotarredona R, 2006, IEEE T CIRCUITS-I, V53, P2548, DOI 10.1109/TCSI.2006.883843; Serrano-Gotarredona R, 2009, IEEE T NEURAL NETWOR, V20, P1417, DOI 10.1109/TNN.2009.2023653; Serrano-Gotarredona T, 2013, IEEE J SOLID-ST CIRC, V48, P827, DOI 10.1109/JSSC.2012.2230553; Silver R, 2007, J NEUROSCI, V27, P11807, DOI 10.1523/JNEUROSCI.3575-07.2007; VAILLANT R, 1994, IEE P-VIS IMAGE SIGN, V141, P245, DOI 10.1049/ip-vis:19941301; Zaghloul KA, 2004, IEEE T BIO-MED ENG, V51, P667, DOI 10.1109/TBME.2003.821040; Zaghloul KA, 2004, IEEE T BIO-MED ENG, V51, P657, DOI 10.1109/TBME.2003.821039; Zamarreno-Ramos C., IEEE T BIOM IN PRESS; Zamarreno-Ramos C, 2013, IEEE T BIOMED CIRC S, V7, P82, DOI 10.1109/TBCAS.2012.2195725; Zamarreno-Ramos C, 2012, IEEE T BIOMED CIRC S, V6, P486, DOI 10.1109/TBCAS.2012.2186136; Zamarreno-Ramos C, 2011, IEEE T CIRCUITS-I, V58, P2647, DOI 10.1109/TCSI.2011.2151070	50	176	185	2	48	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2013	35	11					2706	2719		10.1109/TPAMI.2013.71	http://dx.doi.org/10.1109/TPAMI.2013.71			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	223SU	24051730	Green Submitted			2022-12-18	WOS:000324830900011
J	Wang, C; Zhang, JP; Wang, L; Pu, J; Yuan, XR				Wang, Chen; Zhang, Junping; Wang, Liang; Pu, Jian; Yuan, Xiaoru			Human Identification Using Temporal Information Preserving Gait Template	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; gait recognition; biometric authentication; pattern recognition	RECOGNITION; IMAGE; EXTRACTION	Gait Energy Image (GEI) is an efficient template for human identification by gait. However, such a template loses temporal information in a gait sequence, which is critical to the performance of gait recognition. To address this issue, we develop a novel temporal template, named Chrono-Gait Image (CGI), in this paper. The proposed CGI template first extracts the contour in each gait frame, followed by encoding each of the gait contour images in the same gait sequence with a multichannel mapping function and compositing them to a single CGI. To make the templates robust to a complex surrounding environment, we also propose CGI-based real and synthetic temporal information preserving templates by using different gait periods and contour distortion techniques. Extensive experiments on three benchmark gait databases indicate that, compared with the recently published gait recognition approaches, our CGI-based temporal information preserving approach achieves competitive performance in gait recognition with robustness and efficiency.	[Wang, Chen; Zhang, Junping; Pu, Jian] Fudan Univ, Shanghai Key Lab Intelligent Informat Proc, Sch Comp Sci, Shanghai 200433, Peoples R China; [Wang, Liang] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China; [Yuan, Xiaoru] Peking Univ, Sch Elect Engn & Comp Sci, Key Lab Machine Percept, Beijing 100871, Peoples R China	Fudan University; Chinese Academy of Sciences; Institute of Automation, CAS; Peking University	Wang, C (corresponding author), Fudan Univ, Shanghai Key Lab Intelligent Informat Proc, Sch Comp Sci, Handan Rd 220, Shanghai 200433, Peoples R China.	chen.wang0517@gmail.com; jpzhang@fudan.edu.cn; wangliang@nlpr.ia.ac.cn; mydaiyu@hotmail.com; xiaoru.yuan@pku.edu.cn	Yuan, Xiaoru/E-1798-2013	Yuan, Xiaoru/0000-0002-7233-980X	NSFC [60975044, 60903062, 61175003]; 973 program [2010CB327900]; Shanghai Leading Academic Discipline Project [B114]; Hui-Chun Chin, and Tsung-Dao Lee Chinese Undergraduate Research Endowment (CURE)	NSFC(National Natural Science Foundation of China (NSFC)); 973 program(National Basic Research Program of China); Shanghai Leading Academic Discipline Project(Shanghai Leading Academic Discipline Project); Hui-Chun Chin, and Tsung-Dao Lee Chinese Undergraduate Research Endowment (CURE)	This work was supported in part by the NSFC (No. 60975044, 60903062, 61175003), 973 program (No. 2010CB327900), Shanghai Leading Academic Discipline Project No. B114 and Hui-Chun Chin, and Tsung-Dao Lee Chinese Undergraduate Research Endowment (CURE).	Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Bouchrika I, 2007, LECT NOTES COMPUT SC, V4418, P150; Chai YM, 2006, INT C PATT RECOG, P425; CHEN C, 2009, P 3 IAPR IEEE INT C, P1037; Chen CY, 2010, IEEE T SYST MAN CY B, V40, P208, DOI 10.1109/TSMCB.2009.2025028; Guo BF, 2009, IEEE T SYST MAN CY A, V39, P36, DOI 10.1109/TSMCA.2008.2007977; Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38; Jaenicke H, 2007, IEEE T VIS COMPUT GR, V13, P1384, DOI 10.1109/TVCG.2007.70615; Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865; Kobayashi T, 2004, INT C PATT RECOG, P741, DOI 10.1109/ICPR.2004.1333879; Liu ZY, 2006, IEEE T PATTERN ANAL, V28, P863, DOI 10.1109/TPAMI.2006.122; Liu ZY, 2004, INT C PATT RECOG, P211, DOI 10.1109/ICPR.2004.1333741; Liu ZY, 2004, PROC SPIE, V5404, P195, DOI 10.1117/12.543107; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39; Shutler J.D., 2002, P 4 INT C REC ADV SO, P66; Sundaresan A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P93; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Veres GV, 2004, PROC CVPR IEEE, P776; Wang CL, 2008, IEEE T VIS COMPUT GR, V14, P1547, DOI 10.1109/TVCG.2008.140; Wang C, 2010, LECT NOTES COMPUT SC, V6311, P257, DOI 10.1007/978-3-642-15549-9_19; Wang L, 2004, IEEE T CIRC SYST VID, V14, P149, DOI 10.1109/TCSVT.2003.821972; Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144; Wang L, 2003, IEEE T IMAGE PROCESS, V12, P1120, DOI 10.1109/TIP.2003.815251; Winter D., 2009, BIOMECHANICS MOTOR C, V4th; Woodring J., 2003, P 2003 EUR IEEE TVCG, P27, DOI DOI 10.1145/827051.827054; Xu D, 2006, IEEE T CIRC SYST VID, V16, P896, DOI 10.1109/TCSVT.2006.877418; Yam C., 2009, ENCY BIOMETRICS, P633, DOI DOI 10.1007/978-0-387-73003-5_37; Yan CX, 2003, PATTERN RECOGN LETT, V24, P2935, DOI 10.1016/S0167-8655(03)00154-5; Yu SQ, 2006, INT C PATT RECOG, P441; Zhang JP, 2010, IEEE T SYST MAN CY B, V40, P986, DOI 10.1109/TSMCB.2010.2042166	32	176	193	1	54	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2012	34	11					2164	2176		10.1109/TPAMI.2011.260	http://dx.doi.org/10.1109/TPAMI.2011.260			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	005MR	22201053				2022-12-18	WOS:000308755000009
J	Solmaz, B; Moore, BE; Shah, M				Solmaz, Berkan; Moore, Brian E.; Shah, Mubarak			Identifying Behaviors in Crowd Scenes Using Stability Analysis for Dynamical Systems	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video scene analysis; dynamical systems; crowd behaviors	FLOW	A method is proposed for identifying five crowd behaviors (bottlenecks, fountainheads, lanes, arches, and blocking) in visual scenes. In the algorithm, a scene is overlaid by a grid of particles initializing a dynamical system defined by the optical flow. Time integration of the dynamical system provides particle trajectories that represent the motion in the scene; these trajectories are used to locate regions of interest in the scene. Linear approximation of the dynamical system provides behavior classification through the Jacobian matrix; the eigenvalues determine the dynamic stability of points in the flow and each type of stability corresponds to one of the five crowd behaviors. The eigenvalues are only considered in the regions of interest, consistent with the linear approximation and the implicated behaviors. The algorithm is repeated over sequential clips of a video in order to record changes in eigenvalues, which may imply changes in behavior. The method was tested on over 60 crowd and traffic videos.	[Solmaz, Berkan; Shah, Mubarak] Univ Cent Florida, Dept Elect Engn & Comp Sci, Orlando, FL 32816 USA; [Moore, Brian E.] Univ Cent Florida, Dept Math, Orlando, FL 32816 USA	State University System of Florida; University of Central Florida; State University System of Florida; University of Central Florida	Solmaz, B (corresponding author), Univ Cent Florida, Dept Elect Engn & Comp Sci, 4000 Cent Florida Blvd, Orlando, FL 32816 USA.	bsolmaz@eecs.ucf.edu; bmoore@math.ucf.edu; shah@eecs.ucf.edu		Shah, Mubarak/0000-0001-6172-5572	US Army Research Laboratory; US Army Research Office [W9 11NF-09-1-0255]	US Army Research Laboratory(United States Department of DefenseUS Army Research Laboratory (ARL)); US Army Research Office	This research was supported by the US Army Research Laboratory and the US Army Research Office under grant number W9 11NF-09-1-0255.	Ali S., 2007, P IEEE CS C COMP VIS; Ali S, 2008, LECT NOTES COMPUT SC, V5303, P1, DOI 10.1007/978-3-540-88688-4_1; Andrade EL, 2006, INT C PATT RECOG, P175; Brostow G., 2006, P IEEE CS C COMP VIS; Chan AB, 2005, IEEE I CONF COMP VIS, P641; Chan AB, 2009, IEEE I CONF COMP VIS, P545, DOI 10.1109/ICCV.2009.5459191; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Ford RM, 1997, PATTERN RECOGN, V30, P1991, DOI 10.1016/S0031-3203(97)00029-0; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; Haller G, 2000, PHYSICA D, V147, P352, DOI 10.1016/S0167-2789(00)00142-1; Helbing D., 1992, Complex Systems, V6, P391; Hu M., 2008, P INT C PATT REC; Hughes RL, 2002, TRANSPORT RES B-METH, V36, P507, DOI 10.1016/S0191-2615(01)00015-7; Johnson N, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P583; Kratz L., 2010, P IEEE C COMP VIS PA; Kratz L., 2009, P IEEE C COMP VIS PA; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Li R., 2010, P IEEE C COMP VIS PA; Lucas B.D., 1981, IJCAI 81 P 7 INT JOI, P674, DOI DOI 10.1109/HPDC.2004.1323531; Mahadevan V., 2010, P IEEE C COMP VIS PA; Marques J. S., 2003, P 2003 C COMP VIS PA, P101; Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641; OKUBO A, 1970, DEEP-SEA RES, V17, P445, DOI 10.1016/0011-7471(70)90059-8; Pellegrini S., 2009, P 12 IEEE INT C COMP; Pittore M, 2000, INT J COMPUT VISION, V38, P35, DOI 10.1023/A:1008114700759; Rabaud V., 2006, P IEEE CS C COMP VIS; RAO AR, 1992, IEEE T PATTERN ANAL, V14, P693, DOI 10.1109/34.142908; Reisman P, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P66; Sand P., 2006, P IEEE CS C COMP VIS; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Strogatz S.H., 1996, NONLINEAR DYNAMICS C; Tu P., 2008, P 10 EUR C COMP VIS; Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734; Widhalm P., 2010, P INT C PATT REC; Wright J., 2005, P IEEE WORKSH MOT VI, V2, P14; Wu S., 2010, P IEEE C COMP VIS PA; Yang DB, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P122; Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4; Zhao T., 2004, P IEEE CS C COMP VIS; Zhong H., 2004, P IEEE CS C COMP VIS	40	176	180	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2012	34	10					2064	2070		10.1109/TPAMI.2012.123	http://dx.doi.org/10.1109/TPAMI.2012.123			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	988WY	22641705				2022-12-18	WOS:000307522700016
J	Moghaddam, B				Moghaddam, B			Principal manifolds and probabilistic subspaces for visual recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						subspace techniques; PCA; ICA; kernel PCA; probabilistic PCA; learning; density estimation; face recognition	INDEPENDENT COMPONENT ANALYSIS; BLIND SEPARATION	We investigate the use of linear and nonlinear principal manifolds for learning low-dimensional representations for visual recognition. Several leading techniques: Principal Component Analysis (PCA), Independent Component Analysis (ICA), and nonlinear Kernel PCA (KPCA) are examined and tested in a visual recognition experiment using 1,800+ facial images from the "FERET" database. We compare the recognition performance of nearest-neighbor matching with each principal manifold representation to that of a maximum a posteriori (MAP) matching rule using a Bayesian similarity measure derived from dual probabilistic subspaces. The experimental results demonstrate the simplicity, computational economy, and performance superiority of the Bayesian subspace method over principal manifold techniques for visual matching.	Mitsubishi Elect Res Lab, Cambridge, MA 02139 USA		Moghaddam, B (corresponding author), Mitsubishi Elect Res Lab, 201 Broadway, Cambridge, MA 02139 USA.	baback@merl.com						Attias H, 1999, NEURAL COMPUT, V11, P803, DOI 10.1162/089976699300016458; Bartlett MS, 1998, P SOC PHOTO-OPT INS, V3299, P528, DOI 10.1117/12.320144; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; BISHOP CM, 1999, ADV NEURAL INFORMATI, P482; BREGLER C, 1994, ADV NEURAL INFORMATI, V6, P43; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; BURL MC, 1994, P IEEE C COMP VIS PA; Cardoso JF, 1999, NEURAL COMPUT, V11, P157, DOI 10.1162/089976699300016863; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; COURANT R, 1953, METHODS MATH PHYSICS, V1; DEMERS D, 1993, ADV NEURAL INFORMATI; Etemad K, 1996, INT CONF ACOUST SPEE, P2148, DOI 10.1109/ICASSP.1996.545741; Frey BJ, 1999, NEURAL COMPUT, V11, P193, DOI 10.1162/089976699300016872; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; Hastie T., 1984, PRINCIPAL CURVES SUR; HYVARINEN A, 1996, A40 HELS U TECHN; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; JONES MJ, 1996, 1583 AI MIT; JUTTEN C, 1991, SIGNAL PROCESS, V24, P1, DOI 10.1016/0165-1684(91)90079-X; KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209; LOE MM, 1955, PROBABILITY THEORY; Makeig S, 1996, ADV NEUR IN, V8, P145; MALTHOUSE EC, 1998, SOEM THEORETICAL RES; McKeown MJ, 1998, HUM BRAIN MAPP, V6, P160, DOI 10.1002/(SICI)1097-0193(1998)6:3<160::AID-HBM5>3.0.CO;2-1; Moghaddam B, 1996, PROC CVPR IEEE, P638, DOI 10.1109/CVPR.1996.517140; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; MOGHADDAM B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P786, DOI 10.1109/ICCV.1995.466858; Moghaddam B, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P30, DOI 10.1109/AFGR.1998.670921; MOGHADDAM B, 1998, ADV NEURAL INFORMATI, V11, P910; MOGHADDAM B, 1998, P INT C PATT REC AUG; MURASE H, 1993, P QUAL VIS WORKSH CV; MURASE H, 1995, INT COMPUTER VISION, V14; Nayar SK, 1996, PROC CVPR IEEE, P471, DOI 10.1109/CVPR.1996.517114; NAYAR SK, 1994, NEURAL STOCHASTIC ME, V2304; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814; Phillips PJ, 1997, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.1997.609311; RUBIN DB, 1982, PSYCHOMETRIKA, V47, P69, DOI 10.1007/BF02293851; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SCLAROFF S, 1995, IEEE T PATTERN ANAL, V17, P545, DOI 10.1109/34.387502; Taylor C, 1992, P BRIT MACH VIS C, P9, DOI DOI 10.5244/C.6.2; TIPPING M, 1997, NCRG97010 AST U; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; ZEMEL RS, 1994, ADV NEURAL INFORMATI, V6, P11	45	176	204	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2002	24	6					780	788		10.1109/TPAMI.2002.1008384	http://dx.doi.org/10.1109/TPAMI.2002.1008384			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	556JU					2022-12-18	WOS:000175846300006
J	Liu, CJ; Wechsler, H				Liu, CJ; Wechsler, H			Evolutionary pursuit and its application to face recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						evolutionary pursuit; face recognition; genetic algorithms; optimal basis; Principal Component Analysis (PCA); Fisher Linear Discriminant (FLD)	INDEPENDENT COMPONENT ANALYSIS; PROJECTION PURSUIT; REPRESENTATION; APPROXIMATION; ALGORITHM; IMAGES	This paper introduces Evolutionary Pursuit (EP) as a novel and adaptive representation method for image encoding and classification. In analogy to projection pursuit methods, EP seeks to learn an optimal basis for the dual purpose of data compression and pattern classification. The challenge for EP is to increase the generalization ability of the learning machine as a result of seeking the trade-off between minimizing the empirical risk encountered during training and narrowing the confidence interval for reducing the guaranteed risk during future testing on unseen images. Toward that end, EP implements strategies characteristic of genetic algorithms (GAs) for searching the space of possible solutions to determine the optimal basis. EP starts by projecting the original data into a Lower dimensional whitened Principal Component Analysis (PCA) space. Directed but random rotations of the basis Vectors In this space are then searched by GAs where evolution is driven by a fitness function defined in terms of performance accuracy ("empirical risk") and class separation ("confidence interval"). Accuracy indicates the extent to which learning has been successful so far. while separation gives an indication of the expected fitness on future trials. The feasibility of the new method has been successfully tested on face recognition where the large number of possible bases requires some type of greedy search algorithm. The particular face recognition task involves 1,107 FERET frontal face images corresponding to 369 subjects. To assess both accuracy and generalization capability. the data includes for each subject images acquired at different times or under different illumination conditions. The results reported show that EP improves on face recognition performance when compared against PCA ("Eigenfaces") and displays better generalization abilities than the Fisher linear discriminant ("Fisherfaces").	Univ Missouri, Dept Math & Comp Sci, St Louis, MO 63121 USA; George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA	University of Missouri System; University of Missouri Saint Louis; George Mason University	Liu, CJ (corresponding author), Univ Missouri, Dept Math & Comp Sci, St Louis, MO 63121 USA.	cliu@cs.umsl.edu; wechsler@cs.gmu.edu						Barlow HB, 1989, NEURAL COMPUT, V1, P295, DOI 10.1162/neco.1989.1.3.295; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; CHAN TF, 1982, ACM T MATH SOFTWARE, V8, P72, DOI 10.1145/355984.355990; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; CHEN S, 1996, BASIS PURSUIT; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; COOTES TF, 1998, P 5 EUR C COMP VIS; DAUGMAN JG, 1990, COMPUTATIONAL NEUROS, P403; Diamantaras K.I., 1996, PRINCIPAL COMPONENT; Edelman GM, 1989, REMEMBERED PRESENT B; Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; Fukunaga K., 1991, INTRO STAT PATTERN R, Vsecond; Girosi F, 1998, NEURAL COMPUT, V10, P1455, DOI 10.1162/089976698300017269; Goldberg D.E., 1989, GENETIC ALGORITHMS S, DOI DOI 10.1111/J.1365-2486.2009.02080.X; Haykin S., 1994, NEURAL NETWORKS COMP; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; Hyvarinen A, 1997, NEURAL COMPUT, V9, P1483, DOI 10.1162/neco.1997.9.7.1483; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Karhunen J, 1997, IEEE T NEURAL NETWOR, V8, P486, DOI 10.1109/72.572090; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; LINSKER R, 1988, COMPUTER, V21, P105, DOI 10.1109/2.36; LIU C, 1998, P COMP VIS PATT REC; Liu C., 1999, P 2 INT C AUD VID BA; LIU C, 1998, P 14 INT C PATT REC; LIU C, 1998, P 5 EUR C COMP VIS; Liu CJ, 2000, IEEE T IMAGE PROCESS, V9, P132, DOI 10.1109/83.817604; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Penev PS, 1996, NETWORK-COMP NEURAL, V7, P477, DOI 10.1088/0954-898X/7/3/002; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Phillips PJ, 1998, IEEE T IMAGE PROCESS, V7, P1150, DOI 10.1109/83.704308; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; Poggio T, 1998, NEURAL COMPUT, V10, P1445, DOI 10.1162/089976698300017250; Ruderman DL, 1994, NETWORK-COMP NEURAL, V5, P598; SAMAL A, 1992, PATTERN RECOGN, V25, P65, DOI 10.1016/0031-3203(92)90007-6; Sinha P, 1996, NATURE, V384, P404, DOI 10.1038/384404a0; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; Tikhonov A. N., 1977, SOLUTIONS ILL POSED; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; VAPNIK YN, 1995, NATURE STAT LEARNING	42	176	184	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2000	22	6					570	582		10.1109/34.862196	http://dx.doi.org/10.1109/34.862196			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	342WE					2022-12-18	WOS:000088667700003
J	Chen, YC; Zhu, XT; Zheng, WS; Lai, JH				Chen, Ying-Cong; Zhu, Xiatian; Zheng, Wei-Shi; Lai, Jian-Huang			Person Re-Identification by Camera Correlation Aware Feature Augmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Person re-identification; adaptive feature augmentation; view-specific transformation	ADAPTATION; NETWORK	The challenge of person re-identification (re-id) is to match individual images of the same person captured by different non-overlapping camera views against significant and unknown cross-view feature distortion. While a large number of distance metric/subspace learning models have been developed for re-id, the cross-view transformations they learned are view-generic and thus potentially less effective in quantifying the feature distortion inherent to each camera view. Learning view-specific feature transformations for re-id (i.e., view-specific re-id), an under-studied approach, becomes an alternative resort for this problem. In this work, we formulate a novel view-specific person re-identification framework from the feature augmentation point of view, called Camera coRrelation Aware Feature augmenTation (CRAFT). Specifically, CRAFT performs cross-view adaptation by automatically measuring camera correlation from cross-view visual data distribution and adaptively conducting feature augmentation to transform the original features into a new adaptive space. Through our augmentation framework, view-generic learning algorithms can be readily generalized to learn and optimize view-specific sub-models whilst simultaneously modelling view-generic discrimination information. Therefore, our framework not only inherits the strength of view-generic model learning but also provides an effective way to take into account view specific characteristics. Our CRAFT framework can be extended to jointly learn view-specific feature transformations for person re-id across a large network with more than two cameras, a largely under-investigated but realistic re-id setting. Additionally, we present a domain-generic deep person appearance representation which is designed particularly to be towards view invariant for facilitating cross-view adaptation by CRAFT. We conducted extensively comparative experiments to validate the superiority and advantages of our proposed framework over state-of-the-art competitors on contemporary challenging person re-id datasets.	[Chen, Ying-Cong; Zhu, Xiatian; Zheng, Wei-Shi; Lai, Jian-Huang] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510275, Guangdong, Peoples R China; [Chen, Ying-Cong] Natl Univ Def Technol, Collaborat Innovat Ctr High Performance Comp, Changsha 410073, Hunan, Peoples R China; [Chen, Ying-Cong] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Sha Tin, Hong Kong, Peoples R China; [Zhu, Xiatian] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England; [Zheng, Wei-Shi] Sun Yat Sen Univ, Minist Educ, Key Lab Machine Intelligence & Adv Comp, Guangzhou 510275, Guangdong, Peoples R China; [Lai, Jian-Huang] Guangdong Prov Key Lab Informat Secur, Guangzhou 510275, Guangdong, Peoples R China	Sun Yat Sen University; National University of Defense Technology - China; Chinese University of Hong Kong; University of London; Queen Mary University London; Sun Yat Sen University	Chen, YC (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510275, Guangdong, Peoples R China.; Chen, YC (corresponding author), Natl Univ Def Technol, Collaborat Innovat Ctr High Performance Comp, Changsha 410073, Hunan, Peoples R China.; Chen, YC (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Sha Tin, Hong Kong, Peoples R China.	yingcong.ian.chen@gmail.com; xiatian.zhu@qmul.ac.uk; wszheng@ieee.org; stsljh@mail.sysu.edu.cn	Chen, Ying-Cong/ABE-3123-2020; Zhu, Xiatian/Y-1601-2019	Chen, Ying-Cong/0000-0002-9565-8205; Zhu, Xiatian/0000-0002-9284-2955	National Key Research and Development Program of China [2016YFB1001002]; NSFC [61522115, 61573387, 61661130157]; RS-Newton AdvancedFellowship [NA150459]; Guangdong Natural Science Funds for Distinguished Young Scholar [S2013050014265]	National Key Research and Development Program of China; NSFC(National Natural Science Foundation of China (NSFC)); RS-Newton AdvancedFellowship; Guangdong Natural Science Funds for Distinguished Young Scholar	This work was supported partially by the National Key Research and Development Program of China (2016YFB1001002), NSFC(61522115, 61573387, 61661130157), and the RS-Newton AdvancedFellowship (NA150459), and Guangdong Natural Science Funds for Distinguished Young Scholar under Grant S2013050014265. This work was finished when Mr. Chen was a master student at Sun Yat-sen University. The corresponding author and principal investigator for this paper is Wei-Shi Zheng.	Ahmed E., 2015, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2015.7299016; An L, 2016, IEEE T CIRC SYST VID, V26, P776, DOI 10.1109/TCSVT.2015.2416561; An L, 2015, IEEE SIGNAL PROC LET, V22, P1103, DOI 10.1109/LSP.2015.2390222; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2015, PROC CVPR IEEE; Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P435, DOI 10.1109/AVSS.2010.34; Chakraborty A, 2016, IEEE T PATTERN ANAL, V38, P1859, DOI 10.1109/TPAMI.2015.2491922; Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142; Chen DP, 2015, PROC CVPR IEEE, P1565, DOI 10.1109/CVPR.2015.7298764; Chen JX, 2014, INT C PATT RECOG, P1657, DOI 10.1109/ICPR.2014.292; Chen SZ, 2016, IEEE T IMAGE PROCESS, V25, P2353, DOI 10.1109/TIP.2016.2545929; Chen YC, 2017, IEEE T CIRC SYST VID, V27, P1661, DOI 10.1109/TCSVT.2016.2515309; Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149; Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68; Choi E, 2003, PATTERN RECOGN, V36, P1703, DOI 10.1016/S0031-3203(03)00035-9; Daume III Hal, 2007, P 45 ANN M ASS COMP, P256, DOI DOI 10.48550/ARXIV.0907.1815; Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005; Donahue J, 2014, PR MACH LEARN RES, V32; Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926; Geng B, 2011, IEEE T IMAGE PROCESS, V20, P2980, DOI 10.1109/TIP.2011.2134107; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Gong S., 2014, PERSON REIDENTIFICAT, V1; Gopalan R, 2014, IEEE T PATTERN ANAL, V36, P2288, DOI 10.1109/TPAMI.2013.249; Gray D., 2007, IEEE INT WORKSH PERF, V3, P1; Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21; Hamm J., 2008, P INT C MACH LEARN I, P376, DOI DOI 10.1145/1390156.1390204; Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56; Hu JL, 2015, PROC CVPR IEEE, P325, DOI 10.1109/CVPR.2015.7298629; Kodirov E, 2015, P BRIT MACH VIS C; Kostinger Martin, 2012, CVPR, DOI DOI 10.1109/CVPR.2012.6247939; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kviatkovsky I, 2013, IEEE T PATTERN ANAL, V35, P1622, DOI 10.1109/TPAMI.2012.246; Li W., 2013, LNCS, V7724, P31, DOI [10.1007/978-3-642-37331-2, DOI 10.1007/978-3-642-37331-2]; Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27; Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167; Li X, 2015, IEEE I CONF COMP VIS, P3765, DOI 10.1109/ICCV.2015.429; Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463; Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420; Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832; Lisanti G., 2014, P INT C DISTRIBUTED, P1, DOI DOI 10.1145/2659021.2659036; Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055; Loy CC, 2013, IEEE IMAGE PROC, P3567, DOI 10.1109/ICIP.2013.6738736; Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827; Ma LY, 2014, IEEE T IMAGE PROCESS, V23, P3656, DOI 10.1109/TIP.2014.2331755; Ma XL, 2017, PATTERN RECOGN, V65, P197, DOI 10.1016/j.patcog.2016.11.018; Martinel N, 2015, IEEE T IMAGE PROCESS, V24, P5645, DOI 10.1109/TIP.2015.2487048; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152; Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987; Muquet B, 2002, IEEE T COMMUN, V50, P2136, DOI 10.1109/TCOMM.2002.806518; Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426; Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146; Prosser B. J., 2010, PROC BRIT MACH VIS C, P6, DOI DOI 10.5244/C.24.21; Shen Y, 2015, IEEE I CONF COMP VIS, P3200, DOI 10.1109/ICCV.2015.366; Si S, 2010, IEEE T KNOWL DATA EN, V22, P929, DOI 10.1109/TKDE.2009.126; Sinha P., 1995, THESIS; Sun ZN, 2005, PROC CVPR IEEE, P279; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48; Wang D, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P205; Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144; Wang HX, 2016, IEEE IMAGE PROC, P769, DOI 10.1109/ICIP.2016.7532461; Wang HX, 2016, LECT NOTES COMPUT SC, V9908, P405, DOI 10.1007/978-3-319-46493-0_25; Wang TQ, 2016, IEEE T PATTERN ANAL, V38, P2501, DOI 10.1109/TPAMI.2016.2522418; Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45; Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010; Wang XJ, 2016, IEEE T CIRC SYST VID, V26, P1447, DOI 10.1109/TCSVT.2015.2450331; Weinberger Kilian Q, 2006, ADV NEURAL INFORM PR, P1473, DOI DOI 10.1007/978-3-319-13168-9_; WONG YC, 1967, P NATL ACAD SCI USA, V57, P589, DOI 10.1073/pnas.57.3.589; Wu SX., 2016, IEEE WINTER C APPL C, P1, DOI [DOI 10.1109/WACV.2016.7477681, 10.48550/arXiv.1809.02983, DOI 10.48550/ARXIV.1809.02983]; Xiao M, 2015, IEEE T PATTERN ANAL, V37, P54, DOI 10.1109/TPAMI.2014.2343216; Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140; Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1; Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35; Yi D, 2014, ARXIV PREPRINT ARXIV; You JJ, 2016, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2016.150; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139; Zhang Y, 2016, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR.2016.143; Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26; Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133; Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531; Zheng WS, 2016, IEEE T PATTERN ANAL, V38, P591, DOI 10.1109/TPAMI.2015.2453984; Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138; Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598	92	175	188	4	55	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2018	40	2					392	408		10.1109/TPAMI.2017.2666805	http://dx.doi.org/10.1109/TPAMI.2017.2666805			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FS9AN	28207383	Green Submitted			2022-12-18	WOS:000422706000010
J	Tai, YW; Tan, P; Brown, MS				Tai, Yu-Wing; Tan, Ping; Brown, Michael S.			Richardson-Lucy Deblurring for Scenes under a Projective Motion Path	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Motion deblurring; spatially verying motion blur		This paper addresses how to model and correct image blur that arises when a camera undergoes ego motion while observing a distant scene. In particular, we discuss how the blurred image can be modeled as an integration of the clear scene under a sequence of planar projective transformations (i.e., homographies) that describe the camera's path. This projective motion path blur model is more effective at modeling the spatially varying motion blur exhibited by ego motion than conventional methods based on space-invariant blur kernels. To correct the blurred image, we describe how to modify the Richardson-Lucy (RL) algorithm to incorporate this new blur model. In addition, we show that our projective motion RL algorithm can incorporate state-of-the-art regularization priors to improve the deblurred results. The projective motion path blur model, along with the modified RL algorithm, is detailed, together with experimental results demonstrating its overall effectiveness. Statistical analysis on the algorithm's convergence properties and robustness to noise is also provided.	[Tai, Yu-Wing] Korea Adv Inst Sci & Technol, Dept Comp Sci, Taejon 305701, South Korea; [Tan, Ping] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore; [Brown, Michael S.] Natl Univ Singapore, Sch Comp, Singapore 117417, Singapore	Korea Advanced Institute of Science & Technology (KAIST); National University of Singapore; National University of Singapore	Tai, YW (corresponding author), Korea Adv Inst Sci & Technol, Dept Comp Sci, Rm 2425,E3-1 CS Bldg,373-1 Guseong Dong, Taejon 305701, South Korea.	yuwing@cs.kaist.ac.kr; eletp@nus.edu.sg; brown@comp.nus.edu.sg	Tai, Yu Wing/C-2047-2011	Tai, Yu Wing/0000-0002-3148-0380	Ministry of Culture, Sports and Tourism (MCST); Korea Content Agency (KOCCA); KAIST [G04090064]; Singapore grant [R-263-000-555-112, R-263-000-477-112]; NUS RFC [R-252-000-423-112]	Ministry of Culture, Sports and Tourism (MCST); Korea Content Agency (KOCCA); KAIST; Singapore grant; NUS RFC	The authors thank the associate editor and all reviewers for their thorough and constructive suggestions, which were instrumental in improving the quality of the final paper. Y.-W. Tai was supported by the Ministry of Culture, Sports and Tourism (MCST) and the Korea Content Agency (KOCCA) in the Culture Technology (CT) Research & Development Program 2010, and KAIST seed grant (No. G04090064). P. Tan was supported by Singapore grant R-263-000-555-112 and R-263-000-477-112. M.S. Brown was supported by NUS RFC (No. R-252-000-423-112). The authors owe special thanks to Long Gao, who did the initial implementation of the algorithm in Matlab.	Agrawal A, 2007, P IEEE C COMP VIS PA, P1; BARDSLEY J, 2006, P OPTICS EXPRESS, P1767; Ben-Ezra M, 2004, IEEE T PATTERN ANAL, V26, P689, DOI 10.1109/TPAMI.2004.1; Ben-Ezra M, 2003, PROC CVPR IEEE, P657; Bini D, 2005, NUMER ALGORITHMS, V39, P349, DOI 10.1007/s11075-004-6709-8; Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187; Cho S, 2007, IEEE I CONF COMP VIS, P596; Dai S., 2008, P IEEE C COMP VIS PA, P1; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dey N, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 and 2, P1223; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; Hong G., 2008, P ACM MULT, P749; Jia J., 2007, IEEE C COMP VIS PATT, P1; Joshi N, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778767; Levin A., 2006, ADV NEURAL INFORM PR, V19, P841; LEVIN A, 2009, P IEEE C COMP VIS PA; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; Li F., 2008, P IEEE C COMP VIS PA; Li Y., 2010, P IEEE C COMP VIS PA; LUCY LB, 1974, ASTRON J, V79, P745, DOI 10.1086/111605; Raskar R, 2006, ACM T GRAPHIC, V25, P795, DOI 10.1145/1141911.1141957; RICHARDSON WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055; SAWCHUK AA, 1974, J OPT SOC AM, V64, P138, DOI 10.1364/JOSA.64.000138; Shan Q., 2007, P IEEE INT C COMP VI; Shan Q., 2008, ACM T GRAPHICS, V27; Tai Y.-W., 2010, P IEEE C COMP VIS PA; Tai Y. - W., 2008, P IEEE C COMP VIS PA; Tai YW, 2010, IEEE T PATTERN ANAL, V32, P1012, DOI 10.1109/TPAMI.2009.97; Vardi Y, 1969, NONLINEAR PROGRAMMIN; Whyte O., 2010, P IEEE C COMP VIS PA; Wiener, 1949, EXTRAPOLATION INTERP; Yuan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360673	33	175	188	1	57	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2011	33	8					1603	1618		10.1109/TPAMI.2010.222	http://dx.doi.org/10.1109/TPAMI.2010.222			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	779UH	21173447				2022-12-18	WOS:000291807200009
J	Cousty, J; Bertrand, G; Najman, L; Couprie, M				Cousty, Jean; Bertrand, Gilles; Najman, Laurent; Couprie, Michel			Watershed Cuts: Minimum Spanning Forests and the Drop of Water Principle	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Watershed; minimum spanning forest; minimum spanning tree; graph; mathematical morphology; image segmentation	FUZZY CONNECTEDNESS; OBJECT DEFINITION; ALGORITHMS; TREE	We study the watersheds in edge-weighted graphs. We define the watershed cuts following the intuitive idea of drops of water flowing on a topographic surface. We first establish the consistency of these watersheds: They can be equivalently defined by their "catchment basins" (through a steepest descent property) or by the "dividing lines" separating these catchment basins (through the drop of water principle). Then, we prove, through an equivalence theorem, their optimality in terms of minimum spanning forests. Afterward, we introduce a linear-time algorithm to compute them. To the best of our knowledge, similar properties are not verified in other frameworks and the proposed algorithm is the most efficient existing algorithm, both in theory and in practice. Finally, the defined concepts are illustrated in image segmentation, leading to the conclusion that the proposed approach improves, on the tested images, the quality of watershed-based segmentations.	[Cousty, Jean] Univ Paris Est, Lab Informat Gaspard Monge, Equipe A3SI, ESIEE, Paris, France; [Cousty, Jean; Bertrand, Gilles; Najman, Laurent; Couprie, Michel] Asclepios Team, INRIA Sophia Antipolis, Sophia Antipolis, France; [Cousty, Jean] INRIA, ASCLEPIOS Res team, Sophia Antipolis, France	Universite Gustave-Eiffel; ESIEE Paris; Inria	Cousty, J (corresponding author), Univ Paris Est, Lab Informat Gaspard Monge, Equipe A3SI, ESIEE, Paris, France.	j.cousty@esiee.fr; m.couprie@esiee.fr	Najman, Laurent/AAB-4212-2020	Najman, Laurent/0000-0002-6190-0235	ANR [SURF-NT05-2,45825]	ANR(French National Research Agency (ANR))	This work was partially supported by ANR grant SURF-NT05-2,45825.	Allene, 2007, MATH MORPHOLOGY ITS, V1, P253; Bertrand G, 2005, J MATH IMAGING VIS, V22, P217, DOI 10.1007/s10851-005-4891-5; Bertrand G, 2007, IMAGE VISION COMPUT, V25, P447, DOI 10.1016/j.imavis.2006.04.017; Beucher S, 1994, COMP IMAG VIS, V2, P69; Beucher S., 1979, INT WORK IMAGE PROCE; BEUCHER S, 1993, MATH MORPHOLOGY IMAG, P443; Bieniek A, 1998, COMP IMAG VIS, V12, P215; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Breen EJ, 1996, COMPUT VIS IMAGE UND, V64, P377, DOI 10.1006/cviu.1996.0066; Chazelle B, 2000, J ACM, V47, P1028, DOI 10.1145/355541.355562; Couprie M, 2005, J MATH IMAGING VIS, V22, P231, DOI 10.1007/s10851-005-4892-4; Couprie M, 1997, P SOC PHOTO-OPT INS, V3168, P136, DOI 10.1117/12.292778; COUSTY J, 1957, MINIMUM SPANNI UNPUB; COUSTY J, IEEE T PATTERN ANAL; Cousty J., 2007, THESIS U MARNE LA VA; COUSTY J, 2007, P ISMM, P301; Cousty J, 2008, DISCRETE APPL MATH, V156, P3011, DOI 10.1016/j.dam.2008.01.005; Cousty J, 2008, LECT NOTES COMPUT SC, V4992, P434, DOI 10.1007/978-3-540-79126-3_39; Dahlhaus E., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, P241, DOI 10.1145/129712.129736; DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164; DIESTEL R, 1997, GRAPH THEORY, P28; Digabel H., 1978, P 2 EUR S QUANT AN M, P85; Duda R.O., 2000, PATTERN CLASSIFICATI; Englert R, 2000, LECT NOTES COMPUT SC, V1779, P297; Falcao AX, 2004, IEEE T PATTERN ANAL, V26, P19, DOI 10.1109/TPAMI.2004.1261076; GRAHAM RL, 1985, ANN HIST COMPUT, V7, P43; Grimaud M., 1992, P SOC PHOTO-OPT INS, P292, DOI DOI 10.1117/12.60650; JORDAN C, 1872, CR HEBD ACAD SCI, V75, P1023; KONG TY, 1989, COMPUT VISION GRAPH, V48, P357, DOI 10.1016/0734-189X(89)90147-3; Kruskal J. B., 1956, P AM MATH SOC, V7, P48, DOI [DOI 10.1090/S0002-9939-1956-0078686-7, 10.2307/2033241]; LEMONNIER F, 1996, THESIS ECOLE MINES P; LOTUFO R, 2000, P 5 INT S MATH MORPH, P341; Maxwell J.C., 1870, PHILOS MAGAZ J SCI, V40, P421; MEIJSTER A, 1998, P EUR SIGN PROC C, P1669; MEYER F, 1994, SIGNAL PROCESS, V38, P113, DOI 10.1016/0165-1684(94)90060-4; Meyer F, 1996, COMPUT IMAGING VIS, P329; Meyer F, 1994, COMP IMAG VIS, V2, P77; MEYER F, 1991, P 8 C AFCET LYON VIL, P847; MEYER F, 2008, SERIE SIGNAL IMAGE, P201; Najman L, 2005, DISCRETE APPL MATH, V147, P301, DOI 10.1016/j.dam.2004.09.017; Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254; NAJMAN L, 1993, SIGNAL PROCESS, V38, P68; Najman L, 2006, IEEE T IMAGE PROCESS, V15, P3531, DOI 10.1109/TIP.2006.877518; Nesetril J, 2001, DISCRETE MATH, V233, P3, DOI 10.1016/S0012-365X(00)00224-7; PRIM RC, 1957, AT&T TECH J, V36, P1389, DOI 10.1002/j.1538-7305.1957.tb01515.x; Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187; Saha PK, 2000, COMPUT VIS IMAGE UND, V77, P145, DOI 10.1006/cviu.1999.0813; SERRA J, 1992, CIRC SYST SIGNAL PR, V11, P47, DOI 10.1007/BF01189221; Serra J., 1988, IMAGE ANAL MATH MORP; Soille P., 1994, Journal of Visual Communication and Image Representation, V5, P181, DOI 10.1006/jvci.1994.1017; Soille P., 1999, MORPHOLOGICAL IMAGE; STOEV S, 2000, P 8 INT C COMP GRAPH; TARJAN RE, 1975, J ACM, V22, P215, DOI 10.1145/321879.321884; Thorup M, 1996, PROCEEDINGS OF THE SEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P59; Udupa JK, 1996, GRAPH MODEL IM PROC, V58, P246, DOI 10.1006/gmip.1996.0021; Udupa JK, 2002, IEEE T PATTERN ANAL, V24, P1485, DOI 10.1109/TPAMI.2002.1046162; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083; Zhuge Y, 2006, COMPUT VIS IMAGE UND, V101, P177, DOI 10.1016/j.cviu.2005.07.009	59	175	183	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2009	31	8					1362	1374		10.1109/TPAMI.2008.173	http://dx.doi.org/10.1109/TPAMI.2008.173			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	458UN	19542572	Green Submitted			2022-12-18	WOS:000267050600002
J	Paragios, N; Mellina-Gottardo, O; Ramesh, V				Paragios, N; Mellina-Gottardo, O; Ramesh, V			Gradient vector flow fast geometric active contours	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						boundary extraction; image segmentation; gradient vector flow; geodesic active contours; level set methods; additive operator splitting	SNAKES	In this paper, we propose an edge-driven bidirectional geometric flow for boundary extraction. To this end, we combine the geodesic active contour flow [3] and the gradient vector flow external force for snakes [25]. The resulting motion equation is considered within a level set formulation [19], can deal with topological changes and important shape deformations. An efficient numerical schema is used for the flow implementation that exhibits robust behavior and has fast convergence rate [8], [23]. Promising results on real and synthetic images demonstrate the potentials of the flow.	Siemens Corp Res, Real Time Vis & Modeling Dept, Princeton, NJ 08540 USA	Siemens AG	Paragios, N (corresponding author), Siemens Corp Res, Real Time Vis & Modeling Dept, 755 Coll Rd E, Princeton, NJ 08540 USA.	nikos@sr.siemens.com; rameshv@scr.siemens.com						ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; CASELLES V, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P694, DOI 10.1109/ICCV.1995.466871; Chan T, 1999, LECT NOTES COMPUT SC, V1682, P141; DELINGETTE H, 2000, LNCS, V1843, P381; Goldenberg R, 2001, IEEE T IMAGE PROCESS, V10, P1467, DOI 10.1109/83.951533; KASS M, 1987, P INT C COMP VIS, P261; Kervrann C., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P963, DOI 10.1109/ICCV.1999.790352; KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855; Kimmel R, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P59, DOI 10.1007/0-387-21810-6_4; KIMMEL R, 2001, P IM VIS COMP C; LIPSON P, 1990, P 1 EUR C COMP VIS, P413; MALLADI R, 1994, P 3 EUR C COMP VIS, P1; MCIRNERNEY T, 1995, P INT C COMP VIS ICC, P840; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Osher S., 2003, GEOMETRIC LEVEL SET; Paragios N, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P67, DOI 10.1109/ICCV.2001.937500; Paragios N., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P926, DOI 10.1109/ICCV.1999.790347; PARAGIOS N, 1998, RR 3440 INRIA; Vasilevskiy A, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P149, DOI 10.1109/ICCV.2001.937511; Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190; Weickert J, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P43, DOI 10.1007/0-387-21810-6_3; Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186; Xu CY, 1998, SIGNAL PROCESS, V71, P131, DOI 10.1016/S0165-1684(98)00140-6; Xu CY, 2000, CONF REC ASILOMAR C, P483, DOI 10.1109/ACSSC.2000.911003; Yezzi A.  Jr., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P898, DOI 10.1109/ICCV.1999.790317; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343; [No title captured]	29	175	203	3	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2004	26	3					402	407		10.1109/TPAMI.2004.1262337	http://dx.doi.org/10.1109/TPAMI.2004.1262337			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	773WZ	15376886				2022-12-18	WOS:000188949400010
J	Tao, H; Sawhney, HS; Kumar, R				Tao, H; Sawhney, HS; Kumar, R			Object tracking with Bayesian estimation of dynamic layer representations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion analysis; dynamic layer representation; tracking; aerial video surveillance	MOTION SEGMENTATION; ALGORITHM; MODELS	Decomposing video frames into coherent two-dimensional motion layers is a powerful method for representing videos. Such a representation provides an intermediate description that enables applications such as object tracking, video summarization and visualization, video insertion, and sprite-based video compression. Previous work on motion layer analysis has largely concentrated on two-frame or multiframe batch formulations. The temporal coherency of motion layers and the domain constraints on shapes have not been exploited. This paper introduces a complete dynamic motion layer representation in which spatial and temporal constraints on shape, motion, and layer appearance are modeled and estimated in a maximum a posteriori (MAP) framework using the generalized expectation-maximization (EM) algorithm. In order to limit the computational complexity of tracking arbitrarily shaped layer ownership, we propose a shape prior that parameterizes the representation of shape and prevents motion layers from evolving into arbitrary shapes. In this work, a Gaussian shape prior is chosen to specifically develop a near real-time tracker for vehicle tracking in aerial videos. However, the general idea of using a parametric shape representation as part of the state of a tracker is a powerful one that can be extended to other domains as well. Based on the dynamic layer representation, an iterative algorithm is developed for continuous object tracking over time. The proposed method has been successfully applied in an airborne vehicle tracking system. Its performance is compared with that of a correlation-based tracker and a motion change-based tracker to demonstrate the advantages of the new method. Examples of tracking when the backgrounds are cluttered and the vehicles undergo various rigid motions and complex interactions such as passing, turning, and stop-and-go demonstrate the strength of the complete dynamic layer representation.	Univ Calif Santa Cruz, Dept Comp Engn, Santa Cruz, CA 95064 USA; Sarnoff Corp, Princeton, NJ 08543 USA	University of California System; University of California Santa Cruz; Sarnoff Corporation	Tao, H (corresponding author), Univ Calif Santa Cruz, Dept Comp Engn, Santa Cruz, CA 95064 USA.	tao@soc.ucsc.edu; hsawhney@sarnoff.com; rkumar@sarnoff.com						AYER S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P777, DOI 10.1109/ICCV.1995.466859; BERGEN JR, 1992, P EUR C COMP VIS, P237; BLACK MJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P374, DOI 10.1109/ICCV.1995.466915; Cox IJ, 1996, IEEE T PATTERN ANAL, V18, P138, DOI 10.1109/34.481539; Darrell T., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P173, DOI 10.1109/WVM.1991.212810; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Hager GD, 1996, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.1996.517104; HSU S, 1994, P INT C PATT REC; Jojic N, 2000, PROC CVPR IEEE, P26, DOI 10.1109/CVPR.2000.854728; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Torr P. H. S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P983, DOI 10.1109/ICCV.1999.790355; Vasconcelos N, 1997, PROC CVPR IEEE, P527, DOI 10.1109/CVPR.1997.609376; Wang J. Y. A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P361, DOI 10.1109/CVPR.1993.341105; Weiss Y, 1997, PROC CVPR IEEE, P520, DOI 10.1109/CVPR.1997.609375; Weiss Y, 1996, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.1996.517092	16	175	201	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2002	24	1					75	89		10.1109/34.982885	http://dx.doi.org/10.1109/34.982885			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	506FZ					2022-12-18	WOS:000172960300005
J	Peleg, S; Ben-Ezra, M; Pritch, Y				Peleg, S; Ben-Ezra, M; Pritch, Y			Omnistereo: Panoramic stereo imaging	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						stereo imaging; panoramic imaging; image mosaicing	MOSAICS	AnOmnistereo panorama consists of a pair of panoramic images. where one panorama is for the left eye and another panorama is for the right eye. The panoramic stereo pair provides a stereo sensation up to a full 360 degrees. Omnistereo panoramas cannot be photographed by two omnidirectional cameras from two viewpoints, but can be constructed by mosaicing together images from a rotating stereo pair. A more convenient approach to generate omnistereo panoramas is by mosaicing images from a single rotating camera. This approach also enables the control of stereo disparity, giving larger baselines for faraway scenes, and a smaller baseline for closer scenes. Capturing panoramic omnistereo images with a rotating camera makes it impossible to capture dynamic scenes at video rates and limits omnistereo imaging to stationary scenes. We. therefore, present two possibilities for capturing omnistereo panoramas using optics without any moving parts. A special mirror is introduced such that viewing the scene through this mirror creates the same rays as those used with the rotating cameras. A lens for omnistereo panorama is also introduced. The designs of the mirror and of the lens are based on curves whose caustic is a circle. Omnistereo panoramas can also be rendered by computer graphics methods to represent virtual environments.	Hebrew Univ Jerusalem, Sch Engn & Comp Sci, IL-91904 Jerusalem, Israel	Hebrew University of Jerusalem	Peleg, S (corresponding author), Hebrew Univ Jerusalem, Sch Engn & Comp Sci, IL-91904 Jerusalem, Israel.	peleg@cs.huji.ac.il; moshe@omnistereo.com; yael@omnistereo.com	Peleg, Shmuel/B-7454-2011	Peleg, Shmuel/0000-0002-4468-2619				Chen S. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P29, DOI 10.1145/218380.218395; Gluckman J., 1998, P DARPA IM UND WORKS, V1, P299; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; Huang HC, 1998, GRAPH MODEL IM PROC, V60, P196, DOI 10.1006/gmip.1998.0467; ISHIGURO H, 1992, IEEE T PATTERN ANAL, V14, P257, DOI 10.1109/34.121792; Kang SB, 1996, PROC CVPR IEEE, P364, DOI 10.1109/CVPR.1996.517098; Kawanishi T, 1998, INT C PATT RECOG, P485, DOI 10.1109/ICPR.1998.711187; MANN S, 1994, IEEE IMAGE PROC, P363, DOI 10.1109/ICIP.1994.413336; McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398; Naemura T, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P903, DOI 10.1109/ICIP.1998.723666; Nayar SK, 1997, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1997.609369; Nayar SK, 2000, PROC CVPR IEEE, P388; Peleg S, 1997, PROC CVPR IEEE, P338, DOI 10.1109/CVPR.1997.609346; Peleg S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P395, DOI 10.1109/CVPR.1999.786969; PRITCH Y, 2001, FDN IMAGE PROCESSING; Rademacher P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P199, DOI 10.1145/280814.280871; Shimamura J, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P62, DOI 10.1109/OMNVIS.2000.853806; SHUM HY, 1999, P 7 INT C COMP VIS, P22; Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677; Wood D. N., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P243, DOI 10.1145/258734.258859; Yates R.C, 1952, HDB CURVES THEIR PRO	21	175	207	1	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2001	23	3					279	290		10.1109/34.910880	http://dx.doi.org/10.1109/34.910880			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	407MW					2022-12-18	WOS:000167276200004
J	LO, CH; DON, HS				LO, CH; DON, HS			3-D MOMENT FORMS - THEIR CONSTRUCTION AND APPLICATION TO OBJECT IDENTIFICATION AND POSITIONING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											LO, CH (corresponding author), SUNY STONY BROOK,DEPT ELECT ENGN,STONY BROOK,NY 11794, USA.							ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698, DOI 10.1109/TPAMI.1984.4767594; CYGANSKI D, 1985, IEEE T PATTERN ANAL, V7, P662, DOI 10.1109/TPAMI.1985.4767722; DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; Edmonds AR, 1974, ANGULAR MOMENTUM QUA; FABER TL, 1986, EEE C COMPUT VISION, P440; FAUGERAS OD, 3 DIMENSION MACHINE; Hamermesh M., 1962, GROUP THEORY ITS APP; Horn B., 1986, ROBOT VISION, P1; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; KANATANI KI, 1984, INT J ENG SCI, V22, P531, DOI 10.1016/0020-7225(84)90055-7; KANATANI KI, 1984, INT J ENG SCI, V22, P149, DOI 10.1016/0020-7225(84)90090-9; Lin Z., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P303; MARGENAU H, 1964, MATH PHYSICS CHEM; PINJO Z, 1985, PATTERN RECOGN LETT, V3, P351, DOI 10.1016/0167-8655(85)90067-4; REDDI SS, 1981, IEEE T PATTERN ANAL, V3, P240, DOI 10.1109/TPAMI.1981.4767087; SADJADI FA, 1980, IEEE T PATTERN ANAL, V2, P127, DOI 10.1109/TPAMI.1980.4766990; SCHWARTZ JT, 1987, INT J ROBOT RES, V6, P29, DOI 10.1177/027836498700600203; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913; WIGNEE, 1959, GROUP THEORY ITS APP; WONG RY, 1978, COMPUT VISION GRAPH, V8, P16, DOI 10.1016/S0146-664X(78)80028-8	21	175	193	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1989	11	10					1053	1064		10.1109/34.42836	http://dx.doi.org/10.1109/34.42836			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR689					2022-12-18	WOS:A1989AR68900003
J	Lan, T; Wang, Y; Yang, WL; Robinovitch, SN; Mori, G				Lan, Tian; Wang, Yang; Yang, Weilong; Robinovitch, Stephen N.; Mori, Greg			Discriminative Latent Models for Recognizing Contextual Group Activities	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Group activity recognition; context; latent structured models		In this paper, we go beyond recognizing the actions of individuals and focus on group activities. This is motivated from the observation that human actions are rarely performed in isolation; the contextual information of what other people in the scene are doing provides a useful cue for understanding high-level activities. We propose a novel framework for recognizing group activities which jointly captures the group activity, the individual person actions, and the interactions among them. Two types of contextual information, group-person interaction and person-person interaction, are explored in a latent variable framework. In particular, we propose three different approaches to model the person-person interaction. One approach is to explore the structures of person-person interaction. Differently from most of the previous latent structured models, which assume a predefined structure for the hidden layer, e.g., a tree structure, we treat the structure of the hidden layer as a latent variable and implicitly infer it during learning and inference. The second approach explores person-person interaction in the feature level. We introduce a new feature representation called the action context (AC) descriptor. The AC descriptor encodes information about not only the action of an individual person in the video, but also the behavior of other people nearby. The third approach combines the above two. Our experimental results demonstrate the benefit of using contextual information for disambiguating group activities.	[Lan, Tian; Yang, Weilong; Mori, Greg] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada; [Wang, Yang] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; [Robinovitch, Stephen N.] Simon Fraser Univ, Sch Engn Sci, Burnaby, BC V5A 1S6, Canada	Simon Fraser University; University of Illinois System; University of Illinois Urbana-Champaign; Simon Fraser University	Lan, T (corresponding author), Simon Fraser Univ, Sch Comp Sci, 8888 Univ Dr, Burnaby, BC V5A 1S6, Canada.	tla58@sfu.ca; yangwang@uiuc.edu; wya16@sfu.ca; stever@sfu.ca; mori@cs.sfu.ca	Yang, Yijian/G-1580-2016	Yang, Yijian/0000-0002-5831-186X; Robinovitch, Stephen/0000-0003-3881-6227	Natural Sciences and Engineering Research Council of Canada (NSERC); Canadian Institutes of Health Research (CIHR) [AMG-100487, TIR-103945]	Natural Sciences and Engineering Research Council of Canada (NSERC)(Natural Sciences and Engineering Research Council of Canada (NSERC)); Canadian Institutes of Health Research (CIHR)(Canadian Institutes of Health Research (CIHR))	This work was supported by grants from the Natural Sciences and Engineering Research Council of Canada (NSERC) andthe Canadian Institutes of Health Research (CIHR; grant numbers AMG-100487 and TIR-103945).	Andrews S., 2003, ADV NEURAL INF PROCE; [Anonymous], 2008, P IEEE C COMP VIS PA; BIEDERMAN I, 1982, COGNITIVE PSYCHOL, V14, P143, DOI 10.1016/0010-0285(82)90007-X; Blank M., 2005, P IEEE INT C COMP VI; Chang M.-C., 2010, P WORKSH ACT MON MUL; Choi W., 2009, P INT WORKSH VIS SUR; Cupillard F., 2002, P IEEE C COMP VIS PA; Dalal N., 2005, HISTOGRAMS ORIENTED; Desai C., 2010, P WORKSH STRUCT MOD; Desai Chaitanya, 2009, P IEEE INT C COMP VI; Do T.-M.-T., 2009, P INT C MACH LEARN; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Felzenszwalb P., 2008, P IEEE C COMP VIS PA; Filipovych R., 2008, P IEEE C COMP VIS PA; Gupta A., 2009, P IEEE C COMP VIS PA; Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83; Han D., 2009, P IEEE INT C COMP VI; HEITZ G, 2008, P EUR C COMP VIS; Intille SS, 2001, COMPUT VIS IMAGE UND, V81, P414, DOI 10.1006/cviu.2000.0896; Jain A., 2010, P 11 EUR C COMP VIS; khan S., 2005, P ANN ACM INT C MULT; Kjellstrom H., 2008, P EUR C COMP VIS; Lan T., 2010, P INT WORKSH SIGN GE; Lan T., 2010, P ADV NEUR INF PROC; Loy C.C., 2009, P IEEE INT C COMP VI; Marszalek M., 2009, P IEEE C COMP VIS PA; Medioni G, 2001, IEEE T PATTERN ANAL, V23, P873, DOI 10.1109/34.946990; Mehran Ramin, 2009, P IEEE C COMP VIS PA; MOORE D, 2002, P NAT C ART INT; MORI G., 2009, P IEEE C COMP VIS PA; Murphy K. P., 2004, ADV NEUR INF PROC SY; Niebles J, 2010, P EUR C COMP VIS; Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124; Rabinovich A., 2007, P IEEE INT C COMP VI; RYOO MS, 2010, IEEE INT C PATT REC, P1; Schuldt C., 2004, P INT C PATT REC; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Vaswani N., 2003, P IEEE C COMP VIS PA; Vedaldi A., 2009, P ADV NEUR INF PROC; Wang Y., 2010, P EUR C COMP VIS; Wang Y., 2010, P ADV NEUR INF PROC; Xiang T, 2006, INT J COMPUT VISION, V67, P21, DOI 10.1007/s11263-006-4329-6; Yang W., 2010, P IEEE C COMP VIS PA; Yao B., 2010, P IEEE C COMP VIS PA; YU CN, 2009, P ANN INT C MACH LEA; Zhang D, 2006, IEEE T MULTIMEDIA, V8, P509, DOI 10.1109/TMM.2006.870735; Zhong H., 2004, P IEEE C COMP VIS PA	47	174	185	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2012	34	8					1549	1562		10.1109/TPAMI.2011.228	http://dx.doi.org/10.1109/TPAMI.2011.228			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	957UE	22144516	Green Accepted, Green Submitted			2022-12-18	WOS:000305188500008
J	Pujol, O; Radeva, P; Vitria, J				Pujol, O; Radeva, P; Vitria, J			Discriminant ECOC: A heuristic method for application dependent design of error correcting output codes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multiple classifiers; multiclass classification; visual object recognition	MACHINES	We present a heuristic method for learning error correcting output codes matrices based on a hierarchical partition of the class space that maximizes a discriminative criterion. To achieve this goal, the optimal codeword separation is sacrificed in favor of a maximum class discrimination in the partitions. The creation of the hierarchical partition set is performed using a binary tree. As a result, a compact matrix with high discrimination power is obtained. Our method is validated using the UCI database and applied to a real problem, the classification of traffic sign images.	Univ Barcelona, Dept Matemat Aplicada & Anal, E-08007 Barcelona, Spain; Univ Autonoma Barcelona, Dept Ciencies Computac, Bellaterra 08193, Spain; Univ Autonoma Barcelona, Comp Vis Ctr, Bellaterra 08193, Spain	University of Barcelona; Autonomous University of Barcelona; Autonomous University of Barcelona; Centre de Visio per Computador (CVC)	Pujol, O (corresponding author), Univ Barcelona, Dept Matemat Aplicada & Anal, Gran Via 585, E-08007 Barcelona, Spain.	oriol@maia.ub.es; petia@cvc.uab.es; jordi@cvc.uab.es	Pujol, Oriol/F-7146-2016; Vitria, Jordi/C-7072-2008; Radeva, Petia/I-3385-2015; Vitrià, Jordi/AAF-9668-2020	Pujol, Oriol/0000-0001-7573-009X; Vitria, Jordi/0000-0003-1484-539X; Radeva, Petia/0000-0003-0047-5172; Vitrià, Jordi/0000-0003-1484-539X				Allwein E. L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133; Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2, P263; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Hastie T, 1998, ANN STAT, V26, P451; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Kapur J., 1992, ENTROPY OPTIMIZATION; Kuncheva L I, 2004, COMBINING PATTERN CL; Murphy P., 1994, UCI REPOSITORY MACHI; Passerini A, 2004, IEEE T NEURAL NETWOR, V15, P45, DOI 10.1109/TNN.2003.820841; PRINCIPE JC, 2000, UNSUPERVISED ADAPTIV; PUDIL P, 1994, INT C PATT RECOG, P279, DOI 10.1109/ICPR.1994.576920; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; Schapire R. E., 1997, MACH LEARN P 14 INT, P313; Torkkola K., 2003, Journal of Machine Learning Research, V3, P1415, DOI 10.1162/153244303322753742; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd	17	174	183	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2006	28	6					1007	1012		10.1109/TPAMI.2006.116	http://dx.doi.org/10.1109/TPAMI.2006.116			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	031WB	16724594	Green Published			2022-12-18	WOS:000236734400014
J	LEYMARIE, F; LEVINE, MD				LEYMARIE, F; LEVINE, MD			SIMULATING THE GRASSFIRE TRANSFORM USING AN ACTIVE CONTOUR MODEL	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ACTIVE CONTOUR MODEL; CONTOUR AND REGION SHAPE FEATURES; DEFORMABLE SKELETON; DISTANCE SURFACE; EUCLIDEAN SKELETON; MULTISCALE REPRESENTATION; RIDGE SUPPORT; 2-D GRASSFIRE SIMULATION	THINNING ALGORITHM; DISTANCE TRANSFORMATIONS; SHAPE; SKELETON; IMPLEMENTATION; CURVATURE	In this paper, we present a new method for shape description of planar objects that integrates both region and boundary features. Our method is an implementation of a 2-D dynamic grassfire that relies on a distance surface on which elastic contours minimize an energy function. A Euclidean distance transform combined with an active contour model, such as the snake, is used for this minimization process. Boundary information is integrated into the model by the extraction of curvature extrema and arcs of constant curvature. The use of an active contour on a field of grass, represented as a distance surface, combined with the curvature features of the boundary permits us to extract a Euclidean skeleton representation of the shape while bypassing many of the discretization problems found in other skeletonization algorithms. We propose a new concept for skeletal branch significance based on the notion of the local deformation introduced by symmetry points on the distance surface. We call this the ridge support. Furthermore, we show how the ridge support can be evaluated in terms of the velocity of formation of a symmetric axis or in terms of the slope amplitude of a tangent to the symmetric axis. We propose a new concept (the deformable skeleton), which is useful for tracking deformable shapes. We refer to this as the dynamic skeleton.	MCGILL UNIV,DEPT ELECT ENGN,MONTREAL H3A 2A7,QUEBEC,CANADA	McGill University	LEYMARIE, F (corresponding author), MCGILL UNIV,MCGILL RES CTR INTELLIGENT MACHINES,MONTREAL H3A 2A7,QUEBEC,CANADA.			Leymarie, Frederic/0000-0002-3221-8966				ALI SM, 1988, COMPUT VISION GRAPH, V43, P256, DOI 10.1016/0734-189X(88)90064-3; ARCELLI C, 1985, IEEE T PATTERN ANAL, V7, P463, DOI 10.1109/TPAMI.1985.4767685; ARCELLI C, 1981, IEEE T PATTERN ANAL, V3, P134, DOI 10.1109/TPAMI.1981.4767071; ARCELLI C, 1987, PATTERN RECOGN LETT, V6, P245, DOI 10.1016/0167-8655(87)90084-5; ARCELLI C, 1978, IEEE T SYST MAN CYB, V8, P139; Arcelli C., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P283; Arcelli C., 1986, Image Analysis and Processing. Proceedings of the Third International Conference, P137; ARCELLI C, 1989, IEEE T PATTERN ANAL, V11, P411, DOI 10.1109/34.19037; ARCELLI C, 1981, COMPUT VISION GRAPH, V17, P130, DOI 10.1016/0146-664X(81)90021-6; ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; ATTNEAVE F, 1967, MODELS PERCEPTION SP, P56; Benson A., 1977, ACM Transactions on Mathematical Software, V3, P96, DOI 10.1145/355719.355728; BERGER MO, 1989, CRIN90R081 CTR RECH; BERGER MO, 1990, 10TH P INT C PATT RE, V1, P847; BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154; BLUM H, 1962, AUG I RAD ENG WESC C, V6; Blum H., 1962, BIOL PROTOTYPES SYNT, P244; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V11, P123, DOI 10.1016/0146-664X(79)90062-5; BOOULIGAND G, 1932, INTRO GEOMETRIE INFI; BORGEFORS G, 1984, COMPUT VISION GRAPH, V27, P321, DOI 10.1016/0734-189X(84)90035-5; BORGEFORS G, 1988, 9TH P INT C PATT REC, V1, P504; BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302; Bronshtein IN, 1985, HDB MATH; BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; CHIN RT, 1987, COMPUT VISION GRAPH, V40, P30, DOI 10.1016/0734-189X(87)90054-5; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; DAVID C, 1989, MCRCIM CIM891 MCG U; DAVIES ER, 1981, PATTERN RECOGN, V14, P53, DOI 10.1016/0031-3203(81)90045-5; Desimone R., 1989, HDB NEUROPSYCHOLOGY, P267; DILL AR, 1987, IEEE T PATTERN ANAL, V9, P495, DOI 10.1109/TPAMI.1987.4767937; DOBBINS A, 1987, NATURE, V329, P438, DOI 10.1038/329438a0; Dorst L., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P286; FAVRE A, 1983, COMPUT VISION GRAPH, V23, P99, DOI 10.1016/0734-189X(83)90056-7; Goldstein H., 1980, CLASSICAL MECH, V2nd ed; GOODMAN AW, 1964, AM MATH MON, V71, P257, DOI 10.2307/2312180; Hanks P., 1986, COLLINS DICT ENGLISH; Hilditch C J, 1983, IMAGE VISION COMPUT, V1, P115, DOI DOI 10.1016/0262-8856(83)90063-X; Hilditch C.J., 1969, MACH INTELL, P403; HO SB, 1986, IEEE T PATTERN ANAL, V8, P512, DOI 10.1109/TPAMI.1986.4767815; Jacobs D. A. H., 1977, STATE ART NUMERICAL; KASS M, 1987, 1ST P INT C COMP VIS, P259; KLEIN F, 1987, PATTERN RECOGN LETT, V5, P19, DOI 10.1016/0167-8655(87)90022-5; KOTELLY JC, 1963, AFCRL63164 AIR FORC; KU W, 1987, IEEE T SYST MAN CYB, V17, P847; LEE DT, 1982, IEEE T PATTERN ANAL, V4, P363, DOI 10.1109/TPAMI.1982.4767267; LEVI G, 1970, INFORM CONTROL, V17, P62, DOI 10.1016/S0019-9958(70)80006-7; LEVINE MD, 1985, VISION MAN MACHINE C; LEYMARIE F, 1989, P SOC PHOTO-OPT INS, V1199, P390; LEYMARIE F, IN PRESS COMPUT VISI; LEYMARIE F, 1989, MCRCIM CIM893 MCGILL; LEYMARIE F, 1989, P SPIE INTELL ROBO 2, V1192, P536; LEYMARIE F, 1990, MCRCIM CIM909 TECH R; LEYMARIE F, 1991, PROGR IMAGE ANAL PRO, P186; LEYMARIE F, 1988, MCRCIM CIM8826 MCGIL; LEYTON M, 1987, COMPUT VISION GRAPH, V38, P327, DOI 10.1016/0734-189X(87)90117-4; LEYTON M, 1988, ARTIF INTELL, V34, P213, DOI 10.1016/0004-3702(88)90039-2; MARTINEZPEREZ MP, 1987, COMPUT VISION GRAPH, V39, P186, DOI 10.1016/S0734-189X(87)80165-2; Matheron G., 1988, IMAGE ANAL MATH MORP, V2, P217; MEYER F, 1988, IMAGE ANAL MATH MORP, V2, P258; MONTANARI U, 1968, J ACM, V15, P600, DOI 10.1145/321479.321486; MONTANARI U, 1969, J ACM, V16, P534, DOI 10.1145/321541.321543; Montanvert A., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P430; MOTRZKIN T, 1935, ATT ACCADEMIA NAZION, V21, P773; Motzkin T., 1935, ATTI ACCAD NAZ LINCE, V21, P562; NOBLE PB, 1986, COMPUTER ASSISTED AN; Okabe N, 1983, PATTERN RECOGN LETT, V1, P205, DOI 10.1016/0167-8655(83)90026-0; PAVLIDIS T, 1980, COMPUT VISION GRAPH, V13, P142, DOI 10.1016/S0146-664X(80)80037-2; PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029; PAVLIDIS T, 1982, COMPUT VISION GRAPH, V20, P133, DOI 10.1016/0146-664X(82)90041-7; ROSENFEL.A, 1966, J ACM, V13, P471; Serra J., 1982, IMAGE ANAL MATH MORP, pChap11; SHAPIRO B, 1981, COMPUT VISION GRAPH, V15, P136, DOI 10.1016/0146-664X(81)90075-7; SHIH FY, 1990, 10TH P INT C PATT RE, V1, P723; TANG GY, 1988, COMPUT VISION GRAPH, V42, P297, DOI 10.1016/S0734-189X(88)80040-9; TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447; TERZOPOULOS D, 1987, TECHNICAL DIGEST SER, V12, P160; TERZOPOULOS D, 1987, JUL P SISGRAPH 87 AN; Terzopoulos D., 1987, TECHNICAL DIGEST SER, V12, P164; TSAO YF, 1984, COMPUT VISION GRAPH, V25, P348, DOI 10.1016/0734-189X(84)90200-7; XIA Y, 1989, IEEE T PATTERN ANAL, V11, P1076, DOI 10.1109/34.42838; Ye Q.-Z., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P495, DOI 10.1109/ICPR.1988.28276; YOILLE A, 1987, 1ST P INT C COMP VIS, P721; YOUSSEF YM, 1982, THESIS MCGILL U MONT; Zucker S. W., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P568, DOI 10.1109/CCV.1988.590037	86	174	188	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1992	14	1					56	75		10.1109/34.107013	http://dx.doi.org/10.1109/34.107013			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GV942					2022-12-18	WOS:A1992GV94200004
J	Yang, HF; Lin, K; Chen, CS				Yang, Huei-Fang; Lin, Kevin; Chen, Chu-Song			Supervised Learning of Semantics-Preserving Hash via Deep Convolutional Neural Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image retrieval; supervised hashing; binary codes; deep learning; convolutional neural networks	CODES	This paper presents a simple yet effective supervised deep hash approach that constructs binary hash codes from labeled data for large-scale image search. We assume that the semantic labels are governed by several latent attributes with each attribute on or off, and classification relies on these attributes. Based on this assumption, our approach, dubbed supervised semantics-preserving deep hashing (SSDH), constructs hash functions as a latent layer in a deep network and the binary codes are learned by minimizing an objective function defined over classification error and other desirable hash codes properties. With this design, SSDH has a nice characteristic that classification and retrieval are unified in a single learning model. Moreover, SSDH performs joint learning of image representations, hash codes, and classification in a point-wised manner, and thus is scalable to large-scale datasets. SSDH is simple and can be realized by a slight enhancement of an existing deep architecture for classification; yet it is effective and outperforms other hashing approaches on several benchmarks and large datasets. Compared with state-of-the-art approaches, SSDH achieves higher retrieval accuracy, while the classification performance is not sacrificed.	[Yang, Huei-Fang] Acad Sinica, Res Ctr Informat Technol Innovat, Taipei 11529, Taiwan; [Lin, Kevin] Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA; [Chen, Chu-Song] Acad Sinica, Inst Informat Sci, Taipei 11529, Taiwan	Academia Sinica - Taiwan; University of Washington; University of Washington Seattle; Academia Sinica - Taiwan	Yang, HF (corresponding author), Acad Sinica, Res Ctr Informat Technol Innovat, Taipei 11529, Taiwan.	hfyang@iis.sinica.edu.tw; kvlin@uw.edu; song@iis.sinica.edu.tw	Lin, Kevin/AAL-5205-2020	Lin, Kevin/0000-0001-8944-1336; Yang, Huei-Fang/0000-0001-8261-6965	Ministry of Science and Technology of Taiwan [MOST 104-2221-E-001-023-MY2, MOST 105-2218-E-001-006]	Ministry of Science and Technology of Taiwan(Ministry of Science and Technology, Taiwan)	We thank the anonymous reviewers for their insightful comments. This work is supported in part by the Ministry of Science and Technology of Taiwan under contract MOST 104-2221-E-001-023-MY2 and MOST 105-2218-E-001-006.	Andoni A, 2006, ANN IEEE SYMP FOUND, P459; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Chua Tat-Seng, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646452; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Donahue J, 2014, PR MACH LEARN RES, V32; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fei-Fei Li, 2004, CVPR WORKSH GEN MOD, P178; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384; Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; He J., 2010, P ACM SIGKDD INT C K, P1129; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hsieh C.J., 2008, P 25 INT C MACHINE L, P408, DOI DOI 10.1145/1390156.1390208; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jie Z, 2014, P COMP VIS ACCV, P376; Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272; Kang Y, 2012, IEEE DATA MINING, P930, DOI 10.1109/ICDM.2012.24; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Krizhevsky A., 2011, P 19 EUR S ART NEUR; Kulis B, 2012, IEEE T PATTERN ANAL, V34, P1092, DOI 10.1109/TPAMI.2011.219; Kulis Brian, 2009, ADV NEURAL INFORM PR, P1042; Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947; Lin GS, 2014, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2014.253; Lin GS, 2013, IEEE I CONF COMP VIS, P2552, DOI 10.1109/ICCV.2013.317; Lin K, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P499, DOI 10.1145/2671188.2749318; Lin K, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301269; Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1017/S1368980013002176, 10.1109/PLASMA.2013.6634954]; Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862; Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912; Liu W, 2011, SER INF MANAGE SCI, V10, P1; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Mohammad Norouzi, 2012, ADV NEURAL INFORM PR, P1061; Morere O., 2016, ABS160102093 CORR; Mu YD, 2010, PROC CVPR IEEE, P3344, DOI 10.1109/CVPR.2010.5540024; Norouzi M., 2011, INT C MACHINE LEARNI, P353; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Philbin J, 2008, PROC CVPR IEEE, P2285; Raginsky M., 2009, ADV NEURAL INFORM PR, P1509, DOI [10.5555/2984093.2984263, DOI 10.5555/2984093.2984263]; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Sermanet P., 2013, ARXIV PREPRINT ARXIV; Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598; Snoek J, 2012, ADV NEURAL INF PROCE, V25, P2951; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Wang J, 2013, IEEE I CONF COMP VIS, P3032, DOI 10.1109/ICCV.2013.377; Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48; Wang QF, 2014, LECT NOTES COMPUT SC, V8691, P378, DOI 10.1007/978-3-319-10578-9_25; Weiss Y., 2008, P NIPS, P1753; Xia RK, 2014, AAAI CONF ARTIF INTE, P2156; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Yandex Artem Babenko, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1269, DOI 10.1109/ICCV.2015.150; Yu A, 2014, PROC CVPR IEEE, P192, DOI 10.1109/CVPR.2014.32; Zeiler MD, 2013, ARXIV13013557, DOI DOI 10.1007/978-3-319-26532-2_6; Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763; Zhou Bolei, 2014, ADV NEURAL INFORM PR, P7, DOI DOI 10.5555/2968826.2968881	66	173	188	5	65	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2018	40	2					437	451		10.1109/TPAMI.2017.2666812	http://dx.doi.org/10.1109/TPAMI.2017.2666812			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FS9AN	28207384	Green Submitted			2022-12-18	WOS:000422706000013
J	Hernandez, C; Vogiatzis, G; Cipolla, R				Hernandez, Carlos; Vogiatzis, George; Cipolla, Roberto			Multiview photometric stereo	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						photometric stereo; multiple views; light calibration; silhouette	MODEL	This paper addresses the problem of obtaining complete, detailed reconstructions of textureless shiny objects. We present an algorithm which uses silhouettes of the object, as well as images obtained under changing illumination conditions. In contrast with previous photometric stereo techniques, ours is not limited to a single viewpoint but produces accurate reconstructions in full 3D. A number of images of the object are obtained from multiple viewpoints, under varying lighting conditions. Starting from the silhouettes, the algorithm recovers camera motion and constructs the object's visual hull. This is then used to recover the illumination and initialize a multiview photometric stereo scheme to obtain a closed surface reconstruction. There are two main contributions in this paper: First, we describe a robust technique to estimate light directions and intensities and, second, we introduce a novel formulation of photometric stereo which combines multiple viewpoints and, hence, allows closed surface reconstructions. The algorithm has been implemented as a practical model acquisition system. Here, a quantitative evaluation of the algorithm on synthetic data is presented together with complete reconstructions of challenging real objects. Finally, we show experimentally how, even in the case of highly textured objects, this technique can greatly improve on correspondence-based multiview stereo results.	[Hernandez, Carlos; Vogiatzis, George] Toshiba Res Europe, Comp Vis Grp, Cambridge CB4 0GZ, England; [Cipolla, Roberto] Univ Cambridge, Cambridge CB2 1PZ, England	Toshiba Corporation; University of Cambridge	Hernandez, C (corresponding author), Toshiba Res Europe, Comp Vis Grp, 208 Cambridge Sci Pk, Cambridge CB4 0GZ, England.	carlos.hernandez@crl.toshiba.co.uk; george@crl.toshiba.co.uk; cipolla@eng.cam.ac.uk	Arandjelović, Ognjen/V-5255-2019	Arandjelović, Ognjen/0000-0002-9314-194X; Cipolla, Roberto/0000-0002-8999-2151; Vogiatzis, George/0000-0002-3226-0603				Bernardini F, 2002, IEEE COMPUT GRAPH, V22, P59, DOI 10.1109/38.974519; Cipolla R., 1999, VISUAL MOTION CURVES; DBROHLAV O, 2005, P IEEE I C COMP VIS, P1850; Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Hernandez C, 2007, IEEE T PATTERN ANAL, V29, P343, DOI 10.1109/TPAMI.2007.42; JIN H, 2004, P IEEE C COMP VIS PA, V1, P36; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; LEVOY M, 2002, WHY IS 3D SCANNING H; Lim J, 2005, IEEE I CONF COMP VIS, P1635; Nehab D, 2005, ACM T GRAPHIC, V24, P536, DOI 10.1145/1073204.1073226; Paterson JA, 2005, COMPUT GRAPH FORUM, V24, P383, DOI 10.1111/j.1467-8659.2005.00863.x; Seitz S., 2006, P CVPR 06 IE COMP SO, V1, P519, DOI DOI 10.1109/CVPR.2006.19; Vogiatzis G, 2005, IEEE I CONF COMP VIS, P228; VOGIATZIS G, 2006, P IEEE C COMP VIS PA, V2, P1847; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479	16	173	184	2	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2008	30	3					548	554		10.1109/TPAMI.2007.70820	http://dx.doi.org/10.1109/TPAMI.2007.70820			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	250FT	18195448	Green Submitted, Green Accepted			2022-12-18	WOS:000252286100016
J	Grother, P; Tabassi, E				Grother, Patrick; Tabassi, Elham			Performance of biometric quality measures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						biometrics; quality measurement; authentication; evaluation; performance measures		We document methods for the quantitative evaluation of systems that produce a scalar summary of a biometric sample's quality. We are motivated by a need to test claims that quality measures are predictive of matching performance. We regard a quality measurement algorithm as a black box that converts an input sample to an output scalar. We evaluate it by quantifying the association between those values and observed matching results. We advance detection error trade-off and error versus reject characteristics as metrics for the comparative evaluation of sample quality measurement algorithms. We proceed this with a definition of sample quality, a description of the operational use of quality measures. We emphasize the performance goal by including a procedure for annotating the samples of a reference corpus with quality values derived from empirical recognition scores.	NIST, Informat Access Div, Informat Technol Lab, Gaithersburg, MD 20899 USA; NIST, Informat Technol Lab, Image Grp, Informat Access Div, Gaithersburg, MD 20899 USA	National Institute of Standards & Technology (NIST) - USA; National Institute of Standards & Technology (NIST) - USA	Grother, P (corresponding author), NIST, Informat Access Div, Informat Technol Lab, 100 Bur Dr,Bldg 225,Room A203,MS 8940, Gaithersburg, MD 20899 USA.	pgrother@nist.gov; tabassi@nist.gov						ALONSOFERNANDEZ F, 2005, COST 275 BIOMETRICS; [Anonymous], 2006, P NIST BIOM QUAL WOR; BENINI D, 2006, 297941 ISOIEC; *BIOSCR INC, 1999, SYST METH ID VER COM; Chambers J. M., 1983, GRAPHICAL METHODS DA; Chen Y, 2005, LECT NOTES COMPUT SC, V3546, P160; Fierrez-Aguilar J, 2005, PATTERN RECOGN, V38, P777, DOI 10.1016/j.patcog.2004.11.012; FIERREZAGUILAR J, 2005, P IEEE INT CARN C SE; *ISO IECJTC1 SC37, 2005, 19794 ISOIEC; Ko T., 2004, Proceedings. 33rd Applied Imagery Pattern Recognition Workshop, P159; Lim E, 2002, IEEE IMAGE PROC, P469; Mansfield A.J., 2002, 1402 CMSC NAT PHYS L; MANSFIELD AJ, 2005, 197951 ISOIEC; MARTIN A, 1997, P EUROSPEECH, P1895; *NAT I STAND TECHN, 2002, COL FERET FAC DAT; Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078; SIMONZORITA D, 2003, IEE P-VIS IMAGE SIGN, V150, P395; TABASSI E, 2006, IEEE CS C COMP VIS P; TABASSI E, 2004, 7151 NISTIR NFIQ; TABASSI E, 2006, 7300 NISTIR; Tabassi E., 2005, P IEEE INT C IM PROC; THIEME M, 2005, 197952 ISOIEC; TILTON C, 2002, BIOAPI SPECIFICATION; WEIN LM, 2005, P NATL ACAD SCI; YOSHIDA A, 2006, P NIST BIOM QUAL WOR	25	173	181	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2007	29	4					531	543		10.1109/TPAMI.2007.1019	http://dx.doi.org/10.1109/TPAMI.2007.1019			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HJ	17299212				2022-12-18	WOS:000244855600003
J	PAVLIDIS, T				PAVLIDIS, T			ALGORITHMS FOR SHAPE-ANALYSIS OF CONTOURS AND WAVEFORMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article													Rohlf, F J/A-8710-2008					AGRAWALA AK, 1977, COMPUT VISION GRAPH, V6, P538, DOI 10.1016/S0146-664X(77)80015-4; Albano A., 1974, COMPUT VISION GRAPH, V3, P23, DOI [10.1016/0146-664X(74)90008-2, DOI 10.1016/0146-664X(74)90008-2, DOI 10.1016/0146-664X(74)90008-2CGIPBG0146-664X]; ALI F, 1977, IEEE T SYST MAN CYB, V7, P537, DOI 10.1109/TSMC.1977.4309763; ARAKAWA K, 1978, 4TH P INT JOINT C PA, P810; BAJCSY R, 1977, PATTERN RECOGN, V9, P1, DOI 10.1016/0031-3203(77)90025-5; BENNETT JR, 1975, IEEE T COMPUT, V24, P803, DOI 10.1109/T-C.1975.224312; BJORKLUND CM, 1977, JUN P IEEE PATT REC, P198; BJORKLUND CM, 1979, 1979 P IEEE C PATT R, P445; BLUM H, 1964, S MODELS PERCEPTION; BLUM H, 1977, JUN P IEEE PATT REC, P203; BRIBIESCA E, 1978, 4TH P INT C PATT REC, P608; CEDERBERG RLT, 1978, 4TH P INT C PATT REC, P576; CHANG LP, 1976, 201 PRINC U TECH REP; CHAZELLE B, 1979, 11TH P ACM STOC ATL; COOPER DB, 1976, IEEE T COMPUT, V25, P1020; DANIELSSON PE, 1978, COMPUT VISION GRAPH, V7, P292, DOI 10.1016/0146-664X(78)90119-3; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; DAVIS LS, 1977, IEEE T COMPUT, V26, P236, DOI 10.1109/TC.1977.1674812; de Boor C., 1976, SPLINES LINEAR COMBI, P1; DRUSE B, 1978, 4TH P INT JOINT C PA, P642; Duda R.O., 1973, J ROYAL STAT SOC SER; DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; ECCLES MJ, 1977, PATTERN RECOGN, V9, P31, DOI 10.1016/0031-3203(77)90028-0; FENG HYF, 1975, IEEE T COMPUT, VC 24, P636, DOI 10.1109/T-C.1975.224276; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; FREEMAN H, 1978, MAY P IEEE COMP SOC, P220; FREEMAN H, 1978, 4TH P INT JOINT C PA, P701; Fu K. S., 1978, Pattern Recognition and Signal Processing, P1; Fu K.S., 1974, MATH SCI ENG; FU KS, 1977, IEEE T SYST MAN CYB, V7, P734, DOI 10.1109/TSMC.1977.4309608; FU KS, 1977, SYNTACTIC PATTERN RE; Fujita T., 1976, 3rd International Joint Conference on Pattern Recognition, P119; GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926; GRENADER U, 1976, PATTERN SYNTHESIS LE, V1; Hilditch C.J., 1969, MACH INTELL, P403; HOROWITZ SL, 1975, COMMUN ACM, V18, P281, DOI 10.1145/360762.360810; HOROWITZ SL, 1977, SYNTACTIC PATTERN RE, P31; HSU S, 1978, APR IEEE WORKSH PATT; Ichida K., 1977, ACM Transactions on Mathematical Software, V3, P164, DOI 10.1145/355732.355737; Jarvis J. F., 1976, 3rd International Joint Conference on Pattern Recognition, P189; LEE ET, 1976, IEEE T SYST MAN CYBE, V5, P629; LEWIS JW, 1978, APR IEEE WORKSH PATT; Lipkin BS, 1970, PICTURE PROCESSING P, P241; LOZANOPEREZ T, 1977, COMPUT GRAPHICS IMAG, V6, P43; MCCLURE DE, 1975, J MATH ANAL APPL, V51, P326, DOI 10.1016/0022-247X(75)90125-0; MCCLURE DE, 1975, Q APPL MATH, V33, P1; MCCLURE DE, 1974, 8TH P PRINC C INF SC, P244; MCKEE JW, 1977, IEEE T COMPUT, V26, P790, DOI 10.1109/TC.1977.1674917; MOAYER B, 1976, IEEE T COMPUT, V25, P262, DOI 10.1109/TC.1976.5009253; MOAYER B, 1975, PATTERN RECOGN, V7, P1, DOI 10.1016/0031-3203(75)90011-4; MUNDY JL, 1977, JUN P PATT REC IM PR, P144; PAVLIDIS T, 1979, IEEE T PATTERN ANAL, V1, P307, DOI 10.1109/TPAMI.1979.4766928; PAVLIDIS T, 1979, IEEE T PATTERN ANAL, V1, P2, DOI 10.1109/TPAMI.1979.4766870; PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041; PAVLIDIS T, 1975, IEEE T SYST MAN CYB, V5, P610, DOI 10.1109/TSMC.1975.4309402; PAVLIDIS T, 1977, IEEE T COMPUT, V26, P800, DOI 10.1109/TC.1977.1674918; PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6; PAVLIDIS T, 1972, FRONTIERS PATTERN RE, P421; Pavlidis T., 1977, STRUCTURAL PATTERN R; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; Preston K.  Jr., 1976, Digital picture analysis, P209; RICE JR, 1969, APPROXIMATION FUNCTI, V2, pCH10; RICHARD CW, 1974, IEEE T SYST MAN CYB, VSMC4, P371, DOI 10.1109/TSMC.1974.5408458; RIESENFELD R, UTECCSC73126 U UT RE; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SANKAR PV, 1978, COMPUT VISION GRAPH, V7, P403, DOI 10.1016/S0146-664X(78)80006-9; SCHACHTER B, 1978, IEEE T COMPUT, V27, P1078, DOI 10.1109/TC.1978.1675001; SHAPIRO LG, 1980, IEEE T PATTERN ANAL, V2, P111, DOI 10.1109/TPAMI.1980.4766989; SHAPIRO LG, 1979, PATTERN ANAL MACHINE, V1, P10; STALLINGS W, 1976, PATTERN RECOGN, V8, P87, DOI 10.1016/0031-3203(76)90037-6; STOCKMAN G, 1976, COMMUN ACM, V19, P688, DOI 10.1145/360373.360378; STOCKMAN G, 1978, 4TH P INT JOINT C PA, P696; YAMAGUCHI F, 1978, COMPUT VISION GRAPH, V7, P425, DOI 10.1016/S0146-664X(78)80008-2; YAMAMOTO K, 1978, 4TH P C PATT REC KYO, P794; YOU KC, 1979, IEEE T SYST MAN CYBE, V9; YOUNG IT, 1974, INFORM CONTROL, V25, P357, DOI 10.1016/S0019-9958(74)91038-9; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	78	173	182	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	4					301	312		10.1109/TPAMI.1980.4767029	http://dx.doi.org/10.1109/TPAMI.1980.4767029			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	JZ206	21868906				2022-12-18	WOS:A1980JZ20600003
J	Zou, DP; Tan, P				Zou, Danping; Tan, Ping			CoSLAM: Collaborative Visual SLAM in Dynamic Environments	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual SLAM; swarm; dynamic environments; structure-from-motion	SIMULTANEOUS LOCALIZATION	This paper studies the problem of vision-based simultaneous localization and mapping (SLAM) in dynamic environments with multiple cameras. These cameras move independently and can be mounted on different platforms. All cameras work together to build a global map, including 3D positions of static background points and trajectories of moving foreground points. We introduce intercamera pose estimation and intercamera mapping to deal with dynamic objects in the localization and mapping process. To further enhance the system robustness, we maintain the position uncertainty of each map point. To facilitate intercamera operations, we cluster cameras into groups according to their view overlap, and manage the split and merge of camera groups in real time. Experimental results demonstrate that our system can work robustly in highly dynamic environments and produce more accurate results in static environments.	[Zou, Danping; Tan, Ping] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore	National University of Singapore	Zou, DP (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore.	dannis.zou@gmail.com; eletp@nus.edu.sg			Singapore FRC [R-263-000-620-112]; AORAD [R-263-000-673-597]	Singapore FRC; AORAD	This work is supported by the Singapore FRC grant R-263-000-620-112 and AORAD grant R-263-000-673-597.	Allred J, 2007, SENSYS'07: PROCEEDINGS OF THE 5TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P117; Bibby C., 2007, P ROB SCI SYST; Bibby C, 2010, IEEE INT CONF ROBOT, P257, DOI 10.1109/ROBOT.2010.5509262; Burgard W., 2000, P IEEE INT C ROB AUT, V1, P476; Castle R, 2008, TWELFTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P15, DOI 10.1109/ISWC.2008.4911577; Chli M, 2009, ROBOT AUTON SYST, V57, P1173, DOI 10.1016/j.robot.2009.07.010; Cornelis K, 2004, IEEE T PATTERN ANAL, V26, P1249, DOI 10.1109/TPAMI.2004.85; Davis T.A, 2006, DIRECT METHODS SPARS; Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403; Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049; Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022; Eade E., 2006, IEEE COMP SOC C COMP, V1, P469, DOI [10.1109/CVPR.2006.263, DOI 10.1109/CVPR.2006.263]; Golub GH., 1965, NUMER MATH, V7, P206, DOI DOI 10.1007/BF01436075; Hahnel D, 2003, IEEE INT CONF ROBOT, P1557, DOI 10.1109/ROBOT.2003.1241816; Hartley R., 2000, MULTIPLE VIEW GEOMET, V6; Ho KL, 2007, INT J COMPUT VISION, V74, P261, DOI 10.1007/s11263-006-0020-1; Kaess M, 2006, GITGVU0606; Klein George, 2007, P1; Kundu A., 2010, P 7 IND C COMP VIS G, P251; Leibe B., 2007, P IEEE C COMP VIS PA; Mouragnon E., 2006, IEEE COMP SOC C COMP, V1, P363, DOI DOI 10.1109/CVPR.2006.236; Newcombe RA, 2010, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2010.5539794; Nister D., 2004, P IEEE C COMP VIS PA, V1; Ozden KE, 2010, IEEE T PATTERN ANAL, V32, P1134, DOI 10.1109/TPAMI.2010.23; Paz LM, 2008, IEEE T ROBOT, V24, P946, DOI 10.1109/TRO.2008.2004637; Royer E, 2005, PROC CVPR IEEE, P114; Sahin E, 2005, LECT NOTES COMPUT SC, V3342, P10; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Smith P., 2006, P BRIT MACH VIS C, V1, P17; Strasdat H., 2010, P ROB SCI SYST; Strasdat H, 2012, IMAGE VISION COMPUT, V30, P65, DOI 10.1016/j.imavis.2012.02.009; Strasdat H, 2010, IEEE INT CONF ROBOT, P2657, DOI 10.1109/ROBOT.2010.5509636; Thrun S., 2002, P IEEE C ROB AUT, V1, P321; Wang CC, 2007, INT J ROBOT RES, V26, P889, DOI 10.1177/0278364907081229; Williams BT, 2007, ROUTL STUD LITERACY, V3, P1; Winters N, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P21, DOI 10.1109/OMNVIS.2000.853799; Wolf DF, 2005, AUTON ROBOT, V19, P53, DOI 10.1007/s10514-005-0606-4; Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2; Zuffery J., 2005, THESIS ECOLE POLYTEC	39	172	194	9	98	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2013	35	2					354	366		10.1109/TPAMI.2012.104	http://dx.doi.org/10.1109/TPAMI.2012.104			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	057JX	22547430				2022-12-18	WOS:000312560600009
J	Manay, S; Cremers, D; Hong, BW; Yezzi, AJ; Soatto, S				Manay, Siddharth; Cremers, Daniel; Hong, Byung-Woo; Yezzi, Anthony J., Jr.; Soatto, Stefano			Integral invariants for shape matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						integral invariants; shape; shape matching; shape distance; shape retrieval	OBJECT RECOGNITION; FOURIER DESCRIPTORS; SIMILARITY; CURVES; SPACE; REPRESENTATIONS; CLASSIFICATION; MULTISCALE; SIGNATURES; POINT	For shapes represented as closed planar contours, we introduce a class of functionals which are invariant with respect to the Euclidean group and which are obtained by performing integral operations. While such integral invariants enjoy some of the desirable properties of their differential counterparts, such as locality of computation (which allows matching under occlusions) and uniqueness of representation (asymptotically), they do not exhibit the noise sensitivity associated with differential quantities and, therefore, do not require presmoothing of the input shape. Our formulation allows the analysis of shapes at multiple scales. Based on integral invariants, we define a notion of distance between shapes. The proposed distance measure can be computed efficiently and allows warping the shape boundaries onto each other; its computation results in optimal point correspondence as an intermediate step. Numerical results on shape matching demonstrate that this framework can match shapes despite the deformation of subparts, missing parts and noise. As a quantitative analysis, we report matching scores for shape retrieval from a database.	Lawrence Livermore Natl Lab, Elect Engn Technol Div, Livermore, CA 94551 USA; Univ Bonn, Dept Comp Sci, D-53117 Bonn, Germany; Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA; Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA	United States Department of Energy (DOE); Lawrence Livermore National Laboratory; University of Bonn; University of California System; University of California Los Angeles; University System of Georgia; Georgia Institute of Technology	Manay, S (corresponding author), Lawrence Livermore Natl Lab, Elect Engn Technol Div, POB 508,L-290, Livermore, CA 94551 USA.	smanay.ece98@talumni.org; dcremers@cs.uni-bonn.de; hong@cs.ucla.edu; ayezzi@ece.gatech.edu; soatto@ucla.edu	Yezzi, Anthony/AAB-4235-2020; Rohlf, F J/A-8710-2008	Hong, Byung-Woo/0000-0003-2752-3939	NATIONAL CENTER FOR RESEARCH RESOURCES [U54RR021813] Funding Source: NIH RePORTER; NCRR NIH HHS [U54 RR021813] Funding Source: Medline	NATIONAL CENTER FOR RESEARCH RESOURCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR)); NCRR NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR))		Alferez R, 1999, IEEE T PATTERN ANAL, V21, P505, DOI 10.1109/34.771318; ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206; AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; Bakircioglu M, 1998, HUM BRAIN MAPP, V6, P329; Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BENGTSSON A, 1991, IEEE T PATTERN ANAL, V13, P85, DOI 10.1109/34.67634; Boutin M, 2000, INT J COMPUT VISION, V40, P235, DOI 10.1023/A:1008139427340; Brandt RD, 1996, PATTERN RECOGN LETT, V17, P1001, DOI 10.1016/0167-8655(96)00062-1; BRUCKSTEIN AM, 1993, CVGIP-IMAG UNDERSTAN, V58, P49, DOI 10.1006/ciun.1993.1031; Bruckstein AM, 1997, IMAGE VISION COMPUT, V15, P335, DOI 10.1016/S0262-8856(96)01140-7; BRUCKSTEIN AM, 1992, INT J COMPUT VISION, V7, P271, DOI 10.1007/BF00126396; Calabi E, 1998, INT J COMPUT VISION, V26, P107, DOI 10.1023/A:1007992709392; Chetverikov D, 1999, LECT NOTES COMPUT SC, V1689, P367; COHEN I, 1992, LECT NOTES COMPUT SC, V588, P458; COHIGNAC T, 1994, INT C PATT RECOG, P164, DOI 10.1109/ICPR.1994.576250; COLE JB, 1991, PATTERN RECOGN LETT, V12, P519, DOI 10.1016/0167-8655(91)90091-Y; Cremers D, 2003, PATTERN RECOGN, V36, P1929, DOI 10.1016/S0031-3203(03)00056-6; CREMERS D, 2003, P 2 IEEE WORKSH VAR, P169; CREMERS D, 2004, PATTERN RECOGNIT SEP; Davies RH, 2002, IEEE T MED IMAGING, V21, P525, DOI 10.1109/TMI.2002.1009388; DelBimbo A, 1997, IEEE T PATTERN ANAL, V19, P121, DOI 10.1109/34.574790; DERVIEUX A, 1979, SPRINGER LECT NOTES, V771, P145; Dickson LE, 1914, ALGEBRAIC INVARIANTS; Dieudonne J. A., 1970, INVARIANT THEORY OLD; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233; FORSYTH D, 1991, IMAGE VISION COMPUT, V9, P130, DOI 10.1016/0262-8856(91)90023-I; Gdalyahu Y, 1999, IEEE T PATTERN ANAL, V21, P1312, DOI 10.1109/34.817410; Gool LV, 1992, GEOMETRIC INVARIANCE, P193; Grace John Hilton, 1903, ALGEBRA INVARIANTS; Hann C. E., 2000, INT J COMPUT VISION, V40, P235; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Kanatani Kenichi, 1990, GROUP THEORETICAL ME, P4; Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333; Klein P, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P696; LANE EP, 1992, PROJECTIVE DIFFERENT; Lasenby J, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P313, DOI 10.1109/ICIP.1996.560819; Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802; Latto A., 1984, Proceedings of the Workshop on Computer Vision: Representation and Control, P183; LE HL, 1993, ANN STAT, V21, P1225, DOI 10.1214/aos/1176349259; LEI G, 1990, IEEE T ROBOTIC AUTOM, V6, P432, DOI 10.1109/70.59368; LENZ R, 1990, LECT NOTES COMPUTER, V413; LEVENTON ME, 2000, PROC CVPR IEEE, P316, DOI DOI 10.1109/CVPR.2000.855835; Li S. Z., 1999, PROGR NEURAL NETWORK, V6, P203; Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554; LIU HC, 1990, IEEE T PATTERN ANAL, V12, P1072, DOI 10.1109/34.61706; MANAY S, 2004, P EUR C COMP VIS MAY; Marques JS, 1997, PATTERN RECOGN LETT, V18, P49, DOI 10.1016/S0167-8655(96)00120-1; Miyatake T., 1983, Transactions of the Information Processing Society of Japan, V24, P64; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; Mumford D., 1994, GEOMETRIC INVARIANT; Mumford D., 1991, GEOMETRIC METHODS CO, V1570, P2; Mundy J., 1992, GEOMETRIC INVARIANCE; NIELSEN L, 1991, CVGIP-IMAG UNDERSTAN, V54, P145, DOI 10.1016/1049-9660(91)90079-5; Olver P. J., 1995, EQUIVALENCE INVARIAN, DOI DOI 10.1017/CBO9780511609565; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; PAJDLA T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P390, DOI 10.1109/ICCV.1995.466913; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; PIKAZ A, 1995, PATTERN RECOGN, V28, P199, DOI 10.1016/0031-3203(94)00088-4; PITIOT A, 2003, P C INF PROC MED IM; REISS T, 1993, LECT NOTES COMPUTER, V676; ROTHWELL CA, 1995, INT J COMPUT VISION, V16, P57, DOI 10.1007/BF01428193; ROTHWELL CA, 1992, LECT NOTES COMPUT SC, V588, P757; ROUSSON M, 2002, P EUR C COMP VIS MAY; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; SAPIRO G, 1995, IEEE T PATTERN ANAL, V17, P67, DOI 10.1109/34.368150; SAPIRO G, 1993, INT J COMPUT VISION, V11, P25, DOI 10.1007/BF01420591; Sato J, 1997, IMAGE VISION COMPUT, V15, P627, DOI 10.1016/S0262-8856(97)00011-5; SCHUBERT P, 1995, MUSIC THEOR SPECTRUM, V17, P1, DOI 10.1525/mts.1995.17.1.02a00010; SCHWARTZ JT, 1987, INT J ROBOT RES, V6, P29, DOI 10.1177/027836498700600203; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; SHARON E, 2004, P IEEE C COMP VIS PA; Sharvit D, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P56, DOI 10.1109/IVL.1998.694496; Shashua A, 1996, IEEE T PATTERN ANAL, V18, P873, DOI 10.1109/34.537342; Siddiqi K, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P222, DOI 10.1109/ICCV.1998.710722; Springer C. E., 1964, GEOMETRY ANAL PROJEC; TAGARE HD, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P434, DOI 10.1109/ICCV.1995.466907; Tieng QM, 1997, IEEE T PATTERN ANAL, V19, P910, DOI 10.1109/34.608294; TOMASI C, 1996, P EUR C COMP VIS, P452; TROUVE A, 2000, P 6 EUR C COMP VIS T, P573; Tsai A, 2001, PROC CVPR IEEE, P463; UMEYAMA S, 1993, IEEE T PATTERN ANAL, V15, P136, DOI 10.1109/34.192485; VANGOOL L, 1996, P 4 EUR C COMP VIS, V1, P642; Verestoy J., 1997, MACHINE GRAPHICS VIS, V6, P225; WEISS I, 1993, IEEE T PATTERN ANAL, V15, P943, DOI 10.1109/34.232081; WITKIN A, 1988, P INT JOINT C ART IN, P1019; WOLFSON HJ, 1990, IEEE T PATTERN ANAL, V12, P483, DOI 10.1109/34.55108; Younes L, 1999, IMAGE VISION COMPUT, V17, P381, DOI 10.1016/S0262-8856(98)00125-5; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949; Zhu SC, 1996, INT J COMPUT VISION, V20, P187; ZISSERMAN A, 1995, ARTIF INTELL, V78, P239, DOI 10.1016/0004-3702(95)00023-2; [No title captured]	95	172	186	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2006	28	10					1602	1618		10.1109/TPAMI.2006.208	http://dx.doi.org/10.1109/TPAMI.2006.208			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	071ME	16986542	Green Submitted			2022-12-18	WOS:000239605500005
J	DUNHAM, JG				DUNHAM, JG			OPTIMUM UNIFORM PIECEWISE LINEAR-APPROXIMATION OF PLANAR CURVES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											DUNHAM, JG (corresponding author), SO METHODIST UNIV,DEPT ELECT ENGN,DALLAS,TX 75275, USA.							BADII F, 1982, INT J SYST SCI, V13, P667, DOI 10.1080/00207728208926377; BELLMAN R, 1964, P NATL ACAD SCI USA, V52, P1239, DOI 10.1073/pnas.52.5.1239; BELLMAN R, 1961, COMMUN ACM, V4, P284, DOI 10.1145/366573.366611; Bellman RE, 1957, DYNAMIC PROGRAMMING; Cox MG., 1971, J I MATH APPL, V8, P36, DOI DOI 10.1093/IMAMAT/8.1.36; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; DUDA RO, 1973, PATTERN CLASSIFICATI, P328; GLUSS B, 1962, COMMUN ACM, V5, P441, DOI 10.1145/368637.368753; GLUSS B, 1964, INFORM CONTROL, V7, P200, DOI 10.1016/S0019-9958(64)90109-3; GLUSS B, 1962, INFORM CONTROL, V5, P261, DOI 10.1016/S0019-9958(62)90599-5; GLUSS B, 1963, COMMUN ACM, V6, P172, DOI 10.1145/366349.366550; ICHIDA K, 1975, ELECTRON COMMUN JA D, V58, P689; KUROZUMI Y, 1982, COMPUT VISION GRAPH, V19, P248, DOI 10.1016/0146-664X(82)90011-9; Lawson CL, 1964, NUMER MATH, V6, P293; MONTNARI U, 1970, COMMUN ACM, V13, P41, DOI 10.1145/361953.361967; PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041; PAVLIDIS T, 1973, IEEE T COMPUT, VC 22, P689, DOI 10.1109/TC.1973.5009136; PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029; PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6; PAVLIDIS T, 1982, ALGORITHMS GRAPHICS, P281; Ramer U, 1972, COMPUT GRAPH IMAGE P, V1, P244, DOI [DOI 10.1016/S0146-664X(72)80017-0, 10.1016/S0146-664X(72)80017-0]; Reumann K., 1974, International Computing Symposium 1973, P467; ROBERGE J, 1985, COMPUT VISION GRAPH, V29, P168, DOI 10.1016/0734-189X(85)90117-3; SKLANSKY J, 1980, PATTERN RECOGN, V12, P327, DOI 10.1016/0031-3203(80)90031-X; SKLANSKY J, 1972, IEEE T COMPUT, VC 21, P260, DOI 10.1109/TC.1972.5008948; TOMEK I, 1974, IEEE T COMPUT, VC 23, P445, DOI 10.1109/T-C.1974.223961; VANDEWALLE J, 1975, IEEE T COMPUT, V24, P843, DOI 10.1109/T-C.1975.224320; WILLIAMS CM, 1978, COMPUT VISION GRAPH, V8, P286, DOI 10.1016/0146-664X(78)90055-2	28	172	180	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1986	8	1					67	75		10.1109/TPAMI.1986.4767753	http://dx.doi.org/10.1109/TPAMI.1986.4767753			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AWT86	21869324				2022-12-18	WOS:A1986AWT8600008
J	PENTLAND, AP				PENTLAND, AP			LOCAL SHADING ANALYSIS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MIT,ARTIFICIAL INTELLIGENCE LAB,CAMBRIDGE,MA 02139; STANFORD UNIV,DEPT COMP SCI,STANFORD,CA 94305; STANFORD UNIV,DEPT PSYCHOL,STANFORD,CA 94305	Massachusetts Institute of Technology (MIT); Stanford University; Stanford University	PENTLAND, AP (corresponding author), STANFORD RES INST,ARTIFICIAL INTELLIGENCE LAB,MENLO PK,CA 94025, USA.							BRUSS A, 1981, THESIS MASSACHUSETTS; DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6; DEVALOIS KK, 1979, J PHYSIOL-LONDON, V291, P483, DOI 10.1113/jphysiol.1979.sp012827; HORN BKP, 1970, MIT AI79 TECH REP; HUBEL DH, 1977, PROC R SOC SER B-BIO, V198, P1, DOI 10.1098/rspb.1977.0085; IKEUCHI K, 1981, ARTIFICIAL INTELL, V15; KELLY DH, 1979, J OPT SOC AM, V69, P1340, DOI 10.1364/JOSA.69.001340; KELLY DH, 1975, VISION RES, V15, P665, DOI 10.1016/0042-6989(75)90282-5; KENDER JR, 1979, 6TH P INT JOINT C AR; KUFFLER SW, 1953, J NEUROPHYS, V16, P281; MARR D, 1979, MIT AI518 MEM; PENTLAND A, 1982, J OPT SOC AM, V72; PENTLAND AP, 1982, THESIS MASSACHUSETTS; Ramon, 1911, HISTOLOGIE SYSTEME N, V2; ROSE D, 1979, VISION RES, V19, P533, DOI 10.1016/0042-6989(79)90138-X; SCHARF D, MAGNIFICATIONS PHOTO; SCHILLER PH, 1976, J NEUROPHYSIOL, V39, P1288, DOI 10.1152/jn.1976.39.6.1288; SMITH G, 1983, SRI287 ART INT CEN T; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9	19	172	179	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	2					170	187		10.1109/TPAMI.1984.4767501	http://dx.doi.org/10.1109/TPAMI.1984.4767501			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	SF591	21869181				2022-12-18	WOS:A1984SF59100004
J	Hartley, R; Kang, SB				Hartley, Richard; Kang, Sing Bing			Parameter-free radial distortion correction with center of distortion estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						radial distortion; camera calibration; fundamental matrix	CALIBRATION	We propose a method of simultaneously calibrating the radial distortion function of a camera and the other internal calibration parameters. The method relies on the use of a planar ( or, alternatively, nonplanar) calibration grid which is captured in several images. In this way, the determination of the radial distortion is an easy add-on to the popular calibration method proposed by Zhang [24]. The method is entirely noniterative and, hence, is extremely rapid and immune to the problem of local minima. Our method determines the radial distortion in a parameter-free way, not relying on any particular radial distortion model. This makes it applicable to a large range of cameras from narrow-angle to fish-eye lenses. The method also computes the center of radial distortion, which, we argue, is important in obtaining optimal results. Experiments show that this point may be significantly displaced from the center of the image or the principal point of the camera.	Australian Natl Univ, Dept Informat Engn, Canberra, ACT 0200, Australia; Natl ICT Australia, Canberra, ACT 0200, Australia; Microsoft Corp, Microsoft Res, Redmond, WA 98052 USA	Australian National University; NICTA; Microsoft	Hartley, R (corresponding author), Australian Natl Univ, Dept Informat Engn, Canberra, ACT 0200, Australia.	Richard.Hartley@anu.edu.au; sbkang@microsoft.com		Hartley, Richard/0000-0002-5005-0191				Atkinson KE., 1978, INTRO NUMERICAL ANAL; BECKER S, 1995, P SOC PHOTO-OPT INS, V2410, P447, DOI 10.1117/12.205979; BROWN DC, 1971, PHOTOGRAMM ENG, V37, P855; Brown Duane C, 1966, PHOTOGRAMMETRIC ENG, P2, DOI DOI 10.1234/12345678; CAO ZL, 1986, OPT ENG, V25, P1278, DOI 10.1117/12.7973998; Clarke TA, 1998, PHOTOGRAMM REC, V16, P293, DOI 10.1111/0031-868X.00127; FAIG W, 1975, PHOTOGRAMM ENG REM S, V41, P1479; Fitzgibbon AW, 2001, PROC CVPR IEEE, P125; HARTLEY R, 1998, P 5 EUR C COMP VIS, P20; HARTLEY R, 2004, P 8 EUR C COMP VIS, P363; Hartley RI, 1998, PHILOS T R SOC A, V356, P1175, DOI 10.1098/rsta.1998.0216; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Micusik B, 2003, PROC CVPR IEEE, P485; Ramalingam S, 2005, PROC CVPR IEEE, P1093; SHAH S, 1994, IEEE INT CONF ROBOT, P3422, DOI 10.1109/ROBOT.1994.351044; STEIN GP, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P230, DOI 10.1109/ICCV.1995.466781; Swarninathan R., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P413, DOI 10.1109/CVPR.1999.784714; Tardif J.P., 2006, P 9 EUR C COMP VIS; Thirthala S, 2005, IEEE I CONF COMP VIS, P1539; Thirthala S, 2005, PROC CVPR IEEE, P321; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; WEI GQ, 1994, IEEE T PATTERN ANAL, V16, P469, DOI 10.1109/34.291450; Xiong YL, 1997, PROC CVPR IEEE, P237, DOI 10.1109/CVPR.1997.609326; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	24	171	192	4	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2007	29	8					1309	1321		10.1109/TPAMI.2007.1147	http://dx.doi.org/10.1109/TPAMI.2007.1147			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	177XT	17568137				2022-12-18	WOS:000247186500002
J	Werner, T				Werner, Tomas			A linear programming approach to max-sum problem: A review	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review						Markov random fields; undirected graphical models; constraint satisfaction; belief propagation; linear programming relaxation; max-sum; max-plus; max-product; supermodular optimization	CONSTRAINT SATISFACTION; BELIEF PROPAGATION; ALGORITHM; COMPLEXITY; PRODUCT; BOUNDS	The max-sum labeling problem, defined as maximizing a sum of binary (i.e., pairwise) functions of discrete variables, is a general NP-hard optimization problem with many applications, such as computing the MAP configuration of a Markov random field. We review a not widely known approach to the problem, developed by Ukrainian researchers Schlesinger et al. in 1976, and show how it contributes to recent results, most importantly, those on the convex combination of trees and tree-reweighted max-product. In particular, we review Schlesinger et al.' s upper bound on the max-sum criterion, its minimization by equivalent transformations, its relation to the constraint satisfaction problem, the fact that this minimization is dual to a linear programming relaxation of the original problem, and the three kinds of consistency necessary for optimality of the upper bound. We revisit problems with Boolean variables and supermodular problems. We describe two algorithms for decreasing the upper bound. We present an example application for structural image analysis.	Czech Tech Univ, Fac Elect Engn, Dept Cybernet, Prague, Czech Republic	Czech Technical University Prague	Werner, T (corresponding author), Czech Tech Univ, Fac Elect Engn, Dept Cybernet, Karlovo Namesti 13, Prague, Czech Republic.	werner@cmp.felk.cvut.cz	Werner, Tomas/N-4615-2014	Werner, Tomas/0000-0002-6161-7157				Aji SM, 2000, IEEE T INFORM THEORY, V46, P325, DOI 10.1109/18.825794; [Anonymous], 1990, INTRO LATTICES ORDER; BALINSKI ML, 1965, MANAGE SCI, V12, P253, DOI 10.1287/mnsc.12.3.253; Bistarelli S, 1997, J ACM, V44, P201, DOI 10.1145/256303.256306; Bistarelli S., 1999, Constraints, V4, P199, DOI 10.1023/A:1026441215081; Boros E, 2002, DISCRETE APPL MATH, V123, P155, DOI 10.1016/S0166-218X(01)00336-5; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Bulatov A, 2005, SIAM J COMPUT, V34, P720, DOI 10.1137/S0097539700376676; Burkard RE, 1996, DISCRETE APPL MATH, V70, P95, DOI 10.1016/0166-218X(95)00103-X; Chekuri C, 2001, SIAM PROC S, P109; Cohen D, 2005, DISCRETE APPL MATH, V149, P53, DOI 10.1016/j.dam.2005.03.003; Cohen D, 2004, J ARTIF INTELL RES, V22, P1; Debruyne R, 2001, J ARTIF INTELL RES, V14, P205, DOI 10.1613/jair.834; FALCH B, 2002, THESIS TU DRESDEN GE; FLACH B, 1998, UNPUB DIFFUSION ALGO; GAUBERT S, 1997, 3088 INRIA; GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x; GROTSCHEL M, 1981, COMBINATORICA, V1, P169, DOI 10.1007/BF02579273; Grtschel M., 1993, GEOMETRIC ALGORITHMS; HAMMER PL, 1984, MATH PROGRAM, V28, P121, DOI 10.1007/BF02612354; HAMMER PL, 1965, OPER RES, V13, P388; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; Ishikawa H, 2003, IEEE T PATTERN ANAL, V25, P1333, DOI 10.1109/TPAMI.2003.1233908; Ishikawa H, 1998, PROC CVPR IEEE, P125, DOI 10.1109/CVPR.1998.698598; Iwata S, 2001, J ACM, V48, P761, DOI 10.1145/502090.502096; Kingsford CL, 2005, BIOINFORMATICS, V21, P1028, DOI 10.1093/bioinformatics/bti144; KOLMOGOROV V, 2006, P EUR C COMP VIS ECC; KOLMOGOROV V, 2004, MSRTR200490; KOLMOGOROV V, 2005, MSRTR200437; Kolmogorov V., 2005, P INT WORKSH ART INT; KOLMOGOROV V, 2002, P EUR C COMP VIS ECC, P65; KOLMOGOROV V, 2005, MSRTR200538; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; KOLMOGOROV VN, 2005, P C UNC ART INT UAI; Komodakis N, 2005, IEEE I CONF COMP VIS, P1018; KOSTER AMC, 1999, THESIS U MAASTRICHT; Koster AMCA, 1998, OPER RES LETT, V23, P89, DOI 10.1016/S0167-6377(98)00043-1; KOVAL VK, 1976, USSR ACAD SCI AUTOMA, V8, P149; KOVALEVSKY VA, 1975, UNPUB DIFFUSION ALGO; KOVALEVSKY VA, 1977, Patent No. 576843; Kovtun I, 2003, LECT NOTES COMPUT SC, V2781, P402; KOVTUN I, 2004, THESIS IRTC ITS NATL; Lovasz L., 1983, MATH PROGRAMMING STA, P235, DOI DOI 10.1007/978-3-642-68874-4_10; MACKWORTH A, 1991, ENCY ARTIFICIAL INTE, P285; MACKWORTH AK, 1977, ARTIF INTELL, V8, P99, DOI 10.1016/0004-3702(77)90007-8; Meltzer T, 2005, IEEE I CONF COMP VIS, P428; Minsky M., 1988, PERCEPTRONS INTRO CO; MONTANAR.U, 1974, INFORM SCIENCES, V7, P95, DOI 10.1016/0020-0255(74)90008-5; PEARL J, 1988, PROBABILISTIC RESONA; RAVIKUMAR P, 2006, P INT C MACH LEARN I; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SCHLESINGER D, 2005, THESIS TU DRESEN; SCHLESINGER M, 1976, KIBERNETIKA, V4, P113; Schlesinger M. I., 1989, MATEMATICHESKIE SRED; Schlesinger M. I., 2002, 10 LECT STAT STRUCT; SCHLESINGER MI, 1976, UNPUB FALSE MINIMA A; SCHLESINGER MI, 1996, LECT LAB PROBL ATT A; SCHLESINGER MI, 2000, COMMUNICATION; SCHLESINGER MI, 1978, UNPUB HYDRAULIC MODE; SCHLESINGER MI, 2000, P CZECH PATT REC WOR; Schlitt WJ, 2006, MINER METALL PROC, V23, P1; Schrijver A, 2000, J COMB THEORY B, V80, P346, DOI 10.1006/jctb.2000.1989; SZELISKI R, 2006, P EUR C COMP VIS ECC; TOPKIS DM, 1978, OPER RES, V26, P305, DOI 10.1287/opre.26.2.305; VANDERBEI R. J, 1996, LINEAR PROGRAMMING F; VERDU S, 1987, SIAM J CONTROL OPTIM, V25, P990, DOI 10.1137/0325054; Wainwright M, 2004, STAT COMPUT, V14, P143, DOI 10.1023/B:STCO.0000021412.33763.d5; Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P3697, DOI 10.1109/TIT.2005.856938; Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P2313, DOI 10.1109/TIT.2005.850091; Wainwright MJ, 2003, IEEE T INFORM THEORY, V49, P1120, DOI 10.1109/TIT.2003.810642; WAINWRIGHT MJ, 2003, P C NEUR INF PROC SY; WAINWRIGHT MJ, 2002, P ALL C COMM CONTR C; Waltz D.L., 1972, GENERATING SEMANTIC; Werner T., 2005, CTUCMP200525; WERNER T, 2007, P INT C MACH LEARN J; Werner Toma, 2007, 12 COMP VIS WINT WOR, P27; WIERSCHIN T, 2002, QUADRATIC MINIMIZATI; Yanover C, 2006, J MACH LEARN RES, V7, P1887; Yedidia JS, 2005, IEEE T INFORM THEORY, V51, P2282, DOI 10.1109/TIT.2005.850085	79	171	174	1	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2007	29	7					1165	1179		10.1109/TPAMI.2007.1036	http://dx.doi.org/10.1109/TPAMI.2007.1036			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	166QW	17496375	Green Submitted			2022-12-18	WOS:000246395300005
J	Flusser, J; Suk, T				Flusser, J; Suk, T			Degraded image analysis: An invariant approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						degraded image; symmetric blur; blur invariants; image moments; combined invariants; object recognition	BLIND DECONVOLUTION; MOMENT INVARIANTS; CHARACTER-RECOGNITION; PATTERN-RECOGNITION; PHASE RETRIEVAL; BLURRED IMAGES; ZERO SHEETS; RESTORATION; IDENTIFICATION; RECONSTRUCTION	Analysis and interpretation of an image which was acquired by a nonideal imaging system is the key problem in many application areas. The observed image is usually corrupted by blurring, spatial degradations, and random noise. Classical methods like blind deconvolution try to estimate the blur parameters and to restore the image. In this paper, we propose an alternative approach. We derive the features for image representation which are invariant with respect to blur regardless of the degradation PSF provided that it is centrally symmetric. As we prove in the paper, there exist two classes of such features: the first one in the spatial domain and the second one in the frequency domain. We also derive so-called combined invariants, which are invariant to composite geometric and blur degradations. Knowing these features, we can recognize objects in the degraded scene without any restoration.	Acad Sci Czech Republ, Inst Informat Theory & Automat, Dept Image Proc, CR-18208 Prague 8, Czech Republic	Czech Academy of Sciences; Institute of Information Theory & Automation of the Czech Academy of Sciences	Flusser, J (corresponding author), Acad Sci Czech Republ, Inst Informat Theory & Automat, Dept Image Proc, CR-18208 Prague 8, Czech Republic.		Suk, Tomas/H-3073-2014; Flusser, Jan/F-6209-2014	Flusser, Jan/0000-0003-3747-9214				ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698, DOI 10.1109/TPAMI.1984.4767594; Andrews H.C., 1977, DIGITAL IMAGE RESTOR; AYERS GR, 1988, OPT LETT, V13, P547, DOI 10.1364/OL.13.000547; BARNEA DI, 1972, IEEE T COMPUT, VC 21, P179, DOI 10.1109/TC.1972.5008923; BATES RHT, 1990, J OPT SOC AM A, V7, P468, DOI 10.1364/JOSAA.7.000468; BIEMOND J, 1990, P IEEE, V78, P856, DOI 10.1109/5.53403; BONES PJ, 1995, J OPT SOC AM A, V12, P1842, DOI 10.1364/JOSAA.12.001842; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; CANNON M, 1976, IEEE T ACOUST SPEECH, V24, P58, DOI 10.1109/TASSP.1976.1162770; CASH GL, 1987, COMPUT VISION GRAPH, V39, P291, DOI 10.1016/S0734-189X(87)80183-4; CHANG MM, 1991, IEEE T SIGNAL PROCES, V39, P2323, DOI 10.1109/78.91207; DAVEY BLK, 1989, OPT COMMUN, V69, P353, DOI 10.1016/0030-4018(89)90018-7; FIUSSER J, 1996, P 13 INT C PATT REC, V2, P389; Flusser J, 1996, IEEE T IMAGE PROCESS, V5, P533, DOI 10.1109/83.491327; FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H; FLUSSER J, 1996, COMP SUPPL, V11, P37; GENNERY DB, 1973, J OPT SOC AM, V63, P1571, DOI 10.1364/JOSA.63.001571; GHIGLIA DC, 1993, J OPT SOC AM A, V10, P1024, DOI 10.1364/JOSAA.10.001024; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; HUNT BR, 1973, IEEE T COMPUT, VC 22, P805, DOI 10.1109/TC.1973.5009169; Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268; LAGENDIJK RL, 1990, IEEE T ACOUST SPEECH, V38, P1180, DOI 10.1109/29.57545; LANE RG, 1987, J OPT SOC AM A, V4, P180, DOI 10.1364/JOSAA.4.000180; MCCALLUM BC, 1990, OPT COMMUN, V75, P101, DOI 10.1016/0030-4018(90)90236-M; MOUYAN Z, 1996, P 3 IEEE INT C IM P, V3, P77; Pavlovic G, 1992, IEEE T IMAGE PROCESS, V1, P496, DOI 10.1109/83.199919; PAWLAK M, 1992, IEEE T INFORM THEORY, V38, P1698, DOI 10.1109/18.165444; Reeves SJ, 1992, IEEE T IMAGE PROCESS, V1, P301, DOI 10.1109/ICASSP.1992.226241; REICHENBACH SE, 1995, IEEE T GEOSCI REMOTE, V33, P997, DOI 10.1109/36.406685; REISS TH, 1993, LNCS, V676; SEZAN MI, 1990, OPT ENG, V29, P393, DOI 10.1117/12.55610; STOCKHAM TG, 1975, P IEEE, V63; TEKALP AM, 1986, IEEE T ACOUST SPEECH, V34, P963, DOI 10.1109/TASSP.1986.1164886; WONG WH, 1995, PATTERN RECOGN LETT, V16, P115, DOI 10.1016/0167-8655(94)00089-L; Wood J, 1996, PATTERN RECOGN, V29, P1, DOI 10.1016/0031-3203(95)00069-0; WU HS, 1990, ELECTRON LETT, V26, P1183, DOI 10.1049/el:19900765; XU Y, 1996, P 3 IEEE INT C IM P, V1, P729; YANG YY, 1994, J OPT SOC AM A, V11, P2401, DOI 10.1364/JOSAA.11.002401	38	171	188	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1998	20	6					590	603		10.1109/34.683773	http://dx.doi.org/10.1109/34.683773			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZV807					2022-12-18	WOS:000074343300002
J	HORAUD, R; SKORDAS, T				HORAUD, R; SKORDAS, T			STEREO CORRESPONDENCE THROUGH FEATURE GROUPING AND MAXIMAL CLIQUES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									LAB ELECTR & TECHNOL INFORMAT GRENOBLE, GRENOBLE, FRANCE		HORAUD, R (corresponding author), INST INFORMAT & MATH APPL GRENOBLE, INFORMAT FONDAMENTALE & INTELLIGENCE ARTIFICIAL, GRENOBLE, FRANCE.		Horaud, Radu/AAR-5982-2021	Horaud, Radu/0000-0001-5232-024X				AMBLER AP, 1973, 3RD P INT JOINT C AR, P298; ARNOLD RD, 1980, SPIE, V238, P281; AYACHE N, 1987, INT J COMPUT VISION, V1, P107, DOI 10.1007/BF00123161; BAKER HH, 1981, 7TH P INT JOINT C AR, P631; Ballard D.H., 1982, COMPUTER VISION; BARNARD ST, 1982, COMPUT SURV, V14, P553, DOI 10.1145/356893.356896; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; BOLLES RC, 1986, INT J ROBOT RES, V5, P3, DOI 10.1177/027836498600500301; Bolles RC, 1987, 3 DIMENSIONAL MACHIN, P399; BOYER KL, 1988, IEEE T PATTERN ANAL, V10, P144, DOI 10.1109/34.3880; DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164; EASTMAN RD, 1985, DEC P DARPA IM UND W, P245; FAUGERAS OD, 1986, JUN P IEEE C COMP VI, P15; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; HERMAN M, 1986, ARTIF INTELL, V30, P289, DOI 10.1016/0004-3702(86)90002-0; Lim H. S., 1985, DEC P DARPA IM UND W, P373; MEDIONI G, 1985, COMPUT VISION GRAPH, V31, P2, DOI 10.1016/S0734-189X(85)80073-6; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041; POLLARD SB, 1985, PERCEPTION, V14, P449, DOI 10.1068/p140449; SKORDAS T, 1988, THESIS I NATIONAL PO; Tarjan R., 1972, SIAM Journal on Computing, V1, P146, DOI 10.1137/0201010; YUILLE AL, 1984, MIT AI777 ART INT LA	23	171	177	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1989	11	11					1168	1180		10.1109/34.42855	http://dx.doi.org/10.1109/34.42855			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AW796		Green Submitted			2022-12-18	WOS:A1989AW79600004
J	OROURKE, J; BADLER, NI				OROURKE, J; BADLER, NI			MODEL-BASED IMAGE ANALYSIS OF HUMAN MOTION USING CONSTRAINT PROPAGATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV PENN, MOORE SCH ELECT ENGN, DEPT COMP & INFORMAT SCI, PHILADELPHIA, PA 19104 USA	University of Pennsylvania								AGGARWAL JK, 1975, IEEE T COMPUT, V24, P966, DOI 10.1109/T-C.1975.224102; BADLER NI, 1979, P IEEE, V67, P1397, DOI 10.1109/PROC.1979.11475; BADLER NI, 1979, ACM COMPUT SURV, V11, P19; BADLER NI, 1978, MSCIS7836 U PENNS DE; BADLER NI, 1975, THESIS U TORONTO TOR; BALLARD DH, 1978, COMPUTER VISION SYST, P271; Barrow H., 1978, COMPUT VIS SYST, V2, P2; BATALI J, 1979, NOV P ARPA IM UND WO, P69; CHIEN RT, 1975, 1975 P ICJAI TBIL, P737; CHOW WK, 1977, IEEE T COMPUT, V26, P179, DOI 10.1109/TC.1977.5009299; CLARK JH, 1976, COMMUN ACM, V19, P547, DOI 10.1145/360349.360354; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; EASTMAN CM, 1973, ARTIF INTELL, V4, P41, DOI 10.1016/0004-3702(73)90008-8; ESKENAZI R, 1977, 1977 P IJCAI CAMBR, P769; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; FIKES RE, 1970, ARTIF INTELL, V1, P27, DOI 10.1016/0004-3702(70)90003-2; FREUDER EC, 1978, COMMUN ACM, V21, P958, DOI 10.1145/359642.359654; FUTRELLE RP, 1978 P IEEE C PATT R, P405; FUTRELLE RP, 1974, 1974 P IFIP, P712; GUZMAN A, 1968, FAL AFIPS P JOINT CO, V33, P291; GUZMAN A, 1977, COMPUTER METHODS IMA, P324; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; HAYES PJ, 1978, TR29 U ROCH DEP COMP; HERMAN GT, 1978, COMPUT VISION GRAPH, V7, P130, DOI 10.1016/S0146-664X(78)80018-5; HERMAN M, 1979, TR836 U MAR REP; HERNAN MA, 1979, APR IEEE WORKSH COMP, P134; Hochberg Julian., 1972, ART PERCEPTION REALI, P47; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; JAIN R, 1979, IEEE T PATTERN ANAL, V1, P206, DOI 10.1109/TPAMI.1979.4766907; JOHANSSON G, 1975, SCI AM, V232, P76, DOI 10.1038/scientificamerican0675-76; JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378; KANADE T, 1978, 4TH P INT J C PATT R, P95; KOZLOWSKI LT, 1977, PERCEPT PSYCHOPHYS, V21, P575, DOI 10.3758/BF03198740; LEVIN MD, 1978, 784R MCGILL U DEP EL; LIPPEL B, 1976, P SID, V17, P115; Mackworth A. K., 1978, COMPUTER VISION SYST, P53; MACKWORTH AK, 1977, ARTIF INTELL, V8, P99, DOI 10.1016/0004-3702(77)90007-8; MARR D, 1976, PHILOS T R SOC B, V275, P483, DOI 10.1098/rstb.1976.0090; MARR D, 1976, AI377 MASS I TECHN M; MARTIN WN, 1978, COMPUT VISION GRAPH, V7, P356, DOI 10.1016/S0146-664X(78)80003-3; Minsky M., 1975, PSYCHOL COMPUTER VIS, P211; MONTANAR.U, 1974, INFORM SCIENCES, V7, P95, DOI 10.1016/0020-0255(74)90008-5; NAGEL HH, 1978, COMPUT VISION GRAPH, V7, P149, DOI 10.1016/0146-664X(78)90111-9; NAGEL HH, 1978, 4TH P INT JOINT C PA, P186; Neisser U., 1976, COGNITION REALITY PR; NEUMAN B, 1978, 4TH P INT JOINT C PA, P691; OROURKE J, UNPUBLISHED; OROURKE J, 1980, THESIS U PENNSYLVANI; POTTER JL, 1977, COMPUT VISION GRAPH, V6, P558, DOI 10.1016/S0146-664X(77)80016-6; RASHID R, 1979, NOV P DARPA IM UND W, P57; ROACH JW, 1979, IEEE T PATTERN ANAL, V1, P127, DOI 10.1109/TPAMI.1979.4766898; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; RUSSEL DM, 1979, AUG P C PATT REC IM, P175; SCACCHI W, 1979, AUG P C PATT REC IM, P646; SCHUDY RB, 1979, APR IEEE WORKSH COMP, P87; SHAPIRA R, 1979, COMMUN ACM, V22, P368, DOI 10.1145/359114.359129; SHNEIER MO, 1977 P IJCAI CAMBR, P585; TANIMOTO SL, 1978, COMPUTER VISION SYST, P165; TSOTSOS JK, 1977 P IJCAI CAMBR, P611; TSOTSOS JK, 1977 P IJCAI CAMBR, P699; TSUJI S, 1979, APR IEEE WORKSH COMP, P20; TSUJI S, 1977 P IJCAI CAMBR, P609; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; ULLMANN JR, 1966, INFORM CONTROL, V9, P583, DOI 10.1016/S0019-9958(66)80017-7; WALLACE TP, 1979, APR IEEE WORKSH COMP, P32; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19; Weiler K., 1977, COMPUT GRAPH, V11, P214, DOI DOI 10.1145/965141.563896; YACHIDA M, 1979, APR IEEE WORKSH COMP, P90; Yemini Y., 1979, 20th Annual Symposium of Foundations of Computer Science, P1, DOI 10.1109/SFCS.1979.39; Zucker S. W., 1976, 3rd International Joint Conference on Pattern Recognition, P852	70	171	174	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	6					522	536		10.1109/TPAMI.1980.6447699	http://dx.doi.org/10.1109/TPAMI.1980.6447699			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KS962					2022-12-18	WOS:A1980KS96200005
J	Yu, J; Tan, M; Zhang, HY; Tao, DC; Rui, Y				Yu, Jun; Tan, Min; Zhang, Hongyuan; Tao, Dacheng; Rui, Yong			Hierarchical Deep Click Feature Prediction for Fine-Grained Image Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visualization; Feature extraction; Image recognition; Semantics; Predictive models; Vocabulary; Task analysis; Click prediction; hierarchical model; word embedding; deep neural network; transfer learning	CNNS	The click feature of an image, defined as the user click frequency vector of the image on a predefined word vocabulary, is known to effectively reduce the semantic gap for fine-grained image recognition. Unfortunately, user click frequency data are usually absent in practice. It remains challenging to predict the click feature from the visual feature, because the user click frequency vector of an image is always noisy and sparse. In this paper, we devise a Hierarchical Deep Word Embedding (HDWE) model by integrating sparse constraints and an improved RELU operator to address click feature prediction from visual features. HDWE is a coarse-to-fine click feature predictor that is learned with the help of an auxiliary image dataset containing click information. It can therefore discover the hierarchy of word semantics. We evaluate HDWE on three dog and one bird image datasets, in which Clickture-Dog and Clickture-Bird are utilized as auxiliary datasets to provide click data, respectively. Our empirical studies show that HDWE has 1) higher recognition accuracy, 2) a larger compression ratio, and 3) good one-shot learning ability and scalability to unseen categories.	[Yu, Jun; Tan, Min; Zhang, Hongyuan] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Key Lab Complex Syst Modeling & Simulat, Hangzhou 310018, Peoples R China; [Rui, Yong] Lenovo, 6 Shang Di West Rd, Beijing 100085, Peoples R China; [Tao, Dacheng] Univ Sydney, Fac Engn, Sch Comp Sci, UBTECH Sydney Artificial Intelligence Ctr, 6 Cleveland St, Darlington, NSW 2008, Australia	Hangzhou Dianzi University; Legend Holdings; Lenovo; University of Sydney	Tan, M (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Key Lab Complex Syst Modeling & Simulat, Hangzhou 310018, Peoples R China.	yujun@hdu.edu.cn; tanmin@hdu.edu.cn; zhhy1994226@163.com; dacheng.tao@sydney.edu.au; yongrui@lenovo.com			National Natural Science Foundation of China [61836002, 61602136, 61622205, 61601158]; Zhejiang Provincial Natural Science Foundation of China [LY19F020038]; Australian Research Council [FL-170100117, DP-180103424]; Zhejiang Provincial Key Science and Technology Project Foundation [2018C01012]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Zhejiang Provincial Natural Science Foundation of China(Natural Science Foundation of Zhejiang Province); Australian Research Council(Australian Research Council); Zhejiang Provincial Key Science and Technology Project Foundation	This work was supported by National Natural Science Foundation of China No.61836002, Zhejiang Provincial Natural Science Foundation of China (No.LY19F020038), National Natural Science Foundation of China (No.61602136, No.61622205, and No.61601158), Australian Research Council Projects (FL-170100117 and DP-180103424), and Zhejiang Provincial Key Science and Technology Project Foundation (No.2018C01012).	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bai YL, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P441, DOI 10.1145/2733373.2806243; Branson S., 2014, PROC BRIT MACH VIS C; Chen CH, 2017, PATTERN RECOGN LETT, V93, P113, DOI 10.1016/j.patrec.2016.11.004; Chen TS, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P627; Cui Y, 2017, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR.2017.325; Dubey A, 2018, LECT NOTES COMPUT SC, V11216, P71, DOI 10.1007/978-3-030-01258-8_5; Faghri Fartash, 2017, ARXIV170705612; Feng W, 2017, LECT NOTES COMPUT SC, V10132, P127, DOI 10.1007/978-3-319-51811-4_11; Frome Andrea, 2013, NEURIPS; Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476; Fu RJ, 2015, IEEE-ACM T AUDIO SPE, V23, P461, DOI 10.1109/TASLP.2014.2377580; G_oring C., 2013, ARXIV13104759; Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41; Han K, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P2040, DOI 10.1145/3240508.3240550; He XT, 2017, PROC CVPR IEEE, P7332, DOI 10.1109/CVPR.2017.775; Hua X.-S., 2013, P 21 ACM INT C MULT, P243, DOI DOI 10.1145/2502081.2502283; Huang S., 2015, PART STACKED CNN FIN; Kitazono J, 2016, LECT NOTES COMPUT SC, V9949, P119, DOI 10.1007/978-3-319-46675-0_14; Kong S, 2017, PROC CVPR IEEE, P7025, DOI 10.1109/CVPR.2017.743; Lee CY, 2018, IEEE T PATTERN ANAL, V40, P863, DOI 10.1109/TPAMI.2017.2703082; Li F.-F., 2011, PROC CVPR WORKSHOP F, V2; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Lin TY, 2018, IEEE T PATTERN ANAL, V40, P1309, DOI 10.1109/TPAMI.2017.2723400; Mikolov T., 2013, WORKSHOP TRACK P; Moghimi M, 2016, 2016 IEEE IND APPL S, DOI [10.5244/C.30.24, 10, DOI 10.5244/C.30.24]; Niu ZX, 2017, IEEE I CONF COMP VIS, P1899, DOI 10.1109/ICCV.2017.208; Tan M, 2019, IEEE T IMAGE PROCESS, V28, P6047, DOI 10.1109/TIP.2019.2921861; Tan M, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3209666; Tan M, 2018, MULTIMED TOOLS APPL, V77, P22145, DOI 10.1007/s11042-018-5703-4; Tan M, 2016, IEEE T INTELL TRANSP, V17, P1415, DOI 10.1109/TITS.2015.2506182; Tan M, 2016, NEUROCOMPUTING, V181, P96, DOI 10.1016/j.neucom.2015.04.123; Tan M, 2014, NEUROCOMPUTING, V139, P56, DOI 10.1016/j.neucom.2013.09.054; Wah C., 2011, TECH REP; Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326; Wang JD, 2018, IEEE T PATTERN ANAL, V40, P769, DOI 10.1109/TPAMI.2017.2699960; Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311; Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541; Wei XS, 2017, IEEE T IMAGE PROCESS, V26, P2868, DOI 10.1109/TIP.2017.2688133; Wei Xiu-Shen, 2016, CORR; Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685; Xu D, 2017, ADV NEUR IN, V30; Yang JY, 2017, IEEE INT CON MULTI, P187, DOI 10.1109/ICME.2017.8019312; Yang Z, 2018, LECT NOTES COMPUT SC, V11218, P438, DOI 10.1007/978-3-030-01264-9_26; Yu CJ, 2018, LECT NOTES COMPUT SC, V11220, P595, DOI 10.1007/978-3-030-01270-0_35; Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377; Zhang H, 2016, PROC CVPR IEEE, P1143, DOI 10.1109/CVPR.2016.129; Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54; Zhang X., 2015, ARXIV150300591; Zhao B, 2017, IEEE T MULTIMEDIA, V19, P1245, DOI 10.1109/TMM.2017.2648498; Zheng GJ, 2017, IEEE INT CON MULTI, P661, DOI 10.1109/ICME.2017.8019407; Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557	52	170	170	32	70	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					563	578		10.1109/TPAMI.2019.2932058	http://dx.doi.org/10.1109/TPAMI.2019.2932058			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS					2022-12-18	WOS:000740006100003
J	Fernando, B; Gavves, E; Oramas, MJ; Ghodrati, A; Tuytelaars, T				Fernando, Basura; Gavves, Efstratios; Oramas, Jose M.; Ghodrati, Amir; Tuytelaars, Tinne			Rank Pooling for Action Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action recognition; temporal encoding; temporal pooling; rank pooling; video dynamics		We propose a function-based temporal pooling method that captures the latent structure of the video sequence data - e. g., how frame-level features evolve over time in a video. We show how the parameters of a function that has been fit to the video data can serve as a robust new video representation. As a specific example, we learn a pooling function via ranking machines. By learning to rank the frame-level features of a video in chronological order, we obtain a new representation that captures the video-wide temporal dynamics of a video, suitable for action recognition. Other than ranking functions, we explore different parametric models that could also explain the temporal changes in videos. The proposed functional pooling methods, and rank pooling in particular, is easy to interpret and implement, fast to compute and effective in recognizing a wide variety of actions. We evaluate our method on various benchmarks for generic action, fine-grained action and gesture recognition. Results show that rank pooling brings an absolute improvement of 7-10 average pooling baseline. At the same time, rank pooling is compatible with and complementary to several appearance and local motion based methods and features, such as improved trajectories and deep learning features.	[Fernando, Basura] Australia Natl Univ, ESAT PSI, iMinds, Leuven, Belgium; [Gavves, Efstratios] Univ Amsterdam, QUVA Lab, Amsterdam, Netherlands; [Gavves, Efstratios] ESAT PSI, iMinds, Leuven, Belgium; [Oramas, Jose M.; Ghodrati, Amir; Tuytelaars, Tinne] Katholieke Univ Leuven, ESAT PSI, iMinds, Leuven, Belgium	IMEC; University of Amsterdam; IMEC; IMEC; KU Leuven	Fernando, B (corresponding author), Australia Natl Univ, ESAT PSI, iMinds, Leuven, Belgium.	basura.fernando@anu.edu.au; e.gavves@uva.nl; jose.oramas@esat.kuleuven.be; amir.ghodrati@esat.kuleuven.be; tinne.tuytelaars@esat.kuleuven.be	Oramas, José/AAA-5521-2021; Tuytelaars, Tinne/B-4319-2015; Gavves, Efstratios/AAA-6992-2019	Oramas, José/0000-0002-8607-5067; Tuytelaars, Tinne/0000-0003-3307-9723; Gavves, Efstratios/0000-0001-8947-1332; Fernando, Basura/0000-0002-6920-9916	FP7 ERC Starting Grant [240530 COGNIMUND]; KU Leuven DBOF PhD fellowship; FWO project Monitoring of abnormal activity with camera systems; iMinds High-Tech Visualization project; Australian Research Council Centre of Excellence for Robotic Vision [CE140100016]	FP7 ERC Starting Grant; KU Leuven DBOF PhD fellowship; FWO project Monitoring of abnormal activity with camera systems; iMinds High-Tech Visualization project; Australian Research Council Centre of Excellence for Robotic Vision(Australian Research Council)	The authors acknowledge the support of FP7 ERC Starting Grant 240530 COGNIMUND, KU Leuven DBOF PhD fellowship, the FWO project Monitoring of abnormal activity with camera systems, iMinds High-Tech Visualization project and the Australian Research Council Centre of Excellence for Robotic Vision (project number CE140100016).	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Bilen Hakan, 2016, CVPR, DOI DOI 10.1109/CVPR.2016.331; Binlong Li, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3193, DOI 10.1109/CVPR.2011.5995672; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Cheron G, 2015, IEEE I CONF COMP VIS, P3218, DOI 10.1109/ICCV.2015.368; De Geest R, 2014, IEEE IMAGE PROC, P5771, DOI 10.1109/ICIP.2014.7026167; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Drucker H, 1997, ADV NEUR IN, V9, P155; Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714; Escalera S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2522848.2532595; Fernando B., 2016, P IEEE C COMP VIS PA; Fernando B, 2015, IEEE I CONF COMP VIS, P2785, DOI 10.1109/ICCV.2015.319; Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176; Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368; Gaidon A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3201, DOI 10.1109/CVPR.2011.5995646; Gaidon A, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.30; Gavves E, 2015, INT J COMPUT VISION, V111, P191, DOI 10.1007/s11263-014-0741-5; Gavves E, 2012, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2012.6248106; Gkioxari G, 2015, PROC CVPR IEEE, P759, DOI 10.1109/CVPR.2015.7298676; Hoai M., 2014, P AS C COMP VIS, P3, DOI DOI 10.1007/978-3-319-16814-21; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Izadinia H, 2012, LECT NOTES COMPUT SC, V7575, P430, DOI 10.1007/978-3-642-33765-9_31; Jain M, 2015, PROC CVPR IEEE, P46, DOI 10.1109/CVPR.2015.7298599; Jain M, 2014, PROC CVPR IEEE, P740, DOI 10.1109/CVPR.2014.100; Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330; Joachims T., 2006, P 12 ACM SIGKDD INT, V06, P217, DOI DOI 10.1145/1150402.1150429; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Lan Z., 2015, CORR; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I., 2003, ICCV, P107; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496; Liu T-Y., 2009, FOUND TRENDS INF RET, V3, P225, DOI DOI 10.1561/1500000016; Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229; Marszaek M., 2009, CVPR, P2929, DOI DOI 10.1109/CVPR.2009.5206557; Martinez-Camarena M, 2015, IEEE IMAGE PROC, P2454, DOI 10.1109/ICIP.2015.7351243; Mazloom M, 2014, IEEE T MULTIMEDIA, V16, P2214, DOI 10.1109/TMM.2014.2359771; PASKO A, 1995, VISUAL COMPUT, V11, P429, DOI 10.1007/BF02464333; Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38; PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009; Pfister T, 2014, LECT NOTES COMPUT SC, V8694, P814, DOI 10.1007/978-3-319-10599-4_52; Ponce-Lopez V., 2015, P BRIT MACH VIS C; Raptis M, 2012, PROC CVPR IEEE, P1242, DOI 10.1109/CVPR.2012.6247807; Revaud J, 2013, PROC CVPR IEEE, P2459, DOI 10.1109/CVPR.2013.318; Rohrbach M, 2012, LECT NOTES COMPUT SC, V7572, P144, DOI 10.1007/978-3-642-33718-5_11; Rohrbach M, 2012, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2012.6247801; Ryoo MS, 2006, 2006 IEEE COMPUTER S, V2, P1709, DOI DOI 10.1109/CVPR.2006.242; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Sminchisescu C, 2006, COMPUT VIS IMAGE UND, V104, P210, DOI 10.1016/j.cviu.2006.07.014; Song Y, 2013, PROC CVPR IEEE, P3562, DOI 10.1109/CVPR.2013.457; Srivastava N, 2015, PR MACH LEARN RES, V37, P843; Su WT, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P184, DOI 10.1109/BigMM.2015.55; Sun C, 2013, IEEE I CONF COMP VIS, P913, DOI 10.1109/ICCV.2013.453; Sutskever I., 2014, ARXIV14093215, DOI DOI 10.1007/S10107-014-0839-0; Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808; Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11; VEDALDI A, 2008, P 18 ACM INT C MULT, P1469; Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang Y, 2011, IEEE T PATTERN ANAL, V33, P1310, DOI 10.1109/TPAMI.2010.214; Wu D, 2014, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2014.98; Wu JX, 2014, PROC CVPR IEEE, P2577, DOI 10.1109/CVPR.2014.330; Wu JX, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P453; Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161; Yao A, 2014, PROC CVPR IEEE, P1923, DOI 10.1109/CVPR.2014.247; Zepeda J, 2015, PROC CVPR IEEE, P3052, DOI 10.1109/CVPR.2015.7298924; Zhou Y, 2014, LECT NOTES COMPUT SC, V8692, P481, DOI 10.1007/978-3-319-10593-2_32	74	170	179	1	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2017	39	4					773	787		10.1109/TPAMI.2016.2558148	http://dx.doi.org/10.1109/TPAMI.2016.2558148			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EP9UD	28278449	Green Submitted			2022-12-18	WOS:000397717600013
J	Hu, XY; Mordohai, P				Hu, Xiaoyan; Mordohai, Philippos			A Quantitative Evaluation of Confidence Measures for Stereo Vision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo vision; 3D reconstruction; confidence; correspondence; distinctiveness	RECONSTRUCTION	We present an extensive evaluation of 17 confidence measures for stereo matching that compares the most widely used measures as well as several novel techniques proposed here. We begin by categorizing these methods according to which aspects of stereo cost estimation they take into account and then assess their strengths and weaknesses. The evaluation is conducted using a winner-take-all framework on binocular and multibaseline datasets with ground truth. It measures the capability of each confidence method to rank depth estimates according to their likelihood for being correct, to detect occluded pixels, and to generate low-error depth maps by selecting among multiple hypotheses for each pixel. Our work was motivated by the observation that such an evaluation is missing from the rapidly maturing stereo literature and that our findings would be helpful to researchers in binocular and multiview stereo.	[Hu, Xiaoyan; Mordohai, Philippos] Stevens Inst Technol, Dept Comp Sci, Hoboken, NJ 07030 USA	Stevens Institute of Technology	Hu, XY (corresponding author), Stevens Inst Technol, Dept Comp Sci, Hoboken, NJ 07030 USA.	xhu2@stevens.edu; philippos.mordohai@stevens.edu			US National Science Foundation (NSF) Computing Research Infrastructure grant [CNS-0855218]; Google, Inc.	US National Science Foundation (NSF) Computing Research Infrastructure grant(National Science Foundation (NSF)); Google, Inc.	This work has been supported in part by the US National Science Foundation (NSF) Computing Research Infrastructure grant (CNS-0855218) and Google, Inc., via a Google Research Award.	Bleyer M., 2008, P C INT SOC PHOT REM, P63; Bleyer M., 2010, P INT S 3D DAT PROC; Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890; Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603; Bruhn A, 2006, COMP IMAG VIS, P283; Cech J., 2007, P CVPR WORKSH BENCHM; Chen Q., 1999, P IEEE C COMP VIS PA; Deng Y, 2007, IEEE T PATTERN ANAL, V29, P1068, DOI 10.1109/TPAMI.2007.1043; Dima C, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P3347, DOI 10.1109/ROBOT.2002.1014228; Egnal G, 2004, IMAGE VISION COMPUT, V22, P943, DOI 10.1016/j.imavis.2004.03.018; Egnal G, 2002, IEEE T PATTERN ANAL, V24, P1127, DOI 10.1109/TPAMI.2002.1023808; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Gallup D., 2007, P IEEE C COMP VIS PA; Goesele M., 2007, P IEEE INT C COMP VI; Gong ML, 2007, INT J COMPUT VISION, V75, P283, DOI 10.1007/s11263-006-0032-x; Gong ML, 2005, IEEE T PATTERN ANAL, V27, P998, DOI 10.1109/TPAMI.2005.120; Hirschmuller H, 2009, IEEE T PATTERN ANAL, V31, P1582, DOI 10.1109/TPAMI.2008.221; Hirschmuller H, 2002, INT J COMPUT VISION, V47, P229, DOI 10.1023/A:1014554110407; Hirschmuller H., 2007, P IEEE C COMP VIS PA; Hu X., 2010, P IEEE C COMP VIS PA; Jancosek Michal, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1526, DOI 10.1109/ICCVW.2009.5457432; Jodoin P., 2006, P BRIT MACH VIS C, p[I, I]; Kohli P, 2008, COMPUT VIS IMAGE UND, V112, P30, DOI 10.1016/j.cviu.2008.07.002; Kostliva J., 2007, P CVPR WORKSH BENCHM; Lefebvre Sebastien, 2007, 2007 Third International IEEE Conference on Signal-Image Technologies and Internet-Based System (SITIS), P702, DOI 10.1109/SITIS.2007.25; Lhuillier M, 2005, IEEE T PATTERN ANAL, V27, P418, DOI 10.1109/TPAMI.2005.44; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mac Aodha O, 2010, PROC CVPR IEEE, P1054, DOI 10.1109/CVPR.2010.5540099; Manduchi R., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P26, DOI 10.1109/ICIAP.1999.797566; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; Matthies L., 1991, SPIE, V1570, P187; MERRELL P, 2007, P IEEE INT C COMP VI; Mordohai P., 2009, P IEEE INT C COMP VI; Neilson D., 2008, P IEEE C COMP VIS PA; Pollefeys M, 2008, INT J COMPUT VISION, V78, P143, DOI 10.1007/s11263-007-0086-4; Reynolds M., 2011, P IEEE C COMP VIS PA; Scharstein D, 1998, INT J COMPUT VISION, V28, P155, DOI 10.1023/A:1008015117424; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Scharstein D, 2003, PROC CVPR IEEE, P195; Seitz S.M., 2006, P IEEE COMPUTER SOC, P519; Strecha C., 2008, P IEEE C COMP VIS PA; Sun J, 2005, PROC CVPR IEEE, P399; Tombari F., 2008, P IEEE C COMP VIS PA; Wei YC, 2004, PROC CVPR IEEE, P106; Xu L, 2008, LECT NOTES COMPUT SC, V5305, P775; Yoon KJ, 2008, COMPUT VIS IMAGE UND, V112, P173, DOI 10.1016/j.cviu.2008.02.003; Zhengyou Zhang, 2001, 3D Structure from Images - SMILE 2000. Second European Workshop on 3D Structure from Multiple Images of Large-Scale Environments. Revised Papers (Lecture Notes in Computer Science Vol.2018), P68	47	170	181	2	60	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2012	34	11					2121	2133		10.1109/TPAMI.2012.46	http://dx.doi.org/10.1109/TPAMI.2012.46			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	005MR	22331856				2022-12-18	WOS:000308755000005
J	Frinken, V; Fischer, A; Manmatha, R; Bunke, H				Frinken, Volkmar; Fischer, Andreas; Manmatha, R.; Bunke, Horst			A Novel Word Spotting Method Based on Recurrent Neural Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Keyword spotting; offline handwriting; document analysis; historical documents; neural network; BLSTM	HANDWRITING RECOGNITION; RETRIEVAL; LINE	Keyword spotting refers to the process of retrieving all instances of a given keyword from a document. In the present paper, a novel keyword spotting method for handwritten documents is described. It is derived from a neural network-based system for unconstrained handwriting recognition. As such it performs template-free spotting, i.e., it is not necessary for a keyword to appear in the training set. The keyword spotting is done using a modification of the CTC Token Passing algorithm in conjunction with a recurrent neural network. We demonstrate that the proposed systems outperform not only a classical dynamic time warping-based approach but also a modern keyword spotting system, based on hidden Markov models. Furthermore, we analyze the performance of the underlying neural networks when using them in a recognition task followed by keyword spotting on the produced transcription. We point out the advantages of keyword spotting when compared to classic text line recognition.	[Frinken, Volkmar; Fischer, Andreas; Bunke, Horst] Univ Bern, Inst Comp Sci & Appl Math IAM, CH-3012 Bern, Switzerland; [Manmatha, R.] Univ Massachusetts, Dept Comp Sci, Amherst, MA 01003 USA	University of Bern; University of Massachusetts System; University of Massachusetts Amherst	Frinken, V (corresponding author), Univ Bern, Inst Comp Sci & Appl Math IAM, Neubruckstr 10, CH-3012 Bern, Switzerland.	frinken@iam.unibe.ch; afischer@iam.unibe.ch; manmatha@cs.umass.edu; bunke@iam.unibe.ch			Swiss National Science Foundation [CRSI22_125220]	Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission)	This work has been supported by the Swiss National Science Foundation (Project CRSI22_125220). The authors thank Alex Graves for kindly providing them with the BLSTM Neural Network source code.	Adamek T, 2007, INT J DOC ANAL RECOG, V9, P153, DOI 10.1007/s10032-006-0024-y; Bulacu M, 2007, PROC INT CONF DOC, P357; Cao H., 2007, P 6 INT C ADV PATT R; Cao HG, 2009, PATTERN RECOGN, V42, P3374, DOI 10.1016/j.patcog.2009.02.003; Choisy C, 2007, PROC INT CONF DOC, P242; Edwards J., 2004, P ADV NEUR INF PROC, P385; El-Yacoubi MA, 2002, IEEE T PATTERN ANAL, V24, P172, DOI 10.1109/34.982898; Feng S., 2008, THESIS U MASSACHUSET; Fernandez S, 2007, LECT NOTES COMPUT SC, V4669, P220; Fischer A., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3416, DOI 10.1109/ICPR.2010.834; Fischer A, 2009, 2009 15TH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA PROCEEDINGS (VSMM 2009), P137, DOI 10.1109/VSMM.2009.26; Frinken V., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P352, DOI 10.1109/ICFHR.2010.61; Frinken V, 2010, LECT NOTES ARTIF INT, V5998, P185, DOI 10.1007/978-3-642-12159-3_17; Gatos Basilis, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P271, DOI 10.1109/ICDAR.2009.236; Goodman JT, 2001, MSRTR200172; Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137; Howe N. R., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P377, DOI 10.1145/1076034.1076099; Howe NR, 2009, PATTERN RECOGN, V42, P3338, DOI 10.1016/j.patcog.2009.01.012; Jose D., 2008, 2 INT WORKSH CROSS L, P48; Keshet J, 2009, SPEECH COMMUN, V51, P317, DOI 10.1016/j.specom.2008.10.002; Khurshid Khurram, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P266, DOI 10.1109/ICDAR.2009.161; Kolcz A, 2000, PATTERN ANAL APPL, V3, P153, DOI 10.1007/s100440070020; Kucera H., 1989, MANUAL INFORM ACCOMP; KUO SS, 1994, IEEE T PATTERN ANAL, V16, P842, DOI 10.1109/34.308482; Lavrenko V, 2004, FIRST INTERNATIONAL WORKSHOP ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P278, DOI 10.1109/DIAL.2004.1263256; Levy S., 2004, NEWSWEEK; Leydier Y, 2005, PROC INT CONF DOC, P533, DOI 10.1109/ICDAR.2005.171; Leydier Y, 2007, PATTERN RECOGN, V40, P3552, DOI 10.1016/j.patcog.2007.04.024; Leydier Y, 2009, PATTERN RECOGN, V42, P2089, DOI 10.1016/j.patcog.2009.01.026; Lu Y, 2002, INT C PATT RECOG, P57, DOI 10.1109/ICPR.2002.1047794; Manmatha R, 1996, PROC CVPR IEEE, P631, DOI 10.1109/CVPR.1996.517139; MANMATHA R, 1997, WORD SPOTTING INDEXI, P43; Manmatha T. M. R. R., 2003, P S DOC IM UND TECHN, P77; Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071; Marti UV, 2001, INT J PATTERN RECOGN, V15, P65, DOI 10.1142/S0218001401000848; Metzler D., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P472, DOI 10.1145/1076034.1076115; Moghaddam R.F., 2009, P 10 INT C DOC AN RE, V2, P511; Myers C. S., 1980, ICASSP 80 Proceedings. IEEE International Conference on Acoustics, Speech and Signal Processing, P173; Perronnin Florent, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P106, DOI 10.1109/ICDAR.2009.16; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; Plotz T, 2009, INT J DOC ANAL RECOG, V12, P269, DOI 10.1007/s10032-009-0098-4; Rath T. M., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P369, DOI 10.1145/1008992.1009056; Rath T.M., 2003, MM42 CTR INT INF RET; Rath TM, 2003, PROC CVPR IEEE, P521; Rath TM, 2003, PROC INT CONF DOC, P218; Rath TM, 2007, INT J DOC ANAL RECOG, V9, P139, DOI 10.1007/s10032-006-0027-8; Rodriguez Jose A, 2008, P 19 INT C PATT REC, P1; Rodriguez-Serrano J.A., 2008, INT C FRONTIERS HAND, P7; Rodriguez-Serrano JA, 2009, PATTERN RECOGN, V42, P2106, DOI 10.1016/j.patcog.2009.02.005; Rothfeder J. L., 2003, P IEEE COMP SOC C CO, V3, P30, DOI DOI 10.1109/CVPRW.2003.10021; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Salton G., 1971, SMART RETRIEVAL SYST; Saykol E, 2004, IEEE T IMAGE PROCESS, V13, P314, DOI 10.1109/TIP.2003.821114; Srihari S., 2006, DOCUMENT RECOGNITION, V6067, P606702; Srihari S. N., 2006, Vivek, V16, P2; Stolcke Andreas, 2002, P INT, P901; Terasawa K., 2009, P 10 INT C DOC AN RE, P116; Thomas S., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3412, DOI 10.1109/ICPR.2010.833; Vinciarelli A, 2002, PATTERN RECOGN, V35, P1433, DOI 10.1016/S0031-3203(01)00129-7; Wollmer M, 2009, INT CONF ACOUST SPEE, P3949, DOI 10.1109/ICASSP.2009.4960492; Zhang B, 2004, PROC SPIE, V5296, P45; Ziftci C., 2006, COMP VIS PATT REC 20, P1455, DOI DOI 10.1109/CVPR.2006.269	62	170	174	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2012	34	2					211	224		10.1109/TPAMI.2011.113	http://dx.doi.org/10.1109/TPAMI.2011.113			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	862PJ	21646681	Green Submitted			2022-12-18	WOS:000298105500002
J	Liu, CJ				Liu, CJ			Capitalize on dimensionality increasing techniques for improving face recognition grand challenge performance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						dimensionality increasing techniques; face recognition; Face Recognition Grand Challenge (FRGC); fractional power polynomial models; gabor image representation; Kernel Fisher Analysis (KFA) method	GENERALIZED DISCRIMINANT-ANALYSIS; SINGULAR-VALUE DECOMPOSITION; LINEAR DISCRIMINANT; IMAGE RETRIEVAL; CLASSIFICATION; IDENTIFICATION; PURSUIT; FILTERS; MODELS	This paper presents a novel pattern recognition framework by capitalizing on dimensionality increasing techniques. In particular, the framework integrates Gabor image representation, a novel multiclass Kernel Fisher Analysis (KFA) method, and fractional power polynomial models for improving pattern recognition performance. Gabor image representation, which increases dimensionality by incorporating Gabor filters with different scales and orientations, is characterized by spatial frequency, spatial locality, and orientational selectivity for coping with image variabilities such as illumination variations. The KFA method first performs nonlinear mapping from the input space to a high-dimensional feature space, and then implements the multiclass Fisher discriminant analysis in the feature space. The significance of the nonlinear mapping is that it increases the discriminating power of the KFA method, which is linear in the feature space but nonlinear in the input space. The novelty of the KFA method comes from the fact that 1) it extends the two-class kernel Fisher methods by addressing multiclass pattern classification problems and 2) it improves upon the traditional Generalized Discriminant Analysis (GDA) method by deriving a unique solution (compared to the GDA solution, which is not unique). The fractional power polynomial models further improve performance of the proposed pattern recognition framework. Experiments on face recognition using both the FERET database and the FRGC (Face Recognition Grand Challenge) databases show the feasibility of the proposed framework. In particular, experimental results using the FERET database show that the KFA method performs better than the GDA method and the fractional power polynomial models help both the KFA method and the GDA method improve their face recognition performance. Experimental results using the FRGC databases show that the proposed pattern recognition framework improves face recognition performance upon the BEE baseline algorithm and the LDA-based baseline algorithm by large margins.	New Jersey Inst Technol, Dept Comp Sci, Newark, NJ 07102 USA	New Jersey Institute of Technology	Liu, CJ (corresponding author), New Jersey Inst Technol, Dept Comp Sci, Newark, NJ 07102 USA.	liu@cs.njit.edu						Anderson E., 1999, LAPACK USERS GUIDE S; Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bowyer KW, 2004, INT C PATT RECOG, P358, DOI 10.1109/ICPR.2004.1334126; Cooke T, 2002, IEEE T PATTERN ANAL, V24, P268, DOI 10.1109/34.982904; Cristianini N., 2000, INTRO SUPPORT VECTOR; Daugman J, 1997, IEEE T PATTERN ANAL, V19, P675, DOI 10.1109/34.598225; DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905; Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Gonzalez R., 2001, DIGITAL IMAGE PROCES, V2; Haykin S., 1999, NEURAL NETWORKS COMP; Haykin S, 1998, NEURAL NETWORKS COMP, V2nd; Howland P, 2004, IEEE T PATTERN ANAL, V26, P995, DOI 10.1109/TPAMI.2004.46; Jain AK, 2004, INT C PATT RECOG, P935, DOI 10.1109/ICPR.2004.1334413; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; Liang ZZ, 2005, PATTERN RECOGN, V38, P307, DOI 10.1016/j.patcog.2004.06.006; Liu CJ, 2004, IEEE T SYST MAN CY B, V34, P1117, DOI 10.1109/TSMCB.2003.821449; Liu CJ, 2004, IEEE T PATTERN ANAL, V26, P572, DOI 10.1109/TPAMI.2004.1273927; Liu CJ, 2003, IEEE T PATTERN ANAL, V25, P725, DOI 10.1109/TPAMI.2003.1201822; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Liu CJ, 2000, IEEE T IMAGE PROCESS, V9, P132, DOI 10.1109/83.817604; Liu CJ, 2000, IEEE T PATTERN ANAL, V22, P570, DOI 10.1109/34.862196; Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413; LYONS MJ, 2000, P 4 IEEE INT C AUT F; Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121; Pankanti S, 2000, COMPUTER, V33, P46, DOI 10.1109/2.820038; Park CH, 2005, SIAM J MATRIX ANAL A, V27, P87, DOI 10.1137/S0895479804442334; Phillips P.J., 2005, P IEEE C COMP VIS PA; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Phillips PJ, 1998, IEEE T IMAGE PROCESS, V7, P1150, DOI 10.1109/83.704308; PHILLIPS PJ, 2003, FRVT 2002 EVALUATION; PHILLIPS PJ, 2002, P 5 INT C AUT FAC GE, P224; Scholkopf B., 2001, LEARNING KERNELS SUP; Shih PC, 2005, INT J PATTERN RECOGN, V19, P873, DOI 10.1142/S0218001405004381; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vapnik Y., 1999, NATURE STAT LEARNING; VASILESCU MAO, 2002, P EUR C COMP VIS; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; Yang J, 2005, IEEE T PATTERN ANAL, V27, P230, DOI 10.1109/TPAMI.2005.33; YANG MH, 2002, P 5 INT C AUT FAC GE; Ye JP, 2004, IEEE T PATTERN ANAL, V26, P982, DOI 10.1109/TPAMI.2004.37; Zhang F., 1999, MATRIX THEORY BASIC; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; Zheng WM, 2004, NEURAL COMPUT, V16, P1283, DOI 10.1162/089976604773717612	50	170	186	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2006	28	5					725	737		10.1109/TPAMI.2006.90	http://dx.doi.org/10.1109/TPAMI.2006.90			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	020CO	16640259				2022-12-18	WOS:000235885700005
J	Finlayson, GD				Finlayson, GD			Color in perspective	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						color; color constancy; physics-based vision	CONSTANCY	Simple constraints on the sets of possible surface reflectances and illuminants are exploited in a new color constancy algorithm that builds upon Forsyth's [1] theory of color constancy. Forsyth's method invokes the constraint that the surface colors under a canonical illuminant all fall within an established maximal convex gamut of possible colors. Unfortunately the method works only when restrictive conditions are imposed on the world: the illumination must be uniform, the surfaces must be planar, and there can be no specularities. To overcome these restrictions, we modify Forsyth's algorithm so that it works with the colors under a perspective projection (in essence in a chromaticity space). The new algorithm working in perspective is simpler than Forsyth's (its computational complexity is reduced) and more importantly the restrictions on the illuminant, surface shape and specularities can be relaxed. The algorithm is then extended to include a maximal gamut constraint on the set of illuminants that is analogous to the gamut constraint on surface colors. Tests on real images shaw that the algorithm provides good color constancy.			Finlayson, GD (corresponding author), UNIV YORK,DEPT COMP SCI,YORK YO1 5DD,N YORKSHIRE,ENGLAND.							BARNARD K, 1995, THESIS S FRASER U; BERNS RS, 1988, COLOR RES APPL, V4, P243; BRELSTAFF G, 1989, THESIS U EDINBURGH; FINLAYSON GD, 1994, J OPT SOC AM A, V11, P1553, DOI 10.1364/JOSAA.11.001553; FINLAYSON GD, 1995, 95 CSS LCCR S FRAS U; Foley J. D., 1990, FUNDAMENTALS INTERAC; FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770; JUDD DB, 1964, J OPT SOC AM, V54, P1031, DOI 10.1364/JOSA.54.001031; MALONEY LT, 1986, J OPT SOC AM A, V3, P29, DOI 10.1364/JOSAA.3.000029; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; Wyszecki Gunter, 1982, COLOR SCI, V8; [No title captured]	13	170	182	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1996	18	10					1034	1038		10.1109/34.541413	http://dx.doi.org/10.1109/34.541413			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VP691					2022-12-18	WOS:A1996VP69100008
J	WENG, JY; AHUJA, N; HUANG, TS				WENG, JY; AHUJA, N; HUANG, TS			OPTIMAL MOTION AND STRUCTURE ESTIMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CRAMER-RAO BOUND; EXTENDED KALMAN FILTER; MAXIMUM LIKELIHOOD ESTIMATION; MINIMUM VARIANCE ESTIMATION; MOTION ESTIMATION; NONLINEAR LEAST-SQUARES; STRUCTURE FROM MOTION	2 PERSPECTIVE VIEWS; IMAGE SEQUENCES; ERROR ANALYSIS; OPTICAL-FLOW; RIGID BODY; 3-D MOTION; PARAMETERS; ALGORITHMS; OBJECTS	The existing linear algorithms exhibit various high sensitivities to noise. The analysis presented in this paper provides insight into the causes for such high sensitivities. It is shown in this paper that even a small pixel-level perturbation may override the epipolar information that is essential for the linear algorithms to distinguish different motions. This analysis indicates the need for optimal estimation in the presence of noise. Then, we introduce methods for optimal motion and structure estimation under two situations of noise distribution: 1) known and 2) unknown. Computationally, the optimal estimation amounts to minimizing a nonlinear function. For the correct convergence of this nonlinear minimization, we use a two-step approach. The first step is using a linear algorithm to give a preliminary estimate for the parameters. The second step is minimizing the optimal objective function starting from that preliminary estimate as an initial guess. A remarkable accuracy improvement has been achieved by this two-step approach over using the linear algorithm alone. In order to assess the accuracy of the optimal solution, the error in the solution of the optimal estimation algorithm is compared with a theoretical lower error bound-Cramer-Rao bound. The simulations have shown that with Gaussian noise added to the coordinates of the image points, the actual error in the optimal solution is very close to the bound. In addition, we also use the Cramer-Rao bound to indicate the inherent instability of motion estimation from small image disparities, such as motion from optical flow. Finally, it is known that given the same nonlinear objective function and the same initial guess, different minimization methods may lead to different solutions. We investigate the performance difference between a batch least-squares technique (Levenberg-Marquardt) and a sequential least-squares technique (iterated extended Kalman filter) for this motion estimation problem, and the simulations showed that the former gives better results.	UNIV ILLINOIS, BECKMAN INST, URBANA, IL 61801 USA; UNIV ILLINOIS, COORDINATED SCI LAB, DEPT ELECT & COMP ENGN, URBANA, IL 61801 USA	University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign								ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; AISBETT J, 1990, IEEE T PATTERN ANAL, V12, P1092, DOI 10.1109/34.61709; Anderson B. D. O., 1979, OPTIMAL FILTERING; BAKER HH, 1987, 41ST P PHOT WEEK STU, P7; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; BROWN KM, 1972, NUMER MATH, V18, P289; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; CRAMER H, 1946, MATH METHODS STATIST; CUI N, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P222; FAUGERAS OD, 1986, APR P IEEE C ROB AUT, P1433; FAUGERAS OD, 1987, P INT C COMPUT VISIO; FITZGERALD RJ, 1971, IEEE T AUTOMAT CONTR, VAC16, P736, DOI 10.1109/TAC.1971.1099836; Gelb A., 1974, APPL OPTIMAL ESTIMAT; GIORDANO AA, 1985, LEAST SQUARES ESTIMA; HARALICK R, 1983, JUN P IMAG UND WORKS; HEEGER DJ, 1987, 1ST P INT C COMP VIS, P181; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P1310, DOI 10.1109/34.41368; Huber P., 1981, ROBUST STATISTICS, DOI [10.1002/0471725250, 10.1002/0471725250.ch1]; JORTEGA JM, 1970, ITERATIVE SOLUTION N; Kalman RE., 1960, T ASME J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; Levenberg K., 1944, Q APPL MATH, V2, P164, DOI 10.1090/qam/10666; Longuet-Higgins H. C., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P395; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Luenberger D. G., 1969, OPTIMIZATION VECTOR; LUENBERGER DG, 1982, LINEAR NONLINEAR PRO; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030; MATHIES L, 1988, JUN P IEEE C COMP VI, P199; Maybeck P. S., 1982, STOCHASTIC MODELS ES, V2; Maybeck P. S., 1982, STOCHASTIC MODELS ES; MITCHIE A, 1986, HDB PATTERN RECOGNIT; Moore E. H., 1935, MEMOIRS AM PHILOS SO, VI; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; Penrose R., 1955, P CAMBRIDGE PHILOS S, V51, P406, DOI [10.1017/S0305004100030401, DOI 10.1017/S0305004100030401]; Penrose R., 1956, MATH P CAMB PHIL SOC, V52, P17, DOI 10.1017/s0305004100030929; RAO CR, 1973, LINEAR STATISTICAL I; RIVES P, 1986, DEC P C INT AUT SYST; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; SCHLEE FH, 1967, AIAA J, V5, P1114, DOI 10.2514/3.4146; Sorenson H. W, 1980, CONTROL SYSTEMS THEO; Sorenson HW., 1985, KALMAN FILTERING THE; SPETSAKIS ME, 1989, MAR P IEEE WORKSH VI, P229; TOSCANI G, 1987, NOV P IEEE WORKSH CO, P345; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; VANTREES HL, 1969, DETECTION ESTIMATION, V1; VERRI A, 1987, 1ST P INT C COMP VIS, P171; WAXMAN AM, 1987, 1ST P INT C COMP VIS, P12; WENG J, 1987, NOV P IEEE COMP SOC, P355; WENG J, 1987, JUN P INT C COMP VIS; WENG J, 1988, JUN P IEEE C COMP VI, P381; WENG J, 1989, JUN P IEEE C COMP VI, P144; WENG JY, 1992, IEEE T PATTERN ANAL, V14, P806, DOI 10.1109/34.149592; WENG JY, 1987, IEEE T PATTERN ANAL, V9, P370, DOI 10.1109/TPAMI.1987.4767920; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; WILKS SS, 1962, MATH STATISTICS; YEN BL, 1983, COMPUT VISION GRAPH, V21, P21, DOI 10.1016/S0734-189X(83)80027-9; ZACKS S, 1971, THEORY STATISTICAL I; ZHUANG XH, 1986, J OPT SOC AM A, V3, P1492, DOI 10.1364/JOSAA.3.001492; ZHUANG XH, 1988, COMPUT VISION GRAPH, V42, P334, DOI 10.1016/S0734-189X(88)80043-4	60	170	180	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1993	15	9					864	884		10.1109/34.232074	http://dx.doi.org/10.1109/34.232074			21	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LW676					2022-12-18	WOS:A1993LW67600002
J	Wu, Q; Shen, CH; Wang, P; Dick, A; van den Hengel, A				Wu, Qi; Shen, Chunhua; Wang, Peng; Dick, Anthony; van den Hengel, Anton			Image Captioning and Visual Question Answering Based on Attributes and External Knowledge	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image captioning; visual question answering; concepts learning; recurrent neural networks; LSTM		Much of the recent progress in Vision-to-Language problems has been achieved through a combination of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). This approach does not explicitly represent high-level semantic concepts, but rather seeks to progress directly from image features to text. In this paper we first propose a method of incorporating high-level concepts into the successful CNN-RNN approach, and show that it achieves a significant improvement on the state-of-the-art in both image captioning and visual question answering. We further show that the same mechanism can be used to incorporate external knowledge, which is critically important for answering high level visual questions. Specifically, we design a visual question answering model that combines an internal representation of the content of an image with information extracted from a general knowledge base to answer a broad range of image-based questions. It particularly allows questions to be asked where the image alone does not contain the information required to select the appropriate answer. Our final model achieves the best reported results for both image captioning and visual question answering on several of the major benchmark datasets.	[Wu, Qi; Shen, Chunhua; Wang, Peng; Dick, Anthony; van den Hengel, Anton] Univ Adelaide, Australian Ctr Visual Technol, Adelaide, SA 5005, Australia; [Wu, Qi; Shen, Chunhua; Wang, Peng; Dick, Anthony; van den Hengel, Anton] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Wu, Qi; Shen, Chunhua; Dick, Anthony; van den Hengel, Anton] ARC Ctr Excellence Robot Vis, Brisbane, Qld, Australia	University of Adelaide; University of Adelaide; Australian Centre for Robotic Vision	Shen, CH (corresponding author), Univ Adelaide, Australian Ctr Visual Technol, Adelaide, SA 5005, Australia.; Shen, CH (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.	qi.wu01@adelaide.edu.au; chunhua.shen@adelaide.edu.au; p.wang@adelaide.edu.au; anthony.dick@adelaide.edu.au; anton.vandenhengel@adelaide.edu.au	Wu, Qi/ABD-6304-2021	Wu, Qi/0000-0003-3631-256X; Shen, Chunhua/0000-0002-8648-8718; Dick, Anthony/0000-0001-9049-7345; van den Hengel, Anton/0000-0003-3027-8364	ARC Future Fellowship [FT120100969]	ARC Future Fellowship(Australian Research Council)	C. Shen's participation was in part supported by ARC Future Fellowship FT120100969.	Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12; Andreas Jacob, 2016, ARXIV160101705, P1545, DOI [DOI 10.18653/V1/N16-1181, 10.18653/v1/N16-1181]; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Auer Soren, 2007, DBPEDIA NUCL WEB OPE; Banerjee S., 2005, P ACL WORKSH INTR EX, P65; Bengio Y., 2014, ARXIV14061078; Berant Jonathan, 2013, P 2013 C EMP METH NA, P1533; Chen Kan, 2015, CORR; Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856; Devlin J., 2015, CORR; Devlin J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P100; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Evans C., 2008, P 2008 ACM SIGMOD IN, P1247, DOI [DOI 10.1145/1376616.1376746, 10.1145/1376616]; Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754; Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Ferrucci D, 2010, AI MAG, V31, P59, DOI 10.1609/aimag.v31i3.2303; Gao H., 2015, ADV NEURAL INFORM PR, V28, P2296, DOI DOI 10.1145/2733373.2807418; Geman D, 2015, P NATL ACAD SCI USA, V112, P3618, DOI 10.1073/pnas.1422953112; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Glorot X., 2010, PROC MACH LEARN RES, P249; Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; jia Li L., 2010, NIPS, DOI [10.1184/R1/6475985.v1, DOI 10.1184/R1/6475985.V1]; Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277; Jia YQ, 2011, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2011.6126524; Jiang A., 2015, CORR; Jin J., 2015, CORR; Jingna Mao, 2015, 2015 IEEE Biomedical Circuits and Systems Conference (BioCAS), P1, DOI 10.1109/BioCAS.2015.7348279; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kiros R, 2014, PR MACH LEARN RES, V32, P595; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li L.-J., 2012, TRENDS TOPICS COMPUT, V6553, P57, DOI DOI 10.1007/978-3-642-35749-7; Li S., 2011, P 15 C COMPUTATIONAL, P220; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Ma L., 2015, AAAI, P3567; Malinowski M., 2014, ADV NEURAL INFORM PR, V27, P1682; Malinowski M, 2015, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2015.9; Malinowski Mateusz, 2014, CORR; Noh H, 2016, PROC CVPR IEEE, P30, DOI 10.1109/CVPR.2016.11; Ordonez Vicente, 2011, ADV NEURAL INFORM PR, P1143; Pan Y., 2016, CORR; Papineni K., 2002, P C ASS COMP LING; Pont-Tuset J, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481406; Le Q, 2014, PR MACH LEARN RES, V32, P1188; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rohrbach M., 2016, CORR; Rohrbach M, 2013, IEEE I CONF COMP VIS, P433, DOI 10.1109/ICCV.2013.61; Sadeghi F, 2015, PROC CVPR IEEE, P1456, DOI 10.1109/CVPR.2015.7298752; Socher R., 2014, J T ASS COMPUT LINGU, V2, P207, DOI DOI 10.1162/TACL_A_00177; Su Y, 2012, INT J COMPUT VISION, V100, P59, DOI 10.1007/s11263-012-0529-4; Sutskever I., 2014, ARXIV14093215, DOI DOI 10.1007/S10107-014-0839-0; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tin X, 2015, PROC CVPR IEEE, P2984, DOI 10.1109/CVPR.2015.7298917; VEDANTAM R, 2015, PROC CVPR IEEE, P4566, DOI DOI 10.1109/CVPR.2015.7299087; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Viola P., 2005, ADV NEURAL INFORM PR, P1417; Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1; Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251; Wei Y., 2014, IEEE T PATTERN ANAL, V38, P1901; Weinberger KQ, 2014, ADV NEURAL INFORM PR, P1889; Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29; Wu Q, 2016, PROC CVPR IEEE, P4622, DOI 10.1109/CVPR.2016.500; WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133; Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10; Yao BZ, 2010, P IEEE, V98, P1485, DOI 10.1109/JPROC.2010.2050411; Yao L., 2016, P BRIT MACH VIS C; You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503; Young P., 2014, P TACL, V2, P67, DOI 10.1162/tacl_a_00166; Zaremba W, 2014, CORR; Zemel, 2015, ADV NEURAL INFORM PR, V1, P5; Zhou Bolei, 2015, ARXIV151202167; Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540; Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11	82	169	180	11	76	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2018	40	6					1367	1381		10.1109/TPAMI.2017.2708709	http://dx.doi.org/10.1109/TPAMI.2017.2708709			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GE9BK	28574341	Green Submitted			2022-12-18	WOS:000431524700007
J	Jiang, YG; Wu, ZX; Wang, J; Xue, XY; Chang, SF				Jiang, Yu-Gang; Wu, Zuxuan; Wang, Jun; Xue, Xiangyang; Chang, Shih-Fu			Exploiting Feature and Class Relationships in Video Categorization with Regularized Deep Neural Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video categorization; deep neural networks; regularization; feature fusion; class relationships; benchmark dataset	LATE FUSION; CLASSIFICATION; IMAGE	In this paper, we study the challenging problem of categorizing videos according to high-level semantics such as the existence of a particular human action or a complex event. Although extensive efforts have been devoted in recent years, most existing works combined multiple video features using simple fusion strategies and neglected the utilization of inter-class semantic relationships. This paper proposes a novel unified framework that jointly exploits the feature relationships and the class relationships for improved categorization performance. Specifically, these two types of relationships are estimated and utilized by imposing regularizations in the learning process of a deep neural network (DNN). Through arming the DNN with better capability of harnessing both the feature and the class relationships, the proposed regularized DNN (rDNN) is more suitable for modeling video semantics. We show that rDNN produces better performance over several state-of-the-art approaches. Competitive results are reported on the well-known Hollywood2 and Columbia Consumer Video benchmarks. In addition, to stimulate future research on large scale video categorization, we collect and release a new benchmark dataset, called FCVID, which contains 91,223 Internet videos and 239 manually annotated categories.	[Jiang, Yu-Gang; Wu, Zuxuan; Xue, Xiangyang] Fudan Univ, Sch Comp Sci, Shanghai 200433, Peoples R China; [Wang, Jun] East China Normal Univ, Sch Comp Sci & Software Engn, Shanghai 200062, Peoples R China; [Chang, Shih-Fu] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA	Fudan University; East China Normal University; Columbia University	Jiang, YG (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai 200433, Peoples R China.	ygj@fudan.edu.cn; zxwu@fudan.edu.cn; wongjun@gmail.com; xyxue@fudan.edu.cn; sfchang@ee.columbia.edu			NSF China [61622204, 61572138]; STCSM, Shanghai, China [16JC1420401]	NSF China(National Natural Science Foundation of China (NSFC)); STCSM, Shanghai, China	This work was supported in part by two grants from NSF China (#61622204, #61572138) and a grant from STCSM, Shanghai, China (#16JC1420401).	Aly R., 2013, P NIST TRECVID WORKS; Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471; Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8; Assari SM, 2014, PROC CVPR IEEE, P2529, DOI 10.1109/CVPR.2014.324; Bach F.R., 2004, P 21 INT C MACHINE L, P6, DOI 10.1145/ 1015330.1015424; Bengio Samy., 2013, ABS13125697 CORR; Cao LL, 2009, IEEE I CONF COMP VIS, P1095, DOI 10.1109/ICCV.2009.5459401; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chen J., 2011, PROC 17 ACM SIGKDD I, P42; Cotton CV, 2013, INT CONF ACOUST SPEE, P8663, DOI 10.1109/ICASSP.2013.6639357; Deng J, 2014, LECT NOTES COMPUT SC, V8689, P48, DOI 10.1007/978-3-319-10590-1_4; Fei HL, 2013, KNOWL INF SYST, V35, P345, DOI 10.1007/s10115-012-0543-4; Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213; Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176; Ghosn J, 1997, ADV NEUR IN, V9, P946; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; HEILBRON FC, 2015, PROC CVPR IEEE, P961, DOI DOI 10.1109/CVPR.2015.7298698; Hoai M., 2014, P AS C COMP VIS, P3, DOI DOI 10.1007/978-3-319-16814-21; Jacob L, 2008, ARXIV PREPRINT ARXIV; Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330; Jhuang H, 2007, IEEE I CONF COMP VIS, P1253; Jhuo IH, 2014, MACH VISION APPL, V25, P33, DOI 10.1007/s00138-013-0567-0; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Jiang W, 2009, P 17 ACM INT C MULT, P5; Jiang Y.-G., 2012, P ACM INT C MULT RET; Jiang Y.-G., 2011, ICMR, P1; Jiang YG, 2012, IEEE T IMAGE PROCESS, V21, P3080, DOI 10.1109/TIP.2012.2188038; Kang Z., 2011, P INT C MACH LEARN, V2, P4; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Kim I, 2012, LECT NOTES COMPUT SC, V7585, P395, DOI 10.1007/978-3-642-33885-4_40; Kloft M, 2011, J MACH LEARN RES, V12, P953; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lan Z.-Z., 2013, P NIST TRECVID WORKS; Lan ZZ, 2015, PROC CVPR IEEE, P204, DOI 10.1109/CVPR.2015.7298616; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Liu D, 2013, PROC CVPR IEEE, P803, DOI 10.1109/CVPR.2013.109; Liu J., 2009, P 25 C UNCERTAINTY A, P339, DOI DOI 10.5555/1795114.1795154; Ma AJ, 2014, INT J COMPUT VISION, V109, P233, DOI 10.1007/s11263-014-0723-7; Maji S, 2008, PROC CVPR IEEE, P2245; Mensink T, 2014, PROC CVPR IEEE, P2441, DOI 10.1109/CVPR.2014.313; Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601; Natarajan P, 2012, PROC CVPR IEEE, P1298, DOI 10.1109/CVPR.2012.6247814; Ngiam Jiquan, 2011, ICML, DOI DOI 10.5555/3104482.3104569; Ni BB, 2014, PROC CVPR IEEE, P963, DOI 10.1109/CVPR.2014.128; Ohshiro T, 2011, NAT NEUROSCI, V14, P775, DOI 10.1038/nn.2815; Pu J., 2013, P 23 INT JOINT C ART, P1607; Qi G.-J., 2007, P 15 INT C MULT, P17, DOI DOI 10.1145/1291233.1291245; Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Smith JR, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P445; Sohn K., 2014, P 27 INT C NEURAL IN, V2, P2141; Srivastava N, 2015, PR MACH LEARN RES, V37, P843; Srivastava Nitish, 2012, ADV NEURAL INFORM PR, P2222, DOI DOI 10.1109/CVPR.2013.49; Stein BE, 2008, NAT REV NEUROSCI, V9, P255, DOI 10.1038/nrn2331; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Weng MF, 2012, IEEE T PATTERN ANAL, V34, P1927, DOI 10.1109/TPAMI.2011.273; Wu ZX, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P461, DOI 10.1145/2733373.2806222; Wu ZX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P167, DOI 10.1145/2647868.2654931; Xu ZW, 2013, IEEE I CONF COMP VIS, P3440, DOI 10.1109/ICCV.2013.427; Yadan O., 2013, ARXIV13125853, V9; Ye GG, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P471, DOI 10.1145/2733373.2806221; Ye GN, 2013, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2013.282; Ye GN, 2012, PROC CVPR IEEE, P3021, DOI 10.1109/CVPR.2012.6248032; Zhang DQ, 2012, NEUROIMAGE, V59, P895, DOI 10.1016/j.neuroimage.2011.09.069; Zhang H, 2014, PROC CVPR IEEE, P2067, DOI 10.1109/CVPR.2014.265; Zhang Y, 2010, PROCEEDINGS OF THE ASME 29TH INTERNATIONAL CONFERENCE ON OCEAN, OFFSHORE AND ARCTIC ENGINEERING, 2010, VOL 6, P733; Zhou J., 2011, P 17 ACM SIGKDD INT, P814, DOI [10.1145/2020408.2020549, DOI 10.1145/2020408.2020549]; Zhu B., 2010, P 18 ACM INT C MULT, P987; Zou YQ, 2014, PROC VLDB ENDOW, V7, P1772, DOI 10.14778/2733004.2733082	74	169	176	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2018	40	2					352	364		10.1109/TPAMI.2017.2670560	http://dx.doi.org/10.1109/TPAMI.2017.2670560			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FS9AN	28221992	hybrid, Green Submitted			2022-12-18	WOS:000422706000007
J	Pont-Tuset, J; Arbelaez, P; Barron, JT; Marques, F; Malik, J				Pont-Tuset, Jordi; Arbelaez, Pablo; Barron, Jonathan T.; Marques, Ferran; Malik, Jitendra			Multiscale Combinatorial Grouping for Image Segmentation and Object Proposal Generation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image segmentation; object proposals; normalized cuts	GRADIENTS; CONTOURS	We propose a unified approach for bottom-up hierarchical image segmentation and object proposal generation for recognition, called Multiscale Combinatorial Grouping (MCG). For this purpose, we first develop a fast normalized cuts algorithm. We then propose a high-performance hierarchical segmenter that makes effective use of multiscale information. Finally, we propose a grouping strategy that combines our multiscale regions into highly-accurate object proposals by exploring efficiently their combinatorial space. We also present Single-scale Combinatorial Grouping (SCG), a faster version of MCG that produces competitive proposals in under five seconds per image. We conduct an extensive and comprehensive empirical validation on the BSDS500, SegVOC12, SBD, and COCO datasets, showing that MCG produces state-of-the-art contours, hierarchical regions, and object proposals.	[Pont-Tuset, Jordi; Marques, Ferran] Univ Politecn Cataluna, BarcelonaTech, Dept Signal Theory & Commun, Barcelona, Spain; [Arbelaez, Pablo] Univ Los Andes, Dept Biomed Engn, Bogota, Colombia; [Barron, Jonathan T.; Malik, Jitendra] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA	Universitat Politecnica de Catalunya; Universidad de los Andes (Colombia); University of California System; University of California Berkeley	Pont-Tuset, J (corresponding author), Univ Politecn Cataluna, BarcelonaTech, Dept Signal Theory & Commun, Barcelona, Spain.	jordi.pont@upc.edu; pa.arbelaez@uniandes.edu.co; barron@eecs.berkeley.edu; ferran.marques@upc.edu; malik@eecs.berkeley.edu			FPU [AP2008-01164]; Spanish Ministerio de Economia y Competitividad; European Regional Development Fund (ERDF); ONR MURI [N000141010933];  [BIG-GRAPH-TEC2013-43935-R]	FPU(Spanish Government); Spanish Ministerio de Economia y Competitividad(Spanish Government); European Regional Development Fund (ERDF)(European Commission); ONR MURI(MURIOffice of Naval Research); 	The last iterations of this work have been done while Jordi Pont-Tuset has been at Prof. Luc Van Gool's Computer Vision Lab (CVL) of ETHZ, Switzerland. This work has been partly developed in the framework of the project BIG-GRAPH-TEC2013-43935-R and the FPU grant AP2008-01164; financed by the Spanish Ministerio de Economia y Competitividad, and the European Regional Development Fund (ERDF). This work was partially supported by ONR MURI N000141010933. Jordi Pont-Tuset and Pablo Arbelaez contributed equally.	Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; [Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Arbelaez P., 2006, COMP VIS PATT REC WO, P182, DOI DOI 10.1109/CVPRW.2006.48; Arbelaez P, 2012, PROC CVPR IEEE, P3378, DOI 10.1109/CVPR.2012.6248077; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; Carreira J, 2012, INT J COMPUT VISION, V98, P243, DOI 10.1007/s11263-011-0507-2; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dollar P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231; Ehrgott M., 2005, MULTICRITERIA OPTIMI; Endres I, 2014, IEEE T PATTERN ANAL, V36, P222, DOI 10.1109/TPAMI.2013.122; Everingham M., 2006, P 7 EUR C COMP VIS, P34; Everingham M., 2012, INT J COMPUT VISION, V111, P98; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Gu CH, 2009, PROC CVPR IEEE, P1030, DOI 10.1109/CVPRW.2009.5206727; Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; Hoiem D, 2011, INT J COMPUT VISION, V91, P328, DOI 10.1007/s11263-010-0400-4; Hosang J., 2014, BRIT MACH VIS C NOTT; Hosang Jan, 2016, IEEE Trans Pattern Anal Mach Intell, V38, P814, DOI 10.1109/TPAMI.2015.2465908; Humayun A, 2014, PROC CVPR IEEE, P336, DOI 10.1109/CVPR.2014.50; Ion A, 2014, INT J COMPUT VISION, V107, P40, DOI 10.1007/s11263-013-0663-7; Kim J, 2012, LECT NOTES COMPUT SC, V7578, P444, DOI 10.1007/978-3-642-33786-4_33; Krahenbuhl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Maire M, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.84; Maire M, 2013, IEEE I CONF COMP VIS, P2184, DOI 10.1109/ICCV.2013.272; Malisiewicz T., 2007, P BRIT MACH VIS C UK, DOI 10.5244/C.21.55; Manen S, 2013, IEEE I CONF COMP VIS, P2536, DOI 10.1109/ICCV.2013.315; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254; Pont-Tuset J, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481406; Pont-Tuset J, 2015, IEEE I CONF COMP VIS, P1546, DOI 10.1109/ICCV.2015.181; Pont-Tuset J, 2013, PROC CVPR IEEE, P2131, DOI 10.1109/CVPR.2013.277; Rantalankila P, 2014, PROC CVPR IEEE, P2417, DOI 10.1109/CVPR.2014.310; Ren ZL, 2013, PROC CVPR IEEE, P2011, DOI 10.1109/CVPR.2013.262; Taylor CJ, 2013, PROC CVPR IEEE, P1916, DOI 10.1109/CVPR.2013.250; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Weiss D, 2013, PROC CVPR IEEE, P2035, DOI 10.1109/CVPR.2013.265; Xiaofeng R., 2012, P ADV NEUR INF PROC, P584, DOI DOI 10.1634/THEONCOLOGIST.8-3-252; Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	45	169	177	4	57	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2017	39	1					128	140		10.1109/TPAMI.2016.2537320	http://dx.doi.org/10.1109/TPAMI.2016.2537320			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EF6DP	26955014	Green Published, Green Submitted			2022-12-18	WOS:000390421300012
J	Ess, A; Leibe, B; Schindler, K; van Gool, L				Ess, Andreas; Leibe, Bastian; Schindler, Konrad; van Gool, Luc			Robust Multiperson Tracking from a Mobile Platform	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Mobile vision; multiobject tracking; pedestrian detection; stereo depth; visual odometry; graphical model	OBJECT DETECTION; PROPAGATION; MULTIPLE	In this paper, we address the problem of multiperson tracking in busy pedestrian zones using a stereo rig mounted on a mobile platform. The complexity of the problem calls for an integrated solution that extracts as much visual information as possible and combines it through cognitive feedback cycles. We propose such an approach, which jointly estimates camera position, stereo depth, object detection, and tracking. The interplay between those components is represented by a graphical model. Since the model has to incorporate object-object interactions and temporal links to past frames, direct inference is intractable. We, therefore, propose a two-stage procedure: for each frame, we first solve a simplified version of the model (disregarding interactions and temporal continuity) to estimate the scene geometry and an overcomplete set of object detections. Conditioned on these results, we then address object interactions, tracking, and prediction in a second step. The approach is experimentally evaluated on several long and difficult video sequences from busy inner-city locations. Our results show that the proposed integration makes it possible to deliver robust tracking performance in scenes of realistic complexity.	[Ess, Andreas; van Gool, Luc] ETH, Comp Vis Lab, CH-8092 Zurich, Switzerland; [Leibe, Bastian] Rhein Westfal TH Aachen, UMIC Res Ctr, D-52056 Aachen, Germany; [Schindler, Konrad] Tech Univ Darmstadt, Dept Comp Sci, D-64289 Darmstadt, Germany; [van Gool, Luc] Katholieke Univ Leuven, ESAT PSI VISICS IBBT, Louvain, Belgium	Swiss Federal Institutes of Technology Domain; ETH Zurich; RWTH Aachen University; Technical University of Darmstadt; KU Leuven	Ess, A (corresponding author), ETH, Comp Vis Lab, Sternwartstr 7, CH-8092 Zurich, Switzerland.	aess@vision.ee.ethz.ch; leibe@umic.rwth-aachen.de; schindler@cs.tu-darmstadt.de; vangool@vision.ee.ethz.ch	Leibe, Bastian/E-5499-2017	Leibe, Bastian/0000-0003-4225-0051; Pauldurai, Jona/0000-0002-7217-0872	Toyota Motor Corporation; EU [IST-027787, IST-027110]	Toyota Motor Corporation; EU(European Commission)	This research has been funded, in part, by Toyota Motor Corporation and the EU projects DIRAC (IST-027787) and HERMES (IST-027110).	Andriluka M., 2008, P IEEE C COMP VIS PA; Avidan S., 2005, P IEEE C COMP VIS PA; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Berclaz J., 2006, P IEEE C COMP VIS PA; BIBBY C, 2007, P C ROB SCI SYST; Bishop C.M, 2006, PATTERN RECOGN; BORENSTEIN E, 2002, P EUR C COMP VIS; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; COX IJ, 1993, INT J COMPUT VISION, V10, P53, DOI 10.1007/BF01440847; Dalal N., 2005, HISTOGRAMS ORIENTED; Dalal N., 2006, P EUR C COMP VIS; DAVISON AJ, 2003, P INT C COMP VIS; EADE E, 2006, P IEEE C COMP VIS PA; Ess A., 2008, P IEEE C COMP VIS PA; Ess A., 2007, P INT C COMP VIS; Felzenszwalb P., 2008, P IEEE C COMP VIS PA; Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4; FORTMANN TE, 1983, IEEE J OCEANIC ENG, V8, P173, DOI 10.1109/JOE.1983.1145560; Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7; GELB A, 1996, APPL OPTIMAL ESTIMAT; Grabner H., 2006, 2006 IEEE COMP SOC C, P260; HAHNEL D, 2003, P INT C ROB AUT; Hartley R., 2004, ROBOTICA; HOIEM D, 2006, P IEEE C COMP VIS PA; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Kaucic R., 2005, P IEEE C COMP VIS PA; Labayrade R., 2002, P IEEE INT VEH S; Lanz O, 2006, IEEE T PATTERN ANAL, V28, P1436, DOI 10.1109/TPAMI.2006.177; Leibe B., 2007, P INT C COMP VIS; LEIBE B., 2005, P IEEE C COMP VIS PA; Leibe B., 2007, P IEEE C COMP VIS PA; Leibe B, 2008, IEEE T PATTERN ANAL, V30, P1683, DOI 10.1109/TPAMI.2008.170; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; LI T, 2007, P IEEE C COMP VIS PA; MAKADIA A, 2005, P IEEE C COMP VIS PA; MURPHY KP, 2003, P C NEUR INF PROC SY; Nister D., CVPR; Okuma K., 2004, P EUR C COMP VIS; OMMER B, 2005, P INT C EN MIN METH; OZDEN KE, 2007, P INT C COMP VIS; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; REID DB, 1979, IEEE T AUTOMATIC CON, V24, P6; Rother C., 2007, P IEEE C COMP VIS PA; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; SCHINDLER K, 2006, P EUR C COMP VIS; SE S, 2002, P INT C INT ROB SYST; SHARMA V, 2007, P INT C COMP VIS; Stauffer C., 1999, P IEEE COMP SOC C CO, V2; Sudderth E.B., 2005, P INT C COMP VIS; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Toyama K., 1999, P INT C COMP VIS; TUZEL O, 2007, P IEEE C COMP VIS PA; Viola P., 2003, P INT C COMP VIS; Wang CC, 2007, INT J ROBOT RES, V26, P889, DOI 10.1177/0278364907081229; Wojek C, 2008, P S GERM ASS PATT RE; WU B., 2007, P IEEE C COMP VIS PA; Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7; YAN F, 2006, P IEEE C COMP VIS PA; Zhang L., 2008, P IEEE C COMP VIS PA; Zhu ZW, 2006, P WORKSH PERF METR I	60	169	176	1	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2009	31	10					1831	1846		10.1109/TPAMI.2009.109	http://dx.doi.org/10.1109/TPAMI.2009.109			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	483VK	19696453	Green Submitted			2022-12-18	WOS:000268996500009
J	Cappelli, R; Lumini, A; Maio, D; Maltoni, D				Cappelli, Raffaele; Lumini, Alessandra; Maio, Dario; Maltoni, Davide			Fingerprint image reconstruction from standard templates	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						biometric systems; security; ISO/IEC 19794-2 fingerprint standard template; fingerprint reconstruction; minutiae	FIELDS; MODEL	A minutiae-based template is a very compact representation of a fingerprint image, and for a long time, it has been assumed that it did not contain enough information to allow the reconstruction of the original fingerprint. This work proposes a novel approach to reconstruct fingerprint images from standard templates and investigates to what extent the reconstructed images are similar to the original ones (that is, those the templates were extracted from). The efficacy of the reconstruction technique has been assessed by estimating the success chances of a masquerade attack against nine different fingerprint recognition algorithms. The experimental results show that the reconstructed images are very realistic and that, although it is unlikely that they can fool a human expert, there is a high chance to deceive state-of-the-art commercial fingerprint recognition systems.	Univ Bologna, I-40126 Bologna, Italy; Univ Bologna, CNR, CSITE, Dept Elect Informat & Syst, I-40136 Bologna, Italy	University of Bologna; Consiglio Nazionale delle Ricerche (CNR); University of Bologna	Cappelli, R (corresponding author), Univ Bologna, Via Sacchi 3, I-40126 Bologna, Italy.	cappelli@csr.unibo.it; lumini@csr.unibo.it; dmaio@deis.unibo.it; maltoni@csr.unibo.it	Lumini, Alessandra/B-6100-2013; Lumini, Alessandra/AAF-2975-2020	Lumini, Alessandra/0000-0003-0290-7354; Lumini, Alessandra/0000-0003-0290-7354; Cappelli, Raffaele/0000-0003-3054-9363				ADLER A, 2003, P BIOM CONS C SEPT; ANSI/INCITS, 2004, 3782004 ANSIINCITS; Antonelli A, 2006, IEEE T INF FOREN SEC, V1, P360, DOI 10.1109/TIFS.2006.879289; BALDISSERRA D, 2006, P INT C BIOM AUTH JA; Bazen AM, 2002, IEEE T PATTERN ANAL, V24, P905, DOI 10.1109/TPAMI.2002.1017618; *BIOSEC EUR RES, 2005, FP6IST2002001766 BIO; BLOMME J, 2003, THESIS; Cappelli R, 2006, IEEE T PATTERN ANAL, V28, P3, DOI 10.1109/TPAMI.2006.20; CAPPELLI R, 2006, P 9 INT C CONTR AUT; Cappelli R, 2003, HDB FINGERPRINT RECO; DONAHUE MJ, 1993, CVGIP-IMAG UNDERSTAN, V57, P185, DOI 10.1006/ciun.1993.1012; Hill C.J., 2001, THESIS AUSTR NATL U; ILO, 2006, SID0002 ILO; International Biometric Group, 2002, GEN IM TEMPL; *ISO IEC, 2005, 1979422005 ISOIEC 2; Kang HS, 2003, LECT NOTES ARTIF INT, V2774, P1245; Li J, 2006, PATTERN RECOGN, V39, P102, DOI 10.1016/j.patcog.2005.08.010; Maio D, 1997, IEEE T PATTERN ANAL, V19, P27, DOI 10.1109/34.566808; Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144; MATSUMOTO T, 2002, SPIE, V4677; *NIST, 2005, 80076 NIST; *NIST, 2006, NIST MIN INT EXCH TE; Prabhakar S., 2003, HDB FINGERPRINT RECO; Press WH, 1988, NUMERICAL RECIPES C; Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614; RATHA NK, 2001, P 3 INT C AUD VID BA, P223; Ross A, 2005, PROC SPIE, V5779, P68, DOI 10.1117/12.604477; SHERLOCK BG, 1993, PATTERN RECOGN, V26, P1047, DOI 10.1016/0031-3203(93)90006-I; THALHEIM L, 2002, CT MAGAZINE      NOV; Uludag U, 2004, PROC SPIE, V5306, P622, DOI 10.1117/12.530907; *US GEN ACC OFF, 2002, GAO03174; van der Putte T, 2000, INT FED INFO PROC, V52, P289; Vizcaya PR, 1996, PATTERN RECOGN, V29, P1221, DOI 10.1016/0031-3203(95)00154-9; WATSON C, 2006, NIST FINGERPRINT IMA; Wiehe A., 2004, ATTACKING FINGERPRIN; Zhou J, 2004, PATTERN RECOGN, V37, P389, DOI 10.1016/S0031-3203(03)00186-9; 2002, P 2 INT COMP FING VE	37	169	192	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2007	29	9					1489	1503		10.1109/TPAMI.2007.1087	http://dx.doi.org/10.1109/TPAMI.2007.1087			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	189CD	17627039				2022-12-18	WOS:000247965600001
J	Mori, G; Malik, J				Mori, G; Malik, J			Recovering 3D human body configurations using shape contexts	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape; object recognition; tracking; human body pose estimation	HUMAN MOTION; TRACKING; RECONSTRUCTION	The problem we consider in this paper is to take a single two-dimensional image containing a human figure, locate the joint positions, and use these to estimate the body configuration and pose in three-dimensional space. The basic approach is to store a number of exemplar 2D views of the human body in a variety of different configurations and viewpoints with respect to the camera. On each of these stored views, the locations of the body joints (left elbow, right knee, etc.) are manually marked and labeled for future use. The input image is then matched to each stored view, using the technique of shape context matching in conjunction with a kinematic chain-based deformation model. Assuming that there is a stored view sufficiently similar in configuration and pose, the correspondence process will succeed. The locations of the body joints are then transferred from the exemplar view to the test shape. Given the 2D joint locations, the 3D body configuration and pose are then estimated using an existing algorithm. We can apply this technique to video by treating each frame independently - tracking just becomes repeated recognition. We present results on a variety of data sets.	Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada; Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Div Comp Sci, Berkeley, CA 94720 USA	Simon Fraser University; University of California System; University of California Berkeley	Mori, G (corresponding author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.	mori@cs.sfu.ca; malik@cs.berkeley.edu						Ambrosio J, 2001, HUM MOVEMENT SCI, V20, P829, DOI 10.1016/S0167-9457(01)00056-2; Barron C, 2001, COMPUT VIS IMAGE UND, V81, P269, DOI 10.1006/cviu.2000.0888; BAUMBERG A, 1994, LECT NOTES COMPUTER, V800, P299; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Brand M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1237, DOI 10.1109/ICCV.1999.790422; Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; Cormen T.H., 1990, INTRO ALGORITHMS 2 V; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056; Gross R, 2001, CMURITR0118; HOGG D, 1983, IMAGE VISION COMPUT, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3; Kakadiaris I, 2000, IEEE T PATTERN ANAL, V22, P1453, DOI 10.1109/34.895978; LEE HJ, 1985, COMPUT VISION GRAPH, V30, P148, DOI 10.1016/0734-189X(85)90094-5; MARTIN D, 2002, NEURAL INFORMATION P; Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220; Morris DD, 1998, PROC CVPR IEEE, P289, DOI 10.1109/CVPR.1998.698622; OROURKE J, 1980, IEEE T PATTERN ANAL, V2, P522, DOI 10.1109/TPAMI.1980.6447699; Rohr K., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P8, DOI 10.1109/CVPR.1993.341008; Sidenbladh H, 2003, INT J COMPUT VISION, V54, P181, DOI 10.1023/A:1023765619733; SMINCHISESCU C, **NON-TRADITIONAL**; Song Y, 2003, IEEE T PATTERN ANAL, V25, P814, DOI 10.1109/TPAMI.2003.1206511; Taylor CJ, 2000, COMPUT VIS IMAGE UND, V80, P349, DOI 10.1006/cviu.2000.0878; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; Yamamoto M., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P664, DOI 10.1109/CVPR.1991.139772; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]	41	169	189	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2006	28	7					1052	1062		10.1109/TPAMI.2006.149	http://dx.doi.org/10.1109/TPAMI.2006.149			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	041AG	16792095	Green Submitted			2022-12-18	WOS:000237424400003
J	Sigal, L; Sclaroff, S; Athitsos, V				Sigal, L; Sclaroff, S; Athitsos, V			Skin color-based video segmentation under time-varying illumination	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						color video segmentation; human skin detection; dynamic Markov model	TRACKING	A novel approach for real-time skin segmentation in video sequences is described. The approach enables reliable skin segmentation despite wide variation in illumination during tracking. An explicit second order Markov model is used to predict evolution of the skin-color (HSV) histogram over time. Histograms are dynamically updated based on feedback from the current segmentation and predictions of the Markov model. The evolution of the skin-color distribution at each frame is parameterized by translation, scaling, and rotation in color space. Consequent changes in geometric parameterization of the distribution are propagated by warping and resampling the histogram. The parameters of the discrete-time dynamic Markov model are estimated using Maximum Likelihood Estimation and also evolve over time. The accuracy of the new dynamic skin color segmentation algorithm is compared to that obtained via a static color model. Segmentation accuracy is evaluated using labeled ground-truth video sequences taken from staged experiments and popular movies. An overall increase in segmentation accuracy of up to 24 percent is observed in 17 out of 21 test sequences. In all but one case, the skin-color classification rates for our system were higher, with background classification rates comparable to those of the static segmentation.	Brown Univ, Dept Comp Sci, Providence, RI 02912 USA; Boston Univ, Image & Video Comp Grp, Dept Comp Sci, Boston, MA 02115 USA	Brown University; Boston University	Sigal, L (corresponding author), Brown Univ, Dept Comp Sci, 115 Waterman St, Providence, RI 02912 USA.	ls@cs.brown.edu; sclaroff@cs.bu.edu; athitsos@cs.bu.edu	Athitsos, Vassilis/AAF-8496-2020					Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614; BLAKE A, 1995, ARTIF INTELL, V78, P179, DOI 10.1016/0004-3702(95)00032-1; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Darrell T, 1998, PROC CVPR IEEE, P601, DOI 10.1109/CVPR.1998.698667; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Hafner W., 1997, Pattern Recognition and Image Analysis, V7, P47; Hastie T., 2002, ELEMENTS STAT LEARNI; Imagawa K, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P462, DOI 10.1109/AFGR.1998.670991; Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198; Kim EC, 1998, J AM ETHNIC HIST, V17, P76; Kjeldsen R, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P312, DOI 10.1109/AFGR.1996.557283; LIU X, 2002, P IEEE INT VEH S; Oliver N, 1997, PROC CVPR IEEE, P123, DOI 10.1109/CVPR.1997.609309; Raja Y, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P228, DOI 10.1109/AFGR.1998.670953; Rosales R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P378, DOI 10.1109/ICCV.2001.937543; Saxe D, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P379, DOI 10.1109/AFGR.1996.557295; Schwerdt K., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P90, DOI 10.1109/AFGR.2000.840617; Sigal L, 2000, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2000.854764; SINGH S, 1997, VISION BASED DETECTI; Smith P., 2000, P INT C PATT REC; Soriano M, 2000, INT C PATT RECOG, P839, DOI 10.1109/ICPR.2000.905542; Storring M., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P64, DOI 10.1109/AFGR.2000.840613; STORRING M, 1999, P 7 S INT ROB SYST, P187; Terrillon J.-C., 1999, Proceedings Vision Interface '99, P180; Terrillon JC, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P112, DOI 10.1109/AFGR.1998.670934; TERRILLON JC, 2001, P INT C QUAL CONTR A, V2, P409; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; WU Y, 1999, P IEEE C COMP VIS PA, V1, P133; YANG J, 1998, P ACCV 98, V2, P687; Yang MH, 1998, PROC SPIE, V3656, P458, DOI 10.1117/12.333865; Yang MH, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P127, DOI 10.1109/ICIP.1998.723442; ZHU X, 2000, P 4 INT C AUT FAC GE, P446	33	169	183	2	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2004	26	7					862	877		10.1109/TPAMI.2004.35	http://dx.doi.org/10.1109/TPAMI.2004.35			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	819OG	18579945				2022-12-18	WOS:000221323900004
J	VANDENBRANDE, JH; REQUICHA, AAG				VANDENBRANDE, JH; REQUICHA, AAG			SPATIAL REASONING FOR THE AUTOMATIC RECOGNITION OF MACHINABLE FEATURES IN SOLID MODELS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						FEATURE RECOGNITION; CAD CAM; SPATIAL REASONING; PROCESS PLANNING; SOLID MODELING; VOLUME DECOMPOSITION		The generation of correct and efficient plans for machining mechanical components requires the identification of features such as holes, slots and pockets, which are associated with distinctive manufacturing processes. This paper discusses an automatic feature recognizer that extends the state of the art in several directions. The recognizer decomposes the total volume to be machined into volumetric (i.e., solid) features that satisfy stringent conditions for manufacturability, and correspond to operations typically performed in 3-axis machining centers. Unlike most of the previous research, our approach is based on general techniques for dealing with features with intersecting volumes. Feature interactions are represented explicitly in the recognizer's output, to facilitate spatial reasoning in subsequent planning stages. The feature finder's architecture combines partial evidence from various sources such as nominal surface geometry, tolerances, attributes (e.g., threads), and design form features. A generate-and-test strategy is used. OPS-5 production rules generate hints or clues for the existence of features, and post them on a blackboard. The clues are assessed, and those judged promising are processed to ensure that they correspond to actual features, and to gather information for process planning. An incompletely-specified solid feature, represented as a partially-filled frame, is associated with each promising hint. Computational geometry techniques are used to produce the largest volumetric feature compatible with the available data. The feature's accessibility, and its interactions with others are analyzed. Interactions are represented by segmenting the feature into ''optional'' and ''required'' volumes. Because some of the proposed features may rely on faulty hints, these are tested for validity in a verification phase. The validity tests ensure that the proposed features are accessible, do not intrude into the desired part, and satisfy other machinability conditions. The process continues until it produces a complete decomposition of the volume to be machined into fully-specified features. The recognizer is implemented in a rapid prototyping test bed consisting of the KnowledgeCraft(TM) environment tightly coupled with the PADL-2 solid modeler, and running on Sun workstations.	UNIV SO CALIF,DEPT COMP SCI,LOS ANGELES,CA 90089; UNIV SO CALIF,INST ROBOT & INTELLIGENT SYST,LOS ANGELES,CA 90089	University of Southern California; University of Southern California								BROWN CM, 1982, IEEE COMPUT GRAPH, V2, P68; DEFLORIANI L, 1989, IEEE T PATTERN ANAL, V11, P785, DOI 10.1109/34.31442; Ernst G, 1969, GPS CASE STUDY GEN P; Gadh R., 1991, Manufacturing Review, V4, P115; HAYESROTH B, 1985, ARTIF INTELL, V26, P251, DOI 10.1016/0004-3702(85)90063-3; HENDERSON MR, 1984, THESIS PURDUE U W LA; HUMMEL KE, 1989, JUL P ASME INT COMP, V1, P409; KYPRIANOU LK, 1980, THESIS KINGS COLLEGE; MAREFAT M, 1990, IEEE T PATTERN ANAL, V12, P949, DOI 10.1109/34.58868; NII HP, 1986, AI MAG, V7, P38; PINILLA JM, 1989, JUN NSF ENG DES RES, P285; Requicha A. G., 1980, ACM COMPUT SURV, P437; REQUICHA AAG, 1985, P IEEE, V73, P30, DOI 10.1109/PROC.1985.13108; SAKURAI H, 1988, JUL P ASME INT COMP, V1, P515; SPYRIDI AJ, 1990, MAY P IEEE INT C ROB, P1284; SPYRIDI AJ, 1991, ENG SYSTEMS INTELLIG, P317; TILOVE RB, 1980, IEEE T COMPUT, V29, P874, DOI 10.1109/TC.1980.1675470; VANDENBRANDE JH, 1990, THESIS U ROCHESTER; [No title captured]	19	169	193	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1993	15	12					1269	1285		10.1109/34.250845	http://dx.doi.org/10.1109/34.250845			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MP176					2022-12-18	WOS:A1993MP17600005
J	BROOKS, RA				BROOKS, RA			MODEL-BASED 3-DIMENSIONAL INTERPRETATIONS OF TWO-DIMENSIONAL IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									STANFORD UNIV,STANFORD ARTIFICIAL INTELLIGENCE LAB,STANFORD,CA 94305	Stanford University								BAKER HH, 1981, 7TH P INT JOINT C AR, P631; BINFORD T, 1971, DEC IEEE SYST SCI CY; BINFORD TO, 1979, SEP P NSF GRANT C IN; BLEDSOE WW, 1974, DEP MATH COMPUT SCI, V18; Bobrow DG., 1977, COGNITIVE SCI, V1, P3, DOI [DOI 10.1207/S15516709C0G0101_, 10.1207/s15516709cog0101_2, DOI 10.1207/S15516709COG0101_2]; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; BROOKS RA, AIM343 DEP COMP SCI; BROOKS RA, 1979, AUG P IJCAI, P105; BROOKS RA, 1979, APR P DARPA IM UND W, P72; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; SHOSTAK RE, 1977, J ACM, V24, P529, DOI 10.1145/322033.322034; SOROKA BI, 1980, NOV AUT W C SOC MAN	12	169	180	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	2					140	150		10.1109/TPAMI.1983.4767366	http://dx.doi.org/10.1109/TPAMI.1983.4767366			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QJ974	21869095				2022-12-18	WOS:A1983QJ97400002
J	Chen, XZ; Kundu, K; Zhu, YK; Ma, HM; Fidler, S; Urtasun, R				Chen, Xiaozhi; Kundu, Kaustav; Zhu, Yukun; Ma, Huimin; Fidler, Sanja; Urtasun, Raquel			3D Object Proposals Using Stereo Imagery for Accurate Object Class Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object proposals; 3D object detection; convolutional neural networks; autonomous driving; stereo; LIDAR	MULTIVIEW	The goal of this paper is to perform 3D object detection in the context of autonomous driving. Our method aims at generating a set of high-quality 3D object proposals by exploiting stereo imagery. We formulate the problem as minimizing an energy function that encodes object size priors, placement of objects on the ground plane as well as several depth informed features that reason about free space, point cloud densities and distance to the ground. We then exploit a CNN on top of these proposals to perform object detection. In particular, we employ a convolutional neural net (CNN) that exploits context and depth information to jointly regress to 3D bounding box coordinates and object pose. Our experiments show significant performance gains over existing RGB and RGB-D object proposal methods on the challenging KITTI benchmark. When combined with the CNN, our approach outperforms all existing results in object detection and orientation estimation tasks for all three KITTI object classes. Furthermore, we experiment also with the setting where LIDAR information is available, and show that using both LIDAR and stereo leads to the best result.	[Chen, Xiaozhi; Ma, Huimin] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China; [Kundu, Kaustav; Zhu, Yukun; Fidler, Sanja; Urtasun, Raquel] Univ Toronto, Dept Comp Sci, Toronto, ON M5S, Canada	Tsinghua University; University of Toronto	Ma, HM (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.	chenxz12@mails.tsinghua.edu.cn; kkundu@cs.toronto.edu; yukun@cs.toronto.edu; mhmpub@tsinghua.edu.cn; fidler@cs.toronto.edu; rurtasun@ttic.edu			NSFC [61171113]; NBRPC [2016YFB0100900]; NSERC; Toyota Motor Corporation;  [ONR-N00014-14-1-0232]	NSFC(National Natural Science Foundation of China (NSFC)); NBRPC(National Basic Research Program of China); NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC)); Toyota Motor Corporation; 	The work was partially supported by NSFC 61171113, NBRPC 2016YFB0100900, NSERC, ONR-N00014-14-1-0232 and Toyota Motor Corporation. We would like to thank NVIDIA for supporting our research by donating GPUs. Xiaozhi Chen and Kaustav Kundu are equal contribution.	Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Banica D., 2013, ARXIV13127715; Behley J, 2013, IEEE INT C INT ROBOT, P4195, DOI 10.1109/IROS.2013.6696957; Cai ZW, 2015, IEEE I CONF COMP VIS, P3361, DOI 10.1109/ICCV.2015.384; Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Chen XZ, 2015, ADV NEUR IN, V28; Chen XZ, 2015, PROC CVPR IEEE, P2587, DOI 10.1109/CVPR.2015.7298874; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Erhan D., 2007, INT J COMPUT VISION, V88, P303; Fidler S, 2013, PROC CVPR IEEE, P3294, DOI 10.1109/CVPR.2013.423; Fragkiadaki K, 2015, PROC CVPR IEEE, P4083, DOI 10.1109/CVPR.2015.7299035; Geiger A., 2011, ADV NEURAL INFORM PR, VVol. 24, P1467; Geiger A., 2012, P IEEE COMP SOC C CO; Ghodrati A, 2015, IEEE I CONF COMP VIS, P2578, DOI 10.1109/ICCV.2015.296; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gonzalez A, 2015, IEEE INT VEH SYM, P356, DOI 10.1109/IVS.2015.7225711; Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23; Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908; Hosang J, 2015, PROC CVPR IEEE, P4073, DOI 10.1109/CVPR.2015.7299034; Hu QC, 2016, IEEE T INTELL TRANSP, V17, P1002, DOI 10.1109/TITS.2015.2496795; Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]; Karpathy A, 2013, IEEE INT CONF ROBOT, P2088, DOI 10.1109/ICRA.2013.6630857; Krahenbuhl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47; Krahenbuhl P, 2015, PROC CVPR IEEE, P1574, DOI 10.1109/CVPR.2015.7298765; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lee T, 2015, IEEE I CONF COMP VIS, P1680, DOI 10.1109/ICCV.2015.196; Li B, 2016, ROBOTICS: SCIENCE AND SYSTEMS XII; Li B, 2014, LECT NOTES COMPUT SC, V8694, P652, DOI 10.1007/978-3-319-10599-4_42; Lin DH, 2013, IEEE I CONF COMP VIS, P1417, DOI 10.1109/ICCV.2013.179; Long C., 2014, P AS C COMP VIS, P260; Manen S, 2013, IEEE I CONF COMP VIS, P2536, DOI 10.1109/ICCV.2013.315; Ohn-Bar E, 2015, IEEE T INTELL TRANSP, V16, P2511, DOI 10.1109/TITS.2015.2409889; Oneata D, 2014, LECT NOTES COMPUT SC, V8691, P737, DOI 10.1007/978-3-319-10578-9_48; Paisitkriangi S., 2014, ARXIV14095209; Pepik B, 2015, IEEE T PATTERN ANAL, V37, P2232, DOI 10.1109/TPAMI.2015.2408347; Pepikj Bojan, 2013, PROC CVPR IEEE, P3286, DOI DOI 10.1109/CVPR.2013.422; Plotkin L., 2015, THESIS; Premebida C, 2014, IEEE INT C INT ROBOT, P4112, DOI 10.1109/IROS.2014.6943141; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Schwing AG, 2013, IEEE I CONF COMP VIS, P353, DOI 10.1109/ICCV.2013.51; Song SR, 2014, LECT NOTES COMPUT SC, V8694, P634, DOI 10.1007/978-3-319-10599-4_41; Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221; Tsochantaridis Ioannis, 2004, P 21 INT C MACH LEAR; van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456; Wang DL, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI; Wang SL, 2015, PROC CVPR IEEE, P3964, DOI 10.1109/CVPR.2015.7299022; Xiang Y, 2015, PROC CVPR IEEE, P1903, DOI 10.1109/CVPR.2015.7298800; Xu J., 2014, ARXIV14085400; Yamaguchi K, 2014, LECT NOTES COMPUT SC, V8693, P756, DOI 10.1007/978-3-319-10602-1_49; ZHANG SS, 2015, PROC CVPR IEEE, P1751, DOI DOI 10.1109/CVPR.2015.7298784; Zhang Z., 2015, ARXIV151104511; Zhu Y, 2015, PROC CVPR IEEE, P4703, DOI 10.1109/CVPR.2015.7299102; Zia MZ, 2015, INT J COMPUT VISION, V112, P188, DOI 10.1007/s11263-014-0780-y; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	61	168	179	10	81	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2018	40	5					1259	1272		10.1109/TPAMI.2017.2706685	http://dx.doi.org/10.1109/TPAMI.2017.2706685			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GB2RB	28541196	Green Submitted			2022-12-18	WOS:000428901200018
J	Trigeorgis, G; Bousmalis, K; Zafeiriou, S; Schuller, BW				Trigeorgis, George; Bousmalis, Konstantinos; Zafeiriou, Stefanos; Schuller, Bjorn W.			A Deep Matrix Factorization Method for Learning Attribute Representations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semi-NMF; deep semi-NMF; unsupervised feature learning; face clustering; semi-supervised learning; Deep WSF; WSF; matrix factorization; face classification	NONNEGATIVE MATRIX; DIMENSIONALITY; RECOGNITION; ALGORITHMS; POSE	Semi-Non-negative Matrix Factorization is a technique that learns a low-dimensional representation of a dataset that lends itself to a clustering interpretation. It is possible that the mapping between this new representation and our original data matrix contains rather complex hierarchical information with implicit lower-level hidden attributes, that classical one level clustering methodologies cannot interpret. In this work we propose a novel model, Deep Semi-NMF, that is able to learn such hidden representations that allow themselves to an interpretation of clustering according to different, unknown attributes of a given dataset. We also present a semi-supervised version of the algorithm, named Deep WSF, that allows the use of (partial) prior information for each of the known attributes of a dataset, that allows the model to be used on datasets with mixed attribute knowledge. Finally, we show that our models are able to learn low-dimensional representations that are better suited for clustering, but also classification, outperforming Semi-Non-negative Matrix Factorization, but also other state-of-the-art methodologies variants.	[Trigeorgis, George; Zafeiriou, Stefanos; Schuller, Bjorn W.] Imperial Coll London, Dept Comp, London SW7 2RH, England; [Bousmalis, Konstantinos] Google Res, Mountain View, CA 94043 USA	Imperial College London; Google Incorporated	Trigeorgis, G (corresponding author), Imperial Coll London, Dept Comp, London SW7 2RH, England.	gt108@ic.ac.uk; konstantinos@google.com; s.zafeiriou@imperial.ac.uk; bjoern.schuller@imperial.ac.uk	Trigeorgis, George/Y-8208-2019	Schuller, Bjorn/0000-0002-6478-8699	Department of Computing, Imperial College London; Google Europe Fellowship in Social Signal Processing; EPSRC [EP/J017787/1]; European Community [645378]; EPSRC [EP/N007743/1, EP/H016988/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [EP/N007743/1, EP/H016988/1, EP/J017787/1] Funding Source: researchfish	Department of Computing, Imperial College London; Google Europe Fellowship in Social Signal Processing(Google Incorporated); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); European Community(European Commission); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	George Trigeorgis is a recipient of the fellowship of the Department of Computing, Imperial College London, and this work was partially funded by it. The work of Konstantinos Bousmalis was funded partially from the Google Europe Fellowship in Social Signal Processing. The work of Stefanos Zafeiriou was partially funded by the EPSRC project EP/J017787/1 (4D-FAB). The work of Bjorn W. Schuller was partially funded by the European Community's Horizon 2020 Framework Programme under grant agreement No. 645378 (ARIA-VALUSPA). The responsibility lies with the authors.	Ahn J.-H., 2004, P 21 INT C MACH LEAR, P3; Ba J., 2015, ICLR; Belkin M, 2002, ADV NEUR IN, V14, P585; Belkin M., 2002, P ADV NEUR INF PROC, P328; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024; Berry M. W., 2005, Computational & Mathematical Organization Theory, V11, P249, DOI 10.1007/s10588-005-5380-5; Boutsidis C, 2008, PATTERN RECOGN, V41, P1350, DOI 10.1016/j.patcog.2007.09.010; Brunet JP, 2004, P NATL ACAD SCI USA, V101, P4164, DOI 10.1073/pnas.0308531101; Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231; Cichocki A, 2006, ELECTRON LETT, V42, P947, DOI 10.1049/el:20060983; Cvetkovic D. M., 1980, SPECTRA GRAPHS THEOR, V413; Devarajan K, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000029; Ding C, 2005, SIAM PROC S, P606; Ding C, 2010, IEEE T PATTERN ANAL, V32, P45, DOI 10.1109/TPAMI.2008.277; Gillis N, 2015, SIAM J MATRIX ANAL A, V36, P1404, DOI 10.1137/140993272; GOLUB GH, 1970, NUMER MATH, V14, P403, DOI 10.1007/BF02163027; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Guan NY, 2012, IEEE T SIGNAL PROCES, V60, P2882, DOI 10.1109/TSP.2012.2190406; Hao Y., 2013, P 2012 INT C INFORM, P1; Herrero J, 2001, BIOINFORMATICS, V17, P126, DOI 10.1093/bioinformatics/17.2.126; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Kotsia I, 2007, IEEE T INF FOREN SEC, V2, P588, DOI 10.1109/TIFS.2007.902017; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2; Lee DD, 2001, ADV NEUR IN, V13, P556; Lei Z., 2014, LEARNING FACE REPRES; Li M, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P661, DOI 10.1145/2623330.2623612; Li SZ, 2001, PROC CVPR IEEE, P207; Liu HF, 2012, IEEE T PATTERN ANAL, V34, P1299, DOI 10.1109/TPAMI.2011.217; Malo J, 2006, IEEE T IMAGE PROCESS, V15, P68, DOI 10.1109/TIP.2005.860325; Messer K., 2005, P 2 INT C AUD VID BA, VVolume 964, P965; Nesterov Y, 2013, MATH PROGRAM, V140, P125, DOI 10.1007/s10107-012-0629-5; PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203; Prince SJD, 2008, IEEE T PATTERN ANAL, V30, P970, DOI 10.1109/TPAMI.2008.48; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819; Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59; Sagonas C, 2013, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2013.132; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Song H. A., 2013, P INT C LEARN REPR; Trigeorgis G, 2014, PR MACH LEARN RES, V32, P1692; Tsoumakas G., 2007, INT J DATA WAREHOUS, V3, P1; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wang, 2013, ADV NEURAL INFORM PR, P602; Weninger F, 2012, J SIGNAL PROCESS SYS, V69, P267, DOI 10.1007/s11265-012-0673-7; WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9; Xu W., 2003, P 26 ANN INT ACM SIG, P267, DOI DOI 10.1145/860435.860485; Zafeiriou S, 2006, IEEE T NEURAL NETWOR, V17, P683, DOI 10.1109/TNN.2006.873291; Zafeiriou S, 2009, ADV PATTERN RECOGNIT, P105, DOI 10.1007/978-1-84882-299-3_5; Zafeiriou S, 2009, IEEE T NEURAL NETWOR, V20, P217, DOI 10.1109/TNN.2008.2005293; Zhang Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1839490.1839495; Zhao Y, 2005, DATA MIN KNOWL DISC, V10, P141, DOI 10.1007/s10618-005-0361-3	53	168	174	5	74	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	3					417	429		10.1109/TPAMI.2016.2554555	http://dx.doi.org/10.1109/TPAMI.2016.2554555			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8IP	28113886	Green Submitted			2022-12-18	WOS:000395555100001
J	Huang, YZ; Wu, ZF; Wang, L; Tan, T				Huang, Yongzhen; Wu, Zifeng; Wang, Liang; Tan, Tieniu			Feature Coding in Image Classification: A Comprehensive Study	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image classification; feature coding; bag-of-features	TEXTURE	Image classification is a hot topic in computer vision and pattern recognition. Feature coding, as a key component of image classification, has been widely studied over the past several years, and a number of coding algorithms have been proposed. However, there is no comprehensive study concerning the connections between different coding methods, especially how they have evolved. In this paper, we first make a survey on various feature coding methods, including their motivations and mathematical representations, and then exploit their relations, based on which a taxonomy is proposed to reveal their evolution. Further, we summarize the main characteristics of current algorithms, each of which is shared by several coding strategies. Finally, we choose several representatives from different kinds of coding approaches and empirically evaluate them with respect to the size of the codebook and the number of training samples on several widely used databases (15-Scenes, Caltech-256, PASCAL VOC07, and SUN397). Experimental findings firmly justify our theoretical analysis, which is expected to benefit both practical applications and future research.	[Huang, Yongzhen; Wu, Zifeng; Wang, Liang; Tan, Tieniu] Chinese Acad Sci CASIA, Inst Automat, Natl Lab Pattern Recognit NLPR, CRIPAC, 95 ZhongGuanCun East St, Beijing 100190, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS	Huang, YZ (corresponding author), Chinese Acad Sci CASIA, Inst Automat, Natl Lab Pattern Recognit NLPR, CRIPAC, 95 ZhongGuanCun East St, Beijing 100190, Peoples R China.	yzhuang@nlpr.ia.ac.cn; zfwu@nlpr.ia.ac.cn; wangliang@nlpr.ia.ac.cn; tnt@nlpr.ia.ac.cn		Wang, Yunlong/0000-0002-3535-308X	National Natural Science Foundation of China [61135002, 61203252]; National Basic Research Program of China [2012CB316300]; Tsinghua National Laboratory for Information Science and Technology Cross-discipline Foundation; Hundred Talents Program of CAS	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China(National Basic Research Program of China); Tsinghua National Laboratory for Information Science and Technology Cross-discipline Foundation; Hundred Talents Program of CAS(Chinese Academy of Sciences)	This work was jointly supported by the National Natural Science Foundation of China (61135002, 61203252) and the National Basic Research Program of China (2012CB316300), Tsinghua National Laboratory for Information Science and Technology Cross-discipline Foundation, and Hundred Talents Program of CAS. The source code of all coding algorithms and experimental figures in this paper have been released on http://nlpr-web.ia.ac.cn/english/irds/people/yzhuang.html.	[Anonymous], 2010, P IEEE C COMP VIS PA; Boureau Y., 2010, P IEEE C COMP VIS PA; Boureau Y.-L, 2010, P 27 INT C MACH LEAR; Bradley D. M., 2008, P ADV NEUR INF PROC; Cao L., 2012, P IEEE C COMP VIS PA; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Cinbis R.G., 2012, P IEEE C COMP VIS PA; Csurka Gabriella, 2004, P ECCV INT WORKSH ST; Dalal N., 2005, HISTOGRAMS ORIENTED; Feng J., 2011, P IEEE C COMP VIS PA; Gao SH, 2011, PROC CVPR IEEE; Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943; Gemert J., 2008, P 10 EUR C COMP VI 3; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Huang Y., 2011, P IEEE C COMP VIS PA; Jaakkola T., 1999, P C ADV NEUR INF PRO; Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349; Jegou H., 2010, P IEEE C COMP VIS PA; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Jia Y., 2012, P IEEE C COMP VIS PA; Jiang Z., 2012, P IEEE C COMP VIS PA; Joachims Thorsten, 2006, P 10 EUR C MACH LEAR; Kanade T., 2000, CMURITR0012; Kosala Raymond, 2000, SIGKDD EXPLORATIONS, V2, P1, DOI DOI 10.1145/360402.360406; Lazebnik S., 2006, P IEEE C COMP VIS PA; Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mairal J., 2008, P ADV NEUR INF PROC; MARSZALEK M, 2007, P VIS REC CHALL WORK; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; Mclachlan G., 2000, WILEY SER PROB STAT; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Naveen K., 2011, P IEEE C COMP VIS PA; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226; Perronnin F, 2007, P IEEE C COMP VIS PA; Perronnin F., 2010, P IEEE C COMP VIS PA; Perronnin F., 2010, P 11 EUR C COMP VI 4; Picard D., 2011, P 18 IEEE INT C IM P; Shabou A., 2012, P IEEE C COMP VIS PA; Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8; Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448; van Gemert J., 2008, P 10 EUR C COMP VI 3; van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132; Wu Z., 2012, P 21 INT C PATT REC; Xiao J, 2010, P IEEE C COMP VIS PA; Yang J., 2010, P IEEE C COMP VIS PA; Yang J., 2010, P 11 EUR C COMP V 5; Yang J., 2009, P IEEE C COMP VIS PA; Yu K., 2011, P IEEE C COMP VIS PA; Yu K., 2010, P INT C MACH LEARN I; Yu K., 2009, P ADV NEURAL INFORM; Zhang C., 2011, P IEEE C COMP VIS PA; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhou X., 2010, P 11 EUR C COMP VI 5	56	168	184	0	78	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2014	36	3					493	506		10.1109/TPAMI.2013.113	http://dx.doi.org/10.1109/TPAMI.2013.113			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AA9YX	24457506				2022-12-18	WOS:000331450100008
J	Suo, JL; Zhu, SC; Shan, SG; Chen, XL				Suo, Jinli; Zhu, Song-Chun; Shan, Shiguang; Chen, Xilin			A Compositional and Dynamic Model for Face Aging	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face aging modeling; face age estimation; generative model; And-Or graph; ANOVA	HUMAN AGE ESTIMATION; SHAPE	In this paper, we present a compositional and dynamic model for face aging. The compositional model represents faces in each age group by a hierarchical And-Or graph, in which And nodes decompose a face into parts to describe details (e. g., hair, wrinkles, etc.) crucial for age perception and Or nodes represent large diversity of faces by alternative selections. Then a face instance is a transverse of the And-Or graph-parse graph. Face aging is modeled as a Markov process on the parse graph representation. We learn the parameters of the dynamic model from a large annotated face data set and the stochasticity of face aging is modeled in the dynamics explicitly. Based on this model, we propose a face aging simulation and prediction algorithm. Inversely, an automatic age estimation algorithm is also developed under this representation. We study two criteria to evaluate the aging results using human perception experiments: 1) the accuracy of simulation: whether the aged faces are perceived of the intended age group, and 2) preservation of identity: whether the aged faces are perceived as the same person. Quantitative statistical analysis validates the performance of our aging model and age estimation algorithm.	[Suo, Jinli] Chinese Acad Sci, Grad Univ, Beijing 100080, Peoples R China; [Zhu, Song-Chun] Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA; [Zhu, Song-Chun] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA; [Shan, Shiguang; Chen, Xilin] Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, Beijing 100190, Peoples R China	Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; University of California System; University of California Los Angeles; University of California System; University of California Los Angeles; Chinese Academy of Sciences; Institute of Computing Technology, CAS	Suo, JL (corresponding author), Chinese Acad Sci, Grad Univ, Room 753,ICT Bldg,6 Kexueyuannanlu Rd, Beijing 100080, Peoples R China.	jlsuo@jdl.ac.cn; sczhu@stat.ucla.edu; sgshan@ict.ac.cn; xlchen@ict.ac.cn		Shan, Shiguang/0000-0002-8348-392X	NSFC [60672162, 60728203]; 863 programs [2006AA01Z121, 2007AA01Z340]	NSFC(National Natural Science Foundation of China (NSFC)); 863 programs(National High Technology Research and Development Program of China)	This work is done at the Lotus Hill Institute and the data used in this paper were provided by the Lotus Hill Annotation project [47]. This project is supported by grants from NSFC China under contract No. 60672162, No. 60728203 and two 863 programs No. 2006AA01Z121 and No. 2007AA01Z340.	Albert AM, 2007, FORENSIC SCI INT, V172, P1, DOI 10.1016/j.forsciint.2007.03.015; Bando Y, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P166, DOI 10.1109/PCCGA.2002.1167852; Behrents RG, 1985, ATLAS GROWTH AGING C; Berg AC, 2003, IEEE INFOR VIS, P164, DOI 10.1109/IV.2003.1217974; Berg AC, 2006, INFORMATION VISUALIZATION-BOOK, P791; Boissieux L, 2000, SPRING COMP SCI, P15; BURT DM, 1995, P ROY SOC B-BIOL SCI, V259, P137, DOI 10.1098/rspb.1995.0021; Chen H, 2006, IEEE T PATTERN ANAL, V28, P1025, DOI 10.1109/TPAMI.2006.131; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; DECARLO D, 1998, P SIGGRAPH 98, P67, DOI DOI 10.1145/280814.280823; Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847; Fu Y, 2006, IEEE T CIRC SYST VID, V16, P830, DOI 10.1109/TCSVT.2006.877398; Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733; Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280; Haibin Ling, 2007, 2007 11th IEEE International Conference on Computer Vision, P1; HILL CM, 2005, P IEE INT S IM CRIM, P89; Hutton TJ, 2003, IEEE T MED IMAGING, V22, P747, DOI 10.1109/TMI.2003.814784; Jiang FY, 2008, IEEE IMAGE PROC, P1648, DOI 10.1109/ICIP.2008.4712088; Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549; Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091; Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553; LANITIS A, 2008, P 8 INT C AUT FAC GE; Lanitis A, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/239480; Lee WS, 1999, P IEEE VIRT REAL ANN, P61, DOI 10.1109/VR.1999.756924; Leta F.R., 1996, P 9 BRAZ S COMP GRAP, P167; Liu ZC, 2004, IEEE COMPUT GRAPH, V24, P30, DOI 10.1109/MCG.2004.1297008; Mukaida S., 2002, Proceedings of Second IASTED International Conference Visualization, Imaging, and Image Processing, P12; PARK U, 2008, P 8 INT C AUT FAC GE; Patterson E., 2006, P 6 IASTED INT C VIS, P612; Perez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269; RAMANATHAN N, 2008, P 8 INT C AUT FAC GE; RAMANATHAN N, 2006, P IEEE C COMP VIS PA, V1, P387; Ramanathan N, 2006, IEEE T IMAGE PROCESS, V15, P3349, DOI 10.1109/TIP.2006.881993; Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341; Scandrett CM, 2006, PATTERN RECOGN LETT, V27, P1776, DOI 10.1016/j.patrec.2006.02.007; Singh R, 2007, LECT NOTES COMPUT SC, V4815, P576; SUO J, 2008, P 8 INT C AUT FAC GE; Suo J. L., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383055; TIDDEMAN BP, 2006, P 24 C THEOR PRAC CO, P105; Wang JC, 2004, Proceedings of the World Engineers' Convention 2004: Vol D, Environment Protection and Disaster Mitigation, P499; Wang JY, 2006, INT C PATT RECOG, P913; WU Y, 1995, J VISUAL COMP ANIMAT, V6, P195, DOI 10.1002/vis.4340060403; Xiao Y, 2006, IEEE ICC, P955; Xu ZH, 2008, FOREIGN LIT STUD, V30, P6; Yan S., 2007, P IEEE INT C COMP VI, P1; Zimbler M S, 2001, Facial Plast Surg Clin North Am, V9, P179; 2008, FACE GESTURE RECOGNI; [No title captured]	49	168	183	1	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2010	32	3					385	401		10.1109/TPAMI.2009.39	http://dx.doi.org/10.1109/TPAMI.2009.39			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	543WG	20075467	Green Submitted			2022-12-18	WOS:000273609600001
J	Ferrer, MA; Alonso, JB; Travieso, CM				Ferrer, MA; Alonso, JB; Travieso, CM			Offline geometric parameters for automatic signature verification using fixed-point arithmetic	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						automatic signature verification (ASV); hidden Markov models (HMM); support vector machines (SVM); fixed-point arithmetic	HANDWRITTEN SIGNATURES; RECOGNITION	This paper presents a set of geometric signature features for offline automatic signature verification based on the description of the signature envelope and the interior stroke distribution in polar and Cartesian coordinates. The features have been calculated using 16 bits fixed-point arithmetic and tested with different classifiers, such as hidden Markov models, support vector machines, and Euclidean distance classifier. The experiments have shown promising results in the task of discriminating random and simple forgeries.	Univ Las Palmas Gran Canaria, Dept Senales & Comunicac, E-35017 Las Palmas Gran Canaria, Spain	Universidad de Las Palmas de Gran Canaria	Ferrer, MA (corresponding author), Univ Las Palmas Gran Canaria, Dept Senales & Comunicac, Campus Tafira, E-35017 Las Palmas Gran Canaria, Spain.	mferrer@dsc.ulpgc.es; jalonso@dsc.ulpgc.es; ctravieso@dsc.ulpgc.es	Travieso-González, Carlos M./N-5967-2014; Ferrer, Miguel/AFU-8286-2022; Ferrer, Miguel A A/L-3863-2013; Alonso, Jesus/N-5977-2014	Travieso-González, Carlos M./0000-0002-4621-2768; Ferrer, Miguel A A/0000-0002-2924-1225; Alonso, Jesus/0000-0002-7866-585X				Anguita D, 2003, IEEE T NEURAL NETWOR, V14, P993, DOI 10.1109/TNN.2003.816033; BRAULT JJ, 1993, IEEE T PATTERN ANAL, V15, P953, DOI 10.1109/34.232079; Davis LE, 2004, J ANIM FEED SCI, V13, P479, DOI 10.22358/jafs/73970/2004; Fairhurst MC, 2003, IEE P-VIS IMAGE SIGN, V150, P389, DOI 10.1049/ip-vis:20031046; Ferrer MA, 2000, ELECTRON LETT, V36, P1165, DOI 10.1049/el:20000826; FUENTES M, 2002, P 8 INT WORKSH FRONT, P253; Hernando J, 1997, SPEECH COMMUN, V21, P17, DOI 10.1016/S0167-6393(96)00074-X; JUSTINO E, 2001, 6 INT C DOC AN REC, P1031; Justino EJR, 2002, SIBGRAPI 2002: XV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P197, DOI 10.1109/SIBGRA.2002.1167143; JUSTINO EJR, 2000, P 4 INT WORKSH DOC A, P211; Leclerc F., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P643, DOI 10.1142/S0218001494000346; MARTINEZ LE, 2004, P 38 IEEE INT CARN C, P193; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; PLAMONDON R, 1995, P EUR CONV SEC DET 1, P23; Rabiner L., 1993, FUNDAMENTALS SPEECH; ROSS A, 2004, P 12 EUR SIGN PROC C, P1221; XIAOLIN L, 2000, IEEE T PATTERN ANAL, V22, P371; ZIMMER A, 2003, P 7 INT C DOC AN REC, V1, P424	19	168	174	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2005	27	6					993	997		10.1109/TPAMI.2005.125	http://dx.doi.org/10.1109/TPAMI.2005.125			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	915TR	15943430				2022-12-18	WOS:000228334700014
J	Rosin, PL				Rosin, PL			Techniques for assessing polygonal approximations of curves	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						polygonal approximation; assessment; optimal breakpoints; dynamic programming	PIECEWISE LINEAR-APPROXIMATION; CHAIN-CODED CURVES; DOMINANT POINT DETECTION; PLANAR CURVES; CORNER DETECTION; DIGITAL CURVES; DIGITIZED-CURVES; ALGORITHM; SEGMENTATION; SHAPE	Given the enormous number of available methods for finding polygonal approximations to curves techniques are required to assess different algorithms. Some of the standard approaches are shown to be unsuitable if the approximations contain varying numbers of lines. Instead, we suggest assessing an algorithm's results relative to an optimal polygon, and describe a measure which combines the relative fidelity and efficiency of a curve segmentation. We use this measure to compare the application of 23 algorithms to a curve first used by Teh and Chin [37]; their ISEs are assessed relative to the optimal ISE. In addition, using an example of pose estimation, it is shown how goal-directed evaluation can be used to select an appropriate assessment criterion.			Rosin, PL (corresponding author), BRUNEL UNIV,DEPT COMP SCI & INFORMAT SYST,UXBRIDGE UB8 3PH,MIDDX,ENGLAND.							ABE K, 1993, INT C DOC AN REC, P954; ANDERSON IM, 1984, IEEE T PATTERN ANAL, V6, P27, DOI 10.1109/TPAMI.1984.4767472; ANSARI N, 1991, PATTERN RECOGN, V24, P849, DOI 10.1016/0031-3203(91)90004-O; AOYAMA H, 1991, CVGIP-GRAPH MODEL IM, V53, P435, DOI 10.1016/1049-9652(91)90028-I; ARCELLI C, 1993, PATTERN RECOGN, V26, P1563, DOI 10.1016/0031-3203(93)90161-O; BANERJEE S, 1996, 10007 RJ IBM RES DIV; CHUNG PC, 1994, PATTERN RECOGN, V27, P1505, DOI 10.1016/0031-3203(94)90128-7; DEGUCHI A, 1990, INT C PATT REC, V1, P865; DOUGLAS DH, 1973, CANADIAN CARTOGRAPHE, V10, P111; DUNHAM JG, 1986, IEEE T PATTERN ANAL, V8, P67, DOI 10.1109/TPAMI.1986.4767753; FISCHLER MA, 1994, IEEE T PATTERN ANAL, V16, P113, DOI 10.1109/34.273737; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; GRITZALI F, 1983, SIGNAL PROCESS, V5, P221, DOI 10.1016/0165-1684(83)90070-1; HARALICK RM, 1992, PATTERN RECOGN LETT, V13, P5, DOI 10.1016/0167-8655(92)90108-C; HELD A, 1994, IEEE T SYST MAN CYB, V24, P942, DOI 10.1109/21.293514; KADONAGA T, 1995, INT WORKSH GRAPH REC, P3; KANUNGO T, 1995, IEEE T IMAGE PROCESS, V4, P1667, DOI 10.1109/83.475516; KOPLOWITZ J, 1995, PATTERN RECOGN, V28, P843, DOI 10.1016/0031-3203(94)00100-Z; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; MELEN T, 1993, P 5 INT C COMP AN IM; MONTNARI U, 1970, COMMUN ACM, V13, P41, DOI 10.1145/361953.361967; OGAWA H, 1989, PATTERN RECOGN, V22, P351, DOI 10.1016/0031-3203(89)90044-7; PEREZ JC, 1994, PATTERN RECOGN LETT, V15, P743, DOI 10.1016/0167-8655(94)90002-7; PHILLIPS TY, 1987, PATTERN RECOGN LETT, V5, P285, DOI 10.1016/0167-8655(87)90059-6; Ramer U, 1972, COMPUT GRAPH IMAGE P, V1, P244, DOI [DOI 10.1016/S0146-664X(72)80017-0, 10.1016/S0146-664X(72)80017-0]; RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805; RAY BK, 1992, PATTERN RECOGN LETT, V13, P849, DOI 10.1016/0167-8655(92)90084-D; RAY BK, 1992, PATTERN RECOGN, V12, P443; ROSENFELD A, 1975, IEEE T COMPUT, V24, P940, DOI 10.1109/T-C.1975.224342; ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188; ROSIN PL, 1992, PATTERN RECOGN, V25, P1315, DOI 10.1016/0031-3203(92)90144-8; ROSIN PL, 1995, IEEE T PATTERN ANAL, V17, P1140, DOI 10.1109/34.476507; ROSIN PL, 1996, CSTR963 BRUN U; SANKAR PV, 1978, COMPUT VISION GRAPH, V7, P403, DOI 10.1016/S0146-664X(78)80006-9; SARKAR D, 1993, PATTERN RECOGN LETT, V14, P959, DOI 10.1016/0167-8655(93)90004-W; SATO Y, 1992, PATTERN RECOGN, V25, P1535, DOI 10.1016/0031-3203(92)90126-4; TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447; TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P1191, DOI 10.1109/34.476511; VENTURA JA, 1992, PATTERN RECOGN, V25, P1129, DOI 10.1016/0031-3203(92)90016-C; WALL K, 1984, COMPUT VISION GRAPH, V28, P220, DOI 10.1016/S0734-189X(84)80023-7; WILLIAMS CM, 1978, COMPUT VISION GRAPH, V8, P286, DOI 10.1016/0146-664X(78)90055-2; ZHANG X, 1994, INT C PATT RECOG, P549	42	168	176	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1997	19	6					659	666		10.1109/34.601253	http://dx.doi.org/10.1109/34.601253			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XG302					2022-12-18	WOS:A1997XG30200010
J	LI, HB; ROIVAINEN, P; FORCHHEIMER, R				LI, HB; ROIVAINEN, P; FORCHHEIMER, R			3-D MOTION ESTIMATION IN MODEL-BASED FACIAL IMAGE-CODING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ADAPTIVE PREDICTION; ANALYSIS-SYNTHESIS TECHNIQUE; COMPUTER GRAPHICS; COMPUTER VISION; FACIAL IMAGE CODING; FEEDBACK TECHNIQUE; MODEL-BASED IMAGE CODING; MOTION TRACKING; NONRIGID MOTION ESTIMATION; 3-D MODELING	PARAMETERS	This paper addresses the issue of 3-D motion estimation in model-based facial image coding. A new approach to estimating the motion of the head and the facial expressions is presented and has the following characteristics: 1) An affine nonrigid motion model is set up. The specific knowledge about facial shape and facial expression is formulated by this model in the form of parameters. This affine motion model is especially suitable to such a type of nonrigid motion as facial expressions. 2) Based on the affine model, we present a direct method of estimating the two-view motion parameters. Because this method neither necessitates solving the correspondence problem nor computing optical flow, motion parameters can be simply and reliably recovered. 3) Based on the reasonable assumption that the 3-D motion of the face is almost smooth in the time domain, we propose several approaches to predicting the motion of the next frame. In this way, the temporal motion information existing in the image sequence is fully exploited. With a good motion predictor the error arising from the treatment of motion by a linear method will be reduced. 4) Using a 3-D model, the new approach is characterized by a feedback loop connecting computer vision and computer graphics. Embedding the synthesis techniques into the analysis phase greatly improves the performance of motion estimation. Our simulations and experiments with long image sequences of real-world scenes indicate that the method developed in this paper not only greatly reduces computational complexity but also substantially improves estimation accuracy. The synthesized image sequence using the estimated motion parameters, a 3-D model of the face, and a frame of textured image looks very natural.	LINKOPING UNIV,INFORMAT THEORY LAB,S-58183 LINKOPING,SWEDEN	Linkoping University	LI, HB (corresponding author), LINKOPING UNIV,DEPT ELECT ENGN,S-58183 LINKOPING,SWEDEN.							ADVI G, 1989, IEEE T PATTERN ANAL, V11, P477; AGGARWAL JK, 1988, AUG P IEEE, P917; AIZAWA K, 1987, NOV P GLOBECOM 87, P45; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; BUSCH H, 1989, 3RD P IEE INT C IM P; CHEN SS, 1986, COMPUT VISION GRAPH, V36, P175, DOI 10.1016/0734-189X(86)90075-7; Ekman P., 1978, FACIAL ACTION CODING, DOI [10.1037/t27734-000, DOI 10.1037/T27734-000]; FORCHHEIMER R, 1989, IEEE T ACOUST SP DEC, V37; FORCHHEIMER R, 1983, MAR P PICT COD S PCS, P113; FORCHHEIMER R, 1987, JUN P PICT COD S PCS, P171; HJORTSJO CH, 1969, STUDENTLITTERATUR; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1987, 1ST P ICCV; HUANG TS, 1990, 10TH P INT C PATT RE; HUANG TS, 1983, IMAGE SEQUENCE PROCE; Kaneko M., 1991, Journal of Visual Communication and Image Representation, V2, P39, DOI 10.1016/1047-3203(91)90034-D; KAPPEI F, 1987, P SOC PHOTO-OPT INS, V860, P126; LI HB, 1991, LITHISYI1278 LINK U; MAGNENATTHALMAN.N, 1987, IMAGE SYNTHESIS THEO; MUSMANN HG, 1989, IMAGE COMMUN, V1, P117; NETRAVALI AN, 1985, AT T TECHN J, V64; NEWMAN WM, 1973, PRINCIPLES INTERACTI; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P730, DOI 10.1109/34.85661; PERSON DE, 1990, IMAGE COMMUN, V2, P377; ROIVAINEN P, 1990, THESIS LINKOPING U; RYDFALK M, 1987, LITHISYI0866 LINK U; SETHI IK, 1987, IEEE T PATTERN ANAL, V9, P56, DOI 10.1109/TPAMI.1987.4767872; SHULMAN D, 1988, PROC R SOC SER B-BIO, V233, P217, DOI 10.1098/rspb.1988.0020; SOMMERFELD A, 1950, MECHANICS DEFORMABLE; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; TERZOPOULOS D, 1990, 3RD P INT C COMP VIS, P306; TSAI RY, 1981, IEEE T ACOUST SPEECH, V29, P1147, DOI 10.1109/TASSP.1981.1163710; Welsh B., 1991, THESIS BRIT TELECOM; YAU J, 1988, COMPUT GRAPH FORUM, P129	34	168	199	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1993	15	6					545	555		10.1109/34.216724	http://dx.doi.org/10.1109/34.216724			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LF257					2022-12-18	WOS:A1993LF25700003
J	LIU, YC; HUANG, TS; FAUGERAS, OD				LIU, YC; HUANG, TS; FAUGERAS, OD			DETERMINATION OF CAMERA LOCATION FROM 2-D TO 3-D LINE AND POINT CORRESPONDENCES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									INST NATL RECH INFORMAT & AUTOMAT ROQUENCOURT,ROBOT & COMP VIS PROJECT,BP 105,F-78153 LE CHESNAY,FRANCE		LIU, YC (corresponding author), UNIV ILLINOIS,COORDINATED SCI LAB,COMP VIS GRP,1101 W SPRINGFIELD AVE,URBANA,IL 61801, USA.							CHEN HH, 1989, UNPUB MAY IEEE ROB A; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GANAPATHY S, 1984, P INT C ROBOTICS, P130; JUDD PR, 1987, P IEEE INT C ROBOTIC; KELLER M, 1966, ESSA32 US COAST GEOD; LENZ RK, 1988, JUN P COMP VIS PATT, P67; LIU YC, 1988, COMPUT VISION GRAPH, V44, P35, DOI 10.1016/S0734-189X(88)80030-6; LIU YC, 1986, MAY P IEEE WORKSH MO, P47; TSAI R, 1988, APR P INT C ROB AUT; WHITNEY DE, 1986, J DYNAMIC SYST MEAS; Wolf P.R., 1974, ELEMENTS PHOTOGRAMME	11	168	193	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1990	12	1					28	37		10.1109/34.41381	http://dx.doi.org/10.1109/34.41381			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CG247					2022-12-18	WOS:A1990CG24700003
J	Shi, SS; Wang, Z; Shi, JP; Wang, XG; Li, HS				Shi, Shaoshuai; Wang, Zhe; Shi, Jianping; Wang, Xiaogang; Li, Hongsheng			From Points to Parts: 3D Object Detection From Point Cloud With Part-Aware and Part-Aggregation Network	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D object detection; point cloud; part location; LiDAR; convolutional neural network; autonomous driving		3D object detection from LiDAR point cloud is a challenging problem in 3D scene understanding and has many practical applications. In this paper, we extend our preliminary work PointRCNN to a novel and strong point-cloud-based 3D object detection framework, the part-aware and aggregation neural network (Part-A(2) net). The whole framework consists of the part-aware stage and the part-aggregation stage. First, the part-aware stage for the first time fully utilizes free-of-charge part supervisions derived from 3D ground-truth boxes to simultaneously predict high quality 3D proposals and accurate intra-object part locations. The predicted intra-object part locations within the same proposal are grouped by our new-designed RoI-aware point cloud pooling module, which results in an effective representation to encode the geometry-specific features of each 3D proposal. Then the part-aggregation stage learns to re-score the box and refine the box location by exploring the spatial relationship of the pooled intra-object part locations. Extensive experiments are conducted to demonstrate the performance improvements from each component of our proposed framework. Our Part-A(2) net outperforms all existing 3D detection methods and achieves new state-of-the-art on KITTI 3D object detection dataset by utilizing only the LiDAR point cloud data.	[Shi, Shaoshuai; Wang, Xiaogang; Li, Hongsheng] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China; [Wang, Zhe; Shi, Jianping] SenseTime Res, Beijing, Peoples R China	Chinese University of Hong Kong	Li, HS (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.	ssshi@ee.cuhk.edu.hk; wangzhe@sensetime.com; shijianping@sensetime.com; xgwang@ee.cuhk.edu.hk; hsli@ee.cuhk.edu.hk	Wang, Zhe/ABG-6377-2021; Shi, Shaoshuai/AAV-3211-2021	Wang, Zhe/0000-0002-0597-4475; 				Bai M, 2017, PROC CVPR IEEE, P2858, DOI 10.1109/CVPR.2017.305; Brabandere B. D., 2017, CORR; Chabot Florian, 2017, P IEEE C COMP VIS PA, P2040; Chen XZ, 2016, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2016.236; Chen XZ, 2015, ADV NEUR IN, V28; Chen Xiaozhi, 2017, P IEEE C COMP VIS PA, DOI 10.1109/cvpr.2017.691.2017; Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Du XX, 2018, IEEE INT CONF ROBOT, P3194; Fidler S., 2012, P ADV NEURAL INFORM, P611; Geiger A., 2012, P IEEE COMP SOC C CO; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Graham B, 2018, PROC CVPR IEEE, P9224, DOI 10.1109/CVPR.2018.00961; Graham Benjamin, 2017, ARXIV170601307; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; Hou J, 2019, PROC CVPR IEEE, P4416, DOI 10.1109/CVPR.2019.00455; Huang QG, 2018, PROC CVPR IEEE, P2626, DOI 10.1109/CVPR.2018.00278; Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48; Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049; Ku J, 2019, PROC CVPR IEEE, P11859, DOI 10.1109/CVPR.2019.01214; Lahoud J, 2019, IEEE I CONF COMP VIS, P9255, DOI 10.1109/ICCV.2019.00935; Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298; Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45; Li BY, 2019, PROC CVPR IEEE, P1019, DOI 10.1109/CVPR.2019.00111; Li PL, 2019, PROC CVPR IEEE, P7636, DOI 10.1109/CVPR.2019.00783; Li YY, 2018, ADV NEUR IN, V31; Liang M, 2019, PROC CVPR IEEE, P7337, DOI 10.1109/CVPR.2019.00752; Liang M, 2018, LECT NOTES COMPUT SC, V11220, P663, DOI 10.1007/978-3-030-01270-0_39; Lim JJ, 2014, LECT NOTES COMPUT SC, V8694, P478, DOI 10.1007/978-3-319-10599-4_31; Lin T.-Y., 2017, PROC CVPR IEEE, P936, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Manhardt F, 2019, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2019.00217; Mottaghi R, 2015, PROC CVPR IEEE, P418, DOI 10.1109/CVPR.2015.7298639; Mousavian A., 2017, PROC CVPR IEEE, P7074, DOI DOI 10.1109/CVPR.2017.597; Pepik B, 2012, LECT NOTES COMPUT SC, V7577, P356, DOI 10.1007/978-3-642-33783-3_26; Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102; Qi Charles R, 2017, ARXIV170602413; Redmon J., 2016, IEEE C COMPUTER VISI, DOI [10.1109/CVPR.2017.690, DOI 10.1109/CVPR.2017.690]; Redmon J, 2016, YOU ONLY LOOK ONCE U, DOI [DOI 10.1109/CVPR.2016.91, 10.1109/CVPR.2016.91]; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086; Simon Martin, 2018, EUR C COMP VIS, P197; Song SR, 2016, PROC CVPR IEEE, P808, DOI 10.1109/CVPR.2016.94; Song SR, 2014, LECT NOTES COMPUT SC, V8694, P634, DOI 10.1007/978-3-319-10599-4_41; Sun SY, 2018, ADV NEUR IN, V31; Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274; Wang WY, 2018, PROC CVPR IEEE, P2569, DOI 10.1109/CVPR.2018.00272; Wang XL, 2019, PROC CVPR IEEE, P4091, DOI 10.1109/CVPR.2019.00422; Wang Y, 2019, PROC CVPR IEEE, P8063, DOI 10.1109/CVPR.2019.00826; Wang ZX, 2019, IEEE INT C INT ROBOT, P1742, DOI 10.1109/IROS40897.2019.8968513; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985; Xu DF, 2018, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2018.00033; Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337; Yang B., 2018, C ROBOT LEARNING; Yang B, 2018, PROC CVPR IEEE, P7652, DOI 10.1109/CVPR.2018.00798; Yi L, 2019, PROC CVPR IEEE, P3942, DOI 10.1109/CVPR.2019.00407; Zhao HS, 2019, PROC CVPR IEEE, P5550, DOI 10.1109/CVPR.2019.00571; Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644; Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472; Zhu ML, 2014, IEEE INT CONF ROBOT, P3936, DOI 10.1109/ICRA.2014.6907430	64	167	169	47	131	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG 1	2021	43	8					2647	2664		10.1109/TPAMI.2020.2977026	http://dx.doi.org/10.1109/TPAMI.2020.2977026			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TF2YV	32142423	Green Submitted			2022-12-18	WOS:000670578800010
J	Rozantsev, A; Salzmann, M; Fua, P				Rozantsev, Artem; Salzmann, Mathieu; Fua, Pascal			Beyond Sharing Weights for Deep Domain Adaptation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Domain adaptation; deep learning	RECOGNITION; FEATURES	The performance of a classifier trained on data coming from a specific domain typically degrades when applied to a related but different one. While annotating many samples from the new domain would address this issue, it is often too expensive or impractical. Domain Adaptation has therefore emerged as a solution to this problem; It leverages annotated data from a source domain, in which it is abundant, to train a classifier to operate in a target domain, in which it is either sparse or even lacking altogether. In this context, the recent trend consists of learning deep architectures whose weights are shared for both domains, which essentially amounts to learning domain invariant features. Here, we show that it is more effective to explicitly model the shift from one domain to the other. To this end, we introduce a two-stream architecture, where one operates in the source domain and the other in the target domain. In contrast to other approaches, the weights in corresponding layers are related but not shared. We demonstrate that this both yields higher accuracy than state-of-the-art methods on several object recognition and detection tasks and consistently outperforms networks with shared weights in both supervised and unsupervised settings.	[Rozantsev, Artem; Salzmann, Mathieu; Fua, Pascal] Ecole Polytech Fed Lausanne, Comp Vis Lab, CH-1015 Lausanne, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Rozantsev, A (corresponding author), Ecole Polytech Fed Lausanne, Comp Vis Lab, CH-1015 Lausanne, Switzerland.	artem.rozantsev@epfl.ch; mathieu.salzmann@epfl.ch; pascal.fua@epfl.ch		Rozantsev, Artem/0000-0003-2867-5459; Salzmann, Mathieu/0000-0002-8347-8637	Swiss Commission for Technology and Innovation	Swiss Commission for Technology and Innovation	This work was supported in part by the Swiss Commission for Technology and Innovation.	Alvarez Jose M, 2016, ADV NEURAL INFORM PR, P2270; [Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Baktashmotlagh M, 2013, IEEE I CONF COMP VIS, P769, DOI 10.1109/ICCV.2013.100; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Becker Carlos J, 2013, ADV NEURAL INFORM PR, V1, P485; Bergamo A., 2010, ADV NEURAL INFORM PR, P181; Bousmalis Konstantinos, 2016, ADV NEURAL INFORM PR, P343; Caseiro R, 2015, PROC CVPR IEEE, P3846, DOI 10.1109/CVPR.2015.7299009; Chen Q, 2015, PROC CVPR IEEE, P5315, DOI 10.1109/CVPR.2015.7299169; Chen SJ, 2018, IEEE T SMART GRID, V9, P2327, DOI 10.1109/TSG.2016.2611611; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Chopra S., 2013, P INT C MACH LEARN W; Collins M. D., 2014, CORR; Donahue J, 2014, PR MACH LEARN RES, V32; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114; Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPR.2009.5206747, 10.1109/CVPRW.2009.5206747]; Fernando B, 2015, PATTERN RECOGN LETT, V65, P60, DOI 10.1016/j.patrec.2015.07.009; Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368; Ganin Y, 2016, J MACH LEARN RES, V17; Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36; Ghifary M, 2014, LECT NOTES ARTIF INT, V8862, P898, DOI 10.1007/978-3-319-13560-1_76; Glorot Xavier, 2011, P 28 INT C MACH LEAR, P513, DOI DOI 10.1177/1753193411430810; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Gretton A., 2009, DATASET SHIFT MACHIN, V3, P5; Gretton A., 2008, CORR; Hinton G., 2006, NEURAL COMPUT, V18, P1391; Huang J., 2006, ADV NEURAL INFORM PR, DOI DOI 10.7551/MITPRESS/7503.003.0080; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; Jiang J, 2008, LIT SURVEY DOMAIN AD, V3; Jin JQ, 2014, IEEE T INTELL TRANSP, V15, P1991, DOI 10.1109/TITS.2014.2308281; Kan MN, 2015, IEEE I CONF COMP VIS, P3846, DOI 10.1109/ICCV.2015.438; Kavukcuoglu K, 2015, ADV NEURAL INF PROCE, P2017; Kingma D. P., 2015, P ICLR, P13; Koniusz P, 2017, PROC CVPR IEEE, P7139, DOI 10.1109/CVPR.2017.755; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 1998, NEURAL NETWORKS TRIC; Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167; Li WW, 2020, INT J GEOGR INF SCI, V34, P637, DOI 10.1080/13658816.2018.1542697; Liu P., 2015, P BRIT MACH VIS C; Long M., 2015, P 32 INT C MACH LEAR, V1, P97; Long M, 2016, PROCEEDINGS OF SYMPOSIUM OF POLICING DIPLOMACY AND THE BELT & ROAD INITIATIVE, 2016, P136; Long MS, 2017, PR MACH LEARN RES, V70; Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Ma ZG, 2014, IEEE T PATTERN ANAL, V36, P1789, DOI 10.1109/TPAMI.2014.2306419; Misra I, 2016, PROC CVPR IEEE, P3994, DOI 10.1109/CVPR.2016.433; Muandet Krikamol, 2013, ICML; Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Pan SJ, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1187; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Poynton C., 2003, DIGITAL VIDEO HDTV A; Rozantsev A, 2015, COMPUT VIS IMAGE UND, V137, P24, DOI 10.1016/j.cviu.2014.12.006; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Rusu A. A., 2016, CORR; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Sener Ozan, 2016, ADV NEURAL INFORM PR, P2; Sha, 2013, P INT C MACH LEARN; Si S, 2010, IEEE T KNOWL DATA EN, V22, P929, DOI 10.1109/TKDE.2009.126; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Sun BC, 2017, ADV COMPUT VIS PATT, P153, DOI 10.1007/978-3-319-58347-1_8; Sun BC, 2016, AAAI CONF ARTIF INTE, P2058; Sutskever Ilya, 2013, P MACHINE LEARNING R, V28, P1139; Tommasi T, 2013, IEEE I CONF COMP VIS, P897, DOI 10.1109/ICCV.2013.116; Tsai YHH, 2016, PROC CVPR IEEE, P5081, DOI 10.1109/CVPR.2016.549; Tzeng E., 2014, CORR; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463; Weston J., 2008, P 25 INT C MACHINE L, P1168, DOI [DOI 10.1145/1390156.1390303, 10.1145/1390156.1390303]; Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023	74	167	176	5	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2019	41	4					801	814		10.1109/TPAMI.2018.2814042	http://dx.doi.org/10.1109/TPAMI.2018.2814042			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HO0HP	29994060	Green Submitted			2022-12-18	WOS:000460583500003
J	Li, YF; Zhou, ZH				Li, Yu-Feng; Zhou, Zhi-Hua			Towards Making Unlabeled Data Never Hurt	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Unlabeled data; semi-supervised learning; safe; S3VMs; S4VMs	CONVEX; OPTIMIZATION; WORKING	It is usually expected that learning performance can be improved by exploiting unlabeled data, particularly when the number of labeled data is limited. However, it has been reported that, in some cases existing semi-supervised learning approaches perform even worse than supervised ones which only use labeled data. For this reason, it is desirable to develop safe semi-supervised learning approaches that will not significantly reduce learning performance when unlabeled data are used. This paper focuses on improving the safeness of semi-supervised support vector machines (S3VMs). First, the S3VM-us approach is proposed. It employs a conservative strategy and uses only the unlabeled instances that are very likely to be helpful, while avoiding the use of highly risky ones. This approach improves safeness but its performance improvement using unlabeled data is often much smaller than S3VMs. In order to develop a safe and well-performing approach, we examine the fundamental assumption of S3VMs, i.e., low-density separation. Based on the observation that multiple good candidate low-density separators may be identified from training data, safe semi-supervised support vector machines (S4VMs) are here proposed. This approach uses multiple low-density separators to approximate the ground-truth decision boundary and maximizes the improvement in performance of inductive SVMs for any candidate separator. Under the assumption employed by S3VMs, it is here shown that S4VMs are provably safe and that the performance improvement using unlabeled data can be maximized. An out-of-sample extension of S4VMs is also presented. This extension allows S4VMs to make predictions on unseen instances. Our empirical study on a broad range of data shows that the overall performance of S4VMs is highly competitive with S3VMs, whereas in contrast to S3VMs which hurt performance significantly in many cases, S4VMs rarely perform worse than inductive SVMs.	[Li, Yu-Feng; Zhou, Zhi-Hua] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China; [Li, Yu-Feng; Zhou, Zhi-Hua] Collaborat Innovat Ctr Novel Software Technol & I, Nanjing 210023, Jiangsu, Peoples R China	Nanjing University	Li, YF (corresponding author), Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.	liyf@lamda.nju.edu.cn; zhouzh@lamda.nju.edu.cn			National Fundamental Research Program of China [2014CB340501]; National Science Foundation of China [61403186, 61333014, 61021062]; Jiangsu Science Foundation [BK20140613]; Baidu fund	National Fundamental Research Program of China; National Science Foundation of China(National Natural Science Foundation of China (NSFC)); Jiangsu Science Foundation; Baidu fund	The authors want to thank the associate editor and reviewers for helpful comments and suggestions. They thank Teng Zhang for help in some experiments. They also thank Jianxin Wu and Cam-Tu Nguyen for proofreading the paper. This research was partially supported by the National Fundamental Research Program of China (2014CB340501), the National Science Foundation of China (61403186, 61333014, 61021062), Jiangsu Science Foundation (BK20140613) and Baidu fund.	[Anonymous], 2009, P 26 ANN INT C MACH; [Anonymous], 1987, SIMULATED ANNEALING; Balcan MF, 2010, J ACM, V57, DOI 10.1145/1706591.1706599; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Ben-David S., 2008, C LEARN THEOR COLT; Bennett KP, 1999, ADV NEUR IN, V11, P368; Bezdek J. C., 2003, Neural, Parallel & Scientific Computations, V11, P351; Blum A., 2001, P INT C MACH LEARN I, P19, DOI DOI 10.1184/R1/6606860.V1; Blum A, 1998, P 7 ANN C COMP LEARN; Chapelle O, 2005, P INT WORKSH ART INT, V2005, P57; Chapelle O., 2006, P 23 INT C MACH LEAR, P185; Chapelle O., 2006, IEEE T NEURAL NETW, V20, P542; Chapelle O, 2008, J MACH LEARN RES, V9, P203; Chawla N, 2005, J ARTIF INTELL RES, V23, P331, DOI 10.1613/jair.1509; Chen K, 2011, IEEE T PATTERN ANAL, V33, P129, DOI 10.1109/TPAMI.2010.92; Cozman F. G., 2003, P 20 INT C MACH LEAR, P99; De Bie T, 2004, ADV NEUR IN, V16, P73; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Fan RE, 2005, J MACH LEARN RES, V6, P1889; Goutte C., 2002, P 6 C NAT LANG LEARN, V20, P1; Hsieh C.-J., 2008, P 25 INT C MACH LEAR, P408, DOI [10.1145/1390156.1390208, DOI 10.1145/1390156.1390208]; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; Kasabov N, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P1; KIRKPATRICK S, 1984, J STAT PHYS, V34, P975, DOI 10.1007/BF01009452; Li M, 2005, LECT NOTES ARTIF INT, V3518, P611; Li Y, 2009, P INT C MACH LEARN, P633, DOI DOI 10.1145/1553374.1553456; Li Y., 2011, P 28 INT C MACH LEAR, P1081; Li Y.-F., 2011, P 25 AAAI C ART INT, P386; Li Y.-F., 2009, P 12 INT C ART INT S, V5, P344; Li YF, 2013, J MACH LEARN RES, V14, P2151; Liu W., 2010, P 27 INT C MACH LEAR, P679; Liu W, 2012, P IEEE, V100, P2624, DOI 10.1109/JPROC.2012.2197809; Miller DJ, 1997, ADV NEUR IN, V9, P571; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Sindhwani V., 2006, P 23 INT C MACH LEAR, V23, P841, DOI DOI 10.1145/1143844.1143950; Tang EK, 2006, MACH LEARN, V65, P247, DOI 10.1007/s10994-006-9449-2; Vapnik V.N, 1998, STAT LEARNING THEORY; Wang J., 2008, P 25 INT C MACH LEAR, P1144, DOI DOI 10.1145/1390156.1390300; Wang L, 2003, PROC CVPR IEEE, P629; Xu L., 2005, P 20 NAT C ART INT, V2, P904; Yuille AL, 2003, NEURAL COMPUT, V15, P915, DOI 10.1162/08997660360581958; Zhang K., 2007, P 24 INT C MACH LEAR, V227, P1119; Zhang Tong, 2000, P 17 INT C MACHINE L, P1191; Zhou D., 2004, NIPS, V16, P595; Zhou Z.-H, 2012, ENSEMBLE METHODS FDN, DOI DOI 10.1201/B12207; Zhou ZH, 2005, IEEE T KNOWL DATA EN, V17, P1529, DOI 10.1109/TKDE.2005.186; Zhou ZH, 2010, KNOWL INF SYST, V24, P415, DOI 10.1007/s10115-009-0209-z; Zhu X., 2007, TECHNICAL REPORT; Zhu X., 2009, ADV NEURAL INFORM PR, P1513; Zhu Xiaojin., 2003, P ICLR, P912; [No title captured]	53	167	179	3	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2015	37	1					175	188		10.1109/TPAMI.2014.2299812	http://dx.doi.org/10.1109/TPAMI.2014.2299812			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AX5ML	26353217	Green Published			2022-12-18	WOS:000346970600015
J	Simonyan, K; Vedaldi, A; Zisserman, A				Simonyan, Karen; Vedaldi, Andrea; Zisserman, Andrew			Learning Local Feature Descriptors Using Convex Optimisation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Descriptor learning; feature descriptor; binary descriptor; dimensionality reduction; sparsity; nuclear norm; trace norm; feature matching; image retrieval		The objective of this work is to learn descriptors suitable for the sparse feature detectors used in viewpoint invariant matching. We make a number of novel contributions towards this goal. First, it is shown that learning the pooling regions for the descriptor can be formulated as a convex optimisation problem selecting the regions using sparsity. Second, it is shown that descriptor dimensionality reduction can also be formulated as a convex optimisation problem, using Mahalanobis matrix nuclear norm regularisation. Both formulations are based on discriminative large margin learning constraints. As the third contribution, we evaluate the performance of the compressed descriptors, obtained from the learnt real-valued descriptors by binarisation. Finally, we propose an extension of our learning formulations to a weakly supervised case, which allows us to learn the descriptors from unannotated image collections. It is demonstrated that the new learning methods improve over the state of the art in descriptor learning on the annotated local patches data set of Brown et al. [3] and unannotated photo collections of Philbin et al. [22].	[Simonyan, Karen; Vedaldi, Andrea; Zisserman, Andrew] Univ Oxford, Dept Engn Sci, Visual Geometry Grp, Oxford OX1 3PJ, England	University of Oxford	Simonyan, K (corresponding author), Univ Oxford, Dept Engn Sci, Visual Geometry Grp, Parks Rd, Oxford OX1 3PJ, England.	karen@robots.ox.ac.uk; vedaldi@robots.ox.ac.uk; az@robots.ox.ac.uk	Vedaldi, Andrea/B-9071-2015	Vedaldi, Andrea/0000-0003-1374-2858	Microsoft; ERC [228180]; Violette and Samuel Glasstone Fellowship	Microsoft(Microsoft); ERC(European Research Council (ERC)European Commission); Violette and Samuel Glasstone Fellowship	This work was supported by the Microsoft Research PhD Scholarship Programme and ERC grant VisRec no. 228180. Andrea Vedaldi was partially supported by the Violette and Samuel Glasstone Fellowship.	[Anonymous], [No title captured]; Boix X., 2013, P IEEE C COMP VIS PA; Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54; Calonder M., 2010, P 11 EUR C COMP VIS; Charikar M.S., 2002, P 34 ANN ACM S THEOR, V34, P380, DOI DOI 10.1145/509907.509965; Fazel M, 2001, P AMER CONTR CONF, P4734, DOI 10.1109/ACC.2001.945730; Gong YC, 2011, PROC CVPR IEEE; Guillaumin M, 2010, LECT NOTES COMPUT SC, V6311, P634, DOI 10.1007/978-3-642-15549-9_46; Jegou H., 2010, P IEEE C COMP VIS PA; Jegou H, 2012, INT CONF ACOUST SPEE, P2029, DOI 10.1109/ICASSP.2012.6288307; Joachims T., 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]; Kovacevic J, 2008, FOUND TRENDS SIGNAL, V2, P1, DOI 10.1561/2000000006; Kumar M., 2010, NIPS, P1189, DOI DOI 10.5555/2997189.2997322; Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Mikolajczyk K., 2002, P 7 EUR C COMP VIS E; Nesterov Y, 2009, MATH PROGRAM, V120, P221, DOI 10.1007/s10107-007-0149-x; Philbin J, 2007, CVPR; Philbin J., 2010, P 11 EUR C COMP VIS; Rennie J. D., 2005, P 22 INT C MACHINE L, P713; Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414; Simonyan K., 2012, P EUR C COMP VIS ECC; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; TOLA E, 2008, P IEEE C COMP VIS PA; Torresani L., 2007, ADV NEURAL INFORM PR, V19, P1385; Trzcinski T., 2013, P IEEE C COMP VIS PA; Trzcinski T., 2012, P 12 EUR C COMP VIS; Trzcinski Tomasz, 2012, ADV NEURAL INFORM PR, P269, DOI DOI 10.1177/1753193411419945; Vedaldi A., 2010, P ACM INT C MULT; Weinberger K., 2006, P ADV NEUR INF PROC; Xiao L, 2010, J MACH LEARN RES, V11, P2543	36	167	183	1	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2014	36	8					1573	1585		10.1109/TPAMI.2014.2301163	http://dx.doi.org/10.1109/TPAMI.2014.2301163			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9HN	26353339				2022-12-18	WOS:000340191900007
J	Gdalyahu, Y; Weinshall, D				Gdalyahu, Y; Weinshall, D			Flexible syntactic matching of curves and its application to automatic hierarchical classification of silhouettes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						curve matching; syntactic matching; image database; silhouettes	TWO-DIMENSIONAL OBJECTS; CHARACTER-RECOGNITION; SHAPE-RECOGNITION; INVARIANT; RELAXATION; SIMILARITY; ALIGNMENT; TRACKING; CONTOURS; DISTANCE	Curve matching is one instance of the fundamental correspondence problem. Our flexible algorithm is designed to match curves under substantial deformations and arbitrary large scaling and rigid transformations. A syntactic representation is constructed for both curves and an edit transformation which maps one curve to the other is found using dynamic programming. We present extensive experiments where we apply the algorithm to silhouette matching. In these experiments, we examine partial occlusion, viewpoint variation. articulation, and class matching (where silhouettes of similar objects are matched). Based on the qualitative syntactic matching, we define a dissimilarity measure and we compute it for every pair of images in a database of 121 images. We use this experiment to objectively evaluate our algorithm: First, we compare our results to those reported by others. Second, we use the dissimilarity values in order to organize the image database into shape categories. The veridical hierarchical organization stands as evidence to the quality of our matching and similarity estimation.	Hebrew Univ Jerusalem, Inst Comp Sci, IL-91904 Jerusalem, Israel	Hebrew University of Jerusalem	Gdalyahu, Y (corresponding author), Hebrew Univ Jerusalem, Inst Comp Sci, IL-91904 Jerusalem, Israel.	yoram@cs.huji.ac.il; daphna@cs.huji.ac.il						ANSARI N, 1990, IEEE T PATTERN ANAL, V12, P470, DOI 10.1109/34.55107; ARKIN EM, 1991, IEEE T PATTERN ANAL, V13, P209, DOI 10.1109/34.75509; ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P137, DOI 10.1109/TPAMI.1984.4767499; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; BRINT AT, 1990, IMAGE VISION COMPUT, V8, P50, DOI 10.1016/0262-8856(90)90056-B; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; COHEN I, 1992, LECT NOTES COMPUT SC, V588, P458; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; DelBimbo A, 1997, IEEE T PATTERN ANAL, V19, P121, DOI 10.1109/34.574790; Dembo A., 1994, ANN PROBAB, V22, P1993; GDALYAHU Y, 1999, P IEEE C COMP VIS PA; GEIGER D, 1995, IEEE T PATTERN ANAL, V17, P294, DOI 10.1109/34.368194; GORMAN JW, 1988, IEEE T PATTERN ANAL, V10, P257, DOI 10.1109/34.3887; GREGOR J, 1993, IEEE T PATTERN ANAL, V15, P129, DOI 10.1109/34.192484; HORAUD R, 1989, IEEE T PATTERN ANAL, V11, P1168, DOI 10.1109/34.42855; Huttenlocher D. P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P102; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; JACOBS DW, 1998, P 6 INT C COMP VIS B; KAMGARPARSI B, 1991, CVGIP-IMAG UNDERSTAN, V53, P227, DOI 10.1016/1049-9660(91)90030-S; KOCH MW, 1987, IEEE T PATTERN ANAL, V9, P483, DOI 10.1109/TPAMI.1987.4767936; LAMDAN Y, 1990, IEEE T ROBOTIC AUTOM, V6, P578, DOI 10.1109/70.62047; LATECKI LJ, 1998, P 4 IEEE WORKSH APPL; LI SZ, 1992, PATTERN RECOGN, V25, P583, DOI 10.1016/0031-3203(92)90075-T; LIUAND H, 1990, IEEE T PATTERN ANAL, V12, P1072; LU CC, 1993, PATTERN RECOGN LETT, V14, P945, DOI 10.1016/0167-8655(93)90002-U; MARZAL A, 1993, IEEE T PATTERN ANAL, V15, P926, DOI 10.1109/34.232078; MCCONNELL R, 1991, IEEE T GEOSCI REMOTE, V29, P1004, DOI 10.1109/36.101377; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; PELILLO M, 1998, P EUR C COMP VIS, P3; ROCHA J, 1994, IEEE T PATTERN ANAL, V16, P393, DOI 10.1109/34.277592; SCLAROFF S, 1995, IEEE T PATTERN ANAL, V17, P545, DOI 10.1109/34.387502; SHAPIRO LS, 1992, IMAGE VISION COMPUT, V10, P283, DOI 10.1016/0262-8856(92)90043-3; SHARVIT D, 1998, J VISUAL COMM IMAGE; Shokoufandeh A., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P491, DOI 10.1109/CVPR.1999.784726; Siddiqi K, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P222, DOI 10.1109/ICCV.1998.710722; STOCKMAN G, 1982, IEEE T PATTERN ANAL, V4, P229, DOI 10.1109/TPAMI.1982.4767240; TIRTHAPURA S, 1998, SPIE P MULT STOR ARC, V3, P25; TSAI WH, 1985, IEEE T PATTERN ANAL, V7, P453, DOI 10.1109/TPAMI.1985.4767684; TSAY YT, 1993, IEEE T PATTERN ANAL, V15, P180, DOI 10.1109/34.192491; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/h0026750; UEDA N, 1993, IEEE T PATTERN ANAL, V15, P337, DOI 10.1109/34.206954; UMEYAMA S, 1993, IEEE T PATTERN ANAL, V15, P136, DOI 10.1109/34.192485; WANG YP, 1990, IEEE T PATTERN ANAL, V12, P1080, DOI 10.1109/34.61707; Weinshall D, 1997, IEEE T PATTERN ANAL, V19, P97, DOI 10.1109/34.574783; WERMAN M, 1995, IEEE T PATTERN ANAL, V17, P810, DOI 10.1109/34.400572; [No title captured]	48	167	173	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1999	21	12					1312	1328		10.1109/34.817410	http://dx.doi.org/10.1109/34.817410			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	275PG					2022-12-18	WOS:000084828100005
J	HEITZ, F; BOUTHEMY, P				HEITZ, F; BOUTHEMY, P			MULTIMODAL ESTIMATION OF DISCONTINUOUS OPTICAL-FLOW USING MARKOV RANDOM-FIELDS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						VISUAL MOTION ANALYSIS; DISCONTINUITIES IN OPTICAL FLOW; OCCLUSION PROCESSING; MULTIPLE CONSTRAINTS; MULTIRESOLUTION ANALYSIS; MAP ESTIMATE; MARKOV RANDOM FIELDS; DETERMINISTIC RELAXATION	IMAGE SEQUENCES; VECTOR-FIELDS; MOTION; OPTIMIZATION; SEGMENTATION; RELAXATION	The estimation of dense velocity fields from image sequences is basically an ill-posed problem, primarily because the data only partially constrain the solution. It is rendered especially difficult by the presence of motion boundaries and occlusion regions which are not taken into account by standard regularization approaches. In this paper, we present a multimodal approach to the problem of motion estimation in which the computation of visual motion is based on several complementary constraints. It is shown that multiple constraints can provide more accurate flow estimation in a wide range of circumstances. The theoretical framework relies on bayesian estimation associated with global statistical models, namely, Markov Random Fields. The constraints introduced here aim to address the following issues: optical flow estimation while preserving motion boundaries, processing of occlusion regions, fusion between gradient and feature-based motion constraint equations. Deterministic relaxation algorithms are used to merge information and to provide a solution to the maximum a posteriori estimation of the unknown dense motion field. The algorithm is well suited to a multiresolution implementation which brings an appreciable speed-up as well as a significant improvement of estimation when large displacements are present in the scene. Experiments on synthetic and real world image sequences are reported.			HEITZ, F (corresponding author), INRIA,IRISA,CAMPUS UNIV BEAULIEU,F-35042 RENNES,FRANCE.		HEITZ, Fabrice/R-4100-2017	HEITZ, Fabrice/0000-0002-3004-0957				ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965; BARNARD ST, 1989, INT J COMPUT VISION, V3, P17, DOI 10.1007/BF00054836; BERGEN JR, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P27; BESAG J, 1986, J R STAT SOC B, V48, P259; BLACK MJ, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P33; BOUTHEMY P, 1989, IEEE T PATTERN ANAL, V11, P499, DOI 10.1109/34.24782; BOUTHEMY P, 1993, INT J COMPUT VISION, V10, P157, DOI 10.1007/BF01420735; BOUTHEMY P, 1990, 1ST P EUR C COMP VIS, P307; DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164; ENKELMANN W, 1988, COMPUT VISION GRAPH, V43, P150, DOI 10.1016/0734-189X(88)90059-X; GAMBLE E, 1987, MIT AI970 TECH REP; GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HEITZ F, 1991, 1367 INRIA TECH REP; HEITZ F, 1990, 10TH P INT C PATT RE, V1, P378; HEITZ F, 1993, IN PRESS CVGIP IMAGE; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HUTCHINSON J, 1988, COMPUTER, V21, P52, DOI 10.1109/2.31; Konrad J., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P1072, DOI 10.1109/ICASSP.1988.196780; KONRAD J, 1992, IEEE T PATTERN ANAL, V14, P910, DOI 10.1109/34.161350; LITTLE J, 1990, 1ST ECCV ANT, P336; MITICHE A, 1987, PATTERN RECOGN, V20, P173, DOI 10.1016/0031-3203(87)90051-3; MURRAY DW, 1987, IEEE T PATTERN ANAL, V9, P220, DOI 10.1109/TPAMI.1987.4767896; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NAGEL HH, 1987, ARTIF INTELL, V33, P299, DOI 10.1016/0004-3702(87)90041-5; PELEG S, 1990, 10TH P INT C PATT RE, V1, P109; SCHUNCK BG, 1989, IEEE T PATTERN ANAL, V11, P1010, DOI 10.1109/34.42834; SHIZAWA M, 1990, 10TH P INT C PATT RE, V1, P274; SINGH A, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P168; SPOERRI A, 1987, JUN P INT C COMP VIS, P209; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767; VERRI A, 1989, IEEE T PATTERN ANAL, V11, P490, DOI 10.1109/34.24781; WOHN K, 1990, COMPUT VISION GRAPH, V49, P127, DOI 10.1016/0734-189X(90)90134-H	35	167	177	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1993	15	12					1217	1232		10.1109/34.250841	http://dx.doi.org/10.1109/34.250841			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MP176		Green Submitted			2022-12-18	WOS:A1993MP17600001
J	Yin, XC; Pei, WY; Zhang, J; Hao, HW				Yin, Xu-Cheng; Pei, Wei-Yi; Zhang, Jun; Hao, Hong-Wei			Multi-Orientation Scene Text Detection with Adaptive Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Scene text detection; multi-orientation; adaptive hierarchical clustering; coarse-to-fine grouping	LINE SEGMENTATION; IMAGES; DOCUMENTS	Text detection in natural scene images is an important prerequisite for many content-based image analysis tasks, while most current research efforts only focus on horizontal or near horizontal scene text. In this paper, first we present a unified distance metric learning framework for adaptive hierarchical clustering, which can simultaneously learn similarity weights (to adaptively combine different feature similarities) and the clustering threshold (to automatically determine the number of clusters). Then, we propose an effective multi-orientation scene text detection system, which constructs text candidates by grouping characters based on this adaptive clustering. Our text candidates construction method consists of several sequential coarse-to-fine grouping steps: morphology-based grouping via single-link clustering, orientation-based grouping via divisive hierarchical clustering, and projection-based grouping also via divisive clustering. The effectiveness of our proposed system is evaluated on several public scene text databases, e.g., ICDAR Robust Reading Competition data sets (2011 and 2013), MSRA-TD500 and NEOCR. Specifically, on the multi-orientation text data set MSRA-TD500, the f measure of our system is 71 percent, much better than the state-of-the-art performance. We also construct and release a practical challenging multi-orientation scene text data set (USTB-SV1K), which is available at http://prir.ustb.edu.cn/TexStar/MOMV-text-detection/.	[Yin, Xu-Cheng] Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Beijing Key Lab Mat Sci Knowledge Engn, Dept Comp Sci & Technol, Beijing 100083, Peoples R China; [Pei, Wei-Yi; Zhang, Jun] Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Dept Comp Sci & Technol, Beijing 100083, Peoples R China; [Hao, Hong-Wei] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China	University of Science & Technology Beijing; University of Science & Technology Beijing; Chinese Academy of Sciences; Institute of Automation, CAS	Yin, XC (corresponding author), Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Beijing Key Lab Mat Sci Knowledge Engn, Dept Comp Sci & Technol, Beijing 100083, Peoples R China.	xuchengyin@ustb.edu.cn; peiweiyi.ustb@gmail.com; zj123zyx@gmail.com; hongwei.hao@ia.ac.cn		Yin, Xucheng/0000-0003-0023-0220	National Natural Science Foundation of China [61105018, 61175020, 61473036]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The authors are grateful to Xuwang Yin, Prof. Kaizhu Huang, Dr. Jacqueline Feild and Chia-Jung Lee for helpful discussions, and to the anonymous reviewers for their constructive comments. The authors would like to thank Prof. Xiang Bai for providing the results of their method [18] on USTB-SV1K. The research is partly supported by National Natural Science Foundation of China (61105018, 61175020, 61473036). X.-C. Yin is the corresponding author.	Bilenko M, 2004, ICML; Bishop C.M, 2006, PATTERN RECOGN; Bissacco A., 2013, P INT C COMP VIS, P4321; Chen XR, 2004, PROC CVPR IEEE, P366; Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041; Kang L, 2014, PROC CVPR IEEE, P4034, DOI 10.1109/CVPR.2014.514; Karatzas D., 2013, P ICDAR, P1115; Kim KI, 2003, IEEE T PATTERN ANAL, V25, P1631, DOI 10.1109/TPAMI.2003.1251157; Koo HI, 2013, IEEE T IMAGE PROCESS, V22, P2296, DOI 10.1109/TIP.2013.2249082; Koo HI, 2012, IEEE T IMAGE PROCESS, V21, P1169, DOI 10.1109/TIP.2011.2166972; Lee J., 2011, P INT C DOC AN REC 2, V2011, P429, DOI DOI 10.1371/J0URNAL.P0NE.0090352; Li Y, 2008, IEEE T PATTERN ANAL, V30, P1313, DOI 10.1109/TPAMI.2007.70792; Likforman-Sulem L, 2007, INT J DOC ANAL RECOG, V9, P123, DOI 10.1007/s10032-006-0023-z; Liu Wei, 2016, CBDAR WORKSH 2011 IC; Neumann L, 2013, IEEE I CONF COMP VIS, P97, DOI 10.1109/ICCV.2013.19; Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097; OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677; Pan YF, 2011, IEEE T IMAGE PROCESS, V20, P800, DOI 10.1109/TIP.2010.2070803; Phan TQ, 2012, P 20 ACM INT C MULT, P765, DOI 10.1145/2393347.2396307; Russell S. J, 2002, ADV NEURAL INFORM PR, P12, DOI DOI 10.5555/2968618.2968683; Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296; Shi CZ, 2013, PATTERN RECOGN LETT, V34, P107, DOI 10.1016/j.patrec.2012.09.019; Shivakumara P, 2013, PROC INT CONF DOC, P594, DOI 10.1109/ICDAR.2013.123; Shivakumara P, 2013, IEEE T CIRC SYST VID, V23, P1729, DOI 10.1109/TCSVT.2013.2255396; Shivakumara P, 2012, IEEE T CIRC SYST VID, V22, P1227, DOI 10.1109/TCSVT.2012.2198129; Shivakumara P, 2011, IEEE T PATTERN ANAL, V33, P412, DOI 10.1109/TPAMI.2010.166; Stamatopoulos N, 2013, PROC INT CONF DOC, P1402, DOI 10.1109/ICDAR.2013.283; Wang K, 2010, LECT NOTES COMPUT SC, V6311, P591, DOI 10.1007/978-3-642-15549-9_43; Wang T, 2012, INT C PATT RECOG, P3304; Weinman JJ, 2014, IEEE T PATTERN ANAL, V36, P375, DOI 10.1109/TPAMI.2013.126; Weinman JJ, 2009, IEEE T PATTERN ANAL, V31, P1733, DOI 10.1109/TPAMI.2009.38; Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787; Yao Cong, 2014, IEEE T IMAGE PROCESS, V23, P11, DOI DOI 10.1109/TIP.2014.2353813; Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765; Yi CC, 2013, COMPUT VIS IMAGE UND, V117, P182, DOI 10.1016/j.cviu.2012.11.002; Yi CC, 2012, IEEE T IMAGE PROCESS, V21, P4256, DOI 10.1109/TIP.2012.2199327; Yin F, 2009, PATTERN RECOGN, V42, P3146, DOI 10.1016/j.patcog.2008.12.013; Yin XC, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P1091; Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182; Yin XC, 2011, PROC INT CONF DOC, P136, DOI 10.1109/ICDAR.2011.36; Yin XW, 2012, INT C PATT RECOG, P725	41	166	177	0	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2015	37	9					1930	1937		10.1109/TPAMI.2014.2388210	http://dx.doi.org/10.1109/TPAMI.2014.2388210			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CO5RQ	26353137				2022-12-18	WOS:000359216600015
J	Tan, VYF; Fevotte, C				Tan, Vincent Y. F.; Fevotte, Cedric			Automatic Relevance Determination in Nonnegative Matrix Factorization with the beta-Divergence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Nonnegative matrix factorization; model order selection; majorization-minimization; group-sparsity; automatic relevance determination	SPARSITY; ROBUST	This paper addresses the estimation of the latent dimensionality in nonnegative matrix factorization (NMF) with the beta-divergence. The beta-divergence is a family of cost functions that includes the squared euclidean distance, Kullback-Leibler (KL) and Itakura-Saito (IS) divergences as special cases. Learning the model order is important as it is necessary to strike the right balance between data fidelity and overfitting. We propose a Bayesian model based on automatic relevance determination (ARD) in which the columns of the dictionary matrix and the rows of the activation matrix are tied together through a common scale parameter in their prior. A family of majorization-minimization (MM) algorithms is proposed for maximum a posteriori (MAP) estimation. A subset of scale parameters is driven to a small lower bound in the course of inference, with the effect of pruning the corresponding spurious components. We demonstrate the efficacy and robustness of our algorithms by performing extensive experiments on synthetic data, the swimmer dataset, a music decomposition example, and a stock price prediction task.	[Tan, Vincent Y. F.] ASTAR, Inst Infocomm Res, Singapore 138632, Singapore; [Tan, Vincent Y. F.] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117548, Singapore; [Fevotte, Cedric] Observ Cote Azur, CNRS, Lab Lagrange, F-06000 Nice, France; [Fevotte, Cedric] Univ Nice Sophia Antipolis, F-06000 Nice, France	Agency for Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R); National University of Singapore; Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; Universite Cote d'Azur; Observatoire de la Cote d'Azur; UDICE-French Research Universities; Universite Cote d'Azur	Tan, VYF (corresponding author), ASTAR, Inst Infocomm Res, 1 Fusionopolis Way,21-01 Connexis South Tower, Singapore 138632, Singapore.	vtan@nus.edu.sg; cfevotte@unice.fr			A*STAR, Singapore;  [ANR-09-JCJC-0073-01 TANGERINE]	A*STAR, Singapore(Agency for Science Technology & Research (A*STAR)); 	The authors would like to acknowledge Francis Bach for discussions related to this work, Y. Kenan Yilmaz and A. Taylan Cemgil for discussions on Tweedie distributions, as well as Morten Morup and Matt Hoffman for sharing their code. They would also like to thank the reviewers whose comments helped to greatly improve the paper. The work of V.Y. F. Tan is supported by A*STAR, Singapore. The work of C. Fevotte is supported by project ANR-09-JCJC-0073-01 TANGERINE (theory and applications of nonnegative matrix factorization).	Bach F, 2012, FOUND TRENDS MACH LE, V4, P1, DOI 10.1561/2200000015; Basu A, 1998, BIOMETRIKA, V85, P549, DOI 10.1093/biomet/85.3.549; Bishop CM, 1999, ADV NEUR IN, V11, P382; Candes EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x; Cemgil Ali Taylan, 2009, Comput Intell Neurosci, P785152, DOI 10.1155/2009/785152; Cichocki A, 2006, LECT NOTES COMPUT SC, V3889, P32; Cichocki A, 2011, ENTROPY-SWITZ, V13, P134, DOI 10.3390/e13010134; Cichocki Andrzej, 2009, NONNEGATIVE MATRIX T, P2; Donoho D., 2004, P AD VNEUR INF PROC; Drakakis K., 2007, INT J MATH SCI, V6; Eggert J, 2004, IEEE IJCNN, P2529; Eguchi S., 2001, TECHNICAL REPORT; Fevotte C, 2011, NEURAL COMPUT, V23, P2421, DOI 10.1162/NECO_a_00168; Fevotte C, 2009, NEURAL COMPUT, V21, P793, DOI 10.1162/neco.2008.04-08-771; Gao Y, 2005, BIOINFORMATICS, V21, P3970, DOI 10.1093/bioinformatics/bti653; Guillamet D., 2002, P INT C PATT REC; Ho N.-D., 2008, THESIS U K DELOUVAIN; Hoffman M. D., 2010, P INT C MACH LEARN; Hunter DR, 2004, AM STAT, V58, P30, DOI 10.1198/0003130042836; Jorgensen B., 1987, J ROYAL STAT SOC B, V49; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Lefevre A., 2011, P IEEE WORKSH APPL S; MACKAY DJC, 1995, NETWORK-COMP NEURAL, V6, P469, DOI 10.1088/0954-898X/6/3/011; Mairal J, 2010, J MACH LEARN RES, V11, P19; Morup M., 2009, P 17 EUR SIGN PROC C; Morup M, 2009, J CHEMOMETR, V23, P352, DOI 10.1002/cem.1223; Nakano M., 2010, P IEEE INT WORKSH MA; PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203; Salakhutdinov R., 2007, P ADV NEUR INF PROC, V19; Schmidt M. N., 2009, P 8 INT C IND COMP A; Schmidt M. N., 2010, P EUR SIGN PROC C; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Tan V. Y. F., 2009, P WORKSH SIGN PROC A; Tan V. Y. F., 2012, SUPPLEMENTARY MAT AU, DOI DOI 10.1109/TPAMI.2012.240; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Tweedie M.C.K., 1984, STAT APPL NEW DIRECT, P579; Wipf DP, 2011, IEEE T INFORM THEORY, V57, P6236, DOI 10.1109/TIT.2011.2162174; Yang ZR, 2010, LECT NOTES COMPUT SC, V6365, P514, DOI 10.1007/978-3-642-15995-4_64; Yang ZR, 2010, IEEE T NEURAL NETWOR, V21, P734, DOI 10.1109/TNN.2010.2041361; Yilmaz Y. K., 2012, THESIS BOGAZICI U; Yuan M, 2006, J R STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Zhong M., 2009, P INT C ART INT STAT, P8	43	166	170	2	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2013	35	7					1592	1605		10.1109/TPAMI.2012.240	http://dx.doi.org/10.1109/TPAMI.2012.240			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	146AG	23681989				2022-12-18	WOS:000319060600005
J	Suk, HI; Lee, SW				Suk, Heung-Il; Lee, Seong-Whan			A Novel Bayesian Framework for Discriminative Feature Extraction in Brain-Computer Interfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Discriminative feature extraction; spatiospectral filter optimization; Brain-Computer Interface (BCI); ElectroEncephaloGraphy (EEG); motor imagery classification	SINGLE-TRIAL EEG; COMMON SPATIAL-PATTERNS; MOTOR IMAGERY; MUTUAL INFORMATION; FEATURE-SELECTION; SPECTRAL FILTERS; CLASSIFICATION; OPTIMIZATION; ALGORITHMS; FREQUENCY	As there has been a paradigm shift in the learning load from a human subject to a computer, machine learning has been considered as a useful tool for Brain-Computer Interfaces (BCIs). In this paper, we propose a novel Bayesian framework for discriminative feature extraction for motor imagery classification in an EEG-based BCI in which the class-discriminative frequency bands and the corresponding spatial filters are optimized by means of the probabilistic and information-theoretic approaches. In our framework, the problem of simultaneous spatiospectral filter optimization is formulated as the estimation of an unknown posterior probability density function (pdf) that represents the probability that a single-trial EEG of predefined mental tasks can be discriminated in a state. In order to estimate the posterior pdf, we propose a particle-based approximation method by extending a factored-sampling technique with a diffusion process. An information-theoretic observation model is also devised to measure discriminative power of features between classes. From the viewpoint of classifier design, the proposed method naturally allows us to construct a spectrally weighted label decision rule by linearly combining the outputs from multiple classifiers. We demonstrate the feasibility and effectiveness of the proposed method by analyzing the results and its success on three public databases.	[Lee, Seong-Whan] Korea Univ, Dept Brain & Cognit Engn, Seoul 136713, South Korea; [Suk, Heung-Il] Korea Univ, Dept Comp Sci & Engn, Seoul 136713, South Korea	Korea University; Korea University	Lee, SW (corresponding author), Korea Univ, Dept Brain & Cognit Engn, Woo Jung Coll Informat & Commun Bldg,Room 410, Seoul 136713, South Korea.	hisuk@image.korea.ac.kr; swlee@image.korea.ac.kr		Suk, Heung-Il/0000-0001-7019-8962	World Class University (WCU) Program through the National Research Foundation of Korea; Ministry of Education, Science, and Technology [R31-10008]; National Research Foundation; Korea government (MEST) [2012-005741]	World Class University (WCU) Program through the National Research Foundation of Korea(National Research Foundation of Korea); Ministry of Education, Science, and Technology(Ministry of Education, Science & Technology (MEST), Republic of Korea); National Research Foundation; Korea government (MEST)(Ministry of Education, Science & Technology (MEST), Republic of KoreaKorean Government)	This work was supported by the World Class University (WCU) Program through the National Research Foundation of Korea funded by the Ministry of Education, Science, and Technology (R31-10008). This work was also supported by the National Research Foundation grant funded by the Korea government (MEST) (No. 2012-005741). All correspondence should be directed to S.-W. Lee.	Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116; Ang KK, 2008, IEEE IJCNN, P2390, DOI 10.1109/IJCNN.2008.4634130; Babiloni C, 1999, NEUROIMAGE, V10, P658, DOI 10.1006/nimg.1999.0504; Bashashati A, 2007, J NEURAL ENG, V4, pR32, DOI 10.1088/1741-2560/4/2/R03; Blankertz B., 2008, ADV NEURAL INFORM PR, P113; Blankertz B, 2008, IEEE SIGNAL PROC MAG, V25, P41, DOI 10.1109/MSP.2008.4408441; Brunner C, 2008, BCI COMPETITION 2008; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Cecotti H, 2011, IEEE T PATTERN ANAL, V33, P433, DOI 10.1109/TPAMI.2010.125; Cecotti H, 2010, IEEE T NEUR SYS REH, V18, P127, DOI 10.1109/TNSRE.2009.2039594; Dalponte M, 2007, ELECTRON LETT, V43, P1406, DOI 10.1049/el:20072428; Dornhege G, 2004, IEEE T BIO-MED ENG, V51, P993, DOI 10.1109/TBME.2004.827088; Dornhege G., 2007, BRAIN COMPUTER INTER; Dornhege G, 2003, ADV NEURAL INF P SYS, V15, P1115; Dornhege G, 2006, IEEE T BIO-MED ENG, V53, P2274, DOI 10.1109/TBME.2006.883649; Doucet A., 2001, SEQUENTIAL MONTE CAR; Fazli S., 2009, ADV NEURAL INFORM PR, P513; Garcia GN, 2003, I IEEE EMBS C NEUR E, P591, DOI 10.1109/CNE.2003.1196897; Garrett D, 2003, IEEE T NEUR SYS REH, V11, P141, DOI 10.1109/TNSRE.2003.814441; Grenander U., 1991, PATTERN THEORETICAL; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Krauledat M, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002967; Lan T, 2005, P ANN INT IEEE EMBS, P7064; Leiva-Murillo JM, 2007, IEEE T NEURAL NETWOR, V18, P1433, DOI 10.1109/TNN.2007.891630; Lemm S, 2005, IEEE T BIO-MED ENG, V52, P1541, DOI 10.1109/TBME.2005.851521; Lotte F, 2007, J NEURAL ENG, V4, pR1, DOI 10.1088/1741-2560/4/2/R01; Lotte F, 2011, IEEE T BIO-MED ENG, V58, P355, DOI 10.1109/TBME.2010.2082539; Lu HP, 2010, IEEE T BIO-MED ENG, V57, P2936, DOI 10.1109/TBME.2010.2082540; Muller K-R., 2004, BIOMED TECH, V49, P11, DOI [10.13109/9783666351419.11, DOI 10.13109/9783666351419.11]; Oveisi F, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/673040; Palaniappan R, 2007, IEEE T PATTERN ANAL, V29, P738, DOI 10.1109/TPAMI.2007.1013; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159; Pfurtscheller G, 2001, P IEEE, V89, P1123, DOI 10.1109/5.939829; Ramoser H, 2000, IEEE T REHABIL ENG, V8, P441, DOI 10.1109/86.895946; Suk HI, 2011, IEEE SYS MAN CYBERN, P19, DOI 10.1109/ICSMC.2011.6083636; Suk HI, 2011, INT J IMAG SYST TECH, V21, P123, DOI 10.1002/ima.20283; Thomas KP, 2009, IEEE T BIO-MED ENG, V56, P2730, DOI 10.1109/TBME.2009.2026181; Thomas KP, 2008, IEEE ENG MED BIO, P1104, DOI 10.1109/IEMBS.2008.4649353; Tomioka R, 2010, NEUROIMAGE, V49, P415, DOI 10.1016/j.neuroimage.2009.07.045; Wang HX, 2008, IEEE T NEUR SYS REH, V16, P131, DOI 10.1109/TNSRE.2007.914468; Wu W, 2008, IEEE T BIO-MED ENG, V55, P1733, DOI 10.1109/TBME.2008.919125; Zhang HH, 2011, IEEE T NEURAL NETWOR, V22, P52, DOI 10.1109/TNN.2010.2084099	44	166	169	7	104	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2013	35	2					286	299		10.1109/TPAMI.2012.69	http://dx.doi.org/10.1109/TPAMI.2012.69			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	057JX	22431526	Green Submitted			2022-12-18	WOS:000312560600004
J	Bhattacharya, U; Chaudhuri, BB				Bhattacharya, Ujjwal; Chaudhuri, B. B.			Handwritten Numeral Databases of Indian Scripts and Multistage Recognition of Mixed Numerals	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Handwritten character recognition; Indian script character recognition; multiresolution recognition of characters; multistage recognition of characters	CHARACTER-RECOGNITION; MACHINE RECOGNITION; FEATURE-EXTRACTION; TRANSFORM; GRADIENT; OCR	This paper primarily concerns the problem of isolated handwritten numeral recognition of major Indian scripts. The principal contributions presented here are 1) pioneering development of two databases for handwritten numerals of the two most popular Indian scripts, 2) a multistage cascaded recognition scheme using wavelet-based multiresolution representations and multilayer perceptron (MLP) classifiers, and 3) application of 2 for the recognition of mixed handwritten numerals of three Indian scripts-Devanagari, Bangla, and English. The present databases include, respectively, 22,556 and 23,392 handwritten isolated numeral samples of Devanagari and Bangla collected from real-life situations, and these can be made available free of cost to researchers of other academic institutions. In the proposed scheme, a numeral is subjected to three MLP classifiers corresponding to three coarse-to-fine resolution levels in a cascaded manner. If rejection occurs even at the highest resolution, another MLP is used as the final attempt to recognize the input numeral by combining the outputs of three classifiers of the previous stages. This scheme has been extended to the situation when the script of a document is not known a priori or the numerals written on a document belong to different scripts. Handwritten numerals in mixed scripts are frequently found in Indian postal mail and tabular form documents.	[Bhattacharya, Ujjwal; Chaudhuri, B. B.] Indian Stat Inst, Comp Vis & Pattern Recognit Unit, Kolkata 700108, India	Indian Statistical Institute; Indian Statistical Institute Kolkata	Bhattacharya, U (corresponding author), Indian Stat Inst, Comp Vis & Pattern Recognit Unit, 203 BT Rd, Kolkata 700108, India.	ujjwal@isical.ac.in; bbc@isical.ac.in	Bhattacharya, Ujjwal/E-7891-2010					Al-Ohali Y, 2003, PATTERN RECOGN, V36, P111, DOI 10.1016/S0031-3203(02)00064-X; AMIN A, 1994, INT C PATT RECOG, P536, DOI 10.1109/ICPR.1994.577012; [Anonymous], 1998, NEURAL NETWORKS COMP; Arica N, 2001, IEEE T SYST MAN CY C, V31, P216, DOI 10.1109/5326.941845; Bajaj R, 2002, SADHANA-ACAD P ENG S, V27, P59, DOI 10.1007/BF02703312; Bansal V, 2000, IEEE T SYST MAN CY A, V30, P500, DOI 10.1109/3468.852443; Battacharya U, 2005, PROC INT CONF DOC, P789; Bhattacharya U, 2005, PROC INT CONF DOC, P322, DOI 10.1109/ICDAR.2005.118; Bhattacharya U, 2002, INT J PATTERN RECOGN, V16, P845, DOI 10.1142/S0218001402002027; Bhattacharya U., 2006, P 10 IWFHR, P613; BHATTACHARYA U, 2002, P 3 IND C COMP VIS G, P137; Bhownik TK, 2004, LECT NOTES COMPUT SC, V3316, P814; Bishop, 1995, NEURAL NETWORKS PATT; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CAO J, 1995, PATTERN RECOGN, V28, P153, DOI 10.1016/0031-3203(94)00094-3; Chaudhuri BB, 1998, PATTERN RECOGN, V31, P531, DOI 10.1016/S0031-3203(97)00078-2; Chaudhuri BB, 1997, IEEE T PATTERN ANAL, V19, P182, DOI 10.1109/34.574803; CHINNUSWAMY P, 1980, PATTERN RECOGN, V12, P141, DOI 10.1016/0031-3203(80)90038-2; DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199; Favata J.T., 1994, P 4 INT WORKSH FRONT, P57; Giusti N, 2002, IEEE T PATTERN ANAL, V24, P893, DOI 10.1109/TPAMI.2002.1017617; Hanmandlu M, 2007, PATTERN RECOGN, V40, P1840, DOI 10.1016/j.patcog.2006.08.014; Heutte L, 1998, PATTERN RECOGN LETT, V19, P629, DOI 10.1016/S0167-8655(98)00039-7; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; KIMURA F, 1987, IEEE T PATTERN ANAL, V9, P149, DOI 10.1109/TPAMI.1987.4767881; Kimura F., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P906, DOI 10.1109/ICDAR.1995.602048; KIMURA F, 2007, OCR TECHNOLOGIES MAC, P49; KRESSEL JSU, 1997, PATTERN CLASSIFICATI, P49; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LECUN Y, 1995, P INT C ART NEUR NET, P5360; LEE SW, 1994, PATTERN RECOGN, V27, P895, DOI 10.1016/0031-3203(94)90155-4; Lippmann R. P., 1988, Computer Architecture News, V16, P7, DOI [10.1109/MASSP.1987.1165576, 10.1145/44571.44572]; Liu CL, 2003, PATTERN RECOGN, V36, P2271, DOI 10.1016/S0031-3203(03)00085-2; LIU CL, 2002, INT J DOC ANAL RECOG, V4, P191; Liu HL, 2005, PROC INT CONF DOC, P19; MALLAT S, 1989, IEEE T PATTERN ANAL, V11, P7; NOUMI T, 1994, AUT M IEICE D, V309; Nunes CM, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P365, DOI 10.1109/IWFHR.2004.18; OH IS, 1998, INT J DOC ANAL RECOG, V1, P73; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Park J, 2000, IEEE T PATTERN ANAL, V22, P400, DOI 10.1109/34.845383; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; RAMAKRISHNAN KR, 1999, P 5 ICDAR, P414; Ramteke R. J., 2005, P INT C COGN REC, P482; ROY K, 2005, P IEEE IND ANN C, P570; Rumelhart D. E., 1985, 8506 U CAL I COGN SC; SAITO T, 1985, IEICE T D, V68, P757; SETHI IK, 1977, PATTERN RECOGN, V9, P69, DOI 10.1016/0031-3203(77)90017-6; Shi M, 2002, PATTERN RECOGN, V35, P2051, DOI 10.1016/S0031-3203(01)00203-5; SHUSTOROVICH A, 1994, NEURAL NETWORKS, V7, P1295, DOI 10.1016/0893-6080(94)90010-8; SINHA RMK, 1987, PATTERN RECOGN, V20, P475, DOI 10.1016/0031-3203(87)90075-6; SINHA RMK, 1979, IEEE T SYST MAN CYB, V9, P435; SOULIE FF, 1993, INT J PATTERN RECOGN, V5, P721; Srihari SN, 1989, INT J RES ENG POSTAL, V1, P37; SUEN CY, 1980, P IEEE, V68, P469, DOI 10.1109/PROC.1980.11675; Suen CY, 2005, PATTERN RECOGN LETT, V26, P369, DOI 10.1016/j.patrec.2004.10.019; SUKHASWAMI MB, 1995, INT J NEURAL SYST, V6, P317, DOI 10.1142/S0129065795000238; Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2; TSUKUMO J, 1988, P 9 INT C PATT REC, P168; Wanas N, 1998, UNIVERSITY AND INDUSTRY - PARTNERS IN SUCCESS, CONFERENCE PROCEEDINGS VOLS 1-2, P918, DOI 10.1109/CCECE.1998.685648; YAMADA H, 1990, PATTERN RECOGN, V23, P1023, DOI 10.1016/0031-3203(90)90110-7; [No title captured]	62	166	166	2	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2009	31	3					444	457		10.1109/TPAMI.2008.88	http://dx.doi.org/10.1109/TPAMI.2008.88			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	394VO	19147874				2022-12-18	WOS:000262480200005
J	Grady, L; Schwartz, EL				Grady, L; Schwartz, EL			Isoperimetric graph partitioning for image segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						graph-theoretic methods; graphs and networks; graph algorithms; image representation; special architectures; algorithms; computer vision; applications	SPARSE MATRICES; INEQUALITIES	Spectral graph partitioning provides a powerful approach to image segmentation. We introduce an alternate idea that finds partitions with a small isoperimetric constant, requiring solution to a linear system rather than an eigenvector problem. This approach produces the high quality segmentations of spectral methods, but with improved speed and stability.	Siemens Corp Res, Dept Imaging & Visualizat, Princeton, NJ 08540 USA; Boston Univ, Dept Cognit & Neural Syst, Boston, MA 02215 USA; Boston Univ, Dept Elect & Comp Engn, Boston, MA 02215 USA	Siemens AG; Boston University; Boston University	Grady, L (corresponding author), Siemens Corp Res, Dept Imaging & Visualizat, 755 Coll Rd E, Princeton, NJ 08540 USA.	leo.grady@siemens.com; eric@bu.edu	Patanaik, Amiya/G-4336-2010					ALON N, 1985, J COMB THEORY B, V38, P73, DOI 10.1016/0095-8956(85)90092-9; ANDERSON WN, 1971, 7145 TR U MAR; [Anonymous], 1977, VISUAL SYSTEM VERTEB, DOI [10.1007/978-3-642-66468-7_11, DOI 10.1007/978-3-642-66468-7_11, DOI 10.1007/978-3-642-66468-7]; Biggs N., 1974, CAMBRIDGE TRACTS MAT, V67; Boykov Y.Y., 2001, ICCV, V1, P105, DOI DOI 10.1109/ICCV.2001.937505; Branin FH, 1966, S GEN NETW, P453; CHEEGER J., 1970, PROBLEMS ANAL PAPERS, P195, DOI [10.1515/9781400869312-013, DOI 10.1515/9781400869312-013]; CHUNG F, 1997, REG C SER MATH, V92; DODZIUK J, 1984, T AM MATH SOC, V284, P787, DOI 10.2307/1999107; DODZIUK J, 1986, LOCAL TIMES GLOBAL G, P68; Doyle P.G., 1984, CARUS MATH MONOGRAPH, V22, DOI 10.4169/j.ctt5hh804; FIEDLER M, 1973, CZECH MATH J, V23, P298; Fiedler M., 1986, SPECIAL MATRICES THE; FINEMAN M, 1996, NATURE VISUAL ILLUSI; GILBERT JR, 1992, SIAM J MATRIX ANAL A, V13, P333, DOI 10.1137/0613024; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Grady L, 2004, PROC CVPR IEEE, P360; Grady L, 2004, LECT NOTES COMPUT SC, V3117, P230; GRADY L, 2005, SIAM J SCI COMPUTING; Grady L., 2004, THESIS BOSTON U; HAGEN L, 1992, IEEE T COMPUT AID D, V11, P1074, DOI 10.1109/43.159993; HU YF, 1994, PARALLEL COMPUT, V20, P815, DOI 10.1016/0167-8191(94)90009-4; Lehoucq RB, 1998, ARPACK USERS GUIDE S; MOHAR B, 1988, LINEAR ALGEBRA APPL, V103, P119, DOI 10.1016/0024-3795(88)90224-8; MOHAR B, 1989, J COMB THEORY B, V47, P274, DOI 10.1016/0095-8956(89)90029-4; POTHEN A, 1990, SIAM J MATRIX ANAL A, V11, P430, DOI 10.1137/0611030; Sarkar S, 2000, IEEE T PATTERN ANAL, V22, P504, DOI 10.1109/34.857006; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; SPIELMAN DA, 1996, CSD96898 UCB; Tetali P., 1991, J THEOR PROBAB, V4, P101, DOI [10.1007/BF01046996, DOI 10.1007/BF01046996]; Wang S, 2003, IEEE T PATTERN ANAL, V25, P675, DOI 10.1109/TPAMI.2003.1201819; WEI YC, 1991, IEEE T COMPUT AID D, V10, P911, DOI 10.1109/43.87601; WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673	33	166	200	0	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2006	28	3					469	475		10.1109/TPAMI.2006.57	http://dx.doi.org/10.1109/TPAMI.2006.57			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	001FB	16526432				2022-12-18	WOS:000234517900012
J	Vedula, S; Baker, S; Rander, P; Collins, R; Kanade, T				Vedula, S; Baker, S; Rander, P; Collins, R; Kanade, T			Three-dimensional scene flow	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						scene flow; three-dimensional dense nonrigid motion; optical flow; the brightness constancy constraint; normal flow; three-dimensional normal flow	NONRIGID MOTION; RECONSTRUCTION; RECOVERY	Just as optical flow is the two-dimensional motion of points in an image, scene flow is the three-dimensional motion of points in the world. The fundamental difficulty with optical flow is that only the normal flow can be computed directly from the image measurements, without some form of smoothing or regularization. In this paper, we begin by showing that the same fundamental limitation applies to scene flow; however, many cameras are used to image the scene. There are then two choices when computing scene flow: 1) perform the regularization in the images or 2) perform the regularization on the surface of the object in the scene. In this paper, we choose to compute scene flow using regularization in the images. We describe three algorithms, the first two for computing scene flow from optical flows and the third for constraining scene structure from the inconsistencies in multiple optical flows.	Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; Natl Robot Engn Consortium, Pittsburgh, PA 15201 USA	Carnegie Mellon University	Vedula, S (corresponding author), 970 Corte Madera Ct 204, Sunnyvale, CA 94085 USA.	srv@cs.cmu.edu; simonb@cs.cmu.edu; rander@cs.smu.edu; rcollins@cs.cmu.edu; tk@cs.cmu.edu						AVIDAN S, 1998, IEEE C COMPUTER VISI, V2, P62; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Black M. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P231, DOI 10.1109/ICCV.1993.378214; Carceroni RL, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P60; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; Horn B., 1986, ROBOT VISION, P1; KANADE T, 1998, CMURITR9834; Landy M.S., 1991, COMPUTATIONAL MODELS; Liao WH, 1997, MACH VISION APPL, V9, P166, DOI 10.1007/s001380050038; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; Malassiotis S, 1997, COMPUT VIS IMAGE UND, V65, P79, DOI 10.1006/cviu.1996.0481; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; NEGAHDARIPOUR S, 1987, IEEE T PATTERN ANAL, V9, P168, DOI 10.1109/TPAMI.1987.4767884; PENNA MA, 1994, CVGIP-IMAG UNDERSTAN, V60, P141, DOI 10.1006/ciun.1994.1043; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P730, DOI 10.1109/34.85661; Seitz SM, 1999, INT J COMPUT VISION, V35, P151, DOI 10.1023/A:1008176507526; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; ULLMAN S, 1984, PERCEPTION, V13, P255, DOI 10.1068/p130255; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; Vedula S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P722, DOI 10.1109/ICCV.1999.790293; VEDULA S, 2002, P 13 ACM EUR WORKSH, P65; VEDULA S, 2001, THESIS CARNEGIE MELL; WAXMAN AM, 1986, IEEE T PATTERN ANAL, V8, P715, DOI 10.1109/TPAMI.1986.4767853; YOUNG GS, 1999, IEEE T PATTERN ANAL, V12, P735	24	166	171	1	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2005	27	3					475	480		10.1109/TPAMI.2005.63	http://dx.doi.org/10.1109/TPAMI.2005.63			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	887IW	15747803				2022-12-18	WOS:000226300200017
J	Somol, P; Pudil, P; Kittler, J				Somol, P; Pudil, P; Kittler, J			Fast branch & bound algorithms for optimal feature selection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						subset search; feature selection; search tree; optimum search; subset selection; dimensionality reduction; artificial intelligence	FEATURE SUBSET-SELECTION; SEARCH	A novel search principle for optimal feature subset selection using the Branch & Bound method is introduced. Thanks to a simple mechanism for predicting criterion values, a considerable amount of time can be saved by avoiding many slow criterion evaluations. We propose two implementations of the proposed prediction mechanism that are suitable for use with nonrecursive and recursive criterion forms, respectively. Both algorithms find the optimum usually several times faster than any other known Branch & Bound algorithm. As the algorithm computational efficiency is crucial, due to the exponential nature of the search problem, we also investigate other factors that affect the search performance of all Branch & Bound algorithms. Using a set of synthetic criteria, we show that the speed of the Branch & Bound algorithms strongly depends on the diversity among features, feature stability with respect to different subsets, and criterion function dependence on feature set size. We identify the scenarios where the search is accelerated the most dramatically (finish in linear time), as well as the worst conditions. We verify our conclusions experimentally on three real data sets using traditional probabilistic distance criteria.	Acad Sci, Inst Informat Theory & Automat, Dept Pattern Recognit, Prague 18208, Czech Republic; Prague Univ Econ, Fac Management, Jindrichuv Hradec 37701, Czech Republic; Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England	Czech Academy of Sciences; Institute of Information Theory & Automation of the Czech Academy of Sciences; University of Surrey	Somol, P (corresponding author), Acad Sci, Inst Informat Theory & Automat, Dept Pattern Recognit, Pod Vodarenskou Vezi 4, Prague 18208, Czech Republic.	somol@utia.cas.cz; pudil@fm.vse.cz; j.kittler@eim.surrey.ac.uk	Pudil, Pavel/AAL-7594-2020; Pudil, Pavel/I-6071-2013	Pudil, Pavel/0000-0002-6474-0257; 	Engineering and Physical Sciences Research Council [GR/S46543/01] Funding Source: researchfish	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		Caruna R, 1994, P 11 INT C MACH LEAR, P28; CHAIKLA N, 1999, P 1999 IEEE INT C SY, V5, P538; Devijver PA, 1982, PATTERN RECOGNITION; FOROUTAN I, 1987, IEEE T SYST MAN CYB, V17, P187, DOI 10.1109/TSMC.1987.4309029; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; GENGLER M, 1994, PARALLEL ALGORITHMS, V2, P61; HAMAMOTO Y, 1990, PATTERN RECOGN LETT, V11, P453, DOI 10.1016/0167-8655(90)90078-G; Iamnitchi A, 2000, PROC INT CONF PARAL, P4, DOI 10.1109/ICPP.2000.876065; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Koller D, 1996, P 13 INT C MACH LEAR, V96, P284; KORF RE, 1999, HDB ALGORITHMS THEOR, pCH36; Kudo M, 2000, PATTERN RECOGN, V33, P25, DOI 10.1016/S0031-3203(99)00041-2; KUMAR V, 1983, ARTIF INTELL, V21, P179, DOI 10.1016/S0004-3702(83)80009-5; LAWLER EL, 1966, OPER RES, V14, P699, DOI 10.1287/opre.14.4.699; Liu H, 1998, P EUR C MACH LEARN, P101; MITSCHELETHIEL A, 1994, TRANSPUT OCCAM ENG S, P153; Murphy P., 1994, UCI REPOSITORY MACHI; NARENDRA P, 1977, IEEE T COMPUT, V26, P917, DOI 10.1109/TC.1977.1674939; Nilsson J., 1999, ARTIF INTELL; Nilsson N.J., 1971, PROBLEM SOLVING METH; SOMOL P, 2001, LECT NOTES COMPUTER, V2013, P230; Somol P., 2000, P 4T WORLD MULT SYST, V7, P646; Webb GI, 1995, J ARTIF INTELL RES, V3, P431, DOI 10.1613/jair.227; Yang M. K., 1999, Proceedings of the 1999 International Conference on Parallel Processing, P112, DOI 10.1109/ICPP.1999.797395; YU B, 1993, PATTERN RECOGN, V26, P883, DOI 10.1016/0031-3203(93)90054-Z; [No title captured]	28	166	174	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2004	26	7					900	912		10.1109/TPAMI.2004.28	http://dx.doi.org/10.1109/TPAMI.2004.28			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	819OG	18579948	Green Submitted			2022-12-18	WOS:000221323900007
J	Vinciarelli, A; Bengio, S; Bunke, H				Vinciarelli, A; Bengio, S; Bunke, H			Offline recognition of unconstrained handwritten texts using HMMs and statistical language models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						offline cursive handwriting recognition; statistical language models; N-grams; continuous density Hidden Markov Models	PROBABILISTIC FUNCTIONS; LINE	This paper presents a system for the offline recognition of large vocabulary unconstrained handwritten texts. The only assumption made about the data is that it is written in English. This allows the application of Statistical Language Models in order to improve the performance of our system. Several experiments have been performed using both single and multiple writer data. Lexica of variable size (from 10,000 to 50,000 words) have been used. The use of language models is shown to improve the accuracy of the system (when the lexicon contains 50,000 words, the error rate is reduced by similar to 50 percent for single writer data and by similar to 25 percent for multiple writer data). Our approach is described in detail and compared with other methods presented in the literature to deal with the same problem. An experimental setup to correctly deal with unconstrained text recognition is proposed.	IDIAP, Dalle Molle Inst Perceptual Artificial Intelligen, CH-1920 Martigny, Switzerland; Univ Bern, CH-3012 Bern, Switzerland	University of Bern	Vinciarelli, A (corresponding author), IDIAP, Dalle Molle Inst Perceptual Artificial Intelligen, Rua Simplon 4, CH-1920 Martigny, Switzerland.	vincia@idiap.ch; bengio@idiap.ch; bunke@iam.unibe.ch	Vinciarelli, Alessandro/C-1651-2012	Vinciarelli, Alessandro/0000-0002-9048-0524				BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; Baum LE, 1972, INEQUALITIES, V3, P1; BELLMAN R, 1991, ADAPTIVE CONTROL PRO; Chen SF, 2000, IEEE T SPEECH AUDI P, V8, P37, DOI 10.1109/89.817452; COHEN E, 1994, IEEE T PATTERN ANAL, V16, P1049, DOI 10.1109/34.329003; El Yacoubi A., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P1024, DOI 10.1109/ICDAR.1995.602077; El-Yacoubi MA, 2002, IEEE T PATTERN ANAL, V24, P172, DOI 10.1109/34.982898; GRAFF D, 2000, P TOP DET TRACK WORK; Guillevic D, 1998, PATTERN ANAL APPL, V1, P28, DOI 10.1007/BF01238024; JELINEK F, 1989, READINGS SPEECH RECO, P450; JELINEK F, 1998, STAT ASPECTS SPEECH; KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125; Kim G., 1999, International Journal on Document Analysis and Recognition, V2, P37, DOI 10.1007/s100320050035; KIM G, 1999, PATTERN RECOGN, V2, P37; Kim GG, 1998, PATTERN RECOGN, V31, P41, DOI 10.1016/S0031-3203(97)00023-X; Klakow D, 2002, SPEECH COMMUN, V38, P19, DOI 10.1016/S0167-6393(01)00041-3; Luttin J., 2000, P 7 INT WORKSH FRONT, P493; Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071; Marti UV, 2001, INT J PATTERN RECOGN, V15, P65, DOI 10.1142/S0218001401000848; PAQUET T, 1993, PATTERN RECOGN, V26, P391, DOI 10.1016/0031-3203(93)90167-U; Park J, 2002, PATTERN RECOGN, V35, P245, DOI 10.1016/S0031-3203(00)00176-X; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083; Rosenfeld R, 1996, COMPUT SPEECH LANG, V10, P187, DOI 10.1006/csla.1996.0011; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Senior AW, 1998, IEEE T PATTERN ANAL, V20, P309, DOI 10.1109/34.667887; SRIHARI RK, 1993, IJCAI-93, VOLS 1 AND 2, P1262; SRIHARI RK, 1994, P ARPA WORKSH HUM LA, P403; STEINHERZ T, 1999, INT J DOC ANAL RECOG, V2, P1; Vinciarelli A, 2002, PATTERN RECOGN, V35, P1433, DOI 10.1016/S0031-3203(01)00129-7; Vinciarelli A, 2001, PATTERN RECOGN LETT, V22, P1043, DOI 10.1016/S0167-8655(01)00042-3; VINCIARELLI A, 2002, P INT C PATT REC ICP, P493; VINCIARELLI A, 2003, P INT C DOC AN REC; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010; Zimmermann M, 2002, INT C PATT RECOG, P35, DOI 10.1109/ICPR.2002.1047394	37	166	171	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2004	26	6					709	720						12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	811EZ	18579932	Green Submitted			2022-12-18	WOS:000220756500005
J	Dy, JG; Brodley, CE; Kak, A; Broderick, LS; Aisen, AM				Dy, JG; Brodley, CE; Kak, A; Broderick, LS; Aisen, AM			Unsupervised feature selection applied to content-based retrieval of lung images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image retrieval; feature selection; clustering; expectation-maximization; unsupervised learning		This paper describes a new hierarchical approach to content-based image retrieval called the "customized-queries" approach (CQA). Contrary to the single feature vector approach which tries to classify the query and retrieve similar images in one step, CQA uses multiple feature sets and a two-step approach to retrieval. The first step classifies the query according to the class labels of the images using the features that best discriminate the classes. The second step then retrieves the most similar images within the predicted class using the features customized to distinguish "subclasses" within that class. Needing to find the customized feature subset for each class led us to investigate feature selection for unsupervised learning. As a result, we developed a new algorithm called FSSEM (feature subset selection using expectation-maximization clustering). We applied our approach to a database of high resolution computed tomography lung images and show that CQA radically improves the retrieval precision over the single feature vector approach. To determine whether our CBIR system is helpful to physicians, we conducted an evaluation trial with eight radiologists. The results show that our system using CQA retrieval doubled the doctors' diagnostic accuracy.	Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA; Indiana Univ, Med Ctr, Dept Radiol, Indianapolis, IN 46202 USA; Univ Wisconsin, Dept Radiol, Madison, WI 53706 USA; Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA	Northeastern University; Indiana University System; Indiana University-Purdue University Indianapolis; University of Wisconsin System; University of Wisconsin Madison; Purdue University System; Purdue University; Purdue University West Lafayette Campus	Dy, JG (corresponding author), Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.	jdy@ece.neu.edu; brodley@ecn.purdue.edu; kak@ecn.purdue.edu; lsbroderick@facstaff.wisc.edu; aaisen@iupui.edu						ALMUALLIM H, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P547; [Anonymous], 1997, ARCHITECTURE PLUS DE, V14, P92; Cardie C., 1993, P 10 INT C MACH LEAR, P25; CHEN J, 1998, P SPIE IS T C HUM VI, V3299; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dy J.-G., 2000, 17 INT C MACHINE LEA, P247; Dy JG, 1998, PROC SPIE, V3656, P22, DOI 10.1117/12.333849; DY JG, 2001, THESIS PURDUE U W LA; DY JG, 1999, P IEEE C COMP VIS PA, V2, P400; Fayyad U., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining, P194; Fisher D. H., 1987, Machine Learning, V2, P139, DOI 10.1007/BF00114265; FLICKNER M, 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Fukunaga K, 1990, STAT PATTERN RECOGNI; Kittler J., 1978, Pattern Recognition and Signal Processing, P41; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Ma WY, 1996, PROC CVPR IEEE, P425, DOI 10.1109/CVPR.1996.517107; McLachlan G.J., 1988, MIXTURE MODELS INFER, V38; Minka TP, 1996, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.1996.517110; Pentland A., 1994, SPIE STORAGE RETRIEV; Quinlan JR, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P725; RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150; Rui Y, 2000, PROC CVPR IEEE, P236, DOI 10.1109/CVPR.2000.855825; RUSSELL JS, 1995, ARTIFICIAL INTELLIGE; SCHAPIRE RE, 1997, P 14 INT C MACH LEAR, P322; Shyu CR, 1999, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES (CBAIVL'99) - PROCEEDINGS, P102, DOI 10.1109/IVL.1999.781132; Shyu CR, 1999, COMPUT VIS IMAGE UND, V75, P111, DOI 10.1006/cviu.1999.0768; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; SMYTH P, 1996, P 2 INT C KNOWL DISC, P126; Talavera L, 1999, MACHINE LEARNING, PROCEEDINGS, P389; TAYCHER L, 1997, P INT C VIS INF; Tieu K, 2000, PROC CVPR IEEE, P228, DOI 10.1109/CVPR.2000.855824; TITTERINGTON DM, 1985, STAT FINITE MIXTURE; Vaithyanathan S, 1999, MACHINE LEARNING, PROCEEDINGS, P433; Webb W.R., 2014, HIGH RESOLUTION CT L; WOLFE JH, 1970, MULTIVARIATE BEHAV R, V5, P101	36	166	177	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2003	25	3					373	378		10.1109/TPAMI.2003.1182100	http://dx.doi.org/10.1109/TPAMI.2003.1182100			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	647BL		Green Submitted			2022-12-18	WOS:000181071300009
J	Lee, LL; Berger, T; Aviczer, E				Lee, LL; Berger, T; Aviczer, E			Reliable on-line human signature verification systems	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						signature verification; human signature verification; dynamic signature verification; on-line signature verification; point-of-sale; point-of-delivery; forgery		On-line dynamic signature verification systems were designed and tested. A data base of more than 10,000 signatures in (x(t), y(t))-form was acquired using a graphics tablet. We extracted a 42-parameter feature set at first, and advanced to a set of 49 normalized features that tolerate inconsistencies in genuine signatures while retaining the power to discriminate against forgeries. We studied algorithms for selecting and perhaps orthogonalizing features in accordance with the availability of training data and the level of system complexity. For decision making we studied several classifiers types. A modified version of our majority classifier yielded 2.5% equal error rate and, more importantly, an asymptotic performance of 7% false acceptance rate at zero false rejection rate, was robust to the speed of genuine signatures, and used only 15 parameter features.	CORNELL UNIV,SCH ELECT ENGN,ITHACA,NY 14853; AT&T BELL LABS,HOLMDEL,NJ	Cornell University; AT&T; Nokia Corporation; Nokia Bell Labs	Lee, LL (corresponding author), UNIV CAMPINAS,FAC ELECT ENGN,DECOM FEE,BR-13081970 CAMPINAS,SP,BRAZIL.		Ling, Lee L/V-5185-2017	Ling, Lee L/0000-0002-0835-1601				ACHEMLAL M, 1989, SECURITY PROTECTION, P381; AVICZER E, 1991, ON LINE SIGNATURE VE; BONNEFOY JP, 1981, P 3 C REC FORM INT A, P267; CHIU YJ, 1992, ON LINE SIGNATURE VE; CRANE HD, 1983, IEEE T SYST MAN CYB, V12, P329; Dimauro G., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P771, DOI 10.1142/S0218001494000401; Fairhurst M. C., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P661, DOI 10.1142/S0218001494000358; KISHON E, 1991, P IEEE C SYSTEMS MAN; Leclerc F., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P643, DOI 10.1142/S0218001494000346; LEE LL, 1992, THESIS CORNELL U; LEE LL, 1993, P INT C SIGN PROC IC; LEE LL, 1996, Patent No. 7790965; LEE LL, 1993, P INT C ART NEUR NET; LORETTE G, 1984, P 7 INT C PATT REC M, V2, P1284; Nelson W., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P749, DOI 10.1142/S0218001494000395; Plamondon R., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P795, DOI 10.1142/S0218001494000413; PLAMONDON R, 1989, PATTERN RECOGN, V22, P107, DOI 10.1016/0031-3203(89)90059-9; SATO Y, 1982, 6TH P INT C PATT REC, P823; YANG L, 1995, PATTERN RECOGN, V28, P161, DOI 10.1016/0031-3203(94)00092-Z	19	166	175	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1996	18	6					643	647		10.1109/34.506415	http://dx.doi.org/10.1109/34.506415			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UR254					2022-12-18	WOS:A1996UR25400008
J	BEAULIEU, JM; GOLDBERG, M				BEAULIEU, JM; GOLDBERG, M			HIERARCHY IN PICTURE SEGMENTATION - A STEPWISE OPTIMIZATION APPROACH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV OTTAWA,DEPT ELECT ENGN,OTTAWA K1N 6N5,ONTARIO,CANADA	University of Ottawa	BEAULIEU, JM (corresponding author), UNIV LAVAL,DEPT COMP SCI,QUEBEC CITY G1K 7P4,QUEBEC,CANADA.							Bacus J. W., 1977, The First Annual Symposium on Computer Application in Medical Care, P24; Bajcsy R., 1980, STRUCTURED COMPUTER, P133; Ballard D.H., 1982, COMPUTER VISION; BEAULIEU JM, 1982, P CAN COMM EN C MONT, P393; BEAULIEU JM, 1985, THESIS U OTTAWA OTTA; BOULT TE, 1985, P IMAGE UNDERSTANDIN, P197; BRICE CR, 1970, ARTIF INTELL, V1, P205, DOI 10.1016/0004-3702(70)90008-1; Carlton S. G., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing, P360; CHEN PC, 1980, COMPUT VISION GRAPH, V12, P153, DOI 10.1016/0146-664X(80)90009-X; Davis L. S., 1975, COMPUT VISION GRAPH, V4, P248, DOI [DOI 10.1016/0146-664X(75)90012-X, 10.1016/0146-664X(75)90012-X]; Duda R.O., 1973, J ROYAL STAT SOC SER; FREUDER EC, 1976, COMPUT GRAPHICS IMAG, V5, P254; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GUPTA JN, 1975, IEEE T CIRCUITS SYST, VCA22, P351, DOI 10.1109/TCS.1975.1084043; HARALICK RM, 1980, COMPUT VISION GRAPH, V12, P60, DOI 10.1016/0146-664X(80)90004-0; HOROWITZ SL, 1976, J ACM, V23, P368, DOI 10.1145/321941.321956; KETTIG RL, 1976, IEEE T GEOSCI REMOTE, V14, P19, DOI 10.1109/TGE.1976.294460; KOHLER R, 1981, COMPUT VISION GRAPH, V15, P319, DOI 10.1016/S0146-664X(81)80015-9; LEVINE MD, 1985, IEEE T PATTERN ANAL, V7, P155, DOI 10.1109/TPAMI.1985.4767640; LINDGREN BW, 1976, STATISTICAL THEORY; Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22; Nagao M., 1980, STRUCTURAL ANAL COMP; NARAYANAN KA, 1982, IEEE T SYST MAN CYB, V12, P91; PARMA CC, 1980, EXPT SCHEMA DRIVEN I; PELEG S, 1984, COMPUT VISION GRAPH, V25, P122, DOI 10.1016/0734-189X(84)90052-5; POGGIO T, 1985, COMPUT VISION GRAPH, V31, P139, DOI 10.1016/S0734-189X(85)80003-7; SIMON JC, 1978, 4TH P INT JOINT C PA, P19; Sneath P.H.A., 1973, NUMERICAL TAXONOMY P; TANIMOTO S, 1980, STRUCTURED COMPUTER; TANIMOTO SL, 1978, COMPUTER VISION SYST, P165; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; Tikhonov A., 1977, SOLUTIONS ILL POSED; Tou JT, 1974, PATTERN RECOGN; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; Zucker S. W., 1976, Computer Graphics and Image Processing, V5, P382, DOI 10.1016/S0146-664X(76)80014-7; [No title captured]	36	166	188	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1989	11	2					150	163		10.1109/34.16711	http://dx.doi.org/10.1109/34.16711			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	R9989					2022-12-18	WOS:A1989R998900004
J	JAIN, R; NAGEL, HH				JAIN, R; NAGEL, HH			ANALYSIS OF ACCUMULATIVE DIFFERENCE PICTURES FROM IMAGE SEQUENCES OF REAL WORLD SCENES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV TEXAS,DEPT ELECT ENGN,AUSTIN,TX 78712; UNIV HAMBURG,FACHBEREICH INFORMAT,D-2000 HAMBURG 13,FED REP GER	University of Texas System; University of Texas Austin; University of Hamburg								ALLEN AD, 1974, IEEE T SYST MAN CYB, VSMC4, P66, DOI 10.1109/TSMC.1974.5408522; JAIN R, 1978, APR IEEE WORKSH PATT; JAIN R, 1977, 1977 INT JOINT C ART, P612; MARTIN WN, 1978, COMPUT VISION GRAPH, V7, P356, DOI 10.1016/S0146-664X(78)80003-3; NAGEL HH, 1978, COMPUT VISION GRAPH, V7, P149, DOI 10.1016/0146-664X(78)90111-9; NAGEL HH, 1976, 1976 P IJCPR COR, P803; NAGEL HH, 1977, 1977 P IJCAI CAMBR, P626; NAGEL HH, 1978, NOV IJCPR KYOT; YAKIMOVSKY Y, 1976, J ACM, V23, P599, DOI 10.1145/321978.321981	9	166	184	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	2					206	214		10.1109/TPAMI.1979.4766907	http://dx.doi.org/10.1109/TPAMI.1979.4766907			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HA304	21868850				2022-12-18	WOS:A1979HA30400011
J	Marteau, PF				Marteau, Pierre-Francois			Time Warp Edit Distance with Stiffness Adjustment for Time Series Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pattern recognition; time series; algorithms; similarity measures	APPROXIMATION; ALGORITHM; SEQUENCE; SEARCH	In a way similar to the string-to-string correction problem, we address discrete time series similarity in light of a time-series-to-time-series-correction problem for which the similarity between two time series is measured as the minimum cost sequence of edit operations needed to transform one time series into another. To define the edit operations, we use the paradigm of a graphical editing process and end up with a dynamic programming algorithm that we call Time Warp Edit Distance (TWED). TWED is slightly different in form from Dynamic Time Warping (DTW), Longest Common Subsequence (LCSS), or Edit Distance with Real Penalty (ERP) algorithms. In particular, it highlights a parameter that controls a kind of stiffness of the elastic measure along the time axis. We show that the similarity provided by TWED is a potentially useful metric in time series retrieval applications since it could benefit from the triangular inequality property to speed up the retrieval process while tuning the parameters of the elastic measure. In that context, a lower bound is derived to link the matching of time series into downsampled representation spaces to the matching into the original space. The empiric quality of the TWED distance is evaluated on a simple classification task. Compared to Edit Distance, DTW, LCSS, and ERP, TWED has proved to be quite effective on the considered experimental task.	Univ Europeenne Bretagne Sud VALOR IA, F-56017 Vannes, France		Marteau, PF (corresponding author), Univ Europeenne Bretagne Sud VALOR IA, Campus Tohann Bat Yves Coppens,BP 573, F-56017 Vannes, France.	pierre-francois.marteau@univ-ubs.fr	Marteau, Pierre-Francois/U-5184-2019	Marteau, Pierre-Francois/0000-0002-3963-8795	French Ministere de l'Enseignement Superieur et de la Recherche	French Ministere de l'Enseignement Superieur et de la Recherche	This work was partially supported by the French Ministere de l'Enseignement Superieur et de la Recherche.	AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Bellman RE, 1957, DYNAMIC PROGRAMMING; Chavez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808; Chen L., 2004, P 30 INT C VERY LARG, V30, P792, DOI [10.1016/B978-012088469-8/50070-X, DOI 10.1016/B978-012088469-8/50070-X]; Chen L., 2005, P 2005 ACM SIGMOD IN, P491, DOI DOI 10.1145/1066157.1066213; Chiba S., 1971, P 7 INT C ACOUSTICS, VVolume 3, P65; DAS G, 1997, P C PRINC KNOWL DISC, P454; Douglas DH, 1973, CARTOGR INT J GEOGR, V10, P112, DOI [10.3138/fm57-6770-u75u-7727, DOI 10.3138/FM57-6770-U75U-7727]; Durbin R., 1998, BIOL SEQUENCE ANAL P; FINK E, 2004, DATA MINING TIME SER, P43; Imai H., 1988, COMPUTATIONAL MORPHO, P71; Keogh E., 2001, Knowledge and Information Systems, V3, P263, DOI 10.1007/PL00011669; KEOGH E, 2006, P 32 INT C VER LARG, P882; Keogh E, 2006, UCR TIME SERIES CLAS; Keogh EJ, 2000, LECT NOTES ARTIF INT, V1805, P122, DOI 10.1007/3-540-45571-x_14; Kolesnikov A, 2003, PATTERN RECOGN LETT, V24, P2243, DOI 10.1016/S0167-8655(03)00051-5; LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845; Lin J, 2005, COMP MED SY, P329, DOI 10.1109/CBMS.2005.34; Makinen V, 2001, EIGHTH SYMPOSIUM ON STRING PROCESSING AND INFORMATION RETRIEVAL, PROCEEDINGS, P153, DOI 10.1109/SPIRE.2001.989751; MANINEN V, 2003, THESIS U HELSINKI; MARTEAU PF, 2008, VALORIAUBS20083V; MARTEAU PF, 2008, J PATTERN ANAL A JUN, P1; Martin E, 2006, ADV GLOB CHANGE RES, V23, P235; Moore P, 2007, IMVIP 2007: INTERNATIONAL MACHINE VISION AND IMAGE PROCESSING CONFERENCE, PROCEEDINGS, P55, DOI 10.1109/IMVIP.2007.31; NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4; NG MK, 1997, LECT NOTES COMPUTER, P2; Park S, 2007, INFORM SCIENCES, V177, P4859, DOI 10.1016/j.ins.2007.06.020; PEREZ JC, 1994, PATTERN RECOGN LETT, V15, P743, DOI 10.1016/0167-8655(94)90002-7; Ratanamahatana CA, 2004, SIAM PROC S, P11; SINGH A, 1998, DEFORMABLE MODELS ME; VELICHKO VM, 1970, INT J MAN MACH STUD, V2, P223, DOI 10.1016/S0020-7373(70)80008-6; Vlachos M, 2003, P 9 ACM SIGKDD INT C, P216, DOI DOI 10.1145/956750.956777; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; Wang YQ, 2003, CHINESE EDUC SOC, V36, P74; WU H, 2004, P INT C MAN DAT ACM, P23, DOI DOI 10.1145/1007568.1007574	37	165	176	3	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2009	31	2					306	318		10.1109/TPAMI.2008.76	http://dx.doi.org/10.1109/TPAMI.2008.76			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	385XL	19110495	Green Submitted			2022-12-18	WOS:000261846800008
J	Nock, R; Nielsen, F				Nock, Richard; Nielsen, Frank			On weighting clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						clustering; Bregman divergences; k-means; fuzzy k-means; expectation maximization; harmonic means clustering		Recent papers and patents in iterative unsupervised learning have emphasized a new trend in clustering. It basically consists of penalizing solutions via weights on the instance points, somehow making clustering move toward the hardest points to cluster. The motivations come principally from an analogy with powerful supervised classification methods known as boosting algorithms. However, interest in this analogy has so far been mainly borne out from experimental studies only. This paper is, to the best of our knowledge, the first attempt at its formalization. More precisely, we handle clustering as a constrained minimization of a Bregman divergence. Weight modifications rely on the local variations of the expected complete log- likelihoods. Theoretical results show benefits resembling those of boosting algorithms and bring modified ( weighted) versions of clustering algorithms such as k- means, fuzzy c- means, Expectation Maximization ( EM), and k- harmonic means. Experiments are provided for all these algorithms, with a readily available code. They display the advantages that subtle data reweighting may bring to clustering.	Univ Antilles Guyane, GRIMAAG Lab, Dept Sci Interfac, F-97278 Schoelcher, Martinique, France; Sony Comp Sci Labs Inc, Shinagawa Ku, Tokyo 1410022, Japan	Sony Corporation	Nock, R (corresponding author), Univ Antilles Guyane, GRIMAAG Lab, Dept Sci Interfac, BP 7209, F-97278 Schoelcher, Martinique, France.	rnock@martinique.univ-ag.fr; Frank.Nielsen@acm.org		Nielsen, Frank/0000-0001-5728-0726				[Anonymous], 1997, P UNC ART INT AUG; Attias H, 2000, ADV NEUR IN, V12, P209; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; Banerjee A, 2004, SIAM PROC S, P234; Beal MJ, 2003, BAYESIAN STATISTICS 7, P453; Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; BUDIMIR I, 2000, I INEQUALITIES PURE, V3; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; GENTILE C, 2000, P TUT 13 INT C COMP; Hamerly G., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P600, DOI 10.1145/584792.584890; Kearns M., 1988, THOUGHTS HYPOTHESIS; Kivinen J., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, P134, DOI 10.1145/307400.307424; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Topchy A, 2004, INT C PATT RECOG, P272, DOI 10.1109/ICPR.2004.1334105; ZHANG B, 2000, TRHPL2000137 HEWL PA; ZHANG B, 2000, TEMPORAL SPATIAL SPA, P31; Zhang B., 2000, US Patent, Patent No. [6,584,433, 6584433]	20	165	172	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2006	28	8					1223	1235		10.1109/TPAMI.2006.168	http://dx.doi.org/10.1109/TPAMI.2006.168			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	051LK	16886859				2022-12-18	WOS:000238162400005
J	Pernkopf, F; Bouchaffra, D				Pernkopf, F; Bouchaffra, D			Genetic-based EM algorithm for learning Gaussian mixture models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						unsupervised learning; clustering; Gaussian mixture models; EM algorithm; genetic algorithm; minimum description length		We propose a genetic-based expectation-maximization (GA-EM) algorithm for learning Gaussian mixture models from multivariate data. This algorithm is capable of selecting the number of components of the model using the minimum description length (MDL) criterion. Our approach benefits from the properties of Genetic algorithms (GA) and the EM algorithm by combination of both into a single procedure. The population-based stochastic search of the GA explores the search space more thoroughly than the EM method. Therefore, our algorithm enables escaping from local optimal solutions since the algorithm becomes less sensitive to its initialization. The GA-EM algorithm is elitist which maintains the monotonic convergence property of the EM algorithm. The experiments on simulated and real data show that the GA-EM outperforms the EM method since: 1) We have obtained a better MDL score while using exactly the same termination condition for both algorithms. 2) Our approach identifies the number of components which were used to generate the underlying data more often than the EM algorithm.	Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA; Graz Univ Technol, Lab Signal Proc & Speech Commun, A-8010 Graz, Austria; Oakland Univ, Dept Comp Sci & Engn, Rochester, MI 48309 USA	University of Washington; University of Washington Seattle; Graz University of Technology; Oakland University	Pernkopf, F (corresponding author), Univ Washington, Dept Elect Engn, M254 EE-CSE Bldg,Box 352500, Seattle, WA 98195 USA.	fpernkop@ee.washington.edu; bouchaff@oakland.edu						Back T, 1996, IEEE C EVOL COMPUTAT, P20, DOI 10.1109/ICEC.1996.542329; Back T, 1996, EVOLUTIONARY ALGORIT; CELEUX G, 1999, 3746 INRIA; Dasgupta S., 1999, P 40 ANN S FDN COMP, P634, DOI [10.5555/795665.796496, DOI 10.5555/795665.796496, DOI 10.1109/SFFCS.1999.814639]; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Duda R.O., 2000, PATTERN CLASSIFICATI; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Martinez AM, 2001, IEEE T SYST MAN CY B, V31, P669, DOI 10.1109/3477.956029; Martinez AM, 2000, PATTERN RECOGN LETT, V21, P759, DOI 10.1016/S0167-8655(00)00031-3; Mclachlan G., 2000, WILEY SER PROB STAT; Merz C.J., 1997, UCI REPOSITORY MACHI; MICHALEWICZ Z, 2000, HOW SOLVE IT MODERN; PERNKOPF F, 2004, GENETIC BASED EM ALG; Titterington DM, 1985, STAT ANAL FINITE MIX; Ueda N, 2000, NEURAL COMPUT, V12, P2109, DOI 10.1162/089976600300015088; Verbeek JJ, 2003, NEURAL COMPUT, V15, P469, DOI 10.1162/089976603762553004; Xu L, 1996, NEURAL COMPUT, V8, P129, DOI 10.1162/neco.1996.8.1.129; Xu L, 2002, NEURAL NETWORKS, V15, P1125, DOI 10.1016/S0893-6080(02)00084-9; Xu L, 1997, PATTERN RECOGN LETT, V18, P1167, DOI 10.1016/S0167-8655(97)00121-9	19	165	175	4	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2005	27	8					1344	1348		10.1109/TPAMI.2005.162	http://dx.doi.org/10.1109/TPAMI.2005.162			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	934HW	16119273				2022-12-18	WOS:000229700900015
J	Pito, R				Pito, R			A solution to the next best view problem for automated surface acquisition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						active vision; next best view; sensor planning; range imaging; reverse engineering; automated surface acquisition; model acquisition	SENSOR; EXPLORATION; INSPECTION; SYSTEM; VISION	A solution to the "next best view" (NBV) problem for automated surface acquisition is presented. The NBV problem is to determine which areas of a scanner's viewing volume need to be scanned to sample all of the visible surfaces of an a priori unknown object and where to position/control the scanner to sample them. It is argued that solutions to the NBV problem are constrained by the other steps in a surface acquisition system and by the range scanner's particular sampling physics. A method for determining the unscanned areas of the viewing volume is presented. In addition, a novel representation, positional space (PS), is presented which facilitates a solution to the NBV problem by representing what must be and what can be scanned in a single data structure. The number of costly computations needed to determine if an area of the viewing volume would be occluded from some scanning position is decoupled from the number of positions considered for the NBV, thus reducing the computational cost of choosing one. An automated surface acquisition systems designed to scan all visible surfaces of an a priori unknown object is demonstrated on real objects.	Invenio Technol Co, Boston, MA 02116 USA; MIT, Dept Ocean Engn, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT)	Pito, R (corresponding author), Invenio Technol Co, 699 Boylston St, Boston, MA 02116 USA.	pito@invenio.com						Aloimonos J., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P35; BAJCSY R, 1988, P IEEE, V76, P996, DOI 10.1109/5.5968; BANTA J, 1995, P SPIE INT S INT SYS; Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Chaumette F, 1996, IEEE T PATTERN ANAL, V18, P492, DOI 10.1109/34.494639; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; CHEN YD, 1993, IEEE T ROBOTIC AUTOM, V9, P318, DOI 10.1109/70.240202; Connolly C., 1985, 1985 IEEE INT C ROBO, P432; COWAN C, 1988, IEEE T ROBOTIC AUTOM, V10, P86; CURLESS B, 1996, ANN C SERIES SIGGRAP; CURWEN R, 1992, P EUR C COMP VIS, P879; DAILY M, 1988, P C COMP VIS PATT RE, P3; HILTON A, 1996, P INT C IM PROC SEPT, V2; Horn B., 1986, ROBOT VISION, P1; HUTCHINSON SA, 1989, IEEE T ROBOTIC AUTOM, V5, P765, DOI 10.1109/70.88098; Johnson A. E., 1997, P INT C REC ADV 3 D; KAHN J, 1980, RJ3021 IBM; Kemmotsu K., 1994, Proceedings 1994 IEEE International Conference on Robotics and Automation (Cat. No.94CH3375-3), P1357, DOI 10.1109/ROBOT.1994.351299; KUTULAKOS K, 1994, ARTIF INTELL, V78, P147; KWEON IS, 1991, CMURITR911 CARN MELL; LEVOY M, 1996, ANN C SERIES SIGGRAP; Marchand E, 1996, PROC CVPR IEEE, P169, DOI 10.1109/CVPR.1996.517070; MARSHALL A, 1995, P SPIE INT S INT SYS; MAVER J, 1993, IEEE T PATTERN ANAL, V15, P417, DOI 10.1109/34.211463; Milroy MJ, 1996, MACH VISION APPL, V9, P106, DOI 10.1007/BF01216816; MIURA J, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1106, DOI 10.1109/ICCV.1995.466811; PAPDOPOULOSORFA.D, 1995, P 4 EUR C RAP PROT P; PAPDOPOULOSORFA.D, 1997, P INT C REC ADV 3 D; PITO R, 1997, P INT C REC ADV 3D I; PITO R, 1995, P SPIE INT S INT SYS; PITO R, 1995, MSCIS9505 U PENNS GR; PITO R, 1996, P ICPR, P941; Pito R., 1997, THESIS U PENNSYLVANI; PITO R, 1996, P INT C IM PROC SEPT, V2, P397; REED M, 1997, P INT C REC ADV 3 D; RUTISHAUSER M, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P573, DOI 10.1109/CVPR.1994.323797; SCHROEDER WJ, 1992, COMP GRAPH, V26, P65, DOI 10.1145/142920.134010; SMITH CE, 1994, IEEE INT CONF ROBOT, P2516, DOI 10.1109/ROBOT.1994.351133; TARABANIS K, 1994, CVGIP-IMAG UNDERSTAN, V59, P340, DOI 10.1006/ciun.1994.1024; Tarabanis K, 1996, IEEE T PATTERN ANAL, V18, P279, DOI 10.1109/34.485556; TARABANIS KA, 1995, IEEE T ROBOTIC AUTOM, V11, P86, DOI 10.1109/70.345940; TARBOX GH, 1995, COMPUT VIS IMAGE UND, V61, P84, DOI 10.1006/cviu.1995.1007; TARBOX GH, 1995, COMPUT VIS IMAGE UND, V61, P430, DOI 10.1006/cviu.1995.1032; TURK G, 1994, ANN C SERIES, P311; WHAITE P, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P339, DOI 10.1109/CVPR.1994.323849; Wilkes D., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P136, DOI 10.1109/CVPR.1992.223215; WIXSON L, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P800, DOI 10.1109/CVPR.1994.323902; Xie S., 1986, P INT C PATT REC, P154; YUAN X, 1995, IEEE T PATTERN ANAL, V17; ZHAO H, 1997, P INT C REC ADV 3 D	51	165	173	4	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1999	21	10					1016	1030		10.1109/34.799908	http://dx.doi.org/10.1109/34.799908			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	248DB					2022-12-18	WOS:000083259100005
J	Yang, M; Wu, Y; Hua, G				Yang, Ming; Wu, Ying; Hua, Gang			Context-Aware Visual Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; visual object tracking; context aware; collaborative tracking; data mining; robust fusion; belief inconsistency	ALGORITHM	Enormous uncertainties in unconstrained environments lead to a fundamental dilemma that many tracking algorithms have to face in practice: Tracking has to be computationally efficient, but verifying whether or not the tracker is following the true target tends to be demanding, especially when the background is cluttered and/or when occlusion occurs. Due to the lack of a good solution to this problem, many existing methods tend to be either effective but computationally intensive by using sophisticated image observation models or efficient but vulnerable to false alarms. This greatly challenges long-duration robust tracking. This paper presents a novel solution to this dilemma by considering the context of the tracking scene. Specifically, we integrate into the tracking process a set of auxiliary objects that are automatically discovered in the video on the fly by data mining. Auxiliary objects have three properties, at least in a short time interval: 1) persistent co-occurrence with the target, 2) consistent motion correlation to the target, and 3) easy to track. Regarding these auxiliary objects as the context of the target, the collaborative tracking of these auxiliary objects leads to efficient computation as well as strong verification. Our extensive experiments have exhibited exciting performance in very challenging real-world testing cases.	[Yang, Ming; Wu, Ying] Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA; [Hua, Gang] Microsoft Res, Speech Technol Grp, Redmond, WA 98063 USA	Northwestern University; Microsoft	Yang, M (corresponding author), Northwestern Univ, Dept Elect Engn & Comp Sci, 2145 Sheridan Rd, Evanston, IL 60208 USA.	m-yang4@u.northwestern.edu; yingwu@ece.northwestern.edu; ganghua@microsoft.com	Yang, Ming-Hsuan/T-9533-2019; Yang, Ming-Hsuan/AAE-7350-2019; Wu, Ying/B-7283-2009	Yang, Ming-Hsuan/0000-0003-4848-2304; Yang, Ming/0000-0003-1691-6817; Koochak, Atousa/0000-0001-6547-2728	US National Science Foundation [IIS-0347877, IIS-0308222]; OMRON	US National Science Foundation(National Science Foundation (NSF)); OMRON	This work was supported in part by the US National Science Foundation under Grant IIS-0347877 and Grant IIS-0308222 and in part by OMRON.	Agrawal R., 1994, P 20 INT C VER LARG, P487; Avidan S, 2005, PROC CVPR IEEE, P494; Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53; Bar-Shalom Y., 1988, TRACKING DATA ASS; Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614; BLACK MJ, 1996, P EUR C COMP VIS, P329; BROX T, 2004, P 8 EUR C COMP VIS, V4, P25; Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Cox IJ, 1996, IEEE T PATTERN ANAL, V18, P138, DOI 10.1109/34.481539; *EC, EC FUND CAVIAR PROJ; Fitzgibbon A, 2002, LECT NOTES COMPUT SC, V2352, P304; Grabsch Brenda, 2006, Palliat Support Care, V4, P47; Hager GD, 1996, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.1996.517104; Hager GD, 2004, PROC CVPR IEEE, P790; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HUA G, 2006, P IEEE C COMP VIS PA, V1, P650; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; ISARD M, 1996, P EUR C COMP VIS, P343; Jain R., 1995, MACHINE VISION; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Julier SJ, 1997, P AMER CONTR CONF, P2369, DOI 10.1109/ACC.1997.609105; Lee KC, 2005, PROC CVPR IEEE, P852; Leordeanu M, 2005, PROC CVPR IEEE, P1142; Lim J., 2004, P ADV NEUR INF PROC, P2; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561; OKUMA K, 2004, P EUR C COMP VIS, P28; PAVLOVIC VI, 1999, THESIS U ILLINOIS UR; Ramanan D, 2007, IEEE T PATTERN ANAL, V29, P65, DOI 10.1109/TPAMI.2007.250600; Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458; REID DB, 1979, IEEE T AUTOMATIC CON, V24, P6; Roth S, 2005, IEEE I CONF COMP VIS, P42; Shi JB, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1154, DOI 10.1109/ICCV.1998.710861; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Sivic J, 2004, PROC CVPR IEEE, P488; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Wang JY, 2005, PROC CVPR IEEE, P1037; Williams O, 2005, IEEE T PATTERN ANAL, V27, P1292, DOI 10.1109/TPAMI.2005.167; Wu Y, 2004, INT J COMPUT VISION, V58, P55, DOI 10.1023/B:VISI.0000016147.97880.cd; Yang M, 2005, PROC CVPR IEEE, P1059; Yang M., 2006, P IEEE INT C COMP VI, V1, P697; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Zhao T, 2004, IEEE T PATTERN ANAL, V26, P1208, DOI 10.1109/TPAMI.2004.73; Zhou XS, 2005, IEEE T PATTERN ANAL, V27, P115, DOI 10.1109/TPAMI.2005.3; 2008, DGC RACE	48	164	180	1	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2009	31	7					1195	1209		10.1109/TPAMI.2008.146	http://dx.doi.org/10.1109/TPAMI.2008.146			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	447KB	19443919	Green Submitted			2022-12-18	WOS:000266188900005
J	Levin, A; Rav-Acha, A; Lischinski, D				Levin, Anat; Rav-Acha, Alex; Lischinski, Dani			Spectral matting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition	JUN 17-22, 2007	Minneapolis, MN	IEEE, hp invent, INI-GraphicsNet, VIOSO		image matting; unsupervised segmentation; spectral analysis	EIGENVECTORS; MATRICES; CUTS	We present spectral matting: a new approach to natural image matting that automatically computes a basis set of fuzzy matting components from the smallest eigenvectors of a suitably defined Laplacian matrix. Thus, our approach extends spectral segmentation techniques, whose goal is to extract hard segments, to the extraction of soft matting components. These components may then be used as building blocks to easily construct semantically meaningful foreground mattes, either in an unsupervised fashion or based on a small amount of user input.	[Levin, Anat] MIT CSAIL, Stata Ctr, Cambridge, MA 02139 USA; [Rav-Acha, Alex] Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel; [Lischinski, Dani] Hebrew Univ Jerusalem, Sch Comp Sci & Engn, IL-91904 Jerusalem, Israel	Massachusetts Institute of Technology (MIT); Weizmann Institute of Science; Hebrew University of Jerusalem	Levin, A (corresponding author), MIT CSAIL, Stata Ctr, 32-D466,32 Vassar St, Cambridge, MA 02139 USA.	alevin@csail.mit.edu; reavach@gmail.com; danix@cs.huji.ac.il	chen, mingang/C-7691-2011	Lischinski, Dani/0000-0002-6191-0361; Levin, Anat/0000-0002-9849-9043				BORENSTEIN E, 2002, P EUR C COMP VIS, P109; Chuang YY, 2001, PROC CVPR IEEE, P264; Dennis J.E., 1983, NUMERICAL METHODS UN; DONATH W, 1973, ALGORITHMS PARTITION; FIEDLER M, 1975, CZECH MATH J, V25, P607; FIEDLER M, 1973, CZECH MATH J, V23, P298; FIEDLER M, 1975, CZECH MATH J, V25, P619; Goldfarb D., 2005, P ADV NEUR INF PROC; Grady L, 2005, PROCEEDINGS OF THE FIFTH IASTED INTERNATIONAL CONFERENCE ON VISUALIZATION, IMAGING, AND IMAGE PROCESSING, P423; Guan Y, 2006, COMPUT GRAPH FORUM, V25, P567, DOI 10.1111/j.1467-8659.2006.00976.x; Guattery S, 1998, SIAM J MATRIX ANAL A, V19, P701, DOI 10.1137/S0895479896312262; HALL KM, 1970, MANAGE SCI, V17, P219, DOI 10.1287/mnsc.17.3.219; Kolmogorov V, 2007, IEEE T PATTERN ANAL, V29, P1274, DOI 10.1109/TPAMI.2007.1031; Langman J, 2004, LAT TRADE, V12, P18; LEVIN A, 2007, P IEEE INT C COMP VI; LEVIN A, 2006, P IEEE CVPR 2006, P61; Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719; Ng A., 2001, P ADV NEURAL INFORM; POTHEN A, 1990, SIAM J MATRIX ANAL A, V11, P430, DOI 10.1137/0611030; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; SMITH AR, 1996, P SIGGRAPH 96, P259; Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721; TOLLIVER D, 2006, P IEEE INT C COMP VI, P1053; Wang J, 2005, IEEE I CONF COMP VIS, P936; Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P975, DOI 10.1109/ICCV.1999.790354; Yu SX, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P313, DOI 10.1109/iccv.2003.1238361	27	164	188	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2008	30	10					1699	1712		10.1109/TPAMI.2008.168	http://dx.doi.org/10.1109/TPAMI.2008.168			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	336DQ	18703825				2022-12-18	WOS:000258344900003
J	Li, Y; Ai, HZ; Yamashita, T; Lao, SH; Kawade, M				Li, Yuan; Ai, Haizhou; Yamashita, Takayoshi; Lao, Shihong; Kawade, Masato			Tracking in low frame rate video: A cascade particle filter with discriminative observers of different life spans	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition	JUN 17-22, 2007	Minneapolis, MN	IEEE, hp invent, INI-GraphicsNet, VIOSO		object tracking; low frame rate video; abrupt motion; discriminative model; particle filter		Tracking objects in low frame rate (LFR) video or with abrupt motion poses two main difficulties which most conventional tracking methods can hardly handle: 1) poor motion continuity and increased search space and 2) fast appearance variation of target and more background clutter due to increased search space. In this paper, we address the problem from a view which integrates conventional tracking and detection and present a temporal probabilistic combination of discriminative observers of different life spans. Each observer is learned from different ranges of samples, with different subsets of features, to achieve varying levels of discriminative power at varying costs. An efficient fusion and temporal inference is then done by a cascade particle filter which consists of multiple stages of importance sampling. Experiments show significantly improved accuracy of the proposed approach in comparison with existing tracking methods, under the condition of LFR data and abrupt motion of both target and camera.	[Li, Yuan] Univ So Calif, Dept Comp Sci, Los Angeles, CA 90089 USA; [Ai, Haizhou] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China; [Yamashita, Takayoshi; Lao, Shihong; Kawade, Masato] OMRON Corp, Sensing & Control Technol Lab, Kyoto 6190283, Japan	University of Southern California; Tsinghua University; Omron Corporation	Li, Y (corresponding author), Univ So Calif, Dept Comp Sci, 3737 Watt Way,USC PHE 224,MC 0273, Los Angeles, CA 90089 USA.	yli8@usc.edu; ahz@mail.tsinghua.edu.cn; takayosi@ari.ncl.omron.co.jp; lao@ari.ncl.omron.co.jp; kawade@ari.ncl.omron.co.jp						Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35; BIRCHFIELD S, 2006, SOURCE CODE KLT FEAT; Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205; Comaniciu D., 2000, P IEEE C COMP VIS PA; Dalai N., 2005, P IEEE C COMP VIS PA; Deutscher J., 2000, P IEEE C COMP VIS PA; Freund Y., 1996, P INT C MACH LEARN I; HAN M, 2004, P IEEE INT C IM PROC; HOU C, 2007, P AS C COMP VIS ACCV; HUA G, 2004, P IEEE C COMP VIS PA; HUANG C, 2005, P IEEE INT C COMP VI; Huang C, 2007, IEEE T PATTERN ANAL, V29, P671, DOI 10.1109/TPAMI.2007.1011; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Kaucic R., 2005, P IEEE C COMP VIS PA; LEE K, 2005, P IEEE C COMP VIS PA; LIM J, 2004, ADV NEURAL INFORM PR; LIU C, 2002, P EUR C COMP VIS ECC; LIU JS, 1994, MONTE CARLO STRATEGI; MACCORMICK J, 2000, P EUR C COMP VIS ECC; MACCORMICK J, 2003, INT J COMPUT VISION, V39, P57; OKUMA K, 2004, P EUR C COMP VIS ECC; *OP, 2008, INT OPENCV LIB; Porikli F, 2005, PROC SPIE, V5685, P72, DOI 10.1117/12.587907; SULLIVAN J, 1999, P IEEE INT C COMP VI; Tomasi C, 1991, CMUCS91132; VIOLA P, 2001, P IEEE WORKSH STAT T; WANG J, 2005, P IEEE C COMP VIS PA; WU B, 2006, P IEEE C COMP VIS PA; YANG C, 2005, P IEEE INT C COMP VI; YU T, 2004, P IEEE C COMP VIS PA; 2008, CMU VIVID DATASET; 2008, CAVIAR DATASET; 2008, PETS 2006 DATASET	34	164	172	0	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2008	30	10					1728	1740		10.1109/TPAMI.2008.73	http://dx.doi.org/10.1109/TPAMI.2008.73			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	336DQ	18703827				2022-12-18	WOS:000258344900005
