PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	BOIE, RA; COX, IJ				BOIE, RA; COX, IJ			AN ANALYSIS OF CAMERA NOISE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CAMERA NOISE; CCD; POISSON NOISE; VIDICON		An analysis of camera noise is presented. We examine the class of cameras that are based on ionization sensors, which includes the most common charge-coupled device (CCD) and vidicon cameras. Camera signals are shown to be corrupted by direction-dependent stationary electronic noise sources and flucuations due to the statistical nature of the sensing process. The paper develops and tests a model of the inherent noises in cameras. These results are confirmed by measurement, and they suggest a locally stationary model of noise for adaptive signal processing.	NEC RES INST,PRINCETON,NJ 08540	NEC Corporation	BOIE, RA (corresponding author), AT&T BELL LABS,MURRAY HILL,NJ 07974, USA.							CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Carlson AB, 1975, COMMUNICATION SYSTEM; Robinson F. N. H., 1974, NOISE FLUCTUATIONS E	3	43	43	2	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1992	14	6					671	674		10.1109/34.141557	http://dx.doi.org/10.1109/34.141557			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HX546					2022-12-18	WOS:A1992HX54600007
J	LU, Y; JAIN, RC				LU, Y; JAIN, RC			REASONING ABOUT EDGES IN SCALE SPACE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						EDGES; KNOWLEDGE REPRESENTATION; LAPLACIAN OF GAUSSIAN; MULTISCALE; REASONING; SCALE PARAMETERS; SCALE SPACE	2ND DIRECTIONAL-DERIVATIVES; DIGITAL STEP EDGES; ZERO CROSSINGS	The importance of applying different knowledge has been recognized since the early days of computer vision. A common belief in the field is that the low-level processes are dominated by data-driven operations such as edge detection, and the high-level processes use explicit knowledge. This belief has resulted in emphasis on filtering operations in the low-level processes and on reasoning approaches in the high-level processes. Many techniques have been developed for low-level vision processing, but their performance on real images is far from satisfactory. This paper explores the role of reasoning in early vision processing. In particular, we address the problem of detecting edges. We do not try to develop one more edge detector, but rather, we study an edge detector rigorously to understand its behavior well enough to formulate a reasoning process that will allow appliance of the detector judiciously to recover useful information. We present a multiscale reasoning algorithm for edge recovery: reasoning about edges in scale space (RESS). The knowledge in RESS is acquired from the theory of edge behavior in scale space and represented by a number of procedures. RESS recovers desired edge curves through a number of reasoning processes on zero crossing images at various scales. The knowledge of edge behavior in scale space enables RESS to select proper scale parameters, recover missing edges, eliminate noise or false edges, and correct the locations of edges. A brief evaluation of RESS is performed by comparing it with two well-known multistage edge detection algorithms.	UNIV MICHIGAN, DEPT ELECT ENGN & COMP SCI, ARTIFICIAL INTELLIGENCE LAB, ANN ARBOR, MI 48109 USA	University of Michigan System; University of Michigan	LU, Y (corresponding author), ENVIRONM RES INST MICHIGAN, ANN ARBOR, MI 48113 USA.							[Anonymous], 1975, PSYCHOL COMPUTER VIS; BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9, P726, DOI 10.1109/TPAMI.1987.4767980; BISCHOF WF, 1988, COMPUT VISION GRAPH, V42, P192, DOI 10.1016/0734-189X(88)90163-6; BRADY M, 1985, COMPUT VISION GRAPH, V32, P1, DOI 10.1016/0734-189X(85)90001-5; BREZINS V, 1984, COMPUT VISION GRAPH, P195; Brooks R., 1984, MODEL BASED COMPUTER; Canny, 1983, AITR720 MIT ART INT; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CLARK JJ, 1988, IEEE T PATTERN ANAL, V10, P720, DOI 10.1109/34.6782; Eklundh J. O., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P1109; GEORGEFF MP, 1986, OCT P IEEE, P1383; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P121, DOI 10.1109/TPAMI.1985.4767628; HANSON A, 1978, VISIONS COMPUTER SYS; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HEEGER DJ, 1987, INT J COMPUT VISION, V1, P279, DOI 10.1007/BF00133568; HILDRETH EC, 1983, COMPUT VISION GRAPH, V22, P1, DOI 10.1016/0734-189X(83)90093-2; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HUMMEL RA, 1986, JUN P IEEE COMP SOC; LEVINE MD, 1978, KNOWLEDGE BASED COMP; LEVINE MD, 1981, IEEE T PATT AN M SEP; LOGAN BF, 1977, AT&T TECH J, V56, P487, DOI 10.1002/j.1538-7305.1977.tb00522.x; LU Y, 1989, IEEE T PATTERN ANAL, V11, P337, DOI 10.1109/34.19032; LU Y, 1989, THESIS U MICHIGAN AN; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Marr D., 1982, VISION; Minsky M., 2019, FRAMEWORK REPRESENTI; NAGEL HH, 1987, ARTIFICIAL INTELL; NALWA VS, 1986, IEEE T PATT ANAL MAC, V8; Rock I., 1983, LOGIC PERCEPTION; SANZ JLC, IN PRESS IMAGE REPRE; SHAH M, 1986, COMPUT VISION GRAPH, V34, P321, DOI 10.1016/S0734-189X(86)80046-9; TORRE V, 1986, IEEE T PATT ANAL MAC, V8; WILLIAMS D, 1989, SPIE APPLICATIONS AR, P13; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]	38	43	46	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1992	14	4					450	468		10.1109/34.126806	http://dx.doi.org/10.1109/34.126806			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HL193					2022-12-18	WOS:A1992HL19300004
J	HSIAO, JY; SAWCHUK, AA				HSIAO, JY; SAWCHUK, AA			SUPERVISED TEXTURED IMAGE SEGMENTATION USING FEATURE SMOOTHING AND PROBABILISTIC RELAXATION TECHNIQUES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									HUGHES AIRCRAFT CO,ELECTROOPT & DATA SYST GRP,LOS ANGELES,CA 90245; UNIV SO CALIF,DEPT ELECT ENGN,LOS ANGELES,CA 90089; UNIV SO CALIF,INST SIGNAL & IMAGE PROC,LOS ANGELES,CA 90089	Hughes Aircraft Company; University of Southern California; University of Southern California								ADE F, 1983, SIGNAL PROCESS, V5, P451, DOI 10.1016/0165-1684(83)90008-7; BAJCSY R, 1973, 3RD P INT JOINT C AI; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; CARLTON SG, 1977, JUN P IEEE C PATT RE; CHATTERJEE S, 1985, P IEEE C COMPUT VISI; Chellappa R., 1985, DIGITAL IMAGE PROCES, V2; COHEN FS, 1983, P SPIE, V449; COLEMAN GB, 1979, P IEEE, V67, P773, DOI 10.1109/PROC.1979.11327; CONNERS RW, 1984, COMPUT VISION GRAPH, V25, P273, DOI 10.1016/0734-189X(84)90197-X; DERIN H, 1986, COMPUT VISION GRAPH, V35, P72, DOI 10.1016/0734-189X(86)90126-X; Devijver PA, 1982, PATTERN RECOGNITION; Duda R.O., 1973, J ROYAL STAT SOC SER; EKLUNDH JO, 1980, IEEE T PATTERN ANAL, V2, P72, DOI 10.1109/TPAMI.1980.4766973; FAUGERAS OD, 1981, IEEE T PATTERN ANAL, V3, P412, DOI 10.1109/TPAMI.1981.4767127; HARALICK RM, 1980, COMPUT VISION GRAPH, V13, P242, DOI 10.1016/0146-664X(80)90048-9; HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7; HSIAO JY, 1987, USCSIPI114 U SO CAL; HSIAO JY, 1989, COMPUT VISION GRAPH, V48; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; JIANG SS, 1986, APPL OPTICS, V25, P2326, DOI 10.1364/AO.25.002326; KNUTSSON H, 1983, P ICASSP 83 IEEE C A; KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641; Laws K. I., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238, P376; LAWS KI, 1980, USCIPI940 U SO CAL R; MITCHELL OR, 1979, P IEEE C PATTERN REC; NAGAO M, 1979, COMPUT VISION GRAPH, V9, P394, DOI 10.1016/0146-664X(79)90102-3; NAGIN PA, 1982, IEEE T PATTERN ANAL, V4, P263, DOI 10.1109/TPAMI.1982.4767243; OHLANDER R, 1978, COMPUT VISION GRAPH, V8, P313, DOI 10.1016/0146-664X(78)90060-6; PAVLIDIS T, 1975, P C COMPUT GRAPH PAT; PAVLIDIS T, 1979, COMPUTER GRAPHICS IM, V10, P172; PAVLIDIS T, 1980, 5TH P INT C PATT REC; PELEG S, 1978, IEEE T SYST MAN CYB, V8, P548; PELEG S, 1980, IEEE T PATTERN ANAL, V2, P362, DOI 10.1109/TPAMI.1980.4767035; PIETIKAINEN M, 1981, IEEE T SYST MAN CYB, V11, P822; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2; SCHACHTER BJ, 1979, PATTERN RECOGN, V11, P19, DOI 10.1016/0031-3203(79)90025-6; THERRIEN CW, 1983, COMPUT VISION GRAPH, V22, P313, DOI 10.1016/0734-189X(83)90079-8; THERRIEN CW, 1980, 5TH P INT C PATT REC; UNSER M, 1986, SIGNAL PROCESS, V11, P61, DOI 10.1016/0165-1684(86)90095-2; VILNROTTER F, 1980, 5TH P INT PATT REC C; ZUCKER SW, 1978, IEEE T SYST MAN CYB, V8, P41; ZUCKER SW, 1975, IEEE T COMPUT, V24, P1228, DOI 10.1109/T-C.1975.224169	43	43	54	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1989	11	12					1279	1292		10.1109/34.41366	http://dx.doi.org/10.1109/34.41366			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB716					2022-12-18	WOS:A1989CB71600004
J	CHEN, JS; MEDIONI, G				CHEN, JS; MEDIONI, G			DETECTION, LOCALIZATION, AND ESTIMATION OF EDGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											CHEN, JS (corresponding author), UNIV SO CALIF, SCH ENGN, LOS ANGELES, CA 90089 USA.							BERZINS V, 1984, COMPUT VISION GRAPH, V27, P195, DOI 10.1016/S0734-189X(84)80043-2; BINFORD TO, 1981, ARTIF INTELL, V17, P205, DOI 10.1016/0004-3702(81)90025-4; BRADY M, 1982, COMPUT SURV, V14, P3, DOI 10.1145/356869.356871; CANNY JF, 1983, MIT720 ART INT LAB T; Chen J. S., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P293; CHEN JS, 1987, NOV P WORKSH COMP VI; CLARK JJ, 1987, JUN P ICCV 87 LOND, P491; Davis L. S., 1975, COMPUT VISION GRAPH, V4, P248, DOI [DOI 10.1016/0146-664X(75)90012-X, 10.1016/0146-664X(75)90012-X]; DICKEY FM, 1977, APPL OPTICS, V16, P145, DOI 10.1364/AO.16.000145; HARALICK RM, 1980, COMPUT VISION GRAPH, V12, P60, DOI 10.1016/0146-664X(80)90004-0; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HARALICK RM, 1981, P PATTERN RECOG IMAG, P285; HILDRETH EC, 1983, COMPUT VISION GRAPH, V22, P1, DOI 10.1016/0734-189X(83)90093-2; KROTKOV EP, 1986, CIS8622 U PENNS TECH; LUNSCHER WHHJ, 1986, IEEE T PATTERN ANAL, V8, P164, DOI 10.1109/TPAMI.1986.4767770; MADIONI G, 1987, P IU WORKSHOP 87 LOS, P968; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940; Roberts L, 1965, MACHINE PERCEPTION 3; Shen J., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P109; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]	25	43	50	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1989	11	2					191	198		10.1109/34.16714	http://dx.doi.org/10.1109/34.16714			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	R9989					2022-12-18	WOS:A1989R998900007
J	CAPSON, DW; ENG, SK				CAPSON, DW; ENG, SK			A TIERED-COLOR ILLUMINATION APPROACH FOR MACHINE INSPECTION OF SOLDER JOINTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											CAPSON, DW (corresponding author), MCMASTER UNIV,DEPT ELECT & COMP ENGN,HAMILTON L8S 4L7,ONTARIO,CANADA.							Besl P. J., 1985, IEEE Journal of Robotics and Automation, VRA-1, P42, DOI 10.1109/JRA.1985.1086997; BILLOTA AJ, 1985, CONNECTIONS ELECTRON, P1; BOWLBY R, 1985, IEEE SPECTRUM, V22, P37, DOI 10.1109/MSPEC.1985.6370492; CAPSON DW, 1984, COMPUT VISION GRAPH, V28, P109, DOI 10.1016/0734-189X(84)90143-9; CHIN RT, 1982, IEEE T PATTERN ANAL, V4, P557, DOI 10.1109/TPAMI.1982.4767309; CHOU JK, 1985, MAR SME VIS 85 C P; COOMBS CF, 1967, PRINTED CIRCUITS HDB; GOTO N, 1980, PATTERN RECOGN, V12, P443, DOI 10.1016/0031-3203(80)90020-5; HARA Y, 1983, IEEE T PATTERN ANAL, V5, P623, DOI 10.1109/TPAMI.1983.4767453; JARVIS JF, 1980, IEEE T PATTERN ANAL, V2, P77, DOI 10.1109/TPAMI.1980.4766975; JOWETT CE, 1970, RELIABLE ELECTRONIC, P53; KAUFMANN P, 1984, PATTERN RECOGN, V17, P485, DOI 10.1016/0031-3203(84)90046-3; Manko H., 1979, SOLDERS SOLDERING; MANKO HH, 1986, SOLDERING HDB PRINTE; MCINTOSH WE, 1983, ROBOTICS TODAY   JUN, P75; MERRILL PA, 1984, THESIS MCGILL U MONT; NAKAGAWA Y, 1982, P SOC PHOTO-OPT INST, V336, P121, DOI 10.1117/12.933619; ROWLAND R, 1984, ASSEMBLY AUTOMAT FEB, P14; SANZ JLC, 1986, J OPT SOC AM A, V3, P1465, DOI 10.1364/JOSAA.3.001465; SEAH MP, 1985, J PHYS E SCI INSTRUM, V18, P676, DOI 10.1088/0022-3735/18/8/008; SILVEN O, 1984, 7TH P INT C PATT REC, V2, P1355; SKAGGS FL, 1985, SOC MANUFACTURING EN, P123; VANZETTI R, 1981, 24TH P IPC ANN M, P1; WEST GAW, 1984, IEEE T SYST MAN CYB, V14, P767, DOI 10.1109/TSMC.1984.6313300; WEST MA, 1983, IBM J RES DEV, V27, P50, DOI 10.1147/rd.271.0050; 1985, AT T IMAGE CAPTURE B; PANASONIC WV CD120 S	27	43	53	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1988	10	3					387	393		10.1109/34.3902	http://dx.doi.org/10.1109/34.3902			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	N5337					2022-12-18	WOS:A1988N533700009
J	WOODS, JW; DRAVIDA, S; MEDIAVILLA, R				WOODS, JW; DRAVIDA, S; MEDIAVILLA, R			IMAGE ESTIMATION USING DOUBLY STOCHASTIC GAUSSIAN RANDOM FIELD MODELS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											WOODS, JW (corresponding author), RENSSELAER POLYTECH INST,DEPT ELECT COMP & SYST ENGN,TROY,NY 12180, USA.							ABRAMATIC JF, 1982, IEEE T PATTERN ANAL, V4, P141, DOI 10.1109/TPAMI.1982.4767220; ACKERSON GA, 1970, IEEE T AUTOMAT CONTR, VAC15, P10, DOI 10.1109/TAC.1970.1099359; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; INGLE VK, 1979, APR P ICASSP 79 WASH, P642; KAUFMAN H, 1983, IEEE T AUTOMAT CONTR, V28, P745, DOI 10.1109/TAC.1983.1103311; KNUTSSON HE, 1983, IEEE T COMMUN, V31, P388, DOI 10.1109/TCOM.1983.1095832; LEE JS, 1981, COMPUT VISION GRAPH, V15, P380, DOI 10.1016/S0146-664X(81)80018-4; LIM JS, 1980, IEEE T ACOUST SPEECH, V28, P191; MEDIAVILLA R, 1982, 6TH P IFAC S IND SYS; PREUSS D, 1975, NACHRICHTENTECH Z, V28, P358; PREUSS D, 1975, P ICC; TEKALP AM, 1983, APR P ICASSP 83 BOST, P832; TUGNAIT JK, 1979, AUTOMATICA, V15, P477, DOI 10.1016/0005-1098(79)90023-2; WALLIS R, 1976, NOV P S CURR MATH PR, P107; WOODS JW, 1979, IEEE T INFORM THEORY, V25, P628, DOI 10.1109/TIT.1979.1056079; WOODS JW, 1977, IEEE T INFORM THEORY, V23, P473, DOI 10.1109/TIT.1977.1055750; WOODS JW, 1981, IEEE T ACOUST SPEECH, V29, P188, DOI 10.1109/TASSP.1981.1163533; WOODS JW, 1980, JUN P ICC 80; WOODS JW, 1981, 2 DIMENSIONAL TRANSF, P155	19	43	43	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1987	9	2					245	253		10.1109/TPAMI.1987.4767898	http://dx.doi.org/10.1109/TPAMI.1987.4767898			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	G1633	21869394				2022-12-18	WOS:A1987G163300005
J	HARA, Y; AKIYAMA, N; KARASAKI, K				HARA, Y; AKIYAMA, N; KARASAKI, K			AUTOMATIC INSPECTION SYSTEM FOR PRINTED-CIRCUIT BOARDS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									HITACHI LTD,HATANO,KANAGAWA 25913,JAPAN	Hitachi Limited	HARA, Y (corresponding author), HITACHI LTD,PROD ENGN RES LAB,292 YOSHIDA CHO,TOTSUKA KU,YOKOHAMA 244,JAPAN.							BRUNING JH, 1975, IEEE T ELECTRON DEV, VED22, P487, DOI 10.1109/T-ED.1975.18167; Ejiri M., 1973, COMPUT VISION GRAPH, V2, P326, DOI 10.1016/0146-664X(73)90011-7; HARA Y, 1980, 5TH P INT JOINT C PA, P273; JARVIS JF, 1980, IEEE T PATTERN ANAL, V2, P77, DOI 10.1109/TPAMI.1980.4766975; RESTRICK RC, 1977, P SPIE SOLID STATE I, V116, P76; STERLING WM, 1979, AUG P IEEE C PATT RE, P93	6	43	47	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	6					623	630		10.1109/TPAMI.1983.4767453	http://dx.doi.org/10.1109/TPAMI.1983.4767453			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RV488	21869150				2022-12-18	WOS:A1983RV48800010
J	JAIN, R				JAIN, R			DIRECT COMPUTATION OF THE FOCUS OF EXPANSION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									WAYNE STATE UNIV,DEPT COMP SCI,DETROIT,MI 48202	Wayne State University								AGGARWAL JK, 1975, IEEE T COMPUT, V24, P966, DOI 10.1109/T-C.1975.224102; ARIKI Y, 1978, 4TH P IJCPR, P681; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; CLOCKSIN WF, 1980, PERCEPTION, V9, P253, DOI 10.1068/p090253; CLOCKSIN WF, 1978, JUL P ART INT SIM BE, P93; DRESCHLER L, 1981, P IJCAI VANCOUVER; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; Gibson J., 1979, ECOLOGICAL APPROACH; GLAZER F, 1981, P IJCAI81, P644; HAYNES S, UNPUB SOME EXPERIMEN; HOGG DC, 1976, 29 DEP COMP SCI REP; HORN BKP, 1981, ARTIFICIAL INTELL, V17; JAIN R, 1979, COMPUT VISION GRAPH, V11, P13, DOI 10.1016/0146-664X(79)90074-1; JAIN R, 1981, IEEE T PATTERN ANAL, V3, P489, DOI 10.1109/TPAMI.1981.4767143; LAWTON D, 1981, P INT JOINT C ART IN, P700; LEE DN, 1980, PHILOS T R SOC B, V290, P169, DOI 10.1098/rstb.1980.0089; MARTIN WN, 1979, PATTERN RECOGN, V11, P169, DOI 10.1016/0031-3203(79)90004-9; PRAGER JM, 1979, COINS TR797 U MASS; PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077; PRAZDNY K, 1979, 6TH P INT JOINT C AR, P702; PRAZDNY K, 1981, TR1009 U MAR COMP VI; PRAZDNY K, 1980, INFORMATION OPTICAL; RASHID RF, 1980, IEEE T PATTERN ANAL, V2, P574, DOI 10.1109/TPAMI.1980.6447705; ROACH JW, 1979, IEEE T PATTERN ANAL, V1, P127, DOI 10.1109/TPAMI.1979.4766898; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SCHUNCK BG, 1981, P PATT REC M PROC C, P205; ULLMAN S, 1981, COMPUTER, V14, P57, DOI 10.1109/C-M.1981.220564; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; YACHIDA M, 1981, P INT JOINT C ART IN, P716	29	43	45	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	1					58	64		10.1109/TPAMI.1983.4767345	http://dx.doi.org/10.1109/TPAMI.1983.4767345			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PZ844	21869084				2022-12-18	WOS:A1983PZ84400008
J	HARALICK, RM; SHAPIRO, LG				HARALICK, RM; SHAPIRO, LG			THE CONSISTENT LABELING PROBLEM .2.	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV KANSAS, DEPT ELECT ENGN, LAWRENCE, KS 66045 USA; UNIV KANSAS, DEPT COMP SCI, LAWRENCE, KS 66045 USA	University of Kansas; University of Kansas			Haralick, Robert/AAW-5151-2020	manickam, vijayabhama.M/0000-0001-9437-9477				BARROW HG, 1976, SRI121 STANF RES I A; COOK SA, 1971, 3RD P ANN ACM S THEO, P151; GINZBERG A, 1968, ALGEBRAIC THEORY AUT; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; HARALICK RM, 1978, IEEE T SYST MAN CYB, V8, P600, DOI 10.1109/TSMC.1978.4310036; HARALICK RM, 1978, INFORM SCIENCES, V14, P199, DOI 10.1016/0020-0255(78)90043-9; Harary F., 1994, GRAPH THEORY; MACKWORTH AK, 1977, ARTIF INTELL, V8, P99, DOI 10.1016/0004-3702(77)90007-8; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; ULLMANN JR, 1976, ACM, V23, P31; WEIDE B, 1977, ACM COMPUT SURV, V9, P291; [No title captured]	12	43	44	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	3					193	203		10.1109/TPAMI.1980.4767007	http://dx.doi.org/10.1109/TPAMI.1980.4767007			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JR843	21868893				2022-12-18	WOS:A1980JR84300001
J	ROACH, JW; AGGARWAL, JK				ROACH, JW; AGGARWAL, JK			COMPUTER TRACKING OF OBJECTS MOVING IN SPACE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											ROACH, JW (corresponding author), UNIV TEXAS,DEPT ELECT ENGN & COMP SCI,AUSTIN,TX 78712, USA.							AGGARWAL JK, 1975, IEEE T COMPUT, V24, P966, DOI 10.1109/T-C.1975.224102; BADLER N, 1975, THESIS U TORONTO; CHIEN RT, 1975, 4TH P INT JOINT C AR, P737; CHOW CK, 1977, IEEE T COMPUTERS, V26, P179; DUDA RO, 1973, PATTERN CLASSIFICATI, pCH11; Endlich R.M., 1971, J APPL METEOROL CLIM, V10, P105; ITTELSON WH, 1951, AM J PSYCHOL, V64, P54, DOI 10.2307/1418595; JAIN R, 1977, 5TH P INT JOINT C AR, P612; JAIN R, 1979, P IEEE           MAY, P805; MARTIN W, 1978, COMPUTER GRAPHICS IM, V7; MCKEE JW, 1975, PATTERN RECOGN, V7, P25, DOI 10.1016/0031-3203(75)90012-6; Roberts L, 1965, MACHINE PERCEPTION 3; UNDERWOOD SA, 1975, IEEE T COMPUT, VC 24, P651, DOI 10.1109/T-C.1975.224277; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19	14	43	43	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	2					127	135		10.1109/TPAMI.1979.4766898	http://dx.doi.org/10.1109/TPAMI.1979.4766898			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	HA304	21868841				2022-12-18	WOS:A1979HA30400002
J	Jing, XY; Zhang, XY; Zhu, XK; Wu, F; You, XG; Gao, Y; Shan, SG; Yang, JY				Jing, Xiao-Yuan; Zhang, Xinyu; Zhu, Xiaoke; Wu, Fei; You, Xinge; Gao, Yang; Shan, Shiguang; Yang, Jing-Yu			Multiset Feature Learning for Highly Imbalanced Data Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Highly imbalanced data classification; multiset feature learning; deep metric learning; generative adversarial network; cost-sensitive factor; weighted uncorrelated constraint	DATA-SETS; FRAMEWORK; SMOTE	With the expansion of data, increasing imbalanced data has emerged. When the imbalance ratio (IR) of data is high, most existing imbalanced learning methods decline seriously in classification performance. In this paper, we systematically investigate the highly imbalanced data classification problem, and propose an uncorrelated cost-sensitive multiset learning (UCML) approach for it. Specifically, UCML first constructs multiple balanced subsets through random partition, and then employs the multiset feature learning (MFL) to learn discriminant features from the constructed multiset. To enhance the usability of each subset and deal with the nonlinearity issue existed in each subset, we further propose a deep metric based UCML (DM-UCML) approach. DM-UCML introduces the generative adversarial network technique into the multiset constructing process, such that each subset can own similar distribution with the original dataset. To cope with the non-linearity issue, DM-UCML integrates deep metric learning with MFL, such that more favorable performance can be achieved. In addition, DM-UCML designs a new discriminant term to enhance the discriminability of learned metrics. Experiments on eight traditional highly class-imbalanced datasets and two large-scale datasets indicate that: the proposed approaches outperform state-of-the-art highly imbalanced learning methods and are more robust to high IR.	[Jing, Xiao-Yuan; Zhang, Xinyu] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China; [Jing, Xiao-Yuan] Guangdong Univ Petrochem Technol, Sch Comp, Maoming 525000, Peoples R China; [Jing, Xiao-Yuan; Wu, Fei] Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing 210003, Peoples R China; [Zhu, Xiaoke] Henan Univ, Henan Key Lab Big Data Anal & Proc, Kaifeng 475004, Peoples R China; [You, Xinge] Huazhong Univ Sci & Technol, Dept Elect & Informat Engn, Wuhan 430074, Peoples R China; [Gao, Yang] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210094, Peoples R China; [Shan, Shiguang] Chinese Acad Sci, Inst Comp Technol, CAS, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China; [Yang, Jing-Yu] Nanjing Univ Sci & Technol, Coll Comp Sci, Nanjing 210094, Peoples R China	Wuhan University; Guangdong University of Petrochemical Technology; Nanjing University of Posts & Telecommunications; Henan University; Huazhong University of Science & Technology; Nanjing University; Chinese Academy of Sciences; Institute of Computing Technology, CAS; Nanjing University of Science & Technology	Jing, XY (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.; Jing, XY (corresponding author), Guangdong Univ Petrochem Technol, Sch Comp, Maoming 525000, Peoples R China.; Wu, F (corresponding author), Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing 210003, Peoples R China.; Zhu, XK (corresponding author), Henan Univ, Henan Key Lab Big Data Anal & Proc, Kaifeng 475004, Peoples R China.	jingxy_2000@126.com; zhangxinyu@whu.edu.cn; whuzxk@whu.edu.cn; wufei_8888@126.com; youxg@mail.hust.edu.cn; gaoy@nju.edu.cn; sgshan@ict.ac.cn; yangjy@mail.njust.edu.cn		zhang, xinyu/0000-0002-9109-1889; Wu, Fei/0000-0001-5498-4947; Gao, Yang/0000-0002-2488-1813; You, Xinge/0000-0002-6227-1346; Shan, Shiguang/0000-0002-8348-392X; Zhu, Xiaoke/0000-0002-0664-1832	NSFC-Key Project of General Technology Fundamental Research United Fund [U1736211]; National Natural Science Foundation of China [61672208, 61702280, 61772220, 61432008]; key research and development program of China [2016YFE0121200]; Key Science and Technology Innovation Program of Hubei Province [2017AAA017, 2018ACA135]; Natural Science Foundation Key Project for Innovation Group of Hubei Province [2018CFA024]; Natural Science Foundation of Jiangsu Province [BK20170900]; National Postdoctoral Program for Innovative Talents [BX20180146]; Higher Education Institution Key Research Projects of Henan Province [19A520001]	NSFC-Key Project of General Technology Fundamental Research United Fund; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); key research and development program of China; Key Science and Technology Innovation Program of Hubei Province; Natural Science Foundation Key Project for Innovation Group of Hubei Province; Natural Science Foundation of Jiangsu Province(Natural Science Foundation of Jiangsu Province); National Postdoctoral Program for Innovative Talents; Higher Education Institution Key Research Projects of Henan Province	The authors would like to thank the editor, the associate editor, and anonymous reviewers for their constructive comments in helping improve our work. This work was supported by the NSFC-Key Project of General Technology Fundamental Research United Fund No. U1736211, the National Natural Science Foundation of China under Grant Nos. 61672208, 61702280, 61772220 and 61432008, the key research and development program of China under Grant No. 2016YFE0121200, the Key Science and Technology Innovation Program of Hubei Province under Grant Nos. 2017AAA017 and 2018ACA135, the Natural Science Foundation Key Project for Innovation Group of Hubei Province under Grant No. 2018CFA024, the Natural Science Foundation of Jiangsu Province under Grant No. BK20170900, the National Postdoctoral Program for Innovative Talents under Grant No. BX20180146, the Higher Education Institution Key Research Projects of Henan Province under Grant No. 19A520001. Xiao-Yuan Jing and Xinyu Zhang are cofirst authors of this paper.	Alcala-Fdez J, 2011, J MULT-VALUED LOG S, V17, P255; Ando S, 2017, LECT NOTES ARTIF INT, V10534, P770, DOI 10.1007/978-3-319-71249-9_46; Barua S, 2014, IEEE T KNOWL DATA EN, V26, P405, DOI 10.1109/TKDE.2012.232; Castro CL, 2013, IEEE T NEUR NET LEAR, V24, P888, DOI 10.1109/TNNLS.2013.2246188; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953; Chen JJ, 2006, SAR QSAR ENVIRON RES, V17, P337, DOI 10.1080/10659360600787700; Chen Q, 2015, PROC CVPR IEEE, P5315, DOI 10.1109/CVPR.2015.7299169; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Diaz-Vico D, 2018, IEEE IJCNN, P612; Diethe T., 2008, P NEUR INF PROC SYST; Donahue J., 2014, INT C MACH LEARN, P647; Dong Q, 2019, IEEE T PATTERN ANAL, V41, P1367, DOI 10.1109/TPAMI.2018.2832629; Dong Q, 2017, IEEE I CONF COMP VIS, P1869, DOI 10.1109/ICCV.2017.205; Drummond JJ, 2003, ETHICS AND THEOLOGICAL DISCLOSURES: THE THOUGHT OF ROBERT SOKOLOWSKI, P1; Duan YQ, 2019, PROC CVPR IEEE, P4959, DOI 10.1109/CVPR.2019.00510; Duan YQ, 2018, PROC CVPR IEEE, P2780, DOI 10.1109/CVPR.2018.00294; Dubey R, 2014, NEUROIMAGE, V87, P220, DOI 10.1016/j.neuroimage.2013.10.005; Fernandez A, 2008, FUZZY SET SYST, V159, P2378, DOI 10.1016/j.fss.2007.12.023; Fernandez A, 2013, KNOWL-BASED SYST, V42, P97, DOI 10.1016/j.knosys.2013.01.018; Galar M, 2012, IEEE T SYST MAN CY C, V42, P463, DOI 10.1109/TSMCC.2011.2161285; Galar M, 2013, PATTERN RECOGN, V46, P3460, DOI 10.1016/j.patcog.2013.05.006; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gui C, 2017, ARTIF INTELL RES, V6, P93; Harwood B, 2017, IEEE I CONF COMP VIS, P2840, DOI 10.1109/ICCV.2017.307; He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239; Hermans Alexander, 2017, ARXIV, P1; Hong ZB, 2013, IEEE I CONF COMP VIS, P649, DOI 10.1109/ICCV.2013.86; Hu JL, 2018, IEEE T PATTERN ANAL, V40, P2281, DOI 10.1109/TPAMI.2017.2749576; Hu JL, 2015, PROC CVPR IEEE, P325, DOI 10.1109/CVPR.2015.7298629; Huang C, 2016, PROC CVPR IEEE, P5375, DOI 10.1109/CVPR.2016.580; Huang KH, 2017, MACH LEARN, V106, P1725, DOI 10.1007/s10994-017-5659-z; Jeatrakul P, 2010, LECT NOTES COMPUT SC, V6444, P152, DOI 10.1007/978-3-642-17534-3_19; Jia PF, 2014, INT CONF BIG DATA, P217, DOI 10.1109/BIGCOMP.2014.6741439; Jing XY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2255; Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740; Khan Salman H, 2018, IEEE Trans Neural Netw Learn Syst, V29, P3573, DOI 10.1109/TNNLS.2017.2732482; Kozlovskaia N, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P908, DOI 10.1109/ICMLA.2017.00-39; Li QL, 2009, BIOINFORMATICS, V25, P3310, DOI 10.1093/bioinformatics/btp589; Li W, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2194; Liu YH, 2018, IEEE DATA MINING, P1146, DOI 10.1109/ICDM.2018.00150; Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Lopez V, 2013, KNOWL-BASED SYST, V38, P85, DOI 10.1016/j.knosys.2012.08.025; Loyola-Gonzalez Octavio, 2013, Pattern Recognition. 5th Mexican Conference, MCPR 2013. Proceedings: LNCS 7914, P264, DOI 10.1007/978-3-642-38989-4_27; Lu HJ, 2017, NEUROCOMPUTING, V228, P270, DOI 10.1016/j.neucom.2016.09.077; Melville P, 2005, LECT NOTES ARTIF INT, V3720, P268, DOI 10.1007/11564096_28; Memisevic R., 2012, P INT C MACH LEARN, P1; Menzies T, 2007, IEEE T SOFTWARE ENG, V33, P2, DOI 10.1109/TSE.2007.256941; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Song H. O., 2015, COMPUTER SCI, P4004; Sun Y., 2014, ADV NEURAL INFORM PR, P1988; Szegedy Christian, 2013, ADV NEURAL INFORM PR, P3, DOI DOI 10.5555/2999792.2999897; Tang YC, 2009, IEEE T SYST MAN CY B, V39, P281, DOI 10.1109/TSMCB.2008.2002909; Thai-Nghe N., 2010, 2010 INT JOINT C NEU, P1, DOI [10.1109/IJCNN.2010.5596486, DOI 10.1109/IJCNN.2010.5596486]; Triguero I, 2015, IEEE C EVOL COMPUTAT, P715, DOI 10.1109/CEC.2015.7256961; Wang L, 2018, J TOXICOL-US, V2018, DOI 10.1155/2018/6362426; Wang S, 2015, IEEE T KNOWL DATA EN, V27, P1356, DOI 10.1109/TKDE.2014.2345380; Wu CY, 2017, IEEE I CONF COMP VIS, P2859, DOI 10.1109/ICCV.2017.309; Wu F, 2017, AAAI CONF ARTIF INTE, P1583; Xia K, 2017, INT CONF NANO MICRO, P291, DOI 10.1109/NEMS.2017.8017027; Xiao Qiqi, 2017, ARXIV171000478; Xiaoyuan Jing, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3049, DOI 10.1109/ICIP.2011.6116307; Yambor W. S., 2002, EMPIRICAL EVALUATION, P39, DOI DOI 10.1142/9789812777423_0003; Yan DD, 2017, J INTELL FUZZY SYST, V32, P2315, DOI 10.3233/JIFS-16270; Yan YL, 2015, IEEE INT SYM MULTIM, P483, DOI 10.1109/ISM.2015.126; Yang PY, 2014, IEEE T CYBERNETICS, V44, P445, DOI 10.1109/TCYB.2013.2257480; Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583; Yu J, 2012, IEEE T IMAGE PROCESS, V21, P4636, DOI 10.1109/TIP.2012.2207395; Zhang C, 2019, IEEE T NEUR NET LEAR, V30, P109, DOI 10.1109/TNNLS.2018.2832648; Zhang C, 2016, IEEE IJCNN, P4362, DOI 10.1109/IJCNN.2016.7727769; Zhang H., 2017, P IEEE 1 INT C DAT S, P532; Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212; Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241; Zheng ZY, 2015, COMPUT INFORM, V34, P1017	74	42	44	57	223	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2021	43	1					139	156		10.1109/TPAMI.2019.2929166	http://dx.doi.org/10.1109/TPAMI.2019.2929166			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PC7WN	31331881				2022-12-18	WOS:000597206900010
J	Zhang, B; Xiong, DY; Su, JS				Zhang, Biao; Xiong, Deyi; Su, Jinsong			Neural Machine Translation with Deep Attention	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Decoding; Task analysis; Semantics; NIST; Encoding; Neural networks; Analytical models; Deep attention network; neural machine translation (NMT); attention-based sequence-to-sequence learning; natural language processing		Deepening neural models has been proven very successful in improving the models capacity when solving complex learning tasks, such as the machine translation task. Previous efforts on deep neural machine translation mainly focus on the encoder and the decoder, while little on the attention mechanism. However, the attention mechanism is of vital importance to induce the translation correspondence between different languages where shallow neural networks are relatively insufficient, especially when the encoder and decoder are deep. In this paper, we propose a deep attention model (DeepAtt). Based on the low-level attention information, DeepAtt is capable of automatically determining what should be passed or suppressed from the corresponding encoder layer so as to make the distributed representation appropriate for high-level attention and translation. We conduct experiments on NIST Chinese-English, WMT English-German, and WMT English-French translation tasks, where, with five attention layers, DeepAtt yields very competitive performance against the state-of-the-art results. We empirically find that with an adequate increase of attention layers, DeepAtt tends to produce more accurate attention weights. An in-depth analysis on the translation of important context words further reveals that DeepAtt significantly improves the faithfulness of system translations.	[Zhang, Biao; Su, Jinsong] Xiamen Univ, Software Sch, Xiamen 361005, Fujian, Peoples R China; [Xiong, Deyi] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China	Xiamen University; Tianjin University	Su, JS (corresponding author), Xiamen Univ, Software Sch, Xiamen 361005, Fujian, Peoples R China.	zb@stu.xmu.edu.cn; dyxiong@tju.edu.cn; jssu@xmu.edu.cn		Xiong, Deyi/0000-0002-2353-5038	National Natural Science Foundation of China [61672440, 61622209]; Fundamental Research Funds for the Central Universities [ZK1024]; Scientific Research Project of National Language Committee of China [YB135-49]; Baidu Scholarship	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Scientific Research Project of National Language Committee of China; Baidu Scholarship	The authors were supported by the National Natural Science Foundation of China (Nos. 61672440 and 61622209), the Fundamental Research Funds for the Central Universities (Grant No. ZK1024), and Scientific Research Project of National Language Committee of China (Grant No. YB135-49). Biao Zhang greatly acknowledges the support of the Baidu Scholarship. The authors also thank the reviewers for their insightful comments.	[Anonymous], [No title captured]; [Anonymous], 2018, P 21 ANN C EUR SOC M; Bahdanau Dzmitry, 2015, ICLR; Buck C, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3579; Cheng Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1756; Chung Junyoung, 2014, ARXIV PREPRINT ARXIV; Gehring J, 2017, PR MACH LEARN RES, V70; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jean S, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1; Koehn Philipp, 2004, EMNLP; Liu Y, 2015, AAAI CONF ARTIF INTE, P2295; Luong MT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P11; Och FJ, 2003, COMPUT LINGUIST, V29, pc; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715; Shen SQ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1683; Srivastava R.K., 2015, P 28 INT C NEUR INF, P2377, DOI [10.5555/2969442.2969505, DOI 10.5555/2969442.2969505]; Su JS, 2018, AAAI CONF ARTIF INTE, P5488; Sutskever I., 2014, P ADV INT C NEUR INF, P3104; Tu ZP, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P76; Vaswani A., 2017, ADV NEURAL INFORM PR, V30; Wang  M., 2016, P 2016 C EMP METH NA, P278; Wang MX, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P136, DOI 10.18653/v1/P17-1013; Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10; Zeiler M.D., 2012, ADADELTA ADAPTIVE LE, DOI DOI 10.48550/ARXIV.1212.5701; Zhang B., 2016, ARXIV160708725; Zhang B., 2017, ARXIV170408430; Zhang B, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1789; Zhang X., 2018, CORR; Zhou J., 2016, T ASSOC COMPUT LING, V4, P371, DOI [DOI 10.1162/TACL_A_00105, 10.1162/tacl_a_00105]	32	42	45	5	65	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2020	42	1					154	163		10.1109/TPAMI.2018.2876404	http://dx.doi.org/10.1109/TPAMI.2018.2876404			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JV3VQ	30334781				2022-12-18	WOS:000502294300012
J	Xie, ZC; Sun, ZH; Jin, LW; Ni, H; Lyons, T				Xie, Zecheng; Sun, Zenghui; Jin, Lianwen; Ni, Hao; Lyons, Terry			Learning Spatial-Semantic Context with Fully Convolutional Recurrent Network for Online Handwritten Chinese Text Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Handwritten Chinese text recognition; path signature; residual recurrent network; multiple spatial contexts; implicit language model	SEGMENTATION	Online handwritten Chinese text recognition (OHCTR) is a challenging problem as it involves a large-scale character set, ambiguous segmentation, and variable-length input sequences. In this paper, we exploit the outstanding capability of path signature to translate online pen-tip trajectories into informative signature feature maps, successfully capturing the analytic and geometric properties of pen strokes with strong local invariance and robustness. A multi-spatial-context fully convolutional recurrent network (MC-FCRN) is proposed to exploit the multiple spatial contexts from the signature feature maps and generate a prediction sequence while completely avoiding the difficult segmentation problem. Furthermore, an implicit language model is developed to make predictions based on semantic context within a predicting feature sequence, providing a new perspective for incorporating lexicon constraints and prior knowledge about a certain language in the recognition procedure. Experiments on two standard benchmarks, Dataset-CASIA and Dataset-ICDAR, yielded outstanding results, with correct rates of 97.50 and 96.58 percent, respectively, which are significantly better than the best result reported thus far in the literature.	[Xie, Zecheng; Sun, Zenghui; Jin, Lianwen] South China Univ Technol, Coll Elect & Informat Engn, Guangzhou 510630, Guangdong, Peoples R China; [Ni, Hao] UCL, Dept Math, London WC1E 6BT, England; [Ni, Hao; Lyons, Terry] Alan Turing Inst, London NW1 2DB, England; [Lyons, Terry] Univ Oxford, Math Inst, Oxford OX1 3BD, England	South China University of Technology; University of London; University College London; University of Oxford	Jin, LW (corresponding author), South China Univ Technol, Coll Elect & Informat Engn, Guangzhou 510630, Guangdong, Peoples R China.	zcheng.xie@gmail.com; sunfreding@gmail.com; lianwen.jin@gmail.com; ucahhni@ucl.ac.uk; tlyons@maths.ox.ac.uk	Ni, Hao/AAF-4684-2020; Lyons, Terry/AAG-6890-2020		NSFC [61472144, 61673182]; National Key Research & Development Plan of China [2016YFB1001405]; GDSTP [2015B010101004, 2015B010130003]; GZSTP [201607010227]; Alan Turing Institute under the EPSRC [EP/N510129/1]; ERC advanced grant ESig [291244]; Alan Turing Institute [TU/B/000039] Funding Source: researchfish	NSFC(National Natural Science Foundation of China (NSFC)); National Key Research & Development Plan of China; GDSTP; GZSTP; Alan Turing Institute under the EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); ERC advanced grant ESig; Alan Turing Institute	This work was supported in part by NSFC (Grant No.: 61472144, 61673182), the National Key Research & Development Plan of China (No. 2016YFB1001405), GDSTP (Grant No.:, 2015B010101004, 2015B010130003), GZSTP(no. 201607010227), the Alan Turing Institute under the EPSRC grant EP/N510129/1, and ERC advanced grant ESig (agreement no. 291244).	[Anonymous], 2009, CHIN LING DAT CONS; Bai ZL, 2005, PROC INT CONF DOC, P262; Bengio Y, 2006, STUD FUZZ SOFT COMP, V194, P137; Bengio Y., 1999, Neural Computing Surveys, V2; Biadsy F., 2006, P 10 INT WORKSH FRON, P85; Bluche T, 2016, 160403286 ARXIV; Bluche Thdodore, 2016, ADV NEURAL INFORM PR, P838, DOI DOI 10.5555/3157096.3157190; Chen K.-T., 1958, T AM MATH SOC, P395, DOI [10.2307/1993193, DOI 10.1090/S0002-9947-1958-0106258-0]; Cheriet M, 2007, CHARACTER RECOGNITION SYSTEMS: A GUIDE FOR STUDENTS AND PRACTIONERS, P1, DOI 10.1002/9780470176535; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Dzmitry Bahdanau, 2016, Arxiv, DOI arXiv:1409.0473; Graham B., 2013, ARXIV13080371; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; Graves A, 2014, PR MACH LEARN RES, V32, P1764; Graves A, 2012, STUD COMPUT INTELL, V385, P37; Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137; Hambly B, 2010, ANN MATH, V171, P109, DOI 10.4007/annals.2010.171.109; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; He P, 2016, AAAI CONF ARTIF INTE, P3501; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jin G., THE PH CORPUS; KIMURA F, 1987, IEEE T PATTERN ANAL, V9, P149, DOI 10.1109/TPAMI.1987.4767881; Liu C.-L., 2006, P 10 IWFHR, P217; Liu CL, 2011, PROC INT CONF DOC, P1464, DOI 10.1109/ICDAR.2011.291; Liu CL, 2011, PROC INT CONF DOC, P37, DOI 10.1109/ICDAR.2011.17; Liwicki M, 2007, PROC INT CONF DOC, P367; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lyons T., 2002, SYSTEM CONTROL ROUGH; Lyons T, 2014, PROCEEDINGS OF THE INTERNATIONAL CONGRESS OF MATHEMATICIANS (ICM 2014), VOL IV, P163; Marukatat S, 2001, PROC INT CONF DOC, P731, DOI 10.1109/ICDAR.2001.953886; Messina R, 2015, PROC INT CONF DOC, P171; Mikoshiba T, 2010, ASME PRESSURE VESSELS AND PIPING CONFERENCE, VOL 8: SEISMIC ENGINEERING, P3; Mukherjee T., 2016, P C EMP METH NAT LAN, P912; Pan YW, 2016, PROC CVPR IEEE, P4594, DOI 10.1109/CVPR.2016.497; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; Qiu-Feng Wang, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1036, DOI 10.1109/ICDAR.2009.96; Sahu D. K., 2015, ARXIV151104176; Schenk J., 2006, P 10 INT WORKSH FRON, P619; SENI G, 1994, PATTERN RECOGN, V27, P41, DOI 10.1016/0031-3203(94)90016-7; Shi B., 2016, IEEE T PATTERN ANAL, DOI [10.1109/TPAMI.2016.2346371, DOI 10.1109/TPAMI.2016.2346371]; Srivastava Rupesh Kumar, 2015, ADV NEURAL INFORM PR, P2377; Stolcke Andreas, 2002, P INT, P901; Su TH, 2009, PATTERN RECOGN, V42, P167, DOI 10.1016/j.patcog.2008.05.012; Sun LF, 2016, ACSR ADV COMPUT, V47, P271; Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194; Sutskever I., 2014, ARXIV14093215, DOI DOI 10.1007/S10107-014-0839-0; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515; Verma B, 2004, IEEE IJCNN, P1337; Vilnis L., 2014, P INT C LEARN REPR, P1; Wang DH, 2012, PATTERN RECOGN, V45, P3661, DOI 10.1016/j.patcog.2012.04.020; Wang QF, 2012, IEEE T PATTERN ANAL, V34, P1469, DOI 10.1109/TPAMI.2011.264; Wu YC, 2017, PATTERN RECOGN, V65, P251, DOI 10.1016/j.patcog.2016.12.026; Xie ZC, 2016, INT C PATT RECOG, P4011; Yang WX, 2016, PATTERN RECOGN, V58, P190, DOI 10.1016/j.patcog.2016.04.007; Yang WX, 2015, PROC INT CONF DOC, P551, DOI 10.1109/ICDAR.2015.7333822; Yin F, 2013, PROC INT CONF DOC, P1464, DOI 10.1109/ICDAR.2013.218; Zhou XD, 2014, PATTERN RECOGN, V47, P1904, DOI 10.1016/j.patcog.2013.12.002; Zhou XD, 2013, IEEE T PATTERN ANAL, V35, P2413, DOI 10.1109/TPAMI.2013.49	65	42	42	2	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2018	40	8					1903	1917		10.1109/TPAMI.2017.2732978	http://dx.doi.org/10.1109/TPAMI.2017.2732978			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GL6DT	28767364	Green Submitted, Green Published			2022-12-18	WOS:000437271100009
J	Crivellaro, A; Rad, M; Verdie, Y; Yi, KM; Fua, P; Lepetit, V				Crivellaro, Alberto; Rad, Mahdi; Verdie, Yannick; Yi, Kwang Moo; Fua, Pascal; Lepetit, Vincent			Robust 3D Object Tracking from Monocular Images Using Stable Parts	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D detection; 3D tracking		We present an algorithm for estimating the pose of a rigid object in real-time under challenging conditions. Our method effectively handles poorly textured objects in cluttered, changing environments, even when their appearance is corrupted by large occlusions, and it relies on grayscale images to handle metallic environments on which depth cameras would fail. As a result, our method is suitable for practical Augmented Reality applications including industrial environments. At the core of our approach is a novel representation for the 3D pose of object parts: We predict the 3D pose of each part in the form of the 2D projections of a few control points. The advantages of this representation is three-fold: We can predict the 3D pose of the object even when only one part is visible; when several parts are visible, we can easily combine them to compute a better pose of the object; the 3D pose we obtain is usually very accurate, even when only few parts are visible. We show how to use this representation in a robust 3D tracking framework. In addition to extensive comparisons with the state-of-the-art, we demonstrate our method on a practical Augmented Reality application for maintenance assistance in the ATLAS particle detector at CERN.	[Crivellaro, Alberto] S&H, I-20068 Milan, Italy; [Yi, Kwang Moo; Fua, Pascal] Ecole Polytech Fed Lausanne, IC Fac, Comp Vis Lab, CH-1015 Lausanne, Switzerland; [Rad, Mahdi; Lepetit, Vincent] Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria; [Verdie, Yannick] NCam Tech, F-75005 Paris, France	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Graz University of Technology	Crivellaro, A (corresponding author), S&H, I-20068 Milan, Italy.	a.crivellaro@sehitaly.com; rad@icg.tugraz.at; yannick.verdie@ncam-tech.com; kwang.yi@epfl.ch; pascal.fua@epfl.ch; lepetit@icg.tugraz.at	Yi, Kwang Moo/C-2612-2016	Yi, Kwang Moo/0000-0001-9036-3822	CDL Semantic for 3D Computer Vision; EU project EDU-SAFE; EU project MAGELLAN	CDL Semantic for 3D Computer Vision; EU project EDU-SAFE; EU project MAGELLAN	This work was supported in part by the CDL Semantic for 3D Computer Vision and in part by the EU projects EDU-SAFE and MAGELLAN.	[Anonymous], 2014, 2 INT C LEARN REPR I; [Anonymous], 2006, P BRIT MACH VIS C BM; Bastien F., 2012, P INT C NEUR INF PRO; Brachmann E, 2014, LECT NOTES COMPUT SC, V8690, P536, DOI 10.1007/978-3-319-10605-2_35; Chliveros Georgios, 2013, Computer Vision Systems. 9th International Conference, ICVS 2013. Proceedings: LNCS 7963, P234, DOI 10.1007/978-3-642-39402-7_24; Choi C, 2013, IEEE INT C INT ROBOT, P1568, DOI 10.1109/IROS.2013.6696558; Crivellaro A, 2015, IEEE I CONF COMP VIS, P4391, DOI 10.1109/ICCV.2015.499; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Damen D, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.23; Drost B, 2010, PROC CVPR IEEE, P998, DOI 10.1109/CVPR.2010.5540108; Eggert DW, 1997, MACH VISION APPL, V9, P272, DOI 10.1007/s001380050048; Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54; Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005; Giusti A, 2013, IEEE IMAGE PROC, P4034, DOI 10.1109/ICIP.2013.6738831; Harris C., 1990, P BRIT MECH VIS C; He K, 2014, LECT NOTES COMPUT SC, V8692, P450, DOI 10.1007/978-3-319-10593-2_30; HINTERSTOISSER S, 2008, P IEEE C COMP VIS PA, P1; Hinterstoisser S, 2012, IEEE T PATTERN ANAL, V34, P876, DOI 10.1109/TPAMI.2011.206; Hodan T, 2017, IEEE WINT CONF APPL, P880, DOI 10.1109/WACV.2017.103; Klein George, 2007, P1; Koser K, 2007, IEEE I CONF COMP VIS, P70; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; KRULL A, 2015, IEEE I CONF COMP VIS, P954, DOI DOI 10.1109/ICCV.2015.115; Kyriazis N, 2014, PROC CVPR IEEE, P3430, DOI 10.1109/CVPR.2014.438; Lai K., 2011, P AAAI C ART INT, P1474; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lim JJ, 2014, LECT NOTES COMPUT SC, V8694, P478, DOI 10.1007/978-3-319-10599-4_31; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; Markley FL, 2007, J GUID CONTROL DYNAM, V30, P1193, DOI 10.2514/1.28949; Moreno-Noguer F, 2008, LECT NOTES COMPUT SC, V5303, P405, DOI 10.1007/978-3-540-88688-4_30; Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513; Pauwels K, 2013, PROC CVPR IEEE, P2347, DOI 10.1109/CVPR.2013.304; Payet N, 2011, IEEE I CONF COMP VIS, P983, DOI 10.1109/ICCV.2011.6126342; Pepik B, 2012, PROC CVPR IEEE, P3362, DOI 10.1109/CVPR.2012.6248075; Prisacariu V. A., 2012, LNCS, P593, DOI DOI 10.1007/978-3-642-37331-2_45; Prisacariu VA, 2012, INT J COMPUT VISION, V98, P335, DOI 10.1007/s11263-011-0514-3; Rios-Cabrera R, 2013, IEEE I CONF COMP VIS, P2048, DOI 10.1109/ICCV.2013.256; Rosten E, 2005, IEEE I CONF COMP VIS, P1508; Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178; Shrivastava A, 2013, IEEE I CONF COMP VIS, P1745, DOI 10.1109/ICCV.2013.219; Simonyan K, 2015, 3 INT C LEARN REPR I; Skrypnyk I, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P110, DOI 10.1109/ISMAR.2004.53; Song SR, 2014, LECT NOTES COMPUT SC, V8694, P634, DOI 10.1007/978-3-319-10599-4_41; Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773; Tan DJ, 2014, PROC CVPR IEEE, P1202, DOI 10.1109/CVPR.2014.157; Tejani A, 2014, LECT NOTES COMPUT SC, V8694, P462, DOI 10.1007/978-3-319-10599-4_30; Tombari F, 2013, IEEE I CONF COMP VIS, P1265, DOI 10.1109/ICCV.2013.160; Ude A, 1999, ROBOT AUTON SYST, V28, P163, DOI 10.1016/S0921-8890(99)00014-7; UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573; Vacchetti L, 2004, IEEE T PATTERN ANAL, V26, P1385, DOI 10.1109/TPAMI.2004.92; Wagner D, 2008, INT SYM MIX AUGMENT, P125, DOI 10.1109/ISMAR.2008.4637338; Welch G., 1995, INTRO KALMAN FILTER; Wohlhart P, 2015, PROC CVPR IEEE, P3109, DOI 10.1109/CVPR.2015.7298930; Xiang Y, 2014, LECT NOTES COMPUT SC, V8694, P220, DOI 10.1007/978-3-319-10599-4_15	54	42	45	1	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2018	40	6					1465	1479		10.1109/TPAMI.2017.2708711	http://dx.doi.org/10.1109/TPAMI.2017.2708711			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GE9BK	28574342				2022-12-18	WOS:000431524700014
J	Torii, A; Arandjelovic, R; Sivic, J; Okutomi, M; Pajdla, T				Torii, Akihiko; Arandjelovic, Relja; Sivic, Josef; Okutomi, Masatoshi; Pajdla, Tomas			24/7 Place Recognition by View Synthesis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Place recognition; view synthesis; compact image descriptor; image retrieval	SCENE	We address the problem of large-scale visual place recognition for situations where the scene undergoes a major change in appearance, for example, due to illumination (day/night), change of seasons, aging, or structural modifications over time such as buildings being built or destroyed. Such situations represent a major challenge for current large-scale place recognition methods. This work has the following three principal contributions. First, we demonstrate that matching across large changes in the scene appearance becomes much easier when both the query image and the database image depict the scene from approximately the same viewpoint. Second, based on this observation, we develop a new place recognition approach that combines (i) an efficient synthesis of novel views with (ii) a compact indexable image representation. Third, we introduce a new challenging dataset of 1,125 camera-phone query images of Tokyo that contain major changes in illumination (day, sunset, night) as well as structural changes in the scene. We demonstrate that the proposed approach significantly outperforms other large-scale place recognition techniques on this challenging data.	[Torii, Akihiko; Okutomi, Masatoshi] Tokyo Inst Technol, Dept Syst & Control Engn, Sch Engn, Tokyo 1528550, Japan; [Arandjelovic, Relja; Sivic, Josef] CNRS, INRIA, ENS, WILLOW,Dept Informat,UMR8548, Paris, France; [Sivic, Josef] Czech Tech Univ, Czech Inst Informat Robot & Cybernet, Prague 16636, Czech Republic; [Pajdla, Tomas] Czech Tech Univ, Fac Elect Engn, Ctr Machine Percept, Dept Cybernet, Prague 16636, Czech Republic	Tokyo Institute of Technology; Centre National de la Recherche Scientifique (CNRS); Inria; UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS); Universite Paris Cite; Czech Technical University Prague; Czech Technical University Prague	Torii, A (corresponding author), Tokyo Inst Technol, Dept Syst & Control Engn, Sch Engn, Tokyo 1528550, Japan.	torii@ctrl.titech.ac.jp; relja.arandjelovic@inria.fr; Josef.Sivic@ens.fr; mxo@ctrl.titech.ac.jp; pajdla@cvut.cz		Okutomi, Masatoshi/0000-0001-5787-0742; Pajdla, Tomas/0000-0001-6325-0072	JSPS KAKENHI [15H05313]; Project LADIO EU H2020 [731970]; Google; CityLabs@Inria; ERC project LEAP [336845]; ANR [ANR-13-CORD-0003]; CIFAR Learning in MachinesBrains program; Project IMPACT [CZ.02.1.01/0.0/0.0/15_003/0000468]; European Regional Development Fund; Intelligence Advanced Research Projects Activity (IARPA) via Air Force Research Laboratory [FA8650-12-C-7212]	JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)); Project LADIO EU H2020; Google(Google Incorporated); CityLabs@Inria; ERC project LEAP; ANR(French National Research Agency (ANR)); CIFAR Learning in MachinesBrains program; Project IMPACT; European Regional Development Fund(European Commission); Intelligence Advanced Research Projects Activity (IARPA) via Air Force Research Laboratory	The authors were partially supported by JSPS KAKENHI Grant Number 15H05313, Project LADIO EU H2020 No. 731970, Google, CityLabs@Inria, the ERC project LEAP (no. 336845), ANR project Semapolis (ANR-13-CORD-0003), CIFAR Learning in Machines&Brains program, Project IMPACT CZ.02.1.01/0.0/0.0/15_003/0000468 and the European Regional Development Fund, and the Intelligence Advanced Research Projects Activity (IARPA) via Air Force Research Laboratory, contract FA8650-12-C-7212. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. Disclaimer: The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, AFRL, or the U.S. Government.	Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/CVPR.2016.572, 10.1109/TPAMI.2017.2711011]; Arandjelovic R, 2015, LECT NOTES COMPUT SC, V9006, P188, DOI 10.1007/978-3-319-16817-3_13; Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Aubry M., 2014, ACM T GRAPHIC, V33; Azizpour H, 2016, IEEE T PATTERN ANAL, V38, P1790, DOI 10.1109/TPAMI.2015.2500224; Bosch A, 2007, IEEE I CONF COMP VIS, P1863; Cao S, 2014, PROC CVPR IEEE, P461, DOI 10.1109/CVPR.2014.66; Cao S, 2013, PROC CVPR IEEE, P700, DOI 10.1109/CVPR.2013.96; Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Cummins M., 2009, ROB SCI SYST SEATTL; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Flynn J, 2016, PROC CVPR IEEE, P5515, DOI 10.1109/CVPR.2016.595; Ge TZ, 2014, IEEE T PATTERN ANAL, V36, P744, DOI 10.1109/TPAMI.2013.240; Hauagge D., 2014, P BRIT MACH VIS C; Hauagge DC, 2012, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2012.6247677; Hays James, 2008, CVPR, DOI DOI 10.1109/CVPR.2008.4587784; Irschara Arnold, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2599, DOI 10.1109/CVPRW.2009.5206587; Jacobs N, 2007, IEEE I CONF COMP VIS, P1305; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Jegou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Kim K., 2016, P 14 EUR C COMP VIS, P750, DOI DOI 10.1007/978-3-319-46487-9; Klingner B, 2013, IEEE I CONF COMP VIS, P953, DOI 10.1109/ICCV.2013.122; KNOPP J, 2010, PROC 11 EUR CONF, V6311, P748; Laffont PY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601101; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li FY, 2006, IEEE INT CONF ROBOT, P3405, DOI 10.1109/ROBOT.2006.1642222; Li YP, 2012, LECT NOTES COMPUT SC, V7572, P15, DOI 10.1007/978-3-642-33718-5_2; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maddern W, 2014, P IEEE C ROB AUT ICR, V2, P3; MATZEN K, 2014, PROC 13 EUR C COMP, V8695, P615, DOI DOI 10.1007/978-3-319-10584-0; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Neubert P, 2015, ROBOT AUTON SYST, V69, P15, DOI 10.1016/j.robot.2014.08.005; Norouzi M, 2013, PROC CVPR IEEE, P3017, DOI 10.1109/CVPR.2013.388; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278; Razavian A. S., 2014, P DEEPVISION DEEP LE; Razavian AS, 2015, P INT C LEARN REPR; SATTLER T, 2012, PROC 12 EUR CONF, V7572, P752; Sattler T, 2016, PROC CVPR IEEE, P1582, DOI 10.1109/CVPR.2016.175; Sattler T, 2015, IEEE I CONF COMP VIS, P2102, DOI 10.1109/ICCV.2015.243; Sattler T, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.76; Schindler Grant, 2007, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2007.383150; Shan Q., 2014, 2014 2 INT C 3D VIS, VVolume 1, P525; Sibbing D, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P56, DOI 10.1109/3DV.2013.16; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Sunderhauf N., 2015, CVPR 2015 WORKSH VIS; Sunderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI; Torii A, 2015, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2015.7298790; Torii A, 2013, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2013.119; Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Wu CC, 2008, PROC CVPR IEEE, P1229; Zamir AR, 2010, LECT NOTES COMPUT SC, V6314, P255, DOI 10.1007/978-3-642-15561-1_19; Zhao WL, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.99	60	42	42	2	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2018	40	2					257	271		10.1109/TPAMI.2017.2667665	http://dx.doi.org/10.1109/TPAMI.2017.2667665			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FS9AN	28207385	Green Submitted			2022-12-18	WOS:000422706000001
J	Purkait, P; Chin, TJ; Sadri, A; Suter, D				Purkait, Pulak; Chin, Tat-Jun; Sadri, Alireza; Suter, David			Clustering with Hypergraphs: The Case for Large Hyperedges	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Higher order grouping; hypergraph clustering; motion segmentation	SEGMENTATION; TUTORIAL; OBJECTS; MODEL; CUTS	The extension of conventional clustering to hypergraph clustering, which involves higher order similarities instead of pairwise similarities, is increasingly gaining attention in computer vision. This is due to the fact that many clustering problems require an affinity measure that must involve a subset of data of size more than two. In the context of hypergraph clustering, the calculation of such higher order similarities on data subsets gives rise to hyperedges. Almost all previous work on hypergraph clustering in computer vision, however, has considered the smallest possible hyperedge size, due to a lack of study into the potential benefits of large hyperedges and effective algorithms to generate them. In this paper, we show that large hyperedges are better from both a theoretical and an empirical standpoint. We then propose a novel guided sampling strategy for large hyperedges, based on the concept of random cluster models. Our method can generate large pure hyperedges that significantly improve grouping accuracy without exponential increases in sampling costs. We demonstrate the efficacy of our technique on various higher-order grouping problems. In particular, we show that our approach improves the accuracy and efficiency of motion segmentation from dense, long-term, trajectories.	[Purkait, Pulak] Univ Birmingham, Sch Comp Sci, Birmingham B15 2TT, W Midlands, England; [Chin, Tat-Jun; Suter, David] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Sadri, Alireza] RMIT Univ, Aerosp Mech & Mfg Engn, Melbourne, Vic 3000, Australia	University of Birmingham; University of Adelaide; Royal Melbourne Institute of Technology (RMIT)	Purkait, P (corresponding author), Univ Birmingham, Sch Comp Sci, Birmingham B15 2TT, W Midlands, England.	pulak.isi@gmail.com; tat-jun.chin@adelaide.edu.au; s3391149@student.rmit.edu.au; david.suter@adelaide.edu.au		Suter, David/0000-0001-6306-3023; Purkait, Pulak/0000-0003-0684-1209	ARC [DP130102524]	ARC(Australian Research Council)	This work was supported by ARC grant DP130102524.	Agarwal S, 2005, PROC CVPR IEEE, P838; Agarwal S., 2006, ICML, P17, DOI DOI 10.1145/1143844.1143847; ALPERT CJ, 1995, INTEGRATION, V19, P1, DOI 10.1016/0167-9260(95)00008-4; [Anonymous], 2012, CVX MATL SOFTW DISC; Barbu A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P320; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484; Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21; Chen GL, 2009, INT J COMPUT VISION, V81, P317, DOI 10.1007/s11263-008-0178-9; Chin TJ, 2012, IEEE T PATTERN ANAL, V34, P625, DOI 10.1109/TPAMI.2011.169; Chin TJ, 2010, LECT NOTES COMPUT SC, V6315, P533, DOI 10.1007/978-3-642-15555-0_39; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Govindu VM, 2005, PROC CVPR IEEE, P1150; Ho J, 2003, PROC CVPR IEEE, P11, DOI 10.1109/cvpr.2003.1211332; Jain S, 2013, IEEE I CONF COMP VIS, P3511, DOI 10.1109/ICCV.2013.436; Kappes JH, 2016, COMPUT VIS IMAGE UND, V143, P104, DOI 10.1016/j.cviu.2015.11.005; Kim S, 2014, IEEE T PATTERN ANAL, V36, P1761, DOI 10.1109/TPAMI.2014.2303095; Liu G., 2010, P 27 INT C MACHINE L, P663, DOI DOI 10.1109/ICDMW.2010.64; Liu H., 2010, ADV NEURAL INFORM PR, P1414; Liu HR, 2012, PROC CVPR IEEE, P574, DOI 10.1109/CVPR.2012.6247723; Ma Y, 2007, IEEE T PATTERN ANAL, V29, P1546, DOI 10.1109/TP'AMI.2007.1085; MacKay D. J. C., 2003, INFORM THEORY INFERE, P269; Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242; Ochs P, 2012, PROC CVPR IEEE, P614, DOI 10.1109/CVPR.2012.6247728; Purkait P, 2014, LECT NOTES COMPUT SC, V8692, P672, DOI 10.1007/978-3-319-10593-2_44; Tran QH, 2014, INT J COMPUT VISION, V106, P93, DOI 10.1007/s11263-013-0643-y; Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4_37; Rital S, 2009, FUND INFORM, V96, P153, DOI 10.3233/FI-2009-172; Shi F, 2013, IEEE I CONF COMP VIS, P3088, DOI 10.1109/ICCV.2013.383; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Tordoff B, 2002, LECT NOTES COMPUT SC, V2350, P82; Torr PHS, 1998, PHILOS T R SOC A, V356, P1321, DOI 10.1098/rsta.1998.0224; Tron R, 2007, PROC CVPR IEEE, P41, DOI 10.1109/cvpr.2007.382974; Pham TT, 2012, PROC CVPR IEEE, P710, DOI 10.1109/CVPR.2012.6247740; Vidal R, 2005, IEEE T PATTERN ANAL, V27, P1945, DOI 10.1109/TPAMI.2005.244; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Yan JY, 2006, LECT NOTES COMPUT SC, V3954, P94; Zhang T, 2012, INT J COMPUT VISION, V100, P217, DOI 10.1007/s11263-012-0535-6; Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2; Zhou D., 2006, ADV NEURAL INF PROCE, V19, P1601; Zien JY, 1999, IEEE T COMPUT AID D, V18, P1389, DOI 10.1109/43.784130	43	42	47	3	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2017	39	9					1697	1711		10.1109/TPAMI.2016.2614980	http://dx.doi.org/10.1109/TPAMI.2016.2614980			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FC4WC	28113490				2022-12-18	WOS:000406840800001
J	Belagiannis, V; Amin, S; Andriluka, M; Schiele, B; Navab, N; Ilic, S				Belagiannis, Vasileios; Amin, Sikandar; Andriluka, Mykhaylo; Schiele, Bernt; Navab, Nassir; Ilic, Slobodan			3D Pictorial Structures Revisited: Multiple Human Pose Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human pose estimation; 3D pictorial structures; part-based models	MOTION CAPTURE; PEOPLE	We address the problem of 3D pose estimation of multiple humans from multiple views. The transition from single to multiple human pose estimation and from the 2D to 3D space is challenging due to a much larger state space, occlusions and across-view ambiguities when not knowing the identity of the humans in advance. To address these problems, we first create a reduced state space by triangulation of corresponding pairs of body parts obtained by part detectors for each camera view. In order to resolve ambiguities of wrong and mixed parts of multiple humans after triangulation and also those coming from false positive detections, we introduce a 3D pictorial structures (3DPS) model. Our model builds on multi-view unary potentials, while a prior model is integrated into pairwise and ternary potential functions. To balance the potentials' influence, the model parameters are learnt using a Structured SVM (SSVM). The model is generic and applicable to both single and multiple human pose estimation. To evaluate our model on single and multiple human pose estimation, we rely on four different datasets. We first analyse the contribution of the potentials and then compare our results with related work where we demonstrate superior performance.	[Belagiannis, Vasileios; Navab, Nassir] Tech Univ Munich, Comp Aided Med Procedures, D-80290 Munich, Germany; [Amin, Sikandar] Tech Univ Munich, Intelligent Autonomous Syst, D-80290 Munich, Germany; [Andriluka, Mykhaylo] Stanford Univ, Stanford, CA 94305 USA; [Schiele, Bernt] Max Planck Inst Informat, Saarbrucken, Germany; [Ilic, Slobodan] Siemens AG, Munich, Germany	Technical University of Munich; Technical University of Munich; Stanford University; Max Planck Society; Siemens AG; Siemens Germany	Belagiannis, V (corresponding author), Tech Univ Munich, Comp Aided Med Procedures, D-80290 Munich, Germany.	belagian@in.tum.de; sikandar.amin@in.tum.de; andriluka@mpi-inf.mpg.de; schiele@mpi-inf.mpg.de; navab@cs.tum.edu; Slobodan.Ilic@in.tum.de	Peters, Terry M/K-6853-2013; Belagiannis, Vasileios/W-2665-2019	Peters, Terry M/0000-0003-1440-7488; Belagiannis, Vasileios/0000-0003-0960-8453	DFG	DFG(German Research Foundation (DFG))	This work was funded by the DFG Project "Advanced Learning for Tracking and Detection in Medical Workflow Analysis". The authors would like to thank Xinchao Wang for providing the tracking information, as well as Maximilian Baust and Peter Gehler for their helpful discussions.	Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21; Alahari K, 2013, IEEE I CONF COMP VIS, P2112, DOI 10.1109/ICCV.2013.263; Amin S, 2014, LECT NOTES COMPUT SC, V8753, P253, DOI 10.1007/978-3-319-11752-2_20; Amin S, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.45; Andriluka M, 2008, PROC CVPR IEEE, P1873, DOI 10.1109/CVPR.2008.4587583; Andriluka M, 2010, PROC CVPR IEEE, P623, DOI 10.1109/CVPR.2010.5540156; Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754; Belagiannis V, 2014, PROC CVPR IEEE, P1669, DOI 10.1109/CVPR.2014.216; Belagiannis Vasileios, 2014, PROC EUR C COMPUT VI, P742; Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21; Bishop C.M, 2006, PATTERN RECOGN; Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; Burenius M, 2013, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2013.464; Chen X., 2014, P 27 ANN C NEURAL IN, P1736, DOI DOI 10.1109/CVPR.2018.00742; Deutscher J, 2005, INT J COMPUT VISION, V61, P185, DOI 10.1023/B:VISI.0000043757.18370.9c; Eichner M, 2010, LECT NOTES COMPUT SC, V6311, P228, DOI 10.1007/978-3-642-15549-9_17; Elhayek A, 2015, COMPUT GRAPH FORUM, V34, P86, DOI 10.1111/cgf.12519; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468; Finley T., 2008, INT C MACHINE LEARNI, P304, DOI DOI 10.1145/1390156.1390195; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Gall J, 2010, INT J COMPUT VISION, V87, P75, DOI 10.1007/s11263-008-0173-1; Grauman K, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P641; Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20; Hartley R., 2003, MULTIPLE VIEW GEOMET; Hofmann M, 2012, INT J COMPUT VISION, V96, P103, DOI 10.1007/s11263-011-0451-1; Kazemi V, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.48; Lallemand J, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P271, DOI 10.1109/3DV.2013.43; Lee MW, 2006, LECT NOTES COMPUT SC, V3953, P368; Li SJ, 2015, LECT NOTES COMPUT SC, V9004, P332, DOI 10.1007/978-3-319-16808-1_23; Li Y., 2012, 12 EUR C COMP VIS EC, P400; Mitchelson J., 2003, P BRIT MACH VIS C, P1; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; Nowozin S, 2010, LECT NOTES COMPUT SC, V6316, P98, DOI 10.1007/978-3-642-15567-3_8; Plankers R, 2003, IEEE T PATTERN ANAL, V25, P1182, DOI 10.1109/TPAMI.2003.1227995; Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381; Sidenbladh H., 2000, LNCS, V2, P702; Sigal L, 2012, INT J COMPUT VISION, V98, P15, DOI 10.1007/s11263-011-0493-4; Sminchisescu C, 2005, PROC CVPR IEEE, P390; Sudderth EB, 2010, COMMUN ACM, V53, P95, DOI 10.1145/1831407.1831431; Taylor GW, 2010, PROC CVPR IEEE, P631, DOI 10.1109/CVPR.2010.5540157; Tompson J.J., 2014, ADV NEURAL INFORM PR, V27, P1799; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; Tsochantaridis Ioannis, 2004, P 21 INT C MACH LEAR; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Yao A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.67; Zhao T, 2004, IEEE T PATTERN ANAL, V26, P1208, DOI 10.1109/TPAMI.2004.73	48	42	43	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2016	38	10					1929	1942		10.1109/TPAMI.2015.2509986	http://dx.doi.org/10.1109/TPAMI.2015.2509986			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DX2YV	26700970				2022-12-18	WOS:000384240600001
J	Tao, MW; Su, JC; Wang, TC; Malik, J; Ramamoorthi, R				Tao, Michael W.; Su, Jong-Chyi; Wang, Ting-Chun; Malik, Jitendra; Ramamoorthi, Ravi			Depth Estimation and Specular Removal for Glossy Surfaces Using Point and Line Consistency with Light-Field Cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Light fields; 3D reconstruction; specular-free image; reflection components separation; dichromatic reflection model	REFLECTION COMPONENTS; COLOR CONSTANCY; STEREO; SEPARATION	Light-field cameras have now become available in both consumer and industrial applications, and recent papers have demonstrated practical algorithms for depth recovery from a passive single-shot capture. However, current light-field depth estimation methods are designed for Lambertian objects and fail or degrade for glossy or specular surfaces. The standard Lambertian photoconsistency measure considers the variance of different views, effectively enforcing point-consistency, i.e., that all views map to the same point in RGB space. This variance or point-consistency condition is a poor metric for glossy surfaces. In this paper, we present a novel theory of the relationship between light-field data and reflectance from the dichromatic model. We present a physically-based and practical method to estimate the light source color and separate specularity. We present a new photo consistency metric, line-consistency, which represents how viewpoint changes affect specular points. We then show how the new metric can be used in combination with the standard Lambertian variance or point-consistency measure to give us results that are robust against scenes with glossy surfaces. With our analysis, we can also robustly estimate multiple light source colors and remove the specular component from glossy objects. We show that our method outperforms current state-of-the-art specular removal and depth estimation algorithms in multiple real world scenarios using the consumer Lytro and Lytro Illum light field cameras.	[Tao, Michael W.; Wang, Ting-Chun; Malik, Jitendra] Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA; [Su, Jong-Chyi; Ramamoorthi, Ravi] Univ Calif San Diego, CSE Dept, San Diego, CA 92093 USA	University of California System; University of California Berkeley; University of California System; University of California San Diego	Tao, MW; Wang, TC; Malik, J (corresponding author), Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA.; Su, JC; Ramamoorthi, R (corresponding author), Univ Calif San Diego, CSE Dept, San Diego, CA 92093 USA.	mtaomalik@eecs.berkeley.edu; jcsu@eng.ucsd.edu; tcwang0509malik@eecs.berkeley.edu; malik@eecs.berkeley.edu; ravir@cs.ucsd.edu	Wang, Ting-Chun/AAZ-2408-2020; Su, Jong-Chyi/AAC-1003-2021; Wang, Ting-Chun/AAD-4410-2021	Wang, Ting-Chun/0000-0002-1522-2381; Su, Jong-Chyi/0000-0002-7933-8308; 	ONR [N00014-09-1-0741, N00014-14-1-0332, N00014-15-1-2013]; Adobe; Nokia; Samsung (GRO); Sony; US National Science Foundation (NSF); Berkeley Fellowship	ONR(Office of Naval Research); Adobe; Nokia(Nokia Corporation); Samsung (GRO)(Samsung); Sony; US National Science Foundation (NSF)(National Science Foundation (NSF)); Berkeley Fellowship	The authors acknowledge support from ONR grants N00014-09-1-0741, N00014-14-1-0332, and N00014-15-1-2013, funding from Adobe, Nokia and Samsung (GRO), support from Sony to the UC San Diego Center for Visual Computing, the US National Science Foundation (NSF) Fellowship to Michael Tao, and a Berkeley Fellowship to Ting-Chun Wang. They would also like to thank Stefan Heber for running results for his paper.	Artusi A, 2011, COMPUT GRAPH FORUM, V30, P2208, DOI 10.1111/j.1467-8659.2011.01971.x; Bajcsy R, 1996, INT J COMPUT VISION, V17, P241, DOI 10.1007/BF00128233; Chen C, 2014, PROC CVPR IEEE, P1518, DOI 10.1109/CVPR.2014.197; Finlayson GD, 2001, INT J COMPUT VISION, V42, P127, DOI 10.1023/A:1011120214885; Goldluecke B, 2013, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2013.134; Gortler S.J., 1996, ACM T GRAPHIC, V23, P43, DOI DOI 10.1145/237170.237200; Heber Stefan, 2014, Computer Vision - ECCV 2014. 13th European Conference. Proceedings: LNCS 8694, P751, DOI 10.1007/978-3-319-10599-4_48; Hirschmuller H, 2002, INT J COMPUT VISION, V47, P229, DOI 10.1023/A:1014554110407; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Janoch A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1168, DOI 10.1109/ICCVW.2011.6130382; Jin HL, 2003, PROC CVPR IEEE, P171; Kim C., 2013, P SIGGRAPH, P73; Kim H, 2013, PROC CVPR IEEE, P1460, DOI 10.1109/CVPR.2013.192; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Lin S, 2002, LECT NOTES COMPUT SC, V2352, P210; Lucas B. D., 1981, IJCAI, P121, DOI DOI 10.5555/1623264.1623280; Mallick SP, 2006, LECT NOTES COMPUT SC, V3951, P550; Mallick SP, 2005, PROC CVPR IEEE, P619; Min DB, 2013, IEEE T PATTERN ANAL, V35, P2539, DOI 10.1109/TPAMI.2013.15; Ng R., 2005, 200502 STANF U COMP; Nishino K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P599, DOI 10.1109/ICCV.2001.937573; Park JB, 2003, P SOC PHOTO-OPT INS, V5267, P163, DOI 10.1117/12.519400; PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940; Perez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269; Pharr M., 2004, PHYS BASED RENDERING; Sabater N., 2014, P ECCV WORKSH LIGHT, P548; SATO Y, 1994, J OPT SOC AM A, V11, P2990, DOI 10.1364/JOSAA.11.002990; Seitz SM, 1997, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.1997.609462; Shafer S. A., 1985, COLOR RES APPL; Tan P., 2006, P IEEE COMP SOC C CO, P1855; Tan RT, 2005, IEEE T PATTERN ANAL, V27, P178, DOI 10.1109/TPAMI.2005.36; Tan RT, 2004, J OPT SOC AM A, V21, P321, DOI 10.1364/JOSAA.21.000321; Tao M., 2014, EUR C COMP VIS, P533; Tao M, 2012, COMPUT GRAPH FORUM, V31, P345, DOI 10.1111/j.1467-8659.2012.03013.x; Tao MW, 2013, IEEE I CONF COMP VIS, P673, DOI 10.1109/ICCV.2013.89; Wanner S, 2014, IEEE T PATTERN ANAL, V36, P606, DOI 10.1109/TPAMI.2013.147; Wanner S, 2013, LECT NOTES COMPUT SC, V8142, P1, DOI 10.1007/978-3-642-40602-7_1; Wanner S, 2012, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2012.6247656; Watanabe M, 1998, INT J COMPUT VISION, V27, P203, DOI 10.1023/A:1007905828438; Xiong Y., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P68, DOI 10.1109/CVPR.1993.340977; Yang QX, 2010, LECT NOTES COMPUT SC, V6314, P87, DOI 10.1007/978-3-642-15561-1_7; Yoon KJ, 2006, IEEE IMAGE PROC, P973, DOI 10.1109/ICIP.2006.312650; Yu Jingyi, 2004, INT J IMAGE GRAPHICS, V4, P605	43	42	43	0	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2016	38	6					1155	1169		10.1109/TPAMI.2015.2477811	http://dx.doi.org/10.1109/TPAMI.2015.2477811			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DL4LU	26372203	hybrid, Green Submitted			2022-12-18	WOS:000375609000009
J	Kwon, J; Lee, KM				Kwon, Junseok; Lee, Kyoung Mu			Tracking by Sampling and Integrating Multiple Trackers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object tracking; abrupt motion; severe appearance change; interacting Markov Chain Monte Carlo; visual tracker sampler; visual tracking decomposition	VISUAL TRACKING; ROBUST; MCMC; MODELS	We propose the visual tracker sampler, a novel tracking algorithm that can work robustly in challenging scenarios, where several kinds of appearance and motion changes of an object can occur simultaneously. The proposed tracking algorithm accurately tracks a target by searching for appropriate trackers in each frame. Since the real-world tracking environment varies severely over time, the trackers should be adapted or newly constructed depending on the current situation, so that each specific tracker takes charge of a certain change in the object. To do this, our method obtains several samples of not only the states of the target but also the trackers themselves during the sampling process. The trackers are efficiently sampled using the Markov Chain Monte Carlo (MCMC) method from the predefined tracker space by proposing new appearance models, motion models, state representation types, and observation types, which are the important ingredients of visual trackers. All trackers are then integrated into one compound tracker through an Interacting MCMC (IMCMC) method, in which the trackers interactively communicate with one another while running in parallel. By exchanging information with others, each tracker further improves its performance, thus increasing overall tracking performance. Experimental results show that our method tracks the object accurately and reliably in realistic videos, where appearance and motion drastically change over time, and outperforms even state-of-the-art tracking methods.	[Kwon, Junseok; Lee, Kyoung Mu] Seoul Natl Univ, Dept Elect Engn & Comp Sci, Automat & Syst Res Inst, Seoul 151744, South Korea	Seoul National University (SNU)	Kwon, J (corresponding author), Seoul Natl Univ, Dept Elect Engn & Comp Sci, Automat & Syst Res Inst, 1 Ganak Ro, Seoul 151744, South Korea.	s98parad@gmail.com; kyoungmu@snu.ac.kr	Lee, Kyoung Mu/AAC-4063-2020	Lee, Kyoung Mu/0000-0001-7210-1036				Adam A., 2006, P IEEE C COMP VIS PA; Babenko B., 2009, P IEEE C COMP VIS PA; Badrinarayanan V., 2007, P IEEE 11 INT C COMP; Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205; Comaniciu D., 2000, P IEEE C COMP VIS PA; Corander J, 2008, DATA MIN KNOWL DISC, V17, P431, DOI 10.1007/s10618-008-0099-9; Corander J, 2006, STAT COMPUT, V16, P355, DOI 10.1007/s11222-006-9391-y; d'Aspremont A, 2007, SIAM REV, V49, P434, DOI 10.1137/050645506; Dinh T.B., 2011, P IEEE C COMP VIS PA; Du W., 2008, P 10 EUR C COMP VIS; GOOD IJ, 1952, J ROY STAT SOC B, V14, P107; Grabner H, 2008, P 10 EUR C COMP VIS; Han B., 2007, P IEEE 11 INT C COMP; Han B, 2005, P 10 IEEE INT C COMP; Isard M., 1998, P 5 EUR C COMP VIS E; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Kalal Z., 2010, P IEEE C COMP VIS PA; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; KOVESI P, 1999, J COMPUTER VISION RE, V1; Kwon J., 2008, P 10 EUR C COMP VIS; Kwon J., 2010, P IEEE C COMP VIS PA; Kwon J., 2011, P IEEE INT C COMP VI; Leibe B, 2008, IEEE T PATTERN ANAL, V30, P1683, DOI 10.1109/TPAMI.2008.170; Leichter I, 2006, INT J COMPUT VISION, V67, P343, DOI 10.1007/s11263-006-5568-2; Li Q., 2012, P AS C COMP VIS ACCV; Li Y., 2007, P IEEE C COMP VIS PA; Ling H., 2006, P IEEE C COMP VIS PA; Mei X., 2009, P 12 IEEE INT C COMP; Perez P, 2002, P 7 EUR C COMP VIS E; Raftery AE, 2003, J AM STAT ASSOC, V98, P931, DOI 10.1198/016214503000000891; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Santner J., 2010, P IEEE C COMP VIS PA; Siebel N.T., 2002, P 7 EUR C COMP VIS E; Smith K, 2005, P IEEE C COMP VIS PA; Stalder S., 2010, P 11 EUR C COMP VIS; Stenger B., 2009, P IEEE C COMP VIS PA; Sullivan J, 2001, INT J COMPUT VISION, V44, P111, DOI 10.1023/A:1011818912717; TOYAMA K, 2000, P 4 AS C COMP VIS AC; Wang FL, 2010, AEU-INT J ELECTRON C, V64, P614, DOI 10.1016/j.aeue.2009.04.004; Yang M, 2005, P IEEE C COMP VIS PA; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Zhang B, 1999, HEWLETT PACKARD LABS; ZHAO T, 2004, P IEEE C COMP VIS PA; Zhong B., 2010, P IEEE C COMP VIS PA	45	42	47	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2014	36	7					1428	1441		10.1109/TPAMI.2013.213	http://dx.doi.org/10.1109/TPAMI.2013.213			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AK1WS	26353313				2022-12-18	WOS:000338209900011
J	Kwon, J; Lee, HS; Park, FC; Lee, KM				Kwon, Junghyun; Lee, Hee Seok; Park, Frank C.; Lee, Kyoung Mu			A Geometric Particle Filter for Template-Based Visual Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual tracking; object template; particle filtering; Lie group; special linear group; affine group; Gaussian importance function	OBJECT TRACKING; MUTUAL-INFORMATION; MODELS; POSE	Existing approaches to template-based visual tracking, in which the objective is to continuously estimate the spatial transformation parameters of an object template over video frames, have primarily been based on deterministic optimization, which as is well-known can result in convergence to local optima. To overcome this limitation of the deterministic optimization approach, in this paper we present a novel particle filtering approach to template-based visual tracking. We formulate the problem as a particle filtering problem on matrix Lie groups, specifically the three-dimensional Special Linear group SL(3) and the two-dimensional affine group Aff(2). Computational performance and robustness are enhanced through a number of features: (i) Gaussian importance functions on the groups are iteratively constructed via local linearization; (ii) the inverse formulation of the Jacobian calculation is used; (iii) template resizing is performed; and (iv) parent-child particles are developed and used. Extensive experimental results using challenging video sequences demonstrate the enhanced performance and robustness of our particle filtering-based approach to template-based visual tracking. We also show that our approach outperforms several state-of-the-art template-based visual tracking methods via experiments using the publicly available benchmark data set.	[Kwon, Junghyun] TeleSecur Sci Inc, Las Vegas, NV 89128 USA; [Lee, Hee Seok; Lee, Kyoung Mu] Seoul Natl Univ, Automat Syst Res Inst, Dept Elect Engn & Comp Sci, Seoul 151744, South Korea; [Park, Frank C.] Seoul Natl Univ, Sch Mech & Aerosp Engn, Seoul 151744, South Korea	Seoul National University (SNU); Seoul National University (SNU)	Kwon, J (corresponding author), TeleSecur Sci Inc, 7391 Prairie Falcon Rd,Suite 150-B, Las Vegas, NV 89128 USA.	junghyunkwon@gmail.com; ultra21@snu.ac.kr; fcp@snu.ac.kr; kyoungmu@snu.ac.kr	Lee, Kyoung Mu/AAC-4063-2020	Lee, Kyoung Mu/0000-0001-7210-1036	AIM; BMRR; SNU-MAE BK21+; SNU-IAMD; Forensic Research Program of the National Forensic Service (NFS), Ministry of Security and Public Administration, Korea [NFS-NG-2013-11]	AIM; BMRR; SNU-MAE BK21+; SNU-IAMD; Forensic Research Program of the National Forensic Service (NFS), Ministry of Security and Public Administration, Korea	F.C. Park was supported in part by grants from AIM, BMRR, SNU-MAE BK21+, and SNU-IAMD. K. M. Lee was supported by the Forensic Research Program of the National Forensic Service (NFS), Ministry of Security and Public Administration, Korea (NFS-NG-2013-11).	Arnaud E, 2007, INT J COMPUT VISION, V74, P75, DOI 10.1007/s11263-006-0003-2; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Bao C. L., 2012, P IEEE C COMP VIS PA; Bar-Shalom Y., 2002, ESTIMATION APPL TRAC; BAY H, 2006, P 9 EUR C COMP VIS E; Begelfor E, 2005, IEEE T PATTERN ANAL, V27, P1666, DOI 10.1109/TPAMI.2005.200; Benhimane S, 2007, INT J ROBOT RES, V26, P661, DOI 10.1177/0278364907080252; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; Bolic M., 2003, P INT C AC SPEECH SI; Brooks R, 2010, INT J COMPUT VISION, V87, P191, DOI 10.1007/s11263-009-0263-8; Chiuso A, 2000, IEEE DECIS CONTR P, P304, DOI 10.1109/CDC.2000.912777; Datta A., 2006, CMURITR0611; Dellaert F, 1999, P IEEE INT C COMP VI; Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038; Doucet A., 2001, SEQUENTIAL MONTE CAR; Dowson N, 2008, IEEE T PATTERN ANAL, V30, P180, DOI 10.1109/TPAMI.2007.70757; Grenander U., 1963, PROBABILITIES ALGEBR; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; Hall B, 2004, LIE ALGEBRAS REPRESE; Hauberg S, 2013, J MATH IMAGING VIS, V46, P103, DOI 10.1007/s10851-012-0372-9; Hinterstoisser S., 2009, P IEEE C COMP VIS PA; Holzer S., 2010, P IEEE C COMP VIS PA; Hu WM, 2012, IEEE T PATTERN ANAL, V34, P2420, DOI 10.1109/TPAMI.2012.42; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Julier SJ, 2004, P IEEE, V92, P401, DOI 10.1109/JPROC.2003.823141; Jurie F, 2002, IEEE T PATTERN ANAL, V24, P996, DOI 10.1109/TPAMI.2002.1017625; Jurie F., 2002, P 13 BRIT MACH VIS C; Kwon J., 2010, P IEEE C COMP VIS PA; Kwon J., 2009, P IEEE C COMP VIS PA; Kwon J, 2007, ROBOTICA, V25, P725, DOI 10.1017/S0263574707003529; Kwon J, 2010, INT J ROBOT RES, V29, P198, DOI 10.1177/0278364909345167; Lee KC, 2005, COMPUT VIS IMAGE UND, V99, P303, DOI 10.1016/j.cviu.2005.02.002; Li M, 2012, IEEE T IMAGE PROCESS, V21, P1298, DOI 10.1109/TIP.2011.2169970; Li PH, 2003, IMAGE VISION COMPUT, V21, P111, DOI 10.1016/S0262-8856(02)00133-6; Lieberknecht S., 2009, P IEEE 8 INT S MIX A; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas B. D., 1981, INT JOINT C ART INT, P674, DOI DOI 10.5555/1623264.1623280; Mahony R, 2002, J GLOBAL OPTIM, V23, P309, DOI 10.1023/A:1016586831090; Malis E., ESM SOFTWARE DEV KIT; Ozuysal M., 2007, P IEEE C COMP VIS PA; Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758; Pennec X, 2006, J MATH IMAGING VIS, V25, P127, DOI 10.1007/s10851-006-6228-4; Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867; Ponsa D, 2009, PATTERN RECOGN, V42, P2372, DOI 10.1016/j.patcog.2009.04.007; Prince SJD, 2002, IEEE COMPUT GRAPH, V22, P39, DOI 10.1109/MCG.2002.1046627; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; RUI Y, 2001, P IEEE C COMP VIS PA; Saha S, 2009, STAT COMPUT, V19, P203, DOI 10.1007/s11222-008-9084-9; Shen C., 2005, P 17 AUSTR JOINT C A, P180; Silveira G, 2008, IEEE T ROBOT, V24, P969, DOI 10.1109/TRO.2008.2004829; Silveira G, 2010, INT J COMPUT VISION, V89, P84, DOI 10.1007/s11263-010-0324-z; Srivastava A, 2002, J STAT PLAN INFER, V103, P15, DOI 10.1016/S0378-3758(01)00195-1; Srivastava A, 2000, PROC SPIE, V4052, P160, DOI 10.1117/12.395067; Subbarao R, 2009, INT J COMPUT VISION, V84, P1, DOI 10.1007/s11263-008-0195-8; Sun ZH, 2010, INT J COMPUT VISION, V88, P461, DOI 10.1007/s11263-010-0316-z; Taylor C J, 1994, TECHNICAL REPORT; Tuzel O., 2008, P IEEE C COMP VIS PA; Vercauteren T., 2008, P C INF MED IM, P495; Wang HZ, 2007, IEEE T PATTERN ANAL, V29, P1661, DOI [10.1109/TPAMI.2007.1112, 10.1109/TPAMl.2007.1112]; Wang Y., 2009, P IEEE INT C IM PROC; XAVIER J, 2006, P IEEE INT C AC SPEE; Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152; Zimmermann K, 2009, IEEE T PATTERN ANAL, V31, P677, DOI 10.1109/TPAMI.2008.119	65	42	44	0	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2014	36	4					625	643		10.1109/TPAMI.2013.170	http://dx.doi.org/10.1109/TPAMI.2013.170			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AE6MX	26353190				2022-12-18	WOS:000334109000001
J	Chandraker, M; Bai, JM; Ramamoorthi, R				Chandraker, Manmohan; Bai, Jiamin; Ramamoorthi, Ravi			On Differential Photometric Reconstruction for Unknown, Isotropic BRDFs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Surface reconstruction; general BRDF; photometric invariants; differential theory	SHAPE; STEREO	This paper presents a comprehensive theory of photometric surface reconstruction from image derivatives in the presence of a general, unknown isotropic BRDF. We derive precise topological classes up to which the surface may be determined and specify exact priors for a full geometric reconstruction. These results are the culmination of a series of fundamental observations. First, we exploit the linearity of chain rule differentiation to discover photometric invariants that relate image derivatives to the surface geometry, regardless of the form of isotropic BRDF. For the problem of shape-from-shading, we show that a reconstruction may be performed up to isocontours of constant magnitude of the gradient. For the problem of photometric stereo, we show that just two measurements of spatial and temporal image derivatives, from unknown light directions on a circle, suffice to recover surface information from the photometric invariant. Surprisingly, the form of the invariant bears a striking resemblance to optical flow; however, it does not suffer from the aperture problem. This photometric flow is shown to determine the surface up to isocontours of constant magnitude of the surface gradient, as well as isocontours of constant depth. Further, we prove that specification of the surface normal at a single point completely determines the surface depth from these isocontours. In addition, we propose practical algorithms that require additional initial or boundary information, but recover depth from lower order derivatives. Our theoretical results are illustrated with several examples on synthetic and real data.	[Chandraker, Manmohan] NEC Labs Amer Inc, Cupertino, CA 95014 USA; [Bai, Jiamin; Ramamoorthi, Ravi] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA	NEC Corporation; University of California System; University of California Berkeley	Chandraker, M (corresponding author), NEC Labs Amer Inc, 10080 North Wolfe Rd,Suite SW3-350, Cupertino, CA 95014 USA.	manu@sv.nec-labs.com; bjiamin@eecs.berkeley.edu; ravir@cs.berkeley.edu	Chandraker, Manmohan/AAU-4762-2021		ONR PECASE [N00014-09-1-0741]; National Science Scholarship from the A*STAR Graduate Academy of Singapore; Intel; Adobe; NVIDIA; Pixar	ONR PECASE(Office of Naval Research); National Science Scholarship from the A*STAR Graduate Academy of Singapore; Intel(Intel Corporation); Adobe; NVIDIA; Pixar	This work was funded by ONR PECASE grant N00014-09-1-0741, a National Science Scholarship from the A*STAR Graduate Academy of Singapore, and generous support from Intel, Adobe, NVIDIA, and Pixar. The authors gratefully acknowledge the resources provided by Professor Marc Levoy and help from Andrew Adams toward data acquisition using the Stanford Spherical Gantry. They thank Milos Hasan for the bunny data, Neil Alldrin for the code from [ 1], Professors Todd Zickler, Steve Marschner, and Szymon Rusinkiewicz for insightful discussions, and the anonymous reviewers of [4] for helpful comments.	Alldrin N., 2008, P IEEE C COMP VIS PA; ALLDRIN N, 2007, P IEEE INT C COMP VI; Barsky S, 2003, IEEE T PATTERN ANAL, V25, P1239, DOI 10.1109/TPAMI.2003.1233898; Brooks M. J., 1985, SHAPE SOURCE SHADING; Chandraker M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2505, DOI 10.1109/CVPR.2011.5995603; Clark J. J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P29, DOI 10.1109/CVPR.1992.223231; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; Grant M., 2014, CVX MATLAB SOFTWARE; Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158; Higo T, 2010, PROC CVPR IEEE, P1157, DOI 10.1109/CVPR.2010.5540084; Holroyd M., 2008, P SIGGR AS; Horn B., 1986, ROBOT VISION, P1; Lee KM, 1997, COMPUT VIS IMAGE UND, V67, P143, DOI 10.1006/cviu.1997.0522; Lucas B. D., 1981, IJCAI, P121, DOI DOI 10.5555/1623264.1623280; Prados E, 2005, PROC CVPR IEEE, P870; Ramamoorthi R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1186644.1186646; Sato I, 2007, IEEE I CONF COMP VIS, P1493; SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047; Tan P., 2009, P IEEE C COMP VIS PA; Tan P., 2007, P IEEE C COMP VIS PA; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; Zickler T., 2003, IJCV, V49, P1215	23	42	43	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2013	35	12					2941	2955		10.1109/TPAMI.2012.217	http://dx.doi.org/10.1109/TPAMI.2012.217			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	245YV	24136432				2022-12-18	WOS:000326502200011
J	Mao, Q; Tsang, IWH				Mao, Qi; Tsang, Ivor Wai-Hung			A Feature Selection Method for Multivariate Performance Measures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature selection; performance measure; multiple kernel learning; multi-instance learning; structural SVMs	OPTIMIZATION	Feature selection with specific multivariate performance measures is the key to the success of many applications such as image retrieval and text classification. The existing feature selection methods are usually designed for classification error. In this paper, we propose a generalized sparse regularizer. Based on the proposed regularizer, we present a unified feature selection framework for general loss functions. In particular, we study the novel feature selection paradigm by optimizing multivariate performance measures. The resultant formulation is a challenging problem for high-dimensional data. Hence, a two-layer cutting plane algorithm is proposed to solve this problem, and the convergence is presented. In addition, we adapt the proposed method to optimize multivariate measures for multiple-instance learning problems. The analyses by comparing with the state-of-the-art feature selection methods show that the proposed method is superior to others. Extensive experiments on large-scale and high-dimensional real-world datasets show that the proposed method outperforms l(1)-SVM and SVM-RFE when choosing a small subset of features, and achieves significantly improved performances over SVMperf in terms of F-1-score.	[Mao, Qi; Tsang, Ivor Wai-Hung] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Mao, Q (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Blk N4, B1A-02,Nanyang Ave, Singapore 639798, Singapore.	Qmao1@ntu.edu.sg; IvorTsang@ntu.edu.sg	Tsang, Ivor/E-8653-2011	Tsang, Ivor/0000-0003-2211-8176; Tsang, Ivor/0000-0001-8095-4637	Singapore A*star [SERC 112 280 4005]	Singapore A*star(Agency for Science Technology & Research (A*STAR))	This work was supported by Singapore A*star under Grant SERC 112 280 4005.	Andrews S., 2003, ADV NEURAL INF PROCE; Bach F.R., 2004, P INT C MACH LEARN; Bach F, 2012, FOUND TRENDS MACH LE, V4, P1, DOI 10.1561/2200000015; Borwein J., 2006, CONVEX ANAL NONLINEA, DOI [10.1007/978-0-387-31256-9, DOI 10.1007/978-0-387-31256-9]; Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Fung GM, 2004, COMPUT OPTIM APPL, V28, P185, DOI 10.1023/B:COAP.0000026884.66338.df; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hiriart-Urruty J.-B., 1993, CONVEX ANAL MINIMIZA, V306, pxviii+346, DOI 10.1007/978-3-662-06409-2; Joachims T, 2006, P ACM SIGKDD INT C K; Joachims T., 2005, P INT C MACH LEARN; Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]; KELLEY JE, 1960, J SOC IND APPL MATH, V8, P703, DOI 10.1137/0108053; Lal TN, 2006, STUD FUZZ SOFT COMP, V207, P137; Le Q. V., 2007, J MACHINE LEARNING R, V1, P1; Lin D., 2010, TECHNICAL REPORT; Liu ZQ, 2007, STAT APPL GENET MOL, V6, DOI 10.2202/1544-6115.1248; Mao Q., 2011, P INT C DAT MIN; Maron O., 1998, P INT C MACH LEARN; Musicant David R., 2003, FLAIRS C; Mutapcic A, 2009, OPTIM METHOD SOFTW, V24, P381, DOI 10.1080/10556780802712889; Ng A. Y., 2004, P INT C MACH LEARN; Rakotomamonjy A., 2008, J MACHINE LEARNING R, V3, P1439; Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531; Tan M., 2010, P INT C MACH LEARN; Teo CH, 2010, J MACH LEARN RES, V11, P311; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Valizadengan H., 2009, P ADV NEUR INF PROC; Weston J., 2003, Journal of Machine Learning Research, V3, P1439, DOI 10.1162/153244303322753751; Xu Z., 2009, P INT C MACH LEARN; Xu Z., 2008, P ADV NEUR INF PROC; Yuan GX, 2010, J MACH LEARN RES, V11, P3183; Yue Y., 2007, P ANN INT ACM SIGIR; Zhang Q., 2002, P INT C MACH LEARN; Zhang T, 2010, J MACH LEARN RES, V11, P1081; Zhang X., 2011, P UNC ART INT C; Zhou Z.-H., 2007, P ADV NEUR INF PROC; Zhu J., 2003, P ADV NEUR INF PROC; Zien A., 2007, P INT C MACH LEARN	39	42	44	1	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2013	35	9					2051	2063		10.1109/TPAMI.2012.266	http://dx.doi.org/10.1109/TPAMI.2012.266			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	186GB	23868769	Green Submitted			2022-12-18	WOS:000322029000001
J	Hartley, R; Li, HD				Hartley, Richard; Li, Hongdong			An Efficient Hidden Variable Approach to Minimal-Case Camera Motion Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Camera calibration; camera motion estimation; epipolar geometry; minimal solver; polynomial root finding	RELATIVE POSE	In this paper, we present an efficient new approach for solving two-view minimal-case problems in camera motion estimation, most notably the so-called five-point relative orientation problem and the six-point focal-length problem. Our approach is based on the hidden variable technique used in solving multivariate polynomial systems. The resulting algorithm is conceptually simple, which involves a relaxation which replaces monomials in all but one of the variables to reduce the problem to the solution of sets of linear equations, as well as solving a polynomial eigenvalue problem (polyeig). To efficiently find the polynomial eigenvalues, we make novel use of several numeric techniques, which include quotient-free Gaussian elimination, Levinson-Durbin iteration, and also a dedicated root-polishing procedure. We have tested the approach on different minimal cases and extensions, with satisfactory results obtained. Both the executables and source codes of the proposed algorithms are made freely downloadable.	[Hartley, Richard; Li, Hongdong] Australian Natl Univ, Coll Engn & Comp Sci, Res Sch Engn RSISE, Canberra, ACT 0200, Australia	Australian National University	Hartley, R (corresponding author), Australian Natl Univ, Coll Engn & Comp Sci, Res Sch Engn RSISE, Bldg 115, Canberra, ACT 0200, Australia.	Richard.Hartley@anu.edu.au; hongdong.LI@anu.edu.au		Hartley, Richard/0000-0002-5005-0191	Australian Research Council-ARC; Australian Government; Australian Research Council through the ICT Centre of Excellence Program	Australian Research Council-ARC(Australian Research Council); Australian Government(Australian GovernmentCGIAR); Australian Research Council through the ICT Centre of Excellence Program(Australian Research Council)	The author wish to thank the editors and anonymous reviewers for invaluable comments and thank David Nister and Fredrik Kahl for invaluable discussions related to this work. The work is partially funded by Australian Research Council-ARC Grants. NICTA is funded by the Australian Government and the Australian Research Council through the ICT Centre of Excellence Program.	BAREISS EH, 1968, MATH COMPUT, V22, P565; Cox D. A., 2005, USING ALGEBRAIC GEOM, V185; CYBENKO G, 1980, SIAM J SCI STAT COMP, V1, P303, DOI 10.1137/0901021; Faugeras O.D., 1989, P WORKSH VIS MOT; Fitzgibbon A. W., 2001, P IEEE C COMP VIS PA, V1; Hartley R., 2004, ROBOTICA; HARTLEY RI, 1992, LECT NOTES COMPUT SC, V588, P579; Helmke U, 2007, INT J COMPUT VISION, V74, P117, DOI 10.1007/s11263-006-0005-0; Kukelova Z., 2008, P BRIT MACH VIS C; Li HD, 2006, INT C PATT RECOG, P630; Li HD, 2006, LECT NOTES COMPUT SC, V3954, P200; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; Nister D., 2007, P IEEE C COMP VIS PA; Nister D., 2003, P IEEE C COMP VIS PA; Stewenius H, 2005, PROC CVPR IEEE, P789; Stewenius H., 2006, P IEEE C COMP VIS PA; Stewenius H, 2006, ISPRS J PHOTOGRAMM, V60, P284, DOI 10.1016/j.isprsjprs.2006.03.005	17	42	45	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2012	34	12					2303	2314		10.1109/TPAMI.2012.43	http://dx.doi.org/10.1109/TPAMI.2012.43			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	021VO	22331858	Green Published			2022-12-18	WOS:000309913700002
J	Eriksson, A; van den Hengel, A				Eriksson, Anders; van den Hengel, Anton			Efficient Computation of Robust Weighted Low-Rank Matrix Approximations Using the L-1 Norm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Low-rank matrix approximation; L-1-minimization	PRINCIPAL COMPONENT ANALYSIS; MISSING DATA; FACTORIZATION; ALGORITHM; MODEL	The calculation of a low-rank approximation to a matrix is fundamental to many algorithms in computer vision and other fields. One of the primary tools used for calculating such low-rank approximations is the Singular Value Decomposition, but this method is not applicable in the case where there are outliers or missing elements in the data. Unfortunately, this is often the case in practice. We present a method for low-rank matrix approximation which is a generalization of the Wiberg algorithm. Our method calculates the rank-constrained factorization, which minimizes the L-1 norm and does so in the presence of missing data. This is achieved by exploiting the differentiability of linear programs, and results in an algorithm can be efficiently implemented using existing optimization software. We show the results of experiments on synthetic and real data.	[Eriksson, Anders; van den Hengel, Anton] Univ Adelaide, Dept Comp Sci, Adelaide, SA 5005, Australia	University of Adelaide	Eriksson, A (corresponding author), Univ Adelaide, Dept Comp Sci, North Terrace, Adelaide, SA 5005, Australia.	anders.eriksson@adelaide.edu.au; anton.vandenhengel@adelaide.edu.au		van den Hengel, Anton/0000-0003-3027-8364; Eriksson, Anders/0000-0003-2652-7110	Australian Research Council [DP0988439]	Australian Research Council(Australian Research Council)	The authors would like to thank Carl Olsson and Fredrik Kahl of Lund University for the use of their visualization tool. This research was supported under the Australian Research Council's Discovery Projects funding scheme (project DP0988439).	Aanaes H, 2002, IEEE T PATTERN ANAL, V24, P1215, DOI 10.1109/TPAMI.2002.1033213; Alvira M., 2001, 2001004 AI MIT CTR B; BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2; BJORCK A, 1995, NUMERICAL METHODS LE; Black M.J., 1998, INT J COMPUT VISION, V26, P329; Buchanan AM, 2005, PROC CVPR IEEE, P316; Candes E., 2009, COMPUTING RES REPOSI; Chandraker M., 2008, P IEEE C COMP VIS PA; Croux Christophe, 1998, COMPSTAT, P245; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; Eriksson A., 2010, P IEEE C COMP VIS PA; FLETCHER R, 1982, MATH PROGRAM STUD, V17, P67; Fletcher R, 1987, PRACTICAL METHODS OP, V1; Hayakawa H., 1992, J OPT SOC AM A, V11, P3079; Ke Q., 2001, P IEEE CS C COMP VIS; Ke QF, 2005, PROC CVPR IEEE, P739; OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687; Okatani T, 2007, INT J COMPUT VISION, V72, P329, DOI 10.1007/s11263-006-9785-5; Olsson C, 2010, J MATH IMAGING VIS, V38, P35, DOI 10.1007/s10851-010-0207-5; SHUM HY, 1995, IEEE T PATTERN ANAL, V17, P854, DOI 10.1109/34.406651; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; TORRESANI L, 2003, P NEUR INF PROC SYST; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Watson GA, 1980, APPROXIMATION THEORY; Wiberg T, 1976, P 2 S COMP STAT, P229; YUAN Y, 1985, MATH PROGRAM, V31, P269, DOI 10.1007/BF02591949; Yuan Y., 1983, SOME PROPERTIES TRUS	27	42	43	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2012	34	9					1681	1690		10.1109/TPAMI.2012.116	http://dx.doi.org/10.1109/TPAMI.2012.116			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	974DD	22641698				2022-12-18	WOS:000306409100003
J	Davenport, MA; Baraniuk, RG; Scott, CD				Davenport, Mark A.; Baraniuk, Richard G.; Scott, Clayton D.			Tuning Support Vector Machines for Minimax and Neyman-Pearson Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Minimax classification; Neyman-Pearson classification; support vector machine; error estimation; parameter selection	CLASSIFIERS	This paper studies the training of support vector machine (SVM) classifiers with respect to the minimax and Neyman-Pearson criteria. In principle, these criteria can be optimized in a straightforward way using a cost-sensitive SVM. In practice, however, because these criteria require especially accurate error estimation, standard techniques for tuning SVM parameters, such as cross-validation, can lead to poor classifier performance. To address this issue, we first prove that the usual cost-sensitive SVM, here called the 2C-SVM, is equivalent to another formulation called the 2 nu-SVM. We then exploit a characterization of the 2 nu-SVM parameter space to develop a simple yet powerful approach to error estimation based on smoothing. In an extensive experimental study, we demonstrate that smoothing significantly improves the accuracy of cross-validation error estimates, leading to dramatic performance gains. Furthermore, we propose coordinate descent strategies that offer significant gains in computational efficiency, with little to no loss in performance.	[Davenport, Mark A.] Stanford Univ, Dept Stat, Stanford, CA 94305 USA; [Baraniuk, Richard G.] Rice Univ, Dept Elect & Comp Engn, Houston, TX 77005 USA; [Scott, Clayton D.] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48105 USA	Stanford University; Rice University; University of Michigan System; University of Michigan	Davenport, MA (corresponding author), Stanford Univ, Dept Stat, 390 Serra Mall, Stanford, CA 94305 USA.	md@rice.edu; richb@rice.edu; cscott@eecs.umich.edu	Baraniuk, Richard/ABA-1743-2020		US National Science Foundation (NSF) [CCF-0431150]; Texas Instruments Leadership University; NSF Vertical Integration of Research and Education [0240068]	US National Science Foundation (NSF)(National Science Foundation (NSF)); Texas Instruments Leadership University; NSF Vertical Integration of Research and Education	The work of Mark A. Davenport and Richard G. Baraniuk was supported by US National Science Foundation (NSF) Grant CCF-0431150 and the Texas Instruments Leadership University Program. The work of Clayton D. Scott was partially supported by NSF Vertical Integration of Research and Education grant 0240068 while he was a postdoctoral fellow at Rice University (for more details, see www.eecs.umich.edu/cscott).	Bach FR, 2006, J MACH LEARN RES, V7, P1713; BENGIO S, 2005, P INT C MACH LEARN; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; CANNON A, 2002, 022951 LAUR LOS AL N; Chang CC, 2001, NEURAL COMPUT, V13, P2119, DOI 10.1162/089976601750399335; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chen PH, 2005, APPL STOCH MODEL BUS, V21, P111, DOI 10.1002/asmb.537; Chew HG, 2001, INT CONF ACOUST SPEE, P1269; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; DAVENPORT MA, 2007, P IEEE WORKSH STAT S; DAVENPORT MA, 2007, THESIS RICE U; DAVENPORT MA, 2006, P IEEE INT C AC SPEE; Demsar J, 2006, J MACH LEARN RES, V7, P1; Lin Y., 2000, 1016 U WISC DEP STAT; Osuna E., 1997, 1602 MIT ART INT LAB; Scharf L.L, 1991, STAT SIGNAL PROCESSI; Scholkopf B., 2002, LEARNING KERNELS; Scott C, 2005, IEEE T INFORM THEORY, V51, P3806, DOI 10.1109/TIT.2005.856955; Scott C, 2007, IEEE T INFORM THEORY, V53, P2852, DOI 10.1109/TIT.2007.901152; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Veropoulos K., 1999, P INT JOINT C ART IN	22	42	44	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2010	32	10					1888	1898		10.1109/TPAMI.2010.29	http://dx.doi.org/10.1109/TPAMI.2010.29			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	639US	20724764	Green Submitted			2022-12-18	WOS:000281000700013
J	Maver, J				Maver, Jasna			Self-Similarity and Points of Interest	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Interest point detector; self-similarity; visual attention; visual perception; linear predictors; the total sum of squares	SYMMETRY	In this work, we present a new approach to interest point detection. Different types of features in images are detected by using a common computational concept. The proposed approach considers the total variability of local regions. The total sum of squares computed on the intensity values of a local circular region is divided into three components: between-circumferences sum of squares, between-radii sum of squares, and the remainder. These three components normalized by the total sum of squares represent three new saliency measures, namely, radial, tangential, and residual. The saliency measures are computed for regions with different radii and scale spaces are built in this way. Local extrema in scale space of each of the saliency measures are located. They represent features with complementary image properties: blob-like features, corner-like features, and highly textured points. Results obtained on image sets of different object classes and image sets under different types of photometric and geometric transformations show high robustness of the method to intraclass variations as well as to different photometric transformations and moderate geometric transformations and compare favorably with the results obtained by the leading interest point detectors from the literature. The proposed approach gives a rich set of highly distinctive local regions that can be used for object recognition and image matching.	[Maver, Jasna] Fac Arts, Dept Lib & Informat Sci & Book Studies, Ljubljana 1000, Slovenia; [Maver, Jasna] Univ Ljubljana, Comp Vis Lab, Fac Comp & Informat Sci, Ljubljana 1000, Slovenia	University of Ljubljana	Maver, J (corresponding author), Fac Arts, Dept Lib & Informat Sci & Book Studies, Askerceva 2, Ljubljana 1000, Slovenia.	jasna.maver@ff.uni-lj.si			Research program Computer Vision [P2-0214]	Research program Computer Vision	The author would like to thank Richard I. Hartley, Jiri Matas, and Jan Sochman for reading the paper draft and giving valuable comments, and Michal Perdoch, Dusan Omercevic, and Luka Cehovin for help with software and experimental work. This research work has been supported by the Research program Computer Vision P2-0214 (RS).	BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; BRADY M, 1983, HUMAN MACHINE VISION; Chella A, 1999, LECT NOTES COMPUT SC, V1681, P264; Cornelius H, 2007, LECT NOTES COMPUT SC, V4522, P152; Cornelius H, 2006, INT C PATT RECOG, P292; Deng H., 2007, P IEEE C COMP VIS PA; Di Gesu V, 2001, SIGNAL PROCESS, V81, P265, DOI 10.1016/S0165-1684(00)00206-1; DIGESU V, 1995, 01195 DMA PAL U; DIGESU V, 1995, P 1 CCMA WORKSH VIS; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; GIBLIN PJ, 1985, AM MATH MON, V92, P689, DOI 10.2307/2323220; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; JOHANSSON B, 2000, P EUR C COMP VIS 1, P871; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; Kadir T., 2004, P 8 EUR C COMP VIS P, P345; KIMM C, 1997, COMMUN ACM, V18, P120; KOVESI P, 1999, VIDERE J COMPUTER VI, V1; KOVESI P, 1997, P 10 AUSTR JOINT C A, P185; LEE S, 2008, P IEEE C COMP VIS PA; Lin CC, 1996, PATTERN RECOGN, V29, P2079, DOI 10.1016/S0031-3203(96)00034-9; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Loy G, 2003, IEEE T PATTERN ANAL, V25, P959, DOI 10.1109/TPAMI.2003.1217601; Loy G, 2006, LECT NOTES COMPUT SC, V3952, P508; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; MIKOLAJCZYK K, 2002, P 7 EUR C COMP VIS; MINOR LG, 1981, IEEE T SYST MAN CYB, V11, P194, DOI 10.1109/TSMC.1981.4308652; MOROVEC H, 1980, CMURITR3; Palenichka RM, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P95, DOI 10.1109/ICIAP.2001.956991; REISFELD D, 1995, INT J COMPUT VISION, V14, P119, DOI 10.1007/BF01418978; RIKLINRAVIV T, 2006, P IEEE C COMP VIS PA, P1015; Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414; Schaffalitzky F, 2003, COMPUT VIS IMAGE UND, V92, P236, DOI 10.1016/j.cviu.2003.06.008; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Sela G, 1997, REAL-TIME IMAGING, V3, P173, DOI 10.1006/rtim.1996.0057; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710; Smithson M, 2000, STAT CONFIDENCE; Sun QB, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P130, DOI 10.1109/AFGR.1998.670937; Trajkovic M, 1998, IMAGE VISION COMPUT, V16, P75, DOI 10.1016/S0262-8856(97)00056-5; Tuytelaars T., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P412; TUYTELAARS T, 1999, P 3 INT C VIS INF SY, P493	43	42	42	1	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2010	32	7					1211	1226		10.1109/TPAMI.2009.105	http://dx.doi.org/10.1109/TPAMI.2009.105			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	595YC	20489225				2022-12-18	WOS:000277649100005
J	Castillo, CD; Jacobs, DW				Castillo, Carlos D.; Jacobs, David W.			Using Stereo Matching with General Epipolar Geometry for 2D Face Recognition across Pose	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; pose; stereo matching; epipolar geometry	ILLUMINATION; INVARIANT; 3D	Face recognition across pose is a problem of fundamental importance in computer vision. We propose to address this problem by using stereo matching to judge the similarity of two, 2D images of faces seen from different poses. Stereo matching allows for arbitrary, physically valid, continuous correspondences. We show that the stereo matching cost provides a very robust measure of similarity of faces that is insensitive to pose variations. To enable this, we show that, for conditions common in face recognition, the epipolar geometry of face images can be computed using either four or three feature points. We also provide a straightforward adaptation of a stereo matching algorithm to compute the similarity between faces. The proposed approach has been tested on the CMU PIE data set and demonstrates superior performance compared to existing methods in the presence of pose variation. It also shows robustness to lighting variation.	[Castillo, Carlos D.; Jacobs, David W.] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA	University System of Maryland; University of Maryland College Park	Castillo, CD (corresponding author), Univ Maryland, Dept Comp Sci, 4420 AV Williams Bldg, College Pk, MD 20742 USA.	carlos@cs.umd.edu; djacobs@cs.umd.edu	Castillo, Carlos/E-4752-2016	Castillo, Carlos/0000-0003-4544-0416; Castillo, Carlos/0000-0001-5308-4824	P. Horvitz (Apptis, Inc.); Honda Research Initiation; US Office of Naval Research [N00014-08-10638]	P. Horvitz (Apptis, Inc.); Honda Research Initiation; US Office of Naval Research(Office of Naval Research)	The authors gratefully acknowledge financial support from a fellowship from P. Horvitz (Apptis, Inc.), from the Honda Research Initiation Grant and from the US Office of Naval Research Under MURI Grant N00014-08-10638. They would like to thank Olga Veksler for her advice about stereo. They would like to thank Peter Belhumeur for his insights on the interactions between pose and illumination in face recognition.	Ashraf A.B., 2008, P IEEE INT C COMP VI; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Beymer D., 1995, AIM1536, P537; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005; Castillo C.D., 2007, P IEEE INT C COMP VI; Chai XJ, 2007, IEEE T IMAGE PROCESS, V16, P1716, DOI 10.1109/TIP.2007.899195; Cox IJ, 1996, COMPUT VIS IMAGE UND, V63, P542, DOI 10.1006/cviu.1996.0040; Criminisi A, 2007, INT J COMPUT VISION, V71, P89, DOI 10.1007/s11263-006-8525-1; DOMKE J, 2006, P 3 INT S 3D DAT PRO, P41; Domke Justin, 2006, P WORKSH DYN VIS, P232; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Gizatdinova Y, 2006, IEEE T PATTERN ANAL, V28, P135, DOI 10.1109/TPAMI.2006.10; Gross R, 2004, IEEE T PATTERN ANAL, V26, P449, DOI 10.1109/TPAMI.2004.1265861; GROSS R, 2003, P 4 INT C AUD VID BA; GROSS R, 2004, HDB FACE RECOGNITION; Hartley R., 2004, ROBOTICA; Hsieh CK, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P987; Huang G. B., 2008, P FAC REAL LIF IM WO; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucey S, 2008, INT J COMPUT VISION, V80, P58, DOI 10.1007/s11263-007-0119-z; Martinez AM, 2003, VISION RES, V43, P1047, DOI 10.1016/S0042-6989(03)00079-8; Romdhani S, 2002, LECT NOTES COMPUT SC, V2353, P3; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; TURK M, 1991, P IEEE C COMP VIS PA, P586, DOI DOI 10.1109/CVPR.1991.139758; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Viola P., 2002, INT J COMPUTER VISIO; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; 2009, LABELED FACES WILD W	30	42	44	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2009	31	12					2298	2304		10.1109/TPAMI.2009.123	http://dx.doi.org/10.1109/TPAMI.2009.123			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	511BY	19834149	Green Submitted			2022-12-18	WOS:000271140100016
J	Dahyot, R				Dahyot, Rozenn			Statistical Hough Transform	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hough transform; Radon transform; kernel probability density function; uncertainty; line detection	MEAN SHIFT; IMAGES	The Standard Hough Transform is a popular method in image processing and is traditionally estimated using histograms. Densities modeled with histograms in high dimensional space and/or with few observations, can be very sparse and highly demanding in memory. In this paper, we propose first to extend the formulation to continuous kernel estimates. Second, when dependencies in between variables are well taken into account, the estimated density is also robust to noise and insensitive to the choice of the origin of the spatial coordinates. Finally, our new statistical framework is unsupervised (all needed parameters are automatically estimated) and flexible (priors can easily be attached to the observations). We show experimentally that our new modeling encodes better the alignment content of images.	Trinity Coll Dublin, Sch Comp Sci & Stat, Dept Stat, Lloyd Inst, Dublin 2, Ireland	Trinity College Dublin	Dahyot, R (corresponding author), Trinity Coll Dublin, Sch Comp Sci & Stat, Dept Stat, Lloyd Inst, Room 128, Dublin 2, Ireland.	Rozenn.Dahyot@tcd.ie	Dahyot, Rozenn/AAN-4260-2020	Dahyot, Rozenn/0000-0003-0983-3052	Enterprise Ireland Innovation Partnership [IP-2006-412]; Research Google Award	Enterprise Ireland Innovation Partnership; Research Google Award(Google Incorporated)	This work has been supported by the Enterprise Ireland Innovation Partnership IP-2006-412 and a Research Google Award.	Aggarwal N, 2006, IEEE T IMAGE PROCESS, V15, P582, DOI 10.1109/TIP.2005.863021; Aguado AS, 2000, J MATH IMAGING VIS, V12, P25, DOI 10.1023/A:1008388322921; Ballester P., 1996, VISTAS ASTRON, V40, P479; Bandera A, 2006, PATTERN RECOGN LETT, V27, P578, DOI 10.1016/j.patrec.2005.09.023; BOBER M, 1994, IMAGE VISION COMPUT, V12, P661, DOI 10.1016/0262-8856(94)90041-8; Bonci A, 2005, IEEE T SYST MAN CY A, V35, P945, DOI 10.1109/TSMCA.2005.853481; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cooper GRJ, 2004, COMPUT GEOSCI-UK, V30, P101, DOI 10.1016/j.cageo.2003.08.006; Dahyot R, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P482; DAHYOT R, 2001, P IEEE INT C IM PROC; DAHYOT R, 2008, P IEEE INT C PATT RE; DAHYOT R, 2006, ADV METHODOLOGY STAT, V3, P21; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FREEMAN WT, 1992, THESIS MIT; Goldenshluger A, 2004, ANN STAT, V32, P1908, DOI 10.1214/009053604000000760; Goulermas JY, 1999, PATTERN ANAL APPL, V2, P239, DOI 10.1007/s100440050032; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; Huber P., 1981, ROBUST STAT; Ji Q, 2001, PATTERN RECOGN LETT, V22, P813, DOI 10.1016/S0167-8655(01)00026-5; LAI G, 2000, P IEEE INT S CIRC SY, V5, P37; Meer P, 2001, IEEE T PATTERN ANAL, V23, P1351, DOI 10.1109/34.977560; Princen J., 1992, Journal of Mathematical Imaging and Vision, V1, P153, DOI 10.1007/BF00122210; Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972; Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446; Sheather SJ, 2004, STAT SCI, V19, P588, DOI 10.1214/088342304000000297; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; Steele RM, 2005, PROC CVPR IEEE, P1063; STEPHENS RS, 1991, IMAGE VISION COMPUT, V9, P66, DOI 10.1016/0262-8856(91)90051-P; Walsh D, 2002, PATTERN RECOGN, V35, P1421, DOI 10.1016/S0031-3203(01)00114-5	30	42	52	2	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2009	31	8					1502	1509		10.1109/TPAMI.2008.288	http://dx.doi.org/10.1109/TPAMI.2008.288			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	458UN	19542582	Green Submitted, Green Accepted			2022-12-18	WOS:000267050600012
J	Chen, H; Bhanu, B				Chen, Hui; Bhanu, Bir			Efficient Recognition of Highly Similar 3D Objects in Range Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D ear indexing; 3D ear recognition; biometrics; ear databases; feature embedding; rank learning; local surface patch representation	REPRESENTATION; REGISTRATION	Most existing work in 3D object recognition in computer vision has been on recognizing dissimilar objects using a small database. For rapid indexing and recognition of highly similar objects, this paper proposes a novel method which combines the feature embedding for the fast retrieval of surface descriptors, novel similarity measures for correspondence, and a support vector machine-based learning technique for ranking the hypotheses. The local surface patch representation is used to find the correspondences between a model-test pair. Due to its high dimensionality, an embedding algorithm is used that maps the feature vectors to a low-dimensional space where distance relationships are preserved. By searching the nearest neighbors in low dimensions, the similarity between a model-test pair is computed using the novel features. The similarities for all model-test pairs are ranked using the learning algorithm to generate a short list of candidate models for verification. The verification is performed by aligning a model with the test object. The experimental results, on the University of Notre Dame data set (302 subjects with 604 images) and the University of California at Riverside data set (155 subjects with 902 images) which contain 3D human ears, are presented and compared with the geometric hashing technique to demonstrate the efficiency and effectiveness of the proposed approach.	[Chen, Hui] Motorola Biometr Business Unit, Anaheim, CA 92807 USA; [Bhanu, Bir] Univ Calif Riverside, Ctr Res Intelligent Syst, Riverside, CA 92521 USA	University of California System; University of California Riverside	Chen, H (corresponding author), Motorola Biometr Business Unit, 1250 N Tustin Ave, Anaheim, CA 92807 USA.	hui.chen002@gmail.com; bhanu@cris.ucr.edu		Bhanu, Bir/0000-0001-8971-6416				Athitsos V, 2004, PROC CVPR IEEE, P268; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bhanu B, 2003, IEEE T PATTERN ANAL, V25, P616, DOI 10.1109/TPAMI.2003.1195995; Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889; Chen H, 2004, INT C PATT RECOG, P136, DOI 10.1109/ICPR.2004.1334487; Chen H, 2007, IEEE T PATTERN ANAL, V29, P718, DOI 10.1109/TPAMI.2007.1005; Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186; Faloutsos C., 1995, P 1995 ACM SIGMOD IN, P163; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Hjaltason GR, 2003, IEEE T PATTERN ANAL, V25, P530, DOI 10.1109/TPAMI.2003.1195989; Joachims T., 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Matei B, 2006, IEEE T PATTERN ANAL, V28, P1111, DOI 10.1109/TPAMI.2006.148; Mokhtarian F, 2001, IMAGE VISION COMPUT, V19, P271, DOI 10.1016/S0262-8856(00)00076-7; Muller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701; STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785; Tan XJ, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P151, DOI 10.1109/AVSS.2003.1217915; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; WANG X, 2000, KNOWL INF SYST, V2, P161; Yan P, 2007, IEEE T PATTERN ANAL, V29, P1297, DOI 10.1109/TPAMI.2007.1067; Yi JH, 1998, COMPUT VIS IMAGE UND, V69, P87, DOI 10.1006/cviu.1997.0597; Young F.W., 1987, MULTIDIMENSIONAL SCA; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149	25	42	45	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2009	31	1					172	179		10.1109/TPAMI.2008.176	http://dx.doi.org/10.1109/TPAMI.2008.176			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	372GI	19029555				2022-12-18	WOS:000260889700015
J	Fujino, A; Ueda, N; Saito, K				Fujino, Akinori; Ueda, Naonori; Saito, Kazumi			Semisupervised learning for a hybrid generative/discriminative classifier based on the maximum entropy principle	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						generative model; maximum entropy principle; bias correction; unlabeled samples; text classification	TEXT CLASSIFICATION	This paper presents a method for designing semisupervised classifiers trained on labeled and unlabeled samples. We focus on a probabilistic semisupervised classifier design for multiclass and single-labeled classification problems and propose a hybrid approach that takes advantage of generative and discriminative approaches. In our approach, we first consider a generative model trained by using labeled samples and introduce a bias correction model, where these models belong to the same model family but have different parameters. Then, we construct a hybrid classifier by combining these models based on the maximum entropy principle. To enable us to apply our hybrid approach to text classification problems, we employed naive Bayes models as the generative and bias correction models. Our experimental results for four text data sets confirmed that the generalization ability of our hybrid classifier was much improved by using a large number of unlabeled samples for training when there were too few labeled samples to obtain good performance. We also confirmed that our hybrid approach significantly outperformed the generative and discriminative approaches when the performance of the generative and discriminative approaches was comparable. Moreover, we examined the performance of our hybrid classifier when the labeled and unlabeled data distributions were different.	[Fujino, Akinori; Ueda, Naonori] NTT Corp, NTT Commun Sci Labs, Kyoto 6190237, Japan; [Saito, Kazumi] Univ Shizuoka, Sch Adm & Informat, Suruga Ku, Shizuoka 4228526, Japan	Nippon Telegraph & Telephone Corporation; University of Shizuoka	Fujino, A (corresponding author), NTT Corp, NTT Commun Sci Labs, 2-4 Hikaridai,Seika Cho, Kyoto 6190237, Japan.	a.fujino@cslab.kecl.ntt.co.jp; ueda@cslab.kecl.ntt.co.jp; k-saito@u-shizuoka-ken.ac.jp						Amini MR, 2002, FR ART INT, V77, P390; BEKKERMAN R, 2001, P SIGIR 01 24 ACM IN, P146; Berger AL, 1996, COMPUT LINGUIST, V22, P39; BLUM A, 1998, P 11 AM C COMP LEARN, V11; Chawla N, 2005, J ARTIF INTELL RES, V23, P331, DOI 10.1613/jair.1509; CHEN SF, 1999, GAUSSIAN PRIOR SMOOT; Cozman F. G., 2002, P 15 INT FLOR ART IN, P327; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971; Forman G., 2003, Journal of Machine Learning Research, V3, P1289, DOI 10.1162/153244303322753670; Fujino A., 2005, PROC AAAI, P764; FUJINO A, 2005, INFORM TECHNOLOGY LE, V4, P161; Fujino A, 2007, INFORM PROCESS MANAG, V43, P379, DOI 10.1016/j.ipm.2006.07.013; Grandvalet Y., 2005, CAP, P529; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; Inoue M, 2003, IEEE T PATTERN ANAL, V25, P1570, DOI 10.1109/TPAMI.2003.1251150; Jelinek F., 1980, Pattern Recognition in Practice. Proceedings of an International Workshop, P381; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; Manning CD, 1999, FDN STAT NATURAL LAN; McCallum A, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P662; Miller DJ, 1997, ADV NEUR IN, V9, P571; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Raina R., 2004, ADV NEURAL INFORM PR, V16; Salton G., 1983, INTRO MODERN INFORM; Seeger M., 2010, LEARNING LABELED UNL; Szummer M, 2001, ADV NEUR IN, V13, P626; Tong S, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P658; Yang YM, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P42, DOI 10.1145/312624.312647; Zhu X., 2003, INT C MACH LEARN	32	42	46	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2008	30	3					424	437		10.1109/TPAMI.2007.70710	http://dx.doi.org/10.1109/TPAMI.2007.70710			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	250FT	18195437				2022-12-18	WOS:000252286100005
J	Ghosh, AK; Chaudhuri, P; Murthy, CA				Ghosh, AK; Chaudhuri, P; Murthy, CA			On visualization and aggregation of nearest neighbor classifiers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian strength function; misclassification rates; multiscale visualization; neighborhood parameter; posterior probability; prior distribution; weighted averaging	CLASSIFICATION	Nearest neighbor classification is one of the simplest and most popular methods for statistical pattern recognition. A major issue in k-nearest neighbor classification is how to find an optimal value of the neighborhood parameter k. In practice, this value is generally estimated by the method of cross-validation. However, the ideal value of k in a classification problem not only depends on the entire data set, but also on the specific observation to be classified. Instead of using any single value of k, this paper studies results for a finite sequence of classifiers indexed by k. Along with the usual posterior probability estimates, a new measure, called the Bayesian measure of strength, is proposed and investigated in this paper as a measure of evidence for different classes. The results of these classifiers and their corresponding estimated misclassification probabilities are visually displayed using shaded strips. These plots provide an effective visualization of the evidence in favor of different classes when a given data point is to be classified. We also propose a simple weighted averaging technique that aggregates the results of different nearest neighbor classifiers to arrive at the final decision. Based on the analysis of several benchmark data sets, the proposed method is found to be better than using a single value of k.	Indian Stat Inst, Theoret Studies & Math Unit, Kolkata 700108, W Bengal, India; Indian Stat Inst, Machine Intelligence Unit, Kolkata 700108, W Bengal, India	Indian Statistical Institute; Indian Statistical Institute Kolkata; Indian Statistical Institute; Indian Statistical Institute Kolkata	Ghosh, AK (corresponding author), Indian Stat Inst, Theoret Studies & Math Unit, 203 BT Rd, Kolkata 700108, W Bengal, India.	anilkghosh@rediffmail.com; probal@isical.ac.in; murthy@isical.ac.in						Aho AV, 1974, DESIGN ANAL COMPUTER; Alpaydin E, 1997, ARTIF INTELL REV, V11, P115, DOI 10.1023/A:1006563312922; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; Chaudhuri P, 1999, J AM STAT ASSOC, V94, P807, DOI 10.2307/2669996; Cooley CA, 1998, BIOMETRIKA, V85, P823, DOI 10.1093/biomet/85.4.823; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Dasarathy B.V., 1991, NEAREST NEIGHBOR NN; Devijver PA, 1982, PATTERN RECOGNITION; Duda R.O., 2000, PATTERN CLASSIFICATI; Fix E., 1951, 4 USAF SCH AV MED, P261; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914; FRIEDMAN JH, 1996, FLEXIBLE METRIC NEAR; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; GHOSH AK, TECHNOMETRICS; GHOSH AK, 2003, P 5 INT C ADV PATT R, P89; Godtliebsen F, 2002, J COMPUT GRAPH STAT, V11, P1, DOI 10.1198/106186002317375596; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716; Holmes CC, 2003, BIOMETRIKA, V90, P99, DOI 10.1093/biomet/90.1.99; Holmes CC, 2002, J ROY STAT SOC B, V64, P295, DOI 10.1111/1467-9868.00338; Johnson R. A., 2014, APPL MULTIVARIATE ST, V6; LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219; LOFTSGAARDEN DO, 1965, ANN MATH STAT, V36, P1049, DOI 10.1214/aoms/1177700079; Mahalanobis, 1936, P NATL I SCI INDIA, V2, P49; Mclachlan GJ., 2005, DISCRIMINANT ANAL ST; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P734, DOI 10.1109/TPAMI.2002.1008381; Olshen R., 1984, CLASSIFICATION REGRE; Opitz D., 1999, J ARTIF INTELLIG RES, V11, P169, DOI [DOI 10.1613/JAIR.614, 10.1613/jair.614]; PAIK M, 2004, STAT APPL GENETICS M, V3; Pal SK, 1998, IEEE T SYST MAN CY B, V28, P816, DOI 10.1109/3477.735391; PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875; Ripley BD., 1996; Schapire RE, 1998, ANN STAT, V26, P1651; SHALAK DB, 1996, THESIS U MASSACHUSET; STONE M, 1977, MATH OPERATIONSFORSC, V9, P127	40	42	46	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2005	27	10					1592	1602		10.1109/TPAMI.2005.204	http://dx.doi.org/10.1109/TPAMI.2005.204			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	953OM	16237994				2022-12-18	WOS:000231086700007
J	Chen, CS; Chang, WY				Chen, CS; Chang, WY			On pose recovery for generalized visual sensors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; camera pose estimation; generalized imaging device (GID); perspective n point problem (PnP); nonperspective n point problem (NPnP)	CLOSED-FORM SOLUTION; REGISTRATION	With the advances in imaging technologies for robot or machine vision, new imaging devices are being developed for robot navigation or image-based rendering. However, to satisfy some design criterion, such as image resolution or viewing ranges, these devices are not necessarily being designed to follow the perspective rule and, thus, the imaging rays may not pass through a common point. Such generalized imaging devices may not be perspective and, therefore, their poses cannot be estimated with traditional techniques. In this paper, we propose a systematic method for pose estimation of such a generalized imaging device. We formulate it as a nonperspective n point (NPnP) problem. The case with exact solutions, n = 3, is investigated comprehensively. Approximate solutions can be found for n > 3 in a least-squared-error manner by combining an initial-pose-estimation procedure and an orthogonally iterative procedure. This proposed method can be applied not only to nonperspective imaging devices but also perspective ones. Results from experiments show that our approach can solve the NPnP problem accurately.	Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan	Academia Sinica - Taiwan	Chen, CS (corresponding author), Acad Sinica, Inst Informat Sci, 128 Acad Rd,Sec 2, Taipei 115, Taiwan.	song@iis.sinica.edu.tw; wychang@ii.sinica.edu.tw						ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; Baker S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P35, DOI 10.1109/ICCV.1998.710698; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Chen CC, 1998, COMMUN ANAL GEOM, V6, P1; Chen CS, 1999, IEEE T PATTERN ANAL, V21, P1229, DOI 10.1109/34.809117; Chen YZ, 2002, ORG LETT, V4, P2937, DOI 10.1021/ol026336q; Chetverikov D, 2002, INT C PATT RECOG, P545, DOI 10.1109/ICPR.2002.1047997; DEMENTHON DF, 1995, INT J COMPUT VISION, V15, P123, DOI 10.1007/BF01450852; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599; Grossman R, 2001, MASSIVE COMP, V2, P115; Gupta R, 1997, IEEE T PATTERN ANAL, V19, P963, DOI 10.1109/34.615446; Haralick R. M., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P592, DOI 10.1109/CVPR.1991.139759; HORAUD R, 1989, COMPUT VISION GRAPH, V47, P33, DOI 10.1016/0734-189X(89)90052-2; HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; Huang F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P560, DOI 10.1109/ICCV.2001.937566; Jenkins M. A., 1975, ACM Transactions on Mathematical Software, V1, P178, DOI 10.1145/355637.355643; LANG M, 1994, IEEE SIGNAL PROCESSI; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Lorusso A, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P237; LOWE DG, 1992, INT J COMPUT VISION, V8, P113, DOI 10.1007/BF00127170; Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199; MIYAMOTO K, 1964, J OPT SOC AM, V54, P1060, DOI 10.1364/JOSA.54.001060; PRESS WH, 1999, NUMERICAL RECIPES C, pCH9; Rademacher P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P199, DOI 10.1145/280814.280871; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Sharp GC, 2002, IEEE T PATTERN ANAL, V24, P90, DOI 10.1109/34.982886; Smith B. T., 1976, LECT NOTES COMPUTER, V6; Swaminathan R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P2, DOI 10.1109/ICCV.2001.937581; WALKER MW, 1991, CVGIP-IMAG UNDERSTAN, V54, P358, DOI 10.1016/1049-9660(91)90036-O; Wunsch P., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P78, DOI 10.1109/ICPR.1996.545995; YAGI YS, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P910, DOI 10.1109/ROBOT.1991.131704; YAMAZAWA K, 1995, IEEE INT CONF ROBOT, P1062, DOI 10.1109/ROBOT.1995.525422; YUAN JSC, 1989, IEEE T ROBOTIC AUTOM, V5, P129, DOI 10.1109/70.88034	35	42	46	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2004	26	7					848	861		10.1109/TPAMI.2004.34	http://dx.doi.org/10.1109/TPAMI.2004.34			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	819OG	18579944				2022-12-18	WOS:000221323900003
J	Chojnacki, W; Brooks, MJ; van den Hengel, A; Gawley, D				Chojnacki, W; Brooks, MJ; van den Hengel, A; Gawley, D			Revisiting Hartley's normalized eight-point algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						epipolar equation; fundamental matrix; eght-point algorithm; data normalization		Hartley's eight-point algorithm has maintained an important place in computer vision, notably as a means of providing an initial value of the fundamental matrix for use in iterative estimation methods. In this paper, a novel explanation is given for the improvement in performance of the eight-point algorithm that results from using normalized data. It is first established that the normalized algorithm acts to minimize a specific cost function. It is then shown that this cost function is statistically better founded than the cost function associated with the nonnormalized algorithm. This augments the original argument that improved performance is due to the better conditioning of a pivotal matrix. Experimental results are given that support the adopted approach. This work continues a wider effort to place a variety of estimation techniques within a coherent framework.	Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia	University of Adelaide	Chojnacki, W (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.	wojtek@cs.adelaide.edu.au; mjb@cs.adelaide.edu.au; hengel@cs.adelaide.edu.au; dg@cs.adelaide.edu.au	Brooks, Michael/G-5614-2012; Chojnacki, Wojciech/AAE-9875-2020	Brooks, Michael/0000-0001-9612-5884; Chojnacki, Wojciech/0000-0001-7782-1956; van den Hengel, Anton/0000-0003-3027-8364				Chojnacki W., 2002, Proceedings of the Statistical Methods in Video Processing Workshop, P43; Chojnacki W, 2001, J MATH IMAGING VIS, V14, P21, DOI 10.1023/A:1008355213497; Chojnacki W, 2000, IEEE T PATTERN ANAL, V22, P1294, DOI 10.1109/34.888714; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P564; HARTLEY RI, 1992, LECT NOTES COMPUT SC, V588, P579; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Kanatani K., 1996, STAT OPTIMIZATION GE; Leedan Y, 2000, INT J COMPUT VISION, V37, P127, DOI 10.1023/A:1008185619375; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; MUHLICH M, 1998, LECT NOTES COMPUTER, V1407, P305; Torr P.H.S., 1995, THESIS U OXFORD; TORR PHS, 2002, MSRTR200250; VANDENHENGEL A, 2002, P 13 BRIT MACH VIS C, P468; Zhang ZY, 1998, IEEE T PATTERN ANAL, V20, P717, DOI 10.1109/34.689302	16	42	43	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2003	25	9					1172	1177		10.1109/TPAMI.2003.1227992	http://dx.doi.org/10.1109/TPAMI.2003.1227992			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	715MX		Green Submitted			2022-12-18	WOS:000184977300012
J	Hasler, D; Sbaiz, L; Susstrunk, S; Vetterli, M				Hasler, D; Sbaiz, L; Susstrunk, S; Vetterli, M			Outlier modeling in image matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						outlier model; outlier rejection; mixture model; robust pose estimation; M-estimators		We address the question of how to characterize the outliers that may appear when matching two views of the same scene. The match is performed by comparing the difference of the two views at a pixel level aiming at a better registration of the images. When using digital photographs as input, we notice that an outlier is often a region that has been occluded, an object that suddenly appears in one of the images, or a region that undergoes an unexpected motion. By assuming that the error in pixel intensity generated by the outlier is similar to an error generated by comparing two random regions in the scene, we can build a model for the outliers based on the content of the two views. We illustrate our model by solving a pose estimation problem: the goal is to compute the camera motion between two views. The matching is expressed as a mixture of inliers versus outliers, and defines a function to minimize for improving the pose estimation. Our model has two benefits: First, it delivers a probability for each pixel to belong to the outliers. Second, our tests show that the method is substantially more robust than traditional robust estimators (M-estimators) used in image stitching applications, with only a slightly higher computational complexity.	LOGO GmbH, D-48565 Steinfurt, Germany; Dartfish SA, CH-1705 Fribourg, Switzerland; Ecole Polytech Fed Lausanne, Swiss Fed Inst Technol, Ecublens,Audiovisual Commun Lab, Sch Comp & Commun Sci 1&C,LCAV, CH-1015 Lausanne, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Hasler, D (corresponding author), LOGO GmbH, D-48565 Steinfurt, Germany.		Süsstrunk, Sabine/I-2466-2013; Vetterli, Martin/B-3612-2010	Vetterli, Martin/0000-0002-6122-1216				Aiazzi B, 1999, IEEE SIGNAL PROC LET, V6, P138, DOI 10.1109/97.763145; AYER S, 1995, THESIS SWISS FED I T; BRIALOVVSKY VL, 1996, P INT C PATT REC, P70; GAO X, 2000, P COMP VIS PATT REC; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; HASLER D, 2001, THESIS SWISS FED I T; Huber P., 1981, ROBUST STAT; Leon-Garcia A, 2008, PROBABILITY STAT RAN; McLachlan G. J., 2000, FINITE MIXTURE MODEL; Mendel J. M, 1995, LESSONS ESTIMATION T; NETANYAHU NS, 1994, P 12 IAPR INT C COMP, V2, P406; OSLON CF, 2000, P COMP VIS PATT REC; PARK JI, 1994, IEEE T CIRC SYST VID, V4, P288, DOI 10.1109/76.305873; Rousseeuw P, 1987, APPL PROBABILITY STA; Sawhney HS, 1996, IEEE T PATTERN ANAL, V18, P814, DOI 10.1109/34.531801; Schroeter P, 1998, IEEE T MED IMAGING, V17, P172, DOI 10.1109/42.700730; TORR PS, 1999, P INT C COMP VIS; [No title captured]	18	42	44	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2003	25	3					301	315		10.1109/TPAMI.2003.1182094	http://dx.doi.org/10.1109/TPAMI.2003.1182094			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	647BL		Green Submitted			2022-12-18	WOS:000181071300003
J	Nishino, K; Sato, Y; Ikeuchi, K				Nishino, K; Sato, Y; Ikeuchi, K			Eigen-texture method: Appearance compression and synthesis based on a 3D model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image synthesis; texture; appearance; model-based rendering; image-based rendering; principle component analysis	RECOGNITION; OBJECTS	Image-based and model-based methods are two representative rendering methods for generating virtual images of objects from their real images. However, both methods still have several drawbacks when we attempt to apply them to mixed reality where we integrate virtual images with real background images. To overcome these difficulties, we propose a new method, which we refer to as the Eigen-Texture method. The proposed method samples appearances of a real object under various illumination and viewing conditions, and compresses them in the 2D coordinate system defined on the 3D model surface generated from a sequence of range images. The Eigen-Texture method is an example of a view-dependent texturing approach which combines the advantages of image-based and model-based approaches: No reflectance analysis of the object surface is needed, while an accurate 3D geometric model facilitates integration with other scenes. This paper describes the method and reports on its implementation.	Univ Tokyo, Grad Sch Sci, Dept Informat Sci, Meguro Ku, Tokyo 1538505, Japan; Univ Tokyo, Inst Ind Sci, Meguro Ku, Tokyo 1538505, Japan	University of Tokyo; University of Tokyo	Nishino, K (corresponding author), Univ Tokyo, Grad Sch Sci, Dept Informat Sci, Meguro Ku, 461 Komaba, Tokyo 1538505, Japan.	kon@cvl.iis.u-tokyo.ac.jp; ysato@iis.u-tokyo.ac.jp; ki@cvl.iis.u-tokyo.ac.jp						BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Chen S. E., 1993, Computer Graphics Proceedings, P279, DOI 10.1145/166117.166153; CULBERTSON WB, 1999, VISION ALGOITHMS THE; DEBEVEC P, 1998, P 9 EUR WORKSH REND, P105; Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; KUTULAKOS KN, 1998, 680 U ROCH COMP SCI; Landy M.S., 1991, COMPUTATIONAL MODELS; LEUNG T, 1999, P INT C COMP VIS, V2, P1010; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Nishino K., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P618, DOI 10.1109/CVPR.1999.787003; NISHINO K, 1999, P 7 INT C COMP VIS I, V1, P38; Paul D., 1998, P SIGGRAPH 98, P189, DOI [10.1145/280814.280864, DOI 10.1145/280814.280864]; PULLI K, 1997, P 8 EUR WORKSH REND; Sato I, 1999, IEEE T VIS COMPUT GR, V5, P1, DOI 10.1109/2945.764865; Sato K., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P657; SATO Y, 1994, J OPT SOC AM A, V11, P2990, DOI 10.1364/JOSAA.11.002990; SATO Y, 1997, P SIGGRAPH 97, P379; SEITZ SM, 1996, P SIGGRAPH 96, P21; SEITZ SM, 1997, P COMPUTER VISION PA, P28; Shashua A, 1992, THESIS MIT; Suen PH, 2000, IEEE T PATTERN ANAL, V22, P491, DOI 10.1109/34.857005; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241; Wheeler MD, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P917, DOI 10.1109/ICCV.1998.710826; Woodham R. J., 1978, Proceedings of the Society of Photo-Optical Instrumentation Engineers, vol.155. Image Understanding Systems and Industrial Applications, P136; Zhang ZY, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1041, DOI 10.1109/ICCV.1998.710845	28	42	45	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2001	23	11					1257	1265		10.1109/34.969116	http://dx.doi.org/10.1109/34.969116			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	491KV					2022-12-18	WOS:000172108300004
J	Roberts, SJ; Holmes, C; Denison, D				Roberts, SJ; Holmes, C; Denison, D			Minimum-entropy data partitioning using reversible jump Markov chain Monte Carlo	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						unsupervised data analysis; mixture models; Bayesian analysis; reversible-jump Markov Chain Monte Carlo; number of clusters		Problems in data analysis often require the unsupervised partitioning of a data set into classes. Several methods exist for such partitioning but many have the weakness of being formulated via strict parametric models (e.g., each class is modeled by a single Gaussian) or being computationally intensive in high-dimensional data spaces. We reconsider the notion of such cluster analysis in information-theoretic terms and show that an efficient partitioning may be given via a minimization of partition entropy. A reversible-jump sampling is introduced to explore the variable-dimension space of partition models.	Univ Oxford, Dept Engn Sci, Robot Res Grp, Oxford OX1 6PJ, England; Univ London Imperial Coll Sci & Technol, Dept Math, London SW7 2BZ, England	University of Oxford; Imperial College London	Roberts, SJ (corresponding author), Univ Oxford, Dept Engn Sci, Robot Res Grp, Pks Rd, Oxford OX1 6PJ, England.							AEBERHARD S, 1994, PATTERN RECOGN, V27, P1065, DOI 10.1016/0031-3203(94)90145-7; ANDRIEU C, 1999, P IEEE SIGN PROC WOR; Bernardo J. M., 1994, BAYESIAN THEORY; Bishop, 1995, NEURAL NETWORKS PATT; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; Holmes CC, 1998, NEURAL COMPUT, V10, P1217, DOI 10.1162/089976698300017421; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Neal R. M., 1996, LECT NOTES STAT; REZEK LA, 1998, IEEE T BIOMEDICAL EN, V44; Richardson S, 1997, J ROY STAT SOC B MET, V59, P731, DOI 10.1111/1467-9868.00095; Roberts SJ, 1997, PATTERN RECOGN, V30, P261, DOI 10.1016/S0031-3203(96)00079-9; Roberts SJ, 1998, IEEE T PATTERN ANAL, V20, P1133, DOI 10.1109/34.730550; Roberts SJ, 2000, PATTERN RECOGN, V33, P833, DOI 10.1016/S0031-3203(99)00086-2; ROSE K, 1990, PATTERN RECOGN LETT, V11, P589, DOI 10.1016/0167-8655(90)90010-Y; TIERNEY L, 1994, ANN STAT, V22, P1701, DOI 10.1214/aos/1176325750; WILSON R, 1990, PATTERN RECOGN, V23, P1413, DOI 10.1016/0031-3203(90)90087-2	18	42	42	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2001	23	8					909	914		10.1109/34.946994	http://dx.doi.org/10.1109/34.946994			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	460AH					2022-12-18	WOS:000170283300011
J	Keren, D; Osadchy, M; Gotsman, C				Keren, D; Osadchy, M; Gotsman, C			Antifaces: A novel, fast method for image detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image detection; smoothness; distribution of natural images; rejectors	RECOGNITION; EIGENFACES	This paper offers a novel detection method, which works well even in the case of a complicated image collection-for instance, a frontal face under a large class of linear transformations. It is also successfully applied to detect 3D objects under different views. Call the collection of images, which should be detected, a multitemplate. The detection problem is solved by sequentially applying very simple filters (or detectors), which are designed to yield small results on the multitemplate thence, "antifaces"), and large results on "random" natural images. This is achieved by making use of a simple probabilistic assumption on the distribution of natural images, which is borne out well in practice. Only images which passed the threshold test imposed by the first detector are examined by the second detector, etc. The detectors are designed to act independently so that their false alarms are uncorrelated; this results in a false alarm rate which decreases exponentially in the number of detectors. This, in turn, leads to a very fast detection algorithm. Typically, (1 + delta )N operations are required to classify an N-pixel image, where delta < 0.5. Also, the algorithm requires no training loop. The algorithm's performance compares favorably to the well-known eigenface and support vector machine based algorithms, but is substantially faster.	Univ Haifa, Dept Comp Sci, IL-31905 Haifa, Israel; Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	University of Haifa; Technion Israel Institute of Technology	Keren, D (corresponding author), Univ Haifa, Dept Comp Sci, IL-31905 Haifa, Israel.	dkeren@cs.haifa.ac.il; gamer@cs.haifa.ac.il; gotsman@cs.technion.ac.il		Gotsman, Craig/0000-0001-8579-3588				Baker S, 1996, PROC CVPR IEEE, P544, DOI 10.1109/CVPR.1996.517125; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Ben-Arie J, 1993, IEEE T CIRC SYST VID, V3, P71, DOI 10.1109/76.180691; BICHSEL M, 1994, CVGIP-IMAG UNDERSTAN, V59, P254, DOI 10.1006/ciun.1994.1017; Duda R.O., 1973, J ROYAL STAT SOC SER; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gonzalez R C, 1992, DIGITAL IMAGE PROCES; KEREN D, 1993, IEEE T PATTERN ANAL, V15, P982, DOI 10.1109/34.254057; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; Lamdan Y., 1988, P IEEE INT C COMP VI, P238; LO CH, 1989, IEEE T PATTERN ANAL, V11, P1053, DOI 10.1109/34.42836; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Osuna E., 1997, P IEEE C COMP VIS PA; Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772; Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777; Press WH., 1980, NUMERICAL RECIPES FO; RAO KR, 1994, IEEE T CIRC SYST VID, V4, P490, DOI 10.1109/76.322996; RAO KR, 1994, CVGIP-GRAPH MODEL IM, V56, P149, DOI 10.1006/cgip.1994.1014; Rowley H., 1998, P IEEE C COMP VIS PA; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Shashua A, 1999, NEURAL PROCESS LETT, V9, P129, DOI 10.1023/A:1018677409366; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; STOCKHAM TG, 1975, P IEEE, V63, P678, DOI 10.1109/PROC.1975.9800; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; TURK M, 1991, P IEEE C COMP VIS PA, P586, DOI DOI 10.1109/CVPR.1991.139758; TURK M, 1999, COMMUNICATION; Uenohara M, 1997, IEEE T PATTERN ANAL, V19, P891, DOI 10.1109/34.608291; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; WEISS I, 1993, INT J COMPUT VISION, V10, P207, DOI 10.1007/BF01539536; [No title captured]	34	42	43	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2001	23	7					747	761		10.1109/34.935848	http://dx.doi.org/10.1109/34.935848			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	449TV					2022-12-18	WOS:000169704000005
J	Sharon, E; Brandt, A; Basri, R				Sharon, E; Brandt, A; Basri, R			Completion energies and scale	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						curve completion; curve saliency; least-energy curve; perceptual grouping; elastica curve; scale; induction field; completion field; fast summation; multiscale	FIELDS; CONTOURS; PARALLEL; CURVE; SHAPE	The detection of smooth curves in images and their completion over gaps are two important problems in perceptual grouping. In this study, we examine the notion of completion energy of curve elements, showing, and exploiting its intrinsic dependence on length and width scales. We introduce a fast method for computing the most likely completion between two elements, by developing novel analytic approximations and a fast numerical procedure for computing the curve of least energy. We then use our newly developed energies to find the most likely completions in images through a generalized summation of induction fields. This is done through multiscale procedures, i.e., separate processing at different scales with some interscale interactions. Such procedures allow the summation of all induction fields to be done in a total of only O(N log N) operations, where N is the number of pixels in the image. More important, such procedures yield a more realistic dependence of the induction field on the length and width scales: The field of a long element is very different from the sum of the fields of its composing short segments.	Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel	Weizmann Institute of Science	Sharon, E (corresponding author), Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel.							Alter T, 1998, INT J COMPUT VISION, V27, P51, DOI 10.1023/A:1007953729443; BRADY M, 1980, P 1 ANN C ART INT; Brandt A, 1999, SIAM J SCI COMPUT, V20, P1417, DOI 10.1137/S1064827595285718; BRANDT A, 1991, COMPUT PHYS COMMUN, V65, P24, DOI 10.1016/0010-4655(91)90151-A; BRUCKSTEIN AM, 1990, COMPUT VISION GRAPH, V49, P283, DOI 10.1016/0734-189X(90)90105-5; DOLAN J, 1989, P IMAGE UNDERSTANDIN, P1135; ELSGOLTS LE, 1961, INT SERIES MONOGRAPH, V19; FIELD DJ, 1993, VISION RES, V33, P173, DOI 10.1016/0042-6989(93)90156-Q; Grossberg S., 1987, PERCEPTION ILLUSORY, P116, DOI [10.1007/978-1-4612-4760-9_12, DOI 10.1007/978-1-4612-4760-9_12]; Guy G, 1996, INT J COMPUT VISION, V20, P113, DOI 10.1007/BF00144119; HEITGER S, 1993, P INT C COMP VIS, P32; HERAULT L, 1993, IEEE T PATTERN ANAL, V15, P899, DOI 10.1109/34.232076; HORN BKP, 1983, ACM T MATH SOFTWARE, V9, P441, DOI 10.1145/356056.356061; Kanizsa G., 1979, ORG VISION; KAPADIA MK, 1995, NEURON, V15, P843, DOI 10.1016/0896-6273(95)90175-2; KELLMAN PJ, 1991, COGNITIVE PSYCHOL, V23, P141, DOI 10.1016/0010-0285(91)90009-D; Mumford D., 1994, ALGEBRAIC GEOMETRY I, V5681, P491, DOI DOI 10.1007/978-1-4612-2628-4_31; Nitzberg M., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P138, DOI 10.1109/ICCV.1990.139511; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; Pearson C, 2012, HDB APPL MATH SELECT; POLAT U, 1993, VISION RES, V33, P993, DOI 10.1016/0042-6989(93)90081-7; RUBIN N, 1995, INVEST OPHTHALMOL  S, V36, P1037; RUTKOWSKI WS, 1979, COMPUT VISION GRAPH, V9, P89, DOI 10.1016/0146-664X(79)90086-8; Sarkar S, 1996, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.1996.517115; Saund E., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P624, DOI 10.1109/CVPR.1999.784988; Thornber KK, 1996, BIOL CYBERN, V75, P141, DOI 10.1007/s004220050282; THORNBER KK, 1996, INT WORKSH EN MIN ME; ULLMAN S, 1976, BIOL CYBERN, V25, P1; WEISS I, 1988, COMPUT VISION GRAPH, V41, P80, DOI 10.1016/0734-189X(88)90118-1; WILLIAMS KK, 1994, P IEEE COMP VIS PATT; Williams LR, 1997, NEURAL COMPUT, V9, P859, DOI 10.1162/neco.1997.9.4.859; Williams LR, 1997, NEURAL COMPUT, V9, P837, DOI 10.1162/neco.1997.9.4.837; YEN S, 1996, INVESTIGATIVE OPHTHA, V37; ZUCKER SW, 1979, COMPUT VISION GRAPH, V9, P213, DOI 10.1016/0146-664X(79)90038-8; ZUCKER SW, 1988, P INT C COMPUTER VIS, P568; [No title captured]	36	42	47	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2000	22	10					1117	1131		10.1109/34.879792	http://dx.doi.org/10.1109/34.879792			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	369LQ					2022-12-18	WOS:000165067100005
J	Xu, YH; Nagy, G				Xu, YH; Nagy, G			Prototype extraction and adaptive OCR	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						optical character recognition; adaptive classification; template matching; segmentation; document image analysis; text reader	SEGMENTATION	To maintain OCR accuracy with decreasing quality of page image composition, production, and digitization, it is essential to tune the system to each document. We propose a prototype extraction method for document-specific OCR systems. The method automatically generates training samples from unsegmented text images and the corresponding transcripts. It is tolerant of transcription errors, so a transcript produced automatically by an imperfect omnifont OCR system can be used. The method is based on new algorithms for estimating character widths, character locations in a word, and match/nonmatch probabilities from unsegmented text. An experimental word recognition system is designed and developed to combine prototype extraction algorithms and segmentation-free word recognition. The system can adapt itself to different page images and achieve high recognition accuracy on heavily degraded print.	Hewlett Packard Labs, Palo Alto, CA 94304 USA; Rensselaer Polytech Inst, Dept Elect & Comp Syst Engn, Troy, NY 12180 USA	Hewlett-Packard; Rensselaer Polytechnic Institute	Xu, YH (corresponding author), Hewlett Packard Labs, 1501 Page Mill Rd,MS 3U-3, Palo Alto, CA 94304 USA.							Baird H.S., 1987, P C SOC PHOT SCI ENG, P14; BAIRD HS, 1994, P SOC PHOTO-OPT INS, V2181, P106, DOI 10.1117/12.171098; Carroll JohnB., 1967, COMPUTATIONAL ANAL P; Duda R.O., 1973, J ROYAL STAT SOC SER; ELNASAN A, 1998, INKLINK UNCONSTRAINT; ESPOSITO R, 1990, P 10 INT C PATT REC, P557; Heaps HS, 1978, INFORMATION RETRIEVA; HONG T, 1995, P SOC PHOTO-OPT INS, V2422, P15, DOI 10.1117/12.205820; INGOLD R, 1994, THESIS ECOLE POLYTEC; Kopec GE, 1993, IEEE T IMAGE PROCESS, V2, P510, DOI 10.1109/83.242359; Kopec GE, 1996, P SOC PHOTO-OPT INS, V2660, P14, DOI 10.1117/12.234712; KOPEC GE, 1994, IEEE T PATTERN ANAL, V16, P602, DOI 10.1109/34.295905; Lawson C. L., 1974, SOLVING LEAST SQUARE; NAGY G, 1966, IEEE T INFORM THEORY, V12, P215, DOI 10.1109/TIT.1966.1053864; Nagy G, 1997, PATTERN RECOGN LETT, V18, P1117, DOI 10.1016/S0167-8655(97)00100-1; Nagy G, 1997, PROC INT CONF DOC, P278, DOI 10.1109/ICDAR.1997.619856; NAGY G, 1996, P WORKSH DOC AN SYST, P263; RICE SVC, 1993, UNLV INF SCI RES I 1; SPITZ L, 1995, P 3 INT C DOC AN REC, P723; SZIRANYI T, 1991, OPT ENG, V30, P1878, DOI 10.1117/12.56017; VALDES R, 1992, DR DOBBS J, P56; Witten I.H., 1994, MANAGING GIGABYTES C	22	42	46	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1999	21	12					1280	1296		10.1109/34.817408	http://dx.doi.org/10.1109/34.817408			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	275PG					2022-12-18	WOS:000084828100003
J	Voss, K; Suesse, H				Voss, K; Suesse, H			Invariant fitting of planar objects by primitives	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						invariant fitting; normalization; planar objects; geometrical primitives; invariant features; affine transformations; canonical frame; moments	CURVES	The determination of invariant characteristics is an important problem in pattern recognition. Many invariants are known which have been obtained by the method of normalization. In this paper, we introduce a new approach of fitting planar objects by primitives using the method of normalization (for instance: fitting by lines, triangles, rectangles, circles, ellipses, super-quadrics, etc.). Objects and primitives are described by features, for example, by moments. The main advantage is that the normalization process provides us with a canonical frame or the object and the primitive. Therefore, the fit is invariant with respect to the transformation used. By this new method, an analytical fitting of non-analytical objects can be achieved, for example, fitting by polygons. Furthermore, the numerical effort can be reduced drastically by normalizing of the object and the primitive.			Voss, K (corresponding author), UNIV JENA,FAK MATH & INFORMAT,ERNST ABBE PLATZ 1,D-07743 JENA,GERMANY.							ASTROM K, 1995, IEEE T PATTERN ANAL, V17, P77, DOI 10.1109/34.368148; BLAKE A, 1990, ARTIF INTELL, V45, P323, DOI 10.1016/0004-3702(90)90011-N; DIRILTEN H, 1977, IEEE T COMPUT, V26, P314, DOI 10.1109/TC.1977.1674832; REEVES AP, 1988, IEEE T PATTERN ANAL, V10, P937, DOI 10.1109/34.9115; REEVES AP, 1981, P PRIP, P171; Reiss T.H., 1993, RECOGNIZING PLANAR O; ROSENFELD A, DIGITAL PICTURE PROC, P405; Rothe I, 1996, IEEE T PATTERN ANAL, V18, P366, DOI 10.1109/34.491618; ROTHE I, 1994, 503 U ROCH; SAAFEE R, 1992, IEEE T PATTERN ANAL, V4, P2465; SINCLAIR D, 1994, IEEE T PATTERN ANAL, V16, P769, DOI 10.1109/34.308471; SUESSE H, 1995, LECT NOTES COMPUTER, V970, P9; UDAGAWA K, 1964, ELECTR COMMUN JPN, V47, P34; VOSS K, 1995, ADAPTIVE MODELLE INV; WANG K, 1977, THESIS SYRACUSE U	15	42	47	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1997	19	1					80	84		10.1109/34.566815	http://dx.doi.org/10.1109/34.566815			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WE528					2022-12-18	WOS:A1997WE52800010
J	BROWN, LG; SHVAYTSER, H				BROWN, LG; SHVAYTSER, H			SURFACE ORIENTATION FROM PROJECTIVE FORESHORTENING OF ISOTROPIC TEXTURE AUTOCORRELATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									DAVID SARNOFF RES CTR,PRINCETON,NJ 08543	Sarnoff Corporation	BROWN, LG (corresponding author), COLUMBIA UNIV,DEPT COMP SCI,NEW YORK,NY 10027, USA.							ALOIMONIOS J, 1988, BIOL CYBERN, V58; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Rosenfeld A., 1982, DIGITAL PICTURE PROC, V1; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9	5	42	43	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1990	12	6					584	588		10.1109/34.56194	http://dx.doi.org/10.1109/34.56194			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE003					2022-12-18	WOS:A1990DE00300007
J	BAIM, PW				BAIM, PW			A METHOD FOR ATTRIBUTE SELECTION IN INDUCTIVE LEARNING-SYSTEMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											BAIM, PW (corresponding author), ATLANTIC AEROSP ELECTR CORP,470 TOTTEN POND RD,WALTHAM,MA 02154, USA.							Andrews H. C., 1972, INTRO MATH TECHNIQUE; ANGLUIN D, 1982, 250 YAL U TECH REP; BAIM PW, 1984, THESIS U ILLINOIS UR; BETHKE AD, 1980, THESIS U MICHIGAN; BOOZE JH, 1985, 2ND P C AI APPL MIAM; BUCHANAN BG, 1979, HPP7928 STANF U MEM; CHIN CH, 1975, PATTERN RECOGNITION, V7, P87; CLANCEY WJ, 1981, STANCS81896 STANF U; DAVIS J, 1981, THESIS U ILLINOIS UR; DIETTERICH TD, 1981, STANCS81891 STANF U; Duda R.O., 1973, J ROYAL STAT SOC SER; Feigenbaum E. A., 1982, HDB ARTIFICIAL INTEL, V3; Harmon H. H, 1960, MODERN FACTOR ANAL; HAYESROTH F, 1984, COMPUTER, V17, P11, DOI 10.1109/MC.1984.1659242; HAYESROTH F, 1980, R2540NSF RAND PUBL S; KANAL LN, 1978, TR640 U MAR COMP SCI; KODRATOFF Y, 1982, P EUROPEAN C AI ORSA; LAWLEY DN, 1963, FACTOR ANAL STATISTI; LBOV GS, 1965, 19 AC SCI I MATH REP; MICHALSKI RS, 1982, P EUROPEAN C AI ORSA; MICHALSKI RS, 1980, SEP P INT WORKSH PRO; MICHALSKI RS, 1972, GRAPHIC LANGUAGES; MICHALSKI RS, 1978, 867 U ILL DEP COMP S; MICHALSKI RS, 1982, UNPUB STUDIES INDUCT; POPLE H, P IJCAI 5; QUINLAN JR, 1982, INTRO READINGS EXPER; QUINLAN JR, 1983, MACHINE LEARNING; RABIN M, 1974, INFORMATION PROCESSI; SHAPIRO EY, 1981, 192 YAL U DEP COMP S; Smith Stephen Frederick, 1980, LEARNING SYSTEM BASE; SPACKMAN K, 1983, COMMUNICATION; Stearns S. R., 1976, SELECTING FEATURES P; STEPP RE, 1983, GEM USERS GUIDE; Tou JT, 1974, PATTERN RECOGN; TUNSTALL KW, 1975, PATTERN RECOGN, V7, P95, DOI 10.1016/0031-3203(75)90019-9; Van Trees H., 2013, DETECTION ESTIMATION; Zadeh L. A., 1981, MATH FRONTIERS SOCIA	37	42	45	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1988	10	6					888	896		10.1109/34.9110	http://dx.doi.org/10.1109/34.9110			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	Q9971					2022-12-18	WOS:A1988Q997100010
J	NOBORIO, H; FUKUDA, S; ARIMOTO, S				NOBORIO, H; FUKUDA, S; ARIMOTO, S			CONSTRUCTION OF THE OCTREE APPROXIMATING 3-DIMENSIONAL OBJECTS BY USING MULTIPLE VIEWS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									OSAKA UNIV, DEPT MECH ENGN, TOYONAKA, OSAKA 560, JAPAN	Osaka University								ARIMOTO S, 1987, 4TH P INT S ROB RES, P163; HONG TH, 1985, IEEE T PATTERN ANAL, V7, P721, DOI 10.1109/TPAMI.1985.4767730; Horn B.K.P., 1975, PSYCHOL COMPUTER VIS; JACKINS CL, 1980, COMPUT VISION GRAPH, V14, P249, DOI 10.1016/0146-664X(80)90055-6; KAWAGUCHI E, 1980, IEEE T PATTERN ANAL, V2, P27, DOI 10.1109/TPAMI.1980.4766967; KIM YC, 1986, IEEE T ROBOTIC AUTOM, V2, P127; MEAGHER D, 1982, COMPUT VISION GRAPH, V19, P129, DOI 10.1016/0146-664X(82)90104-6; MIYAKE T, 1984, ISP JAPAN, V25, P745; NOBORIO H, 1987, 1987 IEEE INT C ROB; NOBORIO H, 1987, J ROBOTICS SOC JAPAN, V5, P189; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; PAVLIDIS T, 1982, ALGORITHMS GRAPHICS, pCH15; Pavlidis T., 1977, STRUCTURAL PATTERN R; POTMESIL M, 1987, COMPUT VISION GRAPH, V40, P1, DOI 10.1016/0734-189X(87)90053-3; Shamos M.I., 1978, THESIS YALE U	15	42	46	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1988	10	6					769	782		10.1109/34.9101	http://dx.doi.org/10.1109/34.9101			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q9971					2022-12-18	WOS:A1988Q997100001
J	NANDHAKUMAR, N; AGGARWAL, JK				NANDHAKUMAR, N; AGGARWAL, JK			INTEGRATED ANALYSIS OF THERMAL AND VISUAL IMAGES FOR SCENE INTERPRETATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											NANDHAKUMAR, N (corresponding author), UNIV TEXAS,COLL ENGN,COMP & VIS RES CTR,AUSTIN,TX 78712, USA.							Aguilera R. A., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V253, P58; BESL PJ, 1985, JUN P COMPUT VIS PAT, P430; BUKOWSKI ME, 1983, 2462 U TEX CEN TRANS; BURTON M, 1981, P SOC PHOTO-OPT INST, V302, P26; CASASENT D, 1981, P SOC PHOTO-OPT INST, V302, P126; Clifford G.E., 1984, HEATING VENTILATING; HESTER CF, 1981, P SOC PHOTO-OPT INST, V302, P108; HINDERER J, 1981, P SOC PHOTO-OPT INST, V302, P8; HORN BKP, 1979, APPL OPTICS, V18, P1770, DOI 10.1364/AO.18.001770; HORN BKP, P IEEE, V19, P14; Howell J.R., 1982, SOLAR THERMAL ENERGY; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; Incropera F. P., 1981, FUNDAMENTALS HEAT TR; JAREM JM, 1984, P SPIE, V510, P94; KENG J, 1981, P SOC PHOTO-OPT INST, V302, P122; Kim J. H., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P170; KIM YC, 1985, JUN P IEEE C COMP VI, P289; KUMAR M, 1980, P SPIE, V234, P77; LIN YKJ, 1981, P SOC PHOTO-OPT INST, V302, P117; LLOYD MJ, 1975, THERMAL IMAGING SYST; NANDHAKUMAR N, 1985, PATTERN RECOGN, V18, P383, DOI 10.1016/0031-3203(85)90009-3; Nicodemus FE, 1977, NBS MONOGRAPH, V160; OHMAN C, 1981, P SOC PHOTO-OPT INST, V313, P204; PEARCE JA, 1983, P SPIE, V446, P218; ROSHENAW WM, 1973, HDB HEAT TRANSFER; RYU ZM, 1985, COMMUNICATION    JUN; SCHOTT JR, 1983, P SOC PHOTO-OPT INST, V430, P45; SEVIGNY L, 1983, COMPUT VISION GRAPH, V24, P229, DOI 10.1016/0734-189X(83)90045-2; SEVIGNY L, 1981, DREV R417280 DEF RES; Siegel R., 1981, THERMAL RAD HEAT TRA; Stamper E., 1979, HDB AIR CONDITIONING; Strock C., 1965, HDB AIR CONDITIONING; THEPCHATRI T, 1977, 231 U TEX CEN HIGHW; VANGRONINGEN WDH, 1985, IEEE T PATTERN ANAL, V7, P610, DOI 10.1109/TPAMI.1985.4767708; WOODHAM RJ, 1981, ARTIF INTELL, V17, P117, DOI 10.1016/0004-3702(81)90022-9	35	42	46	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1988	10	4					469	481		10.1109/34.3911	http://dx.doi.org/10.1109/34.3911			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	P1493					2022-12-18	WOS:A1988P149300004
J	FU, KS				FU, KS			A STEP TOWARDS UNIFICATION OF SYNTACTIC AND STATISTICAL PATTERN-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											FU, KS (corresponding author), PURDUE UNIV, SCH ELECT ENGN, W LAFAYETTE, IN 47907 USA.							Aho A.V., 1972, THEORY PARSING TRANS; [Anonymous], PATTERN RECOGNITION; BANAMINI R, 1982, PATTERN RECOGNITION; BUNKE H, 1979, GRAPH GRAMMAR APPLIC; FAN TI, 1979, COMPUT VISION GRAPH, V11, P138, DOI 10.1016/0146-664X(79)90063-7; FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5; FU KS, 1980, DIGITAL PATTERN RECO; FU KS, 1982, SYNTACTIC PATTERN RE; FU KS, 1980, IEEE T COMPUT, V29; FU KS, 1981, JUN WORKSH STRUCT SY; FU KS, 1982, 1982 P PRIP C LAS VE; GEORGEFF MP, 1982, ARTIF INTELL, P173; GIESE DA, 1979, IEEE T SYST MAN CYBE, V9; Gonzalez RC, 1978, SYNTACTIC PATTERN RE; Knuth D. E., 1968, Mathematical Systems Theory, V2, P127, DOI 10.1007/BF01692511; LEDLEY RL, 1965, OPTICAL ELECTRO OPTI; Lewis PM, 1976, COMPILER DESIGN THEO; LIU HH, 1982, IEEE T PATTERN ANAL, V4; MOAYER B, 1975, PATTERN RECOGN, V7, P210; MUNDY JL, 1977, 1977 P IEEE COMP SOC; Pavlidis T., 1977, STRUCTURAL PATTERN R; PYSTER A, 1978, INFORM CONTR, V39, P320; ROSENFELD A, 1981, COMPUT GRAPHICS IMAG, V16; SANFELIU A, 1981, JUN NSF WORKSH STRUC; SANFELIU A, UNPUB DISTANCE MEASU; SANFELIU A, 1982, 2ND P INT WORKSH GRA; SHAPIRO L, 1981, ORG RELATIONAL MODEL; SHAW AC, 1969, INFORM CONTROL, V14, P9, DOI 10.1016/S0019-9958(69)90017-5; SHI QY, 1982, 6TH P INT C PATT REC; SHI QY, 1982, INFORM SCI, V26; STOCKMAN G, 1976, COMMUN ASS COMPUT MA, V19; TAI JW, 1982, 6TH P INT C PATT REC; THOMASON MG, 1975, IEEE T COMPUT, V24; TSAI WH, 1979, IEEE T SYST MAN CYBE, V9; TSAI WH, 1980, 5TH P INT C PATT REC; TSAI WH, 1983, IEEE T SYST MAN CYBE, V13; Winston P. H., 1975, PSYCHOL COMPUTER VIS; YOU KC, 1979, IEEE T SYST MAN CYBE, V9	38	42	43	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	2					200	205						6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QJ974					2022-12-18	WOS:A1983QJ97400009
J	GU, YX; WANG, QR; SUEN, CY				GU, YX; WANG, QR; SUEN, CY			APPLICATION OF A MULTILAYER DECISION TREE IN COMPUTER RECOGNITION OF CHINESE-CHARACTERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											GU, YX (corresponding author), CONCORDIA UNIV,DEPT COMP SCI,MONTREAL H3G 1M8,QUEBEC,CANADA.							ANDREWS HC, 1971, IEEE T COMPUT, VC 20, P1045, DOI 10.1109/T-C.1971.223400; CHAI KL, 1980, P INT COMPUT C; HIRAI S, 1980, 5TH P INT C PATT REC, P867; MORI K, 1980, 5TH P INT C PATT REC, P692; Nakano Y., 1973, 1st International Joint Conference on Pattern Recognition, P172; NAKATA K, 1972, APR P C MACH PERC PA, P45; PAVLIDIS T, 1977, STRUCTUAL PATTERN RE, P150; SUEN CY, 1982, SIGNAL PROCESS, V4, P193, DOI 10.1016/0165-1684(82)90021-4; SWAIN PH, 1977, IEEE T GEOSCI REMOTE, V15, P142, DOI 10.1109/TGE.1977.6498972; WANG QR, UNPUB 4TH MOMENT INF; WENDLING S, 1978, IEEE T COMPUT, V27, P1213, DOI 10.1109/TC.1978.1675030; YOU KC, 1976, 3RD P S MACH PROC RE; [No title captured]	13	42	44	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	1					83	89		10.1109/TPAMI.1983.4767349	http://dx.doi.org/10.1109/TPAMI.1983.4767349			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	PZ844	21869088				2022-12-18	WOS:A1983PZ84400012
J	SCLOVE, SL				SCLOVE, SL			APPLICATION OF THE CONDITIONAL POPULATION-MIXTURE MODEL TO IMAGE SEGMENTATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SCLOVE, SL (corresponding author), UNIV ILLINOIS,DEPT QUANTITAT METHODS,CHICAGO,IL 60680, USA.							AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; AKAIKE H, 1981, J ECONOMETRICS, V16, P1; Anderson T.W, 1958, INTRO MULTIVARIATE S; [Anonymous], 1940, RELAXATION METHODS E; BALL GH, 1967, BEHAV SCI, V12, P153, DOI 10.1002/bs.3830120210; DAY NE, 1969, BIOMETRIKA, V56, P463, DOI 10.1093/biomet/56.3.463; EKLUNDH JO, 1980, IEEE T PATTERN ANAL, V2, P72, DOI 10.1109/TPAMI.1980.4766973; MacQueen J., 1967, 5 BERK S MATH STAT P, P281; Ortega J. M., 1970, ITERATIVE SOLUTION N, V30; SCLOVE SL, 1977, COMMUN STAT A-THEOR, V6, P417, DOI 10.1080/03610927708827502; SCLOVE SL, 1982, UNPUB MAY P WORKSH S; Southwell RV., 1956, RELAXATION METHODS T; WOLFE JH, 1970, MULTIVAR BEHAV RES, V5, P329, DOI 10.1207/s15327906mbr0503_6; [No title captured]	14	42	46	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	4					428	433		10.1109/TPAMI.1983.4767412	http://dx.doi.org/10.1109/TPAMI.1983.4767412			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RA578	21869127				2022-12-18	WOS:A1983RA57800008
J	HULL, JJ; SRIHARI, SN				HULL, JJ; SRIHARI, SN			EXPERIMENTS IN TEXT RECOGNITION WITH BINARY N-GRAM AND VITERBI ALGORITHMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											HULL, JJ (corresponding author), SUNY BUFFALO, DEPT COMP SCI, AMHERST, NY 14226 USA.		Srihari, Sargur N/E-8100-2011					BORNAT R, 1976, INT J MAN MACH STUD, V8, P13, DOI 10.1016/S0020-7373(76)80008-9; Doster W., 1980, Proceedings of the 5th International Conference on Pattern Recognition, P853; DUDA RO, 1968, FAL P JOINT COMP C, P1139; FISHER EG, 1976, THESIS U MASSACHUSET; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; GOOD IJ, 1965, RES MONO, V30; HALL PAV, 1980, COMPUT SURV, V12, P381, DOI 10.1145/356827.356830; MUNSON JH, 1968, FALL P JOINT COMP C, P1125; NEUHOFF DL, 1975, IEEE T INFORM THEORY, V21, P222, DOI 10.1109/TIT.1975.1055355; PETERSON JL, 1980, COMMUN ACM, V23, P676, DOI 10.1145/359038.359041; RISEMAN EM, 1971, IEEE T COMPUT, VC 20, P397, DOI 10.1109/T-C.1971.223255; RISEMAN EM, 1974, IEEE T COMPUT, VC 23, P480, DOI 10.1109/T-C.1974.223971; SHINGHAL R, 1979, INT J MAN MACH STUD, V11, P201, DOI 10.1016/S0020-7373(79)80017-6; SHINGHAL R, 1979, IEEE T PATTERN ANAL, V1, P184, DOI 10.1109/TPAMI.1979.4766904; SRIHARI SN, 1982, JUN P ACM SIGOA C OF, P108; SUEN CY, 1979, IEEE T PATTERN ANAL, V1, P164, DOI 10.1109/TPAMI.1979.4766902; Tanenbaum A. S, 2005, STRUCTURED COMPUTER, V5th; TOUSSAINT GT, 1979, P IEEE COMPUT SOC C, P164; ULLMANN JR, 1977, COMPUT J, V20, P141, DOI 10.1093/comjnl/20.2.141; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010; Winston P. H., 1977, ARTIFICIAL INTELLIGE	21	42	45	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	5					520	530		10.1109/TPAMI.1982.4767297	http://dx.doi.org/10.1109/TPAMI.1982.4767297			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PG894	21869072				2022-12-18	WOS:A1982PG89400009
J	SAMET, H				SAMET, H			DISTANCE TRANSFORM FOR IMAGES REPRESENTED BY QUADTREES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											SAMET, H (corresponding author), UNIV MARYLAND,DEPT COMP SCI,COLLEGE PK,MD 20742, USA.							Duda R.O., 1973, J ROYAL STAT SOC SER; DYER CR, 1980, COMMUN ACM, V23, P171, DOI 10.1145/358826.358838; HUNTER GM, 1979, IEEE T PATTERN ANAL, V1, P145, DOI 10.1109/TPAMI.1979.4766900; HUNTER GM, 1979, COMPUT VISION GRAPH, V10, P289, DOI 10.1016/0146-664X(79)90008-X; HUNTER GM, 1978, THESIS PRINCETON U P; KLINGER A, 1979, IEEE T PATTERN ANAL, V1, P50, DOI 10.1109/TPAMI.1979.4766875; Klinger A., 1976, COMPUT VISION GRAPH, V5, P68, DOI [10.1016/S0146-664X(76)80006-8, DOI 10.1016/S0146-664X(76)80006-8]; KLINGER A, 1971, OPTIMIZING METHODS S; Pavlidis T., 1977, STRUCTURAL PATTERN R; SAMET H, 1981, J ACM, V28, P487, DOI 10.1145/322261.322267; SAMET H, 1980, COMMUN ACM, V23, P163, DOI 10.1145/358826.358836; SAMET H, 1979, TR755 U MAR DEP COMP; SAMET H, 1979, TR780 U MAR DEP COMP; SAMET H, UNPUB IEEE T PATTERN; SHNEIER M, 1981, INFORM SCIENCES, V23, P49, DOI 10.1016/0020-0255(81)90040-2	15	42	42	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	3					298	303		10.1109/TPAMI.1982.4767246	http://dx.doi.org/10.1109/TPAMI.1982.4767246			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	NN069	21869036				2022-12-18	WOS:A1982NN06900007
J	Kossaifi, J; Walecki, R; Panagakis, Y; Shen, J; Schmitt, M; Ringeval, F; Han, J; Pandit, V; Toisoul, A; Schuller, B; Star, K; Hajiyev, E; Pantic, M				Kossaifi, Jean; Walecki, Robert; Panagakis, Yannis; Shen, Jie; Schmitt, Maximilian; Ringeval, Fabien; Han, Jing; Pandit, Vedhas; Toisoul, Antoine; Schuller, Bjorn; Star, Kam; Hajiyev, Elnar; Pantic, Maja			SEWA DB: A Rich Database for Audio-Visual Emotion and Sentiment Research in the Wild	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Databases; Tools; Computational modeling; Biological system modeling; Sensors; Affective computing; Emotion recognition; SEWA; affect analysis; in-the-wild; emotion recognition; database; valence; arousal; facial action units	FACIAL-EXPRESSION; FRAMEWORK; CONFLICT; AUDIO	Natural human-computer interaction and audio-visual human behaviour sensing systems, which would achieve robust performance in-the-wild are more needed than ever as digital devices are increasingly becoming an indispensable part of our life. Accurately annotated real-world data are the crux in devising such systems. However, existing databases usually consider controlled settings, low demographic variability, and a single task. In this paper, we introduce the SEWA database of more than 2,000 minutes of audio-visual data of 398 people coming from six cultures, 50 percent female, and uniformly spanning the age range of 18 to 65 years old. Subjects were recorded in two different contexts: while watching adverts and while discussing adverts in a video chat. The database includes rich annotations of the recordings in terms of facial landmarks, facial action units (FAU), various vocalisations, mirroring, and continuously valued valence, arousal, liking, agreement, and prototypic examples of (dis)liking. This database aims to be an extremely valuable resource for researchers in affective computing and automatic human sensing and is expected to push forward the research in human behaviour analysis, including cultural studies. Along with the database, we provide extensive baseline experiments for automatic FAU detection and automatic valence, arousal, and (dis)liking intensity estimation.	[Kossaifi, Jean; Walecki, Robert; Panagakis, Yannis; Shen, Jie; Toisoul, Antoine; Schuller, Bjorn; Pantic, Maja] Imperial Coll London, Dept Comp, London SW7 2AZ, England; [Schmitt, Maximilian; Han, Jing; Pandit, Vedhas] Univ Augsburg, Chair Embedded Intelligence Hlth Care & Wellbeing, D-86159 Augsburg, Bavaria, Germany; [Ringeval, Fabien] Univ Grenoble Alpes, Grenoble, France; [Star, Kam] Playgen, London EC2A 4BX, England; [Hajiyev, Elnar] Real Eyes, London W1F 8WE, England	Imperial College London; University of Augsburg; Communaute Universite Grenoble Alpes; UDICE-French Research Universities; Universite Grenoble Alpes (UGA)	Kossaifi, J (corresponding author), Imperial Coll London, Dept Comp, London SW7 2AZ, England.	jean.kossaifi@gmail.com; r.walecki14@imperial.ac.uk; i.panagakis@imperial.ac.uk; jie.shen07@imperial.ac.uk; maximilian.schmitt@informatik.uni-augsburg.de; fabien.ringeval@imag.fr; jing.han@informatik.uni-augsburg.de; vedhas.pandit@informatik.uni-augsburg.de; antoine.toisoul13@imperial.ac.uk; bjoern.schuller@imperial.ac.uk; kam@playgen.com; elnar@realeyesit.com; maja.pantic@gmail.com	Kossaifi, Jean/AAW-8519-2021; Schmitt, Maximilian/ABD-4551-2020; Pandit, Vedhas/AAG-4308-2020	Kossaifi, Jean/0000-0002-4445-3429; Schmitt, Maximilian/0000-0001-7453-5612; Pandit, Vedhas/0000-0002-1983-8140; Han, Jing/0000-0001-5776-6849; Panagakis, Ioannis/0000-0003-0153-5210; Schuller, Bjorn/0000-0002-6478-8699	European Community Horizon 2020 [H2020/2014-2020] [645094]; NVIDIA Corporation	European Community Horizon 2020 [H2020/2014-2020]; NVIDIA Corporation	This work was funded by the European Community Horizon 2020 [H2020/2014-2020] under grant agreement no. 645094 (SEWA). Yannis Panagakis gratefully acknowledges the support of NVIDIA Corporation with the donation of the Titan Xp used for this research.	Ambadar Z, 2009, J NONVERBAL BEHAV, V33, P17, DOI 10.1007/s10919-008-0059-5; Asthana A, 2015, IEEE T PATTERN ANAL, V37, P1312, DOI 10.1109/TPAMI.2014.2362142; Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240; Aubrey AJ, 2013, IEEE COMPUT SOC CONF, P277, DOI 10.1109/CVPRW.2013.48; Banziger T, 2012, EMOTION, V12, P1161, DOI 10.1037/a0025827; Baltrusaitis T, 2013, IEEE INT CONF AUTOMA; Bilakhia S, 2015, PATTERN RECOGN LETT, V66, P52, DOI 10.1016/j.patrec.2015.03.005; Bock R, 2011, LECT NOTES COMPUT SC, V6974, P25, DOI 10.1007/978-3-642-24600-5_6; Bone D, 2014, IEEE T AFFECT COMPUT, V5, P201, DOI 10.1109/TAFFC.2014.2326393; Bradley M.M., 2007, HDB EMOTION ELICITAT, P29; Brave S, 2003, HUM FAC ER, P81; Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6; Chen H, 2015, PROC CVPR IEEE, P1836, DOI 10.1109/CVPR.2015.7298793; Chrysos GG, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P954, DOI 10.1109/ICCVW.2015.126; Cowie R., 2000, ISCA TUT RES WORKSH, P19; D'Mello SK, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2682899; Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26; EKMAN P, 1993, AM PSYCHOL, V48, P384, DOI 10.1037/0003-066X.48.4.384; Ekman P, 2011, EMOT REV, V3, P364, DOI 10.1177/1754073911410740; El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020; Eyben F, 2016, SPRINGER THESES-RECO, P1, DOI 10.1007/978-3-319-27299-3; Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417; Eyben Florian, 2013, P 21 ACM INT C MULT, P835; Francis AL, 2003, J ACOUST SOC AM, V113, P1025, DOI 10.1121/1.1536169; Georgakis C, 2017, IMAGE VISION COMPUT, V65, P37, DOI 10.1016/j.imavis.2016.12.001; Graves A, 2012, STUD COMPUT INTELL, V385, P5; Grimm M., 2007, ROBUST SPEECH; Grimm M, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P865, DOI 10.1109/ICME.2008.4607572; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Gunes H, 2013, IMAGE VISION COMPUT, V31, P120, DOI 10.1016/j.imavis.2012.06.016; Han J, 2017, IMAGE VISION COMPUT, V65, P76, DOI 10.1016/j.imavis.2016.11.020; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241; Kim J, 2008, IEEE T PATTERN ANAL, V30, P2067, DOI 10.1109/TPAMI.2008.26; Kipp M., 2001, 7 EUR C SPEECH COMM; Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15; Kossaifi J, 2017, IMAGE VISION COMPUT, V65, P23, DOI 10.1016/j.imavis.2017.02.001; Kossaifi J, 2017, IEEE T IMAGE PROCESS, V26, P1040, DOI 10.1109/TIP.2016.2642828; Kossaifi J, 2014, IEEE IMAGE PROC, P1420, DOI 10.1109/ICIP.2014.7025284; Kossatfi J, 2015, IEEE IMAGE PROC, P1135, DOI 10.1109/ICIP.2015.7350977; Labov William., 1972, SOCIOLINGUISTIC PATT; Liu YL, 2013, IEEE INT WORKS GENET, P1, DOI 10.1109/GEFS.2013.6601048; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Marchi E., 2015, EVALUATING ROLE SPEE; Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4; McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20; Meudt S., 2012, P 1 INT C AFF PLEAS, P5347; Meudt S., 2010, P INT C LANG RES EV, P1172; Nicolaou MA, 2014, IEEE T PATTERN ANAL, V36, P1299, DOI 10.1109/TPAMI.2014.16; Nicolaou MA, 2012, IMAGE VISION COMPUT, V30, P186, DOI 10.1016/j.imavis.2011.12.005; Ostfeld-Etzion S, 2015, MOL AUTISM, V6, DOI [10.1186/s13229-015-0007-2, 10.1186/s13229-015-0018-z]; Panagakis Y, 2016, IEEE T PATTERN ANAL, V38, P1665, DOI 10.1109/TPAMI.2015.2497700; Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122; Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Petridis S, 2013, IMAGE VISION COMPUT, V31, P186, DOI 10.1016/j.imavis.2012.08.014; Ringeval F., 2015, P 5 INT WORKSH AUD V, P3, DOI DOI 10.1145/2808196.2811642; Ringeval F, 2013, IEEE INT CONF AUTOMA; Ringeval Fabien, 2013, AUT FAC GEST REC FG, P1, DOI [10.1109/FG.2013.6553805, DOI 10.1109/FG.2013.6553805]; RINN WE, 1984, PSYCHOL BULL, V95, P52, DOI 10.1037/0033-2909.95.1.52; Russell JA, 2003, ANNU REV PSYCHOL, V54, P329, DOI 10.1146/annurev.psych.54.101601.145102; Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127; Scherer KR, 1997, MOTIV EMOTION, V21, P211, DOI 10.1023/A:1024498629430; Schiel F., 2002, P INT C LANG RES EV, P200; Schuller B, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P478; Schuller B, 2013, INTERSPEECH, P148; Schuller B, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P449; Schuller B, 2014, INTERSPEECH, P427; Schuller B, 2011, SPEECH COMMUN, V53, P1062, DOI 10.1016/j.specom.2011.01.011; Shen J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1003, DOI 10.1109/ICCVW.2015.132; Shen J, 2013, IEEE T CYBERNETICS, V43, P1593, DOI 10.1109/TCYB.2013.2271563; Sneddon I, 2012, IEEE T AFFECT COMPUT, V3, P32, DOI 10.1109/T-AFFC.2011.26; Valstar M., 2014, P 4 INT WORKSHOP AUD, P3, DOI [10.1145/2661806.2661807, DOI 10.1145/2661806.2661807]; Valstar M., 2013, P 3 ACM INT WORKSHOP, P3, DOI DOI 10.1145/2512530.2512533; Valstar M, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P3, DOI 10.1145/2988257.2988258; Vandeventer J., 2015, P 1 JOINT C FAC AN A, P157; W_ollmer M., 2013, COMPUT SPEECH LANG, V27, P780; Walecki R., 2015, P IEEE INT C AUT FAC, P1, DOI DOI 10.1109/FG.2015.7163137; Walter S, 2013, IEEE T SYST MAN CY-S, V43, P988, DOI 10.1109/TSMCA.2012.2216869; Weninger F, 2015, J MACH LEARN RES, V16, P547; Wittenburg P., 2006, P 5 INT C LANG RES E, V2006, P5; Wollmer M, 2011, LECT NOTES COMPUT SC, V6676, P496, DOI 10.1007/978-3-642-21090-7_58; Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52; Zhang ZX, 2016, INTERSPEECH, P3593, DOI 10.21437/Interspeech.2016-998; Zhou F, 2016, IEEE T PATTERN ANAL, V38, P279, DOI 10.1109/TPAMI.2015.2414429	85	41	41	5	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					1022	1040		10.1109/TPAMI.2019.2944808	http://dx.doi.org/10.1109/TPAMI.2019.2944808			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	QE6IS	31581074	Green Submitted			2022-12-18	WOS:000616309900019
J	Liu, X; Hu, ZK; Ling, HB; Cheung, YM				Liu, Xin; Hu, Zhikai; Ling, Haibin; Cheung, Yiu-Ming			MTFH: A Matrix Tri-Factorization Hashing Framework for Efficient Cross-Modal Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Lips; Semantics; Computer science; Adaptation models; Task analysis; Encoding; Correlation; Cross-modal retrieval; matrix tri-factorization hashing; varying hash length; semantic correlation matrix	SPARSE	Hashing has recently sparked a great revolution in cross-modal retrieval because of its low storage cost and high query speed. Recent cross-modal hashing methods often learn unified or equal-length hash codes to represent the multi-modal data and make them intuitively comparable. However, such unified or equal-length hash representations could inherently sacrifice their representation scalability because the data from different modalities may not have one-to-one correspondence and could be encoded more efficiently by different hash codes of unequal lengths. To mitigate these problems, this paper exploits a related and relatively unexplored problem: encode the heterogeneous data with varying hash lengths and generalize the cross-modal retrieval in various challenging scenarios. To this end, a generalized and flexible cross-modal hashing framework, termed Matrix Tri-Factorization Hashing (MTFH), is proposed to work seamlessly in various settings including paired or unpaired multi-modal data, and equal or varying hash length encoding scenarios. More specifically, MTFH exploits an efficient objective function to flexibly learn the modality-specific hash codes with different length settings, while synchronously learning two semantic correlation matrices to semantically correlate the different hash representations for heterogeneous data comparable. As a result, the derived hash codes are more semantically meaningful for various challenging cross-modal retrieval tasks. Extensive experiments evaluated on public benchmark datasets highlight the superiority of MTFH under various retrieval scenarios and show its competitive performance with the state-of-the-arts.	[Liu, Xin; Hu, Zhikai] Huaqiao Univ, Dept Comp Sci, Xiamen 361021, Peoples R China; [Liu, Xin] Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China; [Hu, Zhikai] Huaqiao Univ, Fujian Key Lab Big Data Intelligence & Secur, Xiamen 361021, Peoples R China; [Ling, Haibin] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA; [Cheung, Yiu-Ming] Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Peoples R China	Huaqiao University; Xidian University; Huaqiao University; State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook; Hong Kong Baptist University	Liu, X (corresponding author), Huaqiao Univ, Dept Comp Sci, Xiamen 361021, Peoples R China.; Cheung, YM (corresponding author), Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Peoples R China.	xliu@hqu.edu.cn; zkhu@hqu.edu.cn; hling@cs.stonybrook.edu; ymc@comp.hkbu.edu.hk	; Cheung, Yiu-ming/E-2050-2015	Hu, Zhikai/0000-0001-7278-9977; Cheung, Yiu-ming/0000-0001-7629-4648; Ling, Haibin/0000-0003-4094-8413	National Science Foundation of China [61673185, 61672444]; Fundamental Research Funds for the Central Universities of Huaqiao University [ZQN-PY309]; State Key Laboratory of Integrated Services Networks of Xidian University [ISN2011]; National Science Foundation of Fujian Province [2017J01112]; Quanzhou City Science & Technology Program of China [2018C107R]; ITF project of HKSAR [ITS/339/18]; Hong Kong Baptist University, Research Committee, Initiation Grant-Faculty Niche Research Areas (IG-FNRA) 2018/19 [RC-FNRA-IG/18-19/SCI/03]	National Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities of Huaqiao University; State Key Laboratory of Integrated Services Networks of Xidian University; National Science Foundation of Fujian Province; Quanzhou City Science & Technology Program of China; ITF project of HKSAR; Hong Kong Baptist University, Research Committee, Initiation Grant-Faculty Niche Research Areas (IG-FNRA) 2018/19	This work was supported by the National Science Foundation of China (No. 61673185 and No. 61672444), Fundamental Research Funds for the Central Universities of Huaqiao University (No. ZQN-PY309), State Key Laboratory of Integrated Services Networks of Xidian University (No. ISN2011), National Science Foundation of Fujian Province (No. 2017J01112), Quanzhou City Science & Technology Program of China (No. 2018C107R), the ITF project of HKSAR (No. ITS/339/18), and Hong Kong Baptist University, Research Committee, Initiation Grant-Faculty Niche Research Areas (IG-FNRA) 2018/19 (No. RC-FNRA-IG/18-19/SCI/03).	Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928; Cao Y, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1445, DOI 10.1145/2939672.2939812; Cao Y, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P197, DOI 10.1145/2911996.2912000; Chua Tat-Seng, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646452; Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142; Ding GG, 2016, IEEE T IMAGE PROCESS, V25, P5427, DOI 10.1109/TIP.2016.2607421; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; Gui J, 2018, IEEE T PATTERN ANAL, V40, P490, DOI 10.1109/TPAMI.2017.2678475; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378; Huiskes Mark J, 2008, P 1 ACM INT C MULTIM, P39, DOI DOI 10.1145/1460096.1460104; Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348; Jiang QY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2248; Kulis B, 2012, IEEE T PATTERN ANAL, V34, P1092, DOI 10.1109/TPAMI.2011.219; Kumar S, 2011, P TWENTYSECOND INT J, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230; Li Y, 2015, PROC CVPR IEEE, P4758, DOI 10.1109/CVPR.2015.7299108; Lin Q., 2014, ADV NEURAL INFORM PR, P3059; Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011; Liong VE, 2018, PATTERN RECOGN, V79, P114, DOI 10.1016/j.patcog.2018.02.002; Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227; Liu H, 2017, PROC CVPR IEEE, P6345, DOI 10.1109/CVPR.2017.672; Liu LC, 2018, LECT NOTES COMPUT SC, V10828, P606, DOI 10.1007/978-3-319-91458-9_37; Mandal D, 2017, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR.2017.282; Masci J, 2014, IEEE T PATTERN ANAL, V36, P824, DOI 10.1109/TPAMI.2013.225; Peng YX, 2016, IEEE T CIRC SYST VID, V26, P583, DOI 10.1109/TCSVT.2015.2400779; Raginsky M., 2009, ADV NEURAL INFORM PR, P1509, DOI [10.5555/2984093.2984263, DOI 10.5555/2984093.2984263]; Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.1002/ACP.3140; Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923; Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598; Song J., 2013, P 2013 ACM SIGMOD IN, P785, DOI [10.1145/2463676.2465274, DOI 10.1145/2463676.2465274]; Tang J, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2564638; Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349; Wang JD, 2018, IEEE T PATTERN ANAL, V40, P769, DOI 10.1109/TPAMI.2017.2699960; Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311; Wei Y, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P791, DOI 10.1145/2623330.2623688; Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824; Wright SJ, 2015, MATH PROGRAM, V151, P3, DOI 10.1007/s10107-015-0892-3; Wu BT, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3946; Wu F, 2014, IEEE T MULTIMEDIA, V16, P427, DOI 10.1109/TMM.2013.2291214; Xia RK, 2014, AAAI CONF ARTIF INTE, P2156; Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345; Zhai D., 2013, P 23 INT JOINT C ART, P2754; Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704; Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177; Zhen Y., 2012, ADV NEURAL INFORM PR, P1376, DOI [10.5555/2999134.2999288, DOI 10.5555/2999134.2999288]; Zhen Y., 2012, PA CM SIGKDD INT C K, P940, DOI DOI 10.1145/2339530.2339678; Zheng F, 2018, IEEE T PATTERN ANAL, V40, P1059, DOI 10.1109/TPAMI.2016.2645565; Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415	54	41	42	3	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					964	981		10.1109/TPAMI.2019.2940446	http://dx.doi.org/10.1109/TPAMI.2019.2940446			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE6IS	31514125	Green Submitted			2022-12-18	WOS:000616309900015
J	Paredes-Valles, F; Scheper, KYW; de Croon, GCHE				Paredes-Valles, Federico; Scheper, Kirk Y. W.; de Croon, Guido C. H. E.			Unsupervised Learning of a Hierarchical Spiking Neural Network for Optical Flow Estimation: From Events to Global Motion Perception	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Neurons; Visualization; Biomedical optical imaging; Optical sensors; Biological system modeling; Biological information theory; Vision sensors; Event-based vision; feature extraction; motion detection; neural nets; neuromorphic computing; unsupervised learning	TIMING-DEPENDENT PLASTICITY; CIRCUIT; STDP; FLY	The combination of spiking neural networks and event-based vision sensors holds the potential of highly efficient and high-bandwidth optical flow estimation. This paper presents the first hierarchical spiking architecture in which motion (direction and speed) selectivity emerges in an unsupervised fashion from the raw stimuli generated with an event-based camera. A novel adaptive neuron model and stable spike-timing-dependent plasticity formulation are at the core of this neural network governing its spike-based processing and learning, respectively. After convergence, the neural architecture exhibits the main properties of biological visual motion systems, namely feature extraction and local and global motion perception. Convolutional layers with input synapses characterized by single and multiple transmission delays are employed for feature and local motion perception, respectively; while global motion selectivity emerges in a final fully-connected layer. The proposed solution is validated using synthetic and real event sequences. Along with this paper, we provide the cuSNN library, a framework that enables GPU-accelerated simulations of large-scale spiking neural networks. Source code and samples are available at https://github.com/tudelft/cuSNN.	[Paredes-Valles, Federico; Scheper, Kirk Y. W.; de Croon, Guido C. H. E.] Delft Univ Technol, Dept Control & Simulat, Micro Air Vehicle Lab, Fac Aerosp Engn, Kluyverweg 1, NL-2629 HS Delft, Netherlands	Delft University of Technology	Paredes-Valles, F (corresponding author), Delft Univ Technol, Dept Control & Simulat, Micro Air Vehicle Lab, Fac Aerosp Engn, Kluyverweg 1, NL-2629 HS Delft, Netherlands.	f.paredesvalles@tudelft.nl; k.y.w.scheper@tudelft.nl; g.c.h.e.decroon@tudelft.nl		Paredes-Valles, Federico/0000-0002-9478-7195				Abercrombie M., 2017, DICT BIOL; Adams S. V., 2015, SCI REP, V5, P1; ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; Perez-Carrasco JA, 2013, IEEE T PATTERN ANAL, V35, P2706, DOI 10.1109/TPAMI.2013.71; Aung M, 2018, IEEE CONF COMPU INTE, P117, DOI 10.1109/ISCAS.2018.8351588; BARLOW HB, 1965, J PHYSIOL-LONDON, V178, P477, DOI 10.1113/jphysiol.1965.sp007638; Barranco F, 2015, LECT NOTES COMPUT SC, V9094, P309, DOI 10.1007/978-3-319-19258-1_27; Baudry M, 1998, NEUROBIOL LEARN MEM, V70, P113, DOI 10.1006/nlme.1998.3842; Benosman R, 2014, IEEE T NEUR NET LEAR, V25, P407, DOI 10.1109/TNNLS.2013.2273537; Benosman R, 2012, NEURAL NETWORKS, V27, P32, DOI 10.1016/j.neunet.2011.11.001; Bingsheng Zhang, 2018, 2018 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData). Proceedings; Bohte S. M., 2012, ADV NEURAL INFORM PR, P1835; Borst A, 2015, NAT NEUROSCI, V18, P1067, DOI 10.1038/nn.4050; Borst A, 2010, ANNU REV NEUROSCI, V33, P49, DOI 10.1146/annurev-neuro-060909-153155; Brandli C., 2018, SILICON EYE EVENT SE; Brandli C, 2014, IEEE J SOLID-ST CIRC, V49, P2333, DOI 10.1109/JSSC.2014.2342715; Brosch T., 2016, P 9 EAI INT C BIOINS, P551, DOI [10.4108/eai.3-12-2015.2262447, DOI 10.4108/EAI.3-12-2015.2262447]; Brosch T, 2015, FRONT NEUROSCI-SWITZ, V9, DOI [10.3389/fnins.7015.00137, 10.3389/fnins.2015.00137]; Caporale N, 2008, ANNU REV NEUROSCI, V31, P25, DOI 10.1146/annurev.neuro.31.060407.125639; Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359; De Wagter C, 2014, IEEE INT CONF ROBOT, P4982, DOI 10.1109/ICRA.2014.6907589; Diehl PU, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00099; Doya K, 1999, NEURAL NETWORKS, V12, P961, DOI 10.1016/S0893-6080(99)00046-5; Florian RV, 2007, NEURAL COMPUT, V19, P1468, DOI 10.1162/neco.2007.19.6.1468; Fortun D, 2015, COMPUT VIS IMAGE UND, V134, P1, DOI 10.1016/j.cviu.2015.02.008; Friedrich J, 2016, J NEUROSCI, V36, P1529, DOI 10.1523/JNEUROSCI.2854-15.2016; Gallego G, 2018, PROC CVPR IEEE, P3867, DOI 10.1109/CVPR.2018.00407; Gallego G, 2017, IEEE ROBOT AUTOM LET, V2, P632, DOI 10.1109/LRA.2016.2647639; Gerstner W., 2002, SPIKING NEURON MODEL; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; Giulioni M, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00035; Haessig G, 2018, IEEE T BIOMED CIRC S, V12, P860, DOI 10.1109/TBCAS.2018.2834558; Hebb D. O., 1952, ORG BEHAV NEUROPSYCH; HODGKIN AL, 1990, B MATH BIOL, V52, P25, DOI 10.1016/S0092-8240(05)80004-7; Hordijk BJP, 2018, J FIELD ROBOT, V35, P69, DOI 10.1002/rob.21764; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Izhikevich EM, 2003, IEEE T NEURAL NETWOR, V14, P1569, DOI 10.1109/TNN.2003.820440; Izhikevich EM, 2007, CEREB CORTEX, V17, P2443, DOI 10.1093/cercor/bhl152; Karasek M, 2018, SCIENCE, V361, P1089, DOI 10.1126/science.aat0350; Katz LC, 1996, SCIENCE, V274, P1133, DOI 10.1126/science.274.5290.1133; Kheradpisheh SR, 2018, NEURAL NETWORKS, V99, P56, DOI 10.1016/j.neunet.2017.12.005; KIRKWOOD A, 1994, J NEUROSCI, V14, P1634, DOI 10.1523/JNEUROSCI.14-03-01634.1994; Kistler WM, 1997, NEURAL COMPUT, V9, P1015, DOI 10.1162/neco.1997.9.5.1015; Lagorce X, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00046; Lee J. T., 2016, FRONT NEUROSCI-SWITZ, P1, DOI DOI 10.HTTP://DX.D0I.0RG/10.3389/FNINS.2016.00508; Lichtsteiner P, 2008, IEEE J SOLID-ST CIRC, V43, P566, DOI 10.1109/JSSC.2007.914337; Liu M., 2018, ABMOF NOVEL OPTICAL; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Maass W, 1997, NEURAL NETWORKS, V10, P1659, DOI 10.1016/S0893-6080(97)00011-7; Masquelier T, 2007, PLOS COMPUT BIOL, V3, P247, DOI 10.1371/journal.pcbi.0030031; McGuire K, 2016, IEEE INT CONF ROBOT, P3255, DOI 10.1109/ICRA.2016.7487496; Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642; Mitrokhin A., 2018, EVENT BASED MOVING O; Morrison A, 2007, NEURAL COMPUT, V19, P1437, DOI 10.1162/neco.2007.19.6.1437; Mozafari M., 2018, COMBINING STDP REWAR; Mueggler E, 2017, INT J ROBOT RES, V36, P142, DOI 10.1177/0278364917691115; Orchard G, 2014, P IEEE, V102, P1520, DOI 10.1109/JPROC.2014.2346763; Orchard G, 2013, BIOMED CIRC SYST C, P298, DOI 10.1109/BioCAS.2013.6679698; Paredes-Valles F., 2018, THESIS; Posch C, 2011, IEEE J SOLID-ST CIRC, V46, P259, DOI 10.1109/JSSC.2010.2085952; Reichardt W., 1961, SENSORY COMMUNICATIO, P303; Richter C., 2014, P BERNST C COMP NEUR; Rombouts J., 2012, ADV NEURAL INFORM PR, P1871; Rombouts Jaldert O., 2012, Artificial Neural Networks and Machine Learning - ICANN 2012. Proceedings 22nd International Conference on Artificial Neural Networks, P443, DOI 10.1007/978-3-642-33269-2_56; Rueckauer B., 2017, FRONTIERS NEUROSCIEN, V11, P1; Rueckauer B, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00176; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Shon AP, 2004, NETWORK-COMP NEURAL, V15, P179, DOI 10.1088/0954-898X/15/3/002; Shrestha A, 2017, IEEE IJCNN, P1999, DOI 10.1109/IJCNN.2017.7966096; Shrestha S. B., 2018, P INT C NEUR INF PRO, P1417; Srinivasan MV, 1996, J EXP BIOL, V199, P237; STEIN RB, 1965, BIOPHYS J, V5, P173, DOI 10.1016/S0006-3495(65)86709-1; Taherkhani A, 2018, IEEE T NEUR NET LEAR, V29, P5394, DOI 10.1109/TNNLS.2018.2797801; Tavanaei A, 2017, IEEE IJCNN, P2023, DOI 10.1109/IJCNN.2017.7966099; THORPE SJ, 1990, PARALLEL PROCESSING IN NEURAL SYSTEMS AND COMPUTERS, P91; Tschechne Stephan, 2014, Artificial Neural Networks in Pattern Recognition. 6th IAPR TC 3 International Workshop, ANNPR 2014. Proceedings: LNCS 8774, P171, DOI 10.1007/978-3-319-11656-3_16; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; van Rossum MCW, 2000, J NEUROSCI, V20, P8812; Wenisch OG, 2005, BIOL CYBERN, V93, P239, DOI 10.1007/s00422-005-0006-z; Wu T, 2018, FRONT BEHAV NEUROSCI, V12, P1, DOI 10.3389/fnbeh.2018.00169; Ye C., 2018, UNSUPERVISED LEARNIN; Zambrano D., 2017, EFFICIENT COMPUTATIO; Zhu Alex Zihao, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4465, DOI 10.1109/ICRA.2017.7989517; Zhu A. Z., 2018, P ROB SCI SYST	85	41	43	7	44	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG. 1	2020	42	8					2051	2064		10.1109/TPAMI.2019.2903179	http://dx.doi.org/10.1109/TPAMI.2019.2903179			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MF5XR	30843817	Green Submitted, Green Published			2022-12-18	WOS:000545415400018
J	Zhang, Y; David, P; Foroosh, H; Gong, BQ				Zhang, Yang; David, Philip; Foroosh, Hassan; Gong, Boqing			A Curriculum Domain Adaptation Approach to the Semantic Segmentation of Urban Scenes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Image segmentation; Task analysis; Adaptation models; Neural networks; Training; Buildings; Domain adaptation; semantic segmentation; curriculum learning; curriculum domain adaptation; deep learning; self-driving	OBJECT CLASSES; KERNEL	During the last half decade, convolutional neural networks (CNNs) have triumphed over semantic segmentation, which is one of the core tasks in many applications such as autonomous driving and augmented reality. However, to train CNNs requires a considerable amount of data, which is difficult to collect and laborious to annotate. Recent advances in computer graphics make it possible to train CNNs on photo-realistic synthetic imagery with computer-generated annotations. Despite this, the domain mismatch between real images and the synthetic data hinders the models' performance. Hence, we propose a curriculum-style learning approach to minimizing the domain gap in urban scene semantic segmentation. The curriculum domain adaptation solves easy tasks first to infer necessary properties about the target domain; in particular, the first task is to learn global label distributions over images and local distributions over landmark superpixels. These are easy to estimate because images of urban scenes have strong idiosyncrasies (e.g., the size and spatial relations of buildings, streets, cars, etc.). We then train a segmentation network, while regularizing its predictions in the target domain to follow those inferred properties. In experiments, our method outperforms the baselines on two datasets and three backbone networks. We also report extensive ablation studies about our approach.	[Zhang, Yang; Foroosh, Hassan] Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA; [David, Philip] US Army Res Lab, Computat & Informat Sci Directorate, Adelphi, MD 20742 USA; [Gong, Boqing] Tencent, AI Lab, Bellevue, WA 98004 USA	State University System of Florida; University of Central Florida; United States Department of Defense; United States Army; US Army Research, Development & Engineering Command (RDECOM); US Army Research Laboratory (ARL)	Zhang, Y (corresponding author), Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA.	yangzhang@knights.ucf.edu; philip.j.david4.civ@mail.mil; foroosh@cs.ucf.edu; boqinggo@outlook.com		Zhang, Yang/0000-0002-5138-6578	NSF award IIS [1566511]; GPU from NVIDIA; NSF [IIS-1212948]	NSF award IIS; GPU from NVIDIA; NSF(National Science Foundation (NSF))	This work was supported by the NSF award IIS #1566511, a gift from Adobe Systems Inc., and a GPU from NVIDIA. It was also in part supported by the NSF grant IIS-1212948, and a gift from Uber Technologies Inc.	Al-Rfou R, 2016, THEANO PYTHON FRAMEW; Aljundi R, 2015, PROC CVPR IEEE, P56, DOI 10.1109/CVPR.2015.7298600; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Barata C, 2015, IEEE J BIOMED HEALTH, V19, P1146, DOI 10.1109/JBHI.2014.2336473; Bengio Yoshua., 2009, P 26 ANN INT C MACHI, P41, DOI 10.1145/ 1553374.1553380; Bilen H, 2014, P BMVC 2014, P1997; Bousmalis K., 2016, ARXIV161205424; Brostow GJ, 2008, LECT NOTES COMPUT SC, V5302, P44, DOI 10.1007/978-3-540-88682-2_5; Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005; Bucila C, 2006, P 12 ACM SIGKDD INT, P535, DOI DOI 10.1145/1150402.1150464; Chen L.-C., 2014, ARXIV PREPRINT ARXIV; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen YH, 2017, IEEE I CONF COMP VIS, P2011, DOI 10.1109/ICCV.2017.220; Chen YH, 2018, PROC CVPR IEEE, P7892, DOI 10.1109/CVPR.2018.00823; Chollet F., 2015, KERAS; Cipoll Roberto, 2008, PROC CVPR IEEE, P1; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Csurka Gabriela, 2017, ARXIV170205374; Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343; Dosovitskiy A., 2017, C ROBOT LEARNING, P1; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368; Foster DH, 2011, VISION RES, V51, P674, DOI 10.1016/j.visres.2010.09.006; GAIDON A, 2016, PROC CVPR IEEE, P4340, DOI DOI 10.1109/CVPR.2016.470; Ganchev K, 2010, J MACH LEARN RES, V11, P2001; Ganin Y., 2015, CORR; Ganin Yaroslav, 2015, ICML; García Herrera Arístides Lázaro, 2017, Rev.Med.Electrón., P1; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Gijsenij A, 2011, IEEE T IMAGE PROCESS, V20, P2475, DOI 10.1109/TIP.2011.2118224; Gijsenij A, 2010, INT J COMPUT VISION, V86, P127, DOI 10.1007/s11263-008-0171-3; Gong B., 2012, P NIPS WORKSH LARG S; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Gretton A., 2008, DATASET SHIFT MACHIN; Gretton A, 2012, J MACH LEARN RES, V13, P723; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; Hinton G., 2015, ARXIV150302531; Hoffman J, 2018, PR MACH LEARN RES, V80; Hoffmann Johannes, 2016, 2016 Conference on Precision Electromagnetic Measurements (CPEM), P1, DOI 10.1109/CPEM.2016.7540615; Hong S, 2016, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR.2016.349; Hong WX, 2018, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2018.00145; Hu ZT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2410, DOI 10.18653/v1/p16-1228; Huang HS, 2018, LECT NOTES COMPUT SC, V11220, P611, DOI 10.1007/978-3-030-01270-0_36; Khosla A, 2012, LECT NOTES COMPUT SC, V7572, P158, DOI 10.1007/978-3-642-33718-5_12; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702; Langkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LI ZQ, 2015, PROC CVPR IEEE, P1356, DOI DOI 10.1109/CVPR.2015.7298741; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Neuhold G, 2017, IEEE I CONF COMP VIS, P5000, DOI 10.1109/ICCV.2017.534; Noei E, 2018, ESEC/FSE'18: PROCEEDINGS OF THE 2018 26TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P283, DOI 10.1145/3236024.3236044; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Pan XG, 2018, LECT NOTES COMPUT SC, V11208, P484, DOI 10.1007/978-3-030-01225-0_29; Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203; Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P53, DOI 10.1109/MSP.2014.2347059; Pathak D, 2015, IEEE I CONF COMP VIS, P1796, DOI 10.1109/ICCV.2015.209; Peng X., 2017, ARXIV170105524; Peng Xingchao, 2017, VISDA VISUAL DOMAIN; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Perronnin F, 2007, PROC CVPR IEEE, P2272; Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780; Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI 10.1109/ICPHM.2017.7998297; Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7; Romijnders R, 2019, IEEE WINT CONF APPL, P1866, DOI 10.1109/WACV.2019.00203; ROS G, 2016, PROC CVPR IEEE, P3234, DOI DOI 10.1109/CVPR.2016.352; Ros G., 2016, CORR; Ruano A., 2017, DEEPGTAV; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Saito K., 2018, ICLR; Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392; Sakaridis C, 2018, LECT NOTES COMPUT SC, V11217, P707, DOI 10.1007/978-3-030-01261-8_42; Saleh FS, 2018, LECT NOTES COMPUT SC, V11206, P86, DOI 10.1007/978-3-030-01216-8_6; Sankaranarayanan S, 2018, PROC CVPR IEEE, P8503, DOI 10.1109/CVPR.2018.00887; Shafaei A., 2016, ARXIV160801745; Shah Shital, 2018, FIELD SERVICE ROBOTI, P621, DOI [10.1007/978-3-319-67361-5_40, DOI 10.1007/978-3-319-67361-5_40]; Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89; Sun B., 2014, BMVC, V1, P3, DOI DOI 10.5244/C.28.82; Sun BC, 2016, AAAI CONF ARTIF INTE, P2058; Tighe J, 2010, LECT NOTES COMPUT SC, V6315, P352, DOI 10.1007/978-3-642-15555-0_26; Tommasi T., CORR; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Tsai YH, 2018, PROC CVPR IEEE, P7472, DOI 10.1109/CVPR.2018.00780; Tzeng E., 2014, ARXIV PREPRINT ARXIV; Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463; Vazquez D, 2014, IEEE T PATTERN ANAL, V36, P797, DOI 10.1109/TPAMI.2013.163; Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6; Wu Z, 2016, CORR, P1; Wu ZX, 2018, LECT NOTES COMPUT SC, V11209, P535, DOI 10.1007/978-3-030-01228-1_32; Xie CC, 2013, INT CONF COMPUTAT, P222, DOI 10.1109/ICCPS.2013.6893597; Xu H., 2016, ARXIV161201079; Xu J., 2014, ARXIV14085400 CORR; Yong-Ping Zhang, 2017, 2017 IEEE 85th Vehicular Technology Conference (VTC Spring), DOI 10.1109/VTCSpring.2017.8108382; Zeiler Matthew D, 2012, ARXIV12125701; Zhang CX, 2010, LECT NOTES COMPUT SC, V6314, P708, DOI 10.1007/978-3-642-15561-1_51; Zhang LH, 2015, INT CONF SOFTW ENG, P931, DOI 10.1109/ICSESS.2015.7339207; Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zhu XG, 2018, LECT NOTES COMPUT SC, V11211, P587, DOI 10.1007/978-3-030-01234-2_35	108	41	41	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG. 1	2020	42	8					1823	1841		10.1109/TPAMI.2019.2903401	http://dx.doi.org/10.1109/TPAMI.2019.2903401			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MF5XR	30843818	hybrid, Green Submitted			2022-12-18	WOS:000545415400002
J	Liu, J; Shahroudy, A; Wang, G; Duan, LY; Kot, AC				Liu, Jun; Shahroudy, Amir; Wang, Gang; Duan, Ling-Yu; Kot, Alex C.			Skeleton-Based Online Action Prediction Using Scale Selection Network	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Microsoft Windows; Skeleton; Three-dimensional displays; Task analysis; Videos; Real-time systems; Pattern recognition; Action prediction; scale selection; sliding window; dilated convolution; skeleton data	ACTION RECOGNITION; MODEL	Action prediction is to recognize the class label of an ongoing activity when only a part of it is observed. In this paper, we focus on online action prediction in streaming 3D skeleton sequences. A dilated convolutional network is introduced to model the motion dynamics in temporal dimension via a sliding window over the temporal axis. Since there are significant temporal scale variations in the observed part of the ongoing action at different time steps, a novel window scale selection method is proposed to make our network focus on the performed part of the ongoing action and try to suppress the possible incoming interference from the previous actions at each step. An activation sharing scheme is also proposed to handle the overlapping computations among the adjacent time steps, which enables our framework to run more efficiently. Moreover, to enhance the performance of our framework for action prediction with the skeletal input data, a hierarchy of dilated tree convolutions are also designed to learn the multi-level structured semantic representations over the skeleton joints at each frame. Our proposed approach is evaluated on four challenging datasets. The extensive experiments demonstrate the effectiveness of our method for skeleton-based online action prediction.	[Liu, Jun; Kot, Alex C.] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; [Shahroudy, Amir] Chalmers Univ Technol, Dept Elect Engn, S-41296 Gothenburg, Sweden; [Wang, Gang] Alibaba Grp, Hangzhou 310052, Peoples R China; [Duan, Ling-Yu] Peking Univ, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China; [Duan, Ling-Yu] Peng Cheng Lab, Shenzhen 518000, Peoples R China	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Chalmers University of Technology; Alibaba Group; Peking University; Peng Cheng Laboratory	Liu, J (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.; Duan, LY (corresponding author), Peking Univ, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China.	jliu029@ntu.edu.sg; amirsh@chalmers.se; wanggang@ntu.edu.sg; lingyu@pku.edu.cn; eackot@ntu.edu.sg	Shahroudy, Amir/T-2261-2017	Shahroudy, Amir/0000-0002-1045-6437; Liu, Jun/0000-0002-4365-4165; Kot, Alex/0000-0001-6262-8125	National Research Foundation, Singapore; Infocomm Media Development Authority, Singapore; National Basic Research Program of China [2015CB351806]; National Natural Science Foundation of China [61661146005, U1611461]	National Research Foundation, Singapore(National Research Foundation, Singapore); Infocomm Media Development Authority, Singapore; National Basic Research Program of China(National Basic Research Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This research was carried out at Rapid-Rich Object Search (ROSE) Lab at Nanyang Technological University. ROSE Lab is supported by the National Research Foundation, Singapore, and the Infocomm Media Development Authority, Singapore. This work was supported in part by the National Basic Research Program of China under Grant 2015CB351806, and the National Natural Science Foundation of China under Grant 61661146005 and Grant U1611461. Weacknowledge the NVIDIA AI Technology Centre (NVAITC) for the GPU donation.	Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011; [Anonymous], 2016, ARXIV160903499; [Anonymous], 2017, 2017 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2017.106; [Anonymous], P 26 INT JOINT C ART; Baek S, 2017, IEEE WINT CONF APPL, P158, DOI 10.1109/WACV.2017.25; Bloom V., 2012, 2012 IEEE COMPUTER S, P7, DOI DOI 10.1109/CVPRW.2012.6239175; Cao Y, 2013, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2013.343; Collobert R., 2011, NIPS; Dai XY, 2017, IEEE I CONF COMP VIS, P5727, DOI 10.1109/ICCV.2017.610; Dauphin YN, 2017, PR MACH LEARN RES, V70; Du Y, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P579, DOI 10.1109/ACPR.2015.7486569; Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714; Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260; Escalera S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2522848.2532595; Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772; Gao JY, 2017, IEEE I CONF COMP VIS, P3648, DOI 10.1109/ICCV.2017.392; Gao Jiyang, 2017, ARXIV170501180; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Han F, 2017, COMPUT VIS IMAGE UND, V158, P85, DOI 10.1016/j.cviu.2017.01.011; Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; Hu JF, 2017, IEEE T PATTERN ANAL, V39, P2186, DOI 10.1109/TPAMI.2016.2640292; Hu JF, 2016, LECT NOTES COMPUT SC, V9905, P280, DOI 10.1007/978-3-319-46448-0_17; Huang ZW, 2017, PROC CVPR IEEE, P1243, DOI 10.1109/CVPR.2017.137; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378; Ke Q., 2018, COMPUTER VISION ASSI; Ke Q, 2018, IEEE T MULTIMEDIA, V20, P1712, DOI 10.1109/TMM.2017.2778559; Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486; Ke QH, 2017, IEEE SIGNAL PROC LET, V24, P731, DOI 10.1109/LSP.2017.2690339; Ke QH, 2016, LECT NOTES COMPUT SC, V9914, P403, DOI 10.1007/978-3-319-48881-3_28; Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207; Kong Y, 2017, PROC CVPR IEEE, P3662, DOI 10.1109/CVPR.2017.390; Kong Y, 2014, LECT NOTES COMPUT SC, V8693, P596, DOI 10.1007/978-3-319-10602-1_39; Lea C, 2017, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2017.113; LeCun Y., 1998, CONVOLUTIONAL NETWOR, V3361, P255, DOI DOI 10.1109/IJCNN.2004.1381049; Li CL, 2018, AAAI CONF ARTIF INTE, P3482; Li Kang, 2014, IEEE Trans Pattern Anal Mach Intell, V36, P1644, DOI 10.1109/TPAMI.2013.2297321; Li K, 2012, LECT NOTES COMPUT SC, V7572, P286, DOI 10.1007/978-3-642-33718-5_21; Li YH, 2016, LECT NOTES COMPUT SC, V9911, P203, DOI 10.1007/978-3-319-46478-7_13; Liu C., 2017, P WORKSH VIS AN SMAR, DOI DOI 10.1145/3132734.3132739; Liu J, 2018, IEEE T IMAGE PROCESS, V27, P1586, DOI 10.1109/TIP.2017.2785279; Liu J, 2018, PROC CVPR IEEE, P8349, DOI 10.1109/CVPR.2018.00871; Liu J, 2018, IEEE T PATTERN ANAL, V40, P3007, DOI 10.1109/TPAMI.2017.2771306; Liu J, 2017, PROC CVPR IEEE, P3671, DOI 10.1109/CVPR.2017.391; Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50; Liu MY, 2017, IEEE IMAGE PROC, P3670; Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019; Hoai M, 2014, INT J COMPUT VISION, V107, P191, DOI 10.1007/s11263-013-0683-3; Mutch J, 2006, IEEE CVPR, V1, P11, DOI DOI 10.1109/CVPR.2006.200; Ni GM, 2017, 2017 IEEE 2ND ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P1414, DOI 10.1109/IAEAC.2017.8054247; Oneata Dan, 2014, LEAR SUBMISSION THUM, P2; Rahmani H, 2017, IEEE I CONF COMP VIS, P5833, DOI 10.1109/ICCV.2017.621; Rahmani H, 2014, IEEE WINT CONF APPL, P626, DOI 10.1109/WACV.2014.6836044; Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349; Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115; Shahroudy A, 2016, IEEE T PATTERN ANAL, V38, P2123, DOI 10.1109/TPAMI.2015.2505295; Sharaf A, 2015, IEEE WINT CONF APPL, P998, DOI 10.1109/WACV.2015.138; Shou Z, 2017, PROC CVPR IEEE, P1417, DOI 10.1109/CVPR.2017.155; Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119; Siva P, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.65; Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460; Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82; Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198; Wang LM, 2017, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2017.678; Wang P, 2016, LECT NOTES COMPUT SC, V9911, P370, DOI 10.1007/978-3-319-46478-7_23; Wang PC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P97, DOI 10.1145/2964284.2967191; Wang QL, 2020, IEEE T EMERG TOP COM, V8, P148, DOI 10.1109/TETC.2017.2699169; Wei P, 2013, IEEE I CONF COMP VIS, P3136, DOI 10.1109/ICCV.2013.389; Xu Z, 2015, IEEE I CONF COMP VIS, P3191, DOI 10.1109/ICCV.2015.365; Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444; Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001; Yeung S, 2016, PROC CVPR IEEE, P2678, DOI 10.1109/CVPR.2016.293; Yu FP, 2016, PROCEEDINGS OF 2016 SYMPOSIUM ON PIEZOELECTRICITY, ACOUSTIC WAVES, AND DEVICE APPLICATIONS (SPAWDA), P1, DOI 10.1109/SPAWDA.2016.7829944; Yu G, 2015, LECT NOTES COMPUT SC, V9007, P50, DOI 10.1007/978-3-319-16814-2_4; Yun Kiwon, 2012, 2012 IEEE COMP SOC C, P28; Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342; Zhang J, 2016, PATTERN RECOGN, V60, P86, DOI 10.1016/j.patcog.2016.05.019; Zhang PF, 2017, IEEE I CONF COMP VIS, P2136, DOI 10.1109/ICCV.2017.233; Zhang SY, 2017, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2017.24; Zhang YP, 2012, IEEE VTS VEH TECHNOL; Zhao L, 2017, INT CONF ASIC, P616; Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317; Zhu WT, 2016, AAAI CONF ARTIF INTE, P3697; Zhu Y, 2017, IEEE WINT CONF APPL, P197, DOI 10.1109/WACV.2017.29	86	41	44	2	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2020	42	6					1453	1467		10.1109/TPAMI.2019.2898954	http://dx.doi.org/10.1109/TPAMI.2019.2898954			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR3TM	30762531	Green Submitted			2022-12-18	WOS:000535615700012
J	He, R; Cao, J; Song, LX; Sun, ZN; Tan, TN				He, Ran; Cao, Jie; Song, Lingxiao; Sun, Zhenan; Tan, Tieniu			Adversarial Cross-Spectral Face Completion for NIR-VIS Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Heterogeneous face recognition; near infrared-visible matching; face completion; face inpainting	COUPLED DICTIONARY; REGRESSION	Near infrared-visible (NIR-VIS) heterogeneous face recognition refers to the process of matching NIR to VIS face images. Current heterogeneous methods try to extend VIS face recognition methods to the NIR spectrum by synthesizing VIS images from NIR images. However, due to the self-occlusion and sensing gap, NIR face images lose some visible lighting contents so that they are always incomplete compared to VIS face images. This paper models high-resolution heterogeneous face synthesis as a complementary combination of two components: a texture inpainting component and a pose correction component. The inpainting component synthesizes and inpaints VIS image textures from NIR image textures. The correction component maps any pose in NIR images to a frontal pose in VIS images, resulting in paired NIR and VIS textures. A warping procedure is developed to integrate the two components into an end-to-end deep network. A fine-grained discriminator and a wavelet-based discriminator are designed to improve visual quality. A novel 3D-based pose correction loss, two adversarial losses, and a pixel loss are imposed to ensure synthesis results. We demonstrate that by attaching the correction component, we can simplify heterogeneous face synthesis from one-to-many unpaired image translation to one-to-one paired image translation, and minimize the spectral and pose discrepancy during heterogeneous recognition. Extensive experimental results show that our network not only generates high-resolution VIS face images but also facilitates the accuracy improvement of heterogeneous face recognition.	[He, Ran; Cao, Jie; Song, Lingxiao; Sun, Zhenan; Tan, Tieniu] Chinese Acad Sci, Ctr Excellence Brain Sci & Intelligence Technol, Ctr Res Intelligent Percept & Comp, CASIA,Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [He, Ran; Cao, Jie; Song, Lingxiao; Sun, Zhenan; Tan, Tieniu] Univ Chinese Acad Sci, Beijing 100190, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	He, R (corresponding author), Chinese Acad Sci, Ctr Excellence Brain Sci & Intelligence Technol, Ctr Res Intelligent Percept & Comp, CASIA,Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.; He, R (corresponding author), Univ Chinese Acad Sci, Beijing 100190, Peoples R China.	rhe@nlpr.ia.ac.cn; jie.cao@nlpr.ia.ac.cn; lingxiao.song@nlpr.ia.ac.cn; znsun@nlpr.ia.ac.cn; tnt@nlpr.ia.ac.cn	song, ling/GQZ-5934-2022	cao, jie/0000-0001-6368-4495	National Natural Science Foundation of China [61622310]; Beijing Natural Science Foundation [JQ18017]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Natural Science Foundation(Beijing Natural Science Foundation)	The authors would like to greatly thank the associate editor and the reviewers for their valuable comments and advice. This work was supported in part by the National Natural Science Foundation of China under Grant 61622310, and in part by the Beijing Natural Science Foundation under Grant JQ18017.	Booth J, 2014, IEEE IMAGE PROC, P4672, DOI 10.1109/ICIP.2014.7025947; Chen J, 2009, PROC CVPR IEEE, P156, DOI 10.1109/CVPRW.2009.5206832; Deng JK, 2018, PROC CVPR IEEE, P7093, DOI 10.1109/CVPR.2018.00741; Dhamecha TI, 2014, INT C PATT RECOG, P1788, DOI 10.1109/ICPR.2014.314; Gong DH, 2017, IEEE T IMAGE PROCESS, V26, P2079, DOI 10.1109/TIP.2017.2651380; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Goswami D, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS); Gui J, 2018, IEEE DATA MINING, P983, DOI 10.1109/ICDM.2018.00122; He R, 2019, IEEE T PATTERN ANAL, V41, P1761, DOI 10.1109/TPAMI.2018.2842770; He R, 2017, AAAI CONF ARTIF INTE, P2000; Hou CA, 2014, INT C PATT RECOG, P3068, DOI 10.1109/ICPR.2014.529; Huang D., 2012, IRIPTR12FR001 BEIH U, P3; Huang DA, 2013, IEEE I CONF COMP VIS, P2496, DOI 10.1109/ICCV.2013.310; Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267; Huang XS, 2013, IEEE T IMAGE PROCESS, V22, P353, DOI 10.1109/TIP.2012.2215617; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Jin Y, 2017, MULTIDIM SYST SIGN P, V28, P905, DOI 10.1007/s11045-016-0401-8; Jin Y, 2015, IEEE T INF FOREN SEC, V10, P640, DOI 10.1109/TIFS.2015.2390414; Juefei-Xu Felix, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P141, DOI 10.1109/CVPRW.2015.7301308; Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740; Kingma D.P, P 3 INT C LEARNING R; Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229; Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180; Lei Z, 2012, IEEE T INF FOREN SEC, V7, P1707, DOI 10.1109/TIFS.2012.2210041; Lei Z, 2009, PROC CVPR IEEE, P1123, DOI 10.1109/CVPRW.2009.5206860; Lei Z, 2008, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2008.4563043; Lezama J, 2017, PROC CVPR IEEE, P6807, DOI 10.1109/CVPR.2017.720; Li SZ, 2013, IEEE COMPUT SOC CONF, P348, DOI 10.1109/CVPRW.2013.59; Li SZ, 2006, LECT NOTES COMPUT SC, V3832, P151; Li ZF, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2807705; Liao SC, 2009, LECT NOTES COMPUT SC, V5558, P209, DOI 10.1007/978-3-642-01793-3_22; Lin DH, 2006, LECT NOTES COMPUT SC, V3954, P13; Liu XX, 2016, INT CONF BIOMETR; Liu X, 2017, FRONT COMPUT SCI-CHI, V11, P208, DOI 10.1007/s11704-016-6076-3; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Mudunuri SP, 2019, IEEE T INF FOREN SEC, V14, P886, DOI 10.1109/TIFS.2018.2868173; Ouyang SX, 2016, IMAGE VISION COMPUT, V56, P28, DOI 10.1016/j.imavis.2016.09.001; Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58; Peng CL, 2019, IEEE T IMAGE PROCESS, V28, P4553, DOI 10.1109/TIP.2019.2912360; Peng CL, 2019, PATTERN RECOGN, V90, P161, DOI 10.1016/j.patcog.2019.01.041; Reale C, 2016, IEEE COMPUT SOC CONF, P320, DOI 10.1109/CVPRW.2016.47; Riggan BS, 2016, INT CONF BIOMETR THE; Romdhani S, 2005, PROC CVPR IEEE, P986; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sarfraz MS, 2017, INT J COMPUT VISION, V122, P426, DOI 10.1007/s11263-016-0933-2; Saxena S, 2016, LECT NOTES COMPUT SC, V9915, P483, DOI 10.1007/978-3-319-49409-8_40; Shao M, 2017, IEEE T NEUR NET LEAR, V28, P451, DOI 10.1109/TNNLS.2016.2517014; Shao M, 2014, INT J COMPUT VISION, V109, P74, DOI 10.1007/s11263-014-0696-6; Sharma P, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901319; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Song LX, 2018, AAAI CONF ARTIF INTE, P7355; Strasser W., 1974, THESIS, DOI [10.2312/2631196, DOI 10.2312/2631196]; Tang XO, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P687, DOI 10.1109/ICCV.2003.1238414; Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311; Wang R, 2009, LECT NOTES COMPUT SC, V5558, P319, DOI 10.1007/978-3-642-01793-3_33; Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Wu X, 2019, AAAI CONF ARTIF INTE, P9005; Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032; Xiao LH, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS); Yi DW, 2015, INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ARTIFICIAL INTELLIGENCE (ICCSAI 2014), P1; Zhang H, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P100; Zhang MJ, 2019, IEEE T IMAGE PROCESS, V28, P642, DOI 10.1109/TIP.2018.2869688; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zhu JY, 2014, IEEE T INF FOREN SEC, V9, P501, DOI 10.1109/TIFS.2014.2299977	66	41	43	6	49	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2020	42	5					1025	1037		10.1109/TPAMI.2019.2961900	http://dx.doi.org/10.1109/TPAMI.2019.2961900			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LA0ZT	31880541				2022-12-18	WOS:000523685800002
J	Long, Y; Liu, L; Shen, FM; Shao, L; Li, XL				Long, Yang; Liu, Li; Shen, Fumin; Shao, Ling; Li, Xuelong			Zero-Shot Learning Using Synthesised Unseen Visual Data with Diffusion Regularisation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Zero-shot learning; data synthesis; diffusion regularisation; visual-semantic embedding; object recognition	RECOGNITION	Sufficient training examples are the fundamental requirement for most of the learning tasks. However, collecting well-labelled training examples is costly. Inspired by Zero-shot Learning (ZSL) that can make use of visual attributes or natural language semantics as an intermediate level clue to associate low-level features with high-level classes, in a novel extension of this idea, we aim to synthesise training data for novel classes using only semantic attributes. Despite the simplicity of this idea, there are several challenges. First, how to prevent the synthesised data from over-fitting to training classes? Second, how to guarantee the synthesised data is discriminative for ZSL tasks? Third, we observe that only a few dimensions of the learnt features gain high variances whereas most of the remaining dimensions are not informative. Thus, the question is how to make the concentrated information diffuse to most of the dimensions of synthesised data. To address the above issues, we propose a novel embedding algorithm named Unseen Visual Data Synthesis (UVDS) that projects semantic features to the high-dimensional visual feature space. Two main techniques are introduced in our proposed algorithm. (1) We introduce a latent embedding space which aims to reconcile the structural difference between the visual and semantic spaces, meanwhile preserve the local structure. (2) We propose a novel Diffusion Regularisation (DR) that explicitly forces the variances to diffuse over most dimensions of the synthesised data. By an orthogonal rotation (more precisely, an orthogonal transformation), DR can remove the redundant correlated attributes and further alleviate the over-fitting problem. On four benchmark datasets, we demonstrate the benefit of using synthesised unseen data for zero-shot learning. Extensive experimental results suggest that our proposed approach significantly outperforms the state-of-the-art methods.	[Long, Yang] Univ Newcastle, Sch Comp Sci, OpenLab, Newcastle Upon Tyne NE4 5TG, Tyne & Wear, England; [Liu, Li; Shao, Ling] Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates; [Liu, Li; Shao, Ling] Univ East Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England; [Shen, Fumin] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Sichuan, Peoples R China; [Li, Xuelong] Chinese Acad Sci, Xian Inst Opt & Precis Mech, Xian 710119, Shaanxi, Peoples R China	Newcastle University - UK; University of East Anglia; University of Electronic Science & Technology of China; Chinese Academy of Sciences; Xi'an Institute of Optics & Precision Mechanics, CAS	Shao, L (corresponding author), Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates.	yang.long@ieee.org; fumin.shen@gmail.com; ling.shao@ieee.org; xuelong_li@opt.ac.cn	Li, Xuelong/ABF-3381-2020; Shao, Ling/D-3535-2011; Long, Yang/X-4184-2019; Li, Xuelong/Z-3785-2019; li, xiang/GWM-6319-2022; Shen, Heng Tao/ABD-5331-2021	Long, Yang/0000-0002-2445-6112; Shao, Ling/0000-0002-8264-6117; Li, Xuelong/0000-0002-0019-4197	National Natural Science Foundation of China [61528106]; MRC [MR/S003916/1] Funding Source: UKRI	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); MRC(UK Research & Innovation (UKRI)Medical Research Council UK (MRC))	This work was supported in part by National Natural Science Foundation of China under Grant 61528106.	Akata Z, 2016, PROC CVPR IEEE, P59, DOI 10.1109/CVPR.2016.14; Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911; Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111; Akata Zeynep, 2017, P IEEE C COMP VIS PA; Al-Halah Z, 2015, IEEE WINT CONF APPL, P837, DOI 10.1109/WACV.2015.116; [Anonymous], 2014, P INT C LEARN REPR; Ba JL, 2015, IEEE I CONF COMP VIS, P4247, DOI 10.1109/ICCV.2015.483; Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231; Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575; Chao WL, 2016, LECT NOTES COMPUT SC, V9906, P52, DOI 10.1007/978-3-319-46475-6_4; Chen X., 2016, P 28 INT C NEUR INF; Elhoseiny M, 2013, IEEE I CONF COMP VIS, P2584, DOI 10.1109/ICCV.2013.321; Fang XZ, 2017, NEURAL NETWORKS, V88, P1, DOI 10.1016/j.neunet.2017.01.001; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Frome Andrea, 2013, NEURIPS; Fu YW, 2015, IEEE T PATTERN ANAL, V37, P2332, DOI 10.1109/TPAMI.2015.2408354; Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P584, DOI 10.1007/978-3-319-10605-2_38; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; He XF, 2016, IEEE T PATTERN ANAL, V38, P1009, DOI 10.1109/TPAMI.2015.2439252; Jayaraman D, 2014, ADV NEUR IN, V27; Jayaraman D, 2014, PROC CVPR IEEE, P1629, DOI 10.1109/CVPR.2014.211; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Kong W., 2012, P NIPS, P1646; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Larochelle H., 2008, P 23 AAAI C ART INT, P646; Liang KM, 2015, IEEE I CONF COMP VIS, P2506, DOI 10.1109/ICCV.2015.288; Liu L, 2017, INT J COMPUT VISION, V122, P439, DOI 10.1007/s11263-016-0931-4; Liu W., 2011, P 29 INT C MACH LEAR; Long Y., 2016, P BRIT MACH VIS C; Long Y., 2017, P 19 ACM INT C MULT; Long Y, 2017, IEEE WINT CONF APPL, P944, DOI 10.1109/WACV.2017.110; Long Y, 2017, IEEE WINT CONF APPL, P907, DOI 10.1109/WACV.2017.106; Long Yang, 2017, P IEEE C COMP VIS PA; Mensink T, 2014, PROC CVPR IEEE, P2441, DOI 10.1109/CVPR.2014.313; Mikolov Tomas., 2013, ADV NEURAL INF PROCE, V2, P3111, DOI DOI 10.5555/2999792.2999959; Mu N, 2017, IEEE INT C ELECTR TA; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Palatucci Mark, 2009, ADV NEURAL INFORM PR, P1410; Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281; Patterson G, 2014, INT J COMPUT VISION, V108, P59, DOI 10.1007/s11263-013-0695-z; Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13; Rohrbach M, 2011, PROC CVPR IEEE, P1641, DOI 10.1109/CVPR.2011.5995627; Rohrbach M, 2010, PROC CVPR IEEE, P910, DOI 10.1109/CVPR.2010.5540121; Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152; Sharmanska V, 2012, LECT NOTES COMPUT SC, V7576, P242, DOI 10.1007/978-3-642-33715-4_18; Simonyan K., 2014, 14091556 ARXIV; Socher Richard, 2013, NEURIPS; Wah C., 2011, CALTECHUCSD BIRDS 20; Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994; Wen ZW, 2013, MATH PROGRAM, V142, P397, DOI 10.1007/s10107-012-0584-1; Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15; Xu B, 2013, P INT JOINT C ART IN, P1820; Yu FLX, 2013, PROC CVPR IEEE, P771, DOI 10.1109/CVPR.2013.105; Yu MY, 2016, IEEE T PATTERN ANAL, V38, P1908, DOI 10.1109/TPAMI.2015.2497686; Yu MY, 2016, IEEE T PATTERN ANAL, V38, P1651, DOI 10.1109/TPAMI.2015.2491925; Yu XD, 2010, LECT NOTES COMPUT SC, V6315, P127; Zhang WZ, 2017, IEEE T PATTERN ANAL, V39, P1223, DOI 10.1109/TPAMI.2016.2578323; Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474; ZHANG ZM, 2016, PROC CVPR IEEE, P6034, DOI DOI 10.1109/CVPR.2016.649; Zhou D., 2007, P 24 INT C MACHINE L, P1159, DOI DOI 10.1145/1273496.1273642; Zhou DY, 2004, ADV NEUR IN, V16, P321	63	41	42	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2018	40	10					2498	2512		10.1109/TPAMI.2017.2762295	http://dx.doi.org/10.1109/TPAMI.2017.2762295			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GS7IZ		Green Accepted			2022-12-18	WOS:000443875500016
J	Gilani, SZ; Mian, A; Shafait, F; Reid, I				Gilani, Syed Zulqarnain; Mian, Ajmal; Shafait, Faisal; Reid, Ian			Dense 3D Face Correspondence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dense correspondence; 3D face; morphing; keypoint detection; level sets; geodesic curves; deformable model	NONRIGID REGISTRATION; SHAPE CORRESPONDENCE; KEYPOINT DETECTION; RECOGNITION; MODEL; OPTIMIZATION; EXPRESSIONS	We present an algorithm that automatically establishes dense correspondences between a large number of 3D faces. Starting from automatically detected sparse correspondences on the outer boundary of 3D faces, the algorithm triangulates existing correspondences and expands them iteratively by matching points of distinctive surface curvature along the triangle edges. After exhausting keypoint matches, further correspondences are established by generating evenly distributed points within triangles by evolving level set geodesic curves from the centroids of large triangles. A deformable model (K3DM) is constructed from the dense corresponded faces and an algorithm is proposed for morphing the K3DM to fit unseen faces. This algorithm iterates between rigid alignment of an unseen face followed by regularized morphing of the deformable model. We have extensively evaluated the proposed algorithms on synthetic data and real 3D faces from the FRGCv2, Bosphorus, BU3DFE and UND Ear databases using quantitative and qualitative benchmarks. Our algorithm achieved dense correspondences with a mean localisation error of 1.28 mm on synthetic faces and detected 14 anthropometric landmarks on unseen real faces from the FRGCv2 database with 3 mm precision. Furthermore, our deformable model fitting algorithm achieved 98.5 percent face recognition accuracy on the FRGCv2 and 98.6 percent on Bosphorus database. Our dense model is also able to generalize to unseen datasets.	[Gilani, Syed Zulqarnain; Mian, Ajmal; Shafait, Faisal] Univ Western Australia, Sch Comp Sci & Software Engn, 35 Stirling Highway, Crawley, WA 6009, Australia; [Reid, Ian] Univ Adelaide, Sch Comp Sci, North Terrace Campus, Adelaide, SA 5005, Australia	University of Western Australia; University of Adelaide	Gilani, SZ (corresponding author), Univ Western Australia, Sch Comp Sci & Software Engn, 35 Stirling Highway, Crawley, WA 6009, Australia.	syedzulqarnain.gilani@research.uwa.edu.au; ajmal.mian@uwa.edu.au; faisal.shafait@uwa.edu.au; ian.reid@adelaide.edu.au	Gilani, Syed Zulqarnain/AAJ-8482-2021	Gilani, Syed Zulqarnain/0000-0002-7448-2327; Mian, Ajmal/0000-0002-5206-3842; Reid, Ian/0000-0001-7790-6423	ARC [DP110102399, DP160101458]; Australian Research Council [CE140100016, FL130100102]	ARC(Australian Research Council); Australian Research Council(Australian Research Council)	This research was supported by ARC Discovery Grants DP110102399 and DP160101458. I. Reid gratefully acknowledges the financial support of the Australian Research Council through grants CE140100016 and FL130100102.	Aiger D., 2008, ACM T GRAPHIC, V27; Al-Osaimi F, 2009, INT J COMPUT VISION, V81, P302, DOI 10.1007/s11263-008-0174-0; Alexa M, 2002, COMPUT GRAPH FORUM, V21, P173, DOI 10.1111/1467-8659.00575; Alyuz N., 2008, 2 IEEE INT C BIOM TH, P1; Amberg Brian, 2007, CVPR '07. IEEE Conference on Computer Vision and Pattern Recognition, P1; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Berretti S, 2013, COMPUT GRAPH-UK, V37, P509, DOI 10.1016/j.cag.2013.04.001; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Blanz V., 2007, P IEEE 11 INT C COMP, P1; Bolkart T, 2016, PROC CVPR IEEE, P4911, DOI 10.1109/CVPR.2016.531; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598; BOWYER K., 2006, P 3 INT S 3D DAT PRO, P326, DOI DOI 10.1109/3DPVT.2006.25; Brown BJ, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239472; Chang W, 2008, COMPUT GRAPH FORUM, V27, P1459, DOI 10.1111/j.1467-8659.2008.01286.x; Colombo A, 2011, J MATH IMAGING VIS, V40, P105, DOI 10.1007/s10851-010-0252-0; Creusot C, 2013, INT J COMPUT VISION, V102, P146, DOI 10.1007/s11263-012-0605-9; Davies RH, 2002, LECT NOTES COMPUT SC, V2352, P3; Dehghan A., 2014, P IEEE C COMP VIS PA, P171; Drira H, 2013, IEEE T PATTERN ANAL, V35, P2270, DOI 10.1109/TPAMI.2013.48; Erico J. D, 2008, MATLAB CENTRAL FILE; Farkas Leslie G., 1994, P71; Funkhouser T., 2006, PROC EUROGRAPHICS S, P131; Gilani SZ, 2017, PATTERN RECOGN, V69, P238, DOI 10.1016/j.patcog.2017.04.013; Gilani SZ, 2015, PROC CVPR IEEE, P4639, DOI 10.1109/CVPR.2015.7299095; Gilani SZ, 2015, J NEURODEV DISORD, V7, DOI 10.1186/s11689-015-9109-6; Gilani SZ, 2014, INT C PATT RECOG, P2413, DOI 10.1109/ICPR.2014.418; Gilani SZ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099483; Gilani SZ, 2014, IEEE WINT CONF APPL, P191, DOI 10.1109/WACV.2014.6836102; Gilani SZ, 2013, 2013 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES & APPLICATIONS (DICTA), P96; Gonzalez R.C., 2006, DIGITAL IMAGE PROCES; Guo YL, 2013, INT J COMPUT VISION, V105, P63, DOI 10.1007/s11263-013-0627-y; Hammond P, 2007, ARCH DIS CHILD, V92, P1120, DOI 10.1136/adc.2006.103507; Heimann T, 2009, MED IMAGE ANAL, V13, P543, DOI 10.1016/j.media.2009.05.004; Hochheiser H, 2011, DEV BIOL, V355, P175, DOI 10.1016/j.ydbio.2011.02.033; Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017; Kim V., 2011, P SIGGRAPH, V30, P4; Kraevoy V, 2004, ACM T GRAPHIC, V23, P861, DOI 10.1145/1015706.1015811; Kroon D. -J., 2009, MATLAB CENTRAL FILE; Li H, 2008, COMPUT GRAPH FORUM, V27, P1421, DOI 10.1111/j.1467-8659.2008.01282.x; Li H, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1618452.1618521, 10.1145/1618452.1618503]; Li HB, 2015, INT J COMPUT VISION, V113, P128, DOI 10.1007/s11263-014-0785-6; Lu XG, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P585; Mian A, 2010, INT J COMPUT VISION, V89, P348, DOI 10.1007/s11263-009-0296-z; Mian AS, 2008, INT J COMPUT VISION, V79, P1, DOI 10.1007/s11263-007-0085-5; Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105; Mirzaalian H, 2009, PROC CVPR IEEE, P2152, DOI 10.1109/CVPRW.2009.5206725; Munsell BC, 2008, IEEE T PATTERN ANAL, V30, P2023, DOI 10.1109/TPAMI.2007.70841; Munsell BC, 2009, PROC CVPR IEEE, P840, DOI 10.1109/CVPRW.2009.5206611; Nair P, 2009, IEEE T MULTIMEDIA, V11, P611, DOI 10.1109/TMM.2009.2017629; Novatnack J, 2008, LECT NOTES COMPUT SC, V5304, P440, DOI 10.1007/978-3-540-88690-7_33; Oosterhof NN, 2008, P NATL ACAD SCI USA, V105, P11087, DOI 10.1073/pnas.0805664105; Passalis G., 2005, P IEEE WORKSH FAC RE, P171, DOI DOI 10.1109/CVPR.2005.573; Passalis G, 2011, IEEE T PATTERN ANAL, V33, P1938, DOI 10.1109/TPAMI.2011.49; Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58; Perakis P, 2014, PATTERN RECOGN, V47, P2783, DOI 10.1016/j.patcog.2014.03.007; Perakis P, 2013, IEEE T PATTERN ANAL, V35, P1552, DOI 10.1109/TPAMI.2012.247; Peyre G, 2011, COMPUT SCI ENG, V13, P94, DOI 10.1109/MCSE.2011.71; Phillips PJ, 2005, PROC CVPR IEEE, P947; Prabhu U, 2011, IEEE T PATTERN ANAL, V33, P1952, DOI 10.1109/TPAMI.2011.123; Queirolo CC, 2010, IEEE T PATTERN ANAL, V32, P206, DOI 10.1109/TPAMI.2009.14; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Salazar A, 2014, MACH VISION APPL, V25, P859, DOI 10.1007/s00138-013-0579-9; Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6; Segundo MP, 2010, IEEE T SYST MAN CY B, V40, P1319, DOI 10.1109/TSMCB.2009.2038233; Sethian JA, 2001, J COMPUT PHYS, V169, P503, DOI 10.1006/jcph.2000.6657; Smeets D, 2013, COMPUT VIS IMAGE UND, V117, P158, DOI 10.1016/j.cviu.2012.10.002; Sukno FM, 2015, IEEE T CYBERNETICS, V45, P1717, DOI 10.1109/TCYB.2014.2359056; Sun Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P263, DOI 10.1109/ICCV.2001.937634; Sun YY, 2003, IEEE T SYST MAN CY B, V33, P712, DOI 10.1109/TSMCB.2003.814295; Szeptycki P., 2009, IEEE 3 INT C BIOM TH, P1, DOI DOI 10.1109/BTAS.2009.5339052; Todorov A, 2008, SOC COGN AFFECT NEUR, V3, P119, DOI 10.1093/scan/nsn009; Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26; van Kaick O, 2011, COMPUT GRAPH FORUM, V30, P1681, DOI 10.1111/j.1467-8659.2011.01884.x; Varun J., 2007, INT J SHAPE MODELING, V13, P101, DOI DOI 10.1142/S0218654307000968; Wang S, 2007, IEEE T PATTERN ANAL, V29, P1209, DOI 10.1109/TPAMI.2007.1050; Whitehouse AJO, 2015, P ROY SOC B-BIOL SCI, V282, DOI 10.1098/rspb.2015.1351; Yan P., 2005, P 2005 IEEE COMPUTER, P41, DOI [DOI 10.1109/CVPR.2005.450, 10.1109/CVPR.2005.450]; Zhang H, 2008, COMPUT GRAPH FORUM, V27, P1431, DOI 10.1111/j.1467-8659.2008.01283.x	81	41	41	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2018	40	7					1584	1598		10.1109/TPAMI.2017.2725279	http://dx.doi.org/10.1109/TPAMI.2017.2725279			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GI3TS	28708544	Green Submitted			2022-12-18	WOS:000434294800004
J	Gebru, ID; Ba, S; Li, XF; Horaud, R				Gebru, Israel D.; Ba, Sileye; Li, Xiaofei; Horaud, Radu			Audio-Visual Speaker Diarization Based on Spatiotemporal Bayesian Fusion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Speaker diarization; audio-visual tracking; dynamic Bayesian network; sound source localization	BLIND SOURCE SEPARATION; LOCALIZATION; TRACKING	Speaker diarization consists of assigning speech signals to people engaged in a dialogue. An audio-visual spatiotemporal diarization model is proposed. The model is well suited for challenging scenarios that consist of several participants engaged in multi-party interaction while they move around and turn their heads towards the other participants rather than facing the cameras and the microphones. Multiple-person visual tracking is combined with multiple speech-source localization in order to tackle the speech-to-person association problem. The latter is solved within a novel audio-visual fusion method on the following grounds: binaural spectral features are first extracted from a microphone pair, then a supervised audio-visual alignment technique maps these features onto an image, and finally a semi-supervised clustering method assigns binaural spectral features to visible persons. The main advantage of this method over previous work is that it processes in a principled way speech signals uttered simultaneously by multiple persons. The diarization itself is cast into a latent-variable temporal graphical model that infers speaker identities and speech turns, based on the output of an audio-visual association process, executed at each time slice, and on the dynamics of the diarization variable itself. The proposed formulation yields an efficient exact inference procedure. A novel dataset, that contains audio-visual training data as well as a number of scenarios involving several participants engaged in formal and informal dialogue, is introduced. The proposed method is thoroughly tested and benchmarked with respect to several state-of-the art diarization algorithms.	[Gebru, Israel D.; Ba, Sileye; Li, Xiaofei; Horaud, Radu] INRIA Grenoble Rhone Alpes, F-38330 Montbonnot St Martin, France		Gebru, ID (corresponding author), INRIA Grenoble Rhone Alpes, F-38330 Montbonnot St Martin, France.	israel-dejene.gebru@inria.fr; sileye.ba@inria.fr; xiaofei.li@inria.fr; radu.horaud@inria.fr	Li, xiaofei/GXF-7187-2022; Gebru, Israel D/ABA-4507-2021; Gebru, Israel Dejene/W-2439-2019; Horaud, Radu/AAR-5982-2021	Gebru, Israel Dejene/0000-0003-1433-5891; Horaud, Radu/0000-0001-5232-024X	European Union FP7 ERC Advanced Grant VHIA [340113]; XEROX University Affairs Committee (UAC) grant	European Union FP7 ERC Advanced Grant VHIA; XEROX University Affairs Committee (UAC) grant	Funding from the European Union FP7 ERC Advanced Grant VHIA (\#340113) and from XEROX University Affairs Committee (UAC) grant (2015-2017) is greatly acknowledged.	Alameda-Pineda X, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P5, DOI 10.1145/2733373.2806238; Miro XA, 2012, IEEE T AUDIO SPEECH, V20, P356, DOI 10.1109/TASL.2011.2125954; [Anonymous], 2015, P IEEE INT C COMP VI; Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159; Barzelay Z, 2010, IEEE T MULTIMEDIA, V12, P108, DOI 10.1109/TMM.2009.2037387; Blandin C, 2012, SIGNAL PROCESS, V92, P1950, DOI 10.1016/j.sigpro.2011.09.032; Bohus D., 2011, P 13 INT C MULT INT, P153, DOI DOI 10.1145/2070481.2070507; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Carletta J, 2005, LECT NOTES COMPUT SC, V3869, P28; Deleforge A, 2015, IEEE-ACM T AUDIO SPE, V23, P718, DOI 10.1109/TASLP.2015.2405475; Dorfan Y, 2015, IEEE-ACM T AUDIO SPE, V23, P1692, DOI 10.1109/TASLP.2015.2444654; El Khoury E, 2014, MULTIMED TOOLS APPL, V68, P747, DOI 10.1007/s11042-012-1080-6; Fisher J. W., 2000, ADV NEURAL INFORM PR, P772; Garau G., 2010, P INT C SPEECH LANG, P2654; Gatica-Perez D, 2007, IEEE T AUDIO SPEECH, V15, P601, DOI 10.1109/TASL.2006.881678; GEBRU ID, 2015, P INT C LAT VAR AN S, V9237, P143, DOI DOI 10.1007/978-3-319-22482-4_17; Gebru ID, 2016, IEEE T PATTERN ANAL, V38, P2402, DOI 10.1109/TPAMI.2016.2522425; Hershey J, 2000, ADV NEUR IN, V12, P813; Kapsouras I, 2017, MULTIMED TOOLS APPL, V76, P2223, DOI 10.1007/s11042-015-3181-5; Khalidov V, 2013, IEEE INT WORKSH MULT, P242, DOI 10.1109/MMSP.2013.6659295; Khalidov V, 2011, NEURAL COMPUT, V23, P517, DOI 10.1162/NECO_a_00074; Kidron E, 2005, PROC CVPR IEEE, P88; Kidron E, 2007, IEEE T SIGNAL PROCES, V55, P1390, DOI 10.1109/TSP.2006.888095; Kilic V, 2015, IEEE T MULTIMEDIA, V17, P186, DOI 10.1109/TMM.2014.2377515; Lathoud G, 2005, LECT NOTES COMPUT SC, V3361, P182; Li X., 2015, P EUR SIGN PROC C AU; Li XF, 2016, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.2016.7471661; Li XF, 2015, INT CONF ACOUST SPEE, P320, DOI 10.1109/ICASSP.2015.7177983; Mandel MI, 2010, IEEE T AUDIO SPEECH, V18, P382, DOI 10.1109/TASL.2009.2029711; Minotto VP, 2015, IEEE T MULTIMEDIA, V17, P1694, DOI 10.1109/TMM.2015.2463722; Naqvi SM, 2010, IEEE J-STSP, V4, P895, DOI 10.1109/JSTSP.2010.2057198; Nock HJ, 2003, LECT NOTES COMPUT SC, V2728, P488; Noulas A, 2012, IEEE T PATTERN ANAL, V34, P79, DOI 10.1109/TPAMI.2011.47; Noulas AK, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P350; Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150; Rivet B, 2007, IEEE T AUDIO SPEECH, V15, P96, DOI 10.1109/TASL.2006.872619; Sarafianos N, 2016, MULTIMED TOOLS APPL, V75, P115, DOI 10.1007/s11042-014-2274-x; Sargin ME, 2007, IEEE T MULTIMEDIA, V9, P1396, DOI 10.1109/TMM.2007.906583; Siracusa MR, 2007, INT CONF ACOUST SPEE, P457; Skantze G, 2014, SPEECH COMMUN, V65, P50, DOI 10.1016/j.specom.2014.05.005; Van Veen B. D., 1988, IEEE ASSP Magazine, V5, P4, DOI 10.1109/53.665; Vijayasenan D., 2012, INTERSPEECH, P2170; Wooters C, 2008, LECT NOTES COMPUT SC, V4625, P509; Yan Y, 2013, IEEE I CONF COMP VIS, P1177, DOI 10.1109/ICCV.2013.150; Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X	45	41	42	2	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2018	40	5					1086	1099		10.1109/TPAMI.2017.2648793	http://dx.doi.org/10.1109/TPAMI.2017.2648793			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GB2RB	28103192	Green Submitted			2022-12-18	WOS:000428901200006
J	Qi, GJ; Liu, W; Aggarwal, C; Huang, T				Qi, Guo-Jun; Liu, Wei; Aggarwal, Charu; Huang, Thomas			Joint Intermodal and Intramodal Label Transfers for Extremely Rare or Unseen Classes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multimodal analysis; intermodal and intramodal label transfers (I2LT); image classification; zero-shot learning	LATENT; FEATURES	In this paper, we present a label transfer model from texts to images for image classification tasks. The problem of image classification is often much more challenging than text classification. On one hand, labeled text data is more widely available than the labeled images for classification tasks. On the other hand, text data tends to have natural semantic interpretability, and they are often more directly related to class labels. On the contrary, the image features are not directly related to concepts inherent in class labels. One of our goals in this paper is to develop a model for revealing the functional relationships between text and image features as to directly transfer intermodal and intramodal labels to annotate the images. This is implemented by learning a transfer function as a bridge to propagate the labels between two multimodal spaces. However, the intermodal label transfers could be undermined by blindly transferring the labels of noisy texts to annotate images. To mitigate this problem, we present an intramodal label transfer process, which complements the intermodal label transfer by transferring the image labels instead when relevant text is absent from the source corpus. In addition, we generalize the inter-modal label transfer to zero-shot learning scenario where there are only text examples available to label unseen classes of images without any positive image examples. We evaluate our algorithm on an image classification task and show the effectiveness with respect to the other compared algorithms.	[Qi, Guo-Jun] Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA; [Liu, Wei; Aggarwal, Charu] IBM Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA; [Huang, Thomas] Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA	State University System of Florida; University of Central Florida; International Business Machines (IBM); University of Illinois System; University of Illinois Urbana-Champaign	Qi, GJ (corresponding author), Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA.	guojun.qi@ucf.edu; weiliu@us.ibm.com; charu@us.ibm.com; huang@ifp.uiuc.edu	Qi, Guo-Jun/AAH-8294-2019	Liu, Wei/0000-0002-3865-8145; Qi, Guo-Jun/0000-0003-3508-1851	US National Science Foundation [16406218]	US National Science Foundation(National Science Foundation (NSF))	The first author was partly supported by US National Science Foundation grant 16406218. We also would like to thank the anonymous reviewers for bringing the zero-shot learning problem into our attention, which inspires us to study the applicability of the proposed approach to this problem.	Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911; Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111; Amit Y., 2007, ICML 07 P 24 INT C M, P17, DOI DOI 10.1145/1273496.1273499; Bach F.R., 2004, P 21 INT C MACHINE L, P6, DOI 10.1145/ 1015330.1015424; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Bo LF, 2010, INT J COMPUT VISION, V87, P28, DOI 10.1007/s11263-008-0204-y; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Chen YX, 2014, IEEE T CIRC SYST VID, V24, P1992, DOI 10.1109/TCSVT.2014.2329380; Chua Tat-Seng, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646452; Cristianini Nello, 2000, INTRO SUPPORT VECTOR, DOI DOI 10.1017/CBO9780511801389; Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPR.2009.5206747, 10.1109/CVPRW.2009.5206747]; Elhoseiny M, 2013, IEEE I CONF COMP VIS, P2584, DOI 10.1109/ICCV.2013.321; Fu YW, 2014, IEEE T PATTERN ANAL, V36, P303, DOI 10.1109/TPAMI.2013.128; Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hofmann T, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P289; Huang T, 2011, P 20 INT C WORLD WID, P297, DOI DOI 10.1145/1963405.1963449; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028; Li W, 2014, LECT NOTES COMPUT SC, V8693, P437, DOI 10.1007/978-3-319-10602-1_29; Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Masci J, 2014, IEEE T PATTERN ANAL, V36, P824, DOI 10.1109/TPAMI.2013.225; Moon S., 2014, ARXIV14123121; Ngiam Jiquan, 2011, ICML, DOI DOI 10.5555/3104482.3104569; Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47; Niu L., 2015, INT J COMPUT VISION, V118, P1; Ordonez Vicente, 2011, ADV NEURAL INFORM PR, P1143; Palatucci Mark, 2009, ADV NEURAL INFORM PR, P1410; Qi G.-J., 2009, P 17 ACM INT C MULT, P243; Qi GJ, 2012, IEEE T PATTERN ANAL, V34, P850, DOI 10.1109/TPAMI.2011.191; Qi GJ, 2011, PROC CVPR IEEE, P897, DOI 10.1109/CVPR.2011.5995312; Raina R., 2007, LEARNING, P759, DOI DOI 10.1145/1273496.1273592; Raina R., 2006, PROC 23 INT C MACH L, P713, DOI DOI 10.1145/1143844.1143934; Rosenstein M. T., 2005, P NIPS WORKSH TRANSF, V898, P1; Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899; Srebro N., 2005, P ADV NEURAL INFORM; Toh KC, 2010, PAC J OPTIM, V6, P615; Venugopalan Subhashini, 2014, ARXIV14124729; Welinder P., 2010, CNSTR2010001 CALTECH; Wu, 2004, P 21 INT C MACH LEAR, P110; Yang Q., 2009, P JOINT C 47 ANN M A, P1; Zhu M., 2004, RECALL PRECISION AVE; Zhu Y., 2011, P 25 AAAI C ART INT	49	41	42	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2017	39	7					1360	1373		10.1109/TPAMI.2016.2587643	http://dx.doi.org/10.1109/TPAMI.2016.2587643			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EW8BZ	27392343	hybrid, Green Submitted			2022-12-18	WOS:000402744400007
J	Feng, LN; Bhanu, B				Feng, Linan; Bhanu, Bir			Semantic Concept Co-Occurrence Patterns for Image Annotation and Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Community detection; contextual information; hierarchical co-occurrence patterns; image concept signature	OBJECT; DATABASE; SCALE; SCENE	Describing visual image contents by semantic concepts is an effective and straightforward way to facilitate various high level applications. Inferring semantic concepts from low-level pictorial feature analysis is challenging due to the semantic gap problem, while manually labeling concepts is unwise because of a large number of images in both online and offline collections. In this paper, we present a novel approach to automatically generate intermediate image descriptors by exploiting concept co-occurrence patterns in the pre-labeled training set that renders it possible to depict complex scene images semantically. Our work is motivated by the fact that multiple concepts that frequently co-occur across images form patterns which could provide contextual cues for individual concept inference. We discover the co-occurrence patterns as hierarchical communities by graph modularity maximization in a network with nodes and edges representing concepts and co-occurrence relationships separately. A random walk process working on the inferred concept probabilities with the discovered co-occurrence patterns is applied to acquire the refined concept signature representation. Through experiments in automatic image annotation and semantic image retrieval on several challenging datasets, we demonstrate the effectiveness of the proposed concept co-occurrence patterns as well as the concept signature representation in comparison with state-of-the-art approaches.	[Feng, Linan] Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA; [Bhanu, Bir] Univ Calif Riverside, Ctr Res Intelligent Syst, Riverside, CA 92521 USA	University of California System; University of California Riverside; University of California System; University of California Riverside	Feng, LN (corresponding author), Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.; Bhanu, B (corresponding author), Univ Calif Riverside, Ctr Res Intelligent Syst, Riverside, CA 92521 USA.	fengl@cs.ucr.edu; bhanu@cris.ucr.edu		Bhanu, Bir/0000-0001-8971-6416	National Science Foundation [0905671, 1552454]	National Science Foundation(National Science Foundation (NSF))	This material is based upon work supported by the National Science Foundation under Grant No. 0905671 and 1552454.	[Anonymous], [No title captured]; [Anonymous], [No title captured]; Aslandogan YA, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P286, DOI 10.1145/278459.258591; Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008; Bosch A., 2007, P 6 ACM INT C IM VID, V5, P401, DOI [10.1145/1282280.1282340, DOI 10.1145/1282280]; Bourdev L, 2011, IEEE I CONF COMP VIS, P1543, DOI 10.1109/ICCV.2011.6126413; Cacheda F, 2011, ACM T WEB, V5, DOI 10.1145/1921591.1921593; Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Desai C, 2011, INT J COMPUT VISION, V95, P1, DOI 10.1007/s11263-011-0439-x; Dill S, 2003, P 12 INT C WORLD WID, P178; Divvala SK, 2009, PROC CVPR IEEE, P1271, DOI 10.1109/CVPRW.2009.5206532; Douze M, 2011, PROC CVPR IEEE, P745, DOI 10.1109/CVPR.2011.5995595; Fan JP, 2008, IEEE T IMAGE PROCESS, V17, P407, DOI 10.1109/TIP.2008.916999; Fan JP, 2008, IEEE T MULTIMEDIA, V10, P167, DOI 10.1109/TMM.2007.911775; Farhadi A, 2010, PROC CVPR IEEE, P2352, DOI 10.1109/CVPR.2010.5539924; Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002; Fu G, 2011, PATTERN RECOGN, V44, P284, DOI 10.1016/j.patcog.2010.08.027; Galleguillos C, 2008, PROC CVPR IEEE, P3552; GOLDBERG D, 1992, COMMUN ACM, V35, P61, DOI 10.1145/138859.138867; Hsu W.H., 2007, P ACM INT C MULT, P971, DOI DOI 10.1145/1291233.1291446.ISBN; Hu YQ, 2008, PHYS REV E, V78, DOI 10.1103/PhysRevE.78.016115; Hwang SJ, 2012, IEEE T PATTERN ANAL, V34, P1145, DOI 10.1109/TPAMI.2011.190; Jia D, 2011, PROC CVPR IEEE, P785, DOI 10.1109/CVPR.2011.5995516; Jianping Fan, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P111; Jin YH, 2005, LECT NOTES COMPUT SC, V3665, P115; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Lavrenko V, 2003, P ADV NEUR INF PROC; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Li Zheng, 2010, Proceedings of the SICE 2010 - 49th Annual Conference of the Society of Instrument and Control Engineers of Japan, P1187, DOI 10.1145/1873951.1874183; Liu D., 2009, P 18 INT C WORLD WID, P351; Liu Y., 2006, AAAI, P421; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Luo X, 2014, IEEE T IND INFORM, V10, P1273, DOI 10.1109/TII.2014.2308433; Ma H, 2010, IEEE T MULTIMEDIA, V12, P462, DOI 10.1109/TMM.2010.2051360; Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Mitrovic M, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.026123; Newman MEJ, 2004, PHYS REV E, V70, DOI [10.1103/PhysRevE.70.056131, 10.1103/PhysRevE.69.026113]; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Ordonez Vicente, 2011, ADV NEURAL INFORM PR, P1143; Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Shechtman E, 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383198; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; Siddiquie B, 2011, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2011.5995329; Su H., 2010, ADV NEURAL PROCESSIN, V1, P1378; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Torralba A., 2004, NEURAL INFORM PROCES; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56; Uchihashi S, 2005, LECT NOTES COMPUT SC, V3568, P650; Wang Y, 2010, LECT NOTES COMPUT SC, V6315, P155, DOI 10.1007/978-3-642-15555-0_12; Wu L, 2012, IEEE T PATTERN ANAL, V34, P863, DOI 10.1109/TPAMI.2011.195; Xiang Y, 2010, PROC CVPR IEEE, P3368, DOI 10.1109/CVPR.2010.5540015; Yohan Jin, 2005, 13th Annual ACM International Conference on Multimedia, P706; Yu FX, 2012, PROC CVPR IEEE, P2949, DOI 10.1109/CVPR.2012.6248023; Zhou N, 2011, IEEE T PATTERN ANAL, V33, P1281, DOI 10.1109/TPAMI.2010.204	64	41	43	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2016	38	4					785	799		10.1109/TPAMI.2015.2469281	http://dx.doi.org/10.1109/TPAMI.2015.2469281			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DH1MW	26959678	Green Published			2022-12-18	WOS:000372549700014
J	Kamyshanska, H; Memisevic, R				Kamyshanska, Hanna; Memisevic, Roland			The Potential Energy of an Autoencoder	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Autoencoders; representation learning; unsupervised learning; generative classification	STATISTICAL-MODELS	Autoencoders are popular feature learning models, that are conceptually simple, easy to train and allow for efficient inference. Recent work has shown how certain autoencoders can be associated with an energy landscape, akin to negative log-probability in a probabilistic model, which measures how well the autoencoder can represent regions in the input space. The energy landscape has been commonly inferred heuristically, by using a training criterion that relates the autoencoder to a probabilistic model such as a Restricted Boltzmann Machine (RBM). In this paper we show how most common autoencoders are naturally associated with an energy function, independent of the training procedure, and that the energy landscape can be inferred analytically by integrating the reconstruction function of the autoencoder. For autoencoders with sigmoid hidden units, the energy function is identical to the free energy of an RBM, which helps shed light onto the relationship between these two types of model. We also show that the autoencoder energy function allows us to explain common regularization procedures, such as contractive training, from the perspective of dynamical systems. As a practical application of the energy function, a generative classifier based on class-specific autoencoders is presented.	[Kamyshanska, Hanna] Frankfurt Inst Adv Studies, Dept Computat Neurosci, D-60438 Frankfurt, Germany; [Memisevic, Roland] Univ Montreal, Dept Comp Sci, Montreal, PQ H3C 3J7, Canada	Universite de Montreal	Kamyshanska, H (corresponding author), Frankfurt Inst Adv Studies, Dept Computat Neurosci, Ruth Moufang Str 1, D-60438 Frankfurt, Germany.	kamyshanska@fias.uni-frankfurt.de; roland.memisevic@umontreal.ca			German Federal Ministry of Education and Research (BMBF) [01GQ0841]; NSERC	German Federal Ministry of Education and Research (BMBF)(Federal Ministry of Education & Research (BMBF)); NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC))	This work was supported in part by the German Federal Ministry of Education and Research (BMBF) in the project 01GQ0841 (BFNT Frankfurt), and by an NSERC discovery grant. We also thank the reviewers for several useful suggestions.	ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; Alain G., 2013, P INT C LEARN REPR; Alain G., 2012, 1211 ARXIV U MONTR; [Anonymous], 2006, IEEE T AUTOM SCI ENG; BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2; Bengio Y., 2007, P 24 INT C MACH LEAR, P473, DOI DOI 10.1145/1273496.1273556; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bergstra J., 2010, P PYTH SCI COMP C SC, V4, P1, DOI DOI 10.25080/MAJORA-92BF1922-003; Bishop C.M, 2006, PATTERN RECOGN; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; Gutmann MU, 2012, J MACH LEARN RES, V13, P307; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hyvarinen A, 2005, J MACH LEARN RES, V6, P695; Hyvarinen A, 2007, IEEE T NEURAL NETWOR, V18, P1529, DOI 10.1109/TNN.2007.895819; Kamyshanska H., 2013, ICML, V28, P720; Konda K. R., 2014, INT C LEARN REPR ICL; Le Q., 2012, INT C MACH LEARN, DOI DOI 10.1109/MSP.2011.940881; Lee J.M., 2001, INTRO SMOOTH MANIFOL; Memisevic R., 2011, P ADV NEUR INF PROC, V23, P1603; Memisevic R, 2013, IEEE T PATTERN ANAL, V35, P1829, DOI 10.1109/TPAMI.2013.53; Memisevic R, 2011, IEEE I CONF COMP VIS, P1591, DOI 10.1109/ICCV.2011.6126419; Memisevic R, 2010, NEURAL COMPUT, V22, P1473, DOI 10.1162/neco.2010.01-09-953; Nair V., 2010, ICML, P807; Rifai S., 2011, PROC INT C MACH LEAR; Rolfe J. T., 2013, P INT C LEARN REPR; Santilli RM., 1982, FDN THEORETICAL MECH; Saxe A.M., 2014, 2 INT C LEARN REPR; Schmah T., 2008, ADV NEURAL INFORM PR, P1409; Seung HS, 1998, ADV NEUR IN, V10, P654; Socher Richard, 2011, P C EMP METH NAT LAN, P151; Swersky K., 2011, PROC 28 INT C MACH L, P1201; Taylor Graham, 2009, P 26 ANN INT C MACH, DOI DOI 10.1145/1553374.1553505; Vincent P., 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Vincent P, 2011, NEURAL COMPUT, V23, P1661, DOI 10.1162/NECO_a_00142; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Welling M., 2005, ADV NEURAL INF PROCE, V17, P1481; Zou W., 2012, ADV NEURAL INFORM PR, P3203	39	41	43	0	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2015	37	6					1261	1273		10.1109/TPAMI.2014.2362140	http://dx.doi.org/10.1109/TPAMI.2014.2362140			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CH9SR	26357347	Green Published			2022-12-18	WOS:000354377100011
J	He, R; Tan, TN; Wang, L				He, Ran; Tan, Tieniu; Wang, Liang			Robust Recovery of Corrupted Low-Rank Matrix by Implicit Regularizers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						PCA; implicit regularizers; low-rank matrix recovery; correntropy; l(1) regularization	THRESHOLDING ALGORITHM; RECOGNITION; SPARSE; SIGNAL; FRAMEWORK; SHRINKAGE	Low-rank matrix recovery algorithms aim to recover a corrupted low-rank matrix with sparse errors. However, corrupted errors may not be sparse in real-world problems and the relationship between l(1) regularizer on noise and robust M-estimators is still unknown. This paper proposes a general robust framework for low-rank matrix recovery via implicit regularizers of robust M-estimators, which are derived from convex conjugacy and can be used to model arbitrarily corrupted errors. Based on the additive form of half-quadratic optimization, proximity operators of implicit regularizers are developed such that both low-rank structure and corrupted errors can be alternately recovered. In particular, the dual relationship between the absolute function in l(1) regularizer and Huber M-estimator is studied, which establishes a connection between robust low-rank matrix recovery methods and M-estimators based robust principal component analysis methods. Extensive experiments on synthetic and real-world data sets corroborate our claims and verify the robustness of the proposed framework.	[He, Ran; Tan, Tieniu; Wang, Liang] Chinese Acad Sci, Ctr Res Intelligent Percept & Comp CRIPAC, Beijing 100190, Peoples R China; [He, Ran; Tan, Tieniu; Wang, Liang] Chinese Acad Sci, Natl Lab Pattern Recognit NLPR, Inst Automat, Beijing 100190, Peoples R China	Chinese Academy of Sciences; Chinese Academy of Sciences; Institute of Automation, CAS	He, R (corresponding author), Chinese Acad Sci, Ctr Res Intelligent Percept & Comp CRIPAC, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.	rhe@nlpr.ia.ac.cn; tnt@nlpr.ia.ac.cn; wangliang@nlpr.ia.ac.cn		Wang, Yunlong/0000-0002-3535-308X	National Basic Research Program of China [2012CB316300]; National Natural Science Foundation of China [61103155, 61175003]; Strategic Priority Research Program of the Chinese Academy of Sciences [XDA06030300]	National Basic Research Program of China(National Basic Research Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Strategic Priority Research Program of the Chinese Academy of Sciences(Chinese Academy of Sciences)	The authors would like to greatly thank the associate editor and the reviewers for their valuable comments and suggestions, and thank Dr. Xiao-tong Yuan, Dr. Wei-shi Zheng, Dr. Jing Dong, Shuai Zheng and Haiqing Li for designing the experiments and helping revising the paper. This work is funded by National Basic Research Program of China (Grant No. 2012CB316300), National Natural Science Foundation of China (Grant No. 61103155,61175003), and the Strategic Priority Research Program of the Chinese Academy of Sciences (Grant No. XDA06030300).	Afonso MV, 2010, IEEE IMAGE PROC, P4169, DOI 10.1109/ICIP.2010.5650379; Angst R, 2011, IEEE I CONF COMP VIS, P2502, DOI 10.1109/ICCV.2011.6126536; [Anonymous], 2009, P INT WORKSH COMP AD; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319; Bioucas-Dias JM, 2008, IEEE IMAGE PROC, P685, DOI 10.1109/ICIP.2008.4711847; BISHOP CM, 2006, PATTEN RECOGNITION M; Boyd S, 2004, CONVEX OPTIMIZATION; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Candes EJ, 2010, IEEE T INFORM THEORY, V56, P2053, DOI 10.1109/TIT.2010.2044061; Chandrasekaran V, 2009, ANN ALLERTON CONF, P962, DOI 10.1109/ALLERTON.2009.5394889; Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; Ding C., 2006, PROC INT C MACH LEAR, P281, DOI DOI 10.1145/1143844.1143880; Fazel M., 2002, THESIS STANFORD U; Fornasier M., 2011, SIAM J OPTIMIZ UNPUB, P1; Ganesh A., 2010, COMPUTING RES REPOSI; Ganesh A., 2008, P INT WORKSH COMP AD; Gong P., 2013, ICML; Grave E., 2012, P ADV NEUR INF PROC; Gross D, 2011, IEEE T INFORM THEORY, V57, P1548, DOI 10.1109/TIT.2011.2104999; Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38; He R., 2011, P IEEE C COMP VIS PA; He R, 2011, IEEE T IMAGE PROCESS, V20, P1485, DOI 10.1109/TIP.2010.2103949; He R, 2011, IEEE T PATTERN ANAL, V33, P1561, DOI 10.1109/TPAMI.2010.220; Hsu D, 2011, IEEE T INFORM THEORY, V57, P7221, DOI 10.1109/TIT.2011.2158250; Huber P., 1981, ROBUST STAT; Idier J, 2001, IEEE T IMAGE PROCESS, V10, P1001, DOI 10.1109/83.931094; Iglesias JE, 2007, LECT NOTES COMPUT SC, V4792, P178; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169; Lin Z, 2009, UILUENG092215 UIUC; Liu G., 2010, COMPUTING RES REPOSI; Liu WF, 2007, IEEE T SIGNAL PROCES, V55, P5286, DOI 10.1109/TSP.2007.896065; Maronna R, 2005, TECHNOMETRICS, V47, P264, DOI 10.1198/004017005000000166; Micchelli C., 2010, P ADV NEUR INF PROC, P1; Nikolova M, 2005, SIAM J SCI COMPUT, V27, P937, DOI 10.1137/030600862; Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39; Seth S., 2008, P INT C AC SPEECH SI; Singer A, 2010, SIAM J MATRIX ANAL A, V31, P1621, DOI 10.1137/090750688; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Toh KC, 2010, PAC J OPTIM, V6, P615; Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144; Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57; Weifeng Liu, 2006, Proceedings of the 2006 IEEE Signal Processing Society Workshop, P179; Wright J., 2009, P NEUR INF PROC SYST, V4, P1; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Yadong Mu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2609, DOI 10.1109/CVPR.2011.5995369; Yuan L, 2013, IEEE T PATTERN ANAL, V35, P2104, DOI 10.1109/TPAMI.2013.17; Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2; Zheng S., 2011, P INT C IM PROC	53	41	43	1	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2014	36	4					770	783		10.1109/TPAMI.2013.188	http://dx.doi.org/10.1109/TPAMI.2013.188			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AE6MX	26353199				2022-12-18	WOS:000334109000011
J	Sussman, DL; Tang, M; Priebe, CE				Sussman, Daniel L.; Minh Tang; Priebe, Carey E.			Consistent Latent Position Estimation and Vertex Classification for Random Dot Product Graphs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Random graph; k-nearest-neighbor; latent space model; universal consistency	STOCHASTIC BLOCKMODELS; MODELS	In this work, we show that using the eigen-decomposition of the adjacency matrix, we can consistently estimate latent positions for random dot product graphs provided the latent positions are i.i.d. from some distribution. If class labels are observed for a number of vertices tending to infinity, then we show that the remaining vertices can be classified with error converging to Bayes optimal using the k-nearest-neighbors classification rule. We evaluate the proposed methods on simulated data and a graph derived from Wikipedia.	[Sussman, Daniel L.; Minh Tang] Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD 21218 USA; [Priebe, Carey E.] Johns Hopkins Univ, Dept Appl Math & Stat, Whiting Sch Engn, Baltimore, MD 21218 USA	Johns Hopkins University; Johns Hopkins University	Sussman, DL (corresponding author), Johns Hopkins Univ, Dept Appl Math & Stat, Whitehead 100,3400 N Charles St, Baltimore, MD 21218 USA.	dsussma3@jhu.edu		Tang, Minh/0000-0003-1420-7187; Sussman, Daniel/0000-0002-8307-2610	Natinal Security Science and Engineering Faculty Fellowship (NSSEFF); Acheson J. Duncan Fund for the Advancement of Research in Statistics; Johns Hopkins University Human Language Technology Center of Excellence (JHU HLT COE)	Natinal Security Science and Engineering Faculty Fellowship (NSSEFF); Acheson J. Duncan Fund for the Advancement of Research in Statistics; Johns Hopkins University Human Language Technology Center of Excellence (JHU HLT COE)	This work was partially supported by a Natinal Security Science and Engineering Faculty Fellowship (NSSEFF), by the Acheson J. Duncan Fund for the Advancement of Research in Statistics, and by the Johns Hopkins University Human Language Technology Center of Excellence (JHU HLT COE).	Airoldi EM, 2008, J MACH LEARN RES, V9, P1981; ALDOUS DJ, 1981, J MULTIVARIATE ANAL, V11, P581, DOI 10.1016/0047-259X(81)90099-3; Bickel PJ, 2009, P NATL ACAD SCI USA, V106, P21068, DOI 10.1073/pnas.0907096106; Choi DS, 2012, BIOMETRIKA, V99, P273, DOI 10.1093/biomet/asr053; Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; DAVIS C, 1970, SIAM J NUMER ANAL, V7, P1, DOI 10.1137/0707001; FIEDLER M, 1973, CZECH MATH J, V23, P298; Fishkind D. E., 2012, CONSISTENT ADJACENCY; Handcock MS, 2007, J ROY STAT SOC A STA, V170, P301, DOI 10.1111/j.1467-985X.2007.00471.x; Hoff PD, 2002, J AM STAT ASSOC, V97, P1090, DOI 10.1198/016214502388618906; HOLLAND PW, 1983, SOC NETWORKS, V5, P109, DOI 10.1016/0378-8733(83)90021-7; HOOVER D, 1979, RELATIONS PROBABILIT; Horn R. A., 1986, MATRIX ANAL; KALLENBERG O, 2005, PROB APPL S; Lu L., 2004, INTERNET MATH, V1, P257, DOI [DOI 10.1080/15427951.2004.10129089, 10.1080/15427951.2004.10129089]; Ma Z., 2012, STAT ANAL DATA MIN, V5, P187, DOI DOI 10.1002/sam.11142; Marchette D., 2011, P 57 ISI WORLD STAT; McSherry F, 2001, ANN IEEE SYMP FOUND, P529, DOI 10.1109/SFCS.2001.959929; Nickel C.L.M., 2006, THESIS J HOPKINS U; Oliveira R. I., 2009, CONCENTRATION ADJACE; Rohe K, 2011, ANN STAT, V39, P1878, DOI 10.1214/11-AOS887; Snijders TAB, 1997, J CLASSIF, V14, P75, DOI 10.1007/s003579900004; Sussman DL, 2012, J AM STAT ASSOC, V107, P1119, DOI 10.1080/01621459.2012.699795; Young SJ, 2007, LECT NOTES COMPUT SC, V4863, P138	27	41	41	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2014	36	1					48	57		10.1109/TPAMI.2013.135	http://dx.doi.org/10.1109/TPAMI.2013.135			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	265PV	24231865				2022-12-18	WOS:000327965100005
J	Lafarge, F; Keriven, R; Bredif, M; Vu, HH				Lafarge, Florent; Keriven, Renaud; Bredif, Mathieu; Hoang-Hiep Vu			A Hybrid Multiview Stereo Algorithm for Modeling Urban Scenes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D modeling; multiview stereo; urban scenes; hybrid representation; jump-diffusion	LARGE-SCALE; SEGMENTATION; RECONSTRUCTION	We present an original multiview stereo reconstruction algorithm which allows the 3D-modeling of urban scenes as a combination of meshes and geometric primitives. The method provides a compact model while preserving details: Irregular elements such as statues and ornaments are described by meshes, whereas regular structures such as columns and walls are described by primitives (planes, spheres, cylinders, cones, and tori). We adopt a two-step strategy consisting first in segmenting the initial mesh-based surface using a multilabel Markov Random Field-based model and second in sampling primitive and mesh components simultaneously on the obtained partition by a Jump-Diffusion process. The quality of a reconstruction is measured by a multi-object energy model which takes into account both photo-consistency and semantic considerations (i.e., geometry and shape layout). The segmentation and sampling steps are embedded into an iterative refinement procedure which provides an increasingly accurate hybrid representation. Experimental results on complex urban structures and large scenes are presented and compared to state-of-the-art multiview stereo meshing algorithms.	[Lafarge, Florent] INRIA Sophia Antipolis, Geometr Res Grp, F-06902 Sophia Antipolis, France; [Keriven, Renaud] Acute3D, F-06560 Sophia Antipolis, France; [Bredif, Mathieu] Univ Paris Est, IGN, French Mapping Agcy, Matis Lab, F-94165 St Mande, France; [Hoang-Hiep Vu] Univ Paris Est, LIGM, Ecole Ponts ParisTech, Imagine Grp, F-77455 Marne La Vallee, France	Universite Gustave-Eiffel; Ecole des Ponts ParisTech; Universite Gustave-Eiffel; ESIEE Paris	Lafarge, F (corresponding author), INRIA Sophia Antipolis, Geometr Res Grp, 2004 Route Lucioles, F-06902 Sophia Antipolis, France.	florent.lafarge@inria.fr; Renaud.Keriven@acute3D.com; Mathieu.bredif@ign.fr; vhh@imagine.enpc.fr	Brédif, Mathieu/T-3029-2018	Brédif, Mathieu/0000-0003-0228-1232	EADS foundation	EADS foundation	The authors are grateful to the EADS foundation for partial financial support, and to the reviewers for their helpful comments. They thank C. Strecha, B. Curless, and D. Scharstein for the data and the multiview stereo challenges.	Agarwal N., 2009, P IEEE INT C COMP VI; Attene M., 2006, P IEEE INT C SHAP MO; BAILLARD C, 1999, P IEEE C COMP VIS PA; Banno A, 2008, INT J COMPUT VISION, V78, P207, DOI 10.1007/s11263-007-0104-6; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Bredif M., 2007, 2007 IEEE INT C IMAG; Brenner C., 2006, P C PHOT COMP VIS; Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603; Campbell N., 2008, P 10 EUR C COMP VIS; Chauve Anne-Laure, 2010, P IEEE C COMP VIS PA; Coughlan J. M., 2000, P C NEUR INF PROC SY; Dick AR, 2004, INT J COMPUT VISION, V60, P111, DOI 10.1023/B:VISI.0000029665.07652.61; Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183; Frahm J, 2010, P 11 EUR C COMP VIS; Fruh C, 2004, INT J COMPUT VISION, V60, P5, DOI 10.1023/B:VISI.0000027787.82851.b6; Furukawa Y., 2009, P IEEE C COMP VIS PA; Furukawa Yasutaka, 2007, P IEEE C COMP VIS PA; Gallup David, 2010, P IEEE C COMP VIS PA; GEMAN S, 1986, SIAM J CONTROL OPTIM, V24, P1031, DOI 10.1137/0324060; GOESELE M, 2007, P 11 IEEE INT C COMP; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; GRENANDER U, 1994, J R STAT SOC B, V56, P549; Han F, 2004, IEEE T PATTERN ANAL, V26, P1138, DOI 10.1109/TPAMI.2004.70; Han F., 2005, P IEEE C COMP VIS PA; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; Kobbelt L., 1998, P ACM SIGGRAPH; Kolev K., 2008, P 10 EUR C COMP VIS; Koutsourakis P., 2009, P 12 IEEE INT C COMP; Labatut P., 2009, P 12 IEEE INT COMP V; Labatut P., 2007, P 11 IEEE INT C COMP; Lafarge F., 2010, P IEEE C COMP VIS PA; Lafarge F., 2008, P IEEE C COMP VIS PA; Lafarge F, 2010, IEEE T IMAGE PROCESS, V19, P1683, DOI 10.1109/TIP.2010.2045695; Lee S., 2004, P IEEE C COMP VIS PA; Marshall D, 2001, IEEE T PATTERN ANAL, V23, P304, DOI 10.1109/34.910883; Mayer H, 2008, ISPRS J PHOTOGRAMM, V63, P213, DOI 10.1016/j.isprsjprs.2007.08.008; Muller P., 2007, P ACM SIGGRAPH; Osher S, 2003, LEVEL SET METHODS DY; Pauly M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360642; Pollefeys M, 2008, INT J COMPUT VISION, V78, P143, DOI 10.1007/s11263-007-0086-4; Pons JP, 2007, INT J COMPUT VISION, V72, P179, DOI 10.1007/s11263-006-8671-5; SALAMON P, 2002, SIAM MONOGRAPHS MATH; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Seitz Steven M., 2006, IEEE C COMP VIS PATT; Shamir A, 2008, COMPUT GRAPH FORUM, V27, P1539, DOI 10.1111/j.1467-8659.2007.01103.x; Shen C, 2004, ACM T GRAPHIC, V23, P896, DOI 10.1145/1015706.1015816; Sinha S. N., 2009, P 12 IEEE INT C COMP; SRIVASTAVA A, 1995, IEEE T SIGNAL PROCES, V43, P1282, DOI 10.1109/78.382418; Strecha C., 2008, P IEEE C COMP VIS PA; Tu Z., 2005, P IEEE 9 INT C COMP, V63; Vanegas C., 2010, P IEEE C COMP VIS PA; VU H, 2009, P IEEE C COMP VIS PA; WHITE S, 1984, P IEEE INT C COMP DE; Xiao JX, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409114; ZHU Z, 2008, INT J COMPUTER VISIO, V78	56	41	43	0	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2013	35	1					5	17		10.1109/TPAMI.2012.84	http://dx.doi.org/10.1109/TPAMI.2012.84			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	037SV	22487981	Green Submitted			2022-12-18	WOS:000311127700003
J	Lee, YJ; Grauman, K				Lee, Yong Jae; Grauman, Kristen			Object-Graphs for Context-Aware Visual Category Discovery	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object recognition; context; category discovery; unsupervised learning		How can knowing about some categories help us to discover new ones in unlabeled images? Unsupervised visual category discovery is useful to mine for recurring objects without human supervision, but existing methods assume no prior information and thus tend to perform poorly for cluttered scenes with multiple objects. We propose to leverage knowledge about previously learned categories to enable more accurate discovery, and address challenges in estimating their familiarity in unsegmented, unlabeled images. We introduce two variants of a novel object-graph descriptor to encode the 2D and 3D spatial layout of object-level co-occurrence patterns relative to an unfamiliar region and show that by using them to model the interaction between an image's known and unknown objects, we can better detect new visual categories. Rather than mine for all categories from scratch, our method identifies new objects while drawing on useful cues from familiar ones. We evaluate our approach on several benchmark data sets and demonstrate clear improvements in discovery over conventional purely appearance-based baselines.	[Lee, Yong Jae] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA; [Grauman, Kristen] Univ Texas Austin, Dept Comp Sci, Austin, TX 78701 USA	University of Texas System; University of Texas Austin; University of Texas System; University of Texas Austin	Lee, YJ (corresponding author), Univ Texas Austin, Dept Elect & Comp Engn, ACES 3-302,1 Univ Stn C0803, Austin, TX 78712 USA.	yjlee0222@utexas.edu; grauman@cs.utexas.edu			US Army Research Laboratory [W911NF-10-2-0059]; DARPA CSSG; US National Science Foundation (NSF) [IIS-0747356]	US Army Research Laboratory(United States Department of DefenseUS Army Research Laboratory (ARL)); DARPA CSSG(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); US National Science Foundation (NSF)(National Science Foundation (NSF))	The authors thank Alex Sorokin for helping them with the MTurk data collection, Bryan Russell for sharing his code, and Alyosha Efros for helpful discussions, and the anonymous reviewers for their thoughtful suggestions. This research was sponsored in part by the US Army Research Laboratory under Cooperative Agreement Number W911NF-10-2-0059, DARPA CSSG, and US National Science Foundation (NSF) CAREER IIS-0747356. The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Laboratory, US Defense Advanced Research Projects Agency (DARPA), or the Government. The US Government is authorized to reproduce and distribute reprints for Government policies notwithstanding any copyright notation herein.	ARBELAEZ P, 2009, P IEEE C COMP VIS PA; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; artner Thomas G, 2003, P ANN C COMP LEARN T; Bach F.R., 2004, P INT C MACH LEARN; BART E, 2005, P IEEE CS C COMP VIS; Bosch A., 2007, P 6 ACM INT C IM VID, P30; Cho M., 2010, P IEEE C COMP VIS PA; Dueck D., 2007, P IEEE C COMP VIS PA; FEIFEI L, 2003, P IEEE INT C COMP VI; Galleguillos C., 2008, P IEEE C COMP VIS PA; Gould S., 2009, P IEEE INT C COMP VI; Grauman K., 2006, P IEEE CS C COMP VIS; He X., 2004, P IEEE CS C COMP VIS; HEBERT M., 2007, P IEEE INT C COMP VI; HEITZ G, 2008, P EUR C COMP VIS; HOIEM D, 2006, P IEEE CS C COMP VIS; HOIEM D, 2005, P IEEE INT C COMP VI; Kaplan AS, 1999, MEM COGNITION, V27, P699, DOI 10.3758/BF03211563; KASHIMA H, 2004, KERNELS BIOINFORMATI; Kim G., 2008, P IEEE C COMP VIS PA; Lazebnik S., 2009, P IEEE C COMP VIS PA; LEE Y. J., 2010, P IEEE C COMP VIS PA; Lee YJ, 2009, INT J COMPUT VISION, V85, P143, DOI 10.1007/s11263-009-0252-y; Liu D., 2007, P IEEE INT C COMP VI; Malisiewicz T., 2009, P NEURAL INFORM PROC; Malisiewicz T., 2007, P BRIT MACH VIS C; Ng A., 2001, P NEURAL INFORM PROC; PARIKH D, 2008, P IEEE C COMP VIS PA; Platt J., 1999, ADV LARGE MARGIN CLA; RUSSELL BC, 2006, P IEEE CS C COMP VIS; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shotton J., 2006, P ECCV; Singhal A., 2003, P IEEE CS C COMP VIS; Tan PN, 2016, INTRO DATA MINING; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Tu Z., 2008, P IEEE C COMP VIS PA; Vedaldi A., 2008, P IEEE C COMP VIS PA; Weischedel R., 1990, P WORKSH SPEECH NAT	39	41	41	1	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2012	34	2					346	358		10.1109/TPAMI.2011.122	http://dx.doi.org/10.1109/TPAMI.2011.122			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	862PJ	21670480				2022-12-18	WOS:000298105500012
J	Morris, NJW; Kutulakos, KN				Morris, Nigel J. W.; Kutulakos, Kiriakos N.			Dynamic Refraction Stereo	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo; time-varying imagery; shape-from-X; transparency; refractive index estimation	WIND-WAVES; WATER; SHAPE	In this paper we consider the problem of reconstructing the 3D position and surface normal of points on an unknown, arbitrarily-shaped refractive surface. We show that two viewpoints are sufficient to solve this problem in the general case, even if the refractive index is unknown. The key requirements are 1) knowledge of a function that maps each point on the two image planes to a known 3D point that refracts to it, and 2) light is refracted only once. We apply this result to the problem of reconstructing the time-varying surface of a liquid from patterns placed below it. To do this, we introduce a novel "stereo matching" criterion called refractive disparity, appropriate for refractive scenes, and develop an optimization-based algorithm for individually reconstructing the position and normal of each point projecting to a pixel in the input views. Results on reconstructing a variety of complex, deforming liquid surfaces suggest that our technique can yield detailed reconstructions that capture the dynamic behavior of free-flowing liquids.	[Morris, Nigel J. W.] Morgan Solar Inc, Toronto, ON, Canada; [Kutulakos, Kiriakos N.] Univ Toronto, Toronto, ON M5S 3G4, Canada	University of Toronto	Morris, NJW (corresponding author), Morgan Solar Inc, Toronto, ON, Canada.	nmorris@dgp.toronto.edu; kyros@cs.toronto.edu			Natural Sciences and Engineering Research Council of Canada; Province of Ontario; Alfred P. Sloan Foundation; Ontario Premier's Research Excellence Award	Natural Sciences and Engineering Research Council of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)CGIAR); Province of Ontario; Alfred P. Sloan Foundation(Alfred P. Sloan Foundation); Ontario Premier's Research Excellence Award	This work was supported in part by the Natural Sciences and Engineering Research Council of Canada under the RGPIN program, by the Province of Ontario under the OGSST program, by a fellowship from the Alfred P. Sloan Foundation, and by an Ontario Premier's Research Excellence Award. A preliminary version of this work appears in [38].	Adato Y, 2007, IEEE I CONF COMP VIS, P433; Agarwal S, 2004, LECT NOTES COMPUT SC, V3022, P483; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Ben-Ezra M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1025; BLAKE A, 1985, P INT JOINT C ART IN, P973; Bonfort T, 2006, LECT NOTES COMPUT SC, V3852, P872; Bonfort T, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P591; Bouguet J. Y., 2010, MATLAB CAMERA CALIBR; Chen T, 2006, P IEEE C COMP VIS PA, P1825, DOI [10.1109/CVPR.2006.182, DOI 10.1109/CVPR.2006.182]; Chuang YY, 2000, COMP GRAPH, P121, DOI 10.1145/344779.344844; DAIDA JM, 1995, P GEOSC REM SENS S C, V3, P1881; DING Y, 2009, P IEEE C COMP VIS PA; Ding Y., 2008, P 2008 IEEE INT VACU, P1; Enright D, 2002, ACM T GRAPHIC, V21, P736, DOI [10.1145/566570.566645, 10.1145/566570.566581]; FLACH P, 2000, P INT ARCH PHOTOGRAM, P195; Francken Y, 2008, CVPR, P1; Glassner A. S., 1995, PRINCIPLES DIGITAL I; Gross Markus, 2003, P 2003 ACM SIGGRAPH, P154; HALSTEAD MA, 1996, P ACM SIGGRAPH, P335; HARLOW FH, 1965, PHYS FLUIDS, V8, P2182, DOI 10.1063/1.1761178; Harris C. G., 1988, P 4 ALV VIS C, V15, P10, DOI [10.5244/C.2.23, DOI 10.5244/C.2.23]; Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HOHLE J, 1971, PHOTOGRAMM ENG, V37, P948; Hullin MB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360686; IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; JAHNE B, 1994, J OPT SOC AM A, V11, P2197, DOI 10.1364/JOSAA.11.002197; Jahne B, 2005, MEAS SCI TECHNOL, V16, P1937, DOI 10.1088/0957-0233/16/10/008; JAHNE B, 1992, P INT SEM IM TRANSP; KAMINSKI J, 2005, P 5 INT WORKSH AUT P; KELLER WC, 1983, APPL OPTICS, V22, P3476, DOI 10.1364/AO.22.003476; KOENDERINK JJ, 1979, BIOL CYBERN, V33, P151, DOI 10.1007/BF00337293; Kolev K, 2009, INT J COMPUT VISION, V84, P80, DOI 10.1007/s11263-009-0233-1; Kutulakos KN, 2005, IEEE I CONF COMP VIS, P1448; Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745; Maas H. G., 1995, OPTICAL 3D MEASUREME; MOLER CB, 1976, COMPUTER METHODS MAT; Morris NJW, 2005, IEEE I CONF COMP VIS, P1573; Murase H, 1990, P 3 INT C COMP VIS O, P313; Nehab D, 2005, ACM T GRAPHIC, V24, P536, DOI 10.1145/1073204.1073226; OKAMOTO A, 1984, PHOTOGRAMMETRIC ENG, P303; OREN M, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P740, DOI 10.1109/ICCV.1995.466864; Press, 1988, NUMERICAL RECIPIES C; SANDERSON AC, 1988, IEEE T PATTERN ANAL, V10, P44, DOI 10.1109/34.3866; Savarese S, 2002, LECT NOTES COMPUT SC, V2351, P759; SCHULTZ H, 1994, IEEE T PATTERN ANAL, V16, P195, DOI 10.1109/34.273732; SHEMDIN OH, 1990, P ENG OC ENV C, P568; SULLIVAN SA, 1963, J OPT SOC AM, V53, P962, DOI 10.1364/JOSA.53.000962; TARINI M, 2003, MPII20034001; Treibitz T., 2008, IEEE C COMPUT VIS PA, P1, DOI [10.1109/CVPR.2008.4587844, DOI 10.1109/CVPR.2008.4587844]; Trifonov B., 2006, PROC EUROGRAPHICS C, P51; Triggs B., 2000, LECT NOTES COMPUTER, V1883, P298, DOI [DOI 10.1007/3-540-44480-7, DOI 10.1007/3-540-44480-7_21]; VASILYEV Y, 2008, P IEEE COMP SOC C CO, P1; Wang J, 2006, IEEE T PATTERN ANAL, V28, P446, DOI 10.1109/TPAMI.2006.63; WU Z, 1990, P ENG OC ENV C, P416; Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759; ZHANG X, 1994, EXP FLUIDS, V17, P225; Zhou L, 2000, PROC CVPR IEEE, P744, DOI 10.1109/CVPR.2000.854949	59	41	46	2	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2011	33	8					1518	1531		10.1109/TPAMI.2011.24	http://dx.doi.org/10.1109/TPAMI.2011.24			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	779UH	21282852				2022-12-18	WOS:000291807200003
J	Bronstein, MM; Bronstein, AM				Bronstein, Michael M.; Bronstein, Alexander M.			Shape Recognition with Spectral Distances	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Diffusion distance; commute time; spectral distance; eigenmap; Laplace-Beltrami operator; heat kernel; distribution; global point signature; nonrigid shapes; similarity		Recent works have shown the use of diffusion geometry for various pattern recognition applications, including nonrigid shape analysis. In this paper, we introduce spectral shape distance as a general framework for distribution-based shape similarity and show that two recent methods for shape similarity due to Rustamov and Mahmoudi and Sapiro are particular cases thereof.	[Bronstein, Michael M.] Univ Svizzera Italiana, Inst Computat Sci, Fac Informat, CH-6900 Lugano, Switzerland; [Bronstein, Alexander M.] Tel Aviv Univ, Dept Elect Engn, Tel Aviv, Israel	Universita della Svizzera Italiana; Tel Aviv University	Bronstein, MM (corresponding author), Univ Svizzera Italiana, Inst Computat Sci, Fac Informat, CH-6900 Lugano, Switzerland.	michael.bronstein@usi.ch; alexbron@ieee.org			Office of Naval Research	Office of Naval Research(Office of Naval Research)	The authors are grateful to Ron Kimmel, Radu Horaud, and Guillermo Sapiro for insightful discussions. This research was supported in part by the Office of Naval Research Grant.	Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Belkin M., 2009, P S COMP GEOM, P278; Ben Hamza A, 2006, IEEE T IMAGE PROCESS, V15, P2249, DOI 10.1109/TIP.2006.875250; BERARD P, 1994, GEOM FUNCT ANAL, V4, P373, DOI 10.1007/BF01896401; Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1; Bronstein AM, 2010, INT J COMPUT VISION, V89, P266, DOI 10.1007/s11263-009-0301-6; Bronstein AM, 2009, INT J COMPUT VISION, V81, P281, DOI 10.1007/s11263-008-0172-2; BRONSTEIN AM, 2009, P WORKSH NONRIGID SH; Bronstein M.M., 2010, P IEEE C COMP VIS PA; BRONSTEIN MM, 2009, 200914 CIS; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006; ION A, 2009, INT J COMPUTER VISIO; LEVY B, 2006, INT C SHAPE MODELING; Ling H., 2006, P IEEE C COMP VIS PA; Mahmoudi M, 2009, GRAPH MODELS, V71, P22, DOI 10.1016/j.gmod.2008.10.002; Mateus D, 2008, P IEEE C COMP VIS PA; MEMOLI F, 2009, P WORKSH NONRIGID SH; Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648; OVSJANIKOV M, 2009, P WORKSH NONRIGID SH; Pinkall U., 1993, EXPT MATH, V2, P15, DOI DOI 10.1080/10586458.1993.10504266; Qiu HJ, 2007, IEEE T PATTERN ANAL, V29, P1873, DOI 10.1109/TPAMI.2007.1103; Reuter M, 2009, COMPUT GRAPH-UK, V33, P381, DOI 10.1016/j.cag.2009.03.005; RUGGERI MR, 2008, PEUR WORKSH 3D OBJ R; Rustamov Raif M, 2007, P 5 EUR S GEOM PROC, P225, DOI DOI 10.2312/SGP/SGP07/225-233; Sun Jian, 2009, P S GEOM PROC	25	41	42	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2011	33	5					1065	1071		10.1109/TPAMI.2010.210	http://dx.doi.org/10.1109/TPAMI.2010.210			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	738YF					2022-12-18	WOS:000288677800016
J	Papadakis, N; Bugeau, A				Papadakis, Nicolas; Bugeau, Aurelie			Tracking with Occlusions via Graph Cuts	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Tracking; interacting objects; occlusions; graph cuts optimization	ENERGY MINIMIZATION; STEREO	This work presents a new method for tracking and segmenting along time-interacting objects within an image sequence. One major contribution of the paper is the formalization of the notion of visible and occluded parts. For each object, we aim at tracking these two parts. Assuming that the velocity of each object is driven by a dynamical law, predictions can be used to guide the successive estimations. Separating these predicted areas into good and bad parts with respect to the final segmentation and representing the objects with their visible and occluded parts permit handling partial and complete occlusions. To achieve this tracking, a label is assigned to each object and an energy function representing the multilabel problem is minimized via a graph cuts optimization. This energy contains terms based on image intensities which enable segmenting and regularizing the visible parts of the objects. It also includes terms dedicated to the management of the occluded and disappearing areas, which are defined on the areas of prediction of the objects. The results on several challenging sequences prove the strength of the proposed approach.	[Papadakis, Nicolas; Bugeau, Aurelie] Barcelona Media, Image Grp, Barcelona 08017, Spain		Papadakis, N (corresponding author), Barcelona Media, Image Grp, Edificio Imagina,Planta 9,Ave Diagonal 177, Barcelona 08017, Spain.	nicolas.papadakis@barcelonamedia.org; aurelie.bugeau@barcelonamedia.org		Bugeau, Aurelie/0000-0002-4858-4944	i3media Spanish Project [CENIT 2007-1012]; Ministerio de Educacion y Ciencia Espanol	i3media Spanish Project; Ministerio de Educacion y Ciencia Espanol(Spanish Government)	The authors would like to thank the two reviewers for their helpful suggestions and Vicent Caselles for the many useful discussions they had with him. They would also like to acknowledge the support received from the i3media Spanish Project (CENIT 2007-1012) and the Torres Quevedo fellowship from the Ministerio de Educacion y Ciencia Espanol.	Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Boykov Y.Y., 2001, ICCV, V1, P105, DOI DOI 10.1109/ICCV.2001.937505; BRAY M, 2006, P EUR C COMP VIS; BUGEAU A, 2008, P INT C COMP VIS THE, V2, P447; Bugeau A, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/317278; Corpetti T, 2002, IEEE T PATTERN ANAL, V24, P365, DOI 10.1109/34.990137; Cox IJ, 1996, COMPUT VIS IMAGE UND, V63, P542, DOI 10.1006/cviu.1996.0040; Cremers D, 2006, IEEE T PATTERN ANAL, V28, P1262, DOI 10.1109/TPAMI.2006.161; Criminisi A, 2007, INT J COMPUT VISION, V71, P89, DOI 10.1007/s11263-006-8525-1; CRIMINISI A, 2006, P IEEE C COMP VIS PA, V1, P53; DAMBREVILLE S, 2006, P AM CONTR C; Freedman D, 2005, PROC CVPR IEEE, P10; Freedman D, 2004, IEEE T IMAGE PROCESS, V13, P518, DOI 10.1109/TIP.2003.821445; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Kolmogorov V, 2005, PROC CVPR IEEE, P407; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; MALCOLM J, 2007, P IEEE INT C COMP VI; MALCOLM J, 2007, P BRIT MACH VIS C; Mota C, 2005, SIGNAL PROCESS-IMAGE, V20, P529, DOI 10.1016/j.image.2005.03.008; Nguyen HT, 2004, IEEE T PATTERN ANAL, V26, P1099, DOI 10.1109/TPAMI.2004.45; Niethammer M, 2004, PROC CVPR IEEE, P660; Papadakis N, 2008, J MATH IMAGING VIS, V31, P81, DOI 10.1007/s10851-008-0069-2; RAMANAN D, 2007, P IEEE C COMP VIS PA; Rathi Y, 2007, IEEE T PATTERN ANAL, V29, P1470, DOI 10.1109/TPAMI.2007.1081; Schmidt FR, 2007, LECT NOTES COMPUT SC, V4679, P39; Terzopoulos D., 1993, ACT VIS, P3; Xu N, 2007, COMPUT VIS IMAGE UND, V107, P210, DOI 10.1016/j.cviu.2006.11.004; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Yu WC, 2002, IEEE T PATTERN ANAL, V24, P1286, DOI 10.1109/TPAMI.2002.1033220; ZHAO L, 2005, P IEEE INT C COMP VI	35	41	45	0	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2011	33	1					144	157		10.1109/TPAMI.2010.56	http://dx.doi.org/10.1109/TPAMI.2010.56			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	681AC	21088324				2022-12-18	WOS:000284277600011
J	Wu, H; Sankaranarayanan, AC; Chellappa, R				Wu, Hao; Sankaranarayanan, Aswin C.; Chellappa, Rama			Online Empirical Evaluation of Tracking Algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Performance evaluation; tracking; particle filters; model validation	PERFORMANCE EVALUATION; PARTICLE METHODS; MODELS	Evaluation of tracking algorithms in the absence of ground truth is a challenging problem. There exist a variety of approaches for this problem, ranging from formal model validation techniques to heuristics that look for mismatches between track properties and the observed data. However, few of these methods scale up to the task of visual tracking, where the models are usually nonlinear and complex and typically lie in a high-dimensional space. Further, scenarios that cause track failures and/or poor tracking performance are also quite diverse for the visual tracking problem. In this paper, we propose an online performance evaluation strategy for tracking systems based on particle filters using a time-reversed Markov chain. The key intuition of our proposed methodology relies on the time-reversible nature of physical motion exhibited by most objects, which in turn should be possessed by a good tracker. In the presence of tracking failures due to occlusion, low SNR, or modeling errors, this reversible nature of the tracker is violated. We use this property for detection of track failures. To evaluate the performance of the tracker at time instant t, we use the posterior of the tracking algorithm to initialize a time-reversed Markov chain. We compute the posterior density of track parameters at the starting time t 0 by filtering back in time to the initial time instant. The distance between the posterior density of the time-reversed chain (at t 0) and the prior density used to initialize the tracking algorithm forms the decision statistic for evaluation. It is observed that when the data are generated by the underlying models, the decision statistic takes a low value. We provide a thorough experimental analysis of the evaluation methodology. Specifically, we demonstrate the effectiveness of our approach for tackling common challenges such as occlusion, pose, and illumination changes and provide the Receiver Operating Characteristic (ROC) curves. Finally, we also show the applicability of the core ideas of the paper to other tracking algorithms such as the Kanade-Lucas-Tomasi (KLT) feature tracker and the mean-shift tracker.	[Wu, Hao] Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA; Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA	University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park	Wu, H (corresponding author), Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA.	wh2003@umiacs.umd.edu; aswch@umiacs.umd.edu; rama@umiacs.umd.edu	Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/B-6573-2012	Sankaranarayanan, Aswin/0000-0003-0906-4046	JHU Applied Physics Laboratory	JHU Applied Physics Laboratory	This work is partially funded by a contract from the JHU Applied Physics Laboratory.	Andrieu C, 2004, P IEEE, V92, P423, DOI 10.1109/JPROC.2003.823142; BLACK J, 2003, P IEEE INT WORKSH VI, P125; Christensen GE, 2001, IEEE T MED IMAGING, V20, P568, DOI 10.1109/42.932742; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761; Doucet A., 2001, SEQUENTIAL MONTO CAR; Duda R.O., 2000, PATTERN CLASSIFICATI; Erdem CE, 2001, PROC CVPR IEEE, P323; Erdem CE, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P69, DOI 10.1109/ICIP.2001.958426; GEORIS B, 2003, P INT C VIS IM IM PR; GERLACH R, 1999, J TIME SER ANAL, V20, P309; Goldberger J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P487; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; KASTURI R, 2006, PERFORMANCE EVALUATI; Klaas M., 2006, P 23 INT C MACH LEAR, P481, DOI DOI 10.1145/1143844.1143905; KLASS M, 2006, P IEEE INT C MACH LE; List T., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P129; LU L, 2004, IEEE P COMP VIS PATT; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; Nascimento JC, 2006, IEEE T MULTIMEDIA, V8, P761, DOI 10.1109/TMM.2006.876287; Nghiem AT, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P476, DOI 10.1109/AVSS.2007.4425357; NGHIEM AT, 2007, P IEEE WORKSH MOT VI, P15; Ross S., 1996, STOCHASTIC PROCESSES; SCHLOGL T, 2004, P INT C PATT REC, V4; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Tomasi C, 1991, CMUCS91132; van der Heijden F, 2006, IEEE T PATTERN ANAL, V28, P140, DOI 10.1109/TPAMI.2006.5; Vaswani N, 2007, IEEE T SIGNAL PROCES, V55, P859, DOI 10.1109/TSP.2006.887111; Veeraraghavan A, 2008, IEEE T PATTERN ANAL, V30, P463, DOI 10.1109/TPAMI.2007.70707; Vermaak J, 2002, IEEE T SPEECH AUDI P, V10, P173, DOI 10.1109/TSA.2002.1001982; WU H, 2004, P ARM SCI C; Wu H., 2007, P IEEE C COMP VIS PA; Wu HHP, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS, P35; Yeung SK, 2005, LECT NOTES COMPUT SC, V3750, P188, DOI 10.1007/11566489_24; Yilmaz A, 2007, PROC CVPR IEEE, P140; ZHENG QF, 1995, INT J COMPUT VISION, V15, P31, DOI 10.1007/BF01450849; Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152	38	41	42	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2010	32	8					1443	1458		10.1109/TPAMI.2009.135	http://dx.doi.org/10.1109/TPAMI.2009.135			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	611XQ	20558876				2022-12-18	WOS:000278858600007
J	Liu, JZ; Cao, LL; Li, ZG; Tang, XO				Liu, Jianzhuang; Cao, Liangliang; Li, Zhenguo; Tang, Xiaoou			Plane-based optimization for 3D object reconstruction from single line drawings	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D object reconstruction; degree of reconstruction freedom; line drawing; null space; singular value decomposition	SCENE ANALYSIS; FACES; SHAPE; IDENTIFICATION; PROJECTIONS	In previous optimization-based methods of 3D planar-faced object reconstruction from single 2D line drawings, the missing depths of the vertices of a line drawing (and other parameters in some methods) are used as the variables of the objective functions. A 3D object with planar faces is derived by finding values for these variables that minimize the objective functions. These methods work well for simple objects with a small number N of variables. As N grows, however, it is very difficult for them to find the expected objects. This is because with the nonlinear objective functions in a space of large dimension N, the search for optimal solutions can easily get trapped into local minima. In this paper, we use the parameters of the planes that pass through the planar faces of an object as the variables of the objective function. This leads to a set of linear constraints on the planes of the object, resulting in a much lower dimensional null space where optimization is easier to achieve. We prove that the dimension of this null space is exactly equal to the minimum number of vertex depths that define the 3D object. Since a practical line drawing is usually not an exact projection of a 3D object, we expand the null space to a larger space based on the singular value decomposition of the projection matrix of the line drawing. In this space, robust 3D reconstruction can be achieved. Compared with the two most related methods, our method not only can reconstruct more complex 3D objects from 2D line drawings but also is computationally more efficient.	[Liu, Jianzhuang; Li, Zhenguo; Tang, Xiaoou] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Peoples R China; [Cao, Liangliang] Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA	Chinese University of Hong Kong; University of Illinois System; University of Illinois Urbana-Champaign	Liu, JZ (corresponding author), Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Peoples R China.	zliu@ie.cuhk.edu.hk; cao4@uiuc.edu; zgli5@ie.cuhk.edu.hk; xtang@ie.cuhk.edu.hk	Tang, Xiaoou/G-6509-2012					AGARWAL SC, 1992, COMPUT AIDED DESIGN, V24, P123, DOI 10.1016/0010-4485(92)90032-6; Brown EW, 1996, P SOC PHOTO-OPT INS, V2904, P138, DOI 10.1117/12.256269; Cao LL, 2005, IEEE I CONF COMP VIS, P272; Company P, 2005, COMPUT GRAPH-UK, V29, P892, DOI 10.1016/j.cag.2005.09.007; Company P, 2004, COMPUT GRAPH-UK, V28, P955, DOI 10.1016/j.cag.2004.08.007; Cooper MC, 2005, INT J COMPUT VISION, V64, P69, DOI 10.1007/s11263-005-1087-9; Cooper MC, 2001, INT J COMPUT VISION, V43, P75, DOI 10.1023/A:1011166601983; Courter S. M., 1986, Computer Graphics, V20, P171, DOI 10.1145/15886.15905; Heyden A, 1996, J MATH IMAGING VIS, V6, P393, DOI 10.1007/BF00123354; LECLERC YG, 1992, INT J COMPUT VISION, V9, P113, DOI 10.1007/BF00129683; Li HB, 2006, LECT NOTES ARTIF INT, V3763, P169; Li HB, 2005, LECT NOTES COMPUT SC, V3519, P383; Lipson H, 1996, COMPUT AIDED DESIGN, V28, P651, DOI 10.1016/0010-4485(95)00081-X; Liu JZ, 2005, IEEE T PATTERN ANAL, V27, P861, DOI 10.1109/TPAMI.2005.119; Liu JZ, 2002, IEEE T PATTERN ANAL, V24, P1579, DOI 10.1109/TPAMI.2002.1114850; Liu JZ, 2001, IEEE T PATTERN ANAL, V23, P1106; MARILL T, 1991, INT J COMPUT VISION, V6, P147, DOI 10.1007/BF00128154; MARKOWSKY G, 1980, IBM J RES DEV, V24, P582, DOI 10.1147/rd.245.0582; Michalewicz Z., 1996, GENETIC ALGORITHMS D, V3rd; PIQUER A, 2003, P 5 IAPR INT WORKSH, P182; Press WH., 2002, NUMERICAL RECIPES C, V2; Ros L, 2002, IEEE T PATTERN ANAL, V24, P456, DOI 10.1109/34.993554; SHESH A, 2004, PO AM C EUR ASS COMP; Shimodaira H, 2006, IEEE T PATTERN ANAL, V28, P612, DOI 10.1109/TPAMI.2006.67; Shimshoni I, 1997, COMPUT VIS IMAGE UND, V65, P296, DOI 10.1006/cviu.1996.0569; Shoji K, 2001, PROC CVPR IEEE, P90; Shpitalni M, 1996, IEEE T PATTERN ANAL, V18, P1000, DOI 10.1109/34.541409; Strang G., 1998, INTRO LINEAR ALGEBRA; SUGIHARA K, 1984, ARTIF INTELL, V23, P59, DOI 10.1016/0004-3702(84)90005-5; SUGIHARA K, 1986, MACH INTERPRETATION; Turner A, 2000, COMPUT GRAPH-UK, V24, P869, DOI 10.1016/S0097-8493(00)00089-3; Varley PAC, 2005, COMPUT AIDED DESIGN, V37, P1285, DOI 10.1016/j.cad.2005.01.002; VARLEY PAC, 2002, P 7 ACM S SOL MOD AP, P180; WHITELEY W, 1989, DISCRETE COMPUT GEOM, V4, P75, DOI 10.1007/BF02187716	34	41	48	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2008	30	2					315	327		10.1109/TPAMI.2007.1172	http://dx.doi.org/10.1109/TPAMI.2007.1172			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	240IC	18084061	Green Submitted			2022-12-18	WOS:000251580300009
J	Liu, CJ				Liu, Chengjun			The Bayes decision rule induced similarity measures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face Recognition Grand Challenge ( FRGC); PRM Whitened Cosine (PWC) similarity measure; whitened cosine similarity measure; Within-Class whitened cosine (WWC) similarity measure	FACE-RECOGNITION; RETRIEVAL	This paper first shows that the popular whitened cosine similarity measure is related to the Bayes decision rule under specific assumptions and then presents two new similarity measures: the PRM Whitened Cosine (PWC) similarity measure and the Within-Class Whitened Cosine (WWC) similarity measure. Experiments on face recognition using the Face Recognition Grand Challenge (FRGC) version 2 database show the effectiveness of the new measures.	New Jersey Inst Technol, Dept Comp Sci, Newark, NJ 07102 USA	New Jersey Institute of Technology	Liu, CJ (corresponding author), New Jersey Inst Technol, Dept Comp Sci, Newark, NJ 07102 USA.	chengjun.liu@njit.edu						Beveridge JR, 2005, MACH VISION APPL, V16, P128, DOI 10.1007/s00138-004-0144-7; Bowyer K., 1998, EMPIRICAL EVALUATION; Bowyer K., 2006, P 2 WORKSH MULT US A; Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Jain AK, 2004, INT C PATT RECOG, P935, DOI 10.1109/ICPR.2004.1334413; Kumar B.V.K.V., 2002, P IEEE INT C IM PROC; Lebanon G, 2006, IEEE T PATTERN ANAL, V28, P497, DOI 10.1109/TPAMI.2006.77; Liu CJ, 2006, IEEE T PATTERN ANAL, V28, P725, DOI 10.1109/TPAMI.2006.90; Liu CJ, 2000, IEEE T IMAGE PROCESS, V9, P132, DOI 10.1109/83.817604; Moon H, 2001, PERCEPTION, V30, P303, DOI 10.1068/p2896; Pankanti S, 2000, COMPUTER, V33, P46, DOI 10.1109/2.820038; Paredes R, 2006, IEEE T PATTERN ANAL, V28, P1100, DOI 10.1109/TPAMI.2006.145; Phillips P.J., 2005, P IEEE C COMP VIS PA; Sebe N, 2000, IEEE T PATTERN ANAL, V22, P1132, DOI 10.1109/34.879793; Shih PC, 2005, INT J PATTERN RECOGN, V19, P873, DOI 10.1142/S0218001405004381; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wang H, 2006, IEEE T PATTERN ANAL, V28, P942, DOI 10.1109/TPAMI.2006.126; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	19	41	42	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2007	29	6					1086	1090		10.1109/TPAMI.2007.1063	http://dx.doi.org/10.1109/TPAMI.2007.1063			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	155TJ	17431305				2022-12-18	WOS:000245600800013
J	Dass, SC; Zhu, YF; Jain, AK				Dass, Sarat C.; Zhu, Yongfang; Jain, Anil K.			Validating a biometric authentication system: Sample size requirements	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						biometric authentication; error estimation; Gaussian copula models; bootstrap; ROC confidence bands		Authentication systems based on biometric features (e.g., fingerprint impressions, iris scans, human face images, etc.) are increasingly gaining widespread use and popularity. Often, vendors and owners of these commercial biometric systems claim impressive performance that is estimated based on some proprietary data. In such situations, there is a need to independently validate the claimed performance levels. System performance is typically evaluated by collecting biometric templates from n different subjects, and for convenience, acquiring multiple instances of the biometric for each of the n subjects. Very little work has been done in 1) constructing confidence regions based on the ROC curve for validating the claimed performance levels and 2) determining the required number of biometric samples needed to establish confidence regions of prespecified width for the ROC curve. To simplify the analysis that address these two problems, several previous studies have assumed that multiple acquisitions of the biometric entity are statistically independent. This assumption is too restrictive and is generally not valid. We have developed a validation technique based on multivariate copula models for correlated biometric acquisitions. Based on the same model, we also determine the minimum number of samples required to achieve confidence bands of desired width for the ROC curve. We illustrate the estimation of the confidence bands as well as the required number of biometric samples using a fingerprint matching system that is applied on samples collected from a small population.	Michigan State Univ, Dept Stat & Probabil, E Lansing, MI 48824 USA; Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Michigan State University; Michigan State University	Dass, SC (corresponding author), Michigan State Univ, Dept Stat & Probabil, A-430 Wells Hall, E Lansing, MI 48824 USA.	sdass@msu.edu; zhuyongf@msu.edu; jain@cse.msu.edu		Dass, Sarat/0000-0002-7376-0436				BEVERIDGE JR, 2001, P IEEE C COMP VIS PA; Biometrics Working Group (UK, 2000, BEST PRACT TEST REP; Bolle RM, 2004, COMPUT VIS IMAGE UND, V93, P1, DOI 10.1016/j.cviu.2003.08.002; Bolle RM, 2000, INT C PATT RECOG, P831, DOI 10.1109/ICPR.2000.906204; Bucklew J., 2013, SPR PRO COM, DOI [10.1007/978-1-4757-4078-3, 10.1007/978-1-4757-4036-3]; Cherubini U., 2004, COPULA METHODS FINAN; DASS SC, 2005, MSUCSE0523 DEP COMP; Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996; Jain AK, 1999, TR9914 MICH STAT U; Johnson AR., 1988, APPL MULTIVARIATE ST, V44, P920; MICHEALS RJ, 2001, P IEEE C COMP VIS PA; Miller RG., 1981, SIMULTANEOUS STAT IN, P1, DOI [10.1007/978-1-4613-8122-8_1, DOI 10.1007/978-1-4613-8122-8]; Morrison D. F., 1990, MULTIVARIATE STAT ME; Nelsen R., 1999, INTRO COPULAS; Porter J. E., 2000, NATL BIOMETRIC CTR C, P51; RAO CR, 1991, LINEAR STAT INFERENC; Schuckers ME., 2003, INT J IMAGE GR, V3, P523, DOI [10.1142/S0219467803001147, DOI 10.1142/S0219467803001147]; WAYMAN J, 1999, BIOMETRICS PERSONAL; WAYMAN J, 2000, NATL BIOMETRIC CTR C, P91; WAYMAN J, 2000, NATL BIOMETRIC CTR C, P67	20	41	42	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2006	28	12					1902	1913		10.1109/TPAMI.2006.255	http://dx.doi.org/10.1109/TPAMI.2006.255			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	093UL	17108366				2022-12-18	WOS:000241195700002
J	Salzenstein, F; Collet, C				Salzenstein, Fabien; Collet, Christophe			Fuzzy Markov random fields versus chains for multispectral image segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fuzzy Markov field; fuzzy Markov chain; parameterized joint density; multispectral image segmentation; missing data	CLASSIFICATION; INFERENCE	This paper deals with a comparison of recent statistical models based on fuzzy Markov random fields and chains for multispectral image segmentation. The fuzzy scheme takes into account discrete and continuous classes which model the imprecision of the hidden data. In this framework, we assume the dependence between bands and we express the general model for the covariance matrix. A fuzzy Markov chain model is developed in an unsupervised way. This method is compared with the fuzzy Markovian field model previously proposed by one of the authors. The segmentation task is processed with Bayesian tools, such as the well-known MPM (Mode of Posterior Marginals) criterion. Our goal is to compare the robustness and rapidity for both methods (fuzzy Markov fields versus fuzzy Markov chains). Indeed, such fuzzy-based procedures seem to be a good answer, e. g., for astronomical observations when the patterns present diffuse structures. Moreover, these approaches allow us to process missing data in one or several spectral bands which correspond to specific situations in astronomy [1]. To validate both models, we perform and compare the segmentation on synthetic images and raw multispectral astronomical data.	Inst Elect Solide & Syst, Lab InESS, F-67037 Strasbourg 2, France; Univ Strasbourg 1, ULP, CNRS, UMR 7005,LSIIT, F-67412 Illkirch Graffenstaden, France	Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; Universites de Strasbourg Etablissements Associes; Universite de Strasbourg	Salzenstein, F (corresponding author), Inst Elect Solide & Syst, Lab InESS, 23 Rue Loess,BP 20 CR, F-67037 Strasbourg 2, France.	salzenst@iness.c-strasbourg.fr; Christophe.Collet@ensps.u-strasbg.fr						Avrachenkov K. E., 2002, Fuzzy Optimization and Decision Making, V1, P143, DOI 10.1023/A:1015729400380; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; Benmiloud B., 1995, Traitement du Signal, V12, P433; Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; CAILLOL H, 1993, IEEE T GEOSCI REMOTE, V31, P801, DOI 10.1109/36.239902; CARINCOTTE C, 2005, P IEEE INT C FUZZ SY; CARINCOTTE C, 2004, P IEEE INT C AC SPEE; Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544; DEVIJVER PA, 1985, PATTERN RECOGN LETT, V3, P369, DOI 10.1016/0167-8655(85)90023-6; Fjortoft R, 2003, IEEE T GEOSCI REMOTE, V41, P675, DOI 10.1109/TGRS.2003.809940; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Germain M, 2002, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION FUSION, VOL I, P178, DOI 10.1109/ICIF.2002.1021148; Giordana N, 1997, IEEE T PATTERN ANAL, V19, P465, DOI 10.1109/34.589206; Hilbert D., 1891, MATH ANN, V38, P459, DOI [10.1007/bf01199431, DOI 10.1007/BF01199431, 10.1007/978-3-662-38452-7_1, 10.1007/BF01199431]; KENT JT, 1988, IEEE T PATTERN ANAL, V10, P659, DOI 10.1109/34.6774; Laferte JM, 2000, IEEE T IMAGE PROCESS, V9, P390, DOI 10.1109/83.826777; LIN Y, 2003, P INT C IM PROC ICIP; LOUYS M, 2003, P 3 WORKSH PHYS SIGN, P29; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; Mohamed MA, 2000, IEEE T FUZZY SYST, V8, P67, DOI 10.1109/91.824772; PEDRYCZ W, 1990, PATTERN RECOGN, V23, P121, DOI 10.1016/0031-3203(90)90054-O; PIECZYNSKI W, 1992, MACHINE GRAPHICS VIS, V1, P261; Provost JN, 2004, COMPUT VIS IMAGE UND, V93, P155, DOI 10.1016/j.cviu.2003.07.004; Ruan S, 2002, COMPUT VIS IMAGE UND, V85, P54, DOI 10.1006/cviu.2002.0957; Salzenstein F., 2004, Traitement du Signal, V21, P37; Salzenstein F, 1997, GRAPH MODEL IM PROC, V59, P205, DOI 10.1006/gmip.1997.0431; YOUNES L, 1989, PROBAB THEORY REL, V82, P625, DOI 10.1007/BF00341287; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	29	41	45	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2006	28	11					1753	1767		10.1109/TPAMI.2006.228	http://dx.doi.org/10.1109/TPAMI.2006.228			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	083GC	17063681				2022-12-18	WOS:000240443400004
J	Lim, CP; Leong, JH; Kuan, MM				Lim, CP; Leong, JH; Kuan, MM			A hybrid neural network system for pattern classification tasks with missing features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						missing data; Fuzzy ARTMAP; Fuzzy c-Means Clustering; pattern classification	INCOMPLETE DATA; ARCHITECTURE; ALGORITHM; TRIALS	A hybrid neural network comprising Fuzzy ARTMAP and Fuzzy C-Means Clustering is proposed for pattern classification with incomplete training and test data. Two benchmark problems and a real medical pattern classification task are employed to evaluate the effectiveness of the hybrid network. The results are analyzed and compared with those from other methods.	Univ Sci Malaysia, Sch Elect & Elect Engn, Nibong Tebal 14300, Penang, Malaysia	Universiti Sains Malaysia	Lim, CP (corresponding author), Univ Sci Malaysia, Sch Elect & Elect Engn, Engn Campus, Nibong Tebal 14300, Penang, Malaysia.	cplim@eng.usm.my; hwai@eng.usm.my; mmkuan@hotmail.com	Lim, Chee Peng/AAS-4698-2021; Lim, CP/D-1999-2009	Lim, CP/0000-0003-4191-9083				AFIFI AA, 1966, J AM STAT ASSOC, V61, P595, DOI 10.2307/2282773; Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; CARPENTER GA, 1992, IEEE T NEURAL NETWOR, V3, P698, DOI 10.1109/72.159059; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; Caudill M, 1990, NATURALLY INTELLIGEN; Curran D, 1998, STAT MED, V17, P697, DOI 10.1002/(SICI)1097-0258(19980315/15)17:5/7<697::AID-SIM815>3.0.CO;2-Y; Davidson A.C., 1997, BOOTSTRAP METHODS TH; EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552; FERNANDEZ M, 1998, P INT JOINT C NEUR N, V2, P1450; GHAHRAMANI Z, 1994, P ADV NEURAL INFORMA, V6, P120; GRANGER E, 2001, P IEEE INNS ENNS INT, V6, P35; Hathaway R. J., 2001, Neural, Parallel & Scientific Computations, V9, P19; Hathaway RJ, 2001, IEEE T SYST MAN CY B, V31, P735, DOI 10.1109/3477.956035; Huang XL, 2002, PATTERN RECOGN LETT, V23, P1613, DOI 10.1016/S0167-8655(02)00125-3; ISHIBUCHI H, 1993, P IEEE INT JOINT C N, P1871; Kahl F, 2001, IEEE T PATTERN ANAL, V23, P418, DOI 10.1109/34.917578; King G, 2001, AM POLIT SCI REV, V95, P49, DOI 10.1017/S0003055401000235; Lim CP, 1997, NEURAL NETWORKS, V10, P925, DOI 10.1016/S0893-6080(96)00123-2; Little R. J., 2019, STAT ANAL MISSING DA, V793; Morris AC, 1998, INT CONF ACOUST SPEE, P737, DOI 10.1109/ICASSP.1998.675370; MURRAY GD, 1988, STAT MED, V7, P941, DOI 10.1002/sim.4780070905; Newman C. B. D., 1998, UCI REPOSITORY MACHI; Nijman MJ, 1997, INT J NEURAL SYST, V8, P301, DOI 10.1142/S0129065797000318; TRESP V, 1995, P ADV NEURAL INFORMA, V7, P689; Yoon SY, 1999, NEURAL PROCESS LETT, V10, P171, DOI 10.1023/A:1018772122605	26	41	44	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2005	27	4					648	653		10.1109/TPAMI.2005.64	http://dx.doi.org/10.1109/TPAMI.2005.64			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	895FG	15794170				2022-12-18	WOS:000226845700016
J	Heidemann, G				Heidemann, G			Focus-of-attention from local color symmetries	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						focus-of-attention; color vision; symmetry; saliency maps; object recognition	CORNER DETECTION; MODEL; REPRESENTATION; RECOGNITION; FIXATION	In this paper, a continuous valued measure for local color symmetry is introduced. The new algorithm is an extension of the successful gray value-based symmetry map proposed by Reisfeld et al. The use of color facilitates the detection of focus points (FPs) on objects that are difficult to detect using gray-value contrast only. The detection of FPs is aimed at guiding the attention of an object recognition system; therefore, FPs have to fulfill three major requirements: stability, distinctiveness, and usability. The proposed algorithm is evaluated for these criteria and compared with the gray value-based symmetry measure and two other methods from the literature. Stability is tested against noise, object rotation, and variations of lighting. As a measure for the distinctiveness of FPs, the principal components of FP-centered windows are compared with those of windows at randomly chosen points on a large database of natural images. Finally, usability is evaluated in the context of an object recognition task.	Univ Bielefeld, Fac Technol, Neuroinformat Grp, D-33501 Bielefeld, Germany	University of Bielefeld	Heidemann, G (corresponding author), Univ Bielefeld, Fac Technol, Neuroinformat Grp, POB 100131, D-33501 Bielefeld, Germany.	gheidema@techfak.uni-bielefeld.de						ALOIMONOS J, 1987, INT J COMPUT VISION, V1, P333; ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; Backer G, 2001, IEEE T PATTERN ANAL, V23, P1415, DOI 10.1109/34.977565; BAJCSY R, 1992, CVGIP-IMAG UNDERSTAN, V56, P31, DOI 10.1016/1049-9660(92)90083-F; Bauckhage C., 1999, Pattern Recognition and Image Analysis, V9, P542; Beaudet P. R., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P579; BRAUN E, 1999, PATTERN RECOGNITION, V6; BRES S, 1999, P 3 INT C VIS INF SY, P424; BRUCE VG, 1975, PERCEPTION, V4, P239, DOI 10.1068/p040239; Brunnstrom K, 1996, INT J COMPUT VISION, V17, P137, DOI 10.1007/BF00058749; CHEN CH, 1995, PATTERN RECOGN, V28, P853, DOI 10.1016/0031-3203(94)00169-M; COTTIER JC, 1994, EXTRACTION APPARIEME; CROWLEY JL, 1993, PATTERN RECOGNITION, V7; DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705; DRESCHLER L, 1982, COMPUT VISION GRAPH, V20, P199, DOI 10.1016/0146-664X(82)90081-8; FORSTNER W, 1994, P EUR C COMP VIS, P383; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; HANCOCK PJB, 1992, NETWORK-COMP NEURAL, V3, P61, DOI 10.1088/0954-898X/3/1/008; Handmann U, 2000, IMAGE VISION COMPUT, V18, P367, DOI 10.1016/S0262-8856(99)00032-3; Haralick R.M., 1993, COMPUTER ROBOT VISIO, V2; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Heidemann G, 2000, INT C PATT RECOG, P9, DOI 10.1109/ICPR.2000.905265; Heidemann G, 2001, NEURAL PROCESS LETT, V13, P17, DOI 10.1023/A:1009678928250; Heidemann G, 1999, IEE CONF PUBL, P365, DOI 10.1049/cp:19991136; HEIDEMANN G, 1998, THESIS U BIELEFELD T; HEIDEMANN G, 1998, P 4 WORKSH FARBB VER, P65; HEITGER F, 1992, VISION RES, V32, P963, DOI 10.1016/0042-6989(92)90039-L; HORAUD R, 1990, P 1 EUR C COMP VIS A, P374; Householder A.S., 1964, THEORY MATRICES NUME; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; KALINKE T, 1996, MUSTERERKENNUNG 1996, P627; KAUFMAN L, 1969, PERCEPT PSYCHOPHYS, V5, P85, DOI 10.3758/BF03210527; Kitchen L, 1982, PATTERN RECOGN LETT, V1, P95, DOI 10.1016/0167-8655(82)90020-4; KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371; LAGANIERE R, 1996, P 6 INT C COMP VIS, P280; LEE JS, 1995, IEEE T IMAGE PROCESS, V4, P100, DOI 10.1109/83.350810; LINDEBERG T, 1993, INT J COMPUT VISION, V11, P283, DOI 10.1007/BF01469346; Locher PaulJ., 1987, EYE MOVEMENTS PHYSL, P353, DOI DOI 10.1016/B978-0-444-70113-8.50051-5; Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8; Mallat S., 1999, WAVELET TOUR SIGNAL; MEDIONI G, 1987, COMPUT VISION GRAPH, V39, P267, DOI 10.1016/S0734-189X(87)80181-0; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; Morevec H.P., 1977, INT JOINT C ART INT, V2, P584; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; NATTKEMPER TW, 1997, THESIS BIELEFELD U; Nene A. S., 1996, CUCS00696; *NOV DEV CORP, ART EXPL PHOT GALL; PALMER S, 1983, HUMAN MACHINE VISION; Privitera CM, 2000, IEEE T PATTERN ANAL, V22, P970, DOI 10.1109/34.877520; RAO RPN, 1995, ARTIF INTELL, V78, P461, DOI 10.1016/0004-3702(95)00026-7; RAO RPN, 1995, ADV NEURAL INFORMATI, V8; REISFELD D, 1995, INT J COMPUT VISION, V14, P119, DOI 10.1007/BF01418978; Rickheit G, 1996, ARTIF INTELL REV, V10, P165, DOI 10.1007/BF00127677; SANGER TD, 1989, NEURAL NETWORKS, V2, P459, DOI 10.1016/0893-6080(89)90044-0; Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Shilat E, 1997, PROC CVPR IEEE, P976, DOI 10.1109/CVPR.1997.609446; Shokoufandeh A, 1999, IMAGE VISION COMPUT, V17, P445, DOI 10.1016/S0262-8856(98)00124-3; Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710; STEIL J, 2001, P IEEE RSJ INT C INT; Tian Q, 2001, J ELECTRON IMAGING, V10, P835, DOI 10.1117/1.1406945; Tomasi C, 1991, CMUCS91132; TUYTELAARS T, 1999, P 3 INT C VIS INF SY, P493; ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508; Zheng ZQ, 1999, PATTERN RECOGN LETT, V20, P149, DOI 10.1016/S0167-8655(98)00134-2; Zitova B, 1999, PATTERN RECOGN LETT, V20, P199, DOI 10.1016/S0167-8655(98)00135-4	67	41	42	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2004	26	7					817	830		10.1109/TPAMI.2004.29	http://dx.doi.org/10.1109/TPAMI.2004.29			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	819OG	18579942				2022-12-18	WOS:000221323900001
J	Lam, W; Han, YQ				Lam, W; Han, YQ			Automatic textual document categorization based on generalized instance sets and a metamodel	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						text classification; instance-based learning; metamodel learning		We propose a new approach to text categorization known as generalized instance set (GIS) algorithm under the framework of generalized instance patterns. Our GIS algorithm unifies the strengths of k-NN and linear classifiers and adapts to characteristics of text categorization problems. It focuses on refining the original instances and constructs a set of generalized instances. We also propose a metamodel framework based on category feature characteristics. It has a metalearning phase which discovers a relationship between category feature characteristics and each component algorithm. Extensive experiments have been conducted on two large-scale document corpora for both GIS and the metamodel. The results demonstrate that both approaches generally achieve promising text categorization performance.	Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Shatin, Hong Kong, Peoples R China	Chinese University of Hong Kong	Lam, W (corresponding author), Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Shatin, Hong Kong, Peoples R China.	wlam@se.cuhk.edu.hk; yqhan@se.cuhk.edu.hk	Lam, Wai/GNW-3026-2022					Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, P148, DOI 10.1145/288627.288651; Joachims T., 2001, P 24 ANN INT ACM SIG, P128, DOI DOI 10.1145/383952.383974; KNERR S, 1992, IEEE T NEURAL NETWOR, V3, P962, DOI 10.1109/72.165597; LAM L, 1995, PATTERN RECOGN LETT, V16, P945, DOI 10.1016/0167-8655(95)00050-Q; LAM W, 1998, P 21 ANN INT ACM SIG, P81, DOI DOI 10.1145/290941.290961; LEWIS DD, 1996, P 19 ANN INT ACM SIG, P298; Nigam K., 1998, AAAI WORKSH; Rocchio J., 1971, SMART RETRIEVAL SYST, P313; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Sebastiani F., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P78, DOI 10.1145/354756.354804; Wermter S, 2000, INFORM RETRIEVAL, V3, P87, DOI 10.1023/A:1009942513170; Widrow B., 1985, ADAPTIVE SIGNAL PROC; YANG Y, 2000, P 17 INT C MACH LEAR, P1167; YANG Y, 1994, P 17 ANN INT ACM SIG, P13; Yang YM, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P42, DOI 10.1145/312624.312647	16	41	44	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2003	25	5					628	633		10.1109/TPAMI.2003.1195997	http://dx.doi.org/10.1109/TPAMI.2003.1195997			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	669FY					2022-12-18	WOS:000182342300009
J	Saund, E				Saund, E			Finding perceptually closed paths in sketches and drawings	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						contour closure; closed path; perceptual organization; Gestalt laws; sketch interpretation; line art analysis; graphics recognition	REPRESENTATION; IMAGE	Closed or nearly closed regions are an important form of perceptual structure arising both in natural imagery and in many forms of human-created imagery including sketches, line art, graphics, and formal drawings. This paper presents an effective algorithm especially suited for finding perceptually salient, compact closed region structure in hand-drawn sketches and line art. We start with a graph of curvilinear fragments whose proximal endpoints; form junctions. The key problem is to manage the search of possible path continuations through junctions in an effort to find paths satisfying global criteria for closure and figural salience. We identify constraints particular to this domain for ranking path continuations through junctions, based on observations of the ways that junctions arise in line drawings. In particular, we delineate the roles of the principle of good continuation versus maximally turning paths. Best-first bidirectional search checks for the cleanest, most obvious paths first, then reverts to more exhaustive search to find paths cluttered by blind alleys. Results are demonstrated on line drawings from several sources including line art, engineering drawings, sketches on whiteboards, as well as contours from photographic imagery.	Palo Alto Res Ctr, Palo Alto, CA 94304 USA		Saund, E (corresponding author), Palo Alto Res Ctr, 3333 Coyote Hill Rd, Palo Alto, CA 94304 USA.	saund@parc.com						ABLAMAYKO S, 1999, P 3 IAPR INT WORKSH, P313; Canham RO, 2000, PATTERN ANAL APPL, V3, P335, DOI 10.1007/s100440070005; Casadei S, 1999, COMPUT VIS IMAGE UND, V76, P19, DOI 10.1006/cviu.1999.0790; Dolan J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P264, DOI 10.1109/CVPR.1992.223265; ELDER JH, 1996, P 4 EUR C COMP VIS, P399; Fleck M. M., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P332; HUTTENLOCHER DP, 1992, INT J COMPUT VISION, V8, P7, DOI 10.1007/BF00126398; Jacobs DW, 1996, IEEE T PATTERN ANAL, V18, P23, DOI 10.1109/34.476008; JORGE J, 1999, P 3 IAPR INT WORKSH, P251; MAHAMUD S, 1999, P INT C COMP VIS; MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P1121, DOI 10.1109/34.42852; Pavlidis T., 1985, Computer Graphics, V19, P225, DOI 10.1145/325165.325240; SARKAR S, 1993, IEEE T PATTERN ANAL, V15, P256, DOI 10.1109/34.204907; Saund E., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P257, DOI 10.1109/CVPR.1992.223266; SAUND E, 1992, ARTIF INTELL, V54, P71, DOI 10.1016/0004-3702(92)90088-F; SAUND E, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P597, DOI 10.1109/ICCV.1995.466884; SAUND E, 1990, IEEE T PATTERN ANAL, V12, P817, DOI 10.1109/34.57672; SAUND E, 2001, P 4 IAPR INT WORKSH; SAUND E, 1994, P ACM S US INT SOFTW, P175; SAUND E, 1999, LECT NOTES COMPUTER, V1670; ULLMAN S, 1984, COGNITION, V18, P97, DOI 10.1016/0010-0277(84)90023-4	21	41	47	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2003	25	4					475	491		10.1109/TPAMI.2003.1190573	http://dx.doi.org/10.1109/TPAMI.2003.1190573			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	659BV					2022-12-18	WOS:000181758100008
J	Shi, D; Gunn, SR; Damper, RI				Shi, D; Gunn, SR; Damper, RI			Handwritten Chinese radical recognition using nonlinear active shape models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						handwritten Chinese character recognition; active shape model; kernel principal component analysis; chamfer distance transform; dynamic tunneling algorithm		Handwritten Chinese characters can be recognized by first extracting the basic shapes (radicals) of which they are composed. Radicals are described by nonlinear active shape models and optimal parameters found using the chamfer distance transform and a dynamic tunneling algorithm. The radical recognition rate is 96.5 percent correct (writer-independent) on 280,000 characters containing 98 radical classes.	Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; Univ Southampton, Dept Elect & Comp Sci, ISIS Grp, Southampton SO17 1BJ, Hants, England; Univ Southampton, Dept Elect & Comp Sci, ISIS Res Grp, Southampton SO17 1BJ, Hants, England	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; University of Southampton; University of Southampton	Shi, D (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Nanyang Ave, Singapore 639798, Singapore.	ASDMShi@ntu.edu.sg; srg@ecs.soton.ac.uk; rid@ecs.soton.ac.uk	Shi, Daming/F-6017-2013					BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; CHANG SK, 1973, IEEE T SYST MAN CYB, VSMC3, P257, DOI 10.1109/TSMC.1973.4309214; Chung FL, 2001, IEEE T SYST MAN CY C, V31, P126, DOI 10.1109/5326.923276; Cootes TF, 1999, IMAGE VISION COMPUT, V17, P567, DOI 10.1016/S0262-8856(98)00175-9; Duta N, 2001, IEEE T PATTERN ANAL, V23, P433, DOI 10.1109/34.922703; HEAP T, 1997, P BRIT MACH VIS C, P80; Jain AK, 1997, IEEE T PATTERN ANAL, V19, P1386, DOI 10.1109/34.643899; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Romdhani S, 1999, P 10 BRIT MACH VIS C, P483, DOI [10.5244/C.13.48, DOI 10.5244/C.13.48]; RoyChowdhury P, 2000, IEEE T SYST MAN CY A, V30, P384, DOI 10.1109/3468.844362; Scholkopf B, 1999, ADVANCES IN KERNEL METHODS, P327; SCHOLKOPF B, 1998, P 8 INT C ART NEUR N, P147; SHI D, 2001, P IEEE COMP SOC C CO, V1, P670; Sozou PD, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P107; SOZOU PD, 1995, IMAGE VISION COMPUT, V13, P451, DOI 10.1016/0262-8856(95)99732-G; Twining C. J., 2001, P BRIT MACH VIS C, V1, P23; Wang AB, 2001, PATTERN RECOGN, V34, P15, DOI 10.1016/S0031-3203(99)00207-1; YAO Y, 1989, IEEE T SYST MAN CYB, V19, P1222, DOI 10.1109/21.44040	19	41	45	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2003	25	2					277	280		10.1109/TPAMI.2003.1177158	http://dx.doi.org/10.1109/TPAMI.2003.1177158			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	637NX		Green Accepted			2022-12-18	WOS:000180519800011
J	Highnam, R; Brady, M				Highnam, R; Brady, M			Model-based image enhancement of far infrared images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image enhancement; far infrared imagery; homomorphic filtering; spatiotemporal filtering; Prometheus	LIGHTNESS	We devise enhancement algorithms for far infrared images based upon a model of an idealized far infrared image being piecewise-constant. We then apply two known enhancement algorithms: median filtering and spatial homomorphic filtering, and then extend the model to develop spatiotemporal homomorphic filtering. The algorithms have been applied io several image sequences and work well, showing significant image enhancement.			Highnam, R (corresponding author), UNIV OXFORD,DEPT ENGN SCI,ROBOT RES GRP,OXFORD OX1 3PJ,ENGLAND.							BLAKE A, 1985, COMPUT VISION GRAPH, V32, P314, DOI 10.1016/0734-189X(85)90054-4; BRELSTAFF G, 1987, PATTERN RECOGN LETT, V5, P129, DOI 10.1016/0167-8655(87)90034-1; FOULKES P, 1991, THESIS OXFORD U; HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126; Hecht E., 1974, OPTICS; HIGHNAM RP, 1996, 208796 OUEL OXF U EN; Horn B. K., 1974, COMPUT VISION GRAPH, V3, P277, DOI DOI 10.1016/0146-664X(74)90022-7; HORN BKP, 1985, ROBOT VISION; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; NANDHAKUMAR N, 1988, IEEE T PATTERN ANAL, V10, P469, DOI 10.1109/34.3911; NANDHAKUMAR N, 1986, SPIE APPL ARTIFICIAL, V635, P132; OHMAN C, 1981, SPIE, V313, P204; Wolfe W., 1985, INFRARED HDB	13	41	51	2	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1997	19	4					410	415		10.1109/34.588029	http://dx.doi.org/10.1109/34.588029			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WW122					2022-12-18	WOS:A1997WW12200012
J	Cabrera, J; Meer, P				Cabrera, J; Meer, P			Unbiased estimation of ellipses by bootstrapping	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						implicit models; curve fitting; bootstrap; low-level processing	ERROR	A general method for eliminating the bias of nonlinear estimators using bootstrap is presented. Instead of the traditional mean bias we consider the definition of bias based on the median. The method is applied to the problem of fitting ellipse segments to noisy data. No assumption beyond being independent identically distributed (i.i.d.) is made about the error distribution and experiments with both synthetic and real data prove the effectiveness of the technique.	RUTGERS STATE UNIV,DEPT ELECT & COMP ENGN,PISCATAWAY,NJ 08855	Rutgers State University New Brunswick	Cabrera, J (corresponding author), RUTGERS STATE UNIV,DEPT STAT,PISCATAWAY,NJ 08855, USA.							BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; CABRERA J, 1996, IN PRESS STAT PLANNI; CABRERA J, 1995, P 1995 C ISA BEIJ CH, P134; Chambers JM., 1992, STAT MODELS S; CHO K, 1995, IEEE INT S COMP VIS, P491; Efron B., 1994, MONOGR STAT APPL PRO, DOI DOI 10.1007/978-1-4899-4541-9; ELLIS T, 1992, IMAGE VISION COMPUT, V10, P271, DOI 10.1016/0262-8856(92)90041-Z; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Fuller W. A., 2009, MEASUREMENT ERROR MO; Haralick RM., 1992, COMPUTER ROBOT VISIO; JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628, DOI 10.1109/TPAMI.1987.4767957; JOSEPH SH, 1994, CVGIP-GRAPH MODEL IM, V56, P424, DOI 10.1006/cgip.1994.1039; KANATANI K, 1994, IEEE T PATTERN ANAL, V16, P320, DOI 10.1109/34.276132; Kanatani K., 1993, GEOMETRIC COMPUTATIO; KANAZAWA Y, 1995, P 2 AS C COMP VIS SI, V3, P397; Luong QT, 1996, INT J COMPUT VISION, V17, P43, DOI 10.1007/BF00127818; MANTEIGA WG, 1994, COMPUTATION STAT, V9, P165; POLITIS DN, 1994, ANN STAT, V22, P2031, DOI 10.1214/aos/1176325770; PORRILL J, 1990, IMAGE VISION COMPUT, V8, P37, DOI 10.1016/0262-8856(90)90054-9; ROSIN PL, 1993, PATTERN RECOGN LETT, V14, P799, DOI 10.1016/0167-8655(93)90062-I; SAFAEERAD R, 1991, CVGIP-IMAG UNDERSTAN, V54, P259, DOI 10.1016/1049-9660(91)90067-Y; THISTED RA, 1985, ELEMENTS STAT COMPUT; WERMAN M, 1995, IEEE T PATTERN ANAL, V17, P207, DOI 10.1109/34.368167; YOUNG GA, 1994, STAT SCI, V9, P382, DOI 10.1214/ss/1177010383	24	41	43	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1996	18	7					752	756		10.1109/34.506797	http://dx.doi.org/10.1109/34.506797			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UZ457					2022-12-18	WOS:A1996UZ45700007
J	SHU, CF; JAIN, RC				SHU, CF; JAIN, RC			VECTOR FIELD ANALYSIS FOR ORIENTED PATTERNS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						ORIENTED TEXTURES; FLUID FLOW VISUALIZATION; ESTIMATION THEORY	TOPOLOGY; PARALLAX; MOVEMENT	We present a method, based on the properties of vector fields, for the estimation of a set of symbolic descriptors (node, saddle, star-node, improper-node, center, and spiral) from linear orientation fields. Planar first-order phase portraits are used to model the linear orientation fields. A weighted linear estimator is developed to estimate linear phase portraits, using only the flow orientation. A classification scheme for planar first-order phase portraits, based on their local properties: curl, divergence, and deformation is developed. We present results of experiments on noise-added synthetic flow patterns and real oriented textures.	UNIV CALIF SAN DIEGO,DEPT ELECT & COMP ENGN,LA JOLLA,CA 92093	University of California System; University of California San Diego	SHU, CF (corresponding author), VIRAGE INC,11230 SORRENTO VALLEY RD,SUITE 150,SAN DIEGO,CA 92121, USA.							Arrowsmith D.K., 1982, ORDINARY DIFFERENTIA; DALLMAN U, 1983, DFVLRIB22182 TECH RE; DICKINSON RR, 1991, IBM J RES DEV, V35, P59, DOI 10.1147/rd.351.0059; Dyke M. V., 1982, ALBUM FLUID MOTION; HELMAN J, 1989, COMPUTER, P27; KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0; KOENDERINK JJ, 1975, OPT ACTA, V22, P773, DOI 10.1080/713819112; KOENDERINK JJ, 1976, J OPT SOC AM, V66, P717, DOI 10.1364/JOSA.66.000717; Kreyszig E., 1979, ADV ENG MATH; Lefschetz S., 1957, DIFF EQUAT+; Merzkirch W., 1974, FLOW VISUALIZATION; Ottino, 1989, KINEMATICS MIXING ST; Petterssen S., 1956, WEATHER ANAL FORECAS, VI; Press WH, 1988, NUMERICAL RECIPES C; RAO AR, 1992, IEEE T PATTERN ANAL, V14, P693, DOI 10.1109/34.142908; RAO AR, 1990, IBM RC15464 RES REP; RAO R, 1989, P IEEE C COMPUT VISI, P61; RAO R, 1990, 10 INT C PATT REC, V1, P336; Shu C.-F., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P352, DOI 10.1109/CVPR.1991.139715; SHU CF, 1993, THESIS U MICHIGAN AN; STRANG G, 1988, LINEAR ALGEBRA ITS A; TOBAK M, 1982, ANNU REV FLUID MECH, V14, P61, DOI 10.1146/annurev.fl.14.010182.000425	22	41	43	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1994	16	9					946	950		10.1109/34.310692	http://dx.doi.org/10.1109/34.310692			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PE802					2022-12-18	WOS:A1994PE80200012
J	YAOU, MH; CHANG, WT				YAOU, MH; CHANG, WT			FAST SURFACE INTERPOLATION USING MULTIRESOLUTION WAVELET TRANSFORM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						SURFACE INTERPOLATION; DISCRETIZATION; WAVELET TRANSFORM; BASIS TRANSFER SCHEME; PRECONDITIONING; REGULARIZATION	STEREO; RECONSTRUCTION	Discrete formulation of the surface interpolation problem usually leads to a large sparse linear equation system. Due to the poor convergence condition of the equation system, the convergence rate of solving this problem with iterative method is very slow. To improve this condition, a multiresolution basis transfer scheme based on the wavelet transform is proposed. By applying the wavelet transform, the original interpolation basis is transformed into two sets of bases with larger supports while the admissible solution space remains unchanged. With this basis transfer, a new set of nodal variables results and an equivalent equation system with better convergence condition can be solved. The basis transfer can be easily implemented by using an QMF matrix pair associated with the chosen interpolation basis. The consequence of the basis transfer scheme can be regarded as a preconditioner to the subsequent iterative computation method. The effect of the transfer is that the interpolated surface is decomposed into its low-frequency and high-frequency portions in the frequency domain. It has been indicated that the convergence rate of the interpolated surface is dominated by the low-frequency portion. With this frequency domain decomposition, the low-frequency portion of the interpolated surface can be emphasized. As compared with other acceleration methods, this basis transfer scheme provides a more systematical approach for fast surface interpolation. The easy implementation and high flexibility of the proposed algorithm also make it applicable to various regularization problems.	NATL CHZAO TUNG UNIV,CTR TELECOMMUN RES,DEPT COMMUN ENGN,HSINCHU 30039,TAIWAN		YAOU, MH (corresponding author), NATL CHIAO TUNG UNIV,INST COMMUN ENGN,DEPT ELECTR ENGN,HSINCHU 30039,TAIWAN.							[Anonymous], 1986, LONDON ACAD PRESS; CHIARADIA MT, 1989, OPT ENG, V28, P935, DOI 10.1117/12.7977065; CHUI CK, 1992, T AM MATH SOC, V330, P903, DOI 10.2307/2153941; Chui CK, 1992, INTRO WAVELETS; DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705; EASTMAN RD, 1987, COMPUT VISION GRAPH, V39, P73, DOI 10.1016/S0734-189X(87)80203-7; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; GRIMSON WEL, 1983, COMPUT VISION GRAPH, V22, P39, DOI 10.1016/0734-189X(83)90095-6; Groetsch C., 1984, SIAM REV; HACKBUSCH W., 1985, SPRINGER SER COMPUT, V4; HACKBUSCH W, 1982, MULTIGRID METHODS; HAGEMAN LA, 1981, APPLIED ITERATIVE ME; HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709; JAFFARD S, 1992, SIAM J NUMER ANAL, V29, P965, DOI 10.1137/0729059; MALLAT SG, 1989, IEEE T ACOUST SPEECH, V37, P2091, DOI 10.1109/29.45554; Marr D., 1982, VISION COMPUTATIONAL; PENTLAND AP, 1994, IEEE T PATTERN ANAL, V16, P410, DOI 10.1109/34.277594; PENTLAND AP, 1993, NEURAL COMPUT, V5, P430, DOI 10.1162/neco.1993.5.3.430; Prenter PM., 1975, SPLINES VARIATIONAL; REKTORYS K, 1980, VARIATIONAL METHODS; RUSKAI MB, 1992, WAVELETS THEIR APPLI; SZELISKI R, 1990, IEEE T PATTERN ANAL, V12, P513, DOI 10.1109/34.56188; TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; YOUNG DM, 1971, ITERATIVE SOLUTION L; YSERENTANT H, 1986, NUMER MATH, V49, P379, DOI 10.1007/BF01389538; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]	40	41	44	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1994	16	7					673	688		10.1109/34.297948	http://dx.doi.org/10.1109/34.297948			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NY134					2022-12-18	WOS:A1994NY13400001
J	LINDENBAUM, M; BRUCKSTEIN, A				LINDENBAUM, M; BRUCKSTEIN, A			ON RECURSIVE, O(N) PARTITIONING OF A DIGITIZED CURVE INTO DIGITAL STRAIGHT SEGMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						CHAIN CODE; DIGITAL STRAIGHT LINES; ONLINE ALGORITHMS; NUMBER THEORY	LINES; ALGORITHM; ESTIMATORS	A simple on-line algorithm for partitioning of a digital curve into digital straight-line segments of maximal length is given. The algorithm requires O(N) time and O(1) space and is therefore optimal. Efficient representations of the digital segments are obtained as byproducts. The algorithm also solves a number-theoretical problem concerning nonhomogeneus spectra of numbers.			LINDENBAUM, M (corresponding author), TECHNION ISRAEL INST TECHNOL,DEPT COMP SCI,HAIFA,ISRAEL.							BERENSTEIN CA, 1987, COMPUT VISION GRAPH, V40, P334, DOI 10.1016/S0734-189X(87)80146-9; BOSHERNITZAN M, 1984, J ALGORITHM, V5, P187, DOI 10.1016/0196-6774(84)90026-9; BRUCKSTEIN AM, 1991, CONT MATH, V119, P1; DORST L, 1984, IEEE T PATTERN ANAL, V6, P450, DOI 10.1109/TPAMI.1984.4767550; DORST L, 1986, IEEE T PATTERN ANAL, V8, P276, DOI 10.1109/TPAMI.1986.4767781; DORST L, 1987, COMPUT VISION GRAPH, V40, P311, DOI 10.1016/S0734-189X(87)80145-7; Fraenkel A.S., 1978, CANAD MATH B, V21, P441; GRAHAM RL, 1978, MATH MAG, V51, P174; HUNG SHY, 1985, IEEE T PATTERN ANAL, V7, P203, DOI 10.1109/TPAMI.1985.4767644; KIM CE, 1982, IEEE T PATTERN ANAL, V4, P149, DOI 10.1109/TPAMI.1982.4767221; Knuth D. E., 1969, ART COMPUTER PROGRAM, V2; KOPLOWITZ J, 1987, IEEE T PATTERN ANAL, V9, P451, DOI 10.1109/TPAMI.1987.4767927; KOPLOWITZ J, 1990, IEEE T INFORM THEORY, V36, P192, DOI 10.1109/18.50392; LINDENBAUM M, 1988, PATTERN RECOGN LETT, V7, P167, DOI 10.1016/0167-8655(88)90061-X; LINDENBAUM M, 1991, IEEE T PATTERN ANAL, V13, P847, DOI 10.1109/34.85678; MCILROY MD, 1984, AT&T TECH J, V64, P481; OROURKE J, 1981, COMMUN ACM, V24, P574, DOI 10.1145/358746.358758; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; RONSE C, 1989, IEEE T PATTERN ANAL, V11, P181, DOI 10.1109/34.16713; ROSENFELD A, 1974, IEEE T COMPUT, VC 23, P1264, DOI 10.1109/T-C.1974.223845; SMUELDERS AWM, 1991, VISION GEOMETRY, V119, P169; Venkov B.A., 1970, ELEMENTARY NUMBER TH; WERMAN M, 1987, PATTERN RECOGN LETT, V5, P207, DOI 10.1016/0167-8655(87)90065-1; Wright E., 1979, INTRO THEORY NUMBERS; WU LD, 1982, IEEE T PATTERN ANAL, V4, P347, DOI 10.1109/TPAMI.1982.4767258	25	41	41	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1993	15	9					949	953		10.1109/34.232082	http://dx.doi.org/10.1109/34.232082			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LW676					2022-12-18	WOS:A1993LW67600009
J	NASRABADI, NM				NASRABADI, NM			A STEREO VISION TECHNIQUE USING CURVE-SEGMENTS AND RELAXATION MATCHING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						BINOCULAR STEREO; STEREO VISION; 3-D COMPUTER VISION		In this paper, a multichannel feature-based stereo vision technique is described where curve segments are used as feature primitives in the matching process. The left image and the right image are first filtered by using several Laplacian of Gaussian operators DELTA-2 G of different widths (channel). Curve segments are extracted by a tracking algorithm, and their centroids are obtained. At each channel, the generalized Hough transform of each curve segment in the left and the right image is evaluated. This is done by calculating the R table representation of each curve segment using the centroid of the curve segment as the reference point. TheR table is used as a local feature vector in representing the distinctive characteristics of the curve segment. The epipolar constraint on the centroids of the curve segment and the channel size is used to limit the searching space in the right image. To resolve the ambiguity of the false targets (multiple matches), a relaxation technique is used where the initial scores of the node assignments am updated by the compatibility measures between the centroids of the curve segments. The node assignments with the highest score are chosen as the matching curve segments.	WORCESTER POLYTECH INST,DEPT ELECT ENGN,COMP VIS RES GRP,WORCESTER,MA 01609	Worcester Polytechnic Institute								BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BARNARD ST, 1982, ACM COMPUT SURV, V14, P553, DOI DOI 10.1145/356893.356896; BARNARD TB, 1988, APR P DARPA IMAG UND, P769; DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; MEDIONI G, 1985, COMPUT VISION GRAPH, V31, P2, DOI 10.1016/S0734-189X(85)80073-6; NASRABADI NM, 1989, IMAGE VISION COMPUT, V7, P237, DOI 10.1016/0262-8856(89)90026-7; NASRABADI NM, 1989, J OPT SOC AM A, V6, P900, DOI 10.1364/JOSAA.6.000900; RANADE S, 1980, PATTERN RECOGN, V12, P267	10	41	44	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1992	14	5					566	572		10.1109/34.134060	http://dx.doi.org/10.1109/34.134060			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HR650					2022-12-18	WOS:A1992HR65000005
J	FORSYTH, D; ZISSERMAN, A				FORSYTH, D; ZISSERMAN, A			REFLECTIONS ON SHADING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COMPUTER VISION; RADIOSITY; SHAPE FROM SHADING	ILLUMINATION; PERCEPTION; SHAPE	Mutual illumination forms a significant component of image radiance that is not modeled by the image irradiance equation. Its effects, which are easy to observe in real scenes, lead to complicated structures in radiance. Because mutual illumination is a global interaction, accounting for its effects in shape from shading schemes is impossible in the general case. We argue that as a result, dense depth maps produced by schemes that assume the image irradiance equation are intrinsically inaccurate. Discontinuities in radiance are well behaved (in a sense made precise in the paper) under mutual illumination and are a robust shape cue as a result. We discuss the few other such sources known at present. Throughout, these points are illustrated by images of real scenes.			FORSYTH, D (corresponding author), UNIV OXFORD,DEPT ENGN SCI,ROBOT RES GRP,OXFORD,ENGLAND.							BAUM DR, 1989, P COMPUTER GRAPHICS, P325; BLAKE A, 1985, IMAGE VISION COMPUT, V3, P183, DOI 10.1016/0262-8856(85)90006-X; BRADY JM, 1985, MIT AL824 LAB MEM; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CARRIHILL B, 1985, COMPUT VISION GRAPH, V32, P337, DOI 10.1016/0734-189X(85)90056-8; Cohen M.F., 1985, P ACM SIGGRAPH 85, P31; Cohen M.R., 1988, P SIGGRAPH 88, P75; COHEN MF, 1986, MAR IEEE COMP GRAPH, P27; FORSYTH D, 1990, IMAGE VISION COMPUT, V8, P42, DOI 10.1016/0262-8856(90)90055-A; FORSYTH DA, 1989, P CVPR; GILCHRIST A, 1984, PERCEPTION, V13, P5, DOI 10.1068/p130005; GILCHRIST AL, 1979, SCI AM, V240, P112, DOI 10.1038/scientificamerican0379-112; GORAL CM, 1984, P 11 ANN C COMP GRAP, P213; HATZITHEODOROU MG, 1988, P CVPR; HATZITHEODOROU MG, 1989, P DARPA IMAGE UNDERS; HEALEY G, 1987, 1ST P INT C COMP VIS, P151; Horn B., 1986, ROBOT VISION, P1; Horn B.K.P., 1975, PSYCHOL COMPUTER VIS; Horn B.K.P., 1989, SHAPE SHADING; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; IKEUCHI K, 1987, INT J ROBOT RES, V6; IKEUCHI K, 1986, INT J ROBOT RES, V5; KENDER J, 1986, P AAAI; KOENDERINK JJ, 1980, OPT ACTA, V27, P981, DOI 10.1080/713820338; KOENDERINK JJ, 1983, J OPT SOC AM, V73, P843, DOI 10.1364/JOSA.73.000843; MEYER GW, 1986, ACM T GRAPHIC, V5, P30, DOI 10.1145/7529.7920; MORRONE MC, 1987, PATTERN RECOGN LETT, V6, P303, DOI 10.1016/0167-8655(87)90013-4; Nayar S. K., 1990, CMURITR9014 CARN MEL; ONeill B., 1966, ELEMENTARY DIFFERENT; PEARSON DE, 1985, P IEEE, V74, P795; PERONA P, 1990, 3RD INT C COMP VIS; Tagare H. D., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P38, DOI 10.1109/CVPR.1989.37826; Tricomi F.G., 1985, INTEGRAL EQUATIONS, V5; WALLACE JR, 1987, P SIGGRAPH 87, P311; WALLACE JR, 1989, P SIGGRAPH 89 JUL, P315	35	41	43	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1991	13	7					671	679		10.1109/34.85657	http://dx.doi.org/10.1109/34.85657			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GA139					2022-12-18	WOS:A1991GA13900005
J	KUAN, D; PHIPPS, G; HSUEH, AC				KUAN, D; PHIPPS, G; HSUEH, AC			AUTONOMOUS ROBOTIC VEHICLE ROAD FOLLOWING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									FMC CORP,CENT ENGN LABS,CTR ARTIFICIAL INTELLIGENCE,SANTA CLARA,CA 95052									Duda R.O., 1973, J ROYAL STAT SOC SER; HSUEH A, 1986, TERRAIN TYPING VISIO; KUAN D, 1986, AUG P AAAI 86 NAT C; KUAN D, 1987, 1987 P IEEE INT C RO; KUAN D, 1985, 1985 P IEEE INT C RO; NITAO JJ, 1985, IEEE CONTR SYST  DEC; OHLANDER R, 1975, THESIS CARNEGIE MELL; OHTA Y, 1985, KNOWLEDGE BASED INTE; PEARSON G, 1985, 2ND P IEEE C ART INT; TURK M, 1986, OCT P SPIE MOB ROB C; Van Trees H., 2013, DETECTION ESTIMATION; WALLACE R, 1986, 1986 P IEEE INT C RO; WAXMAN AM, 1985, 1985 P IEEE INT C RO	13	41	69	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1988	10	5					648	658		10.1109/34.6773	http://dx.doi.org/10.1109/34.6773			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q4255					2022-12-18	WOS:A1988Q425500004
J	LECLERC, YG; ZUCKER, SW				LECLERC, YG; ZUCKER, SW			THE LOCAL-STRUCTURE OF IMAGE DISCONTINUITIES IN ONE DIMENSION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MCGILL UNIV,DEPT ELECT ENGN,COMP VIS & ROBOT LAB,MONTREAL H3A 2A8,QUEBEC,CANADA	McGill University	LECLERC, YG (corresponding author), SRI INT,CTR ARTIFICIAL INTELLIGENCE,MENLO PK,CA 94025, USA.							[Anonymous], 1985, PERCEPTUAL ORG VISUA; ASADA H, 1984, MIT AI758 MEM; Barrow H., 1978, COMPUT VIS SYST, V2, P2; Beck J., 1972, SURFACE COLOR PERCEP; BINFORD TO, 1981, ARTIF INTELL, V17, P205, DOI 10.1016/0004-3702(81)90025-4; BLAKE A, 1983, PATTERN RECOGNITION, V1, P392; BRAESS D, 1971, NUMER MATH, V17, P357, DOI 10.1007/BF01436085; CANNY JF, 1983, MIT AI720 MEM; CHOW GC, 1960, ECONOMETRICA, V28, P591, DOI 10.2307/1910133; Cornsweet T., 1970, VISUAL PERCEPTION; DEBOOR C, 1972, SPLINE FUNCTIONS APP, V21, P57; DESOUZA P, 1983, COMPUT VISION GRAPH, V23, P1, DOI 10.1016/0734-189X(83)90051-8; FISCHLER MA, 1983, 8TH P INT JOINT C AR; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; GILCHRIST AL, 1984, SCI AM, V240, P112; GRIMSON WEL, 1981, PHILOS T ROY SOC B, V292, P217, DOI 10.1098/rstb.1981.0031; HARALICK RM, 1980, COMPUT VISION GRAPH, V12, P60, DOI 10.1016/0146-664X(80)90004-0; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; HORN BKP, 1981, ARTIF INTELL, V15, P141; KENDER JR, 1979, 6 IJCAI TOK, P475; LECLERC YG, 1987, THESIS MCGILL U MONT; LECLERC YG, 1985, JUN P IEEE COMP SOC; LOZANOPEREZ T, 1977, COMPUT GRAPHICS IMAG, V6, P43; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Marr D., 1982, VISION; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; MCCLURE D, 1975, Q APPL MATH, V23, P1; MORGENTHALER DG, 1981, COMPUT VISION GRAPH, V16, P166, DOI 10.1016/0146-664X(81)90054-X; PENTLAND A, 1982, P NAT C ARTIF INTELL; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591; POGGIO T, 1985, MIT AI833 MEM; RUBIN JM, 1981, MIT AI631 MEM; RUTKOWSKI WS, 1978, TR623 U MAR COMP SCI; SHIRAI Y, 1978, COMPUTER VISION SYST; SUEN CY, 1980, P IEEE, V68, P469, DOI 10.1109/PROC.1980.11675; TENENBAUM JM, 1981, IMAGE MODELING, P371; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V3, P413; ULMAN S, 1979, ARTIFICIAL INTELLIGE, V2, P83; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19; Wikipedia, 2021, LINEAR REGRESSION; WITKIN A, 1983, 8TH P INT JOINT C AR; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9; WITKIN AW, 1982, P AAAI 82; ZUCKER SW, 1975, 4TH P INT JOINT C AR	46	41	41	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1987	9	3					341	355		10.1109/TPAMI.1987.4767918	http://dx.doi.org/10.1109/TPAMI.1987.4767918			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	H0768	22516629				2022-12-18	WOS:A1987H076800001
J	CROWLEY, JL; SANDERSON, AC				CROWLEY, JL; SANDERSON, AC			MULTIPLE RESOLUTION REPRESENTATION AND PROBABILISTIC MATCHING OF 2-D GRAY-SCALE SHAPE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									CARNEGIE MELLON UNIV,INST ROBOT,PITTSBURGH,PA 15213	Carnegie Mellon University								AYACHE N, 1984, 7TH P INT C PATT REC; BOLLES R, 1979, APR P SPIE TECH S IM; BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; CAMPBELL FW, 1968, J PHYSIOL-LONDON, V197, P551, DOI 10.1113/jphysiol.1968.sp008574; CAMPBELL FW, 1974, TRANSMISSION SPATIAL; CROWLEY JL, 1984, IEEE T PATTERN ANAL, V6, P156, DOI 10.1109/TPAMI.1984.4767500; CROWLEY JL, 1984, IEEE T PATTERN ANAL, V6, P212, DOI 10.1109/TPAMI.1984.4767504; CROWLEY JL, 1984, UNPUB MULTIRESOLUTIO; CROWLEY JL, CMURITR834 ROB I TEC; CROWLEY JL, 1981, THESIS CARNEGIEMELLO; GRIMSON WEL, 1981, IMAGES SURFACES; Hanson A., 1978, COMPUTER VISION SYST; HEBERT M, 1984, 8TH P IN C ART INT L; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; Kelly M., 1971, MACHINE INTELLIGENCE; Marr D., 1982, VISION; Pavlidis T., 1977, STRUCTURAL PATTERN R; ROSENFELD A, 1977, IEEE T SYST MAN CYB, V7, P104; SACHS MB, 1971, J OPT SOC AM, V61, P1176, DOI 10.1364/JOSA.61.001176; SANDERSON A, 1984, UNPUB PROBABILISTIC; SANDERSON AC, 1983, P IEEE, V71, P856, DOI 10.1109/PROC.1983.12683; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175; STOCKMAN G, 1984, TR84002 MICH STAT U; TANIMOTO SL, 1978, COMPUTER VISION SYST; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WILSON HR, 1979, VISION RES, V19, P19, DOI 10.1016/0042-6989(79)90117-2; Winston P. H., 1977, ARTIFICIAL INTELLIGE; WITKIN AP, 1983, 8TH P IJCAI; WONG AKC, 1980, IEEE T PATTERN ANAL, V2, P341, DOI 10.1109/TPAMI.1980.4767033	29	41	43	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1987	9	1					113	121		10.1109/TPAMI.1987.4767876	http://dx.doi.org/10.1109/TPAMI.1987.4767876			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	F3785	21869381				2022-12-18	WOS:A1987F378500009
J	FUKUNAGA, K; HUMMELS, DM				FUKUNAGA, K; HUMMELS, DM			BIAS OF NEAREST NEIGHBOR ERROR-ESTIMATES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											FUKUNAGA, K (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.							Beck J., 1979, Problems of Control and Information Theory, V8, P303; Cover T, 1968, P HAW INT C SYST SCI, V415, P413; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVROYE L, 1981, ANN STAT, V9, P1310, DOI 10.1214/aos/1176345647; DEVROYE L, 1981, IEEE T PATTERN ANAL, V3, P75, DOI 10.1109/TPAMI.1981.4767052; DEVROYE LP, 1980, ANN STAT, V8, P231, DOI 10.1214/aos/1176344949; FRASER DAS, 1957, NONPARAMETRIC METHOD, pCH4; FRITZ J, 1975, IEEE T INFORM THEORY, V21, P552, DOI 10.1109/TIT.1975.1055443; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P314, DOI 10.1109/TPAMI.1984.4767523; FUKUNAGA K, 1973, IEEE T INFORM THEORY, V19, P320, DOI 10.1109/TIT.1973.1055003; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P779, DOI 10.1109/TPAMI.1984.4767601; FUKUNAGA K, 1972, INTRO STATISTICAL PA, pCH2; GYORFI L, 1981, IEEE T INFORM THEORY, V27, P362, DOI 10.1109/TIT.1981.1056344; PETTIS KW, 1979, IEEE T PATTERN ANAL, V1, P25, DOI 10.1109/TPAMI.1979.4766873; ROGERS WH, 1978, ANN STAT, V6, P506, DOI 10.1214/aos/1176344196; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; WAGNER TJ, 1971, IEEE T INFORM THEORY, V17, P566, DOI 10.1109/TIT.1971.1054698	18	41	41	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1987	9	1					103	112		10.1109/TPAMI.1987.4767875	http://dx.doi.org/10.1109/TPAMI.1987.4767875			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	F3785	21869380				2022-12-18	WOS:A1987F378500008
J	MOAYER, B; FU, KS				MOAYER, B; FU, KS			A TREE SYSTEM APPROACH FOR FINGERPRINT PATTERN-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907	Purdue University System; Purdue University; Purdue University West Lafayette Campus								BHARGAVA BK, 1974, OCT P IEEE INT C SYS; CHAPEL C, 1971, FINGERPRINTING MANUA; CUMINS H, 1943, FINGERPRINTS PALMS S; DACEY NF, 1970, PATTERN RECOGNIT JAN; ELECCION M, 1973, IEEE SPECTRUM, V10, P36, DOI 10.1109/MSPEC.1973.5212832; FEDER J, 1971, INFORM SCI, V3; Fu K.S., 1974, MATH SCI ENG; FU KS, 1973, IEEE T COMPUT, VC 22, P1087, DOI 10.1109/T-C.1973.223654; FU KS, 1972, TREE7218 PURD U; GALLUS G, 1970, PHYS MED BIOL, V15, P435, DOI 10.1088/0031-9155/15/3/004; KIRSCH RA, 1964, IEEE T COMPUT, VEC13, P363, DOI 10.1109/PGEC.1964.263816; KOVASZNAY LSG, 1955, P IRE, V43, P560; LEE HC, 1972, DEC P COINS 72 S BAL; MOAYER B, 1973, OCT INT JOINT C PATT; MOAYER B, 1973, TREE7318 PURD U SCH; MOAYER B, 1974, PATTERN RECOGNITION, V6; PAVLIDIS I, 1972, J ASS COMPUT MAC JAN; PFALTZ JL, 1969, P INT JOINT C ARTIFI; 1963, FBI MANUAL	19	41	44	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1986	8	3					376	387		10.1109/TPAMI.1986.4767798	http://dx.doi.org/10.1109/TPAMI.1986.4767798			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	C0841	21869354				2022-12-18	WOS:A1986C084100007
J	BALLARD, DH; SABBAH, D				BALLARD, DH; SABBAH, D			VIEWER INDEPENDENT SHAPE-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											BALLARD, DH (corresponding author), UNIV ROCHESTER,DEPT COMP SCI,ROCHESTER,NY 14627, USA.							AGIN GJ, 1976, IEEE T COMPUT, V25, P440; BADLER NI, 1977, REPRESENTATION DISPL; BAJCSY R, 1980, 5TH P INT JOINT C PA; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BALLARD DH, 1981, RIGID BODY MOTION DE; BALLARD DH, 1981, 7TH P IJCAI VANC; BALLARD DH, UNPUB IEEE T PATTERN; BALLARD DH, 1982, COMPUT GRAPHICS IMAG; BALLARD DH, 1983, UNPUB ARTIFICIAL INT; BARROW HG, 1978, 157 SRI INT AI CTR T; BAUMGART BG, 1972, STANCS320AIM179 STAN; BROWN CM, 1981, IEEE T PATTERN ANAL, V3, P444, DOI 10.1109/TPAMI.1981.4767129; FELDMAN JA, 1982, 99 U ROCH DEP COMP S; FELDMAN JA, 1982, COGNITIVE SCI; FELDMAN JA, 1981, PARALLEL MODELS ASS; FELDMAN JA, 1981, 72 U ROCH DEP COMP S; Hinton G. E., 1979, COGNITIVE SCI, V3; HINTON GE, 1981, 7TH P INT JOINT C AR, P1088; HINTON GE, 1981, AUG P COGN SCI C BER, P56; HORN BKP, 1980, MIT AI572 MEM; IKEUCHI K, 1980, MIT AI566 MEM; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; MARR D, 1977, MIT AI451 MEM; Marr D, 1978, COMPUTER VISION SYST; PALMER SE, 1981, 3RD P ANN C COGN SCI, P41; ROCK I, 1973, ORIENTATION FORM; SCHUDY RB, THESIS U ROCHESTER; SHANI U, 1981, 82 U ROCH DEP COMP S; SLOAN KR, 1980, 5TH P INT C PATT REC, P174; SMITH D, 1979, MIT AI530 MEM; SUGIHARA K, 1979, ARTIFICIAL INTELL, V12	32	41	41	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	6					653	660		10.1109/TPAMI.1983.4767456	http://dx.doi.org/10.1109/TPAMI.1983.4767456			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RV488	21869153				2022-12-18	WOS:A1983RV48800013
J	ROSENFELD, A; SMITH, RC				ROSENFELD, A; SMITH, RC			THRESHOLDING USING RELAXATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											ROSENFELD, A (corresponding author), UNIV MARYLAND,CTR COMP SCI,COMP VIS LAB,COLLEGE PK,MD 20742, USA.							AHUJA N, 1980, PATTERN RECOGN, V12, P251, DOI 10.1016/0031-3203(80)90065-5; COLEMAN GB, 1979, P IEEE, V67, P773, DOI 10.1109/PROC.1979.11327; DANKER AJ, 1981, IEEE T PATTERN ANAL, V3, P79, DOI 10.1109/TPAMI.1981.4767053; DAVIS LS, 1978, IEEE T SYST MAN CYB, V8, P705; Dinneen G., 1955, P W JOINT COMP C, P94, DOI DOI 10.1145/1455292.1455311; EKLUNDH JO, 1980, IEEE T PATTERN ANAL, V2, P72, DOI 10.1109/TPAMI.1980.4766973; FEKETE G, UNPUBLISHED; PELEG S, 1978, IEEE T SYST MAN CYB, V8, P548; PELEG S, 1980, IEEE T PATTERN ANAL, V2, P362, DOI 10.1109/TPAMI.1980.4767035; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SCHACHTER BJ, 1977, IEEE T SYST MAN CYB, V7, P813; SCHACHTER BJ, 1978, PATTERN RECOGN, V11, P19; WESZKA JS, 1978, COMPUT VISION GRAPH, V7, P259, DOI 10.1016/0146-664X(78)90116-8; YAMAMOTO H, 1980, CGIP, V12, P31	15	41	44	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	5					598	606		10.1109/TPAMI.1981.4767152	http://dx.doi.org/10.1109/TPAMI.1981.4767152			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MQ358	21868978				2022-12-18	WOS:A1981MQ35800010
J	DYER, CR; ROSENFELD, A				DYER, CR; ROSENFELD, A			THINNING ALGORITHMS FOR GRAY-SCALE PICTURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											DYER, CR (corresponding author), UNIV MARYLAND,CTR COMP SCI,COLLEGE PK,MD 20742, USA.							ROSENFELD A, 1975, INFORM CONTROL, V29, P286, DOI 10.1016/S0019-9958(75)90448-9; ROSENFELD A, 1977, 573 U MAR COMP SCI T; STEFANELLI R, 1971, J ACM, V18, P255, DOI 10.1145/321637.321646	3	41	42	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	1					88	89		10.1109/TPAMI.1979.4766880	http://dx.doi.org/10.1109/TPAMI.1979.4766880			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HA303	21868835				2022-12-18	WOS:A1979HA30300011
J	SHINGHAL, R; TOUSSAINT, GT				SHINGHAL, R; TOUSSAINT, GT			EXPERIMENTS IN TEXT RECOGNITION WITH THE MODIFIED VITERBI ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MCGILL UNIV, SCH COMP SCI, MONTREAL H3C 3G1, QUEBEC, CANADA	McGill University	SHINGHAL, R (corresponding author), CONCORDIA UNIV, DEPT COMP SCI, MONTREAL H3G 1M8, QUEBEC, CANADA.							ABEND K, 1968, PATTERN RECOGN, P207; BAKER JK, 1975, SPEECH RECOGNITION, P521; BLEDSOE W. W., 1966, P301; CARLSON G, 1966, SPR P JOINT COMP C, P189; CHUNG SS, 1975, THESIS MCGILL U; CORNEW RW, 1968, INFORM CONTROL, V12, P79, DOI 10.1016/S0019-9958(68)90201-5; DONALDSON RW, 1970, IEEE T COMPUT, VC 19, P1096, DOI 10.1109/T-C.1970.222839; DUDA RO, 1968, 1968 FALL JOINT COMP, V33, P1139; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; Gardner W.R., 1962, UNCERTAINTY STRUCTUR; HANSON AR, 1976, PATTERN RECOGN, V8, P35, DOI 10.1016/0031-3203(76)90027-3; JELINEK F, 1976, P IEEE, V64, P532, DOI 10.1109/PROC.1976.10159; KASHYAP RL, 1977, JUN P IEEE COMP SOC, P76; Knuth D.E, 1975, ART COMPUTER PROGRAM, V1; KNUTH DE, 1975, ART COMPUTER PROGRAM, V3; NEUHOFF DL, 1975, IEEE T INFORM THEORY, V21, P222, DOI 10.1109/TIT.1975.1055355; RAVIV J, 1967, IEEE T INFORM THEORY, V13, P536, DOI 10.1109/TIT.1967.1054060; REDDY DR, 1976, P IEEE, V64, P501, DOI 10.1109/PROC.1976.10158; SHINGHAL R, 1978, IEEE T SYST MAN CYB, V8, P412; SHINGHAL R, 1977, THESIS MCGILL U; TOUSSAINT GT, 1978, MAY P IEEE COMP SOC, P164; TOUSSAINT GT, UNPUBLISHED; TOUSSAINT GT, 1972, P ANNU CANADIAN COMP; TOUSSAINT GT, 1977, JUN P IEEE COMP SOC, P1; VOSSLER CM, 1964, 19TH P ACM NAT C; Wolf J. J., 1976, Digital pattern recognition, P167	26	41	42	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	2					184	193		10.1109/TPAMI.1979.4766904	http://dx.doi.org/10.1109/TPAMI.1979.4766904			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HA304	21868847				2022-12-18	WOS:A1979HA30400008
J	He, W; Yao, QM; Li, C; Yokoya, N; Zhao, QB; Zhang, HY; Zhang, LP				He, Wei; Yao, Quanming; Li, Chao; Yokoya, Naoto; Zhao, Qibin; Zhang, Hongyan; Zhang, Liangpei			Non-Local Meets Global: An Iterative Paradigm for Hyperspectral Image Restoration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image restoration; Noise reduction; Tensile stress; Correlation; Task analysis; Image reconstruction; Image coding; Hyperspectral image; denoising; image restoration; non-local image modeling; low-rank tensor	MATRIX FACTORIZATION; FACE RECOGNITION; SPARSITY; RECONSTRUCTION; REPRESENTATION; MINIMIZATION; ALGORITHM; MODEL	Non-local low-rank tensor approximation has been developed as a state-of-the-art method for hyperspectral image (HSI) restoration, which includes the tasks of denoising, compressed HSI reconstruction and inpainting. Unfortunately, while its restoration performance benefits from more spectral bands, its runtime also substantially increases. In this paper, we claim that the HSI lies in a global spectral low-rank subspace, and the spectral subspaces of each full band patch group should lie in this global low-rank subspace. This motivates us to propose a unified paradigm combining the spatial and spectral properties for HSI restoration. The proposed paradigm enjoys performance superiority from the non-local spatial denoising and light computation complexity from the low-rank orthogonal basis exploration. An efficient alternating minimization algorithm with rank adaptation is developed. It is done by first solving a fidelity term-related problem for the update of a latent input image, and then learning a low-dimensional orthogonal basis and the related reduced image from the latent input image. Subsequently, non-local low-rank denoising is developed to refine the reduced image and orthogonal basis iteratively. Finally, the experiments on HSI denoising, compressed reconstruction, and inpainting tasks, with both simulated and real datasets, demonstrate its superiority with respect to state-of-the-art HSI restoration methods.	[He, Wei; Li, Chao; Yokoya, Naoto; Zhao, Qibin] RIKEN, Ctr Adv Intelligence Project AIP, Tokyo 1030027, Japan; [Yao, Quanming] Tsinghua Univ, Dept Elect Engn, Beijing 100083, Peoples R China; [Yao, Quanming] 4Paradigm Inc, Beijing 100083, Peoples R China; [Yokoya, Naoto] Univ Tokyo, Grad Sch Frontier Sci, Chiba 2778561, Japan; [Zhao, Qibin] Guangdong Univ Technol, Guangzhou 510006, Peoples R China; [Zhang, Hongyan; Zhang, Liangpei] Wuhan Univ, LISMARS, Wuhan 430072, Peoples R China	RIKEN; Tsinghua University; University of Tokyo; Guangdong University of Technology; Wuhan University	Yao, QM (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing 100083, Peoples R China.	wei.he@riken.jp; qyaoaa@connect.ust.hk; chao.li@riken.jp; naoto.yokoya@riken.jp; qibin.zhao@riken.jp; zhanghongyan@whu.edu.cn; zlp62@whu.edu.cn	Yao, Quanming/Y-6095-2019	Yao, Quanming/0000-0001-8944-8618	Japan Society for the Promotion of Science [KAKENHI 19K20308, KAKENHI 18K18067, KAKENHI 17K00326, KAKANHI 20H04249]; National Key Research and Development Program of China [2018YFB0504500]; National Natural Science Foundation of China [61871298, 62071132]	Japan Society for the Promotion of Science(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of Science); National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the Japan Society for the Promotion of Science (KAKENHI 19K20308; KAKENHI 18K18067; KAKENHI 17K00326; and KAKANHI 20H04249), the National Key Research and Development Program of China (2018YFB0504500) and the National Natural Science Foundation of China (61871298, 62071132).	An LTH, 2005, ANN OPER RES, V133, P23, DOI 10.1007/s10479-004-5022-1; Arce GR, 2014, IEEE SIGNAL PROC MAG, V31, P105, DOI 10.1109/MSP.2013.2278763; Bai X, 2018, IEEE J-STARS, V11, P701, DOI 10.1109/JSTARS.2018.2791718; Bauschke HH, 2008, SIAM J OPTIMIZ, V19, P766, DOI 10.1137/070687542; Bioucas-Dias JM, 2012, IEEE J-STARS, V5, P354, DOI 10.1109/JSTARS.2012.2194696; Bioucas-Dias JM, 2008, IEEE T GEOSCI REMOTE, V46, P2435, DOI 10.1109/TGRS.2008.918089; Cao CH, 2019, IEEE J-STARS, V12, P973, DOI 10.1109/JSTARS.2019.2896031; Cao WF, 2016, IEEE T IMAGE PROCESS, V25, P4075, DOI 10.1109/TIP.2016.2579262; Cao XY, 2016, IEEE T IMAGE PROCESS, V25, P4677, DOI 10.1109/TIP.2016.2593343; Chakrabarti A, 2011, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2011.5995660; Chang Y, 2020, IEEE T CYBERNETICS, V50, P4558, DOI 10.1109/TCYB.2020.2983102; Chang Y, 2019, IEEE T GEOSCI REMOTE, V57, P667, DOI 10.1109/TGRS.2018.2859203; Chang Y, 2017, PROC CVPR IEEE, P5901, DOI 10.1109/CVPR.2017.625; Chang Y, 2015, IEEE T IMAGE PROCESS, V24, P1852, DOI 10.1109/TIP.2015.2404782; Chen Y, 2020, IEEE T IMAGE PROCESS, V29, P6813, DOI 10.1109/TIP.2020.2994411; Chen Y, 2020, IEEE T CYBERNETICS, V50, P3556, DOI 10.1109/TCYB.2019.2936042; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Dian RW, 2020, IEEE T CYBERNETICS, V50, P4469, DOI 10.1109/TCYB.2019.2951572; Dian RW, 2021, IEEE T NEUR NET LEAR, V32, P1124, DOI 10.1109/TNNLS.2020.2980398; Dian RW, 2019, IEEE T IMAGE PROCESS, V28, P5135, DOI 10.1109/TIP.2019.2916734; Dian RW, 2019, IEEE T NEUR NET LEAR, V30, P2672, DOI 10.1109/TNNLS.2018.2885616; Dian RW, 2018, IEEE T NEUR NET LEAR, V29, P5345, DOI 10.1109/TNNLS.2018.2798162; Dian RW, 2017, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2017.411; Dong WS, 2015, IEEE I CONF COMP VIS, P442, DOI 10.1109/ICCV.2015.58; Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449; Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729; Fan B, 2015, IEEE J-STSP, V9, P990, DOI 10.1109/JSTSP.2015.2428678; Fowler JE, 2009, IEEE T IMAGE PROCESS, V18, P2230, DOI 10.1109/TIP.2009.2025089; Fu Y, 2017, INT J COMPUT VISION, V122, P228, DOI 10.1007/s11263-016-0921-6; Fu Y, 2016, PROC CVPR IEEE, P3727, DOI 10.1109/CVPR.2016.405; Gendrin C, 2008, J PHARMACEUT BIOMED, V48, P533, DOI 10.1016/j.jpba.2008.08.014; Golbabaee M, 2012, IEEE IMAGE PROC, P933, DOI 10.1109/ICIP.2012.6467014; Gong X, 2020, IEEE T SIGNAL PROCES, V68, P1168, DOI 10.1109/TSP.2020.2971441; Green RO, 1998, REMOTE SENS ENVIRON, V65, P227, DOI 10.1016/S0034-4257(98)00064-9; Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366; He W, 2019, PROC CVPR IEEE, P6861, DOI 10.1109/CVPR.2019.00703; He W, 2019, IEEE T GEOSCI REMOTE, V57, P8998, DOI 10.1109/TGRS.2019.2924017; He W, 2016, IEEE T GEOSCI REMOTE, V54, P176, DOI 10.1109/TGRS.2015.2452812; He W, 2015, IEEE J-STARS, V8, P3050, DOI 10.1109/JSTARS.2015.2398433; Ji TY, 2018, IEEE T GEOSCI REMOTE, V56, P3047, DOI 10.1109/TGRS.2018.2790262; Ji TY, 2016, INFORM SCIENCES, V326, P243, DOI 10.1016/j.ins.2015.07.049; Khan Z, 2015, IEEE T IMAGE PROCESS, V24, P4934, DOI 10.1109/TIP.2015.2472280; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Kwon H, 2006, IEEE T PATTERN ANAL, V28, P178, DOI 10.1109/TPAMI.2006.39; Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39; Liu XF, 2012, IEEE T GEOSCI REMOTE, V50, P3717, DOI 10.1109/TGRS.2012.2187063; Liu Y, 2019, IEEE T PATTERN ANAL, V41, P2990, DOI 10.1109/TPAMI.2018.2873587; Lu GL, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.1.010901; Lu XQ, 2013, IEEE T GEOSCI REMOTE, V51, P4009, DOI 10.1109/TGRS.2012.2226730; Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452; Martin G, 2016, IEEE J-STARS, V9, P2390, DOI 10.1109/JSTARS.2016.2541541; Martin G, 2015, IEEE T GEOSCI REMOTE, V53, P2819, DOI 10.1109/TGRS.2014.2365534; Ng MKP, 2017, IEEE T GEOSCI REMOTE, V55, P3367, DOI 10.1109/TGRS.2017.2670021; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Pan ZH, 2003, IEEE T PATTERN ANAL, V25, P1552, DOI 10.1109/TPAMI.2003.1251148; Parikh N., 2014, FDN TRENDS OPTIM, V1, P127, DOI DOI 10.1561/2400000003; Peng JJ, 2020, IEEE T IMAGE PROCESS, V29, P7889, DOI 10.1109/TIP.2020.3007840; Peng Y, 2014, PROC CVPR IEEE, P2949, DOI 10.1109/CVPR.2014.377; Rasti B, 2014, IEEE J-STARS, V7, P2458, DOI 10.1109/JSTARS.2013.2272879; Renard N, 2008, IEEE GEOSCI REMOTE S, V5, P138, DOI 10.1109/LGRS.2008.915736; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Stein DWJ, 2002, IEEE SIGNAL PROC MAG, V19, P58, DOI 10.1109/79.974730; Uzair M, 2015, IEEE T IMAGE PROCESS, V24, P1127, DOI 10.1109/TIP.2015.2393057; Wang LZ, 2017, IEEE T PATTERN ANAL, V39, P2104, DOI 10.1109/TPAMI.2016.2621050; Wang Y, 2017, IEEE GEOSCI REMOTE S, V14, P2457, DOI 10.1109/LGRS.2017.2771212; Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Waters A. E., 2011, 25 ANN C NEURAL INFO, P1089; Xie Q, 2018, IEEE T PATTERN ANAL, V40, P1888, DOI 10.1109/TPAMI.2017.2734888; Xie T, 2019, IEEE T CYBERNETICS, V49, P2344, DOI 10.1109/TCYB.2018.2825598; Xie Y, 2016, IEEE T IMAGE PROCESS, V25, P4842, DOI 10.1109/TIP.2016.2599290; Xie Y, 2016, IEEE T GEOSCI REMOTE, V54, P4642, DOI 10.1109/TGRS.2016.2547879; Xu YY, 2015, INVERSE PROBL IMAG, V9, P601, DOI 10.3934/ipi.2015.9.601; Xue J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020193; Yao QM, 2020, AAAI CONF ARTIF INTE, V34, P6664; Yao QM, 2019, PR MACH LEARN RES, V97; Yao Quanming, 2018, ARXIV181013306; Yasuma F, 2010, IEEE T IMAGE PROCESS, V19, P2241, DOI 10.1109/TIP.2010.2046811; Ye MC, 2015, IEEE T GEOSCI REMOTE, V53, P2621, DOI 10.1109/TGRS.2014.2363101; Yu Y., 2013, ADV NEURAL INFORM PR, P458; Yuan QQ, 2019, IEEE T GEOSCI REMOTE, V57, P1205, DOI 10.1109/TGRS.2018.2865197; Yuan X, 2016, IEEE IMAGE PROC, P2539, DOI 10.1109/ICIP.2016.7532817; Zhang HY, 2014, IEEE T GEOSCI REMOTE, V52, P4729, DOI 10.1109/TGRS.2013.2284280; Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300; Zhang L, 2018, INT J COMPUT VISION, V126, P797, DOI 10.1007/s11263-018-1080-8; Zhang L, 2016, IEEE T GEOSCI REMOTE, V54, P7223, DOI 10.1109/TGRS.2016.2598577; Zhang L, 2015, PROC CVPR IEEE, P2274, DOI 10.1109/CVPR.2015.7298840; Zhang SP, 2019, IEEE I CONF COMP VIS, P10182, DOI 10.1109/ICCV.2019.01028; Zhang ZM, 2014, PROC CVPR IEEE, P3842, DOI 10.1109/CVPR.2014.485; Zhuang L, 2018, IEEE J-STARS, V11, P730, DOI 10.1109/JSTARS.2018.2796570; Zhuang LN, 2017, IEEE IMAGE PROC, P1900	91	40	40	39	61	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					2089	2107		10.1109/TPAMI.2020.3027563	http://dx.doi.org/10.1109/TPAMI.2020.3027563			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	32991278				2022-12-18	WOS:000764815300032
J	Xie, Q; Zhou, MH; Zhao, Q; Xu, ZB; Meng, DY				Xie, Qi; Zhou, Minghao; Zhao, Qian; Xu, Zongben; Meng, Deyu			MHF-Net: An Interpretable Deep Network for Multispectral and Hyperspectral Image Fusion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Hyperspectral imaging; Task analysis; Network architecture; Testing; Sensors; Multispectral and hyperspectral image fusion; interpretable deep learning; image restoration; generalization	MATRIX FACTORIZATION; CLASSIFICATION; REGRESSION; RESOLUTION	Multispectral and hyperspectral image fusion (MS/HS fusion) aims to fuse a high-resolution multispectral (HrMS) and a low-resolution hyperspectral (LrHS) images to generate a high-resolution hyperspectral (HrHS) image, which has become one of the most commonly addressed problems for hyperspectral image processing. In this paper, we specifically designed a network architecture for the MS/HS fusion task, called MHF-net, which not only contains clear interpretability, but also reasonably embeds the well studied linear mapping that links the HrHS image to HrMS and LrHS images. In particular, we first construct an MS/HS fusion model which merges the generalization models of low-resolution images and the low-rankness prior knowledge of HrHS image into a concise formulation, and then we build the proposed network by unfolding the proximal gradient algorithm for solving the proposed model. As a result of the careful design for the model and algorithm, all the fundamental modules in MHF-net have clear physical meanings and are thus easily interpretable. This not only greatly facilitates an easy intuitive observation and analysis on what happens inside the network, but also leads to its good generalization capability. Based on the architecture of MHF-net, we further design two deep learning regimes for two general cases in practice: consistent MHF-net and blind MHF-net. The former is suitable in the case that spectral and spatial responses of training and testing data are consistent, just as considered in most of the pervious general supervised MS/HS fusion researches. The latter ensures a good generalization in mismatch cases of spectral and spatial responses in training and testing data, and even across different sensors, which is generally considered to be a challenging issue for general supervised MS/HS fusion methods. Experimental results on simulated and real data substantiate the superiority of our method both visually and quantitatively as compared with state-of-the-art methods along this line of research.	[Xie, Qi; Zhou, Minghao; Zhao, Qian; Xu, Zongben; Meng, Deyu] Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Shaanxi, Peoples R China; [Xie, Qi; Zhou, Minghao; Zhao, Qian; Xu, Zongben; Meng, Deyu] Xi An Jiao Tong Univ, Minist Educ, Key Lab Intelligent Networks & Network Secur, Xian 710049, Shaanxi, Peoples R China	Xi'an Jiaotong University; Xi'an Jiaotong University	Meng, DY (corresponding author), Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Shaanxi, Peoples R China.; Meng, DY (corresponding author), Xi An Jiao Tong Univ, Minist Educ, Key Lab Intelligent Networks & Network Secur, Xian 710049, Shaanxi, Peoples R China.	xq.liwu@stu.xjtu.edu.cn; woshizhouminghao@stu.xjtu.edu.cn; timmy.zhaoqian@mail.xjtu.edu.cn; zbxu@mail.xjtu.edu.cn; dymeng@mail.xjtu.edu.cn	zhou, minghao/GZA-7244-2022		National Key R&D Program of China [2018YFB1004300]; China NSFC [11690011,61721002, U1811461, 61773367]	National Key R&D Program of China; China NSFC(National Natural Science Foundation of China (NSFC))	This work was supported by the National Key R&D Program of China (2018YFB1004300), and the China NSFC projects under contracts 11690011,61721002, U1811461, and 61773367.	Aiazzi B, 2007, IEEE T GEOSCI REMOTE, V45, P3230, DOI 10.1109/TGRS.2007.901007; Akhtar N, 2014, LECT NOTES COMPUT SC, V8695, P63, DOI 10.1007/978-3-319-10584-0_5; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Bioucas-Dias JM, 2012, IEEE J-STARS, V5, P354, DOI 10.1109/JSTARS.2012.2194696; Cao XY, 2020, IEEE T GEOSCI REMOTE, V58, P4604, DOI 10.1109/TGRS.2020.2964627; CHAVEZ PS, 1991, PHOTOGRAMM ENG REM S, V57, P295; Debes C, 2014, IEEE J-STARS, V7, P2405, DOI 10.1109/JSTARS.2014.2305441; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Dong WS, 2019, IEEE T PATTERN ANAL, V41, P2305, DOI 10.1109/TPAMI.2018.2873610; DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009; Fauvel M, 2013, P IEEE, V101, P652, DOI 10.1109/JPROC.2012.2197589; Francesco Visin, 2018, Arxiv, DOI arXiv:1603.07285; Gomez RB, 2001, P SOC PHOTO-OPT INS, V4383, P36, DOI 10.1117/12.428249; Grohnfeldt C, 2013, INT GEOSCI REMOTE SE, P4090, DOI 10.1109/IGARSS.2013.6723732; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He L, 2019, IEEE J-STARS, V12, P3092, DOI 10.1109/JSTARS.2019.2917584; He L, 2019, IEEE J-STARS, V12, P1188, DOI 10.1109/JSTARS.2019.2898574; Huang B, 2014, IEEE T GEOSCI REMOTE, V52, P1693, DOI 10.1109/TGRS.2013.2253612; Jiang J, 2013, IEEE WORK APP COMP, P168, DOI 10.1109/WACV.2013.6475015; Kawakami R., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2329, DOI 10.1109/CVPR.2011.5995457; Lanaras C, 2015, IEEE I CONF COMP VIS, P3586, DOI 10.1109/ICCV.2015.409; Li ST, 2018, IEEE T IMAGE PROCESS, V27, P4118, DOI 10.1109/TIP.2018.2836307; Liu JG, 2000, INT J REMOTE SENS, V21, P3461, DOI 10.1080/014311600750037499; Loncan L, 2015, IEEE GEOSC REM SEN M, V3, P27, DOI 10.1109/MGRS.2015.2440094; Manolakis D, 2002, IEEE SIGNAL PROC MAG, V19, P29, DOI 10.1109/79.974724; Masi G, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8070594; Michel S., 2011, 2011 3 WORKSHOP HYPE, DOI [10.1109/WHISPERS.2011.6080864, DOI 10.1109/WHISPERS.2011.6080864]; Molina R, 2008, APPL COMPUT HARMON A, V24, P251, DOI 10.1016/j.acha.2007.03.006; Nezhad ZH, 2016, IEEE J-STARS, V9, P2377, DOI 10.1109/JSTARS.2016.2528339; Palsson F, 2017, IEEE GEOSCI REMOTE S, V14, P639, DOI 10.1109/LGRS.2017.2668299; Palsson F, 2014, IEEE GEOSCI REMOTE S, V11, P318, DOI 10.1109/LGRS.2013.2257669; Qu Y, 2018, PROC CVPR IEEE, P2511, DOI 10.1109/CVPR.2018.00266; Rao YZ, 2017, 2017 INTERNATIONAL WORKSHOP ON REMOTE SENSING WITH INTELLIGENT PROCESSING (RSIP 2017); Scarpa G, 2018, IEEE T GEOSCI REMOTE, V56, P5443, DOI 10.1109/TGRS.2018.2817393; Selva M, 2015, IEEE J-STARS, V8, P3008, DOI 10.1109/JSTARS.2015.2440092; Shao ZF, 2018, IEEE J-STARS, V11, P1656, DOI 10.1109/JSTARS.2018.2805923; Starck JL, 2007, IEEE T IMAGE PROCESS, V16, P297, DOI 10.1109/TIP.2006.887733; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tarabalka Y, 2010, IEEE T SYST MAN CY B, V40, P1267, DOI 10.1109/TSMCB.2009.2037132; Uzair M, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.57; Wald Lucien, 2002, DATA FUSION DEFINITI, P6; Wang LZ, 2019, PROC CVPR IEEE, P8024, DOI 10.1109/CVPR.2019.00822; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wei Q, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS (MFI), P21; Wei Q, 2015, IEEE T IMAGE PROCESS, V24, P4109, DOI 10.1109/TIP.2015.2458572; Wei YC, 2017, IEEE GEOSCI REMOTE S, V14, P1795, DOI 10.1109/LGRS.2017.2736020; Xie Q, 2019, PROC CVPR IEEE, P1585, DOI 10.1109/CVPR.2019.00168; Xie Q, 2018, IEEE T PATTERN ANAL, V40, P1888, DOI 10.1109/TPAMI.2017.2734888; Yang D, 2018, LECT NOTES COMPUT SC, V11211, P729, DOI 10.1007/978-3-030-01234-2_43; Yang Y, 2016, ADV NEUR IN, V29; Yasuma F, 2010, IEEE T IMAGE PROCESS, V19, P2241, DOI 10.1109/TIP.2010.2046811; Yokoya N, 2017, IEEE GEOSC REM SEN M, V5, P29, DOI 10.1109/MGRS.2016.2637824; Yokoya N, 2011, INT GEOSCI REMOTE SE, P1779, DOI 10.1109/IGARSS.2011.6049465; Yong HW, 2018, IEEE T PATTERN ANAL, V40, P1726, DOI 10.1109/TPAMI.2017.2732350; Yue ZS, 2019, ADV NEUR IN, V32; Yuhas R.H., 1993, DETERMINATION SEMIAR; Zeng Y., 2010, 2010 18 INT C GEOINF, P1, DOI DOI 10.1109/GEOINFORMATICS.2010.5568105; Zhang J, 2018, PROC CVPR IEEE, P1828, DOI 10.1109/CVPR.2018.00196; Zhang JW, 2017, PROC CVPR IEEE, P6969, DOI 10.1109/CVPR.2017.737; Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730; Zhang YF, 2015, INT GEOSCI REMOTE SE, P1929, DOI 10.1109/IGARSS.2015.7326172; Zhang YF, 2009, IEEE T GEOSCI REMOTE, V47, P3834, DOI 10.1109/TGRS.2009.2017737; Zhao YQ, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-87	64	40	42	50	95	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1457	1473		10.1109/TPAMI.2020.3015691	http://dx.doi.org/10.1109/TPAMI.2020.3015691			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32780695				2022-12-18	WOS:000752018000028
J	Lei, H; Akhtar, N; Mian, A				Lei, Huan; Akhtar, Naveed; Mian, Ajmal			Spherical Kernel for Efficient Graph Convolution on 3D Point Clouds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Kernel; Convolution; Neural networks; Feature extraction; Semantics; Computer architecture; 3D point cloud; spherical kernel; graph neural network; semantic segmentation	HISTOGRAMS	We propose a spherical kernel for efficient graph convolution of 3D point clouds. Our metric-based kernels systematically quantize the local 3D space to identify distinctive geometric relationships in the data. Similar to the regular grid CNN kernels, the spherical kernel maintains translation-invariance and asymmetry properties, where the former guarantees weight sharing among similar local structures in the data and the latter facilitates fine geometric learning. The proposed kernel is applied to graph neural networks without edge-dependent filter generation, making it computationally attractive for large point clouds. In our graph networks, each vertex is associated with a single point location and edges connect the neighborhood points within a defined range. The graph gets coarsened in the network with farthest point sampling. Analogous to the standard CNNs, we define pooling and unpooling operations for our network. We demonstrate the effectiveness of the proposed spherical kernel with graph neural networks for point cloud classification and semantic segmentation using ModelNet, ShapeNet, RueMonge2014, ScanNet and S3DIS datasets. The source code and the trained models can be downloaded from https://github.com/hlei-ziyan/SPH3D-GCN.	[Lei, Huan; Akhtar, Naveed; Mian, Ajmal] Univ Western Australia, Dept Comp Sci & Software Engn, 35 Stirling Highway, Crawley, WA 6009, Australia	University of Western Australia	Lei, H (corresponding author), Univ Western Australia, Dept Comp Sci & Software Engn, 35 Stirling Highway, Crawley, WA 6009, Australia.	huan.lei@research.uwa.edu.au; naveed.akhtar@uwa.edu.au; ajmal.mian@uwa.edu.au	AKHTAR, NAVEED/AAT-1283-2020	AKHTAR, NAVEED/0000-0003-3406-673X; Mian, Ajmal/0000-0002-5206-3842	Australian Research Council (ARC) [DP190102443]	Australian Research Council (ARC)(Australian Research Council)	This research was supported by the Australian Research Council (ARC) grant DP190102443. The Titan Xp GPU used for this research is donated by the NVIDIA Corporation.	Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/2951913.2976746, 10.1145/3022670.2976746]; Armeni I, 2016, PROC CVPR IEEE, P1534, DOI 10.1109/CVPR.2016.170; Atzmon M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201301; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Hua BS, 2018, PROC CVPR IEEE, P984, DOI 10.1109/CVPR.2018.00109; Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418; Bruna Joan, 2014, ICLR, DOI DOI 10.1145/3170427.3188467; Chang Angel X., 2015, ARXIV151203012CSGR P; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Choy C, 2019, PROC CVPR IEEE, P3070, DOI 10.1109/CVPR.2019.00319; Cohen T. S., 2018, P INT C LEARN REPR; Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693; Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; De Brabandere B, 2016, ADV NEUR IN, V29; Defferrard M, 2016, ADV NEUR IN, V29; Djork-Arn, ICLR 2016; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Dovrat O, 2019, PROC CVPR IEEE, P2755, DOI 10.1109/CVPR.2019.00287; Engelcke Martin, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1355, DOI 10.1109/ICRA.2017.7989161; Engelmann F, 2017, IEEE INT CONF COMP V, P716, DOI 10.1109/ICCVW.2017.90; Fey M, 2018, PROC CVPR IEEE, P869, DOI 10.1109/CVPR.2018.00097; Frome A, 2004, LECT NOTES COMPUT SC, V3023, P224; Gadde R, 2018, IEEE T PATTERN ANAL, V40, P1273, DOI 10.1109/TPAMI.2017.2696526; Gilani SZ, 2018, IEEE T PATTERN ANAL, V40, P1584, DOI 10.1109/TPAMI.2017.2725279; Graham B, 2018, PROC CVPR IEEE, P9224, DOI 10.1109/CVPR.2018.00961; Graham Benjamin, 2017, ARXIV170601307; Groh Fabian, 2018, ASIAN C COMPUTER VIS, P105; Hackel Timo, 2017, ARXIV170403847, VIV-1-W1, P91, DOI DOI 10.5194/ISPRS-ANNALS-IV-1-W1-91-2017; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hermosilla P, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275110; Huang J, 2016, INT C PATT RECOG, P2670, DOI 10.1109/ICPR.2016.7900038; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jaderberg M, 2015, ADV NEUR IN, V28; Kingma D.P, P 3 INT C LEARNING R; Kipf T.N., 2017, 5 INT C LEARN REPRES, P1; Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lafferty J., 2001, P 18 INT C MACHINE L, P282, DOI DOI 10.5555/645530.655813; Landrieu L, 2019, PROC CVPR IEEE, P7432, DOI 10.1109/CVPR.2019.00762; Landrieu L, 2018, PROC CVPR IEEE, P4558, DOI 10.1109/CVPR.2018.00479; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lei H, 2019, PROC CVPR IEEE, P9623, DOI 10.1109/CVPR.2019.00986; Li JX, 2018, PROC CVPR IEEE, P9397, DOI 10.1109/CVPR.2018.00979; Li YY, 2018, ADV NEUR IN, V31; Li YY, 2016, ADV NEUR IN, V29; Li Yujia, 2016, P INT C LEARN REPR I, P2; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Martinovic A, 2015, PROC CVPR IEEE, P4456, DOI 10.1109/CVPR.2015.7299075; Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481; Preparata F.P., 2012, COMPUTATIONAL GEOMET; Qi C.R., 2017, C NEUR INF PROC SYST, V5, P7; Qi XJ, 2017, IEEE I CONF COMP VIS, P5209, DOI 10.1109/ICCV.2017.556; Rao YM, 2019, PROC CVPR IEEE, P452, DOI 10.1109/CVPR.2019.00054; Redmon J., 2016, P IEEE C COMPUTER VI, P779, DOI DOI 10.1109/CVPR.2016.91; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701; Riemenschneider H, 2014, LECT NOTES COMPUT SC, V8693, P516, DOI 10.1007/978-3-319-10602-1_34; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Sedaghat N., 2017, P BRIT MACH VIS C BM; Shen YR, 2018, PROC CVPR IEEE, P4548, DOI 10.1109/CVPR.2018.00478; Simonovsky M, 2017, PROC CVPR IEEE, P29, DOI 10.1109/CVPR.2017.11; Simonyan Karen, 2015, INT C LEARN REPR; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187; Su H, 2018, PROC CVPR IEEE, P2530, DOI 10.1109/CVPR.2018.00268; Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tatarchenko M, 2018, PROC CVPR IEEE, P3887, DOI 10.1109/CVPR.2018.00409; Tchapmi LP, 2017, INT CONF 3D VISION, P537, DOI 10.1109/3DV.2017.00067; Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651; Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26; Tombari Federico, 2010, P ACM WORKSH 3D OBJ, P57, DOI DOI 10.1145/1877808.1877821; Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412; Wang L, 2019, PROC CVPR IEEE, P10288, DOI 10.1109/CVPR.2019.01054; Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274; Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985; Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801; Wu ZZ, 2014, COMPUT GRAPH-UK, V38, P248, DOI 10.1016/j.cag.2013.11.009; Xie SN, 2018, PROC CVPR IEEE, P4606, DOI 10.1109/CVPR.2018.00484; Xu YF, 2018, LECT NOTES COMPUT SC, V11212, P90, DOI 10.1007/978-3-030-01237-3_6; Ye XQ, 2018, LECT NOTES COMPUT SC, V11211, P415, DOI 10.1007/978-3-030-01234-2_25; Yi L, 2017, PROC CVPR IEEE, P6584, DOI 10.1109/CVPR.2017.697; Yi L, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980238; Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29; Zhang Yonghui, 2017, ICCV	93	40	41	13	48	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2021	43	10					3664	3680		10.1109/TPAMI.2020.2983410	http://dx.doi.org/10.1109/TPAMI.2020.2983410			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UK8RG	32248091	Green Submitted			2022-12-18	WOS:000692232400029
J	Li, YJ; Huang, JB; Ahuja, N; Yang, MH				Li, Yijun; Huang, Jia-Bin; Ahuja, Narendra; Yang, Ming-Hsuan			Joint Image Filtering with Deep Convolutional Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Joint filtering; deep convolutional neural networks; depth upsampling		Joint image filters leverage the guidance image as a prior and transfer the structural details from the guidance image to the target image for suppressing noise or enhancing spatial resolution. Existing methods either rely on various explicit filter constructions or hand-designed objective functions, thereby making it difficult to understand, improve, and accelerate these filters in a coherent framework. In this paper, we propose a learning-based approach for constructing joint filters based on Convolutional Neural Networks. In contrast to existing methods that consider only the guidance image, the proposed algorithm can selectively transfer salient structures that are consistent with both guidance and target images. We show that the model trained on a certain type of data, e.g., RGB and depth images, generalizes well to other modalities, e.g., flash/non-Flash and RGB/NIR images. We validate the effectiveness of the proposed joint filter through extensive experimental evaluations with state-of-the-art methods.	[Li, Yijun; Yang, Ming-Hsuan] Univ Calif Merced, Sch Engn, Merced, CA 95343 USA; [Huang, Jia-Bin] Virginia Tech, Dept Elect & Comp Engn, Blacksburg, VA 24061 USA; [Ahuja, Narendra] Univ Illinois, Dept Elect & Comp Engn, Champaign, IL 61820 USA	University of California System; University of California Merced; Virginia Polytechnic Institute & State University; University of Illinois System; University of Illinois Urbana-Champaign	Yang, MH (corresponding author), Univ Calif Merced, Sch Engn, Merced, CA 95343 USA.	yli62@ucmerced.edu; jbhuang@vt.edu; n-ahuja@illinois.edu; mhyang@ucmerced.edu	Yang, Ming-Hsuan/T-9533-2019; Yang, Ming-Hsuan/AAE-7350-2019	Yang, Ming-Hsuan/0000-0003-4848-2304; 				Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191; Barron JT, 2016, LECT NOTES COMPUT SC, V9907, P617, DOI 10.1007/978-3-319-46487-9_38; Burger HC, 2012, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2012.6247952; Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44; Chen QF, 2017, IEEE I CONF COMP VIS, P2516, DOI 10.1109/ICCV.2017.273; Diebel James, 2005, NEURAL INF PROCESS S, P291; Dollar P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Eigen D, 2013, IEEE I CONF COMP VIS, P633, DOI 10.1109/ICCV.2013.84; Eigen David, 2014, NEURIPS; Eisemann E, 2004, ACM T GRAPHIC, V23, P673, DOI 10.1145/1015706.1015778; Ferstl D, 2013, IEEE I CONF COMP VIS, P993, DOI 10.1109/ICCV.2013.127; Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592; Gu SH, 2017, PROC CVPR IEEE, P712, DOI 10.1109/CVPR.2017.83; Ham B, 2015, PROC CVPR IEEE, P4823, DOI 10.1109/CVPR.2015.7299115; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213; Hirschmuller Heiko, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383248; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Hui TW, 2016, LECT NOTES COMPUT SC, V9907, P353, DOI 10.1007/978-3-319-46487-9_22; JAMPANI V, 2016, PROC CVPR IEEE, P4452, DOI DOI 10.1109/CVPR.2016.482; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239547, 10.1145/1276377.1276497]; Kopf J, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366159; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618; Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780; Li YJ, 2016, LECT NOTES COMPUT SC, V9908, P154, DOI 10.1007/978-3-319-46493-0_10; Liu MY, 2013, PROC CVPR IEEE, P169, DOI 10.1109/CVPR.2013.29; Lu S, 2014, PROC CVPR IEEE, P3390, DOI 10.1109/CVPR.2014.433; Mai L, 2014, LECT NOTES COMPUT SC, V8691, P76, DOI 10.1007/978-3-319-10578-9_6; Park J, 2011, IEEE I CONF COMP VIS, P1623, DOI 10.1109/ICCV.2011.6126423; Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777; Shen XY, 2015, IEEE I CONF COMP VIS, P3406, DOI 10.1109/ICCV.2015.389; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412; Wu HY, 2007, IEEE I CONF COMP VIS, P628, DOI 10.1109/cvpr.2007.383211; Xu L, 2012, ACM T GRAPHIC, V31; Xu L, 2015, PR MACH LEARN RES, V37, P1669; Yan Q, 2013, IEEE I CONF COMP VIS, P1537, DOI 10.1109/ICCV.2013.194; Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407; Zhang JW, 2017, PROC CVPR IEEE, P6969, DOI 10.1109/CVPR.2017.737; Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53	48	40	42	2	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2019	41	8					1909	1923		10.1109/TPAMI.2018.2890623	http://dx.doi.org/10.1109/TPAMI.2018.2890623			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IG2BD	30605094	hybrid, Green Submitted			2022-12-18	WOS:000473598800009
J	Tang, JH; Shu, XB; Li, ZC; Jiang, YG; Tian, Q				Tang, Jinhui; Shu, Xiangbo; Li, Zechao; Jiang, Yu-Gang; Tian, Qi			Social Anchor-Unit Graph Regularized Tensor Completion for Large-Scale Image Retagging	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image retagging; anchor graph; tensor completion; image retrieval	TAG COMPLETION; MATRIX COMPLETION; FACTORIZATION; REFINEMENT; SEARCH; ROBUST; SPACE	Image retagging aims to improve the tag quality of social images by completing the missing tags, rectifying the noise-corrupted tags, and assigning new high-quality tags. Recent approaches simultaneously explore visual, user and tag information to improve the performance of image retagging by mining the tag-image-user associations. However, such methods will become computationally infeasible with the rapidly increasing number of images, tags and users. It has been proven that the anchor graph can significantly accelerate large-scale graph-based learning by exploring only a small number of anchor points. Inspired by this, we propose a novel Social anchor-Unit GrAph Regularized Tensor Completion (SUGAR-TC) method to efficiently refine the tags of social images, which is insensitive to the scale of data. First, we construct an anchor-unit graph across multiple domains (e.g., image and user domains) rather than traditional anchor graph in a single domain. Second, a tensor completion based on Social anchor-Unit GrAph Regularization (SUGAR) is implemented to refine the tags of the anchor images. Finally, we efficiently assign tags to non-anchor images by leveraging the relationship between the non-anchor units and the anchor units. Experimental results on a real-world social image database well demonstrate the effectiveness and efficiency of SUGAR-TC, outperforming the state-of-the-art methods.	[Tang, Jinhui; Shu, Xiangbo; Li, Zechao] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China; [Jiang, Yu-Gang] Fudan Univ, Sch Comp Sci, Shanghai 201203, Peoples R China; [Tian, Qi] Huawei, Noahs Ark Lab, Shenzhen 518129, Peoples R China	Nanjing University of Science & Technology; Fudan University; Huawei Technologies	Shu, XB (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.	jinhuitang@njust.edu.cn; shuxb@njust.edu.cn; zechao.li@njust.edu.cn; ygj@fudan.edu.cn; tian.qi1@huawei.com	Shu, Xiangbo/AAC-6245-2022	Shu, Xiangbo/0000-0003-4902-4663; Tang, Jinhui/0000-0001-9008-222X	National Key Research and Development Program of China [2016YFB1001001]; National Natural Science Foundation of China [61732007, 61702265]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by the National Key Research and Development Program of China under Grant 2016YFB1001001, in part by the National Natural Science Foundation of China under Grant 61732007 and Grant 61702265.	Candes EJ, 2010, P IEEE, V98, P925, DOI 10.1109/JPROC.2009.2035722; Chen B., 2012, P 20 ACM INT C MULTI, P1133; Chen Minmin, 2013, P 30 INT C MACH LEAR, P1274; Chua Tat-Seng, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646452; Cui P., 2014, TOIS, V32, P2; Deng C, 2013, IEEE I CONF COMP VIS, P2600, DOI 10.1109/ICCV.2013.323; Dhillon I. S., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P269, DOI 10.1145/502512.502550; Feng ZY, 2014, LECT NOTES COMPUT SC, V8695, P424, DOI 10.1007/978-3-319-10584-0_28; Fu JL, 2015, IEEE T CIRC SYST VID, V25, P1409, DOI 10.1109/TCSVT.2014.2380211; Harwood B, 2016, PROC CVPR IEEE, P5713, DOI 10.1109/CVPR.2016.616; Jiang QY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2248; Kim S, 2013, INT CONF ACOUST SPEE, P3123, DOI 10.1109/ICASSP.2013.6638233; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Li XR, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2906152; Li X, 2014, IEEE IMAGE PROC, P3062, DOI 10.1109/ICIP.2014.7025619; Li X, 2016, IEEE T MULTIMEDIA, V18, P474, DOI 10.1109/TMM.2016.2518478; Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750; Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140; Lin DK, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P64; Lin ZJ, 2013, PROC CVPR IEEE, P1618, DOI 10.1109/CVPR.2013.212; Liu J, 2010, INT CONF COMPUT AUTO, P491, DOI 10.1109/ICCAE.2010.5451908; Liu W., 2010, P 27 INT C MACH LEAR, P679; Liu W., 2014, ADV NEURAL INFORM PR, V4, P3419; Liu W, 2012, P IEEE, V100, P2624, DOI 10.1109/JPROC.2012.2197809; Liu W, 2011, SER INF MANAGE SCI, V10, P1; Liu XB, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2168996.2169001; Norouzi M, 2014, IEEE T PATTERN ANAL, V36, P1107, DOI 10.1109/TPAMI.2013.231; Qi GJ, 2012, IEEE T PATTERN ANAL, V34, P850, DOI 10.1109/TPAMI.2011.191; Rafailidis D, 2014, ACM T INTERACT INTEL, V3, DOI 10.1145/2487164; Sang J., 2011, P 19 ACM INT C MULT, P1129, DOI DOI 10.1145/2072298.2071956.ISBN; Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782; Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746; Suzuki I, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P857, DOI 10.1145/3077136.3080662; Tang J., 2011, ACM T INTEL SYST TEC, P14, DOI [10.1145/1899412.1899418, DOI 10.1145/1899412.1899418]; Tang JH, 2017, IEEE T PATTERN ANAL, V39, P1662, DOI 10.1109/TPAMI.2016.2608882; Tang JH, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2998574; Wang M, 2017, IEEE T KNOWL DATA EN, V29, P1101, DOI 10.1109/TKDE.2017.2654445; Wang M, 2016, IEEE T KNOWL DATA EN, V28, P1864, DOI 10.1109/TKDE.2016.2535367; Wang M, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333120; Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124; Wu YW, 2015, IEEE T IMAGE PROCESS, V24, P1510, DOI 10.1109/TIP.2015.2405479; Xiong YJ, 2013, IEEE I CONF COMP VIS, P585, DOI 10.1109/ICCV.2013.78; Xu B, 2015, IEEE T KNOWL DATA EN, V27, P102, DOI 10.1109/TKDE.2013.70; Xu HX, 2009, PROCEEDINGS OF THE 2009 WRI GLOBAL CONGRESS ON INTELLIGENT SYSTEMS, VOL III, P573, DOI 10.1109/GCIS.2009.320; Xu X, 2017, IEEE ACCESS, V5, P6688, DOI 10.1109/ACCESS.2016.2624267; Yang Y, 2011, WORLD WIDE WEB, V14, P133, DOI 10.1007/s11280-010-0099-8; Zhu G., 2010, ACM MULT, P461	49	40	40	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2019	41	8					2027	2034		10.1109/TPAMI.2019.2906603	http://dx.doi.org/10.1109/TPAMI.2019.2906603			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IG2BD	30908192	Green Submitted			2022-12-18	WOS:000473598800017
J	Tan, ZC; Wan, J; Lei, Z; Zhi, RC; Guo, GD; Li, SZ				Tan, Zichang; Wan, Jun; Lei, Zhen; Zhi, Ruicong; Guo, Guodong; Li, Stan Z.			Efficient Group-n Encoding and Decoding for Facial Age Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Age estimation; deep learning; convolutional neural network; age grouping; data imbalance	CLASSIFICATION; REGRESSION	Different ages are closely related especially among the adjacent ages because aging is a slow and extremely non-stationary process with much randomness. To explore the relationship between the real age and its adjacent ages, an age group-n encoding (AGEn) method is proposed in this paper. In our model, adjacent ages are grouped into the same group and each age corresponds to n groups. The ages grouped into the same group would be regarded as an independent class in the training stage. On this basis, the original age estimation problem can be transformed into a series of binary classification sub-problems. And a deep Convolutional Neural Networks (CNN) with multiple classifiers is designed to cope with such sub-problems. Later, a Local Age Decoding (LAD) strategy is further presented to accelerate the prediction process, which locally decodes the estimated age value from ordinal classifiers. Besides, to alleviate the imbalance data learning problem of each classifier, a penalty factor is inserted into the unified objective function to favor the minority class. To compare with state-of-the-art methods, we evaluate the proposed method on FG-NET. MORPH II, CACD and Chalearn LAP 2015 databases and it achieves the best performance.	[Tan, Zichang; Wan, Jun; Lei, Zhen; Li, Stan Z.] Chinese Acad Sci, Ctr Biometr & Secur Res, Room 1402,Intelligent Bldg,95 Zhongguancun Donglu, Beijing 100190, Peoples R China; [Tan, Zichang; Wan, Jun; Lei, Zhen; Li, Stan Z.] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Room 1402,Intelligent Bldg,95 Zhongguancun Donglu, Beijing 100190, Peoples R China; [Tan, Zichang] Univ Chinese Acad Sci, Beijing 100049, Peoples R China; [Zhi, Ruicong] Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Beijing 100083, Peoples R China; [Guo, Guodong] West Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA	Chinese Academy of Sciences; Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; University of Science & Technology Beijing; West Virginia University	Wan, J (corresponding author), Chinese Acad Sci, Ctr Biometr & Secur Res, Room 1402,Intelligent Bldg,95 Zhongguancun Donglu, Beijing 100190, Peoples R China.; Wan, J (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Room 1402,Intelligent Bldg,95 Zhongguancun Donglu, Beijing 100190, Peoples R China.	tanzichang2016@ia.ac.cn; jun.wan@nlpr.ia.ac.cn; zlei@nlpr.ia.ac.cn; zhirc@ustb.edu.cn; guodong.guo@mail.wvu.edu; szli@nlpr.ia.ac.cn	Guo, Guodong/M-5066-2015	Guo, Guodong/0000-0001-9583-0055; wan, jun/0000-0002-4735-2885	National Key Research and Development Plan [2016YFC0801002]; Chinese National Natural Science Foundation Projects [61502491, 61473291, 61572501, 61572536, 61673052]; Science and Technology Development Fund of Macau [112/2014/A3, 151/2017/A, 152/2017/A]; NVIDIA GPU donation program; AuthenMetric RD Funds	National Key Research and Development Plan; Chinese National Natural Science Foundation Projects(National Natural Science Foundation of China (NSFC)); Science and Technology Development Fund of Macau; NVIDIA GPU donation program; AuthenMetric RD Funds	This work was supported by the National Key Research and Development Plan (Grant No. 2016YFC0801002), the Chinese National Natural Science Foundation Projects #61502491, #61473291, #61572501, #61572536, #61673052, Science and Technology Development Fund of Macau (No. 112/2014/A3, 151/2017/A, 152/2017/A), NVIDIA GPU donation program and AuthenMetric R&D Funds. Zichang Tan and Jun Wan contribute equally to this paper.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], BMVC; Antipov G., 2016, P IEEE C COMP VIS PA, P96; Baro X, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301329; Basak D, 2007, NEURAL INFORM PROCES, V11, P203, DOI DOI 10.1007/978-1-4302-5990-9_4; Chang KY, 2011, PROC CVPR IEEE, P585, DOI 10.1109/CVPR.2011.5995437; Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374; CHEN K, 2013, PROC CVPR IEEE, P2467, DOI DOI 10.1109/CVPR.2013.319; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Escalera S, 2016, IEEE COMPUT SOC CONF, P706, DOI 10.1109/CVPRW.2016.93; Escalera S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P243, DOI 10.1109/ICCVW.2015.40; Fairhurst M., 2013, AGE FACTORS BIOMETRI; Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847; Fu Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1383; Gao F, 2009, LECT NOTES COMPUT SC, V5558, P132; GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9; Geng X, 2006, P 14 ACM INT C MULT, P307, DOI DOI 10.1145/1180639.1180711; Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733; Geng X, 2014, INT C PATT RECOG, P4465, DOI 10.1109/ICPR.2014.764; Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51; Gunay A, 2008, 23RD INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, P378; Guo G., 2013, P 10 IEEE INT C WORK, P1; Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280; Guo GD, 2011, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2011.5995404; Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681; Gurpinar F, 2016, IEEE COMPUT SOC CONF, P785, DOI 10.1109/CVPRW.2016.103; Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239; Huo Z., 2016, P IEEE C COMP VIS PA, P17; Huo ZW, 2016, IEEE COMPUT SOC CONF, P722, DOI 10.1109/CVPRW.2016.95; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549; Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091; Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352; Li S.Z., 2005, BENCAO GANGMU; Liu T, 2015, LECT NOTES COMPUT SC, V9428, P649, DOI 10.1007/978-3-319-25417-3_76; Liu X, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P258, DOI 10.1109/ICCVW.2015.42; Longadge R., 2013, INT J COMPUT SCI NET; Ma Y., 2009, INTELLIGENT VIDEO SU; Malli RC, 2016, IEEE COMPUT SOC CONF, P714, DOI 10.1109/CVPRW.2016.94; NIU ZX, 2016, PROC CVPR IEEE, P4920, DOI DOI 10.1109/CVPR.2016.532; Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341; Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3; Rothe R, 2016, PROC CVPR IEEE, P5553, DOI 10.1109/CVPR.2016.599; Rothe R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P252, DOI 10.1109/ICCVW.2015.41; Shan C., 2012, VIDEO ANAL BUSINESS; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tan Z., 2016, P AS C COMP VIS, P203; Uricar M, 2016, IEEE COMPUT SOC CONF, P730, DOI 10.1109/CVPRW.2016.96; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang XL, 2015, IEEE WINT CONF APPL, P534, DOI 10.1109/WACV.2015.77; Yang M, 2011, PROC CVPR IEEE, P505, DOI 10.1109/CVPR.2011.5995481; Yang X, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P344, DOI 10.1109/ICCVW.2015.53; Yi D, 2015, LECT NOTES COMPUT SC, V9005, P144, DOI 10.1007/978-3-319-16811-1_10; Zhang Y, 2010, PROC CVPR IEEE, P2622, DOI 10.1109/CVPR.2010.5539975; Zhu Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P267, DOI 10.1109/ICCVW.2015.43	59	40	43	1	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2018	40	11					2610	2623		10.1109/TPAMI.2017.2779808	http://dx.doi.org/10.1109/TPAMI.2017.2779808			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GW2AF	29990187				2022-12-18	WOS:000446683700007
J	Lapin, M; Hein, M; Schiele, B				Lapin, Maksim; Hein, Matthias; Schiele, Bernt			Analysis and Optimization of Loss Functions for Multiclass, Top-k, and Multilabel Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multiclass classification; multilabel classification; top-k error; top-k calibration; SDCA optimization	ALGORITHMS; CONSISTENCY	Top-k error is currently a popular performance measure on large scale image classification benchmarks such as ImageNet and Places. Despite its wide acceptance, our understanding of this metric is limited as most of the previous research is focused on its special case, the top-1 error. In this work, we explore two directions that shed more light on the top-k error. First, we provide an in-depth analysis of established and recently proposed single-label multiclass methods along with a detailed account of efficient optimization algorithms for them. Our results indicate that the softmax loss and the smooth multiclass SVM are surprisingly competitive in top-k error uniformly across all k, which can be explained by our analysis of multiclass top-k calibration. Further improvements for a specific k are possible with a number of proposed top-k loss functions. Second, we use the top-k methods to explore the transition from multiclass to multilabel learning. In particular, we find that it is possible to obtain effective multilabel classifiers on Pascal VOC using a single label per image for training, while the gap between multiclass and multilabel methods on MS COCO is more significant. Finally, our contribution of efficient algorithms for training with the considered top-k and multilabel loss functions is of independent interest.	[Lapin, Maksim; Schiele, Bernt] Max Planck Inst Informat, Comp Vis & Multimodal Comp Grp, D-66123 Saarbrucken, Saarland, Germany; [Hein, Matthias] Univ Saarland, Dept Math & Comp Sci, D-66123 Saarbrucken, Saarland, Germany	Max Planck Society; Saarland University	Lapin, M (corresponding author), Max Planck Inst Informat, Comp Vis & Multimodal Comp Grp, D-66123 Saarbrucken, Saarland, Germany.	mlapin@mpi-inf.mpg.de; hein@cs.uni-saarland.de; schiele@mpi-inf.mpg.de						Agarwal Shivani, 2011, P 2011 SIAM INT C DA; Akata Z, 2014, IEEE T PATTERN ANAL, V36, P507, DOI 10.1109/TPAMI.2013.146; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2009, 26 ANN INT C MACH LE, DOI DOI 10.1145/1553374.1553459; [Anonymous], 2013, ARXIV13124894; Bartlett PL, 2006, J AM STAT ASSOC, V101, P138, DOI 10.1198/016214505000000907; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Borwein J., 2006, CONVEX ANAL NONLINEA, DOI [10.1007/978-0-387-31256-9, DOI 10.1007/978-0-387-31256-9]; Boyd S, 2004, CONVEX OPTIMIZATION; Boyd S, 2012, ADV NEURAL INFORM PR, P953; Calauzenes C., 2012, ADV NEURAL INFORM PR, V25, P197; Cao Z., 2007, P 24 INT C MACH LEAR, P129, DOI DOI 10.1145/1273496.1273513; Chatfield K., 2014, BRIT MACH VIS C; Cheng W., 2010, P 27 INT C MACH LEAR, P279; Chris Burges T.S., 2005, P 22 INT MACH LEARN, DOI 10.1145/1102351.1102363; Cimpoi M, 2015, PROC CVPR IEEE, P3828, DOI 10.1109/CVPR.2015.7299007; Condat L, 2016, MATH PROGRAM, V158, P575, DOI 10.1007/s10107-015-0946-6; Corless RM, 1996, ADV COMPUT MATH, V5, P329, DOI 10.1007/BF02124750; Cossock D, 2006, LECT NOTES ARTIF INT, V4005, P605, DOI 10.1007/11776420_44; Crammer K, 2003, J MACH LEARN RES, V3, P1025, DOI 10.1162/153244303322533188; Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628; du Plessis MC, 2014, ADV NEUR IN, V27; Duchi John C., 2010, P 27 INT C MACH LEAR, P327; Elisseeff A, 2002, ADV NEUR IN, V14, P681; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fercoq O, 2015, SIAM J OPTIMIZ, V25, P1997, DOI 10.1137/130949993; Furnkranz J, 2008, MACH LEARN, V73, P133, DOI 10.1007/s10994-008-5064-8; Fukushima T, 2013, J COMPUT APPL MATH, V244, P77, DOI 10.1016/j.cam.2012.11.021; Gao W., 2011, P 24 ANN C LEARN THE, V19, P341; Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266; Guo Y., 2011, P 25 AAAI C ART INT, P374; Gupta MR, 2014, J MACH LEARN RES, V15, P1461; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Householder A.S., 1970, NUMERICAL TREATMENT; Hsieh C.J., 2008, P 25 INT C MACHINE L, P408, DOI DOI 10.1145/1390156.1390208; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Joachims T., 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]; Joachims Thorsten, 2005, ICML, DOI DOI 10.1145/1102351.1102399; Joulin A, 2016, LECT NOTES COMPUT SC, V9911, P67, DOI 10.1007/978-3-319-46478-7_5; Kanehira A, 2016, PROC CVPR IEEE, P5138, DOI 10.1109/CVPR.2016.555; Kiwiel KC, 2008, J OPTIMIZ THEORY APP, V136, P445, DOI 10.1007/s10957-007-9317-7; Kiwiel KC, 2008, MATH PROGRAM, V112, P473, DOI 10.1007/s10107-006-0050-z; Kocev D, 2007, LECT NOTES ARTIF INT, V4701, P624; Koyejo Oluwasanmi O, 2015, NIPS, V28, P3321; Krishnapuram B, 2005, IEEE T PATTERN ANAL, V27, P957, DOI 10.1109/TPAMI.2005.127; LAPIN M, 2015, ADV NEURAL INFORM PR, P325; Lapin M, 2016, PROC CVPR IEEE, P1468, DOI 10.1109/CVPR.2016.163; Li N., 2014, P NIPS, P1502; Li Ping, 2007, ADV NEURAL INFORM PR, P897; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu T-Y., 2009, FOUND TRENDS INF RET, V3, P225, DOI DOI 10.1561/1500000016; Liu TL, 2016, IEEE T PATTERN ANAL, V38, P447, DOI 10.1109/TPAMI.2015.2456899; Madjarov G, 2012, PATTERN RECOGN, V45, P3084, DOI 10.1016/j.patcog.2012.03.004; Mairal J., 2010, ADV NEURAL INFORM PR, P1558, DOI [DOI 10.5555/2997046.2997070, 10.5555/2997046.2997070]; McAuley JJ, 2013, INT J COMPUT VISION, V104, P343, DOI 10.1007/s11263-012-0561-4; McFee B., 2010, P 27 INT C MACHINE L, P775; Mensink T, 2013, IEEE T PATTERN ANAL, V35, P2624, DOI 10.1109/TPAMI.2013.83; Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Oquab M, 2015, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2015.7298668; Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222; Parikh Neal, 2014, Foundations and Trends in Optimization, V1, P127, DOI 10.1561/2400000003; Patriksson M, 2015, EUR J OPER RES, V243, P703, DOI 10.1016/j.ejor.2015.01.029; Peters J, 2017, ADAPT COMPUT MACH LE; Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537; Rakotomamonjy A., 2012, P 29 ICML, P1335; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Reid MD, 2010, J MACH LEARN RES, V11, P2387; Rifkin R, 2004, J MACH LEARN RES, V5, P101; Ross S., 2013, P INT C MACH LEARN; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Schutze H., 2008, INTRO INFORM RETRIEV, V39; Shalev-Shwartz S, 2006, J MACH LEARN RES, V7, P1567; Shalev-Shwartz S, 2016, MATH PROGRAM, V155, P105, DOI 10.1007/s10107-014-0839-0; Swersky K., 2012, NIPS, P3050; Taylor M., 2008, P 2008 INT C WEB SEA, P77, DOI DOI 10.1145/1341531.1341544; Tewari A, 2007, J MACH LEARN RES, V8, P1007; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Tsoumakas G., 2007, INT J DATA WAREHOUS, V3, P1; Tsoumakas  Grigorios, 2008, P ECML PKDD 2008 WOR, V21, P53; Usunier Nicolas, 2009, ICML; Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412; Vembu S, 2010, PREFERENCE LEARNING, P45, DOI 10.1007/978-3-642-14125-6_3; Vernet Elodie, 2011, NIPS 24, P1224; Wah Catherine, 2011, CALTECH UCSD BIRDS 2; Wang J., 2016, ARXIV160404573; Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180; Wang Limin, 2015, ARXIV150702159; Wang M, 2016, IEEE T IMAGE PROCESS, V26, P5678, DOI 10.1109/TIP.2016.2612829; Wang M, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333120; Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929; Wei ZJ, 2016, PROC CVPR IEEE, P2987, DOI 10.1109/CVPR.2016.326; Weston Jason, 2011, 22 INT JOINT C ART I; Xia Fen, 2008, P 25 INT C MACH LEAR, P1192, DOI DOI 10.1145/1390156.1390306; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Yisong Yue, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P271; Yu HF, 2011, MACH LEARN, V85, P41, DOI 10.1007/s10994-010-5221-8; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39; Zhang T, 2004, ANN STAT, V32, P56; Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763; Zhao  Rui-Wei, 2016, P BRIT MACH VIS C; Zhou Bolei, 2014, ADV NEURAL INFORM PR, P7, DOI DOI 10.5555/2968826.2968881	108	40	40	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2018	40	7					1533	1554		10.1109/TPAMI.2017.2751607	http://dx.doi.org/10.1109/TPAMI.2017.2751607			22	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GI3TS	28920896	Green Submitted			2022-12-18	WOS:000434294800001
J	Carletti, V; Foggia, P; Saggese, A; Vento, M				Carletti, Vincenzo; Foggia, Pasquale; Saggese, Alessia; Vento, Mario			Challenging the Time Complexity of Exact Subgraph Isomorphism for Huge and Dense Graphs with VF3	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graphs; graph matching; graph isomorphism; subgraph isomorphism; graphs dataset	ALGORITHM; COMPUTATION; NETWORKS	Graph matching is essential in several fields that use structured information, such as biology, chemistry, social networks, knowledge management, document analysis and others. Except for special classes of graphs, graph matching has in the worst-case an exponential complexity; however, there are algorithms that show an acceptable execution time, as long as the graphs are not too large and not too dense. In this paper we introduce a novel subgraph isomorphism algorithm, VF3, particularly efficient in the challenging case of graphs with thousands of nodes and a high edge density. Its performance, both in terms of time and memory, has been assessed on a large dataset of 12,700 random graphs with a size up to 10,000 nodes, made publicly available. VF3 has been compared with four other state-of-the-art algorithms, and the huge experimentation required more than two years of processing time. The results confirm that VF3 definitely outperforms the other algorithms when the graphs become huge and dense, but also has a very good performance on smaller or sparser graphs.	[Carletti, Vincenzo; Foggia, Pasquale; Saggese, Alessia; Vento, Mario] Univ Salerno, Dept Informat & Elect Engn & Appl Math, I-84084 Fisciano, SA, Italy	University of Salerno	Carletti, V (corresponding author), Univ Salerno, Dept Informat & Elect Engn & Appl Math, I-84084 Fisciano, SA, Italy.	vcarletti@unisa.it; pfoggia@unisa.it; asaggese@unisa.it; mvento@unisa.it	Saggese, Alessia/AAB-2397-2019	Saggese, Alessia/0000-0003-4687-7994; Vento, Mario/0000-0002-2948-741X				Almasri I, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P517, DOI 10.1109/ICDMW.2014.65; [Anonymous], 2017, VF3 EXPT RESULTS; [Anonymous], 2017, MIVIA LARGE DENSE GR; [Anonymous], JEA; [Anonymous], 2014, PATTERN RECOG; Battiti R., 2007, ALGORITHM PORTFOLIO, P106; Boccaletti S, 2006, PHYS REP, V424, P175, DOI 10.1016/j.physrep.2005.10.009; Bonnici V, 2017, IEEE ACM T COMPUT BI, V14, P193, DOI 10.1109/TCBB.2016.2515595; Bonnici V, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-S7-S13; Bunke H., 1999, P 2 WORKSH GRAPH BAS, P109; Carletti Vincenzo, 2015, Graph-Based Representations in Pattern Recognition. 10th IAPR-TC-15 International Workshop, GbRPR 2015. Proceedings: LNCS 9069, P178, DOI 10.1007/978-3-319-18224-7_18; Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228; Cordella L. P., 2001, 3 IAPR TC15 WORKSH G, P149; Cordella LP, 2004, IEEE T PATTERN ANAL, V26, P1367, DOI 10.1109/TPAMI.2004.75; De Santo M, 2003, PATTERN RECOGN LETT, V24, P1067, DOI 10.1016/S0167-8655(02)00253-2; Foggia P., 2001, P 3 IAPR TC 15 WORKS, P188; Foggia P., 2001, P 3 IAPR TC 15 INT W, P176; Foggia P, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414500013; Han Wook-Shin, 2013, SIGMOD, P337, DOI [10.1145, 10.1145/ferenceonManagementof2463676.2465300]; He H., 2008, P ACM SIGMOD INT C M, P405, DOI [10.1145/1376616.1376660, DOI 10.1145/1376616.1376660]; KOTTHOFF L, 2016, P LEARN INT OPT C, V79, P107, DOI DOI 10.1007/978-3-319-50349-3_8; Larrosa J., 2002, Mathematical Structures in Computer Science, V12, P403, DOI 10.1017/S0960129501003577; Liu CL, 2017, PATTERN RECOGN LETT, V87, P1, DOI 10.1016/j.patrec.2016.10.008; Livi L, 2013, PATTERN ANAL APPL, V16, P253, DOI 10.1007/s10044-012-0284-8; LUKS EM, 1982, J COMPUT SYST SCI, V25, P42, DOI 10.1016/0022-0000(82)90009-5; Luo B, 2001, IEEE T PATTERN ANAL, V23, P1120, DOI 10.1109/34.954602; MCGREGOR JJ, 1979, INFORM SCIENCES, V19, P229, DOI 10.1016/0020-0255(79)90023-9; Nilsson N., 1982, PRINCIPLES ARTIFICIA; Pelillo M, 1999, NEURAL COMPUT, V11, P1933, DOI 10.1162/089976699300016034; Riesen K, 2009, IMAGE VISION COMPUT, V27, P950, DOI 10.1016/j.imavis.2008.04.004; Serratosa F, 2015, IMAGE VISION COMPUT, V40, P38, DOI 10.1016/j.imavis.2015.06.005; Serratosa F, 2014, PATTERN RECOGN LETT, V45, P244, DOI 10.1016/j.patrec.2014.04.015; Shang HC, 2008, PROC VLDB ENDOW, V1, P364, DOI 10.14778/1453856.1453899; Solnon C, 2010, ARTIF INTELL, V174, P850, DOI 10.1016/j.artint.2010.05.002; ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925; Zampelli S, 2010, CONSTRAINTS, V15, P327, DOI 10.1007/s10601-009-9074-3; Zhang S., 2009, P INT C EXT DAT TECH, P192, DOI DOI 10.1145/1516360.1516384; Zhao PX, 2010, PROC VLDB ENDOW, V3, P340, DOI 10.14778/1920841.1920887	38	40	45	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2018	40	4					804	818		10.1109/TPAMI.2017.2696940	http://dx.doi.org/10.1109/TPAMI.2017.2696940			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FY2ZU	28436848				2022-12-18	WOS:000426687100003
J	Wen, LY; Lei, Z; Lyu, SW; Li, SZ; Yang, MH				Wen, Longyin; Lei, Zhen; Lyu, Siwei; Li, Stan Z.; Yang, Ming-Hsuan			Exploiting Hierarchical Dense Structures on Hypergraphs for Multi-Object Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-object tracking; tracklet; hierarchical; undirected affinity hypergraph; dense structures	MULTIPLE-TARGET TRACKING; ROBUST FACE TRACKING; MULTITARGET TRACKING; FRAMEWORK; LINKING	Most multi-object tracking algorithms are developed within the tracking-by-detection framework that consider the pairwise appearance similarities between detection responses or tracklets within a limited temporal window, and thus less effective in handling long-term occlusions or distinguishing spatially close targets with similar appearance in crowded scenes. In this work, we propose an algorithm that formulates the multi-object tracking task as one to exploit hierarchical dense structures on an undirected hypergraph constructed based on tracklet affinity. The dense structures indicate a group of vertices that are inter-connected with a set of hyperedges with high affinity values. The appearance and motion similarities among multiple tracklets across the spatio-temporal domain are considered globally by exploiting high-order similarities rather than pairwise ones, thereby facilitating distinguish spatially close targets with similar appearance. In addition, the hierarchical design of the optimization process helps the proposed tracking algorithm handle long-term occlusions robustly. Extensive experiments on various challenging datasets of both multi-pedestrian and multi-face tracking tasks, demonstrate that the proposed algorithm performs favorably against the state-of-the-art methods.	[Wen, Longyin; Lei, Zhen; Li, Stan Z.] Chinese Acad Sci, Ctr Biometr & Secur Res, Beijing, Peoples R China; [Wen, Longyin; Lei, Zhen; Li, Stan Z.] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China; [Lyu, Siwei] SUNY Albany, Dept Comp Sci, Albany, NY USA; [Yang, Ming-Hsuan] Univ Calif Merced, Sch Engn, Merced, CA USA	Chinese Academy of Sciences; Chinese Academy of Sciences; Institute of Automation, CAS; State University of New York (SUNY) System; State University of New York (SUNY) Albany; University of California System; University of California Merced	Wen, LY (corresponding author), Chinese Acad Sci, Ctr Biometr & Secur Res, Beijing, Peoples R China.; Wen, LY (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.	lywen@cbsr.ia.ac.cn; zlei@cbsr.ia.ac.cn; slyu@albany.edu; szli@cbsr.ia.ac.cn; mhyang@ucmerced.edu	Yang, Ming-Hsuan/T-9533-2019; Yang, Ming-Hsuan/AAE-7350-2019	Yang, Ming-Hsuan/0000-0003-4848-2304; Lyu, Siwei/0000-0002-0992-685X	National Natural Science Foundation of China [61375037, 61473291, 61572501, 61572536]; National Science and Technology Support Program Project [2013BAK02B01]; Chinese Academy of Sciences Project [KGZD-EW-102-2]; AuthenMetric RD Funds; US NSF [IIS-0953373, CCF-1319800]; NSF [1149783]; NSF IIS Grant [1152576]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Science and Technology Support Program Project; Chinese Academy of Sciences Project(Chinese Academy of Sciences); AuthenMetric RD Funds; US NSF(National Science Foundation (NSF)); NSF(National Science Foundation (NSF)); NSF IIS Grant	Longyin Wen, Zhen Lei and Stan Z. Li are supported by the National Natural Science Foundation of China Projects (No. 61375037, No. 61473291, No. 61572501, No. 61572536), National Science and Technology Support Program Project (No. 2013BAK02B01), Chinese Academy of Sciences Project (No. KGZD-EW-102-2), and AuthenMetric R&D Funds. Siwei Lyu is supported by US NSF CAREER Award IIS-0953373 and US NSF Research Grant CCF-1319800. Ming-Hsuan Yang is supported in part by NSF CAREER Grant (No. 1149783) and NSF IIS Grant (No. 1152576). Zhen Lei is the corresponding author.	Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667; Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21; BRON C, 1973, COMMUN ACM, V16, P575, DOI 10.1145/362342.362367; Cai Z., 2013, 10 IEEE INT C WORKSH, P1; Collins RT, 2012, PROC CVPR IEEE, P1744, DOI 10.1109/CVPR.2012.6247870; Duffner S, 2013, IEEE T IMAGE PROCESS, V22, P272, DOI 10.1109/TIP.2012.2210238; FORTMANN TE, 1983, IEEE J OCEANIC ENG, V8, P173, DOI 10.1109/JOE.1983.1145560; Ge W., 2008, P 4 INT C WIR COMM N, P1, DOI DOI 10.1109/WIC0M.2008.2806; Hofmann M, 2013, PROC CVPR IEEE, P3650, DOI 10.1109/CVPR.2013.468; Huang C, 2013, IEEE T PATTERN ANAL, V35, P898, DOI 10.1109/TPAMI.2012.159; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Izadinia H, 2012, LECT NOTES COMPUT SC, V7577, P100, DOI 10.1007/978-3-642-33783-3_8; Kalal Z, 2010, IEEE IMAGE PROC, P3789, DOI 10.1109/ICIP.2010.5653525; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; Kim M, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.1093; Leven WF, 2009, IEEE T AUTOMAT CONTR, V54, P370, DOI 10.1109/TAC.2008.2008327; Li SZ, 2002, LECT NOTES COMPUT SC, V2353, P67; Liu H., 2010, ADV NEURAL INFORM PR, P1414; Liu HR, 2012, PROC CVPR IEEE, P574, DOI 10.1109/CVPR.2012.6247723; Liu HR, 2012, INT J COMPUT VISION, V98, P65, DOI 10.1007/s11263-011-0496-1; Magee DR, 2004, IMAGE VISION COMPUT, V22, P143, DOI 10.1016/S0262-8856(03)00145-8; Marcenaro L, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P341, DOI 10.1109/ICIP.2002.1038975; Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103; Milan A, 2013, IEEE COMPUT SOC CONF, P735, DOI 10.1109/CVPRW.2013.111; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Roth M, 2012, INT C PATT RECOG, P1012; Shi XC, 2014, PROC CVPR IEEE, P3518, DOI 10.1109/CVPR.2014.450; Shi XC, 2013, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2013.309; Shu G, 2012, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2012.6247879; Smith K, 2005, PROC CVPR IEEE, P962; Stiefelhagen R., 2006, INT EV WORKSH CLASS, P1; Sung J, 2008, INT J COMPUT VISION, V80, P260, DOI 10.1007/s11263-007-0125-1; Wang P, 2008, IEEE T IMAGE PROCESS, V17, P1189, DOI 10.1109/TIP.2008.924287; Wu BY, 2013, IEEE I CONF COMP VIS, P2856, DOI 10.1109/ICCV.2013.355; Wu Z, 2011, PROC CVPR IEEE, P1185, DOI 10.1109/CVPR.2011.5995515; Yan JJ, 2012, PROC CVPR IEEE, P3124, DOI 10.1109/CVPR.2012.6248045; Yang B, 2012, PROC CVPR IEEE, P1918, DOI 10.1109/CVPR.2012.6247892; Yang B, 2011, PROC CVPR IEEE, P1233, DOI 10.1109/CVPR.2011.5995587; Yang ML, 2014, PROC CVPR IEEE, P1298, DOI 10.1109/CVPR.2014.169; Yang T, 2005, PROC CVPR IEEE, P970; Yu Q, 2009, IEEE T PATTERN ANAL, V31, P2196, DOI 10.1109/TPAMI.2008.253; Zhang L, 2008, INT C WAVEL ANAL PAT, P11, DOI 10.1109/ICWAPR.2008.4635742; Zhou MC, 2010, PROC CVPR IEEE, P701, DOI 10.1109/CVPR.2010.5540146	54	40	39	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2016	38	10					1983	1996		10.1109/TPAMI.2015.2509979	http://dx.doi.org/10.1109/TPAMI.2015.2509979			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DX2YV	26700969				2022-12-18	WOS:000384240600005
J	Jung, J; Lee, JY; Jeong, Y; Kweon, IS				Jung, Jiyoung; Lee, Joon-Young; Jeong, Yekeun; Kweon, In So			Time-of-Flight Sensor Calibration for a Color and Depth Camera Pair	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Time-of-flight sensor calibration; time-of-flight range error analysis; color-depth camera fusion; Kinect		We present a calibration method of a time-of-flight (ToF) sensor and a color camera pair to align the 3D measurements with the color image correctly. We have designed a 2.5D pattern board with irregularly placed holes to be accurately detected from low resolution depth images of a ToF camera as well as from high resolution color images. In order to improve the accuracy of the 3D measurements of a ToF camera, we propose to perform ray correction and range bias correction. We reset the transformation of the ToF sensor which transforms the radial distance into the scene depth in Cartesian coordinate through ray correction. Then we capture a planar scene from different depths to correct the distance error that is shown to be dependent not only on the distance but also on the pixel location. The range error profiles along the calibrated distance are classified according to their wiggling shapes and each cluster of profiles with similar shape are separately estimated using a B-spline function. The standard deviation of the remaining random noise is recorded as an uncertainty information of distance measurements. We show the performance of our calibration method quantitatively and qualitatively on various datasets, and validate the impact of our method by demonstrating an RGB-D shape refinement application.	[Jung, Jiyoung; Lee, Joon-Young; Kweon, In So] Korea Adv Inst Sci & Technol, Dept Elect Engn, Taejon 305701, South Korea; [Jeong, Yekeun] Microsoft Corp, Redmond, WA 98052 USA	Korea Advanced Institute of Science & Technology (KAIST); Microsoft	Jung, J (corresponding author), Korea Adv Inst Sci & Technol, Dept Elect Engn, 291 Daehak Ro, Taejon 305701, South Korea.	jyjung@rcv.kaist.ac.kr; jylee@rcv.kaist.ac.kr; yejeong@microsoft.com; iskweon@kaist.ac.kr	Kweon, In So/C-2023-2011		National Research Foundation of Korea (NRF) - Korea government (MSIP) [2010-0028680]	National Research Foundation of Korea (NRF) - Korea government (MSIP)	This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIP) (No. 2010-0028680). The authors thank Hyowon Ha for his help with the comparison evaluation using a structured light method. In So Kweon is the corresponding author of the article.	Beder Christian, 2008, International Journal of Intelligent Systems Technologies and Applications, V5, P285, DOI 10.1504/IJISTA.2008.021291; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bok Y, 2011, INT J COMPUT VISION, V94, P36, DOI 10.1007/s11263-010-0397-8; Bouguet J.Y., 2013, CAMERA CALIBRATION T; Donghoon Yeo, 2010, Proceedings 2010 International SoC Design Conference (ISOCC 2010), P36, DOI 10.1109/SOCDC.2010.5682980; Fuchs S., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587828; Han Y, 2013, IEEE I CONF COMP VIS, P1617, DOI 10.1109/ICCV.2013.204; Herrera CD, 2012, IEEE T PATTERN ANAL, V34, P2058, DOI 10.1109/TPAMI.2012.125; Izadi Shahram, 2011, UIST, DOI [10.1145/2047196.2047270, DOI 10.1145/2047196.2047270]; Jung J., 2014, WEBSITE PUBLIC SOURC; Jung J, 2011, IEEE INT C INT ROBOT, P3290, DOI 10.1109/IROS.2011.6048877; Kahlmann T., 2006, PROC 5 ISPRS COMMISS, P136; Kern F, 2001, P INT S CIPA, P454; Kim Y. S., 2012, P SPIE 3 DIMENSIONAL; Knies R., 2013, COLLABORATION EXPERT; Lefloch Damien, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P3, DOI 10.1007/978-3-642-44964-2_1; Levoy M, 2000, COMP GRAPH, P131, DOI 10.1145/344779.344849; Lindner Marvin, 2008, International Journal of Intelligent Systems Technologies and Applications, V5, P344, DOI 10.1504/IJISTA.2008.021297; Lindner M, 2006, LECT NOTES COMPUT SC, V4292, P524; Lindner M, 2007, PROC SPIE, V6764, DOI 10.1117/12.752808; Lindner M, 2010, COMPUT VIS IMAGE UND, V114, P1318, DOI 10.1016/j.cviu.2009.11.002; Park J, 2011, IEEE I CONF COMP VIS, P1623, DOI 10.1109/ICCV.2011.6126423; Pathak K, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3519, DOI 10.1109/IROS.2008.4650841; RAPP H, 2007, THESIS U HEIDELBERG; Reynolds M, 2011, PROC CVPR IEEE, P945, DOI 10.1109/CVPR.2011.5995550; Scharstein D, 2003, PROC CVPR IEEE, P195; Schiller I., 2008, INT ARCH PHOTOGRAMM, V37, P297; Schiller I., 2011, MIP MULTICAMERACALIB; Schmidt M., 2011, THESIS U HEIDELBERG; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Simonite Tom., 2013, MIT TECHNOL REV; Smisek J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1154, DOI 10.1109/ICCVW.2011.6130380; Steiger O, 2008, IEEE IMAGE PROC, P1968, DOI 10.1109/ICIP.2008.4712168; Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773; Swadzba Agnes, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563155; Vogiatzis G., 2010, AUTOMATIC CAMERA POS; Young Min Kim, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563160; Zhang Q., 2004, PROC IEEERSJ INT C I, P2301, DOI 10.1109/IROS.2004.1389752; Zhang Q, 2012, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2012.6247962; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	40	40	48	4	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2015	37	7					1501	1513		10.1109/TPAMI.2014.2363827	http://dx.doi.org/10.1109/TPAMI.2014.2363827			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CK0YG	26352455				2022-12-18	WOS:000355931100015
J	Park, C; Woehl, TJ; Evans, JE; Browning, ND				Park, Chiwoo; Woehl, Taylor J.; Evans, James E.; Browning, Nigel D.			Minimum Cost Multi-Way Data Association for Optimizing Multitarget Tracking of Interacting Objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Data association; binary integer programming; decomposition; lagrange dual relaxation	PROBABILISTIC DATA ASSOCIATION; MULTIOBJECT TRACKING; MULTIPLE; SPLIT; TARGETS	This paper presents a general formulation for a minimum cost data association problem which associates data features via one-to-one, m-to-one and one-to-n links with minimum total cost of the links. A motivating example is a problem of tracking multiple interacting nanoparticles imaged on video frames, where particles can aggregate into one particle or a particle can be split into multiple particles. Many existing multitarget tracking methods are capable of tracking non-interacting targets or tracking interacting targets of restricted degrees of interactions. The proposed formulation solves a multitarget tracking problem for general degrees of inter-object interactions. The formulation is in the form of a binary integer programming problem. We propose a polynomial time solution approach that can obtain a good relaxation solution of the binary integer programming, so the approach can be applied for multitarget tracking problems of a moderate size (for hundreds of targets over tens of time frames). The resulting solution is always integral and obtains a better duality gap than the simple linear relaxation solution of the corresponding problem. The proposed method was validated through applications to simulated multitarget tracking problems and a real multitarget tracking problem.	[Park, Chiwoo] Florida State Univ, Dept Ind & Mfg Engn, Tallahassee, FL 32310 USA; [Woehl, Taylor J.] Ames Natl Lab, Div Mat Sci & Engn, Ames, IA USA; [Evans, James E.] Pacific NW Natl Lab, Dept Environm & Mol Sci, Richland, WA USA; [Browning, Nigel D.] Pacific NW Natl Lab, Dept Fundamental & Computat Sci, Richland, WA 99352 USA	State University System of Florida; Florida State University; United States Department of Energy (DOE); Ames National Laboratory; United States Department of Energy (DOE); Pacific Northwest National Laboratory; United States Department of Energy (DOE); Pacific Northwest National Laboratory	Park, C (corresponding author), Florida State Univ, Dept Ind & Mfg Engn, Tallahassee, FL 32310 USA.	cpark5@fsu.edu; tjwoehl@ameslab.gov; james.evans@pnnl.gov; nigel.browning@pnnl.gov	Park, Chiwoo/ABA-4876-2021; Woehl, Taylor/AFQ-8991-2022	Park, Chiwoo/0000-0002-2463-8901; Browning, Nigel/0000-0003-0491-251X	FSU COFRS [032968]; Ralph E. Powe Junior Faculty Enhancement Award; NIH [5RC1GM091755]; DOE [DE-FG02-03ER46057]; UC Lab Fee Program; UC Academic Senate; Chemical Imaging Initiative at Pacific Northwest National Laboratory (PNNL) [DE-AC05-76RL01830];  [NSF-CMMI-1334012]; NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES [RC1GM091755] Funding Source: NIH RePORTER	FSU COFRS; Ralph E. Powe Junior Faculty Enhancement Award; NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); DOE(United States Department of Energy (DOE)); UC Lab Fee Program; UC Academic Senate; Chemical Imaging Initiative at Pacific Northwest National Laboratory (PNNL); ; NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS))	The authors thank Abhishek Shrivastava for useful discussions. We would like to acknowledge support for this project. Park is supported by the FSU COFRS 032968, the Ralph E. Powe Junior Faculty Enhancement Award, and NSF-CMMI-1334012. Evans and Browning acknowledge NIH funding support from grant no. 5RC1GM091755. Browning also acknowledges DOE funding support from grant no. DE-FG02-03ER46057. Support for Woehl was provided by the UC Lab Fee Program and the UC Academic Senate. A portion of this work is part of the Chemical Imaging Initiative at Pacific Northwest National Laboratory (PNNL) under Contract DE-AC05-76RL01830. It was conducted under the Laboratory Directed Research and Development Program at PNNL.	Anstreicher KM, 1999, SIAM J OPTIMIZ, V9, P803, DOI 10.1137/S1052623497323194; Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21; Bose B., 2007, P 2007 IEEE C COMP V, P1; CHANG KC, 1984, IEEE T AUTOMAT CONTR, V29, P585, DOI 10.1109/TAC.1984.1103597; Choi W, 2012, LECT NOTES COMPUT SC, V7575, P215, DOI 10.1007/978-3-642-33765-9_16; COX IJ, 1993, INT J COMPUT VISION, V10, P53, DOI 10.1007/BF01440847; Evans JE, 2011, NANO LETT, V11, P2809, DOI 10.1021/nl201166k; FORTMANN TE, 1983, IEEE J OCEANIC ENG, V8, P173, DOI 10.1109/JOE.1983.1145560; Gennari G, 2004, PROC CVPR IEEE, P876; Genovesio A, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P1239; Genovesio A, 2004, INT C PATT RECOG, P677, DOI 10.1109/ICPR.2004.1333863; Henriques JF, 2011, IEEE I CONF COMP VIS, P2470, DOI 10.1109/ICCV.2011.6126532; Trinh H, 2012, PROC CVPR IEEE, P1902, DOI 10.1109/CVPR.2012.6247890; Huang C, 2008, LECT NOTES COMPUT SC, V5303, P788, DOI 10.1007/978-3-540-88688-4_58; Jaqaman K, 2008, NAT METHODS, V5, P695, DOI 10.1038/nmeth.1237; Joo SW, 2007, IEEE T IMAGE PROCESS, V16, P2849, DOI 10.1109/TIP.2007.906254; Khan Z, 2005, PROC CVPR IEEE, P605; Khan Z, 2006, IEEE T PATTERN ANAL, V28, P1960, DOI 10.1109/TPAMI.2006.247; Kumar P, 2006, IEEE T CIRC SYST VID, V16, P1477, DOI 10.1109/TCSVT.2006.885715; Makris A, 2014, IEEE T GEOSCI REMOTE, V52, P7684, DOI 10.1109/TGRS.2014.2316600; Nemhauser G.L., 1988, INTEGER COMBINATORIA; Pardalos P. M., 1991, J GLOBAL OPTIM, V1, P15; Perera A. A., 2006, 2006 IEEE COMPUTER S, V1, P666; Polyak B. T., 1987, INTRO OPTIMIZATION; Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Schrijver A, 2003, COMBINATORIAL OPTIMI, V24; Serge A, 2008, NAT METHODS, V5, P687, DOI 10.1038/nmeth.1233; Sierksma G., 2001, LINEAR INTEGER PROGR, V245; Storlie CB, 2009, STAT SINICA, V19, P1; Woehl TJ, 2012, ACS NANO, V6, P8599, DOI 10.1021/nn303371y; Xing JL, 2009, PROC CVPR IEEE, P1200, DOI 10.1109/CVPRW.2009.5206745; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Yu Q, 2009, IEEE T PATTERN ANAL, V31, P2196, DOI 10.1109/TPAMI.2008.253; Zhang L, 2008, INT C WAVEL ANAL PAT, P11, DOI 10.1109/ICWAPR.2008.4635742	37	40	43	0	39	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2015	37	3					611	624		10.1109/TPAMI.2014.2346202	http://dx.doi.org/10.1109/TPAMI.2014.2346202			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VK	26353265				2022-12-18	WOS:000349626200010
J	Ikehata, S; Wipf, D; Matsushita, Y; Aizawa, K				Ikehata, Satoshi; Wipf, David; Matsushita, Yasuyuki; Aizawa, Kiyoharu			Photometric Stereo Using Sparse Bayesian Regression for General Diffuse Surfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Photometric stereo; sparse regression; piecewise linear regression; sparse bayesian learning	REFLECTION	Most conventional algorithms for non-Lambertian photometric stereo can be partitioned into two categories. The first category is built upon stable outlier rejection techniques while assuming a dense Lambertian structure for the inliers, and thus performance degrades when general diffuse regions are present. The second utilizes complex reflectance representations and non-linear optimization over pixels to handle non-Lambertian surfaces, but does not explicitly account for shadows or other forms of corrupting outliers. In this paper, we present a purely pixel-wise photometric stereo method that stably and efficiently handles various non-Lambertian effects by assuming that appearances can be decomposed into a sparse, non-diffuse component (e. g., shadows, specularities, etc.) and a diffuse component represented by a monotonic function of the surface normal and lighting dot-product. This function is constructed using a piecewise linear approximation to the inverse diffuse model, leading to closed-form estimates of the surface normals and model parameters in the absence of non-diffuse corruptions. The latter are modeled as latent variables embedded within a hierarchical Bayesian model such that we may accurately compute the unknown surface normals while simultaneously separating diffuse from non-diffuse components. Extensive evaluations are performed that show state-of-the-art performance using both synthetic and real-world images.	[Ikehata, Satoshi; Aizawa, Kiyoharu] Univ Tokyo, Dept Informat Sci & Technol, Bunkyo Ku, Tokyo, Japan; [Ikehata, Satoshi] Washington Univ, Dept Comp Sci & Engn, St Louis, MO 63130 USA; [Ikehata, Satoshi; Wipf, David; Matsushita, Yasuyuki] Microsoft Res Asia, Visual Comp Grp, Beijing, Peoples R China; [Wipf, David] Univ Calif San Francisco, Biomagnet Imaging Lab, San Francisco, CA 94143 USA; [Matsushita, Yasuyuki] Osaka Univ, Suita, Osaka 565, Japan; [Matsushita, Yasuyuki] PSIVT 2010, Singapore, Singapore; [Matsushita, Yasuyuki] 3DIMPVT 2011, Hangzhou, Zhejiang, Peoples R China; [Matsushita, Yasuyuki] ACCV 2012, Taejon, South Korea; [Matsushita, Yasuyuki] ICCV 2017, Santiago, Chile; [Matsushita, Yasuyuki] ACCV 2014, Singapore, Singapore	University of Tokyo; Washington University (WUSTL); Microsoft; Microsoft Research Asia; University of California System; University of California San Francisco; Osaka University	Ikehata, S (corresponding author), Univ Tokyo, Dept Informat Sci & Technol, Bunkyo Ku, Tokyo, Japan.	ikehata@hal.t.u-tokyo.ac.jp; davidwip@microsoft.com; yasumat@microsoft.com; aizawa@hal.t.u-tokyo.ac.jp		Wipf, David/0000-0002-2768-4540; Matsushita, Yasuyui/0000-0002-1935-4752	 [248615]		This work was supported by the Grants-in-Aid for JSPS Fellows (248615).	Ackermann J., 2012, P IEEE C COMP VIS PA; Agrawal A., 2006, P 9 EUR C COMP VIS E; Alldrin N., 2008, P IEEEC COMP VIS PA; Alldrin N.G., 2007, P IEEE 11 INT C COMP; Argyriou V., 2008, P IEEEC COMP VIS PA; Barsky S, 2003, IEEE T PATTERN ANAL, V25, P1239, DOI 10.1109/TPAMI.2003.1233898; Boyd S, 2004, CONVEX OPTIMIZATION; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Chandraker M., 2011, P IEEE C COMP VIS PA; Chandraker M., 2011, P IEEE INT C COMP VI; Chandraker M.K., 2007, P IEEE C COMP VIS PA; Chung H., 2008, P IEEE C COMP VIS PA; Cook R. L., 1981, Computer Graphics, V15, P307, DOI 10.1145/965161.806819; Deguchi K., 2012, P IEEE C COMP VIS PA; Del Bue A, 2012, IEEE T PATTERN ANAL, V34, P1496, DOI 10.1109/TPAMI.2011.238; Favaro P., 2012, P IEEE C COMP VIS PA; Georghiades A.S., 2003, P IEE 9 INT C COMP V; Goldman D. B., 2005, P IEEE 10 INT C COMP; Hernandez C, 2008, IEEE T PATTERN ANAL, V30, P548, DOI 10.1109/TPAMI.2007.70820; Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158; Higo T., 2010, P IEEE C COMP VIS PA; Ikehata S., 2012, P IEEE C COMP VIS PA; Lafortune E., 1997, P ACM SIGGRAPH; Liao M., 2011, P IEEE C COMP VIS PA; MALLICK SP, 2005, P IEEE C COMP VIS PA; Matusik W, 2003, ACM T GRAPHIC, V22, P759, DOI 10.1145/882262.882343; Miyazaki D, 2010, INT J COMPUT VISION, V86, P229, DOI 10.1007/s11263-009-0262-9; Mukaigawa Y, 2007, J OPT SOC AM A, V24, P3326, DOI 10.1364/JOSAA.24.003326; Romeiro F., 2010, P 11 EUR C COMP VIS; Rusinkiewicz S., 1998, P EUR WORKSH REND; Sato I., 2007, P IEEE 11 INT C COMP; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; Shi B., 2012, P 12 EUR C COMP VIS; Shi B., 2012, P IEEE C COMP VIS PA; Silver W, 1980, THESIS MIT; Sunkavalli K., 2010, P 11 EUR C COMP VIS; Tan P., 2007, P IEEE C COMP VIS PA; Tan P, 2011, IEEE T PATTERN ANAL, V33, P2506, DOI 10.1109/TPAMI.2011.35; Tang K., 2005, P IEEE C COMP VIS PA; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; Verbiest F., 2008, P IEEEC COMP VIS PA; VIETH E, 1989, J APPL PHYSIOL, V67, P390, DOI 10.1152/jappl.1989.67.1.390; WARD GJ, 1992, COMP GRAPH, V26, P265, DOI 10.1145/142920.134078; Wipf DP, 2011, IEEE T INFORM THEORY, V57, P6236, DOI 10.1109/TIT.2011.2162174; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Wu L., 2010, P 10 AS C COMP VIS A; Wu T., 2005, P IEEE C COMP VIS PA; Yu C., 2010, P 11 EUR C COMP VIS	50	40	42	1	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2014	36	9					1816	1831		10.1109/TPAMI.2014.2299798	http://dx.doi.org/10.1109/TPAMI.2014.2299798			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9OE	26352234				2022-12-18	WOS:000340210100009
J	Zhang, HC; Wipf, D; Zhang, YN				Zhang, Haichao; Wipf, David; Zhang, Yanning			Multi-Observation Blind Deconvolution with an Adaptive Sparse Prior	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-observation blind deconvolution; blind image deblurring; sparse priors; sparse estimation		This paper describes a robust algorithm for estimating a single latent sharp image given multiple blurry and/or noisy observations. The underlying multi-image blind deconvolution problem is solved by linking all of the observations together via a Bayesian-inspired penalty function, which couples the unknown latent image along with a separate blur kernel and noise variance associated with each observation, all of which are estimated jointly from the data. This coupled penalty function enjoys a number of desirable properties, including a mechanism whereby the relative-concavity or sparsity is adapted as a function of the intrinsic quality of each corrupted observation. In this way, higher quality observations may automatically contribute more to the final estimate than heavily degraded ones, while troublesome local minima can largely be avoided. The resulting algorithm, which requires no essential tuning parameters, can recover a sharp image from a set of observations containing potentially both blurry and noisy examples, without knowing a priori the degradation type of each observation. Experimental results on both synthetic and real-world test images clearly demonstrate the efficacy of the proposed method.	[Zhang, Haichao; Zhang, Yanning] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China; [Wipf, David] Microsoft Res Asia, Beijing 100080, Peoples R China	Northwestern Polytechnical University; Microsoft; Microsoft Research Asia	Zhang, HC (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.	hczhang1@gmail.com; davidwipf@gmail.com; ynzhang@nwpu.edu.cn		Wipf, David/0000-0002-2768-4540	NSF-China [61231016]	NSF-China(National Natural Science Foundation of China (NSFC))	We would like to thank the Associate Editor and all the reviewers for their useful comments and suggestions. We would also like to thank F. Sroubek for the help in producing some results of his method included in this paper. This work was supported in part by NSF-China (61231016).	Agrawal A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531401; [Anonymous], 2011, P ADV NEUR INF PROC; Babacan S. D., 2012, P ECCV; Boyd S, 2004, CONVEX OPTIMIZATION; Cai JF, 2009, J COMPUT PHYS, V228, P5057, DOI 10.1016/j.jcp.2009.04.022; Chartrand R., 2008, P ICASSP; Chen J., 2008, P IEEE CVPR; Cho S., 2009, P SIGGRAPH AS NEW YO; Cho T. S., 2011, P IEEE CVPR; Fergus R., 2006, P SIGGRAPH; Furuya K, 2007, IEEE T AUDIO SPEECH, V15, P1579, DOI 10.1109/TASL.2007.898456; Hu W, 2012, IEEE T IMAGE PROCESS, V21, P386, DOI 10.1109/TIP.2011.2160073; Kenig T, 2010, IEEE T PATTERN ANAL, V32, P2191, DOI 10.1109/TPAMI.2010.45; Levin A., 2009, P IEEE CVPR; Levin A., 2011, P IEEE CVPR; Li W, 2011, P IEEE CVPR; Miskin J. W., 2000, P ADV ICA; Palmer J. A., 2006, P NIPS; Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282; Pozidis H., 1996, P 8 IEEE SSAP CORF G; Rav-Acha A, 2005, PATTERN RECOGN LETT, V26, P311, DOI 10.1016/j.patrec.2004.10.017; Shan Q., 2008, P SIGGRAPH; Sroubek F, 2012, IEEE T IMAGE PROCESS, V21, P1687, DOI 10.1109/TIP.2011.2175740; Tai YW, 2011, IEEE T PATTERN ANAL, V33, P1603, DOI 10.1109/TPAMI.2010.222; Tai YW, 2010, IEEE T PATTERN ANAL, V32, P1012, DOI 10.1109/TPAMI.2009.97; Temerinac-Ott M, 2012, IEEE T IMAGE PROCESS, V21, P1863, DOI 10.1109/TIP.2011.2181528; Tzikas DG, 2009, IEEE T IMAGE PROCESS, V18, P753, DOI 10.1109/TIP.2008.2011757; Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7; Wipf D., 2013, REVISITING BAYESIAN; Wipf DP, 2011, IEEE T INFORM THEORY, V57, P6236, DOI 10.1109/TIT.2011.2162174; Xu L., 2010, P ECCV; Yuan L., 2007, P IEEE ICCV RIO DE J; Yuan L., 2007, P SIGGRAPH; Zhang H., 2011, P IEEE ICCV BARC SPA; Zhang H., 2013, P IEEE CVPR; Zhang Y, 2004, J DYN SYST-T ASME, V126, P834, DOI 10.1115/1.1852460; Zhou CY, 2011, INT J COMPUT VISION, V93, P53, DOI 10.1007/s11263-010-0409-8; Zhu X., 2012, P 12 ECCV BERL GERM; Zhuo S., 2010, P IEEE CVPR	39	40	43	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2014	36	8					1628	1643		10.1109/TPAMI.2013.241	http://dx.doi.org/10.1109/TPAMI.2013.241			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9HN	26353343				2022-12-18	WOS:000340191900011
J	Shen, XH; Lin, Z; Brandt, J; Wu, Y				Shen, Xiaohui; Lin, Zhe; Brandt, Jonathan; Wu, Ying			Spatially-Constrained Similarity Measure for Large-Scale Object Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object retrieval; bag-of-words; spatially-constrained similarity measure; k-NN re-ranking; product image search		One fundamental problem in object retrieval with the bag-of-words model is its lack of spatial information. Although various approaches are proposed to incorporate spatial constraints into the model, most of them are either too strict or too loose so that they are only effective in limited cases. In this paper, a new spatially-constrained similarity measure (SCSM) is proposed to handle object rotation, scaling, view point change and appearance deformation. The similarity measure can be efficiently calculated by a voting-based method using inverted files. During the retrieval process, object localization in the database images can also be simultaneously achieved using SCSM without post-processing. Furthermore, based on the retrieval and localization results of SCSM, we introduce a novel and robust re-ranking method with the k-nearest neighbors of the query for automatically refining the initial search results. Extensive performance evaluations on six public data sets show that SCSM significantly outperforms other spatial models including RANSAC-based spatial verification, while k-NN re-ranking outperforms most state-of-the-art approaches using query expansion. We also adapted SCSM for mobile product image search with an iterative algorithm to simultaneously extract the product instance from the mobile query image, identify the instance, and retrieve visually similar product images. Experiments on two product image search data sets show that our approach can robustly localize and extract the product in the query image, and hence drastically improve the retrieval accuracy over baseline methods.	[Shen, Xiaohui; Lin, Zhe; Brandt, Jonathan] Adobe Res, San Jose, CA 95110 USA; [Wu, Ying] Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA	Adobe Systems Inc.; Northwestern University	Shen, XH (corresponding author), Adobe Res, 345 Pk Ave, San Jose, CA 95110 USA.	xshen@adobe.com; zlin@adobe.com; jbrandt@adobe.com; yingwu@eecs.northwestern.edu	Wu, Ying/B-7283-2009	Koochak, Atousa/0000-0001-6547-2728	Adobe Systems, Incorporated; US National Science Foundation [IIS-0347877, IIS-0916607]; US Army Research Laboratory; US Army Research Office [ARO W911NF-08-1-0504]; DARPA [FA 8650-11-1-7149]	Adobe Systems, Incorporated; US National Science Foundation(National Science Foundation (NSF)); US Army Research Laboratory(United States Department of DefenseUS Army Research Laboratory (ARL)); US Army Research Office; DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	This work was partially supported by Adobe Systems, Incorporated, and in part by US National Science Foundation grant IIS-0347877, IIS-0916607, US Army Research Laboratory and the US Army Research Office under grant ARO W911NF-08-1-0504, and DARPA Award FA 8650-11-1-7149.	CAO Y., 2010, P IEEE C COMP VIS PA; Chen H., 2011, P ACM MULT SYST C; Chum O., 2011, P IEEE C COMP VIS PA; Chum O., 2009, P IEEE C COMP VIS PA; Chum O., 2010, P IEEE C COMP VIS PA; Chum O., 2007, P IEEE INT C COMP VI; Girod B., 2011, IEEE SIGNAL PROCESSI, V28; Griffin Gregory, 2007, CALTECH 256 OBJECT C; He J., 2012, P IEEE C COMP VIS PA; He J, 2011, P 19 ACM INT C MULT; Jegou H., 2010, P IEEE C COMP VIS PA; Jegou H, 2008, P 10 EUR C COMP VIS; JEGOU H, 2009, P IEEE C COMP VIS PA; Jing Y, 2008, P 17 INT C WORLD WID; Lampert Christoph H., 2009, P IEEE INT C COMP VI; LEIBE B., 2004, P ECCV WORKSH STAT L; Lin X., 2008, P SPIE; Lin Z., 2010, P 11 EUR C COMP VIS; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikulik A., 2010, P 11 EUR C COMP VIS; Muja M., 2009, P VISAPP INT C COMP; Nister D., 2006, P 2006 IEEE COMP SOC; Pedronette D.C.G., 2011, P ACM 1 INT C MULT R; Perd'och M., 2009, P IEEE C COMP VIS PA; Philbin J., 2008, P IEEE C COMP VIS PA; Philbin J, 2007, CVPR; Philbin J., 2010, P 11 EUR C COMP VIS; Qin D., 2011, P IEEE C COMP VIS PA; Rother C., 2004, P ACM SIGGRAPH; Shen X., 2012, P 12 EUR C COMP VIS; Shen X., 2012, P IEEE C COMP VIS PA; Sivic J, 2003, P IEEE INT C COMP VI; Tolias G., 2011, P IEEE INT C COMP VI; Wang X, 2011, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY (ACE 2011); WU Z., 2009, P IEEE C COMP VIS PA; Zhang Y., 2011, P IEEE C COMP VIS PA; [No title captured]	37	40	40	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2014	36	6					1229	1241		10.1109/TPAMI.2013.237	http://dx.doi.org/10.1109/TPAMI.2013.237			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AI8AJ	26353283				2022-12-18	WOS:000337124200014
J	Mumtaz, A; Coviello, E; Lanckriet, GRG; Chan, AB				Mumtaz, Adeel; Coviello, Emanuele; Lanckriet, Gert R. G.; Chan, Antoni B.			Clustering Dynamic Textures with the Hierarchical EM Algorithm for Modeling Video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dynamic textures; expectation maximization; Kalman filter; bag of systems; video annotation; sensitivity analysis	KERNELS; CLASSIFICATION; RECOGNITION	Dynamic texture (DT) is a probabilistic generative model, defined over space and time, that represents a video as the output of a linear dynamical system (LDS). The DT model has been applied to a wide variety of computer vision problems, such as motion segmentation, motion classification, and video registration. In this paper, we derive a new algorithm for clustering DT models that is based on the hierarchical EM algorithm. The proposed clustering algorithm is capable of both clustering DTs and learning novel DT cluster centers that are representative of the cluster members in a manner that is consistent with the underlying generative probabilistic model of the DT. We also derive an efficient recursive algorithm for sensitivity analysis of the discrete-time Kalman smoothing filter, which is used as the basis for computing expectations in the E-step of the HEM algorithm. Finally, we demonstrate the efficacy of the clustering algorithm on several applications in motion analysis, including hierarchical motion clustering, semantic motion annotation, and learning bag-of-systems (BoS) codebooks for dynamic texture recognition.	[Mumtaz, Adeel; Chan, Antoni B.] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China; [Coviello, Emanuele; Lanckriet, Gert R. G.] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA	City University of Hong Kong; University of California System; University of California San Diego	Mumtaz, A (corresponding author), City Univ Hong Kong, Dept Comp Sci, Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.	adeelmumtaz@gmail.com; ecoviell@ucsd.edu; gert@ece.ucsd.edu; abchan@cityu.edu.hk	CHAN, Antoni B./D-7858-2013	CHAN, Antoni B./0000-0002-2886-2513	Research Grants Council of the Hong Kong Special Administrative Region, China [CityU 110610]; Qualcomm, Inc.; Yahoo! Inc.; Hellman Fellowship Program; Alfred P. Sloan Foundation; US National Science Foundation (NSF) [CCF-0830535, IIS-1054960]; University of California San Diego FWGrid Project; NSF Research Infrastructure Grant [EIA-0303622]; Google Research Award	Research Grants Council of the Hong Kong Special Administrative Region, China(Hong Kong Research Grants Council); Qualcomm, Inc.; Yahoo! Inc.; Hellman Fellowship Program; Alfred P. Sloan Foundation(Alfred P. Sloan Foundation); US National Science Foundation (NSF)(National Science Foundation (NSF)); University of California San Diego FWGrid Project; NSF Research Infrastructure Grant; Google Research Award(Google Incorporated)	The authors would like to thank R. Peteri for the DynTex dataset and G. Doretto for the UCLA dataset. Adeel Mumtaz and Antoni B. Chan were supported by the Research Grants Council of the Hong Kong Special Administrative Region, China [CityU 110610]. Emanuele Coviello and Gert R. G. Lanckriet acknowledge support from Qualcomm, Inc., Yahoo! Inc., the Hellman Fellowship Program, the Alfred P. Sloan Foundation, US National Science Foundation (NSF) Grants CCF-0830535 and IIS-1054960, and the University of California San Diego FWGrid Project, NSF Research Infrastructure Grant Number EIA-0303622. Antoni B. Chan, Emanuele Coviello, and Gert R. G. Lankriet also received support from a Google Research Award.	[Anonymous], 2001, P IEEE C COMP VIS PA; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; Bissacco A, 2007, IEEE T PATTERN ANAL, V29, P1958, DOI 10.1109/TPAMI.2007.1101; Blei DM, 2006, BAYESIAN ANAL, V1, P121, DOI 10.1214/06-BA104; Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61; Cetingul H., 2009, P IEEE C COMP VIS PA; Chan A., 2007, P IEEE C COMP VIS PA; Chan A., 2010, P IEEE C COMP VIS PA; Chan AB, 2005, PROC CVPR IEEE, P846; Chan AB, 2008, IEEE T PATTERN ANAL, V30, P909, DOI 10.1109/TPAMI.2007.70738; Chan AB, 2009, IEEE T PATTERN ANAL, V31, P1862, DOI 10.1109/TPAMI.2009.110; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chaudry R., 2009, P IEEE C COMP VIS PA; Coviello E, 2011, IEEE T AUDIO SPEECH, V19, P1343, DOI 10.1109/TASL.2010.2090148; Davis J. V., 2006, P ADV NEUR INF PROC; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Derpanis K., 2010, P IEEE C COMP VIS PA; Doretto G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1236; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Fitzgibbon AW, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P662, DOI 10.1109/ICCV.2001.937584; Gelb A., 1974, APPL OPTIMAL ESTIMAT; Ghanem B., 2007, P IEEE INT C COMP VI; Ghoreyshi A., 2006, P DYN VIS WORKSH EUR; Goh A., 2008, P IEEE C COMP VIS PA; Goldberger J., 2005, ADV NEURAL INFORM PR, V17, P505; GRIFFIN RE, 1969, AIAA J, V7, P1890, DOI 10.2514/3.5477; Hastie T, 2009, ELEMENTS STAT LEARNI; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Kay S. M., 1993, FUNDAMENTALS STAT SI; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Peteri R, 2010, PATTERN RECOGN LETT, V31, P1627, DOI 10.1016/j.patrec.2010.05.009; Ravichandran A., 2009, P IEEE C COMP VIS PA; Ravichandran A, 2013, IEEE T PATTERN ANAL, V35, P342, DOI 10.1109/TPAMI.2012.83; Ravichandran A, 2011, IEEE T PATTERN ANAL, V33, P158, DOI 10.1109/TPAMI.2010.61; Saisan P, 2001, PROC CVPR IEEE, P58; Shumway R. H., 1982, Journal of Time Series Analysis, V3, P253, DOI 10.1111/j.1467-9892.1982.tb00349.x; Vasconcelos N., 1998, P NEUR INF PROC SYST; Vidal R, 2005, PROC CVPR IEEE, P516; Vidal R., 2007, P IEEE INT C COMP VI; Vishwanathan SVN, 2007, INT J COMPUT VISION, V73, P95, DOI 10.1007/s11263-006-9352-0; Wall J. E.  Jr., 1981, Stochastics, V5, P1, DOI 10.1080/17442508108833172; Woolfe F., 2006, P 9 EUR C COMP VIS; Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110	43	40	41	0	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2013	35	7					1606	1621		10.1109/TPAMI.2012.236	http://dx.doi.org/10.1109/TPAMI.2012.236			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	146AG	23681990				2022-12-18	WOS:000319060600006
J	Wang, F; Lee, N; Hu, JY; Sun, JM; Ebadollahi, S; Laine, AF				Wang, Fei; Lee, Noah; Hu, Jianying; Sun, Jimeng; Ebadollahi, Shahram; Laine, Andrew F.			A Framework for Mining Signatures from Event Sequences and Its Applications in Healthcare Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Temporal signature mining; sparse coding; dictionary learning; nonnegative matrix factorization; stochastic gradient descent; beta-divergence	NONNEGATIVE MATRIX FACTORIZATION; SPARSENESS	This paper proposes a novel temporal knowledge representation and learning framework to perform large-scale temporal signature mining of longitudinal heterogeneous event data. The framework enables the representation, extraction, and mining of high-order latent event structure and relationships within single and multiple event sequences. The proposed knowledge representation maps the heterogeneous event sequences to a geometric image by encoding events as a structured spatial-temporal shape process. We present a doubly constrained convolutional sparse coding framework that learns interpretable and shift-invariant latent temporal event signatures. We show how to cope with the sparsity in the data as well as in the latent factor model by inducing a double sparsity constraint on the beta-divergence to learn an overcomplete sparse latent factor model. A novel stochastic optimization scheme performs large-scale incremental learning of group-specific temporal event signatures. We validate the framework on synthetic data and on an electronic health record dataset.	[Wang, Fei; Lee, Noah; Hu, Jianying; Sun, Jimeng; Ebadollahi, Shahram] IBM TJ Watson Res Ctr, Hawthorne, NY 10532 USA; [Lee, Noah] 1010data, New York, NY 10169 USA; [Laine, Andrew F.] Columbia Univ, Dept Biomed Engn, New York, NY 10027 USA	International Business Machines (IBM); Columbia University	Wang, F (corresponding author), IBM TJ Watson Res Ctr, 19 Skyline Dr, Hawthorne, NY 10532 USA.	fwang@us.ibm.com; nl2168@gmail.com; jyhu@us.ibm.com; jimeng@us.ibm.com; ebad@us.ibm.com; al418@columbia.edu	Lee, Noah/AEX-3553-2022; Lee, Noah/AAG-9697-2022	Sun, Jimeng/0000-0003-1512-6426	IBM	IBM(International Business Machines (IBM))	The authors would like to thank Robert Sorrentino (MD), Martin Kohn (MD), and Arno Klein (PhD). Noah Lee performed this work during a summer internship at IBM T.J. Watson Research Center and was supported by the IBM PhD Fellowship Award 2010-2011.	Cao B, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2689; Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; Ding C, 2010, IEEE T PATTERN ANAL, V32, P45, DOI 10.1109/TPAMI.2008.277; Dong M., 2010, MATH PROBL ENG, V2010, P1; Eggert J, 2004, IEEE IJCNN, P2529; Fei W., 2011, P 11 SIAM INT C DAT; Fevotte C., 2010, ARXIV10101763; Hoyer Patrik O, 2002, P 12 IEEE WORKSH NEU; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Lin J., 2003, P 8 ACM SIGMOD WORKS, P2, DOI DOI 10.1145/882082.882086; Mairal J, 2010, J MACH LEARN RES, V11, P19; Moerchen F., 2006, THESIS; Morchen F, 2007, DATA MIN KNOWL DISC, V15, P181, DOI 10.1007/s10618-007-0070-1; Morchen F., 2010, P 2010 SIAM INT C DA, P315; O'Grady PD, 2007, LECT NOTES COMPUT SC, V4666, P520; Ramesh Kumar Y.R., 2010, INT J ENG SCI, V2, P3305; Russell RA, 2004, AUTON ROBOT, V16, P81, DOI 10.1023/B:AURO.0000008672.32974.bb; Shlens J, 2009, J NEUROSCI, V29, P5022, DOI 10.1523/JNEUROSCI.5187-08.2009; Smaragdis P., 2004, P 5 INT C IND COMP A; Xie LX, 2008, P IEEE, V96, P623, DOI 10.1109/JPROC.2008.916362; Young BA, 2008, AM J MANAG CARE, V14, P15	22	40	41	1	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2013	35	2					272	285		10.1109/TPAMI.2012.111	http://dx.doi.org/10.1109/TPAMI.2012.111			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	057JX	22585098				2022-12-18	WOS:000312560600003
J	Liu, YM; Xu, D; Tsang, IWH; Luo, JB				Liu, Yiming; Xu, Dong; Tsang, Ivor Wai-Hung; Luo, Jiebo			Textual Query of Personal Photos Facilitated by Large-Scale Web Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Textual query-based consumer photo retrieval; large-scale Web data; cross-domain learning	IMAGES	The rapid popularization of digital cameras and mobile phone cameras has led to an explosive growth of personal photo collections by consumers. In this paper, we present a real-time textual query-based personal photo retrieval system by leveraging millions of Web images and their associated rich textual descriptions (captions, categories, etc.). After a user provides a textual query (e. g., "water"), our system exploits the inverted file to automatically find the positive Web images that are related to the textual query "water" as well as the negative Web images that are irrelevant to the textual query. Based on these automatically retrieved relevant and irrelevant Web images, we employ three simple but effective classification methods, k-Nearest Neighbor (kNN), decision stumps, and linear SVM, to rank personal photos. To further improve the photo retrieval performance, we propose two relevance feedback methods via cross-domain learning, which effectively utilize both the Web images and personal images. In particular, our proposed cross-domain learning methods can learn robust classifiers with only a very limited amount of labeled personal photos from the user by leveraging the prelearned linear SVM classifiers in real time. We further propose an incremental cross-domain learning method in order to significantly accelerate the relevance feedback process on large consumer photo databases. Extensive experiments on two consumer photo data sets demonstrate the effectiveness and efficiency of our system, which is also inherently not limited by any predefined lexicon.	[Liu, Yiming; Xu, Dong; Tsang, Ivor Wai-Hung] Nanyang Technol Univ, Sch Comp Engn, 50 Nanyang Ave,Blk N4, Singapore 639798, Singapore; [Luo, Jiebo] Eastman Kodak Co, Kodak Res Labs, Rochester, NY 14650 USA	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Eastman Kodak	Liu, YM (corresponding author), Nanyang Technol Univ, Sch Comp Engn, 50 Nanyang Ave,Blk N4, Singapore 639798, Singapore.	lym@liuyiming.info; dongxu@ntu.edu.sg; ivortsang@ntu.edu.sg; jiebo.luo@kodak.com	Luo, Jiebo/AAI-7549-2020; Xu, Dong/A-3694-2011; Tsang, Ivor/E-8653-2011	Xu, Dong/0000-0003-2775-9730; Tsang, Ivor/0000-0003-2211-8176; Tsang, Ivor/0000-0001-8095-4637; Luo, Jiebo/0000-0002-4516-9729	Singapore National Research Foundation [NRF2008IDM-IDM004-018]	Singapore National Research Foundation(National Research Foundation, Singapore)	This work was supported by the Singapore National Research Foundation Interactive Digital Media R&D Program, under research Grant NRF2008IDM-IDM004-018. The authors also thank Yi Yang for his helpful discussions and suggestions.	ARTAE M, 2002, P INT C PATT REC; Blitzer J., P 45 ANN M ASS COMP, P440, DOI DOI 10.1109/IRPS.2011.5784441; CAO L, 2008, P ACM C MULTIMEDIA; CAUWENBERGHS G, 2000, NEURAL INFORM PROCES; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; CHANG SF, 2007, P ACM SIGMM WORKSH M; CHANG SF, 2008, P NIST TRECVID WORKS; CHEN L, 2010, P IEEE C COMP VIS PA; Chua Tat-Seng, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646452; Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248; DAUM H, 2007, P ANN M ASS COMP LIN; DUAN L, 2009, P INT C MACH LEARN; Duan LX, 2010, PROC CVPR IEEE, P1959, DOI 10.1109/CVPR.2010.5539870; Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPR.2009.5206747, 10.1109/CVPRW.2009.5206747]; Fellbaum Christiane, 1998, WORDNET ELECT DATABA; FERGUS R, 2004, P EUR C COMP VIS; HE J, 2004, P ACM C MULT; He X., 2004, P ACM C MULT; Herbrich R., 2001, NEURAL INFORM PROCES; HOI SCH, 2008, P IEEE C COMP VIS PA, V27; JIA J, 2008, P ACM C MULT; JIANG W, 2008, P IEEE INT C IM PROC; Liu Jiaomin, 2009, Proceedings of the 2009 Second International Conference on Intelligent Networks and Intelligent Systems (ICINIS 2009), P15, DOI [10.1109/CVPRW.2009.5206744, 10.1109/ICINIS.2009.13]; Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847; LI X, 2006, P ACM C MULT; LIU Y, 2009, P ACM C MULT; LOUI A, 2007, P ACM WORKSH MULT IN; MARSZALEK M, 2007, P VIS REC CHALL WORK; Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63; RUI Y, 1997, P IEEE INT C IM PROC; Schweikert G.B., 2008, P 21 INT C NEUR INF, V8, P1433; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134; TONG S, 2001, P ACM C MULT; Torralba A., 2008, P IEEE C COMP VIS PA; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; UIJLINGS JRR, 2009, P ACM INT C IM VID R; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; WANG C, 2008, P ACM SIGIR; Wang C., 2007, P IEEE C COMP VIS PA; Wang G., 2009, P IEEE INT C COMP VI; Wang X.-J., 2006, P IEEE C COMP VIS PA; Wang XJ, 2008, IEEE T PATTERN ANAL, V30, P1919, DOI 10.1109/TPAMI.2008.127; Weiss Y., 2008, NEURAL INFORM PROCES; Witten I.H., 1999, MORGAN KAUFMANN SERI; WU P, 2004, P INT C MACH LEARN; YANG J, 2007, P ACM C MULT; ZHANG L, 2001, P IEEE INT C IM PROC; ZHOU XS, 2001, P IEEE C COMP VIS PA; Zhu X, 2008, SEMISUPERVISED LEARN	52	40	41	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2011	33	5					1022	1036		10.1109/TPAMI.2010.142	http://dx.doi.org/10.1109/TPAMI.2010.142			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	738YF	20714015				2022-12-18	WOS:000288677800012
J	Hochbaum, DS				Hochbaum, Dorit S.			Polynomial Time Algorithms for Ratio Regions and a Variant of Normalized Cut	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Grouping; image segmentation; graph theoretic methods; partitioning	IMAGE SEGMENTATION; VARIABLES	In partitioning, clustering, and grouping problems, a typical goal is to group together similar objects, or pixels in the case of image processing. At the same time, another goal is to have each group distinctly dissimilar from the rest and possibly to have the group size fairly large. These goals are often combined as a ratio optimization problem. One example of such a problem is a variant of the normalized cut problem, another is the ratio regions problem. We devise here the first polynomial time algorithms solving optimally the ratio region problem and the variant of normalized cut, as well as a few other ratio problems. The algorithms are efficient and combinatorial, in contrast with nonlinear continuous approaches used in the image segmentation literature, which often employ spectral techniques. Such techniques deliver solutions in real numbers which are not feasible to the discrete partitioning problem. Furthermore, these continuous approaches are computationally expensive compared to the algorithms proposed here. The algorithms presented here use as a subroutine a minimum s, t-cut procedure on a related graph which is of polynomial size. The output consists of the optimal solution to the respective ratio problem, as well as a sequence of nested solutions with respect to any relative weighting of the objectives of the numerator and denominator.	[Hochbaum, Dorit S.] Univ Calif Berkeley, Dept Ind Engn & Operat Res, Berkeley, CA 94720 USA; [Hochbaum, Dorit S.] Haas Sch Business, Mfg & Informat Technol Grp, Philadelphia, PA USA; [Hochbaum, Dorit S.] UC Berkeley Supply Chain Initiat, Berkeley, CA USA	University of California System; University of California Berkeley	Hochbaum, DS (corresponding author), Univ Calif Berkeley, Dept Ind Engn & Operat Res, Etcheverry Hall, Berkeley, CA 94720 USA.	hochbaum@ieor.berkeley.edu						AHUJA RK, 1994, SIAM J COMPUT, V23, P906, DOI 10.1137/S0097539791199334; [Anonymous], 2008, MATLAB NORMALIZED CU; Boykov Y.Y., 2001, ICCV, V1, P105, DOI DOI 10.1109/ICCV.2001.937505; Chandran BG, 2009, OPER RES, V57, P358, DOI 10.1287/opre.1080.0572; CHEEGER J., 1970, PROBLEMS ANAL PAPERS, P195, DOI [10.1515/9781400869312-013, DOI 10.1515/9781400869312-013]; Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; COX IJ, 1996, P INT C PATT REC, V2, P557; CUNNINGHAM WH, 1985, J ACM, V32, P549, DOI 10.1145/3828.3829; GALLO G, 1989, SIAM J COMPUT, V18, P30, DOI 10.1137/0218003; Goldberg A. V., UCBCSD84171; GOLDBERG AV, 1988, J ACM, V35, P921, DOI 10.1145/48014.61051; GOLDSHTEIN V, 1994, INTEGR EQUAT OPER TH, V19, P1, DOI 10.1007/BF01202289; Grady L, 2006, IEEE T PATTERN ANAL, V28, P469, DOI 10.1109/TPAMI.2006.57; HALL KM, 1970, MANAGE SCI, V17, P219, DOI 10.1287/mnsc.17.3.219; HAO JX, 1994, J ALGORITHM, V17, P424, DOI 10.1006/jagm.1994.1043; Hochbaum DS, 2009, EUR J OPER RES, V193, P649, DOI 10.1016/j.ejor.2007.07.027; Hochbaum DS, 2008, OPER RES, V56, P992, DOI 10.1287/opre.1080.0524; Hochbaum DS, 2002, EUR J OPER RES, V140, P291, DOI 10.1016/S0377-2217(02)00071-1; Hochbaum DS, 2001, J ACM, V48, P686, DOI 10.1145/502090.502093; HOCHBAUM DS, 2008, REPLACING SPEC UNPUB; Kohli P, 2007, IEEE T PATTERN ANAL, V29, P2079, DOI 10.1109/TPAMI.2007.1128; Kolmogorov V, 2007, IEEE I CONF COMP VIS, P644; Komodakis N, 2007, IEEE I CONF COMP VIS, P488; Sarkar S, 1996, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.1996.517115; Sharon E, 2006, NATURE, V442, P810, DOI 10.1038/nature04977; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; TOLLIVER D, 2006, P IEEE INT C COMP VI, P1053; Wang S, 2003, IEEE T PATTERN ANAL, V25, P675, DOI 10.1109/TPAMI.2003.1201819	29	40	43	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2010	32	5					889	898		10.1109/TPAMI.2009.80	http://dx.doi.org/10.1109/TPAMI.2009.80			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	569AW	20299712				2022-12-18	WOS:000275569300009
J	Detry, R; Pugeault, N; Piater, JH				Detry, Renaud; Pugeault, Nicolas; Piater, Justus H.			A Probabilistic Framework for 3D Visual Object Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; 3D object representation; pose estimation; nonparametric belief propagation	BELIEF PROPAGATION; RECOGNITION; MODELS	We present an object representation framework that encodes probabilistic spatial relations between 3D features and organizes these features in a hierarchy. Features at the bottom of the hierarchy are bound to local 3D descriptors. Higher level features recursively encode probabilistic spatial configurations of more elementary features. The hierarchy is implemented in a Markov network. Detection is carried out by a belief propagation algorithm, which infers the pose of high-level features from local evidence and reinforces local evidence from globally consistent knowledge, effectively producing a likelihood for the pose of the object in the detection scene. We also present a simple learning algorithm that autonomously builds hierarchies from local object descriptors. We explain how to use our framework to estimate the pose of a known object in an unknown scene. Experiments demonstrate the robustness of hierarchies to input noise, viewpoint changes, and occlusions.	[Detry, Renaud; Piater, Justus H.] Univ Liege, Inst Montefiore, Dept Elect Engn & Comp Sci, INTELSIG Grp, B-4000 Liege, Belgium; [Pugeault, Nicolas] Univ So Denmark, Maersk Mc Kinney Moller Inst, Cognit Vis Lab, Odense, Denmark	University of Liege; University of Southern Denmark	Detry, R (corresponding author), Univ Liege, Inst Montefiore, Dept Elect Engn & Comp Sci, INTELSIG Grp, B28, B-4000 Liege, Belgium.	renaud.detry@ulg.ac.be; npugeaul@inf.ed.ac.uk; justus.piater@ulg.ac.be	Pugeault, Nicolas/AAF-9768-2019; Pugeault, Nicolas/I-1873-2015	Pugeault, Nicolas/0000-0002-3455-6280; Pugeault, Nicolas/0000-0002-3455-6280; Piater, Justus/0000-0002-1898-3362	Belgian National Fund for Scientific Research (FNRS); EU [IST-FP6-IP-027657]	Belgian National Fund for Scientific Research (FNRS)(Fonds de la Recherche Scientifique - FNRS); EU(European Commission)	The authors warmly thank Professor Norbert Kruger for his tireless support, and for very fruitful discussions. The authors also thank Dirk Kraft for providing us with object imagery annotated with ground-truth motion. This work was supported by the Belgian National Fund for Scientific Research (FNRS) and the EU Cognitive Systems project PACO-PLUS (IST-FP6-IP-027657).	BIENENSTOCK E, 1996, ADV NEURAL INFORM PR; Bouchard G, 2005, PROC CVPR IEEE, P710; Coughlan J, 2007, COMPUT VIS IMAGE UND, V106, P47, DOI 10.1016/j.cviu.2005.09.008; DEGRANVILLE C, 2006, P INT C DEV LEARN; DETRY R, 2009, PROBABILISTIC FRAMEW; DETRY R, 2008, P INT COGN VIS WORKS; DETRY R, 2007, P ROB MAN SENS AD RE; DRYDEN IL, 2005, STAT ANAL HIGH DIMEN; EPSHTEIN B, 2005, P IEEE INT C COMP VI; Felzenszwalb PF, 2000, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.2000.854739; Fidler S., 2007, CVPR; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Gordon I, 2006, LECT NOTES COMPUT SC, V4170, P67; Hua G, 2005, PROC CVPR IEEE, P747; Ihler AT, 2005, IEEE J SEL AREA COMM, V23, P809, DOI 10.1109/JSAC.2005.843548; IHLER AT, 2003, P C NEUR INF PROC SY; Isard M, 2003, PROC CVPR IEEE, P613; JORDAN MI, 2002, HDB BRAIN THEORY NEU; Kraft D., 2008, INT J HUMANOID ROBOT; KRAFT D, OBJECT SEQUENCES; Kruger N, 2005, LECT NOTES COMPUT SC, V3704, P157, DOI 10.1007/11565123_16; KUFFNER J, 2004, P INT C ROB AUT MAY; Kushal A, 2006, LECT NOTES COMPUT SC, V3952, P563; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Liebelt J., 2008, P INT C COMP VIS PAT; Mardia K.V., 2000, DIRECTIONAL STAT, P15, DOI [10.1002/9780470316979, DOI 10.1002/9780470316979]; PARK M, 2008, P IEEE C COMP VIS PA, P24; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; PIATER J, 2008, P 12 INT C COGN NEUR; Pugeault N., 2008, EARLY COGNITIVE VISI; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819; Rodgers J., 2006, P IEEE C COMP VIS PA; Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1; Savarese S, 2007, IEEE I CONF COMP VIS, P1245; SCALZO F, 2005, P IEEE C COMP VIS PA; Sigal L, 2004, PROC CVPR IEEE, P421; SIGAL L, 2004, P INT WORKSH COMPL M, P223; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; Sudderth E, 2006, THESIS MIT; SUDDERTH EB, 2003, P IEEE C COMP VIS PA; Toews M, 2007, IEEE I CONF COMP VIS, P31; Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x; Yan P., 2007, COMP VIS 2007 ICCV 2, P1; Yedidia J. S., 2002, UNDERSTANDING BELIEF; Zhang J., 2006, P IEEE C COMP VIS PA, P1536; Zhu SC, 1999, IEEE T PATTERN ANAL, V21, P1170, DOI 10.1109/34.809110	46	40	40	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2009	31	10					1790	1803		10.1109/TPAMI.2009.64	http://dx.doi.org/10.1109/TPAMI.2009.64			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	483VK	19696450	Green Submitted			2022-12-18	WOS:000268996500006
J	Lejsek, H; Asmundsson, FH; Jonsson, BP; Amsaleg, L				Lejsek, Herwig; Asmundsson, Friorik Heioar; Jonsson, Bjorn Por; Amsaleg, Laurent			NV-Tree: An Efficient Disk-Based Index for Approximate Search in Very Large High-Dimensional Collections	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						High-dimensional indexing; multimedia indexing; very large databases; approximate searches		Over the last two decades, much research effort has been spent on nearest neighbor search in high-dimensional data sets. Most of the approaches published thus far have, however, only been tested on rather small collections. When large collections have been considered, high-performance environments have been used, in particular systems with a large main memory. Accessing data on disk has largely been avoided because disk operations are considered to be too slow. It has been shown, however, that using large amounts of memory is generally not an economic choice. Therefore, we propose the NV-tree, which is a very efficient disk-based data structure that can give good approximate answers to nearest neighbor queries with a single disk operation, even for very large collections of high-dimensional data. Using a single NV-tree, the returned results have high recall but contain a number of false positives. By combining two or three NV-trees, most of those false positives can be avoided while retaining the high recall. Finally, we compare the NV-tree to Locality Sensitive Hashing, a popular method for epsilon-distance search. We show that they return results of similar quality, but the NV-tree uses many fewer disk reads.	[Lejsek, Herwig; Asmundsson, Friorik Heioar] EFF2 Technol Ehf, IS-103 Reykjavik, Iceland; [Jonsson, Bjorn Por] Reykjavik Univ, IS-103 Reykjavik, Iceland; [Amsaleg, Laurent] IRISA, CNRS IRISA, F-35042 Rennes, France	Reykjavik University; Centre National de la Recherche Scientifique (CNRS)	Lejsek, H (corresponding author), EFF2 Technol Ehf, Kringlan 1, IS-103 Reykjavik, Iceland.	herwig@eff2.net; fridrik@eff2.net; bjorn@ru.is; Laurent.Amsaleg@irisa.fr	Lejsek, Herwig/AAA-4776-2020		Icelandic Research Fund [060036021]; INRIA Eff<SUP>2</SUP> Associate Teams; EGIDE Jules Verne	Icelandic Research Fund; INRIA Eff<SUP>2</SUP> Associate Teams; EGIDE Jules Verne	This work was partially supported by Icelandic Research Fund Grant 060036021, by an INRIA Eff<SUP>2</SUP> Associate Teams grant, and by an EGIDE Jules Verne travel grant. The authors would like to thank Morgunbladid for the use of their large picture collection, the authors of LSH and SIFT for giving them access to their implementations, and the anonymous reviewers for their excellent comments that significantly improved the presentation of this paper.	Amsaleg L, 2001, PATTERN ANAL APPL, V4, P108, DOI 10.1007/s100440170011; Andoni A., 2005, E2LSH 0 1 USER MANUA; BALUJA S, 2006, P IET C MULT; Berrani S. - A., 2003, P 2003 ACM CIKM INT, P24; Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217; Fagin R., 2003, P 2003 ACM SIGMOD IN, P301, DOI [10.1145/872757.872795, DOI 10.1145/872757.872795]; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Gray J., 1997, SIGMOD Record, V26, P63, DOI 10.1145/271074.271094; Gray J., 1987, P ASS COMP MACH SPEC, P395; Joly A, 2007, IEEE T MULTIMEDIA, V9, P293, DOI 10.1109/TMM.2006.886278; KE Y, 2004, P 12 ACM INT C MULT, P869, DOI DOI 10.1145/1027527.1027729]; Kleinberg J. M., 1997, P 20 9 ANN ACM S THE, P599; LEJSEK H, 2006, P 14 ANN ACM INT C M, P589; Lejsek H., 2005, P JOURN BAS DONN AV; Li C, 2002, IEEE T KNOWL DATA EN, V14, P792, DOI 10.1109/TKDE.2002.1019214; LIU T, 2006, THESIS CARNEGIE MELL; Liu T., 2007, P 8 IEEE WORKSH APPL, P28, DOI 10.1109/WACV.2007.18; Liu T., 2004, NIPS 2004, P825; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mirrokni V., 2006, LOCALITY SENSITIVE H; PETITCOLAS FAP, 2001, P ELECT IMAGING SECU, V3, P575; Shaft U, 2006, ACM T DATABASE SYST, V31, P814, DOI 10.1145/1166074.1166077; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194	25	40	41	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2009	31	5					869	883		10.1109/TPAMI.2008.130	http://dx.doi.org/10.1109/TPAMI.2008.130			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	418JM	19299861				2022-12-18	WOS:000264144500008
J	Ho, SS; Wechsler, H				Ho, Shen-Shyang; Wechsler, Harry			Query by transduction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						active learning; hypothesis testing; transductive inference; Kolmogorov complexity; support vector machine		There has recently been a growing interest in the use of transductive inference for learning. We expand here the scope of transductive inference to active learning in a stream-based setting. Toward that end, this paper proposes Query-by-Transduction (QBT) as a novel active learning algorithm. QBT queries the label of an example based on the p-values obtained using transduction. We show that QBT is closely related to Query-by-Committee (QBC) using relations between transduction, Bayesian statistical testing, Kullback-Leibler divergence, and Shannon information. The feasibility and utility of QBT is shown on both binary and multiclass classification tasks using a support vector machine (SVM) as the choice classifier. Our experimental results show that QBT compares favorably, in terms of mean generalization, against random sampling, committee-based active learning, margin-based active learning, and QBC in the stream-based setting.	[Wechsler, Harry] George Mason Univ, Ctr Distributed & Intelligent Computat, Fairfax, VA 22030 USA	George Mason University		sho@jpl.nasa.gov; wechsler@gmu.edu	Ho, Shen-Shyang/B-7034-2012	Ho, Shen-Shyang/0000-0002-0353-7159				ABE N, 1998, P 15 INT C MACH LEAR, P1; Baram Y, 2004, J MACH LEARN RES, V5, P255; Brinker K, 2004, THESIS U PADERBORN; Campbell C., 2000, P 17 IN C MACH LAM S, P111; Cauwenberghs G, 2001, ADV NEUR IN, V13, P409; Chapelle O., 2006, IEEE T NEURAL NETW, V20, P542; Cherkassky V. S., 1998, LEARNING DATA CONCEP, V1st; Cohn DA, 1996, J ARTIF INTELL RES, V4, P129, DOI 10.1613/jair.295; CRAIG R, 2006, P ACM S APPL COMP, P161; Dagan Ido, 1995, P 12 INT C MACH LEAR, P150, DOI [10.1016/B978-1-55860-377-6.50027-X, DOI 10.1016/B978-1-55860-377-6.50027-X]; DASGUPTA S, 2005, P 18 ANN C LEARN THE; DIMA C, 2005, ROBOTICS SCI SYSTEMS, P9; Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534; FREY PW, 1991, MACH LEARN, V6, P161, DOI 10.1023/A:1022606404104; Gammerman A, 2002, THEOR COMPUT SCI, V287, P209, DOI 10.1016/S0304-3975(02)00100-7; GILADBACHRACH R, 2005, P ANN C ADV NEUR INF; GOH KS, 2004, P 12 ANN ACM INT C M, P564, DOI DOI 10.1145/1027527.1027664; GRAEPEL T, 2000, P ANN C ADV NEUR INF, P514; GRAEPEL T, 1999, P ANN C ADV NEUR INF, P456; HO SS, 2004, P ICDM WORKSH TEMP D; HO SS, 2003, P INT JOINT C NEUR N; Hoi SCH, 2006, P 15 INT C WORLD WID, P633, DOI [10.1145/1135777.1135870, DOI 10.1145/1135777.1135870]; Hoi SCH, 2006, P 23 INT C MACH LEAR, V148, P417, DOI [10.1145/1143844.1143897, DOI 10.1145/1143844.1143897]; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; Kothari R, 2003, IEEE T NEURAL NETWOR, V14, P1496, DOI 10.1109/TNN.2003.820446; Kullback S, 1959, INFORM THEORY STAT; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; Lewis David D, 1994, P 11 INT C MACH LEAR, P148, DOI [10.1016/b978-1-55860-335-6.50026-x, DOI 10.1016/B978-1-55860-335-6.50026-X]; Li F, 2005, IEEE T PATTERN ANAL, V27, P1686, DOI 10.1109/TPAMI.2005.224; Li M., 1997, INTRO KOLMOGOROV COM, DOI 10.1016/b978-0-444-88071-0.50009-6; Li MK, 2006, IEEE T PATTERN ANAL, V28, P1251, DOI 10.1109/TPAMI.2006.156; Luo T, 2005, J MACH LEARN RES, V6, P589; MACKAY DJC, 1992, NEURAL COMPUT, V4, P590, DOI 10.1162/neco.1992.4.4.590; McCallumzy A.K., 1998, ICML, V98, P359; Melluish T, 2001, LECT NOTES ARTIF INT, P360; MELVILLE P, 2005, P 16 EUR C MACH LEAR, P268; Mitra P, 2004, IEEE T PATTERN ANAL, V26, P413, DOI 10.1109/TPAMI.2004.1262340; Mooney PremMelvilleandRaymondJ., 2004, INPROCEEDINGSOFTHETW, P74, DOI [10.1145/1015330.1015385, DOI 10.1145/1015330.1015385, 10.1145/1015330.1015385event-place, DOI 10.1145/1015330.1015385EVENT-PLACE]; OKABE M, 2005, P HUM LANG TECHN C C, P963; PROEDRU K, 2002, P 13 EUR C MACH LEAR, P381; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; Roy Nicholas, 2001, P 18 INT C MACH LEAR, P441; Saunders C, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P722; Schohn G., 2000, P INT C MACH LEARN, P839; Sellke T, 2001, AM STAT, V55, P62, DOI 10.1198/000313001300339950; Seung H. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P287, DOI 10.1145/130385.130417; Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243; Tong S., 2001, PROC ACM INT C MULTI, V9, P107; Tur G, 2003, P IEEE INT C AC SPEE; Vapnik V., 2000, NATURE STAT LEARNING; Vovk V, 1999, MACHINE LEARNING, PROCEEDINGS, P444; Vovk V., 2005, ALGORITHMIC LEARNING, DOI DOI 10.1007/B106715; Warmuth MK, 2003, J CHEM INF COMP SCI, V43, P667, DOI 10.1021/ci025620t; Weerahandi S, 1994, EXACT STAT METHODS D; Yan R, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P516; YAN R, 2004, P IEEE INT C MULT EX, P67; Yu K., 2006, P 23 INT C MACH LEAR, P1081; Zhang C, 2002, IEEE T MULTIMEDIA, V4, P260, DOI 10.1109/TMM.2002.1017738; Zhang Tong, 2000, P 17 INT C MACHINE L, P1191; ZHU X, 2003, P ICML WORKSH CONT L	60	40	41	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2008	30	9					1557	1571		10.1109/TPAMI.2007.70811	http://dx.doi.org/10.1109/TPAMI.2007.70811			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	324FZ	18617715				2022-12-18	WOS:000257504400005
J	Bertelli, L; Sumengen, B; Manjunath, BS; Gibou, F				Bertelli, Luca; Sumengen, Baris; Manjunath, B. S.; Gibou, Frederic			A variational framework for multiregion pairwise-similarity-based image segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						region-based image segmentation; grouping; level sets; multiphase motion; pairwise similarity measure	ACTIVE CONTOURS; SHAPE PRIORS	Variational cost functions that are based on pairwise similarity between pixels can be minimized within the level set framework, resulting in a binary image segmentation. In this paper, we extend such cost functions and address the multiregion image segmentation problem by employing a multiphase level set framework. For multimodal images cost functions become more complicated and relatively difficult to minimize. We extend our previous work [1], proposed for background-foreground separation, to the segmentation of images into more than two regions. We also demonstrate an efficient implementation of the curve evolution, which reduces the computational time significantly. Finally, we validate the proposed method on the Berkeley Segmentation Data Set by comparing its performance with other segmentation techniques.	[Bertelli, Luca; Manjunath, B. S.] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA; [Sumengen, Baris] Riya Inc, San Mateo, CA 94403 USA; [Gibou, Frederic] Univ Calif Santa Barbara, Dept Mech Engn, Santa Barbara, CA 93106 USA; [Gibou, Frederic] Univ Calif Santa Barbara, Dept Comp Sci, Santa Barbara, CA 93106 USA	University of California System; University of California Santa Barbara; University of California System; University of California Santa Barbara; University of California System; University of California Santa Barbara	Bertelli, L (corresponding author), Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.	lbertelli@ece.ucsb.edu; sumengen@ece.ucsb.edu; manj@ece.ucsb.edu; fgibou@engineering.ucsb.edu	Manjunath, B S/AAM-8190-2020; Gibou, Frederic/AAU-4944-2020	Manjunath, B S/0000-0003-2804-3611; 				AUBERT G, 2003, SIAM APPL MATH; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; Chakraborty A, 1999, IEEE T PATTERN ANAL, V21, P12, DOI 10.1109/34.745730; Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; CREMERS D, 2004, P EUR C COMP VIS, P74; Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5; Cremers D, 2006, IEEE T PATTERN ANAL, V28, P1262, DOI 10.1109/TPAMI.2006.161; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; Gibou F., 2005, P 4 ANN HAW INT C ST; Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Malik J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P918, DOI 10.1109/ICCV.1999.790346; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; PARAGIOS N, 1999, P IEEE INT C COMP VI, V2, P926; PARAGIOS N, 2002, INT J COMPUT VISION, P223; PERONA P, 1998, P EUR C COMP VIS, P655; RAVIV TR, 2005, P 10 IEEE INT C COMP, P204; RAVIV TR, 2006, INT J COMPU IN PRESS; RAVIV TR, 2006, P IEEE CS C COMP VIS; Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10; SETHIAN JA, 1996, P NAT ACAD SCI, V93, P4; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Sumengen B, 2006, IEEE T PATTERN ANAL, V28, P509, DOI 10.1109/TPAMI.2006.76; SUMENGEN B, 2006, P 5 IEEE CS WORKSH P; Theodoridis S., 2006, PATTERN RECOGN; Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033; Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076; Yezzi A.  Jr., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P898, DOI 10.1109/ICCV.1999.790317; Zhao HK, 1996, J COMPUT PHYS, V127, P179, DOI 10.1006/jcph.1996.0167; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343; ZHU SC, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P416, DOI 10.1109/ICCV.1995.466909	35	40	47	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2008	30	8					1400	1414		10.1109/TPAMI.2007.70785	http://dx.doi.org/10.1109/TPAMI.2007.70785			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	312OC	18566494				2022-12-18	WOS:000256679700007
J	Deng, WH; Hu, JN; Guo, J; Zhang, HG; Zhang, C				Deng, Weihong; Hu, Jiani; Guo, Jun; Zhang, Honggang; Zhang, Chuang			Comments on "globally maximizing, locally minimizing: Unsupervised discriminant projection with application to face and palm biometrics"	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						dimensionality reduction; unsupervised discriminant projection (UDP); locality preserving projection (LPP)		In [1], UDP is proposed to address the limitation of LPP for the clustering and classification tasks. In this communication, we show that the basic ideas of UDP and LPP are identical. In particular, UDP is just a simplified version of LPP on the assumption that the local density is uniform.	[Deng, Weihong; Hu, Jiani; Guo, Jun; Zhang, Honggang; Zhang, Chuang] Beijing Univ Posts & Telecommun, Sch Informat Engn, Lab Pattern Recognit & Intelligent System, Beijing 100876, Peoples R China	Beijing University of Posts & Telecommunications	Deng, WH (corresponding author), Beijing Univ Posts & Telecommun, Sch Informat Engn, Lab Pattern Recognit & Intelligent System, POB 186, Beijing 100876, Peoples R China.	whdeng@bupt.edu.cn; guojun@bupt.edu.cn; zhhg@bupt.edu.cn; cughu@126.com	Deng, Wei/GWC-9207-2022	Deng, Weihong/0000-0001-5952-6996				Cai D, 2005, IEEE T KNOWL DATA EN, V17, P1624, DOI 10.1109/TKDE.2005.198; He  X., 2005, P 22 INT C MACH LEAR, V22, P281; He X, 2003, NIPS; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008	5	40	50	0	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2008	30	8					1503	1504		10.1109/TPAMI.2007.70783	http://dx.doi.org/10.1109/TPAMI.2007.70783			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	312OC	18566503				2022-12-18	WOS:000256679700016
J	Calderara, S; Cucchiara, R; Prati, A				Calderara, Simone; Cucchiara, Rita; Prati, Andrea			Bayesian-competitive consistent labeling for people surveillance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						consistent labeling; multicamera video surveillance; epipolar geometry	TRACKING; OBJECTS	This paper presents a novel and robust approach to consistent labeling for people surveillance in multicamera systems. A general framework scalable to any number of cameras with overlapped views is devised. An offline training process automatically computes ground-plane homography and recovers epipolar geometry. When a new object is detected in any one camera, hypotheses for potential matching objects in the other cameras are established. Each of the hypotheses is evaluated using a prior and likelihood value. The prior accounts for the positions of the potential matching objects, while the likelihood is computed by warping the vertical axis of the new object on the field of view of the other cameras and measuring the amount of match. In the likelihood, two contributions ( forward and backward) are considered so as to correctly handle the case of groups of people merged into single objects. Eventually, a maximum-a-posteriori approach estimates the best label assignment for the new object. Comparisons with other methods based on homography and extensive outdoor experiments demonstrate that the proposed approach is accurate and robust in coping with segmentation errors and in disambiguating groups.	[Calderara, Simone; Cucchiara, Rita] Univ Modena & Reggio Emilia, Dipartimento Ingn Informaz, I-41100 Modena, Italy; [Prati, Andrea] Univ Modena & Reggio Emilia, Dipartimento Sci Method Ingn, I-42100 Reggio Emilia, Italy	Universita di Modena e Reggio Emilia; Universita di Modena e Reggio Emilia	Calderara, S (corresponding author), Univ Modena & Reggio Emilia, Dipartimento Ingn Informaz, Via Vignolese 905, I-41100 Modena, Italy.	simone.calderara@unimore.it; rita.cucchiara@unimore.it; andrea.prati@unimore.it	Calderara, Simone/M-6932-2015; Prati, Andrea/B-7440-2014; Cucchiara, Rita/L-3006-2015	Calderara, Simone/0000-0001-9056-1538; Prati, Andrea/0000-0002-1211-529X; Cucchiara, Rita/0000-0002-2239-283X				Brauer-Burchardt C, 2000, INT C PATT RECOG, P559, DOI 10.1109/ICPR.2000.905399; CALDERARA S, 2005, P IEEE INT C ADV VID, P93; Chang TH, 2001, 2001 IEEE WORKSHOP ON MULTI-OBJECT TRACKING, PROCEEDINGS, P19, DOI 10.1109/MOT.2001.937977; Cucchiara R, 2004, INT C PATT RECOG, P132, DOI 10.1109/ICPR.2004.1334025; Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909; Dockstader SL, 2001, P IEEE, V89, P1441, DOI 10.1109/5.959340; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683; Huang T, 1997, INT JOINT CONF ARTIF, P1276; Javed O, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P952; JIANG L, 2002, P IEEE INT C CONTR A, V1, P309; KANG J, 2004, P INT C PATT REC AUG, V4, P759; KANG JM, 2003, P IEEE INT C COMP VI, V1; KETTNAKER V, 1999, P CVPR, V2, P253; Khan S, 2003, IEEE T PATTERN ANAL, V25, P1355, DOI 10.1109/TPAMI.2003.1233912; Krumm J, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P3, DOI 10.1109/VS.2000.856852; LUONG QT, 1993, DETERMINING FUNDAMEN; Lv FJ, 2002, INT C PATT RECOG, P562, DOI 10.1109/ICPR.2002.1044793; Mittal A, 2003, INT J COMPUT VISION, V51, P189, DOI 10.1023/A:1021849801764; Niu W, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P719, DOI 10.1109/ICME.2004.1394293; Nummiaro K, 2003, LECT NOTES COMPUT SC, V2781, P591; Orwell J, 1999, SECOND IEEE WORKSHOP ON VISUAL SURVEILLANCE (VS'99), PROCEEDINGS, P14, DOI 10.1109/VS.1999.780264; Pasula H, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P1160; Stauffer C, 2003, PROC CVPR IEEE, P259; Stein G. P., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P521, DOI 10.1109/CVPR.1999.786987; TAN MH, 2003, P 2003 JOINT C 4 INT, V3, P1335; Yue ZF, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P1; Zhou QM, 2006, IMAGE VISION COMPUT, V24, P1244, DOI 10.1016/j.imavis.2005.06.008	28	40	40	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2008	30	2					354	360		10.1109/TPAMI.2007.70814	http://dx.doi.org/10.1109/TPAMI.2007.70814			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	240IC	18084065				2022-12-18	WOS:000251580300013
J	Hasinoff, SW; Kutulakos, KN				Hasinoff, Samuel W.; Kutulakos, Kiriakos N.			Photo-consistent reconstruction of semitransparent scenes by density-sheet decomposition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						semitransparent scenes; fire; volumetric reconstruction; 3D reconstruction; computerized tomography; view synthesis; image-based modeling; image-based rendering	TOMOGRAPHY; MODEL	This paper considers the problem of reconstructing visually realistic 3D models of dynamic semitransparent scenes, such as fire, from a very small set of simultaneous views ( even two). We show that this problem is equivalent to a severely underconstrained computerized tomography problem, for which traditional methods break down. Our approach is based on the observation that every pair of photographs of a semitransparent scene defines a unique density field, called a Density Sheet, that 1) concentrates all its density on one connected, semitransparent surface, 2) reproduces the two photos exactly, and 3) is the most spatially compact density field that does so. From this observation, we reduce reconstruction to the convex combination of sheet-like density fields, each of which is derived from the Density Sheet of two input views. We have applied this method specifically to the problem of reconstructing 3D models of fire. Experimental results suggest that this method enables high-quality view synthesis without overfitting artifacts.	Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada	University of Toronto	Hasinoff, SW (corresponding author), Univ Toronto, Dept Comp Sci, 10 Kings Coll Rd,Room 3302, Toronto, ON M5S 3G4, Canada.	hasinoff@cs.toronto.edu; kyros@cs.toronto.edu						Agrawal AK, 1998, APPL OPTICS, V37, P479, DOI 10.1364/AO.37.000479; ALBERS BW, 1999, SCHLIEREN ANAL OSCIL, V199, P84; [Anonymous], 1999, NUMERICAL OPTIMIZATI; Baum RT, 1998, COMBUST FLAME, V113, P358, DOI 10.1016/S0010-2180(97)00219-8; BHAT KS, 2004, P ACM SIGGRAPH 2004, P360; BHOTIKA R, 2002, P EUR C COMP VIS, V3, P112; BONET JD, 1999, P 7 INT C COMP VIS, P418; Bouguet J. Y, 2002, CAMERA CALIBRATION T; CHIBA N, 1994, J VISUAL COMP ANIMAT, V5, P37, DOI 10.1002/vis.4340050104; Correia DP, 2001, COMBUST SCI TECHNOL, V163, P1, DOI 10.1080/00102200108952149; DACHILLE F, 2000, P IEEE S VOL VIS, P109; Doretto G, 2003, PROC CVPR IEEE, P137; Drysdale D., 1998, INTRO FIRE DYNAMICS, Vsecond; Duderstadt J. J., 1979, Transport theory; Elangovan V., 2001, P 4 INT C MED IM COM, P213; FARIS GW, 1987, OPT LETT, V12, P155, DOI 10.1364/OL.12.000155; FARIS GW, 1987, OPT LETT, V12, P72, DOI 10.1364/OL.12.000072; Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260; FOSTER N, 1997, P SIGGRAPH 97, P181; Frese T, 2002, IEEE T IMAGE PROCESS, V11, P756, DOI [10.1109/TIP.2002.801586, 10.1109/TIP2002.801586]; HASINOFF SW, 2002, 3 DIMENSIONAL RECONS; HAWKINS T, 2005, P ACM SIGGRAPH 2005, P812; IHRKE I, 2005, GROVISFIRE MULTI VID; Ihrke I., 2004, P ACM SIGGRAPH EUR S, P367; Jos Stam, 1995, P 22 ANN C COMP GRAP, P129, DOI [10.1145/218380.218430, DOI 10.1145/218380.218430]; Kak A.V., 1988, PRINCIPLES COMPUTERI, DOI DOI 10.1137/1.9780898719277.CH7; Kuba A., 1999, DISCRETE TOMOGRAPHY; Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264; Lamorlette A, 2002, ACM T GRAPHIC, V21, P729, DOI 10.1145/566570.566644; Mohammad-Djafari A., 1996, Proceedings of the IASTED International Conference: Signal and Image Processing (SIP-96), P325; Narayanan PJ, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P3, DOI 10.1109/ICCV.1998.710694; Nguyen DQ, 2002, ACM T GRAPHIC, V21, P721, DOI 10.1145/566570.566643; Otsuka T, 2001, J LOSS PREVENT PROC, V14, P503, DOI 10.1016/S0950-4230(01)00045-6; RECHE A, 2004, P ACM SIGGRAPH, P720; Schodl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012; Schwarz A, 1996, MEAS SCI TECHNOL, V7, P406, DOI 10.1088/0957-0233/7/3/023; SEITZ SM, 1996, P SIGGRAPH 96, P21; SILVA C, 2000, P 6 EUR C COMP VIS, V1, P100; Soatto S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P439, DOI 10.1109/ICCV.2001.937658; Stewart G., 1973, INTRO MATRIX COMPUTA; Szeliski R, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P517, DOI 10.1109/ICCV.1998.710766; TAKAI Y, 1995, VISUAL COMPUT, V11, P240, DOI 10.1007/BF01901042; Wolberg G, 1990, DIGITAL IMAGE WARPIN; XUE W, 2001, USE MOIRE TOMOGRAPHY, V37, P440; 2003, DIGITAL AIR INCORPOR	45	40	42	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2007	29	5					870	885		10.1109/TPAMI.2007.1056	http://dx.doi.org/10.1109/TPAMI.2007.1056			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HK	17356205				2022-12-18	WOS:000244855700009
J	Meinicke, P; Klanke, S; Memisevic, R; Ritter, H				Meinicke, P; Klanke, S; Memisevic, R; Ritter, H			Principal surfaces from unsupervised kernel regression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						dimensionality reduction; principal curves; principal surfaces; density estimation; model selection; kernel methods	DIMENSIONALITY REDUCTION	We propose a nonparametric approach to learning of principal surfaces based on an unsupervised formulation of the Nadaraya-Watson kernel regression estimator. As compared with previous approaches to principal curves and surfaces, the new method offers several advantages: First, it provides a practical solution to the model selection problem because all parameters can be estimated by leave-one-out cross-validation without additional computational cost. In addition, our approach allows for a convenient incorporation of nonlinear spectral methods for parameter initialization, beyond classical initializations based on linear PCA. Furthermore, it shows a simple way to fit principal surfaces in general feature spaces, beyond the usual data space setup. The experimental results illustrate these convenient features on simulated and real data.	Univ Gottingen, Fac Biol, Bioinformat Dept, D-37077 Gottingen, Germany; Univ Bielefeld, Fac Technol, Neuroinformat Grp, D-33501 Bielefeld, Germany; Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada	University of Gottingen; University of Bielefeld; University of Toronto	Meinicke, P (corresponding author), Univ Gottingen, Fac Biol, Bioinformat Dept, Goldschmidtstr 1, D-37077 Gottingen, Germany.	pmeinic@gwdg.de; sklanke@techfak.uni-bielefeld.de; roland@cs.toronto.edu; helge@techfak.uni-bielefeld.de						[Anonymous], 2002, LEARNING KERNELS; BAKIR GH, 2003, ADV NEURAL INFORMATI; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bengio Y, 2004, NEURAL COMPUT, V16, P2197, DOI 10.1162/0899766041732396; Bishop CM, 1998, NEUROCOMPUTING, V21, P203, DOI 10.1016/S0925-2312(98)00043-5; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Chang K, 2001, IEEE T PATTERN ANAL, V23, P22, DOI 10.1109/34.899944; Hastie T., 1984, THESIS STANFORD U; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; Kegl B, 2000, IEEE T PATTERN ANAL, V22, P281, DOI 10.1109/34.841759; Kohonen T., 1995, SELF ORG MAPS, V30, DOI 10.1007/978-3-642-97610-0; KWOK JT, 2002, P 6 ANN WORKSH KERN; Lagarias JC, 1998, SIAM J OPTIMIZ, V9, P112, DOI 10.1137/S1052623496303470; LEBLANC M, 1994, J AM STAT ASSOC, V89, P53; MEINICKE P, 2000, THESIS U BIELEFELD; NADARAYA EA, 1965, THEOR PROBAB APPL+, V10, P186, DOI 10.1137/1110024; REINER H, 1995, HDB GLOBALM OPTIMIZA; RIEDMILLER M, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P586, DOI 10.1109/ICNN.1993.298623; RITTER H, 1992, NEURAL COMPUTING SEL; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Sandilya S, 2002, IEEE T INFORM THEORY, V48, P2789, DOI 10.1109/TIT.2002.802614; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SCOTT DV, 1992, MULTIVARIATE DENISTY; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; Smola AJ, 2001, J MACH LEARN RES, V1, P179, DOI 10.1162/15324430152748227; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Walter J, 1996, NEUROCOMPUTING, V12, P131, DOI 10.1016/0925-2312(95)00117-4; Watson G.S., 1964, SANKHYA SER A, V26, P359, DOI DOI 10.2307/25049340; Westermeyer RR, 2003, J EMERG MED, V24, P15, DOI 10.1016/S0736-4679(02)00661-3	30	40	40	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2005	27	9					1379	1391		10.1109/TPAMI.2005.183	http://dx.doi.org/10.1109/TPAMI.2005.183			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	944XB	16173183	Green Submitted			2022-12-18	WOS:000230463300003
J	Dorst, L				Dorst, L			First order error propagation of the Procrustes method for 3D attitude estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						rigid body motion analysis; pose estimation; attitude estimation; Procrustes method; orthogonal Procrustes problem; perturbation analysis; error propagation; polar decomposition	CLOSED-FORM SOLUTION	The well-known Procrustes method determines the optimal rigid body motion that registers two point clouds by minimizing the square distances of the residuals. In this paper, we perform the first order error analysis of this method for the 3D case, fully specifying how directional noise in the point clouds affects the estimated parameters of the rigid body motion. These results are much more specific than the error bounds which have been established in numerical analysis. We provide an intuitive understanding of the outcome to facilitate direct use in applications.	Univ Amsterdam, Intelligent Syst Lab, NL-1098 SJ Amsterdam, Netherlands	University of Amsterdam	Dorst, L (corresponding author), Univ Amsterdam, Intelligent Syst Lab, Kruislaan 403, NL-1098 SJ Amsterdam, Netherlands.	leo@science.uva.nl						ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; Chu MT, 1998, STAT COMPUT, V8, P125, DOI 10.1023/A:1008934100736; DORST L, 2005, IN PRESS PHILOS T RO; Eggert DW, 1997, MACH VISION APPL, V9, P272, DOI 10.1007/s001380050048; FARRELL JL, 1960, PHOTOGRAMMETRIA, V16, P34; GREEN BF, 1952, PSYCHOMETRIKA, V17, P429; HANSON RJ, 1981, SIAM J SCI STAT COMP, V2, P363, DOI 10.1137/0902029; HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; KANATANI K, 1994, IEEE T PATTERN ANAL, V16; *MATH WORKS INC, 1984, MATL LANG TECHN COMP; McRobie FA, 1999, INT J NUMER METH ENG, V45, P377, DOI 10.1002/(SICI)1097-0207(19990610)45:4<377::AID-NME586>3.0.CO;2-P; Ohta N, 1998, IEICE T INF SYST, VE81D, P1247; SCHONEMA.PH, 1966, PSYCHOMETRIKA, V31, P1, DOI 10.1007/BF02289451; SIBSON R, 1978, J ROY STAT SOC B MET, V40, P234; SODERKVIST I, 1993, BIT, V33, P687, DOI 10.1007/BF01990543; SODERKVIST I, 1994, ACM T DATABASE SYST, V34, P424; UMEYAMA S, 1991, IEEE PATTERN ANAL MA, V13	18	40	48	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2005	27	2					221	229		10.1109/TPAMI.2005.29	http://dx.doi.org/10.1109/TPAMI.2005.29			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	879AR	15688559				2022-12-18	WOS:000225689300005
J	Sarkar, P; Nagy, G				Sarkar, P; Nagy, G			Style consistent classification of isogenous patterns	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						style; isogenous patterns; style consistency; style constrained classification; style-bound variant; style-shared variant; Optical Character Recognition; font recognition; field classification; mixture model	RECOGNITION	In many applications of pattern recognition, patterns appear together in groups ( fields) that have a common origin. For example, a printed word is usually a field of character patterns printed in the same font. A common origin induces consistency of style in features measured on patterns. The features of patterns co-occurring in a field are statistically dependent because they share the same, albeit unknown, style. Style constrained classifiers achieve higher classification accuracy by modeling such dependence among patterns in a field. Effects of style consistency on the distributions of field-features ( concatenation of pattern features) can be modeled by hierarchical mixtures. Each field derives from a mixture of styles, while, within a field, a pattern derives from a class-style conditional mixture of Gaussians. Based on this model, an optimal style constrained classifier processes entire fields of patterns rendered in a consistent but unknown style. In a laboratory experiment, style constrained classification reduced errors on fields of printed digits by nearly 25 percent over singlet classifiers. Longer fields favor our classification method because they furnish more information about the underlying style.	Palo Alto Res Ctr, Palo Alto, CA 94304 USA; Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA	Rensselaer Polytechnic Institute	Sarkar, P (corresponding author), Palo Alto Res Ctr, 3333 Coyote Hill Rd, Palo Alto, CA 94304 USA.	psarkar@parc.com; nagy@ecse.rpi.edu		Nagy, George/0000-0002-0521-1443				BAIRD HS, 1994, P SOC PHOTO-OPT INS, V2181, P106, DOI 10.1117/12.171098; Bazzi I, 1999, IEEE T PATTERN ANAL, V21, P495, DOI 10.1109/34.771314; Bickel P., 2015, MATH STAT BASIC IDEA; Bouletreau V, 1997, PROC INT CONF DOC, P102, DOI 10.1109/ICDAR.1997.619822; CASEY RG, 1986, P ICPR 8 PARIS, P349; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Duda R.O., 1973, J ROYAL STAT SOC SER; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Ho T. K., 1991, P 1 INT C DOC AN REC, P905; HULL JJ, 1982, IEEE T PATTERN ANAL, V4, P520, DOI 10.1109/TPAMI.1982.4767297; Jelinek Frederick, 1997, STAT METHODS SPEECH; Mathis C, 2002, INT C PATT RECOG, P103, DOI 10.1109/ICPR.2002.1044623; NAGY G, 1992, P 11 INT C PATT REC, V2, P225; NATHAN KS, 1993, P IEEE INT C AC SPEE, V5, P121; PLAMONDON R, 1999, WILEY ENCY ELECT ELE, V15, P123; Sarkar P, 2003, PROC INT CONF DOC, P38; Sarkar P, 2002, INT C PATT RECOG, P243, DOI 10.1109/ICPR.2002.1047442; Sarkar P, 2001, PROC INT CONF DOC, P1169, DOI 10.1109/ICDAR.2001.953969; Sarkar P, 2000, INT C PATT RECOG, P855, DOI 10.1109/ICPR.2000.906209; SARKAR P, 2000, THESIS RENSSELAER PO; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SINHA RMK, 1988, PATTERN RECOGN, V21, P463, DOI 10.1016/0031-3203(88)90006-4; TENENBAUM JB, 1997, ADV NEURAL INFORMATI, V9; Veeramachaneni S, 2005, IEEE T PATTERN ANAL, V27, P14, DOI 10.1109/TPAMI.2005.19; Veeramachaneni S, 2002, INT C PATT RECOG, P72, DOI 10.1109/ICPR.2002.1048239; Veeramachaneni S, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P41, DOI 10.1109/IWFHR.2002.1030882; Veeramachaneni S., 2003, INT J DOC ANAL RECOG, V6, P154; Xu YH, 1999, IEEE T PATTERN ANAL, V21, P1280, DOI 10.1109/34.817408; Zramdini A, 1998, IEEE T PATTERN ANAL, V20, P877, DOI 10.1109/34.709616	29	40	43	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2005	27	1					88	98		10.1109/TPAMI.2005.18	http://dx.doi.org/10.1109/TPAMI.2005.18			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	870BE	15628271				2022-12-18	WOS:000225028200009
J	van Wyk, BJ; van Wyk, MA				van Wyk, BJ; van Wyk, MA			A POCS-based graph matching algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						graph matching; subgraph matching; contextual correspondence matching; projection onto convex sets	RELAXATION; INVARIANT; MODEL	A novel Projections Onto Convex Sets (POCS) graph matching algorithm is presented. Two-way assignment constraints are enforced without using elaborate penalty terms, graduated nonconvexity, or sophisticated annealing mechanisms to escape from poor local minima. Results indicate that the presented algorithm is robust and compares favorably to other well-known algorithms.	Tshwane Univ Technol, French S African Tech Inst Elect, ZA-0001 Pretoria, South Africa	Tshwane University of Technology	van Wyk, BJ (corresponding author), Tshwane Univ Technol, French S African Tech Inst Elect, Private Bag X680, ZA-0001 Pretoria, South Africa.	ben.van.wyk@fsatie.ac.za; mavw@fsatie.ac.za		Van Wyk, Barend/0000-0002-2222-4393				CHEN TW, 1994, IEEE T PATTERN ANAL, V16, P719, DOI 10.1109/34.297953; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; FAUGERAS OD, 1981, IEEE T PATTERN ANAL, V3, P633, DOI 10.1109/TPAMI.1981.4767164; Finch AM, 1998, PATTERN RECOGN, V31, P1777, DOI 10.1016/S0031-3203(98)00010-7; FINCH AM, 1995, P CAIP, P350; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; Kittler J, 1998, PATTERN RECOGN, V31, P1455, DOI 10.1016/S0031-3203(98)00142-3; Lee YL, 2002, PATTERN RECOGN, V35, P299, DOI 10.1016/S0031-3203(01)00022-X; LI SZ, 1992, PATTERN RECOGN, V25, P583, DOI 10.1016/0031-3203(92)90075-T; Messmer BT, 1998, IEEE T PATTERN ANAL, V20, P493, DOI 10.1109/34.682179; MJOLSNESS E, 1990, NEURAL NETWORKS, V3, P651, DOI 10.1016/0893-6080(90)90055-P; Mjolsness E, 1989, NEURAL COMPUT, V1, P218, DOI 10.1162/neco.1989.1.2.218; PELEG S, 1980, IEEE T PATTERN ANAL, V2, P362, DOI 10.1109/TPAMI.1980.4767035; Pelillo M, 1999, NEURAL COMPUT, V11, P1933, DOI 10.1162/089976699300016034; PENG MK, 1995, INT J ELEC ENG EDUC, V32, P31, DOI 10.1177/002072099503200104; PRICE KE, 1985, IEEE T PATTERN ANAL, V7, P617, DOI 10.1109/TPAMI.1985.4767709; Rangarajan A, 1999, NEURAL COMPUT, V11, P1455, DOI 10.1162/089976699300016313; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Simic PD, 1991, NEURAL COMPUT, V3, P268, DOI 10.1162/neco.1991.3.2.268; Stark H., 1998, WILEY S TEL; Suganthan PN, 1998, PATTERN RECOGN, V31, P623, DOI 10.1016/S0031-3203(97)00067-8; van Wyk BJ, 2003, PATTERN RECOGN, V36, P2019, DOI 10.1016/S0031-3203(03)00009-8; VANWYK BJ, 2002, P JOINT IAPR INT WOR, P263; VANWYK BJ, 2004, P 14 ANN S PATT REC, P125; VANWYK BJ, 2003, THESIS U WITWATERSRA; Williams ML, 1997, PATTERN RECOGN LETT, V18, P1275, DOI 10.1016/S0167-8655(97)00117-7; Wilson RC, 1996, PATTERN RECOGN LETT, V17, P263, DOI 10.1016/0167-8655(95)00115-8; YOULA DC, 1987, IMAGE RECOVERY THEOR, pCH2; YU SS, 1992, PATTERN RECOGN, V25, P197, DOI 10.1016/0031-3203(92)90101-N	30	40	40	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2004	26	11					1526	1530		10.1109/TPAMI.2004.95	http://dx.doi.org/10.1109/TPAMI.2004.95			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	852EC	15521499				2022-12-18	WOS:000223737000011
J	Tuytelaars, T; Turina, A; Van Gool, L				Tuytelaars, T; Turina, A; Van Gool, L			Noncombinatorial detection of regular repetitions under perspective skew	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						grouping; planar homologies; elations; Hough transform; symmetry detection; repetitions		We present a geometric framework for the efficient detection of regular repetitions of planar (but not necessarily coplanar) patterns. At the heart of our system, lie the fixed structures of the transformations that describe these regular configurations. The approach detects a number of symmetric configurations that have traditionally been dealt with separately, in that all configurations corresponding to planar homologies are detected. These include important cases such as periodicities, mirror symmetries, and reflections about a point. The approach can handle perspective distortions. It avoids to get trapped in combinatories through invariant-based hashing for pattern matching and through Hough transforms for the detection of fixed structures. Additional efficiency and robustness are obtained from the system's ability to "reason" about the consistency of multiple homologies. The performance of the system is demonstrated with several examples.	Katholieke Univ Leuven, ESAT PSI Vis, B-3001 Louvain, Belgium; Swiss Fed Inst Technol, Comp Vis Lab, CH-8092 Zurich, Switzerland	KU Leuven; Swiss Federal Institutes of Technology Domain; ETH Zurich	Tuytelaars, T (corresponding author), Katholieke Univ Leuven, ESAT PSI Vis, Kasteelpk Arenberg 10, B-3001 Louvain, Belgium.	Tinne.Tuytelaars@esat.kuleuven.ac.be; aturina@vision.ee.ethz.ch; vangool@esat.kuleuven.ac.be	Tuytelaars, Tinne/B-4319-2015	Tuytelaars, Tinne/0000-0003-3307-9723				[Anonymous], 1985, PERCEPTUAL ORG VISUA; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CHAM TJ, 1996, P 4 EUR C COMP VIS A, P385; DHOME M, 1993, COMPUTER VISION GRAP, V57, P219; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FRIEDBERG SA, 1986, COMPUT VISION GRAPH, V34, P138, DOI 10.1016/S0734-189X(86)80055-X; Gottschaldt K., 1950, SOURCEBOOK GESTALT P, P109122; GROSS A, 1991, IEEE C COMP VIS PATT, P744; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Leung T., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P546, DOI 10.1007/BFb0015565; LI M, 1993, P INT C COMP VIS; Liu Y., 2000, P IEEE CS C COMP VIS, V1, P537; LUTTON E, 1994, IEEE T PATTERN ANAL, V16, P430, DOI 10.1109/34.277598; Meserve B. E., 1953, FUNDAMENTAL CONCEPTS; Mindru F., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P368, DOI 10.1109/CVPR.1999.786965; MUKHERJEE DP, 1995, PHILOS T R SOC A, V351, P77, DOI 10.1098/rsta.1995.0026; PAUWELS F, 1999, COMPUTER VISION IMAG, V75; PONCE J, 1988, P IMAGE UNDERSTANDIN, V2, P1074; Schaffalitzky F, 2000, IMAGE VISION COMPUT, V18, P647, DOI 10.1016/S0262-8856(99)00069-4; Semple J., 1979, ALGEBRAIC PROJECTIVE; Shi JB, 1997, PROC CVPR IEEE, P731, DOI 10.1109/CVPR.1997.609407; SINGER W, 1995, ANNU REV NEUROSCI, V18, P555, DOI 10.1146/annurev.ne.18.030195.003011; Turina A, 2001, PROC CVPR IEEE, P247; Tuytelaars T., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P412; Tuytelaars T, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P67, DOI 10.1109/ICCV.1998.710702; TUYTELAARS T, 1999, P 3 INT C VIS INF SY, P493; Van Gool L, 1998, IMAGE VISION COMPUT, V16, P21, DOI 10.1016/S0262-8856(97)00046-2; VanGool L, 1996, PROC CVPR IEEE, P285, DOI 10.1109/CVPR.1996.517087; XU L, 1988, P INT C PATT REC, P610	29	40	41	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2003	25	4					418	432		10.1109/TPAMI.2003.1190569	http://dx.doi.org/10.1109/TPAMI.2003.1190569			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	659BV					2022-12-18	WOS:000181758100004
J	Stanford, DC; Raftery, AE				Stanford, DC; Raftery, AE			Approximate Bayes factors for image segmentation: The Pseudolikelihood Information Criterion (PLIC)	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						BIC; color image quantization; ICM algorithm; image segmentation; Markov random field; medical image; mixture model; posterior model probability; pseudolikelihood; satellite image	MODEL; PARAMETERS; FEATURES; TEXTURE; ORDER	We propose a method for choosing the number of colors or true gray levels in an image; this allows fully automatic segmentation of images. Our underlying probability model is a hidden Markov random field. Each number of colors considered is viewed as corresponding to a statistical model for the image, and the resulting models are compared via approximate Bayes factors. The Bayes factors are approximated using BIC (Bayesian Information Criterion), where the required maximized likelihood is approximated by the Qian-Titterington pseudolikelihood. We call the resulting criterion PLIC (Pseudolikelihood Information Criterion). We also discuss a simpler approximation, MIMIC (Marginal Mixture Information Criterion), which is based only on the marginal distribution of pixel values. This turns out to be useful for initialization and it also has moderately good performance by itself when the amount of spatial dependence in an image is low. We apply PLIC and MMIC to a medical image segmentation problem.	Insightful Corp, Seattle, WA 98109 USA; Univ Washington, Dept Stat, Seattle, WA 98195 USA	University of Washington; University of Washington Seattle	Stanford, DC (corresponding author), Insightful Corp, 1700 Westlake Ave N, Seattle, WA 98109 USA.							BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; BESAG J, 1991, ANN I STAT MATH, V43, P1, DOI 10.1007/BF00116466; BESAG J, 1986, J R STAT SOC B, V48, P259; Byng JW, 1997, RADIOLOGY, V203, P564, DOI 10.1148/radiology.203.2.9114122; Chib S, 1995, J AM STAT ASSOC, V90, P1313, DOI 10.2307/2291521; Cox D.R., 1978, PROBLEMS SOLUTIONS T; Dasgupta A, 1998, J AM STAT ASSOC, V93, P294, DOI 10.2307/2669625; DESCOMBES X, 1996, 3015 INRIA; DiCiccio TJ, 1997, J AM STAT ASSOC, V92, P903, DOI 10.2307/2965554; DIXIT S, 1991, COMPUT GRAPH, V15, P561, DOI 10.1016/0097-8493(91)90057-O; Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578; Hance GA, 1996, IEEE ENG MED BIOL, V15, P104, DOI 10.1109/51.482850; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; KASS RE, 1995, J AM STAT ASSOC, V90, P928, DOI 10.2307/2291327; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572; Keribin C, 1998, CR ACAD SCI I-MATH, V326, P243, DOI 10.1016/S0764-4442(97)89479-7; NEWTON MA, 1994, J R STAT SOC B, V56, P3; POSSE C, 2000, IN PRESS J COMPUTATI; QIAN W, 1991, PHILOS T ROY SOC A, V337, P407, DOI 10.1098/rsta.1991.0132; Qian W., 1992, J STATIST COMPUT SIM, V40, P55; Raftery Adrian E., 1995, PRACTICAL MARKOV CHA, P163; Raftery AE, 1995, SOCIOL METHODOL, V25, P111, DOI 10.2307/271063; Raftery AE, 1999, SOCIOL METHOD RES, V27, P411, DOI 10.1177/0049124199027003005; Roeder K, 1997, J AM STAT ASSOC, V92, P894, DOI 10.2307/2965553; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Serra J, 1982, IMAGE ANAL MATH MORP; STANFORD D, 1999, THESIS U WASHINGTON; Stanford DC, 2000, IEEE T PATTERN ANAL, V22, P601, DOI 10.1109/34.862198; Tjelmeland H, 1998, SCAND J STAT, V25, P415, DOI 10.1111/1467-9469.00113; UMBAUGH SE, 1993, IEEE ENG MED BIOL, V12, P75, DOI 10.1109/51.232346; Valckx FMJ, 1997, ULTRASOUND MED BIOL, V23, P559, DOI 10.1016/S0301-5629(97)00041-0	33	40	41	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2002	24	11					1517	1520		10.1109/TPAMI.2002.1046170	http://dx.doi.org/10.1109/TPAMI.2002.1046170			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	608KY		Green Submitted			2022-12-18	WOS:000178846400008
J	Sawhney, HS; Guo, YL; Kumar, R				Sawhney, HS; Guo, YL; Kumar, R			Independent motion detection in 3D scenes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion analysis; 3D scene analysis; moving object detection; dynamic 3D analysis	RECOVERY	This paper presents an algorithmic approach to the problem of detecting independently moving objects in 3D scenes that are viewed under camera motion. There are two fundamental constraints that can be exploited for the problem: 1) two/multiview camera motion constraint (for instance, the epipolar/trilinear constraint) and 2) shape constancy constraint. Previous approaches to the problem either use only partial constraints, or rely on dense correspondences or flow. We employ both the fundamental constraints in an algorithm that does not demand a priori availability of correspondences or flow. Our approach uses the plane-plus-parallax decomposition to enforce the two constraints. It is also demonstrated that for a class of scenes, called sparse 3D scenes in which genuine parallax and independent motions may be confounded, how the plane-plus-parallax decomposition allows progressive introduction, and verification of the fundamental constraints. Results of the algorithm on some difficult sparse 3D scenes are promising.	Sarnoff Corp, Princeton, NJ 08543 USA	Sarnoff Corporation	Sawhney, HS (corresponding author), Sarnoff Corp, CN5300, Princeton, NJ 08543 USA.	hsawhney@sarnoff.com; yguo@sarnoff.com; rkumar@sarnoff.com						ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; BERGEN JR, 1992, P EUR C COMP VIS, P237; Fejes S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P979, DOI 10.1109/ICCV.1998.710835; Hanna K. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P357, DOI 10.1109/ICCV.1993.378192; Hartley R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P549, DOI 10.1109/CVPR.1993.341076; Irani M, 1998, IEEE T PATTERN ANAL, V20, P577, DOI 10.1109/34.683770; KUMAR R, 1994, INT C PATT RECOG, P685, DOI 10.1109/ICPR.1994.576402; Lourakis MIA, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1012, DOI 10.1109/ICCV.1998.710840; Lucas Bruce D, 1981, P 7 INT JOINT C ART, DOI DOI 10.1042/CS0730285; SAWHNEY HS, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P929, DOI 10.1109/CVPR.1994.323927; SAWHNEY HS, 1995, P INT C COMP VIS; SHASHUA A, 1995, IEEE T PATTERN ANAL, V17, P779, DOI 10.1109/34.400567; SHASHUA A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P483, DOI 10.1109/CVPR.1994.323870; Stein GP, 1997, PROC CVPR IEEE, P400, DOI 10.1109/CVPR.1997.609356; Torr PHS, 1998, PHILOS T R SOC A, V356, P1321, DOI 10.1098/rsta.1998.0224; Torr PHS, 1998, COMPUT VIS IMAGE UND, V71, P312, DOI 10.1006/cviu.1997.0559; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4	17	40	41	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2000	22	10					1191	1199		10.1109/34.879803	http://dx.doi.org/10.1109/34.879803			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	369LQ					2022-12-18	WOS:000165067100013
J	Liu, CL; Nakagawa, M				Liu, CL; Nakagawa, M			Precise candidate selection for large character set recognition by confidence evaluation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						handwritten character recognition; large character set; candidate selection; confidence evaluation; Bayesian inference	REJECTION RULE	This paper proposes a precise candidate selection method for large character set recognition by confidence evaluation of distance-based classifiers. The proposed method is applicable to a wide variety of distance metrics and experiments on Euclidean distance and city block distance have achieved promising results. By confidence evaluation, the distribution of distances is analyzed to derive the probabilities of classes in two steps: output probability evaluation and input probability inference. Using the input probabilities as confidences, several selection rules have been tested and the rule that selects the classes with high confidence ratio to the first rank class produced best results. The experiments were implemented on the ETL9B database and the results show that the proposed method selects about one-fourth as many candidates with accuracy preserved compared to the conventional method that selects a fixed number of candidates.	Hitachi Ltd, Cent Res Lab, Multimedia Syst Res Dept, Kokubunji, Tokyo 1858601, Japan; Tokyo Univ Agr & Technol, Dept Comp Sci, Koganei, Tokyo 1848588, Japan	Hitachi Limited; Tokyo University of Agriculture & Technology	Liu, CL (corresponding author), Hitachi Ltd, Cent Res Lab, Multimedia Syst Res Dept, 1-280 Higashi Koigakubo, Kokubunji, Tokyo 1858601, Japan.		Nakagawa, Masaki/B-9966-2013	Nakagawa, Masaki/0000-0001-7872-156X				Bouchaffra D, 1999, IEEE T PATTERN ANAL, V21, P923, DOI 10.1109/34.790432; Duda R.O., 1973, J ROYAL STAT SOC SER; Ha TM, 1997, IEEE T PATTERN ANAL, V19, P608, DOI 10.1109/34.601248; Horiuchi T, 1998, PATTERN RECOGN, V31, P1579, DOI 10.1016/S0031-3203(97)00136-2; HU J, 1996, P INT C PATTERN REC, V3, P23; HUANG YS, 1995, IEEE T PATTERN ANAL, V17, P90, DOI 10.1109/34.368145; ISHIDERA E, 1998, PRMU98160 IEICE; KUMAMOTO T, 1991, PATTERN RECOGN, V24, P793, DOI 10.1016/0031-3203(91)90046-8; Lin XF, 1998, PATTERN RECOGN LETT, V19, P975, DOI 10.1016/S0167-8655(98)00072-5; Liu CL, 1997, PROC INT CONF DOC, P1033, DOI 10.1109/ICDAR.1997.620666; MORI S, 1984, IEEE T PATTERN ANAL, V6, P386, DOI 10.1109/TPAMI.1984.4767545; NAKAGAWA M, 1996, P 5 IWFHR, P417; SHURMANN J, 1996, PATTERN CLASSIFICATI; Sun F, 1996, IEICE T INF SYST, VE79D, P510; Tang YY, 1998, IEEE T PATTERN ANAL, V20, P556, DOI 10.1109/34.682186; Tseng YH, 1998, PATTERN RECOGN, V31, P1601, DOI 10.1016/S0031-3203(98)00043-0; TUNG CH, 1994, PATTERN RECOGN, V27, P1093, DOI 10.1016/0031-3203(94)90147-3; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; YAMADA H, 1990, PATTERN RECOGN, V23, P1023, DOI 10.1016/0031-3203(90)90110-7; YAMAMOTO K, 1984, P 7 ICPR MONTR, P385	20	40	48	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2000	22	6					636	642		10.1109/34.862202	http://dx.doi.org/10.1109/34.862202			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	342WE					2022-12-18	WOS:000088667700009
J	Yuille, AL; Coughlan, JM				Yuille, AL; Coughlan, JM			Fundamental limits of Bayesian inference: Order parameters and phase transitions for road tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian inference; phase transitions; curve tracking		There is a growing interest in formulating vision problems in terms of Bayesian inference and, in particular, the maximimum a posteriori (MAP) estimator. This approach involves putting prior probability distributions, P(X), on the variables X to be inferred and a conditional distribution P(Y\X) for the measurements Y. For example, X could denote the position and configuration of a road in an aerial image and Y can be the aerial image itself (or a filtered version). We observe that these distributions define a probability distribution P(X, Y) on the ensemble of problem instances. In this paper, we consider the special case of detecting roads from aerial images [9] and demonstrate that analysis of this ensemble enables us to determine fundamental bounds on the performance of the MAP estimate (independent of the inference algorithm employed). We demonstrate that performance measures-such as the accuracy of the estimate and whether the road can be detected at all-depend on the probabilities P(Y\X), P(X) only by an order parameter K. Intuitively, K summarizes the strength of local cues (as provided by local edge filters) together with prior information (i.e., the probable shapes of roads). We demonstrate that there is a phase transition at a critical value of the order parameter K-below this phase transition, it is impossible to detect the road by any algorithm. In related work [25], [5], we derive closely related order parameters which determine the time and memory complexity of search and the accuracy of the solution using the A* search strategy. Our approach can be applied to other vision problems and we briefly summarize results when the model uses the "wrong prior" [26]. We comment on how our work relates to studies of the complexity of visual search [21] and to critical behaviour(i.e., phase transitions) in the computational cost of solving NP-complete problems [19].	Smith Kettlewell Eye Res Inst, San Francisco, CA 94115 USA	The Smith-Kettlewell Eye Research Institute	Yuille, AL (corresponding author), Smith Kettlewell Eye Res Inst, 2318 Fillmore St, San Francisco, CA 94115 USA.	yuille@attila.ski.org; coughlan@ski.org		Yuille, Alan L./0000-0001-5207-9249				Amit DJ, 1989, MODELING BRAIN FUNCT, DOI 10.1017/CBO9780511623257; BALBOA R, 1997, THESIS U ALICANTE SP; Cheeseman PC., 1991, IJCAI, V91, P331; COUGHLAN JM, 1998, P COMP VIS PATT REC; COUGHLAN JM, 1999, P EMMCVPR 99 YORK EN; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; Garey M.R., 1979, COMPUTERS INTRACTABI; GEIGER D, 1997, P INT WORKSH EN MIN; Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006; ISARD M, 1996, P EUR C COMP VIS, P343; Jacobs DW, 1996, IEEE T PATTERN ANAL, V18, P23, DOI 10.1109/34.476008; Kass M., 1987, International Journal of Computer Vision, V1, P321, DOI 10.1007/BF00133570; Knill DC, 1996, PERCEPTION BAYESIAN; KONISHI SM, 1999, P COMP VIS PATT REC; Lewis J. T., 1995, MARKOV PROCESS RELAT, V1, P319; Parodi P, 1998, ARTIF INTELL, V105, P47, DOI 10.1016/S0004-3702(98)00077-0; Pearl Judea, 1984, HEURISTICS; Ripley B.D., 1995, PATTERN RECOGNITION; Russell S., 2021, ARTIF INTELL, V19, P23; Selman B, 1996, ARTIF INTELL, V81, P273, DOI 10.1016/0004-3702(95)00056-9; TSOTSOS JK, 1990, BEHAV BRAIN SCI, V13; TSOTSOS JK, 1992, INT J COMPUTER VISIO, V7; WU YN, 1999, P INT C COMP VIS COR; YUILLE AL, 1997, P INT WORKSH EN MIN; YUILLE AL, 1998, P NIPS 98; YUILLE AL, 1999, P COMP VIS PATT REC; ZHU S, 1997, NEURAL COMPUTATION, V9; Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420; Zhu SC, 1997, IEEE T PATTERN ANAL, V19, P1236, DOI 10.1109/34.632983; ZHU SC, UNPUB IEEE CS WORKSH	30	40	41	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2000	22	2					160	173		10.1109/34.825754	http://dx.doi.org/10.1109/34.825754			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	292JU					2022-12-18	WOS:000085791400003
J	Shinagawa, Y; Kunii, TL				Shinagawa, Y; Kunii, TL			Unconstrained automatic image matching using multiresolutional critical-point filters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image matching; multiresolution; nonlinear filters; critical-point filters; singularity; homotopy; image interpolation; morphing; volume rendering	OPTICAL-FLOW; STEREO; SURFACES; COMPUTATION; MODEL	This paper proposes a novel method for matching images. The results can be used for a variety of applications: fully automatic morphing, object recognition, stereo photogrammetry, and volume rendering. Optimal mappings between the given images are computed automatically using multiresolutional nonlinear filters that extract the critical points of the images of each resolution. Parameters are set completely automatically by dynamical computation analogous to human visual systems. No prior knowledge about the objects is necessary. The matching results can be used to generate intermediate views when given two different views of objects. When used for morphing, our method automatically transforms the given images. There is no need for manually specifying the correspondence between the two images. When used for volume rendering, our method reconstructs the intermediate images between cross-sections accurately, even when the distance between them is long and the cross-sections vary widely in shape; A large number of experiments has been carried out to show the usefulness and capability of our method.	Univ Tokyo, Dept Informat Sci, Bunkyo Ku, Tokyo 113, Japan; Hosei Univ, Computat Sci Res Ctr, Tokyo, Japan	University of Tokyo; Hosei University	Shinagawa, Y (corresponding author), Univ Tokyo, Dept Informat Sci, Bunkyo Ku, 7-3-1 Hongo, Tokyo 113, Japan.							BAJCSY R, 1989, COMPUT VISION GRAPH, V46, P1, DOI 10.1016/S0734-189X(89)80014-3; Bangham JA, 1996, IEEE T PATTERN ANAL, V18, P520, DOI 10.1109/34.494641; Barequet G, 1997, IEEE T PATTERN ANAL, V19, P929, DOI 10.1109/34.615444; BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; BROOKSHIRE G, 1990, COMPUT VISION GRAPH, V52, P276, DOI 10.1016/0734-189X(90)90059-5; BURR DJ, 1981, COMPUT VISION GRAPH, V15, P102, DOI 10.1016/0146-664X(81)90072-1; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; Chui C.K., 1992, INTRO WAVELETS; Daubechies I., 1992, 10 LECT WAVELETS, DOI [10.1137/1.9781611970104.ch1, DOI 10.1137/1.9781611970104.CH1]; Faugeras O, 1996, INT J COMPUT VISION, V18, P5, DOI 10.1007/BF00126137; GEIGER D, 1995, INT J COMPUT VISION, V14, P211, DOI 10.1007/BF01679683; GRIMSON WEL, 1983, COMPUT VISION GRAPH, V22, P39, DOI 10.1016/0734-189X(83)90095-6; GUPTA NC, 1995, ARTIF INTELL, V78, P45, DOI 10.1016/0004-3702(95)00031-3; HERMAN M, 1984, IEEE T PATTERN ANAL, V6, P331, DOI 10.1109/TPAMI.1984.4767526; HERMAN M, 1986, ARTIF INTELL, V30, P289, DOI 10.1016/0004-3702(86)90002-0; HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709; Horn B., 1986, ROBOT VISION, P1; LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Meyer Y, 1993, WAVELETS ALGORITHMS; NISHITA T, 1993, MULTIMEDIA MODELING, P162; OTTE M, 1995, ARTIF INTELL, V78, P5, DOI 10.1016/0004-3702(95)00033-X; SEITZ SM, 1996, P SIGGRAPH 96, P21; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; VENKATESWAR V, 1995, INT J COMPUT VISION, V15, P245, DOI 10.1007/BF01451743; WEBER J, 1995, INT J COMPUT VISION, V14, P67, DOI 10.1007/BF01421489; Wolberg G, 1990, DIGITAL IMAGE WARPIN; YANG YB, 1995, ARTIF INTELL, V78, P121, DOI 10.1016/0004-3702(95)00028-3; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4	32	40	45	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1998	20	9					994	1010		10.1109/34.713364	http://dx.doi.org/10.1109/34.713364			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	117AX					2022-12-18	WOS:000075758500007
J	Rajagopalan, AN; Chaudhuri, S				Rajagopalan, AN; Chaudhuri, S			A variational approach to recovering depth from defocused images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						depth from defocus; space-variant blur; complex spectrogram; Wigner distribution; space-variant filtering; regularization; Euler equation	WIGNER DISTRIBUTION; SIGNALS; FOCUS	In this paper, we propose a regularized solution to the depth from defocus (DFD) problem using the space-frequency representation (SFR) framework. A smoothness constraint is imposed on the estimates of the blur parameter, and a variational approach to the DFD problem is developed. Among the numerous SFRs, we study the applicability of the complex spectrogram and the Wigner distribution, in particular, for depth recovery. The performance of the proposed variational method is tested on both synthetic and real images. The method yields good results, and the quality of the estimates is significantly better than that obtained without the smoothness constraint on the blur parameter.			Rajagopalan, AN (corresponding author), INDIAN INST TECHNOL, DEPT ELECT ENGN, BOMBAY 400076, MAHARASHTRA, INDIA.			Ambasamudram, Rajagopalan/0000-0002-0006-6961				BOVE VM, 1993, J OPT SOC AM A, V10, P561, DOI 10.1364/JOSAA.10.000561; CLAASEN TACM, 1980, PHILIPS J RES, V35, P276; COURANT R, 1962, METHODS MATH PHYSICS, V1; CRISTOBAL G, 1991, ADV ELECTRON EL PHYS, V80, P309; ENS J, 1993, IEEE T PATTERN ANAL, V15, P97, DOI 10.1109/34.192482; GOKSTORP M, 1994, INT C PATT RECOG, P153; Hlawatsch F, 1992, IEEE SIGNAL PROC MAG, V9, P21, DOI 10.1109/79.127284; Hwang T.-l., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P476, DOI 10.1109/CVPR.1989.37890; Nayar SK, 1996, IEEE T PATTERN ANAL, V18, P1186, DOI 10.1109/34.546256; PENTLAND A, 1994, J OPT SOC AM A, V11, P2925, DOI 10.1364/JOSAA.11.002925; PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940; Rajagopalan A. N., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P636, DOI 10.1109/ICIP.1995.537715; RAJAGOPALAN AN, 1995, P IND C PATT REC IM, P95; RAJAGOPALAN AN, 1995, P INT C INT ROB SYST, P45; SALEH BEA, 1985, IEEE T ACOUST SPEECH, V33, P1479, DOI 10.1109/TASSP.1985.1164753; SCHREIBER WF, 1986, FUNDAMENTALS ELECT I; Subbarao M., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P149, DOI 10.1109/CCV.1988.589986; Watanabe M, 1996, PROC CVPR IEEE, P431, DOI 10.1109/CVPR.1996.517108; Xiong Y., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P68, DOI 10.1109/CVPR.1993.340977; XIONG Y, 1994, P IEEE C COMP VIS PA, P668	20	40	47	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1997	19	10					1158	1164		10.1109/34.625126	http://dx.doi.org/10.1109/34.625126			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YB678					2022-12-18	WOS:A1997YB67800012
J	Yu, YH; Samal, A; Seth, SC				Yu, YH; Samal, A; Seth, SC			A system for recognizing a large class of engineering drawings	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						symbolic drawings; flow diagrams; segmentation and labeling; domain independence; automatic and interactive error correction		We present a system for recognizing a large class of engineering drawings characterized by alternating instances of symbols and connection lines. The class includes domains such as flowcharts, logic and electrical circuits, and chemical plant diagrams. The output of the system, a netlist identifying the symbol types and interconnections, may be used for design simulation or as a compact portable representation of the drawing. The automatic recognition task is divided into two stages: 1) Domain-independent rules are used to segment symbols from connection lines in the drawing image that has been thinned, vectorized, and preprocessed in routine ways. 2) A drawing understanding subsystem works in concert with a set of domain-specific matchers to classify symbols and correct errors automatically. A graphical user interface is provided to correct residual errors interactively and to log data for reporting errors objectively. The system has been tested on a database of 64 printed images drawn from text books and handbooks in different domains and scanned at 150 and 300 dpi resolution.	UNIV NEBRASKA,DEPT COMP ENGN & SCI,LINCOLN,NE 68588	University of Nebraska System; University of Nebraska Lincoln	Yu, YH (corresponding author), LUCENT TECHNOL INC,2000 NAPERVILLE RD,NAPERVILLE,IL 60540, USA.		SETH, SHARAD/F-9880-2010					[Anonymous], 1992, STRUCTURED DOCUMENT, DOI DOI 10.1007/978-3-642-77281-8_16; BENJAMIN D, 1988, P 9 IEEE ICPR, P119; Casey R., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P627, DOI 10.1109/ICDAR.1993.395658; DORI D, 1995, J LOGIC COMPUT, P1; FAHN CS, 1988, COMPUT VISION GRAPH, V44, P119, DOI 10.1016/S0734-189X(88)80001-X; GROEN FCA, 1985, PATTERN RECOGN LETT, V3, P343, DOI 10.1016/0167-8655(85)90066-2; HADDAD RW, 1995, 951 W RES LAB; Hamada A. H., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P369, DOI 10.1109/ICDAR.1993.395713; KASTURI R, 1990, IEEE T PATTERN ANAL, V12, P978, DOI 10.1109/34.58870; Kim S. H., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P349, DOI 10.1109/ICDAR.1993.395717; KOJIMA H, 1988, P 9 INT C PATT REC N, P1138; LIN XG, 1985, COMPUT VISION GRAPH, V30, P84, DOI 10.1016/0734-189X(85)90020-9; *MICR INC, 1994, TNTMIPS V4 40 MAP IM; MULDER JA, 1988, IEEE T PATTERN ANAL, V10, P866, DOI 10.1109/34.9108; Nardelli E., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P951, DOI 10.1109/ICDAR.1993.395579; OKAZAKI A, 1988, IEEE T PATTERN ANAL, V10, P331, DOI 10.1109/34.3898; OKAZAKI S, 1988, P PATT REC 4 INT C M, P627; Pasternak B., 1994, P IAPR WORKSH DOC AN, P349; Shimotsuji S., 1994, P IAPR WORKSH DOC AN, P337; TURVE S, 1994, P IAPR WORKSH DOC AN, P313; VACIVIERE P, 1994, P IAPR WORKSH DOC AN, P313; YU Y, 1994, THESIS U NEBRASKA LI; YU YH, 1994, PATTERN RECOGN, V27, P391, DOI 10.1016/0031-3203(94)90116-3	23	40	57	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1997	19	8					868	890						23	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XT987		Green Submitted, Green Published			2022-12-18	WOS:A1997XT98700006
J	FUNT, BV; DREW, MS				FUNT, BV; DREW, MS			COLOR SPACE ANALYSIS OF MUTUAL ILLUMINATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						MUTUAL ILLUMINATION; INTERREFLECTION; COLOR VISION; COLOR HISTOGRAM; COMPUTER VISION; SHAPE FROM SHADING	REFLECTANCE; CONSTANCY; COMPONENTS; HIGHLIGHTS; IMAGES	Mutual illumination occurs when light reflected from one surface impinges on a second one. The resulting additional illumination incident on the second surface affects both the color and intensity of the light reflected from it. As a consequence, the image of a surface in the presence of mutual illumination differs from what it otherwise would have been in the absence of mutual illumination. Unaccounted for mutual illumination can easily confuse methods that rely on intensity or color such as shape-from-shading or color-based object recognition. In this correspondence, we introduce an algorithm that removes mutual illumination effects from images. The domain is that of previously-segmented images of convex surfaces of uniform color and diffuse reflectance where for each surface the interreflection occurs mainly from one other surface and can be accurately accounted for within a one-bounce model. The algorithm is based on a singular value decomposition of the colors coming from each surface. Geometrical information about where on the surface the colors emanate from is not required. The RGB triples from a single convex surface experiencing interreflection fall in a plane; intersecting the planes generated from two interreflecting surfaces results in a unique interreflection color. Each pixel can then be factored into its interreflection and no-interreflection components so that a complete no-interreflection image is produced.			FUNT, BV (corresponding author), SIMON FRASER UNIV,SCH COMP SCI,BURNABY V5A 1S6,BC,CANADA.							BAJCSY R, 1990, IEEE INT C PATT REC, V1, P785; BRILL MH, 1990, J OPT SOC AM A, V7, P2041, DOI 10.1364/JOSAA.7.002041; DREW MS, 1992, J OPT SOC AM A, V32, P1255; DREW MS, 1990, DEC P IEEE INT C COM, P393; Forsyth D., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P466, DOI 10.1109/CVPR.1989.37889; FORSYTH D, 1990, IMAGE VISION COMPUT, V8, P42, DOI 10.1016/0262-8856(90)90055-A; FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770; FUNT BV, 1991, INT J COMPUT VISION, V6, P5, DOI 10.1007/BF00127123; FUNT BV, 1991, CSSLCCRTR9103 S FRAS; Golub G.H., 2013, MATRIX COMPUTATIONS, P357; Goral C. M., 1984, Computers & Graphics, V18, P213; HO JA, 1990, IEEE T PATTERN ANAL, V12, P966, DOI 10.1109/34.58869; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; Kaufman J. E., 1966, IES LIGHTING HDB; KAWATA S, 1987, J OPT SOC AM A, V4, P2101, DOI 10.1364/JOSAA.4.002101; KLINKER GJ, 1988, INT J COMPUT VISION, V2, P7, DOI 10.1007/BF00836279; LAWTON WH, 1971, TECHNOMETRICS, V13, P617, DOI 10.2307/1267173; LEE HC, 1986, J OPT SOC AM A, V3, P1694, DOI 10.1364/JOSAA.3.001694; NAYAR SK, 1992, IMAGE UNDERSTANDING; NAYAR SK, 1990, DEC P IEEE INT C COM, P2; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; SHAFER SA, 1990, P SOC PHOTO-OPT INS, V1250, P222, DOI 10.1117/12.19714; Siegel R., 1981, THERMAL RAD HEAT TRA; TOMINAGA S, 1989, J OPT SOC AM A, V6, P576, DOI 10.1364/JOSAA.6.000576; TOMINAGA S, 1990, J OPT SOC AM A, V7, P312, DOI 10.1364/JOSAA.7.000312; TONG F, 1989, COMPUTER VISION SHAP; TONG F, 1988, 1988 P VIS INT EDM, P98; Wyszecki Gunter, 1982, COLOR SCI, V8	28	40	41	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1993	15	12					1319	1326		10.1109/34.250838	http://dx.doi.org/10.1109/34.250838			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MP176		Green Submitted			2022-12-18	WOS:A1993MP17600009
J	SAINTMARC, P; ROM, H; MEDIONI, G				SAINTMARC, P; ROM, H; MEDIONI, G			B-SPLINE CONTOUR REPRESENTATION AND SYMMETRY DETECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						B-SPLINES; CONTOUR REPRESENTATION; SHAPE REPRESENTATION; SPLINE APPROXIMATION; SYMMETRY; SYMMETRY DETECTION	SHAPE; OBJECTS; MODELS; CURVES; VISION	The detection of edges is only one of many steps in the understanding of images. Further processing necessarily involves grouping operations between contours. We present a representation of edge contours by approximating B-splines and show that such a representation facilitates the extraction of symmetries between contours. Our representation is rich, compact, stable, and does not critically depend on feature extraction. We turn our attention to the detection of three types of symmetries: skew symmetries and parallel symmetries, which have proven to be of great importance in inferring shape from contour, and smooth local symmetries, which have been used for planar shape description. We show that our representation facilitates the computation of these symmetries.	UNIV SO CALIF,INST ROBOT & INTELLIGENT SYST,LOS ANGELES,CA 90089	University of Southern California	SAINTMARC, P (corresponding author), MATRA MS2I,SIGNAL & IMAGE PROC LAB,ST QUENTIN EN YVELYNES,FRANCE.							ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; Ballard D.H., 1982, COMPUTER VISION; Bartels RH, 1987, INTRO SPLINES USE CO; Blum H., 1967, S MODELS PERCEPTION; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V11, P123, DOI 10.1016/0146-664X(79)90062-5; BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302; Brent R.P., 1973, ALGORITHMS MINIMIZAT; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CONNELL JH, 1987, ARTIF INTELL, V31, P159, DOI 10.1016/0004-3702(87)90018-X; Farin G., 1988, CURVES SURFACES COMP; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; FRIEDBERG SA, 1986, COMPUT VISION GRAPH, V34, P138, DOI 10.1016/S0734-189X(86)80055-X; GIBLIN PJ, 1985, AM MATH MON, V92, P689, DOI 10.2307/2323220; Gross A. D., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P744, DOI 10.1109/CVPR.1991.139810; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; KRIEGMAN DJ, 1990, CURVES SURFACES, P1; LEYTON M, 1988, ARTIF INTELL, V34, P213, DOI 10.1016/0004-3702(88)90039-2; MARIMONT DH, 1984, 4TH P NAT C ART INT, P237; MEDIONI G, 1987, COMPUT VISION GRAPH, V39, P267, DOI 10.1016/S0734-189X(87)80181-0; MOHAN R, 1989, THESIS U SO CALIFORN; NALWA VS, 1987, COMPUT VISION GRAPH, V40, P79, DOI 10.1016/0734-189X(87)90057-0; NALWA VS, 1989, IEEE T PATTERN ANAL, V11, P1117, DOI 10.1109/34.42842; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; Plass M., 1983, Computer Graphics, V17, P229, DOI 10.1145/964967.801153; PONCE J, 1989, IEEE T PATTERN ANAL, V11, P951, DOI 10.1109/34.35498; PONCE J, 1990, COMPUT VISION GRAPH, V52, P328, DOI 10.1016/0734-189X(90)90079-B; RAO K, 1987, OCT WORKSH SPAT REAS, P168; RICHARDS W, 1985, COMPUT VISION GRAPH, V31, P265, DOI 10.1016/0734-189X(85)90031-3; ROM H, 1992, JUN P IEEE C COMP VI, P49; ROM H, 1992, RECH REP; ROM H, 1992, JAN P DARPA IM UND W, P607; ROM H, 1993, IEEE T PATTERN ANAL, V15, P972; ROSENFELD A, 1986, COMPUT VISION GRAPH, V33, P156, DOI 10.1016/0734-189X(86)90113-1; ROSSIGNAC JR, 1987, IBM J RES DEV, V31, P296, DOI 10.1147/rd.313.0296; SAINTMARC P, 1991, IEEE T PATTERN ANAL, V13, P514, DOI 10.1109/34.87339; SAINTMARC P, 1990, P EURO C COMPUT VISI, P604; Ulupinar F., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P147, DOI 10.1109/ICPR.1990.118080; Ulupinar F., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P674, DOI 10.1109/CVPR.1991.139777; Ulupinar F., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P582, DOI 10.1109/ICCV.1990.139600; Van Gool L., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P454, DOI 10.1109/CVPR.1991.139735; YUEN SYK, 1989, 141 U SUSS SCH COGN	44	40	40	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1993	15	11					1191	1197		10.1109/34.244680	http://dx.doi.org/10.1109/34.244680			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MH083					2022-12-18	WOS:A1993MH08300008
J	LINDEBERG, T				LINDEBERG, T			EFFECTIVE SCALE - A NATURAL UNIT FOR MEASURING SCALE-SPACE LIFETIME	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						COMPUTER VISION; DENSITY OF LOCAL EXTREMA; DIGITAL SIGNAL PROCESSING; DISCRETE SMOOTHING TRANSFORMATIONS; EFFECTIVE SCALE; MULTISCALE REPRESENTATION; SCALE SPACE; SCALE-SPACE LIFETIME	IMAGES	The article develops a manner in which a notion of effective scale can be introduced in a formal way. For continuous signals, a scaling argument directly gives that a natural unit for measuring scale-space lifetime is in terms of the logarithm of the ordinary scale parameter. That approach is, however, not appropriate for discrete signals since then, an infinite lifetime would be assigned to structures existing in the original signal. Here, it is shown how such an effective scale parameter can be defined to give consistent results for both discrete and continuous signals. The treatment is based on the assumption that the probability that a local extremum disappears during a short-scale interval should not vary with scale. As a tool for the analysis, estimates are given of how the density of local extrema can be expected to vary with scale in the scale-space representation of different random noise signals both in the continuous and discrete cases.			LINDEBERG, T (corresponding author), ROYAL INST TECHNOL, DEPT NUMER ANAL & COMP SCI, COMPUTAT VIS & ACT PERCEPT LAB, S-10044 STOCKHOLM 70, SWEDEN.		Lindeberg, Tony/G-3580-2011	Lindeberg, Tony/0000-0002-9081-2170				Abramowitz M., 1964, HDB MATH FUNCTIONS, V55; BARNSLEY MF, 1988, SCI FRACTALS; Cramer H., 2004, STATIONARY RELATED S; CROWLEY JL, 1984, IEEE T PATTERN ANAL, V6, P212, DOI 10.1109/TPAMI.1984.4767504; FLORACK LMJ, 1992, IMAGE VISION COMPUT, V10, P376, DOI 10.1016/0262-8856(92)90024-W; LINDEBERG T, 1993, INT J COMPUT VISION, V11, P283, DOI 10.1007/BF01469346; LINDEBERG T, 1990, IEEE T PATTERN ANAL, V12, P234, DOI 10.1109/34.49051; Lindeberg T., 1991, Journal of Visual Communication and Image Representation, V2, P55, DOI 10.1016/1047-3203(91)90035-E; Lindeberg T., 1992, Journal of Mathematical Imaging and Vision, V1, P65, DOI 10.1007/BF00135225; LINDEBERG T, 1992, IMAGE VISION COMPUT, V10, P3, DOI 10.1016/0262-8856(92)90079-I; Lindeberg T, 1991, THESIS ROYAL I TECHN; MUSSIGMANN U, 1989, 6TH P SCAND C IM AN, P987; PAPOULIS A, 1972, PROBABILITY RANDOM V; RICE SO, 1945, AT&T TECH J, V24, P46, DOI 10.1002/j.1538-7305.1945.tb00453.x; Spiegel MR., 1968, MATH HDB FORMULAS TA; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]	19	40	41	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1993	15	10					1068	1074		10.1109/34.254063	http://dx.doi.org/10.1109/34.254063			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MD775		Green Submitted			2022-12-18	WOS:A1993MD77500008
J	KAKARALA, R; HERO, AO				KAKARALA, R; HERO, AO			ON ACHIEVABLE ACCURACY IN EDGE LOCALIZATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						CRAMER-RAO LOWER BOUND; EDGE DETECTION; EDGE LOCALIZATION; MAXIMUM-LIKELIHOOD ESTIMATOR; MEAN SQUARED ERROR	LOWER BOUNDS; PERFORMANCE	Edge localization occurs when an edge detector determines the location of an edge in an image. In this note, we use statistical parameter estimation techniques to derive bounds on achievable accuracy in edge localization. These bounds, known as the Cramer-Rao bounds, reveal the effect on localization of factors such as signal-to-noise ratio (SNR), extent of edge observed, scale of smoothing filter, and a priori uncertainty about edge intensity. By using continuous values for both image coordinates and intensity, we focus on the effect of these factors prior to sampling and quantization. We analyze the Canny algorithm and show that for high SNR, its mean squared error is only a factor of two higher than the lower limit established by the Cramer-Rao bound. Although this is very good, we show that for high SNR, the maximum-likelihood estimator, which is also derived here, virtually achieves the lower bound.	UNIV MICHIGAN,DEPT ELECT ENGN & COMP SCI,ANN ARBOR,MI 48019	University of Michigan System; University of Michigan	KAKARALA, R (corresponding author), UNIV CALIF IRVINE,DEPT MATH,IRVINE,CA 92717, USA.		Kakarala, .Ramakrishna/A-3677-2011	Hero, Alfred/0000-0002-2531-9670				BERZINS V, 1984, COMPUT VISION GRAPH, V27, P195, DOI 10.1016/S0734-189X(84)80043-2; BULRNETT JW, 1978, J OPT SOC AM, V68; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; GONSLAVES RA, 1976, APPLIED OPT, V15; GRIMSON WEL, 1981, IMAGES SURFACES; HAVELOCK DI, 1989, IEEE T PATTERN ANAL, V11, P1065, DOI 10.1109/34.42837; HERO AO, 1989, IEEE T INFORM THEORY, V35, P843, DOI 10.1109/18.32161; HUERTAS A, 1986, IEEE T PATTERN ANAL, V8, P651, DOI 10.1109/TPAMI.1986.4767838; HYDE PD, 1983, PATTERN RECOGN, V16, P413, DOI 10.1016/0031-3203(83)90063-8; KAKARALA R, 1990, ACHIEVABLE ACCURACY; Kay S.M, 1988, MODERN SPECTRAL ESTI; LYVERS EP, 1989, IEEE T PATTERN ANAL, V11, P1293, DOI 10.1109/34.41367; MARR DC, 1983, P ROY SOC LOND B BIO, V207, P187; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; SHAH M, 1986, COMPUT VISION GRAPH, V34, P321, DOI 10.1016/S0734-189X(86)80046-9; TABATABAI AJ, 1984, IEEE T PATTERN ANAL, V6, P188, DOI 10.1109/TPAMI.1984.4767502; VanTrees H., 1968, DETECTION ESTIMATION, V1; WINICK KA, 1986, J OPT SOC AM A, V3, P1809, DOI 10.1364/JOSAA.3.001809; ZIV J, 1969, IEEE T INFORM THEORY, V15, P386, DOI 10.1109/TIT.1969.1054301	19	40	42	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1992	14	7					777	785		10.1109/34.142913	http://dx.doi.org/10.1109/34.142913			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JB675					2022-12-18	WOS:A1992JB67500006
J	KOPLOWITZ, J; BRUCKSTEIN, AM				KOPLOWITZ, J; BRUCKSTEIN, AM			DESIGN OF PERIMETER ESTIMATORS FOR DIGITIZED PLANAR SHAPES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									TECHNION ISRAEL INST TECHNOL,DEPT ELECT ENGN,IL-32000 HAIFA,ISRAEL	Technion Israel Institute of Technology	KOPLOWITZ, J (corresponding author), CLARKSON UNIV,DEPT ELECT & COMP ENGN,POTSDAM,NY 13676, USA.							Billingsley Patrick, 1965, ERGODIC THEORY INFOR; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; GRANT G, 1980, MIKROSKOPIE, V37, P455; HO CS, 1983, IEEE T PATTERN ANAL, V5, P593, DOI 10.1109/TPAMI.1983.4767448; KOPLOWITZ J, 1981, IEEE T PATTERN ANAL, V3, P180, DOI 10.1109/TPAMI.1981.4767075; KOPLOWITZ J, 1976, OCT P CAN C COMM POW; KULPA Z, 1983, COMPUT VISION GRAPH, V22, P268, DOI 10.1016/0734-189X(83)90069-5; Kulpa Z., 1977, COMPUTER GRAPHICS IM, V6, P434, DOI [10.1016/S0146-664X(77)80021-X, DOI 10.1016/S0146-664X(77)80021-X]; Lipkin BS, 1970, PICTURE PROCESSING P, P241; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; MONTNARI U, 1970, COMMUN ACM, V13, P41, DOI 10.1145/361953.361967; PROFFITT D, 1979, COMPUT VISION GRAPH, V10, P318, DOI 10.1016/S0146-664X(79)80041-6; RINK M, 1976, J MICROSC-OXFORD, V107, P267, DOI 10.1111/j.1365-2818.1976.tb02448.x; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; VOSSEPOEL AM, 1982, COMPUT VISION GRAPH, V20, P347, DOI 10.1016/0146-664X(82)90057-0; WECHSLER H, 1981, COMPUT VISION GRAPH, V17, P375, DOI 10.1016/0146-664X(81)90015-0	16	40	40	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1989	11	6					611	622		10.1109/34.24795	http://dx.doi.org/10.1109/34.24795			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	U6749					2022-12-18	WOS:A1989U674900006
J	OKAZAKI, A; KONDO, T; MORI, K; TSUNEKAWA, S; KAWAMOTO, E				OKAZAKI, A; KONDO, T; MORI, K; TSUNEKAWA, S; KAWAMOTO, E			AN AUTOMATIC CIRCUIT DIAGRAM READER WITH LOOP-STRUCTURE-BASED SYMBOL RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									TOSHIBA SEMICOND INC,DEPT CAD & CAT ENGN,DIV INTEGRATED CIRCUITS,SUNNYVALE,CA 94086; TOSHIBA CORP,TOSHIBA RES & DEV CTR,INFORMAT & COMMUN SYST LAB,DEPT MAN MACHINE INTERFACE,KAWASAKI 210,JAPAN	Toshiba Corporation; Toshiba Corporation	OKAZAKI, A (corresponding author), TOSHIBA CORP,TOSHIBA RES & DEV CTR,INFORMAT SYST LAB,1 KOMUKAI TOSHIBA CHO,SAIWAI KU,KAWASAKI 210,JAPAN.							AGIN GJ, 1980, COMPUTER, V13, P11, DOI 10.1109/MC.1980.1653613; BLEY H, 1984, COMPUT VISION GRAPH, V28, P271, DOI 10.1016/S0734-189X(84)80008-0; DATTATREYA GR, 1981, IEEE T PATTERN ANAL, V3, P293, DOI 10.1109/TPAMI.1981.4767102; Groen F. C. A., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P1310; Haralick R. M., 1981, Real-Time/Parallel Computing. Image Analysis. Proceedings of Part of the Japan-United States Seminar on Research Towards Real-Time Parallel Image Analysis and Recognition, P11; Kakumoto S., 1978, Artificial Intelligence and Pattern Recognition in Computer Aided Design, P457; KAWAMOTO E, 1984, P IEEE ICCAD 84, P87; Kidode M., 1981, Real-Time/Parallel Computing. Image Analysis. Proceedings of Part of the Japan-United States Seminar on Research Towards Real-Time Parallel Image Analysis and Recognition, P279; Kurosawa Y., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P1063; OKAZAKI A, 1985, P IEEE WORKSHOP CAPA, P524; Pavlidis T., 1977, STRUCTURAL PATTERN R; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SIMIZU S, 1982, 6TH P INT C PATT REC, P717; Suzuki R., 1980, Real-Time Medical Image Processing. Proceedings of the Japan-United States Seminar on Research Towards Real-Time Parallel Image Analysis and Recognition, P207; Takebayashi Y., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P1232; Watanabe S., 1980, Real-Time Medical Image Processing. Proceedings of the Japan-United States Seminar on Research Towards Real-Time Parallel Image Analysis and Recognition, P221; Yoshino Y., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P510; [No title captured]	18	40	45	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1988	10	3					331	341		10.1109/34.3898	http://dx.doi.org/10.1109/34.3898			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	N5337					2022-12-18	WOS:A1988N533700005
J	WANG, YF; MITICHE, A; AGGARWAL, JK				WANG, YF; MITICHE, A; AGGARWAL, JK			COMPUTATION OF SURFACE ORIENTATION AND STRUCTURE OF OBJECTS USING GRID CODING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											WANG, YF (corresponding author), UNIV TEXAS,IMAGE & SIGNAL ANAL LAB,AUSTIN,TX 78712, USA.							Ahlberg J.H., 1967, THEORY SPLINES THEIR; Bajcsy R., 1976, COMPUT GRAPHICS IMAG, V5, P52, DOI DOI 10.1016/S0146-664X(76)80005-6; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P340, DOI 10.1109/TPAMI.1984.4767527; BHANU B, 1982, JUN P IEEE PATT REC, P349; BOLLE RM, 1982, JUN P C PATT REC IM, P611; CERNUSCHIFRIAS B, 1982, JUN P C PATT REC IM, P605; CLINE AK, 1981, CNA170 U TEX AUST; CLINE AK, 1973, ATMOS TECHNOL, V3, P60; COLEMAN EN, 1982, COMPUT VISION GRAPH, V18, P309, DOI 10.1016/0146-664X(82)90001-6; COLEMAN EN, 1981, 7TH P INT JOINT C AR, P652; Foley J. D., 1982, FUNDAMENTALS INTERAC, P2; FROBIN W, 1981, PHOTOGRAMM ENG REM S, V47, P1717; FROBIN W, 1982, PHOTOGRAMM ENG REM S, V48, P215; FROBIN W, 1982, PHOTOGRAMM ENG REM S, V48, P67; GRIMSON WEL, 1981, PHILOS T ROY SOC B, V292, P217, DOI 10.1098/rstb.1981.0031; GRIMSON WEL, 1981, IMAGES SURFACES; Hall E.L., 1982, COMPUTER         DEC, P42; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; HORN BKP, 1975, PSYCHOL COMPUTER VIS, pCH4; HUFFMAN DA, 1977, MACHINE INTELLIGENCE, P279; HUFFMAN DA, 1977, MACHINE INTELLIGENCE, P475; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; IKEUCHI K, 1980, MIT AI567 TECH REP M; IKEUCHI K, 1979, 6TH P INT JOINT C AR, P413; IKEUCHI K, 1984, 7TH P INT C PATT REC, V1, P736; JULESZ B, 1971, F CYCLOPEAN PERCEPTI; KANADE T, 1980, ARTIF INTELL, V13, P279, DOI 10.1016/0004-3702(80)90004-1; KENDER JR, 1979, 6TH P INT JOINT C AR, V1, P475; KENDER JR, 1978, NOV P DARPA IM UND W, P79; Le Moigne J., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P203; LEE HC, 1982, JUN P C PATT REC IM, P466; MARKWORTH AK, 1973, ARTIFICIAL INTELL, V4, P121; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; MARTIN WN, 1983, IEEE T PATTERN ANAL, V5, P150, DOI 10.1109/TPAMI.1983.4767367; MARTIN WN, 1981, AUG P C PATT REC IM, P189; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; MCPHERSON CA, 1982, JUN P IEEE C PATT RE, P363; MULGAONKAR PG, 1982, JUN P C PATT REC IM, P479; Ohta T.I., 1981, P INT JOINT C ART IN, P746; OSGOOD WF, 1951, PLANE SOLID ANAL GEO; Pennington K. S., 1970, Optics Communications, V2, P167, DOI 10.1016/0030-4018(70)90007-6; POSDAMER JL, 1982, COMPUT VISION GRAPH, V18, P1, DOI 10.1016/0146-664X(82)90096-X; POTMESIL M, 1979, MAY P WORKSH REPR 3; STEVENS KA, 1981, ARTIF INTELL, V17, P47, DOI 10.1016/0004-3702(81)90020-5; SUGIHARA K, 1984, ARTIFICIAL INTELL, V2, P167; SUGIHARA K, 1985, 2ND P INT S ROB RES; SUGIHARA K, 1982, IEEE T PATTERN ANAL, P458; TIO JBK, 1982, JUN C PATT REC IM P, P370; Vemuri B. C., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P752; WEI D, 1983, ROBOT VISION, P143; WILL PM, 1972, PR INST ELECTR ELECT, V60, P669, DOI 10.1109/PROC.1972.8726; WILL PM, 1971, ARTIFICIAL INTELL, P319; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9; WOODHAM RJ, 1977, 5TH P INT JOINT C AR, P635	55	40	47	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1987	9	1					129	137		10.1109/TPAMI.1987.4767878	http://dx.doi.org/10.1109/TPAMI.1987.4767878			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	F3785	21869383				2022-12-18	WOS:A1987F378500011
J	HARALICK, RM				HARALICK, RM			DECISION-MAKING IN CONTEXT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									VIRGINIA POLYTECH INST & STATE UNIV, DEPT COMP SCI, BLACKSBURG, VA 24061 USA	Virginia Polytechnic Institute & State University	HARALICK, RM (corresponding author), VIRGINIA POLYTECH INST & STATE UNIV, DEPT ELECT ENGN, BLACKSBURG, VA 24061 USA.		Haralick, Robert/AAW-5151-2020	manickam, vijayabhama.M/0000-0001-9437-9477				ASKAR M, 1981, IEEE T AUTOMAT CONTR, V26, P558, DOI 10.1109/TAC.1981.1102630; BELLMAN R, 1963, APPLIED DYNAMICS PRO; BLEDSOE WW, 1959, P E JOINT COMPUT C, V16, P225; Chow C. K., 1962, IRE T ELECTRON COM, VEC-11, P683; DUDA R, 1968, P AFIPS C, V33, P1139; ERMAN LD, 1980, COMPUT SURV, V12, P213, DOI 10.1145/356810.356816; FELDMAN JA, 1974, ARTIF INTELL, V5, P349, DOI 10.1016/0004-3702(74)90002-2; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; FU KS, 1980, IEEE T COMPUT, V29, P845, DOI 10.1109/TC.1980.1675467; HANSON AR, 1976, PATTERN RECOGN, V8, P35, DOI 10.1016/0031-3203(76)90027-3; HARALICK RM, 1980, COMPUT VISION GRAPH, V13, P242, DOI 10.1016/0146-664X(80)90048-9; HARALICK RM, 1981, COMPUT VISION GRAPH, V15, P113, DOI 10.1016/0146-664X(81)90073-3; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; KANAL LN, 1979, IEEE T PATTERN ANAL, V1, P193, DOI 10.1109/TPAMI.1979.4766905; LEHAN F, 1980, COMMUNICATION; LOWERRE BT, 1980, TRENDS SPEECH UNDERS; NAGAO M, 1979, COMPUT VISION GRAPH, V9, P394, DOI 10.1016/0146-664X(79)90102-3; NAGY G, 1968, PR INST ELECTR ELECT, V56, P836, DOI 10.1109/PROC.1968.6414; PELEG S, 1980, IEEE T PATTERN ANAL, V2, P362, DOI 10.1109/TPAMI.1980.4767035; RAVIV J, 1962, IEEE T INFORM THEORY, V3, P536; RISEMAN EM, 1971, IEEE T COMPUT, VC 20, P397, DOI 10.1109/T-C.1971.223255; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; RUBIN SM, 1977, P INT JOINT C ART IN, P590; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144; SHINGHAL R, 1978, IEEE T SYST MAN CYB, V8, P412; STOCKMAN G, 1976, COMMUN ACM, V19, P688, DOI 10.1145/360373.360378; TENENBAUM JM, 1977, ARTIF INTELL, V8, P241, DOI 10.1016/0004-3702(77)90031-5; TOMITA F, 1977, IEEE T SYST MAN CYB, V7, P107; TOUSSAINT GT, 1978, PATTERN RECOGN, V10, P189, DOI 10.1016/0031-3203(78)90027-4; WALTZ D, 1972, MIT AI TR271 ART INT; ZUCKER SW, 1978, IEEE T SYST MAN CYB, V8, P41; ZUCKER SW, 1978, JUN PATT REC IM PROC	32	40	40	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	4					417	428		10.1109/TPAMI.1983.4767411	http://dx.doi.org/10.1109/TPAMI.1983.4767411			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RA578	21869126				2022-12-18	WOS:A1983RA57800007
J	SURESH, BR; FUNDAKOWSKI, RA; LEVITT, TS; OVERLAND, JE				SURESH, BR; FUNDAKOWSKI, RA; LEVITT, TS; OVERLAND, JE			A REAL-TIME AUTOMATED VISUAL INSPECTION SYSTEM FOR HOT STEEL SLABS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											SURESH, BR (corresponding author), HONEYWELL INC,CTR SYST & RES,2600 RIDGWAY PKWY,MINNEAPOLIS,MN 55413, USA.							CHIN RT, 1982, IEEE T PATTERN ANAL, V4, P557, DOI 10.1109/TPAMI.1982.4767309; FUNDAKOWSKI RA, 1982, 6TH P IFAC S ID SYST, P157; KRUGER RP, 1981, P IEEE, V69, P1524, DOI 10.1109/PROC.1981.12199; MUNDY JL, 1980, APPLICATIONS PATTERN; PORTER GB, 1980, 5TH P INT C PATT REC; PORTER GB, 1982, MAY IEEE C REC IND A; Pratt W. K., 1978, DIGITAL IMAGE PROCES; SARIDIS GN, 1979, AUTOMATICA, V15, P505, DOI 10.1016/0005-1098(79)90001-3	8	40	46	6	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	6					563	572		10.1109/TPAMI.1983.4767445	http://dx.doi.org/10.1109/TPAMI.1983.4767445			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RV488	21869142				2022-12-18	WOS:A1983RV48800002
J	ABRAMATIC, JF; SILVERMAN, LM				ABRAMATIC, JF; SILVERMAN, LM			NON-LINEAR RESTORATION OF NOISY IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV SO CALIF, DEPT ELECT ENGN, LOS ANGELES, CA 90007 USA	University of Southern California	ABRAMATIC, JF (corresponding author), INST NATL RECH INFORMAT AUTOMAT, LE CHESNAY, FRANCE.							ABOUTALIB AO, 1977, IEEE T AUTOMAT CONTR, V22, P294, DOI 10.1109/TAC.1977.1101503; ANDERSON GL, 1976, IEEE T SYST MAN CYB, V6, P845, DOI 10.1109/TSMC.1976.4309481; Andrews H.C., 1977, DIGITAL IMAGE RESTOR; ATTASI S, 1976, SYSTEM IDENTIFICATIO; BACKUS G, 1970, PHILOS TR R SOC S-A, V266, P123, DOI 10.1098/rsta.1970.0005; CLARA FJ, 1980, THESIS PARIS 6; FRIEDEN BR, 1975, TOPICS APPLIED PHYSI; HABIBI A, 1972, PR INST ELECTR ELECT, V60, P878, DOI 10.1109/PROC.1972.8787; HELSTROM CW, 1967, J OPT SOC AM, V57, P297, DOI 10.1364/JOSA.57.000297; Ingle V. K., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing, P105; INGLE VK, 1976, P ICASSP 76 WASH, P642; NAHI NE, 1972, PR INST ELECTR ELECT, V60, P872, DOI 10.1109/PROC.1972.8786; NAHI NE, 1975, IEEE T CIRCUITS SYST, VCA22, P286, DOI 10.1109/TCS.1975.1084029; PEYROVIAN MJ, 1977, APPL OPTICS, V16, P3147, DOI 10.1364/AO.16.003147; PRATT WK, 1972, IEEE T COMPUT, VC 21, P636, DOI 10.1109/T-C.1972.223567; RAJALA SA, 1979, THESIS RICE U; TRAITEMENT BD, 1977, C NAT TRAIT SIGN APP; WOODS JW, 1977, IEEE T INFORM THEORY, V23, P473, DOI 10.1109/TIT.1977.1055750	18	40	41	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	2					141	149		10.1109/TPAMI.1982.4767220	http://dx.doi.org/10.1109/TPAMI.1982.4767220			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NE957	21869019				2022-12-18	WOS:A1982NE95700009
J	AHUJA, N; ROSENFELD, A				AHUJA, N; ROSENFELD, A			MOSAIC MODELS FOR TEXTURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MARYLAND,CTR COMP SCI,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park								ABEND K, 1965, IEEE T INFORM THEORY, V11, P538, DOI 10.1109/TIT.1965.1053827; AHUJA N, HDB STATISTICS; Ahuja N., 1981, IMAGE TEXTURE ANAL; AHUJA N, UNPUBLISHED; Box J., 1976, TIME SERIES ANAL; DEGUCHI K, 1978, IEEE T COMPUT, V27, P846; GAGALOWICZ A, 1978, 4TH P INT JOINT C PA, P541; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HARALICK RM, 1978, 4TH P INT JOINT C PA, P45; HASSNER M, 1978, 4TH P INT JOINT C PA, P538; Hawkins JK, 1970, PICTURE PROCESSING P, P347; HUNT BR, 1977, IEEE T COMPUT, V26, P219, DOI 10.1109/TC.1977.1674810; HUNT BR, 1976, IEEE T SYST MAN CYB, V6, P876; LONGUETHIGGINS MS, 1952, J MAR RES, V11, P245; LONGUETHIGGINS MS, 1957, PHILOS TR R SOC S-A, V249, P321, DOI 10.1098/rsta.1957.0002; LONGUETHIGGINS MS, 1957, PHILOS T R SOC A, V250, P151; Mandelbrot B.B., 1977, FRACTALS FORM CHANCE; Matheron G., 1971, CAHIERS CTR MORPHOLO; Matheron G, 1967, ELEMENTS THEORIE MIL; McCormick B. H., 1974, International Journal of Computer & Information Sciences, V3, P329, DOI 10.1007/BF00978978; MCCORMICK BH, 1975, INT J COMPUT INF SCI, V4, P1, DOI 10.1007/BF00976216; McCullagh, 1975, DISPLAY ANAL SPATIAL, P38; MICHALSKI RS, 1971, 3 P ANN HOUST C COMP, P213; NAHI NE, 1978, IEEE T AUTOMAT CONTR, V23, P834, DOI 10.1109/TAC.1978.1101841; NAHI NE, 1977, IEEE T COMPUT, V26, P772, DOI 10.1109/TC.1977.1674915; PANDA DP, 1979, COMPUT VISION GRAPH, V11, P313, DOI 10.1016/0146-664X(79)90069-8; PANDA DP, 1978, COMPUT GRAPHICS IMAG, V18, P334; PICKETT RM, 1970, PICTURE PROCESSING P, P289; PRATT WK, 1978, IEEE T SYST MAN CYB, V8, P796, DOI 10.1109/TSMC.1978.4309867; PRATT WK, 1978, 4TH P INT JT C PATT, P545; READ JS, 1972, IEEE T COMPUT, VC 21, P803, DOI 10.1109/T-C.1972.223585; Rosenfeld A., 1970, PICTURE PROCESSING P, P309; SCHACHTER B, 1979, COMPUT VISION GRAPH, V10, P95, DOI 10.1016/0146-664X(79)90044-3; SCHACHTER BJ, 1978, IEEE T SYST MAN CYB, V8, P694; SERRA J, 1973, FILM SCI TECHNOL, V6, P141; TOU JT, 1976, 3RD P INT JOINT C PA; TOU JT, 1976, 1976 P IEEE C DEC CO, P398; TRUSSELL HJ, 1978, IEEE T SYST MAN CYB, V8, P579, DOI 10.1109/TSMC.1978.4310026; WHITTLE P, 1954, BIOMETRIKA, V41, P434; WONG E, 1968, SIAM J APPL MATH, V16, P756, DOI 10.1137/0116062; YOKOYAMA R, 1978, COMPUT VISION GRAPH, V8, P369, DOI 10.1016/0146-664X(78)90063-1; Zucker SW., 1976, COMPUTER GRAPHICS IM, V5, P190, DOI [10.1016/0146-664X(76)90027-7, DOI 10.1016/0146-664X(76)90027-7]	42	40	41	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	1					1	11		10.1109/TPAMI.1981.4767045	http://dx.doi.org/10.1109/TPAMI.1981.4767045			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LK116	21868914				2022-12-18	WOS:A1981LK11600001
J	YACHIDA, M; ASADA, M; TSUJI, S				YACHIDA, M; ASADA, M; TSUJI, S			AUTOMATIC-ANALYSIS OF MOVING IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											YACHIDA, M (corresponding author), OSAKA UNIV,FAC ENGN SCI,DEPT CONTROL ENGN,OSAKA,JAPAN.							CHIEN RT, 1975, 4TH P INT JOINT C AR, P737; CHOW CK, 1972, FRONTIERS PATTERN RE; CHOW WK, 1977, IEEE T COMPUT, V26, P179, DOI 10.1109/TC.1977.5009299; JAIN R, 1977, 5TH P INT JOINT C AR, P612; MARTIN WN, 1978, COMPUT VISION GRAPH, V7, P356, DOI 10.1016/S0146-664X(78)80003-3; NAGEL HH, 1978, 4TH P INT JOINT C PA, P186; POTTER JL, 1975, 4TH P INT C ART INT, P803; YACHIDA M, 1978, 4TH P INT JOINT C PA, P726	8	40	45	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	1					12	20		10.1109/TPAMI.1981.4767046	http://dx.doi.org/10.1109/TPAMI.1981.4767046			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LK116	21868915				2022-12-18	WOS:A1981LK11600002
J	Zha, ZJ; Liu, DQ; Zhang, HW; Zhang, YD; Wu, F				Zha, Zheng-Jun; Liu, Daqing; Zhang, Hanwang; Zhang, Yongdong; Wu, Feng			Context-Aware Visual Policy Network for Fine-Grained Image Captioning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visualization; Task analysis; Cognition; Decision making; Training; Natural languages; Reinforcement learning; Image captioning; reinforcement learning; visual context; policy network		With the maturity of visual detection techniques, we are more ambitious in describing visual content with open-vocabulary, fine-grained and free-form language, i.e., the task of image captioning. In particular, we are interested in generating longer, richer and more fine-grained sentences and paragraphs as image descriptions. Image captioning can be translated to the task of sequential language prediction given visual content, where the output sequence forms natural language description with plausible grammar. However, existing image captioning methods focus only on language policy while not visual policy, and thus fail to capture visual context that are crucial for compositional reasoning such as object relationships (e.g., "man riding horse") and visual comparisons (e.g., "small(er) cat"). This issue is especially severe when generating longer sequences such as a paragraph. To fill the gap, we propose a Context-Aware Visual Policy network (CAVP) for fine-grained image-to-language generation: image sentence captioning and image paragraph captioning. During captioning, CAVP explicitly considers the previous visual attentions as context, and decides whether the context is used for the current word/sentence generation given the current visual attention. Compared against traditional visual attention mechanism that only fixes a single visual region at each step, CAVP can attend to complex visual compositions over time. The whole image captioning model-CAVP and its subsequent language policy network-can be efficiently optimized end-to-end by using an actor-critic policy gradient method. We have demonstrated the effectiveness of CAVP by state-of-the-art performances on MS-COCO and Stanford captioning datasets, using various metrics and sensible visualizations of qualitative visual context.	[Zha, Zheng-Jun; Liu, Daqing; Zhang, Yongdong; Wu, Feng] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230022, Peoples R China; [Zhang, Hanwang] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore	Chinese Academy of Sciences; University of Science & Technology of China, CAS; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Zha, ZJ (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230022, Peoples R China.	zhazj@ustc.edu.cn; liudq@mail.ustc.edu.cn; hanwangzhang@ntu.edu.sg; zhyd73@ustc.edu.cn; fengwu@ustc.edu.cn	Zha, Zheng-Jun/AAE-8408-2020	Zha, Zheng-Jun/0000-0003-2510-8993; Zhang, Hanwang/0000-0001-7374-8739; Liu, Daqing/0000-0002-8286-0105	National Key R&D Program of China [2017YFB1300201]; National Natural Science Foundation of China (NSFC) [61622211, 61620106009, 61525206]; Fundamental Research Funds for the Central Universities [WK2100100030]	National Key R&D Program of China; National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	This work was supported by the National Key R&D Program of China under Grant 2017YFB1300201, the National Natural Science Foundation of China (NSFC) under Grants 61622211, 61620106009 and 61525206 as well as the Fundamental Research Funds for the Central Universities under Grant WK2100100030.	Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636; Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Banerjee Satanjeev, 2005, P ACL WORKSH INTR EX, P65; Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667; Dzmitry Bahdanau, 2016, Arxiv, DOI arXiv:1409.0473; Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754; Geman D, 2015, P NATL ACAD SCI USA, V112, P3618, DOI 10.1073/pnas.1422953112; Gu JX, 2018, AAAI CONF ARTIF INTE, P6837; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Hu RH, 2017, IEEE I CONF COMP VIS, P804, DOI 10.1109/ICCV.2017.93; Jabri A, 2016, LECT NOTES COMPUT SC, V9912, P727, DOI 10.1007/978-3-319-46484-8_44; Jingna Mao, 2015, 2015 IEEE Biomedical Circuits and Systems Conference (BioCAS), P1, DOI 10.1109/BioCAS.2015.7348279; Johnson J, 2017, IEEE I CONF COMP VIS, P3008, DOI 10.1109/ICCV.2017.325; Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; King DB, 2015, ACS SYM SER, V1214, P1; Krause J, 2017, PROC CVPR IEEE, P3337, DOI 10.1109/CVPR.2017.356; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lake BM, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X16001837; Liang XD, 2017, IEEE I CONF COMP VIS, P3382, DOI 10.1109/ICCV.2017.364; Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.3115/V1/D14-1020; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu L, 2017, ARXIV PREPRINT ARXIV; Liu SQ, 2017, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2017.100; Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Ranzato M, 2016, ICLR; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ren Z, 2017, PROC CVPR IEEE, P1151, DOI 10.1109/CVPR.2017.128; Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Simonyan K., 2015, ICLR; Stanfill C., 1986, Communications of the ACM, V29, P1213, DOI 10.1145/7902.7906; Sutton RS, 2018, ADAPT COMPUT MACH LE, P1; Toutanova K, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P252, DOI 10.3115/1073445.1073478; Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696; Xu DF, 2017, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2017.330; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524; Yu LT, 2017, AAAI CONF ARTIF INTE, P2852; Zhang HW, 2018, PROC CVPR IEEE, P4158, DOI 10.1109/CVPR.2018.00437; Zhang HW, 2017, PROC CVPR IEEE, P3107, DOI 10.1109/CVPR.2017.331; Zhang QS, 2018, PROC CVPR IEEE, P8827, DOI 10.1109/CVPR.2018.00920	49	39	40	28	60	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					710	722		10.1109/TPAMI.2019.2909864	http://dx.doi.org/10.1109/TPAMI.2019.2909864			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS	30969916	Green Submitted			2022-12-18	WOS:000740006100013
J	Ge, LH; Liang, H; Yuan, JS; Thalmann, D				Ge, Liuhao; Liang, Hui; Yuan, Junsong; Thalmann, Daniel			Real-Time 3D Hand Pose Estimation with 3D Convolutional Neural Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D hand pose estimation; 3D convolutional neural networks; deep learning	RECOGNITION; REGRESSION	In this paper, we present a novel method for real-time 3D hand pose estimation from single depth images using 3D Convolutional Neural Networks (CNNs). Image-based features extracted by 2D CNNs are not directly suitable for 3D hand pose estimation due to the lack of 3D spatial information. Our proposed 3D CNN-based method, taking a 3D volumetric representation of the hand depth image as input and extracting 3D features from the volumetric input, can capture the 3D spatial structure of the hand and accurately regress full 3D hand pose in a single pass. In order to make the 3D CNN robust to variations in hand sizes and global orientations, we perform 3D data augmentation on the training data. To further improve the estimation accuracy, we propose applying the 3D deep network architectures and leveraging the complete hand surface as intermediate supervision for learning 3D hand pose from depth images. Extensive experiments on three challenging datasets demonstrate that our proposed approach outperforms baselines and state-of-the-art methods. A cross-dataset experiment also shows that our method has good generalization ability. Furthermore, our method is fast as our implementation runs at over 91 frames per second on a standard computer with a single GPU.	[Ge, Liuhao; Liang, Hui] Nanyang Technol Univ, Inst Media Innovat, Singapore 639798, Singapore; [Yuan, Junsong] SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA; [Thalmann, Daniel] Ecole Polytech Fed Lausanne, CH-1015 Lausanne, Switzerland	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; State University of New York (SUNY) System; State University of New York (SUNY) Buffalo; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Yuan, JS (corresponding author), SUNY Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA.	ge0001ao@e.ntu.edu.sg; hulia@amazon.com; jsyuan@buffalo.edu; daniel.thalmann@epfl.ch	Yuan, Junsong/R-4352-2019; Thalmann, Daniel/AAL-1097-2020	Thalmann, Daniel/0000-0002-0451-7491	BeingTogether Centre; NTU Singapore; UNC at Chapel Hill; National Research Foundation, Prime Minister's Office, Singapore under its International Research Centres in Singapore Funding Initiative; Singapore Ministry of Education Academic Research Fund Tier 2 [MOE2015-T2-2-114]; Microsoft Research Asia; University at Buffalo	BeingTogether Centre; NTU Singapore(Nanyang Technological University); UNC at Chapel Hill; National Research Foundation, Prime Minister's Office, Singapore under its International Research Centres in Singapore Funding Initiative(National Research Foundation, Singapore); Singapore Ministry of Education Academic Research Fund Tier 2(Ministry of Education, Singapore); Microsoft Research Asia(Microsoft); University at Buffalo	This research is supported by the BeingTogether Centre, a collaboration between NTU Singapore and UNC at Chapel Hill. The BeingTogether Centre is supported by the National Research Foundation, Prime Minister's Office, Singapore under its International Research Centres in Singapore Funding Initiative. This work is also supported in part by Singapore Ministry of Education Academic Research Fund Tier 2 MOE2015-T2-2-114, a grant from Microsoft Research Asia, and start-up grants from University at Buffalo.	Ballan L, 2012, LECT NOTES COMPUT SC, V7577, P640, DOI 10.1007/978-3-642-33783-3_46; Camgoz NC, 2016, INT C PATT RECOG, P49, DOI 10.1109/ICPR.2016.7899606; Chen X., 2017, POSE GUIDED STRUCTUR; Choi C, 2015, IEEE I CONF COMP VIS, P2336, DOI 10.1109/ICCV.2015.269; Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Ge LH, 2017, PROC CVPR IEEE, P5679, DOI 10.1109/CVPR.2017.602; Ge L, 2016, PROC CVPR IEEE, P3593, DOI 10.1109/CVPR.2016.391; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Guo H., 2017, GOOD PRACTICES DEEP; Guo HK, 2017, IEEE IMAGE PROC, P4512; Haque A, 2016, LECT NOTES COMPUT SC, V9905, P160, DOI 10.1007/978-3-319-46448-0_10; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Jung HY, 2016, LECT NOTES COMPUT SC, V9909, P747, DOI 10.1007/978-3-319-46454-1_45; Keskin C, 2012, LECT NOTES COMPUT SC, V7577, P852, DOI 10.1007/978-3-642-33783-3_61; Khamis S, 2015, PROC CVPR IEEE, P2540, DOI 10.1109/CVPR.2015.7298869; Kinga D., 2014, METHOD STOCHASTIC OP; Koller O, 2016, PROC CVPR IEEE, P3793, DOI 10.1109/CVPR.2016.412; Krejov Philip, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163141; Krejov P, 2017, COMPUT VIS IMAGE UND, V155, P124, DOI 10.1016/j.cviu.2016.11.005; Li PY, 2015, IEEE I CONF COMP VIS, P819, DOI 10.1109/ICCV.2015.100; Liang H, 2015, IEEE T CIRC SYST VID, V25, P1125, DOI 10.1109/TCSVT.2014.2363750; Liang H, 2014, IEEE T MULTIMEDIA, V16, P1241, DOI 10.1109/TMM.2014.2306177; Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481; Maturana D, 2015, IEEE INT CONF ROBOT, P3471, DOI 10.1109/ICRA.2015.7139679; MOLCHANOV P, 2016, PROC CVPR IEEE, P4207, DOI DOI 10.1109/CVPR.2016.456; Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Oberweger M., 2016, P IEEE C COMP VIS PA, P3593; Oberweger M, 2017, IEEE INT CONF COMP V, P585, DOI 10.1109/ICCVW.2017.75; Oberweger M, 2015, IEEE I CONF COMP VIS, P3316, DOI 10.1109/ICCV.2015.379; Oberweger Markus, 2015, ARXIV150206807; Ohn-Bar E, 2014, IEEE T INTELL TRANSP, V15, P2368, DOI 10.1109/TITS.2014.2337331; Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101; Pellegrini S., 2008, P BRIT MACH VIS C; Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609; QIAN C, 2014, PROC CVPR IEEE, P1106, DOI DOI 10.1109/CVPR.2014.145; Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148; Romero J., 2009, P 9 IEEE RAS INT C H, P87; Romero J, 2010, IEEE INT CONF ROBOT, P458, DOI 10.1109/ROBOT.2010.5509753; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; Sharp T, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3633, DOI 10.1145/2702123.2702179; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Sinha A, 2016, PROC CVPR IEEE, P4150, DOI 10.1109/CVPR.2016.450; Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28; Song SR, 2016, PROC CVPR IEEE, P808, DOI 10.1109/CVPR.2016.94; Springenberg J.T., 2014, ARXIV14126806; Sridhar S, 2016, LECT NOTES COMPUT SC, V9906, P294, DOI 10.1007/978-3-319-46475-6_19; Sridhar S, 2015, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2015.7298941; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Sun X, 2015, PROC CVPR IEEE, P824, DOI 10.1109/CVPR.2015.7298683; Tagliasacchi A, 2015, COMPUT GRAPH FORUM, V34, P101, DOI 10.1111/cgf.12700; Tang DH, 2015, IEEE I CONF COMP VIS, P3325, DOI 10.1109/ICCV.2015.380; Tang DH, 2014, PROC CVPR IEEE, P3786, DOI 10.1109/CVPR.2014.490; Taylor J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925965; Taylor J, 2012, PROC CVPR IEEE, P103, DOI 10.1109/CVPR.2012.6247664; Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500; Tzionas D, 2016, INT J COMPUT VISION, V118, P172, DOI 10.1007/s11263-016-0895-4; Wan CD, 2016, LECT NOTES COMPUT SC, V9907, P554, DOI 10.1007/978-3-319-46487-9_34; Wan Chengde, 2017, CVPR; Wu Y, 2001, IEEE SIGNAL PROC MAG, V18, P51; WU ZR, 2015, PROC CVPR IEEE, P1912, DOI DOI 10.1109/CVPR.2015.7298801; Xu C, 2017, INT J COMPUT VISION, V123, P454, DOI 10.1007/s11263-017-0998-6; Xu C, 2013, IEEE I CONF COMP VIS, P3456, DOI 10.1109/ICCV.2013.429; Ye M, 2016, IEEE T PATTERN ANAL, V38, P1517, DOI 10.1109/TPAMI.2016.2557783; Ye Q, 2016, LECT NOTES COMPUT SC, V9912, P346, DOI 10.1007/978-3-319-46484-8_21; Yumer ME, 2016, LECT NOTES COMPUT SC, V9910, P294, DOI 10.1007/978-3-319-46466-4_18; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhou X., 2016, ARXIV160606854	73	39	42	2	52	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2019	41	4					956	970		10.1109/TPAMI.2018.2827052	http://dx.doi.org/10.1109/TPAMI.2018.2827052			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HO0HP	29993927	Green Accepted			2022-12-18	WOS:000460583500013
J	Zare, A; Jiao, CZ; Glenn, T				Zare, Alina; Jiao, Changzhe; Glenn, Taylor			Discriminative Multiple Instance Hyperspectral Target Characterization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Target detection; target characterization; hyperspectral; adaptive cosine estimator; spectral matched filter; multiple instance	MATCHED-FILTER DETECTION; DETECTORS	In this paper, two methods for discriminative multiple instance target characterization, MI-SMF and MI-ACE, are presented. MI-SMF and MI-ACE estimate a discriminative target signature from imprecisely-labeled and mixed training data. In many applications, such as sub-pixel target detection in remotely-sensed hyperspectral imagery, accurate pixel-level labels on training data is often unavailable and infeasible to obtain. Furthermore, since sub-pixel targets are smaller in size than the resolution of a single pixel, training data is comprised only of mixed data points (in which target training points are mixtures of responses from both target and non-target classes). Results show improved, consistent performance over existing multiple instance concept learning methods on several hyperspectral sub-pixel target detection problems.	[Zare, Alina] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA; [Jiao, Changzhe] Xidian Univ, Sch Artificial Intelligence, Key Lab Intelligent Percept & Image Understanding, Minist Educ China, Xian 710071, Shaanxi, Peoples R China; [Glenn, Taylor] Precis Silver LLC, Gainesville, FL 32611 USA	State University System of Florida; University of Florida; Ministry of Education, China; Xidian University	Zare, A (corresponding author), Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.	azare@ufl.edu; cjiao@xidian.edu.cn; tcg@precisionsilver.com	Zare, Alina/AAJ-4411-2020	Zare, Alina/0000-0002-4847-7604; Jiao, Changzhe/0000-0002-1392-8348	National Science Foundation [IIS-1350078]	National Science Foundation(National Science Foundation (NSF))	This material is based upon work supported by the National Science Foundation under Grant No. IIS-1350078 - CAREER: Supervised Learning for Incomplete and Uncertain Data. The authors would also like to acknowledge James Theiler and Amanda Ziemann for their insightful discussions.	Akhter MA, 2015, IEEE GEOSCI REMOTE S, V12, P661, DOI 10.1109/LGRS.2014.2355915; Andrews S., 2002, NIPS, V2, P561; [Anonymous], THESIS; [Anonymous], 2013, BULLWINKLE SCORING C; Bajorski P, 2012, IEEE J-STARS, V5, P462, DOI 10.1109/JSTARS.2012.2188278; Baldridge AM, 2009, REMOTE SENS ENVIRON, V113, P711, DOI 10.1016/j.rse.2008.11.007; Basener WF, 2010, P SOC PHOTO-OPT INS, V7695, DOI 10.1117/12.850303; Bernacki BE, 2010, P SOC PHOTO-OPT INS, V7665, DOI 10.1117/12.849543; Bolton J, 2011, INFORM SCIENCES, V181, P2061, DOI 10.1016/j.ins.2010.12.020; Broadwater J, 2007, IEEE T PATTERN ANAL, V29, P1891, DOI 10.1109/TPAMI.2007.1104; Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Eismann M.T., 2012, HYPERSPECTRAL REMOTE; Eismann MT, 2009, P IEEE, V97, P1031, DOI 10.1109/JPROC.2009.2013561; Funk CC, 2001, IEEE T GEOSCI REMOTE, V39, P1410, DOI 10.1109/36.934073; Gader P., 2013, 2013570 U FLOR; Jiao CZ, 2015, IEEE T GEOSCI REMOTE, V53, P4670, DOI 10.1109/TGRS.2015.2406334; Kay S. M., 1993, FUNDAMENTAL STAT SIG, V2; Kraut S, 1999, IEEE T SIGNAL PROCES, V47, P2538, DOI 10.1109/78.782198; Kraut S, 2001, IEEE T SIGNAL PROCES, V49, P1, DOI 10.1109/78.890324; Kwon H, 2006, IEEE T PATTERN ANAL, V28, P178, DOI 10.1109/TPAMI.2006.39; Manolakis D, 2007, INT CONF ACOUST SPEE, P529; Manolakis D., 2003, Lincoln Laboratory Journal, V14, P79; Maron O, 1998, ADV NEUR IN, V10, P570; Martin R, 2012, INT J HEALTH GEOGR, V11, DOI 10.1186/1476-072X-11-21; Martinez A., 1998, 24 CVC U AUT BARC, V24; Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974; Matteoli S, 2014, IEEE J-STARS, V7, P2317, DOI 10.1109/JSTARS.2014.2315772; Mehl PM, 2004, J FOOD ENG, V61, P67, DOI 10.1016/S0260-8774(03)00188-2; Nascimento JMP, 2005, IEEE T GEOSCI REMOTE, V43, P898, DOI 10.1109/TGRS.2005.844293; Nasrabadi NM, 2008, IEEE SIGNAL PROC LET, V15, P317, DOI 10.1109/LSP.2008.917805; Nasrabadi NM, 2014, IEEE SIGNAL PROC MAG, V31, P34, DOI 10.1109/MSP.2013.2278992; Rahmani Rouhollah, 2005, P 7 ACM SIGMM INT WO, P227, DOI DOI 10.1145/1101826.1101863; Shrivastava A, 2015, INT J COMPUT VISION, V114, P288, DOI 10.1007/s11263-015-0831-z; Shrivastava A, 2014, IEEE IMAGE PROC, P160, DOI 10.1109/ICIP.2014.7025031; Theiler J, 2006, IEEE GEOSCI REMOTE S, V3, P98, DOI 10.1109/LGRS.2005.857619; Theiler J, 2005, P SOC PHOTO-OPT INS, V5806, P182, DOI 10.1117/12.604075; Zare A., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1092, DOI 10.1109/ICPR.2010.273; Zare A, 2008, IEEE T GEOSCI REMOTE, V46, P172, DOI 10.1109/TGRS.2007.906438; Zare A, 2014, IEEE SIGNAL PROC MAG, V31, P95, DOI 10.1109/MSP.2013.2279177; Zhang Q, 2002, ADV NEUR IN, V14, P1073; Ziemann A K, 2015, P IEEE APPL IM PATT, P1	42	39	40	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2018	40	10					2342	2354		10.1109/TPAMI.2017.2756632	http://dx.doi.org/10.1109/TPAMI.2017.2756632			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GS7IZ	28961102	hybrid			2022-12-18	WOS:000443875500005
J	Xu, YC; Geraud, T; Najman, L				Xu, Yongchao; Geraud, Thierry; Najman, Laurent			Connected Filtering on Tree-Based Shape-Spaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Mathematical morphology; connected filtering; shape-space filtering; Max-tree; Min-tree; tree of shapes; graph; shape-based lower/upper leveling; blood vessel segmentation; shaping	RETINAL BLOOD-VESSELS; MORPHOLOGICAL IMAGE; SEGMENTATION; OPERATORS; REPRESENTATION; COMPUTATION	Connected filters are well-known for their good contour preservation property. A popular implementation strategy relies on tree-based image representations: for example, one can compute an attribute characterizing the connected component represented by each node of the tree and keep only the nodes for which the attribute is sufficiently high. This operation can be seen as a thresholding of the tree, seen as a graph whose nodes are weighted by the attribute. Rather than being satisfied with a mere thresholding, we propose to expand on this idea, and to apply connected filters on this latest graph. Consequently, the filtering is performed not in the space of the image, but in the space of shapes built from the image. Such a processing of shape-space filtering is a generalization of the existing tree-based connected operators. Indeed, the framework includes the classical existing connected operators by attributes. It also allows us to propose a class of novel connected operators from the leveling family, based on non-increasing attributes. Finally, we also propose a new class of connected operators that we call morphological shapings. Some illustrations and quantitative evaluations demonstrate the usefulness and robustness of the proposed shape-space filters.	[Xu, Yongchao; Geraud, Thierry] EPITA Res & Dev Lab LRDE, 14-16 Rue Voltaire, FR-94270 Le Kremlin Bicetre, France; [Xu, Yongchao; Geraud, Thierry; Najman, Laurent] Univ Paris Est, Lab Informat Gaspard Monge, ESIEE Paris, Equipe A3SI, FR-93160 Noisy Le Grand, France; [Xu, Yongchao] Telecom ParisTech, Dept Signal & Image Proc, 46 Rue Barrault, F-75013 Paris, France	Universite Gustave-Eiffel; ESIEE Paris; IMT - Institut Mines-Telecom; Institut Polytechnique de Paris	Xu, YC; Geraud, T (corresponding author), EPITA Res & Dev Lab LRDE, 14-16 Rue Voltaire, FR-94270 Le Kremlin Bicetre, France.; Xu, YC; Geraud, T; Najman, L (corresponding author), Univ Paris Est, Lab Informat Gaspard Monge, ESIEE Paris, Equipe A3SI, FR-93160 Noisy Le Grand, France.; Xu, YC (corresponding author), Telecom ParisTech, Dept Signal & Image Proc, 46 Rue Barrault, F-75013 Paris, France.	yongchao.xu@lrde.epita.fr; thierry.geraud@lrde.epita.fr; l.najman@esiee.fr	Géraud, Thierry/AAT-8485-2020; Xu, Yongchao/F-2080-2019; Najman, Laurent/AAB-4212-2020	Xu, Yongchao/0000-0002-7253-3151; Najman, Laurent/0000-0002-6190-0235; Geraud, Thierry/0000-0002-0380-7948				Al-Diri B, 2009, IEEE T MED IMAGING, V28, P1488, DOI 10.1109/TMI.2009.2017941; Braga-Neto U, 2003, J MATH IMAGING VIS, V19, P5, DOI 10.1023/A:1024476403183; Breen EJ, 1996, COMPUT VIS IMAGE UND, V64, P377, DOI 10.1006/cviu.1996.0066; Cao F, 2005, J MATH IMAGING VIS, V22, P159, DOI 10.1007/s10851-005-4888-0; Caselles V., 2009, LECT NOTES MATH, V1984; Crespo J, 1997, J MATH IMAGING VIS, V7, P85, DOI 10.1023/A:1008270125009; Desolneux A, 2001, J MATH IMAGING VIS, V14, P271, DOI 10.1023/A:1011290230196; Donoser M., 2006, 2006 IEEE COMPUTER S, V1, P553, DOI DOI 10.1109/CVPR.2006.107; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Grady L.J., 2010, DISCRETE CALCULUS AP; Grossiord E, 2015, I S BIOMED IMAGING, P1118, DOI 10.1109/ISBI.2015.7164068; Heijmans HJAM, 1999, COMPUT VIS IMAGE UND, V73, P99, DOI 10.1006/cviu.1998.0703; Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178; Jiang XY, 2003, IEEE T PATTERN ANAL, V25, P131, DOI 10.1109/TPAMI.2003.1159954; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Levillain R, 2010, IEEE IMAGE PROC, P1941, DOI 10.1109/ICIP.2010.5649620; Lezoray O., 2012, SERIES DIGITAL IMAGI; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P586, DOI 10.1109/34.24793; Martinez-Perez M., 1999, MED IMAGE COMPUTING, P90; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Mendonca AM, 2006, IEEE T MED IMAGING, V25, P1200, DOI 10.1109/TMI.2006.879955; Meyer F, 2004, J MATH IMAGING VIS, V20, P59, DOI 10.1023/B:JMIV.0000011319.21884.39; Meyer F, 1998, COMP IMAG VIS, V12, P191; Monasse P, 2000, IEEE T IMAGE PROCESS, V9, P860, DOI 10.1109/83.841532; Najman Laurent, 2013, Mathematical Morphology and Its Applications to Signal and Image Processing. 11th International Symposium, ISMM 2013. Proceedings, P37, DOI 10.1007/978-3-642-38294-9_4; Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254; Najman L, 2011, J MATH IMAGING VIS, V40, P231, DOI 10.1007/s10851-011-0259-1; Ouzounis GK, 2007, IEEE T PATTERN ANAL, V29, P990, DOI 10.1109/TPAMI.2007.1045; Ouzounis GK, 2011, IEEE T PATTERN ANAL, V33, P224, DOI 10.1109/TPAMI.2010.74; Passat N, 2014, J MATH IMAGING VIS, V49, P37, DOI 10.1007/s10851-013-0438-3; Perret B, 2015, COMPUT VIS IMAGE UND, V133, P1, DOI 10.1016/j.cviu.2014.09.008; Perret B, 2015, IEEE T PATTERN ANAL, V37, P1162, DOI 10.1109/TPAMI.2014.2366145; Purnama IKE, 2010, INT J E-HEALTH MED C, V1, P16, DOI 10.4018/jehmc.2010070102; Purnama Ketut E., 2007, VISAPP 2007. Second International Conference on Computer Vision Theory and Applications, P328; SALEMBIER P, 1995, IEEE T IMAGE PROCESS, V4, P1153, DOI 10.1109/83.403422; Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500; Salembier P, 2000, IEEE T IMAGE PROCESS, V9, P561, DOI 10.1109/83.841934; Salembier P, 2009, IEEE SIGNAL PROC MAG, V26, P136, DOI 10.1109/MSP.2009.934154; Serra J, 1998, J MATH IMAGING VIS, V9, P231, DOI 10.1023/A:1008324520475; SERRA J, 1993, P SOC PHOTO-OPT INS, V2030, P65, DOI 10.1117/12.146672; Serra J., 1982, IMAGE ANAL MATH MORP, pChap11; Shuman DI, 2013, IEEE SIGNAL PROC MAG, V30, P83, DOI 10.1109/MSP.2012.2235192; Soille P, 2008, IEEE T PATTERN ANAL, V30, P1132, DOI 10.1109/TPAMI.2007.70817; Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627; Urbach ER, 2007, IEEE T PATTERN ANAL, V29, P272, DOI 10.1109/TPAMI.2007.28; Urbach ER, 2009, 2009 24TH INTERNATIONAL CONFERENCE IMAGE AND VISION COMPUTING NEW ZEALAND (IVCNZ 2009), P299, DOI 10.1109/IVCNZ.2009.5378393; Vachier C., 1995, P IEEE WORKSH NONL S, P254; Westenberg MA, 2007, IEEE T IMAGE PROCESS, V16, P2943, DOI 10.1109/TIP.2007.909317; Wilkinson MHF, 2008, IEEE T PATTERN ANAL, V30, P1800, DOI 10.1109/TPAMI.2007.70836; Xu, 2013, THESIS U PARIS EST F; Xu YC, 2014, IEEE T IMAGE PROCESS, V23, P5612, DOI 10.1109/TIP.2014.2364127; Xu YC, 2012, INT C PATT RECOG, P485; Xu YC, 2012, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2012.6467175; Yongchao Xu, 2013, Mathematical Morphology and Its Applications to Signal and Image Processing. 11th International Symposium, ISMM 2013. Proceedings, P390, DOI 10.1007/978-3-642-38294-9_33; Zana F, 2001, IEEE T IMAGE PROCESS, V10, P1010, DOI 10.1109/83.931095	57	39	39	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2016	38	6					1126	1140		10.1109/TPAMI.2015.2441070	http://dx.doi.org/10.1109/TPAMI.2015.2441070			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DL4LU	26415150	Green Submitted			2022-12-18	WOS:000375609000007
J	Song, SY; Chandraker, M; Guest, CC				Song, Shiyu; Chandraker, Manmohan; Guest, Clark C.			High Accuracy Monocular SFM and Scale Correction for Autonomous Driving	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Monocular structure-from-motion; scale drift; ground plane estimation; object localization	VISUAL SLAM; PARALLEL	We present a real-time monocular visual odometry system that achieves high accuracy in real-world autonomous driving applications. First, we demonstrate robust monocular SFM that exploits multithreading to handle driving scenes with large motions and rapidly changing imagery. To correct for scale drift, we use known height of the camera from the ground plane. Our second contribution is a novel data-driven mechanism for cue combination that allows highly accurate ground plane estimation by adapting observation covariances of multiple cues, such as sparse feature matching and dense inter-frame stereo, based on their relative confidences inferred from visual data on a per-frame basis. Finally, we demonstrate extensive benchmark performance and comparisons on the challenging KITTI dataset, achieving accuracy comparable to stereo and exceeding prior monocular systems. Our SFM system is optimized to output pose within 50 ms in the worst case, while average case operation is over 30 fps. Our framework also significantly boosts the accuracy of applications like object localization that rely on the ground plane.	[Song, Shiyu; Guest, Clark C.] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA; [Chandraker, Manmohan] NEC Labs Amer, Media Analyt, Cupertino, CA 95014 USA	University of California System; University of California San Diego; NEC Corporation	Song, SY; Guest, CC (corresponding author), Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.; Chandraker, M (corresponding author), NEC Labs Amer, Media Analyt, Cupertino, CA 95014 USA.	shs012@ucsd.edu; manu@nec-labs.com; cguest@ucsd.edu	Chandraker, Manmohan/AAU-4762-2021					Achtelik Markus, 2011, IEEE International Conference on Robotics and Automation, P3056; Ahn SH, 2008, AUTON ROBOT, V24, P315, DOI 10.1007/s10514-007-9083-2; Changchang Wu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3057, DOI 10.1109/CVPR.2011.5995552; Choi W., 2010, ECCV, P553; Civera J, 2010, J FIELD ROBOT, V27, P609, DOI 10.1002/rob.20345; Clipp B, 2010, IEEE INT C INT ROBOT, P3961, DOI 10.1109/IROS.2010.5653696; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403; Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049; Endres F, 2012, IEEE INT CONF ROBOT, P1691, DOI 10.1109/ICRA.2012.6225199; Ess A, 2009, IEEE T PATTERN ANAL, V31, P1831, DOI 10.1109/TPAMI.2009.109; Faugeras O. D., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P485, DOI 10.1142/S0218001488000285; Geiger A., 2012, KITTI VISION BENCHMA; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405; Handa A, 2010, PROC CVPR IEEE, P1546, DOI 10.1109/CVPR.2010.5539788; Hansen P, 2011, IEEE INT CONF ROBOT; Klein G, 2008, LECT NOTES COMPUT SC, V5303, P802, DOI 10.1007/978-3-540-88688-4_59; Klein George, 2007, P1; Kummerle R, 2009, AUTON ROBOT, V27, P387, DOI 10.1007/s10514-009-9155-6; Kundu A, 2011, IEEE I CONF COMP VIS, P2080, DOI 10.1109/ICCV.2011.6126482; Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; Nister D, 2004, PROC CVPR IEEE, P652; Odelson BJ, 2006, AUTOMATICA, V42, P303, DOI 10.1016/j.automatica.2005.09.006; Oliensis J, 2005, INT J COMPUT VISION, V61, P259, DOI 10.1023/B:VISI.0000045326.88734.8b; Ozden K., 2007, ICCV, P1; Ozden KE, 2010, IEEE T PATTERN ANAL, V32, P1134, DOI 10.1109/TPAMI.2010.23; Scaramuzza D, 2008, IEEE T ROBOT, V24, P1015, DOI 10.1109/TRO.2008.2004490; Scaramuzza D, 2009, IEEE I CONF COMP VIS, P1413, DOI 10.1109/ICCV.2009.5459294; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Song SY, 2015, PROC CVPR IEEE, P3734, DOI 10.1109/CVPR.2015.7298997; Song SY, 2014, PROC CVPR IEEE, P1566, DOI 10.1109/CVPR.2014.203; Song SY, 2013, IEEE INT CONF ROBOT, P4698, DOI 10.1109/ICRA.2013.6631246; Strasdat H., 2010, ROBOTICS SCI SYSTEMS; Strasdat H, 2012, IMAGE VISION COMPUT, V30, P65, DOI 10.1016/j.imavis.2012.02.009; Tardif JP, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2531, DOI 10.1109/IROS.2008.4651205; Weiss S, 2011, J FIELD ROBOT, V28, P854, DOI 10.1002/rob.20412; Wojek C, 2013, IEEE T PATTERN ANAL, V35, P882, DOI 10.1109/TPAMI.2012.174	42	39	42	0	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2016	38	4					730	743		10.1109/TPAMI.2015.2469274	http://dx.doi.org/10.1109/TPAMI.2015.2469274			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DH1MW	26513777				2022-12-18	WOS:000372549700010
J	Sun, YF; Gao, JB; Hong, X; Mishra, B; Yin, BC				Sun, Yanfeng; Gao, Junbin; Hong, Xia; Mishra, Bamdev; Yin, Baocai			Heterogeneous Tensor Decomposition for Clustering via Manifold Optimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Tensor clustering; multinomial manifold; Fisher metric; Riemannian optimization; trust-region	NONNEGATIVE MATRIX FACTORIZATION; RECOGNITION; RANK-1	Tensor clustering is an important tool that exploits intrinsically rich structures in real-world multiarray or Tensor datasets. Often in dealing with those datasets, standard practice is to use subspace clustering that is based on vectorizing multiarray data. However, vectorization of tensorial data does not exploit complete structure information. In this paper, we propose a subspace clustering algorithm without adopting any vectorization process. Our approach is based on a novel heterogeneous Tucker decomposition model taking into account cluster membership information. We propose a new clustering algorithm that alternates between different modes of the proposed heterogeneous tensor model. All but the last mode have closed-form updates. Updating the last mode reduces to optimizing over the multinomial manifold for which we investigate second order Riemannian geometry and propose a trust-region algorithm. Numerical experiments show that our proposed algorithm compete effectively with state-of-the-art clustering algorithms that are based on tensor factorization.	[Sun, Yanfeng; Yin, Baocai] Beijing Univ Technol, Coll Metropolitan Transportat, Beijing Municipal Key Lab Multimedia & Intelligen, Beijing 100124, Peoples R China; [Yin, Baocai] Dalian Univ Technol, Sch Software Technol, Dalian 116024, Peoples R China; [Gao, Junbin] Charles Sturt Univ, Sch Comp & Math, Bathurst, NSW 2795, Australia; [Hong, Xia] Univ Reading, Sch Syst Engn, Reading RG6 6AY, Berks, England; [Mishra, Bamdev] Univ Liege, Dept Elect Engn & Comp Sci, Liege, Belgium; [Mishra, Bamdev] Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England	Beijing University of Technology; Dalian University of Technology; Charles Sturt University; University of Reading; University of Liege; University of Cambridge	Sun, YF; Yin, BC (corresponding author), Beijing Univ Technol, Coll Metropolitan Transportat, Beijing Municipal Key Lab Multimedia & Intelligen, Beijing 100124, Peoples R China.; Yin, BC (corresponding author), Dalian Univ Technol, Sch Software Technol, Dalian 116024, Peoples R China.; Gao, JB (corresponding author), Charles Sturt Univ, Sch Comp & Math, Bathurst, NSW 2795, Australia.; Hong, X (corresponding author), Univ Reading, Sch Syst Engn, Reading RG6 6AY, Berks, England.; Mishra, B (corresponding author), Univ Liege, Dept Elect Engn & Comp Sci, Liege, Belgium.; Mishra, B (corresponding author), Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England.	yfsun@bjut.edu.cn; jbgao@csu.edu.au; x.hong@reading.ac.uk; b.mishra@ulg.ac.be; ybc@bjut.edu.cn	Gao, Junbin/C-6566-2008; Gao, Junbin/A-1766-2009	Gao, Junbin/0000-0001-9803-0256; Mishra, Bamdev/0000-0001-7430-2843	Australian Research Council's Discovery Projects funding scheme [DP130100364]; National Natural Science Foundation of China [61370119, 61133003, 61390510]; Natural Science Foundation of Beijing [4132013]	Australian Research Council's Discovery Projects funding scheme(Australian Research Council); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Beijing(Beijing Natural Science Foundation)	The authors wish to thank all the anonymous reviewers for their comments and suggestions to improve the quality of the paper. They also thank Kasper Winther Joergensen for providing the NMF toolbox. This research was supported under Australian Research Council's Discovery Projects funding scheme (project number DP130100364). This work was also partially supported by the National Natural Science Foundation of China (No. 61370119, 61133003 and 61390510) and the Natural Science Foundation of Beijing (No. 4132013). Bamdev Mishra is supported as an F.R.S-FNRS research fellow (Belgian Fund for Scientific Research).	Absil PA, 2007, FOUND COMPUT MATH, V7, P303, DOI 10.1007/s10208-005-0179-9; Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1; Acar E, 2009, IEEE T KNOWL DATA EN, V21, P6, DOI 10.1109/TKDE.2008.112; [Anonymous], 2002, LEARNING KERNELS; Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; Boumal N., 2014, THESIS U CATHOLIQUE; Boumal N, 2014, J MACH LEARN RES, V15, P1455; Cai D., 2006, P 29 ANN INT ACM SIG, P625; Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231; Cai D, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1010; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S1064827596304010; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1324, DOI 10.1137/S0895479898346995; Forsati R, 2013, INFORM SCIENCES, V220, P269, DOI 10.1016/j.ins.2012.07.025; Friedlander MP, 2008, OPTIM METHOD SOFTW, V23, P631, DOI 10.1080/10556780801996244; Ghanem B, 2010, LECT NOTES COMPUT SC, V6312, P223; Gu QQ, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P359; Guo X, 2013, ISPRS J PHOTOGRAMM, V83, P50, DOI 10.1016/j.isprsjprs.2013.06.001; Harandi M, 2015, INT J COMPUT VISION, V114, P113, DOI 10.1007/s11263-015-0833-x; Inokuchi R, 2007, LECT NOTES ARTIF INT, V4617, P261; Kiers HAL, 2000, J CHEMOMETR, V14, P105, DOI 10.1002/1099-128X(200005/06)14:3<105::AID-CEM582>3.0.CO;2-I; Kim H, 2007, BIOINFORMATICS, V23, P1495, DOI 10.1093/bioinformatics/btm134; Kolda T. G., 2006, SAND2006281 SAND NAT, P1; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Lebanon G., 2004, P 21 INT C MACH LEAR, P66; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Lee DD, 2001, ADV NEUR IN, V13, P556; LEE JM, 2002, GRADUATE TEXTS MATH, V218; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Lin CJ, 2007, NEURAL COMPUT, V19, P2756, DOI 10.1162/neco.2007.19.10.2756; Liu HF, 2012, IEEE T PATTERN ANAL, V34, P1299, DOI 10.1109/TPAMI.2011.217; Liu J, 2012, PATTERN RECOGN, V45, P649, DOI 10.1016/j.patcog.2011.05.015; Lu HP, 2011, PATTERN RECOGN, V44, P1540, DOI 10.1016/j.patcog.2011.01.004; Luenberger D.G., 2008, LINEAR NONLINEAR PRO; Lui YM, 2012, IMAGE VISION COMPUT, V30, P380, DOI 10.1016/j.imavis.2011.08.002; Meyer G., 2011, THESIS U LIEGE LIEGE; Mishra B, 2013, SIAM J OPTIMIZ, V23, P2124, DOI 10.1137/110859646; Morup M, 2011, WIRES DATA MIN KNOWL, V1, P24, DOI 10.1002/widm.1; Munoz-Moreno E, 2009, ADV PATTERN RECOGNIT, P79, DOI 10.1007/978-1-84882-299-3_4; Peng W, 2011, INTELL DATA ANAL, V15, P695, DOI 10.3233/IDA-2011-0490; PETERSEN KB, 2008, MATRIX COOKBOOK VERS; Schmidt MN, 2009, LECT NOTES COMPUT SC, V5441, P540, DOI 10.1007/978-3-642-00599-2_68; Shashua A., 2005, P 22 INT C MACHINE L, P792, DOI [10.1145/1102351.1102451, DOI 10.1145/1102351.1102451]; Shaw G. A., 2003, Lincoln Laboratory Journal, V14, P3; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Sun Jian-Tao, 2005, PROC 14 INT C WORLD, P382, DOI DOI 10.1145/1060745.1060803; Sun YF, 2014, IEEE IJCNN, P1565, DOI 10.1109/IJCNN.2014.6889385; Tang Yichuan, 2013, INT C MACH LEARN, P163; Tseng P, 2010, COMPUT OPTIM APPL, V47, P179, DOI 10.1007/s10589-008-9215-4; VANDEREYCKEN B., 2010, THESIS KATHOLIEKE U; Vichi M, 2007, J CLASSIF, V24, P71, DOI 10.1007/s00357-007-0006-x; Welling M, 2001, PATTERN RECOGN LETT, V22, P1255, DOI 10.1016/S0167-8655(01)00070-8; Wu F., 2013, P 27 AAAI C ART INT, P962; Xie Yuchen, 2013, JMLR Workshop Conf Proc, V28, P1480; Zhang D., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P266, DOI 10.1145/1076034.1076081; Zhang ZY, 2013, KNOWL INF SYST, V34, P243, DOI 10.1007/s10115-011-0460-y	56	39	39	3	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2016	38	3					476	489		10.1109/TPAMI.2015.2465901	http://dx.doi.org/10.1109/TPAMI.2015.2465901			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE6JD	27046492	Green Submitted			2022-12-18	WOS:000370738900005
J	Bianco, S; Schettini, R				Bianco, Simone; Schettini, Raimondo			Adaptive Color Constancy Using Faces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Color constancy; face detection; global illuminant estimation; local illuminant estimation	SKIN-COLOR; MODEL	In this work we design an adaptive color constancy algorithm that, exploiting the skin regions found in faces, is able to estimate and correct the scene illumination. The algorithm automatically switches from global to spatially varying color correction on the basis of the illuminant estimations on the different faces detected in the image. An extensive comparison with both global and local color constancy algorithms is carried out to validate the effectiveness of the proposed algorithm in terms of both statistical and perceptual significance on a large heterogeneous data set of RAW images containing faces.	[Bianco, Simone; Schettini, Raimondo] Univ Milano Bicocca, Dept Informat Syst & Commun, Milan, Italy	University of Milano-Bicocca	Bianco, S (corresponding author), Univ Milano Bicocca, Dept Informat Syst & Commun, Viale Sarca 336,Edificio U14, Milan, Italy.	bianco@disco.unimib.it; schettini@disco.unimib.it	Bianco, Simone/T-1224-2019	Bianco, Simone/0000-0002-7070-1545; SCHETTINI, RAIMONDO/0000-0001-7461-1451				Barnard K, 2000, LECT NOTES COMPUT SC, V1842, P390; Bianco S, 2010, PATTERN RECOGN, V43, P695, DOI 10.1016/j.patcog.2009.08.007; Bianco S., 2007, J ELECT IMAGING, V17; Bianco S, 2008, IEEE T IMAGE PROCESS, V17, P2381, DOI 10.1109/TIP.2008.2006661; Bianco S, 2012, LECT NOTES COMPUT SC, V7584, P390, DOI 10.1007/978-3-642-33868-7_39; Bianco S, 2012, PROC CVPR IEEE, P65, DOI 10.1109/CVPR.2012.6247659; Bleier M., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P774, DOI 10.1109/ICCVW.2011.6130331; Boyadzhiev I, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366219; BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7; C. I. Group, 2007, I3A CPIQ PHASE 1 DOC, P1; Cardei VC, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P97; Chakrabarti A, 2012, IEEE T PATTERN ANAL, V34, P1509, DOI 10.1109/TPAMI.2011.252; Crichton Stuart, 2012, CGIV 2012. 6th European Conference on Colour in Graphics, Imaging, and Vision, P266; de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677; Ebner M, 2009, MACH VISION APPL, V20, P283, DOI 10.1007/s00138-008-0126-2; Finayson GD, 2001, IEEE T PATTERN ANAL, V23, P1209, DOI 10.1109/34.969113; Finlayson G.D., 2004, J OPT SOC AM A, V11, P3011; FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770; Funt B., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P445, DOI 10.1007/BFb0055683; Gasparini F, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2916715; Gehler PV, 2008, PROC CVPR IEEE, P3291; Geusebroek J.-M., 2012, COLOR COMPUTER VISIO; Gijsenij A, 2012, IEEE T IMAGE PROCESS, V21, P697, DOI 10.1109/TIP.2011.2165219; Gijsenij A, 2011, IEEE T IMAGE PROCESS, V20, P2475, DOI 10.1109/TIP.2011.2118224; Gijsenij A, 2011, IEEE T PATTERN ANAL, V33, P687, DOI 10.1109/TPAMI.2010.93; Gijsenij A, 2010, INT J COMPUT VISION, V86, P127, DOI 10.1007/s11263-008-0171-3; Gijsenij A, 2009, J OPT SOC AM A, V26, P2243, DOI 10.1364/JOSAA.26.002243; Gottumukkal R, 2005, PROC SPIE, V5685, P969, DOI 10.1117/12.587934; Hansen T, 2006, NAT NEUROSCI, V9, P1367, DOI 10.1038/nn1794; Hordley SD, 2004, INT C PATT RECOG, P76, DOI 10.1109/ICPR.2004.1334009; Hordley SD, 2006, COLOR RES APPL, V31, P303, DOI 10.1002/col.20226; Hsu E, 2008, ACM T GRAPHIC, V27, DOI [10.1145/1399504.1360669, 10.1145/1360612.1360669]; Huang R, 2011, IEEE IMAGE PROC, P13, DOI 10.1109/ICIP.2011.6115701; ISO, 2003, 160662003E ISOTR; Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010; Kemelmacher-Shlizerman I, 2011, IEEE I CONF COMP VIS, P1746, DOI 10.1109/ICCV.2011.6126439; Kim SJ, 2012, IEEE T PATTERN ANAL, V34, P2289, DOI 10.1109/TPAMI.2012.58; LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108; Lu R, 2009, IEEE I CONF COMP VIS, P1749, DOI 10.1109/ICCV.2009.5459391; Marguier J, 2007, INT J IMAG SYST TECH, V17, P143, DOI 10.1002/ima.20114; Montojo J, 2009, FACE BASED CHROMATIC; Moreno A, 2011, LECT NOTES COMPUT SC, V6626, P165, DOI 10.1007/978-3-642-20404-3_13; Nachlieli H., 2009, HPL200913, P1; Nishino K, 2005, IEEE I CONF COMP VIS, P519; Nishino K, 2004, PROC CVPR IEEE, P444; Nishino K, 2004, ACM T GRAPHIC, V23, P704, DOI 10.1145/1015706.1015783; Ramanath R, 2005, IEEE SIGNAL PROC MAG, V22, P34, DOI 10.1109/MSP.2005.1407713; Shi L., 2013, REPROCESSED VERSION; Soriano M., 2000, NORSIG2000. Nordic Signal Processing Symposium, P383; Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808; van de Weijer J, 2007, IEEE I CONF COMP VIS, P2197; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; von Kries J., 1902, SPIE MILESTONE SERIE; WILCOXON F, 1946, J ECON ENTOMOL, V39, P269, DOI 10.1093/jee/39.2.269; Witkin A., 1984, P IEEE INT C AC SPEE, V9, P150, DOI DOI 10.1109/ICASSP.1984.1172729	55	39	41	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2014	36	8					1505	1518		10.1109/TPAMI.2013.2297710	http://dx.doi.org/10.1109/TPAMI.2013.2297710			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9HN	26353334				2022-12-18	WOS:000340191900002
J	Niu, DL; Dy, JG; Jordan, MI				Niu, Donglin; Dy, Jennifer G.; Jordan, Michael I.			Iterative Discovery of Multiple Alternative Clustering Views	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Kernel methods; non-redundant clustering; alternative clustering; multiple clustering; dimensionality reduction		Complex data can be grouped and interpreted in many different ways. Most existing clustering algorithms, however, only find one clustering solution, and provide little guidance to data analysts who may not be satisfied with that single clustering and may wish to explore alternatives. We introduce a novel approach that provides several clustering solutions to the user for the purposes of exploratory data analysis. Our approach additionally captures the notion that alternative clusterings may reside in different subspaces (or views). We present an algorithm that simultaneously finds these subspaces and the corresponding clusterings. The algorithm is based on an optimization procedure that incorporates terms for cluster quality and novelty relative to previously discovered clustering solutions. We present a range of experiments that compare our approach to alternatives and explore the connections between simultaneous and iterative modes of discovery of multiple clusterings.	[Niu, Donglin; Dy, Jennifer G.] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA; [Jordan, Michael I.] Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA; [Jordan, Michael I.] Univ Calif Berkeley, Dept Stat, Berkeley, CA 94720 USA	Northeastern University; University of California System; University of California Berkeley; University of California System; University of California Berkeley	Niu, DL (corresponding author), Northeastern Univ, Dept Elect & Comp Engn, 409 Dana Res Bldg, Boston, MA 02115 USA.	dniu@ece.neu.edu; jdy@ece.neu.edu; jordan@cs.berkeley.edu	Jordan, Michael I/C-5253-2013	Jordan, Michael/0000-0001-8935-817X	US National Science Foundation [NSF IIS-0915910]; Office of Naval Research [N00014-11-1-0688]	US National Science Foundation(National Science Foundation (NSF)); Office of Naval Research(Office of Naval Research)	This work was supported by US National Science Foundation NSF IIS-0915910 and by the Office of Naval Research under contract/grant number N00014-11-1-0688.	Bach FR, 2003, J MACH LEARN RES, V3, P1, DOI 10.1162/153244303768966085; Bae E, 2006, IEEE DATA MINING, P53; BAY SD, 1999, UCI KDD ARCH; Caruana R, 2006, IEEE DATA MINING, P107; CMU, 1997, CMU 4 U WEBKB DAT; Cui Y, 2007, IEEE DATA MINING, P133, DOI 10.1109/ICDM.2007.94; Cui Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1839490.1839496; Dang X. H., 2010, P 16 ACM SIGKDD INT, P573, DOI DOI 10.1145/1835804.1835878; Dang X. H., 2010, SDM, P118; Dasgupta S., 2010, P 27 INT C MACH LEAR, P263; Davidson I, 2008, IEEE DATA MINING, P773, DOI 10.1109/ICDM.2008.141; Ding C., 2004, P 21 ST INT C MACHIN, P29, DOI DOI 10.1145/1015330.1015408; Gondek D, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P75, DOI 10.1109/ICDM.2004.10104; Gretton A, 2005, LECT NOTES ARTIF INT, V3734, P63; Guan Y., 2010, 1 INT WORKSH MULTICL; HARTIGAN JA, 1985, J CLASSIF, V2, P63, DOI 10.1007/BF01908064; Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011; JAIN P., 2008, P SIAM INT C DAT MIN, P858; Mansinghka Vikash K, 2009, NONP BAYES WORKSH NI; Moise G, 2008, P 14 ACM SIGKDD INT, P533, DOI DOI 10.1145/1401890.1401956; Muller E, 2009, IEEE DATA MINING, P377, DOI 10.1109/ICDM.2009.10; Ng AY, 2002, ADV NEUR IN, V14, P849; Niu D., 2010, PROC 27 INT C MACH L, P831; Niu D., 2012, INT C ART INT STAT, P814; Niu D., 2011, P 14 INT C ART INT S, P552; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Parsons L., 2004, SIGKDD EXPLOR NEWSL, V6, P90, DOI DOI 10.1145/1007730.1007731; Poon L., 2010, P 27 INT C MACH LEAR, P887; Qi ZJ, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P717; Sim K, 2013, DATA MIN KNOWL DISC, V26, P332, DOI 10.1007/s10618-012-0258-x; Song L., 2007, ICML, P815; Strehl A., 2003, Journal of Machine Learning Research, V3, P583, DOI 10.1162/153244303321897735; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z	34	39	39	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2014	36	7					1340	1353		10.1109/TPAMI.2013.180	http://dx.doi.org/10.1109/TPAMI.2013.180			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AK1WS	26353307	Green Submitted			2022-12-18	WOS:000338209900005
J	Seidenari, L; Serra, G; Bagdanov, AD; Del Bimbo, A				Seidenari, Lorenzo; Serra, Giuseppe; Bagdanov, Andrew D.; Del Bimbo, Alberto			Local Pyramidal Descriptors for Image Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object categorization; local features; kernel methods		In this paper, we present a novel method to improve the flexibility of descriptor matching for image recognition by using local multiresolution pyramids in feature space. We propose that image patches be represented at multiple levels of descriptor detail and that these levels be defined in terms of local spatial pooling resolution. Preserving multiple levels of detail in local descriptors is a way of hedging one's bets on which levels will most relevant for matching during learning and recognition. We introduce the Pyramid SIFT (P-SIFT) descriptor and show that its use in four state-of-the-art image recognition pipelines improves accuracy and yields state-of-the-art results. Our technique is applicable independently of spatial pyramid matching and we show that spatial pyramids can be combined with local pyramids to obtain further improvement. We achieve state-of-the-art results on Caltech-101 (80.1%) and Caltech-256 (52.6%) when compared to other approaches based on SIFT features over intensity images. Our technique is efficient and is extremely easy to integrate into image recognition pipelines.	[Seidenari, Lorenzo; Bagdanov, Andrew D.; Del Bimbo, Alberto] Univ Florence, Media Integrat & Commun Ctr, I-50139 Florence, Italy; [Serra, Giuseppe] Univ Modena & Reggio Emilia, I-41100 Modena, Italy	University of Florence; Universita di Modena e Reggio Emilia	Seidenari, L (corresponding author), Univ Florence, Media Integrat & Commun Ctr, I-50139 Florence, Italy.	seidenari@dsi.unifi.it; giuseppe.serra@unimore.it; bagdanov@dsi.unifi.it; delbimbo@dsi.unifi.it	Serra, Giuseppe/M-3572-2015; Seidenari, Lorenzo/AAA-1848-2020; Bagdanov, Andrew/K-3932-2014	Serra, Giuseppe/0000-0002-4269-4501; Seidenari, Lorenzo/0000-0003-4816-0268; Bagdanov, Andrew/0000-0001-6408-7043; DEL BIMBO, ALBERTO/0000-0002-1052-8322				Bo L., 2009, P NIPS; Bo L., 2013, P CVPR; Boiman O., 2008, P CVPR; Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54; Cao L., 2012, P CVPR; Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32; Chatfield K., 2011, P RMVC; Dalal N., 2005, P CVPR; Duchenne O., 2011, P ICCV; Fei-Fei L., 2005, P CVPR; Gehler P. V., 2009, P ICCV; Grauman K, 2007, J MACH LEARN RES, V8, P725; Griffin G., CALTECH 256 OBJECT C; Lazebnik S., 2006, P IEEE C COMP VIS PA, P1; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Liu L., 2011, P ICCV; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; LYU S, 2005, P CVPR; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Parsana M., 2007, P NIPS; Perronnin F., 2010, P 11 ECCV CRET GREEC; Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111; Todorovic S., 2008, P CVPR; Tuytelaars T., 2011, P ICCV; van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154; Vedaldi A., 2010, P ACM MM FIR IT; Wang J., 2010, P CVPR; Yang J. C., 2009, P CVPR; Zhang C., 2011, P CVPR	30	39	40	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2014	36	5					1033	1040		10.1109/TPAMI.2013.232	http://dx.doi.org/10.1109/TPAMI.2013.232			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AH3VN	26353235				2022-12-18	WOS:000336054200016
J	Teboul, O; Kokkinos, I; Simon, L; Koutsourakis, P; Paragios, N				Teboul, Olivier; Kokkinos, Iasonas; Simon, Loic; Koutsourakis, Panagiotis; Paragios, Nikos			Parsing Facades with Shape Grammars and Reinforcement Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image arsing; shape grammar; reinforcement learning; semantic segmentation; data-driven exploration; Markov decision processes	SEGMENTATION	In this paper, we use shape grammars (SGs) for facade parsing, which amounts to segmenting 2D building facades into balconies, walls, windows, and doors in an architecturally meaningful manner. The main thrust of our work is the introduction of reinforcement learning (RL) techniques to deal with the computational complexity of the problem. RL provides us with techniques such as Q-learning and state aggregation which we exploit to efficiently solve facade parsing. We initially phrase the 1D parsing problem in terms of a Markov Decision Process, paving the way for the application of RL-based tools. We then develop novel techniques for the 2D shape parsing problem that take into account the specificities of the facade parsing problem. Specifically, we use state aggregation to enforce the symmetry of facade floors and demonstrate how to use RL to exploit bottom-up, image-based guidance during optimization. We provide systematic results on the Paris building dataset and obtain state-of-the-art results in a fraction of the time required by previous methods. We validate our method under diverse imaging conditions and make our software and results available online.	[Teboul, Olivier] Ecole Cent Paris, MAS Lab, F-92290 Chatenay Malabry, France; [Teboul, Olivier] Google Inc, BR-30170010 Belo Horizonte, MG, Brazil; [Kokkinos, Iasonas] Ecole Cent Paris, INRIA Saclay, F-92295 Chatenay Malabry, France; [Simon, Loic] Ecole Natl Super Ingn Caen, CNRS, GREYC UMR 6072, F-14050 Caen, France; [Koutsourakis, Panagiotis] Univ Crete, Ecole Cent Paris, F-92295 Chatenay Malabry, France; [Paragios, Nikos] Ecole Cent Paris, Ecole Ponts, ParisTech, INRIA Saclay, F-92295 Chatenay Malabry, France	UDICE-French Research Universities; Universite Paris Saclay; Google Incorporated; UDICE-French Research Universities; Universite Paris Saclay; Centre National de la Recherche Scientifique (CNRS); Universite de Caen Normandie; UDICE-French Research Universities; Universite Paris Saclay; Ecole des Ponts ParisTech; UDICE-French Research Universities; Universite Paris Saclay	Teboul, O (corresponding author), Ecole Cent Paris, MAS Lab, F-92290 Chatenay Malabry, France.	olivier.teboul@ecp.fr; iasonas.kokkinos@ecp.fr; loic.simon@ensicaen.fr; panagiotis.koutsourakis@ecp.fr; nikos.paragios@ecp.fr			Microsoft Research Cambridge	Microsoft Research Cambridge(Microsoft)	The authors would like to thank Microsoft Research Cambridge for support through the PhD scholarship program, Prof. Alan Yuille and Dr. Sylvain Lefebvre for helpful discussions, and the reviewers for their thorough and constructive criticism.	Alegre F., 2004, P INT WORKSH VIS TEC; Barto AG, 2003, DISCRETE EVENT DYN S, V13, P41, DOI 10.1023/A:1025696116075; Berg AC, 2007, IEEE I CONF COMP VIS, P2057; BLAKE A, 2004, P EUR C COMP VIS; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Cech J., 2008, P INT WORKSH COMB IM; Cech J, 2009, INT J IMAG SYST TECH, V19, P69, DOI 10.1002/ima.20181; Chen Y., 2007, SCI TECHNOLOGY; Dietterich TG, 2000, J ARTIF INTELL RES, V13, P227, DOI 10.1613/jair.639; Havemann S., 2005, THESIS BRAUNSCHWEIG; John Christopher, 1989, THESIS; Koutsourakis P., 2009, P IEEE INT C COMP VI; Lee S. C., 2004, P IEEE C COMP VIS PA, V1; Leung T., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P546, DOI 10.1007/BFb0015565; Liu C., 2010, INT J VIRTUAL REALIT, V9, P13; Liu YX, 2005, INT J COMPUT VISION, V62, P145, DOI 10.1007/s11263-005-4639-0; Marthi B., 2007, P 17 INT C AUT PLANN; Muller P, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276484, 10.1145/1239451.1239536]; Muller P, 2006, ACM T GRAPHIC, V25, P614, DOI 10.1145/1141911.1141931; Musialski P, 2009, P VIS MOD VIS WORKSH; Musialski P, 2012, COMPUT GRAPH FORUM, V31, P661, DOI 10.1111/j.1467-8659.2012.03045.x; Neu G, 2009, MACH LEARN, V77, P303, DOI 10.1007/s10994-009-5110-1; Ohta Y., 1978, P INT JOINT C PATT R, V1; Park M., 2010, P AS C COMP VIS; REZNIK S., 2007, INT ARCH PHOTOGRAMME, V36, P173; Ripperda N., 2009, PROC 12 AGILE C GISC, P1; SCHLESINGER M, 2002, 10 LECT STAT STRUCTU; Shen CH, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024218; Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1; Simon L., 2012, P IEEE C COMP VIS PA; STINY G, 1978, ENVIRON PLANN B, V5, P5, DOI 10.1068/b050005; Stiny G., 1972, Information Processing 71 Proceedings of the IFIP Congress 1971. Volume 2, P1460; Sutton RS, 2018, ADAPT COMPUT MACH LE, P1; TEBOUL O, 2010, PROC CVPR IEEE, P3105, DOI DOI 10.1109/CVPR.2010.5540068; Teoh S. T., 2009, P 5 EUR C COMP AESTH; Thrun S.B., 1992, EFFICIENT EXPLORATIO; Tighe J, 2010, LECT NOTES COMPUT SC, V6315, P352, DOI 10.1007/978-3-642-15555-0_26; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Tylecek R, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS); Weber B, 2009, COMPUT GRAPH FORUM, V28, P481, DOI 10.1111/j.1467-8659.2009.01387.x; Whiting E, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618458; Wonka P, 2003, ACM T GRAPHIC, V22, P669, DOI 10.1145/882262.882324; Zhu S.-C., 2000, P IEEE C COMP VIS PA; Zhu SC, 2006, FOUND TRENDS COMPUT, V2, P259, DOI 10.1561/0600000018	44	39	39	0	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2013	35	7					1744	1756		10.1109/TPAMI.2012.252	http://dx.doi.org/10.1109/TPAMI.2012.252			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	146AG	23682000				2022-12-18	WOS:000319060600016
J	Huang, S; Li, J; Ye, JP; Fleisher, A; Chen, KW; Wu, T; Reiman, E				Huang, Shuai; Li, Jing; Ye, Jieping; Fleisher, Adam; Chen, Kewei; Wu, Teresa; Reiman, Eric		Alzheimers Dis Neuroimaging Initia	A Sparse Structure Learning Algorithm for Gaussian Bayesian Network Identification from High-Dimensional Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian network; machine learning; data mining	ALZHEIMERS-DISEASE; FUNCTIONAL CONNECTIVITY; PROBABILISTIC NETWORKS; CAUSAL DISCOVERY; BELIEF NETWORKS; DISRUPTION; KNOWLEDGE; DEMENTIA	Structure learning of Bayesian Networks (BNs) is an important topic in machine learning. Driven by modern applications in genetics and brain sciences, accurate and efficient learning of large-scale BN structures from high-dimensional data becomes a challenging problem. To tackle this challenge, we propose a Sparse Bayesian Network (SBN) structure learning algorithm that employs a novel formulation involving one L1-norm penalty term to impose sparsity and another penalty term to ensure that the learned BN is a Directed Acyclic Graph (DAG)-a required property of BNs. Through both theoretical analysis and extensive experiments on 11 moderate and large benchmark networks with various sample sizes, we show that SBN leads to improved learning accuracy, scalability, and efficiency as compared with 10 existing popular BN learning algorithms. We apply SBN to a real-world application of brain connectivity modeling for Alzheimer's disease (AD) and reveal findings that could lead to advancements in AD research.	[Huang, Shuai; Li, Jing; Ye, Jieping; Wu, Teresa] Arizona State Univ, Sch Comp Informat & Decis Syst Engn, Tempe, AZ 85287 USA; [Fleisher, Adam; Chen, Kewei; Reiman, Eric] Banner Alzheimers Inst, Phoenix, AZ 85006 USA	Arizona State University; Arizona State University-Tempe; Banner Research; Banner Health; Banner Alzheimer's Institute	Huang, S (corresponding author), Arizona State Univ, Sch Comp Informat & Decis Syst Engn, POB 878809, Tempe, AZ 85287 USA.	jinglz@asu.edu	Chen, Kewei/P-6304-2015	Chen, Kewei/0000-0001-8497-3069	US National Science Foundation [CMMI-0825827, CMMI-1069246, MCB-1026710]; National Institutes of Health [1ROIGM096194-01]; Alzheimer's Disease Neuroimaging Initiative (ADNI); NIH [U01 AG024904]; National Institute on Aging; National Institute of Biomedical Imaging and Bioengineering (NIBIB); NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES [R01GM096194] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON AGING [U01AG024904] Funding Source: NIH RePORTER; Div Of Molecular and Cellular Bioscience [1026710] Funding Source: National Science Foundation	US National Science Foundation(National Science Foundation (NSF)); National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Alzheimer's Disease Neuroimaging Initiative (ADNI); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); National Institute on Aging(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Aging (NIA)); National Institute of Biomedical Imaging and Bioengineering (NIBIB)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS)); NATIONAL INSTITUTE ON AGING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Aging (NIA)); Div Of Molecular and Cellular Bioscience(National Science Foundation (NSF)NSF - Directorate for Biological Sciences (BIO))	This material is based in part on work supported by the US National Science Foundation under Grant No. CMMI-0825827, CMMI-1069246, MCB-1026710, and the National Institutes of Health under Grant No. 1ROIGM096194-01. Data collection and sharing for this project were funded by the Alzheimer's Disease Neuroimaging Initiative (ADNI; Principal Investigator: Michael Weiner; NIH grant U01 AG024904). ADNI is funded byt he National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering (NIBIB), and through generous contributions from the following: Pfizer Inc., Wyeth Research, Bristol-Myers Squibb, Eli Lilly and Company, GlaxoSmithKline, Merck & Co. Inc., AstraZeneca AB, Novartis Pharmaceuticals Corporation, Alzheimer'sAssociation, Eisai Global Clinical Development, Elan Corporation plc, Forest Laboratories, and the Institute for the Study of Aging, with participation from the US Food and Drug Administration. Industry partnerships are coordinated through the Foundation for the National Institutes of Health. The grantee organization is the Northern California Institute for Research and Education, and the study is coordinated by the Alzheimer's Disease Cooperative Study at the University of California, San Diego. ADNI data are disseminated by the Laboratory of Neuro Imaging at the University of California, Los Angeles.	Alexander GE, 2002, AM J PSYCHIAT, V159, P738, DOI 10.1176/appi.ajp.159.5.738; Aliferis C., 2003, P AMIA ANN S; Andrews-Hanna JR, 2007, NEURON, V56, P924, DOI 10.1016/j.neuron.2007.10.038; [Anonymous], 2011, BAYESIAN NETWORK REP; [Anonymous], 1992, NEURODEGENERATION; Bertsekas D. P., 1999, NONLINEAR PROGRAM, V2nd; Borsuk ME, 2004, ECOL MODEL, V173, P219, DOI 10.1016/j.ecolmodel.2003.08.020; Bouckaert R. R., 1993, Symbolic and Quantitative Approaches to Reasoning and Uncertainty. European Conference ECSQARU '93 Proceedings, P41, DOI 10.1007/BFb0028180; BRAAK H, 1993, EUR NEUROL, V33, P403, DOI 10.1159/000116984; Braak H, 1996, ACTA NEUROL SCAND, V93, P3; Buntine W, 1996, IEEE T KNOWL DATA EN, V8, P195, DOI 10.1109/69.494161; Castelo R., 2003, J MACHINE LEARNING R, V4, P527; Chen XW, 2008, IEEE T KNOWL DATA EN, V20, P628, DOI 10.1109/TKDE.2007.190732; Chickering D, 1995, P 5 INT WORKSH ART I; Chickering D. M., 2003, Journal of Machine Learning Research, V3, P507, DOI 10.1162/153244303321897717; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1023/A:1022649401552; Cormen T. H., 2009, INTRO ALGORITHMS, V3rd; Dai HH, 1997, INT JOINT CONF ARTIF, P1304; De Campos LM, 1998, J EXP THEOR ARTIF IN, V10, P511, DOI 10.1080/095281398146743; de Campos LM, 2000, INT J APPROX REASON, V24, P11, DOI 10.1016/S0888-613X(99)00042-0; Efron B., 1994, INTRO BOOTSTRAP; Estrada E, 2008, PHYS REV E, V77, DOI 10.1103/PhysRevE.77.036111; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Friedman N, 2003, MACH LEARN, V50, P95, DOI 10.1023/A:1020249912095; Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961; FRIEDMAN N, 1996, P 12 C UNC ART INT; Friedman N., 1999, P 15 C UNC ART INT; Friston Karl J., 1994, Human Brain Mapping, V2, P56, DOI 10.1002/hbm.460020107; Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712; Good PI, 2005, PERMUTATION PARAMETR; Gould RL, 2006, NEUROLOGY, V67, P1011, DOI 10.1212/01.wnl.0000237534.31734.1b; Greicius MD, 2004, P NATL ACAD SCI USA, V101, P4637, DOI 10.1073/pnas.0308627101; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; Heckerman D., 1996, MSRTR9506; Hedden T, 2009, J NEUROSCI, V29, P12686, DOI 10.1523/JNEUROSCI.3189-09.2009; Hoyer P., 2009, P C NEUR INF PROC SY; Ikonomovic MD, 2008, BRAIN, V131, P1630, DOI 10.1093/brain/awn016; Klunk WE, 2004, ANN NEUROL, V55, P306, DOI 10.1002/ana.20009; Korb K.B., 2004, COM SCI DAT; Larranaga P, 1996, IEEE T SYST MAN CY A, V26, P487, DOI 10.1109/3468.508827; Larranaga P, 1996, IEEE T PATTERN ANAL, V18, P912, DOI 10.1109/34.537345; Li J.N., 2008, NEUROIMAGE, V37, P749; Li J, 2007, IIE TRANS, V39, P681, DOI 10.1080/07408170600899532; Lipton AM, 2004, DEMENT GERIATR COGN, V17, P324, DOI 10.1159/000077164; Luus R, 1996, HUNG J IND CHEM, V24, P273; MACKEY D, 2003, INFORM THEORY INFERE; Mani S, 1999, J AM MED INFORM ASSN, P315; Marcot BG, 2001, FOREST ECOL MANAG, V153, P29, DOI 10.1016/S0378-1127(01)00452-2; Margaritis D., 1999, P C ADV NEUR INF PRO; Meek C., 1995, P 11 C UNC ART INT; Meinshausen N, 2010, J R STAT SOC B, V72, P417, DOI 10.1111/j.1467-9868.2010.00740.x; PEARL J, 1990, P 6 C UNC ART INT; Pellet JP, 2008, J MACH LEARN RES, V9, P1295; Peng J, 2009, J AM STAT ASSOC, V104, P735, DOI 10.1198/jasa.2009.0126; Rajapakse JC, 2007, NEUROIMAGE, V37, P749, DOI 10.1016/j.neuroimage.2007.06.003; Reuter-Lorenz PA, 2005, NEUROPSYCHOLOGIA, V43, P1307, DOI 10.1016/j.neuropsychologia.2004.12.007; Rodin AS, 2005, BIOINFORMATICS, V21, P3273, DOI 10.1093/bioinformatics/bti505; Schmidt M, 2007, P 22 NAT C ART INT; Spirtes P., 2000, CAUSATION PREDICTION; Sporns O, 2004, TRENDS COGN SCI, V8, P418, DOI 10.1016/j.tics.2004.07.008; Stern Y, 2006, ALZ DIS ASSOC DIS, V20, pS69, DOI 10.1097/00002093-200607001-00010; Supekar K, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000100; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tsamardinos I., 2003, P 9 INT WORKSH ART I; Tsamardinos I., 2006, P 19 INT FLAIRS C; Tsamardinos I, 2006, MACH LEARN, V65, P31, DOI 10.1007/s10994-006-6889-7; Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978; Wai Lam, 1994, Computational Intelligence, V10, P269, DOI 10.1111/j.1467-8640.1994.tb00166.x; Wang K, 2007, HUM BRAIN MAPP, V28, P967, DOI 10.1002/hbm.20324; Wu X, 2011, HUM BRAIN MAPP, V32, P1868, DOI 10.1002/hbm.21153; [No title captured]	73	39	52	4	58	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2013	35	6					1328	1342		10.1109/TPAMI.2012.129	http://dx.doi.org/10.1109/TPAMI.2012.129			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	129QV	22665720	Green Accepted			2022-12-18	WOS:000317857900005
J	Arashloo, SR; Kittler, J				Arashloo, Shervin Rahimzadeh; Kittler, Josef			Energy Normalization for Pose-Invariant Face Recognition Based on MRF Model Image Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Markov random fields; structural image analysis; image matching; face recognition; pose invariance	MINIMIZATION	A pose-invariant face recognition system based on an image matching method formulated on MRFs is presented. The method uses the energy of the established match between a pair of images as a measure of goodness-of-match. The method can tolerate moderate global spatial transformations between the gallery and the test images and alleviate the need for geometric preprocessing of facial images by encapsulating a registration step as part of the system. It requires no training on nonfrontal face images. A number of innovations, such as a dynamic block size and block shape adaptation, as well as label pruning and error prewhitening measures have been introduced to increase the effectiveness of the approach. The experimental evaluation of the method is performed on two publicly available databases. First, the method is tested on the rotation shots of the XM2VTS data set in a verification scenario. Next, the evaluation is conducted in an identification scenario on the CMU-PIE database. The method compares favorably with the existing 2D or 3D generative model-based methods on both databases in both identification and verification scenarios.	[Arashloo, Shervin Rahimzadeh; Kittler, Josef] Univ Surrey, Ctr Vis Speech & Signal Proc, Fac Engn & Phys Sci, Guildford GU2 7XH, Surrey, England	University of Surrey	Arashloo, SR (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Fac Engn & Phys Sci, Guildford GU2 7XH, Surrey, England.	sr00048@surrey.ac.uk; j.kittler@surrey.ac.uk	Arashloo, Shervin Rahimzadeh/A-6381-2019	Rahimzadeh Arashloo, Shervin/0000-0003-0189-4774				AHMADYFARD AR, 2000, P BRIT MACH VIS C, V2, P745; ARASHLOO S, 2010, 4 IEEE INT C BIOM TH, P1; ARASHLOO SR, 2009, P IEEE CS C COMP VIS, P56; Ashraf A.B., 2008, CVPR, P1, DOI DOI 10.1109/CVPR.2008.4587754; BEYMER DJ, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P756, DOI 10.1109/CVPR.1994.323893; BLANZ V, 2002, IEEE C AUT FAC GEST, P192; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; CASTILLO CD, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/MED.2007.4433726; Chai XJ, 2007, IEEE T IMAGE PROCESS, V16, P1716, DOI 10.1109/TIP.2007.899195; Chan CH, 2008, THESIS; Cootes T. F., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P227, DOI 10.1109/AFGR.2000.840639; Glocker B, 2007, LECT NOTES COMPUT SC, V4584, P408; Gonzalez-Jimenez D, 2007, IEEE T INF FOREN SEC, V2, P413, DOI 10.1109/TIFS.2007.903543; Gross R, 2004, IEEE T PATTERN ANAL, V26, P449, DOI 10.1109/TPAMI.2004.1265861; Huang J, 2007, IEEE T SYST MAN CY B, V37, P847, DOI 10.1109/TSMCB.2007.895328; Huang R, 2004, INT C PATT RECOG, P157, DOI 10.1109/ICPR.2004.1334492; Kanade T, 2003, 2003 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, VOLS I-III, PROCEEDINGS, P954; Kim TK, 2005, IEEE T PATTERN ANAL, V27, P318, DOI 10.1109/TPAMI.2005.58; Kisku DR, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P1150, DOI 10.1109/ICARCV.2008.4795683; KITTLER J, 1991, SPEECH RECOGNITION U, P537; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; Komodakis Nikos, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2985, DOI 10.1109/CVPRW.2009.5206846; Kumar MP, 2008, INT J COMPUT VISION, V76, P301, DOI 10.1007/s11263-007-0064-x; Messer K., 1999, 2 INT C AUDIO VIDEO, P965; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Park BG, 2005, IEEE T PATTERN ANAL, V27, P1982, DOI 10.1109/TPAMI.2005.243; PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814; PRESS WH, 1992, NUMERICAL RECIPES C, pCH15; Romdhani S, 2002, LECT NOTES COMPUT SC, V2353, P3; Rother C, 2009, PROC CVPR IEEE, P1382, DOI 10.1109/CVPRW.2009.5206739; Shekhovtsov A, 2007, PROC CVPR IEEE, P1800; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168; TENA J, 2007, P INT C VID SIGN BAS, P1; Tistarelli M, 2009, ADV PATTERN RECOGNIT, P1, DOI 10.1007/978-1-84882-385-3; WANG R, 2009, P 3 INT C ADV BIOM, P42; Werner T, 2008, PROC CVPR IEEE, P109; Zhang XZ, 2008, IEEE T INF FOREN SEC, V3, P684, DOI 10.1109/TIFS.2008.2004286; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; [No title captured]	40	39	41	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2011	33	6					1274	1280		10.1109/TPAMI.2010.209	http://dx.doi.org/10.1109/TPAMI.2010.209			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	750DE	21135436				2022-12-18	WOS:000289524000015
J	Thevenaz, P; Delgado-Gonzalo, R; Unser, M				Thevenaz, Philippe; Delgado-Gonzalo, Ricard; Unser, Michael			The Ovuscule	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Snakuscule; snake; dynamic contour; ellipse	HOUGH TRANSFORM; ELLIPSES; IMAGES; SEGMENTATION; OBJECTS	We propose an active contour (a.k.a. snake) that takes the shape of an ellipse. Its evolution is driven by surface terms made of two contributions: the integral of the data over an inner ellipse, counterbalanced by the integral of the data over an outer elliptical shell. We iteratively adapt the active contour to maximize the contrast between the two domains, which results in a snake that seeks elliptical bright blobs. We provide analytic expressions for the gradient of the snake with respect to its defining parameters, which allows for the use of efficient optimizers. An important contribution here is the parameterization of the ellipse which we define in such a way that all parameters have equal importance; this creates a favorable landscape for the proceedings of the optimizer. We validate our construct with synthetic data and illustrate its use on real data as well.	[Thevenaz, Philippe; Delgado-Gonzalo, Ricard; Unser, Michael] Ecole Polytech Fed Lausanne, EPFL STI IMT LIB, Stn 17, CH-1015 Lausanne, VD, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Thevenaz, P (corresponding author), Ecole Polytech Fed Lausanne, EPFL STI IMT LIB, Stn 17, CH-1015 Lausanne, VD, Switzerland.	philippe.thevenaz@epfl.ch; ricard.delgado@epfl.ch; michael.unser@epfl.ch	Delgado-Gonzalo, Ricard/K-9714-2019; Delgado-Gonzalo, Ricard/B-1090-2011; Unser, Michael/A-1550-2008	Delgado-Gonzalo, Ricard/0000-0002-7183-6257; 	Swiss SystemsX.ch initiative [2008/005]	Swiss SystemsX.ch initiative	This work was funded in part by the Swiss SystemsX.ch initiative under Grant 2008/005. This work is available as a plugin for ImageJ and can be downloaded from http://bigwww.epfl.ch/thevenaz/ovuscule.	BASCLE B, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P659, DOI 10.1109/ICPR.1992.202072; Bennett N, 1999, IEEE T PATTERN ANAL, V21, P652, DOI 10.1109/34.777377; BLOKLAND JAK, 1987, IEEE T MED IMAGING, V6, P57, DOI 10.1109/TMI.1987.4307798; BRIGHT DS, 1987, J MICROSC-OXFORD, V146, P191, DOI 10.1111/j.1365-2818.1987.tb01340.x; Cabrera J, 1996, IEEE T PATTERN ANAL, V18, P752, DOI 10.1109/34.506797; Dura E, 2008, IEEE J OCEANIC ENG, V33, P434, DOI 10.1109/JOE.2008.2002962; ESCOLANO F, 1997, P INT WORKSH EN MIN, P521; Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658; Fok YL, 1996, IEEE T MED IMAGING, V15, P353, DOI 10.1109/42.500144; Garrido A, 2000, PATTERN RECOGN, V33, P821, DOI 10.1016/S0031-3203(99)00091-6; Guerrero J, 2007, IEEE T MED IMAGING, V26, P1079, DOI 10.1109/TMI.2007.899180; Kass M., 1987, International Journal of Computer Vision, V1, P321, DOI 10.1007/BF00133570; Kharma N, 2007, IET IMAGE PROCESS, V1, P39, DOI 10.1049/iet-ipr:20045262; LI H, 2008, P 2 INT C BIOINF BIO, V2, P2526; LIPSON P, 1990, P 1 EUR C COMP VIS, P413; McLaughlin RA, 1998, IEEE T PATTERN ANAL, V20, P396, DOI 10.1109/34.677267; PEDOE D, 1970, AM MATH MON, V77, P711, DOI 10.2307/2316201; SHEPP LA, 1974, IEEE T NUCL SCI, VNS21, P21, DOI 10.1109/TNS.1974.6499235; Thevenaz P, 2008, IEEE T IMAGE PROCESS, V17, P585, DOI 10.1109/TIP.2007.914742; TSUJI S, 1978, IEEE T COMPUT, V27, P777, DOI 10.1109/TC.1978.1675191; Voss K, 1999, IEEE T PATTERN ANAL, V21, P646, DOI 10.1109/34.777376; WUEST J, 2008, EXPT TECHNIQUES  SEP; YAP C, 2008, P 4 INT S VIS COMP D, P582	23	39	40	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2011	33	2					382	393		10.1109/TPAMI.2010.112	http://dx.doi.org/10.1109/TPAMI.2010.112			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	694QR	20513925	Green Submitted			2022-12-18	WOS:000285313200013
J	Nedovic, V; Smeulders, AWM; Redert, A; Geusebroek, JM				Nedovic, Vladimir; Smeulders, Arnold W. M.; Redert, Andre; Geusebroek, Jan-Mark			Stages as Models of Scene Geometry	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Scene geometry; scene structure; depth estimation; scene categorization; stages	DEPTH; IMAGES; SHAPE	Reconstruction of 3D scene geometry is an important element for scene understanding, autonomous vehicle and robot navigation, image retrieval, and 3D television. We propose accounting for the inherent structure of the visual world when trying to solve the scene reconstruction problem. Consequently, we identify geometric scene categorization as the first step toward robust and efficient depth estimation from single images. We introduce 15 typical 3D scene geometries called stages, each with a unique depth profile, which roughly correspond to a large majority of broadcast video frames. Stage information serves as a first approximation of global depth, narrowing down the search space in depth estimation and object localization. We propose different sets of low-level features for depth estimation, and perform stage classification on two diverse data sets of television broadcasts. Classification results demonstrate that stages can often be efficiently learned from low-dimensional image representations.	[Nedovic, Vladimir; Smeulders, Arnold W. M.; Geusebroek, Jan-Mark] Univ Amsterdam, ISLA, NL-1098 XG Amsterdam, Netherlands; [Redert, Andre] Philips Res Labs, NL-5656 AE Eindhoven, Netherlands	University of Amsterdam; Philips; Philips Research	Nedovic, V (corresponding author), Univ Amsterdam, ISLA, Sci Pk 107, NL-1098 XG Amsterdam, Netherlands.	vnedovic@science.uva.nl; smeulders@science.uva.nl; andre.redert@philips.com; mark@science.uva.nl						Bajcsy R., 1976, COMPUT GRAPHICS IMAG, V5, P52, DOI DOI 10.1016/S0146-664X(76)80005-6; Barinova O., 2008, P EUR C COMP VIS; BARNARD S, 1986, P 5 NAT C ART INT; BARROW HG, 1981, ARTIF INTELL, V17, P75, DOI 10.1016/0004-3702(81)90021-7; Bosch A., 2006, P EUR C COMP VIS; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; COZMAN F, 1997, P IEEE C COMP VIS PA; DELAGE E, 2006, P IEEE C COMP VIS PA; Duda R.O., 2000, PATTERN CLASSIFICATI; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Geusebroek JM, 2005, INT J COMPUT VISION, V62, P7, DOI 10.1007/s11263-005-4632-7; Geusebroek JM, 2003, IEEE T IMAGE PROCESS, V12, P938, DOI 10.1109/TIP.2003.812429; HEBERT M., 2007, P IEEE INT C COMP VI; HOIEM D, 2005, P IEEE INT C COMP VI; HOIEM D, 2006, P IEEE C COMP VIS PA; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; Horn B.K.P., 1989, SHAPE SHADING; Huang J., 1999, P IEEE C COMP VIS PA; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; LIU X, 2008, P IEEE C COMP VIS PA; MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032; Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723; NEDOVIC V, 2007, P IEEE INT C COMP VI; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Palmer S., 1999, VISION SCI; PAYNE A, 2005, P INT C ADV PATT REC; QUELHAS P, 2005, P IEEE INT C COMP VI; RICHARDS W, 1996, PERCEPTION BAYESIAN, P80; RUDERMAN DL, 1994, PHYS REV LETT, V73, P814, DOI 10.1103/PhysRevLett.73.814; RUSSELL BC, 2009, P IEEE C COMP VIS PA; SAXENA A, 2005, P NEUR INF PROC SYST; Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y; SIVIC J, 2008, P 1 IEEE WORKSH INT; Smeaton A.F., 2006, P ACM INT WORKSH MUL; Snoek CGM, 2006, IEEE T PATTERN ANAL, V28, P1678, DOI 10.1109/TPAMI.2006.212; SNOEK CGM, 2008, P 6 TRECVID WORKSH; SUDDERTH EB, 2006, P IEEE C COMP VIS PA; Szummer M., 1998, P IEEE INT WORKSH CO; Torralba A, 2002, IEEE T PATTERN ANAL, V24, P1226, DOI 10.1109/TPAMI.2002.1033214; UIJLINGS JRR, 2009, P IEEE C COMP VIS PA; Vailaya A, 1998, PATTERN RECOGN, V31, P1921, DOI 10.1016/S0031-3203(98)00079-X; VANGEMERT J, 2006, P IEEE C COMP VIS PA; Yang ZY, 2003, NAT NEUROSCI, V6, P632, DOI 10.1038/nn1059; YEUNG M, 1996, P INT C MULT COMP SY; YU SX, 2008, P 6 IEEE WORKSH PERC	46	39	39	1	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2010	32	9					1673	1687		10.1109/TPAMI.2009.174	http://dx.doi.org/10.1109/TPAMI.2009.174			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	626MB	20634560				2022-12-18	WOS:000279969000010
J	Lin, LA; Liu, XB; Zhu, SC				Lin, Liang; Liu, Xiaobai; Zhu, Song-Chun			Layered Graph Matching with Composite Cluster Sampling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graph matching; graph partitioning; DDMCMC; cluster sampling	OBJECT RECOGNITION; SWENDSEN-WANG; SEGMENTATION	This paper presents a framework of layered graph matching for integrating graph partition and matching. The objective is to find an unknown number of corresponding graph structures in two images. We extract discriminative local primitives from both images and construct a candidacy graph whose vertices are matching candidates (i.e., a pair of primitives) and whose edges are either negative for mutual exclusion or positive for mutual consistence. Then we pose layered graph matching as a multicoloring problem on the candidacy graph and solve it using a composite cluster sampling algorithm. This algorithm assigns some vertices into a number of colors, each being a matched layer, and turns off all the remaining candidates. The algorithm iterates two steps: 1) Sampling the positive and negative edges probabilistically to form a composite cluster, which consists of a few mutually conflicting connected components (CCPs) in different colors and 2) assigning new colors to these CCPs with consistence and exclusion relations maintained, and the assignments are accepted by the Markov Chain Monte Carlo (MCMC) mechanism to preserve detailed balance. This framework demonstrates state-of-the-art performance on several applications, such as multi-object matching with large motion, shape matching and retrieval, and object localization in cluttered background.	[Lin, Liang] Sun Yat Sen Univ, Sch Software, Guangzhou Higher Educ Mega Ctr, Guangzhou 51000, Peoples R China; [Liu, Xiaobai] Lotus Hill Res Inst Comp Vis & Informat Sci, Ezhou 436000, Hubei, Peoples R China; [Zhu, Song-Chun] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA	Sun Yat Sen University; University of California System; University of California Los Angeles	Lin, LA (corresponding author), Sun Yat Sen Univ, Sch Software, Guangzhou Higher Educ Mega Ctr, 132 Waihuandong Rd, Guangzhou 51000, Peoples R China.	linliang@ieee.org; xbliu@lotushill.org; sczhu@stat.ucla.edu			US National Science Foundation (NSF) [IIS-0713652]; NSFC [60728203, 60970156]; China 863 [2007AA01Z340]	US National Science Foundation (NSF)(National Science Foundation (NSF)); NSFC(National Natural Science Foundation of China (NSFC)); China 863(National High Technology Research and Development Program of China)	The authors would like to thank Ziqiang Liu and Han Lv for their assistance in experiments, and they thank Lotus Hill Institute for the annotated data set. The work at UCLA is supported by the US National Science Foundation (NSF) grant IIS-0713652, and the work at LHI is supported by NSFC grants 60728203, 60970156, and a China 863 grant 2007AA01Z340.	Barbu A, 2005, IEEE T PATTERN ANAL, V27, P1239, DOI 10.1109/TPAMI.2005.161; Bay H, 2005, PROC CVPR IEEE, P329; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; EDWARDS RG, 1988, PHYS REV D, V38, P2009, DOI 10.1103/PhysRevD.38.2009; Felzenszwalb P., 2007, P IEEE C COMP VIS PA; Feris R, 2005, IEEE I CONF COMP VIS, P412; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Guo CE, 2007, COMPUT VIS IMAGE UND, V106, P5, DOI 10.1016/j.cviu.2005.09.004; Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850; LIN L, 2009, P IEEE C COMP VIS PA; Lin L, 2007, P INT C COMP VIS, V1, P419; LIN L, 2007, P IEEE C COMP VIS PA, V1, P885; Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41; Liu C., 2006, ADV NEURAL INFORM PR; LIU X, 2008, P IEEE C PATT REC; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Nister D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P199; PORWAY J, 2008, C4 STOCHASTIC INFERE; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; Sharp GC, 2002, IEEE T PATTERN ANAL, V24, P90, DOI 10.1109/34.982886; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Siddiqi K, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P222, DOI 10.1109/ICCV.1998.710722; Sim DG, 1999, IEEE T IMAGE PROCESS, V8, P425, DOI 10.1109/83.748897; Smith P, 2004, IEEE T PATTERN ANAL, V26, P479, DOI 10.1109/TPAMI.2004.1265863; SWENDSEN RH, 1987, PHYS REV LETT, V58, P86, DOI 10.1103/PhysRevLett.58.86; Todorovic S, 2008, IEEE T PATTERN ANAL, V30, P2158, DOI 10.1109/TPAMI.2008.24; Tu ZW, 2008, COMPUT VIS IMAGE UND, V109, P290, DOI 10.1016/j.cviu.2007.04.004; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Weiss Y, 1997, PROC CVPR IEEE, P520, DOI 10.1109/CVPR.1997.609375; Weiss Y., 1998, 1624 MIT AI; Wills J, 2006, INT J COMPUT VISION, V68, P125, DOI 10.1007/s11263-006-6660-3; Zhu SC, 1996, INT J COMPUT VISION, V20, P187	37	39	41	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2010	32	8					1426	1442		10.1109/TPAMI.2009.150	http://dx.doi.org/10.1109/TPAMI.2009.150			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	611XQ	20558875	Green Submitted			2022-12-18	WOS:000278858600006
J	Balagani, KS; Phoha, VV				Balagani, Kiran S.; Phoha, Vir V.			On the Feature Selection Criterion Based on an Approximation of Multidimensional Mutual Information	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature selection; entropy; mutual information; Bayes classification error; entropy estimation	CLASSIFICATION	We derive the feature selection criterion presented in [1] and [2] from the multidimensional mutual information between features and the class. Our derivation: 1) specifies and validates the lower-order dependency assumptions of the criterion and 2) mathematically justifies the utility of the criterion by relating it to Bayes classification error.	[Balagani, Kiran S.; Phoha, Vir V.] Louisiana Tech Univ, Ctr Secure Cyberspace, Ruston, LA 71272 USA	University of Louisiana System; Louisiana Technical University	Balagani, KS (corresponding author), Louisiana Tech Univ, Ctr Secure Cyberspace, Nethken Hall,600 W Arizona Ave, Ruston, LA 71272 USA.	ksb011@latech.edu; phoha@latech.edu		Phoha, Vir/0000-0002-5390-8253	Louisiana Board of Regents [LEQSF (2007-12)-ENH-PKSFI-PRS-03]	Louisiana Board of Regents	The authors thank the three anonymous reviewers for their comments. In particular, they are thankful to Reviewer 1 and Reviewer 2 for their insightful suggestions that improved the paper. This work was supported in part by the Louisiana Board of Regents under P-KSFI Grant LEQSF (2007-12)-ENH-PKSFI-PRS-03.	BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Beirlant J., 1997, INT J MATH STAT SCI, V6, P17; Bonev B, 2008, PATTERN ANAL APPL, V11, P309, DOI 10.1007/s10044-008-0107-0; Cover T, 2004, ELEMENTS INFORM THEO; HELLMAN ME, 1970, IEEE T INFORM THEORY, V16, P368, DOI 10.1109/TIT.1970.1054466; Hero AO, 2002, IEEE SIGNAL PROC MAG, V19, P85, DOI 10.1109/MSP.2002.1028355; Kwak N, 2002, IEEE T NEURAL NETWOR, V13, P143, DOI 10.1109/72.977291; LEWIS PM, 1962, IRE T INFORM THEOR, V8, P171, DOI 10.1109/TIT.1962.1057691; Neemuchwala H, 2005, SIGNAL PROCESS, V85, P277, DOI 10.1016/j.sigpro.2004.10.002; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159; Yang H., 1999, P INT ICSC S ADV INT, P22	12	39	41	1	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2010	32	7					1342	1343		10.1109/TPAMI.2010.62	http://dx.doi.org/10.1109/TPAMI.2010.62			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	595YC	20489237				2022-12-18	WOS:000277649100017
J	Ward, AD; Hamarneh, G				Ward, Aaron D.; Hamarneh, Ghassan			The Groupwise Medial Axis Transform for Fuzzy Skeletonization and Pruning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Skeletonization; pruning; medial axis transform; object retrieval; shape analysis; medical image analysis; graph matching; groupwise information	3D; SHAPE	Medial representations of shapes are useful due to their use of an object-centered coordinate system that directly captures intuitive notions of shape such as thickness, bending, and elongation. However, it is well known that an object's medial axis transform (MAT) is unstable with respect to small perturbations of its boundary. This instability results in additional, unwanted branches in the skeletons, which must be pruned in order to recover the portions of the skeletons arising purely from the uncorrupted shape information. Almost all approaches to skeleton pruning compute a significance measure for each branch according to some heuristic criteria, and then prune the least significant branches first. Current approaches to branch significance computation can be classified as either local, solely using information from a neighborhood surrounding each branch, or global, using information about the shape as a whole. In this paper, we propose a third, groupwise approach to branch significance computation. We develop a groupwise skeletonization framework that yields a fuzzy significance measure for each branch, derived from information provided by the group of shapes. We call this framework the Groupwise Medial Axis Transform (G-MAT). We propose and evaluate four groupwise methods for computing branch significance and report superior performance compared to a recent, leading method. We measure the performance of each pruning algorithm using denoising, classification, and within-class skeleton similarity measures. This research has several applications, including object retrieval and shape analysis.	[Ward, Aaron D.] Univ Western Ontario, Robarts Res Inst, London, ON N6A 5K8, Canada; [Hamarneh, Ghassan] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada	Western University (University of Western Ontario); Simon Fraser University	Ward, AD (corresponding author), Univ Western Ontario, Robarts Res Inst, POB 5015,100 Perth Dr, London, ON N6A 5K8, Canada.	ward@robarts.ca; hamarneh@cs.sfu.ca	Ward, Aaron/B-4950-2015; Hamarneh, Ghassan/B-1063-2009; Hamarneh, Ghassan/AAE-6673-2021	Hamarneh, Ghassan/0000-0001-5040-7448	Natural Sciences and Engineering Research Council (NSERC) of Canada; Michael Smith Foundation for Health Research (MSFHR) of British Columbia	Natural Sciences and Engineering Research Council (NSERC) of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)); Michael Smith Foundation for Health Research (MSFHR) of British Columbia(Michael Smith Foundation for Health Research)	The authors would like to acknowledge the generous funding provided in support of this work by the Natural Sciences and Engineering Research Council (NSERC) of Canada and the Michael Smith Foundation for Health Research (MSFHR) of British Columbia. The authors would also like to thank Ms. Lisa Tang and Mr. Oliver van Kaick for their helpful proofreading of the manuscript. They also thank the Delft University of Technology for the use of their PRTools machine learning toolbox for MATLAB, as well as Markus Buehren for his MATLAB code implementing the Hungarian algorithm for bipartite graph matching. Finally, they would like to thank the reviewers and the editor for their constructive comments, which have served to greatly improve this manuscript.	Bai X, 2007, IEEE T PATTERN ANAL, V29, P449, DOI 10.1109/TPAMI.2007.59; Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154; Choi WP, 2003, PATTERN RECOGN, V36, P721, DOI 10.1016/S0031-3203(02)00098-5; David S, 2002, J SUSTAIN AGR, V21, P5, DOI 10.1300/J064v21n02_03; Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793; Golland P, 2000, PROC CVPR IEEE, P10, DOI 10.1109/CVPR.2000.855792; Hamarneh G., 2004, International Journal of Shape Modeling, V10, P187, DOI 10.1142/S0218654304000663; HAMARNEH G, 2007, P IEEE INT S BIOM IM, P1232; HAN Q, 2004, P INT S BIOM IM APR, P1251; HAN Q, 2007, P INF PROC MED IM, P751; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Katz RA, 2003, INT J COMPUT VISION, V55, P139, DOI 10.1023/A:1026183017197; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; LEE SW, 1993, PATTERN RECOGN, V7, P1203; NAEF M, 1996, P WORKSH MATH METH B, P139; OGNIEWICZ RL, 1995, PATTERN RECOGN, V28, P343, DOI 10.1016/0031-3203(94)00105-U; Pizer SM, 2003, INT J COMPUT VISION, V55, P85, DOI 10.1023/A:1026313132218; Pizer SM, 2003, P IEEE, V91, P1670, DOI 10.1109/JPROC.2003.817876; RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150; RUTOVITZ D, 1966, J R STAT SOC SER A-G, V129, P504, DOI 10.2307/2982255; Saha PK, 1996, COMPUT VIS IMAGE UND, V63, P418, DOI 10.1006/cviu.1996.0032; Salkind N., 2007, ENCY MEASUREMENT STA; Shaked D, 1998, COMPUT VIS IMAGE UND, V69, P156, DOI 10.1006/cviu.1997.0598; Sharma A, 2007, PATTERN RECOGN LETT, V28, P1151, DOI 10.1016/j.patrec.2007.01.012; Sharvit D, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P56, DOI 10.1109/IVL.1998.694496; Siddiqi K, 2008, COMPUT IMAGING VIS, V37, P1, DOI 10.1007/978-1-4020-8658-8; Siddiqi K, 2008, MACH VISION APPL, V19, P261, DOI 10.1007/s00138-007-0097-8; Styner M, 2003, INT J COMPUT VISION, V55, P107, DOI 10.1023/A:1026378916288; STYNER M, 2001, THESIS U N CAROLINA; WARD AD, 2007, P SPIE INT SOC OPT E; Yushkevich P, 2003, IMAGE VISION COMPUT, V21, P17, DOI 10.1016/S0262-8856(02)00135-X; [No title captured]	33	39	40	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2010	32	6					1084	1096		10.1109/TPAMI.2009.81	http://dx.doi.org/10.1109/TPAMI.2009.81			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	583JU	20431133	Green Submitted			2022-12-18	WOS:000276671900010
J	Wu, TP; Tang, CK				Wu, Tai-Pang; Tang, Chi-Keung			Photometric Stereo via Expectation Maximization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Photometric stereo; expectation maximization; normal; albedo and visible surface reconstruction	SURFACES; SHAPE	This paper presents a robust and automatic approach to photometric stereo, where the two main components, namely surface normals and visible surfaces, are respectively optimized by Expectation Maximization (EM). A dense set of input images is conveniently captured using a digital video camera while a handheld spotlight is being moved around the target object and a small mirror sphere. In our approach, the inherently complex optimization problem is simplified into a two-step optimization, where EM is employed in each step: 1) Using the dense input, the weight or importance of each observation is alternately optimized with the normal and albedo at each pixel and 2) using the optimized normals and employing the Markov Random Fields (MRFs), surface integrabilities and discontinuities are alternately optimized in visible surface reconstruction. Our mathematical derivation gives simple updating rules for the EM algorithms, leading to a stable, practical, and parameter-free implementation that is very robust even in the presence of complex geometry, shadows, highlight, and transparency. We present high-quality results on normal and visible surface reconstruction, where fine geometric details are automatically recovered by our method.	[Wu, Tai-Pang; Tang, Chi-Keung] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China	Hong Kong University of Science & Technology	Wu, TP (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China.	pang@cs.ust.hk; cktang@cs.ust.hk			Hong Kong Research Grant Council [620309]	Hong Kong Research Grant Council(Hong Kong Research Grants Council)	The authors would like to thank all of the anonymous reviewers for their thoughtful comments and constructive suggestions. This research is supported by the Hong Kong Research Grant Council (grant number 620309).	Agrawal A, 2005, IEEE I CONF COMP VIS, P174, DOI 10.1109/ICCV.2005.31; AGRAWAL A, 2006, P EUR C COMP VIS, P578; Barsky S, 2003, IEEE T PATTERN ANAL, V25, P1239, DOI 10.1109/TPAMI.2003.1233898; Basri R, 2001, PROC CVPR IEEE, P374; Bilmes JA, 1997, ICSITR97021; Chung H.-S., 2008, P IEEE C COMP VIS PA; COLEMAN EN, 1982, COMPUT VISION GRAPH, V18, P309, DOI 10.1016/0146-664X(82)90001-6; Forsyth David A, 2012, COMPUTER VISION MODE; Frankot R. T., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P118; Georghiades AS, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P816; GOLDMAN DB, 2005, P INT C COMP VIS OCT; Hertzmann A, 2003, PROC CVPR IEEE, P533; Horn B., 1986, ROBOT VISION, P1; Horn B.K., 1978, DETERMINING SHAPE RE; HSIEH JW, 1995, GRAPH MODEL IM PROC, V57, P343, DOI 10.1006/gmip.1995.1030; Karacali B, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P525; Karacali B, 2003, COMPUT VIS IMAGE UND, V92, P78, DOI 10.1016/S1077-3142(03)00095-X; Kay G, 1995, GRAPH MODEL IM PROC, V57, P365, DOI 10.1006/gmip.1995.1032; Kovesi P, 2005, IEEE I CONF COMP VIS, P994; NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P418, DOI 10.1109/70.59367; Petrovic N, 2001, PROC CVPR IEEE, P743; SIMCHONY T, 1990, IEEE T PATTERN ANAL, V12, P435, DOI 10.1109/34.55103; Solomon F, 1996, IEEE T PATTERN ANAL, V18, P449, DOI 10.1109/34.491627; TAGARE HD, 1991, IEEE T PATTERN ANAL, V13, P133, DOI 10.1109/34.67643; Tang KL, 2005, PROC CVPR IEEE, P132; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; Verbiest F, 2008, PROC CVPR IEEE, P2886; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Wu TP, 2006, IEEE T PATTERN ANAL, V28, P1830, DOI 10.1109/TPAMI.2006.224; Wu TP, 2005, PROC CVPR IEEE, P140; WU TP, 2006, P EUR C COMP VIS, V4, P159; WU TP, 2006, P IEEE C COMP VIS PA, V2, P1793	32	39	40	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2010	32	3					546	560		10.1109/TPAMI.2009.15	http://dx.doi.org/10.1109/TPAMI.2009.15			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	543WG	20075477				2022-12-18	WOS:000273609600011
J	Lee, HS; Kim, D				Lee, Hyung-Soo; Kim, Daijin			Tensor-Based AAM with Continuous Variation Estimation: Application to Variation-Robust Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Tensor algebra; multilinear analysis; AAM; indirect AAM feature transformation; variation-robust face recognition	APPEARANCE; SEARCH	The Active appearance model (AAM) is a well-known model that can represent a nonrigid object effectively. However, because it uses a fixed model of shape and appearance, the fitting result is often unsatisfactory when an input image deviates from the training images. To obtain more robust AAM fitting, we propose a tensor-based AAM that can handle a variety of subjects, poses, expressions, and illuminations in the tensor algebra framework. It consists of an image tensor and a model tensor. The image tensor is used to estimate image variations such as pose, expression, and illumination of the input image. Here, we introduce two different variation estimation approaches: discrete and continuous variation estimation. Then, the model tensor generates a variation-specific AAM from a tensor representation, using the estimation results. This process ensures more accurate fitting results. To validate the usefulness of the tensor-based AAM, we performed variation-robust face recognition using the tensor-based AAM fitting results. To do this, we propose indirect AAM feature transformation. Experimental results show that the tensor-based AAM with continuous variation estimation outperforms that with discrete variation estimation and conventional AAM in terms of the average fitting error and the face recognition rate.	[Lee, Hyung-Soo] Olaworks Inc, Res Lab, Seoul 135924, South Korea; [Kim, Daijin] Pohang Univ Sci & Technol POSTECH, Dept Comp Sci & Engn, Pohang 790784, South Korea	Pohang University of Science & Technology (POSTECH)	Lee, HS (corresponding author), Olaworks Inc, Res Lab, 738-1,Yeoksam 1 Dong, Seoul 135924, South Korea.	sooz@olaworks.com; dkim@postech.ac.kr			Korea Science and Engineering Foundation ( KOSEF); Yonsei University [R112002105070030(2008)]; Intelligent Robotics Development Program; Ministry of Commerce, Industry, and Energy (MOCIE)	Korea Science and Engineering Foundation ( KOSEF)(Korea Science and Engineering Foundation); Yonsei University; Intelligent Robotics Development Program; Ministry of Commerce, Industry, and Energy (MOCIE)(Ministry of Trade, Industry & Energy (MOTIE), Republic of Korea)	This work was supported by the Korea Science and Engineering Foundation ( KOSEF) through the Biometrics Engineering Research Center (BERC) at Yonsei University (R112002105070030(2008)). This work was also supported by the Intelligent Robotics Development Program, one of the 21st Century Frontier R&D Programs funded by the Ministry of Commerce, Industry, and Energy (MOCIE).	ABBOUD B, 2004, P WORKSH IM AN MULT; Beichel R, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P589, DOI 10.1109/ICIP.2001.958561; Chen HF, 2000, PROC CVPR IEEE, P254, DOI 10.1109/CVPR.2000.855827; Christoudias CM, 2006, COMPUT VIS IMAGE UND, V104, P16, DOI 10.1016/j.cviu.2006.06.001; Christoudias CM, 2005, PROC CVPR IEEE, P1067; CHRISTOUDIAS CM, 2004, P EUR C COMP VIS, P481; Cootes T. F., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P227, DOI 10.1109/AFGR.2000.840639; Cootes TF, 2001, PROC CVPR IEEE, P1114; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; COOTES TF, 1998, P EUR C COMP VIS, V2, P484; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1324, DOI 10.1137/S0895479898346995; Donner R, 2006, IEEE T PATTERN ANAL, V28, P1690, DOI 10.1109/TPAMI.2006.206; Du YZ, 2003, PATTERN RECOGN LETT, V24, P2923, DOI 10.1016/S0167-8655(03)00153-3; EDWARDS GJ, 1998, P EUR C COMP VIS, V2, P581; Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009; Jun B, 2007, LECT NOTES COMPUT SC, V4642, P29; Lee H.-S., 2008, P IEEE INT C AUT FAC; LEE HS, 2007, P PAC RIM C MULT, P675; Lee HS, 2008, PATTERN RECOGN LETT, V29, P1797, DOI 10.1016/j.patrec.2008.05.012; Lee HS, 2008, IEEE SIGNAL PROC LET, V15, P565, DOI 10.1109/LSP.2008.2001116; Lee S, 2007, PHYSOCARPUS GENERA V, P538; Li Y, 2005, IEEE I CONF COMP VIS, P114; LIN D, 2005, P INT C IM PROC; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; Lucey S, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P155; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; MATTHEWS I, 2003, LUCAS KANADE 20 YE 3; Park SW, 2007, IEEE T SYST MAN CY B, V37, P1156, DOI 10.1109/TSMCB.2007.904575; Scott IM, 2003, LECT NOTES COMPUT SC, V2732, P258; Stegmann MB, 2003, IEEE T MED IMAGING, V22, P1319, DOI 10.1109/TMI.2003.817780; Sung JW, 2006, IEEE IMAGE PROC, P2781, DOI 10.1109/ICIP.2006.313124; Sung JW, 2007, INT J COMPUT VISION, V75, P297, DOI 10.1007/s11263-006-0034-8; SUNG JW, 2006, P INT C PATT REC; Vasilescu M.A.O., 2002, P EUR C COMP VIS, P447; VASILESCU MAO, 2002, P INT C PATT REC; Xiaoming L., 2007, P IEEE C COMP VIS PA, P1; Yan S., 2002, P INT WORKSH GEN MOD; Yan SC, 2003, INT J IMAG SYST TECH, V13, P106, DOI 10.1002/ima.10039	39	39	46	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2009	31	6					1102	1116		10.1109/TPAMI.2008.286	http://dx.doi.org/10.1109/TPAMI.2008.286			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431YF	19372613				2022-12-18	WOS:000265100000011
J	Li, YH; Dong, M; Hua, J				Li, Yuanhong; Dong, Ming; Hua, Jing			Simultaneous Localized Feature Selection and Model Detection for Gaussian Mixtures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Unsupervised; localized; feature selection; Bayesian		In this paper, we propose a novel approach of simultaneous localized feature selection and model detection for unsupervised learning. In our approach, local feature saliency, together with other parameters of Gaussian mixtures, are estimated by Bayesian variational learning. Experiments performed on both synthetic and real-world data sets demonstrate that our approach is superior over both global feature selection and subspace clustering methods.	[Li, Yuanhong; Dong, Ming] Wayne State Univ, Dept Comp Sci, Machine Vis & Pattern Recognit Lab, Detroit, MI 48202 USA; [Hua, Jing] Wayne State Univ, Dept Comp Sci, Graph & Imaging Lab, Detroit, MI 48202 USA	Wayne State University; Wayne State University	Li, YH (corresponding author), Wayne State Univ, Dept Comp Sci, Machine Vis & Pattern Recognit Lab, Detroit, MI 48202 USA.	yhli@wayne.edu; mdong@cs.wayne.edu; jinghua@cs.wayne.edu			US National Science Foundation [IIS-0713315, CNS-0751045]; State of Michigan [06-1-P1-0193]	US National Science Foundation(National Science Foundation (NSF)); State of Michigan	This research was partially funded by the US National Science Foundation under grants IIS-0713315 and CNS-0751045 and by the 21st Century Jobs Fund Award, State of Michigan, under grant: 06-1-P1-0193.	AGGARWALA KR, 1999, EUROPEAN OPTICAL SOC, V23, P61; Asuncion A, 2007, UCI MACHINE LEARNING; AVIDAN S, 2004, P IEEE C COMP VIS PA; Baumgartner C, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P11, DOI 10.1109/ICDM.2004.10112; Bishop C. M., 2006, PATTERN RECOGN; Chang S, 2005, PROC CVPR IEEE, P1043; Constantinopoulos C, 2006, IEEE T PATTERN ANAL, V28, P1013, DOI 10.1109/TPAMI.2006.111; Dash M, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P115, DOI 10.1109/ICDM.2002.1183893; Dash M., 2000, P PAC AS C KNOWL DIS, P110; Dong M, 2003, PATTERN RECOGN LETT, V24, P1215, DOI 10.1016/S0167-8655(02)00303-3; Duda R.O., 2000, PATTERN CLASSIFICATI; Dy JG, 2004, J MACH LEARN RES, V5, P845; Friedman JH, 2004, J R STAT SOC B, V66, P815, DOI 10.1111/j.1467-9868.2004.02059.x; Graham MW, 2006, IEEE T SIGNAL PROCES, V54, P1289, DOI 10.1109/TSP.2006.870586; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Ke QF, 2004, PROC CVPR IEEE, P592; Law MHC, 2004, IEEE T PATTERN ANAL, V26, P1154, DOI 10.1109/TPAMI.2004.71; Li YH, 2008, PATTERN RECOGN LETT, V29, P10, DOI 10.1016/j.patrec.2007.08.012; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491, DOI 10.1109/TKDE.2005.66; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133; Parsons L., 2004, ACM SIGKDD EXPLOR NE, V6, P90, DOI [10.1145/1007730.1007731, DOI 10.1145/1007730.1007731]; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159; Raftery AE, 2006, J AM STAT ASSOC, V101, P168, DOI 10.1198/016214506000000113; REGE M, 2006, P IEEE INT C DAT MIN; Singhi S.K., 2006, P 23 INT C MACH LEAR, DOI 10.1145/1143844.1143951; Wang W, 1998, P ACM SIGMOD INT C M, P186; WU Y, 2004, P IEEE C COMP VIS PA; ZHA H, 2001, P 10 INT C INF KNOWL, P25, DOI DOI 10.1109/ICDM.2008.91	28	39	39	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2009	31	5					953	960		10.1109/TPAMI.2008.261	http://dx.doi.org/10.1109/TPAMI.2008.261			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	418JM	19299867				2022-12-18	WOS:000264144500015
J	Yang, L				Yang, Li			Alignment of overlapping locally scaled patches for multidimensional scaling and dimensionality reduction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						dimensionality reduction; least squares approximation; manifold learning; model alignment; multidimensional scaling	INTRINSIC DIMENSIONALITY; EIGENMAPS	Data observations that lie on a manifold can be approximated by a collection of overlapping local patches, the alignment of which in a low-dimensional euclidean space provides an embedding of the data. This paper describes an embedding method using classical multidimensional scaling as a local model based on the fact that a manifold locally resembles a euclidean space. A set of overlapping neighborhoods are chosen by a greedy approximation algorithm of minimum set cover. Local patches derived from the set of overlapping neighborhoods by classical multidimensional scaling are aligned in order to minimize a residual measure, which has a quadratic form of the resulting global coordinates and can be minimized analytically by solving an eigenvalue problem. This method requires only distances within each neighborhood and provides locally isometric embedding results. The size of the eigenvalue problem scales with the number of overlapping neighborhoods rather than the number of data points. Experiments on both synthetic and real-world data sets demonstrate the effectiveness of this method. Extensions and variations of the method are discussed.	Western Michigan Univ, Dept Comp Sci, Kalamazoo, MI 49008 USA	Western Michigan University	Yang, L (corresponding author), Western Michigan Univ, Dept Comp Sci, Kalamazoo, MI 49008 USA.	li.yang@wmich.edu						Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; BENGIO Y, 2003, P ADV NEUR INF PROC, V16; BENNETT RS, 1969, IEEE T INFORM THEORY, V15, P517, DOI 10.1109/TIT.1969.1054365; Cox T.F., 2001, MULTIDIMENSIONAL SCA, V2nd; Cramer J.S., 2003, ORIGINS LOGISTIC REG; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100; EDMONDS J, 1972, J ACM, V19, P248, DOI 10.1145/321694.321699; Even S., 1975, SIAM Journal on Computing, V4, P507, DOI 10.1137/0204043; Feige U, 1998, J ACM, V45, P634, DOI 10.1145/285055.285059; Ford L. R. J., 1962, FLOWS NETWORKS; FUKUNAGA K, 1971, IEEE T COMPUT, VC 20, P176, DOI 10.1109/T-C.1971.223208; Garey M.R., 1979, COMPUTERS INTRACTABI; Horn R. A., 1986, MATRIX ANAL; Karp RM., 1972, COMPLEXITY COMPUTER, P85; KEGL B, 2002, P ADV NEUR INF PROC, V15; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; LUNG C, 1994, J ACM, V41, P960; NIEMANN H, 1979, IEEE T COMPUT, V28, P142, DOI 10.1109/TC.1979.1675303; PETTIS KW, 1979, IEEE T PATTERN ANAL, V1, P25, DOI 10.1109/TPAMI.1979.4766873; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268; TEH YW, 2002, P ADV NEUR INF PROC; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TRUNK GV, 1976, IEEE T COMPUT, V25, P165, DOI 10.1109/TC.1976.5009231; VERBEEK J, 2003, P NEURAL INF PROC SY, V16; VERVEER PJ, 1995, IEEE T PATTERN ANAL, V17, P81, DOI 10.1109/34.368147; Yang L, 2006, IEEE T PATTERN ANAL, V28, P827, DOI 10.1109/TPAMI.2006.89; Yang L, 2005, IEEE T PATTERN ANAL, V27, P1680, DOI 10.1109/TPAMI.2005.192; YANG L, 2005, PATTERN RECOGN, V26, P2015; Yang L, 2006, INT C PATT RECOG, P202	31	39	46	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2008	30	3					438	450		10.1109/TPAMI.2007.70706	http://dx.doi.org/10.1109/TPAMI.2007.70706			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	250FT	18195438				2022-12-18	WOS:000252286100006
J	Athitsos, V; Alon, J; Sclaroff, S; Kollios, G				Athitsos, Vassilis; Alon, Jonathan; Sclaroff, Stan; Kollios, George			BoostMap: An embedding method for efficient nearest neighbor retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						indexing methods; embedding methods; similarity matching; multimedia databases; nearest neighbor retrieval; nearest neighbor classification; noneuclidean spaces	SIMILARITY SEARCH; METRIC-SPACES; TIME; DISTANCE	This paper describes BoostMap, a method for efficient nearest neighbor retrieval under computationally expensive distance measures. Database and query objects are embedded into a vector space in which distances can be measured efficiently. Each embedding is treated as a classifier that predicts for any three objects X, A, B whether X is closer to A or to B. It is shown that a linear combination of such embedding-based classifiers naturally corresponds to an embedding and a distance measure. Based on this property, the BoostMap method reduces the problem of embedding construction to the classical boosting problem of combining many weak classifiers into an optimized strong classifier. The classification accuracy of the resulting strong classifier is a direct measure of the amount of nearest neighbor structure preserved by the embedding. An important property of BoostMap is that the embedding optimization criterion is equally valid in both metric and nonmetric spaces. Performance is evaluated in databases of hand images, handwritten digits, and time series. In all cases, BoostMap significantly improves retrieval efficiency with small losses in accuracy compared to brute-force search. Moreover, BoostMap significantly outperforms existing nearest neighbor retrieval methods such as Lipschitz embeddings, FastMap, and VP-trees.	Univ Texas, Comp Sci & Engn Dept, Arlington, TX 76019 USA; Boston Univ, Dept Comp Sci, Boston, MA 02215 USA	University of Texas System; University of Texas Arlington; Boston University	Athitsos, V (corresponding author), Univ Texas, Comp Sci & Engn Dept, 416 Yales St, Arlington, TX 76019 USA.	athitsos@uta.edu; jalon@cs.bu.edu; sclaroff@cs.bu.edu; gkollios@cs.bu.edu	Athitsos, Vassilis/AAF-8496-2020					Alon J, 2005, PROC INT CONF DOC, P839, DOI 10.1109/ICDAR.2005.177; Athitsos V, 2005, PROC CVPR IEEE, P486; Athitsos V, 2004, PROC CVPR IEEE, P268; Athitsos V, 2003, PROC CVPR IEEE, P432; Athitsos V., 2005, P ACM SIGMOD INT C M, P706; ATHITSOS V, 2006, THESIS BOSTON U; ATHITSOS V, 2005, P IEEE WORKSH LEARN; Bahlmann C, 2004, IEEE T PATTERN ANAL, V26, P299, DOI 10.1109/TPAMI.2004.1262308; Barrow HG, 1977, P 5 INT JOINT C ART; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bohm C, 2001, ACM COMPUT SURV, V33, P322, DOI 10.1145/502807.502809; Bozkaya T, 1999, ACM T DATABASE SYST, V24, P361, DOI 10.1145/328939.328959; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CHAKRABARTI K, 2000, P 26 INT C VER LARG, P89; Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; *CUR LAB, 2002, POS 5 REF MAN; Devi VS, 2002, PATTERN RECOGN, V35, P505, DOI 10.1016/S0031-3203(00)00184-9; Egecioglu O., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P219, DOI 10.1145/354756.354822; Faloutsos C., 1995, P 1995 ACM SIGMOD IN, P163; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Frome A, 2004, LECT NOTES COMPUT SC, V3023, P224; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Grauman K, 2004, PROC CVPR IEEE, P220; GUYON I, 1994, INT C PATT RECOG, P29, DOI 10.1109/ICPR.1994.576870; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; Hjaltason GR, 2003, ACM T DATABASE SYST, V28, P517, DOI 10.1145/958942.958948; Hjaltason GR, 2003, IEEE T PATTERN ANAL, V25, P530, DOI 10.1109/TPAMI.2003.1195989; Hristescu G., 1999, 9950 RUTG U COMP SCI; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; KANTH KVR, 1998, P ACM SIGMOD INT C M, P166; Keogh E., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P406; Koudas N, 2004, PROC INT CONF DATA, P6, DOI 10.1109/ICDE.2004.1319980; Kruskall J. B., 1983, TIME WARPS; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Levenshtein V. I, 1966, SOV PHYS DOKL, V10, P707; Li C, 2002, IEEE T KNOWL DATA EN, V14, P792, DOI 10.1109/TKDE.2002.1019214; Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68; Linial N., 1994, Proceedings. 35th Annual Symposium on Foundations of Computer Science (Cat. No.94CH35717), P577, DOI 10.1109/SFCS.1994.365733; Liu T., 2004, P ACM SIGKDD INT C K, P629; LIU T, 2003, NEURAL INFORM PROCES; MICO ML, 1994, PATTERN RECOGN LETT, V15, P9, DOI 10.1016/0167-8655(94)90095-7; Mori G, 2001, PROC CVPR IEEE, P723; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Sahinalp SC, 2003, PROC INT CONF DATA, P125, DOI 10.1109/ICDE.2003.1260787; Sakurai Y, 2000, P 26 INT C VER LARG, P516; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Traina C, 2000, LECT NOTES COMPUT SC, V1777, P51; Tuncel E., 2002, P 10 ACM INT C MULT, P543; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; VIDAL E, 1994, PATTERN RECOGN LETT, V15, P1, DOI 10.1016/0167-8655(94)90094-9; Vlachos M, 2003, P 9 ACM SIGKDD INT C, P216, DOI DOI 10.1145/956750.956777; WANG X, 2000, KNOWL INF SYST, V2, P161; Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194; Weber R, 2000, LECT NOTES COMPUT SC, V1777, P21; White DA, 1996, P SOC PHOTO-OPT INS, V2670, P62, DOI 10.1117/12.234810; Yi BK, 1998, PROC INT CONF DATA, P201, DOI 10.1109/ICDE.1998.655778; YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311; Young F.W., 1987, MULTIDIMENSIONAL SCA; Yuan Q, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P250; Zezula P, 1998, VLDB J, V7, P275, DOI 10.1007/s007780050069; Zhang H, 2003, PROC CVPR IEEE, P242	67	39	40	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2008	30	1					89	104		10.1109/TPAMI.2007.1140	http://dx.doi.org/10.1109/TPAMI.2007.1140			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	229YW	18000327	Green Submitted			2022-12-18	WOS:000250843500008
J	Wu, Y; Yu, T				Wu, Y; Yu, T			A field model for human detection and tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object detection; shape; Markov random fields; image models; machine learning; statistical computing; probabilistic algorithms		The large shape variability and partial occlusions challenge most object detection and tracking methods for nonrigid targets such as pedestrians. This paper presents a new approach based on a two-layer statistical field model that characterizes the prior of the complex shape variations as a Boltzmann distribution and embeds this prior and the complex image likelihood into a Markov field. A probabilistic variational analysis of this model reveals a set of fixed-point equations characterizing the equilibrium of the field. It leads to computationally efficient methods for calculating the image likelihood and for training the model. Based on that, effective algorithms for detecting nonrigid objects are developed. This new approach has several advantages. First, it is intrinsically suitable for capturing local nonrigidity. In addition, due to the distributed likelihood, this approach is robust to partial occlusions. Moreover, the two-layer structure provides large flexibility of modeling the image observations, which makes the new method robust to clutters. Extensive experiments demonstrate its effectiveness.	Northwestern Univ, Dept Elect & Comp Engn, Evanston, IL 60208 USA	Northwestern University	Wu, Y (corresponding author), Northwestern Univ, Dept Elect & Comp Engn, 2145 Sheridan Rd, Evanston, IL 60208 USA.	yingwu@ece.northwestern.edu; tingyu@ece.northwestern.edu	Wu, Ying/B-7283-2009					Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733; Collins RT, 2000, IEEE T PATTERN ANAL, V22, P745, DOI 10.1109/TPAMI.2000.868676; COUGHLAN J, 2002, ECCV, V3, P453; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; GAVRILA DM, 1999, P IEEE INT C COMP VI, P87, DOI DOI 10.1109/ICCV.1999.791202; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Haritaoglu I, 1998, INT C PATT RECOG, P77, DOI 10.1109/ICPR.1998.711084; ISARD M, 1996, P EUR C COMP VIS, P343; Jaakkola TS, 2000, TUTORIAL VARIATIONAL; Jojic N, 2000, PROC CVPR IEEE, P26, DOI 10.1109/CVPR.2000.854728; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Kass M., 1987, International Journal of Computer Vision, V1, P321, DOI 10.1007/BF00133570; Leibe B, 2005, PROC CVPR IEEE, P878; Liu YC, 2001, CHINESE J ASTRON AST, V1, P281, DOI 10.1088/1009-9271/1/3/281; MacCormick J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P572, DOI 10.1109/ICCV.1999.791275; Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571; Oren M, 1997, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.1997.609319; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689; Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226; Pentland A, 2000, IEEE T PATTERN ANAL, V22, P107, DOI 10.1109/34.824823; Peterson C., 1987, Complex Systems, V1, P995; Ramanan D, 2003, PROC CVPR IEEE, P467; Rangarajan A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P671; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895; SCLAROFF S, 1995, IEEE T PATTERN ANAL, V17, P545, DOI 10.1109/34.387502; Toyama K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P50, DOI 10.1109/ICCV.2001.937599; Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Weiss Y, 2000, NEURAL COMPUT, V12, P1, DOI 10.1162/089976600300015880; Wu Y, 2005, PROC CVPR IEEE, P1023; YUILLE AL, 1991, J COGNITIVE NEUROSCI, V3, P59, DOI 10.1162/jocn.1991.3.1.59; Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420	40	39	41	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2006	28	5					753	765		10.1109/TPAMI.2006.87	http://dx.doi.org/10.1109/TPAMI.2006.87			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	020CO	16640261	Green Submitted			2022-12-18	WOS:000235885700007
J	Tong, WS; Tang, CK				Tong, WS; Tang, CK			Robust estimation of adaptive tensors of curvature by tensor voting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						curvature; curvature tensor; tensor voting	RANGE DATA; 3D DATA; SEGMENTATION; REPRESENTATION	Although curvature estimation from a given mesh or regularly sampled point set is a well-studied problem, it is still challenging when the input consists of a cloud of unstructured points corrupted by misalignment error and outlier noise. Such input is ubiquitous in computer vision. In this paper, we propose a three-pass tensor voting algorithm to robustly estimate curvature tensors, from which accurate principal curvatures and directions can be calculated. Our quantitative estimation is an improvement over the previous two-pass algorithm, where only qualitative curvature estimation (sign of Gaussian curvature) is performed. To overcome misalignment errors, our improved method automatically corrects input point locations at subvoxel precision, which also rejects outliers that are uncorrectable. To adapt to different scales locally, we define the RadiusHit of a curvature tensor to quantify estimation accuracy and applicability. Our curvature estimation algorithm has been proven with detailed quantitative experiments, performing better in a variety of standard error metrics (percentage error in curvature magnitudes, absolute angle difference in curvature direction) in the presence of a large amount of misalignment noise.	Hong Kong Univ Sci & Technol, Dept Comp Sci, Vis & Graph Grp, Hong Kong, Hong Kong, Peoples R China	Hong Kong University of Science & Technology	Tong, WS (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci, Vis & Graph Grp, Clear Water Bay, Hong Kong, Hong Kong, Peoples R China.	cstws@cs.ust.hk; cktang@cs.ust.hk						Angelopoulou E, 1997, PROC CVPR IEEE, P432, DOI 10.1109/CVPR.1997.609361; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; Carmo M. P., 1976, DIFFERENTIAL GEOMETR, V2nd; Charlebois M, 1996, IEEE INT CONF ROBOT, P3502, DOI 10.1109/ROBOT.1996.509246; DOUROS I, 2002, SCANN 2002 P MAY; DUDEK G, 1997, COMPUTER VISION IMAG, P170; FAN TJ, 1989, DESCRIBING RECOGNIZI; Flynn P. J., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P110, DOI 10.1109/CVPR.1989.37837; Huber DF, 2003, IMAGE VISION COMPUT, V21, P637, DOI 10.1016/S0262-8856(03)00060-X; KARBACHER S, 1998, SPIE P, P168; Khaneja N, 1998, IEEE T PATTERN ANAL, V20, P1260, DOI 10.1109/34.730559; MALLADI R, 2002, P 7 EUR C COMP VIS; MARTIN R, 1998, INT J SHAPE MODELING, P99; Medioni G., 2000, COMPUTATIONAL FRAMEW; PAGE DL, 2001, P IEEE INT C COMP VI; Petitjean S, 2002, ACM COMPUT SURV, V34, P211, DOI 10.1145/508352.508354; RIEGER B, 2002, P 16 INT C PATT REC; SANDER PT, 1990, IEEE T PATTERN ANAL, V12, P833, DOI 10.1109/34.57680; SANDER PT, 1986, P 8 INT C PATT REC P, P1165; Tang CK, 2002, IEEE T PATTERN ANAL, V24, P858, DOI 10.1109/TPAMI.2002.1008395; Tang CK, 2001, IEEE T PATTERN ANAL, V23, P829, DOI 10.1109/34.946987; TANG CK, 1999, P 7 INT C COMP VIS K, P426; TAUBIN G, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P902, DOI 10.1109/ICCV.1995.466840; TONG WS, 2004, MULTISCALE TENSOR VO; TONG WS, 2004, ROBUST ESTIMATION AD; TRUCCO E, 1995, IEEE T PATTERN ANAL, V17, P177, DOI 10.1109/34.368172; VEMURI BC, 1986, IMAGE VISION COMPUT, V4, P107, DOI 10.1016/0262-8856(86)90029-6; Yang M, 1999, COMPUT AIDED DESIGN, V31, P449, DOI 10.1016/S0010-4485(99)00042-1; YUEN P, 1999, P BRIT MACH VIS C, P133	29	39	45	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2005	27	3					434	449		10.1109/TPAMI.2005.62	http://dx.doi.org/10.1109/TPAMI.2005.62			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	887IW	15747797				2022-12-18	WOS:000226300200011
J	Fredembach, C; Schroder, M; Susstrunk, S				Fredembach, C; Schroder, M; Susstrunk, S			Eigenregions for image classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						eigenregions; image classification; region analysis; image features	RETRIEVAL; SEGMENTATION	For certain databases and classification tasks, analyzing images based on region features instead of image features results in more accurate classifications. We introduce eigenregions, which are geometrical features that encompass area, location, and shape properties of an image region, even if the region is spatially incoherent. Eigenregions are calculated using principal component analysis (PCA). On a database of 77,000 different regions obtained through the segmentation of 13,500 real-scene photographic images taken by nonprofessionals, eigenregions improved the detection of localized image classes by a noticeable amount. Additionally, eigenregions allow us to prove that the largest variance in natural image region geometry is due to its area and not to shape or position.	Univ E Anglia, Sch Comp Sci, Norwich NR4 9TJ, Norfolk, England; Swiss Technol Consulting Grp AG, Zurich, Switzerland; Swiss Fed Inst Technol EPFL, Audiovisual Commun Lab LCAV, Lausanne, Switzerland	University of East Anglia; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Fredembach, C (corresponding author), Univ E Anglia, Sch Comp Sci, Norwich NR4 9TJ, Norfolk, England.	clement.fredembach@a3.epfl.ch; michael.schroeder@alumni.ethz.ch	Süsstrunk, Sabine/I-2466-2013					Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; Chang SF, 1997, IEEE SIGNAL PROC MAG, V14, P45, DOI 10.1109/79.598595; CHEN YQ, 1995, THESIS U SOUTHAMPTON; Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238; Fredembach C, 2003, ELEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING - SYSTEMS, TECHNOLOGIES, APPLICATIONS, P59; FREDEMBACH C, 2003, THESIS EPFL; Fuh CS, 2000, IEEE T IMAGE PROCESS, V9, P156, DOI 10.1109/83.817608; Fukunaga K., 1993, HDB PATTERN RECOGNIT, P30; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Jain A. K., 1989, FUNDAMENTALS DIGITAL; Ma WY, 2000, IEEE T IMAGE PROCESS, V9, P1375, DOI 10.1109/83.855433; *MPEG REQ GROUP, 2001, ISOIECJTC1SC29WG11N2; Palus H, 2002, CGIV'2002: FIRST EUROPEAN CONFERENCE ON COLOUR IN GRAPHICS, IMAGING, AND VISION, CONFERENCE PROCEEDINGS, P259; Pun T, 1996, PATTERN RECOGN LETT, V17, P1299, DOI 10.1016/0167-8655(96)84923-3; Ramamoorthi R, 2002, IEEE T PATTERN ANAL, V24, P1322, DOI 10.1109/TPAMI.2002.1039204; Schroder M, 2001, NINTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P41; SCHRODER M, 2000, THESIS ETHZ; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Smits PC, 2000, IEEE T GEOSCI REMOTE, V38, P1484, DOI 10.1109/36.843048; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wyszecki G., 1982, COLOR SCI CONCEPT ME	21	39	42	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2004	26	12					1645	1649		10.1109/TPAMI.2004.123	http://dx.doi.org/10.1109/TPAMI.2004.123			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	861AO	15573825	Green Submitted			2022-12-18	WOS:000224388700010
J	Pun, CM; Lee, MC				Pun, CM; Lee, MC			Extraction of shift invariant wavelet features for classification of images with different sizes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shift invariance; wavelet packet transform; normalization; image classification	ZERO-CROSSINGS; TEXTURE CLASSIFICATION; TRANSLATION-INVARIANT; SCALE; ROTATION; DECOMPOSITION; ALGORITHMS	An effective shift invariant wavelet feature extraction method for classification of images with different sizes is proposed. The feature extraction process involves a normalization followed by an adaptive shift invariant wavelet packet transform. An energy signature is computed for each subband of these invariant wavelet coefficients. A reduced subset of energy signatures is selected as the feature vector for classification of images with different sizes. Experimental results show that the proposed method can achieve high classification accuracy of 98.5 percent and outperforms the other two image classification methods.	Univ Macau, Fac Sci & Technol, Dept Comp & Informat Sci, Macau, Peoples R China; Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China	University of Macau; Chinese University of Hong Kong	Pun, CM (corresponding author), Univ Macau, Fac Sci & Technol, Dept Comp & Informat Sci, Macau, Peoples R China.	cmpun@umac.no; mclee@cse.cuhk.edu.hk	Pun, Chi Man/GRJ-3703-2022	Pun, Chi-Man/0000-0003-1788-3746				BAO F, 1994, P 19 IEEE INT C AC S, P3; BENNO SA, 1995, INT CONF ACOUST SPEE, P1097, DOI 10.1109/ICASSP.1995.480426; BERMAN Z, 1993, IEEE T SIGNAL PROCES, V41, P3216, DOI 10.1109/78.258069; BEYLKIN G, 1992, SIAM J NUMER ANAL, V29, P1716, DOI 10.1137/0729097; Brodatz P., 1966, TEXTURE PHOTOGRAPHIC; BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353; Chen GY, 1999, PATTERN RECOGN, V32, P1083, DOI 10.1016/S0031-3203(98)00148-4; CHEN JL, 1994, IEEE T PATTERN ANAL, V16, P208, DOI 10.1109/34.273730; COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P192, DOI 10.1109/34.67648; Cohen I, 1997, SIGNAL PROCESS, V57, P251, DOI 10.1016/S0165-1684(97)00007-8; Coifman R. R., 1995, TRANSLATION INVARIAN, P125, DOI [DOI 10.1007/978-1-4612-2544-7_9, 10.1007/978-1-4612-2544-7]; COIFMAN RR, 1992, IEEE T INFORM THEORY, V38, P713, DOI 10.1109/18.119732; DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705; Daubechies I., 1992, 10 LECT WAVELETS, V61; HUMMEL R, 1989, IEEE T ACOUST SPEECH, V37, P2111, DOI 10.1109/29.45555; KHOTANZAD A, 1990, IEEE T ACOUST SPEECH, V38, P1028, DOI 10.1109/29.56063; LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679; LEUNG M, 1991, P INT C AC SPEECH SI, P461; Liang J, 1996, IEEE T SIGNAL PROCES, V44, P225, DOI 10.1109/78.485919; MALLAT S, 1991, IEEE T INFORM THEORY, V37, P1019, DOI 10.1109/18.86995; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; PERANTONIS SJ, 1992, IEEE T NEURAL NETWOR, V3, P241, DOI 10.1109/72.125865; Pesquet JC, 1996, IEEE T SIGNAL PROCES, V44, P1964, DOI 10.1109/78.533717; Pun CM, 2003, IEEE T PATTERN ANAL, V25, P590, DOI 10.1109/TPAMI.2003.1195993; RASHKOVSKIY O, 1994, P SOC PHOTO-OPT INS, V2237, P390, DOI 10.1117/12.169445; RIOUL O, 1992, IEEE T INFORM THEORY, V38, P569, DOI 10.1109/18.119724; SAITO N, 1993, IEEE T SIGNAL PROCES, V41, P3584, DOI 10.1109/78.258102; Schalkoff R, 1992, PATTERN RECOGN; SIMONCELLI EP, 1992, IEEE T INFORM THEORY, V38, P587, DOI 10.1109/18.119725; Wu WR, 1996, IEEE T IMAGE PROCESS, V5, P1423, DOI 10.1109/83.536891; Xiong HL, 2000, IEEE T IMAGE PROCESS, V9, P2100, DOI 10.1109/83.887977; YOU J, 1993, PATTERN RECOGN, V26, P245, DOI 10.1016/0031-3203(93)90033-S	34	39	41	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2004	26	9					1228	1233		10.1109/TPAMI.2004.67	http://dx.doi.org/10.1109/TPAMI.2004.67			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	837CM	15742897				2022-12-18	WOS:000222605100011
J	Giblin, PJ; Kimia, BB				Giblin, PJ; Kimia, BB			On the intrinsic reconstruction of shape from its symmetries	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape; reconstruction; shape modeling; symmetry set shocks; medial axis; medial geometry; shock dynamics		The main question we address is: What is the minimal information required to generate closed, nonintersecting planar boundaries? For this paper, we restrict "shape" to this meaning. More precisely, we examine whether the medial axis, together with dynamics, can serve as a language to design shapes and to effect shape changes, e.g., for modeling, to generate a morph sequence, etc. We represent the medial axis together with a direction of flow along the axis as the shock graph and examine the reconstruction of shape along each of the three types of medial axis points, (labeled A(1)(2), A(1)(3), A(3); see below for the A notation) and the associated six types of shock points. First, we show that the tangent and curvature of the medial axis and the speed and acceleration of the shock with respect to time of propagation, i.e., first and second order geometric and dynamic properties, are sufficient to determine the boundary tangent and curvature at corresponding points of the boundary. This implies that a rather coarse sampling of the symmetry axis, its tangent, curvature, speed, and acceleration is sufficient to regenerate accurately a local neighborhood of shape at regular axis points (A(1)(2)). We also show how higher order differential properties of the axis can be related to the higher-order differential properties of the boundary of the same order. Second, we examine the reconstruction of shape at branch points (A(1)(3)) where three regular branches are joined. We show that the three pairs of geometry (that is, curvature) and dynamics (that is, acceleration) must satisfy certain constraints. Finally, we derive similar results for the end points of shock branches (A(3) points). These formulas completely specify the local reconstruction of a shape from its shock-graph or medial axis and the conditions required to form a coherent shape from the medial axis.	Univ Liverpool, Dept Math Sci, Liverpool L69 3BX, Merseyside, England; Brown Univ, Div Engn, Providence, RI 02912 USA	University of Liverpool; Brown University	Giblin, PJ (corresponding author), Univ Liverpool, Dept Math Sci, Liverpool L69 3BX, Merseyside, England.	pjgiblin@liv.ac.uk; kimia@lems.brown.edu						BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; FLETCHER T, 2001, TR01004 U N CAR DEP; Fritsch D, 1997, LECT NOTES COMPUT SC, V1230, P127; Giblin P, 2000, PROC CVPR IEEE, P566, DOI 10.1109/CVPR.2000.855870; Giblin P. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P385, DOI 10.1109/ICCV.1999.791246; Giblin P. J., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P79, DOI 10.1109/CVPR.1999.784612; IGARASHI T, 1998, COMMUNICATION; Kimia BB, 1997, P SOC PHOTO-OPT INS, V3229, P288, DOI 10.1117/12.290349; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; PIZER S, 2000, IEEE T MED IMAGING; PIZER SM, 2000, MED IMAGE ANAL; PLANKERS R, 2001, COMPUTER VISION IMAG, V81; Sebastian T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P755, DOI 10.1109/ICCV.2001.937602; Shaked D, 1996, COMPUT VIS IMAGE UND, V63, P367, DOI 10.1006/cviu.1996.0026; Sharvit D, 1998, J VIS COMMUN IMAGE R, V9, P366, DOI 10.1006/jvci.1998.0396; SHEN J, 1995, P IMPL SURF; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; Siddiqi K, 1996, PROC CVPR IEEE, P507, DOI 10.1109/CVPR.1996.517119; Siddiqi K, 1996, PERCEPTION, V25, P399, DOI 10.1068/p250399; Siddiqi K, 2001, VISION RES, V41, P1153, DOI 10.1016/S0042-6989(00)00274-1; SIERSMA D, 1999, GEOMETRY TOPOLOGY CA, V50, P267; TEICHMANN STM, 1998, P SIGGRAPH; TEK H, 1999, THESIS BROWN U PROVI; Thalmann D, 1996, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P166, DOI 10.1109/CGI.1996.511798; Zeleznik R. C., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P163, DOI 10.1145/237170.237238; ZUCKER SW, 1999, P ASS RES VIS OPHTH	27	39	39	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2003	25	7					895	911		10.1109/TPAMI.2003.1206518	http://dx.doi.org/10.1109/TPAMI.2003.1206518			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	692NN					2022-12-18	WOS:000183667300011
J	Rao, NSV				Rao, NSV			On fusers that perform better than best sensor	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						sensor fusion; multiple sensor system; information fusion; fusion rule estimation	EMPIRICAL RISK MINIMIZATION; NONPARAMETRIC-ESTIMATION; LEARNING ALGORITHMS; NEURAL NETWORKS; CLASSIFICATION; CLASSIFIERS; COMBINATION; FUSION	In a multiple sensor system, sensor S-i, i = 1, 2.... N, outputs Y((i)) epsilon [0, 1], according to an unknown probability distribution P-Y141 \X, in response to input X epsilon [0, 1]. We choose a fuser-that combines the outputs of sensors-from a function class F = {f: [0, 1](N)--> [0, 1]} by minimizing empirical error based on an iid sample. If F satisfies the isolation property, we show that the fuser performs at least as well as the best sensor in a probably approximately correct sense. Several well-known fusers, such as linear combinations, special potential functions, and certain feedforward networks, satisfy the isolation property.	Oak Ridge Natl Lab, Div Math & Comp Sci, Oak Ridge, TN 37831 USA	United States Department of Energy (DOE); Oak Ridge National Laboratory	Rao, NSV (corresponding author), Oak Ridge Natl Lab, Div Math & Comp Sci, Oak Ridge, TN 37831 USA.	nrao@icesar.epm.ornl.gov	Rao, Nageswara/H-8707-2019	Rao, Nageswara/0000-0002-3408-5941				ABIDI M, 1992, DATA FUSION ROBOTICS; AIZERMAN MA, 1970, AM MATH SOC TRANSL, V87, P281; Ali KM, 1996, MACH LEARN, V24, P173, DOI 10.1023/A:1018249309965; Billingsley P., 1986, PROBABILITY MEASURE; Breiman L, 1996, MACH LEARN, V24, P49; Breiman L, 1998, ANN STAT, V26, P801; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; CESABIANCHI N, 1995, J ACM, P382; Gada EF, 2000, NEURAL NETWORKS, V13, P485, DOI 10.1016/S0893-6080(00)00024-1; Hashem S, 1997, NEURAL NETWORKS, V10, P599, DOI 10.1016/S0893-6080(96)00098-6; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Krzyzak A, 1996, IEEE T NEURAL NETWOR, V7, P475, DOI 10.1109/72.485681; LUGOSI G, 1995, IEEE T INFORM THEORY, V41, P677, DOI 10.1109/18.382014; Madan RN, 1999, J FRANKLIN I, V336, P199; MASS W, 1995, NEURAL COMPUT, V7, P1054; MERZ CJ, 1997, MACH LEARN, V36, P9; Mojirsheibani M, 1997, STAT PROBABIL LETT, V36, P43, DOI 10.1016/S0167-7152(97)00047-3; PERNONE M, 1993, NEURAL NETWORKS SPEE; POLLARD D, 1987, CONVERGENCE STOCHAST; Rao N. S. V., 2000, Information Fusion, V1, P35, DOI 10.1016/S1566-2535(00)00004-X; Rao NSV, 1996, IEEE T NEURAL NETWOR, V7, P926, DOI 10.1109/72.508936; RAO NSV, 1994, IEEE T SYST MAN CYB, V24, P319, DOI 10.1109/21.281430; Rao NSV, 1998, NEURAL PROCESS LETT, V7, P125, DOI 10.1023/A:1009640613940; Rao NSV, 1999, J FRANKLIN I, V336, P285, DOI 10.1016/S0016-0032(98)00022-2; RAO NSV, 1998, P SPIE C SENS FUS AR, V2, P25; RAO NSV, 2000, MULTISENSOR FUSION; ROYCHOWDHURY V, 1994, THEORETICAL ADV NEUR; Schaffer C., 1994, MACHINE LEARNING P, P259, DOI DOI 10.1016/B978-1-55860-335-6.50039-8; SCHAPIRE R, 1997, P 14 INT C MACH LEAR; SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760; Sharf BF, 1997, HEALTH COMMUN, V9, P1, DOI 10.1207/s15327027hc0901_1; Sharp M, 1996, NATO ASI S 4 SCI TEC, V8, P3; Taniguchi M, 1997, NEURAL COMPUT, V9, P1163, DOI 10.1162/neco.1997.9.5.1163; Tumer K., 1996, Connection Science, V8, P385, DOI 10.1080/095400996116839; Ueda N, 2000, IEEE T PATTERN ANAL, V22, P207, DOI 10.1109/34.825759; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vapnik V., 1982, ESTIMATION DEPENDENC; Varshney P. K., 1997, DISTRIBUTED DETECTIO; WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1; Woods K, 1997, IEEE T PATTERN ANAL, V19, P405, DOI 10.1109/34.588027	45	39	40	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2001	23	8					904	909		10.1109/34.946993	http://dx.doi.org/10.1109/34.946993			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	460AH					2022-12-18	WOS:000170283300010
J	Faugeras, O; Quan, L; Strum, P				Faugeras, O; Quan, L; Strum, P			Self-calibration of a 1D projective camera and its application to the self-calibration of a 2D projective camera	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						vision geometry; camera model; self-calibration; planar motion; 1D camera	MOVING CAMERA; CORRESPONDENCES; AFFINE	We introduce the concept of self-calibration of a 1D projective camera from point correspondences, and describe a method for uniquely determining the two internal parameters of a 1D camera, based on the trifocal tensor of three 1D images. The method requires the estimation of the trifocal tensor which can be achieved linearly with no approximation unlike the trifocal tensor of 2D images and solving for the roots of a cubic polynomial in one variable. Interestingly enough, we prove that a 2D camera undergoing planar motion reduces to a 1D camera. From this observation, we deduce a new method for self-calibrating a 2D camera using planar motions. Both the self-calibration method for a 1D camera and its applications for 2D camera calibration are demonstrated on real image sequences.	INRIA, F-06902 Sophia Antipolis, France; CNRS, INRIA, ZIRST, F-38330 Montbonnot St Martin, France	Inria; Centre National de la Recherche Scientifique (CNRS); Inria	Faugeras, O (corresponding author), INRIA, 2004,Route Lucioles,BP 93, F-06902 Sophia Antipolis, France.	Oliver.Faugeras@sophia.inria.fr; Long.Quan@inrialpes.fr; Peter.Strum@inrialpes.fr						ARMSTRONG M, 1996, P 4 EUR C COMP VIS C, P3; ARMSTRONG MN, 1996, THESIS U OXFORD; ASTROM K, 1996, THESIS LUND U; BEARDSLEY PA, 1995, PROCEEDINGS OF EUROPE-CHINA WORKSHOP ON GEOMETRICAL MODELING & INVARIANTS FOR COMPUTER VISION, P214; BUCHANAN T, 1988, COMPUT VISION GRAPH, V42, P130, DOI 10.1016/0734-189X(88)90146-6; Faugeras O., 1995, Proceedings IEEE Workshop on Representation of Visual Scenes (In Conjunction with ICCV'95) (Cat. No.95TB8126), P37, DOI 10.1109/WVRS.1995.476850; FAUGERAS O, 1995, J OPT SOC AM A, V12, P465, DOI 10.1364/JOSAA.12.000465; FAUGERAS O, 1987, P INT WORKSH MACH VI; FAUGERAS O, 1998, P EUR C COMP VIS JUN; FAUGERAS OD, 1990, INT J COMPUT VISION, V4, P225, DOI 10.1007/BF00054997; HARTLEY RI, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P882, DOI 10.1109/ICCV.1995.466843; HARTLEY RI, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1064; HARTLEY RI, 1993, P 2 EUR US WORKSH IN, P187; HEYDEN A, 1996, P 4 EUR C COMP VIS, P671; HEYDEN A, 1998, P 5 EUR C COMP VIS F, P3; HEYDEN A, 1995, THESIS LUND U; Luong QT, 1997, INT J COMPUT VISION, V22, P261, DOI 10.1023/A:1007982716991; MAYBANK SJ, 1992, INT J COMPUT VISION, V8, P123, DOI 10.1007/BF00127171; Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705; Quan L, 1997, IEEE T PATTERN ANAL, V19, P834, DOI 10.1109/34.608285; Semple J.G, 1952, ALGEBRAIC PROJECTIVE; SHASHUA A, 1995, IEEE T PATTERN ANAL, V17, P779, DOI 10.1109/34.400567; SPETSAKIS M, 1990, P DARPA IM UND WORKS, P271; STURM P, 1997, THESIS INPG DEC; Torr PHS, 1997, MACH VISION APPL, V9, P321, DOI 10.1007/s001380050051; Triggs B, 1997, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.1997.609388; TRIGGS B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P338, DOI 10.1109/ICCV.1995.466920; ZELLER C, 1996, 2793 INRIA; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4	29	39	42	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2000	22	10					1179	1185		10.1109/34.879801	http://dx.doi.org/10.1109/34.879801			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	369LQ		Green Submitted			2022-12-18	WOS:000165067100011
J	Wang, H; Bell, D; Murtagh, F				Wang, H; Bell, D; Murtagh, F			Axiomatic approach to feature subset selection based on relevance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						machine learning; knowledge discovery; feature subset selection; relevance; entropy	OCCAM	Relevance has traditionally been linked with feature subset selection, but formalization of this link has not been attempted. In this paper. we propose two axioms for feature subset selection-sufficiency axiom and necessity axiom-based on which this link is formalized: The expected feature subset is the one which maximizes relevance. Finding the expected feature subset turns out to be NP-hard. We then devise a heuristic algorithm to find the expected subset which has a polynomial time complexity. The experimental results show that the algorithm finds good enough subset of features which, when presented to C4.5, results in better prediction accuracy.	Univ Ulster, Fac Informat, Sch Informat & Software Engn, Newtownabbey BT37 0QB, North Ireland	Ulster University	Wang, H (corresponding author), Univ Ulster, Fac Informat, Sch Informat & Software Engn, Shore Rd, Newtownabbey BT37 0QB, North Ireland.			Wang, Hui/0000-0003-2633-6015				Aha DW, 1994, AAAI WORKSH CAS BAS, P106; ALMUALLIM H, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P547; ALMUALLIM H, 1994, ARTIF INTELL, V69, P279, DOI 10.1016/0004-3702(94)90084-1; AMIRIKIAN B, 1994, NEURAL NETWORKS, V7, P321, DOI 10.1016/0893-6080(94)90026-4; [Anonymous], 1992, INDUCTIVE LOGIC PROG; ARNAP R, 1962, LOGICAL FDN PROBABIL; BLUMER A, 1987, INFORM PROCESS LETT, V24, P377, DOI 10.1016/0020-0190(87)90114-1; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; DAVIES S, 1994, P 1994 AAAI FALL S R, P37; Devijver PA, 1982, PATTERN RECOGNITION; DUNTSCH I, 1998, IN PRESS ARTIFICIAL; FAYYAD U, 1992, AAAI 92 P 10 NAT C A; FAYYAD U, 1990, AAAI 90 P 8 NAT C AR; GARDENFORS P, 1978, SYNTHESE, V37, P351, DOI 10.1007/BF00873245; *INT SOL LTDF, CLEM DAT MIN SYST; John G.H., 1994, MACHINE LEARNING P 1, DOI 10.1016/B978-1-55860-335-6.50023-4; Keynes J. M, 1921, TREATISE PROBABILITY; KIRA K, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P129; Kohavi R., 1995, P 1 INT C KNOWL DISC, P192; KOHAVI R, 1994, RELEVANCE, P122; KONONENKO I, 1994, P 1994 EUR C MACH LE; LANGLEY P, 1994, RELEVANCE, P127; LEVY AY, 1994, P AAAI 94; LIU H, 1997, IEEE T KNOWLEDGE DAT, V9; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Quinlan J.R, 1993, C45 PROGRAMS MACHINE; QUINLAN JR, 1989, INFORM COMPUT, V80, P227, DOI 10.1016/0890-5401(89)90010-2; RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051; SCHLIMMER JC, 1903, ML93, P284; SCHWEITZER HS, 1995, IEEE T PATTERN ANAL, V17, P1033, DOI 10.1109/34.473229; SHORE J, 1980, IEEE T INFORMATION T, V26; Skalak D. B, 1994, P 11 INT C MACH LEAR, P293, DOI DOI 10.1016/B978-1-55860-335-6.50043-X; SUBRAMANIAN D, 1987, P IJCAI 87, P416; Ullman J. D., 1989, PRINCIPLES DATABASE; WALLACE CS, 1987, J ROY STAT SOC B MET, V49, P240; WANG H, 1996, UNIFIED FRAMEWORK RE; Wolpert D. H., 1990, Complex Systems, V4, P319	37	39	43	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1999	21	3					271	277		10.1109/34.754624	http://dx.doi.org/10.1109/34.754624			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	178YD					2022-12-18	WOS:000079296000010
J	Rao, AV; Miller, DJ; Rose, K; Gersho, A				Rao, AV; Miller, DJ; Rose, K; Gersho, A			A deterministic annealing approach for parsimonious design of piecewise regression models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						statistical regression; piecewise regression; deterministic annealing; parsimonious modeling; generalization; nearest-prototype models	VECTOR QUANTIZATION; CLASSIFICATION; COMPLEXITY; AIR	A new learning algorithm is proposed for piecewise regression modeling. It employs the technique of deterministic annealing to design space partition regression functions. While the performance of traditional space partition regression functions such as CART and MARS is limited by a simple tree-structured partition and by a hierarchical approach for design, the deterministic annealing algorithm enables the joint optimization of a more powerful piecewise structure based on a Voronoi partition. The new method is demonstrated to achieve consistent performance improvements over regular CART as well as over its extension to allow arbitrary hyperplane boundaries. Comparison tests, on several benchmark data sets from the regression literature, are provided.	SignalCom Inc, Goleta, CA 93117 USA; Penn State Univ, University Pk, PA 16802 USA; Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park; University of California System; University of California Santa Barbara	Rao, AV (corresponding author), SignalCom Inc, 7127 Hollister Ave,Suite 109, Goleta, CA 93117 USA.	ajit@dsp-signal.com; miller@pippin.ee.psu.edu; rose@ece.ucsb.edu; gersho@ece.ucsb.edu						AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; BELLMAN R, 1969, J AM STAT ASSOC, V64, P1079; Breiman L., 1985, Computer Science and Statistics. Proceedings of the Sixteenth Symposium on the Interface, P121; BUHMANN J, 1993, IEEE T INFORM THEORY, V39, P1133, DOI 10.1109/18.243432; CHERKASSKY V, 1991, P INT JOINT C NEUR N, V1, P79; CHOU PA, 1991, IEEE T PATTERN ANAL, V13, P340, DOI 10.1109/34.88569; CHOU PA, 1989, IEEE T INFORM THEORY, V35, P299, DOI 10.1109/18.32124; COVER TM, 1968, IEEE T INFORM THEORY, V14, P50, DOI 10.1109/TIT.1968.1054098; FRIEDMAN JH, 1981, J AM STAT ASSOC, V76, P817, DOI 10.2307/2287576; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Gersho A., 1992, VECTOR QUANTIZATION; HARRISON D, 1978, J ENVIRON ECON MANAG, V5, P81, DOI 10.1016/0095-0696(78)90006-2; HINTON GE, 1995, ADV NEURAL INFORMATI, V8, P507; HWANG JN, 1994, IEEE T NEURAL NETWOR, V5, P342, DOI 10.1109/72.286906; KOHONEN T, 1988, NEURAL NETWORKS, V1, P3, DOI 10.1016/0893-6080(88)90020-2; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; LOH WY, 1988, J AM STAT ASSOC, V83, P715, DOI 10.2307/2289295; MCDONALD GC, 1973, TECHNOMETRICS, V15, P463, DOI 10.2307/1266852; Miller D, 1996, IEEE T SIGNAL PROCES, V44, P3108, DOI 10.1109/78.553484; Moody J, 1989, NEURAL COMPUT, V1, P281, DOI 10.1162/neco.1989.1.2.281; Olshen R., 1984, CLASSIFICATION REGRE; RAO A, 1996, P IEEE INT C AC SPEE, V4, P2032; Rao AV, 1997, IEEE T SIGNAL PROCES, V45, P2811, DOI 10.1109/78.650107; RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051; ROSE K, 1992, IEEE T INFORM THEORY, V38, P1249, DOI 10.1109/18.144705; ROSE K, 1993, IEEE T PATTERN ANAL, V15, P785, DOI 10.1109/34.236251; ROSE K, 1994, IEEE T INFORM THEORY, V40, P1939, DOI 10.1109/18.340468; ROSE K, 1990, PHYS REV LETT, V65, P945, DOI 10.1103/PhysRevLett.65.945; Silverman BW., 1986, DENSITY ESTIMATION S, V26, DOI 10.1201/9781315140919; Stork D.G., 1993, ADV NEURAL INF PROCE, P164; TERRELL GR, 1992, ANN STAT, V20, P1236, DOI 10.1214/aos/1176348768; Venables W.N., 2013, MODERN APPL STAT S; WEISS SM, 1987, P NAT C ART INT AAAI; ZHAO J, 1994, P INT C ART NEUR NET, P561; [No title captured]	35	39	43	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1999	21	2					159	173		10.1109/34.748824	http://dx.doi.org/10.1109/34.748824			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	167NL					2022-12-18	WOS:000078639900005
J	Keren, D; Gotsman, C				Keren, D; Gotsman, C			Fitting curves and surfaces with constrained implicit polynomials	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						implicit polynomials; fitting; free-form shapes; topological integrity; starshaped curves and surfaces; positive polynomials	ALGEBRAIC INVARIANTS; RECOGNITION; OBJECTS	A problem which often arises while fitting implicit polynomials to 2D and 3D data sets is the following: Although the data set is simple, the fit exhibits undesired phenomena, such as loops, holes, extraneous components, etc. Previous work tackled these problems by optimizing heuristic cost functions, which penalize some of these topological problems in the fit. This paper suggests a different approach-to design parameterized families of polynomials whose zero-sets are guaranteed to satisfy certain topological properties. Namely, we construct families of polynomials with star-shaped zero-sets, as well as polynomials whose zero-sets are guaranteed not to intersect an ellipse circumscribing the data or to be entirely contained in such an ellipse. This is more rigorous than using heuristics which may fail and result in pathological zero-sets. The ability to parameterize these families depends heavily on the ability to parameterize positive polynomials. To achieve this, we use some powerful recent results from real algebraic geometry.	Univ Haifa, Dept Comp Sci, IL-31905 Haifa, Israel; Technion Israel Inst Technol, Fac Comp Sci, IL-32000 Haifa, Israel	University of Haifa; Technion Israel Institute of Technology	Keren, D (corresponding author), Univ Haifa, Dept Comp Sci, IL-31905 Haifa, Israel.			Gotsman, Craig/0000-0001-8579-3588				BAJAJ C, 1993, ACM T GRAPHIC, V12, P327, DOI 10.1145/159730.159734; BAJAJ CL, 1995, ACM T GRAPHIC, V14, P103, DOI 10.1145/221659.221662; Choi M., 1995, P S PURE MATH 2, V2, P103; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233; FORSYTH DA, 1993, P INT C COMP VIS BER, P476; Hilbert David, 1888, MATH ANN, V32, P342, DOI DOI 10.1007/BF01443605; KEREN D, 1994, IEEE T PATTERN ANAL, V16, P1143, DOI 10.1109/34.334397; KEREN D, 1994, IEEE T PATTERN ANAL, V16, P38, DOI 10.1109/34.273718; KRIEGMAN DJ, 1990, IEEE T PATTERN ANAL, V12, P1127, DOI 10.1109/34.62602; Lei ZB, 1998, IEEE T PATTERN ANAL, V20, P212, DOI 10.1109/34.659942; Levin D., 1995, Numerical Algorithms, V9, P113, DOI 10.1007/BF02143930; SAMPSON PD, 1982, COMPUT VISION GRAPH, V18, P97, DOI 10.1016/0146-664X(82)90101-0; Subrahmonia J, 1996, IEEE T PATTERN ANAL, V18, P505, DOI 10.1109/34.494640; SULLIVAN S, 1994, IEEE T PATTERN ANAL, V16, P1183, DOI 10.1109/34.387489; TAUBIN G, 1994, IEEE T PATTERN ANAL, V16, P287, DOI 10.1109/34.276128; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273	16	39	44	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1999	21	1					31	41		10.1109/34.745731	http://dx.doi.org/10.1109/34.745731			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	163DZ		Green Submitted			2022-12-18	WOS:000078388900004
J	Magni, P; Bellazzi, R; De Nicolao, G				Magni, P; Bellazzi, R; De Nicolao, G			Bayesian function learning using MCMC methods	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian estimation; smoothing; inverse problems; system identification; Markov chain Monte Carlo methods; dynamic systems	INSULIN-SECRETION; MARKOV-CHAINS; DECONVOLUTION; DISTRIBUTIONS; EQUATIONS; NOISY	The paper deals with the problem of reconstructing a continuous one-dimensional function from discrete noisy samples. The measurements may also be indirect in the sense that the samples may be the output of a linear operator applied to the function (linear inverse problem, deconvolution). In some cases, the linear operator could even contain unknown parameters that are estimated from a second experiment (joint identification-deconvolution problem). Bayesian estimation provides a unified treatment of this class of problems, but the practical calculation of posterior densities leads to analytically intractable integrals. In the paper it is shown that a rigourous Bayesian solution can be efficiently implemented by resorting to a MCMC (Markov chain Monte Carte) simulation scheme. In particular, it is discussed how the structure of the problem can be exploited in order to improve computational and convergence performances. The effectiveness of the proposed scheme is demonstrated on two classical benchmark problems as well as on the analysis of IVGTT (IntraVenous Glucose Tolerance Test) data, a complex identification-deconvolution problem concerning the estimation of the insulin secretion rate following the administration of an intravenous glucose injection.	Univ Pavia, Dipartimento Informat & Sistemist, I-27100 Pavia, Italy	University of Pavia	Magni, P (corresponding author), Univ Pavia, Dipartimento Informat & Sistemist, Via Ferrata 1, I-27100 Pavia, Italy.	magni@aimed11.unipv.it; ric@aim.unipv.it; denicolao@conpro.unipv.it	Bellazzi, Riccardo/J-6432-2018	Bellazzi, Riccardo/0000-0002-6974-9808; Magni, Paolo/0000-0002-8931-4676				ANDERSSEN RS, 1974, TECHNOMETRICS, V16, P69; ANSLEY CF, 1993, BIOMETRIKA, V80, P75, DOI 10.2307/2336758; Beck J., 1977, PARAMETER ESTIMATION; BELLAZZI R, 1997, INTELLIGENT DATA ANA, V1; BERTH P, 1989, TENSIDE, V2, P75; Berzuini C, 1996, IEEE T PATTERN ANAL, V18, P109, DOI 10.1109/34.481537; COMMENGES D, 1984, IEEE T AUTOMAT CONTR, V29, P229, DOI 10.1109/TAC.1984.1103492; CRAVEN P, 1979, NUMER MATH, V31, P377, DOI 10.1007/BF01437407; DeNicolao G, 1997, AUTOMATICA, V33, P851, DOI 10.1016/S0005-1098(96)00254-3; Denison DGT, 1998, J ROY STAT SOC B, V60, P333, DOI 10.1111/1467-9868.00128; GAUDERMAN WJ, 1994, GENET EPIDEMIOL, V11, P171, DOI 10.1002/gepi.1370110207; Gelman A., 1996, MARKOV CHAIN MONTE C, P131, DOI DOI 10.1007/978-1-4899-4485-6_8; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GILKS WR, 1992, APPL STAT; Gilks WR, 1996, MARKOV CHAIN MONTE C; HANSEN PC, 1992, INVERSE PROBL, V8, P849, DOI 10.1088/0266-5611/8/6/005; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; HUNT B R, 1970, Mathematical Biosciences, V8, P161, DOI 10.1016/0025-5564(70)90148-3; LITTON C, 1996, MARKOV CHAIN MONTE C, P465; LIU JS, 1995, J AM STAT ASSOC, V90, P567, DOI 10.2307/2291068; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.448; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Neal RM., 1996, BAYESIAN LEARNING NE, P29; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; PHILLIPS DL, 1962, J ASSOC COMPUT MACH, V9, P97; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Raftery A. E., 1996, MARKOV CHAIN MONTE C, P115, DOI DOI 10.1007/978-1-4899-4485-6.1269; SHAPIRO ET, 1988, J CLIN ENDOCR METAB, V67, P1094, DOI 10.1210/jcem-67-5-1094; Shephard N, 1997, BIOMETRIKA, V84, P653, DOI 10.1093/biomet/84.3.653; Sparacino G, 1996, IEEE T BIO-MED ENG, V43, P512, DOI 10.1109/10.488799; TIERNEY L, 1994, ANN STAT, V22, P1701, DOI 10.1214/aos/1176325750; TWOMEY S, 1963, J ACM, V10, P97, DOI 10.1145/321150.321157; TYCHONOV AN, 1977, SOLUTIONS ILL POSED; WAHBA G, 1977, SIAM J NUMER ANAL, V14, P651, DOI 10.1137/0714044; Wahba G., 1990, SPLINE MODELS OBSERV; WILLIAMS C, 1996, ADV NEURAL INFORMATI	36	39	39	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1998	20	12					1319	1331		10.1109/34.735805	http://dx.doi.org/10.1109/34.735805			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	147QV					2022-12-18	WOS:000077578300004
J	Li, SZ				Li, SZ			Close-form solution and parameter selection for convex minimization-based edge-preserving smoothing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						convexity; edge preservation; energy minimization; image smoothing; Markov random field (MRF); maximum a posteriori (MAP); parameter selection; regularization	DETECTORS	This work presents a new approach far the analysis of convex minimization-based edge-preserving image smoothing and the parameter selection therein. The global solution, that is, the response of a convex smoothing model to the ideal step edge, is derived in close-form. By analyzing the close-form solution, insights are drawn into how the optimal solution responds to edges in the data and how the parameter values affect resultant edges in the solution. Based on this, a scheme is proposed for selecting parameters to achieve desirable responses at edges. The theoretic results are substantiated by experiments.	Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Li, SZ (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Block S1,Nanyang Ave, Singapore 639798, Singapore.	szli@szli.eee.ntu.ac.sg						Bournan C, 1993, IEEE T IMAGE PROCESS, V2, P296, DOI 10.1109/83.236536; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GREEN PJ, 1990, IEEE T MED IMAGING, V9, P84, DOI 10.1109/42.52985; Huber P., 1981, ROBUST STAT; JEONG H, 1992, IEEE T PATTERN ANAL, V14, P579, DOI 10.1109/34.134062; LANGE K, 1990, IEEE T MED IMAGING, V9, P439, DOI 10.1109/42.61759; Li S., 1995, MARKOV RANDOM FIELD, P1; LI SZ, 1995, IEEE T PATTERN ANAL, V17, P576, DOI 10.1109/34.387504; LI SZ, 1995, P IEEE INT C IM PROC, V2, P296; MARROQUIN J, 1985, THESIS MIT; Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22; Nadabar SG, 1996, IEEE T PATTERN ANAL, V18, P326, DOI 10.1109/34.485560; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; PETROU M, 1991, IEEE T PATTERN ANAL, V13, P483, DOI 10.1109/34.134047; PITAS I, 1986, IEEE T PATTERN ANAL, V8, P538, DOI 10.1109/TPAMI.1986.4767819; SCHULTZ RR, 1994, IEEE T IMAGE PROCESS, V3, P233, DOI 10.1109/83.287017; Shulman D., 1989, Proceedings. Workshop on Visual Motion (IEEE Cat. No.89CH2716-9), P81, DOI 10.1109/WVM.1989.47097; Stevenson R., 1990, P 1 INT WORKSH ROB C, P127; STEVENSON RL, 1994, IEEE T SYST MAN CYB, V24, P455, DOI 10.1109/21.278994	20	39	42	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1998	20	9					916	932		10.1109/34.713359	http://dx.doi.org/10.1109/34.713359			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	117AX					2022-12-18	WOS:000075758500002
J	Tomasi, C; Manduchi, R				Tomasi, C; Manduchi, R			Stereo matching as a nearest-neighbor problem	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						stereo vision; stereo matching; correspondence problem; disparity; ambiguity; occlusions; search; nearest-neighbor search; dynamic programming	ALGORITHM; TEXTURE; VISION; MOTION	We propose a representation of images, called intrinsic curves, that transforms stereo matching from a search problem into a nearest-neighbor problem. Intrinsic curves are the paths that a set of local image descriptors trace as an image scanline is traversed from left to right. Intrinsic curves are ideally invariant with respect to disparity. Stereo correspondence then becomes a trivial lookup problem in the ideal case. We also show how to use intrinsic curves to match real images in the presence of noise, brightness bias, contrast fluctuations, moderate geometric distortion, image ambiguity, and occlusions. In this case, matching becomes a nearest-neighbor problem, even for very large disparity values.	Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA	Stanford University	Tomasi, C (corresponding author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.	tomasi@cs.stanford.edu; manduchi@cs.stanford.edu						ARNOLD RD, 1978, P SOC PHOTO-OPT INS, V238, P281; ARNOLD VI, 1990, ORDINARY DIFFERENTIA; BAKER HH, 1981, P 7 INT JOINT C ART, P631; Belhumeur P. N., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P506, DOI 10.1109/CVPR.1992.223143; BLAKE A, 1990, ARTIF INTELL, V45, P323, DOI 10.1016/0004-3702(90)90011-N; CAMPANI M, 1992, CVGIP-IMAG UNDERSTAN, V56, P90, DOI 10.1016/1049-9660(92)90088-K; Cox IJ, 1996, COMPUT VIS IMAGE UND, V63, P542, DOI 10.1006/cviu.1996.0040; GEIGER D, 1992, P EUR C COMP VIS, P425; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; INTILLE SS, 1994, P 3 EUR C COMP VIS, P179; JONES DG, 1992, P EUR C COMP VIS, P395; JONES DG, 1992, P 2 EUR C COMP VIS S, P661; KANATANI K, 1984, ARTIF INTELL, V23, P213, DOI 10.1016/0004-3702(84)90010-9; KASS MH, 1984, THESIS MIT; Knuth DE., 1973, ART COMPUTER PROGRAM; KOENDERINK JJ, 1976, BIOL CYBERN, V21, P29, DOI 10.1007/BF00326670; LITTLE J, 1990, P EUR C COMP VIS, P336; MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; MANMATHA R, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P141, DOI 10.1109/CVPR.1994.323821; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; POLLARD SB, 1985, PERCEPTION, V14, P449, DOI 10.1068/p140449; SATO J, 1994, P ECCV 94 STOCKH, P165; Struik D. J., 1988, LECT CLASSICAL DIFFE; Super B. J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P296, DOI 10.1109/CVPR.1992.223260; Toh P.-S., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P126, DOI 10.1109/ICCV.1990.139509; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; WENG JY, 1992, IEEE T PATTERN ANAL, V14, P806, DOI 10.1109/34.149592; Xiong YL, 1997, PROC CVPR IEEE, P1087, DOI 10.1109/CVPR.1997.609465; Yianilos P.N., 1993, P 4 ACM SIAM S DISCR; [No title captured]	31	39	48	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1998	20	3					333	340		10.1109/34.667890	http://dx.doi.org/10.1109/34.667890			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZH156		Green Published			2022-12-18	WOS:000073078400010
J	Raudys, S				Raudys, S			Dimensionality, sample size, and classification error of nonparametric linear classification algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						generalization error; dimensionality; complexity; sample size; training; margin		This paper compares two nonparametric linear classification algorithms--the zero empirical error classifier and the maximum margin classifier--with parametric linear classifiers designed to classify multivariate Gaussian populations [7]. Formulae and a table for the mean expected probability of misclassification MEPN are presented. They show that the classification error is mainly determined by N/p, a learning-set size/dimensionality ratio. However, the influences of learning-set size on the generalization error of parametric and nonparametric linear classifiers are quite different. Under certain conditions the nonparametric approach allows us to obtain reliable rules, even in cases where the number of features is larger than the number of training vectors.			Raudys, S (corresponding author), INST MATH & INFORMAT,AKADEMIJOS 4,LT-2600 VILNIUS,LITHUANIA.							AMARI S, 1993, NEURAL COMPUT, V5, P140, DOI 10.1162/neco.1993.5.1.140; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Mclachlan GJ., 2005, DISCRIMINANT ANAL ST; MEIR R, 1994, P 12 ICPR JER OCT, V2; Raudys S, 1980, IEEE Trans Pattern Anal Mach Intell, V2, P242, DOI 10.1109/TPAMI.1980.4767011; RAUDYS S, 1996, P 13 ICPR TRACK D WI; RAUDYS S, 1995, 9517 LAFORIA U PAR 6; VAPNIK VN, 1982, ESTIMATION DEPENDENC, P448; WYMAN FJ, 1990, PATTERN RECOGN, V23, P775, DOI 10.1016/0031-3203(90)90100-Y	10	39	41	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1997	19	6					667	671		10.1109/34.601254	http://dx.doi.org/10.1109/34.601254			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XG302					2022-12-18	WOS:A1997XG30200011
J	Bangham, JA; Ling, PD; Harvey, R				Bangham, JA; Ling, PD; Harvey, R			Scale-space from nonlinear filters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						scale-space; image processing; morphology; vision; diffusion	MORPHOLOGY; IMAGES	Decomposition by extrema is put into the context of linear vision systems and scale-space. It is proved that discrete one-dimensional, M- and N-sieves neither introduce new edges as the scale increases nor create new extrema. They share this property with diffusion based filters. They are robust and preserve edges of large scale features.			Bangham, JA (corresponding author), UNIV E ANGLIA, SCH INFORMAT SYST, NORWICH NR4 7TJ, NORFOLK, ENGLAND.		Harvey, Richard/AAA-7738-2020	Harvey, Richard/0000-0001-9925-8316				[Anonymous], 1990, NONLINEAR DIGITAL FI; BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; Bangham J. A., 1990, Communication, Control and Signal Processing. Proceedings of the 1990 Bilkent International Conference on New Trends in Communication, Control and Signal Processing, P1591; BANGHAM JA, 1994, SIGNAL PROCESS, V38, P387, DOI 10.1016/0165-1684(94)90156-2; BANGHAM JA, 1993, IEEE T SIGNAL PROCES, V41, P31, DOI 10.1109/TSP.1993.193125; Bangham JA, 1994, COMP IMAG VIS, V2, P179; BANGHAM JA, 1994, P SOC PHOTO-OPT INS, V2180, P90, DOI 10.1117/12.172560; BANGHAM JA, 1996, IN PRESS ECCV CAMBRI; BANGHAM JA, 1994, EUSIPCO; BANGHAM JA, 1995, P IEEE WORKSH NONL S, V2, P1038; BANGHAM JA, 1992, P IEEE WORKSH VIS SI, P37; CHARDAIRE P, 1994, P SOC PHOTO-OPT INS, V2180, P148, DOI 10.1117/12.172552; CHEN MH, 1989, IEEE T PATTERN ANAL, V11, P694, DOI 10.1109/34.192464; Dinneen G., 1955, P W JOINT COMP C, P94, DOI DOI 10.1145/1455292.1455311; DOUGHERTY ER, 1992, PATTERN RECOGN, V25, P1181, DOI 10.1016/0031-3203(92)90020-J; DOUGHERTY ER, 1994, SPIE; GALLAGHER NC, 1981, IEEE T ACOUST SPEECH, V29, P1136, DOI 10.1109/TASSP.1981.1163708; JACKWAY PT, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P252, DOI 10.1109/ICPR.1992.201973; LINDEBERG T, 1990, IEEE T PATTERN ANAL, V12, P234, DOI 10.1109/34.49051; LINDEBERG T, 1994, SCALE SPACE THEORY C, V9, P7923; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; Marr D., 1982, VISION; Matheron G., 1975, RANDOM SETS INTEGRAL; MCLOUGHLIN MP, 1987, IEEE T ACOUST SPEECH, V35, P98, DOI 10.1109/TASSP.1987.1165026; NACKEN PFM, 1994, IEEE T PATTERN ANAL, V16, P656, DOI 10.1109/34.295918; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; PITAS I, 1990, IEEE T PATTERN ANAL, V12, P38, DOI 10.1109/34.41382; SALEMBIER P, 1995, IEEE T IMAGE PROCESS, V4, P1153, DOI 10.1109/83.403422; SALEMBIER P, 1992, SIGNAL PROCESS, V27, P205, DOI 10.1016/0165-1684(92)90008-K; SERRA J, 1986, COMPUT VISION GRAPH, V35, P283, DOI 10.1016/0734-189X(86)90002-2; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; STERNBERG SR, 1986, COMPUT VISION GRAPH, V35, P333, DOI 10.1016/0734-189X(86)90004-6; Vincent L, 1994, COMP IMAG VIS, V2, P265; Vincent L., 1993, P 1 WORKSH MATH MORP, P22; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; YUILLE AL, 1987, SCALING IEEEE T PATT, V9, P15	37	39	39	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1996	18	5					520	528		10.1109/34.494641	http://dx.doi.org/10.1109/34.494641			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL691					2022-12-18	WOS:A1996UL69100004
J	Lovell, BC; Bradley, AP				Lovell, BC; Bradley, AP			The multiscale classifier	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multiscale classification; decision trees; inductive machine learning; tree pruning		In this paper we propose a rule-based inductive learning algorithm called Multiscale Classification (MSC). It can be applied to any N-dimensional real or binary classification problem to classify the training data by successively splitting the feature space in half. The algorithm has several significant differences from existing mts-based approaches: learning is incremental, the tree is non-binary, and backtracking of decisions is possible to some extent. The paper first provides background on current machine learning techniques and outlines some of their strengths and weaknesses. It then describes the MSC algorithm and compares it to other inductive learning algorithms with particular reference to ID3, C4.5, and back-propagation neural networks. Its performance on a number of standard benchmark problems is then discussed and related to standard learning issues such as generalization, representational power, and over-specialization.			Lovell, BC (corresponding author), UNIV QUEENSLAND, DEPT ELECT & COMP ENGN, COOPERAT RES CTR SENSOR SIGNAL & INFORMAT PROC, ST LUCIA, QLD 4072, AUSTRALIA.		Bradley, Andrew P./O-8516-2019; Bradley, Andrew P./C-5685-2009	Bradley, Andrew P./0000-0003-0109-6844; Bradley, Andrew P./0000-0003-0109-6844; Lovell, Brian/0000-0001-6722-1754				Anthony M., 1992, COMPUTATIONAL LEARNI; BLAHUT RE, 1990, DIGITAL TRANSMISSION, P306; BLUMER A, 1987, INFORM PROCESS LETT, V24, P377, DOI 10.1016/0020-0190(87)90114-1; BURNETT R, 1994, THESIS U QUEENSLAND; CESTNIK I, 1987, MACHINE LEARNING; CESTNIK I, 1991, LECTURE NOTES ARTIFI, V482, P138; Fahlman S.E., 1990, ADV NEURAL INFORM PR, P524; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; FORSYTH R, 1986, MACHINE LEARNING APP; GORDON AD, 1981, CLASSIFICATION; Hand D. J, 1981, WILEY SERIES PROBABI; HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932; KNOLL U, 1994, P ECML, V94, P383; LANG K, 1988, P 1988 CONN SUMM SCH; McClelland J. L., 1988, EXPLORATIONS PARALLE, P121; MICHIE D, 1968, MACHINE INTELIGENCE, V2; Mingers J., 1989, Machine Learning, V4, P227, DOI 10.1023/A:1022604100933; Minsky M., 1969, PERCEPTRONS; Olshen R., 1984, CLASSIFICATION REGRE; Quinlan J., 2014, C4 5 PROGRAMS MACHIN, DOI DOI 10.1007/BF00993309; QUINLAN JR, 1987, INT J MAN MACH STUD, V27, P221, DOI 10.1016/S0020-7373(87)80053-6; QUINLAN JR, 1982, INTRO READING EXPERT; QUINLAN JR, 1989, APPLICATIONS EXPERT, P157; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; SAMET H, 1984, COMPUTING SURVEYS, V16; SAMUEL AL, 1967, IBM J RES DEV, V11, P601, DOI 10.1147/rd.116.0601; SMITH JW, 1988, 12TH P ANN S COMP AP, P261; THRUN S, 1991, MONKS PROBLEM PERFOR; TINDER RF, 1991, DIGITAL ENG DESIGN; Weiss Sholom, 1991, COMPUTER SYSTEMS LEA; WOLBERG WH, 1990, P NATL ACAD SCI USA, V87, P9193, DOI 10.1073/pnas.87.23.9193	31	39	40	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1996	18	2					124	137		10.1109/34.481538	http://dx.doi.org/10.1109/34.481538			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TV669					2022-12-18	WOS:A1996TV66900004
J	KOPLOWITZ, J; GRECO, V				KOPLOWITZ, J; GRECO, V			ON TBE EDGE LOCATION ERROR FOR LOCAL MAXIMUM AND ZERO-CROSSING EDGE DETECTORS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						EDGE DETECTION; FEATURE EXTRACTION; IMAGE PROCESSING; IMAGE SEGMENTATION; LOCALIZATION CRITERION		We examine the localization criterion for edge detection and determine the probability density function describing the edge location error. Canny defines the measure of localization as the reciprocal or the Foot-mean-square edge location error and formulates an expression of this measure For local maximum detectors. However, Tagare and deFigueiredo point out that an incorrect assumption is made in the calculation. The same procedure is used by Sarkar and Boyer for their localization measure for zero-crossing detectors. We modify the analysis and obtain a closed form solution of the probability density function of the edge location error. Examination of the density function indicates the variance of the edge location error does not exist, and hence can not be used directly as a measure of localization.	USN,NAVAL UNDERSEA WARFARE,NEWPORT,RI 02841	United States Department of Defense; United States Navy	KOPLOWITZ, J (corresponding author), CLARKSON UNIV,DEPT ELECT & COMP ENGN,POTSDAM,NY 13699, USA.							BABAUD J, 1986, IEEE T PATTERN ANAL, V8; Canny J., 1986, IEEE T PATTERN ANAL, VPAMI-8; Haralick R., 1984, IEEE T PATTERN ANAL, V6; HUERTAS A, 1986, IEEE T PATTERN MACHI, V8; KOPLOWITZ J, 1991, P SOC PHOTO-OPT INS, V1471, P452, DOI 10.1117/12.44901; LYVERS E, 1989, IEEE T PATTERN ANAL, V11; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Papoulis A., 2002, PROBABILITY RANDOM V; RICE SO, 1945, AT&T TECH J, V24, P46, DOI 10.1002/j.1538-7305.1945.tb00453.x; SARKAR S, 1991, IEEE T PATTERN ANAL, V13; SARKAR S, 1991, COMPUT VISION GRAPHI, V54; TABATABAI AJ, 1984, IEEE T PATTERN ANAL, V6; TAGARE HD, 1990, IEEE T PATTERN ANAL, V12; TORRE V, 1986, IEEE T PATTERN ANAL, V8; WILSON HR, VISION RES, V17, P1177; YUILLE A, 1986, IEEE T PATTERN ANAL, V8	16	39	42	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1994	16	12					1207	1212		10.1109/34.387487	http://dx.doi.org/10.1109/34.387487			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QA715					2022-12-18	WOS:A1994QA71500005
J	MARAPANE, SB; TRIVEDI, MM				MARAPANE, SB; TRIVEDI, MM			MULTI-PRIMITIVE HIERARCHICAL (MPH) STEREO ANALYSIS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						COMPUTATIONAL BINOCULAR STEREO; HIERARCHICAL STEREO ANALYSIS; MULTIPLE PRIMITIVE ANALYSIS; DEPTH EXTRACTION	DISPARITY; VISION; COMPUTATION; CONTOURS; IMAGES	This paper develops and demonstrates a new computational framework for an accurate, robust, and efficient stereo approach. In multi-primitive hierarchical (MPH) computational model, stereo analysis is performed in multiple stages, incorporating multiple primitives, utilizing a hierarchical control strategy. The MPH stereo system consists of three integrated subsystems: region-based analysis module; linear edge segment-based analysis module; and edgel-based stereo analysis module. Results of stereo analysis at higher levels of the hierarchy are used for guidance at the lower levels. The MPH stereo system does not overly rely on one type of primitive and therefore will reliably work on a wide range of scenes. The MPH stereo analysis results in the generation of several disparity maps of multiple abstraction. Disparity maps generated at each level can be fused to obtain an accurate and fine resolution disparity map. The MPH approach also provides the capability to selectively analyze image regions with varying detail. This provides the means for adaptively extracting range information of only sufficient resolution. Thus, a stereo system that utilizes primitives of different abstraction and a multilevel hierarchical computational strategy will be superior to a single-level, single-primitive system. Extensive experimentation is carried out on a wide array of scenes of varying complexity from two application domains to systematically evaluate the validity and performance of the MPH framework. The MPH stereo system is able to analyze images in most cases with 85% - 100% matching accuracy in under a minute of processing time and yield depth values typically within +/-2% of the actual depth.			MARAPANE, SB (corresponding author), UNIV TENNESSEE, DEPT ELECT & COMP ENGN, COMP VIS & ROBOT RES LAB, KNOXVILLE, TN 37996 USA.							ARNOLD RD, 1983, THESIS STANFORD U PA; AYACHE N, 1987, INT J COMPUT VISION, V1, P107, DOI 10.1007/BF00123161; BAKER HH, 1981, 7TH P INT JOINT C AR, P631; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BARNARD ST, 1982, ACM COMPUT SURV, V14, P553, DOI DOI 10.1145/356893.356896; BOYER KL, 1991, IEEE T SYST MAN CYB, V21, P143, DOI 10.1109/21.101145; BOYER KL, 1988, IEEE T PATTERN ANAL, V10, P144, DOI 10.1109/34.3880; BURT P, 1980, SCIENCE, V208, P615, DOI 10.1126/science.7367885; Chung R. C., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P50, DOI 10.1109/CVPR.1991.139660; COCHRAN SD, 1989, MAY P IM UND WORKSH, V1, P856; DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067; FRISBY JP, 1979, SEEING; GENNERY D, 1979, P 10 IM UND WORKSH, P101; GENNERY DB, 1977, 5TH P INT JOINT C AR, V2, P576; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; GRIMSON WEL, 1981, IMAGES SURFACES; HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709; HORAUD R, 1989, IEEE T PATTERN ANAL, V11, P1168, DOI 10.1109/34.42855; JULESZ B, 1960, AT&T TECH J, V39, P1125, DOI 10.1002/j.1538-7305.1960.tb03954.x; KIM YC, 1987, IEEE J ROBOT AUTOM, V3, P361; LIM HS, 1988, APR P IM UND WORKSH, V2, P794; LIM HS, 1987, FEB P DARPA IM UND W, P234; MARAPANE SB, 1989, IEEE T SYST MAN CYB, V19, P1447, DOI 10.1109/21.44064; MARAPANE SB, 1993, APR P SENS FUS AER A; MARAPANE SB, 1991, THESIS U TENNESSEE K; MARAPANE SB, 1988, 11 P C APPL DIG IM P; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; MEDIONI G, 1985, COMPUT VISION GRAPH, V31, P2, DOI 10.1016/S0734-189X(85)80073-6; MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P113, DOI 10.1109/34.16708; MORAVEC HP, 1983, P IEEE, V71, P872, DOI 10.1109/PROC.1983.12684; MORAVEC HP, 1977, 5TH P INT JOINT C AR, V2; NISHIHARA HK, 1984, OPT ENG, V23, P536, DOI 10.1117/12.7973334; NISHIHARA HK, 1983, 1ST INT S ROB RES, P489; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; PONG TC, 1989, PATTERN RECOGN LETT, V9, P127, DOI 10.1016/0167-8655(89)90045-7; Randriamasy S., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P736, DOI 10.1109/CVPR.1991.139806; RICHARDS W, 1977, VISION RES, V17, P967, DOI 10.1016/0042-6989(77)90072-4; SHERMAN D, 1990, IEEE T PATTERN ANAL, V12, P1102, DOI 10.1109/34.61711; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; TRIVEDI MM, 1991, ADV COMPUT, V32, P105; Vaidya N. M., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P76, DOI 10.1109/CVPR.1991.139664; VINET L, 1989, P COMPUT VISION PATT; WATANABE M, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P476; XU G, 1989, 11TH P INT JOINT C, V2	46	39	44	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1994	16	3					227	240		10.1109/34.276122	http://dx.doi.org/10.1109/34.276122			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NF114					2022-12-18	WOS:A1994NF11400003
J	MOHAN, R; MEDIONI, G; NEVATIA, R				MOHAN, R; MEDIONI, G; NEVATIA, R			STEREO ERROR-DETECTION, CORRECTION, AND EVALUATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV SO CALIF,DEPT ELECT ENGN,LOS ANGELES,CA 90089; UNIV SO CALIF,DEPT COMP SCI,LOS ANGELES,CA 90089	University of Southern California; University of Southern California	MOHAN, R (corresponding author), UNIV SO CALIF,INST ROBOT & INTELLIGENT SYST,LOS ANGELES,CA 90089, USA.							ARNOLD RD, 1983, STANCS83961 STANF U; BAKER H, 1982, STANCS82930 STAND U; BARNARD ST, 1982, ACM COMPUT SURV, V14, P553, DOI DOI 10.1145/356893.356896; Grimson W. E. L., 1985, IEEE T PATTERN ANAL, V7; GRIMSON WEL, 1981, IMAGES SURFACES; HANNAH MJ, 1982, SEP P IM UND WORKSH; HENDERSON RL, 1979, SOC PHOTOOPT INS AUG, V186; LEGUILLOUX Y, 1984, THESIS ECOLE NATIONA; Marr D., 1982, VISION; MAYHEW JEW, 1980, PERCEPTION, V9, P69, DOI 10.1068/p090069; MAYHEW JEW, 1981, ARTIFICIAL INTELL, V17; MEDIONI G, 1985, COMPUT VISION GRAPH, V31, P2, DOI 10.1016/S0734-189X(85)80073-6; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; OHTA Y, 1983, IEEE T PATTERN ANAL, V5; WALLACE RS, 1985, JUN P IEEE COMP SOC	15	39	41	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1989	11	2					113	120		10.1109/34.16708	http://dx.doi.org/10.1109/34.16708			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	R9989					2022-12-18	WOS:A1989R998900001
J	FOUNTAIN, TJ; MATTHEWS, KN; DUFF, MJB				FOUNTAIN, TJ; MATTHEWS, KN; DUFF, MJB			THE CLIP7A IMAGE-PROCESSOR	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											FOUNTAIN, TJ (corresponding author), UNIV LONDON UNIV COLL,DEPT PHYS & ASTRON,IMAGE PROC GRP,LONDON WC1E 6BT,ENGLAND.							Basille J. L., 1981, Languages and architectures for image processing, P205; BATCHER KE, 1980, IEEE T COMPUT, V29, P836, DOI 10.1109/TC.1980.1675684; Duff M.J.B., 1978, P NATIONAL COMPUTER, P1055; DUFF MJB, 1986, PYRAMIDAL SYSTEMS CO, P59; DUFF MJB, 1986, INTERMEDIATE LEVEL I; FLYNN MJ, 1972, IEEE T COMPUT, VC 21, P948, DOI 10.1109/TC.1972.5009071; FORSHAW MRB, 1986, 865 U COLL LOND DEP; Fountain TJ, 1983, PATTERN RECOGN LETT, V1, P331, DOI 10.1016/0167-8655(83)90072-7; FOUNTAIN TJ, 1981, P IEEECS COMPUT ARCH, P25; HERSCHER HB, 1963, IEEE T MIL, V7, P98; Hillis W., 1985, CONNECTION MACHINE; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837; Ip HHS, 1983, PATTERN RECOGN LETT, V2, P89, DOI 10.1016/0167-8655(83)90043-0; LETTVIN JY, 1959, P IRE, V47, P1940, DOI 10.1109/JRPROC.1959.287207; Lindskog B., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P1248; MATTHEWS KN, 1986, THESIS U LONDON; MATTHEWS KN, 1986, 868 U COLL LOND DEP; OTTO GP, 1986, CELLULAR LOGIC IMAGE, P41; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; REDDAWAY SF, 1973, 1ST ANN S COMP ARCH, P61; RIEGER C, 1981, P IEEE WORKSHOP COMP, P119; SLOTNICK DL, 1971, SCI AM, V224, P76, DOI 10.1038/scientificamerican0271-76; STERNBERG SR, 1978, 8TH P AUT IM PATT RE, P205; Tanimoto S. L., 1983, 10th Annual International Conference on Computer Architecture Conference Proceedings, P372, DOI 10.1145/800046.801676; UNGER SH, 1958, P IRE, V46, P1744, DOI 10.1109/JRPROC.1958.286755; WOOD AM, 1986, CELLULAR LOGIC IMAGE, P69; [No title captured]; 1984, OCCAM PROGRAMMING MA	28	39	42	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1988	10	3					310	319		10.1109/34.3896	http://dx.doi.org/10.1109/34.3896			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	N5337					2022-12-18	WOS:A1988N533700003
J	HANAHARA, K; MARUYAMA, T; UCHIYAMA, T				HANAHARA, K; MARUYAMA, T; UCHIYAMA, T			A REAL-TIME PROCESSOR FOR THE HOUGH TRANSFORM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											HANAHARA, K (corresponding author), FUJITSU LABS LTD,1015 KAMIKODANAKA,NAKAHARA KU,KAWASAKI,KANAGAWA 211,JAPAN.							BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; CHUANG HYH, 1985, P IEEE COMPUT SOC WO, P300; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; DYER CR, 1983, IEEE T PATTERN ANAL, V5, P621, DOI 10.1109/TPAMI.1983.4767452; EVANS F, 1985, P IEEE COMPUTER SOC, P378; Hanahara K., 1986, Proceedings 1986 IEEE International Conference on Robotics and Automation (Cat. No.86CH2282-2), P1954; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; HUANG KY, 1985, PATTERN RECOGN, V18, P429, DOI 10.1016/0031-3203(85)90013-5; Iannino A., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing, P32; Ibrahim H. A. H., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P248; INIGO RM, 1984, IEEE T PATTERN ANAL, V6, P820, DOI 10.1109/TPAMI.1984.4767606; KUSHNIR M, 1985, PATTERN RECOGN, V18, P103, DOI 10.1016/0031-3203(85)90033-0; LI CC, 1985, P IEEE INT C ROBOTIC, P474; Maruyama T., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P546; MERLIN PM, 1975, IEEE T COMPUT, VC 24, P96, DOI 10.1109/T-C.1975.224087; Sanz J. L. C., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P265; Silberberg T. M., 1985, 1985 IEEE Computer Society Workshop on Computer Architecture for Pattern Analysis and Image Database Management (Cat. No.85CH2229-3), P387; STOCKMAN GC, 1977, COMMUN ACM, V20, P820, DOI 10.1145/359863.359882; Tsuji S., 1986, Proceedings 1986 IEEE International Conference on Robotics and Automation (Cat. No.86CH2282-2), P1594; VANVEEN TM, 1981, PATTERN RECOGN, V14, P137, DOI 10.1016/0031-3203(81)90055-8; WALLACE R, 1985, 9TH P INT JOINT C AR, V2, P1089; WAXMAN AM, 1985 P IEEE INT C RO; YALAMANCHILI S, 1985, PATTERN RECOGN, V18, P17, DOI 10.1016/0031-3203(85)90003-2	23	39	42	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1988	10	1					121	125		10.1109/34.3876	http://dx.doi.org/10.1109/34.3876			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	L4366					2022-12-18	WOS:A1988L436600013
J	MEER, P; BAUGHER, ES; ROSENFELD, A				MEER, P; BAUGHER, ES; ROSENFELD, A			FREQUENCY-DOMAIN ANALYSIS AND SYNTHESIS OF IMAGE PYRAMID GENERATING KERNELS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											MEER, P (corresponding author), UNIV MARYLAND,CTR AUTOMAT RES,COLLEGE PK,MD 20742, USA.							BAUGHER ES, 1985, CSTR1488 U MAR COMP; BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; CASTAN S, 1985, JUN P CVPR 85 SAN FR, P420; Crochiere R. E., 1983, MULTIRATE DIGITAL SI; HONG TH, 1984, IEEE T PATTERN ANAL, V6, P222, DOI 10.1109/TPAMI.1984.4767505; MCCLELLAN JH, 1973, IEEE T ACOUST SPEECH, VAU21, P506, DOI 10.1109/TAU.1973.1162525; Oppenheim A.V., 1975, DIGIT SIGNAL PROCESS; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; WELLS WM, 1986, IEEE T PATTERN ANAL, V8, P234, DOI 10.1109/TPAMI.1986.4767776	9	39	39	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1987	9	4					512	522		10.1109/TPAMI.1987.4767939	http://dx.doi.org/10.1109/TPAMI.1987.4767939			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	H9088	21869409				2022-12-18	WOS:A1987H908800005
J	PEET, FG; SAHOTA, TS				PEET, FG; SAHOTA, TS			SURFACE CURVATURE AS A MEASURE OF IMAGE TEXTURE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											PEET, FG (corresponding author), ENVIRONM CANADA,CANADIAN FORESTRY SERV,PACIFIC FOREST RES CTR,VICTORIA V8Z 1M5,BC,CANADA.							BARTELS PH, 1980, METHODS CELL SEPARAT, V3; Dengler J., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P863; DRESCHLER L, 1981, MODELLE STRUKTUREN, V49, P76; FISHER R, 1953, PROC R SOC LON SER-A, V217, P295, DOI 10.1098/rspa.1953.0064; GENCHI H, 1965, DENKIN TSUSHIN GAK 1; Guggenheimer H.W., 1963, DIFFERENTIAL GEOMETR; Hall E. L., 1979, COMPUTER IMAGE PROCE; HARALICK RM, 1981, COMPUT VISION GRAPH, V15, P113, DOI 10.1016/0146-664X(81)90073-3; HARALICK RM, 1983, INT J ROBOT RES, V2, P50, DOI 10.1177/027836498300200105; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HARRIS R, 1978, J APPL METEOROL, V17, P1258, DOI 10.1175/1520-0450(1978)017<1258:TAON>2.0.CO;2; NACKMAN LR, 1984, IEEE T PATTERN ANAL, V6, P442, DOI 10.1109/TPAMI.1984.4767549; ONeill B., 1966, ELEMENTARY DIFFERENT; PEET FG, 1984, ANAL QUANT CYTOL, V6, P59; Peucker T. K., 1975, Computer Graphics and Image Processing, V4, P375, DOI 10.1016/0146-664X(75)90005-2; Pratt W. K., 1978, DIGITAL IMAGE PROCES; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2; ROSENFELD A, 1970, PICTURE PROCESSING P; SHERWOOD EM, 1976, ACTA CYTOL, V20, P255; STRUIK DJ, 1961, LECTURES CLASSICAL D; TANAKA N, 1977, ACTA CYTOL, V21, P72; TORIWAKI JI, 1978, COMPUT VISION GRAPH, V7, P30, DOI 10.1016/S0146-664X(78)80012-4; VIDAL BDC, 1973, ACTA CYTOL, V17, P510; Yokoi S., 1975, System - Computers - Controls, V6, P77	25	39	41	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	6					734	738		10.1109/TPAMI.1985.4767733	http://dx.doi.org/10.1109/TPAMI.1985.4767733			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ATG05	21869315				2022-12-18	WOS:A1985ATG0500015
J	WERMAN, M; PELEG, S				WERMAN, M; PELEG, S			MIN-MAX OPERATORS IN TEXTURE ANALYSIS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											WERMAN, M (corresponding author), UNIV MARYLAND, CTR AUTOMATED RES, COLLEGE PK, MD 20742 USA.		Peleg, Shmuel/B-7454-2011	Peleg, Shmuel/0000-0002-4468-2619				BENTLEY JL, 1980, ACTA INFORM, V13, P155, DOI 10.1007/BF00263991; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; Galloway MM., 1975, COMPUT GRAPHICS IMAG, V4, DOI DOI 10.1016/S0146-664X(75)80008-6; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; JACKINS CL, 1980, COMPUT VISION GRAPH, V14, P249, DOI 10.1016/0146-664X(80)90055-6; Peleg S, 1984, IEEE Trans Pattern Anal Mach Intell, V6, P518, DOI 10.1109/TPAMI.1984.4767557; PELEG S, 1981, IEEE T PATTERN ANAL, V3, P208, DOI 10.1109/TPAMI.1981.4767082; SAMET H, 1981, J ACM, V28, P487, DOI 10.1145/322261.322267; Serra J., 1982, IMAGE ANAL MATH MORP; STERNBERG SR, 1983, COMPUTER, V16, P22, DOI 10.1109/MC.1983.1654163; SUPOWIT KJ, 1983, SIAM J COMPUT, V12, P118, DOI 10.1137/0212008; WERMAN M, J ALGORITHMS; WERMAN M, 1984, TR90 U MAR CTR AUT R; WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777; Wong A. K. C., 1982, Proceedings of PRIP 82. IEEE Computer Society Conference on Pattern Recognition and Image Processing, P208; Zadeh LA, 1975, FUZZY SETS THEIR APP	16	39	40	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	6					730	733		10.1109/TPAMI.1985.4767732	http://dx.doi.org/10.1109/TPAMI.1985.4767732			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ATG05	21869314				2022-12-18	WOS:A1985ATG0500014
J	ALTMANN, J; REITBOCK, HJP				ALTMANN, J; REITBOCK, HJP			A FAST CORRELATION METHOD FOR SCALE-INVARIANT AND TRANSLATION-INVARIANT PATTERN-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									GKSS RES CTR,GEESTHACHT,FED REP GER	Helmholtz Association; Helmholtz-Zentrum Geesthacht - Zentrum fur Material- und Kustenforschung	ALTMANN, J (corresponding author), UNIV MARBURG,ANGEW PHYS & EXPTL BIOPHYS ARBEITSGRP,D-3550 MARBURG,FED REP GER.							ALTES RA, 1978, J ACOUST SOC AM, V63, P174, DOI 10.1121/1.381708; Bracewell R, 1986, PENTAGRAM NOTATION C, V2nd, P192; Brigham E. O., 1974, FAST FOURIER TRANSFO; CASASENT D, 1976, OPT COMMUN, V17, P59, DOI 10.1016/0030-4018(76)90179-6; CASASENT D, 1977, APPL OPTICS, V16, P1472, DOI 10.1364/AO.16.001472; CASASENT D, 1977, P IEEE, V65, P77, DOI 10.1109/PROC.1977.10432; CAVANAGH P, 1978, PERCEPTION, V7, P167, DOI 10.1068/p070167; HAHN H, 1972, ELEKTRON RECHENANLAG, V14, P128; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; HUANG GC, 1975, APR EIA AIPR S U MAR; Kaas J.H., 1978, P151; REITBOCK HJ, 1978, 78IFOFEATR01 WEST RE; REITBOECK H, 1981, BIOPHYS STRUCT MECH, V7, P342, DOI 10.1007/BF02425472; SCHWARTZ EL, 1980, VISION RES, V20, P645, DOI 10.1016/0042-6989(80)90090-5; SCHWARTZ EL, 1980, BIOL CYBERN, V37, P63, DOI 10.1007/BF00364246; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; Titchmarsh E.C., 1959, INTRO THEORY FOURIER, V2; West G., 1979, Elektronische Informationsverarbeitung und Kybernetik (EIK), V15, P507	18	39	42	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	1					46	57		10.1109/TPAMI.1984.4767474	http://dx.doi.org/10.1109/TPAMI.1984.4767474			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SB213	21869164				2022-12-18	WOS:A1984SB21300005
J	KASHYAP, RL; LAPSA, PM				KASHYAP, RL; LAPSA, PM			SYNTHESIS AND ESTIMATION OF RANDOM-FIELDS USING LONG-CORRELATION MODELS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									VIRGINIA POLYTECH INST & STATE UNIV,DEPT ELECT ENGN,BLACKSBURG,VA 24061	Virginia Polytechnic Institute & State University	KASHYAP, RL (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.							ADLER R, 1975, INTRO GENERAL RELATI; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BRODATZ P, 1956, TEXTURES PHOTOGRAPHI; DELP EJ, 1979, PATTERN RECOGN, V11, P313, DOI 10.1016/0031-3203(79)90041-4; Granger C. W. J., 1980, Journal of Time Series Analysis, V1, P15, DOI 10.1111/j.1467-9892.1980.tb00297.x; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HOSKING JRM, 1981, BIOMETRIKA, V68, P165, DOI 10.1093/biomet/68.1.165; KASHYAP RL, 1982, P PATTERN RECOGNITIO; KASHYAP RL, 1980, 5TH P INT C PATT REC; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29; LAPSA PM, 1982, THESIS PURDUE U W LA; LARIMORE WE, 1977, P IEEE, V65, P961, DOI 10.1109/PROC.1977.10593; MODESTINO JW, 1981, IEEE T PATTERN ANAL, V3, P557, DOI 10.1109/TPAMI.1981.4767148; MODESTINO JW, 1980, IEEE T INFORM THEORY, V26, P44, DOI 10.1109/TIT.1980.1056138; WHITTLE P, 1954, BIOMETRIKA, V41, P434; WOODS JW, 1972, IEEE T INFORM THEORY, V18, P232, DOI 10.1109/TIT.1972.1054786	17	39	39	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	6					800	809		10.1109/TPAMI.1984.4767604	http://dx.doi.org/10.1109/TPAMI.1984.4767604			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TX361	22499661				2022-12-18	WOS:A1984TX36100014
J	DEVROYE, L				DEVROYE, L			ANY DISCRIMINATION RULE CAN HAVE AN ARBITRARILY BAD PROBABILITY OF ERROR FOR FINITE-SAMPLE SIZE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											DEVROYE, L (corresponding author), MCGILL UNIV,SCH COMP SCI,MONTREAL H3C 3G1,QUEBEC,CANADA.							Cover T, 1968, P HAW INT C SYST SCI, V415, P413; DEVROYE L, 1980, J MULTIVARIATE ANAL, V10, P539, DOI 10.1016/0047-259X(80)90068-8; DEVROYE L, 1978, 1978 P IEEE COMP SOC, P142; DEVROYE LP, 1980, ANN STAT, V8, P231, DOI 10.1214/aos/1176344949; GORDON L, 1978, ANN STAT, V6, P515, DOI 10.1214/aos/1176344197; GYORFI L, 1981, PROBLEMS CONTROL INF; Olshen R., 1977, ANN STAT, V5, P632; SPIEGELMAN C, 1980, ANN STAT, V8, P240, DOI 10.1214/aos/1176344950	9	39	42	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	2					154	157		10.1109/TPAMI.1982.4767222	http://dx.doi.org/10.1109/TPAMI.1982.4767222			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NE957	21869021				2022-12-18	WOS:A1982NE95700011
J	SCHALKOFF, RJ; MCVEY, ES				SCHALKOFF, RJ; MCVEY, ES			A MODEL AND TRACKING ALGORITHM FOR A CLASS OF VIDEO TARGETS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV VIRGINIA,SCH ENGN & APPL SCI,DEPT ELECT ENGN,CHARLOTTESVILLE,VA 22901	University of Virginia								ARMSTRONG RW, 1978, THESIS U VIRGINIA CH; CAFFORIO C, 1976, IEEE T INFORM THEORY, V22, P573, DOI 10.1109/TIT.1976.1055602; CHOW WK, 1977, IEEE T COMPUT, V26, P187; CLINE RE, 1964, SIAM J, V12, P589; DAHLQUIST GG, 1975, NUMERICAL METHODS; GANS D, 1969, TRANSFORMATIONS GEOM, pCH4; GERSHO A, 1979, P IEEE, V67, P196, DOI 10.1109/PROC.1979.11232; GILBERT AL, 1980, IEEE T PATTERN ANAL, V2, P47, DOI 10.1109/TPAMI.1980.4766969; GROMMES RJ, 1974, 1974 P IEEE SYST MAN, P93; LUBINSKI KS, 1977, COMPUTER DESIGN  DEC, P81; McVey E. S., 1978, 197 Joint Automatic Control Conference, P277; MCVEY ES, 1977, IEEE T AUTOMAT CONTR, V22, P680, DOI 10.1109/TAC.1977.1101578; MCVEY ES, 1979, 1979 P JOINT AUT CON; MILSTEIN LB, 1977, 1977 P C PATT REC IM, P148; MOSKOWITZ S, 1964, IEEE T AEROSP NAVIG, P254; MOSTAFAVI H, 1978, IEEE T AERO ELEC SYS, V14, P494, DOI 10.1109/TAES.1978.308611; MOSTAFAVI H, 1978, IEEE T AEROSP ELECTR, V14; NAHI N, 1978, IEEE T AUTOMATIC CON, V13, P834; NETRAVALI AN, 1979, AT&T TECH J, V58, P631, DOI 10.1002/j.1538-7305.1979.tb02238.x; Oppenheim A.V., 1975, DIGIT SIGNAL PROCESS; PARRISH EA, 1976, IEEE T COMPUT, V25; ROACH JW, 1979, IEEE T PATTERN ANAL, V1, P127, DOI 10.1109/TPAMI.1979.4766898; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SCHALKOFF RJ, 1979, THESIS U VIRGINIA CH; SCHALKOFF RJ, 1979, DISCRETE ANALOG PROC; SEQUIN CH, 1970, CHARGE TRANSFER DEVI; TANIMOTO S, 1978, 1978 P C PATT REC IM, P280; UNO T, 1976, PATTERN RECOGN, V8, P201, DOI 10.1016/0031-3203(76)90040-6	28	39	42	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	1					2	10		10.1109/TPAMI.1982.4767188	http://dx.doi.org/10.1109/TPAMI.1982.4767188			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MY534	21868996				2022-12-18	WOS:A1982MY53400002
J	Fu, KR; Fan, DP; Ji, GP; Zhao, QJ; Shen, JB; Zhu, C				Fu, Keren; Fan, Deng-Ping; Ji, Ge-Peng; Zhao, Qijun; Shen, Jianbing; Zhu, Ce			Siamese Network for RGB-D Salient Object Detection and Beyond	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Siamese network; RGB-D SOD; saliency detection; salient object detection; RGB-D semantic segmentation	IMAGE; SEGMENTATION; DEEP; FUSION; MODEL; CONVOLUTION; FRAMEWORK; CONTRAST; FEATURES; ENERGY	Existing RGB-D salient object detection (SOD) models usually treat RGB and depth as independent information and design separate networks for feature extraction from each. Such schemes can easily be constrained by a limited amount of training data or over-reliance on an elaborately designed training process. Inspired by the observation that RGB and depth modalities actually present certain commonality in distinguishing salient objects, a novel joint learning and densely cooperative fusion (JL-DCF) architecture is designed to learn from both RGB and depth inputs through a shared network backbone, known as the Siamese architecture. In this paper, we propose two effective components: joint learning (JL), and densely cooperative fusion (DCF). The JL module provides robust saliency feature learning by exploiting cross-modal commonality via a Siamese network, while the DCF module is introduced for complementary feature discovery. Comprehensive experiments using five popular metrics show that the designed framework yields a robust RGB-D saliency detector with good generalization. As a result, JL-DCF significantly advances the state-of-the-art models by an average of similar to 2.0% (max F-measure) across seven challenging datasets. In addition, we show that JL-DCF is readily applicable to other related multi-modal detection tasks, including RGB-T (thermal infrared) SOD and video SOD, achieving comparable or even better performance against state-of-the-art methods. We also link JL-DCF to the RGB-D semantic segmentation field, showing its capability of outperforming several semantic segmentation models on the task of RGB-D SOD. These facts further confirm that the proposed framework could offer a potential solution for various applications and provide more insight into the cross-modal complementarity task.	[Fu, Keren; Zhao, Qijun] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Sichuan, Peoples R China; [Fu, Keren; Zhao, Qijun] Sichuan Univ, Natl Key Lab Fundamental Sci Synthet Vis, Chengdu 610017, Sichuan, Peoples R China; [Fan, Deng-Ping] Nankai Univ, Coll Comp Sci, Tianjin 300350, Peoples R China; [Ji, Ge-Peng] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China; [Shen, Jianbing] Univ Macau, Dept Comp & Informat Sci, State Key Lab Internet Things Smart City, Macau, Peoples R China; [Zhu, Ce] Univ Elect Sci & Technol China, Sch Informat & Commun Engn, Chengdu 611731, Sichuan, Peoples R China	Sichuan University; Sichuan University; Nankai University; Wuhan University; University of Macau; University of Electronic Science & Technology of China	Fan, DP (corresponding author), Nankai Univ, Coll Comp Sci, Tianjin 300350, Peoples R China.	fkrsuper@scu.edu.cn; dengpingfan@mail.nankai.edu.cn; gepengaiji@gmail.com; qjzhao@scu.edu.cn; shenjianbingcg@gmail.com; eczhu@uestc.edu.cn	Fan, Deng-Ping/ABD-4052-2020; Zhu, Ce/AEN-1875-2022	Fan, Deng-Ping/0000-0002-5245-7518; Shen, Jianbing/0000-0002-4109-8353	NSFC [61703077, 61773270, 61971005, U19A2052]	NSFC(National Natural Science Foundation of China (NSFC))	This work was supported in part by the NSFC, under Grants 61703077, 61773270, 61971005, and U19A2052. The authors would like to thank Yao Jiang and Suhang Li for their help on implementing JL-DCF in Pytorch. A preliminary version of this work has appeared in CVPR 2020 [1].	Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Al Azzeh J., 2016, INT J COMPUT APPL, V153, P31; Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56; Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833; Borji A, 2019, COMPUT VIS MEDIA, V5, P117, DOI 10.1007/s41095-019-0149-9; Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339; Chen H, 2018, PROC CVPR IEEE, P3051, DOI 10.1109/CVPR.2018.00322; Chen H, 2019, IEEE T IMAGE PROCESS, V28, P2825, DOI 10.1109/TIP.2019.2891104; Chen H, 2019, PATTERN RECOGN, V86, P376, DOI 10.1016/j.patcog.2018.08.007; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen LZ, 2021, IEEE T IMAGE PROCESS, V30, P2313, DOI 10.1109/TIP.2021.3049332; Chen YL, 2019, INT CONF 3D VISION, P173, DOI 10.1109/3DV.2019.00028; Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670; Cheng JC, 2018, PROC CVPR IEEE, P7415, DOI 10.1109/CVPR.2018.00774; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Cheng Y., 2014, P INT C INTERNET MUL, P23; Cheng YH, 2017, PROC CVPR IEEE, P1475, DOI 10.1109/CVPR.2017.161; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Cong RM, 2020, IEEE T CYBERNETICS, V50, P3627, DOI 10.1109/TCYB.2019.2932005; Cong RM, 2019, IEEE T IMAGE PROCESS, V28, P4819, DOI 10.1109/TIP.2019.2910377; Cong RM, 2016, IEEE SIGNAL PROC LET, V23, DOI 10.1109/LSP.2016.2557347; Couprie Camille, 2013, 1 INT C LEARN REPR I; Deng L., 2019, ARXIV; Deng-Ping Fan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P275, DOI 10.1007/978-3-030-58610-2_17; Ding YY, 2011, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2011.5995445; Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487; Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406; Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12; Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875; [范登平 Fan Dengping], 2021, [中国科学. 信息科学, Scientia Sinica Informationis], V51, P1475; Fang YM, 2020, IEEE T IND ELECTRON, V67, P9893, DOI 10.1109/TIE.2019.2956418; Feng D, 2016, PROC CVPR IEEE, P2343, DOI 10.1109/CVPR.2016.257; Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172; Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326; Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312; Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062; Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758; Gao Y, 2015, IEEE T MULTIMEDIA, V17, P359, DOI 10.1109/TMM.2015.2389616; Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929; Gu YC, 2020, AAAI CONF ARTIF INTE, V34, P10869; Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969; Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630; Guo J., 2016, PAPER PRESENTED IEEE, P1; Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23; Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775; Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028; Hazirbas C, 2017, LECT NOTES COMPUT SC, V10111, P213, DOI 10.1007/978-3-319-54181-5_14; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang PS, 2018, INT CONF DIGIT SIG; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Jerripothula KR, 2016, IEEE T MULTIMEDIA, V18, P1896, DOI 10.1109/TMM.2016.2576283; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222; Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17; Khamis S, 2018, LECT NOTES COMPUT SC, V11219, P596, DOI 10.1007/978-3-030-01267-0_35; Kim H, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2425544; Koch G., 2015, ICML DEEP LEARN WORK; Li GB, 2018, PROC CVPR IEEE, P3243, DOI 10.1109/CVPR.2018.00342; Li J, 2018, IEEE T IMAGE PROCESS, V27, P349, DOI 10.1109/TIP.2017.2762594; Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359; Li SY, 2018, LECT NOTES COMPUT SC, V11207, P215, DOI 10.1007/978-3-030-01219-9_13; Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306; Li Z, 2016, LECT NOTES COMPUT SC, V9906, P541, DOI 10.1007/978-3-319-46475-6_34; Liang FF, 2018, NEUROCOMPUTING, V275, P2227, DOI 10.1016/j.neucom.2017.10.052; Lin D, 2017, IEEE I CONF COMP VIS, P1320, DOI 10.1109/ICCV.2017.147; Liu GH, 2014, PROCEEDINGS OF 2013 INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CLOUD COMPUTING COMPANION (ISCC-C), P728, DOI 10.1109/ISCC-C.2013.21; Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404; Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80; Liu RF, 2006, EARTHQ SCI, V19, P1; Liu ZY, 2019, NEUROCOMPUTING, V363, P46, DOI 10.1016/j.neucom.2019.07.012; Liu Z, 2017, IEEE T CIRC SYST VID, V27, P2527, DOI 10.1109/TCSVT.2016.2595324; Liu Z, 2012, IEEE T MULTIMEDIA, V14, P1275, DOI 10.1109/TMM.2012.2190385; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Luo WJ, 2016, PROC CVPR IEEE, P5695, DOI 10.1109/CVPR.2016.614; Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410; Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467; Marvasti-Zadeh SM, 2022, IEEE T INTELL TRANSP, V23, P3943, DOI 10.1109/TITS.2020.3046478; Nian Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13753, DOI 10.1109/CVPR42600.2020.01377; Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708; Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242; Oh SW, 2018, PROC CVPR IEEE, P7376, DOI 10.1109/CVPR.2018.00770; Park SJ, 2017, IEEE I CONF COMP VIS, P4990, DOI 10.1109/ICCV.2017.533; Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743; Piao YR, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P904; Piao YR, 2019, IEEE I CONF COMP VIS, P7253, DOI 10.1109/ICCV.2019.00735; Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5; Qi XJ, 2017, IEEE I CONF COMP VIS, P5209, DOI 10.1109/ICCV.2017.556; Qu LQ, 2017, IEEE T IMAGE PROCESS, V26, P2274, DOI 10.1109/TIP.2017.2682981; Ronneberger O., 2015, P INT C MED IM COMP; Rutishauser U, 2004, PROC CVPR IEEE, P37; Shigematsu R, 2017, IEEE INT CONF COMP V, P2749, DOI 10.1109/ICCVW.2017.323; Simonyan K., 2015, P INT C LEARN REPR, P1, DOI DOI 10.48550/ARXIV.1409.1556; Song HK, 2017, IEEE T IMAGE PROCESS, V26, P4204, DOI 10.1109/TIP.2017.2711277; Song HM, 2018, LECT NOTES COMPUT SC, V11215, P744, DOI 10.1007/978-3-030-01252-6_44; Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28; Stentiford F., 2007, P 5 INT C COMP VIS S; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tang J, 2020, IEEE T CIRC SYST VID, V30, P4421, DOI 10.1109/TCSVT.2019.2951621; Tao Zhou, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10274, DOI 10.1109/CVPR42600.2020.01029; Tu ZZ, 2020, IEEE T MULTIMEDIA, V22, P160, DOI 10.1109/TMM.2019.2924578; Voigtlaender P, 2020, PROC CVPR IEEE, P6577, DOI 10.1109/CVPR42600.2020.00661; Wang AZ, 2017, IEEE SIGNAL PROC LET, V24, P663, DOI 10.1109/LSP.2017.2688136; Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683; Wang JH, 2016, LECT NOTES COMPUT SC, V9909, P664, DOI 10.1007/978-3-319-46454-1_40; Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404; Wang NN, 2019, IEEE ACCESS, V7, P55277, DOI 10.1109/ACCESS.2019.2913107; Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142; Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274; Wang WY, 2018, LECT NOTES COMPUT SC, V11215, P144, DOI 10.1007/978-3-030-01252-6_9; Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3239, DOI 10.1109/TPAMI.2021.3051099; Wang WG, 2021, IEEE T PATTERN ANAL, V43, P220, DOI 10.1109/TPAMI.2019.2924417; Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933; Wang WG, 2019, PROC CVPR IEEE, P1448, DOI 10.1109/CVPR.2019.00154; Wang WG, 2019, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2019.00318; Wang WG, 2019, PROC CVPR IEEE, P5961, DOI 10.1109/CVPR.2019.00612; Wang WG, 2018, PROC CVPR IEEE, P1711, DOI 10.1109/CVPR.2018.00184; Wang WG, 2017, IEEE I CONF COMP VIS, P2205, DOI 10.1109/ICCV.2017.240; Wang Wenguan, 2018, IEEE Trans Image Process, V27, P38, DOI 10.1109/TIP.2017.2754941; Wang WG, 2016, IEEE T IMAGE PROCESS, V25, P5025, DOI 10.1109/TIP.2016.2601784; Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013; Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1; Xiaokang Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P561, DOI 10.1007/978-3-030-58621-8_33; Xu MZ, 2020, IEEE T CIRC SYST VID, V30, P2191, DOI 10.1109/TCSVT.2019.2920652; Xu MZ, 2019, IEEE T MULTIMEDIA, V21, P2790, DOI 10.1109/TMM.2019.2914889; Yajie Xing, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P555, DOI 10.1007/978-3-030-58529-7_33; Ye LW, 2017, IEEE T MULTIMEDIA, V19, P1742, DOI 10.1109/TMM.2017.2693022; Zhai YJ, 2021, Arxiv, DOI arXiv:2007.02713; Yongri Piao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9057, DOI 10.1109/CVPR42600.2020.00908; Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064; Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767; Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393; Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4; Zhang J, 2020, P IEEE CVF C COMP VI, P8582; Zhang Junpeng, 2021, IEEE T PATTERN ANAL, P1; Zhang Kaihua, 2020, P IEEE CVF C COMP VI, P9050; Zhang M, 2020, PROC CVPR IEEE, P3469, DOI 10.1109/CVPR42600.2020.00353; Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31; Zhang Q, 2020, IEEE T IMAGE PROCESS, V29, P3321, DOI 10.1109/TIP.2019.2959253; Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081; Zhang Z, 2021, IEEE T IMAGE PROCESS, V30, P1949, DOI 10.1109/TIP.2021.3049959; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405; Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887; Zhao JW, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1745, DOI 10.1145/3394171.3413855; Tu ZZ, 2021, Arxiv, DOI arXiv:2005.02315; Zhu CB, 2019, IEEE INT CON MULTI, P199, DOI 10.1109/ICME.2019.00042	154	38	38	18	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					5541	5559		10.1109/TPAMI.2021.3073689	http://dx.doi.org/10.1109/TPAMI.2021.3073689			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33861691	Green Submitted			2022-12-18	WOS:000836666600074
J	Oprea, S; Martinez-Gonzalez, P; Garcia-Garcia, A; Castro-Vargas, JA; Orts-Escolano, S; Garcia-Rodriguez, J; Argyros, A				Oprea, Sergiu; Martinez-Gonzalez, Pablo; Garcia-Garcia, Alberto; Castro-Vargas, John Alejandro; Orts-Escolano, Sergio; Garcia-Rodriguez, Jose; Argyros, Antonis			A Review on Deep Learning Techniques for Video Prediction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review						Predictive models; Task analysis; Uncertainty; Deep learning; Computational modeling; Video sequences; Training; Video prediction; future frame prediction; deep learning; representation learning; self-supervised learning	VISUAL-CORTEX; REPRESENTATIONS; RECOGNITION; MOTION; IMAGE	The ability to predict, anticipate and reason about future outcomes is a key component of intelligent decision-making systems. In light of the success of deep learning in computer vision, deep-learning-based video prediction emerged as a promising research direction. Defined as a self-supervised learning task, video prediction represents a suitable framework for representation learning, as it demonstrated potential capabilities for extracting meaningful representations of the underlying patterns in natural videos. Motivated by the increasing interest in this task, we provide a review on the deep learning methods for prediction in video sequences. We first define the video prediction fundamentals, as well as mandatory background concepts and the most used datasets. Next, we carefully analyze existing video prediction models organized according to a proposed taxonomy, highlighting their contributions and their significance in the field. The summary of the datasets and methods is accompanied with experimental results that facilitate the assessment of the state of the art on a quantitative basis. The paper is summarized by drawing some general conclusions, identifying open research challenges and by pointing out future research directions.	[Oprea, Sergiu; Martinez-Gonzalez, Pablo; Castro-Vargas, John Alejandro; Garcia-Rodriguez, Jose] Univ Alicante, Dept Comp Technol, E-03690 Alicante, Spain; [Orts-Escolano, Sergio] Univ Alicante, Dept Comp Sci & Artificial Intelligence, E-03690 Alicante, Spain; [Garcia-Garcia, Alberto] Inst Space Sci ICE CSIC, Campus UAB, E-08193 Barcelona, Spain; [Argyros, Antonis] FORTH, Inst Comp Sci, GR-70013 Iraklion, Greece; [Argyros, Antonis] Univ Crete, Dept Comp Sci, Iraklion 700, Greece	Universitat d'Alacant; Universitat d'Alacant; Autonomous University of Barcelona; Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Instituto de Ciencias del Espacio (ICE); Foundation for Research & Technology - Hellas (FORTH); University of Crete	Oprea, S (corresponding author), Univ Alicante, Dept Comp Technol, E-03690 Alicante, Spain.	soprea@dtic.ua.es; pmartinez@dtic.ua.es; garciagarcia@ice.csic.es; jacastro@dtic.ua.es; sorts@dccia.ua.es; jgarcia@dtic.ua.es; argyros@ics.forth.gr	Argyros, Antonis/GPK-4775-2022; Orts-Escolano, Sergio/L-4671-2014; GARCIA-RODRIGUEZ, JOSE/M-1388-2014	Argyros, Antonis/0000-0001-8230-3192; Orts-Escolano, Sergio/0000-0001-6817-6326; Martinez Gonzalez, Pablo/0000-0001-6037-9815; GARCIA-RODRIGUEZ, JOSE/0000-0002-7798-3055; Garcia-Garcia, Alberto/0000-0002-9575-6403	Spanish Government [PID2019-104818RB-I00]; Feder funds; Spanish national grants [FPU17/00166, ACIF/2018/197]	Spanish Government(Spanish GovernmentEuropean Commission); Feder funds(European Commission); Spanish national grants	This work was supported by the Spanish Government PID2019-104818RB-I00 Grant for the MoDeaAS project, supported with Feder funds. This work was also been supported by two Spanish national grants for PhD studies, FPU17/00166, and ACIF/2018/197 respectively. The authors also acknowledge Zuria Bauer and Victor Villena-Martinez for their valuable discussion and support on this work.	Abu-El-Haija S, 2016, YOUTUBE 8M LARGE SCA; Agrawal P., 2016, ADV NEURAL INFORM PR, P5074; Agrawal P, 2015, IEEE I CONF COMP VIS, P37, DOI 10.1109/ICCV.2015.13; Aigner S., 2018, ARXIV 181001325; Aigner S, 2020, MACH LEARN KNOW EXTR, V2, DOI 10.3390/make2020006; [Anonymous], EUR J NEUROSCI, DOI [10.1016/j.medj.2022.03.004, DOI 10.1016/0735-1933(85)90003-X]; Babaeizadeh Mohammad, 2018, ICLR; Baker R, 2014, VISION RES, V99, P124, DOI 10.1016/j.visres.2013.10.017; Bauer Z, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0168-5; Bellemare MG, 2013, J ARTIF INTELL RES, V47, P253, DOI 10.1613/jair.3912; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bhattacharyya A, 2018, PROC CVPR IEEE, P4194, DOI 10.1109/CVPR.2018.00441; Bhattacharyya Apratim, 2019, ICLR, P7; Brostow GJ, 2008, LECT NOTES COMPUT SC, V5302, P44, DOI 10.1007/978-3-540-88682-2_5; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21; Byeon W, 2018, LECT NOTES COMPUT SC, V11220, P781, DOI 10.1007/978-3-030-01270-0_46; Cadieu CF, 2012, NEURAL COMPUT, V24, P827, DOI 10.1162/NECO_a_00247; Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164; Carl V., 2016, ADV NEURAL INFORM PR, V29, P613, DOI DOI 10.13016/M26GIH-TNYZ; Carreira J., 2018, ARXIV 180801340; Castrejon L, 2019, IEEE I CONF COMP VIS, P7607, DOI 10.1109/ICCV.2019.00770; Chen BY, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P358, DOI 10.1145/3126686.3126737; Chen XT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1503, DOI 10.1145/3123266.3123349; Chiappa Silvia, 2017, ARXIV170402254; Chiu HK, 2020, IEEE ROBOT AUTOM LET, V5, P4202, DOI 10.1109/LRA.2020.2992184; Choi C., 2020, ARXIV 200400202; Clark Aidan, 2019, ARXIV190706571; CLEEREMANS A, 1991, J EXP PSYCHOL GEN, V120, P235, DOI 10.1037/0096-3445.120.3.235; Cleeremans A, 1993, MECH IMPLICIT LEARNI; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Cricri F., 2016, ABS161201756 CORR; Dasari S., 2019, ARXIV 191011215; De Brabandere B, 2016, ADV NEUR IN, V29; Deco G, 2001, NEURAL PROCESS LETT, V14, P107, DOI 10.1023/A:1012423722458; den Ouden HEM, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00548; Denton E, 2018, PR MACH LEARN RES, V80; Dosovitskiy Alexey, 2017, INT C LEARN REPR ICL; Dosovitskiy Alexey, 2016, NEURIPS; Ebert F., 2018, ARXIV 181200568; Ebert Frederik, 2017, ARXIV171005268; Fragkiadaki K., 2016, ICLR; Fragkiadaki K., 2017, ARXIV 170502082; Fushishita N., 2019, ARXIV 190407538; Gammulle H, 2019, IEEE I CONF COMP VIS, P5561, DOI 10.1109/ICCV.2019.00566; Gao H, 2019, IEEE I CONF COMP VIS, P9005, DOI 10.1109/ICCV.2019.00910; Garcia-Garcia A, 2018, IEEE INT C INT ROBOT, P6790, DOI 10.1109/IROS.2018.8594495; Garcia-Garcia A, 2018, APPL SOFT COMPUT, V70, P41, DOI 10.1016/j.asoc.2018.05.018; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Goncalves GR, 2018, SIBGRAPI, P110, DOI 10.1109/SIBGRAPI.2018.00021; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Goroshin R, 2015, IEEE I CONF COMP VIS, P4086, DOI 10.1109/ICCV.2015.465; Goyal R, 2017, IEEE I CONF COMP VIS, P5843, DOI 10.1109/ICCV.2017.622; Gulrajani I., 2017, NEURALPS, P5769, DOI 10.5555/3295222.3295327; Hafner D., 2020, ICLR; Hafner D, 2019, PR MACH LEARN RES, V97; Hao ZK, 2018, PROC CVPR IEEE, P7854, DOI 10.1109/CVPR.2018.00819; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Henaff M., 2017, ARXIV 171104994; Hinton G., 2015, ARXIV150302531; Hollingworth A, 2004, J EXP PSYCHOL HUMAN, V30, P519, DOI 10.1037/0096-1523.30.3.519; Hou R., 2019, P 2019 22 INT C ELEC, P1, DOI DOI 10.1109/ICEMS.2019.8921675; Hsieh JT, 2018, ADV NEUR IN, V31; Hu Anthony, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P767, DOI 10.1007/978-3-030-58517-4_45; Hu Z., 2019, PROC IEEECVF INT C C; Huang DA, 2018, PROC CVPR IEEE, P7366, DOI 10.1109/CVPR.2018.00769; Hwang JJ, 2019, PROC CVPR IEEE, P4051, DOI 10.1109/CVPR.2019.00418; iarai, TRAFFIC4CAST TRAFFIC; Idrees H, 2017, COMPUT VIS IMAGE UND, V155, P1, DOI 10.1016/j.cviu.2016.10.018; Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248; Jaderberg M, 2015, ADV NEUR IN, V28; Janai J, 2018, LECT NOTES COMPUT SC, V11220, P713, DOI 10.1007/978-3-030-01270-0_42; Janocha K., 2017, ARXIV 170205659; Jayaraman D, 2016, LECT NOTES COMPUT SC, V9909, P489, DOI 10.1007/978-3-319-46454-1_30; Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396; Jin BB, 2020, PROC CVPR IEEE, P4553, DOI 10.1109/CVPR42600.2020.00461; Jin BB, 2018, IEEE INT C INT ROBOT, P5801, DOI 10.1109/IROS.2018.8594264; Jin XJ, 2017, IEEE I CONF COMP VIS, P5581, DOI 10.1109/ICCV.2017.595; Jin Xiaojie, 2017, NEURIPS, P2; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kaiser L., 2019, ARXIV190300374; Kalchbrenner N, 2017, PR MACH LEARN RES, V70; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Karras Tero, 2018, INT C LEARN REPR; Kendall A, 2017, PROC CVPR IEEE, P6555, DOI 10.1109/CVPR.2017.694; Kingma DP, 2018, ADV NEUR IN, V31; Kingma DP, 2 INT C LEARN REPR I, P1; Klein B, 2015, PROC CVPR IEEE, P4840, DOI 10.1109/CVPR.2015.7299117; Kong Y., 2018, ARXIV 180611230; Koppula HS, 2016, IEEE T PATTERN ANAL, V38, P14, DOI 10.1109/TPAMI.2015.2430335; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Kumar M., 2020, PROC INT C LEARN REP; Kwon YH, 2019, PROC CVPR IEEE, P1811, DOI 10.1109/CVPR.2019.00191; LeCun Y, 2004, PROC CVPR IEEE, P97; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Lee A. X., 2018, ARXIV 180401523; Lee J., 2019, PROC BRIT MACH VIS C, P296; Liang XD, 2017, IEEE I CONF COMP VIS, P1762, DOI 10.1109/ICCV.2017.194; Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684; Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI 10.1109/ICCV.2017.478; Lotter W., 2017, ICLR, DOI [DOI 10.48550/ARXIV.1605.08104, 10.48550/arXiv.1605.08104]; Lotter William, 2015, ARXIV151106380; Lu CC, 2017, PROC CVPR IEEE, P2137, DOI 10.1109/CVPR.2017.230; Luc P., 2019, THESES; Luc P., 2020, ARXIV 200304035; Luc P, 2018, LECT NOTES COMPUT SC, V11213, P593, DOI 10.1007/978-3-030-01240-3_36; Luc P, 2017, IEEE I CONF COMP VIS, P648, DOI 10.1109/ICCV.2017.77; Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Mathieu M., 2016, P INT C LEARN REPR P; Memisevic R., 2013, PROC 30 INT C MACH L, P100; Memisevic R, 2013, IEEE T PATTERN ANAL, V35, P1829, DOI 10.1109/TPAMI.2013.53; Memisevic R, 2011, IEEE I CONF COMP VIS, P1591, DOI 10.1109/ICCV.2011.6126419; Memisevic R, 2010, NEURAL COMPUT, V22, P1473, DOI 10.1162/neco.2010.01-09-953; Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925; Michalski V, 2014, ADV NEUR IN, V27; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Minderer Matthias, 2019, ARXIV190607889; Misra I, 2016, LECT NOTES COMPUT SC, V9905, P527, DOI 10.1007/978-3-319-46448-0_32; Mnih V, 2016, PR MACH LEARN RES, V48; Nabavi Seyed Shahabeddin, 2018, BMVC; Neuhold G, 2017, IEEE I CONF COMP VIS, P5000, DOI 10.1109/ICCV.2017.534; Oh J., 2015, P ADV NEUR INF PROC, P2863; Oliu M, 2018, LECT NOTES COMPUT SC, V11218, P745, DOI 10.1007/978-3-030-01264-9_44; Patraucean Viorica, 2015, ARXIV151106309; Pickup LC, 2014, PROC CVPR IEEE, P2043, DOI 10.1109/CVPR.2014.262; Pottorff R., 2019, ARXIV 190300133; Premont-Schwarz I., 2017, ADV NEURAL INFORM PR, V30, P6011; Ranzato MarcAurelio, 2014, ARXIV14126604; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577; Reda FA, 2018, LECT NOTES COMPUT SC, V11211, P747, DOI 10.1007/978-3-030-01234-2_44; Reed S, 2015, ADV NEURAL INFORM PR, P1252; Revaud J, 2015, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR.2015.7298720; Rodriguez C., 2018, P EUR C COMP VIS ECC; Rosca M., 2017, ARXIV 170604987; Sajjadi MSM, 2017, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2017.481; Salimans T, 2016, ADV NEUR IN, V29; Santana E., 2016, ARXIV160801230; Santner J, 2010, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2010.5540145; Saric Josip, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10645, DOI 10.1109/CVPR42600.2020.01066; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Seguin G, 2016, PROC CVPR IEEE, P3678, DOI 10.1109/CVPR.2016.400; Shi XJ, 2015, ADV NEUR IN, V28; Shi XJ, 2017, ADV NEUR IN, V30; Shouno O., 2020, ARXIV 200308635; Simonyan K., 2015, INT C LEARN REPR ICL; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Softky WR, 1996, ADV NEUR IN, V8, P809; Sonderby CK, 2016, ADV NEUR IN, V29; Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28; Soomro K., 2012, ARXIV; Srivastava N, 2015, PR MACH LEARN RES, V37, P843; Sun JX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2043, DOI 10.1145/3343031.3350949; Sun P, 2020, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR42600.2020.00252; Sutskever I., 2008, ADV NEURAL INFORM PR, V21, P1601; Tang JL, 2019, IEEE IMAGE PROC, P614, DOI 10.1109/ICIP.2019.8803792; Terwilliger AM, 2019, IEEE WINT CONF APPL, P1703, DOI 10.1109/WACV.2019.00186; Theis Lucas, 2016, ICLR; Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802; Tulyakov S, 2018, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2018.00165; Unterthiner T., 2018, ARXIV 181201717; van Steenkiste Sjoerd, 2017, ADV NEURAL INFORM PR, P6691; vanAmersfoort J. R., 2017, ARXIV 170108435; VanSteenkiste S., 2018, P INT C LEARN REPR P; vanSteenkiste Sjoerd, 2019, ARXIV190512506; Vezzani R, 2010, MULTIMED TOOLS APPL, V50, P359, DOI 10.1007/s11042-009-0402-9; Villegas R, 2019, ADV NEUR IN, V32; Villegas R, 2017, PR MACH LEARN RES, V70; Villegas Ruben, 2017, ICLR 2017; Villena-Martinez V, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217524; Vondrick C, 2017, PROC CVPR IEEE, P2992, DOI 10.1109/CVPR.2017.319; Vondrick C, 2016, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.2016.18; Vora S., 2018, ARXIV 181111358; Walker J, 2017, IEEE I CONF COMP VIS, P3352, DOI 10.1109/ICCV.2017.361; Walker J, 2016, LECT NOTES COMPUT SC, V9911, P835, DOI 10.1007/978-3-319-46478-7_51; Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320; Wang Y., 2019, PROC INT C LEARN REP; Wang YB, 2018, PR MACH LEARN RES, V80; Wang YB, 2017, ADV NEUR IN, V30; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wei DL, 2018, PROC CVPR IEEE, P8052, DOI 10.1109/CVPR.2018.00840; Weissenborn D., 2020, PROC INT C LEARN REP; Wichers N, 2018, PR MACH LEARN RES, V80; Wu HY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185561; Wu Y, 2020, PROC CVPR IEEE, P5538, DOI 10.1109/CVPR42600.2020.00558; Xie AN, 2019, ROBOTICS: SCIENCE AND SYSTEMS XV; Xue Tianfan, 2016, 30 C NEURAL INFORM P; Yan XC, 2016, LECT NOTES COMPUT SC, V9908, P776, DOI 10.1007/978-3-319-46493-0_47; Ye YF, 2019, IEEE I CONF COMP VIS, P10352, DOI 10.1109/ICCV.2019.01045; Yu F., 2018, ARXIV 180504687; Yu F, 2017, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2017.75; Yu Weihao, 2020, ICLR; Zhan Eric, 2019, INT C LEARN REPR; Zhang JK, 2017, AAAI CONF ARTIF INTE, P2891; Zhang JJ, 2019, IEEE INT CON MULTI, P230, DOI 10.1109/ICME.2019.00048; Zhang JB, 2017, AAAI CONF ARTIF INTE, P1655; Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068; Zhang WY, 2013, IEEE I CONF COMP VIS, P2248, DOI 10.1109/ICCV.2013.280; Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhou YP, 2016, LECT NOTES COMPUT SC, V9912, P262, DOI 10.1007/978-3-319-46484-8_16; Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36	211	38	38	89	106	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2022	44	6					2806	2826		10.1109/TPAMI.2020.3045007	http://dx.doi.org/10.1109/TPAMI.2020.3045007			21	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1R1DD	33320810	Green Published, Green Submitted			2022-12-18	WOS:000803117500005
J	Yu, ZT; Wan, J; Qin, YX; Li, XB; Li, SZ; Zhao, GY				Yu, Zitong; Wan, Jun; Qin, Yunxiao; Li, Xiaobai; Li, Stan Z.; Zhao, Guoying			NAS-FAS: Static-Dynamic Central Difference Network Search for Face Anti-Spoofing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Face recognition; Convolution; Testing; Computer architecture; Protocols; Search problems; Face anti-spoofing; neural architecture search; convolution; pooling; static-dynamic; CASIA-SURF 3DMask		Face anti-spoofing (FAS) plays a vital role in securing face recognition systems. Existing methods heavily rely on the expert-designed networks, which may lead to a sub-optimal solution for FAS task. Here we propose the first FAS method based on neural architecture search (NAS), called NAS-FAS, to discover the well-suited task-aware networks. Unlike previous NAS works mainly focus on developing efficient search strategies in generic object classification, we pay more attention to study the search spaces for FAS task. The challenges of utilizing NAS for FAS are in two folds: the networks searched on 1) a specific acquisition condition might perform poorly in unseen conditions, and 2) particular spoofing attacks might generalize badly for unseen attacks. To overcome these two issues, we develop a novel search space consisting of central difference convolution and pooling operators. Moreover, an efficient static-dynamic representation is exploited for fully mining the FAS-aware spatio-temporal discrepancy. Besides, we propose Domain/Type-aware Meta-NAS, which leverages cross-domain/type knowledge for robust searching. Finally, in order to evaluate the NAS transferability for cross datasets and unknown attack types, we release a large-scale 3D mask dataset, namely CASIA-SURF 3DMask, for supporting the new 'cross-dataset cross-type' testing protocol. Experiments demonstrate that the proposed NAS-FAS achieves state-of-the-art performance on nine FAS benchmark datasets with four testing protocols.	[Yu, Zitong; Li, Xiaobai; Zhao, Guoying] Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu 90014, Finland; [Wan, Jun] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China; [Wan, Jun] Univ Chinese Acad Sci, Beijing 100190, Peoples R China; [Qin, Yunxiao] Northwestern Polytech Univ, Xian 710072, Peoples R China; [Li, Stan Z.] Westlake Univ, Sch Engn, Hangzhou 310012, Zhejiang, Peoples R China	University of Oulu; Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Northwestern Polytechnical University; Westlake University	Zhao, GY (corresponding author), Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu 90014, Finland.; Wan, J (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.	zitong.yu@oulu.fi; jun.wan@ia.ac.cn; gyxqyx@mail.nwpu.edu.cn; xiaobai.li@oulu.fi; stan.zq.li@westlake.edu.cn; guoying.zhao@oulu.fi	Zhao, Guoying/ABE-7716-2020	Zhao, Guoying/0000-0003-3694-206X; Yu, Zitong/0000-0001-6505-3304; Li, Xiaobai/0000-0003-4519-7823; wan, jun/0000-0002-4735-2885	Academy of Finland [316765]; Infotech Oulu; Chinese National Natural Science Foundation [61961160704, 61876179]; Science and Technology Development Fund of Macau [0025/2019/A1]; ICT 2023 project [328115]	Academy of Finland(Academy of Finland); Infotech Oulu; Chinese National Natural Science Foundation(National Natural Science Foundation of China (NSFC)); Science and Technology Development Fund of Macau; ICT 2023 project	This work was supported by the Academy of Finland for project MiGA (Grant 316765), ICT 2023 project (Grant 328115), Infotech Oulu, and the Chinese National Natural Science Foundation Projects #61961160704, #61876179, Science and Technology Development Fund of Macau No. 0025/2019/A1. The authors also wish to acknowledge CSCIT Center for Science, Finland.	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Amin J., 2018, P ECCV, P290; Arashloo SR, 2017, IEEE ACCESS, V5, P13868, DOI 10.1109/ACCESS.2017.2729161; Atoum Y, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P319, DOI 10.1109/BTAS.2017.8272713; Boulkenafet Z, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P688; Boulkenafet Z, 2017, IEEE SIGNAL PROC LET, V24, P141, DOI 10.1109/LSP.2016.2630740; Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286; Boulkenafet Z, 2015, IEEE IMAGE PROC, P2636, DOI 10.1109/ICIP.2015.7351280; Boulkenafet Z, 2017, IEEE INT CONF AUTOMA, P612, DOI 10.1109/FG.2017.77; CAI H., 2018, P INT C LEARN REPR; Chen X, 2019, IEEE I CONF COMP VIS, P1294, DOI 10.1109/ICCV.2019.00138; Chingovska I., 2012, EFFECTIVENESS LOCAL; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; de Freitas Pereira Tiago, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P121, DOI 10.1007/978-3-642-37410-4_11; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dong XT, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3023706; Elsken Thomas, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12362, DOI 10.1109/CVPR42600.2020.01238; Erdogmus N, 2014, IEEE T INF FOREN SEC, V9, P1084, DOI 10.1109/TIFS.2014.2322255; Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P557, DOI 10.1007/978-3-030-01264-9_33; Fernando B, 2017, IEEE T PATTERN ANAL, V39, P773, DOI 10.1109/TPAMI.2016.2558148; Gao ZT, 2019, IEEE I CONF COMP VIS, P3354, DOI 10.1109/ICCV.2019.00345; Georgescu A.-L., 2019, 2019 INT C BIOM ICB, P1, DOI DOI 10.1109/ICB45273.2019.8987370; Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720; Grant SJ, 2019, ARXIV PREPRINT ARXIV; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Howard A.G, 2017, ARXIV170404861; Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140; Hu H, 2019, IEEE I CONF COMP VIS, P3463, DOI 10.1109/ICCV.2019.00356; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S; Juefei-Xu F, 2017, PROC CVPR IEEE, P4284, DOI 10.1109/CVPR.2017.456; Kim Jaehong, 2018, ARXIV180606927; Kim T, 2019, IEEE INT CONF COMP V, P494, DOI 10.1109/ICCVW.2019.00062; Komulainen J., 2012, P AS C COMP VIS, P146; Komulainen J., 2013, INT C BIOMETRICS THE, P1; Li HL, 2018, PROC CVPR IEEE, P5400, DOI 10.1109/CVPR.2018.00566; Li L, 2016, INT CONF IMAG PROC; Li L, 2019, IEEE T INF FOREN SEC, V14, P2246, DOI 10.1109/TIFS.2019.2895212; Li XB, 2016, INT C PATT RECOG, P4244, DOI 10.1109/ICPR.2016.7900300; Lian D., 2019, P INT C LEARN REPR; Lin Bofan., 2019, PROC ACM INT C BIOME; Lin C, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P814; Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2; Liu H., 2018, ARXIV180609055; Liu SQ, 2016, LECT NOTES COMPUT SC, V9911, P85, DOI 10.1007/978-3-319-46478-7_6; Liu YJ, 2019, PROC CVPR IEEE, P4675, DOI 10.1109/CVPR.2019.00481; Liu YJ, 2018, PROC CVPR IEEE, P389, DOI 10.1109/CVPR.2018.00048; Luan SZ, 2018, IEEE T IMAGE PROCESS, V27, P4357, DOI 10.1109/TIP.2018.2835143; Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8; Pan G, 2007, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2007.4409068; Patel K, 2016, LECT NOTES COMPUT SC, V9967, P611, DOI 10.1007/978-3-319-46654-5_67; Patel K, 2016, IEEE T INF FOREN SEC, V11, P2268, DOI 10.1109/TIFS.2016.2578288; Qin Y., 2020, P AAAI C ART INTELL, p11 916; Quan RJ, 2019, IEEE I CONF COMP VIS, P3749, DOI 10.1109/ICCV.2019.00385; Ramachandran P, 2019, ADV NEUR IN, V32; Real E, 2019, AAAI CONF ARTIF INTE, P4780; Real E, 2017, PR MACH LEARN RES, V70; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Shao R, 2020, AAAI CONF ARTIF INTE, V34, P11974; Shao R, 2019, PROC CVPR IEEE, P10015, DOI 10.1109/CVPR.2019.01026; Shaw A., 2019, P ANNU C NEURAL INF, P227; Siddiqui TA, 2016, INT C PATT RECOG, P1035, DOI 10.1109/ICPR.2016.7899772; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Tirunagari S, 2015, IEEE T INF FOREN SEC, V10, P762, DOI 10.1109/TIFS.2015.2406533; Wang GQ, 2019, IEEE COMPUT SOC CONF, P1584, DOI 10.1109/CVPRW.2019.00200; Wang JX, 2020, AAAI CONF ARTIF INTE, V34, P6186; Wang J, 2017, IEEE WINT CONF APPL, P168, DOI 10.1109/WACV.2017.26; Wang PC, 2018, AAAI CONF ARTIF INTE, P7404; Wang Z., 2018, ARXIV181105118; Wang ZZ, 2020, PROC CVPR IEEE, P5041, DOI 10.1109/CVPR42600.2020.00509; Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395; Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1; Xiong F, 2018, INT CONF BIOMETR THE; Xu Y., ARXIV190705737; Yang Jianwei, 2014, LEARN CONVOLUTIONAL; Yang X, 2019, PROC CVPR IEEE, P3502, DOI 10.1109/CVPR.2019.00362; Yao QM, 2020, AAAI CONF ARTIF INTE, V34, P6664; Ying C, 2019, PR MACH LEARN RES, V97; Yu F., 2016, ABS151107122 CORR; Yu Z, 2020, P IEEE C COMP VIS PA, P650; Yu Z., 2020, ARXIV200702157; Yu Z., 2020, ARXIV200809412; Yu ZT, 2020, PROC CVPR IEEE, P5294, DOI 10.1109/CVPR42600.2020.00534; Yu ZT, 2020, IEEE SIGNAL PROC LET, V27, P1245, DOI 10.1109/LSP.2020.3007086; Zela A., 2020, INT C LEARN REPRESEN; Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754; Zoph B, ARXIV161101578; Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907	90	38	39	11	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2021	43	9					3005	3023		10.1109/TPAMI.2020.3036338	http://dx.doi.org/10.1109/TPAMI.2020.3036338			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TU6DH	33166249	Green Accepted, Green Submitted			2022-12-18	WOS:000681124300013
J	Yu, K; Liu, L; Li, JY; Ding, W; Le, TD				Yu, Kui; Liu, Lin; Li, Jiuyong; Ding, Wei; Le, Thuc Duy			Multi-Source Causal Feature Selection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Diseases; Training; Search problems; Reliability; Predictive models; Markov processes; Causal feature selection; Markov blanket; multiple datasets; Bayesian network; causal invariance	GENE-EXPRESSION; ADENOCARCINOMA; CLASSIFICATION; INFORMATION; RELEVANCE	Causal feature selection has attracted much attention in recent years, as the causal features selected imply the causal mechanism related to the class attribute, leading to more reliable prediction models built using them. Currently there is a need of developing multi-source feature selection methods, since in many applications data for studying the same problem has been collected from various sources, such as multiple gene expression datasets obtained from different experiments for studying the causes of the same disease. However, the state-of-the-art causal feature selection methods generally tackle a single dataset, and a direct application of the methods to multiple datasets will result in unreliable results as the datasets may have different distributions. To address the challenges, by utilizing the concept of causal invariance in causal inference, we first formulate the problem of causal feature selection with multiple datasets as a search problem for an invariant set across the datasets, then give the upper and lower bounds of the invariant set, and finally we propose a new Multi-source Causal Feature Selection algorithm, MCFS. Using synthetic and real world datasets and 16 feature selection methods, the extensive experiments have validated the effectiveness of MCFS.	[Yu, Kui] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230601, Peoples R China; [Yu, Kui; Liu, Lin; Li, Jiuyong; Le, Thuc Duy] Univ South Australia, Sch Informat Technol & Math Sci, Adelaide, SA 5095, Australia; [Ding, Wei] Univ Massachusetts, Dept Comp Sci, Boston, MA 02125 USA	Hefei University of Technology; University of South Australia; University of Massachusetts System; University of Massachusetts Boston	Yu, K (corresponding author), Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230601, Peoples R China.	ykui713@gmail.com; Lin.Liu@unisa.edu.au; Jiuyong.Li@unisa.edu.au; wei.ding@umb.edu; Thuc.Le@unisa.edu.au	Liu, Lin/ABD-1224-2020; Li, Jiuyong/AAY-2706-2020; Le, Thuc Duy/G-8444-2019	Liu, Lin/0000-0003-2843-5738; Li, Jiuyong/0000-0002-9023-1878; Le, Thuc Duy/0000-0002-9732-4313; Ding, Wei/0000-0002-3383-551X	Australian Research Council (ARC) Discovery Project [DP170101306]; National Key Research and Development Program of China [2016YFB1000901]; National Science Foundation of China [61876206, 61673152]	Australian Research Council (ARC) Discovery Project(Australian Research Council); National Key Research and Development Program of China; National Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work is partly supported by the Australian Research Council (ARC) Discovery Project (under grant DP170101306), the National Key Research and Development Program of China (under grant 2016YFB1000901), and the National Science Foundation of China (under grants 61876206 and 61673152).	Aliferis C F, 2003, AMIA Annu Symp Proc, P21; [Anonymous], 2010, IEEE ENG MED BIO; [Anonymous], 2003, METMBS03 P INT C; Beer DG, 2002, NAT MED, V8, P816, DOI 10.1038/nm733; Beinlich I. A., 1989, P C ART INT EMD CAR, P247; Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998; Brown G, 2012, J MACH LEARN RES, V13, P27; Cover T. M., 2012, ELEMENTS INFORM THEO; Fukunaga K., 2013, INTRO STAT PATTERN R; Gao T, 2017, IEEE T CYBERNETICS, V47, P1169, DOI 10.1109/TCYB.2016.2539338; Garber ME, 2001, P NATL ACAD SCI USA, V98, P13784, DOI 10.1073/pnas.241500798; Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616; Guyon I., 2007, COMPUTATIONAL METHOD, P75; Li JD, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3136625; Magliacane S., 2018, P ADV NEUR INF PROC, P10846; Mooij J. M., 2016, ARXIV161110351; Paninski L, 2003, NEURAL COMPUT, V15, P1191, DOI 10.1162/089976603321780272; Pearl J., 2009, CAUSALITY; Pearl J., 2014, PROBABILISTIC REASON; Pena JM, 2007, INT J APPROX REASON, V45, P211, DOI 10.1016/j.ijar.2006.06.008; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159; Peters J, 2016, J R STAT SOC B, V78, P947, DOI 10.1111/rssb.12167; Rojas-Carulla M, 2018, J MACH LEARN RES, V19; ROUSE CE, 1995, J BUS ECON STAT, V13, P217, DOI 10.2307/1392376; TEBBE DL, 1968, IEEE T INFORM THEORY, V14, P516, DOI 10.1109/TIT.1968.1054135; Tsamardinos I., 2003, P 9 ACM SIGKDD INT C, P673; Tsamardinos I., 2003, P 9 INT WORKSH ART I; Tsamardinos I, 2006, MACH LEARN, V65, P31, DOI 10.1007/s10994-006-6889-7; Yaramakala S, 2005, Fifth IEEE International Conference on Data Mining, Proceedings, P809, DOI 10.1109/ICDM.2005.134; Yu K., 2018, ARXIV180205844; Yu L, 2004, J MACH LEARN RES, V5, P1205; Zhai YT, 2014, IEEE COMPUT INTELL M, V9, P14, DOI 10.1109/MCI.2014.2326099; Zhang K., 2015, CHINA DAILY 0912	34	38	41	13	64	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2020	42	9					2240	2256		10.1109/TPAMI.2019.2908373	http://dx.doi.org/10.1109/TPAMI.2019.2908373			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MW9MI	30946660	Green Accepted			2022-12-18	WOS:000557354900012
J	Zheng, F; Tang, Y; Shao, L				Zheng, Feng; Tang, Yi; Shao, Ling			Hetero-Manifold Regularisation for Cross-Modal Hashing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cross-modal hashing; manifold regularisation; information propagation; hinge loss constraint; cumulative distance inequality		Recently, cross-modal search has attracted considerable attention but remains a very challenging task because of the integration complexity and heterogeneity of the multi-modal data. To address both challenges, in this paper, we propose a novel method termed hetero-manifold regularisation (HMR) to supervise the learning of hash functions for efficient cross-modal search. A hetero-manifold integrates multiple sub-manifolds defined by homogeneous data with the help of cross-modal supervision information. Taking advantages of the hetero-manifold, the similarity between each pair of heterogeneous data could be naturally measured by three order random walks on this hetero-manifold. Furthermore, a novel cumulative distance inequality defined on the hetero-manifold is introduced to avoid the computational difficulty induced by the discreteness of hash codes. By using the inequality, cross-modal hashing is transformed into a problem of hetero-manifold regularised support vector learning. Therefore, the performance of cross-modal search can be significantly improved by seamlessly combining the integrated information of the hetero-manifold and the strong generalisation of the support vector machine. Comprehensive experiments show that the proposed HMR achieve advantageous results over the state-of-the-art methods in several challenging cross-modal tasks.	[Zheng, Feng] Univ Sheffield, Dept Elect & Elect Engn, Sheffield S1 4DE, S Yorkshire, England; [Tang, Yi] Yunnan Minzu Univ, Dept Math & Comp Sci, Key Lab IOT Applicat Technol Univ Yunnan Prov, Kunming 650500, Yunnan, Peoples R China; [Shao, Ling] Univ East Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England	University of Sheffield; Yunnan Minzu University; University of East Anglia	Zheng, F (corresponding author), Univ Sheffield, Dept Elect & Elect Engn, Sheffield S1 4DE, S Yorkshire, England.	cip12fz@sheffield.ac.uk; yitang.math@ieee.org; ling.shao@ieee.org	Shao, Ling/D-3535-2011	Shao, Ling/0000-0002-8264-6117	National Natural Science Foundation of China [61528106, 61462096]; Newton International Exchanges Scheme; Science and Technology Plan Project of Yunnan Province [2014FB148]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Newton International Exchanges Scheme; Science and Technology Plan Project of Yunnan Province	This work was supported in part by National Natural Science Foundation of China under Grant 61528106, and in part by the Newton International Exchanges Scheme. Yi Tang is partly supported by the National Natural Science Foundation of China (Grant no. 61462096) and the Science and Technology Plan Project of Yunnan Province (Grant no. 2014FB148). Ling Shao is the corresponding author.	Amari SI, 2007, NEURAL COMPUT, V19, P2780, DOI 10.1162/neco.2007.19.10.2780; Amiri SH, 2015, PATTERN RECOGN, V48, P2241, DOI 10.1016/j.patcog.2015.01.015; Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928; Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68; Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142; Davis J., 2006, P 23 INT C MACH LEAR, V148, P233, DOI [DOI 10.1145/1143844.1143874, 10.1145/1143844.1143874]; Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267; Face and G. R. W. group, 2000, FG NET AG DAT; Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926; Feng Zheng, 2016, IJCAI, P2399; Gao LL, 2015, PROC CVPR IEEE, P4371, DOI 10.1109/CVPR.2015.7299066; Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21; Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280; Hu  D., 2016, P ACM MULT C, P342, DOI DOI 10.1145/2964284.2967239; Jia YQ, 2011, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2011.6126524; Jiang Q.-Y., 2016, ARXIV160202255V2; Kang C., 2015, P 24 ACM INT C INF K, P1251; Kim S, 2012, LECT NOTES COMPUT SC, V7576, P538, DOI 10.1007/978-3-642-33715-4_39; Kostinger Martin, 2012, CVPR, DOI DOI 10.1109/CVPR.2012.6247939; Kumar S, 2011, P TWENTYSECOND INT J, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230; Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947; Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27; Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463; Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832; Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011; Liu L, 2016, IEEE T CYBERNETICS, V46, P2548, DOI 10.1109/TCYB.2015.2480966; Liu L, 2016, IEEE T NEUR NET LEAR, V27, P2526, DOI 10.1109/TNNLS.2015.2495345; Liu L, 2015, IEEE I CONF COMP VIS, P2821, DOI 10.1109/ICCV.2015.323; Liu L, 2015, IEEE T IMAGE PROCESS, V24, P956, DOI 10.1109/TIP.2015.2390975; Mahadevan V., 2011, ADV NEURAL INFORM PR, P918; Mao X., 2013, P 21 ACM INT C MULT, P897, DOI DOI 10.1145/2502081.2502087; Masci J, 2014, IEEE T PATTERN ANAL, V36, P824, DOI 10.1109/TPAMI.2013.225; Ngiam Jiquan, 2011, ICML, DOI DOI 10.5555/3104482.3104569; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Rastegar M, 2013, PROC IEEE 18 ELECT P, P1; Shao L, 2016, INT J COMPUT VISION, V118, P115, DOI 10.1007/s11263-015-0861-6; Song J., 2013, P 2013 ACM SIGMOD IN, P785, DOI [10.1145/2463676.2465274, DOI 10.1145/2463676.2465274]; Song JK, 2016, IMAGE VISION COMPUT, V55, P101, DOI 10.1016/j.imavis.2016.02.005; Tang J, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2564638; Wang DX, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2291; Wang J., 2016, ARXIV160600185V1; Wang J., 2014, ARXIV14082927; Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261; Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010; Wu D, 2016, IEEE T PATTERN ANAL, V38, P1583, DOI 10.1109/TPAMI.2016.2537340; Yang Y., 2009, P 17 ACM INT C MULTI, V17, P175, DOI DOI 10.1145/1631272.1631298; Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359; You XG, 2016, IEEE T IMAGE PROCESS, V25, P4782, DOI 10.1109/TIP.2016.2598653; Yu MY, 2017, IEEE T NEUR NET LEAR, V28, P2899, DOI 10.1109/TNNLS.2016.2609463; Zhang D, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P225; Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177; Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26; Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; Zheng F, 2013, NEUROCOMPUTING, V103, P210, DOI 10.1016/j.neucom.2012.09.023; Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138; Zhu F, 2014, ACM INT C CONFERENCE, P1479; Zhuang YT, 2008, IEEE T MULTIMEDIA, V10, P221, DOI 10.1109/TMM.2007.911822; Zhuang YT, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P901, DOI 10.1145/2647868.2655059; Zoidi O., 2015, P IEEE 25 INT WORKSH, P1	60	38	40	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2018	40	5					1059	1071		10.1109/TPAMI.2016.2645565	http://dx.doi.org/10.1109/TPAMI.2016.2645565			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GB2RB	28055849	Green Accepted			2022-12-18	WOS:000428901200004
J	Tejani, A; Kouskouridas, R; Doumanoglou, A; Tang, DH; Kim, TK				Tejani, Alykhan; Kouskouridas, Rigas; Doumanoglou, Andreas; Tang, Danhang; Kim, Tae-Kyun			Latent-Class Hough Forests for 6 DoF Object Pose Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D Object detection; pose estimation; hough forests; one-class training; 6 DoF pose estimation	NOVELTY DETECTION; RECOGNITION; REGRESSION	In this paper we present Latent-Class Hough Forests, a method for object detection and 6 DoF pose estimation in heavily cluttered and occluded scenarios. We adapt a state of the art template matching feature into a scale-invariant patch descriptor and integrate it into a regression forest using a novel template-based split function. We train with positive samples only and we treat class distributions at the leaf nodes as latent variables. During testing we infer by iteratively updating these distributions, providing accurate estimation of background clutter and foreground occlusions and, thus, better detection rate. Furthermore, as a by-product, our Latent-Class Hough Forests can provide accurate occlusion aware segmentation masks, even in the multi-instance scenario. In addition to an existing public dataset, which contains only single-instance sequences with large amounts of clutter, we have collected two, more challenging, datasets for multiple-instance detection containing heavy 2D and 3D clutter as well as foreground occlusions. We provide extensive experiments on the various parameters of the framework such as patch size, number of trees and number of iterations to infer class distributions at test time. We also evaluate the Latent-Class Hough Forests on all datasets where we outperform state of the art methods.	[Kouskouridas, Rigas] WIREWAX Ltd, London W1T 2RB, England; [Doumanoglou, Andreas; Kim, Tae-Kyun] Imperial Coll London, Dept Elect & Elect Engn, London SW7 2AZ, England; [Tang, Danhang] perceptiveIO Inc, San Francisco, CA 94103 USA	Imperial College London	Kouskouridas, R (corresponding author), WIREWAX Ltd, London W1T 2RB, England.	alykhan.tejani@gmail.com; rkouskou@gmail.com; a.doumanoglou12@imperial.ac.uk; danhang.tang@gmail.com; tk.kim@imperial.ac.uk		Kouskouridas, Rigas/0000-0002-4866-520X; Tang, Danhang/0000-0001-6164-8263				Aldoma A, 2012, LECT NOTES COMPUT SC, V7574, P511, DOI 10.1007/978-3-642-33712-3_37; BISHOP CM, 1994, IEE P-VIS IMAGE SIGN, V141, P217, DOI 10.1049/ip-vis:19941330; Bonde U, 2014, LECT NOTES COMPUT SC, V8690, P520, DOI 10.1007/978-3-319-10605-2_34; Brachmann E, 2014, LECT NOTES COMPUT SC, V8690, P536, DOI 10.1007/978-3-319-10605-2_35; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Buch AG, 2014, PROC CVPR IEEE, P2075, DOI 10.1109/CVPR.2014.266; Crivellaro A, 2015, IEEE I CONF COMP VIS, P4391, DOI 10.1109/ICCV.2015.499; Doumanoglou A., 2016, ARXIV160702257; Doumanoglou A, 2016, PROC CVPR IEEE, P3583, DOI 10.1109/CVPR.2016.390; Drost Bertram, 2010, 2010 IEEE COMP SOC C, DOI DOI 10.1109/CVPR.2010.5540108; Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458; Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70; Girshick R, 2011, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2011.6126270; Hinterstoisser S, 2011, IEEE I CONF COMP VIS, P858, DOI 10.1109/ICCV.2011.6126326; Hinterstoisser S, 2010, PROC CVPR IEEE, P2257, DOI 10.1109/CVPR.2010.5539908; Hinterstoisser Stefan, 2012, P AS C COMP VIS, P2, DOI DOI 10.1007/978-3-642-37331-2_42; Hsiao E, 2012, PROC CVPR IEEE, P3146, DOI 10.1109/CVPR.2012.6248048; Kokkinos I, 2009, IEEE T PATTERN ANAL, V31, P1486, DOI 10.1109/TPAMI.2008.158; Kouskouridas R, 2014, AUTON ROBOT, V37, P191, DOI 10.1007/s10514-014-9388-x; Kouskouridas R, 2013, NEUROCOMPUTING, V120, P90, DOI 10.1016/j.neucom.2012.11.047; Krull A, 2015, LECT NOTES COMPUT SC, V9006, P384, DOI 10.1007/978-3-319-16817-3_25; Leibe B., 2004, EUROPEAN C COMPUTER, P17; Lim JJ, 2014, LECT NOTES COMPUT SC, V8694, P478, DOI 10.1007/978-3-319-10599-4_31; Liu MY, 2012, INT J ROBOT RES, V31, P951, DOI 10.1177/0278364911436018; Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229; Mathias M, 2013, IEEE I CONF COMP VIS, P1505, DOI 10.1109/ICCV.2013.190; Moya M., 1993, SAND930084C; Moya MM, 1996, NEURAL NETWORKS, V9, P463, DOI 10.1016/0893-6080(95)00120-4; Parra L, 1996, NEURAL COMPUT, V8, P260, DOI 10.1162/neco.1996.8.2.260; Pepik B, 2013, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2013.422; Rios-Cabrera R, 2013, IEEE I CONF COMP VIS, P2048, DOI 10.1109/ICCV.2013.256; Ristin M, 2014, PROC CVPR IEEE, P3654, DOI 10.1109/CVPR.2014.467; Sahin C., 2017, ARXIV170102166; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381; Song SR, 2014, LECT NOTES COMPUT SC, V8694, P634, DOI 10.1007/978-3-319-10599-4_41; Tang DH, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.58; Tang DH, 2013, IEEE I CONF COMP VIS, P3224, DOI 10.1109/ICCV.2013.400; Tax, 2001, ONE CLASS CLASSIFICA; Tejani A, 2014, LECT NOTES COMPUT SC, V8694, P462, DOI 10.1007/978-3-319-10599-4_30; Wang T, 2013, PROC CVPR IEEE, P1790, DOI 10.1109/CVPR.2013.234; Wohlhart P, 2015, PROC CVPR IEEE, P3109, DOI 10.1109/CVPR.2015.7298930; WU ZR, 2015, PROC CVPR IEEE, P1912, DOI DOI 10.1109/CVPR.2015.7298801	43	38	39	4	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2018	40	1					119	132		10.1109/TPAMI.2017.2665623	http://dx.doi.org/10.1109/TPAMI.2017.2665623			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FP7IH	28186878	Green Submitted			2022-12-18	WOS:000417806000010
J	Gu, B; Sheng, VS; Tay, KY; Romano, W; Li, S				Gu, Bin; Sheng, Victor S.; Tay, Keng Yeow; Romano, Walter; Li, Shuo			Cross Validation Through Two-Dimensional Solution Surface for Cost-Sensitive SVM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Solution surface; space partition; cost-sensitive support vector machine; cross validation; solution path	REGULARIZATION PATH; SUPPORT; ALGORITHM	Model selection plays an important role in cost-sensitive SVM (CS-SVM). It has been proven that the global minimum cross validation (CV) error can be efficiently computed based on the solution path for one parameter learning problems. However, it is a challenge to obtain the global minimum CV error for CS-SVM based on one-dimensional solution path and traditional grid search, because CS-SVM is with two regularization parameters. In this paper, we propose a solution and error surfaces based CV approach (CV-SES). More specifically, we first compute a two-dimensional solution surface for CS-SVM based on a bi-parameter space partition algorithm, which can fit solutions of CS-SVM for all values of both regularization parameters. Then, we compute a two-dimensional validation error surface for each CV fold, which can fit validation errors of CS-SVM for all values of both regularization parameters. Finally, we obtain the CV error surface by superposing K validation error surfaces, which can find the global minimum CV error of CS-SVM. Experiments are conducted on seven datasets for cost sensitive learning and on four datasets for imbalanced learning. Experimental results not only show that our proposed CV-SES has a better generalization ability than CS-SVM with various hybrids between grid search and solution path methods, and than recent proposed cost-sensitive hinge loss SVM with three-dimensional grid search, but also show that CV-SES uses less running time.	[Gu, Bin] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing 210024, Jiangsu, Peoples R China; [Gu, Bin] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210024, Jiangsu, Peoples R China; [Gu, Bin] Univ Western Ontario, Dept Med Biophys, London, ON N6A 3K7, Canada; [Sheng, Victor S.] Univ Cent Arkansas, Dept Comp Sci, Conway, AR 72035 USA; [Tay, Keng Yeow] London Hlth Sci Ctr, London, ON N6A 5W9, Canada; [Romano, Walter] St Josephs Hlth Care, London, ON N6C 5J1, Canada; [Li, Shuo] Univ Western Ontario, Dept Med Biophys, London, ON N6A 3K7, Canada	Nanjing University of Information Science & Technology; Nanjing University of Information Science & Technology; Western University (University of Western Ontario); University of Central Arkansas; London Health Sciences Centre; Western University (University of Western Ontario); Western University (University of Western Ontario)	Gu, B (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing 210024, Jiangsu, Peoples R China.; Gu, B (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210024, Jiangsu, Peoples R China.	jsgubin@nuist.edu.cn; ssheng@uca.edu; KengYeow.Tay@lhsc.on.ca; wmromano@rogers.com; slishuo@gmail.com	Gu, Bin/L-2844-2019; Li, Shuo/N-5364-2019; Li, Shuo/GXV-6545-2022	Gu, Bin/0000-0001-8653-1117; Li, Shuo/0000-0002-5184-3230; 	Priority Academic Program Development (PAPD) of Jiangsu Higher Education Institutions; U.S. National Science Foundation [IIS-1115417]; National Natural Science Foundation of China [61232016, 61573191]	Priority Academic Program Development (PAPD) of Jiangsu Higher Education Institutions; U.S. National Science Foundation(National Science Foundation (NSF)); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The authors would like to thank the anonymous reviewers for their constructive comments and suggestions. This work was supported by the Project Funded by the Priority Academic Program Development (PAPD) of Jiangsu Higher Education Institutions, the U.S. National Science Foundation (IIS-1115417), and the National Natural Science Foundation of China (Nos: 61232016, 61573191 and 61573191). Bin Gu is the corresponding author.	AVIS D, 1992, DISCRETE COMPUT GEOM, V8, P295, DOI 10.1007/BF02293050; Bach FR, 2006, J MACH LEARN RES, V7, P1713; Borrelli F., 2003, CONSTRAINED OPTIMAL; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Cai F, 2012, IEEE T NEUR NET LEAR, V23, P997, DOI 10.1109/TNNLS.2012.2187307; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chen PH, 2006, IEEE T NEURAL NETWOR, V17, P893, DOI 10.1109/TNN.2006.875973; Cui G, 2012, J MANAGE INFORM SYST, V29, P341, DOI 10.2753/MIS0742-1222290110; Davenport MA, 2010, IEEE T PATTERN ANAL, V32, P1888, DOI 10.1109/TPAMI.2010.29; Elkan C., 2001, INT JOINT C ART INT, V17, P973, DOI DOI 10.5555/1642194.1642224; Frank A., 2010, UCI MACHINE LEARNING; Giesen J., 2012, ADV NEURAL INFORM PR, V25, P2105; Gu B, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3532; Gu B, 2012, IEEE T NEUR NET LEAR, V23, P800, DOI 10.1109/TNNLS.2012.2183644; Gunter L, 2007, NEURAL COMPUT, V19, P1633, DOI 10.1162/neco.2007.19.6.1633; Hastie T, 2004, J MACH LEARN RES, V5, P1391; He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239; Karakoulas G, 1999, ADV NEUR IN, V11, P253; Laskov P, 2006, J MACH LEARN RES, V7, P1909; Lee G, 2010, IEEE T SIGNAL PROCES, V58, P1648, DOI 10.1109/TSP.2009.2036071; Ling C.X., 2006, P NAT C ART INT, P476; Liu XY, 2006, IEEE DATA MINING, P970; Masnadi-Shirazi H., 2010, ICML, P759; Masnadi- Shirazi H., 2012, ARXIV12120975; Park YJ, 2011, ARTIF INTELL MED, V51, P133, DOI 10.1016/j.artmed.2010.12.001; Rosset S, 2007, ANN STAT, V35, P1012, DOI 10.1214/009053606000001370; Rosset S, 2009, J MACH LEARN RES, V10, P2473; Scholkopf B., 2001, LEARNING KERNELS SUP; Takeuchi I, 2009, NEURAL COMPUT, V21, P533, DOI 10.1162/neco.2008.10-07-628; Vapnik VN, 1998, STAT LEARNING THEORY, DOI DOI 10.1007/978-1-4419-1428-6_5864; Wang G, 2008, IEEE T NEURAL NETWOR, V19, P1753, DOI 10.1109/TNN.2008.2002077; Yang JB, 2011, IEEE T NEURAL NETWOR, V22, P654, DOI 10.1109/TNN.2011.2106219; Zhang Y, 2010, IEEE T PATTERN ANAL, V32, P1758, DOI 10.1109/TPAMI.2009.195	34	38	41	1	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2017	39	6					1103	1121		10.1109/TPAMI.2016.2578326	http://dx.doi.org/10.1109/TPAMI.2016.2578326			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EU5RR	27295653	hybrid			2022-12-18	WOS:000401091200005
J	Xiang, ZJ; Wang, Y; Ramadge, PJ				Xiang, Zhen James; Wang, Yun; Ramadge, Peter J.			Screening Tests for Lasso Problems	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sparse representation; feature selection; lasso; dual lasso; dictionary screening	SPARSE REPRESENTATION; FACE RECOGNITION; SELECTION; CLASSIFICATION; SHRINKAGE; RECOVERY; RULES	This paper is a survey of dictionary screening for the lasso problem. The lasso problem seeks a sparse linear combination of the columns of a dictionary to best match a given target vector. This sparse representation has proven useful in a variety of subsequent processing and decision tasks. For a given target vector, dictionary screening quickly identifies a subset of dictionary columns that will receive zero weight in a solution of the corresponding lasso problem. These columns can be removed from the dictionary prior to solving the lasso problem without impacting the optimality of the solution obtained. This has two potential advantages: it reduces the size of the dictionary, allowing the lasso problem to be solved with less resources, and it may speed up obtaining a solution. Using a geometrically intuitive framework, we provide basic insights for understanding useful lasso screening tests and their limitations. We also provide illustrative numerical studies on several datasets.	[Xiang, Zhen James; Wang, Yun; Ramadge, Peter J.] Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA	Princeton University	Xiang, ZJ (corresponding author), Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.	zhenfavor@gmail.com; ywang721@gmail.com; ramadge@princeton.edu			US National Science Foundation [CIF 1116208]	US National Science Foundation(National Science Foundation (NSF))	This work partially supported by US National Science Foundation grant CIF 1116208.	Anden J., 2011, P INT SOC MUSIC INFO, P657; [Anonymous], 2010, ISMIR; [Anonymous], 2011, P 20 ACM INT C INF K; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Cai D, 2012, IEEE T KNOWL DATA EN, V24, P707, DOI 10.1109/TKDE.2011.104; Dai L, 2012, EUR SIGNAL PR CONF, P654; Dash Sanjeeb, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3360, DOI 10.1109/ICASSP.2014.6854223; Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067; El Ghaoui L, 2012, PAC J OPTIM, V8, P667; Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1; ElGhaoui L., 2010, UCBEECS2010126; Fan JQ, 2008, J R STAT SOC B, V70, P849, DOI 10.1111/j.1467-9868.2008.00674.x; Frank A., 2010, UCI MACHINE LEARNING; Fuchs JJ, 2005, IEEE T INFORM THEORY, V51, P3601, DOI 10.1109/TIT.2005.855614; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Hiriart-Urruty J. B., 2001, FUNDAMENTALS CONVEX; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2007, ADV NEURAL INF PROCE, P801; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Liu J., 2013, ARXIV13077577V2CSLG; Luo S, 2014, J AM STAT ASSOC, V109, P1229, DOI 10.1080/01621459.2013.877275; Mairal J., 2012, P 29 INT C INT C MAC, P1835; Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828; Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452; Nene A. S., 1996, CUCS00696; Perkins S., 2003, P 20 INT C MACH LEAR, P592; Ping-Keng Jao, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5207, DOI 10.1109/ICASSP.2014.6854596; RABBANI T., 2010, PACIFIC J OPTIM, V8, P667; Sainath TN, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2254; Sainath TN, 2010, INT CONF ACOUST SPEE, P4370, DOI 10.1109/ICASSP.2010.5495638; Sastry S. Shankar, 2010, ARXIV10073753; Smith SM, 2004, BRIT J RADIOL, V77, pS167, DOI 10.1259/bjr/33553595; Thompson G. L., 1966, MANAGE SCI, V12, P588, DOI DOI 10.1287/MNSC.12.7.588; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tibshirani R, 2012, J R STAT SOC B, V74, P245, DOI 10.1111/j.1467-9868.2011.01004.x; Tibshirani RJ, 2011, ANN STAT, V39, P1335, DOI 10.1214/11-AOS878; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560; Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112; Wang J, 2015, J MACH LEARN RES, V16, P1063; Wang Y., 2015, 620151 PRINC U; Wang Y, 2013, IEEE GLOB CONF SIG, P1001, DOI 10.1109/GlobalSIP.2013.6737062; Wang Y, 2013, INT CONF ACOUST SPEE, P3297, DOI 10.1109/ICASSP.2013.6638268; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xiang Z., 2011, ADV NEURAL INFORM PR, V24, P900; Xiang ZJ, 2012, INT CONF ACOUST SPEE, P2137, DOI 10.1109/ICASSP.2012.6288334; Yu Kai, 2009, ADV NEURAL INFORM PR, P2223; Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277; Zhou Q, 2015, PR MACH LEARN RES, V37, P1103; Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x	53	38	38	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2017	39	5					1008	1027		10.1109/TPAMI.2016.2568185	http://dx.doi.org/10.1109/TPAMI.2016.2568185			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ES0WO	27187950	Green Submitted, hybrid			2022-12-18	WOS:000399250000013
J	Wang, ZH; Fan, B; Wang, G; Wu, FC				Wang, Zhenhua; Fan, Bin; Wang, Gang; Wu, Fuchao			Exploring Local and Overall Ordinal Information for Robust Feature Description	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature description; intensity order; illumination invariance; image matching	SCALE	This paper aims to build robust feature descriptors by exploring intensity order information in a patch. To this end, the local intensity order pattern (LIOP) and the overall intensity order pattern (OIOP) are proposed to effectively encode intensity order information of each pixel in different aspects. Specifically, LIOP captures the local ordinal information by using the intensity relationships among all the neighbouring sampling points around a pixel, while OIOP exploits the coarsely quantized overall intensity order of these sampling points. These two kinds of patterns are then separately aggregated into different ordinal bins, leading to two kinds of feature descriptors. Furthermore, as these two kinds of descriptors could encode complementary ordinal information, they are combined together to obtain a discriminative and compact mixed intensity order pattern descriptor. All these descriptors are constructed on the basis of relative relationships of intensities in a rotationally invariant way, making them be inherently invariant to image rotation and any monotonic intensity changes. Experimental results on image matching and object recognition are encouraging, demonstrating the superiorities of our descriptors over the state of the art.	[Wang, Zhenhua; Fan, Bin; Wu, Fuchao] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China; [Wang, Zhenhua; Wang, Gang] Nanyang Technol Univ, Sch Elect Elect Engn, Rapid Rich Object Search Lab, Singapore, Singapore	Chinese Academy of Sciences; Institute of Automation, CAS; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Wang, ZH (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.; Wang, ZH (corresponding author), Nanyang Technol Univ, Sch Elect Elect Engn, Rapid Rich Object Search Lab, Singapore, Singapore.	wzh@nlpr.ia.ac.cn; bfan@nlpr.ia.ac.cn; wanggang@ntu.edu.sg; fcwu@nlpr.ia.ac.cn	Fan, Bin/AAD-8307-2019		National Nature Science Foundation of China [61375043, 61203277, 61272394]; Beijing Nature Science Foundation [4142057]; Singapore Ministry of Education (MOE) [ARC28/14]; Singapore A*STAR Science and Engineering Research Council [PSF1321202099]; Rapid-Rich Object Search (ROSE) Lab at Nanyang Technological University	National Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Nature Science Foundation(Beijing Natural Science Foundation); Singapore Ministry of Education (MOE)(Ministry of Education, Singapore); Singapore A*STAR Science and Engineering Research Council; Rapid-Rich Object Search (ROSE) Lab at Nanyang Technological University(Nanyang Technological University)	The work was supported by the National Nature Science Foundation of China (No. 61375043, 61203277, 61272394), the Beijing Nature Science Foundation (No. 4142057), Singapore Ministry of Education (MOE) Tier 2 ARC28/14, and Singapore A*STAR Science and Engineering Research Council PSF1321202099. They also gratefully acknowledge the support of Rapid-Rich Object Search (ROSE) Lab at Nanyang Technological University. B. Fan is the corresponding author.	Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bhat DN, 1998, IEEE T PATTERN ANAL, V20, P415, DOI 10.1109/34.677275; Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3; Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54; Fan B, 2012, IEEE T PATTERN ANAL, V34, P2031, DOI 10.1109/TPAMI.2011.277; Fan B, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995385; Feng Tang, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2631, DOI 10.1109/CVPRW.2009.5206550; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Goswami B, 2010, BIOMETRICS THEORY AP, P1; Gupta R., 2007, P IEEE INT C COMP VI, P18; Gupta R, 2008, LECT NOTES COMPUT SC, V5303, P265, DOI 10.1007/978-3-540-88688-4_20; Gupta R, 2010, PROC CVPR IEEE, P334, DOI 10.1109/CVPR.2010.5540195; Heikkila M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014; Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226; Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Mittal A., 2006, 2006 IEEE COMP SOC C, V1, P849; Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414; Scherer S., 1999, P IEEE C COMP VIS PA, P1076; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Tang F, 2010, IEEE IMAGE PROC, P861, DOI 10.1109/ICIP.2010.5653536; Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77; Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8; Van Gool L., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P642, DOI 10.1007/BFb0015574; Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294; Winder S, 2009, PROC CVPR IEEE, P178, DOI 10.1109/CVPRW.2009.5206839; Winder SAJ, 2007, PROC CVPR IEEE, P17; Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345; Ziegler A, 2012, ADV NEURAL INFORM PR, P1	36	38	42	2	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2016	38	11					2198	2211		10.1109/TPAMI.2015.2513396	http://dx.doi.org/10.1109/TPAMI.2015.2513396			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DZ6AW	26731637				2022-12-18	WOS:000385945000005
J	Korman, S; Avidan, S				Korman, Simon; Avidan, Shai			Coherency Sensitive Hashing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Patch matching; image matching; nearest neighbor fields; video matching	PRODUCT QUANTIZATION; TEXTURE SYNTHESIS; IMAGE; PROPAGATION	Coherency Sensitive Hashing (CSH) extends Locality Sensitivity Hashing (LSH) and PatchMatch to quickly find matching patches between two images. LSH relies on hashing, which maps similar patches to the same bin, in order to find matching patches. PatchMatch, on the other hand, relies on the observation that images are coherent, to propagate good matches to their neighbors in the image plane, using random patch assignment to seed the initial matching. CSH relies on hashing to seed the initial patch matching and on image coherence to propagate good matches. In addition, hashing lets it propagate information between patches with similar appearance (i.e., map to the same bin). This way, information is propagated much faster because it can use similarity in appearance space or neighborhood in the image plane. As a result, CSH is at least three to four times faster than PatchMatch and more accurate, especially in textured regions, where reconstruction artifacts are most noticeable to the human eye. We verified CSH on a new, large scale, data set of 133 image pairs and experimented on several extensions, including: k nearest neighbor search, the addition of rotation and matching three dimensional patches in videos.	[Korman, Simon; Avidan, Shai] Tel Aviv Univ, Dept Elect Engn, Ramat Aviv, Israel	Tel Aviv University	Korman, S; Avidan, S (corresponding author), Tel Aviv Univ, Dept Elect Engn, Ramat Aviv, Israel.	simonkor@mail.tau.ac.il; avidan@eng.tau.ac.il			Israel Science Foundation [1,556/10]; European Community [PIRG05-GA-2009-248527]	Israel Science Foundation(Israel Science Foundation); European Community(European Commission)	This work was partially supported by Israel Science Foundation grant 1,556/10 and European Community grant PIRG05-GA-2009-248527. The authors thank Yonatan Hyatt, Guy Shwartz and Efrat Glikstein for their assistance.	Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Ashikhmin M., 2001, P 2001 S INT 3D GRAP, P217, DOI DOI 10.1145/364338.364405; Barnes C, 2011, THESIS PRINCETON U P; Barnes C, 2010, LECT NOTES COMPUT SC, V6313, P29; Ben-Artzi G, 2007, IEEE T PATTERN ANAL, V29, P382, DOI 10.1109/TPAMI.2007.62; Besse F, 2014, INT J COMPUT VISION, V110, P2, DOI 10.1007/s11263-013-0653-9; Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1; Dabov K., 2007, P 15 EUR SIGN PROC C, V1, P7; Datar M., 2004, P ACM 20 ANN S COMP, P253; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; Ge TZ, 2013, PROC CVPR IEEE, P2946, DOI 10.1109/CVPR.2013.379; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Gong YC, 2013, PROC CVPR IEEE, P484, DOI 10.1109/CVPR.2013.69; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; HaCohen Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964965; He KM, 2012, LECT NOTES COMPUT SC, V7573, P16, DOI 10.1007/978-3-642-33709-3_2; He KM, 2012, PROC CVPR IEEE, P111, DOI 10.1109/CVPR.2012.6247665; Hel-Or Y, 2005, IEEE T PATTERN ANAL, V27, P1430, DOI 10.1109/TPAMI.2005.184; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Korman S., 2015, CSH WEBP; Korman S, 2011, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2011.6126421; Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264; Liu C, 2010, LECT NOTES COMPUT SC, V6313, P706; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Norouzi M, 2013, PROC CVPR IEEE, P3017, DOI 10.1109/CVPR.2013.388; Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2; Olonetsky I, 2012, LECT NOTES COMPUT SC, V7575, P602, DOI 10.1007/978-3-642-33765-9_43; RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006; Salakhutdinov R., 2007, RBM, V500, P500; Shahar O., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3353, DOI 10.1109/CVPR.2011.5995360; Simakov D., 2008, 2008 IEEE CVPR, P1; Tong X, 2002, ACM T GRAPHIC, V21, P665, DOI 10.1145/566570.566634; Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009; Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60; Zolotarev V., 1986, ONE DIMENSIONAL STAB	39	38	39	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2016	38	6					1099	1112		10.1109/TPAMI.2015.2477814	http://dx.doi.org/10.1109/TPAMI.2015.2477814			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DL4LU	26372204				2022-12-18	WOS:000375609000005
J	Zheng, Y; Zhang, YJ; Larochelle, H				Zheng, Yin; Zhang, Yu-Jin; Larochelle, Hugo			A Deep and Autoregressive Approach for Topic Modeling of Multimodal Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multimodal data modeling; topic model; neural autoregressive model; deep neural network		Topic modeling based on latent Dirichlet allocation (LDA) has been a framework of choice to deal with multimodal data, such as in image annotation tasks. Another popular approach to model the multimodal data is through deep neural networks, such as the deep Boltzmann machine (DBM). Recently, a new type of topic model called the Document Neural Autoregressive Distribution Estimator (DocNADE) was proposed and demonstrated state-of-the-art performance for text document modeling. In this work, we show how to successfully apply and extend this model to multimodal data, such as simultaneous image classification and annotation. First, we propose SupDocNADE, a supervised extension of DocNADE, that increases the discriminative power of the learned hidden topic features and show how to employ it to learn a joint representation from image visual words, annotation words and class label information. We test our model on the LabelMe and UIUC-Sports data sets and show that it compares favorably to other topic models. Second, we propose a deep extension of our model and provide an efficient way of training the deep model. Experimental results show that our deep model outperforms its shallow version and reaches state-of-the-art performance on the Multimedia Information Retrieval (MIR) Flickr data set.	[Zheng, Yin; Zhang, Yu-Jin] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China; [Larochelle, Hugo] Univ Sherbrooke, Dept Informat, Sherbrooke, PQ J1K 2R1, Canada	Tsinghua University; University of Sherbrooke	Zheng, Y; Zhang, YJ (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.; Larochelle, H (corresponding author), Univ Sherbrooke, Dept Informat, Sherbrooke, PQ J1K 2R1, Canada.	yzheng3xg@gmail.com; zhang-yj@tsinghua.edu.cn; hugo.larochelle@usherbrooke.ca			Natural Sciences and Engineering Research Council of Canada; Compute Canada; National Nature Science Foundation of China [NNSF: 61171118]; Specialized Research Fund for the Doctoral Program of Higher Education in China [SRFDP-20110002110057]	Natural Sciences and Engineering Research Council of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)CGIAR); Compute Canada; National Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); Specialized Research Fund for the Doctoral Program of Higher Education in China(Specialized Research Fund for the Doctoral Program of Higher Education (SRFDP))	This work was partially supported by the Natural Sciences and Engineering Research Council of Canada and Compute Canada. And it was also partially supported by the National Nature Science Foundation of China (NNSF: 61171118) and Specialized Research Fund for the Doctoral Program of Higher Education in China (SRFDP-20110002110057)	Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Bengio Y., 2012, CORR; Blei D.M., 2003, P 26 ANN INT ACM SIG, P127, DOI [10.1145/860435.860460, DOI 10.1145/860435.860460]; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bouchard Guillaume, 2004, 16 IASC INT S COMP S, P721; Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPRW.2009.5206800, 10.1109/CVPR.2009.5206800]; Glorot X., 2011, P 14 INT C ART INT S, P315; Glorot X., 2010, P 13 INT C ART INT S, P249, DOI DOI 10.1.1/207.2059; Guillaumin M., 2010, P IEEE C COMP VIS PA, P3408; Hinton G.E., 2012, ARXIV; Huiskes Mark J, 2008, P 1 ACM INT C MULTIM, P39, DOI DOI 10.1145/1460096.1460104; Jia YQ, 2011, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2011.6126524; Larochelle H., 2012, ADV NEURAL INFORM PR, P2708; Larochelle H., 2012, J MACH LEARN RES, V15, P38; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Li LJ, 2007, IEEE I CONF COMP VIS, P345; Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424; Mcauliffe Jon D., 2008, P ADV NEURAL INFORM, P121; Nair V., 2010, ICML, P807; Ngiam J, 2011, P 28 INT C MACH LEAR, V28, P689, DOI DOI 10.5555/3104482.3104569; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Putthividhya D, 2010, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2010.5540000; Rasiwasia N, 2010, ACM MM, DOI DOI 10.1145/1873951.1873987; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Salakhutdinov R, 2009, ADV NEURAL INFORM PR; Socher R, 2010, PROC CVPR IEEE, P966, DOI 10.1109/CVPR.2010.5540112; Sohn K., 2014, P 27 INT C NEURAL IN, V2, P2141; Srivastava N., 2012, ADV NEURAL INFORM PR, P2222, DOI [DOI 10.1162/NEC0_A_00311, DOI 10.1109/CVPR.2013.49]; Srivastava Nitish, 2013, NIPS; Swersky K., 2010, INF THEOR APPL WORKS, P1, DOI DOI 10.1109/ITA.2010.5454138; Uria B, 2014, PR MACH LEARN RES, V32; Verbeek J., 2010, P INT C MULT INF RET, P537, DOI DOI 10.1145/1743384.1743476; Wang YXJ, 2011, QUANT IMAGING MED SU, V1, P1, DOI 10.3978/j.issn.2223-4292.2011.09.01; Zheng Y, 2014, PROC CVPR IEEE, P1370, DOI 10.1109/CVPR.2014.178	35	38	44	1	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2016	38	6					1056	1069		10.1109/TPAMI.2015.2476802	http://dx.doi.org/10.1109/TPAMI.2015.2476802			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DL4LU	26372202	Green Submitted			2022-12-18	WOS:000375609000002
J	Loog, M				Loog, Marco			Contrastive Pessimistic Likelihood Estimation for Semi-Supervised Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Maximum likelihood; semi-supervised learning; contrast; pessimism; linear discriminant analysis	DISCRIMINANT FUNCTION; RISK; GENOME	Improvement guarantees for semi-supervised classifiers can currently only be given under restrictive conditions on the data. We propose a general way to perform semi-supervised parameter estimation for likelihood-based classifiers for which, on the full training set, the estimates are never worse than the supervised solution in terms of the log-likelihood. We argue, moreover, that we may expect these solutions to really improve upon the supervised classifier in particular cases. In a worked-out example for LDA, we take it one step further and essentially prove that its semi-supervised version is strictly better than its supervised counterpart. The two new concepts that form the core of our estimation principle are contrast and pessimism. The former refers to the fact that our objective function takes the supervised estimates into account, enabling the semi-supervised solution to explicitly control the potential improvements over this estimate. The latter refers to the fact that our estimates are conservative and therefore resilient to whatever form the true labeling of the unlabeled data takes on. Experiments demonstrate the improvements in terms of both the log-likelihood and the classification error rate on independent test sets.	[Loog, Marco] Delft Univ Technol, Pattern Recognit Lab, Delft, Netherlands; [Loog, Marco] Univ Copenhagen, Image Sect, Copenhagen, Denmark	Delft University of Technology; University of Copenhagen	Loog, M (corresponding author), Delft Univ Technol, Pattern Recognit Lab, Delft, Netherlands.; Loog, M (corresponding author), Univ Copenhagen, Image Sect, Copenhagen, Denmark.	m.loog@tudelft.nl						Abney S., 2004, Computational Linguistics, V30, P365, DOI 10.1162/0891201041850876; Ackermann M, 2013, SCIENCE, V339, P807, DOI 10.1126/science.1231160; Allen J, 2013, SCIENCE, V340, P485, DOI 10.1126/science.1231976; [Anonymous], P 23 C UNC ART INT; Balcan MF, 2010, J ACM, V57, DOI 10.1145/1706591.1706599; Bartlett PL, 2006, J AM STAT ASSOC, V101, P138, DOI 10.1198/016214505000000907; Basu S., 2002, 19 INT C MACH LEARN, P27; Ben-David S., 2012, P 29 ANN INT C MACH, P1863; Ben-David S., 2008, C LEARN THEOR COLT; Bhatt R., 2009, SKIN SEGMENTATION DA; BICKEL P. J., 2001, MATH STAT, VI; Bien J, 2011, BIOMETRIKA, V98, P807, DOI 10.1093/biomet/asr054; Bridge JP, 2014, J AUTOM REASONING, V53, P141, DOI 10.1007/s10817-014-9301-5; Brown L.D., 1986, FUNDAMENTALS STAT EX, V9; Brunton BW, 2013, SCIENCE, V340, P95, DOI 10.1126/science.1233912; Cang H, 2011, NATURE, V469, P385, DOI 10.1038/nature09698; Casella G., 1998, THEORY POINT ESTIMAT; CASTELLI V, 1995, PATTERN RECOGN LETT, V16, P105, DOI 10.1016/0167-8655(94)00074-D; Chang Ming-Wei, 2007, ACL, P280; Chapelle O., 2006, IEEE T NEURAL NETW, V20, P542; Chung YJ, 2013, PSYCHOMETRIKA, V78, P685, DOI 10.1007/s11336-013-9328-2; Cohen I, 2004, IEEE T PATTERN ANAL, V26, P1553, DOI 10.1109/TPAMI.2004.127; Cule M, 2010, J R STAT SOC B, V72, P545, DOI 10.1111/j.1467-9868.2010.00753.x; D'Hont A, 2012, NATURE, V488, P213, DOI 10.1038/nature11241; DICK NP, 1973, BIOMETRICS, V29, P781, DOI 10.2307/2529143; DRESHER M, 1961, GAMES STRATEGY; Fisher R.A., 1922, PHILOS T R SOC LON A, V222, P309, DOI [DOI 10.1098/RSTA.1922.0009, 10.1098/rsta.1922.0009]; Fisher RA, 1925, P CAMB PHILOS SOC, V22, P700, DOI 10.1017/S0305004100009580; Fisher Ronald A., 1912, MESSENGER MATH, V41, P155; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Good P., 2000, PERMUTATION TESTS; Grandvalet Yves, 2004, NIPS, P529; Grunwald PD, 2004, ANN STAT, V32, P1367, DOI 10.1214/009053604000000553; HARTLEY HO, 1968, REV INST INT STAT, V36, P141, DOI 10.2307/1401602; Hastie T, 2009, ELEMENTS STAT LEARNI; HOSMER DW, 1973, BIOMETRICS, V29, P761, DOI 10.2307/2529141; Jiao YN, 2011, NATURE, V473, P97, DOI 10.1038/nature09916; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; Kawakita M, 2014, NEURAL NETWORKS, V53, P146, DOI 10.1016/j.neunet.2014.01.016; Krijthe J. H., 2013, IMPLICITLY CONSTRAIN; Krijthe JH, 2014, INT C PATT RECOG, P3762, DOI 10.1109/ICPR.2014.646; Lafferty J. D., 2007, ADV NEURAL INFORM PR, V20, P801; Laurence TA, 2010, NAT METHODS, V7, P338, DOI 10.1038/nmeth0510-338; Lee J. D., 2012, ARXIV12055012; Lichman M, 2013, UCI MACHINE LEARNING; Loog Marco, 2012, Partially Supervised Learning: First IAPR TC3 Workshop (PSL 2011). Revised Selected Papers, P32, DOI 10.1007/978-3-642-28258-4_4; Loog M, 2015, IEEE T NEUR NET LEAR, V26, P995, DOI 10.1109/TNNLS.2014.2329567; Loog M, 2014, PATTERN RECOGN LETT, V37, P24, DOI 10.1016/j.patrec.2013.03.004; Loog M, 2012, LECT NOTES COMPUT SC, V7626, P327, DOI 10.1007/978-3-642-34166-3_36; Loog M, 2012, LECT NOTES COMPUT SC, V7626, P310, DOI 10.1007/978-3-642-34166-3_34; Loog M, 2010, LECT NOTES ARTIF INT, V6322, P291, DOI 10.1007/978-3-642-15883-4_19; Lucas DD, 2013, GEOSCI MODEL DEV, V6, P1157, DOI 10.5194/gmd-6-1157-2013; MACULAN N, 1989, OPER RES LETT, V8, P219, DOI 10.1016/0167-6377(89)90064-3; Mann GS, 2010, J MACH LEARN RES, V11, P955; Mansouri K, 2013, J CHEM INF MODEL, V53, P867, DOI 10.1021/ci4000213; MCLACHLAN GJ, 1975, J AM STAT ASSOC, V70, P365; MCLACHLAN GJ, 1977, J AM STAT ASSOC, V72, P403, DOI 10.2307/2286807; MCLACHLAN GJ, 1982, COMMUN STAT B-SIMUL, V11, P753, DOI 10.1080/03610918208812293; Mclachlan GJ., 2005, DISCRIMINANT ANAL ST; NAGY G, 1966, IEEE T INFORM THEORY, V12, P215, DOI 10.1109/TIT.1966.1053864; Nigam K, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P792; Nummenmaa L, 2014, P NATL ACAD SCI USA, V111, P646, DOI 10.1073/pnas.1321664111; ONEILL TJ, 1978, J AM STAT ASSOC, V73, P821, DOI 10.2307/2286287; Price DC, 2012, SCIENCE, V335, P843, DOI 10.1126/science.1213561; Reid MD, 2011, J MACH LEARN RES, V12, P731; Reid MD, 2010, J MACH LEARN RES, V11, P2387; Ripley BD., 1996; Saglamyurek E, 2011, NATURE, V469, P512, DOI 10.1038/nature09719; Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4; Simon N., 2011, ARXIV11111687; Singh A., 2008, ADV NEURAL INFORM PR, V21, P1513; Sion M., 1958, PAC J MATH, V8, P171, DOI [10.2140/pjm.1958.8.171, DOI 10.2140/PJM.1958.8.171]; Sokolovska N., 2008, P 25 INT C MACH LEAR, P984; Stigler SM, 2007, STAT SCI, V22, P598, DOI 10.1214/07-STS249; Tamura K, 2011, MOL BIOL EVOL, V28, P2731, DOI 10.1093/molbev/msr121; TAN WY, 1972, BIOMETRICS, V28, P1073, DOI 10.2307/2528641; Thrun S., 2006, PROBABILISTIC ROBOTI; TITTERINGTON DM, 1976, ROY STAT SOC C-APP, V25, P238; Vergara A, 2012, SENSOR ACTUAT B-CHEM, V166, P320, DOI 10.1016/j.snb.2012.01.074; Vittaut J.-N., 2002, LNCS LNAI, V2430, P69; Wang J, 2013, HEREDITY, V111, P165, DOI 10.1038/hdy.2013.34; WHITE H, 1982, ECONOMETRICA, V50, P1, DOI 10.2307/1912526; Yang T, 2011, IEEE T PATTERN ANAL, V33, P2093, DOI 10.1109/TPAMI.2011.45; Yang ZH, 2012, NAT REV GENET, V13, P303, DOI 10.1038/nrg3186; Yarowsky David, 1995, ACL, P2, DOI [10.3115/981658.981684, DOI 10.3115/981658.981684]; Zhang T, 2004, ANN STAT, V32, P56; Zhu X, 2008, SCI YORK, V10, P10, DOI 10.1.1.146.2352; Zhu X, 2009, MORGAN CLAYPOOL, DOI DOI 10.1007/978-3-031-01548-9; Zien A., 2006, SEMISUPERVISED LEARN, P56	90	38	40	1	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2016	38	3					462	475		10.1109/TPAMI.2015.2452921	http://dx.doi.org/10.1109/TPAMI.2015.2452921			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE6JD	27046491	Green Submitted			2022-12-18	WOS:000370738900004
J	Song, HO; Girshick, R; Zickler, S; Geyer, C; Felzenszwalb, P; Darrell, T				Song, Hyun Oh; Girshick, Ross; Zickler, Stefan; Geyer, Christopher; Felzenszwalb, Pedro; Darrell, Trevor			Generalized Sparselet Models for Real-Time Multiclass Object Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection; sparse coding; deformable part models; real-time vision	SELECTION	The problem of real-time multiclass object recognition is of great practical importance in object recognition. In this paper, we describe a framework that simultaneously utilizes shared representation, reconstruction sparsity, and parallelism to enable real-time multiclass object detection with deformable part models at 5Hz on a laptop computer with almost no decrease in task performance. Our framework is trained in the standard structured output prediction formulation and is generically applicable for speeding up object recognition systems where the computational bottleneck is in multiclass, multi-convolutional inference. We experimentally demonstrate the efficiency and task performance of our method on PASCAL VOC, subset of ImageNet, Caltech101 and Caltech256 dataset.	[Song, Hyun Oh; Girshick, Ross; Darrell, Trevor] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA; [Zickler, Stefan] IRobot, Bedford, MA 01730 USA; [Geyer, Christopher] Berkshire Grey Inc, Boston, MA USA; [Felzenszwalb, Pedro] Brown Univ, Dept Engn & Comp Sci, Providence, RI 02912 USA	University of California System; University of California Berkeley; Brown University	Song, HO (corresponding author), Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.	song@eecs.berkeley.edu; rbg@eecs.berkeley.edu; szickler@irobot.com; cmgeyer@gmail.com; pff@brown.edu; trevor@eecs.berkeley.edu			Samsung Scholarship Foundation; NSF [IIS-0746569, IIS-0905647, IIS-0819984]; DARPA [W911NF-10-2-0059]; Toyota; Google	Samsung Scholarship Foundation(Samsung); NSF(National Science Foundation (NSF)); DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); Toyota; Google(Google Incorporated)	H. Song was supported by Samsung Scholarship Foundation. P. Felzenszwalb and R. Girshick were supported in part by NSF grant IIS-0746569. T. Darrell was supported by DARPA contract W911NF-10-2-0059, by NSF awards IIS-0905647, IIS-0819984, and support from Toyota and Google.	[Anonymous], 2007, PASCAL VISUAL OBJECT; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng J, 2010, LECT NOTES COMPUT SC, V6315, P71, DOI 10.1007/978-3-642-15555-0_6; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Felzenszwalb PF, 2010, PROC CVPR IEEE, P2241, DOI 10.1109/CVPR.2010.5539906; Felzenszwalb PF, 2010, DISCRIMINATIVELY TRA; Fidler S., 2009, OBJECT CATEGORIZATIO; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Girshick R., 2011, ADV NEURAL INFORM PR, V24, P442; Griffin Gregory, 2007, CALTECH 256 OBJECT C; Kreutz-Delgado K, 2003, NEURAL COMPUT, V15, P349, DOI 10.1162/089976603762552951; Langford J, 2009, J MACH LEARN RES, V10, P777; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; MAIRAL J., 2009, P 26 ANN INT C MACH, P689, DOI [10.1145/1553374.1553463, DOI 10.1145/1553374.1553463]; Mairal J, 2012, IEEE T PATTERN ANAL, V34, P791, DOI 10.1109/TPAMI.2011.156; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Manduchi R, 1998, IEEE T SIGNAL PROCES, V46, P1168, DOI 10.1109/78.668570; Ott P, 2011, PROC CVPR IEEE, P1513, DOI 10.1109/CVPR.2011.5995357; Pirsiavash H, 2012, PROC CVPR IEEE, P3226, DOI 10.1109/CVPR.2012.6248058; Sarwar B. M., 2000, WEBKDD 2000 WORKSH; Song H.O., 2013, ICML, P196; Song HO, 2012, LECT NOTES COMPUT SC, V7573, P802, DOI 10.1007/978-3-642-33709-3_57; Taskar B, 2004, ADV NEUR IN, V16, P25; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153; Wolf L, 2007, P 11 IEEE INT C COMP, P1, DOI DOI 10.1109/CVPR.2007.383099; Zhu L, 2010, PROC CVPR IEEE, P1919; Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x	33	38	41	1	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2015	37	5					1001	1012		10.1109/TPAMI.2014.2353631	http://dx.doi.org/10.1109/TPAMI.2014.2353631			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CF4PS	26353324				2022-12-18	WOS:000352533000008
J	Nicolaou, MA; Pavlovic, V; Pantic, M				Nicolaou, Mihalis A.; Pavlovic, Vladimir; Pantic, Maja			Dynamic Probabilistic CCA for Analysis of Affective Behavior and Fusion of Continuous Annotations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fusion of continuous annotations; component analysis; temporal alignment; dimensional emotion; affect analysis		Fusing multiple continuous expert annotations is a crucial problem in machine learning and computer vision, particularly when dealing with uncertain and subjective tasks related to affective behavior. Inspired by the concept of inferring shared and individual latent spaces in Probabilistic Canonical Correlation Analysis (PCCA), we propose a novel, generative model that discovers temporal dependencies on the shared/individual spaces (Dynamic Probabilistic CCA, DPCCA). In order to accommodate for temporal lags, which are prominent amongst continuous annotations, we further introduce a latent warping process, leading to the DPCCA with Time Warpings (DPCTW) model. Finally, we propose two supervised variants of DPCCA/DPCTW which incorporate inputs (i.e. visual or audio features), both in a generative (SG-DPCCA) and discriminative manner (SD-DPCCA). We show that the resulting family of models (i) can be used as a unifying framework for solving the problems of temporal alignment and fusion of multiple annotations in time, (ii) can automatically rank and filter annotations based on latent posteriors or other model statistics, and (iii) that by incorporating dynamics, modeling annotation-specific biases, noise estimation, time warping and supervision, DPCTW outperforms state-of-the-art methods for both the aggregation of multiple, yet imperfect expert annotations as well as the alignment of affective behavior.	[Nicolaou, Mihalis A.; Pantic, Maja] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England; [Pavlovic, Vladimir] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA; [Pantic, Maja] Univ Twente, EEMCS, Twente, Netherlands	Imperial College London; Rutgers State University New Brunswick; University of Twente	Nicolaou, MA (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England.	mihalis@imperial.ac.uk; vladimir@cs.rutgers.edu; m.pantic@imperial.ac.uk			European Research Council [ERC-2007-StG-203143]; European Community [288235]; National Science Foundation [IIS 0916812]	European Research Council(European Research Council (ERC)European Commission); European Community(European Commission); National Science Foundation(National Science Foundation (NSF))	This work is supported by the European Research Council under the ERC Starting Grant ERC-2007-StG-203143 (MAHNOB), by the European Communitys 7th Framework Programme [FP7/2007-2013] under Grant 288235 (FROG) and by the National Science Foundation under Grant IIS 0916812.	Audhkhasi K, 2013, IEEE T PATTERN ANAL, V35, P769, DOI 10.1109/TPAMI.2012.139; AUMANN RJ, 1976, ANN STAT, V4, P1236, DOI 10.1214/aos/1176343654; Bach F. R., 2006, 688 U CAL; Bishop C. M., 2006, INFOR MATION SCI STA, V2nd, DOI DOI 10.1117/1.2819119; BROWNE MW, 1979, BRIT J MATH STAT PSY, V32, P75, DOI 10.1111/j.2044-8317.1979.tb00753.x; Cowie R., 2010, STAT ANAL DATA INITI; Ghahramani Z, 1999, ADV NEUR IN, V11, P431; Grimm M, 2007, SPEECH COMMUN, V49, P787, DOI 10.1016/j.specom.2007.01.010; Gunes Hatice, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P827, DOI 10.1109/FG.2011.5771357; Hasan MA, 2009, IEEE IJCNN, P2640; Kim M, 2009, IEEE T PATTERN ANAL, V31, P1847, DOI 10.1109/TPAMI.2009.37; Klami A, 2008, NEUROCOMPUTING, V72, P39, DOI 10.1016/j.neucom.2007.12.044; Larkin MA, 2007, BIOINFORMATICS, V23, P2947, DOI 10.1093/bioinformatics/btm404; McKeown G, 2010, IEEE INT CON MULTI, P1079, DOI 10.1109/ICME.2010.5583006; Nicolaou MA, 2011, IEEE T AFFECT COMPUT, V2, P92, DOI 10.1109/T-AFFC.2011.9; Patras I, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P97, DOI 10.1109/AFGR.2004.1301515; Rabiner L., 1993, FUNDAMENTALS SPEECH; Raykar VC, 2010, J MACH LEARN RES, V11, P1297; Roweis S, 1999, NEURAL COMPUT, V11, P305, DOI 10.1162/089976699300016674; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; TUCKER LR, 1958, PSYCHOMETRIKA, V23, P111, DOI 10.1007/BF02289009; van der Merwe R, 2001, INT CONF ACOUST SPEE, P3461, DOI 10.1109/ICASSP.2001.940586; Wollmer M, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P597; Yu S., 2006, P 12 ACM SIGKDD INT, P464, DOI [DOI 10.1145/1150402.1150454, 10.1145/1150402.1150454]; Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52; Zhou F., 2009, ADV NEURAL INFORM PR, V22, P2286; Zhou F, 2012, PROC CVPR IEEE, P1282, DOI 10.1109/CVPR.2012.6247812	29	38	38	1	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2014	36	7					1299	1311		10.1109/TPAMI.2014.16	http://dx.doi.org/10.1109/TPAMI.2014.16			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AK1WS	26353304	Green Published, Green Accepted			2022-12-18	WOS:000338209900002
J	Nieuwenhuis, C; Cremers, D				Nieuwenhuis, Claudia; Cremers, Daniel			Spatially Varying Color Distributions for Interactive Multilabel Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image segmentation; spatially varying; color distribution; convex optimization	MOTION	We propose a method for interactive multilabel segmentation which explicitly takes into account the spatial variation of color distributions. To this end, we estimate a joint distribution over color and spatial location using a generalized Parzen density estimator applied to each user scribble. In this way, we obtain a likelihood for observing certain color values at a spatial coordinate. This likelihood is then incorporated in a Bayesian MAP estimation approach to multiregion segmentation which in turn is optimized using recently developed convex relaxation techniques. These guarantee global optimality for the two-region case (foreground/background) and solutions of bounded optimality for the multiregion case. We show results on the GrabCut benchmark, the recently published Graz benchmark, and on the Berkeley segmentation database which exceed previous approaches such as GrabCut [32], the Random Walker [15], Santner's approach [35], TV-Seg [39], and interactive graph cuts [4] in accuracy. Our results demonstrate that taking into account the spatial variation of color models leads to drastic improvements for interactive image segmentation.	[Nieuwenhuis, Claudia; Cremers, Daniel] Tech Univ Munich, Fac Comp Sci, D-85748 Garching, Germany	Technical University of Munich	Nieuwenhuis, C (corresponding author), Tech Univ Munich, Fac Comp Sci, Boltzmannstr 3, D-85748 Garching, Germany.	claudia.nieuwenhuis@in.tum.de; daniel.cremers@in.tum.de						Akaike H., 1954, ANN I STAT MATH, V6, P127, DOI DOI 10.1007/BF02900741; Bai X., 2007, P 11 IEEE INT C COMP; BLAKE A, 2004, P EUR C COMP VIS; Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov YY, 2001, P 8 IEEE INT C COMP; Brox T, 2009, INT J COMPUT VISION, V84, P184, DOI 10.1007/s11263-008-0153-5; Chambolle A., 2008, TR200805 U BONN DEP; Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286; Chuang YY, 2001, PROC CVPR IEEE, P264; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1; Duchenne O., 2006, TECHNICAL REPORT; Federer H., 1996, GEOMETRIC MEASURE TH; Gastal ESL, 2010, COMPUT GRAPH FORUM, V29, P575, DOI 10.1111/j.1467-8659.2009.01627.x; Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233; GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x; Kaiming He, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2049, DOI 10.1109/CVPR.2011.5995495; Kohli P., 2010, P 11 EUR C COMP VIS; Lellmann J., 2009, P 12 IEEE INT C COMP; Lellmann J., 2008, TECHNICAL REPORT; McGuinness K, 2010, PATTERN RECOGN, V43, P434, DOI 10.1016/j.patcog.2009.03.008; MICHELOT C, 1986, J OPTIMIZ THEORY APP, V50, P195, DOI 10.1007/BF00938486; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; Nieuwenhuis C., 2011, P 8 INT C EN MIN MET; Nieuwenhuis C, 2010, LECT NOTES COMPUT SC, V6376, P483; Pock T., 2009, P IEEE C COMP VIS PA; POCK T., 2009, P 12 IEEE INT C COMP; Pock T., 2011, P 13 IEEE INT C COMP; POTTS RB, 1952, P CAMB PHILOS SOC, V48, P106, DOI 10.1017/S0305004100027419; ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Santner J., 2010, THESIS U GRAZ; Santner J., 2010, P AS C COMP VIS; Silverman B.W., 1992, DENSITY ESTIMATION S; Tai YW, 2007, IEEE T PATTERN ANAL, V29, P1520, DOI 10.1109/TPAMI.2007.1168; Taron M, 2004, LECT NOTES COMPUT SC, V3216, P443; UNGER M, 2008, P BRIT MACH VIS C; Wang Jue, 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383006; Yuan J., 2010, P BRIT MACH VIS C; Zach C., 2008, P VIS MOD VIS WORKSH	42	38	40	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2013	35	5					1234	1247		10.1109/TPAMI.2012.183	http://dx.doi.org/10.1109/TPAMI.2012.183			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	106EZ	22908123	Green Submitted			2022-12-18	WOS:000316126800016
J	Ouzounis, GK; Pesaresi, M; Soille, P				Ouzounis, Georgios K.; Pesaresi, Martino; Soille, Pierre			Differential Area Profiles: Decomposition Properties and Efficient Computation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Differential area profile; DAP; decomposition; one-pass method; area filter; area zone; segmentation	REMOTE-SENSING IMAGES; CONNECTED OPERATORS; CLASSIFICATION; SEGMENTATION; RECONSTRUCTION; OPENINGS; FILTERS; TREE	Differential area profiles (DAPs) are point-based multiscale descriptors used in pattern analysis and image segmentation. They are defined through sets of size-based connected morphological filters that constitute a joint area opening top-hat and area closing bottom-hat scale-space of the input image. The work presented in this paper explores the properties of this image decomposition through sets of area zones. An area zone defines a single plane of the DAP vector field and contains all the peak components of the input image, whose size is between the zone's attribute extrema. Area zones can be computed efficiently from hierarchical image representation structures, in a way similar to regular attribute filters. Operations on the DAP vector field can then be computed without the need for exporting it first, and an example with the leveling-like convex/concave segmentation scheme is given. This is referred to as the one-pass method and it is demonstrated on the Max-Tree structure. Its computational performance is tested and compared against conventional means for computing differential profiles, relying on iterative application of area openings and closings. Applications making use of the area zone decomposition are demonstrated in problems related to remote sensing and medical image analysis.	[Ouzounis, Georgios K.; Pesaresi, Martino; Soille, Pierre] Joint Res Ctr European Commiss, Global Secur & Crisis Management Unit, Inst Protect & Secur Citizen, I-21027 Ispra, VA, Italy	European Commission Joint Research Centre; EC JRC ISPRA Site	Ouzounis, GK (corresponding author), Joint Res Ctr European Commiss, Global Secur & Crisis Management Unit, Inst Protect & Secur Citizen, TP-267,Via Enrico Fermi 2749, I-21027 Ispra, VA, Italy.	georgios.ouzounis@jrc.ec.europa.eu; martino.pesaresi@jrc.ec.europa.eu; pierre.soille@jrc.ec.europa.eu	Ouzounis, Georgios/AAU-9186-2020	Ouzounis, Georgios/0000-0001-8914-3398; Pesaresi, Martino/0000-0003-0620-439X				Akcay HG, 2008, IEEE T GEOSCI REMOTE, V46, P2097, DOI 10.1109/TGRS.2008.916644; Aytekin O., 2009, P SPIE EUROPEAN REMO, V7477; Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478; Benediktsson JA, 2003, IEEE T GEOSCI REMOTE, V41, P1940, DOI 10.1109/TGRS.2003.814625; BERGER C, 2007, IEEE INT C IM PROC S, V4, P41; Breen EJ, 1996, COMPUT VIS IMAGE UND, V64, P377, DOI 10.1006/cviu.1996.0066; Chanussot J, 2006, IEEE GEOSCI REMOTE S, V3, P40, DOI 10.1109/LGRS.2005.856117; Dalla Mura M, 2011, IEEE GEOSCI REMOTE S, V8, P542, DOI 10.1109/LGRS.2010.2091253; Dalla Mura M, 2010, INT J REMOTE SENS, V31, P5975, DOI 10.1080/01431161.2010.512425; Dalla Mura M, 2010, IEEE T GEOSCI REMOTE, V48, P3747, DOI 10.1109/TGRS.2010.2048116; Gratin C, 1994, COMP IMAG VIS, V2, P309; Gueguen Lionel, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P938, DOI 10.1109/ICPR.2010.235; Heijmans HJAM, 1999, COMPUT VIS IMAGE UND, V73, P99, DOI 10.1006/cviu.1998.0703; Heijmans HJAM, 1997, IEEE T IMAGE PROCESS, V6, P713, DOI 10.1109/83.568928; Jones R, 1999, COMPUT VIS IMAGE UND, V75, P215, DOI 10.1006/cviu.1999.0777; Klaric M, 2005, INT GEOSCI REMOTE SE, P1265; Kothe U., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P219, DOI 10.1007/BFb0015538; Kothe U., 1995, P 17 DAGM S, P554; Lefevre S., 2007, P IEEE ISPRS JOINT W; Lindeberg T., 1993, Proceedings of the 8th Scandinavian Conference on Image Analysis, P857; Lindeberg T., 1994, SCALE SPACE THEORY C; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; MARAGOS P, 1990, IEEE T PATTERN ANAL, V12, P498, DOI 10.1109/34.55110; Matas P, 2008, LECT NOTES COMPUT SC, V5259, P230, DOI 10.1007/978-3-540-88458-3_21; Matheron G., 1975, RANDOM SETS INTEGRAL; Matheron G, 1967, ELEMENTS THEORIE MIL; Meijster A, 2002, IEEE T PATTERN ANAL, V24, P484, DOI 10.1109/34.993556; Menotti D, 2007, P 8 INT S MATH MORPH, V1, P437; Meyer F, 1998, COMP IMAG VIS, V12, P199; Meyer F, 1998, COMP IMAG VIS, V12, P191; Mura M.D., 2009, IMAGE SIGNAL PROCESS; Najman L, 2006, IEEE T IMAGE PROCESS, V15, P3531, DOI 10.1109/TIP.2006.877518; Ouzounis G., 2011, P 34 INT S REM SENS; Ouzounis Georgios K., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4085, DOI 10.1109/ICPR.2010.993; Ouzounis G. K., 2007, P INT S MATH MORPH, P449; Pesaresi M, 2001, IEEE T GEOSCI REMOTE, V39, P309, DOI 10.1109/36.905239; Pesaresi M, 2000, COMPUT IMAGING VIS, V18, P179; SALEMBIER P, 1995, IEEE T IMAGE PROCESS, V4, P1153, DOI 10.1109/83.403422; Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500; SALEMBIER P, 1992, SIGNAL PROCESS, V27, P205, DOI 10.1016/0165-1684(92)90008-K; Salembier P., 2010, MATH MORPHOLOGY THEO, P179; Serra J, 2006, J MATH IMAGING VIS, V24, P83, DOI 10.1007/s10851-005-3616-0; Serra J., 1982, IMAGE ANAL MATH MORP, pChap11; Serra J, 1988, IMAGE ANAL MATH MORP; Shackelford A.K., 2005, P INT SOC PHOT REM S, V36; Shackelford AK, 2004, INT GEOSCI REMOTE SE, P1996; Shackelford AK, 2003, IEEE T GEOSCI REMOTE, V41, P1920, DOI 10.1109/TGRS.2003.814627; Small C., 2001, P IEEE ISPRS JOINT W; Soille P., 2013, MORPHOLOGICAL IMAGE; Urbach ER, 2007, IEEE T PATTERN ANAL, V29, P272, DOI 10.1109/TPAMI.2007.28; Vincent L, 1996, COMP IMAG VIS, P273; Vincent L., 2000, Fundamenta Informaticae, V41, P57; Vincent L, 1992, P NATO SHAP PICT WOR, P197; Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222; Westenberg MA, 2007, IEEE T IMAGE PROCESS, V16, P2943, DOI 10.1109/TIP.2007.909317; Wilkinson MHF, 2008, IEEE T PATTERN ANAL, V30, P1800, DOI 10.1109/TPAMI.2007.70836; Wilkinson MHF, 2008, IEEE IMAGE PROC, P2180, DOI 10.1109/ICIP.2008.4712221	57	38	43	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2012	34	8					1533	1548		10.1109/TPAMI.2011.245	http://dx.doi.org/10.1109/TPAMI.2011.245			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	957UE	22184259				2022-12-18	WOS:000305188500007
J	Kukelova, Z; Pajdla, T				Kukelova, Zuzana; Pajdla, Tomas			A Minimal Solution to Radial Distortion Autocalibration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Minimal problems; radial distortion; Grobner bases; polynomial eigenvalue problems	RELATIVE POSE	Simultaneous estimation of radial distortion, epipolar geometry, and relative camera pose can be formulated as a minimal problem and solved from a minimal number of image points. Finding the solution to this problem leads to solving a system of algebraic equations. In this paper, we provide two different solutions to the problem of estimating radial distortion and epipolar geometry from eight point correspondences in two images. Unlike previous algorithms which were able to solve the problem from nine correspondences only, we enforce the determinant of the fundamental matrix be zero. This leads to a system of eight quadratic and one cubic equation in nine variables. We first simplify this system by eliminating six of these variables and then solve the system by two alternative techniques. The first one is based on the Grobner basis method and the second one on the polynomial eigenvalue computation. We demonstrate that our solutions are efficient, robust, and practical by experiments on synthetic and real data.	[Kukelova, Zuzana; Pajdla, Tomas] Czech Tech Univ, Fac Elect Engn, Dept Cybernet, Prague 12135 2, Czech Republic	Czech Technical University Prague	Kukelova, Z (corresponding author), Czech Tech Univ, Fac Elect Engn, Dept Cybernet, Karlovo Namesti 13, Prague 12135 2, Czech Republic.	kukelova@cmp.felk.cvut.cz; pajdla@cmp.felk.cvut.cz	Kukelova, Zuzana/M-7938-2016; Pajdla, Tomas/K-7954-2013; Kukelova, Zuzana/AAM-9096-2020; Kukelova, Zuzana/GXG-1671-2022	Kukelova, Zuzana/0000-0002-1916-8829; Pajdla, Tomas/0000-0001-6325-0072; Kukelova, Zuzana/0000-0002-1916-8829	EC project [FP7-SPACE-241523 PRoViScout]; Czech Government [MSM6840770038]	EC project; Czech Government	This work has been supported by EC project FP7-SPACE-241523 PRoViScout and by the Czech Government under the research program MSM6840770038.	Bai Zhaojun, 2000, TEMPLATES SOLUTION A; Barreto J., 2005, P IEEE INT C COMP VI; Barreto J. P., 2009, PROCEDINGS BRIT MACH; Brauer-Burchardt C, 2001, IEEE IMAGE PROC, P225, DOI 10.1109/ICIP.2001.958994; Bujnak M., 2008, P IEEE C COMP VIS PA; Bujnak M., 2009, P AS C COMP VIS; Bujnak M., 2010, P AS C COMP VIS; Byrod M, 2009, P 20 BRIT MACH VIS C; BYROD M, 2007, P IEEE INT C COMP VI; Byrod M., 2008, P IEEE C COMP VIS PA; Claus D, 2005, PROC CVPR IEEE, P213; Cox D. A., 2005, USING ALGEBRAIC GEOM, V185; Devernay F, 2001, MACH VISION APPL, V13, P14, DOI 10.1007/PL00013269; Du F., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P477, DOI 10.1109/CVPR.1993.341087; Faugere JC, 1999, J PURE APPL ALGEBRA, V139, P61, DOI 10.1016/S0022-4049(99)00005-5; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fitzgibbon AW, 2001, PROC CVPR IEEE, P125; Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599; Gennery DB, 2006, INT J COMPUT VISION, V68, P239, DOI 10.1007/s11263-006-5168-1; GEYER C, 2007, P IEEE C COMP VIS PA; Hartley R., 2003, MULTIPLE VIEW GEOMET; Hartley RI, 2005, IEEE I CONF COMP VIS, P1834; Josephson K., 2009, P IEEE C COMP VIS PA; KANG S, 2000, P IEEE C COMP VIS PA; Kang S B, 2000, IAPR WORKSH MACH VIS, P603; Kuehnle K., 1996, P INT S SYMB ALG COM; Kukelova Z., 2007, P WORKSH OMN VIS CAM; Kukelova Z., 2008, P EUR C COMP VIS OCT; Kukelova Z., 2007, P IEEE C COMP VIS PA; Kukelova Z., 2008, P BRIT MACH VIS C; Kukelova Z, 2010, COMPUT VIS IMAGE UND, V114, P234, DOI 10.1016/j.cviu.2008.11.008; LI H, 2005, P WORKSH OMN VIS CAM; Li HD, 2006, INT C PATT RECOG, P630; Li HD, 2006, LECT NOTES COMPUT SC, V3954, P200; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; Micusik B, 2006, IEEE T PATTERN ANAL, V28, P1135, DOI 10.1109/TPAMI.2006.151; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; Ramalingam S., 2008, P IEEE C COMP VIS PA; Slama CC., 1980, MANUAL PHOTOGRAMMETR, V4th edn; Steele R., 2006, P EUR C COMP VIS; Stein G.P., 1995, P IEEE INT C COMP VI; Stein GP, 1997, PROC CVPR IEEE, P602, DOI 10.1109/CVPR.1997.609387; Stetter HJ., 2004, NUMERICAL POLYNOMIAL; Stewenius H, 2005, PROC CVPR IEEE, P789; Stewenius H., 2005, THESIS LUND U; Stewenius H., 2005, P WORKSH OMN VIS CAM; Stewenius H, 2006, ISPRS J PHOTOGRAMM, V60, P284, DOI 10.1016/j.isprsjprs.2006.03.005; Strand R., 2005, P BRIT MACH VIS C; Tardif J.-P., 2007, P 11 IEEE INT C COMP; Thirthala S, 2005, IEEE I CONF COMP VIS, P1539; Thirthala S, 2005, PROC CVPR IEEE, P321; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; TRAVERSO C, 1989, LECT NOTES COMPUT SC, V358, P125; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; Zhang Z., 1996, P INT C PATT REC; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	56	38	40	1	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2011	33	12					2410	2422		10.1109/TPAMI.2011.86	http://dx.doi.org/10.1109/TPAMI.2011.86			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	834RE	21576743				2022-12-18	WOS:000295980000008
J	Cech, J; Matas, J; Perdoch, M				Cech, Jan; Matas, Jiri; Perdoch, Michal			Efficient Sequential Correspondence Selection by Cosegmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Correspondence; matching; verification; sequential decision; growing; cosegmentation; stereo; image retrieval; learning	ALGORITHM	In many retrieval, object recognition, and wide-baseline stereo methods, correspondences of interest points (distinguished regions) are commonly established by matching compact descriptors such as SIFTs. We show that a subsequent cosegmentation process coupled with a quasi-optimal sequential decision process leads to a correspondence verification procedure that 1) has high precision (is highly discriminative), 2) has good recall, and 3) is fast. The sequential decision on the correctness of a correspondence is based on simple statistics of a modified dense stereo matching algorithm. The statistics are projected on a prominent discriminative direction by SVM. Wald's sequential probability ratio test is performed on the SVM projection computed on progressively larger cosegmented regions. We show experimentally that the proposed sequential correspondence verification (SCV) algorithm significantly outperforms the standard correspondence selection method based on SIFT distance ratios on challenging matching problems.	[Cech, Jan; Matas, Jiri; Perdoch, Michal] Czech Tech Univ, Dept Cybernet, Fac Elect Engn, Ctr Machine Percept, Prague 16627 6, Czech Republic	Czech Technical University Prague	Cech, J (corresponding author), Czech Tech Univ, Dept Cybernet, Fac Elect Engn, Ctr Machine Percept, Tech 2, Prague 16627 6, Czech Republic.	cechj@cmp.felk.cvut.cz; matas@cmp.felk.cvut.cz; perdom1@cmp.felk.cvut.cz	, Matas/AAW-3282-2020		Czech Academy of Sciences [1ET101210406]; EC [FP6-IST-027113 eTRIMS, ICT-215078 DIPLECS]; Czech Government [MSM6840770038]	Czech Academy of Sciences(Czech Academy of Sciences); EC(European CommissionEuropean Commission Joint Research Centre); Czech Government	The research was supported by the Czech Academy of Sciences project 1ET101210406, by EC projects FP6-IST-027113 eTRIMS and ICT-215078 DIPLECS, and by the Czech Government research program MSM6840770038. The Valbonne images were provided by INRIA Sophia and the Raglan images by Julian Morris.	CECH J, 2007, P BENCOS WORKSH IEEE; CECH J, 2008, P IEEE C COMP VIS PA; Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221; Chum O., 2009, P IEEE C COMP VIS PA; Chum O., 2007, P IEEE INT C COMP VI; Ferrari V, 2006, INT J COMPUT VISION, V67, P159, DOI 10.1007/s11263-005-3964-7; FRANC V, 2008, P INT MACH LEARN C; KANNALA J, 2007, P IEEE C COMP VIS PA; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; Leibe B., 2006, P BRIT MACH VIS C; Lhuillier M, 2002, IEEE T PATTERN ANAL, V24, P1140, DOI 10.1109/TPAMI.2002.1023810; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Megyesi Z., 2006, Machine Graphics & Vision, V15, P3; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Morevec H.P., 1977, INT JOINT C ART INT, V2, P584; Nister David, 2006, CVPR, P2161, DOI DOI 10.1109/CVPR.2006.264; OBDRZALEK S, 2005, P BRIT MACH VIS C; OTTO GP, 1989, IMAGE VISION COMPUT, V7, P83, DOI 10.1016/0262-8856(89)90001-2; Philbin J, 2007, CVPR; Platt JC, 2000, ADV NEUR IN, P61; Rother C., 2006, P IEEE C COMP VIS PA; Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Stewart CV, 2003, IEEE T MED IMAGING, V22, P1379, DOI 10.1109/TMI.2003.819276; Tuytelaars T., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P412; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; VEDALDI A, 2006, P IEEE C COMP VIS PA, P1753; Wald A., 1947, SEQUENTIAL ANAL; Yang GH, 2007, IEEE T PATTERN ANAL, V29, P1973, DOI [10.1109/TPAMI.2007.1116, 10.1109/TPAMl.2007.1116.]	32	38	43	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2010	32	9					1568	1581		10.1109/TPAMI.2009.176	http://dx.doi.org/10.1109/TPAMI.2009.176			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	626MB	20634553	Green Submitted, Green Published			2022-12-18	WOS:000279969000003
J	Mantrach, A; Yen, L; Callut, J; Francoisse, K; Shimbo, M; Saerens, M				Mantrach, Amin; Yen, Luh; Callut, Jerome; Francoisse, Kevin; Shimbo, Masashi; Saerens, Marco			The Sum-over-Paths Covariance Kernel: A Novel Covariance Measure between Nodes of a Directed Graph	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graph mining; kernel on a graph; shortest path; correlation measure; betweenness measure; resistance distance; commute time distance; biased random walk; semi-supervised classification	DIFFUSION MAPS; EIGENVECTORS; MATRICES; DIGRAPH; FORESTS	This work introduces a link-based covariance measure between the nodes of a weighted directed graph, where a cost is associated with each arc. To this end, a probability distribution on the (usually infinite) countable set of paths through the graph is defined by minimizing the total expected cost between all pairs of nodes while fixing the total relative entropy spread in the graph. This results in a Boltzmann distribution on the set of paths such that long (high-cost) paths occur with a low probability while short (low-cost) paths occur with a high probability. The sum-over-paths (SoP) covariance measure between nodes is then defined according to this probability distribution: two nodes are considered as highly correlated if they often co-occur together on the same-preferably short-paths. The resulting covariance matrix between nodes (say n nodes in total) is a Gram matrix and therefore defines a valid kernel on the graph. It is obtained by inverting an n x n matrix depending on the costs assigned to the arcs. In the same spirit, a betweenness score is also defined, measuring the expected number of times a node occurs on a path. The proposed measures could be used for various graph mining tasks such as computing betweenness centrality, semi-supervised classification of nodes, visualization, etc., as shown in Section 7.	[Mantrach, Amin] Univ Libre Bruxelles, IRIDIA, CoDE, B-1050 Brussels, Belgium; [Yen, Luh; Callut, Jerome; Francoisse, Kevin; Saerens, Marco] Catholic Univ Louvain, IAG, ISYS, ISYS,LSM, B-3000 Louvain, Belgium; [Shimbo, Masashi] Nara Inst Sci & Technol, Grad Sch Informat Sci, Nara 6300192, Japan	Universite Libre de Bruxelles; Universite Catholique Louvain; Nara Institute of Science & Technology	Mantrach, A (corresponding author), Univ Libre Bruxelles, IRIDIA, CoDE, 50 Av F Roosevelt,CP 194-6, B-1050 Brussels, Belgium.	amantrac@ulb.ac.be; luh.yen@uclouvain.be; jerome.callut@uclouvain.be; kevin.francoisse@uclouvain.be; shimbo@is.naist.jp; marco.saerens@uclouvain.be			Region wallonne; Belgian "Politique Scientifique Federale."	Region wallonne; Belgian "Politique Scientifique Federale."	The authors thank the anonymous reviewers for their interesting remarks and suggestions that helped to significantly improve the quality of the paper. Part of this work has been funded by projects with the "Region wallonne" and the Belgian "Politique Scientifique Federale." The authors thank these institutions for giving them the	Agaev RP, 2000, AUTOMAT REM CONTR+, V61, P1424; Agaev RP, 2001, AUTOMAT REM CONTR+, V62, P443, DOI 10.1023/A:1002862312617; Akamatsu T, 1996, TRANSPORT RES B-METH, V30, P369, DOI 10.1016/0191-2615(96)00003-3; [Anonymous], 2005, P 11 ACM SIGKDD INT; [Anonymous], 2005, P INT S COMP INF SCI, P284; Bapat R. B., 1999, MATH STUDENT, V68, P87; Blondel VD, 2004, SIAM REV, V46, P647, DOI 10.1137/S0036144502415960; Borg I., 1997, MODERN MULTIDIMENSIO; BORGWARDT K, 2005, BIOINFORMATICS, V12, P337; Brand M, 2005, SIAM PROC S, P12; Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X; Bronson R., 1989, MATRIX OPERATIONS; Callut J, 2008, LECT NOTES ARTIF INT, V5211, P162, DOI 10.1007/978-3-540-87479-9_29; Chandra A. K., 1989, Proceedings of the Twenty First Annual ACM Symposium on Theory of Computing, P574, DOI 10.1145/73007.73062; Chandrasekhar S, 1997, J ASTROPHYS ASTRON, V18, P3, DOI 10.1007/BF02714848; Chapelle O., 2006, SEMISUPERVISED LEARN, P277, DOI DOI 10.7551/MITPRESS/9780262033589; CHEBOTAREV P, 2008, ARXIV08102717V2; Chebotarev PY, 1998, AUTOMAT REM CONTR+, V59, P1443; Chebotarev PY, 1997, AUTOMAT REM CONTR+, V58, P1505; Chen M, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2707; Chung F, 2005, ANN COMB, V9, P1, DOI 10.1007/s00026-005-0237-z; Davis T.A, 2006, DIRECT METHODS SPARS; DELVENNE JC, 2008, ARXIV08121770; Donetti L, 2004, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2004/10/P10012; Doyle PG., 1984, RANDOM WALKS ELECT N, Vvol 22; FIEDLER M, 1975, CZECH MATH J, V25, P607; Fine S, 2002, J MACH LEARN RES, V2, P243, DOI 10.1162/15324430260185619; Fouss F, 2006, IEEE DATA MINING, P863; Fouss F, 2007, IEEE T KNOWL DATA EN, V19, P355, DOI 10.1109/TKDE.2007.46; Golub Gene H., 2013, MATRIX COMPUTATION, V3; GORI M, 2006, P ACM SIGKDD; Greene D., 2006, P 23 INT C MACHINE L, P377, DOI DOI 10.1145/1143844.1143892; Ham J., 2004, P 21 INT C MACH LEAR, P47, DOI [10.1145/1015330.1015417, DOI 10.1145/1015330.1015417]; Harel D., 2001, P LECT NOTES COMPUTE, V2245, P18, DOI DOI 10.1007/3-540-45294-X_3; Harville D.A., 1997, MATRIX ALGEBRA STATI; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; KANDOLA J, 2002, P ADV NEUR INF PROC, P657; Kapur J., 1992, ENTROPY OPTIMIZATION; Kemeny J.G., 1976, MARKOV CHAINS, V6; KESSLER MM, 1963, AM DOC, V14, P10, DOI 10.1002/asi.5090140103; KLEIN DJ, 1993, J MATH CHEM, V12, P81, DOI 10.1007/BF01164627; Kondor R.I., 2002, P 19 INT C MACHINE L, P315; Koren Y., 2006, P 12 ACM SIGKDD INT, P245; Koren Y, 2007, ACM T KNOWLEDGE DISC, V1; Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1393, DOI 10.1109/TPAMI.2006.184; Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591; Lovasz L, 1996, BOLYAI MATH STUD, V2, P353; Lu WZ, 2007, KNOWL INF SYST, V11, P105, DOI 10.1007/s10115-006-0023-9; Macskassy SA, 2007, J MACH LEARN RES, V8, P935; MOHAR B, 1992, DISCRETE MATH, V109, P171, DOI 10.1016/0012-365X(92)90288-Q; NADLER B, 2005, ADV NEURAL INFORM PR, V18, P955; Nadler B, 2006, APPL COMPUT HARMON A, V21, P113, DOI 10.1016/j.acha.2005.07.004; Newman MEJ, 2005, SOC NETWORKS, V27, P39, DOI 10.1016/j.socnet.2004.11.009; Newman MEJ, 2004, PHYS REV E, V70, DOI [10.1103/PhysRevE.70.056131, 10.1103/PhysRevE.69.026113]; Page L., 1999, PAGERANK CITATION RA; Palmer CR, 2003, LECT NOTES ARTIF INT, V2637, P486; PAN JY, 2004, P 10 ACM SIGKDD INT, P653, DOI DOI 10.1145/1014052.1014135; Pons P, 2005, LECT NOTES COMPUT SC, V3733, P284; POTHEN A, 1990, SIAM J MATRIX ANAL A, V11, P430, DOI 10.1137/0611030; Qiu HJ, 2007, IEEE T PATTERN ANAL, V29, P1873, DOI 10.1109/TPAMI.2007.1103; Reichl LE., 1980, MODERN COURSE STAT P; Rudnick J., 2004, ELEMENTS RANDOM WALK; Saerens M, 2004, LECT NOTES COMPUT SC, V3201, P371; Saerens M, 2009, NEURAL COMPUT, V21, P2363, DOI 10.1162/neco.2009.11-07-643; Sage J.L., 2009, INTRO SPATIAL ECONOM; SARKAR P, 2007, P 23 C UNC ART INT; Schabenberger O., 2004, STAT METHODS SPATIAL; Schrodinger E, 1952, STAT THERMODYNAMICS; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; SHIMBO M, 2006, MINING GRAPH DATA, P283, DOI DOI 10.1002/9780470073049.CH12; SMALL H, 1973, J AM SOC INFORM SCI, V24, P265, DOI 10.1002/asi.4630240406; SMOLA AJ, 2003, P 16 ANN C LEARN THE, P144; Tahbaz-Salehi A, 2006, IEEE DECIS CONTR P, P4664, DOI 10.1109/CDC.2006.377308; TONG H, 2007, KNOWLEDGE INFORM SYS; Tong HH, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P747; VISHWANATHAN S, 2009, GRAPH KERNELS; Wasserman S, 1994, SOCIAL NETWORK ANAL, DOI DOI 10.1017/CBO9780511815478; Weston J, 2003, ANN I STAT MATH, V55, P391, DOI 10.1023/A:1026338322729; White S, 2003, P 9 ACM SIGKDD INT C, P266, DOI [10.1145/956750.956782, DOI 10.1145/956750.956782]; Yen L., 2005, P 13 S ART NEUR NETW, P317; Yen L., 2008, P 14 ACM SIGKDD, P785, DOI DOI 10.1145/1401890.1401984; Yen L, 2007, LECT NOTES COMPUT SC, V4426, P1037; Yen L, 2009, DATA KNOWL ENG, V68, P338, DOI 10.1016/j.datak.2008.10.006; ZACHARY WW, 1977, J ANTHROPOL RES, V33, P452, DOI 10.1086/jar.33.4.3629752; Zhao DL, 2007, IEEE I CONF COMP VIS, P2096; Zhou D., 2005, P 22 INT C MACH LEAR, P1036, DOI [10.1145/1102351.1102482, DOI 10.1145/1102351.1102482]; Zhou DY, 2004, LECT NOTES COMPUT SC, V3175, P237; Zhou HJ, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.041908; Zhou HJ, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.061901; [No title captured]	91	38	40	1	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2010	32	6					1112	1126		10.1109/TPAMI.2009.78	http://dx.doi.org/10.1109/TPAMI.2009.78			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	583JU	20431135				2022-12-18	WOS:000276671900012
J	Pele, O; Werman, M				Pele, Ofir; Werman, Michael			Robust real-time pattern matching using Bayesian sequential hypothesis testing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern matching; template matching; pattern detection; image similarity measures; Hamming distance; real time; sequential hypothesis testing; composite hypothesis; image statistics; Bayesian statistics; finite populations	IMAGE REGISTRATION; ALGORITHMS; RECOGNITION; STATISTICS; FEATURES; TEXTURE	This paper describes a method for robust real-time pattern matching. We first introduce a family of image distance measures, the Image Hamming Distance Family. Members of this family are robust to occlusion, small geometrical transforms, light changes, and nonrigid deformations. We then present a novel Bayesian framework for sequential hypothesis testing on finite populations. Based on this framework, we design an optimal rejection/acceptance sampling algorithm. This algorithm quickly determines whether two images are similar with respect to a member of the Image Hamming Distance Family. We also present a fast framework that designs a near-optimal sampling algorithm. Extensive experimental results show that the sequential sampling algorithm's performance is excellent. Implemented on a Pentium IV 3 GHz processor, the detection of a pattern with 2,197 pixels in 640 x 480 pixel frames, where in each frame the pattern rotated and was highly occluded, proceeds at only 0.022 seconds per frame.	[Pele, Ofir; Werman, Michael] Hebrew Univ Jerusalem, Sch Comp Sci & Engn, IL-91904 Jerusalem, Israel	Hebrew University of Jerusalem	Pele, O (corresponding author), Hebrew Univ Jerusalem, Sch Comp Sci & Engn, IL-91904 Jerusalem, Israel.	ofirpele@cs.huji.ac.il; werman@cs.huji.ac.il						Abhyankar A, 2005, PROC SPIE, V5779, P59, DOI 10.1117/12.604212; AHUMADA AJ, 1998, SID INT S, V24, P305; Amir A, 1998, IEEE T PATTERN ANAL, V20, P168, DOI 10.1109/34.659934; Amit Y., 2002, 2D OBJECT DETECTION; Anuta PE., 1970, IEEE T GEOSCI ELECTR, V8, P353, DOI [10.1109/tge.1970.271435, DOI 10.1109/TGE.1970.271435]; AVIDAN S, 2004, NEURAL INFORM PR DEC; BARNEA DI, 1972, IEEE T COMPUT, VC 21, P179, DOI 10.1109/TC.1972.5008923; Bay H., 2006, EUR C COMP VIS ECCV, P404, DOI [10.1007/11744023_32, DOI 10.1007/11744023_32]; Ben-Artzi G, 2007, IEEE T PATTERN ANAL, V29, P382, DOI 10.1109/TPAMI.2007.62; Ben-Yehuda M., 2005, P 12 INT C IM PROC, P834; BLOSTEIN SD, 1991, IEEE T SIGNAL PROCES, V39, P1611, DOI 10.1109/78.134399; Bookstein A, 2002, INFORM RETRIEVAL, V5, P353, DOI 10.1023/A:1020499411651; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; Cha SH, 2000, J MATH IMAGING VIS, V12, P81, DOI 10.1023/A:1008309026555; CYGANEK B, 2004, P 10 INT WORKSH COMB, P534; DAUGMAN JG, 1989, IEEE T BIO-MED ENG, V36, P107, DOI 10.1109/10.16456; Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GHARAVI H, 1990, IEEE T CIRCUITS SYST, V37, P649, DOI 10.1109/31.55010; GIROD B, 1993, WHATS WRONG MEAN SQU, pCH15; Govindarajulu Z., 1975, SEQUENTIAL STAT PROC; Hel-Or Y, 2005, IEEE T PATTERN ANAL, V27, P1430, DOI 10.1109/TPAMI.2005.184; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; IONESCU M, 2004, P 13 IEEE INT C FUZZ; Keren D, 2001, IEEE T PATTERN ANAL, V23, P747, DOI 10.1109/34.935848; Lee J, 2001, J NANOSCI NANOTECHNO, V1, P59, DOI 10.1166/jnn.2001.009; LEHMANN EL, 1959, TESTING STATISTICAL, P104; Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188; LEWIS C, 1990, APPL PSYCH MEAS, V14, P367, DOI 10.1177/014662169001400404; Lewis J., 1995, FAST NORMALIZED CROS; Liang L, 2001, ACM T GRAPHIC, V20, P127, DOI 10.1145/501786.501787; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; LV Q, 2004, P 13 ACM C INF KNOWL, P208; MASCARENHAS NDA, 1992, COMPUT GRAPH, V16, P259, DOI 10.1016/0097-8493(92)90002-D; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Matas J, 2005, IEEE I CONF COMP VIS, P1727; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mittag Hans-Joachim, 1993, STAT METHODS QUALITY; PEREIRA JAG, 1984, COMPUT GRAPH, V8, P247, DOI 10.1016/0097-8493(84)90005-0; Romdhani S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P695, DOI 10.1109/ICCV.2001.937694; Santini S, 1999, IEEE T PATTERN ANAL, V21, P871, DOI 10.1109/34.790428; Shaked D, 1996, COMPUT VIS IMAGE UND, V63, P512, DOI 10.1006/cviu.1996.0038; Siegmund D., 1985, SEQUENTIAL ANAL; Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193; Sochman J, 2005, PROC CVPR IEEE, P150; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Vos HJ, 2007, COMPUT HUM BEHAV, V23, P609, DOI 10.1016/j.chb.2004.11.002; WALD A, 1948, ANN MATH STAT, V19, P326, DOI 10.1214/aoms/1177730197; Wald A., 1947, SEQUENTIAL ANAL; Wyszecki G., 2000, COLOR SCI CONCEPTS M, V2nd; ZABIH R, 1994, P EUR C COMP VIS, P151; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	55	38	39	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2008	30	8					1427	1443		10.1109/TPAMI.2007.70794	http://dx.doi.org/10.1109/TPAMI.2007.70794			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	312OC	18566496	Green Submitted			2022-12-18	WOS:000256679700009
J	Kamel, NS; Sayeed, S; Ellis, GA				Kamel, Nidal S.; Sayeed, Shohel; Ellis, Grant A.			Glove-based approach to online signature verification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						data glove; online signature verification; singular value decomposition		Utilizing the multiple degrees of freedom offered by the data glove for each finger and the hand, a novel online signature verification system using the Singular Value Decomposition (SVD) numerical tool for signature classification and verification is presented. The proposed technique is based on the Singular Value Decomposition in finding r singular vectors sensing the maximal energy of glove data matrix A, called principal subspace, so the effective dimensionality of A can be reduced. Having modeled the data glove signature through its r-principal subspace, signature authentication is performed by finding the angles between the different subspaces. A demonstration of the data glove is presented as an effective high-bandwidth data entry device for signature verification. This SVD-based signature verification technique is tested and its performance is shown to be able to produce Equal Error Rate (EER) of less than 2.37 percent.	[Kamel, Nidal S.; Ellis, Grant A.] Univ Teknol PETRONAS, Dept Elect Engn & Elect, Tronoh 31750, Perak, Malaysia; [Sayeed, Shohel] Multimedia Univ, Fac Informat Sci & Technol, Melaka 75450, Malaysia	Universiti Teknologi Petronas; Multimedia University	Kamel, NS (corresponding author), Univ Teknol PETRONAS, Dept Elect Engn & Elect, Bandar Seri Iskandar, Tronoh 31750, Perak, Malaysia.	nidalkamel@petronas.com.my; grant_ellis@petronas.com.my; shohel.sayeed@mmu.edu.my	SAYEED, MD SHOHEL/AGB-6230-2022; Kamel, Nidal/D-3664-2013; Sayeed, Md Shohel/B-6554-2009	Sayeed, Md Shohel/0000-0002-0052-4870				DEPRETTERE F, 1989, SVD SIGNAL PROCESSIN; Drmac Z, 2000, SIAM J MATRIX ANAL A, V22, P173, DOI 10.1137/S0895479897320824; Fierrez-Aguilar J, 2005, LECT NOTES COMPUT SC, V3546, P523; FIERREZAGUILAR J, 2005, IEEE T SYSTEMS MAN C, V35; Golub Gene H., 2013, MATRIX COMPUTATION, V3; GOLUB GH, 1995, CANONICAL CORRELATIO, P27; KHOLMATOV A, 2005, PATTERN RECOGN, P2400; LEI H, 2004, P 9 INT WORKSH FORNT; MURAMATSU D, 2003, P 17 INT C DOC AN RE; NAKANISHI I, 2006, P INT S INT SIGN PRO; NAKANISHI I, 2005, P INT C AC SPEECH SI; SHINTARO K, 2006, P INT S INT SIGN PRO; YEUNG D, 2004, P INT C BIOM AUTH, P16	13	38	40	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2008	30	6					1109	1113		10.1109/TPAMI.2008.32	http://dx.doi.org/10.1109/TPAMI.2008.32			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	286UW	18421114				2022-12-18	WOS:000254872500014
J	Gupta, A; Mittal, A; Davis, LS				Gupta, Abhinav; Mittal, Anurag; Davis, Larry S.			Constraint integration for efficient multiview pose estimation with self-occlusions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						three-dimensional/stereo scene analysis; motion capture; tracking	BELIEF PROPAGATION; TRACKING PEOPLE; SILHOUETTES; MODELS	Automatic initialization and tracking of human pose is an important task in visual surveillance. We present a part-based approach that incorporates a variety of constraints in a unified framework. These constraints include the kinematic constraints between parts that are physically connected to each other, the occlusion of one part by another, and the high correlation between the appearance of certain parts, such as the arms. The location probability distribution of each part is determined by evaluating appropriate likelihood measures. The graphical (nontree) structure representing the interdependencies between parts is utilized to "connect" such part distributions via nonparametric belief propagation. Methods are also developed to perform this optimization efficiently in the large space of pose configurations.	[Gupta, Abhinav; Davis, Larry S.] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA; [Mittal, Anurag] Indian Inst Technol, Dept Comp Sci & Engn, Madras 600036, Tamil Nadu, India	University System of Maryland; University of Maryland College Park; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Madras	Gupta, A (corresponding author), Univ Maryland, Dept Comp Sci, 3362 AV Williams Bldg, College Pk, MD 20742 USA.	agupta@cs.umd.edu; amittal@cs.iitm.ernet.in; lsd@cs.umd.edu						Agarwal A, 2004, PROC CVPR IEEE, P882; BALAN A, 2005, P IEEE I WORKSH VIS; Brand M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1237, DOI 10.1109/ICCV.1999.790422; Cheung GKM, 2003, PROC CVPR IEEE, P77; Coughlan JM, 2002, LECT NOTES COMPUT SC, V2352, P453; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Delamarre Q., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P716, DOI 10.1109/ICCV.1999.790292; Deutscher J, 2000, PROC CVPR IEEE, P126, DOI 10.1109/CVPR.2000.854758; Elgammal A, 2004, PROC CVPR IEEE, P681; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Felzenszwalb PF, 2000, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.2000.854739; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; GUPTA A, 2006, P I S 3D DAT PROC VI; HOWE NR, 2004, P IEEE WORKSH ART NO; Hua G, 2005, PROC CVPR IEEE, P747; Ihler AT, 2005, J MACH LEARN RES, V6, P905; Ioffe S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1092, DOI 10.1109/ICCV.1999.790398; Ioffe S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P690, DOI 10.1109/ICCV.2001.937589; Isard M, 2003, PROC CVPR IEEE, P613; Ju SX, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P38, DOI 10.1109/AFGR.1996.557241; Lan XY, 2005, IEEE I CONF COMP VIS, P470; Lee MW, 2004, PROC CVPR IEEE, P334; MACCORMICK J, 2000, P EUR C COMP VIS, P3; Mikic I, 2003, INT J COMPUT VISION, V53, P199, DOI 10.1023/A:1023012723347; Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69; Mittal A, 2003, INT J COMPUT VISION, V51, P189, DOI 10.1023/A:1021849801764; MITTAL A, 2003, P I C ADV VID SIGN B; Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897; Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571; Mori G, 2004, PROC CVPR IEEE, P326; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Ramanan D, 2005, PROC CVPR IEEE, P271; Ramanan D, 2003, PROC CVPR IEEE, P467; REN X, 2005, P 10 INT C COMP VIS, V1, P824; Ronfard R, 2002, LECT NOTES COMPUT SC, V2353, P700; Rosales R, 2001, PROC CVPR IEEE, P821; Roth S, 2004, PROC CVPR IEEE, P886; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; Sidenbladh H., 2000, LNCS, V2, P702; Sigal L, 2004, ADV NEUR IN, V16, P1539; Sigal L, 2004, PROC CVPR IEEE, P421; Sigal L., 2006, PROC IEEE C COMPUT V, P2041; Sminchisescu C, 2005, PROC CVPR IEEE, P390; SUDDERTH E, 2004, P ANN C NEUR INF PRO; Sudderth EB, 2003, PROC CVPR IEEE, P605; Tatikonda S. C., 2002, P 18 C UNC ART INT, P493; TU Z, 2002, IEEE T PATTERN ANAL, V24, P131; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wainwright MJ, 2003, IEEE T INFORM THEORY, V49, P1120, DOI 10.1109/TIT.2003.810642; Weiss Y, 2000, NEURAL COMPUT, V12, P1, DOI 10.1162/089976600300015880; Weiss Y, 2001, NEURAL COMPUT, V13, P2173, DOI 10.1162/089976601750541769; WEISS Y, 1996, P ANN C NEUR INF PRO	52	38	39	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2008	30	3					493	506		10.1109/TPAMI.2007.1173	http://dx.doi.org/10.1109/TPAMI.2007.1173			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	250FT	18195442	Green Submitted			2022-12-18	WOS:000252286100010
J	Astorino, A; Fuduli, A				Astorino, Annabella; Fuduli, Antonio			Nonsmooth optimization techniques for semisupervised classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						semisupervised learning; nonsmooth optimization; bundle methods		We apply nonsmooth optimization techniques to classification problems, with particular reference to the Transductive Support Vector Machine ( TSVM) approach, where the considered decision function is nonconvex and nondifferentiable, hence difficult to minimize. We present some numerical results obtained by running the proposed method on some standard test problems drawn from the binary classification literature.	Univ Calabria, Dipartimento Elettron Informat & Sistemist, I-87036 Arcavacata Di Rende, CS, Italy; Univ Calabria, Dipartimento Matemat, I-87036 Arcavacata Di Rende, CS, Italy	University of Calabria; University of Calabria	Astorino, A (corresponding author), Univ Calabria, Dipartimento Elettron Informat & Sistemist, Cubo 41C, I-87036 Arcavacata Di Rende, CS, Italy.	astorino@icar.cnr.it; antonio.fuduli@unical.it	Astorino, Annabella/AAG-5095-2020; Fuduli, Antonio/AAE-8426-2019	Astorino, Annabella/0000-0002-3439-180X; Fuduli, Antonio/0000-0002-1657-0257				Astorino A., 1997, Operations Research Proceedings 1996. Selected Papers of the Symposium on Operations Research (SOR 96), P20; Belkin M, 2004, MACH LEARN, V56, P209, DOI 10.1023/B:MACH.0000033120.25363.1e; Bennett K.P., 1992, OPT MET SOFTW, V1, P23; Bennett KP, 2000, MAA NOTES SER, V53, P132; Bennett KP, 1999, ADV NEUR IN, V11, P368; Chapelle O., 2006, SEMISUPERVISED LEARN, P1; Chapelle O, 2005, P 10 INT WORKSH ART, V2005, P57; Clarke F.H, 1990, CANADIAN MATH SOC SE, V2; COLLOBERT R, 2005, TRADING CONVEXITY SC; Cristianini N., 2000, INTRO SUPPORT VECTOR; Demiriz A, 2001, APPL OPTIM, V50, P121; Fuduli A, 2004, SIAM J OPTIMIZ, V14, P743, DOI 10.1137/S1052623402411459; Fuduli A, 2006, J OPTIMIZ THEORY APP, V130, P95, DOI 10.1007/s10957-006-9090-z; FUDULI A, 2004, OPTIMIZATION METHODS, V18, P89; Fung G, 2001, OPTIM METHOD SOFTW, V15, P29, DOI 10.1080/10556780108805809; FUNG G, 2001, P 7 ACM SIGKDD INT C, P77, DOI DOI 10.1145/502512.502527; Gill P. E., 1981, PRACTICAL OPTIMIZATI; Hiriart-Urruty Jean-Baptiste, 1993, CONVEX ANAL MINIMIZA; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; JOACHIMS T, 1999, ADV KERNAL METHODS S; Joachims T., 2003, P 20 INT C MACH LEAR, P290, DOI DOI 10.1145/2612669.2612699; KIWIEL KC, 1990, MATH PROGRAM, V46, P105, DOI 10.1007/BF01585731; KIWIEL KC, 1985, LECT NOTES MATH, V1133, P1; KIWIEL KC, 1983, MATH PROGRAM, V27, P320, DOI 10.1007/BF02591907; LEMARECHAL C, 1974, P IFIP C; Makela M. M., 1992, WORLD SCI; Mifflin R., 1977, Mathematics of Operations Research, V2, P191, DOI 10.1287/moor.2.2.191; Murphy P.M., 1992, UCI REPOSITORY MACHI; ODEWAHN SC, 1992, ASTRON J, V103, P318, DOI 10.1086/116063; Schramm H, 1992, SIAM J OPTIMIZ, V2, P121, DOI 10.1137/0802008; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Shen XT, 2003, J AM STAT ASSOC, V98, P724, DOI 10.1198/016214503000000639; Smola A.J, 1999, ADV KERNEL METHODS; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Wolfe P, 1975, MATHEMATICAL PROGRAM, V3, P145, DOI [DOI 10.1007/BFB0120703, 10.1007/BFb0120703]; Yuille Alan, 2002, ADV NEURAL INFORM PR, V14; Zhou D., 2003, ADV NEURAL INFORM PR; Zhou DY, 2004, LECT NOTES COMPUT SC, V3175, P237; ZHU X, 2004, P INT C NEUR INF PRO	39	38	43	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2007	29	12					2135	2142		10.1109/TPAMI.2007.1102	http://dx.doi.org/10.1109/TPAMI.2007.1102			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	219LY	17934223				2022-12-18	WOS:000250087900006
J	Sminchisescu, C; Kanaujia, A; Metaxas, DN				Sminchisescu, Cristian; Kanaujia, Atul; Metaxas, Dimitris N.			BM3 E: Discriminative density propagation for visual tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; statistical models; video analysis; motion; tracking	HUMAN MOTION	We introduce (BME)-E-3, a Conditional Bayesian Mixture of Experts Markov Model, that achieves consistent probabilistic estimates for discriminative visual tracking. The model applies to problems of temporal and uncertain inference and represents the unexplored bottom-up counterpart of pervasive generative models estimated with Kalman filtering or particle filtering. Instead of inverting a nonlinear generative observation model at runtime, we learn to cooperatively predict complex state distributions directly from descriptors that encode image observations ( typically, bag-of-feature global image histograms or descriptors computed over regular spatial grids). These are integrated in a conditional graphical model in order to enforce temporal smoothness constraints and allow a principled management of uncertainty. The algorithms combine sparsity, mixture modeling, and nonlinear dimensionality reduction for efficient computation in high-dimensional continuous state spaces. The combined system automatically self-initializes and recovers from failure. The research has three contributions: 1) we establish the density propagation rules for discriminative inference in continuous, temporal chain models, 2) we propose flexible supervised and unsupervised algorithms to learn feed-forward, multivalued contextual mappings (multimodal state distributions) based on compact, conditional Bayesian mixture of experts models, and 3) we validate the framework empirically for the reconstruction of 3D human motion in monocular video sequences. Our tests on both real and motion-capture-based sequences show significant performance gains with respect to competing nearest neighbor, regression, and structured prediction methods.	Univ Chicago, TTI C, Chicago, IL 60637 USA; Rutgers State Univ, Dept Comp Sci, Computat Biomed Imaging & Modeling Ctr, Piscataway, NJ 08854 USA	University of Chicago; Rutgers State University New Brunswick	Sminchisescu, C (corresponding author), Univ Chicago, TTI C, 1427 E 60th St,2nd Floor, Chicago, IL 60637 USA.	crismin@nagoya.uchicago.edu; kanaujia@cs.rutgers.edu; dnm@cs.rutgers.edu						Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21; AGARWAL A, 2005, P WORKSH VIS HUM COM; AHERNE F, 2004, ADV NEURAL INFOM PRO; Belongie S., 2002, IEEE T PATTERN ANAL, V24; BISHOP C, 2003, BAYESIAN MIXTURES EX; BLACK M, 1996, COMPUTER VISION IMAG, V6, P57; Brand M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1237, DOI 10.1109/ICCV.1999.790422; BRAY M, 2006, P 9 EUR C COMP VIS; CHOO K, 2001, P 8 IEEE INT C COMP; Cula OG, 2004, INT J COMPUT VISION, V59, P33, DOI 10.1023/B:VISI.0000020670.05764.55; DESARBO WS, 1988, J CLASSIF, V5, P249, DOI 10.1007/BF01897167; DEUTSCHER J, 2000, P IEEE INT C COMP VI; Elgammal A, 2004, P IEEE INT C COMP VI; ELGAMMAL A, 2002, P IEEE; GORDON N, 1993, IEE P P; Grauman K., 2003, P 9 IEEE INT C COMP; HOWE N, 1999, ADV NEUR INF PROC; ISARD M, 1998, INT J COMP VIS; Jaeggli T, 2006, LECT NOTES COMPUT SC, V4069, P494; JEBARA T, 2000, ADV NEURAL INFORM PR; JORDAN M, 1998, LEARNING GRAPHICAL M; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Kakadiaris IA, 1996, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.1996.517057; Lawrence N., 2003, ADV NEURAL INFORM PR; LEE M, 2004, P IEEE INT C COMP VI; LOWE D, 2004, INT J COMP VIS, V60; MACKAY D, 1909, NEURAL COMPUTATION, V11; MCCALLUM A, 2000, P INT C MACH LEARN; MORI G, 2002, P 7 EUR C COMP VIS; ROSALES R, 2002, ADV NEURAL INFORM PR; ROTH S, 2004, P IEEE INT C COMP VI; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SHAKHNAROVICH G, 2003, P 9 IEEE C COMP VIS; SIDENBLADH H, 2001, P 7 IEEE INT C COMP; SIGAL L, 2004, P IEEE INT C COMP VI; Sminchisescu C, 2005, IEEE I CONF COMP VIS, P1808; Sminchisescu C, 2005, PROC CVPR IEEE, P390; Sminchisescu C, 2004, PROC CVPR IEEE, P608; Sminchisescu C, 2003, INT J ROBOT RES, V22, P371, DOI 10.1177/0278364903022006003; Sminchisescu C, 2003, PROC CVPR IEEE, P69; Sminchisescu C., 2004, ICML; SMINCHISESCU C, 2004, CSRG401 U TOR; SMINCHISESCU C, 2005, ADV NEURAL INFORM P; SMINCHISESCU C, 2004, CSRG502; SMINCHISESCU C, 2006, CSRG543 U TOR; Sudderth E., 2003, P IEEE INT C COMP VI; TIPPING M, 2001, J MACH LEARNING RES; TOMASI C, 2003, P 9 IEEE INT C COMP; Ueda N, 2002, NEURAL NETWORKS, V15, P1223, DOI 10.1016/S0893-6080(02)00040-0; URTASUN R, 2005, P 10 IEEE INT C COMP; WATERHOUSE S, 1996, ADV NEURAL INFOM PRO; WESTON J, 2002, ADV NEURAL INFORM PR; WIPF D, 2003, ADV NEURAL INFOM PRO	53	38	39	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2007	29	11					2030	2044		10.1109/TPAMI.2007.1111	http://dx.doi.org/10.1109/TPAMI.2007.1111			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	208UE	17848782	Green Submitted			2022-12-18	WOS:000249343900012
J	Griffin, LD				Griffin, Lewis D.			The second order local-image-structure solid	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						scale space; image derivatives; feature analysis; noise; natural images	DIFFERENTIAL STRUCTURE; NATURAL IMAGES; SCALE-SPACE; STATISTICS; CONTRAST; DIVERGENCE	Characterization of second order local image structure by a 6D vector ( or jet) of Gaussian derivative measurements is considered. We consider the affect on jets of a group of transformations - affine intensity-scaling, image rotation and reflection, and their compositions - that preserve intrinsic image structure. We show how this group stratifies the jet space into a system of orbits. Considering individual orbits as points, a 3D orbifold is defined. We propose a norm on jet space which we use to induce a metric on the orbifold. The metric tensor shows that the orbifold is intrinsically curved. To allow visualization of the orbifold and numerical computation with it, we present a mildly-distorting but volume-preserving embedding of it into euclidean 3-space. We call the resulting shape, which is like a flattened lemon, the second order local-image-structure solid. As an example use of the solid, we compute the distribution of local structures in noise and natural images. For noise images, analytical results are possible and they agree with the empirical results. For natural images, an excess of locally 1D structure is found.	UCL, Dept Comp Sci, London WC1E 6BT, England	University of London; University College London	Griffin, LD (corresponding author), UCL, Dept Comp Sci, Malet Pl Engn Bldg, London WC1E 6BT, England.	L.Griffin@cs.ucl.ac.uk	Griffin, Lewis/C-2118-2008		EPSRC [EP/D030978/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [EP/D030978/1] Funding Source: researchfish	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		Abramowitz M., 1970, HDB MATH FUNCTIONS F; Bovik A, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P1; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; Doran C., 2003, GEOMETRIC ALGEBRA PH, DOI DOI 10.1017/CBO9780511807497; Field DJ, 1997, VISION RES, V37, P3367, DOI 10.1016/S0042-6989(97)00181-8; Field DJ, 1999, PHILOS T R SOC A, V357, P2527, DOI 10.1098/rsta.1999.0446; FLOR H, 1994, BIOBEHAVIORAL SELF R, V2, P171; Florack L, 1996, INT J COMPUT VISION, V18, P61, DOI 10.1007/BF00126140; FLORACK LMJ, 1992, IMAGE VISION COMPUT, V10, P376, DOI 10.1016/0262-8856(92)90024-W; Florack LMJ, 1997, IMAGE STRUCTURE; Frazor RA, 2006, VISION RES, V46, P1585, DOI 10.1016/j.visres.2005.06.038; GEMAN D, 1999, P IEEE WORKSH STAT C; Gousseau Y, 2000, P SOC PHOTO-OPT INS, V4119, P208, DOI 10.1117/12.408605; Griffin LD, 2005, NETWORK-COMP NEURAL, V16, P301, DOI 10.1080/09548980500289874; Griffin LD, 2004, VISION RES, V44, P407, DOI 10.1016/j.visres.2003.09.025; Griffin LD, 2000, P ROY SOC A-MATH PHY, V456, P2995, DOI 10.1098/rspa.2000.0650; GRIFFIN LD, 1995, IMAGE VISION COMPUT, V13, P543, DOI 10.1016/0262-8856(95)91145-4; GRIFFIN LD, 2006, INT J COMPUTER VISIO, V70; GRIFFIN LD, 2003, LECT NOTES COMPUTER; GRIFFIN LD, 1995, THESIS U LONDON; GRIFFIN LD, 1994, P BRIT MACH VIS C SH, P135; IIJIMA T, 1971, SYSTEMS COMPUTERS CO, V2, P96; KERCKHOVE M, 2001, LECT NOTES COMPUTER; KIMMEL R, 2006, LECT NOTES COMPUTER; KOENDERINK JJ, 1988, J OPT SOC AM A, V5, P1136, DOI 10.1364/JOSAA.5.001136; KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F; Koenderink JJ, 2002, LECT NOTES COMPUT SC, V2350, P158; Koenderink JJ, 2003, IEICE T INF SYST, VE86D, P1165; Koenderink JJ, 1998, ADV IMAG ELECT PHYS, V103, P65, DOI 10.1016/S1076-5670(08)70015-6; KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371; KRETZMER ER, 1952, AT&T TECH J, V31, P751, DOI 10.1002/j.1538-7305.1952.tb01404.x; Lee AB, 2003, INT J COMPUT VISION, V54, P83, DOI 10.1023/A:1023705401078; Lillholm M, 2004, INT C PATT RECOG, P787, DOI 10.1109/ICPR.2004.1334376; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; Lindeberg T., 1994, SCALE SPACE THEORY C; LONGUETHIGGINS MS, 1957, PHILOS TR R SOC S-A, V249, P321, DOI 10.1098/rsta.1957.0002; Misner C. W., 1973, GRAVITATION; NIELSEN M, 1999, LECT NOTES COMPUTER; PEDERSEN K, 2003, THESIS U COPENHAGEN; PEDERSEN KS, 2003, P 4 SCAL SPAC C, P281; PEDERSEN KS, 2002, P 7 EUR C COMP VIS, P328; Pinoli JC, 1997, J MATH IMAGING VIS, V7, P341, DOI 10.1023/A:1008259212169; Ringach DL, 2002, J NEUROPHYSIOL, V88, P455, DOI 10.1152/jn.2002.88.1.455; Romeny B. t. H., 2003, FRONT END VISION MUL; ROMENY BMT, 1994, IMAGE VISION COMPUT, V12, P317, DOI 10.1016/0262-8856(94)90056-6; ROMENY BT, 1997, LNCS, V1252; Ruderman DL, 1997, VISION RES, V37, P3385, DOI 10.1016/S0042-6989(97)00008-4; Tagliati E, 2001, LECT NOTES COMPUT SC, V2106, P51; Thurston W. P., 2002, GEOMETRY TOPOLOGY 3; ULICHNEY RA, 1988, P IEEE, V76, P56, DOI 10.1109/5.3288; Ulichney Robert, 1987, DIGITAL HALFTONING, P5; Van de Weijer J, 2005, INT J COMPUT VISION, V64, P143, DOI 10.1007/s11263-005-1840-0; van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P359, DOI 10.1098/rspb.1998.0303; Victor JD, 2003, PERSPECTIVES AND PROBLEMS IN NONLINEAR SCIENCE, P375; Wolfram S, 1999, MATH BOOK	57	38	39	2	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2007	29	8					1355	1366		10.1109/TPAMI.2007.1066	http://dx.doi.org/10.1109/TPAMI.2007.1066			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	177XT	17568140	Green Submitted			2022-12-18	WOS:000247186500005
J	Briassouli, A; Ahuja, N				Briassouli, Alexia; Ahuja, Narendra			Extraction and analysis of multiple periodic motions in video sequences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						periodic motion analysis; time-frequency distributions; short term Fourier transform	SEGMENTATION; RECOGNITION	The analysis of periodic or repetitive motions is useful in many applications, such as the recognition and classification of human and animal activities. Existing methods for the analysis of periodic motions first extract motion trajectories using spatial information and then determine if they are periodic. These approaches are mostly based on feature matching or spatial correlation, which are often infeasible, unreliable, or computationally demanding. In this paper, we present a new approach, based on the time-frequency analysis of the video sequence as a whole. Multiple periodic trajectories are extracted and their periods are estimated simultaneously. The objects that are moving in a periodic manner are extracted using the spatial domain information. Experiments with synthetic and real sequences display the capabilities of this approach.	Dept Comp & Commun Engn, Volos 38221, Magnisia, Greece; Univ Illinois, Beckman Inst Adv Sci & Technol, Urbana, IL 61801 USA	University of Illinois System; University of Illinois Urbana-Champaign	Briassouli, A (corresponding author), Dept Comp & Commun Engn, 37 Glavanh 37 & 28th October St, Volos 38221, Magnisia, Greece.	briassou@uth.gr; ahuja@vision.ai.uiuc.edu		Briassouli, Alexia/0000-0002-0545-3215				BARAK B, 2002, P IEEE INT C AC SPEE, V2, P1425; Barron J. L., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P236, DOI 10.1109/CVPR.1992.223269; BLAHUT RE, 1984, FAST ALGORITHMS DIGI; Brand M, 2000, IEEE T PATTERN ANAL, V22, P844, DOI 10.1109/34.868685; Briassouli A, 2004, INT C PATT RECOG, P175, DOI 10.1109/ICPR.2004.1334089; BROX T, 2004, P 8 EUR C COMP VIS, V4, P25; Chen WG, 1998, IEEE T IMAGE PROCESS, V7, P1242, DOI 10.1109/83.709656; COHEN L, 1989, P IEEE, V77, P941, DOI 10.1109/5.30749; Cremers D, 2005, INT J COMPUT VISION, V62, P249, DOI 10.1007/s11263-005-4882-4; Cremers D, 2004, LECT NOTES COMPUT SC, V3175, P36; Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681; Czerwinski RN, 1997, IEEE SIGNAL PROC LET, V4, P42, DOI 10.1109/97.554468; DJUROVIC I, 1999, IEEE T SIGNAL PROCES, V47, P493; DOMINGO J, 1997, P IEEE INT C AC SPEE, V4, P3021; DUHAMEL P, 1990, SIGNAL PROCESS, V19, P259, DOI 10.1016/0165-1684(90)90158-U; Elgammal A., 2000, COMPUTER VISION ECCV, P751, DOI [10.1007/3-540-45053-X_48, DOI 10.1007/3-540-45053-X_48]; HARRIS FJ, 1978, P IEEE, V66, P51, DOI 10.1109/PROC.1978.10837; HIRANI AN, 1996, P SIGGRAPH 96, P269; Hoge WS, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P707; Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686; JONES DL, 1992, IEEE T SIGNAL PROCES, V40, P413, DOI 10.1109/78.124951; Kay S.M, 1988, MODERN SPECTRAL ESTI; KOOTSOOKOS PJ, 1992, IEEE T SIGNAL PROCES, V40, P1971, DOI 10.1109/78.149998; Kornprobst P, 1997, PROC CVPR IEEE, P325, DOI 10.1109/CVPR.1997.609344; Liu F, 1996, IEEE T PATTERN ANAL, V18, P722, DOI 10.1109/34.506794; Lu CM, 2004, IEEE T PATTERN ANAL, V26, P258, DOI 10.1109/TPAMI.2004.1262196; Milanfar P, 1999, IEEE T IMAGE PROCESS, V8, P438, DOI 10.1109/83.748900; PAPOULIS A, 1987, PROBABILITY RANDOM V; Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815; PLESS R, 2003, P IEEE CS C COMP VIS, P1063; Polana R, 1997, INT J COMPUT VISION, V23, P261, DOI 10.1023/A:1007975200487; Sayeed AM, 1996, IEEE T SIGNAL PROCES, V44, P3031, DOI 10.1109/78.553477; SAYEED AM, 1995, IEEE T SIGNAL PROCES, V43, P478, DOI 10.1109/78.348130; SAYEED AM, 1999, IEEE T SIGNAL PROCES, V47, P493; Seitz SM, 1997, INT J COMPUT VISION, V25, P231, DOI 10.1023/A:1007928103394; Stankovic S, 2001, ELECTRON LETT, V37, P1446, DOI 10.1049/el:20010970; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; TSAI PS, 1994, PATTERN RECOGN, V27, P1591, DOI 10.1016/0031-3203(94)90079-5; Walker J.S., 1996, FAST FOURIER TRANSFO; Wang L, 2003, IEEE T IMAGE PROCESS, V12, P1120, DOI 10.1109/TIP.2003.815251; Young RW, 1993, IEEE T IMAGE PROCESS, V2, P2, DOI 10.1109/83.210861; Yu WC, 2003, COMPUT VIS IMAGE UND, V90, P129, DOI 10.1016/S1077-3142(03)00011-0	42	38	40	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2007	29	7					1244	1261		10.1109/TPAMI.2007.1042	http://dx.doi.org/10.1109/TPAMI.2007.1042			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	166QW	17496381				2022-12-18	WOS:000246395300011
J	Biem, A				Biem, A			Minimum classification error training for online handwriting recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						minimum classification error; hidden Markov model; handwriting recognition; maximum likelihood; discriminative training; dynamic programming; finite state machine		This paper describes an application of the Minimum Classification Error (MCE) criterion to the problem of recognizing online unconstrained-style characters and words. We describe an HMM-based, character and word-level MCE training aimed at minimizing the character or word error rate while enabling flexibility in writing style through the use of multiple allographs per character. Experiments on a writer-independent character recognition task covering alpha-numerical characters and keyboard symbols show that the MCE criterion achieves more than 30 percent character error rate reduction compared to the baseline Maximum Likelihood-based system. Word recognition results, on vocabularies of 5k to 10k, show that MCE training achieves around 17 percent word error rate reduction when compared to the baseline Maximum Likelihood system.	IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA	International Business Machines (IBM)	Biem, A (corresponding author), IBM Corp, TJ Watson Res Ctr, POB 218, Yorktown Hts, NY 10598 USA.	biem@us.ibm.com						ANDQUETIL E, 1996, P INF PROC MAN UNC K, P259; Biem A, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P868; Biem A, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P61, DOI 10.1109/IWFHR.2002.1030885; Biem A, 1997, IEEE T SIGNAL PROCES, V45, P500, DOI 10.1109/78.554319; Biem A, 2001, IEEE T SPEECH AUDI P, V9, P96, DOI 10.1109/89.902277; BIEM A, 1993, P IEEE INT C AC SPEE, V2, P275; BIEM A, 1997, THESIS U PARIS 6; Biem AE, 2001, INT CONF ACOUST SPEE, P1529, DOI 10.1109/ICASSP.2001.941223; BISHIP CM, 1995, NEURAL NETWORK PATTE; Brakensiek A., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P486, DOI 10.1109/ICDAR.2001.953837; Chen W.-T., 2000, P 7 INT WORKSH FRONT, P393; Chengalvarayan R, 1997, IEEE T SPEECH AUDI P, V5, P243, DOI 10.1109/89.568731; CHOU W, 1992, P INT C AC SPEECH SI, V1, P473; Connell SD, 2002, IEEE T PATTERN ANAL, V24, P329, DOI 10.1109/34.990135; delaTorre A, 1996, SPEECH COMMUN, V20, P273, DOI 10.1016/S0167-6393(96)00061-1; Duda R.O., 1973, J ROYAL STAT SOC SER; Fahlman Scott E, 1988, EMPIRICAL STUDY LEAR; HUO Q, 2001, P IEEE INT C AC SPEE, V3; JELINEK F, 1999, STAT METHODS SPEECH; JUANG BH, 1990, IEEE T ACOUST SPEECH, V38, P1639, DOI 10.1109/29.60082; JUANG BH, 1992, IEEE T SIGNAL PROCES, V40, P3043, DOI 10.1109/78.175747; Katagiri S, 1998, P IEEE, V86, P2345, DOI 10.1109/5.726793; KATAGIRI S, 1991, P IEEE WORKSH NEUR N, P309; KOMORI T, 1995, P AC SOC JAP JUN, V16, P147; Liu CL, 2001, PATTERN RECOGN, V34, P601, DOI 10.1016/S0031-3203(00)00018-2; LIU CS, 1995, J ACOUST SOC AM, V97, P637, DOI 10.1121/1.412286; Matic N., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P187, DOI 10.1109/ICDAR.1993.395752; Matsushita T., 1995, Proceedings of 1994 Topical International Cryogenic Materials Conference, Cryogenic Materials Conference, P81; MCDERMOTT E, 1994, COMPUT SPEECH LANG, V8, P351, DOI 10.1006/csla.1994.1018; MCDERMOTT E, 2005, P IEEE INT C AC SPEE, V1, P113; MCDERMOTT E, THESIS WASEDA U; MCDERMOTT E, 2003, P IEEE INT C AC SPEE, V2, P713; NADAS A, 1983, IEEE T ACOUST SPEECH, V31, P814, DOI 10.1109/TASSP.1983.1164173; NATHAN KS, 1995, P IEEE INT C AC SPEE; Ney H, 2000, P IEEE, V88, P1224, DOI 10.1109/5.880081; Nilsson N., 1982, PRINCIPLES ARTIFICIA; Nopsuwanchai R, 2003, INT CONF ACOUST SPEE, P817; NOPSUWANCHAI R, 2004, P IEEE INT C AC SPEE, V5, P845; Normandin Y., 1991, THESIS MCGILL U MONT; Oudot L, 2004, INT C PATT RECOG, P598; PARIZEAU M, 1995, IEEE T PATTERN ANAL, V17, P702, DOI 10.1109/34.391412; Perrone M. P., 2000, P 7 INT WORKSH FRONT, P229; Prevost L, 1998, INT C PATT RECOG, P381, DOI 10.1109/ICPR.1998.711160; Schluter R, 2001, IEEE SIGNAL PROC LET, V8, P131, DOI 10.1109/97.917693; SOONG FK, 1991, INT CONF ACOUST SPEE, P705, DOI 10.1109/ICASSP.1991.150437; SUBRAHMONIA J, 1996, P ICASSP 96 ATL GEOR, V6, P3478; TYPING ME, 2000, ADV NEURAL INFORMATI, V12; UORI V, 1999, P INT C DOC AN REC, P792; Vapnik V.N, 1998, STAT LEARNING THEORY	49	38	41	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2006	28	7					1041	1051		10.1109/TPAMI.2006.146	http://dx.doi.org/10.1109/TPAMI.2006.146			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	041AG	16792094				2022-12-18	WOS:000237424400002
J	Sakakibara, Y				Sakakibara, Y			Grammatical inference in bioinformatics	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						grammatical inference; bioinformatics; molecular biology; hidden Markov model; stochastic context-free grammar	HIDDEN MARKOV-MODELS; CONTEXT-FREE GRAMMARS; RNA; COMPLEXITY; ALIGNMENT; LANGUAGE	Bioinformatics is an active research area aimed at developing intelligent systems for analyses of molecular biology. Many methods based on formal language theory, statistical theory, and learning theory have been developed for modeling and analyzing biological sequences such as DNA, RNA, and proteins. Especially, grammatical inference methods are expected to find some grammatical structures hidden in biological sequences. In this article, we give an overview of a series of our grammatical approaches to biological sequence analyses and related researches and focus on learning stochastic grammars from biological sequences and predicting their functions based on learned stochastic grammars.	Keio Univ, Dept Biosci & Informat, Kohoku Ku, Yokohama, Kanagawa 2238522, Japan	Keio University	Sakakibara, Y (corresponding author), Keio Univ, Dept Biosci & Informat, Kohoku Ku, 3-14-1 Hiyoshi, Yokohama, Kanagawa 2238522, Japan.	yasu@bio.keio.ac.jp	Sakakibara, Yasubumi/D-9008-2014					ABE N, 1992, MACH LEARN, V9, P205, DOI 10.1007/BF00992677; Abe N, 1999, MACHINE LEARNING, PROCEEDINGS, P3; Aho A.V., 1972, THEORY PARSING TRANS; ANGLUIN D, 1982, J ACM, V29, P741, DOI 10.1145/322326.322334; BAKER JK, 1979, SPEECH COMM PAP 97 M, P547; Cai LM, 2003, BIOINFORMATICS, V19, pi66, DOI 10.1093/bioinformatics/btg1007; DUPONT P, 1994, P 2 INT C GRAMM INF, P26; Durbin R., 1998, BIOL SEQUENCE ANAL P; Eddy SR, 1998, BIOINFORMATICS, V14, P755, DOI 10.1093/bioinformatics/14.9.755; EDDY SR, 1994, NUCLEIC ACIDS RES, V22, P2079, DOI 10.1093/nar/22.11.2079; Holmes I, 2002, Pac Symp Biocomput, P163; Hopcroft John E., 1979, INTRO AUTOMATA THEOR; JIANG T, 1995, THEOR COMPUT SCI, V143, P137, DOI 10.1016/0304-3975(95)80015-8; KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104; Lari K., 1990, Computer Speech and Language, V4, P35, DOI 10.1016/0885-2308(90)90022-X; MATSUI H, 2004, P IEEE CS BIOINF C C; Muggleton SH, 2001, J COMPUT BIOL, V8, P493, DOI 10.1089/106652701753216512; Pachter L, 2002, J COMPUT BIOL, V9, P389, DOI 10.1089/10665270252935520; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rivas E, 2000, BIOINFORMATICS, V16, P334, DOI 10.1093/bioinformatics/16.4.334; Rivas E, 2001, BMC BIOINFORMATICS, V2, DOI 10.1186/1471-2105-2-8; Sakakibara Y, 1997, THEOR COMPUT SCI, V185, P15, DOI 10.1016/S0304-3975(97)00014-5; SAKAKIBARA Y, 1992, INFORM COMPUT, V97, P23, DOI 10.1016/0890-5401(92)90003-X; Sakakibara Y, 1999, MACHINE LEARNING, PROCEEDINGS, P354; SAKAKIBARA Y, 1994, NUCLEIC ACIDS RES, V22, P5112, DOI 10.1093/nar/22.23.5112; SAKAKIBARA Y, IN PRESS PATTERN REC; Sakakibara Y, 2003, BIOINFORMATICS, V19, pi232, DOI 10.1093/bioinformatics/btg1032; Searls D B, 1995, Proc Int Conf Intell Syst Mol Biol, V3, P341; Searls DB, 2002, NATURE, V420, P211, DOI 10.1038/nature01255; STEINBERG S, 1993, NUCLEIC ACIDS RES, V21, P3011, DOI 10.1093/nar/21.13.3011; Stolcke Andreas, 1994, P 2 INT C GRAMM INF, P106; THOMPSON JD, 1994, NUCLEIC ACIDS RES, V22, P4673, DOI 10.1093/nar/22.22.4673; Uemura K, 2003, ONCOL REP, V10, P277; [No title captured]	35	38	40	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2005	27	7					1051	1062		10.1109/TPAMI.2005.140	http://dx.doi.org/10.1109/TPAMI.2005.140			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	925AQ	16013753				2022-12-18	WOS:000229024300005
J	Keller, Y; Shkolnisky, Y; Averbuch, A				Keller, Y; Shkolnisky, Y; Averbuch, A			The angular difference function and its application to image registration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						global motion estimation; Fourier domain; pseudopolar FFT; image alignment	MOTION ESTIMATION; EFFICIENT; ROBUST; TRANSFORM	The estimation of large motions without prior knowledge is an important problem in image registration. In this paper, we present the angular difference function (ADF) and demonstrate its applicability to rotation estimation. The ADF of two functions is defined as the integral of their spectral difference along the radial direction. It is efficiently computed using the pseudopolar Fourier transform, which computes the discrete Fourier transform of an image on a near spherical grid. Unlike other Fourier-based registration schemes, the suggested approach does not require any interpolation. Thus, it is more accurate and significantly faster.	Yale Univ, Dept Math, New Haven, CT 06520 USA; Tel Aviv Univ, Sch Math Sci, Dept Comp Sci, IL-69978 Tel Aviv, Israel	Yale University; Tel Aviv University	Keller, Y (corresponding author), Yale Univ, Dept Math, POB 208283, New Haven, CT 06520 USA.	yosi.keller@yale.edu; yoel@math.tau.ac.il; amir@math.tau.ac.il						AVERBUCH A, IN PRESS SIAM SCI CO; BAILEY DH, 1991, SIAM REV, V33, P389, DOI 10.1137/1033097; CHEN QS, 1994, IEEE T PATTERN ANAL, V16, P1156; Chou YM, 1997, J VIS COMMUN IMAGE R, V8, P83, DOI 10.1006/jvci.1997.0343; Derrode S, 2004, SIGNAL PROCESS, V84, P25, DOI 10.1016/j.sigpro.2003.07.006; Derrode S, 2001, COMPUT VIS IMAGE UND, V83, P57, DOI 10.1006/cviu.2001.0922; Dufaux F, 2000, IEEE T IMAGE PROCESS, V9, P497, DOI 10.1109/83.826785; FLEET DJ, 1994, 1994 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS - HUMANS, INFORMATION AND TECHNOLOGY, VOLS 1-3, P48, DOI 10.1109/ICSMC.1994.399810; Foroosh H, 2002, IEEE T IMAGE PROCESS, V11, P188, DOI 10.1109/83.988953; GONZALEZ RC, 1992, DIGITAL IMAGE PROCES, pCH9; Irani M, 1996, SIGNAL PROCESS-IMAGE, V8, P327, DOI 10.1016/0923-5965(95)00055-0; Kuglin C. D., 1975, Proceedings of the 1975 International Conference on Cybernetics and Society, P163; Lucchese L, 2000, IEEE T SIGNAL PROCES, V48, P1769, DOI 10.1109/78.845934; LUCCHESE L, 2002, P INT C IM PROC ICIP, V2, P793; MANN S, 1994, IEEE IMAGE PROC, P363, DOI 10.1109/ICIP.1994.413336; Milanfar P, 1999, IEEE T IMAGE PROCESS, V8, P438, DOI 10.1109/83.748900; Milanfar P, 1996, J OPT SOC AM A, V13, P2151, DOI 10.1364/JOSAA.13.002151; Porat B., 1997, COURSE DIGITAL SIGNA; RABINER LR, 1969, IEEE T AUDIO ELECTRO, VAU, P86; Reddy BS, 1996, IEEE T IMAGE PROCESS, V5, P1266, DOI 10.1109/83.506761; Stone HS, 2001, IEEE T GEOSCI REMOTE, V39, P2235, DOI 10.1109/36.957286; Szeliski R., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P44, DOI 10.1109/ACV.1994.341287; Tekalp AM, 1995, DIGITAL VIDEO PROCES; Wolberg G, 2000, IEEE IMAGE PROC, P493, DOI 10.1109/ICIP.2000.901003	25	38	42	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2005	27	6					969	976		10.1109/TPAMI.2005.128	http://dx.doi.org/10.1109/TPAMI.2005.128			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	915TR	15943427				2022-12-18	WOS:000228334700011
J	Kenney, CS; Manjunath, BS; Zuliani, M; Hewer, GA; Van Nevel, A				Kenney, CS; Manjunath, BS; Zuliani, M; Hewer, GA; Van Nevel, A			A condition number for point matching with application to registration and postregistration error estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						registration; conditioning; feature representation; motion	SENSITIVITY	Selecting salient points from two or more images for computing correspondence is a well-studied problem in image analysis. This paper describes a new and effective technique for selecting these tiepoints using condition numbers, with application to image registration and mosaicking. Condition numbers are derived for point-matching methods based on minimizing windowed objective functions for 1) translation, 2) rotation-scaling-translation (RST), and 3) affine transformations. Our principal result is that the condition numbers satisfy K-Trans less than or equal to K-RST less than or equal to K-Affine. That is, if a point is ill-conditioned with respect to point-matching via translation, then it is also unsuited for matching with respect to RST and affine transforms. This is fortunate since K-Trans is easily computed whereas K-RST and K-Affine are not. The second half of the paper applies the condition estimation results to the problem of identifying tiepoints in pairs of images for the purpose of registration. Once these points have been matched (after culling outliers using a RANSAC-like procedure), the registration parameters are computed. The postregistration error between the reference image and the stabilized image is then estimated by evaluating the translation between these images at points exhibiting good conditioning with respect to translation. The proposed method of tiepoint selection and matching using condition number provides a reliable basis for registration. The method has been tested on a large number of diverse collection of images-multidate Landsat images, aerial images, aerial videos, and infrared images. A Web site where the users can try our registration software is available and is being actively used by researchers around the world.	Univ Calif Santa Barbara, Dept Elect & Comp, Santa Barbara, CA 93106 USA; USN, Res Dept, Warfare Ctr, Weapons Div, China Lake, CA 93555 USA	University of California System; University of California Santa Barbara; United States Department of Defense; United States Navy; US Navy Naval Air Systems Command	Kenney, CS (corresponding author), Univ Calif Santa Barbara, Dept Elect & Comp, Santa Barbara, CA 93106 USA.	kenney@ece.ucsb.edu; manj@ece.ucsb.edu; zuliani@ece.ucsb.edu; hewerga@navair.navy.mil; vannevelaj@navair.navy.mil	Manjunath, B S/AAM-8190-2020	Manjunath, B S/0000-0003-2804-3611				ATKINSON K. E, 1989, INTRO NUMERICAL ANAL; BAIRD HS, 1985, MODEL BASED IMAGE MA; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141; BENEZRA M, 1988, P DARPA IM UND WORKS, P207; BERGEN JR, 1992, P EUR C COMP VIS, P237; BJORCK A, 1983, LINEAR ALGEBRA APPL, V52-3, P127, DOI 10.1016/0024-3795(83)90010-1; Brooks MJ, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P302, DOI 10.1109/ICCV.2001.937533; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; CLINE AK, 1979, SIAM J NUMER ANAL, V16, P368, DOI 10.1137/0716029; Demmel J, 2001, FOUND COMPUT MATH, V1, P101, DOI 10.1007/s102080010004; DEMMEL J, 1988, MATH COMPUTATION, V50; DEMMEL JW, 1987, NUMER MATH, V51, P251, DOI 10.1007/BF01400115; EFRON B, 1994, SIAM CBMS NSF REGION; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fonseca L, 1999, P SOC PHOTO-OPT INS, V3717, P104, DOI 10.1117/12.353029; Fonseca L. M. G., 1999, XII Brazilian Symposium on Computer Graphics and Image Processing (Cat. No.PR00481), P125, DOI 10.1109/SIBGRA.1999.805717; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Haralick R.M., 1993, COMPUTER ROBOT VISIO, V2; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HEWER G, 1988, SIAM J CONTROL OPTIM, V26, P321, DOI 10.1137/0326018; HEWER G, 1995, P SPIE C JUL; HEWER G, 1994, P SPIE C, V2242, P561; HEWER G, 2002, CONDITION THEORY IMA; HILDRETH EC, 1984, ARTIF INTELL, V23, P309, DOI 10.1016/0004-3702(84)90018-3; HINRICHSEN D, 1986, SYST CONTROL LETT, V7, P1, DOI 10.1016/0167-6911(86)90094-0; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Horn R.A., 2013, TOPICS MATRIX ANAL, DOI DOI 10.1017/CBO9780511840371; IRANI M, 1994, INT J COMPUT VISION, V12, P5, DOI 10.1007/BF01420982; Irani M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P959, DOI 10.1109/ICCV.1998.710832; Kanazawa Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P301, DOI 10.1109/ICCV.2001.937640; KENNEY C, 1989, SIAM J MATRIX ANAL A, V10, P191, DOI 10.1137/0610014; KENNEY C, 1990, SIAM J CONTROL OPTIM, V28, P50, DOI 10.1137/0328003; KENNEY CS, 1994, SIAM J SCI COMPUT, V15, P36, DOI 10.1137/0915003; LI H, 1995, IEEE T IMAGE PROCESS, V4, P320, DOI 10.1109/83.366480; Lucas Bruce D, 1981, P 7 INT JOINT C ART, DOI DOI 10.1042/CS0730285; Luenberger D.G, 2016, LINEAR NONLINEAR PRO, DOI 10.1007/978-3-319-18842-3; MOLER C, 1978, SIAM REV, V20, P801, DOI 10.1137/1020098; Rice JR., 1966, SIAM J NUMER ANAL, V3, P287, DOI DOI 10.1137/0703023; Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; STEWART GW, 1973, SIAM REV, V15, P727, DOI 10.1137/1015095; SUNDARESWARAN V, 1992, MULTISCALE OPTICAL F; TANNER J, 1989, ANALOG VLSI NEURAL S, P229; Tommasini T, 1998, PROC CVPR IEEE, P178, DOI 10.1109/CVPR.1998.698606; Trucco E., 1998, INTRO TECHNIQUES 3D; Van C. Loan, 1984, CONT MATH, V47, P465, DOI [10.1090/conm/047/828319, DOI 10.1090/CONM/047/828319]; Vemuri B C, 1998, Med Image Anal, V2, P79, DOI 10.1016/S1361-8415(01)80029-3; WARD RC, 1977, SIAM J NUMER ANAL, V14, P600, DOI 10.1137/0714039; Wildes RP, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P343, DOI 10.1109/ICCV.2001.937646; WILKINSON JH, 1961, J ACM, V8, P281, DOI 10.1145/321075.321076; Wilkinson JH., 1965, ALGEBRAIC EIGENVALUE; Zheng Q, 1993, IEEE T IMAGE PROCESS, V2, P311, DOI 10.1109/83.236535	56	38	43	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2003	25	11					1437	1454		10.1109/TPAMI.2003.1240118	http://dx.doi.org/10.1109/TPAMI.2003.1240118			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	733NG					2022-12-18	WOS:000186006800009
J	Tagare, HD; Toyama, K; Wang, JG				Tagare, HD; Toyama, K; Wang, JG			A maximum-likelihood strategy for directing attention during visual search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						attention; object recognition; visual search	PARTS	A precise analysis of an entire image is computationally wasteful if one is interested in finding a target object located in a subregion of the image. A useful "attention strategy" can reduce the overall computation by carrying out fast but approximate image measurements and using their results to suggest a promising subregion. This paper proposes a maximum-likelihood attention mechanism that does this. The attention mechanism recognizes that objects are made of parts and that parts have different features. It works by proposing object part and image feature pairings which have the highest likelihood of coming from the target. The exact calculation of the likelihood as well as approximations are provided. The attention mechanism is adaptive. that is, its behavior adapts to the statistics of the image features. Experimental results suggest that, on average, the attention mechanism evaluates less than 2 percent of all part-feature pairs before selecting the actual object, showing a significant reduction in the complexity of visual search.	Yale Univ, Dept Elect Engn, Dept Diagnost Radiol, New Haven, CT 06520 USA; Microsoft Corp, Res, Redmond, WA 98052 USA; Credit Suisse First Boston, New York, NY 10010 USA	Yale University; Microsoft	Tagare, HD (corresponding author), Yale Univ, Dept Elect Engn, Dept Diagnost Radiol, New Haven, CT 06520 USA.	hemant.tagare@yale.edu; kentoy@microsoft.com; jonathan.wang@csfb.com		Toyama, Kentaro/0000-0002-9128-2255				[Anonymous], 1992, SELECTIVE ATTENTION; AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; CLARK JJ, 1988, P 2 INT C COMP VIS; CULHANE SM, 1992, P 2 EUR C COMP VIS, P512; DUNCAN J, 1989, PSYCHOL REV, V96, P433, DOI 10.1037/0033-295X.96.3.433; Ennesser F., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P711, DOI 10.1109/CVPR.1993.341016; Grimson W. E. L., 1990, OBJECT RECOGNITION C; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; Haight FA, 1967, HDB POISSON DISTRIBU; HUMPHREYS GW, 1993, COGNITIVE PSYCHOL, V25, P43, DOI 10.1006/cogp.1993.1002; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; LINDEBERG T, 1993, INT J COMPUTER VISIO, V11; MEDIONI G, 1993, COMPUTER VISION PATT; NEISSER U, 1968, SCI AM, V219, P204, DOI 10.1038/scientificamerican0968-204; PAHLAVAN K, 1992, CVGIP IMAGE UNDERSTA, V56; RIMEY RD, 1992, P EUR C COMP VIS; SYEDAMAHMOOD T, 1993, P 4 BRIT MACH VIS C, P65; SYEDAMAHMOOD TF, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P881, DOI 10.1109/CVPR.1994.323918; TAGARE HD, 1996, 9603 YAL U; Toyama K, 1996, PROC CVPR IEEE, P189, DOI 10.1109/CVPR.1996.517073; TREISMAN A, 1986, SCI AM; TSOTSOS JK, 1990, BEHAV BRAIN SCI, V13, P423, DOI 10.1017/S0140525X00079577; TSOTSOS JK, IN PRESS ARTIFICIAL; TURNEY JL, 1985, IEEE T PATTERN ANAL, V7, P410, DOI 10.1109/TPAMI.1985.4767680; WAI WYK, 1994, P IEEE WORKSH VIS BE; WIXSON LE, 1994, INTL L COMPUTER VISI, V12; WOLFE JM, 1989, J EXPT PSYCHOL HUMAN, V15; [No title captured]	28	38	39	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2001	23	5					490	500		10.1109/34.922707	http://dx.doi.org/10.1109/34.922707			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431QA					2022-12-18	WOS:000168641000005
J	Garcia, JA; Fdez-Valdivia, J; Fdez-Vidal, XR; Rodriguez-Sanchez, R				Garcia, JA; Fdez-Valdivia, J; Fdez-Vidal, XR; Rodriguez-Sanchez, R			Information theoretic measure for visual target distinctness	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						visual target distinctness; information theoretic measures. information conservation constraint; significance conservation constraint; psychophysical experiments; bootstrap methods	OBJECT DETECTION; SEARCH; PERFORMANCE; FEATURES; MODELS	It is of great benefit to have advance knowledge of human visual target acquisition performance for targets or other relevant objects. However, search performance inherently shows a large variance and depends strongly on prior knowledge of the perceived scene. A typical search experiment therefore requires a large number of observers to obtain statistically reliable data. Moreover, measuring target acquisition performance in field situations is usually impractical and often very costly or even dangerous. This paper presents a new method for characterizing information of a target relative to its background. The resultant computational measures are then applied to quantify the visual distinctness of targets in complex natural backgrounds from digital imagery. A generalization of the Kullback-Leibler joint information gain of various random variables is shown to correlate strongly with visual target distinctness as estimated by human observers. Bootstrap methods for assessing statistical accuracy were used to produce this inference.	Univ Granada, ETS Ingn Informat, Dept Ciencias Computac & IA, E-18071 Granada, Spain; Univ Santiago Compostela, Fac Fis, Dept Fis Aplicada, Santiago De Compostela 15706, Spain	University of Granada; University of Sevilla; Universidade de Santiago de Compostela	Garcia, JA (corresponding author), Univ Granada, ETS Ingn Informat, Dept Ciencias Computac & IA, E-18071 Granada, Spain.	jags@decsai.ugr.es; jfv@decsai.ugr.es; faxose@usc.es; rosa@decsai.ugr.es	Fdez-Vidal, Xose R./L-5740-2014; Fdez-Valdivia, J/B-1844-2012; Sanchez, Rosa Maria Rodriguez/B-1847-2012; Garcia, Jose A./C-1703-2010	Fdez-Vidal, Xose R./0000-0001-9388-7461; Fdez-Valdivia, J/0000-0001-7181-1554; Sanchez, Rosa Maria Rodriguez/0000-0001-7886-9329; Garcia, Jose A./0000-0001-7742-7270				ACZEL J, 1975, MEASURES INFORMATION; AHUMADA AJ, 1995, INVEST OPHTH VIS SCI, V36, pS439; BURBEA J, 1982, IEEE T INFORM THEORY, V28, P489, DOI 10.1109/TIT.1982.1056497; DOLL TJ, 1993, P SOC PHOTO-OPT INS, V1967, P432, DOI 10.1117/12.151064; Efron B., 1994, MONOGR STAT APPL PRO, DOI DOI 10.1007/978-1-4899-4541-9; Fdez-Valdivia J, 1998, IEEE T PATTERN ANAL, V20, P458, DOI 10.1109/34.682176; Fdez-Vidal XR, 2000, OPT ENG, V39, P415, DOI 10.1117/1.602380; Fdez-Vidal XR, 1998, PATTERN RECOGN LETT, V19, P77, DOI 10.1016/S0167-8655(97)00150-5; Fdez-Vidal XR, 1997, PATTERN RECOGN LETT, V18, P733, DOI 10.1016/S0167-8655(97)00053-6; Fdez-Vidal XR, 2000, OPT ENG, V39, P267, DOI 10.1117/1.602360; Fisher RA, 1935, J R STAT SOC, V98, P39, DOI 10.2307/2342435; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; GARCIA JA, 2001, COMPUTATIONAL MODELS; GARCIA JA, 1999, P NATO SCI 12 WORKSH; GERHART G, 1995, P SOC PHOTO-OPT INS, V6, P12; Havrda J., 1967, KYBERNETIKA, V3, P30; HECKER R, 1992, P SOC PHOTO-OPT INS, V1687, P342, DOI 10.1117/12.137861; JEFFREYS H, 1946, PROC R SOC LON SER-A, V186, P453, DOI 10.1098/rspa.1946.0056; KAPUR JN, 1984, ADV MANAGEMENT STUDI, V3, P1; KRENDEL ES, 1960, J OPT SOC AM, V50, P562, DOI 10.1364/JOSA.50.000562; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; KULLBACK S, 1978, INFORMATION THEORY S; Martinez-Baena J, 1998, PATTERN RECOGN, V31, P1099, DOI 10.1016/S0031-3203(97)00128-3; Martinez-Baena J, 1998, OPT ENG, V37, P1995, DOI 10.1117/1.602030; MORRONE MC, 1988, PROC R SOC SER B-BIO, V235, P221, DOI 10.1098/rspb.1988.0073; MORRONE MC, 1987, PATTERN RECOGN LETT, V6, P303, DOI 10.1016/0167-8655(87)90013-4; Pashler HE, 1998, ATTENTION; RAO CR, 1982, THEOR POPUL BIOL, V21, P24, DOI 10.1016/0040-5809(82)90004-1; Renyi A., 1961, P 4 BERKELEY S MATH, V1; Rodriguez-Sanchez R, 1999, IEEE T PATTERN ANAL, V21, P1044, DOI 10.1109/34.799910; Rohaly AM, 1997, VISION RES, V37, P3225, DOI 10.1016/S0042-6989(97)00156-9; ROTMAN SR, 1989, OPT ENG, V28, P1216; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; Sharma B. D., 1977, J COMB INF SYST SCI, V2, P122; SHORE JE, 1980, IEEE T INFORM THEORY, V26, P26, DOI 10.1109/TIT.1980.1056144; TOET A, 1997, TM97A039 TNO HUM FAC, P74; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; UTTAL WR, 1988, SEEING FORMS; VENKATESH S, 1990, PATTERN RECOGN LETT, V11, P339, DOI 10.1016/0167-8655(90)90043-2; WALDMAN G, 1991, IEEE T SYST MAN CYB, V21, P596, DOI 10.1109/21.97453; Wandell B.A., 1995, FDN VISION; Wiener N, 1950, HUMAN USE HUMAN BEIN	42	38	42	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2001	23	4					362	383		10.1109/34.917572	http://dx.doi.org/10.1109/34.917572			22	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	421MJ					2022-12-18	WOS:000168067900003
J	Han, JH; Park, JS				Han, JH; Park, JS			Contour matching using epipolar geometry	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						contour matching; epipolar geometry; contour motion	MOTION ESTIMATION; LINE CORRESPONDENCES; ALGORITHM; IMAGES	Matching features computed in images is an important process in multiview image analysis. When the motion between two images is large, the matching problem becomes very difficult. In this paper, we propose a contour matching algorithm based on geometric constraints. With the assumption that the contours are obtained from images taken from a moving camera with static scenes, we apply the epipolar constraint between two sets of contours and compute the corresponding points on the contours. From the initial epipolar constraints obtained from corner point matching, candidate contours are selected according to the epipolar geometry, contour end point constraints, and contour distance measures. In order to reduce the possibility of false matches, the number of match points on a contour is also used as a selection measure. The initial epipolar constraint is refined from the matched sets of contours. The algorithm can be applied to a pair or two pairs of images. All of the processes are fully automatic and successfully implemented and tested with various real images.	Pohang Univ Sci & Technol, Dept Comp Sci & Engn, Div Elect & Comp Engn, Pohang 790784, South Korea; Elect & Telecommun Res Inst, Virtual Real Res Ctr, Taejon 305350, South Korea	Pohang University of Science & Technology (POSTECH); Electronics & Telecommunications Research Institute - Korea (ETRI)	Han, JH (corresponding author), Pohang Univ Sci & Technol, Dept Comp Sci & Engn, Div Elect & Comp Engn, San 31 Hyoja Dong, Pohang 790784, South Korea.	joonhan@postech.ac.kr; park@etri.re.kr						BOUFAMA B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1030, DOI 10.1109/ICCV.1995.466821; CLOSE R, 1995, PATTERN RECOGN, V28, P1, DOI 10.1016/0031-3203(94)00084-Y; Deriche R., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P66, DOI 10.1109/ICCV.1990.139495; DERICHE R, 1990, P 10 INT C PATT REC, V1, P240; FAUGERAS OD, 1992, P 2 EUR C COMP VIS S, P563; Hartley R. I., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), P1064, DOI 10.1109/ICCV.1995.466816; Hartley R.I., 1994, P ARPA IM UND WORKSH; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; LIU YC, 1988, COMPUT VISION GRAPH, V44, P35, DOI 10.1016/S0734-189X(88)80030-6; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Park JS, 1998, PATTERN RECOGN, V31, P31, DOI 10.1016/S0031-3203(97)00031-9; RAY BK, 1995, PATTERN RECOGN, V28, P1765, DOI 10.1016/0031-3203(95)00046-3; SPETSAKIS ME, 1990, INT J COMPUT VISION, V4, P171, DOI 10.1007/BF00054994; STRICKLAND RN, 1994, CVGIP-IMAG UNDERSTAN, V60, P157, DOI 10.1006/ciun.1994.1044; Tomasi C, 1991, CMUCS91132; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Xu A., 2018, KINETIC THEORY, DOI [10.1007/978-94-015-8668-9, DOI 10.1007/978]; XU G, 1996, VIDERE J COMPUTER VI, V1, P21; ZHANG Z, 1994, 2340 INRIA; ZHANG Z, 1992, 3D DYNAMIC SCENE ANA; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4	21	38	51	2	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2000	22	4					358	370						13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	317WT					2022-12-18	WOS:000087250500005
J	Park, J; Govindaraju, V; Srihari, SN				Park, J; Govindaraju, V; Srihari, SN			OCR in a Hierarchical feature space	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; character/digit recognition; multiresolution; feature space; hierarchical classification; recursion	CHARACTER-RECOGNITION; HANDWRITTEN	This paper describes a character recognition methodology (henceforth referred to as Hierarchical OCR) that achieves high speed and accuracy by using a multiresolution and hierarchical feature space. Features at different resolutions, from coarse to fine-grained, are implemented by means of a recursive classification scheme. Typically, recognizers have to balance the use of features at many resolutions (which yields a high accuracy), with the burden on computational resources in terms of storage space and processing time. We present in this paper, a method that adaptively determines the degree of resolution necessary in order to classify an input pattern. This leads to optimal use of computational resources. The Hierarchical OCR dynamically adapts to factors such as the quality of the input pattern, its intrinsic similarities and differences from patterns of other classes it is being compared against, and the processing time available. Furthermore, the finer resolution is accorded to only certain "zones" of the input pattern which are deemed important given the classes that are being discriminated. Experimental results support the methodology presented. When tested on standard NIST data sets, the Hierarchical OCR proves to be 300 times faster than a traditional K-nearest-neighbor classification method, and 10 times faster than a neural network method. The comparsion uses the same feature set for all methods. Recognition rate of about 96 percent is achieved by the Hierarchical OCR. This is at par with the other two traditional methods.	SUNY Buffalo, Dept Comp Sci & Engn, Ctr Excellence Document Anal & Recognit, Amherst, NY 14260 USA	State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Park, J (corresponding author), SUNY Buffalo, Dept Comp Sci & Engn, Ctr Excellence Document Anal & Recognit, Amherst, NY 14260 USA.		Srihari, Sargur N/E-8100-2011					BAILEY RR, 1996, IEEE T PATTERN ANAL, V18, P369; DUDA R, 1979, PATTERN CLASSIFICATI; Favata J.T., 1994, P 4 INT WORKSH FRONT, P57; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; GARRIS MD, 1992, NIST SPECIAL DATABAS; Ha TM, 1997, IEEE T PATTERN ANAL, V19, P535, DOI 10.1109/34.589216; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; LU CC, 1991, IEEE T COMMUN, V39, P1511, DOI 10.1109/26.103046; MANTAS J, 1986, PATTERN RECOGN, V19, P425, DOI 10.1016/0031-3203(86)90040-3; MORI S, 1992, P IEEE, V80, P1029, DOI 10.1109/5.156468; NAGY G, 1992, P IEEE, V80, P1093, DOI 10.1109/5.156472; Srikantan G, 1996, PATTERN RECOGN, V29, P1147, DOI 10.1016/0031-3203(95)00146-8; SUEN CY, 1992, P IEEE, V80, P1162, DOI 10.1109/5.156477; Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2	14	38	43	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2000	22	4					400	407		10.1109/34.845383	http://dx.doi.org/10.1109/34.845383			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	317WT		Green Submitted			2022-12-18	WOS:000087250500010
J	Madhvanath, S; Kim, G; Govindaraju, V				Madhvanath, S; Kim, G; Govindaraju, V			Chaincode contour processing for handwritten word recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image processing; chain code; handwriting recognition; preprocessing; segmentation; feature extraction		Contour representations of binary images of handwritten words afford considerable reduction in storage requirements while providing lossless representation. On the other hand, the one-dimensional nature of contours presents interesting challenges for processing images for handwritten word recognition. Our experiments indicate that significant gains are to be realized in both speed and recognition accuracy by using a contour representation in handwriting applications.	IBM Corp, San Jose, CA 95120 USA; Sogang Univ, Dept Elect Engn, Seoul, South Korea; SUNY Buffalo, Dept Comp Sci, CEDAR, Buffalo, NY 14228 USA	International Business Machines (IBM); Sogang University; State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Madhvanath, S (corresponding author), IBM Corp, 650 Harry Rd, San Jose, CA 95120 USA.							BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; BROWN MK, 1983, PATTERN RECOGN, V16, P447, DOI 10.1016/0031-3203(83)90049-3; Caesar T., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P382, DOI 10.1109/ICDAR.1995.599018; Cote M., 1998, International Journal on Document Analysis and Recognition, V1, P3, DOI 10.1007/s100320050002; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; HOLT MJJ, 1992, PIXELS FEATURES, V2, P41; Kim G, 1997, IEEE T PATTERN ANAL, V19, P366, DOI 10.1109/34.588017; Kim GH, 1996, P SOC PHOTO-OPT INS, V2660, P262, DOI 10.1117/12.234708; Kimura F., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P18, DOI 10.1109/ICDAR.1993.395791; KIMURA F, 1993, P 3 INT WORKSH FRONT, P122; LU CC, 1991, IEEE T COMMUN, V39, P1511, DOI 10.1109/26.103046; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; YACOUBI E, 1994, P INT WORKSH FRONT H, P378	13	38	42	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1999	21	9					928	932		10.1109/34.790433	http://dx.doi.org/10.1109/34.790433			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	234TZ		Green Submitted			2022-12-18	WOS:000082501600009
J	Cheung, KW; Yeung, DY; Chin, RT				Cheung, KW; Yeung, DY; Chin, RT			A Bayesian framework for deformable pattern recognition with application to handwritten character recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						deformable models; Bayesian inference; handwriting recognition; expectation-maximization; NIST database	MODELS	Deformable models have recently been proposed for many pattern recognition applications due to their ability to handle large shape variations. These proposed approaches represent patterns or shapes as deformable models, which deform themselves to match with the input image, and subsequently feed the extracted information into a classifier. The three components-modeling, matching, and classification-are often treated as independent tasks, in this paper, we study how to integrate deformable models into a Bayesian framework as a unified approach for modeling, matching, and classifying shapes. Handwritten character recognition serves as a testbed for evaluating the approach. With the use of our system, recognition is invariant to affine transformation as well as other handwriting variations. In addition, no preprocessing or manual setting of hyperparameters (e.g., regularization parameter and character width) is required. Besides, issues on the incorporation of constraints on model flexibility detection of subparts, and speed-up are investigated. Using a model set with only 23 prototypes without any discriminative training, we can achieve an accuracy of 94.7 percent with no rejection on a subset (11,791 images by 100 writers) of handwritten digits from the NIST SD-1 dataset.	Hong Kong Univ Sci & Technol, Dept Comp Sci, Clear Water Bay, Peoples R China	Hong Kong University of Science & Technology	Cheung, KW (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci, Clear Water Bay, Peoples R China.	william@cs.ust.hk; ddyeung@cs.ust.hk; roland@cs.ust.hk	Chin, Roland Tai Hong/E-9856-2010	Cheung, William Kwok Wai/0000-0002-7428-2050				Cheung KW, 1996, PROC CVPR IEEE, P613, DOI 10.1109/CVPR.1996.517136; CHEUNG KW, 1998, P 6 INT WORKSH FRONT; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; GEIST J, 1994, 2 CENS OPT CHAR REC; Jain AK, 1997, IEEE T PATTERN ANAL, V19, P1386, DOI 10.1109/34.643899; Lamdan Y., 1988, P IEEE INT C COMP VI, P238; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.448; Revow M, 1996, IEEE T PATTERN ANAL, V18, P592, DOI 10.1109/34.506410; WAKAHARA T, 1994, IEEE T PATTERN ANAL, V16, P618, DOI 10.1109/34.295906	9	38	39	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1998	20	12					1382	1388		10.1109/34.735813	http://dx.doi.org/10.1109/34.735813			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	147QV					2022-12-18	WOS:000077578300012
J	Wakahara, T; Odaka, K				Wakahara, T; Odaka, K			Adaptive normalization of handwritten characters using global/local affine transformation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						adaptive normalization; deformation model; global and local affine transformation; weighted least-squares criterion; distortion-tolerant shape matching	RECOGNITION	Conventional normalization methods for handwritten characters have limitations as preprocessing operations because they are category-independent. This paper introduces an adaptive or category-dependent normalization method that normalizes an input pattern against each reference pattern using global/local affine transformation (GAT/LAT) in a hierarchical manner as a general deformation model. Also, the normalization criterion is clearly defined as minimization of the mean of nearest-neighbor interpoint distances between each reference pattern and a normalized input pattern. According to the above-mentioned criterion, optimal GAT/LAT is determined by iterative application of weighted least-squares fitting techniques. Experiments using input patterns of 3,171 character categories, including Kanji, Kana, and alphanumerics, written by 36 people in the cursive style against square-style reference patterns show not only that the proposed method can absorb a fairly large amount of handwriting fluctuation within the same category, but also that discrimination ability is greatly improved by the suppression of excessive normalization against similarly shaped but different categories. Furthermore, comparative results obtained by the conventional shape normalization method for preprocessing are presented to show the superiority of the proposed category-dependent GAT/LAT normalization over category-independent normalization.	NTT Corp, NTT Human Interface Labs, Kanagawa 2390847, Japan; Univ Lib & Informat Sci, Fac Lib & Informat Sci, Tsukuba, Ibaraki 3058550, Japan	Nippon Telegraph & Telephone Corporation; University of Tsukuba	Wakahara, T (corresponding author), NTT Corp, NTT Human Interface Labs, 1-1 Hikari No Oka, Kanagawa 2390847, Japan.	waka@marsh.hil.ntt.co.jp; odaka@ulis.ac.jp						CASEY RG, 1970, IBM J RES DEV, V14, P548, DOI 10.1147/rd.145.0548; LEE SW, 1994, PATTERN RECOGN, V27, P895, DOI 10.1016/0031-3203(94)90155-4; *MATH SOC JAP, 1977, ENC DICT MATH; NAGY G, 1970, COMMUN ACM, V13, P475, DOI 10.1145/362705.362708; Simard P., 1993, ADV NEURAL INFORMATI, V5, P50; TSUKUMO J, 1988, P 9 INT C PATT REC, P168; Wakahara T, 1996, IEICE T INF SYST, VE79D, P529; WAKAHARA T, 1994, IEEE T PATTERN ANAL, V16, P618, DOI 10.1109/34.295906; YAMADA H, 1990, PATTERN RECOGN, V23, P1023, DOI 10.1016/0031-3203(90)90110-7; Yamashita Y, 1983, PATTERN RECOGN LETT, V1, P475, DOI 10.1016/0167-8655(83)90089-2	10	38	41	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1998	20	12					1332	1341		10.1109/34.735806	http://dx.doi.org/10.1109/34.735806			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	147QV					2022-12-18	WOS:000077578300005
J	Asada, N; Fujiwara, H; Matsuyama, T				Asada, N; Fujiwara, H; Matsuyama, T			Seeing behind the scene: Analysis of photometric properties of occluding edges by the reversed projection blurring model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						occluding edge; image blurring model; reversed projection; shift-variant point spread function; finite depth of field	DEPTH; FOCUS	This paper analyzes photometric properties of occluding edges and proves that an object surface behind a nearer object is partially observable beyond the occluding edges. We first discuss a limitation of the image blurring model using the convolution, and then present an optical flux based blurring model named the reversed projection blurring (RPB) model. Unlike the multicomponent blurring model proposed by Nguyen et al., the RPB model enables us to explore the optical phenomena caused by a shift-variant point spread function that appears at a depth discontinuity. Using the RPB model, theoretical analysis of occluding edge properties are given and two characteristic phenomena are shown: (1) a blurred occluding edge produces the same brightness profiles as would be predicted for a surface edge on the occluding object when the occluded surface radiance is uniform and (2) a non-monotonic brightness transition would be observed in blurred occluding edge profiles when the occluded object has a surface edge. Experimental results using real images have demonstrated the validity of the RPB model as well as the observability of the characteristic phenomena of blurred occluding edges.	Hiroshima City Univ, Dept Intelligent Syst, Hiroshima 73131, Japan; Ind Res Ctr Okayama, Okayama 70112, Japan; Kyoto Univ, Dept Elect & Commun, Kyoto 60601, Japan	Kyoto University	Asada, N (corresponding author), Hiroshima City Univ, Dept Intelligent Syst, Hiroshima 73131, Japan.	asada@its.horishima-cu.ac.jp; fujiwara@okakogi.go.jp; tm@kuee.kyoto-u.ac.jp						ASADA N, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P150, DOI 10.1109/ICCV.1995.466793; ASADA N, 1993, P AS C COMP VIS, P83; CHEN YC, 1988, P CG INT, P117; COOK RL, 1984, P SIGGRAPH 84, P137; Darrell T., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P504, DOI 10.1109/CVPR.1988.196282; ENS J, 1993, IEEE T PATTERN ANAL, V15, P97, DOI 10.1109/34.192482; GROSSMANN P, 1987, PATTERN RECOGN LETT, V5, P63, DOI 10.1016/0167-8655(87)90026-2; Horn B., 1986, ROBOT VISION, P1; KROTKOV E, 1987, INT J COMPUT VISION, V1, P223, DOI 10.1007/BF00127822; LAI SH, 1992, IEEE T PATTERN ANAL, V14, P405, DOI 10.1109/34.126803; Nair H. N., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P309, DOI 10.1109/CVPR.1992.223258; Nayar S.K., 1992, P IMAGE UNDERSTANDIN, P539; NGUYEN TC, 1992, P EUR C COMP VIS, P347; PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940; Subbarao M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P773, DOI 10.1109/CVPR.1992.223176; SUBBARAO M, 1988, P INT C COMP VIS, P149; WHITTED T, 1980, COMMUN ACM, V23, P343, DOI 10.1145/358876.358882; Xiong Y., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P68, DOI 10.1109/CVPR.1993.340977	18	38	38	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1998	20	2					155	167		10.1109/34.659933	http://dx.doi.org/10.1109/34.659933			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YZ697					2022-12-18	WOS:000072281800005
J	Gader, PD; Khabou, MA				Gader, PD; Khabou, MA			Automatic feature generation for handwritten digit recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						handwritten digit recognition; feature generation; feature selection; entropy; information; orthogonality; neural networks	TEMPLATE; NUMERALS	An automatic feature generation method for handwritten digit recognition is described. Two different evaluation measures, orthogonality and information, are used to guide the search for features. The features are used in a backpropagation trained neural network. Classification rates compare favorably with results published in a survey of high-performance handwritten digit recognition systems. This classifier is combined with several other high performance classifiers. Recognition rates of around 98% are obtained using two classifiers on a test set with 1,000 digits per class.			Gader, PD (corresponding author), UNIV MISSOURI,DEPT ELECT & COMP ENGN,COLUMBIA,MO 65211, USA.							CASEY RG, 1970, IBM J RES DEV, P548; CHIANG JH, 1995, P INT C CFSA IFIS SO, P182; CHO SB, 1995, IEEE T SYST MAN CYB, V25, P380, DOI 10.1109/21.364825; Favata J.T., 1994, P 4 INT WORKSH FRONT; GADER P, 1991, PATTERN RECOGN, V24, P421, DOI 10.1016/0031-3203(91)90055-A; GADER P, 1993, P 3 INT WORKSH FRONT; GADER PD, 1990, P SPSES 43 ANN C ROC; GADER PD, 1994, DIGITAL IMAGE PROCES, P223; GADER PD, 1993, IEEE T SYSTEMS MAN C; GADER PD, 1990, P US POST SERV ADV T; GADER PD, 1990, ADV RES HANDWRITTEN; GADER PD, 1994, SPIE IMAGE ALGEBRA M, V5; GILLIES A, 1990, P SPIE C IM ALG MORP; GILLIES AM, 1993, HANDWRITTEN ADDRESS; HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716; HUANG YS, 1995, IEEE T PATTERN ANAL, V17, P90, DOI 10.1109/34.368145; KELLER JM, 1994, FUZZY SET SYST, V65, P273, DOI 10.1016/0165-0114(94)90024-8; KIMURA F, 1991, PATTERN RECOGN, V24, P969, DOI 10.1016/0031-3203(91)90094-L; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; LECUN Y, 1990, P 1 INT WORKSH FRONT; Mitchell B. T., 1989, Machine Vision and Applications, V2, P231, DOI 10.1007/BF01215877; NAKANE F, 1994, P 4 INT WORKSH FRONT; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; STENTIFORD FWM, 1985, IEEE T PATTERN ANAL, V7, P349, DOI 10.1109/TPAMI.1985.4767665; STRINGA L, 1990, IEEE T PATTERN ANAL, V12, P1210, DOI 10.1109/34.62612; SUEN CY, 1992, P IEEE, V80, P1162, DOI 10.1109/5.156477; TUBBS JD, 1989, PATTERN RECOGN, V22, P359, DOI 10.1016/0031-3203(89)90045-9	27	38	40	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1996	18	12					1256	1261		10.1109/34.546262	http://dx.doi.org/10.1109/34.546262			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VZ150					2022-12-18	WOS:A1996VZ15000011
J	Samet, H; Soffer, A				Samet, H; Soffer, A			MARCO: MAp Retrieval by COntent	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						map storage and retrieval; document storage; digital libraries; automated indexing; retrieval by content; map interpretation; Geographic Information Systems (GIS)	RECOGNITION	A system named MARCO (denoting MAp Retrieval by COntent) that is used for the acquisition, storage, indexing, and retrieval of map images is presented. The input to MARCO are raster images of separate map layers and raster images of map composites. A legend-driven map interpretation system converts map layer images from their physical representation to their logical representation. This logical representation is then used to automatically index both the composite and the layer images. Methods for incorporating logical and physical layer images as well as composite images into the framework of a relational database management system are described. Indices are constructed on both the contextual and the spatial data thereby enabling efficient retrieval of layer and composite images based on contextual as well as spatial specifications. Example queries and query processing strategies using these indices are described. The user interface is demonstrated via the execution of an example query. Results of an experimental study on a large amount of data are presented. The system is evaluated in terms of accuracy and in terms of query execution time.	UNIV MARYLAND, CTR AUTOMAT RES, COLLEGE PK, MD 20742 USA; UNIV MARYLAND, INST ADV COMP SCI, COLLEGE PK, MD 20742 USA; UNIV MARYLAND, DEPT COMP SCI & ELECT ENGN, BALTIMORE, MD 21228 USA; NASA, GODDARD SPACE FLIGHT CTR, CTR EXCELLENCE SPACE DATA & INFORMAT SCI, GREENBELT, MD 20771 USA	University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland Baltimore; National Aeronautics & Space Administration (NASA); NASA Goddard Space Flight Center	Samet, H (corresponding author), UNIV MARYLAND, DEPT COMP SCI, COLLEGE PK, MD 20742 USA.							Ablameyko S. V., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P115, DOI 10.1109/ICDAR.1993.395769; AREF WG, 1991, PROC INT CONF VERY L, P81; ARYA S, 1994, PROCEEDINGS OF THE FIFTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P573; BLUE JL, 1994, PATTERN RECOGN, V27, P485, DOI 10.1016/0031-3203(94)90031-0; CASH GL, 1987, COMPUT VISION GRAPH, V39, P291, DOI 10.1016/S0734-189X(87)80183-4; DEVIJVER P, 1982, STAT PATTERN RECOGNI; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; Guttman A., 1984, ACM SIGMOD RECORD, V14, P47, DOI [DOI 10.1145/602259.602266, 10.1145/971697.602266]; Hjaltason GR, 1995, LECT NOTES COMPUT SC, V951, P83; Kasturi R., 1990, P IAPR WORKSHOP STRU, P192; Larsgaard Mary Lynette, 1987, MAP LIB INTRO; LEVINE MD, 1982, VISION MAN MACHINE; Nelson R. C., 1986, Computer Graphics, V20, P197, DOI 10.1145/15886.15908; NELSON RC, 1986, P SIGGRAPH 86 C DALL; NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173; PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786; PEUQUET DJ, 1981, CARTOGRAPHICA, V18, P34; Rasure J. R., 1991, Journal of Visual Languages and Computing, V2, P217, DOI 10.1016/S1045-926X(06)80007-8; Rosenfeld A., 1982, DIGITAL PICTURE PROC; Rotem D., 1991, Proceedings. Seventh International Conference on Data Engineering (Cat. No.91CH2968-6), P500, DOI 10.1109/ICDE.1991.131499; Samet H., 1990, DESIGN ANAL SPATIAL, V85; Samet H., 1994, P 12 INT C PATT REC, V2, P350; SAMET H, 1994, CSTR3386 U MAR; Samet H., 1995, MODERN DATABASE SYST, P361; SAMET H, 1994, PROGR IMAGE ANAL PRO, V3, P233; SAMET H, 1994, CSTR3371 U MAR; STAR J, 1990, GEOGRAPHIC INFORMATI, P85; STONEBRAKER M, 1993, LECT NOTES COMPUTER, V692, P397; SUZUKI S, 1990, PATTERN RECOGN, V23, P919, DOI 10.1016/0031-3203(90)90137-A; Swain Micheal j, 1993, SPIE P, V1908, P95; Tanaka N., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P680, DOI 10.1109/ICDAR.1993.395646; [No title captured]	32	38	39	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1996	18	8					783	798		10.1109/34.531799	http://dx.doi.org/10.1109/34.531799			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VE318					2022-12-18	WOS:A1996VE31800003
J	GROSSO, E; TISTARELLI, M				GROSSO, E; TISTARELLI, M			ACTIVE DYNAMIC STEREO VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ACTIVE VISION; DYNAMIC VISION; TIME-TO-IMPACT; STEREO VISION; MOTION ANALYSIS; NAVIGATION	BINOCULAR IMAGE FLOWS; ANIMATE VISION; MOBILE ROBOT; OPTICAL-FLOW; MOTION; DEPTH; CALIBRATION	Visual navigation is a challenging issue in automated robot control, In many robot applications, like object manipulation in hazardous environments or autonomous locomotion, it is necessary to automatically detect and avoid obstacles while planning a safe trajectory, In this context the detection of corridors of free space along the robot trajectory is a very important capability which requires nontrivial visual processing. In most cases it is possible to take advantage of the active control of the cameras. In this paper we propose a cooperative schema in which motion and stereo vision are used to infer scene structure and determine free space areas. Binocular disparity, computed on several stereo images over time, is combined with optical flow from the same sequence to obtain a relative-depth map of the scene, Both the time-to-impact and depth scaled by the distance of the camera from the fixation point in space are considered as good, relative measurements which are based on the viewer, but centered on the environment. The need for calibrated parameters is considerably reduced by using an active control strategy. The cameras track a point in space independently of the robot motion and the full rotation of the head, which includes the unknown robot motion, is derived from binocular image data. The feasibility of the approach in real robotic applications is demonstrated by several experiments performed on real image data acquired from an autonomous vehicle and a prototype camera head.			GROSSO, E (corresponding author), UNIV GENOA,DEPT COMMUN COMP & SYST SCI,INTEGRATED LAB ADV ROBOT,VIA OPERA PIA 13,I-16145 GENOA,ITALY.		Tistarelli, Massimo/AAH-9437-2021	Tistarelli, Massimo/0000-0002-3406-3048				AHUJA N, 1993, IEEE T PATTERN ANAL, V15, P1007, DOI 10.1109/34.254059; Aloimonos J., 1987, International Journal of Computer Vision, V1, P333, DOI 10.1007/BF00133571; AYACHE N, 1989, IEEE T ROBOTIC AUTOM, V5, P804, DOI 10.1109/70.88101; BAJCSY RK, 1985, 3RD P IEEE WORKSH CO, P13; BALLARD DH, 1991, ARTIF INTELL, V48, P57, DOI 10.1016/0004-3702(91)90080-4; BALLARD DH, 1992, CVGIP-IMAG UNDERSTAN, V56, P3, DOI 10.1016/1049-9660(92)90081-D; BALLARD DH, 1989, OPT NEWS, V15, P17; Beer R. D., 1990, INTELLIGENCE ADAPTIV; BRIDWELL NJ, 1983, COMPUT VISION GRAPH, V21, P33, DOI 10.1016/S0734-189X(83)80028-0; BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032; BROOKS RA, 1988, P DARPA WORKSHOP IMA, P398; CHANG YL, 1989, IEEE T SYSTEMS MAN C, V19; CUTTING J, 1988, PERCEPTION EYE MOTIO; FERRARI F, 1990, JUL P INT WORKSH INT; GROSSO E, 1992, 2ND P EUR C COMP VIS, P516; GROSSO E, 1989, IEEE T SYSTEMS MAN C, V19; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1990, INT J COMPUTER VISIO, P59; IZAGUIRRE A, 1988, INT J ROBOT RES, P104; KAMGARPARSI B, 1986, CSTR1640 U MAR TECH; KRIEGMAN DJ, 1989, IEEE T ROBOTIC AUTOM, V5, P792, DOI 10.1109/70.88100; LEE DN, 1981, NATURE, V293, P293, DOI 10.1038/293293a0; LI LX, 1993, IEEE T PATTERN ANAL, V15, P657, DOI 10.1109/34.221167; MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032; MATTHIES L, 1987, 4TH P INT S ROB RES, P120; NAGEL HH, 1987, ARTIF INTELL, V33, P299, DOI 10.1016/0004-3702(87)90041-5; NAGEL HH, 1992, ARTIFICIAL BIOL VISI, P193; NELSON RC, 1989, IEEE T PATTERN ANAL, V11, P1102, DOI 10.1109/34.42840; PUGET P, 1990, IMAGE VISION COMPUT, V8, P341, DOI 10.1016/0262-8856(90)80010-Q; SABATA B, 1991, CVGIP-IMAG UNDERSTAN, V54, P309, DOI 10.1016/1049-9660(91)90032-K; SANDINI G, 1990, IEEE T PATTERN ANAL, V12, P13, DOI 10.1109/34.41380; SANDINI G, 1990, OCT P IEEE INT WORKS, P396; TIRUMALAI AP, 1992, IEEE T PATTERN ANAL, V14, P1184, DOI 10.1109/34.177383; TISTARELLI M, 1990, IMAGE VISION COMPUT, V8, P271, DOI 10.1016/0262-8856(90)80003-C; TISTARELLI M, 1992, CVGIP-IMAG UNDERSTAN, V56, P108, DOI 10.1016/1049-9660(92)90089-L; TISTARELLI M, 1994, 3RD P EUR C COMP VIS, P61; TISTARELLI M, 1991, JUN P INT C COMP VIS, P186; URAS S, 1988, BIOL CYBERN, V60, P79, DOI 10.1007/BF00202895; WAXMAN AM, 1986, IEEE T PATTERN ANAL, V8, P715, DOI 10.1109/TPAMI.1986.4767853	40	38	40	2	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1995	17	9					868	879		10.1109/34.406652	http://dx.doi.org/10.1109/34.406652			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RR989					2022-12-18	WOS:A1995RR98900004
J	LEE, SW; KIM, YJ				LEE, SW; KIM, YJ			DIRECT EXTRACTION OF TOPOGRAPHIC FEATURES FOR GRAY-SCALE CHARACTER-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						GRAY SCALE CHARACTER RECOGNITION; PRINCIPAL CURVATURE; PRINCIPAL ORTHOGONAL ELEMENTS; TOPOGRAPHIC FEATURE EXTRACTION		Optical character recognition(OCR) traditionally applies to binary-valued imagery although text is always scanned and stored in gray scale. However, binarization of multivalued image may remove important topological information from characters and introduce noise to character background. In order to avoid this problem, it is indispensable to develop a method which can minimize the information loss due to binarization by extracting features directly from gray scale character images. In this paper, we propose a new method for the direct extraction of topographic features from gray scale character images. By comparing the proposed method with Wang and Pavlidis' method, we realized that the proposed method enhanced the performance of topographic feature extraction by computing the directions of principal curvature efficiently and prevented the extraction of unnecessary features. We also show that the proposed method is very effective for gray scale skeletonization compared to Levi and Montanari's method.	BIT COMP CO LTD,SEOUL 135080,SOUTH KOREA		LEE, SW (corresponding author), KOREA UNIV,DEPT COMP SCI,SEOUL 136701,SOUTH KOREA.		Lee, Seong-Whan/C-7928-2012					HARALICK RM, 1983, INT J ROBOT RES, V2, P50, DOI 10.1177/027836498300200105; KIM DH, 1993, 2ND P INT C DOC AN R, P470; LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346; LAM SW, 1992, P SOC PHOTO-OPT INS, V1661, P98, DOI 10.1117/12.130278; LEE SW, 1993, PATTERN RECOGN, V7, P1203; Leung C. H., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P532; LEVI G, 1970, INFORM CONTROL, V17, P62, DOI 10.1016/S0019-9958(70)80006-7; MURAKAMI H, 1982, IEEE T PATTERN ANAL, V4, P511, DOI 10.1109/TPAMI.1982.4767295; Pavlidis T., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P570; PAVLIDIS T, 1992, 2ND P IPTP C TOK, P65; PAVLIDIS T, 1992, P SPIE C MACHINE VI, V1661, P1; WANG L, 1993, IEEE T PATTERN ANAL, V15, P1053, DOI 10.1109/34.254062; WANG L, 1992, JUN P IEEE C COMP VI, V2, P665	13	38	45	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1995	17	7					724	729		10.1109/34.391416	http://dx.doi.org/10.1109/34.391416			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RF224					2022-12-18	WOS:A1995RF22400009
J	NELSON, RC				NELSON, RC			FINDING LINE SEGMENTS BY STICK GROWING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						LINE DETECTION; FEATURE EXTRACTION; EDGE DETECTION; ENERGY MINIMIZATION; GRADIENT DESCENT	EDGE-DETECTION; PICTURES	A method is described for extracting lineal features from an image using extended local information to provide robustness and sensitivity. The method utilizes both gradient magnitude and direction information, and incorporates explicit lineal and end-stop terms. These terms are combined nonlinearly to produce an energy landscape in which local minima correspond to lineal features called sticks that can be represented as line segments. A hill climbing (stick-growing) process is used to find these minima. The method is compared to two others, and found to have improved gap-crossing characteristics.			NELSON, RC (corresponding author), UNIV ROCHESTER, DEPT COMP SCI, ROCHESTER, NY 14627 USA.							[Anonymous], 1985, PERCEPTUAL ORG VISUA; BURNS JB, 1984, P DARPA IU WORKSHOP, P165; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; ETEMADI A, 1990, ROBUST SEGMENTATION; HONG TH, 1983, IEEE T SYST MAN CYB, V13, P631, DOI 10.1109/TSMC.1983.6313152; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; MANSOURI AR, 1987, COMPUT VISION GRAPH, V40, P95, DOI 10.1016/0734-189X(87)90058-2; NALWA VS, 1987, COMPUT VISION GRAPH, V40, P79, DOI 10.1016/0734-189X(87)90057-0; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; PRINCEN J, 1990, COMPUT VISION GRAPH, V52, P57, DOI 10.1016/0734-189X(90)90123-D; ZHOU YT, 1989, IEEE T PATTERN ANAL, V11, P84, DOI 10.1109/34.23115	12	38	42	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1994	16	5					519	523		10.1109/34.291445	http://dx.doi.org/10.1109/34.291445			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NP141					2022-12-18	WOS:A1994NP14100008
J	CHENG, FH; HSU, WH; CHEN, MY				CHENG, FH; HSU, WH; CHEN, MY			RECOGNITION OF HANDWRITTEN CHINESE-CHARACTERS BY MODIFIED HOUGH TRANSFORM TECHNIQUES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									ACAD SINICA,INST INFORMAT SCI,TAIPEI 11529,TAIWAN	Academia Sinica - Taiwan	CHENG, FH (corresponding author), NATL TSING HUA UNIV,INST ELECT ENGN,HSINCHU 30043,TAIWAN.							BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; CHEN YS, 1985, P NAT COMP S, P295; CHEUNG YS, 1985, 1985 P IEEE INT C SY, P42; DAVIS LS, 1982, PATTERN RECOGN, V15, P277, DOI 10.1016/0031-3203(82)90030-9; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; GLUCKSMAN JHA, 1976, 1ST DIG ANN IEEE COM, P137; GU YX, 1983, IEEE T PATTERN ANAL, V5, P83, DOI 10.1109/TPAMI.1983.4767349; HAGITA N, 1981, T IECE JAPAN, V81, P95; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; HSING TR, 1982, P SOC PHOTO-OPT INST, V341, P94; HSU WH, 1985, J COMPUT PROCESSING, V2, P101; HSU WH, 1982, T IECE JAPAN J D, V65, P1159; KUROSAWA Y, 1981, P IECE ANN CONV  OCT, P71; KUSHNIR M, 1983, PATTERN RECOGN, V16, P183, DOI 10.1016/0031-3203(83)90021-3; KUSHNIR M, 1985, PATTERN RECOGN, V18, P103, DOI 10.1016/0031-3203(85)90033-0; MAO YH, 1982, P INT C CHINESE LANG, P432; MORI S, 1984, IEEE T PATTERN ANAL, V6, P386, DOI 10.1109/TPAMI.1984.4767545; NAITO S, 1981, T IECE JAPAN D, V64, P757; Nakata K., 1972, Proceedings of the Conference on Machine Perception of Patterns and Pictures, P45; Oka RI, 1982, P INT C PATTERN RECO, V2, P783; SAITO T, 1982, I IECE JAPAN J D, V65, P550; Sakai K., 1976, 3rd International Joint Conference on Pattern Recognition, P122; SHAPIRO SD, 1980, PATTERN RECOGN, V12, P333, DOI 10.1016/0031-3203(80)90032-1; SHIO A, 1980, T IECE JAPAN, V14, P83; WANG PP, 1973, PATTERN RECOGN, V5, P303, DOI 10.1016/0031-3203(73)90023-X; WANG YT, 1984, 1984 INT COMPT S TAI, P441; YASUDA M, 1979, J IECE JAPAN J D, V62, P217; 1981, NIKKEI ELECTRON, V12, P148	28	38	46	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1989	11	4					429	439		10.1109/34.19042	http://dx.doi.org/10.1109/34.19042			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	T9100					2022-12-18	WOS:A1989T910000011
J	FUKUNAGA, K; HAYES, RR				FUKUNAGA, K; HAYES, RR			THE REDUCED PARZEN CLASSIFIER	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											FUKUNAGA, K (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.							DEVIJVER PA, 1980, 5TH P INT C PATT REC, P72; EVERITT BS, 1981, FINITE MISTURE DISTR; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P115, DOI 10.1109/TPAMI.1984.4767485; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634, DOI 10.1109/TPAMI.1987.4767958; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; GEMAN S, 1982, ANN STAT, V10, P401, DOI 10.1214/aos/1176345782; HAND DJ, 1982, KERNEL DISCRIMINANT; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; TITTERINGTON DM, 1985, STATISTICAL ANAL FIN	10	38	41	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1989	11	4					423	425		10.1109/34.19040	http://dx.doi.org/10.1109/34.19040			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	T9100					2022-12-18	WOS:A1989T910000009
J	GRIMSON, WEL; HILDRETH, EC				GRIMSON, WEL; HILDRETH, EC			DIGITAL STEP EDGES FROM ZERO CROSSINGS OF 2ND DIRECTIONAL-DERIVATIVES - COMMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											GRIMSON, WEL (corresponding author), MIT,ARTIFICIAL INTELLIGENCE LAB,CAMBRIDGE,MA 02139, USA.							BERZINS V, 1983, 8314 U MINN COMP SCI; BINFORD TO, 1981, ARTIF INTELL, V17, P205, DOI 10.1016/0004-3702(81)90025-4; BOLLES RC, 1983, 8TH P INT JOINT C AR, V2, P1116; BOLLES RC, 1983, 1ST P INT S ROB RES; BRADY JM, 1981, VISIBLE LANG, V15, P183; CANNY J, 1983, MIT AITR720 ART INT; CLARK JJ, 1983, MULTIRESOLUTION IMAG; CORNELIUS N, 1983, ACM WORKSH MOT TOR, P50; GLICKSMAN J, 1983, 8TH P INT JOINT C AR, V2, P1078; GLICKSMAN J, 1982, TN8213 U BRIT COL DE; GRIMSON WEL, 1982, PHILOS T ROY SOC B, V298, P395, DOI 10.1098/rstb.1982.0088; GRIMSON WEL, 1981, PHILOS T ROY SOC B, V292, P217, DOI 10.1098/rstb.1981.0031; GRIMSON WEL, 1981, IMAGES SURFACES; HAVENS WS, UNPUB IMPROVED OPERA; HILDRETH EC, 1983, COMPUT VISION GRAPH, V22, P1, DOI 10.1016/0734-189X(83)90093-2; HILDRETH EC, 1982, MECH ENG, V104, P48; HILDRETH EC, 1981, ROBOT AGE        SEP, P8; KAK AC, 1983, TREE8344 PURD U TECH; KNIGHT T, 1983, THESIS MIT; LAWTON DT, 1983, COMPUT VISION GRAPH, V22, P116, DOI 10.1016/0734-189X(83)90098-1; LAWTON DT, 1982, AUG P IEEE WORKSH CO, P59; LUNSCHER WHH, 1983, THESIS U BRIT COLUMB; LUNSCHER WHHJ, 1983, IEEE T PATTERN ANAL, V5, P678, DOI 10.1109/TPAMI.1983.4767462; MAJKA MS, 1982, THESIS U BRIT COLUMB; MARR D, 1981, PROC R SOC SER B-BIO, V211, P151, DOI 10.1098/rspb.1981.0001; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MARR D, 1980, MIT558 ART INT LAB M; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; MAYHEW JEW, 1983, PHYSICAL BIOL PROCES; NISHIHARA HK, 1981, P DARPA IMAGE UNDERS, P114; Prewitt, 1970, PICTURE PROCESSING P, V10, P15, DOI DOI 10.4236/AD.2014.22003; TORRE V, 1983, MIT768 ART INT LAB M; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9; YUILLE AL, 1983, MIT730 ART INT LAB M; YUILLE AL, 1983, MIT772 ART INT LAB M; ZUCKER S, 1980, 802R MCGILL U DEP EL; ZUCKER SW, 1981, 7TH P INT JOINT C AR, V2, P1102	37	38	38	2	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	1					121	127		10.1109/TPAMI.1985.4767628	http://dx.doi.org/10.1109/TPAMI.1985.4767628			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ABF09	21869250				2022-12-18	WOS:A1985ABF0900015
J	MAGEE, MJ; BOYTER, BA; CHIEN, CH; AGGARWAL, JK				MAGEE, MJ; BOYTER, BA; CHIEN, CH; AGGARWAL, JK			EXPERIMENTS IN INTENSITY GUIDED RANGE SENSING RECOGNITION OF 3-DIMENSIONAL OBJECTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV TEXAS,IMAGE & SIGNAL ANAL LAB,AUSTIN,TX 78712	University of Texas System; University of Texas Austin								AGGARWAL JK, 1985, DIGITAL IMAGE ANAL, P29; [Anonymous], 1980, PRINCIPLES ARTIFICIA; Duda R.O., 1973, J ROYAL STAT SOC SER; DUDA RO, 1979, IEEE T PATTERN ANAL, V1, P259, DOI 10.1109/TPAMI.1979.4766922; Garvey T. D., 1976, 3rd International Joint Conference on Pattern Recognition, P567; GIL B, 1983, COMPUT VISION GRAPH, V21, P395, DOI 10.1016/S0734-189X(83)80051-6; ISHII M, 1976, PATTERN RECOGN, V8, P229, DOI 10.1016/0031-3203(76)90043-1; KIRSCH RA, 1971, COMPUT BIOMED RES, V4, P315, DOI 10.1016/0010-4809(71)90034-6; MAGEE MJ, 1985, 7TH P INT C PATT REC, P538; MARTIN WN, 1983, IEEE T PATTERN ANAL, V5, P150, DOI 10.1109/TPAMI.1983.4767367; MITICHE A, 1985, JUN P IEEE COMP SOC; NAGEL HH, 1981, COMPUTER, V14, P29, DOI 10.1109/C-M.1981.220560; NEWMAN EA, 1982, SCI AM           MAR, P116; NEWMAN WM, 1979, PRINCIPLES INTERACTI, P498; Nilsson N.J., 1971, PROBLEM SOLVING METH; NITZAN D, 1977, P IEEE, V65, P206, DOI 10.1109/PROC.1977.10458; Rich E., 1983, ARTIF INTELL; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WINSTON PH, 1973, MIT TR281 ART INT LA, P243	20	38	38	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	6					629	637		10.1109/TPAMI.1985.4767719	http://dx.doi.org/10.1109/TPAMI.1985.4767719			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ATG05	21869301				2022-12-18	WOS:A1985ATG0500001
J	WU, LD				WU, LD			ON THE CHAIN CODE OF A LINE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									BROWN UNIV,DIV APPL MATH,PROVIDENCE,RI 02912	Brown University	WU, LD (corresponding author), FUDAN UNIV,DEPT COMP SCI,SHANGHAI,PEOPLES R CHINA.							Arcelli C., 1975, Computer Graphics and Image Processing, V4, P339, DOI 10.1016/0146-664X(75)90003-9; ARCELLI C, 1978, COMPUT VISION GRAPH, V7, P67, DOI 10.1016/S0146-664X(78)80014-8; BRESENHAM JE, 1965, IBM SYST J, V4, P25, DOI 10.1147/sj.41.0025; BRONS R, 1974, COMPUT GRAPHICS IMAG, V2, P48; GAAFAR M, 1977, COMPUTER GRAPHICS IM, V6, P361; Lipkin BS, 1970, PICTURE PROCESSING P, P241; Pavlidis T., 1977, STRUCTURAL PATTERN R; ROSENFELD A, 1974, IEEE T COMPUT, VC 23, P1264, DOI 10.1109/T-C.1974.223845; WU LD, 1980, 5TH P ICPR	9	38	41	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	3					347	353		10.1109/TPAMI.1982.4767258	http://dx.doi.org/10.1109/TPAMI.1982.4767258			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	NN069	21869048				2022-12-18	WOS:A1982NN06900019
J	DAVIS, LS; CLEARMAN, M; AGGARWAL, JK				DAVIS, LS; CLEARMAN, M; AGGARWAL, JK			AN EMPIRICAL-EVALUATION OF GENERALIZED CO-OCCURRENCE MATRICES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV TEXAS,DEPT ELECT ENGN,AUSTIN,TX 78712	University of Texas System; University of Texas Austin	DAVIS, LS (corresponding author), UNIV TEXAS,DEPT COMP SCI,AUSTIN,TX 78712, USA.							BAJSCY R, 1976, COMPUTER GRAPHICS IM, V5, P52; Barrow H., 1978, COMPUTER VISION SYST; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P251, DOI 10.1109/TPAMI.1979.4766921; FAUGERAS OD, 1980, IEEE T PATTERN ANAL, V2, P323, DOI 10.1109/TPAMI.1980.4767031; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; JULESZ B, P IMAGE MODELLING WO; KIRSCH RA, 1971, COMPUT BIOMED RES, V4, P315, DOI 10.1016/0010-4809(71)90034-6; MALESON JT, 1977, P DARPA IM UNDERST W, P19; Pratt W. K., 1978, DIGITAL IMAGE PROCES; ROSENFELD A, 1970, C REC S FEATURE EXTR, P115; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SCHACHTER B, 1979, IEEE T SYST MAN CYBE, V9, P694; WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777; ODNORM IMSL LIB0007	16	38	39	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	2					214	221		10.1109/TPAMI.1981.4767084	http://dx.doi.org/10.1109/TPAMI.1981.4767084			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	MN968	21868941				2022-12-18	WOS:A1981MN96800016
J	ROSENFELD, A				ROSENFELD, A			THE ROBERTS,MAX OPERATOR IS A HUECKEL-TYPE EDGE DETECTOR	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											ROSENFELD, A (corresponding author), UNIV MARYLAND,CTR COMP SCI,COLLEGE PK,MD 20742, USA.							Davies D. L., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing, P42; HUECKEL MH, 1973, J ACM, V20, P634, DOI 10.1145/321784.321791; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; HUMMEL RA, 1979, COMPUT VISION GRAPH, V9, P40, DOI 10.1016/0146-664X(79)90081-9; Iannino A., 1979, Proceedings of the 1979 IEEE Computer Society Conference on Pattern Recognition and Image Processing, P130; MERO L, 1975, 4TH P INT JOINT C AR, P650; NEVATIA R, 1977, COMPUT VISION GRAPH, V6, P582, DOI 10.1016/S0146-664X(77)80017-8; OGORMAN F, 1978, ARTIF INTELL, V10, P215, DOI 10.1016/S0004-3702(78)80013-7; ROSENFELD A, 1976, DIGITAL PICTURE PROC, P280	9	38	42	4	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	1					101	103		10.1109/TPAMI.1981.4767056	http://dx.doi.org/10.1109/TPAMI.1981.4767056			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	LK116	21868924				2022-12-18	WOS:A1981LK11600012
J	WILLIAMS, TD				WILLIAMS, TD			DEPTH FROM CAMERA MOTION IN A REAL WORLD SCENE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											WILLIAMS, TD (corresponding author), DIGITAL EQUIPMENT CORP,CORP RES GRP,MAYNARD,MA 01754, USA.							BARROW H, 1978, 157 STANF RES INT TE; HANSON A, 1979, COMPUTER VISION SYST; MARTIN W, 1977, DYNAMIC SCENE ANAL S; NAGIN P, 1979, THESIS U MASSACHUSET; NEVATIA R, 1976, COMPUT GRAPHICS  MAY; PILIPHUCK A, 1979, COMMUNICATION; QUAM L, 1974, 239 STANF ART INT LA; WILLIAMS T, THESIS U MASSACHUSET	8	38	40	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	6					511	516		10.1109/TPAMI.1980.6447697	http://dx.doi.org/10.1109/TPAMI.1980.6447697			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KS962					2022-12-18	WOS:A1980KS96200003
J	Guo, XJ; Yu, L; Ma, JY; Ling, HB				Guo, Xiaojie; Yu, Li; Ma, Jiayi; Ling, Haibin			Mutually Guided Image Filtering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image edge detection; Image restoration; Computer vision; Task analysis; Kernel; Image color analysis; Sensors; Image filtering; joint image filtering; guided image filtering; mutually guided image filtering	MINIMIZATION; RECOVERY	Filtering images is required by numerous multimedia, computer vision and graphics tasks. Despite diverse goals of different tasks, making effective rules is key to the filtering performance. Linear translation-invariant filters with manually designed kernels have been widely used. However, their performance suffers from content-blindness. To mitigate the content-blindness, a family of filters, called joint/guided filters, have attracted a great amount of attention from the community. The main drawback of most joint/guided filters comes from the ignorance of structural inconsistency between the reference and target signals like color, infrared, and depth images captured under different conditions. Simply adopting such guidelines very likely leads to unsatisfactory results. To address the above issues, this paper designs a simple yet effective filter, named mutually guided image filter (muGIF), which jointly preserves mutual structures, avoids misleading from inconsistent structures and smooths flat regions. The proposed muGIF is very flexible, which can work in various modes including dynamic only (self-guided), static/dynamic (reference-guided) and dynamic/dynamic (mutually guided) modes. Although the objective of muGIF is in nature non-convex, by subtly decomposing the objective, we can solve it effectively and efficiently. The advantages of muGIF in effectiveness and flexibility are demonstrated over other state-of-the-art alternatives on a variety of applications. Our code is publicly available at https://sites.google.com/view/xjguo/mugif.	[Guo, Xiaojie] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China; [Yu, Li] Adv Digital Sci Ctr, Singapore 138632, Singapore; [Ma, Jiayi] Wuhan Univ, Elect Informat Sch, Wuhan 430072, Peoples R China; [Ling, Haibin] Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA	Tianjin University; Wuhan University; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University	Guo, XJ (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.	xj.max.guo@gmail.com; liyu@adsc.sg; jyma2010@gmail.com; hbling@temple.edu	Guo, Xiaojie/AAC-3114-2022; Ma, Jiayi/Y-2470-2019	Ma, Jiayi/0000-0003-3264-3265; Ling, Haibin/0000-0003-4094-8413; LI, Yu/0000-0003-1865-8276	NSFC [61773295]; CCF-Tencent Open Research Fund; US NSF [1618398, 1350521]	NSFC(National Natural Science Foundation of China (NSFC)); CCF-Tencent Open Research Fund; US NSF(National Science Foundation (NSF))	We thank Semir Elezovikj for carefully proofreading the manuscript. We also thank the anonymous reviewers for valuable comments and suggestions. X. Guo was supported by NSFC (grant no. 61772512) and CCF-Tencent Open Research Fund. J. Ma was supported by NSFC (grand no. 61773295). H. Ling was supported in part by US NSF (grants 1618398 and 1350521).	Bae SM, 2006, ACM T GRAPHIC, V25, P637, DOI 10.1145/1141911.1141935; Candes EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x; Cao Chen, 2011, P 19 ACM INT C MULT, P1041; Chan SH, 2011, IEEE T IMAGE PROCESS, V20, P3097, DOI 10.1109/TIP.2011.2158229; Chen J, 2007, ACM T GRAPHIC, V26, DOI [10.1109/SARNOF.2007.4567317, 10.1145/1239451.1239554, 10.1145/1276377.1276506]; Daubechies I, 2010, COMMUN PUR APPL MATH, V63, P1, DOI 10.1002/cpa.20303; El Hamidi A, 2010, PATTERN RECOGN, V43, P1564, DOI 10.1016/j.patcog.2009.10.011; Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666; Ferstl D, 2013, IEEE I CONF COMP VIS, P993, DOI 10.1109/ICCV.2013.127; Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964; Gonzalez R.C., 2006, DIGITAL IMAGE PROCES; Guo XJ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1283, DOI 10.1145/3123266.3123378; Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450; Guo XJ, 2015, PROC CVPR IEEE, P3603, DOI 10.1109/CVPR.2015.7298983; Ham B, 2018, IEEE T PATTERN ANAL, V40, P192, DOI 10.1109/TPAMI.2017.2669034; Ham B, 2016, PROC CVPR IEEE, P3475, DOI 10.1109/CVPR.2016.378; He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213; Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156; Hunter DR, 2004, AM STAT, V58, P30, DOI 10.1198/0003130042836; Jian-Guang Lou, 2005, 13th Annual ACM International Conference on Multimedia, P161; Kass M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778837; Khajehnejad MA, 2009, IEEE INT SYMP INFO, P483, DOI 10.1109/ISIT.2009.5205716; Krishnan D, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024211; Lange K, 2000, J COMPUT GRAPH STAT, V9, P1, DOI 10.2307/1390605; Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780; Li Y, 2016, LECT NOTES COMPUT SC, V9907, P717, DOI 10.1007/978-3-319-46487-9_44; Lischinski D, 2006, ACM T GRAPHIC, V25, P646, DOI 10.1145/1141911.1141936; Liu MY, 2013, PROC CVPR IEEE, P169, DOI 10.1109/CVPR.2013.29; Ma ZY, 2013, IEEE I CONF COMP VIS, P49, DOI 10.1109/ICCV.2013.13; Min DB, 2014, IEEE T IMAGE PROCESS, V23, P5638, DOI 10.1109/TIP.2014.2366600; Needell D, 2017, INF INFERENCE, V6, P284, DOI 10.1093/imaiai/iaw023; Park J, 2011, IEEE I CONF COMP VIS, P1623, DOI 10.1109/ICCV.2011.6126423; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777; Revaud J, 2015, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR.2015.7298720; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Shen XY, 2015, IEEE I CONF COMP VIS, P3406, DOI 10.1109/ICCV.2015.389; Shen XY, 2015, IEEE T PATTERN ANAL, V37, P2518, DOI 10.1109/TPAMI.2015.2417569; Szeliski R, 2006, ACM T GRAPHIC, V25, P1135, DOI 10.1145/1141911.1142005; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; van de Weijer J, 2001, PROC CVPR IEEE, P428; Weiss B, 2006, ACM T GRAPHIC, V25, P519, DOI 10.1145/1141911.1141918; Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158; Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208; Yang JY, 2014, IEEE T IMAGE PROCESS, V23, P3443, DOI 10.1109/TIP.2014.2329776; Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70; Zhang Q, 2014, PROC CVPR IEEE, P2830, DOI 10.1109/CVPR.2014.362; Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53; Zhou TH, 2015, PROC CVPR IEEE, P1191, DOI 10.1109/CVPR.2015.7298723	50	37	39	9	53	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2020	42	3					694	707		10.1109/TPAMI.2018.2883553	http://dx.doi.org/10.1109/TPAMI.2018.2883553			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LC5KN	30507494	hybrid			2022-12-18	WOS:000525365300013
J	Yang, B; Rosa, S; Markham, A; Trigoni, N; Wen, HK				Yang, Bo; Rosa, Stefano; Markham, Andrew; Trigoni, Niki; Wen, Hongkai			Dense 3D Object Reconstruction from a Single Depth View	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D Reconstruction; shape completion; shape inpainting; single depth view; adversarial learning; conditional GAN	SHAPE	In this paper, we propose a novel approach, 3D-RecGAN++, which reconstructs the complete 3D structure of a given object from a single arbitrary depth view using generative adversarial networks. Unlike existing work which typically requires multiple views of the same object or class labels to recover the full 3D geometry, the proposed 3D-RecGAN++ only takes the voxel grid representation of a depth view of the object as input, and is able to generate the complete 3D occupancy grid with a high resolution of $\boldsymbol{256<^>3}$2563 by recovering the occluded/missing regions. The key idea is to combine the generative capabilities of 3D encoder-decoder and the conditional adversarial networks framework, to infer accurate and fine-grained 3D structures of objects in high-dimensional voxel space. Extensive experiments on large synthetic datasets and real-world Kinect datasets show that the proposed 3D-RecGAN++ significantly outperforms the state of the art in single view 3D object reconstruction, and is able to reconstruct unseen types of objects.	[Yang, Bo; Rosa, Stefano; Markham, Andrew; Trigoni, Niki] Univ Oxford, Dept Comp Sci, Oxford OX1 2JD, England; [Wen, Hongkai] Univ Warwick, Dept Comp Sci, Coventry CV4 7AL, W Midlands, England	University of Oxford; University of Warwick	Yang, B (corresponding author), Univ Oxford, Dept Comp Sci, Oxford OX1 2JD, England.	bo.yang@cs.ox.ac.uk; stefatio.rosa@cs.ox.ac.uk; andrew.markham@cs.ox.ac.uk; niki.trigoni@cs.ox.ac.uk; hongkai.wen@dcs.warwick.ac.uk	Wen, Hongkai/GLN-4621-2022	Wen, Hongkai/0000-0003-1159-090X; Markham, Andrew/0000-0001-5716-3941; YANG, Bo/0000-0002-2419-4140; ROSA, STEFANO/0000-0001-6458-6344; Trigoni, Niki/0000-0001-6236-9645				Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arjovsky M., 2017, ARXIV170107875; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Bane C, 2017, INT CONF 3D VISION, P412, DOI 10.1109/3DV.2017.00054; Bao JM, 2017, IEEE I CONF COMP VIS, P2764, DOI 10.1109/ICCV.2017.299; Bao SY, 2013, PROC CVPR IEEE, P1264, DOI 10.1109/CVPR.2013.167; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Brock A., 2016, P C NEUR INF PROC SY; Chang Angel X., 2015, ARXIV151203012CSGR P; Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38; Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693; Dame A, 2013, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2013.170; Di XH, 2016, LECT NOTES COMPUT SC, V9915, P251, DOI 10.1007/978-3-319-49409-8_21; Dou P, 2017, PROC CVPR IEEE, P1503, DOI 10.1109/CVPR.2017.164; Engelmann F, 2016, LECT NOTES COMPUT SC, V9796, P219, DOI 10.1007/978-3-319-45886-1_18; Firman M, 2016, PROC CVPR IEEE, P5431, DOI 10.1109/CVPR.2016.586; Gadelha M, 2017, INT CONF 3D VISION, P402, DOI 10.1109/3DV.2017.00053; Girdhar R, 2016, LECT NOTES COMPUT SC, V9910, P484, DOI 10.1007/978-3-319-46466-4_29; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Grant E, 2016, LECT NOTES COMPUT SC, V9915, P266, DOI 10.1007/978-3-319-49409-8_22; Gulrajani I, 2017, P NIPS 2017; Gwak J, 2017, INT CONF 3D VISION, P263, DOI 10.1109/3DV.2017.00038; Han XG, 2017, IEEE I CONF COMP VIS, P85, DOI 10.1109/ICCV.2017.19; Hartley R., 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; Hu Zhiting, 2017, P INT C MACH LEARN; Huang HB, 2015, COMPUT GRAPH FORUM, V34, P25, DOI 10.1111/cgf.12694; Ji MQ, 2017, IEEE I CONF COMP VIS, P2326, DOI 10.1109/ICCV.2017.253; JiajunWu Chengkai Zhang, 2016, ADV NEURAL INFORM PR, V29, DOI DOI 10.5555/3157096.3157106; Johnston A, 2017, IEEE INT CONF COMP V, P930, DOI 10.1109/ICCVW.2017.114; Kar A., 2017, ADV NEURAL INFORM PR; Kar A, 2015, PROC CVPR IEEE, P1966, DOI 10.1109/CVPR.2015.7298807; Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237; Kazhdan Michael, 2006, P EUR S GEOM PROC, V7, P2; Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437; Kim YM, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366157; Kingma D.P, P 3 INT C LEARNING R; Kong C, 2017, PROC CVPR IEEE, P5603, DOI 10.1109/CVPR.2017.594; Kulkarni TD, 2015, ADV NEUR IN, V28; Kurenkov A., 2017, P IEEE WINT C APPL C, P858; Larsen ABL, 2016, PR MACH LEARN RES, V48; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Li YY, 2015, COMPUT GRAPH FORUM, V34, P435, DOI 10.1111/cgf.12573; Lin CY, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P3, DOI 10.1109/ISMAR-Adjunct.2018.00021; Lun ZL, 2017, INT CONF 3D VISION, P67, DOI 10.1109/3DV.2017.00018; Mirza M., 2014, ARXIV; Mitra NJ, 2006, ACM T GRAPHIC, V25, P560, DOI 10.1145/1141911.1141924; MONSZPART A, 2015, J TITLE ACM T GRAPHI, V34, P1, DOI DOI 10.1145/2766995; Mroueh Y, 2017, PR MACH LEARN RES, V70; Murthy J. Krishna, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P724, DOI 10.1109/ICRA.2017.7989089; NAN L., 2012, SIGGRAPH ASIA, V31, P6, DOI DOI 10.1145/2366145; Nealen A., 2006, P 4 INT C COMP GRAPH, P381, DOI DOI 10.1145/1174429.1174494; Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513; Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378; Niessner M, 2013, ACM T GRAPHIC, V32, P1, DOI DOI 10.1145/2508363.2508374; Pauly M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360642; Reed S, 2016, PR MACH LEARN RES, V48; Rezende DJ, 2016, ADV NEUR IN, V29; Riegler G, 2017, INT CONF 3D VISION, P57, DOI 10.1109/3DV.2017.00017; Rock J, 2015, PROC CVPR IEEE, P2484, DOI 10.1109/CVPR.2015.7298863; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Shao TJ, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366155; Sharma A, 2016, LECT NOTES COMPUT SC, V9915, P236, DOI 10.1007/978-3-319-49409-8_20; Shi YF, 2016, COMPUT GRAPH-UK, V55, P55, DOI 10.1016/j.cag.2015.11.003; Sipiran I, 2014, COMPUT GRAPH FORUM, V33, P131, DOI 10.1111/cgf.12481; Smith Edward J., 2017, ABS170709557 CORR; Soltani AA, 2017, PROC CVPR IEEE, P2511, DOI 10.1109/CVPR.2017.269; Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28; Speciale P, 2016, LECT NOTES COMPUT SC, V9912, P313, DOI 10.1007/978-3-319-46484-8_19; Steinbrucker F, 2013, IEEE I CONF COMP VIS, P3264, DOI 10.1109/ICCV.2013.405; Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230; Thrun S, 2005, IEEE I CONF COMP VIS, P1824; Tulsiani S, 2017, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.2017.30; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Varley J, 2017, IEEE INT C INT ROBOT, P2442; Wang WY, 2017, IEEE I CONF COMP VIS, P2317, DOI 10.1109/ICCV.2017.252; Wang Z., 2018, P INT C ROB AUT; Whelan T., 2012, P ROB SCI SYST WORKS; Whelan T, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI; Wu JJ, 2017, ADV NEUR IN, V30; WU ZR, 2015, PROC CVPR IEEE, P1912, DOI DOI 10.1109/CVPR.2015.7298801; Yang B, 2017, IEEE INT CONF COMP V, P679, DOI 10.1109/ICCVW.2017.86; Zhao W, 2007, VISUAL COMPUT, V23, P987, DOI 10.1007/s00371-007-0167-y; Zou CH, 2017, IEEE I CONF COMP VIS, P900, DOI 10.1109/ICCV.2017.103	87	37	43	7	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2019	41	12					2820	2834		10.1109/TPAMI.2018.2868195	http://dx.doi.org/10.1109/TPAMI.2018.2868195			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JQ0XI	30183619	Green Accepted, Green Submitted			2022-12-18	WOS:000498677600003
J	Chen, CH; Patel, VM; Chellappa, R				Chen, Ching-Hui; Patel, Vishal M.; Chellappa, Rama			Learning from Ambiguously Labeled Face Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Ambiguous learning; labeling imbalance; iterative candidate elimination; matrix completion; low-rank matrix recovery	MULTI-LABEL; CLASSIFICATION	Learning a classifier from ambiguously labeled face images is challenging since training images are not always explicitly-labeled. For instance, face images of two persons in a news photo are not explicitly labeled by their names in the caption. We propose a Matrix Completion for Ambiguity Resolution (MCar) method for predicting the actual labels from ambiguously labeled images. This step is followed by learning a standard supervised classifier from the disambiguated labels to classify new images. To prevent the majority labels from dominating the result of MCar, we generalize MCar to a weighted MCar (WMCar) that handles label imbalance. Since WMCar outputs a soft labeling vector of reduced ambiguity for each instance, we can iteratively refine it by feeding it as the input to WMCar. Nevertheless, such an iterative implementation can be affected by the noisy soft labeling vectors, and thus the performance may degrade. Our proposed Iterative Candidate Elimination (ICE) procedure makes the iterative ambiguity resolution possible by gradually eliminating a portion of least likely candidates in ambiguously labeled faces. We further extend MCar to incorporate the labeling constraints among instances when such prior knowledge is available. Compared to existing methods, our approach demonstrates improvements on several ambiguously labeled datasets.	[Chen, Ching-Hui; Chellappa, Rama] Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA; [Patel, Vishal M.] Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08901 USA	University System of Maryland; University of Maryland College Park; Rutgers State University New Brunswick	Chen, CH (corresponding author), Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA.	ching@umiacs.umd.edu; vishal.m.patel@rutgers.edu; rama@umiacs.umd.edu	Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/B-6573-2012		Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA RD Contract [2014-14071600012]	Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA RD Contract	This research is based upon work supported by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA R&D Contract No. 2014-14071600012. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon.	Ambroise C., 2001, APPL STOCH MODEL BUS, V1, P100; Berg T.L., 2005, ADV NEURAL INFORM PR, V17, P137; Berg TL, 2004, PROC CVPR IEEE, P848; Cabral R. S., 2011, ADV NEURAL INFORM PR, P190; Cabral R, 2015, IEEE T PATTERN ANAL, V37, P121, DOI 10.1109/TPAMI.2014.2343234; Cai J. - F., 2004, SIAM J OPTIMIZ, V20, P1956; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Candes EJ, 2008, ANN ALLERTON CONF, P806, DOI 10.1109/ALLERTON.2008.4797640; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Charte F, 2015, NEUROCOMPUTING, V163, P3, DOI 10.1016/j.neucom.2014.08.091; Chen CF, 2012, PROC CVPR IEEE, P2618, DOI 10.1109/CVPR.2012.6247981; Chen CH, 2015, PROC CVPR IEEE, P4110, DOI 10.1109/CVPR.2015.7299038; Chen K, 2006, IEEE IJCNN, P1770; Chen YC, 2014, IEEE T INF FOREN SEC, V9, P2076, DOI 10.1109/TIFS.2014.2359642; Chen YC, 2013, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2013.52; Cid-Sueiro Jesus, 2012, P ADV NEUR INF PROC, P1565; Cour T, 2011, J MACH LEARN RES, V12, P1501; Cour T, 2009, PROC CVPR IEEE, P919, DOI 10.1109/CVPRW.2009.5206667; COVER TM, 1965, IEEE TRANS ELECTRON, VEC14, P326, DOI 10.1109/PGEC.1965.264137; Duchi J., 2008, PROC 25 INT C MACH L, P272; Everingham M., 2006, BMVC, DOI DOI 10.5244/C.20.92; Goldberg A., 2010, P NIPS, V23, P757; Guillaumin M, 2010, LECT NOTES COMPUT SC, V6311, P634, DOI 10.1007/978-3-642-15549-9_46; He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239; Huang D, 2012, LECT NOTES COMPUT SC, V7575, P616, DOI 10.1007/978-3-642-33765-9_44; Huang GB, 2007, IEEE I CONF COMP VIS, P237, DOI 10.1109/iccv.2007.4408858; Hullermeier E, 2006, INTELL DATA ANAL, V10, P419, DOI 10.3233/IDA-2006-10503; Jin R., 2002, ADV NEURAL INFORM PR, P921; Lin Y, 2002, MACH LEARN, V46, P191, DOI 10.1023/A:1012406528296; Lin Z, 2009, UILUENG092215 UIUC; Liu L. - P., 2014, P INT C MACH LEARN; Liu L.P., 2012, ADV NEURAL INF PROCE, V1, P548; Lu B. - L., 2004, P INT JOINT C NEUR N; Luo J., 2010, PROC NEURAL INF PROC, P1504; Sahare M., 2012, INT J ADV COMPUTER R, V2, P160; Shrivastava A, 2015, PATTERN RECOGN, V48, P3283, DOI 10.1016/j.patcog.2014.07.031; VEROPOULOS K, 1999, P INT JOINT C ART IN, P55; Wu B, 2016, AAAI CONF ARTIF INTE, P2229; Xiao SJ, 2015, IEEE T NEUR NET LEAR, V26, P2440, DOI 10.1109/TNNLS.2014.2386307; Zeng ZN, 2013, PROC CVPR IEEE, P708, DOI 10.1109/CVPR.2013.97; Zhang ML, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4041; Zhang ML, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4048; Zhang ML, 2014, P 14 SIAM INT C DAT, P37; Zhang T, 2004, J MACH LEARN RES, V5, P1225; Zhou Zhi-Hua, 2006, ADV NEURAL INFORM PR, P1609	45	37	38	1	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2018	40	7					1653	1667		10.1109/TPAMI.2017.2723401	http://dx.doi.org/10.1109/TPAMI.2017.2723401			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GI3TS	28692963	Green Submitted			2022-12-18	WOS:000434294800009
J	Cho, NG; Yuille, A; Lee, SW				Cho, Nam-Gyu; Yuille, Alan; Lee, Seong-Whan			A Novel Linelet-Based Representation for Line Segment Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Intrinsic properties of digital line; probabilistic line segment representation; line segment validation; image edge detection	HOUGH TRANSFORM	This paper proposes a method for line segment detection in digital images. We propose a novel linelet-based representation to model intrinsic properties of line segments in rasterized image space. Based on this, line segment detection, validation, and aggregation frameworks are constructed. For a numerical evaluation on real images, we propose a new benchmark dataset of real images with annotated lines called YorkUrban-LineSegment. The results show that the proposed method outperforms state-of-the-art methods numerically and visually. To our best knowledge, this is the first report of numerical evaluation of line segment detection on real images.	[Cho, Nam-Gyu; Lee, Seong-Whan] Korea Univ, Dept Brain & Cognit Engn, Seoul 02841, South Korea; [Yuille, Alan] Johns Hopkins Univ, Dept Cognit Sci, Baltimore, MD 21218 USA; [Yuille, Alan] Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA; [Yuille, Alan] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA	Korea University; Johns Hopkins University; Johns Hopkins University; University of California System; University of California Los Angeles	Lee, SW (corresponding author), Korea Univ, Dept Brain & Cognit Engn, Seoul 02841, South Korea.	southq@korea.ac.kr; yuille@stat.ucla.edu; sw.lee@korea.ac.kr		Cho, Nam-Gyu/0000-0001-7591-9220; Yuille, Alan L./0000-0001-5207-9249	Institute for Information & communications Technology Promotion (IITP) - Korea government (MSIP) [2016-0-00152]; US National Science Foundation Expedition in Computing "Visual Cortex on Silicon" [CCF-1317376]	Institute for Information & communications Technology Promotion (IITP) - Korea government (MSIP); US National Science Foundation Expedition in Computing "Visual Cortex on Silicon"(National Science Foundation (NSF))	The authors would like to thank J. Flynn, B. Bonev, and S. Qiao who helped for improving early draft, in particular J. Flynn for many helpful discussions, and V. Nguyen for setting up the annotation system. The authors also thank to reviewers for their critical reviews. This work was supported by Institute for Information & communications Technology Promotion (IITP) grant funded by the Korea government (MSIP) (No. 2016-0-00152, Development of Smart Car Vision Techniques based on Deep Learning for Pedestrian Safety). Partial support was also provided by US National Science Foundation Expedition in Computing "Visual Cortex on Silicon" with award CCF-1317376. All correspondence should be directed to S.-W. Lee.	Akinlar C, 2011, PATTERN RECOGN LETT, V32, P1633, DOI 10.1016/j.patrec.2011.06.001; Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Bradski G, 2000, DR DOBBS J, V25, P120; BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chia AYS, 2012, IEEE T PATTERN ANAL, V34, P1758, DOI 10.1109/TPAMI.2011.220; Coughlan JM, 2003, NEURAL COMPUT, V15, P1063, DOI 10.1162/089976603765202668; De Bock J, 2007, LECT NOTES COMPUT SC, V4418, P579; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Denis P, 2008, LECT NOTES COMPUT SC, V5303, P197, DOI 10.1007/978-3-540-88688-4_15; Desolneux A., 2007, GESTALT THEORY IMAGE, VVolume 34; DORST L, 1984, IEEE T PATTERN ANAL, V6, P450, DOI 10.1109/TPAMI.1984.4767550; Dubska M, 2011, PROC CVPR IEEE, P1489, DOI 10.1109/CVPR.2011.5995501; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70; Guerreiro RFC, 2012, IEEE T IMAGE PROCESS, V21, P4819, DOI 10.1109/TIP.2012.2202673; Hough, 1959, P INT C HIGH EN ACC, V590914, P554; Kanizsa Gaetano, 1979, ORG VISION ESSAYS GE; Lezama J, 2014, PROC CVPR IEEE, P509, DOI 10.1109/CVPR.2014.72; Liu JC, 2014, PROC CVPR IEEE, P3778, DOI 10.1109/CVPR.2014.489; Liu XL, 2015, IEEE T SYST MAN CY-S, V45, P1522, DOI 10.1109/TSMC.2015.2415764; Matas J, 2000, COMPUT VIS IMAGE UND, V78, P119, DOI 10.1006/cviu.1999.0831; Merlet N, 1996, IEEE T PATTERN ANAL, V18, P426, DOI 10.1109/34.491623; Park M, 2011, LECT NOTES COMPUT SC, V6494, P329, DOI 10.1007/978-3-642-19318-7_26; Ramalingam S, 2013, IEEE I CONF COMP VIS, P497, DOI 10.1109/ICCV.2013.67; Shi DM, 2013, IEEE T IMAGE PROCESS, V22, P2500, DOI 10.1109/TIP.2013.2246522; von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300; Xu YL, 2013, PROC CVPR IEEE, P1376, DOI 10.1109/CVPR.2013.181; Yang K, 2011, COMPUT VIS IMAGE UND, V115, P1207, DOI 10.1016/j.cviu.2011.03.010	32	37	42	3	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2018	40	5					1195	1208		10.1109/TPAMI.2017.2703841	http://dx.doi.org/10.1109/TPAMI.2017.2703841			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GB2RB	28504933	hybrid			2022-12-18	WOS:000428901200014
J	Sun, YL; Zhang, M; Sun, ZN; Tan, TN				Sun, Yunlian; Zhang, Man; Sun, Zhenan; Tan, Tieniu			Demographic Analysis from Biometric Data: Achievements, Challenges, and New Frontiers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Demographic estimation; biometrics; human age estimation; gender classification; race recognition	HUMAN AGE ESTIMATION; MULTIMODAL FACIAL GENDER; LOCAL BINARY PATTERNS; SEX IDENTIFICATION; BIOLOGICAL MOTION; FACE RECOGNITION; CLASSIFICATION; GAIT; IMAGE; FRAMEWORK	Biometrics is the technique of automatically recognizing individuals based on their biological or behavioral characteristics. Various biometric traits have been introduced and widely investigated, including fingerprint, iris, face, voice, palmprint, gait and so forth. Apart from identity, biometric data may convey various other personal information, covering affect, age, gender, race, accent, handedness, height, weight, etc. Among these, analysis of demographics (age, gender, and race) has received tremendous attention owing to its wide real-world applications, with significant efforts devoted and great progress achieved. This survey first presents biometric demographic analysis from the standpoint of human perception, then provides a comprehensive overview of state-of-the-art advances in automated estimation from both academia and industry. Despite these advances, a number of challenging issues continue to inhibit its full potential. We second discuss these open problems, and finally provide an outlook into the future of this very active field of research by sharing some promising opportunities.	[Sun, Yunlian; Zhang, Man; Sun, Zhenan; Tan, Tieniu] Chinese Acad Sci, Ctr Res Intelligent Percept & Comp, Natl Lab Pattern Recognit, Inst Automat,CAS Ctr Excellence Brain Sci & Intel, Beijing 100190, Peoples R China; [Sun, Yunlian] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Nanjing University of Science & Technology	Sun, YL (corresponding author), Chinese Acad Sci, Ctr Res Intelligent Percept & Comp, Natl Lab Pattern Recognit, Inst Automat,CAS Ctr Excellence Brain Sci & Intel, Beijing 100190, Peoples R China.	yunlian.sun@nlpr.ia.ac.cn; zhangman@nlpr.ia.ac.cn; znsun@nlpr.ia.ac.cn; tnt@nlpr.ia.ac.cn		Wang, Yunlong/0000-0002-3535-308X	National Key Research and Development Program of China [2016YFB1001000]; National Natural Science Foundation of China [61603391, 61603385]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	We would like to thank the associate editor and anonymous reviewers for their constructive comments and significant efforts spent to help us for further improving the survey. This work was supported in part by the National Key Research and Development Program of China (Grant No. 2016YFB1001000) and the National Natural Science Foundation of China (Grant No. 61603391, 61603385). Man Zhang is the corresponding author.	ABDI H, 1995, PERCEPTION, V24, P539, DOI 10.1068/p240539; Agnihotri AK, 2006, INTERNET J FORENSIC, V2, P1; Ajmera J., 2008, P OD, P025; Alexandre LA, 2010, PATTERN RECOGN LETT, V31, P1422, DOI 10.1016/j.patrec.2010.02.010; Alnajar F, 2012, IMAGE VISION COMPUT, V30, P946, DOI 10.1016/j.imavis.2012.07.009; Amayeh Gholamreza, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563122; [Anonymous], 2002, FG NET AGING DATABAS; [Anonymous], 2010, P 2010 4 IEEE INT C; [Anonymous], 2012, P EUR C COMPUT VIS; [Anonymous], 2014, P EUR C COMPUT VIS; Antipov G, 2016, IEEE COMPUT SOC CONF, P801, DOI 10.1109/CVPRW.2016.105; Antipov G, 2016, PATTERN RECOGN LETT, V70, P59, DOI 10.1016/j.patrec.2015.11.011; Badawi A. M, 2006, P 2006 INT C IM PROC, V6, P41; Balci K, 2002, INT C PATT RECOG, P363, DOI 10.1109/ICPR.2002.1047869; Ballihi L, 2012, IEEE T INF FOREN SEC, V7, P1766, DOI 10.1109/TIFS.2012.2209876; Baluja S, 2007, INT J COMPUT VISION, V71, P111, DOI 10.1007/s11263-006-8910-9; Bandi K. R., 2005, P 12 INT GRAPH SOC C, P133; Bansal A., 2012, 2012 4th International Conference on Computational Intelligence and Communication Networks (CICN 2012), P425, DOI 10.1109/CICN.2012.192; Bansal A., 2014, RES J RECENT SCI, V3, P20; Begg RK, 2005, IEEE T BIO-MED ENG, V52, P828, DOI 10.1109/TBME.2005.845241; Bekios-Calfa J, 2014, PATTERN RECOGN LETT, V36, P228, DOI 10.1016/j.patrec.2013.04.028; Bekios-Calfa J, 2011, IEEE T PATTERN ANAL, V33, P858, DOI 10.1109/TPAMI.2010.208; Bocklet T., 2010, INTERSPEECH, P2830; Bocklet T, 2008, INT CONF ACOUST SPEE, P1605, DOI 10.1109/ICASSP.2008.4517932; Bohannon RW, 1997, AGE AGEING, V26, P15, DOI 10.1093/ageing/26.1.15; Bourdev L, 2011, IEEE I CONF COMP VIS, P1543, DOI 10.1109/ICCV.2011.6126413; BROWN WS, 1991, J VOICE, V5, P310, DOI 10.1016/S0892-1997(05)80061-X; BRUCE V, 1993, PERCEPTION, V22, P131, DOI 10.1068/p220131; Brunelli R., 1992, P DARPA IM UND WORKS, P311; Burkhardt F., 2007, P 8 ANN C INT SPEECH, P2277; Burkhardt F, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1562; Burnsides D, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P393, DOI 10.1109/IM.2001.924485; BURTON AM, 1993, PERCEPTION, V22, P153, DOI 10.1068/p220153; Cao L, 2008, P 16 ACM INT C MULT, P725, DOI DOI 10.1145/1459359.1459470; Chang KY, 2015, IEEE T IMAGE PROCESS, V24, P785, DOI 10.1109/TIP.2014.2387379; Chang KY, 2011, PROC CVPR IEEE, P585, DOI 10.1109/CVPR.2011.5995437; Chao WL, 2013, PATTERN RECOGN, V46, P628, DOI 10.1016/j.patcog.2012.09.011; Chen C, 2011, P AM MATH SOC, V139, P2839, DOI 10.1090/S0002-9939-2011-10718-4; Chen CJ, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P182; Chen K, 2013, PROC CVPR IEEE, P2467, DOI 10.1109/CVPR.2013.319; Chen L, 2009, LECT NOTES COMPUT SC, V5754, P92, DOI 10.1007/978-3-642-04070-2_11; Chen YL, 2013, IEEE T INF FOREN SEC, V8, P2164, DOI 10.1109/TIFS.2013.2286265; Cherniavsky N., 2010, EUR C COMP VIS, P43; Childers D. G., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P603, DOI 10.1109/ICASSP.1988.196657; Choi SE, 2011, PATTERN RECOGN, V44, P1262, DOI 10.1016/j.patcog.2010.12.005; COLEMAN RO, 1971, J SPEECH HEAR RES, V14, P565, DOI 10.1044/jshr.1403.565; Collins Matthew, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1235, DOI 10.1109/ICCVW.2009.5457467; Costen NP, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P201, DOI 10.1109/AFGR.2004.1301531; COTTRELL GW, 1990, P 1990 C ADV NEUR IN, V3, P564; Dantcheva A, 2017, IEEE T INF FOREN SEC, V12, P719, DOI 10.1109/TIFS.2016.2632070; Dantcheva A, 2016, IEEE T INF FOREN SEC, V11, P441, DOI 10.1109/TIFS.2015.2480381; Davis J. W., 2004, P C COMP VIS PATT RE, P9; Davis JW, 2001, LECT NOTES COMPUT SC, V2091, P295; Deng Yubin, 2015, CORR; Dibeklioglu H, 2015, IEEE T IMAGE PROCESS, V24, P1928, DOI 10.1109/TIP.2015.2412377; Ding H., 2013, 2013 10 IEEE INT C W, P1, DOI [10.1109/FG.2013.6553815, DOI 10.1109/FG.2013.6553815]; Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646; Escalera S., 2015, P IEEE INT C COMP VI, P1; Escalera S, 2016, IEEE COMPUT SOC CONF, P706, DOI 10.1109/CVPRW.2016.93; Escalera S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P243, DOI 10.1109/ICCVW.2015.40; Farinella G, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P383, DOI 10.1109/ICIEV.2012.6317383; Fu SY, 2014, IEEE T PATTERN ANAL, V36, P2483, DOI 10.1109/TPAMI.2014.2321570; Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847; Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36; Gallagher Andrew C., 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4562984; Gallagher AC, 2009, PROC CVPR IEEE, P256, DOI 10.1109/CVPRW.2009.5206828; Gao F, 2009, LECT NOTES COMPUT SC, V5558, P132; Gao W, 2009, LECT NOTES COMPUT SC, V5558, P169, DOI 10.1007/978-3-642-01793-3_18; Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733; Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51; Gnanasivam P., 2012, CORR; Golomb B. A., 1990, NIPS, V1, P572; Graf ABA, 2002, LECT NOTES COMPUT SC, V2525, P491; Guo G., 2010, P 2010 IEEE COMPUTER, P71, DOI DOI 10.1109/CVPRW.2010.5543609; GUO G, 2010, IEEE COMP SOC C COMP, P79; Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280; Guo GD, 2014, IMAGE VISION COMPUT, V32, P761, DOI 10.1016/j.imavis.2014.04.011; Guo GD, 2011, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2011.5995404; Guo GD, 2010, LECT NOTES COMPUT SC, V5996, P236; Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681; Gutta S, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P194, DOI 10.1109/AFGR.1998.670948; Gutta S, 2000, IEEE T NEURAL NETWOR, V11, P948, DOI 10.1109/72.857774; Hadid Abdenour, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P52, DOI 10.1007/978-3-642-25446-8_6; Hadid A, 2013, NEUROCOMPUTING, V100, P197, DOI 10.1016/j.neucom.2011.10.040; Hadid A, 2009, PATTERN RECOGN, V42, P2818, DOI 10.1016/j.patcog.2009.02.011; Hamid S, 1996, J SOC PSYCHOL, V136, P778, DOI 10.1080/00224545.1996.9712254; Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759; Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38; Han X, 2009, 2009 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P114, DOI 10.1109/CW.2009.41; Hassaine A, 2013, PROC INT CONF DOC, P1417, DOI 10.1109/ICDAR.2013.286; HIMANN JE, 1988, MED SCI SPORT EXER, V20, P161, DOI 10.1249/00005768-198820020-00010; Hosoi S, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P195, DOI 10.1109/AFGR.2004.1301530; Hu MD, 2011, IEEE T SYST MAN CY B, V41, P1429, DOI 10.1109/TSMCB.2011.2149518; Hu ZZ, 2017, IEEE T IMAGE PROCESS, V26, P3087, DOI 10.1109/TIP.2016.2633868; Huang D, 2014, IMAGE VISION COMPUT, V32, P1181, DOI 10.1016/j.imavis.2014.06.009; Huang G.B., 2007, 07 UMASS TR, V49, P1; Huang GC, 2007, LECT NOTES COMPUT SC, V4843, P462; Huang T., 2006, P IEEE INT C SIGN PR, V1; Hui Fang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P593, DOI 10.1109/ICPR.2010.150; Huynh T., 2012, P AS C COMP VIS, V7728, P133, DOI [10.1007/978-3-642-37410-412, DOI 10.1007/978-3-642-37410-412]; Jabid Taskeed, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2162, DOI 10.1109/ICPR.2010.373; Jain A, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P159, DOI 10.1109/AFGR.2004.1301524; Jain A. K., 2011, INTRO BIOMETRICS; Jain AK, 2004, LECT NOTES COMPUT SC, V3072, P731; Jain AK, 2016, PATTERN RECOGN LETT, V79, P80, DOI 10.1016/j.patrec.2015.12.013; Jia S, 2015, PATTERN RECOGN LETT, V58, P35, DOI 10.1016/j.patrec.2015.02.006; Juefei-Xu F., 2016, CVPR, P68; Khorsandi R, 2013, IEEE WORK APP COMP, P461, DOI 10.1109/WACV.2013.6475055; Kim HC, 2006, PATTERN RECOGN LETT, V27, P618, DOI 10.1016/j.patrec.2005.09.027; Kockmann M., 2010, P INTERSPEECH, P2822; KOZLOWSKI LT, 1977, PERCEPT PSYCHOPHYS, V21, P575, DOI 10.3758/BF03198740; Kumar N, 2008, LECT NOTES COMPUT SC, V5305, P340, DOI 10.1007/978-3-540-88693-8_25; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; KWON YH, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P762, DOI 10.1109/CVPR.1994.323894; Lagree S., 2011, P IEEE INT C TECHN H; Lagree S., 2011, P 22 MIDW ART INT CO, P225; Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091; Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553; Lapedriza A, 2006, INT C PATT RECOG, P834; LASS NJ, 1976, J ACOUST SOC AM, V59, P675, DOI 10.1121/1.380917; Layne R, 2012, LECT NOTES COMPUT SC, V7583, P402, DOI 10.1007/978-3-642-33863-2_40; Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148; Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406; Lei J., 2013, 2013 INT C BIOM ICB, P1; Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352; Li CS, 2012, PROC CVPR IEEE, P2570, DOI 10.1109/CVPR.2012.6247975; Li M., 2010, INTERSPEECH, P2826; Li XO, 2010, PROC CVPR IEEE, P2590, DOI 10.1109/CVPR.2010.5539969; Li XL, 2008, IEEE T SYST MAN CY C, V38, P145, DOI 10.1109/TSMCC.2007.913886; Lian HC, 2006, LECT NOTES COMPUT SC, V3972, P202; Lingenfelser F., 2010, INTERSPEECH, P2798; LINVILLE SE, 1985, J ACOUST SOC AM, V78, P40, DOI 10.1121/1.392452; Liu JY, 2014, SIGNAL PROCESS, V94, P576, DOI 10.1016/j.sigpro.2013.07.025; Liu X, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P258, DOI 10.1109/ICCVW.2015.42; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Liwicki M, 2007, P 13 C GRAPH SOC, P179; Lu JW, 2014, IEEE T INF FOREN SEC, V9, P51, DOI 10.1109/TIFS.2013.2291969; Lu JW, 2013, IEEE T HUM-MACH SYST, V43, P249, DOI 10.1109/TSMCC.2012.2192727; Lu JW, 2010, IEEE T INF FOREN SEC, V5, P761, DOI 10.1109/TIFS.2010.2069560; Lu JW, 2010, PATTERN RECOGN LETT, V31, P382, DOI 10.1016/j.patrec.2009.11.006; Lu X., 2002, P INT SOC OPT PHOT, P114; Lu XG, 2006, LECT NOTES COMPUT SC, V3832, P554; Luu K, 2009, 2009 IEEE 3 INT C BI, P1, DOI DOI 10.1109/BTAS.2009.5339053; Luu K., 2011, IJCB, P1; Lyle J. R., 2010, BIOM THEOR APPL SYST, P1; Lyle JR, 2012, PATTERN RECOGN, V45, P3877, DOI 10.1016/j.patcog.2012.04.027; Lyons M. J., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P202, DOI 10.1109/AFGR.2000.840635; Makihara Yasushi, 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P440, DOI 10.1007/978-3-642-19309-5_34; Makihara Y., 2011, P IEEE INT JOINT C B, P1, DOI [10.1109/IJCB.2011.6117531, DOI 10.1109/IJCB.2011.6117531]; Maekinen E, 2008, PATTERN RECOGN LETT, V29, P1544, DOI 10.1016/j.patrec.2008.03.016; Makinen E, 2008, IEEE T PATTERN ANAL, V30, P541, DOI 10.1109/TPAMI.2007.70800; Maodi Hu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3679, DOI 10.1109/ICPR.2010.897; Marcel S, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6524-8; MARK LS, 1980, PERCEPT PSYCHOPHYS, V27, P117, DOI 10.3758/BF03204298; Martin-Felez Raul, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3810, DOI 10.1109/ICPR.2010.928; MATHER G, 1994, P ROY SOC B-BIOL SCI, V258, P273, DOI 10.1098/rspb.1994.0173; Meinedo H., 2010, INTERSPEECH, P2818; Menz HB, 2003, AGE AGEING, V32, P137, DOI 10.1093/ageing/32.2.137; Metze F, 2007, INT CONF ACOUST SPEE, P1089; Minematsu N, 2002, INT CONF ACOUST SPEE, P137; Moghaddam B., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P306, DOI 10.1109/AFGR.2000.840651; Montilla A, 2009, IEEE IMAGE PROC, P2465, DOI 10.1109/ICIP.2009.5414103; Muller C., 2003, P 8 EUR C SPEECH COM, P1305; Munoz-Cachon MJ, 2007, COLLEGIUM ANTROPOL, V31, P963; Ng C. B., 2012, CORR; Ngan M., 2014, 7995 NIST; Ni B., 2009, P ACM INT C MULT, P58; Nixon MS, 2015, PATTERN RECOGN LETT, V68, P218, DOI 10.1016/j.patrec.2015.08.006; Ocegueda O, 2013, IEEE T PATTERN ANAL, V35, P728, DOI 10.1109/TPAMI.2012.126; Oren M, 1997, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.1997.609319; Oskuie FB, 2011, LECT NOTES COMPUT SC, V6754, P161, DOI 10.1007/978-3-642-21596-4_17; OToole AJ, 1997, PERCEPTION, V26, P75, DOI 10.1068/p260075; Parris ES, 1996, INT CONF ACOUST SPEE, P685, DOI 10.1109/ICASSP.1996.543213; Phillips PJ, 2005, PROC CVPR IEEE, P947; Proenca H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66; PTACEK PH, 1966, J SPEECH HEAR RES, V9, P273, DOI 10.1044/jshr.0902.273; Qiu X., 2007, P IEEE INT C IM PROC; Qiu XC, 2006, LECT NOTES COMPUT SC, V3832, P411; Ramanathan N., 2006, P IEEE COMP SOC C CO, P387, DOI DOI 10.1109/CVPR.2006.187; Ranjan R., 2016, CORR; Rattani A., 2014, EUROPEAN C COMPUTER, P764; Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341; Roomi S. M. M., 2011, Proceedings of the 2011 Third National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG 2011), P54, DOI 10.1109/NCVPRIPG.2011.19; Ross Arun, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P1221; Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3; Saatci Y, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P393; Samal A, 2007, J VIS COMMUN IMAGE R, V18, P453, DOI 10.1016/j.jvcir.2007.04.010; Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39; Schapire R. E., 1995, COMPUTATIONAL LEARNI, P23, DOI DOI 10.1007/3-540-59119-2_166; Schuller B., 2010, P ANN C INT SPEECH C, V2010, P2795; Schuller B, 2013, COMPUT SPEECH LANG, V27, P4, DOI 10.1016/j.csl.2012.02.005; Shafran I, 2003, ASRU'03: 2003 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING ASRU '03, P31, DOI 10.1109/ASRU.2003.1318399; Shakhnarovich G, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P16, DOI 10.1109/AFGR.2002.1004124; Shan CF, 2008, NEUROCOMPUTING, V71, P1931, DOI 10.1016/j.neucom.2007.09.023; Shan CF, 2012, PATTERN RECOGN LETT, V33, P431, DOI 10.1016/j.patrec.2011.05.016; Sheldon W. H., 1940, VARIETIES HUMAN PHYS, V1; Shue YL, 2008, INT CONF ACOUST SPEE, P4493; Song Z, 2011, IEEE I CONF COMP VIS, P241, DOI 10.1109/ICCV.2011.6126248; Stone A., 2010, AGING PROCESS FACE T; Sun ZH, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P165, DOI 10.1109/ACV.2002.1182176; Sun ZN, 2014, IEEE T PATTERN ANAL, V36, P1120, DOI 10.1109/TPAMI.2013.234; Tamura S, 1996, PATTERN RECOGN, V29, P331, DOI 10.1016/0031-3203(95)00073-9; Tang JS, 2011, IEEE T SYST MAN CY C, V41, P898, DOI 10.1109/TSMCC.2011.2104950; Tapia JE, 2016, IEEE T INF FOREN SEC, V11, P1771, DOI 10.1109/TIFS.2016.2550418; Tapia JE, 2015, LECT NOTES COMPUT SC, V8926, P751, DOI 10.1007/978-3-319-16181-5_57; Tariq U, 2009, IEEE IMAGE PROC, P2441, DOI 10.1109/ICIP.2009.5414117; Thomas VM, 2007, IEEE INT SYMP ELECTR, P180, DOI 10.1109/ISEE.2007.369390; Thukral P, 2012, INT CONF ACOUST SPEE, P1529, DOI 10.1109/ICASSP.2012.6288182; TITZE IR, 1989, J ACOUST SOC AM, V85, P1699, DOI 10.1121/1.397959; Toderici G, 2010, INT J COMPUT VISION, V89, P382, DOI 10.1007/s11263-009-0300-7; Toews M, 2009, IEEE T PATTERN ANAL, V31, P1567, DOI 10.1109/TPAMI.2008.233; Tomai C. I., 2003, Proceedings of the SPIE - The International Society for Optical Engineering, V5296, P116, DOI 10.1117/12.527276; TRAURING M, 1963, NATURE, V197, P938, DOI 10.1038/197938a0; Troje NF, 2002, J VISION, V2, P371, DOI 10.1167/2.5.2; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Verma M, 2009, ADV SOFT COMP, V53, P251; Walavalkar L, 2003, INT J PATTERN RECOGN, V17, P417, DOI 10.1142/S0218001403002447; Wang XL, 2015, IEEE WINT CONF APPL, P534, DOI 10.1109/WACV.2015.77; Wang Y. X., 2016, ARXIV161200991; WILCOX KA, 1980, J GERONTOL, V35, P194, DOI 10.1093/geronj/35.2.194; Wiskott L., 1995, INT WORKSH AUT FAC G, P92; Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566; Wolters M, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P1435; Wu B, 2003, LECT NOTES COMPUT SC, V2688, P104; Wu J, 2010, IMAGE VISION COMPUT, V28, P1039, DOI 10.1016/j.imavis.2009.09.003; Wuhrer Stefanie, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P33, DOI 10.1109/CVPR.2009.5204295; Xia B., 2014, P COMP VIS ECCV 2014, P697; Xiao B, 2009, P 17 ACM INT C MULT, P451, DOI DOI 10.1145/1631272.1631334; Xiaolong Wang, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163119; Xing E., 2002, ADV NEURAL INFORM PR, V15, P505, DOI DOI 10.5555/2968618.2968683; Xu K., 2015, ICML, V14, P77; Yan P., 2005, P 2005 IEEE COMPUTER, P41, DOI [DOI 10.1109/CVPR.2005.450, 10.1109/CVPR.2005.450]; Yan S., 2007, P IEEE INT C COMP VI, P1; Yan S, 2008, PR IEEE COMP DESIGN, P142, DOI 10.1109/ICCD.2008.4751853; Yan SC, 2008, INT CONF ACOUST SPEE, P737; Yang M, 2011, PROC CVPR IEEE, P505, DOI 10.1109/CVPR.2011.5995481; Yang X., 2015, P IEEE INT C COMP VI, P102; Yang ZG, 2007, LECT NOTES COMPUT SC, V4642, P464; Yang ZG, 2006, INT C PATT RECOG, P1099; Yi D., 2014, P AS C COMP VIS, P144, DOI DOI 10.1007/978-3-319-16811-110; Yiting Xie, 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P143, DOI 10.1109/BTAS.2012.6374569; Yoo JH, 2005, LECT NOTES COMPUT SC, V3708, P138; Yu SQ, 2006, INT C PATT RECOG, P441; Yu SQ, 2009, IEEE T IMAGE PROCESS, V18, P1905, DOI 10.1109/TIP.2009.2020535; Zarei A, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 1, P514, DOI 10.1109/ICMLA.2012.94; Zhang G, 2011, INT JOINT C BIOM IEE, P1, DOI [10.1109/IJCB.2011.6117590., DOI 10.1109/IJCB.2011.6117590]; Zhang H, 2011, LECT NOTES COMPUT SC, V7098, P82, DOI 10.1007/978-3-642-25449-9_11; Zhang K, 2016, IEEE C COMPUTER VISI, P34; Zhong C, 2009, LECT NOTES COMPUT SC, V5558, P386, DOI 10.1007/978-3-642-01793-3_40; Zhou SHK, 2005, IEEE I CONF COMP VIS, P541; Zhu JQ, 2015, INT CONF BIOMETR, P535, DOI 10.1109/ICB.2015.7139070; Zhu JQ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P331, DOI 10.1109/ICCVW.2013.51; Zhu Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P267, DOI 10.1109/ICCVW.2015.43; Zhuang X., 2008, P 19 INT C PATT REC, P1	254	37	37	2	38	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2018	40	2					332	351		10.1109/TPAMI.2017.2669035	http://dx.doi.org/10.1109/TPAMI.2017.2669035			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	FS9AN	28212078				2022-12-18	WOS:000422706000006
J	Rodrigues, F; Lourenco, M; Ribeiro, B; Pereira, FC				Rodrigues, Filipe; Lourenco, Mariana; Ribeiro, Bernardete; Pereira, Francisco C.			Learning Supervised Topic Models for Classification and Regression from Crowds	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Topic models; crowdsoucing; multiple annotators; supervised learning	MULTIPLE ANNOTATORS	The growing need to analyze large collections of documents has led to great developments in topic modeling. Since documents are frequently associated with other related variables, such as labels or ratings, much interest has been placed on supervised topic models. However, the nature of most annotation tasks, prone to ambiguity and noise, often with high volumes of documents, deem learning under a single-annotator assumption unrealistic or unpractical for most real-world applications. In this article, we propose two supervised topic models, one for classification and another for regression problems, which account for the heterogeneity and biases among different annotators that are encountered in practice when learning from crowds. We develop an efficient stochastic variational inference algorithm that is able to scale to very large datasets, and we empirically demonstrate the advantages of the proposed model over state-of-the-art approaches.	[Rodrigues, Filipe; Pereira, Francisco C.] Tech Univ Denmark DTU, Bygning 115, DK-2800 Lyngby, Denmark; [Lourenco, Mariana; Ribeiro, Bernardete] Univ Coimbra, Dept Informat Engn, CISUC, P-3000213 Coimbra, Portugal; [Pereira, Francisco C.] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA	Technical University of Denmark; Universidade de Coimbra; Massachusetts Institute of Technology (MIT)	Rodrigues, F (corresponding author), Tech Univ Denmark DTU, Bygning 115, DK-2800 Lyngby, Denmark.	fmpr@dei.uc.pt; mrlouren@student.dei.uc.pt; bribeiro@dei.uc.pt; camara@transport.dtu.dk	Ribeiro, Bernardete/A-8010-2016; Rodrigues, Filipe/H-8695-2019; Pereira, Francisco Camara/B-2111-2010	Ribeiro, Bernardete/0000-0002-9770-7672; Rodrigues, Filipe/0000-0001-6979-6498; Pereira, Francisco Camara/0000-0001-5457-9909	Fundacao para a Ciencia e Tecnologia (FCT) [SFRH/BD/78396/2011, PTDC/ECM-TRA/1898/2012]	Fundacao para a Ciencia e Tecnologia (FCT)(Portuguese Foundation for Science and TechnologyEuropean Commission)	The Fundacao para a Ciencia e Tecnologia (FCT) is gratefully acknowledged for founding this work with the grants SFRH/BD/78396/2011 and PTDC/ECM-TRA/1898/2012 (InfoCROWDS).	Airoldi EM, 2007, LECT NOTES COMPUT SC, V4503, P57; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517; Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPRW.2009.5206800, 10.1109/CVPR.2009.5206800]; Chuang Jason, 2013, P 30 INT C MACH LEAR, P612; Dawid A.P., 1979, APPL STAT, V28, P20, DOI [10.2307/2346806, DOI 10.2307/2346806]; Erosheva EA, 2007, ANN APPL STAT, V1, P502, DOI 10.1214/07-AOAS126; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Groot P, 2011, LECT NOTES COMPUT SC, V6792, P159, DOI 10.1007/978-3-642-21738-8_21; Hoffman MD, 2013, J MACH LEARN RES, V14, P1303; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Lacoste-Julien S, 2009, ADV NEURAL INFORM PR, P897, DOI DOI 10.1007/S10618-010-0175-9; Lang K., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P331; Lewis D. D, 1997, REUTERS 21578 TEXT C; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Maua D., 2009, REPRESENTING CLASSIF; Mcauliffe Jon D., 2008, P ADV NEURAL INFORM, P121; Mimno D.M., 2008, UAI 2008 P 24 C UNCE, P411; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Pang B., 2005, P 43 ANN M ASS COMP, V43, P115, DOI DOI 10.3115/1219840.1219855; PeterWelinder Steve Branson, 2010, P NIPS, V23, P1; Rabinovich M, 2014, PR MACH LEARN RES, V32; Ramage D., 2009, P 2009 C EMP METH NA, V1, P248, DOI DOI 10.3115/1699510.1699543; Raykar VC, 2010, J MACH LEARN RES, V11, P1297; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; Rodrigues F., 2015, P 3 AAAI C HUM COMP; Rodrigues F, 2014, PR MACH LEARN RES, V32, P433; Rodrigues F, 2013, PATTERN RECOGN LETT, V34, P1428, DOI 10.1016/j.patrec.2013.05.012; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Smyth P., 1995, Advances in Neural Information Processing Systems 7, P1085; Snow Rion, 2008, P 2008 C EMP METH NA, P254, DOI DOI 10.3115/1613715.1613751; Taddy M, 2013, J AM STAT ASSOC, V108, P755, DOI 10.1080/01621459.2012.734168; Yan Y., 2010, PMLR P MACHINE LEARN, V9, P932; Yan Y, 2014, MACH LEARN, V95, P291, DOI 10.1007/s10994-013-5412-1; Zhu J, 2012, J MACH LEARN RES, V13, P2237	36	37	39	1	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2017	39	12					2409	2422		10.1109/TPAMI.2017.2648786	http://dx.doi.org/10.1109/TPAMI.2017.2648786			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL6ZQ	28103190	Green Published, Green Submitted			2022-12-18	WOS:000414395400007
J	Majumdar, A; Singh, R; Vatsa, M				Majumdar, Angshul; Singh, Richa; Vatsa, Mayank			Face Verification via Class Sparsity Based Supervised Encoding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face verification; deep learning; supervised feature learning; autoencoders	RECOGNITION; REPRESENTATION; ALGORITHMS	Autoencoders are deep learning architectures that learn feature representation by minimizing the reconstruction error. Using an autoencoder as baseline, this paper presents a novel formulation for a class sparsity based supervised encoder, termed as CSSE. We postulate that features from the same class will have a common sparsity pattern/support in the latent space. Therefore, in the formulation of the autoencoder, a supervision penalty is introduced as a joint-sparsity promoting l(2,1)-norm. The formulation of CSSE is derived for a single hidden layer and it is applied for multiple hidden layers using a greedy layer-by-layer learning approach. The proposed CSSE approach is applied for learning face representation and verification experiments are performed on the LFW and PaSC face databases. The experiments show that the proposed approach yields improved results compared to autoencoders and comparable results with state-of-the-art face recognition algorithms.	[Majumdar, Angshul; Singh, Richa; Vatsa, Mayank] IIIT Delhi, New Delhi, India	Indraprastha Institute of Information Technology Delhi	Majumdar, A (corresponding author), IIIT Delhi, New Delhi, India.	angshul@iiitd.ac.in; rsingh@iiitd.ac.in; mayank@iiitd.ac.in	Vatsa, Mayank/I-5050-2013; Vatsa, Mayank/AAR-7199-2020; Singh, Richa/M-9961-2017	Vatsa, Mayank/0000-0001-5952-2274; Vatsa, Mayank/0000-0001-5952-2274; Singh, Richa/0000-0003-4060-4573	Department of Electronics and Information Technology, Government of India	Department of Electronics and Information Technology, Government of India	Equal contributions by all the authors. Research by M. Vatsa and R. Singh is partly supported through a grant from Department of Electronics and Information Technology, Government of India.	Amos B., OPENFACE FACE RECOGN; [Anonymous], 1998, TECH REP; BALDI P, 1989, NEURAL NETWORKS, V2, P53, DOI 10.1016/0893-6080(89)90014-2; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Beveridge J. R., 2013, BIOM THEOR APPL SYST, P1, DOI DOI 10.1109/BTAS.2013.6712704; Bharadwaj S, 2016, IEEE T INF FOREN SEC, V11, P1630, DOI 10.1109/TIFS.2016.2538744; Bhatt HS, 2013, IEEE T INF FOREN SEC, V8, P89, DOI 10.1109/TIFS.2012.2223684; Blumensath T, 2013, IEEE T INFORM THEORY, V59, P3466, DOI 10.1109/TIT.2013.2245716; Chen M., 2012, 29 INT C MACH LEARN; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S1064827596304010; Cho K., 2013, P INT C MACH LEARN, P432; Das P, 2014, IEEE INT SYMP SIGNAL, P327, DOI 10.1109/ISSPIT.2014.7300609; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Dhamecha TI, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099212; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Gao SH, 2015, IEEE T INF FOREN SEC, V10, P2108, DOI 10.1109/TIFS.2015.2446438; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Goldfarb D, 2011, FOUND COMPUT MATH, V11, P183, DOI 10.1007/s10208-011-9084-6; Goswami G, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014); Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; HASSNER T, 2015, PROC CVPR IEEE, P4295, DOI DOI 10.1109/CVPR.2015.7299058; Hayat M, 2015, IEEE T PATTERN ANAL, V37, P713, DOI 10.1109/TPAMI.2014.2353635; Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242; Huang G.B., 2008, WORKSHOP FACESREAL L; Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469; Kan M, 2014, PROC CVPR IEEE, P1883, DOI 10.1109/CVPR.2014.243; Kavukcuoglu K, 2009, PROC CVPR IEEE, P1605, DOI 10.1109/CVPRW.2009.5206545; Kim M, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.1093; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Larochelle H, 2012, J MACH LEARN RES, V13, P643; Lee H., 2009, P ANN INT C MACH LEA, P609; Lee Honglak, 2008, ADV NEURAL INFORM PR, V20; Li S.Z., 2005, HDB FACE RECOGNITION; Lilei Zheng, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163085; Lu C, 2015, AAAI CONF ARTIF INTE, P3811; Lu JW, 2015, IEEE T INF FOREN SEC, V10, P1371, DOI 10.1109/TIFS.2015.2408431; Ma SQ, 2011, MATH PROGRAM, V128, P321, DOI 10.1007/s10107-009-0306-5; Majumdar A, 2012, INT CONF ACOUST SPEE, P3421, DOI 10.1109/ICASSP.2012.6288651; NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Rifai S., 2011, PROC INT C MACH LEAR; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Selesnick I. W., 2009, P SOC PHOTO-OPT INS, V7446, P74; Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093; Sun Y., 2014, ADV NEURAL INFORM PR, P1988; Sun Y, 2015, ARXIV150200873; Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907; Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tibshirani R, 2011, J R STAT SOC B, V73, P273, DOI 10.1111/j.1467-9868.2011.00771.x; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566; XIE J., 2012, P ADV NEURAL INFORM, P350; Zhang L, 2012, IEEE T SIGNAL PROCES, V60, P1684, DOI 10.1109/TSP.2011.2179539; Zhu Z., 2014, NIPS, P217	59	37	37	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2017	39	6					1273	1280		10.1109/TPAMI.2016.2569436	http://dx.doi.org/10.1109/TPAMI.2016.2569436			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EU5RR	27214891				2022-12-18	WOS:000401091200016
J	Patraucean, V; Gurdjos, P; von Gioi, RG				Patraucean, Viorica; Gurdjos, Pierre; von Gioi, Rafael Grompone			Joint A Contrario Ellipse and Line Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Ellipse detection; line segment detection; a contrario theory; model selection	HOUGH TRANSFORM; SEGMENTATION; IMAGES	Wepropose a line segment and elliptical arc detector that produces a reduced number of false detections on various types of images without any parameter tuning. For a given region of pixels in a grey-scale image, the detector decides whether a line segment or an elliptical arc is present (model validation). If both interpretations are possible for the same region, the detector chooses the one that best explains the data (model selection). Wedescribe a statistical criterion based on the a contrario theory, which serves for both validation and model selection. The experimental results highlight the performance of the proposed approach compared to state-of-the-art detectors, when applied on synthetic and real images.	[Patraucean, Viorica] Univ Cambridge, Dept Engn, Cambridge CB2 1TN, England; [Gurdjos, Pierre] IRIT ENSEEIHT, Toulouse, Midi Pyrenees, France; [von Gioi, Rafael Grompone] CMLA ENS Cachan, F-94235 Cachan, France	University of Cambridge; Universite Federale Toulouse Midi-Pyrenees (ComUE); Universite de Toulouse; Institut National Polytechnique de Toulouse; UDICE-French Research Universities; Universite Paris Saclay	Patraucean, V (corresponding author), Univ Cambridge, Dept Engn, Cambridge CB2 1TN, England.	vp344@cam.ac.uk; Pierre.Gurdjos@enseeiht.fr; grompone@cmla.ens-cachan.fr			Qualcomm postdoctoral program at Ecole Polytechnique Palaiseau; Google Faculty Research Award; Marie Curie grant [WCIG334283-HRGP]; NRS chaire d'excellence and chaire Jean Marjoulet; EPSRC [EP/L010917/1]; Engineering and Physical Sciences Research Council [EP/L010917/1] Funding Source: researchfish	Qualcomm postdoctoral program at Ecole Polytechnique Palaiseau; Google Faculty Research Award(Google Incorporated); Marie Curie grant(European Commission); NRS chaire d'excellence and chaire Jean Marjoulet; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was partially funded by the Qualcomm postdoctoral program at Ecole Polytechnique Palaiseau, a Google Faculty Research Award, the Marie Curie granWCIG334283-HRGP, a CNRS chaire d'excellence and chaire Jean Marjoulet, and EPSRC grant EP/L010917/1.	[Anonymous], 1985, PERCEPTUAL ORG VISUA; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Barinova O, 2010, PROC CVPR IEEE, P2233, DOI 10.1109/CVPR.2010.5539905; Bonci A, 2005, IEEE T SYST MAN CY A, V35, P945, DOI 10.1109/TSMCA.2005.853481; Bradski G., 2000, DOBBS J SOFTW TOOLS; BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808; Cam L.L., 1986, STAT SCI, V1, P78, DOI [10.1214/ss/1177013818, DOI 10.1214/SS/1177013818, DOI 10.1214/ss/1177013818]; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chia AYS, 2011, IEEE T IMAGE PROCESS, V20, P1991, DOI 10.1109/TIP.2010.2099127; Dahyot R, 2009, IEEE T PATTERN ANAL, V31, P1502, DOI 10.1109/TPAMI.2008.288; Desolneux A, 2000, INT J COMPUT VISION, V40, P7, DOI 10.1023/A:1026593302236; Desolneux A., 2007, GESTALT THEORY IMAGE, VVolume 34; Duda R.O., 2000, PATTERN CLASSIFICATI; ETEMADI A, 1992, IEE CONF PUBL, V354, P311; Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658; Galamhos C., 1999, P IEEE INT C COMP VI; Gordon A, 2007, ANN APPL STAT, V1, P179, DOI 10.1214/07-AOAS102; Goulermas JY, 1999, PATTERN ANAL APPL, V2, P239, DOI 10.1007/s100440050032; Heikkila J, 2000, IEEE T PATTERN ANAL, V22, P1066, DOI 10.1109/34.879788; Higuchi M., 1962, METHOD MEANS RECOGNI; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242; Igual L, 2007, INVERSE PROBL IMAG, V1, P319; Isack H, 2012, INT J COMPUT VISION, V97, P123, DOI 10.1007/s11263-011-0474-7; Ji Q, 2001, PATTERN RECOGN LETT, V22, P813, DOI 10.1016/S0167-8655(01)00026-5; Johnson NS, 1995, CONTINUOUS UNIVARIAT, V1-2; Kanatani K, 1997, IEEE T PATTERN ANAL, V19, P1391, DOI 10.1109/34.643901; Lehmann E., 2005, TESTING STAT HYPOTHE, V3rd; LI HW, 1986, COMPUT VISION GRAPH, V36, P139, DOI 10.1016/0734-189X(86)90073-3; Mai F., 2007, P IEEE INT C IM PROC, P345; Moisan L, 2004, INT J COMPUT VISION, V57, P201, DOI 10.1023/B:VISI.0000013094.38752.54; Moisan L, 2012, IMAGE PROCESS ON LIN, V2, P56, DOI 10.5201/ipol.2012.mmm-oh; Myaskouvskey A, 2013, INT J COMPUT VISION, V101, P22, DOI 10.1007/s11263-012-0543-6; Patraucean V., 2012, DETECTION IDENTIFICA; Patraucean V, 2013, IEEE COMPUT SOC CONF, P211, DOI 10.1109/CVPRW.2013.38; Patraucean V, 2012, LECT NOTES COMPUT SC, V7573, P572, DOI 10.1007/978-3-642-33709-3_41; Perrin G., 2005, P INT C IMAG PROC, V1, P661, DOI DOI 10.1109/ICIP.2005.1529837; Prasad DK, 2012, PATTERN RECOGN, V45, P3204, DOI 10.1016/j.patcog.2012.02.014; Press W.H., 2007, NUMERICAL RECIPES; Rabin J, 2009, SIAM J IMAGING SCI, V2, P931, DOI 10.1137/090751359; Rosin PL, 1998, GRAPH MODEL IM PROC, V60, P209, DOI 10.1006/gmip.1998.0471; RUST RT, 1995, MANAGE SCI, V41, P322, DOI 10.1287/mnsc.41.2.322; Smith P., 2006, P BRIT MACH VIS C, V1, P17; Soetedjo A, 2005, IEEE SYS MAN CYBERN, P1341; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; Thomas G, 2007, J REAL-TIME IMAGE PR, V2, P117, DOI 10.1007/s11554-007-0041-1; von Gioi RG, 2012, IMAGE PROCESS ON LIN, V2, P35, DOI 10.5201/ipol.2012.gjmr-lsd; von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300; Gioi RG, 2009, J PHYSIOLOGY-PARIS, V103, P4, DOI 10.1016/j.jphysparis.2009.05.002; VonGioi RC, 2014, SPRINGERBRIEF COMPUT, P1, DOI 10.1007/978-1-4939-0575-1; West G. A. W., 1992, BMVC92. Proceedings of the British Machine Vision Conference, P197; XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z	52	37	39	0	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2017	39	4					788	802		10.1109/TPAMI.2016.2558150	http://dx.doi.org/10.1109/TPAMI.2016.2558150			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EP9UD	28278450				2022-12-18	WOS:000397717600014
J	Wang, B; Wang, G; Chan, KL; Wang, L				Wang, Bing; Wang, Gang; Chan, Kap Luk; Wang, Li			Tracklet Association by Online Target-Specific Metric Learning and Coherent Dynamics Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-object tracking; tracklet association; target-specific metric learning; motion dynamics; network flow optimization	MULTIOBJECT TRACKING; MULTITARGET TRACKING; CRF MODEL; APPEARANCE; MULTIPLE	In this paper, we present a novel method based on online target-specific metric learning and coherent dynamics estimation for tracklet (track fragment) association by network flow optimization in long-term multi-person tracking. Our proposed framework aims to exploit appearance and motion cues to prevent identity switches during tracking and to recover missed detections. Furthermore, target-specific metrics (appearance cue) and motion dynamics (motion cue) are proposed to be learned and estimated online, i.e., during the tracking process. Our approach is effective even when such cues fail to identify or follow the target due to occlusions or object-to-object interactions. We also propose to learn the weights of these two tracking cues to handle the difficult situations, such as severe occlusions and object-to-object interactions effectively. Our method has been validated on several public datasets and the experimental results show that it outperforms several state-of-the-art tracking methods.	[Wang, Bing; Wang, Gang; Chan, Kap Luk; Wang, Li] Nanyang Technol Univ, Sch Elect & Elect Engn, 50 Nanyang Ave, Singapore 639798, Singapore	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Wang, B (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, 50 Nanyang Ave, Singapore 639798, Singapore.	wang0775@ntu.edu.sg; wanggang@ntu.edu.sg; eklchan@ntu.edu.sg; wa0002li@ntu.edu.sg			School of EEE, Nanyang Technological University, Singapore	School of EEE, Nanyang Technological University, Singapore	The authors would like to acknowledge the Research Scholarship from School of EEE, Nanyang Technological University, Singapore.	Andriluka M, 2008, PROC CVPR IEEE, P1873, DOI 10.1109/CVPR.2008.4587583; Andriluka M, 2010, PROC CVPR IEEE, P623, DOI 10.1109/CVPR.2010.5540156; [Anonymous], 2009, ROBUST MULTIPERSON T; [Anonymous], 2015, MULTIPLE OBJECT TRAC; Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159; Ben Shitrit H, 2014, IEEE T PATTERN ANAL, V36, P1614, DOI 10.1109/TPAMI.2013.210; Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667; Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21; Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309; Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232; Camps O, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1048; Chen S, 2014, PROC CVPR IEEE, P1130, DOI 10.1109/CVPR.2014.148; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dicle C, 2013, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2013.286; Ding T, 2008, P 14 INT C AUD DISPL, P1; Ess A, 2009, IEEE T PATTERN ANAL, V31, P1831, DOI 10.1109/TPAMI.2009.109; Felzenszwalb P, 2008, 2008 IEEE C COMP VIS, P1, DOI DOI 10.1109/CVPR.2008.4587597; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174; Ge W., 2008, P BRIT MACH VIS C, DOI 10.5244/C.22.93.5; Geiger A, 2014, IEEE T PATTERN ANAL, V36, P1012, DOI 10.1109/TPAMI.2013.185; Goldberg A. V., 1992, J ALGORITHMS, V22, P1; Henriques JF, 2011, IEEE I CONF COMP VIS, P2470, DOI 10.1109/ICCV.2011.6126532; Hofmann M, 2013, PROC CVPR IEEE, P3650, DOI 10.1109/CVPR.2013.468; Hofmann M, 2013, IEEE INT W PERFORM, P22, DOI 10.1109/PETS.2013.6523791; Huang C, 2008, LECT NOTES COMPUT SC, V5303, P788, DOI 10.1007/978-3-540-88688-4_58; Huang C, 2010, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2010.5540230; Izadinia H, 2012, LECT NOTES COMPUT SC, V7577, P100, DOI 10.1007/978-3-642-33783-3_8; Kuo CH, 2011, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2011.5995384; Leal-Taixe Laura, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P120, DOI 10.1109/ICCVW.2011.6130233; Leal-Taixe L, 2014, PROC CVPR IEEE, P3542, DOI 10.1109/CVPR.2014.453; Milan A., 2015, ARXIV150401942CS; Milan A., 2012, DISCRETE CONTINUOUS; Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103; Milan A, 2013, PROC CVPR IEEE, P3682, DOI 10.1109/CVPR.2013.472; MOONEN M, 1989, INT J CONTROL, V49, P219, DOI 10.1080/00207178908559631; Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260; Possegger H., 2014, P IEEE C COMP VIS PA, P79; Singh V., 2008, INDIAN J SCI TECHNOL, V1, P1, DOI [10.17485/ijst/2008/v1i4.12, DOI 10.17485/IJST/2008/V1I4.12]; Storms PPA, 2003, COMPUT OPER RES, V30, P1067, DOI 10.1016/S0305-0548(02)00057-6; Tuzel O., 2007, PROC CVPR IEEE, P1, DOI [DOI 10.1109/CVPR.2007.383197, 10.1109/CVPR.2007.383197]; Wang B, 2014, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2014.161; Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207; Wu B, 2005, IEEE I CONF COMP VIS, P90; Wu Z., 2013, 24 BRIT MACH VIS C B; Xing JL, 2009, PROC CVPR IEEE, P1200, DOI 10.1109/CVPRW.2009.5206745; Yamaguchi K, 2011, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2011.5995468; Yang B, 2014, INT J COMPUT VISION, V107, P203, DOI 10.1007/s11263-013-0666-4; Yang B, 2012, PROC CVPR IEEE, P1918, DOI 10.1109/CVPR.2012.6247892; Yang J., 2009, P INT WORKSH PERF EV; Yoon JH, 2015, IEEE WINT CONF APPL, P33, DOI 10.1109/WACV.2015.12; Zhang L, 2008, INT C WAVEL ANAL PAT, P11, DOI 10.1109/ICWAPR.2008.4635742; Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138	63	37	38	1	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	3					589	602		10.1109/TPAMI.2016.2551245	http://dx.doi.org/10.1109/TPAMI.2016.2551245			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8IP	28113884	Green Submitted			2022-12-18	WOS:000395555100013
J	Zitnick, CL; Vedantam, R; Parikh, D				Zitnick, C. Lawrence; Vedantam, Ramakrishna; Parikh, Devi			Adopting Abstract Images for Semantic Scene Understanding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantic scene understanding; linguistic meaning; saliency; memorability; abstract images	OBJECTS; MEMORY; MODEL; PREDICT	Relating visual information to its linguistic semantic meaning remains an open and challenging area of research. The semantic meaning of images depends on the presence of objects, their attributes and their relations to other objects. But precisely characterizing this dependence requires extracting complex visual information from an image, which is in general a difficult and yet unsolved problem. In this paper, we propose studying semantic information in abstract images created from collections of clip art. Abstract images provide several advantages over real images. They allow for the direct study of how to infer high-level semantic information, since they remove the reliance on noisy low-level object, attribute and relation detectors, or the tedious hand-labeling of real images. Importantly, abstract images also allow the ability to generate sets of semantically similar scenes. Finding analogous sets of real images that are semantically similar would be nearly impossible. We create 1,002 sets of 10 semantically similar abstract images with corresponding written descriptions. We thoroughly analyze this dataset to discover semantically important features, the relations of words to visual features and methods for measuring semantic similarity. Finally, we study the relation between the saliency and memorability of objects and their semantic importance.	[Zitnick, C. Lawrence] Microsoft Res, Interact Visual Media Grp, One Microsoft Way, Redmond, WA USA; [Vedantam, Ramakrishna; Parikh, Devi] Virginia Tech, Dept Elect & Comp Engn, Blacksburg, VA USA	Microsoft; Virginia Polytechnic Institute & State University	Zitnick, CL (corresponding author), Microsoft Res, Interact Visual Media Grp, One Microsoft Way, Redmond, WA USA.; Vedantam, R; Parikh, D (corresponding author), Virginia Tech, Dept Elect & Comp Engn, Blacksburg, VA USA.	larryz@microsoft.com; vrama91@vt.edu; parikh@vt.edu			US National Science Foundation (NSF) [IIS-1341772]	US National Science Foundation (NSF)(National Science Foundation (NSF))	The authors would like to thank Bryan Russell, Lucy Vanderwende, Michel Galley and Luke Zettlemoyer who helped inspire and shape this paper during discussions. They thank John Gruen for his hard work in creating the clip art dataset. They also thank Phillip Isola and Naman Agrawal for the memorability interface. This work was supported in part by the US National Science Foundation (NSF) IIS-1341772. Dr. C. Lawrence Zitnick is the corresponding author.	Berg AC, 2012, PROC CVPR IEEE, P3562, DOI 10.1109/CVPR.2012.6248100; Berg TL, 2010, LECT NOTES COMPUT SC, V6311, P663, DOI 10.1007/978-3-642-15549-9_48; BIEDERMAN I, 1982, COGNITIVE PSYCHOL, V14, P143, DOI 10.1016/0010-0285(82)90007-X; Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89; Brady TF, 2008, P NATL ACAD SCI USA, V105, P14325, DOI 10.1073/pnas.0803390105; Brown GDA, 2007, PSYCHOL REV, V114, P539, DOI 10.1037/0033-295X.114.3.539; Cohen-Or D, 2006, ACM T GRAPHIC, V25, P624, DOI 10.1145/1141911.1141933; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Das P, 2013, PROC CVPR IEEE, P2634, DOI 10.1109/CVPR.2013.340; Desai C, 2009, IEEE I CONF COMP VIS, P229, DOI 10.1109/ICCV.2009.5459256; Dhar S, 2011, PROC CVPR IEEE, P1657, DOI 10.1109/CVPR.2011.5995467; Einhauser W, 2008, J VISION, V8, DOI 10.1167/8.2.2; Elazary L, 2008, J VISION, V8, DOI 10.1167/8.3.3; Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3; Galleguillos C, 2008, PROC CVPR IEEE, P3552; Gooch B, 2001, SPRING EUROGRAP, P83; Grubinger M., 2006, INT WORKSHOP ONTOIMA, V2; Gupta A, 2008, LECT NOTES COMPUT SC, V5302, P16, DOI 10.1007/978-3-540-88682-2_3; Gupta A, 2010, LECT NOTES COMPUT SC, V6311, P171, DOI 10.1007/978-3-642-15549-9_13; Heider F, 1944, AM J PSYCHOL, V57, P243, DOI 10.2307/1416950; Hoiem D, 2006, CVPR, DOI DOI 10.1109/CVPR.2006.232; Howard MW, 2002, J MATH PSYCHOL, V46, P269, DOI 10.1006/jmps.2001.1388; Hunt R.R., 2006, DISTINCTIVENESS MEMO, P3, DOI [https://doi.org/10.1093/acprof:oso/9780195169669.003.0001, DOI 10.1093/ACPROF:OSO/9780195169669.003.0001, 10.1093/acprof:oso/9780195169669.003.0001]; Hwang SJ, 2012, INT J COMPUT VISION, V100, P134, DOI 10.1007/s11263-011-0494-3; Hwang SJ, 2012, IEEE T PATTERN ANAL, V34, P1145, DOI 10.1109/TPAMI.2011.190; Isola P., 2011, ADV NEURAL INFORM PR, P2429, DOI DOI 10.1167/12.9.1082; Isola P, 2011, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2011.5995721; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Kaneva B, 2011, IEEE I CONF COMP VIS, P2282, DOI 10.1109/ICCV.2011.6126508; Khosla A, 2012, ADV NEURAL INFORM PR, P296; Khosla A, 2013, IEEE I CONF COMP VIS, P3200, DOI 10.1109/ICCV.2013.397; Krishnamoorthy N., 2013, P WORKSHOP VISION NA, P10; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Leyvand T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360637; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin WH, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P41, DOI 10.1109/ICME.2006.262545; Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70; Luo YW, 2008, LECT NOTES COMPUT SC, V5304, P386; Marin J., 2007, P IEEE C COMP VIS PA, P137; MCCLELLAND JL, 1995, PSYCHOL REV, V102, P419, DOI 10.1037/0033-295X.102.3.419; OATLEY K, 1985, BRIT J SOC PSYCHOL, V24, P115, DOI 10.1111/j.2044-8309.1985.tb00670.x; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009; Ordonez Vicente, 2011, ADV NEURAL INFORM PR, P1143; Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281; Privitera CM, 2000, IEEE T PATTERN ANAL, V22, P970, DOI 10.1109/34.877520; Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986; Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.1002/ACP.3140; Renjie L., 2010, OPTIMIZING PHOTOCOMP; Rensink RA, 2002, ANNU REV PSYCHOL, V53, P245, DOI 10.1146/annurev.psych.53.100901.135125; ROCK I, 1959, AM J PSYCHOL, V72, P221; Rohrbach M, 2013, IEEE I CONF COMP VIS, P433, DOI 10.1109/ICCV.2013.61; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711; Saxena A, 2008, INT J ROBOT RES, V27, P157, DOI 10.1177/0278364907087172; Shiffrin RM, 1997, PSYCHON B REV, V4, P145, DOI 10.3758/BF03209391; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Spain M, 2011, INT J COMPUT VISION, V91, P59, DOI 10.1007/s11263-010-0376-0; STANDING L, 1973, Q J EXP PSYCHOL, V25, P207, DOI 10.1080/14640747308400340; Taylor Geoffrey R., 2007, IEEE COMPUTER SOC C, DOI [DOI 10.1109/CVPR.2007.383518, 10.1109/CVPR.2007.383518]; Torralba A., 2004, NEURAL INFORM PROCES; Tseng PH, 2009, J VISION, V9, DOI 10.1167/9.7.4; Turakhia N, 2013, IEEE I CONF COMP VIS, P1225, DOI 10.1109/ICCV.2013.155; Ullman S, 2002, NAT NEUROSCI, V5, P682, DOI 10.1038/nn870; Weinberger Kilian Q, 2006, ADV NEURAL INFORM PR, P1473, DOI DOI 10.1007/978-3-319-13168-9_; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; YAO BP, 2010, PROC CVPR IEEE, P17, DOI DOI 10.1109/CVPR.2010.5540235; Yu H., 2013, 51 ANN M ASS COMP LI, P53; Zitnick CL, 2013, IEEE I CONF COMP VIS, P1681, DOI 10.1109/ICCV.2013.211; Zitnick CL, 2013, PROC CVPR IEEE, P3009, DOI 10.1109/CVPR.2013.387	76	37	40	1	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2016	38	4					627	638		10.1109/TPAMI.2014.2366143	http://dx.doi.org/10.1109/TPAMI.2014.2366143			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DH1MW	26959669	hybrid			2022-12-18	WOS:000372549700002
J	Kumar, A; Kwong, C				Kumar, Ajay; Kwong, Cyril			Towards Contactless, Low-Cost and Accurate 3D Fingerprint Identification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Biometrics; contactless fingerprint identification; 3d fingerprint matching; 3d minutiae; photometric stereo; 3d fingerprint individuality	TOUCHLESS; INDIVIDUALITY; ALGORITHM; GRADIENT	Human identification using fingerprint impressions has been widely studied and employed for more than 2000 years. Despite new advancements in the 3D imaging technologies, widely accepted representation of 3D fingerprint features and matching methodology is yet to emerge. This paper investigates 3D representation of widely employed 2D minutiae features by recovering and incorporating (i) minutiae height z and (ii) its 3D orientation phi information and illustrates an effective matching strategy for matching popular minutiae features extended in 3D space. One of the obstacles of the emerging 3D fingerprint identification systems to replace the conventional 2D fingerprint system lies in their bulk and high cost, which is mainly contributed from the usage of structured lighting system or multiple cameras. This paper attempts to addresses such key limitations of the current 3D fingerprint technologies by developing the single camera-based 3D fingerprint identification system. We develop a generalized 3D minutiae matching model and recover extended 3D fingerprint features from the reconstructed 3D fingerprints. 2D fingerprint images acquired for the 3D fingerprint reconstruction can themselves be employed for the performance improvement and have been illustrated in the work detailed in this paper. This paper also attempts to answer one of the most fundamental questions on the availability of inherent discriminable information from 3D fingerprints. The experimental results are presented on a database of 240 clients 3D fingerprints, which is made publicly available to further research efforts in this area, and illustrate the discriminant power of 3D minutiae representation and matching to achieve performance improvement.	[Kumar, Ajay; Kwong, Cyril] Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China	Hong Kong Polytechnic University	Kumar, A (corresponding author), Hong Kong Polytech Univ, Dept Comp, Kowloon, Hong Kong, Peoples R China.	Ajay.Kumar@polyu.edu.hk; mfckkong@polyu.edu.hk			General Research Fund from Research Grant Council of Hong Kong [PolyU 516913]	General Research Fund from Research Grant Council of Hong Kong	This work is supported by General Research Fund from Research Grant Council of Hong Kong, project number PolyU 516913. The algorithm(s) described in this paper are part of pending US Patent filed in 2012.	Agrawal A, 2006, LECT NOTES COMPUT SC, V3951, P578; [Anonymous], 2011, NBIS REL 4 1 0; Belyaev A., 2006, MPIINFMPGDE, P1; Bolle RM, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P15, DOI 10.1109/AUTOID.2005.48; Bringier B, 2012, J OPT SOC AM A, V29, P11, DOI 10.1364/JOSAA.29.000011; Chen, 2006, P BIOM S BIOM CONS C; Chen F., 2009, US Patent No, Patent No. 7609865; Choi H, 2010, IEEE T INF FOREN SEC, V5, P52, DOI 10.1109/TIFS.2009.2038758; Dandekar K., 1997, 2 MIT DEP MECH ENG T; Dass SC, 2010, IEEE T INF FOREN SEC, V5, P62, DOI 10.1109/TIFS.2009.2039598; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113; Feng JJ, 2008, PATTERN RECOGN, V41, P342, DOI 10.1016/j.patcog.2007.04.016; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; Goldfeather J, 2004, ACM T GRAPHIC, V23, P45, DOI 10.1145/966131.966134; Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565; HORN KP, 1989, SHAPE SHADING; Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996; Jain A. K., 2012, 2 GENERATION BIOMETR; Jea TY, 2005, PATTERN RECOGN, V38, P1672, DOI 10.1016/j.patcog.2005.03.016; Kanhangad V, 2011, IEEE T INF FOREN SEC, V6, P1014, DOI 10.1109/TIFS.2011.2121062; Krishnasamy P., 2011, P 2011 INT JOINT C B, P1; Kucken M, 2005, J THEOR BIOL, V235, P71, DOI 10.1016/j.jtbi.2004.12.020; Kumar A., 2011, P C COMP VIS PATT RE, P114; Kumar A, 2013, PROC CVPR IEEE, P3438, DOI 10.1109/CVPR.2013.441; Kumar A, 2012, IEEE T IMAGE PROCESS, V21, P2228, DOI 10.1109/TIP.2011.2171697; Kumar BVKV, 2004, APPL OPTICS, V43, P391, DOI 10.1364/AO.43.000391; Lalonde J.-F., 2006, MURITR0621; Liu LF, 2006, IEEE T IMAGE PROCESS, V15, P1100, DOI 10.1109/TIP.2005.864161; Maltoni D., 2009, HDB FINGERPRINT RECO; Paar G, 2008, J APPL GEOD, V2, P13, DOI 10.1515/JAG.2008.002; Pankanti S, 2002, IEEE T PATTERN ANAL, V24, P1010, DOI 10.1109/TPAMI.2002.1023799; Parziale G, 2006, LECT NOTES COMPUT SC, V3832, P244; Parziale G, 2009, ADV PATTERN RECOGNIT, P83, DOI 10.1007/978-1-84882-385-3_4; Shafaei Sara, 2009, BIOM THEOR APPL SYST, P1; SIMCHONY T, 1990, IEEE T PATTERN ANAL, V12, P435, DOI 10.1109/34.55103; Taubin G., 2000, P EUROGRAPHICS STATE; Tico M, 2003, IEEE T PATTERN ANAL, V25, P1009, DOI 10.1109/TPAMI.2003.1217604; Vandal N.A., 2010, P 4 IEEE INT C BIOM, P1; Wang Y., 2009, P 2009 IEEE C BIOM I, P22; Wang Y, 2011, IEEE T PATTERN ANAL, V33, P72, DOI 10.1109/TPAMI.2010.73; Wang YC, 2010, IEEE T INF FOREN SEC, V5, P750, DOI 10.1109/TIFS.2010.2062177; Wang YC, 2010, APPL OPTICS, V49, P592, DOI 10.1364/AO.49.000592; WOODHAM RJ, 1994, J OPT SOC AM A, V11, P3050, DOI 10.1364/JOSAA.11.003050; Yoshizawa S, 2008, COMPUT AIDED GEOM D, V25, P545, DOI 10.1016/j.cagd.2008.06.008	44	37	57	2	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2015	37	3					681	696		10.1109/TPAMI.2014.2339818	http://dx.doi.org/10.1109/TPAMI.2014.2339818			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VK	26353269				2022-12-18	WOS:000349626200015
J	Si, XB; Feng, JJ; Zhou, J; Luo, YX				Si, Xuanbin; Feng, Jianjiang; Zhou, Jie; Luo, Yuxuan			Detection and Rectification of Distorted Fingerprints	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fingerprint; distortion; registration; nearest neighbor regression; PCA	IMAGE-QUALITY; ALGORITHM; ENHANCEMENT; PERFORMANCE; SYSTEM; MODEL	Elastic distortion of fingerprints is one of the major causes for false non-match. While this problem affects all fingerprint recognition applications, it is especially dangerous in negative recognition applications, such as watchlist and deduplication applications. In such applications, malicious users may purposely distort their fingerprints to evade identification. In this paper, we proposed novel algorithms to detect and rectify skin distortion based on a single fingerprint image. Distortion detection is viewed as a two-class classification problem, for which the registered ridge orientation map and period map of a fingerprint are used as the feature vector and a SVM classifier is trained to perform the classification task. Distortion rectification (or equivalently distortion field estimation) is viewed as a regression problem, where the input is a distorted fingerprint and the output is the distortion field. To solve this problem, a database (called reference database) of various distorted reference fingerprints and corresponding distortion fields is built in the offline stage, and then in the online stage, the nearest neighbor of the input fingerprint is found in the reference database and the corresponding distortion field is used to transform the input fingerprint into a normal one. Promising results have been obtained on three databases containing many distorted fingerprints, namely FVC2004 DB1, Tsinghua Distorted Fingerprint database, and the NIST SD27 latent fingerprint database.	[Si, Xuanbin; Feng, Jianjiang; Zhou, Jie; Luo, Yuxuan] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China	Tsinghua University	Si, XB (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.	sixb13@mails.tsinghua.edu.cn; jfeng@tsinghua.edu.cn; jzhou@tsinghua.edu.cn; luoyx12@mails.tsinghua.edu.cn	JOURNAL, IJCERT/C-9134-2016	JOURNAL, IJCERT/0000-0002-6073-8440	National Natural Science Foundation of China [61225008, 61373074, 61020106004]; National Basic Research Program of China [2014CB349304]; Ministry of Education of China [20120002110033]; Tsinghua University Initiative Scientific Research Program	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China(National Basic Research Program of China); Ministry of Education of China(Ministry of Education, China); Tsinghua University Initiative Scientific Research Program	This work was supported by the National Natural Science Foundation of China under Grants 61225008, 61373074, and 61020106004, the National Basic Research Program of China under Grant 2014CB349304, the Ministry of Education of China under Grant 20120002110033, and the Tsinghua University Initiative Scientific Research Program.	Alonso-Fernandez F, 2007, IEEE T INF FOREN SEC, V2, P734, DOI 10.1109/TIFS.2007.908228; [Anonymous], 2006, FVC2006 4 INT FINGER; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Bazen AM, 2003, PATTERN RECOGN, V36, P1859, DOI 10.1016/S0031-3203(03)00036-0; Bazen AM, 2002, IEEE T PATTERN ANAL, V24, P905, DOI 10.1109/TPAMI.2002.1017618; Bolle R. M., 2000, U. S. Patent, Patent No. [6064753, 6064753 A]; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chen XJ, 2006, IEEE T IMAGE PROCESS, V15, P767, DOI 10.1109/TIP.2005.860597; Chikkerur S, 2007, PATTERN RECOGN, V40, P198, DOI 10.1016/j.patcog.2006.05.036; Dai JF, 2012, IEEE T PATTERN ANAL, V34, P1618, DOI 10.1109/TPAMI.2011.237; Dorai C, 2004, IEEE T CIRC SYST VID, V14, P58, DOI 10.1109/TCSVT.2003.818354; Dvornychenko V. N., 2006, 7377 NISTIR; Feng JJ, 2008, PATTERN RECOGN, V41, P342, DOI 10.1016/j.patcog.2007.04.016; Feng JJ, 2006, PATTERN RECOGN, V39, P2131, DOI 10.1016/j.patcog.2006.05.001; Feng JJ, 2013, IEEE T PATTERN ANAL, V35, P925, DOI 10.1109/TPAMI.2012.155; Fierrez-Aguilar J, 2006, LECT NOTES COMPUT SC, V3832, P213; Fujii Y., 2010, U. S. Patent, Patent No. [7660447, 7660447 B2]; Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565; Kovacs-Vajna ZM, 2000, IEEE T PATTERN ANAL, V22, P1266, DOI 10.1109/34.888711; Maltoni Davide, 2009, HDB FINGERPRINT RECO, DOI [10.1007/978-1-84882-254-2, DOI 10.1007/978-1-84882-254-2]; Neurotechnology Inc, 2009, VERIFINGER; Novikov S, 2005, LECT NOTES COMPUT SC, V3546, P250; Ratha NK, 1998, INT C PATT RECOG, P1659, DOI 10.1109/ICPR.1998.712037; Ratha NK, 1996, IEEE T PATTERN ANAL, V18, P799, DOI 10.1109/34.531800; Ross A, 2006, IEEE T PATTERN ANAL, V28, P19, DOI 10.1109/TPAMI.2006.11; Ross A, 2005, PATTERN RECOGN, V38, P95, DOI 10.1016/j.patcog.2003.12.021; Rueckert D, 2003, IEEE T MED IMAGING, V22, P1014, DOI 10.1109/TMI.2003.815865; Senior AW, 2001, IEICE T INF SYST, VE84D, P825; Si XB, 2012, IEEE INT WORKS INFOR, P1, DOI 10.1109/WIFS.2012.6412616; Tabassi E., 2004, NIST INTERAGENCY REP; Tang SY, 2009, NEUROIMAGE, V47, P1277, DOI 10.1016/j.neuroimage.2009.02.043; Thebaud L. R., 1999, U. S. Patent, Patent No. [5909501 A, 5909501]; Turroni F., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P152, DOI 10.1109/ICB.2012.6199773; Wan DR, 2006, IEEE T IMAGE PROCESS, V15, P1690, DOI 10.1109/TIP.2006.873442; Wein LM, 2005, P NATL ACAD SCI USA, V102, P7772, DOI 10.1073/pnas.0407496102; Yang X, 2014, IEEE T PATTERN ANAL, V36, P955, DOI 10.1109/TPAMI.2013.184; Yoon S, 2012, IEEE T PATTERN ANAL, V34, P451, DOI 10.1109/TPAMI.2011.161	38	37	38	2	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2015	37	3					555	568		10.1109/TPAMI.2014.2345403	http://dx.doi.org/10.1109/TPAMI.2014.2345403			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VK	26353261				2022-12-18	WOS:000349626200006
J	Doshi-Velez, F; Pfau, D; Wood, F; Roy, N				Doshi-Velez, Finale; Pfau, David; Wood, Frank; Roy, Nicholas			Bayesian Nonparametric Methods for Partially-Observable Reinforcement Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Artificial intelligence; machine learning; reinforcement learning; partially-observable Markov decision process; hierarchial Dirichlet process hidden Markov model	HIDDEN MARKOV-MODELS	Making intelligent decisions from incomplete information is critical in many applications: for example, robots must choose actions based on imperfect sensors, and speech-based interfaces must infer a user's needs from noisy microphone inputs. What makes these tasks hard is that often we do not have a natural representation with which to model the domain and use for choosing actions; we must learn about the domain's properties while simultaneously performing the task. Learning a representation also involves trade-offs between modeling the data that we have seen previously and being able to make predictions about new data. This article explores learning representations of stochastic systems using Bayesian nonparametric statistics. Bayesian nonparametric methods allow the sophistication of a representation to scale gracefully with the complexity in the data. Our main contribution is a careful empirical evaluation of how representations learned using Bayesian nonparametric methods compare to other standard learning approaches, especially in support of planning and control. We show that the Bayesian aspects of the methods result in achieving state-of-the-art performance in decision making with relatively few samples, while the nonparametric aspects often result in fewer computations. These results hold across a variety of different techniques for choosing actions given a representation.	[Doshi-Velez, Finale; Roy, Nicholas] MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA; [Pfau, David] Columbia Univ, Ctr Theoret Neurosci, New York, NY 10032 USA; [Wood, Frank] Univ Oxford, Dept Engn, Oxford OX1 3PJ, England	Massachusetts Institute of Technology (MIT); Columbia University; University of Oxford	Doshi-Velez, F (corresponding author), MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	finale@alum.mit.edu; pfau@neurotheory.columbia.edu; fwood@robots.ox.ac.uk; nickroy@mit.edu		Roy, Nicholas/0000-0002-8293-0492				Asmuth J., 2009, P 25 UAI ARL VA US; Blackwell D., 1954, THEORY GAMES STAT DE, pXI, 355; Brafman R. I., 2004, P NIPS; Breslow L., 1996, 890178 NAV CTR RES L; Castro J, 2008, LECT NOTES ARTIF INT, V5278, P163; Chrisman L., 1992, P 10 NAT C ART INT P; Dearden R, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P150; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dimitrakakis C, 2010, AISTATS, P161; Doshi F., 2008, P 25 ICML NEW YORK N; Doshi-Velez F., 2011, P 28 ICML WASH DC US; Doshi-Velez F., 2010, P NIPS; Doshi-Velez F., 2009, ADV NEURAL INFORM PR, V22, P477; Drescher G, 1991, MADE MINDS CONSTRUCT; Duff M., 2002, THESIS U MASSACHUSET; Dupont P, 2005, PATTERN RECOGN, V38, P1349, DOI 10.1016/j.patcog.2004.03.020; Fox E. B., 2008, P ICML HELS FINL; Gmytrasiewicz P.J., 2004, P 3 INT JOINT C AUT, P1374; Huggins J., IEEE T PATT IN PRESS; Jaulmes R., 2005, P ECML WORKSH; Johnson M., 2010, P UAI; Kaelbling LP, 1998, ARTIF INTELL, V101, P99, DOI 10.1016/S0004-3702(98)00023-X; Kolter J. Z., 2009, P 26 ICML MONTR QC C; Kurniawati H, 2008, P RSS; Littman M. L., 1995, P ICML SAN FRANC CA; MacKay D.J.C., 1997, BOOK ENSEMBLE LEARNI; Mahmud M. M. H., 2010, P 27 ICML HAIF ISR; Maybeck P. S., 1979, MATH SCI ENG; McAllester D., 1999, P 15 UAI; McCallum R. A., 1993, P 10 INT C MACH LEAR, P190, DOI DOI 10.1016/B978-1-55860-307-3.50031-9; Pfau D., 2010, ADV NEURAL INFORM PR, V23, P1930, DOI [10.1109/tpami.1982.4767292, DOI 10.1109/TPAMI.1982.4767292]; Pineau J., 2003, P 18 IJCAI SAN FRANC; Pineau J., 2001, P WORKSH HIER MEM RE P WORKSH HIER MEM RE; Pitman J, 1997, ANN PROBAB, V25, P855; Poupart P., 2008, P ISAIM; RABIN MO, 1963, INFORM CONTROL, V6, P230, DOI 10.1016/S0019-9958(63)90290-0; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Ross S., 2008, P NIPS; Ross S., 2008, P ICRA PAS CA US; Ross S, 2008, J ARTIF INTELL RES, V32, P663, DOI 10.1613/jair.2567; Sabbadin R., 2007, PROC AAAI C ARTIF IN, P1057; SETHURAMAN J, 1994, STAT SINICA, V4, P639; Shalizi CR, 2004, P 20 C UNC ART INT, P504; Smith T., 2004, P 20 C UAI BANFF AB; Sondik EJ, 1971, THESIS I OPERATIONS; Song L., 2010, P 27 ICML HAIF ISR; Stepleton T., 2009, P 12 AISTATS CLEARW; Stolcke A., 1993, P ADV NEUR INF PROC, P11; Strens M., 2000, P 17 ICML SAN FRANC; Sutton Richard S, 1998, INTRO REINFORCEMENT, V2; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Thollard F., 2000, P 17 INT C MACH LEAR, P975; Tishby N., 1999, P 37 ALL C COMM CONT; van Gael J., 2008, P 25 ICML NEW YORK N, V25; VENESS J, 2009, CORR; Williams J., 2005, P IEEE ASRU WORKSH S; Zheng L, 2011, NEURAL PROCESS LETT, V33, P187, DOI 10.1007/s11063-011-9172-2	57	37	38	1	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2015	37	2					394	407		10.1109/TPAMI.2013.191	http://dx.doi.org/10.1109/TPAMI.2013.191			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VD	26353250	Green Published			2022-12-18	WOS:000349625500015
J	Xiong, Y; Chakrabarti, A; Basri, R; Gortler, SJ; Jacobs, DW; Zickler, T				Xiong, Ying; Chakrabarti, Ayan; Basri, Ronen; Gortler, Steven J.; Jacobs, David W.; Zickler, Todd			From Shading to Local Shape	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape from shading; local shape descriptors; statistical models; 3D reconstruction		We develop a framework for extracting a concise representation of the shape information available from diffuse shading in a small image patch. This produces a mid-level scene descriptor, comprised of local shape distributions that are inferred separately at every image patch across multiple scales. The framework is based on a quadratic representation of local shape that, in the absence of noise, has guarantees on recovering accurate local shape and lighting. And when noise is present, the inferred local shape distributions provide useful shape information without over-committing to any particular image explanation. These local shape distributions naturally encode the fact that some smooth diffuse regions are more informative than others, and they enable efficient and robust reconstruction of object-scale shape. Experimental results show that this approach to surface reconstruction compares well against the state-of-art on both synthetic images and captured photographs.	[Xiong, Ying; Chakrabarti, Ayan; Gortler, Steven J.; Zickler, Todd] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA; [Basri, Ronen] Weizmann Inst Sci, IL-76100 Rehovot, Israel; [Jacobs, David W.] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA	Harvard University; Weizmann Institute of Science; University System of Maryland; University of Maryland College Park	Xiong, Y (corresponding author), Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.	yxiong@sens.harvard.edu; ayanc@eecs.harvard.edu; ronen.basri@weizmann.ac.il; sjg@cs.harvard.edu; djacobs@cs.umd.edu; zickler@sens.harvard.edu	Ben-Shahar, Ohad/F-8918-2015		National Science Foundation [1212928, 0926148, 0915977]; US-Israel Binational Science Foundation [2010331]; Citigroup Foundation	National Science Foundation(National Science Foundation (NSF)); US-Israel Binational Science Foundation(US-Israel Binational Science Foundation); Citigroup Foundation	The authors would like to thank the associate editor and reviewers for their valuable comments. YX, AC, DWJ, and TZ acknowledge support from the National Science Foundation under Grants no. 1212928, 0926148, and 0915977. RB and DWJ were supported in part by the US-Israel Binational Science Foundation under Grant no. 2010331. RB also acknowledges support from the Citigroup Foundation. Some of this work was performed while TZ was at the Weizmann Institute of Science as a Feinberg Foundation Visiting Faculty Program Fellow.	Barron J. T., 2013, UCBEECS2013117; Beckmann Petr, 1987, SCATTERING ELECTROMA, P4; Cole F, 2012, LECT NOTES COMPUT SC, V7574, P665, DOI 10.1007/978-3-642-33712-3_48; Durou JD, 2008, COMPUT VIS IMAGE UND, V109, P22, DOI 10.1016/j.cviu.2007.09.003; Ecker A, 2010, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2010.5540219; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Grosse R, 2009, IEEE I CONF COMP VIS, P2335, DOI 10.1109/ICCV.2009.5459428; Haddon J., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P415, DOI 10.1007/BFb0054756; Hassner T., 2006, CVPR WORKSH, P15; Horn B.K.P., 1989, SHAPE SHADING; HUANG XY, 2007, P 6 INT C 3 D DIG IM, P349; Huggins PS, 2001, PROC CVPR IEEE, P718; Johnson M. K., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2553, DOI 10.1109/CVPR.2011.5995510; Kunsberg B., 2013, ARXIV13065480V1CSCV; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030; MARR D, 1976, PHILOS T R SOC B, V275, P483, DOI 10.1098/rstb.1976.0090; OLIENSIS J, 1991, INT J COMPUT VISION, V6, P75, DOI 10.1007/BF00128151; OLIENSIS J, 1991, CVGIP-IMAG UNDERSTAN, V54, P163, DOI 10.1016/1049-9660(91)90061-S; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P170, DOI 10.1109/TPAMI.1984.4767501; Prados E, 2005, INT J COMPUT VISION, V65, P97, DOI 10.1007/s11263-005-3844-1; Prados E, 2005, PROC CVPR IEEE, P870; Prados E, 2004, LECT NOTES COMPUT SC, V2034, P141; Tan P, 2011, IEEE T PATTERN ANAL, V33, P2506, DOI 10.1109/TPAMI.2011.35; Wagemans J, 2010, I-PERCEPTION, V1, P159, DOI 10.1068/i0401; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; Zhu Q, 2006, P 2006 IEEE COMP SOC, V2, P1839	27	37	37	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2015	37	1					67	79		10.1109/TPAMI.2014.2343211	http://dx.doi.org/10.1109/TPAMI.2014.2343211			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AX5ML	26353209	Green Submitted			2022-12-18	WOS:000346970600007
J	Wu, ZY; Radke, RJ				Wu, Ziyan; Radke, Richard J.			Keeping a Pan-Tilt-Zoom Camera Calibrated	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pan-tilt-zoom; calibration; dynamic correction	SELF-CALIBRATION	Pan-tilt-zoom (PTZ) cameras are pervasive in modern surveillance systems. However, we demonstrate that the (pan, tilt) coordinates reported by PTZ cameras become inaccurate after many hours of operation, endangering tracking and 3D localization algorithms that rely on the accuracy of such values. To solve this problem, we propose a complete model for a PTZ camera that explicitly reflects how focal length and lens distortion vary as a function of zoom scale. We show how the parameters of this model can be quickly and accurately estimated using a series of simple initialization steps followed by a nonlinear optimization. Our method requires only 10 images to achieve accurate calibration results. Next, we show how the calibration parameters can be maintained using a one-shot dynamic correction process; this ensures that the camera returns the same field of view every time the user requests a given (pan, tilt, zoom), even after hundreds of hours of operation. The dynamic calibration algorithm is based on matching the current image against a stored feature library created at the time the PTZ camera is mounted. We evaluate the calibration and dynamic correction algorithms on both experimental and real-world datasets, demonstrating the effectiveness of the techniques.	[Wu, Ziyan; Radke, Richard J.] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA	Rensselaer Polytechnic Institute	Wu, ZY (corresponding author), Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, 110 8th St, Troy, NY 12180 USA.	wuz5@rpi.edu; rjradke@ecse.rpi.edu	Radke, Richard J/I-3289-2013; Wu, Ziyan/G-1048-2010	Radke, Richard J/0000-0001-5064-7775; Wu, Ziyan/0000-0002-9774-7770	US Department of Homeland Security [2008-ST-061-ED0001]	US Department of Homeland Security(United States Department of Homeland Security (DHS))	An earlier version of part of the work in this paper appeared in [26]. This material is based upon work supported by the US Department of Homeland Security under Award Number 2008-ST-061-ED0001. The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of the US Department of Homeland Security.	Agapito L, 2001, INT J COMPUT VISION, V45, P107, DOI 10.1023/A:1012471930694; [Anonymous], [No title captured]; Ashraf N., 2008, P INT C PATT REC DEC; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Collins R.T., 1999, P IEEE C COMP VIS PA; Davis J., 2003, P IEEE INT C COMP VI; DEAGAPITO L, 1999, P INT C COMP VIS PAT; Hartley R., 2004, ROBOTICA; Hartley RI, 1997, INT J COMPUT VISION, V22, P5, DOI 10.1023/A:1007957826135; Hayman E, 2003, IEEE T PATTERN ANAL, V25, P1015, DOI 10.1109/TPAMI.2003.1217605; He BW, 2009, OPT ENG, V48, DOI 10.1117/1.3070650; Juan L., 2009, INT J IMAGE PROCESSI, V3, P143, DOI DOI 10.1007/S11270-006-2859-8; Kukelova Z, 2011, IEEE T PATTERN ANAL, V33, P2410, DOI 10.1109/TPAMI.2011.86; LENZ RK, 1987, P IEEE INT C ROB AUT; Li MX, 1996, IEEE T PATTERN ANAL, V18, P1105, DOI 10.1109/34.544080; Lim S.-N., 2003, P INT C MULT EXP; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lv FJ, 2006, IEEE T PATTERN ANAL, V28, P1513, DOI 10.1109/TPAMI.2006.178; Rosten E., 2009, MACH VISION APPL, V22, P77, DOI DOI 10.1007/S00138-009-0196-9(URL; Sarkis M, 2009, IEEE T AUTOM SCI ENG, V6, P492, DOI 10.1109/TASE.2009.2021350; Schoepflin TN, 2003, IEEE T INTELL TRANSP, V4, P90, DOI 10.1109/TITS.2003.821213; Sinha SN, 2006, COMPUT VIS IMAGE UND, V103, P170, DOI 10.1016/j.cviu.2006.06.002; Song KT, 2006, IEEE T SYST MAN CY B, V36, P1091, DOI 10.1109/TSMCB.2006.872271; Steele R., 2006, P EUR C COMP VIS; Tordoff B, 2004, COMPUT VIS IMAGE UND, V96, P17, DOI 10.1016/j.cviu.2004.06.002; Wu Z., 2012, P IEEE WORKSH CAM NE; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	27	37	44	0	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2013	35	8					1994	2007		10.1109/TPAMI.2012.250	http://dx.doi.org/10.1109/TPAMI.2012.250			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	164AP	23787349				2022-12-18	WOS:000320381400014
J	Wachinger, C; Navab, N				Wachinger, Christian; Navab, Nassir			Simultaneous Registration of Multiple Images: Similarity Metrics and Efficient Optimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Registration; groupwise; simultaneous; optimization; similarity measures; multimodal	MUTUAL-INFORMATION	We address the alignment of a group of images with simultaneous registration. Therefore, we provide further insights into a recently introduced framework for multivariate similarity measures, referred to as accumulated pair-wise estimates (APE), and derive efficient optimization methods for it. More specifically, we show a strict mathematical deduction of APE from a maximum-likelihood framework and establish a connection to the congealing framework. This is only possible after an extension of the congealing framework with neighborhood information. Moreover, we address the increased computational complexity of simultaneous registration by deriving efficient gradient-based optimization strategies for APE: Gauss-Newton and the efficient second-order minimization (ESM). We present next to SSD the usage of intrinsically nonsquared similarity measures in this least squares optimization framework. The fundamental assumption of ESM, the approximation of the perfectly aligned moving image through the fixed image, limits its application to monomodal registration. We therefore incorporate recently proposed structural representations of images which allow us to perform multimodal registration with ESM. Finally, we evaluate the performance of the optimization strategies with respect to the similarity measures, leading to very good results for ESM. The extension to multimodal registration is in this context very interesting because it offers further possibilities for evaluations, due to publicly available datasets with ground-truth alignment.	[Wachinger, Christian] Harvard Univ, Sch Med, Comp Sci & Artificial Intelligence Lab, MIT, Cambridge, MA 02139 USA; [Wachinger, Christian] Harvard Univ, Sch Med, Dept Neurol, Cambridge, MA 02139 USA; [Navab, Nassir] Tech Univ Munich, Dept Informat, Inst Informat I16, D-85748 Garching, Germany	Harvard University; Massachusetts Institute of Technology (MIT); Harvard University; Technical University of Munich	Wachinger, C (corresponding author), Harvard Univ, Sch Med, Comp Sci & Artificial Intelligence Lab, MIT, 32 Vassar St,D462, Cambridge, MA 02139 USA.	wachinge@in.tum.de; navab@cs.tum.edu	Wachinger, Christian/AAA-3046-2019; Christian, Wachinger/L-7358-2016; Peters, Terry M/K-6853-2013	Wachinger, Christian/0000-0002-3652-1874; Christian, Wachinger/0000-0002-3652-1874; Peters, Terry M/0000-0003-1440-7488	European Project "PASSPORT" [223904]; Humboldt foundation	European Project "PASSPORT"; Humboldt foundation(Alexander von Humboldt Foundation)	The authors thank S. Benhimane and D. Zikic for valuable discussions as well as Siemens Corporate Research for ultrasound data. They are very grateful to the unknown reviewers for their insightful comments. This work was partly funded by the European Project "PASSPORT" (ref. number 223904) and the Humboldt foundation. This work was completed while Christian Wachinger was the chair for Computer Aided Medical Procedures at the Technische Universitat Munchen.	Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Benhimane S., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P943; Benhimane S., 2006, VERS APPROCHE UNIFIE; Bishop C.M, 2006, PATTERN RECOGN; Chefd'hotel C, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING, PROCEEDINGS, P753; COOTES TF, 2004, P EUR C COMP VIS; Cox M., 2008, P IEEE C COMP VIS PA; Cox M, 2009, IEEE I CONF COMP VIS, P1949, DOI 10.1109/ICCV.2009.5459430; D'Agostino E, 2003, MED IMAGE ANAL, V7, P565, DOI 10.1016/S1361-8415(03)00039-2; Dame Amaury, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P47, DOI 10.1109/ISMAR.2010.5643550; Hermosillo G, 2002, INT J COMPUT VISION, V50, P329, DOI 10.1023/A:1020830525823; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Huang GB, 2007, IEEE I CONF COMP VIS, P237, DOI 10.1109/iccv.2007.4408858; Learned-Miller EG, 2006, IEEE T PATTERN ANAL, V28, P236, DOI 10.1109/TPAMI.2006.34; Lee PY, 2005, J IND MANAG OPTIM, V1, P565, DOI 10.3934/jimo.2005.1.565; Li S, 2009, MARKOV RANDOM FIELD; Lukas B., 1981, P IM UND WORKSH; Madsen K., 2004, INFORM MATH MODELLIN; Mahony R, 2002, J GLOBAL OPTIM, V23, P309, DOI 10.1023/A:1016586831090; Malis E., 2008, METHODOLOGIES ESTIMA; Metz CT, 2011, MED IMAGE ANAL, V15, P238, DOI 10.1016/j.media.2010.10.003; Murray R. M., 1994, MATH INTRO ROBOTIC M; Panin G, 2008, INT J COMPUT VISION, V78, P107, DOI 10.1007/s11263-007-0083-7; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867; Roche A, 2000, INT J IMAG SYST TECH, V11, P71, DOI 10.1002/(SICI)1098-1098(2000)11:1<71::AID-IMA8>3.0.CO;2-5; Sidorov K., 2009, P IEEE C COMP VIS PA; Stefanescu R, 2004, MED IMAGE ANAL, V8, P325, DOI 10.1016/j.media.2004.06.010; Studholme C, 2004, PATTERN RECOGN LETT, V25, P1191, DOI 10.1016/j.patrec.2004.03.015; Thevenaz P, 2000, IEEE T IMAGE PROCESS, V9, P2083, DOI 10.1109/83.887976; Turlach B.A., 1993, CORE I STAT; Vercauteren T., 2007, P INT C INF PROC MED; Vercauteren T, 2009, NEUROIMAGE, V45, pS61, DOI 10.1016/j.neuroimage.2008.10.040; VIOLA P, 1995, THESIS MIT; Wachinger C., 2007, THESIS TU MUNCHEN; Wachinger C., 2012, P IEEE C COMP VIS PA; Wachinger C., 2007, P INT C MED IM COMP; Wachinger C., 2010, PROC IEEE COMPUT SOC, P95; Wachinger C., 2010, P 11 BRIT MACH VIS C; Wachinger C., 2009, P IEEE C COMP VIS PA; Wells W M 3rd, 1996, Med Image Anal, V1, P35; West J, 1997, J COMPUT ASSIST TOMO, V21, P554, DOI 10.1097/00004728-199707000-00007; Yigitsoy M., 2011, P INT C INF PROC MED; Zefran M, 1998, IEEE T ROBOTIC AUTOM, V14, P576, DOI 10.1109/70.704225; Zollei L., 2006, THESIS MIT; Zollei L., 2005, P INT C COMP VIS BIO	46	37	38	1	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2013	35	5					1221	1233		10.1109/TPAMI.2012.196	http://dx.doi.org/10.1109/TPAMI.2012.196			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	106EZ	23520261	Green Submitted			2022-12-18	WOS:000316126800015
J	Sangineto, E				Sangineto, Enver			Pose and Expression Independent Facial Landmark Localization Using Dense-SURF and the Hausdorff Distance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Facial feature detection; head pose estimation; Hausdorff distance; efficient feature extraction	FACE-RECOGNITION; FEATURE TRACKING; MODELS	We present an approach to automatic localization of facial feature points which deals with pose, expression, and identity variations combining 3D shape models with local image patch classification. The latter is performed by means of densely extracted SURF-like features, which we call DU-SURF, while the former is based on a multiclass version of the Hausdorff distance to address local classification errors and nonvisible points. The final system is able to localize facial points in real-world scenarios, dealing with out of plane head, rotations, expression changes, and different lighting conditions. Extensive experimentation with the proposed method has been carried out showing the superiority of our approach with respect to other state-of-the-art systems. Finally, DU-SURF features have been compared with other modern features and we experimentally demonstrate their competitive classification accuracy and computational efficiency.	Ist Italiano Tecnol, Pattern Anal & Comp Vis PAVIS, I-16163 Genoa, Italy	Istituto Italiano di Tecnologia - IIT	Sangineto, E (corresponding author), Ist Italiano Tecnol, Pattern Anal & Comp Vis PAVIS, Via Morego 30, I-16163 Genoa, Italy.	Enver.Sangineto@iit.it	Sangineto, Enver/AAS-9542-2020					Agrawal M., 2008, P EUR C COMP VIS; Salah AA, 2007, ANN TELECOMMUN, V62, P83; Asteriadis S, 2009, PATTERN RECOGN, V42, P1388, DOI 10.1016/j.patcog.2009.01.009; Ballard D.H., 1982, COMPUTER VISION; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602; Bishop, 1995, NEURAL NETWORKS PATT; Black J., 2002, P C INT MULT SYST 2; Calonder M., 2010, P EUR C COMP VIS; Caunce A., 2009, P INT S VIS COMP; Celik T, 2008, COMPUT VIS IMAGE UND, V111, P229, DOI 10.1016/j.cviu.2007.12.001; Chen L., 2004, P INT C AUT FAC GEST; Christoudias CM, 2005, PROC CVPR IEEE, P1067; Conde C, 2006, IEEE IMAGE PROC, P2061, DOI 10.1109/ICIP.2006.312863; Cootes TF, 2002, IMAGE VISION COMPUT, V20, P657, DOI 10.1016/S0262-8856(02)00055-0; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; CRISTINACCE D., 2004, P BRIT MACH VIS C, P277; Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024; Equinox Corp, 2012, DARPAS HUMANID PROGR; Evans C., 2009, CSTR09001 U BRIST; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Felzenszwalb P. F., 2004, TECHNICAL REPORT; Fergus R, 2003, PROC CVPR IEEE, P264; Forsyth David A, 2012, COMPUTER VISION MODE; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Gizatdinova Y, 2006, IEEE T PATTERN ANAL, V28, P135, DOI 10.1109/TPAMI.2006.10; Gourier N., 2004, P IEEE INT C SYST MA; Gourier N., 2004, P ICPR WORKSH VIS OB; Gu L., 2008, P 10 EUR C COMP VIS; Gu L., 2006, P IEEE C COMP VIS PA; Hanif SM, 2008, PATTERN RECOGN LETT, V29, P1094, DOI 10.1016/j.patrec.2007.09.016; Hess R., 2007, TECHNICAL REPORT; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Jebara T., 1997, P IEEE C COMP VIS PA; Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90; Kozakaya T, 2010, IMAGE VISION COMPUT, V28, P772, DOI 10.1016/j.imavis.2009.09.008; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Little G., 2005, P IEEE INT C AC SPEE; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Martinez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382; Masschusetts Inst. of Technology and Center for Biological and Computational Learning, 2012, MIT CBCL FAC REC DAT; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Messer K., 1999, P 2 INT C AUDIO VIDE; Micheloni C., 2009, P 16 SCAND C IM AN; Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106; Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58; PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Romdhani S., 1999, BMVC99. Proceedings of the 10th British Machine Vision Conference, P483; Romdhani S., 2007, P IEEE C COMP VIS PA; Sankaran P., 2005, P IEEE C COMP VIS PA; Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4; Selinger A., 2002, 0201 EQ CORP; Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77; Tong Y, 2007, PATTERN RECOGN, V40, P3195, DOI 10.1016/j.patcog.2007.02.021; Tong Y, 2006, INT C PATT RECOG, P307; Valstar M., 2010, P IEEE C COMP VIS PA; Vetter T., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P499, DOI 10.1007/BFb0054761; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Vukadinovic D., 2005, P IEEE INT C SYST MA; Wang T., 2006, P 18 INT C PATT REC; Weyrauch B., 2004, 2004 C COMP VIS PATT, DOI 10.1109/CVPR.2004.315; Xiao J, 2004, PROC CVPR IEEE, P535; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	66	37	41	0	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2013	35	3					624	638		10.1109/TPAMI.2012.87	http://dx.doi.org/10.1109/TPAMI.2012.87			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	087VS	22487982				2022-12-18	WOS:000314792900009
J	Duan, LX; Xu, D; Tsang, IWH; Luo, JB				Duan, Lixin; Xu, Dong; Tsang, Ivor Wai-Hung; Luo, Jiebo			Visual Event Recognition in Videos by Learning from Web Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Event recognition; transfer learning; domain adaptation; cross-domain learning; adaptive MKL; aligned space-time pyramid matching	KERNEL; CONTEXT; IMAGES; SVM	We propose a visual event recognition framework for consumer videos by leveraging a large amount of loosely labeled web videos (e.g., from YouTube). Observing that consumer videos generally contain large intraclass variations within the same type of events, we first propose a new method, called Aligned Space-Time Pyramid Matching (ASTPM), to measure the distance between any two video clips. Second, we propose a new transfer learning method, referred to as Adaptive Multiple Kernel Learning (A-MKL), in order to 1) fuse the information from multiple pyramid levels and features (i.e., space-time features and static SIFT features) and 2) cope with the considerable variation in feature distributions between videos from two domains (i.e., web video domain and consumer video domain). For each pyramid level and each type of local features, we first train a set of SVM classifiers based on the combined training set from two domains by using multiple base kernels from different kernel types and parameters, which are then fused with equal weights to obtain a prelearned average classifier. In A-MKL, for each event class we learn an adapted target classifier based on multiple base kernels and the prelearned average classifiers from this event class or all the event classes by minimizing both the structural risk functional and the mismatch between data distributions of two domains. Extensive experiments demonstrate the effectiveness of our proposed framework that requires only a small number of labeled consumer videos by leveraging web data. We also conduct an in-depth investigation on various aspects of the proposed method A-MKL, such as the analysis on the combination coefficients on the prelearned classifiers, the convergence of the learning algorithm, and the performance variation by using different proportions of labeled consumer videos. Moreover, we show that A-MKL using the prelearned classifiers from all the event classes leads to better performance when compared with A-MKL using the prelearned classifiers only from each individual event class.	[Duan, Lixin; Xu, Dong; Tsang, Ivor Wai-Hung] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; [Luo, Jiebo] Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; University of Rochester	Duan, LX (corresponding author), Nanyang Technol Univ, Sch Comp Engn, N4-02A-29 Nanyang Ave, Singapore 639798, Singapore.	S080003@ntu.edu.sg; DongXu@ntu.edu.sg; IvorTsang@ntu.edu.sg; jluo@cs.rochester.edu	Xu, Dong/A-3694-2011; Luo, Jiebo/AAI-7549-2020; Tsang, Ivor/E-8653-2011; Hajra, Suvadeep/L-8460-2015	Xu, Dong/0000-0003-2775-9730; Tsang, Ivor/0000-0003-2211-8176; Tsang, Ivor/0000-0001-8095-4637; Luo, Jiebo/0000-0002-4516-9729	Singapore A<SUP>star</SUP>STAR SERC [082 101 0018]	Singapore A<SUP>star</SUP>STAR SERC	This work is supported by Singapore A<SUP>star</SUP>STAR SERC Grant (082 101 0018).	[Anonymous], 2007, P 15 ACM INT C MULTI; Blank M, 2005, IEEE I CONF COMP VIS, P1395; Blitzer J., 2006, P 2006 C EMP METH NA, P120, DOI DOI 10.3115/1610075.1610094; Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242; Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chang S.-F., 2007, P INT WORKSH MULT IN, P255; Daume III Hal, 2007, P 45 ANN M ASS COMP, P256, DOI DOI 10.48550/ARXIV.0907.1815; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Duan Lixin, 2012, IEEE Trans Neural Netw Learn Syst, V23, P504, DOI 10.1109/TNNLS.2011.2178556; Duan LX, 2010, PROC CVPR IEEE, P1959, DOI 10.1109/CVPR.2010.5539870; Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPR.2009.5206747, 10.1109/CVPRW.2009.5206747]; Duchenne O, 2009, IEEE I CONF COMP VIS, P1491, DOI 10.1109/ICCV.2009.5459279; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; Hu YX, 2009, IEEE I CONF COMP VIS, P128, DOI 10.1109/ICCV.2009.5459153; Ikizler-Cinbis N, 2010, LECT NOTES COMPUT SC, V6311, P494, DOI 10.1007/978-3-642-15549-9_36; Ikizler-Cinbis N, 2009, IEEE I CONF COMP VIS, P995, DOI 10.1109/ICCV.2009.5459368; Jensen P.A., 2003, OPERATIONS RES MODEL; Liu Jiaomin, 2009, Proceedings of the 2009 Second International Conference on Intelligent Networks and Intelligent Systems (ICINIS 2009), P15, DOI [10.1109/CVPRW.2009.5206744, 10.1109/ICINIS.2009.13]; Ke Y, 2005, IEEE I CONF COMP VIS, P166; Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881; Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702; Kwok J. T., 2003, P 20 INT C MACH LEAR, P400; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Lin Z, 2009, IEEE I CONF COMP VIS, P444; Liu YM, 2011, IEEE T PATTERN ANAL, V33, P1022, DOI 10.1109/TPAMI.2010.142; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Pele O, 2009, IEEE I CONF COMP VIS, P460, DOI 10.1109/ICCV.2009.5459199; Peursum P, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS (PERCOM 2003), P399, DOI 10.1109/PERCOM.2003.1192764; Qi GJ, 2011, PROC CVPR IEEE, P897, DOI 10.1109/CVPR.2011.5995312; Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491; Rohrbach M, 2010, PROC CVPR IEEE, P910, DOI 10.1109/CVPR.2010.5540121; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Smola AJ, 1999, ADV NEUR IN, V11, P585; Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594; Wang XJ, 2008, IEEE T PATTERN ANAL, V30, P1919, DOI 10.1109/TPAMI.2008.127; Wu XX, 2011, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.2011.5995624; Xu D, 2008, IEEE T PATTERN ANAL, V30, P1985, DOI 10.1109/TPAMI.2008.129; Xu D, 2010, IEEE T CIRC SYST VID, V20, P1068, DOI 10.1109/TCSVT.2010.2051286; Yanagawa A, KODAK CONSUMER VIDEO	50	37	39	2	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2012	34	9					1667	1680		10.1109/TPAMI.2011.265	http://dx.doi.org/10.1109/TPAMI.2011.265			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	974DD	22201057				2022-12-18	WOS:000306409100002
J	Shen, CH; Wang, P; Shen, FM; Wang, HZ				Shen, Chunhua; Wang, Peng; Shen, Fumin; Wang, Hanzi			uBoost: Boosting with the Universum	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Universum; kernel methods; boosting; column generation; convex optimization	MULTILINEAR ANALYSIS	It has been shown that the Universum data, which do not belong to either class of the classification problem of interest, may contain useful prior domain knowledge for training a classifier [1], [2]. In this work, we design a novel boosting algorithm that takes advantage of the available Universum data, hence the name UBoost. UBoost is a boosting implementation of Vapnik's alternative capacity concept to the large margin approach. In addition to the standard regularization term, UBoost also controls the learned model's capacity by maximizing the number of observed contradictions. Our experiments demonstrate that UBoost can deliver improved classification accuracy over standard boosting algorithms that use labeled data alone.	[Shen, Chunhua] Univ Adelaide, Australian Ctr Visual Technol, Adelaide, SA 5005, Australia; [Shen, Chunhua; Wang, Hanzi] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Wang, Peng] Beihang Univ, Sch Automat Sci & Elect Engn, Beijing 100191, Peoples R China; [Shen, Fumin] Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Jiangsu, Peoples R China; [Wang, Hanzi] Xiamen Univ, Sch Informat Sci & Technol, Dept Cognit Sci, Xiamen 361005, Fujian, Peoples R China; [Wang, Hanzi] Xiamen Univ, Fujian Key Lab Brain Intelligent Syst, Xiamen 361005, Fujian, Peoples R China	University of Adelaide; University of Adelaide; Beihang University; Nanjing University of Science & Technology; Xiamen University; Xiamen University	Wang, HZ (corresponding author), Xiamen Univ, Sch Informat Sci & Technol, Dept Cognit Sci, Xiamen 361005, Fujian, Peoples R China.	chunhua.shen@adelaide.edu.au; wangpengnorman@gmail.com; fumin.shen@gmail.com; hanzi.wang@ieee.org	Wang, Hanzi/F-8796-2012; Shen, Fumin/R-2121-2016		NSFC [61170179]; Xiamen Science and Technology Planning project of China [3502Z20116005]	NSFC(National Natural Science Foundation of China (NSFC)); Xiamen Science and Technology Planning project of China	Peng Wang's contribution was made while he was visiting NICTA, Canberra Research Laboratory, Australia. Fumin Shen's contribution was made while he was visiting the School of Computer Science, University of Adelaide. Hanzi Wang was supported by NSFC under project 61170179 and by the Xiamen Science and Technology Planning project (3502Z20116005) of China.	Bai X, 2008, IEEE IJCNN, P746, DOI 10.1109/IJCNN.2008.4633879; Boyd S, 2004, CONVEX OPTIMIZATION; Collins M, 2002, MACH LEARN, V48, P253, DOI 10.1023/A:1013912006537; Demiriz A, 2002, MACH LEARN, V46, P225, DOI 10.1023/A:1012470815092; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Maji S., 2009, UCBEECS2009159 DEP C; Mason L, 2000, ADV NEUR IN, V12, P512; Meir R., 2003, Advanced Lectures on Machine Learning. Machine Learning Summer School 2002. Revised Lectures. (Lecture Notes in Artificial Intelligence Vol.2600), P118; Peng B, 2009, PATTERN RECOGN LETT, V30, P1289, DOI 10.1016/j.patrec.2009.06.007; Peng B, 2008, LECT NOTES COMPUT SC, V5359, P581, DOI 10.1007/978-3-540-89646-3_57; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Shen CH, 2010, LECT NOTES COMPUT SC, V6312, P608, DOI 10.1007/978-3-642-15552-9_44; Shen CH, 2010, IEEE T PATTERN ANAL, V32, P2216, DOI 10.1109/TPAMI.2010.47; Shen CH, 2010, IEEE T NEURAL NETWOR, V21, P659, DOI 10.1109/TNN.2010.2040484; Sinz F.H., 2007, ADV NEURAL INF PROCE, V7, P1; Slonim N, 2000, ADV NEUR IN, V12, P617; Vapnik V.N., 2006, ESTIMATION DEPENDENC, VVolume 40; Weston J., 2006, P 23 INT C MACHINE L, P1009; Zhang D., 2008, SDM, P323; Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236	22	37	39	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2012	34	4					825	832		10.1109/TPAMI.2011.240	http://dx.doi.org/10.1109/TPAMI.2011.240			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	896PO	22156096	Green Published			2022-12-18	WOS:000300581700016
J	Laligant, O; Truchetet, F				Laligant, Olivier; Truchetet, Frederic			A Nonlinear Derivative Scheme Applied to Edge Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Edge detection; regularization filter; edge localization; edge model; neighbor edge; discrete approach; nonlinear derivative; noises; performance measure	CRITERIA; FILTERS; LOCALIZATION; DESIGN	This paper presents a nonlinear derivative approach to addressing the problem of discrete edge detection. This edge detection scheme is based on the nonlinear combination of two polarized derivatives. Its main property is a favorable signal-to-noise ratio (SNR) at a very low computation cost and without any regularization. A 2D extension of the method is presented and the benefits of the 2D localization are discussed. The performance of the localization and SNR are compared to that obtained using classical edge detection schemes. Tests of the regularized versions and a theoretical estimation of the SNR improvement complete this work.	[Laligant, Olivier; Truchetet, Frederic] Univ Bourgogne, CNRS, UMR5158, IUT,Le2i Lab, F-71200 Le Creusot, France	Centre National de la Recherche Scientifique (CNRS); Universite de Bourgogne	Laligant, O (corresponding author), Univ Bourgogne, CNRS, UMR5158, IUT,Le2i Lab, 12 Rue Fonderie, F-71200 Le Creusot, France.	olivier.laligant@u-bourgogne.fr; f.truchetet@u-bourgogne.fr						ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325; Benazza-Benyahia A, 2003, IEEE SIGNAL PROC LET, V10, P360, DOI 10.1109/LSP.2003.818864; Bolon P., 1990, P 5 EUR SIGN PROC C, P813; Bourennane E, 2002, SIGNAL PROCESS, V82, P1317, DOI 10.1016/S0165-1684(02)00283-9; BOYER KL, 1994, IEEE T PATTERN ANAL, V16, P106, DOI 10.1109/34.273710; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; Chen K, 2005, IEEE T PATTERN ANAL, V27, P1552, DOI 10.1109/TPAMI.2005.190; Demigny D, 1997, IEEE T PATTERN ANAL, V19, P1199, DOI 10.1109/34.632980; Demigny D, 2002, IEEE T IMAGE PROCESS, V11, P728, DOI 10.1109/TIP.2002.800887; DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164; Eklundh J-O., 1982, P IEEE INT C PATT RE, V6, P1109; HWANG H, 1994, IEEE T SIGNAL PROCES, V42, P249, DOI 10.1109/78.275599; Jacob M, 2004, IEEE T PATTERN ANAL, V26, P1007, DOI 10.1109/TPAMI.2004.44; Kumar S, 2006, IEEE T PATTERN ANAL, V28, P2042, DOI 10.1109/TPAMI.2006.236; Laligant O, 2007, IEEE SIGNAL PROC LET, V14, P185, DOI 10.1109/LSP.2006.884030; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; MODESTINO JW, 1977, COMPUT GRAPHICS IMAG, V6, P409; PETROU M, 1991, IEEE T PATTERN ANAL, V13, P483, DOI 10.1109/34.134047; PITAS I, 1986, IEEE T ACOUST SPEECH, V34, P573, DOI 10.1109/TASSP.1986.1164857; SCHULZE MA, 1997, NONLINEAR IMAGE PROC, V8, P46; Tabbone S., 1992, Proceedings. 11th IAPR International Conference on Pattern Recognition. Vol.III. Conference C: Image, Speech and Signal Analysis, P655, DOI 10.1109/ICPR.1992.202071; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; Truchetet F, 2001, J ELECTRON IMAGING, V10, P234, DOI 10.1117/1.1316089; ZIOU D, 1991, PATTERN RECOGN, V24, P465, DOI 10.1016/0031-3203(91)90014-V	24	37	41	2	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2010	32	2					242	257		10.1109/TPAMI.2008.282	http://dx.doi.org/10.1109/TPAMI.2008.282			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	532IT	20075456				2022-12-18	WOS:000272741500005
J	Pillonetto, G; Dinuzzo, F; De Nicolao, G				Pillonetto, Gianluigi; Dinuzzo, Francesco; De Nicolao, Giuseppe			Bayesian Online Multitask Learning of Gaussian Processes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Collaborative filtering; multitask learning; mixed effects model; kernel methods; regularization; Gaussian processes; Kalman filtering; pharmacokinetic data	POPULATION; MODELS	Standard single-task kernel methods have recently been extended to the case of multitask learning in the context of regularization theory. There are experimental results, especially in biomedicine, showing the benefit of the multitask approach compared to the single-task one. However, a possible drawback is computational complexity. For instance, when regularization networks are used, complexity scales as the cube of the overall number of training data, which may be large when several tasks are involved. The aim of this paper is to derive an efficient computational scheme for an important class of multitask kernels. More precisely, a quadratic loss is assumed and each task consists of the sum of a common term and a task-specific one. Within a Bayesian setting, a recursive online algorithm is obtained, which updates both estimates and confidence intervals as new data become available. The algorithm is tested on two simulated problems and a real data set relative to xenobiotics administration in human patients.	[Pillonetto, Gianluigi] Univ Padua, Dept Informat Engn, I-35131 Padua, Italy; [Dinuzzo, Francesco] Univ Pavia, Dept Math, I-27100 Pavia, Italy; [De Nicolao, Giuseppe] Univ Pavia, Dipartimento Informat & Sistemist, I-27100 Pavia, Italy	University of Padua; University of Pavia; University of Pavia	Pillonetto, G (corresponding author), Univ Padua, Dept Informat Engn, Via Gradenigo 6-B, I-35131 Padua, Italy.	giapi@dei.unipd.it; francesco.dinuzzo@gmail.com; giuseppe.denicolao@unipv.it			FIRB Project; PRIN Projects; European Community's Seventh Framework Programme [FP7-ICT-223866-FeedNetBack]	FIRB Project; PRIN Projects(Ministry of Education, Universities and Research (MIUR)Research Projects of National Relevance (PRIN)); European Community's Seventh Framework Programme	This research has been partially supported by FIRB Project "Learning theory and application," by the PRIN Projects " New Methods and Algorithms for Identification and Adaptive Control of Technological Systems" and " Artificial Pancreas: physiological models, control algorithms, and clinical test," and by the European Community's Seventh Framework Programme under agreement n. FP7-ICT-223866-FeedNetBack. Data described in [45] were downloaded from the Web site of the Resource Facility for Population Kinetics (http://www.rfpk.washington.edu).	Anderson B. D. O., 1979, OPTIMAL FILTERING; Argyriou A., 2006, P 23 INT C MACH LEAR, P41, DOI DOI 10.1145/1143844.1143850; ARGYRIOU A, 2005, P 18 C LEARN THEOR, P338; Bakker B, 2004, J MACH LEARN RES, V4, P83, DOI 10.1162/153244304322765658; BARRY D, 1986, ANN STAT, V14, P934, DOI 10.1214/aos/1176350043; Baxter J, 1997, MACH LEARN, V28, P7, DOI 10.1023/A:1007327622663; Beal B., 1992, NONMEM USERS GUIDE; Bergman RN, 2005, HORM RES, V64, P8, DOI 10.1159/000089312; BERGMAN RN, 1979, AM J PHYSIOL, V236, pE667, DOI 10.1152/ajpendo.1979.236.6.E667; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Csato L, 2002, NEURAL COMPUT, V14, P641, DOI 10.1162/089976602317250933; Davidian M, 1995, NONLINEAR MODELS REP; Evgeniou T, 2005, J MACH LEARN RES, V6, P615; Evgeniou T, 2007, MARKET SCI, V26, P805, DOI 10.1287/mksc.1070.0291; Fattinger KE, 1995, J PHARMACOKINET BIOP, V23, P581, DOI 10.1007/BF02353463; Ferrazzi F., 2003, P 3 INT WORKSH BIOIN, P53; Jacquez J. A., 1985, COMPARTMENTAL ANAL B; KIMELDOR.GS, 1970, ANN MATH STAT, V41, P495, DOI 10.1214/aoms/1177697089; LAWRENCE ND, 2004, P INT C MACH LEARN, V69, P65; LU Z, 2008, P INT C MACH LEARN, P624; Lunn DJ, 2002, J PHARMACOKINET PHAR, V29, P271, DOI 10.1023/A:1020206907668; Magni P, 2002, J PHARMACOKINET PHAR, V29, P445, DOI 10.1023/A:1022920403166; Maritz J.S., 1989, EMPIRICAL BAYES METH, V2nd ed.; Micchelli CA, 2005, NEURAL COMPUT, V17, P177, DOI 10.1162/0899766052530802; Neve M, 2007, AUTOMATICA, V43, P1134, DOI 10.1016/j.automatica.2006.12.024; NEVE M, 2005, P 16 IFAC WORLD C; Neve M, 2008, IEEE T BIO-MED ENG, V55, P41, DOI 10.1109/TBME.2007.902240; Opper M., 1998, ONLINE LEARNING NEUR; Pillonetto G, 2009, AUTOMATICA, V45, P173, DOI 10.1016/j.automatica.2008.06.003; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Ramsay J.O., 1997, FUNCTIONAL DATA ANAL, DOI 10.1007/978-1-4757-7107-7; RAMSAY JO, 1991, J ROY STAT SOC B MET, V53, P539; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; ROCCHETTI M, 1997, POPULATION APPROACH, P385; SCHOLKOPF B, 2001, P 14 ANN C COMP LEAR, P416; Schwaighofer A., 2005, ADV NEURAL INFORM PR, P1209; Seeger M., 2004, 661 U CAL DEP STAT; SHEINER LB, 1984, DRUG METAB REV, V15, P153, DOI 10.3109/03602538409015063; SHEINER LB, 1977, J PHARMACOKINET BIOP, V5, P445, DOI 10.1007/BF01061728; Shiryaev A.N., 1996, GRADUATE TEXTS MATH, V95; Thrun S., 1997, LEARNING LEARN; Vicini P, 2001, AM J PHYSIOL-ENDOC M, V280, pE179, DOI 10.1152/ajpendo.2001.280.1.E179; Wahba G., 1990, SPLINE MODELS OBSERV; WAKEFIELD JC, 1994, APPL STAT-J ROY ST C, V43, P201; Yu K., 2005, P 22 INT C MACH LEAR, P1012, DOI DOI 10.1145/1102351.1102479	45	37	38	2	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2010	32	2					193	205		10.1109/TPAMI.2008.297	http://dx.doi.org/10.1109/TPAMI.2008.297			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	532IT	20075452	Green Submitted			2022-12-18	WOS:000272741500001
J	Wang, HZ; Mirota, D; Hager, GD				Wang, Hanzi; Mirota, Daniel; Hager, Gregory D.			A Generalized Kernel Consensus-Based Robust Estimator	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Robust statistics; model fitting; kernel density estimation; motion estimation; pose estimation	RANGE IMAGE SEGMENTATION	In this paper, we present a new Adaptive-Scale Kernel Consensus (ASKC) robust estimator as a generalization of the popular and state-of-the-art robust estimators such as RANdom SAmple Consensus (RANSAC), Adaptive Scale Sample Consensus (ASSC), and Maximum Kernel Density Estimator (MKDE). The ASKC framework is grounded on and unifies these robust estimators using nonparametric kernel density estimation theory. In particular, we show that each of these methods is a special case of ASKC using a specific kernel. Like these methods, ASKC can tolerate more than 50 percent outliers, but it can also automatically estimate the scale of inliers. We apply ASKC to two important areas in computer vision, robust motion estimation and pose estimation, and show comparative results on both synthetic and real data.	[Wang, Hanzi] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Mirota, Daniel; Hager, Gregory D.] Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA	University of Adelaide; Johns Hopkins University	Wang, HZ (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.	hanzi.wang@ieee.org; dan@cs.jhu.edu; hager@cs.jhu.edu	Wang, Hanzi/F-8796-2012; Hager, Gregory D/A-3222-2010		US National Institutes of Health [R21EB005201]; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [R21EB005201, R01EB015530] Funding Source: NIH RePORTER	US National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB))	Parts of the work described in this paper appeared in [26], [27]. The authors thank the anonymous reviewers of those papers, and the TPAMI reviewers, Professors David Suter and Russell H. Taylor for their valuable comments and suggestions. The authors also thank Professor Darius Burschka for providing the endoscopic sinus image data. The work was supported by the US National Institutes of Health under grant number R21EB005201 and was done when H. Wang was at Johns Hopkins University.	Bab-Hadiashar A, 1998, INT J COMPUT VISION, V29, P59, DOI 10.1023/A:1008090730467; Bab-Hadiashar A, 2006, IEEE T IMAGE PROCESS, V15, P2006, DOI 10.1109/TIP.2006.877064; Chen HF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P878, DOI 10.1109/ICCV.2003.1238441; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Hartley R., 2004, ROBOTICA; Huber P., 1981, ROBUST STAT; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; JONES MC, 1987, J ROY STAT SOC A STA, V150, P1, DOI 10.2307/2981662; Lavva I, 2008, IEEE T SYST MAN CY B, V38, P826, DOI 10.1109/TSMCB.2008.918567; Lee KM, 1998, IEEE T PATTERN ANAL, V20, P200, DOI 10.1109/34.659940; Li HD, 2006, INT C PATT RECOG, P630; Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199; Miller JV, 1996, PROC CVPR IEEE, P300, DOI 10.1109/CVPR.1996.517089; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; Papenberg N, 2006, INT J COMPUT VISION, V67, P141, DOI 10.1007/s11263-005-3960-y; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; ROUSSEEUW PJ, 1993, J AM STAT ASSOC, V88, P1273, DOI 10.2307/2291267; Rozenfeld S, 2005, PROC CVPR IEEE, P1113; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; SUBBARAO R, 2005, P WORKSH EMP EV METH; TERRELL GR, 1985, J AM STAT ASSOC, V80, P209, DOI 10.2307/2288074; TERRELL GR, 1990, J AM STAT ASSOC, V85, P470, DOI 10.2307/2289786; TORDOFF B, 2002, P 7 ECCV, V1, P82; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; Wand M.P., 1995, KERNEL SMOOTHING; Wang H., 2008, P IEEE C COMP VIS PA; Wang HZ, 2008, INT CONF ACOUST SPEE, P3385; Wang HZ, 2004, IEEE T PATTERN ANAL, V26, P1459, DOI 10.1109/TPAMI.2004.109; YU XM, 1994, IEEE T PATTERN ANAL, V16, P530, DOI 10.1109/34.291443	29	37	44	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2010	32	1					178	184		10.1109/TPAMI.2009.148	http://dx.doi.org/10.1109/TPAMI.2009.148			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	520FQ	19926908	Green Accepted			2022-12-18	WOS:000271826700015
J	Sladoje, N; Lindblad, J				Sladoje, Natasa; Lindblad, Joakim			High-Precision Boundary Length Estimation by Utilizing Gray-Level Information	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Size and shape; length estimate; perimeter; pixel coverage; gray level; quantization	REPRESENTATION; LINES; AREA	We present a novel method that provides an accurate and precise estimate of the length of the boundary (perimeter) of an object by taking into account gray levels on the boundary of the digitization of the same object. Assuming a model where pixel intensity is proportional to the coverage of a pixel, we show that the presented method provides error-free measurements of the length of straight boundary segments in the case of nonquantized pixel values. For a more realistic situation, where pixel values are quantized, we derive optimal estimates that minimize the maximal estimation error. We show that the estimate converges toward a correct value as the number of gray levels tends toward infinity. The method is easy to implement; we provide the complete pseudocode. Since the method utilizes only a small neighborhood, it is very easy to parallelize. We evaluate the estimator on a set of concave and convex shapes with known perimeters, digitized at increasing resolution. In addition, we provide an example of applicability of the method on real images, by suggesting appropriate preprocessing steps and presenting results of a comparison of the suggested method with other local approaches.	[Sladoje, Natasa] Univ Novi Sad, Fac Engn, Novi Sad 21000, Serbia; [Lindblad, Joakim] SLU, Ctr Image Anal, SE-75105 Uppsala, Sweden	University of Novi Sad; Swedish University of Agricultural Sciences	Sladoje, N (corresponding author), Univ Novi Sad, Fac Engn, Trg Dositeja Obradovica 6, Novi Sad 21000, Serbia.	sladoje@uns.ns.ac.yu; joakim@cb.uu.se	Lindblad, Joakim/F-1960-2016	Lindblad, Joakim/0000-0001-7312-8222	Ministry of Science of the Republic of Serbia [ON144018, ON144029]; Mathematical Institute of the Serbian Academy of Science and Arts	Ministry of Science of the Republic of Serbia(Ministry of Education, Science & Technological Development, Serbia); Mathematical Institute of the Serbian Academy of Science and Arts	Natasa Sladoje is financially supported by the Ministry of Science of the Republic of Serbia through the Projects ON144018 and ON144029 of the Mathematical Institute of the Serbian Academy of Science and Arts.	Coeurjolly D, 2004, IEEE T PATTERN ANAL, V26, P252, DOI 10.1109/TPAMI.2004.1262194; DORST L, 1987, COMPUT VISION GRAPH, V40, P311, DOI 10.1016/S0734-189X(87)80145-7; EBERLY D, 1991, CVGIP-GRAPH MODEL IM, V53, P538, DOI 10.1016/1049-9652(91)90004-4; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; KIRYATI N, 1991, CVGIP-GRAPH MODEL IM, V53, P31, DOI 10.1016/1049-9652(91)90017-E; Klette R., 2000, Machine Graphics & Vision, V9, P673; Klette R, 2000, J MATH IMAGING VIS, V13, P173, DOI 10.1023/A:1011289414377; Kulpa Z., 1977, COMPUTER GRAPHICS IM, V6, P434, DOI [10.1016/S0146-664X(77)80021-X, DOI 10.1016/S0146-664X(77)80021-X]; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; PROFFITT D, 1979, COMPUT VISION GRAPH, V10, P318, DOI 10.1016/S0146-664X(79)80041-6; SLADOJE N, 2008, 33 CTR IM AN; SLADOJE N, 1998, P 13 C APPL MATH, P121; TAJINE M, 2003, P 11 INT C DISCR GEO, P114; Verbeek P. W., 1993, Bioimaging, V1, P47, DOI 10.1002/1361-6374(199303)1:1<47::AID-BIO8>3.3.CO;2-Z; VERWER BJH, 1991, PATTERN RECOGN LETT, V12, P671, DOI 10.1016/0167-8655(91)90004-6; VOSSEPOEL AM, 1982, COMPUT VISION GRAPH, V20, P347, DOI 10.1016/0146-664X(82)90057-0	16	37	42	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2009	31	2					357	363		10.1109/TPAMI.2008.184	http://dx.doi.org/10.1109/TPAMI.2008.184			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	385XL	19110499				2022-12-18	WOS:000261846800012
J	Tombari, F; Mattoccia, S; Di Stefano, L				Tombari, Federico; Mattoccia, Stefano; Di Stefano, Luigi			Full-Search-Equivalent Pattern Matching with Incremental Dissimilarity Approximations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pattern matching; IDA; SSD; SAD; efficient; full-search equivalent	ALGORITHMS	This paper proposes a novel method for fast pattern matching based on dissimilarity functions derived from the L-p norm, such as the Sum of Squared Differences (SSD) and the Sum of Absolute Differences (SAD). The proposed method is a full-search equivalent, i. e., it yields the same results as the Full Search (FS) algorithm. In order to pursue computational savings, the method deploys a succession of increasingly tighter lower bounds of the adopted L-p norm-based dissimilarity function. Such bounding functions allow for establishing a hierarchy of pruning conditions aimed at rapidly skipping those candidates that cannot satisfy the matching criterion. The paper includes an experimental comparison between the proposed method and other FS-equivalent approaches known in the literature, which proves the remarkable computational efficiency of our proposal.	[Tombari, Federico; Mattoccia, Stefano; Di Stefano, Luigi] Univ Bologna, DEIS, ARCES, I-40136 Bologna, Italy	University of Bologna	Tombari, F (corresponding author), Univ Bologna, DEIS, ARCES, Viale Risorgimento 2, I-40136 Bologna, Italy.	federico.tombari@unibo.it; stefano.mattoccia@unibo.it; luigi.distefano@unibo.it	Mattoccia, Stefano/AAV-6931-2021; Mattoccia, Stefano/C-5410-2018	Mattoccia, Stefano/0000-0002-3681-7704; Mattoccia, Stefano/0000-0002-3681-7704; Tombari, Federico/0000-0001-5598-5212				BARNEA DI, 1972, IEEE T COMPUT, VC 21, P179, DOI 10.1109/TC.1972.5008923; Crow F. C., 1984, Computers & Graphics, V18, P207; Gao JP, 2000, TRIBOL LETT, V9, P3, DOI 10.1023/A:1018840023845; Goshtasby AA, 2005, 2-D AND 3-D IMAGE REGISTRATION FOR MEDICAL, REMOTE SENSING, AND INDUSTRIAL APPLICATIONS, P1; Hel-Or Y, 2005, IEEE T PATTERN ANAL, V27, P1430, DOI 10.1109/TPAMI.2005.184; Lee CH, 1997, IEEE T IMAGE PROCESS, V6, P1587, DOI 10.1109/83.641419; LEWIS JP, 1995, P VIS INT, P120; MCDONNELL MJ, 1981, COMPUT VISION GRAPH, V17, P65, DOI 10.1016/S0146-664X(81)80009-3; Pan ZB, 2005, IEEE SIGNAL PROC LET, V12, P609, DOI 10.1109/LSP.2005.851263; Royden HL, 1988, REAL ANAL; Sun CM, 2006, PATTERN RECOGN LETT, V27, P556, DOI 10.1016/j.patrec.2005.09.020; TOMBARI F, 2006, P IEEE INT C ADV VID; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	14	37	41	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2009	31	1					129	141		10.1109/TPAMI.2008.46	http://dx.doi.org/10.1109/TPAMI.2008.46			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	372GI	19029551	Green Submitted			2022-12-18	WOS:000260889700011
J	Reddy, CK; Chiang, HD; Rajaratnam, B				Reddy, Chandan K.; Chiang, Hsiao-Dong; Rajaratnam, Bala			TRUST-TECH-based Expectation Maximization for learning finite mixture models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Expectation maximization; unsupervised learning; finite mixture models; dynamical systems; stability regions; model-based clustering	EM ALGORITHM; CLASSIFICATION	The Expectation Maximization (EM) algorithm is widely used for learning finite mixture models despite its greedy nature. Most popular model-based clustering techniques might yield poor clusters if the parameters are not initialized properly. To reduce the sensitivity of initial points, a novel algorithm for learning mixture models from multivariate data is introduced in this paper. The proposed algorithm takes advantage of TRUST-TECH (TRansformation Under STability-reTaining Equilibria CHaracterization) to compute neighborhood local maxima on the likelihood surface using stability regions. Basically, our method coalesces the advantages of the traditional EM with that of the dynamic and geometric characteristics of the stability regions of the corresponding nonlinear dynamical system of the log-likelihood function. Two phases, namely, the EM phase and the stability region phase, are repeated alternatively in the parameter space to achieve local maxima with improved likelihood values. The EM phase obtains the local maximum of the likelihood function and the stability region phase helps to escape out of the local maximum by moving toward the neighboring stability regions. Though applied to Gaussian mixtures in this paper, our technique can be easily generalized to any other parametric finite mixture model. The algorithm has been tested on both synthetic and real data sets and the improvements in the performance compared to other approaches are demonstrated. The robustness with respect to initialization is also illustrated experimentally.	[Reddy, Chandan K.] Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA; [Chiang, Hsiao-Dong] Cornell Univ, Dept Elect & Comp Engn, Ithaca, NY 14853 USA; [Rajaratnam, Bala] Stanford Univ, Dept Stat, Stanford, CA 94305 USA	Wayne State University; Cornell University; Stanford University	Reddy, CK (corresponding author), Wayne State Univ, Dept Comp Sci, 5143 Cass Ave,452 State Hall, Detroit, MI 48202 USA.	reddy@cs.wayne.edu; chiang@ece.cornell.edu; brajarat@stanford.edu		Reddy, Chandan/0000-0003-2839-3662				BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; Bilmes J.A., 1998, INT COMPUT SCI I, V4, P126; Blake C. L., UCI REPOSITORY MACHI; Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; Chiang HD, 1996, IEEE T CIRCUITS-I, V43, P99, DOI 10.1109/81.486432; DEMSPTER AP, 1977, J ROYAL STAT SOC B, V39, P38; Elidan G, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P132; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Ghahramani Zoubin, 1996, CRGTR961 U TOR; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; Hastie T, 1996, J ROY STAT SOC B MET, V58, P155; Lee J, 2004, IEEE T AUTOMAT CONTR, V49, P888, DOI 10.1109/TAC.2004.829603; Li J., 1999, THESIS YALE U; LU Z, 2005, P NEUR INF PROC SYST; Martinez AM, 2000, PATTERN RECOGN LETT, V21, P759, DOI 10.1016/S0167-8655(00)00031-3; McLachlan, 1997, EM ALGORITHM EXTENSI; Mclachlan G., 2000, WILEY SER PROB STAT; McLachlan G.J., 1988, MIXTURE MODELS INFER, V38; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Pernkopf F, 2005, IEEE T PATTERN ANAL, V27, P1344, DOI 10.1109/TPAMI.2005.162; Reddy CK, 2006, J COMPUT BIOL, V13, P745, DOI 10.1089/cmb.2006.13.745; REDDY CK, 2006, BMC ALGORITHMS MOL B, V1, P1; REDDY CK, 2007, THESIS CORNELL U; REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034; Richardson S, 1997, J ROY STAT SOC B MET, V59, P731, DOI 10.1111/1467-9868.00095; Roberts SJ, 1998, IEEE T PATTERN ANAL, V20, P1133, DOI 10.1109/34.730550; Roberts SJ, 2001, IEEE T PATTERN ANAL, V23, P909, DOI 10.1109/34.946994; Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788; Shumway R. H., 1982, Journal of Time Series Analysis, V3, P253, DOI 10.1111/j.1467-9892.1982.tb00349.x; SMYTH P, 2002, STAT COMPUT, V10, P63; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Ueda N, 2000, NEURAL COMPUT, V12, P2109, DOI 10.1162/089976600300015088; Ueda N, 1998, NEURAL NETWORKS, V11, P271, DOI 10.1016/S0893-6080(97)00133-0; Verbeek JJ, 2003, NEURAL COMPUT, V15, P469, DOI 10.1162/089976603762553004; Welch L. R., 2003, IEEE INFORM THEORY S, V53; Xu L, 1996, NEURAL COMPUT, V8, P129, DOI 10.1162/neco.1996.8.1.129; Zhang BB, 2004, PATTERN RECOGN, V37, P131, DOI 10.1016/S0031-3203(03)00140-7; Zivkovic Z, 2004, IEEE T PATTERN ANAL, V26, P651, DOI 10.1109/TPAMI.2004.1273970; [No title captured]	41	37	42	1	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2008	30	7					1146	1157		10.1109/TPAMI.2007.70775	http://dx.doi.org/10.1109/TPAMI.2007.70775			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	307CA	18550899				2022-12-18	WOS:000256294100003
J	Amores, J; Sebe, N; Radeva, P				Amores, Jaume; Sebe, Nicu; Radeva, Petia			Context-based object-class recognition and retrieval by Generalized Correlograms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object recognition; retrieval; Boosting; spatial pattern; contextual information	IMAGE; COLOR	We present a novel approach for retrieval of object categories based on a novel type of image representation: the Generalized Correlogram ( GC). In our image representation, the object is described as a constellation of GCs, where each one encodes information about some local part and the spatial relations from this part to others ( that is, the part's context). We show how such a representation can be used with fast procedures that learn the object category with weak supervision and efficiently match the model of the object against large collections of images. In the learning stage, we show that, by integrating our representation with Boosting, the system is able to obtain a compact model that is represented by very few features, where each feature conveys key properties about the object's parts and their spatial arrangement. In the matching step, we propose direct procedures that exploit our representation for efficiently considering spatial coherence between the matching of local parts. Combined with an appropriate data organization such as Inverted Files, we show that thousands of images can be evaluated efficiently. The framework has been applied to different standard databases, and we show that our results are favorably compared against state-of-the-art methods in both computational cost and accuracy.	INRIA, IMEDIA Res Grp, F-78153 Le Chesnay, France; Univ Amsterdam, Fac Sci, NL-1098 SJ Amsterdam, Netherlands; Univ Autonoma Barcelona, Dept Comp Sci, Ctr Visio Computador, E-08193 Barcelona, Spain	Inria; University of Amsterdam; Autonomous University of Barcelona; Centre de Visio per Computador (CVC)	Amores, J (corresponding author), INRIA, IMEDIA Res Grp, Bat 11,Domaine Voluceau,BP 105, F-78153 Le Chesnay, France.	jaume.amores@inria.fr; nicu@science.uva.nl; petia@cvc.uab.es	Radeva, Petia/I-3385-2015	Radeva, Petia/0000-0003-0047-5172; Sebe, Niculae/0000-0002-6597-7248				Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108; Amores J, 2005, PROC CVPR IEEE, P769; Bar Hillel A, 2005, IEEE I CONF COMP VIS, P1762; BARHILLEL A, INT J COMPUTER VISIO; Barrow HG, 1977, P 5 INT JOINT C ART; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; Chen YX, 2002, IEEE T PATTERN ANAL, V24, P1252, DOI 10.1109/TPAMI.2002.1033216; CRANDALL D, 2005, P IEEE INT C COMP VI; Enser P. G. B., 1993, Journal of Document and Text Management, V1, P25; Fei-Fei L., 2004, P IEEE INT C COMP VI; FERGUS R, 2003, P IEEE INT C COMP VI; Forsyth D, 1997, SCI AM, V276, P88, DOI 10.1038/scientificamerican0697-88; FREUND Y, 1999, J JAPANESE SOC ARTIF; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602; HONG P, 2003, J DISCRETE APPL MATH, V139, P113; Huang J, 1999, INT J COMPUT VISION, V35, P245, DOI 10.1023/A:1008108327226; Li Y, 2005, IEEE I CONF COMP VIS, P1605; Maree R, 2005, PROC CVPR IEEE, P34; Markkula M., 2000, Information Retrieval, V1, P259, DOI 10.1023/A:1009995816485; Murase H, 1996, CUCS00696 COL U; MUTCH J, 2006, P IEEE C COMP VIS PA, V1, P11; Nelson RC, 1998, VISION RES, V38, P2469, DOI 10.1016/S0042-6989(98)00030-3; NOWAK E, 2006, P EUR C COMP VIS; Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143; SCHMID SLC, 2006, P IEEE INT C COMP VI, V2, P2169; Serre T, 2005, PROC CVPR IEEE, P994; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Squire DM, 2000, PATTERN RECOGN LETT, V21, P1193, DOI 10.1016/S0167-8655(00)00081-7; Tieu K, 2004, INT J COMPUT VISION, V56, P17, DOI 10.1023/B:VISI.0000004830.93820.78; Torralba A, 2004, PROC CVPR IEEE, P762; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109; WANG Y, 2004, P ACM MULT, P356; Weber M, 2000, PROC CVPR IEEE, P101, DOI 10.1109/CVPR.2000.854754	36	37	40	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2007	29	10					1818	1833		10.1109/TPAMI.2007.1098	http://dx.doi.org/10.1109/TPAMI.2007.1098			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	199LA	17699925				2022-12-18	WOS:000248696100010
J	Wang, Y; Teoh, EK				Wang, Yue; Teoh, Eam Khwang			2D affine-invariant contour matching using B-Spline model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						curve matching; B-Spline model; curvature scale space; curve smoothing	SCALE-SPACE; SNAKE MODEL; RECOGNITION; IDENTIFICATION; OBJECTS	This paper presents a new affine-invariant matching algorithm based on B-Spline modeling, which solves the problem of the nonuniqueness of B-Spline in curve matching. This method first smoothes the B-Spline curve by increasing the degree of the curve. It is followed by a reduction of the curve degree using the Least Square Error ( LSE) approach to construct the Curvature Scale Space (CSS) image. CSS matching is then carried out. Our method combines the advantages of B-Spline that are continuous curve representation and the robustness of CSS matching with respect to noise and affine transformation. It avoids the need for other matching algorithms that have to use the resampled points on the curve. Thus, the curve matching error is reduced. The proposed algorithm has been tested by matching similar shapes from a prototype database. The experimental results showed the robustness and accuracy of the proposed method in B-Spline curve matching.	Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Wang, Y (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Nanyang Ave, Singapore 639798, Singapore.	s2633175g@ntu.edu.sg; eekteoh@ntu.edu.sg						ALI WSI, 1998, IEEE T MED IMAGING, V17; ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206; COHEN FS, 1995, IEEE T IMAGE PROCESS, V4, P1, DOI 10.1109/83.350818; COHEN FS, 1994, IEEE T PATTERN ANAL, V16, P1, DOI 10.1109/34.273721; Gu YH, 2000, PATTERN RECOGN, V33, P1411, DOI 10.1016/S0031-3203(99)00131-4; Huang ZH, 1996, IEEE T IMAGE PROCESS, V5, P1473, DOI 10.1109/83.536895; Mokhtarian F, 2001, PATTERN ANAL APPL, V4, P1, DOI 10.1007/PL00010984; Mokhtarian F., 1986, IEEE T PAMI, VPAMI-8, P3443; Mokhtarian F., 1996, P 7 BRIT MACH VIS C, VI, P53; SAPIRO G, 1993, INT J COMPUT VISION, V11, P25, DOI 10.1007/BF01420591; Wang Y, 2006, J MATH IMAGING VIS, V24, P295, DOI 10.1007/s10851-005-3629-8; Wang Y, 2004, IEEE IMAGE PROC, P409; Wang Y, 2005, IMAGE VISION COMPUT, V23, P1029, DOI 10.1016/j.imavis.2005.07.006; Zhao DM, 1997, PATTERN RECOGN, V30, P895, DOI 10.1016/S0031-3203(96)00126-4	14	37	46	4	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2007	29	10					1853A	1858		10.1109/TPAMI.2007.1135	http://dx.doi.org/10.1109/TPAMI.2007.1135			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	199LA	17699928				2022-12-18	WOS:000248696100013
J	Meytlis, M; Sirovich, L				Meytlis, Marsha; Sirovich, Lawrence			On the dimensionality of face space	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face and gesture recognition; computational models of vision; psychology; singular value decomposition	KARHUNEN-LOEVE PROCEDURE; RECOGNITION; MACHINE; REPRESENTATION; CLASSIFICATION; EIGENFACES; PERCEPTION; ALGORITHMS; FEATURES; IMAGES	The dimensionality of face space is measured objectively in a psychophysical study. Within this framework, we obtain a measurement of the dimension for the human visual system. Using an eigenface basis, evidence is presented that talented human observers are able to identify familiar faces that lie in a space of roughly 100 dimensions and the average observer requires a space of between 100 and 200 dimensions. This is below most current estimates. It is further argued that these estimates give an upper bound for face space dimension and this might be lowered by better constructed "eigenfaces" and by talented observers.	Mt Sinai Sch Med, Lab Appl Math, New York, NY 10029 USA	Icahn School of Medicine at Mount Sinai	Meytlis, M (corresponding author), Mt Sinai Sch Med, Lab Appl Math, Box 1012,1 Gustave L Levy Pl, New York, NY 10029 USA.	masha707@gmail.com; chico@camelot.mssm.edu						[Anonymous], FACE RECOGNITION SUB; Bartlett MS, 1998, P SOC PHOTO-OPT INS, V3299, P528, DOI 10.1117/12.320144; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; Carmichael O, 2004, IEEE T PATTERN ANAL, V26, P1537, DOI 10.1109/TPAMI.2004.128; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; Duda R., 2000, PATTERN CLASSIFICATI, P48; Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724; EVERSON R, 1995, J OPT SOC AM A, V12, P1657, DOI 10.1364/JOSAA.12.001657; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Graf ABA, 2006, NEURAL COMPUT, V18, P143, DOI 10.1162/089976606774841611; Green DM, 1966, SIGNAL DETECTION THE; Hancock PJB, 1996, MEM COGNITION, V24, P26, DOI 10.3758/BF03197270; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; Liu CJ, 2003, IEEE T NEURAL NETWOR, V14, P919, DOI 10.1109/TNN.2003.813829; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Macmillan NA., 2005, DETECTION THEORY USE, VSecond; MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; MOGHADDAM B, 1998, P IEEE INT C AUT FAC; O'Toole AJ, 1998, MEM COGNITION, V26, P146, DOI 10.3758/BF03211378; Olshausen BA, 2004, CURR OPIN NEUROBIOL, V14, P481, DOI 10.1016/j.conb.2004.07.007; OTOOLE AJ, 1993, J OPT SOC AM A, V10, P405, DOI 10.1364/JOSAA.10.000405; PELLI D, 1994, HDB OPTICS, V1; Penev P. S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P264, DOI 10.1109/AFGR.2000.840645; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; PROVOST F, 1998, P 15 INT C MACH LEAR, P445; QUICK RF, 1974, KYBERNETIK, V16, P65, DOI 10.1007/BF00271628; Simoncelli EP, 2003, CURR OPIN NEUROBIOL, V13, P144, DOI 10.1016/S0959-4388(03)00047-3; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; STEWART GW, 1993, SIAM REV, V35, P551, DOI 10.1137/1035134; Strang G., 1988, LINEAR ALGEBRA APPL, V3rd; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; Tanaka JW, 2001, J EXP PSYCHOL GEN, V130, P534, DOI 10.1037/0096-3445.130.3.534; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758; Wolfe J., 2006, SENSATION PERCEPTION; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883; ZHAO R, 2003, ACM COMPUT SURV, P399	44	37	38	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2007	29	7					1262	1267		10.1109/TPAMI.2007.1033	http://dx.doi.org/10.1109/TPAMI.2007.1033			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	166QW	17496382				2022-12-18	WOS:000246395300012
J	Vicente, MA; Hoyer, PO; Hyvarinen, A				Asuncion Vicente, M.; Hoyer, Patrik O.; Hyvarinen, Aapo			Equivalence of some common linear feature extraction techniques for appearance-based object recognition tasks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; object recognition; principal component analysis; independent component analysis	INDEPENDENT COMPONENT ANALYSIS; FACE RECOGNITION; PCA	Recently, a number of empirical studies have compared the performance of PCA and ICA as feature extraction methods in appearance-based object recognition systems, with mixed and seemingly contradictory results. In this paper, we briefly describe the connection between the two methods and argue that whitened PCA may yield identical results to ICA in some cases. Furthermore, we describe the specific situations in which ICA might significantly improve on PCA.	Miguel Hernandez Univ, Dept Ind Syst Engn, Elche 03202, Alicante, Spain; Univ Helsinki, Helsinki Inst Informat Technol, Basic Res Unit, FIN-00014 Helsinki, Finland	Universidad Miguel Hernandez de Elche; University of Helsinki	Vicente, MA (corresponding author), Miguel Hernandez Univ, Dept Ind Syst Engn, Avenida Univ S-N, Elche 03202, Alicante, Spain.	suni@umh.es; patrik.hoyer@helsinki.fi; aapo.hyvarinen@helsinki.fi	Vicente, Maria Asuncion/F-8859-2016	Vicente, Maria Asuncion/0000-0002-8630-7251; Hyvarinen, Aapo/0000-0002-5806-4432				BACH FR, 2002, J MACHINE LEARNING R, V3, P1; Baek K, 2002, PROCEEDINGS OF THE 6TH JOINT CONFERENCE ON INFORMATION SCIENCES, P824; Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Bressan M, 2003, IEEE T PATTERN ANAL, V25, P1312, DOI 10.1109/TPAMI.2003.1233904; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; Draper BA, 2003, COMPUT VIS IMAGE UND, V91, P115, DOI 10.1016/S1077-3142(03)00077-8; Edelman S, 1997, TRENDS COGN SCI, V1, P296, DOI 10.1016/S1364-6613(97)01090-5; Ekenel HK, 2005, IMAGE VISION COMPUT, V23, P469, DOI 10.1016/j.imavis.2004.09.002; Fortuna J, 2002, INT C PATT RECOG, P11, DOI 10.1109/ICPR.2002.1047783; FORTUNA J, 2004, P 6 IEEE SW S IM AN; Hyvarinen A, 1999, IEEE T NEURAL NETWOR, V10, P626, DOI 10.1109/72.761722; Hyvarinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; Lee TW, 1999, NEURAL COMPUT, V11, P417, DOI 10.1162/089976699300016719; Liu C., 1999, P 2 INT C AUD VID BA; Liu CJ, 2004, IEEE T SYST MAN CY B, V34, P1117, DOI 10.1109/TSMCB.2003.821449; Liu CJ, 2003, IEEE T NEURAL NETWOR, V14, P919, DOI 10.1109/TNN.2003.813829; Martiriggiano T, 2005, LECT NOTES ARTIF INT, V3533, P55; MOGHADDAM B, 2002, IEEE T PATTERN ANAL, V24, P1; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Nayar SK, 1996, IEEE T ROBOTIC AUTOM, V12, P750, DOI 10.1109/70.538979; Nene A. S., 1996, CUCS00696; Ohba K, 1997, IEEE T PATTERN ANAL, V19, P1043, DOI 10.1109/34.615453; Sahambi HS, 2003, IEEE T NEURAL NETWOR, V14, P138, DOI 10.1109/TNN.2002.806949; SOCOLINSKY DA, 2002, P 16 INT C PATT REC; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vicente MA, 2004, LECT NOTES COMPUT SC, V3211, P547; Yang J, 2005, IEEE I CONF COMP VIS, P198; YUEN PC, 2000, P IEEE INT C BIOL MO, P545	32	37	39	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2007	29	5					896	900		10.1109/TPAMI.2007.1025	http://dx.doi.org/10.1109/TPAMI.2007.1025			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HK	17356208				2022-12-18	WOS:000244855700012
J	Artieres, T; Marukatat, S; Gallinari, P				Artieres, Thierry; Marukatat, Sanparith; Gallinari, Patrick			Online handwritten shape recognition using segmental hidden Markov models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						two-dimensional shape recognition; online handwriting; gesture recognition; graphics recognition; pen-based interface; user-centric interface		We investigate a new approach for online handwritten shape recognition. Interesting features of this approach include learning without manual tuning, learning from very few training samples, incremental learning of characters, and adaptation to the user-specific needs. The proposed system can deal with two-dimensional graphical shapes such as Latin and Asian characters, command gestures, symbols, small drawings, and geometric shapes. It can be used as a building block for a series of recognition tasks with many applications.	Univ Paris 06, F-75015 Paris, France; NECTEC, Pathum Thani 12120, Thailand	UDICE-French Research Universities; Sorbonne Universite; National Science & Technology Development Agency - Thailand; National Electronics & Computer Technology Center (NECTEC)	Artieres, T (corresponding author), Univ Paris 06, 8 Rue Capitaine Scott, F-75015 Paris, France.	Thierry.artieres@lip6.fr; sanparith.marukatat@nectec.or.th; Patrick.Gallinari@lip6.fr	Marukatat, Sanparith/T-1863-2017; artières, thierry/E-9155-2019	artières, thierry/0000-0003-3696-0321; Marukatat, Sanparith/0000-0002-8508-8544				Artieres T, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P227, DOI 10.1109/IWFHR.2002.1030914; ARTIERES T, 2000, P 7 INT WORKSH FRONT, P93; BILMES JA, 1999, TR99016 INT COMP SCI; Cho SJ, 2001, PROC INT CONF DOC, P86, DOI 10.1109/ICDAR.2001.953760; Deng L, 1994, IEEE T SPEECH AUDI P, V2, P507, DOI 10.1109/89.326610; Fine S, 1998, MACH LEARN, V32, P41, DOI 10.1023/A:1007469218079; Frankish C., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P503; GUYON I, 1994, INT C PATT RECOG, P29, DOI 10.1109/ICPR.1994.576870; HU J, 1998, P IWFHR 6 TAEJ KOR, P143; Kang KW, 2004, IEEE T PATTERN ANAL, V26, P1185, DOI 10.1109/TPAMI.2004.74; LEE JJ, 2000, P 7 INT WORKSH FRONT, P239; Li HF, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P149, DOI 10.1109/ICMI.2002.1166984; Liu CL, 2001, PATTERN RECOGN, V34, P2339, DOI 10.1016/S0031-3203(00)00165-5; LONG AC, 2000, P HUM FACT COMP SYST, P360; MacKenzie IS, 1997, PROC GRAPH INTERF, P129; Manke S., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P403, DOI 10.1109/ICDAR.1995.599023; Marukatat S, 2001, PROC INT CONF DOC, P731, DOI 10.1109/ICDAR.2001.953886; Marukatat S, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P401, DOI 10.1109/IWFHR.2004.3; Marukatat S, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P14, DOI 10.1109/IWFHR.2004.48; MARUKATAT S, 2004, THESIS U PARIS 6 FRA; MURPHY K, 2001, ADV NEURAL INFORMATI, P833; Murphy KP., 2002, THESIS UC BERKELEY; Nakai M., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P491, DOI 10.1109/ICDAR.2001.953838; OMOHUNDRO SM, 1992, ADV NEURAL INFORMATI, P958; Ostendorf M, 1996, IEEE T SPEECH AUDI P, V4, P360, DOI 10.1109/89.536930; Ratzlaff EH, 2003, PROC INT CONF DOC, P623; Schomaker L., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P293, DOI 10.1109/ICDAR.1999.791782; [No title captured]	28	37	39	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2007	29	2					205	217		10.1109/TPAMI.2007.38	http://dx.doi.org/10.1109/TPAMI.2007.38			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	116TV	17170475				2022-12-18	WOS:000242826900003
J	Rockett, PI				Rockett, PI			An improved rotation-invariant thinning algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						thinning; skeletonization; graph theory	CHARACTER-RECOGNITION	Ahmed and Ward [ 2] have recently presented an elegant, rule-based rotation-invariant thinning algorithm to produce a single-pixel wide skeleton from a binary image. We show examples where this algorithm fails on two-pixel wide lines and propose a modified method which corrects this shortcoming based on graph connectivity.	Univ Sheffield, Dept Elect & Elect Engn, Sheffield S1 3JD, S Yorkshire, England	University of Sheffield	Rockett, PI (corresponding author), Univ Sheffield, Dept Elect & Elect Engn, Mappin St, Sheffield S1 3JD, S Yorkshire, England.	p.rockett@shef.ac.uk						Ahmed M, 2002, IEEE T PATTERN ANAL, V24, P1672, DOI 10.1109/TPAMI.2002.1114862; LAM L, 1995, IEEE T PATTERN ANAL, V17, P914, DOI 10.1109/34.406659; LIN JY, 1995, PATTERN RECOGN, V28, P493, DOI 10.1016/0031-3203(94)00122-3	3	37	45	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2005	27	10					1671	1674		10.1109/TPAMI.2005.191	http://dx.doi.org/10.1109/TPAMI.2005.191			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	953OM	16238001	Green Accepted			2022-12-18	WOS:000231086700014
J	Keselman, Y; Dickinson, S				Keselman, Y; Dickinson, S			Generic model abstraction from examples	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image abstraction; automatic model acquisition; learning from examples; shape description; object recognition; graph algorithms	OBJECT RECOGNITION; SEGMENTATION; RECOVERY; SHAPE; IMAGES	The recognition community has typically avoided bridging the representational gap between traditional, low- level image features and generic models. Instead, the gap has been artificially eliminated by either bringing the image closer to the models using simple scenes containing idealized, textureless objects or by bringing the models closer to the images using 3D CAD model templates or 2D appearance model templates. In this paper, we attempt to bridge the representational gap for the domain of model acquisition. Specifically, we address the problem of automatically acquiring a generic 2D view- based class model from a set of images, each containing an exemplar object belonging to that class. We introduce a novel graph- theoretical formulation of the problem in which we search for the lowest common abstraction among a set of lattices, each representing the space of all possible region groupings in a region adjacency graph representation of an input image. The problem is intractable and we present a shortest path- based approximation algorithm to yield an efficient solution. We demonstrate the approach on real imagery.	Depaul Univ, Sch CTI, Chicago, IL 60604 USA; Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada	DePaul University; University of Toronto	Keselman, Y (corresponding author), Depaul Univ, Sch CTI, 243 S Wabash Ave, Chicago, IL 60604 USA.	ykeselman@cti.depaul.edu; sven@cs.toronto.edu						[Anonymous], 1985, PERCEPTUAL ORG VISUA; Basri R., 1995, Proceedings of the Workshop on Physics-Based Modeling in Computer Vision (Cat. No.95TB8038), P135, DOI 10.1109/PBMCV.1995.514678; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BERGEVIN R, 1993, IEEE T PATTERN ANAL, V15, P19, DOI 10.1109/34.184772; BIEDERMAN I, 1985, COMPUT VISION GRAPH, V32, P29, DOI 10.1016/0734-189X(85)90002-7; BROOKS RA, 1983, IEEE T PATTERN ANAL, V5, P140, DOI 10.1109/TPAMI.1983.4767366; CARNEIRO G, 2002, P EUR C COMP VIS; Comaniciu D, 1997, PROC CVPR IEEE, P750, DOI 10.1109/CVPR.1997.609410; CONNELL JH, 1987, ARTIF INTELL, V31, P159, DOI 10.1016/0004-3702(87)90018-X; CORMEN TH, 1993, INTRO ALGORITHMS, pCH25; Dickinson E., 1994, COLLOID SURFACE B, V3, P1, DOI 10.1016/0927-7765(93)01116-9; Dickinson SJ, 1997, IEEE T PATTERN ANAL, V19, P259, DOI 10.1109/34.584104; DICKINSON SJ, 1992, IEEE T PATTERN ANAL, V14, P174, DOI 10.1109/34.121788; DICKINSON SJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P130, DOI 10.1016/1049-9660(92)90013-S; Dickinson SJ, 1997, COMPUT VIS IMAGE UND, V67, P239, DOI 10.1006/cviu.1997.0532; Eppstein D, 1998, SIAM J COMPUT, V28, P652, DOI 10.1137/S0097539795290477; Ettinger G. J., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P32, DOI 10.1109/CVPR.1988.196212; Fei-Fei L., 2004, P IEEE C COMP VIS PA; Felzenszwalb PF, 1998, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.1998.698594; FERRIE FP, 1993, IEEE T PATTERN ANAL, V15, P771, DOI 10.1109/34.236252; GOULD R, 1988, GRAPH THEORY, P170; HAN J, 2001, DATA MINING CONCEPTS, P228; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; Jiang XY, 2001, IEEE T PATTERN ANAL, V23, P1144; Jolion JM, 2003, PATTERN ANAL APPL, V6, P224, DOI 10.1007/s10044-003-0190-1; KATOH N, 1982, NETWORKS, V12, P411, DOI 10.1002/net.3230120406; Keselman Y, 2001, PROC CVPR IEEE, P856; Keselman Y., 2001, P IEEE WORKSH MOD VE; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; Kropatsch WG, 1995, IEE P-VIS IMAGE SIGN, V142, P366, DOI 10.1049/ip-vis:19952115; Leibe B., 2003, P IEEE C COMP VIS PA; Leonardis A, 1996, PROC CVPR IEEE, P453, DOI 10.1109/CVPR.1996.517111; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; LUO B, 2004, PATTERN RECOGNITION; Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; NELSON R, 1998, P IEEE INT C COMP VI; NISHIDA H, 1993, IEEE T PATTERN ANAL, V15, P1298, DOI 10.1109/34.250847; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P107, DOI 10.1007/BF00127812; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; Pope A. R., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P296, DOI 10.1109/ICCV.1993.378202; RIVLIN E, 1995, COMPUT VIS IMAGE UND, V62, P164, DOI 10.1006/cviu.1995.1048; Schmid C, 1996, PROC CVPR IEEE, P872, DOI 10.1109/CVPR.1996.517174; SCLAROFF S, 1995, IEEE T PATTERN ANAL, V17, P545, DOI 10.1109/34.387502; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; Shi J., 1997, P IEEE C COMP VIS PA; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; UTANS J, 1994, ADV NEURAL INFORMATI, V6, P285; WACHSMUTH S, 2003, P HTLNAACL03 WORKSH; WEBER M, 2000, P ECCV, V1, P18; WINSTON PH, 1975, PSYCHOL COMPUTER VIS, P17; Xu YW, 2004, COMPUT VIS IMAGE UND, V95, P334, DOI 10.1016/j.cviu.2004.04.003; Zhu SC, 1996, INT J COMPUT VISION, V20, P187	56	37	37	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2005	27	7					1141	1156		10.1109/TPAMI.2005.139	http://dx.doi.org/10.1109/TPAMI.2005.139			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	925AQ	16013760	Green Submitted			2022-12-18	WOS:000229024300012
J	Keysers, D; Macherey, W; Ney, G; Dahmen, J				Keysers, D; Macherey, W; Ney, G; Dahmen, J			Adaptation in statistical pattern recognition using tangent vectors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						statistical pattern recognition; adaptation; tangent vectors; linear models		We integrate the tangent method into a statistical framework for classification analytically and practically. The resulting consistent framework for adaptation allows us to efficiently estimate the tangent vectors representing the variability. The framework improves classification results on two real-world pattern recognition tasks from the domains handwritten character recognition and automatic speech recognition.	Rhein Westfal TH Aachen, Aachen Tech Univ, Dept Comp Sci, Lehrstuhl Informat 6, D-52056 Aachen, Germany	RWTH Aachen University	Keysers, D (corresponding author), Rhein Westfal TH Aachen, Aachen Tech Univ, Dept Comp Sci, Lehrstuhl Informat 6, D-52056 Aachen, Germany.	keysers@informatik.rwth-aachen.de; w.macherey@informatik.rwth-aachen.de; ney@informatik.rwth-aachen.de; dahmen@informatik.rwth-aachen.de						Bishop, 1995, NEURAL NETWORKS PATT; Bishop CM, 1999, ADV NEUR IN, V11, P382; Dahmen J, 2001, J MATH IMAGING VIS, V14, P285, DOI 10.1023/A:1011242314266; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; EISELE T, 1996, P INT C SPOK LANG PR, V1, P252; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Hastie T, 1998, STAT SCI, V13, P54; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; Hinton GE, 1997, IEEE T NEURAL NETWOR, V8, P65, DOI 10.1109/72.554192; Kambhatla N, 1997, NEURAL COMPUT, V9, P1493, DOI 10.1162/neco.1997.9.7.1493; KEYSERS D, 2000, P 22 S GERM ASS PATT, P107; KEYSERS D, 2001, LNCS, V2167, P263; Minka TP, 2001, ADV NEUR IN, V13, P598; Roweis S, 1999, NEURAL COMPUT, V11, P305, DOI 10.1162/089976699300016674; Scholkopf B, 1998, ADV NEUR IN, V10, P640; Simard P., 1993, ADV NEURAL INFORMATI, V5, P50; Simard PY, 1998, LECT NOTES COMPUT SC, V1524, P239; Tipping M. E., 2000, ADV NEURAL INFORM PR, V12, P332; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; WELLING L, 1995, P 1995 EUR C SPEECH, V2, P1483	21	37	40	2	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2004	26	2					269	274		10.1109/TPAMI.2004.1262198	http://dx.doi.org/10.1109/TPAMI.2004.1262198			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	762DA	15376902				2022-12-18	WOS:000187954300013
J	Everitt, RAJ; McOwan, PW				Everitt, RAJ; McOwan, PW			Java-based Internet biometric authentication system	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						authentication; biometric; Internet; Java; keyboard dynamics; signature; verification	IDENTIFICATION	An online biometric verification system for use over the Internet and requiring no specialist equipment is presented. Combining two distinct tests to ensure authenticity, a typing style test and a mouse-based signature test, achieves a fraudulent access rate of approximate to 4.4 percent, while authentic users access with a rate of approximate to 99 percent.	Queen Mary Univ London, Dept Comp Sci, London E1 4NS, England	University of London; Queen Mary University London	Everitt, RAJ (corresponding author), Queen Mary Univ London, Dept Comp Sci, Mile End Rd, London E1 4NS, England.	pmco@dcs.qmul.ac.uk						Bishop C. M., 1995, NEURAL NETWORK PATTE, P332; BLEHA SA, 1991, IEEE T SYST MAN CYB, V21, P452, DOI 10.1109/21.87093; BRAULT JJ, 1993, IEEE T PATTERN ANAL, V15, P953, DOI 10.1109/34.232079; CHANGSHUI Z, 2000, P IEEE INT C SYST MA, V4, P2887; CLARKE K, 1994, NEW STATESMAN SOC, V7, P4; Clarkson TG, 2001, IEEE T SYST MAN CY C, V31, P65, DOI 10.1109/5326.923269; George MH, 1995, 29TH ANNUAL 1995 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P41, DOI 10.1109/CCST.1995.524731; Goldberg DE, 1989, GENETIC ALGORITHMS S; GORDON S, 2001, OPTO LASER EUROPE; Haider S, 2000, IEEE SYS MAN CYBERN, P1336, DOI 10.1109/ICSMC.2000.886039; Hangai S, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P489, DOI 10.1109/ICME.2000.869645; Herbst B, 1998, IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS (ISIE 98) - PROCEEDINGS, VOLS 1 AND 2, P600, DOI 10.1109/ISIE.1998.711679; HESKETH GB, 1997, P IEE C NEUR NETW IN; HIGASHINO J, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P517, DOI 10.1109/ICPR.1992.202038; LEE L, 1995, P 3 INT C DOC AN REC, V2, P1055; Martens R, 1997, PROC INT CONF DOC, P657, DOI 10.1109/ICDAR.1997.620588; MILLER B, 1994, IEEE SPECTRUM, V31, P22, DOI 10.1109/6.259484; MINGMING M, 2000, P IEEE IAFE INFORMS, P30; OZCAN E, 1998, P IEEE 7 ANN C EV PR, P527; Robinson JA, 1998, IEEE T SYST MAN CY A, V28, P236, DOI 10.1109/3468.661150; Roddy AR, 1997, P IEEE, V85, P1390, DOI 10.1109/5.628710; Sanchez-Reillo R, 2000, IEEE T PATTERN ANAL, V22, P1168, DOI 10.1109/34.879796; WESSELS T, 2000, P S AFR TEL NETW APP, P5509; XUHUA Y, 1995, P IEEE INT C INT SYS, V5, P4383; Yue KW, 2000, IEEE SYS MAN CYBERN, P2752, DOI 10.1109/ICSMC.2000.884413; Zhu Y, 2000, INT C PATT RECOG, P801, DOI 10.1109/ICPR.2000.906197; Zwiesele A, 2000, 34TH ANNUAL 2000 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P60, DOI 10.1109/CCST.2000.891168	27	37	40	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2003	25	9					1166	1172		10.1109/TPAMI.2003.1227991	http://dx.doi.org/10.1109/TPAMI.2003.1227991			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	715MX					2022-12-18	WOS:000184977300011
J	August, J; Zucker, SW				August, J; Zucker, SW			Sketches with curvature: The curve indicator random field and Markov processes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						random fields; Markov processes; Feynman-Kac formula; curvature Brownian motion; edge detection; posterior mean; sketch; contour enhancement; curve; elastica; Euler spiral; orientation; direction	MODEL; RELAXATION; INFERENCE; SHAPE	While complaints about typical edge operators are common, proposals articulating a notion of the "perfect" edge map are comparatively rare, hindering the improvement of contour enhancement techniques. To address this situation, we suggest that one objective of visual contour computation is the estimation of a clean sketch from a corrupted rendition, the latter modeling noisy and low contrast edge or line operator responses to an image. Our formal model of this clean sketch is the curve indicator random field (CIRF), whose role is to provide a basis for defining edge likelihood models by eliminating the parameter along each curve to create an image of curves. For curves modeled with stationary Markov processes, this ideal edge prior is non-Gaussian and its moment generating functional has a form closely related to the Feynman-Kac formula. This sketch model leads to a nonlinear, minimum mean squared error contour enhancement filter that requires the solution of two elliptic partial differential equations. The framework is also independent of the order of the contour model, allowing us to introduce a Markov process model for contour curvature. We analyze the distribution of such curves and show that its mode is the Euler spiral, a curve minimizing changes in curvature. Example computations using the contour enhancement filter with the curvature-based contour model are provided, highlighting how the filter is curvature-selective even when curvature is absent in the input.	Carnegie Mellon Univ, Inst Robot, Med Robot Technol Ctr, Pittsburgh, PA 15213 USA; Yale Univ, Ctr Computat Vis & Control, Dept Comp Sci, New Haven, CT 06520 USA	Carnegie Mellon University; Yale University	August, J (corresponding author), Carnegie Mellon Univ, Inst Robot, Med Robot Technol Ctr, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	jonas@cs.cmu.edu; steven.zucker@yale.edu						AUGUST J, 2001, THESIS YALE U; AUGUST J, 2000, P 2000 C INF SCI SYS, V1, pWP15; August J., 2000, PERCEPTUAL ORG ARTIF, P265; DEMPSTER AP, 1977, ROYAL STAT SOC, V1, P1; DOBBINS A, 1987, NATURE, V329, P438, DOI 10.1038/329438a0; DYNKIN EB, 1983, J FUNCT ANAL, V50, P167, DOI 10.1016/0022-1236(83)90066-6; DYNKIN EB, 1984, J FUNCT ANAL, V55, P344, DOI 10.1016/0022-1236(84)90004-1; FIELD DJ, 1993, VISION RES, V33, P173, DOI 10.1016/0042-6989(93)90156-Q; Fitzsimmons PJ, 1999, STOCH PROC APPL, V79, P117, DOI 10.1016/S0304-4149(98)00081-7; Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Granlund G.H., 1995, SIGNAL PROCESSING CO; Helstrom C.W., 1991, PROBABILITY STOCHAST, V2rd; HERAULT L, 1993, IEEE T PATTERN ANAL, V15, P899, DOI 10.1109/34.232076; HORN BKP, 1983, ACM T MATH SOFTWARE, V9, P441, DOI 10.1145/356056.356061; IVERSON LA, 1995, IEEE T PATTERN ANAL, V17, P982, DOI 10.1109/34.464562; IVERSON LA, 1994, THESIS MCGILL U MONT; KALITZIN SN, 1997, P SCAL SPAC 97 LICS, P77; Khas'minskii R., 1959, THEOR PROBAB APPL, V4, P309, DOI 10.1137/1104030; KIMIA BB, 2000, PERCEPTUAL ORG ARTIF, P289; KOENDERINK JJ, 1988, J OPT SOC AM A, V5, P1136, DOI 10.1364/JOSAA.5.001136; Leonov V. P., 1959, THEOR PROBAB APPL+, V4, P319; MARROQUIN JL, 1989, BIOL CYBERN, V61, P457, DOI 10.1007/BF02414907; Mumford D., 1994, ALGEBRAIC GEOMETRY I, V5681, P491, DOI DOI 10.1007/978-1-4612-2628-4_31; Nikias C. L., 1993, HIGHER ORDER SPECTRA; Norris J., 1997, MARKOV CHAINS, DOI DOI 10.1017/CBO9780511810633; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; Richards J.I., 1990, THEORY DISTRIBUTIONS; Sharon E, 2000, IEEE T PATTERN ANAL, V22, P1117, DOI 10.1109/34.879792; Tu ZW, 2002, LECT NOTES COMPUT SC, V2352, P393; ULLMAN S, 1976, BIOL CYBERN, V25, P1; URAGO S, 1995, PATTERN RECOGN, V28, P683, DOI 10.1016/0031-3203(94)00136-A; WILLIAMS L, 1997, P 7 INT C COMP AN IM; Williams LR, 1997, NEURAL COMPUT, V9, P837, DOI 10.1162/neco.1997.9.4.837; Williams LR, 2001, NEURAL COMPUT, V13, P1683, DOI 10.1162/08997660152469305; Yuille AL, 2000, IEEE T PATTERN ANAL, V22, P160, DOI 10.1109/34.825754; Zhu SC, 1999, IEEE T PATTERN ANAL, V21, P1170, DOI 10.1109/34.809110; Zucker SW, 1989, NEURAL COMPUT, V1, P68, DOI 10.1162/neco.1989.1.1.68; ZUCKER SW, 1977, IEEE T COMPUT, V26, P394, DOI 10.1109/TC.1977.1674848; [No title captured]	40	37	38	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2003	25	4					387	400		10.1109/TPAMI.2003.1190567	http://dx.doi.org/10.1109/TPAMI.2003.1190567			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	659BV					2022-12-18	WOS:000181758100002
J	Lim, KP; Das, A; Chong, MN				Lim, KP; Das, A; Chong, MN			Estimation of occlusion and dense motion fields in a bidirectional Bayesian framework	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						occlusion detection; dense motion field estimation; Markov random field		This paper presents new MRF models in a bidirectional Bayesian framework for accurate motion and occlusion fields estimation. With careful selection of the five free parameters required by the models, good experimental results have been obtained. The resultant computational speed is also 5.5 times faster compared with the conventional Iterated Conditional Mode relaxation using the proposed fast bidirectional relaxation.	Nanyang Technol Univ, Sch EEE, Ctr Signal Proc, Singapore 639798, Singapore; Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; GDC Technol Ltd, Hong Kong, Hong Kong, Peoples R China	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Lim, KP (corresponding author), Nanyang Technol Univ, Sch EEE, Ctr Signal Proc, Singapore 639798, Singapore.							BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; CHAHINE MJ, 1994, THESIS MCGILL MONTRE; DEPOMMIER R, 1992, P IEEE INT C AC SPEE; Dubois E., 1993, MOTION ANAL IMAGE SE; HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841; HOTTER M, 1988, SIGNAL PROCESS, V15, P315, DOI 10.1016/0165-1684(88)90021-7; KONRAD J, 1992, IEEE T PATTERN ANAL, V14, P910, DOI 10.1109/34.161350; Li S., 1995, MARKOV RANDOM FIELD, P1; Matthews KE, 1998, IEEE T IMAGE PROCESS, V7, P720, DOI 10.1109/83.668028; REDERT PA, 1999, IEEE SIGN PROC MAG M, P29; Tekalp AM, 1995, DIGITAL VIDEO PROCES; Thoma R., 1989, Signal Processing: Image Communication, V1, P191, DOI 10.1016/0923-5965(89)90009-X; ZHANG J, 1995, IEEE T IMAGE PROCESS, V4, P19, DOI 10.1109/83.350816	14	37	64	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2002	24	5					712	718						7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	544XU					2022-12-18	WOS:000175187800012
J	Suen, PH; Healey, G				Suen, PH; Healey, G			The analysis and recognition of real-world textures in three dimensions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D texture; texture; color; recognition; classification; computer vision; bidirectional reflectance distribution function; (BRDF); invariant; bidirectional texture function (BTF)	SURFACES; REFLECTANCE; MODEL; SHAPE	The observed image texture for a rough surface has a complex dependence on the illumination and viewing angles due to effects such as foreshortening, local shading, interreflections, and the shadowing and occlusion of surface elements. We introduce the dimensionality surface as a representation for the visual complexity of a material sample. The dimensionality surface defines the number of basis textures that are required to represent the observed textures for a sample as a function of ranges of illumination and viewing angles. Basis textures are represented using multiband correlation functions that consider both within and between color band correlations. We examine properties of the dimensionality surface for real materials using the Columbia Utrecht Reflectance and Texture (CUReT) database. The analysis shows that the dependence of the dimensionality surface on ranges of illumination and viewing angles is approximately linear with a slope that depends on the complexity of the sample. We extend the analysis to consider the problem of recognizing rough surfaces in color images obtained under unknown illumination and viewing geometry. We show, using a set of 12,505 images from 61 material samples, that the information captured by the multiband correlation model allows surfaces to be recognized over a wide range of conditions. We also show that the use of color information provides significant advantages for three-dimensional texture recognition.	Univ Calif Irvine, Dept Elect & Comp Engn, Irvine, CA 92697 USA	University of California System; University of California Irvine	Suen, PH (corresponding author), Univ Calif Irvine, Dept Elect & Comp Engn, Irvine, CA 92697 USA.	psuen@ece.uci.edu; healey@ece.uci.edu						BAJSCY R, 1976, COMPUTER GRAPHICS IM, V5, P52; BROWN LG, 1990, IEEE T PATTERN ANAL, V12, P584, DOI 10.1109/34.56194; Chellappa R, 1993, MARKOV RANDOM FIELDS; Dana K. J., 1996, CUCS04896; Dana KJ, 1998, PROC CVPR IEEE, P618, DOI 10.1109/CVPR.1998.698669; Dana KJ, 1997, PROC CVPR IEEE, P151, DOI 10.1109/CVPR.1997.609313; Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778; GIBSON JJ, 1950, AM J PSYCHOL, V63, P367, DOI 10.2307/1418003; GOLUB G, 1996, MATTIX COMPUTATIONS; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HEALEY G, 1995, J OPT SOC AM A, V12, P1877, DOI 10.1364/JOSAA.12.001877; HEALEY G, 1999, HDB PATTERN RECOGNIT, P283; JAU JY, 1990, COMPUT VISION GRAPH, V52, P248, DOI 10.1016/0734-189X(90)90057-3; KOENDERINK J, 1996, P EUR C COMP VIS, P28; Koenderink JJ, 1998, J OPT SOC AM A, V15, P2903, DOI 10.1364/JOSAA.15.002903; Koenderink JJ, 1996, J OPT SOC AM A, V13, P452, DOI 10.1364/JOSAA.13.000452; KONDEPUDY R, 1994, J OPT SOC AM A, V11, P3037, DOI 10.1364/JOSAA.11.003037; KRUMM J, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P121, DOI 10.1109/ICCV.1995.466797; Leung T, 1997, PROC CVPR IEEE, P807, DOI 10.1109/CVPR.1997.609420; Malik J., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P267, DOI 10.1109/CVPR.1993.340979; NAYAR SK, 1995, SCIENCE, V267, P1153, DOI 10.1126/science.7855592; Oppenheim A.V., 1989, DISCRETE TIME SIGNAL; OREN M, 1995, INT J COMPUT VISION, V14, P227, DOI 10.1007/BF01679684; PATEL MAS, 1993, IEEE T PATTERN ANAL, V15, P1091, DOI 10.1109/34.254067; Siegel R., 1992, THERMAL RAD HEAT TRA, V3rd ed.; SUPER BJ, 1995, IEEE T PATTERN ANAL, V17, P333, DOI 10.1109/34.385983; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; WOLFF LB, 1994, J OPT SOC AM A, V11, P2956, DOI 10.1364/JOSAA.11.002956	28	37	39	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2000	22	5					491	503		10.1109/34.857005	http://dx.doi.org/10.1109/34.857005			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	337FV					2022-12-18	WOS:000088347500006
J	Runkle, P; Carin, L; Couchman, T; Yoder, TJ; Bucaro, JA				Runkle, P; Carin, L; Couchman, T; Yoder, TJ; Bucaro, JA			Multiaspect target identification with wave-based matched pursuits and continuous hidden Markov models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						hidden Markov model; matched pursuits; classification	SPEECH RECOGNITION; SHELL	Multiaspect target identification is effected by fusing the features extracted from multiple scattered waveforms; these waveforms are characteristic of viewing the target from a sequence of distinct orientations. Classification is performed in the maximum-likelihood sense, which we show. under reasonable assumptions, can be implemented via a hidden Markov model (HMM). We utilize a continuous-HMM paradigm and compare its performance to its discrete counterpart. The feature parsing is performed via wave-based matched pursuits. Algorithm performance is assessed by considering measured acoustic scattering data from five similar submerged elastic targets.	Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA; USN, Res Lab, Washington, DC 20375 USA; SFA Inc, Largo, MD 20785 USA	Duke University; United States Department of Defense; United States Navy; Naval Research Laboratory	Runkle, P (corresponding author), Duke Univ, Dept Elect & Comp Engn, Box 90291, Durham, NC 27708 USA.	lcarin@ee.duke.edu						Arulampalam MS, 1998, IEEE T SIGNAL PROCES, V46, P720, DOI 10.1109/78.661338; Blackman R.B., 1958, MEASUREMENT POWER SP, P95; BONDARYK JE, 1995, J ACOUST SOC AM, V97, P1067, DOI 10.1121/1.412219; CHEN JL, 1994, IEEE T PATTERN ANAL, V16, P208, DOI 10.1109/34.273730; CHEN MY, 1994, IEEE T PATTERN ANAL, V16, P481; HOUSTON BH, 1995, J ACOUST SOC AM, V98, P2851, DOI 10.1121/1.413186; Hu JY, 1996, IEEE T PATTERN ANAL, V18, P1039, DOI 10.1109/34.541414; Kohonen T., 1995, SELF ORG MAPS; LEVINSON SE, 1985, P IEEE, V73, P1625, DOI 10.1109/PROC.1985.13344; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; MAKHOUL J, 1985, P IEEE, V73, P1551, DOI 10.1109/PROC.1985.13340; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; MCCLURE M, 1998, ACOUSTICAL SOC AM, V96; Papoulis A., 1991, COMMUNICATIONS SIGNA, V3; Photiadis DM, 1997, J ACOUST SOC AM, V101, P895, DOI 10.1121/1.418048; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Runkle PR, 1999, IEEE T SIGNAL PROCES, V47, P2035, DOI 10.1109/78.771050; Scharf L.L, 1990, STAT SIGNAL PROCESSI; Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI [10.1109/MASSP.1986.1165342, 10.1002/0471250953.bia03as18]; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010	20	37	38	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1999	21	12					1371	1378		10.1109/34.817415	http://dx.doi.org/10.1109/34.817415			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	275PG					2022-12-18	WOS:000084828100010
J	Yi, XL; Camps, OI				Yi, XL; Camps, OI			Line-based recognition using a multidimensional Hausdorff distance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hausdorff distance; line-feature-based recognition; multidimensional distance transform	ARBITRARY DIMENSIONS	In this paper, a line-feature-based approach for model based recognition using a four-dimensional Hausdorff distance is proposed. This new approach reduces the problem of finding the rotation, scaling, and translation transformations between a model and an image to the problem of finding a single translation minimizing the Hausdorff distance between two sets of points in a four-dimensional space. The implementation of the proposed algorithm can be naturally extended to higher dimensional spaces to efficiently find correspondences between n-dimensional patterns. The method performance and sensitivity to segmentation problems are quantitatively characterized using an experimental protocol with simulated data. It is shown that the algorithm performs well, is robust to occlusion and outliers, and that it degrades nicely as the segmentation problems increase. Experiments with real images are also presented.	ENSCO Inc, Springfield, VA 22151 USA; Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park	Camps, OI (corresponding author), ENSCO Inc, Springfield, VA 22151 USA.	camps@whale.ee.psu.edu						BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; BORGEFORS G, 1984, COMPUT VISION GRAPH, V27, P321, DOI 10.1016/0734-189X(84)90035-5; BORGEFORS G, 1986, P INT JOINT C PATT R, P336; CALIFANO A, 1994, IEEE T PATTERN ANAL, V16, P373, DOI 10.1109/34.277591; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; HUTTENLOCHER DP, 1991, 1211 CORN U DEP COMP; Karzanov A. V., 1992, CYBERNETICS SYSTEM A, P177; LEYMARIE F, 1992, CVGIP-IMAG UNDERSTAN, V55, P84, DOI 10.1016/1049-9660(92)90008-Q; MULLIKIN JC, 1992, COMPUTER VISION GRAP, V27, P526; PAGLIERONI DW, 1990, COMPUTER VISION GRAP, V54, P56; RAGNEMALM I, 1993, PATTERN RECOGN LETT, V14, P883, DOI 10.1016/0167-8655(93)90152-4; Rucklidge WJ, 1997, INT J COMPUT VISION, V24, P251, DOI 10.1023/A:1007975324482; RUCKLIDGE WJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P457, DOI 10.1109/ICCV.1995.466904; SAITO T, 1994, PATTERN RECOGN, V27, P1551, DOI 10.1016/0031-3203(94)90133-3; YI X, 1995, P INT S COMP VIS, P79; YOU J, 1994, P IEEE INT C IM PROC, V1, P968	18	37	43	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1999	21	9					901	916		10.1109/34.790430	http://dx.doi.org/10.1109/34.790430			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	234TZ					2022-12-18	WOS:000082501600006
J	Goodrich, MT; Mitchell, JSB; Orletsky, MW				Goodrich, MT; Mitchell, JSB; Orletsky, MW			Approximate geometric pattern matching under rigid motions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hausdorff distance; pattern matching; registration	CLOSED-FORM SOLUTION; POINT; ALGORITHMS; RELAXATION; CONGRUENCE; POSE	We present techniques for matching point-sets in two and three dimensions under rigid-body transformations. We prove bounds on the worst-case performance of these algorithms to be within a small constant factor of optimal and conduct experiments to show that the average performance of these matching algorithms is often better than that predicted by the worst-case bounds.	Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA; SUNY Stony Brook, Dept Appl Math & Stat, Stony Brook, NY 11794 USA	Johns Hopkins University; State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	Goodrich, MT (corresponding author), Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA.	goodrich@cs.jhu.edu; jsbm@ams.sunysb.edu; orletsky@cs.jhu.edu						AGARWAL PK, 1993, ALGORITHMICA, V9, P495, DOI 10.1007/BF01187037; AHUJA N, 1982, IEEE T PATTERN ANAL, V4, P336, DOI 10.1109/TPAMI.1982.4767255; ALT H, 1995, ANN MATH ARTIF INTEL, V13, P251, DOI 10.1007/BF01530830; ALT H, 1988, DISCRETE COMPUT GEOM, V3, P237, DOI 10.1007/BF02187910; Arkin E. M., 1992, ORSA Journal on Computing, V4, P375, DOI 10.1287/ijoc.4.4.375; ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; Arya S., 1994, P 5 ACM SIAM S DISCR; Chew LP, 1997, COMP GEOM-THEOR APPL, V7, P113, DOI 10.1016/0925-7721(95)00047-X; COLE R, 1989, SIAM J COMPUT, V18, P792, DOI 10.1137/0218055; COLE R, 1988, SIAM J COMPUT, V17, P770, DOI 10.1137/0217049; COLE R, 1987, J ACM, V34, P200, DOI 10.1145/7531.7537; Cormen T.H., 1990, INTRO ALGORITHMS 2 V; Edelsbrunner H., 1987, ALGORITHMS COMBINATO; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233; Goodrich MT, 1998, SIAM J COMPUT, V28, P612, DOI 10.1137/S0097539793254376; HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063; HEFFERNAN PJ, 1994, COMP GEOM-THEOR APPL, V4, P137, DOI 10.1016/0925-7721(94)90004-3; HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; Huttenlocher D. P., 1992, Proceedings of the Eighth Annual Symposium on Computational Geometry, P110, DOI 10.1145/142675.142700; HUTTENLOCHER DP, 1993, DISCRETE COMPUT GEOM, V9, P267, DOI 10.1007/BF02189323; IMAI K, 1989, PROCEEDINGS OF THE FIFTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY, P266; KAHL DJ, 1980, IEEE T SYST MAN CYB, V10, P105; Kitchen L. J., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P405; MEGIDDO N, 1983, J ACM, V30, P852, DOI 10.1145/2157.322410; OGAWA H, 1986, PATTERN RECOGN, V19, P35, DOI 10.1016/0031-3203(86)90029-4; OGAWA H, 1984, PATTERN RECOGN, V17, P569, DOI 10.1016/0031-3203(84)90055-4; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; RANADE S, 1980, PATTERN RECOGN, V12, P269, DOI 10.1016/0031-3203(80)90067-9; STOCKMAN G, 1982, IEEE T PATTERN ANAL, V4, P229, DOI 10.1109/TPAMI.1982.4767240; UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573; WANG CY, 1983, PATTERN RECOGN, V16, P167, DOI 10.1016/0031-3203(83)90020-1; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]	38	37	38	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1999	21	4					371	379		10.1109/34.761267	http://dx.doi.org/10.1109/34.761267			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	187HL		Green Published, Green Submitted			2022-12-18	WOS:000079781200008
J	Georgis, N; Petrou, M; Kittler, J				Georgis, N; Petrou, M; Kittler, J			Error guided design of a 3D vision system	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						performance evaluation; projective geometry; 3D reconstruction	CAMERA CALIBRATION; PERSPECTIVE IMAGES; PLANAR SHAPES; RECOGNITION; METROLOGY; ALGORITHM; MOTION	We argue that for a method to be useful in practice, it is necessary to perform its sensitivity analysis and to investigate its robustness to measurement errors. We present here a complete sensitivity analysis of the 3D reconstruction method based on projective geometry. We use this sensitivity analysis to best design a system for the inference of the shape of a block of granite from cameras placed at 90 degrees angular separation. The system has been tested on both real and synthetic data.	Univ Surrey, Sch Elect Engn Informat Technol & Math, Guildford GU2 5XH, Surrey, England	University of Surrey	Georgis, N (corresponding author), Univ Surrey, Sch Elect Engn Informat Technol & Math, Guildford GU2 5XH, Surrey, England.	ees1ng@ee.surrey.ac.uk; ees1mp@ee.surrey.ac.uk; ees1jk@ee.surrey.ac.uk						ALOIMONOS J, 1990, IEEE T PATTERN ANAL, V12, P504, DOI 10.1109/34.55111; ANANDAN P, 1994, P ICPR 94, VA, P685; CARLSSON S, 1993, P INT C COMP VIS, P471; CHABBI H, 1993, 93R054 CRINCNRSINRIA; CHETVERIKOV D, 1992, PATTERN RECOGN LETT, V13, P669, DOI 10.1016/0167-8655(92)90123-H; Collins R. T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P240, DOI 10.1109/CVPR.1993.340983; Coxeter H.S.M., 1974, PROJECTIVE GEOMETRY, V2nd; CUMANI A, 1993, PATTERN RECOGN LETT, V14, P415, DOI 10.1016/0167-8655(93)90120-3; FAUGERAS OD, 1992, P 2 EUR C COMP VIS S, P563; GEORGIS N, 1995, PROCEEDINGS OF EUROPE-CHINA WORKSHOP ON GEOMETRICAL MODELING & INVARIANTS FOR COMPUTER VISION, P376; GEORGIS N, 1994, THESIS U SURREY; HARALICK RM, 1994, INT C PATT RECOG, P493, DOI 10.1109/ICPR.1994.576335; Herman I., 1992, LECT NOTES COMPUTER; HONG ZQ, 1993, PATTERN RECOGN, V26, P1655, DOI 10.1016/0031-3203(93)90020-W; Jacobs D. W., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P269, DOI 10.1109/CVPR.1991.139700; Maybank S., 1992, THEORY RECONSTRUCTIO; MAYBANK SJ, 1991, IMAGE VISION COMPUT, V9, P93, DOI 10.1016/0262-8856(91)90018-K; Meer P., 1994, P 12 INT C IAPR PATT, V1, P196, DOI [10.1109/ICPR.1994.576256, DOI 10.1109/ICPR.1994.576256]; MOHR R, 1991, PATTERN RECOGN LETT, V12, P39, DOI 10.1016/0167-8655(91)90026-I; MOHR R, 1991, P C COMP VIS PATT RE, P134; Mundy J., 1992, GEOMETRIC INVARIANCE; PIZLO Z, 1992, CVGIP-IMAG UNDERSTAN, V56, P330, DOI 10.1016/1049-9660(92)90046-6; RAO NSV, 1992, IEEE T ROBOTIC AUTOM, V8, P480, DOI 10.1109/70.149946; SAWHNEY HS, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P929, DOI 10.1109/CVPR.1994.323927; SHASHUA A, 1994, IEEE T PATTERN ANAL, V16, P778, DOI 10.1109/34.308472; SHASHUA A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P483, DOI 10.1109/CVPR.1994.323870; Sull S., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P732, DOI 10.1109/CVPR.1991.139804; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; Weng J., 1988, P INT C PATT REC, P247; 1994, NSF APRA WORKSH SEAT	30	37	41	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1998	20	4					366	379		10.1109/34.677262	http://dx.doi.org/10.1109/34.677262			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZP214					2022-12-18	WOS:000073729200002
J	Martin, J; Pentland, A; Sclaroff, S; Kikinis, R				Martin, J; Pentland, A; Sclaroff, S; Kikinis, R			Characterization of neuropathological shape deformations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						medical image analysis; shape description; deformable models; finite element method; modal analysis; principal component analysis; eigenanalysis; clustering	TEMPORAL-LOBE EPILEPSY; INTRACRANIAL COMPARTMENT VOLUMES; NORMAL-PRESSURE HYDROCEPHALUS; FINITE-ELEMENT ANALYSIS; BASAL GANGLIA; COMPUTED-TOMOGRAPHY; TOURETTES-SYNDROME; MRI; RECOGNITION; MODELS	We present a framework for analyzing the shape deformation of structures within the human brain. A mathematical model is developed describing the deformation of any brain structure whose shape is affected by both gross and detailed physical processes. Using our technique, the total shape deformation is decomposed into analytic modes of variation obtained from finite element modeling, and statistical modes of variation obtained from sample data. Our method is general, and can be applied to many problems where the goal is to separate out important from unimportant shape variation across a class of objects. In this paper, we focus on the analysis of diseases that affect the shape of brain structures. Because the shape of these structures is affected not only by pathology but also by overall brain shape, disease discrimination is difficult. By modeling the brain's elastic properties, we are able to compensate for some of the nonpathological modes of shape variation. This allows us to experimentally characterize modes of variation that are indicative of disease processes. We apply our technique to magnetic resonance images of the brains of individuals with schizophrenia, Alzheimer's disease, and normal-pressure hydrocephalus, as well as to healthy volunteers. Classification results are presented.	Millennium Pharmaceut Inc, Cambridge, MA 02142 USA; MIT, Media Lab, Cambridge, MA 02139 USA; Boston Univ, Dept Comp Sci, Boston, MA 02215 USA; Brigham & Womens Hosp, Dept Radiol, Surg Planning Lab, Boston, MA 02115 USA	Takeda Pharmaceutical Company Ltd; Millennium Pharmaceuticals; Massachusetts Institute of Technology (MIT); Boston University; Harvard University; Brigham & Women's Hospital	Martin, J (corresponding author), Millennium Pharmaceut Inc, 238 Main St, Cambridge, MA 02142 USA.	martin@mpi.com; sandy@media.mitt.edu; sclaroff@cs.bu.edu; kikinis@bwh.harvard.edu						AYLWARD EH, 1993, NEUROLOGY, V43, P2099, DOI 10.1212/WNL.43.10.2099; BAJCSY R, 1989, COMPUT VISION GRAPH, V46, P1, DOI 10.1016/S0734-189X(89)80014-3; BARTELT D, 1975, RADIOLOGY, V116, P111, DOI 10.1148/116.1.111; Bathe Klaus Jurgen., 1982, J PRESS VESSEL TECHN; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; BOOKSTEIN FL, 1994, P AAAI S APPL COMP V, P134; BOULT TE, 1994, P NSF WORKSH 3D OBJ; BRECHBUHLER C, IN PRESS COMPUTER VI; CASCINO GD, 1993, NEUROLOGY, V43, P2380, DOI 10.1212/WNL.43.11.2380; CENDES F, 1993, NEUROLOGY, V43, P1083, DOI 10.1212/WNL.43.6.1083; CENDES F, 1993, NEUROLOGY, V43, P719, DOI 10.1212/WNL.43.4.719; CHAN M, 1981, P ASME BIOMECHANICS, P157; CHRISTENSEN CE, 1994, P AAAI S APPL COMP V; CHRISTENSEN GE, 1994, PHYS MED BIOL, V39, P609, DOI 10.1088/0031-9155/39/3/022; CHU CS, 1994, J BIOMECH, V27, P187, DOI 10.1016/0021-9290(94)90208-9; CLINE HE, 1990, J COMPUT ASSIST TOMO, V14, P1037, DOI 10.1097/00004728-199011000-00041; COLLINS DL, 1994, J COMPUT ASSIST TOMO, V18, P192, DOI 10.1097/00004728-199403000-00005; COLLINS DL, 1992, SPIE VISUALIZAT BIOM, P10; COLLINS DL, 1994, SPIE VISUALIZATION B, P180; COOTES T, 1994, P BRIT MACH VIS C; COOTES TF, 1992, IMAGE VISION COMPUT, V10, P289, DOI 10.1016/0262-8856(92)90044-4; DELEON MJ, 1989, AM J NEURORADIOL, V10, P371; ELGAMMAL T, 1987, AM J NEURORADIOL, V8, P591; ESSA IA, 1992, DIRECTIONS GEOMETRIC; ETTINGER G, 1994, CVPR WORKSH BIOM IM; FUKUNAGA K, 1990, INTRO STAT PATTEN RE; GOLDSMITH W, 1972, BIOMECHANICS HEAD IN; HILL A, 1992, P BRIT MACH VIS C, P276; HOKAMA H, 1994, UNPUB CAUDATE PUTAME; HUGHES CP, 1981, RADIOLOGY, V139, P391, DOI 10.1148/radiology.139.2.6971454; HUTTENLOCHER D, 1992, INT J COMPUT VISION, V5, P195; JACK CR, 1987, J COMPUT ASSIST TOMO, V11, P923, DOI 10.1097/00004728-198711000-00001; MARTIN J, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P752, DOI 10.1109/CVPR.1994.323892; Matsumae M, 1996, J NEUROSURG, V84, P972, DOI 10.3171/jns.1996.84.6.0972; Matsumae M, 1996, J NEUROSURG, V84, P982, DOI 10.3171/jns.1996.84.6.0982; MURRO AM, 1993, NEUROLOGY, V43, P2531, DOI 10.1212/WNL.43.12.2531; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; PETERSON B, 1993, NEUROLOGY, V43, P941, DOI 10.1212/WNL.43.5.941; RUAN JS, 1994, J BIOMECH ENG-T ASME, V116, P44, DOI 10.1115/1.2895703; SANDOR T, 1988, AM J NEURORADIOL, V9, P1181; Sclaroff S, 1997, PATTERN RECOGN, V30, P627, DOI 10.1016/S0031-3203(96)00108-2; SCLAROFF S, 1995, IEEE T PATTERN ANAL, V17, P545, DOI 10.1109/34.387502; SCLAROFF S, 1994, CVPR WORKSH BIOM IM; SHENTON ME, 1992, NEW ENGL J MED, V327, P604, DOI 10.1056/NEJM199208273270905; SINGER HS, 1993, NEUROLOGY, V43, P950, DOI 10.1212/WNL.43.5.950; SOININEN HS, 1994, NEUROLOGY, V44, P1660, DOI 10.1212/WNL.44.9.1660; SPENCER SS, 1993, NEUROLOGY, V43, P2117, DOI 10.1212/WNL.43.10.2117; Strang G., 1986, INTRO APPL MATH; SZEKELY G, 1995, UNPUB SEGMENTATION 3; SZELISKI R, 1989, BAYESIAN MODELING UN; TANNER JM, 1990, FETUS MAN PHYSICAL G; TERZOPOULOS D, 1987, INT J COMPUT VISION, V1, P211, DOI 10.1007/BF00127821; Therrien C. W., 1989, DECISION ESTIMATION; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Volpe J., 1995, NEUROLOGY NEWBORN; WIKKELSO C, 1989, NEURORADIOLOGY, V31, P160, DOI 10.1007/BF00698846; Wolberg G, 1990, DIGITAL IMAGE WARPIN; ZHU SC, 1993, 941 HARV ROB LAB	60	37	37	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1998	20	2					97	112		10.1109/34.659928	http://dx.doi.org/10.1109/34.659928			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YZ697		Green Submitted			2022-12-18	WOS:000072281800001
J	Djouadi, A; Bouktache, E				Djouadi, A; Bouktache, E			A fast algorithm for the nearest-neighbor classifier	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nearest neighbor; pattern recognition; feature partition; fast algorithm; classification performance		A fast algorithm that finds the nearest neighbor (NN) of an unknown sample from a design set of labeled samples is proposed. This algorithm requires a quite moderate preprocessing effort and a rather excessive storage, but it accomplishes substantial computational savings during classification. The performance of the algorithm is described and compared to the performance of the conventional one. Results on simulated data are provided to illustrate the computational savings' that may be achieved using this fast algorithm.	PURDUE UNIV CALUMET,DEPT ELECT ENGN TECHNOL,HAMMOND,IN 46323	Purdue University System; Purdue University	Djouadi, A (corresponding author), LUCENT TECHNOL,COLUMBUS,OH, USA.							BELUR, 1979, P IEEE, V67, P708; CHANG CL, 1974, IEEE T COMPUT, VC 23, P1179, DOI 10.1109/T-C.1974.223827; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; Duda R.O., 1973, J ROYAL STAT SOC SER; FUKUNAGA K, 1975, IEEE T COMP, V24, P1000; HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155; RITTER GL, 1975, IEEE T INFORM THEORY, V21, P665, DOI 10.1109/TIT.1975.1055464; SETHI IK, 1981, IEEE T SYST MAN CYB, V11, P245; VASSAIRE C, 1982, IEEE T PATTERN ANAL, V4, P663	9	37	70	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1997	19	3					277	282		10.1109/34.584107	http://dx.doi.org/10.1109/34.584107			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR582					2022-12-18	WOS:A1997WR58200011
J	AVIITZHAK, HI; DIEP, TA; GARLAND, H				AVIITZHAK, HI; DIEP, TA; GARLAND, H			HIGH-ACCURACY OPTICAL CHARACTER-RECOGNITION USING NEURAL NETWORKS WITH CENTROID DITHERING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						PATTERN RECOGNITION; OPTICAL CHARACTER RECOGNITION; NEURAL NETWORKS		Optical character recognition (OCR) refers to a process whereby printed documents are transformed into ASCII files for the purpose of compact storage, editing, fast retrieval, and other file manipulations through the use of a computer. The recognition stage of an OCR process is made difficult by added noise, image distortion, and the various character typefaces, sizes, and fonts that a document may have. In this study a neural network approach is introduced to perform high accuracy recognition on multi-size and multi-font characters; a novel centroid-dithering training process with a low noise-sensitivity normalization procedure is used to achieve high accuracy results. The study consists of two parts. The first part focuses on single size and single font characters, and a two-layered neural network is trained to recognize the full set of 94 ASCII character images in 12-pt Courier font. The second part trades accuracy for additional font and size capability, and a larger two-layered neural network is trained to recognize the full set of 94 ASCII character images for all point sizes from 8 to 32 and for 12 commonly used fonts. The performance of these two networks is evaluated based on a database of more than one million character images from the testing data set.	CANON RES CTR AMER,PALO ALTO,CA 94304	Canon Incorporated	AVIITZHAK, HI (corresponding author), STANFORD UNIV,DEPT ELECT ENGN,STANFORD,CA 94305, USA.							COTE GR, 1992, BYTE             SEP, P198; David E., 1986, PARALLEL DISTRIBUTED, P318, DOI DOI 10.5555/104279.104293; DVORAK JC, 1991, PC COMPUTING, V4, P62; GRUNIN L, 1990, PC MAGAZINE     1030, P299; JENKINS F, 1993, S DUCUMENT ANAL INFO; KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274, DOI 10.1109/TPAMI.1987.4767901; MORI S, 1992, P IEEE, V80, P1029, DOI 10.1109/5.156468; Parzen E., 1960, MODERN PROBABILITY T, DOI 10.1063/1.3056709; RICE SV, 1992, S DOCUMENT ANAL INFO; WIDROW B, 1990, P IEEE, V78, P1415, DOI 10.1109/5.58323; WIDROW B, 1988, IEEE COMPUT MAG, V21, P25	11	37	38	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1995	17	2					218	224		10.1109/34.368165	http://dx.doi.org/10.1109/34.368165			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE825					2022-12-18	WOS:A1995QE82500013
J	NEY, H				NEY, H			ON THE PROBABILISTIC-INTERPRETATION OF NEURAL-NETWORK CLASSIFIERS AND DISCRIMINATIVE TRAINING CRITERIA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						STATISTICAL PATTERN RECOGNITION; NEURAL NETWORKS; DISCRIMINANT FUNCTIONS; TRAINING CRITERIA; SPEECH RECOGNITION	MULTILAYER PERCEPTRONS; SPEECH RECOGNITION	A probabilistic interpretation is presented for two important issues in neural network based classification, namely the interpretation of discriminative training criteria and the neural network outputs as well as the interpretation of the structure of the neural network. The problem of finding a suitable structure of the neural network can be linked to a number of well established techniques in statistical pattern recognition, such as the method of potential functions, kernel densities, and continuous mixture densities. Discriminative training of mural network outputs amounts to approximating the class or posterior probabilities of the classical statistical approach. This paper extends these links by introducing and analyzing novel criteria such as maximizing the class probability and minimizing the smoothed error rate. These criteria are defined in the framework of class-conditional probability density functions. We will show that these criteria can be interpreted in terms of weighted maximum likelihood estimation, where the weights depend in a complicated nonlinear fashion on the model parameters to be trained. In particular, this approach covers widely used techniques such as corrective training, learning vector quantization, and linear discriminant analysis.			NEY, H (corresponding author), RHEIN WESTFAL TH AACHEN,LEHRSTUHL INFORMAT VI,AHORNSTR 55,D-52056 AACHEN,GERMANY.							Aizerman M. A., 1964, AUTOMAT REM CONTR, V25, P821, DOI DOI 10.1234/12345678; AIZERMAN MA, 1964, AUTOMAT REM CONTR, V25, P1175; ASOH H, 1989, P INT JOINT C NEUR N, V2, P411; BAHL LR, 1986, P IEEE INT C AC SPEE, P49; BAHL LR, 1988, APR P IEEE INT C AC, P493; Baker J.K., 1975, SPEECH RECOGNITION, P512; BLAYDON CC, 1966, IEEE T INFORM THEORY, V12, P82, DOI 10.1109/TIT.1966.1053848; BOURLARD H, 1988, BIOL CYBERN, V59, P291, DOI 10.1007/BF00332918; BOURLARD H, 1989, ADV NEURAL INFORMATI, P502; Bridle J. S., 1989, NATO ASI SERIES SYST; David E., 1986, PARALLEL DISTRIBUTED, P318, DOI DOI 10.5555/104279.104293; Duda R.O., 1973, J ROYAL STAT SOC SER; ELJAROUDI A, 1990, P INT JOINT C NEUR N, V3, P185; FUKUNAGA K, 1972, INTRO STATISTICAL PA; GALLINARI P, 1991, NEURAL NETWORKS, V4, P349, DOI 10.1016/0893-6080(91)90071-C; GISH H, 1990, INT CONF ACOUST SPEE, P1361, DOI 10.1109/ICASSP.1990.115636; HAMPSHIRE JB, 1989, JUN P IEEE INT JOINT, V1, P235; HAND DJ, 1982, KERNEL DISCRIMINANT; JELINEK F, 1976, P IEEE, V64, P532, DOI 10.1109/PROC.1976.10159; JUANG BH, 1992, IEEE T SIGNAL PROCES, V40, P3043, DOI 10.1109/78.175747; Kohonen T., 1988, SELF ORG ASS MEMORY; KOHONEN T, 1988, JUL P IEEE INT C NEU; LEE KF, 1989, CMUCS89100CARN MELL; LJOLJE A, 1990, APR P IEEE INT C AC, P709; LOWE D, 1991, IEEE T PATTERN ANAL, V13, P355, DOI 10.1109/34.88570; NADAS A, 1985, IEEE T ACOUST SPEECH, V33, P326, DOI 10.1109/TASSP.1985.1164513; NILES LT, 1990, APR P IEEE INT C AC, P493; PATTERSON JD, 1966, IEEE T SYST SCI CYB, VSSC2, P62, DOI 10.1109/TSSC.1966.300080; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; RAO CR, 1965, LINEAR STATISTICAL I; RENALS S, 1989, P INT JOINT C NEURAL, V1, P461; Richard MD, 1991, NEURAL COMPUT, V3, P461, DOI 10.1162/neco.1991.3.4.461; Solla S. A., 1988, Complex Systems, V2, P625; SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q; TISHBY N, 1989, JUN P IEEE INT JOINT, V2, P403; Viterbi A.J., 1979, PRINCIPLES DIGITAL C; WAIBEL A, 1988, P IEEE ICASSP NEW YO, P107; WEBB AR, 1990, NEURAL NETWORKS, V3, P367, DOI 10.1016/0893-6080(90)90019-H; WHITE H, 1990, NEURAL COMPUT, V1, P425	39	37	40	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1995	17	2					107	119		10.1109/34.368176	http://dx.doi.org/10.1109/34.368176			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE825					2022-12-18	WOS:A1995QE82500002
J	TRIKA, SN; KASHYAP, RL				TRIKA, SN; KASHYAP, RL			GEOMETRIC REASONING FOR EXTRACTION OF MANUFACTURING FEATURES IN ISO-ORIENTED POLYHEDRA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CAD-CAM INTEGRATION; GEOMETRIC REASONING; MANUFACTURING FEATURE EXTRACTION; AUTOMATION; ISO-ORIENTED POLYHEDRA	RECOGNITION; CSG; DESIGN	This paper investigates the extraction of machining features from boundary descriptions of iso-oriented (having no inclined faces) polyhedrons. We prove that manufacturing the features proposed by our feature extractor results exactly in the desired part-in this respect, the approach is both sound and complete. Our method uses the adjacency information between faces to derive the features. This keeps the determination of isolated features in a part straightforward. However, interaction of features creates difficulties since the adjacency information between some faces is lost. We derive this lost information by considering faces that when extended intersect other faces to form concave edges. The derived face adjacencies are termed virtual links. Augmenting the virtual links to the cavity graph of the object leads to its feature graph, and subgraph matching of primitive graphs in this graph results in feature hypotheses. A feature hypothesis is considered valid if the volume corresponding to it is not shared with the part in question; therefore, we verify the feature hypotheses by checking the regularized intersection of the feature volume and the part. Thus, feature verification employs a Constructive Solid Geometry (CSG) approach. We have implemented a prototype of the system in the Smalltalk-80 environment. Simulation results verify our approach.			TRIKA, SN (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.							Aho AV, 1974, DESIGN ANAL COMPUTER; ANDERSON DC, 1990, COMPUT GRAPH, V14, P225, DOI 10.1016/0097-8493(90)90034-U; FIELDS MC, 1993, ADV DESIGN AUTOMATIO, P263; Floriani L. D., 1989, IEEE T PATTERN ANAL, V11, P785; GADH R, 1992, COMPUT AIDED DESIGN, V24, P583, DOI 10.1016/0010-4485(92)90070-Q; HENDERSON MR, 1985, COMPUT IND, V5, P329; Hoffmann C.M., 1989, GEOMETRIC SOLID MODE; HWANG JL, 1991, P ARTIFICIAL NEURAL, P486; JAKUBOWSKI R, 1982, CYBERNET SYST, V13, P1, DOI 10.1080/01969728208927686; JOSHI S, 1988, COMPUT AIDED DESIGN, V20, P58, DOI 10.1016/0010-4485(88)90050-4; KAO CY, 1992, THESIS PENNSYLVANIA; KARINTHI RR, 1992, IEEE T PATTERN ANAL, V14, P469, DOI 10.1109/34.126807; KIM YS, 1992, COMPUT AIDED DESIGN, V24, P461, DOI 10.1016/0010-4485(92)90027-8; KYPRIANOU LK, 1980, THESIS KINGS COLL U; LEE TC, 1992, IEEE INT C SYST MAN, P7; LEE YC, 1987, IEEE COMPUT GRAPH, V7, P20, DOI 10.1109/MCG.1987.277024; Luby S. C., 1986, Computers in Mechanical Engineering, V5, P25; Mantyla M., 1988, INTRODUCTION; MAREFAT M, 1990, IEEE T PATTERN ANAL, V12, P949, DOI 10.1109/34.58868; PERNG DB, 1990, COMPUT AIDED DESIGN, V22, P285, DOI 10.1016/0010-4485(90)90093-R; REGLI WC, 1993, 2 S SOL MOD APPL MON, P293; ROSSIGNAC JR, 1989, ACM T GRAPHIC, V8, P51, DOI 10.1145/49155.51123; Shafer G., 1976, MATH THEORY EVIDENCE, VVolume 1; TRIKA SN, UNPUB SOUND COMPLETE; TRIKA SN, 1992, THESIS PURDUE U W LA; VANDENBRANDE JH, 1993, IEEE T PATTERN ANAL, V15, P1269, DOI 10.1109/34.250845; WOO TC, 1982, MAR P C CAD CAM TECH, P76; YOU IC, 1989, ROBOT CIM-INT MANUF, V6, P181, DOI 10.1016/0736-5845(89)90039-2	28	37	42	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1994	16	11					1087	1100		10.1109/34.334388	http://dx.doi.org/10.1109/34.334388			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PW081					2022-12-18	WOS:A1994PW08100003
J	BOZMA, O; KUC, R				BOZMA, O; KUC, R			A PHYSICAL MODEL-BASED ANALYSIS OF HETEROGENOUS ENVIRONMENTS USING SONAR - ENDURA METHOD	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						SONAR; ACOUSTIC SENSORS; TIME OF FLIGHT; KIRCHHOFF APPROXIMATION METHOD; SMOOTH AND ROUGH SURFACES; ECHO ENERGY; ECHO DURATION	NAVIGATION; SENSOR	A physical model-based analysis of unstructured environments is presented using sonar as a sensing device. Previous methods have relied only on time-of-flight (TOF) methods and have examined only homogenous environments consisting of either smooth or rough surfaces. In this paper, a forward model for the reflection from a class of surfaces with varying degrees of roughness is presented based on the Kirchhoff approximation method. This model integrates different types of environments into a single analytical framework. The echo intensity is parametrized in terms of its energy content and duration, which are functions of the surface roughness, distance, and orientation. The echo-energy and echo-duration maps are introduced to display these parameters. A systematic and robust procedure (ENDURA method) is presented to analyze the reflections and to differentiate and localize the reflecting surfaces. The methodology is verified with experimental results obtained in our laboratory. The results indicate a significant improvement over conventional TOF systems.	YALE UNIV, DEPT ELECT ENGN, INTELLIGENT SENSORS LAB, NEW HAVEN, CT 06520 USA	Yale University								BARSHAN B, 1992, IEEE T SYST MAN CYB, V22, P636, DOI 10.1109/21.156577; BARSHAN B, 1990, IEEE T PATTERN ANAL, V12, P560, DOI 10.1109/34.56192; BARSHAN B, 1991, IEEE T PATTERN ANAL, V22, P636; BECKMAN P, 1963, ELECTROMAGNETIC AUTO; BOZMA O, 1991, J ACOUST SOC AM, V89, P2519, DOI 10.1121/1.400692; BOZMA O, 1991, IEEE T PATTERN ANAL, V13, P1260, DOI 10.1109/34.107000; BOZMA O, 1992, THESIS YALE U; Brown M. K., 1985, IEEE Journal of Robotics and Automation, VRA-1, P191, DOI 10.1109/JRA.1985.1087022; Crowley J. L., 1985, IEEE Journal of Robotics and Automation, VRA-1, P31, DOI 10.1109/JRA.1985.1087002; ECKART C, 1953, J ACOUST SOC AM, V25, P566, DOI 10.1121/1.1907123; ELFES A, 1987, IEEE T ROBOTIC AUTOM, V3, P249, DOI 10.1109/JRA.1987.1087096; GULIN EP, 1975, AM I PHYS, V20, P332; KUC R, 1991, INT J ROBOT RES, V10, P75, DOI 10.1177/027836499101000201; KUC R, 1987, IEEE T PATTERN ANAL, V9, P766, DOI 10.1109/TPAMI.1987.4767983; KUC R, 1990, IEEE T PATTERN ANAL, V12, P686, DOI 10.1109/34.56211; Papoulis A., 2002, PROBABILITY RANDOM V; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2; VanTrees H., 1968, DETECTION ESTIMATION, V1	18	37	37	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1994	16	5					497	506		10.1109/34.291448	http://dx.doi.org/10.1109/34.291448			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NP141					2022-12-18	WOS:A1994NP14100005
J	EGGERT, DW; BOWYER, KW; DYER, CR; CHRISTENSEN, HI; GOLDGOF, DB				EGGERT, DW; BOWYER, KW; DYER, CR; CHRISTENSEN, HI; GOLDGOF, DB			THE SCALE-SPACE ASPECT GRAPH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ASPECT GRAPH; DYNAMIC SHAPE; GAUSSIAN SMOOTHING; IMAGE RESOLUTION; SCALE SPACE; VIEWPOINT SPACE PARTITION	PROJECTION ASPECT GRAPH; CURVED OBJECTS; PLANAR CURVES; SHAPE; REPRESENTATION; REVOLUTION; SURFACES; SOLIDS	Currently the aspect graph is computed from the theoretical standpoint of perfect resolution in object shape, the viewpoint and the projected image. This means that the aspect graph may include details that an observer could never see in practice. Introducing the notion of scale into the aspect graph framework provides a mechanism for selecting a level of detail that is ''large enough'' to merit explicit representation. This effectively allows control over the number of nodes retained in the aspect graph. This paper introduces the concept of the scale space aspect graph, defines three different interpretations of the scale dimension, and presents a detailed example for a simple class of objects, with scale defined in terms of the spatial extent of features in the image.	AALBORG UNIV, INST ELECTR SYST, AALBORG, DENMARK; UNIV WISCONSIN, DEPT COMP SCI, MADISON, WI 53706 USA	Aalborg University; University of Wisconsin System; University of Wisconsin Madison	EGGERT, DW (corresponding author), UNIV S FLORIDA, DEPT COMP SCI & ENGN, TAMPA, FL 33620 USA.		Christensen, Henrik I/A-2261-2009; Goldgof, Dmitry/ABF-1366-2020	Christensen, Henrik Iskov/0000-0002-7465-7502; Bowyer, Kevin/0000-0002-7562-4390				BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; BENARIE J, 1990, PATTERN RECOGN LETT, V11, P421, DOI 10.1016/0167-8655(90)90113-G; BOWYER K, 1993, IEEE T PATTERN ANAL, V15, P605, DOI 10.1109/34.216731; CHEN S, 1991, P IEEE WORKSHOP DIRE, P34; CLARK JJ, 1988, IEEE T PATTERN ANAL, V10, P720, DOI 10.1109/34.6782; COWAN CK, 1991, P IEEE WORKSHOP DIRE, P22; EGGERT D, 1990, PATTERN RECOGN LETT, V11, P751, DOI 10.1016/0167-8655(90)90094-I; EGGERT D, 1993, IEEE T PATTERN ANAL, V15, P109, DOI 10.1109/34.192483; EGGERT D, 1991, THESIS U S FLORIDA; EGGERT DE, 1992, 17TH P ISPRS C IN B5, P633; FAUGERAS O, 1991, P IEEE WORKSHOP DIRE, P98; GIGUS Z, 1991, IEEE T PATTERN ANAL, V13, P542, DOI 10.1109/34.87341; GUALTIERI JA, 1989, COMPUT VISION GRAPH, V46, P96, DOI 10.1016/S0734-189X(89)80018-0; KENDER JR, 1987, P ARPA IMAGE UNDERST, P589; Koenderink J., 1990, SOLID SHAPE; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; KOENDERINK JJ, 1986, BIOL CYBERN, V53, P383, DOI 10.1007/BF00318204; KRIEGMAN DJ, 1990, INT J COMPUT VISION, V5, P119, DOI 10.1007/BF00054918; LEVITT TS, 1990, ARTIF INTELL, V44, P305, DOI 10.1016/0004-3702(90)90027-W; LINDEBERG T, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P416; MALIK J, 1987, INT J COMPUT VISION, V1, P73, DOI 10.1007/BF00128527; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; NALWA VS, 1988, INT J COMPUT VISION, V2, P103, DOI 10.1007/BF00133696; PLANTINGA H, 1990, INT J COMPUT VISION, V5, P137, DOI 10.1007/BF00054919; PONCE J, 1992, P EUROPEAN C COMPUTE, P599; PONCE J, 1987, 8TH P NAT C ART INT, P340; RIEGER JH, 1992, INT J COMPUT VISION, V7, P171, DOI 10.1007/BF00126392; RIEGER JH, 1990, ARTIF INTELL, V44, P1, DOI 10.1016/0004-3702(90)90097-J; SEALES WB, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P698; SRIPRADISVARAKU.T, 1989, NOV P IEEE WORKSH IN, P109; Stewman J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P494, DOI 10.1109/CCV.1988.590029; STEWMAN JH, 1990, COMPUT VISION GRAPH, V51, P20, DOI 10.1016/S0734-189X(05)80060-X; STEWMAN JH, 1987, 13TH P INT WORKSH GR, P230; WANG R, 1990, 10TH P INT C PATT RE, P8; Watts N. A., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P316, DOI 10.1109/ICPR.1988.28231; WITKIN AP, 1986, PIXELS PREDICATES RE, P5; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]; [No title captured]	40	37	40	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1993	15	11					1114	1130		10.1109/34.244674	http://dx.doi.org/10.1109/34.244674			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MH083					2022-12-18	WOS:A1993MH08300002
J	WEISS, I				WEISS, I			NOISE-RESISTANT INVARIANTS OF CURVES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						INVARIANCE; MATCHING; OBJECT RECOGNITION; PERSPECTIVE; POSE; PROJECTIVE; ROBUST ESTIMATION		Projective invariants are shape descriptors that are independent of the point of view from which the shape is seen, and therefore, they are of major importance in object recognition. They make it possible to match an image of an object to one stored in a database without the need to search for the correct viewpoint. In this paper, we obtain an invariant representation (''signature'') of a general curve. The calculation is local and does not suffer from the occlusion problem of global descriptors. To make the method robust, we have developed differentiation techniques that give much more reliable results than previous ones. These differentiation methods are useful in many other applications as well.			WEISS, I (corresponding author), UNIV MARYLAND,CTR AUTOMAT RES,COLL PK,MD 20742, USA.							BARRETT E, 1991, CVGIP IU, V53, P45; BRILL M, 1991, COMMUNICATION; BROWN CM, 1991, TR393 U ROCH COMP SC; BRUCKSTEIN A, 1990, AT T TR          JUL; BURNS JB, 1990, P DARPA IU WORKSHOP; Duda RO, 1973, PATTERN RECOGNITION; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233; GUGGENHEIEMR H, 1963, DIFFERENTIAL GEOMETR; Guggenheimer H.W., 1963, DIFFERENTIAL GEOMETR; HALPHEN, 1880, J EC POLYT, V38; Lane E.P., 1942, TREATISE PROJECTIVE; Meer P., 1992, Journal of Visual Communication and Image Representation, V3, P58, DOI 10.1016/1047-3203(92)90030-W; VANGOOL L, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P530; WEISS I, 1992, GEOMETRIC INVARIANTS; WEISS I, 1988, P IMAGE UNDERSTANDIN, P1125; WEISS I, 1992, P DARPA IMAGE UNDERS, P683; WEISS I, 1992, CARTR612 U MARYL; WEISS I, 1993, INT J COMPUT VISION, V10, P201; WEISS I, 1991, TR CAR545 U MARYL CE; Wilczynski E.J., 1906, PROJECTIVE DIFFERENT	20	37	38	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1993	15	9					943	948		10.1109/34.232081	http://dx.doi.org/10.1109/34.232081			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LW676					2022-12-18	WOS:A1993LW67600008
J	ZHANG, ZY; FAUGERAS, OD				ZHANG, ZY; FAUGERAS, OD			ESTIMATION OF DISPLACEMENTS FROM 2 3-D FRAMES OBTAINED FROM STEREO	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						EXTENDED KALMAN FILTERING; HYPOTHESIZE-AND-VERIFY; MOTION FROM STEREO; MULTIPLE OBJECT MOTIONS; RIGIDITY CONSTRAINTS; ROBOT VISION; 3-D MATCHING; UNCERTAINTY	MOTION ESTIMATION; IMAGE SEQUENCES; ALGORITHM; RECOGNITION; OBJECTS	We present a method for estimating 3-D displacements from two stereo frames. It is based on the hypothesize-and-verify paradigm used to match 3-D line segments between the two frames. In order to reduce the complexity of the method, we make the assumption that objects are rigid. We formulate a set of complete rigidity constraints for 3-D line segments and integrate the uncertainty of measurements in this formulation. The hypothesize-and-verify stages of the method use an extended Kalman filter to produce estimates of the displacements and of their uncertainty. In the experimental sections, the algorithm is shown to work on indoor and natural scenes. Furthermore, it is easily extended, as is also shown, to the case where several mobile objects are present. The method is quite robust, fast, and has been thoroughly tested on hundreds of real stereo frames.	ECOLE POLYTECH, F-91128 PALAISEAU, FRANCE	Institut Polytechnique de Paris	ZHANG, ZY (corresponding author), INST NATL RECH INFORMAT & AUTOMAT, COMP VIS & ROBOT GRP, VALBONNE, FRANCE.							ADIV G, 1985, JUN P IEEE C COMP VI, P70; AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965; ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; AYACHE N, 1989, IEEE T ROBOTIC AUTOM, V5, P804, DOI 10.1109/70.88101; AYACHE N, 1987, 1ST P INT C COMP VIS, P422; AYACHE N, 1985, 3RD P WORKSH COMP VI, P27; AYACHE N, 1987, AUG P INT S ROB RES; AYACHE N, 1987, 1ST P INT C COMP VIS, P73; Ayache N, 1991, ARTIFICIAL VISION MO; BARNARD ST, 1982, ACM COMPUT SURV, V14, P553, DOI DOI 10.1145/356893.356896; Blostein S. D., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P246; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; BROIDA TJ, 1990, IEEE T AERO ELEC SYS, V26, P639, DOI 10.1109/7.55557; BROIDE T, 1989, MAR P IEEE WORKSH VI, P21; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; CHEN HH, 1988, PATTERN RECOGN, V21, P75, DOI 10.1016/0031-3203(88)90016-7; CHEN HH, 1987, NOV P IEEE WORKSH CO, P151; DURRANTWHYTE HF, 1988, IEEE J ROBOT AUTOM, V4, P23, DOI 10.1109/56.768; Faugeras O. D., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P242, DOI 10.1109/ICPR.1988.28214; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; FAUGERAS OD, 1990, INT J COMPUT VISION, V4, P225, DOI 10.1007/BF00054997; FAUGERAS OD, 1986, APR P IEEE C ROB AUT, P1433; FAUGERAS OD, 1987, 1ST P INT C COMP VIS, P25; FAUGERAS OD, 1989, ROBOTICS SCI, P39; FAUNGERAS O, 1983, ROBOT VISION, P129; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; HILDRETH E, 1983, MEASUREMENT VISUAL M; HORAUD P, 1984, MAR P INT C ROB ATL, P78; Horn B., 1986, ROBOT VISION, P1; HORN B, 1981, ARTIF INTELL, V20, P199; HUANG T, 1986, AL ENCY, P620; Huang T.S., 1981, IMAGE SEQUENCE ANAL, P1; HUANG TS, 1985, IEEE C COMPUTER VISI, P518; Jazwinski A.H., 1970, STOCHASTIC PROCESSES; KIM YC, 1987, IEEE T ROBOTIC AUTOM, V3, P599; Lin Z., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P303; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LOWER D, 1985, PERCEPTUAL ORG VISUA; LOWER D, 1987, INT J COMPUT VISION, P57; MAYBANK SJ, 1987, THESIS U LONDON; Maybeck P. S., 1982, STOCHASTIC MODELS ES, V2; Maybeck P. S., 1982, STOCHASTIC MODELS ES; MITICHE A, 1986, MAY P WORKSH MOT REP, P175; MURRAY DW, 1988, INT J COMPUT VISION, V2, P153, DOI 10.1007/BF00133698; Nagel H., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P1174; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; POLLARD SB, 1987, IMAGE VISION COMPUT, V5, P73, DOI 10.1016/0262-8856(87)90030-8; POLLARD SB, 1985, PERCEPTION, V14, P449, DOI 10.1068/p140449; ROBERTS K, 1988, JUN P IEEE C COMP VI, P635; Rodrigues O., 1840, J MATH PURE APPL, V5, P380; SHARIAT H, 1990, IEEE T PATTERN ANAL, V12, P417, DOI 10.1109/34.55102; TSAI RY, 1981, IEEE T ACOUST SPEECH, V29, P1147, DOI 10.1109/TASSP.1981.1163710; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WENG JY, 1987, IEEE T PATTERN ANAL, V9, P370, DOI 10.1109/TPAMI.1987.4767920; YOUNG GSJ, 1990, IEEE T PATTERN ANAL, V12, P735, DOI 10.1109/34.57666; ZHANG Z, 1988, 2ND P INT C COMP VIS, P177; ZHANG Z, 1990, SEP P BRIT MACH VIS, P85; ZHANG Z, 1989, MAR P IEEE WORK VIS, P306; ZHANG Z, 1990, THESIS U PARIS ORSAY; ZHANG Z, 1990, 10TH P INT C PATT RE, P38; ZHANG ZY, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P577	64	37	39	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1992	14	12					1141	1156		10.1109/34.177380	http://dx.doi.org/10.1109/34.177380			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KC573					2022-12-18	WOS:A1992KC57300001
J	SILVERMAN, JF; COOPER, DB				SILVERMAN, JF; COOPER, DB			BAYESIAN CLUSTERING FOR UNSUPERVISED ESTIMATION OF SURFACE AND TEXTURE MODELS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											SILVERMAN, JF (corresponding author), BROWN UNIV,DIV ENGN,ENGN MAN MACHINE SYST LAB,PROVIDENCE,RI 02912, USA.							BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BOLLE RM, 1986, IEEE T PATTERN ANAL, V8, P619, DOI 10.1109/TPAMI.1986.4767836; BOLLE RM, 1984, IEEE T PATTERN ANAL, V6, P418, DOI 10.1109/TPAMI.1984.4767547; CERNUSCHIFRIAS B, 1985, JUN P IEEE COMP SOC, P167; CHEN PC, 1980, COMPUT VISION GRAPH, V12, P153, DOI 10.1016/0146-664X(80)90009-X; Cohen F. S., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P1104; COHEN FS, 1987, IEEE T PATTERN ANAL, V9, P195, DOI 10.1109/TPAMI.1987.4767895; COHEN FS, UNPUB UNSUPERVISED T; COOPER DB, 1983, IEEE T PATTERN ANAL, V5, P299, DOI 10.1109/TPAMI.1983.4767392; DEGROOT MH, 1970, OPTIMAL STATISTICAL, pCH10; DERIN H, 1987, IEEE T PATTERN ANAL, P39; Diday E, 1980, CLUSTERING ANAL DIGI, P47; DUDA RO, 1973, PATTERN CLASSIFICATI, P328; GAGALOWICZ A, 1985, DEC P SPIE C COMP VI, P56; GIDAS B, RENORMALIZATION GROU; Hanson A. R., 1978, COMPUTER VISION SYST, P129; SILVERMAN JF, 1985, SMOOTH SURFACE PARAM; SILVERMAN JF, 1986, 1986 P IEEE INT C RO, P299; THERRIEN CW, 1983, COMPUT VISION GRAPH, V22, P313, DOI 10.1016/0734-189X(83)90079-8; WILKS SS, 1962, MATH STATISTICS, P419	20	37	39	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1988	10	4					482	495		10.1109/34.3912	http://dx.doi.org/10.1109/34.3912			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	P1493					2022-12-18	WOS:A1988P149300005
J	MARSLAND, TA; POPOWICH, F				MARSLAND, TA; POPOWICH, F			PARALLEL GAME-TREE SEARCH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											MARSLAND, TA (corresponding author), UNIV ALBERTA,DEPT COMP SCI,EDMONTON T6G 2E1,ALBERTA,CANADA.							AKL SG, 1982, IEEE T PATTERN ANAL, V4, P192, DOI 10.1109/TPAMI.1982.4767226; BAUDET G, 1978, THESIS CARNEGIEMELLO; BOWEN BA, 1980, LOGICAL DESIGN MULTI; BRATKO I, 1982, ADV COMPUTER CHESS, V3, P31; BURTON FW, 1984, IEEE T COMPUT, V33, P278, DOI 10.1109/TC.1984.1676425; CAMPBELL MS, 1983, ARTIF INTELL, V20, P347, DOI 10.1016/0004-3702(83)90001-2; FINKEL RA, 1982, ARTIF INTELL, V19, P89, DOI 10.1016/0004-3702(82)90022-4; FISHBURN J, 1981, 421 U WISC DEP COMP; FISHBURN J, 1980, 394 U WISC DEP COMP; GILLOGLY JJ, 1978, THESIS CARNEGIEMELLO; KNUTH DE, 1975, ARTIF INTELL, V6, P293, DOI 10.1016/0004-3702(75)90019-3; LINDSTROM G, 1983, UUCS83101 U UT DEP C; Marsland T.A., 1985, ADV COMPUTER CHESS, V4; MARSLAND TA, 1982, COMPUT SURV, V14, P533, DOI 10.1145/356893.356895; MARSLAND TA, 1983, AUG P IJCAI 83 KARLS, P763; MOHAN J, 1982, CMUCS82136 CARN U DE; NEWBORN M, 1982, SOCS823 MCGILL U SCH; Nicholas D., 1978, LIT BIBLIOMETRICS; PEARL J, 1980, ARTIF INTELL, V14, P113, DOI 10.1016/0004-3702(80)90037-5; POPOWICH F, 1983, 837 U ALB DEP COMP S; Slate D. J., 1977, Chess skill in man and machine, P82; THOMPSON K, 1981, COMMUNICATION    OCT; 1981, INTELLIGENT OCTAL SE; 1982, SUN 1 SYSTEM REFEREN	24	37	37	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	4					442	452		10.1109/TPAMI.1985.4767683	http://dx.doi.org/10.1109/TPAMI.1985.4767683			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ALB69	21869282	Green Submitted			2022-12-18	WOS:A1985ALB6900008
J	OGORMAN, L; SANDERSON, AC				OGORMAN, L; SANDERSON, AC			THE CONVERGING SQUARES ALGORITHM - AN EFFICIENT METHOD FOR LOCATING PEAKS IN MULTIDIMENSIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									CARNEGIE MELLON UNIV,DEPT ELECT ENGN,PITTSBURGH,PA 15213; CARNEGIE MELLON UNIV,INST ROBOT,PITTSBURGH,PA 15213	Carnegie Mellon University; Carnegie Mellon University	OGORMAN, L (corresponding author), BELL TEL LABS INC,COMP TECHNOL RES LAB,MURRAY HILL,NJ 07974, USA.							BALLARD DH, 1982, COMPUTER VISION, P106; CABOT RC, 1981, IEEE T ACOUST SPEECH, V29, P607, DOI 10.1109/TASSP.1981.1163564; COX JA, 1981, P SOC PHOTO-OPT INST, V292, P288; CROWLEY JL, 1978, P IEEE C PATT RECOGN, P372; CROWLEY JL, 1982, THESIS CARNEGIE MELL; Duda R.O., 1973, J ROYAL STAT SOC SER; EKLUNDH JO, 1979, IEEE T PATTERN ANAL, V1, P317, DOI 10.1109/TPAMI.1979.4766930; FUKUNAGA K, 1972, INTRO STATISTICAL PA; HALL EL, 1976, 1976 P IEEE C DEC CO, P791; HOROWITZ SL, 1975, COMMUN ACM, V18, P281, DOI 10.1145/360762.360810; JORDAN JR, 1981, IEE PROC-E, V128, P74, DOI 10.1049/ip-e.1981.0014; KELLY MD, 1971, MACHINE INTELLIGENCE, P379; MILGRAM DL, 1978, ADA057191 DEF TECH I; Minsky M., 1963, COMPUT THOUGHT, P406; Newell A., 1959, IFIP C, V256, P64; Oppenheim A.V.., 1983, SIGNALS SYSTEMS; PRESTON K, 1979, P IEEE, V67, P826, DOI 10.1109/PROC.1979.11331; ROSENFELD A, 1977, IEEE T SYSTEMS M FEB, P104; SANKAR PV, 1979, IEEE T PATTERN ANAL, V1, P73, DOI 10.1109/TPAMI.1979.4766877; TANIMOTO SL, 1978, COMPUTER VISION SYST, P165; TUKEY JW, 1977, EXPLORATORY DATA ANA, P555; 1982, 16 BIT MICROPROCESSO	22	37	37	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	3					280	288		10.1109/TPAMI.1984.4767520	http://dx.doi.org/10.1109/TPAMI.1984.4767520			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SR542	21869194				2022-12-18	WOS:A1984SR54200003
J	MILLER, PL				MILLER, PL			ATTENDING - CRITIQUING A PHYSICIANS MANAGEMENT PLAN	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											MILLER, PL (corresponding author), YALE UNIV,SCH MED,DEPT ANESTHESIOL,NEW HAVEN,CT 06510, USA.							APPELT D, 1982, THESIS STANFORD U ST; Fagan L. M., 1980, THESIS STANFORD U; FAGAN LM, 1979, 6TH P INT JOINT C AR, P260; GORRY GA, 1978, AM J MED, V64, P452, DOI 10.1016/0002-9343(78)90232-2; KULIKOWSKI CA, 1980, IEEE T PATTERN ANAL, V2, P464, DOI 10.1109/TPAMI.1980.6592368; MCDONALD DD, 1980, THESIS MASSACHUSETTS; MCKEOWN KR, 1982, THESIS U PENNSYLVANI; MILLER ML, 1977, 5TH P INT JOINT C AR, P773; MILLER PL, 1974, COMMUN ACM, V17, P621, DOI 10.1145/361179.361198; PAUKER SG, 1976, AM J MED, V60, P981, DOI 10.1016/0002-9343(76)90570-2; Pople H. E., 1975, 4TH P INT JOINT C AR, P848; RICH C, 1979, 6TH P IJCAI TOK; Sacerdoti E.D., 1977, STRUCTURE PLANS BEHA; Shortliffe E.H., 2012, COMPUTER BASED MED C; SHORTLIFFE EH, 1979, P IEEE, V67, P1207, DOI 10.1109/PROC.1979.11436; SILVERMAN H, 1975, MIT MACTR143 REP; STEFIK M, 1981, ARTIF INTELL, V16, P111, DOI 10.1016/0004-3702(81)90007-2; Sussman G.J., 1975, COMPUTER MODEL SKILL; SWARTOUT W, 1982, P AAAI NATL C, P404; SZOLOVITS P, 1978, ARTIF INTELL, V11, P115, DOI 10.1016/0004-3702(78)90014-0; Weinstein MC, 1980, CLIN DECISION ANAL; WEISS SM, 1978, ARTIF INTELL, V11, P145, DOI 10.1016/0004-3702(78)90015-2; WEISS SM, 1979, 6TH P INT JOINT C AR, P942; WOODS WA, 1970, COMMUN ACM, V13, P591, DOI 10.1145/355598.362773; [No title captured]	25	37	37	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	5					449	461		10.1109/TPAMI.1983.4767424	http://dx.doi.org/10.1109/TPAMI.1983.4767424			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RM118	21869130				2022-12-18	WOS:A1983RM11800001
J	KIM, CE				KIM, CE			ON THE CELLULAR CONVEXITY OF COMPLEXES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											KIM, CE (corresponding author), UNIV MARYLAND,DEPT COMP SCI,COLLEGE PK,MD 20742, USA.							FAM AT, 1975, THESIS U CALIFORNIA; FEDER J, 1968, INFORM CONTROL, V13, P230, DOI 10.1016/S0019-9958(68)91105-4; Graham R. L., 1972, Information Processing Letters, V1, P132, DOI 10.1016/0020-0190(72)90045-2; HODES L, 1970, SIAM J APPL MATH, V19, P477, DOI 10.1137/0119048; MINSKY M, 1968, PERCEPTIONS; MONTANARI U, 1970, J ASS COMPUT MACH, V17, P348; ROSENFELD A, 1970, J ACM, V17, P146, DOI 10.1145/321556.321570; SKLANSKY J, 1970, PATTERN RECOGN, V2, P3, DOI 10.1016/0031-3203(70)90037-3; SKLANSKY J, 1972, IEEE T COMPUT, VC 21, P260, DOI 10.1109/TC.1972.5008948; SKLANSKY J, 1976, IEEE T SYST MAN CYB, V6, P637, DOI 10.1109/TSMC.1976.4309569; UNGER SH, 1959, P IRE, V47, P1737, DOI 10.1109/JRPROC.1959.287109	11	37	37	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	6					617	625		10.1109/TPAMI.1981.4767162	http://dx.doi.org/10.1109/TPAMI.1981.4767162			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MR996	21868981				2022-12-18	WOS:A1981MR99600001
J	VOGEL, MA; WONG, AKC				VOGEL, MA; WONG, AKC			PFS CLUSTERING METHOD	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV WATERLOO,DEPT SYST DESIGN,WATERLOO N2L 3G1,ONTARIO,CANADA	University of Waterloo	VOGEL, MA (corresponding author), ANAL SCI CORP,READING,MA 01867, USA.							[Anonymous], 1965, ISODATA NOVEL METHOD; BAILEY DE, 1970, CLUSTER ANAL; BALL GH, 1965, AFIPS P, V27, P533; Beale EML, 1969, B ISI, V43, P92; BROWNLEE KA, 1965, STATISTICAL THEORY M; CORMACK RM, 1971, J R STAT SOC SER A-G, V134, P321, DOI 10.2307/2344237; Duda R.O., 1972, PATTERN CLASSIFICATI; FORGY EW, 1965, BIOMETRICS, V21, P768; FRIEDMAN HP, 1967, J AM STAT ASSOC, V62, P1152; FROM KR, 1976, PATTERN RECOGNITION, V8, P107; MacQueen J., 1967, 5 BERK S MATH STAT P, P281; MARONNA R, 1974, BIOMETRICS, V30, P499, DOI 10.2307/2529203; MARRIOTT FH, 1971, BIOMETRICS, V27, P501, DOI 10.2307/2528592; MULAIK SA, 1972, F FACTOR ANAL; Tatsuoka, 1971, MULTIVARIATE ANAL; WARD JH, 1963, EDUC PSYCHOL MEAS, V23, P69, DOI 10.1177/001316446302300107; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; WILKS SS, 1932, BIOMETRIKA, V24, P271; WISHART D, 1969, BIOMETRICS, V25, P165, DOI 10.2307/2528688; WONG AKC, 1975, IEEE T COMPUT, VC 24, P158, DOI 10.1109/T-C.1975.224183; WONG AKC, 1975, 1975 P INT C CYB SOC, P189; WONG AKC, 1975, UNSUPERVISED CLASSIF; YOUNG TY, 1970, CLASSIFICATION ESTIM	23	37	53	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	3					237	245		10.1109/TPAMI.1979.4766919	http://dx.doi.org/10.1109/TPAMI.1979.4766919			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	HC301	21868854				2022-12-18	WOS:A1979HC30100001
J	Bianchi, FM; Grattarola, D; Livi, L; Alippi, C				Bianchi, Filippo Maria; Grattarola, Daniele; Livi, Lorenzo; Alippi, Cesare			Graph Neural Networks With Convolutional ARMA Filters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolution; Laplace equations; Task analysis; Graph neural networks; Chebyshev approximation; Frequency response; Eigenvalues and eigenfunctions; Geometric deep learning; graph filters; graph neural networks; graph theory; graph signal processing		Popular graph neural networks implement convolution operations on graphs based on polynomial spectral filters. In this paper, we propose a novel graph convolutional layer inspired by the auto-regressive moving average (ARMA) filter that, compared to polynomial ones, provides a more flexible frequency response, is more robust to noise, and better captures the global graph structure. We propose a graph neural network implementation of the ARMA filter with a recursive and distributed formulation, obtaining a convolutional layer that is efficient to train, localized in the node space, and can be transferred to new graphs at test time. We perform a spectral analysis to study the filtering effect of the proposed ARMA layer and report experiments on four downstream tasks: semi-supervised node classification, graph signal classification, graph classification, and graph regression. Results show that the proposed ARMA layer brings significant improvements over graph neural networks based on polynomial filters.	[Bianchi, Filippo Maria] UiT Arctic Univ Norway, Dept Math & Stat, N-9019 Tromso, Norway; [Bianchi, Filippo Maria] NORCE Norwegian Res Ctr, N-5008 Bergen, Norway; [Grattarola, Daniele; Alippi, Cesare] Univ Svizzera Italiana, Fac Informat, CH-6900 Lugano, Switzerland; [Livi, Lorenzo] Univ Manitoba, Dept Comp Sci & Math, Winnipeg, MB R3T 2N2, Canada; [Livi, Lorenzo] Univ Exeter, Dept Comp Sci, Exeter EX4 4PY, Devon, England; [Alippi, Cesare] Politecn Milan, Dept Elect Informat & Bioengn, I-20133 Milan, Italy	UiT The Arctic University of Tromso; Norwegian Research Centre (NORCE); Universita della Svizzera Italiana; University of Manitoba; University of Exeter; Polytechnic University of Milan	Bianchi, FM (corresponding author), UiT Arctic Univ Norway, Dept Math & Stat, N-9019 Tromso, Norway.	filippo.m.bianchi@uit.no; daniele.grattarola@usi.ch; L.Livi@exeter.ac.uk; cesare.alippi@polimi.it			Swiss National Science Foundation [200021/172671]; NVIDIA Corporation; Canada Research Chairs program	Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission); NVIDIA Corporation; Canada Research Chairs program(Canada Research Chairs)	The work of Daniele Grattarola was supported by the Swiss National Science Foundation's Grant 200021/172671. The authors gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Xp GPU used for this research. The work of Lorenzo Livi was supported by the Canada Research Chairs program. The authors would also like to thank the anonymous reviewers for their precious suggestions, which helped us to improve ourwork.	Bacciu D, 2018, PR MACH LEARN RES, V80; Battaglia Peter W, 2018, ARXIV180601261; Bianchi F.M., 2018, SPRINGER INT PUBLISH, P1, DOI [10.1007/978-3-319-70338-1, DOI 10.1007/978-3-319-70338-1]; Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418; Bruna J., 2014, C TRACK P; Defferrard M., 2016, P ADV NEURAL INFORM, P3844; Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI [10.1109/TPAMI.2007.1115, 10.1109/TP'AMI.2007.1115]; Duvenaud David K, 2015, P NIPS; Fey M., 2019, ICLR WORKSH REPR LEA; Gallicchio C, 2020, AAAI CONF ARTIF INTE, V34, P3898; Gallicchio C, 2010, IEEE IJCNN; Gama F, 2019, ADV NEUR IN, V32; Gao F, 2019, PR MACH LEARN RES, V97; GOEBEL K, 1972, P AM MATH SOC, V35, P171, DOI 10.2307/2038462; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Grattarola D, 2021, IEEE COMPUT INTELL M, V16, P99, DOI 10.1109/MCI.2020.3039072; Grattarola D, 2020, IEEE T NEUR NET LEAR, V31, P1856, DOI 10.1109/TNNLS.2019.2927301; Hamilton W., 2017, P ADV NEUR INF PROC, P1024; Henaff M, 2015, ARXIV150605163; Holme P, 2015, EUR PHYS J B, V88, DOI 10.1140/epjb/e2015-60657-4; Ioannidis V. N, 2020, PROC INT C LEARN REP; Isufi E., 2019, PROC IEEE 13 INT C S, P1; Isufi E, 2017, IEEE T SIGNAL PROCES, V65, P274, DOI 10.1109/TSP.2016.2614793; Kipf T. N., 2016, PROC NIPS WORKSHOP B; Kipf Thomas N, 2016, 5 INT C LEARN REPR I; Klicpera Johannes, 2019, INT C LEARN REPR ICL; Levie R, 2019, IEEE T SIGNAL PROCES, V67, P97, DOI 10.1109/TSP.2018.2879624; Li QM, 2018, AAAI CONF ARTIF INTE, P3538; Liao R., P ICLR, V1901, P1; Loukas A, 2015, IEEE SIGNAL PROC LET, V22, P1931, DOI 10.1109/LSP.2015.2448655; Lukosevicius M, 2009, COMPUT SCI REV, V3, P127, DOI 10.1016/j.cosrev.2009.03.005; Mikolov T., 2013, ARXIV; Narang SK, 2013, INT CONF ACOUST SPEE, P5445, DOI 10.1109/ICASSP.2013.6638704; Nt H, 2019, ARXIV 190509550; Oppenheim A.V., 1989, DISCRETE TIME SIGNAL; Page L, 1999, PAG ERANK CITATION R; Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732; Raghu M, 2017, PR MACH LEARN RES, V70; Ramakrishnan R, 2014, SCI DATA, V1, DOI 10.1038/sdata.2014.22; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605; Shuman DI, 2011 INT C DISTR COM, P1, DOI DOI 10.1109/DCOSS.2011.5982158; Susnjara A., 2015, ARXIV150904537; Pham T, 2017, AAAI CONF ARTIF INTE, P2485; Tremblay N, 2018, COOPERATIVE AND GRAPH SIGNAL PROCESSING: PRINCIPLES AND APPLICATIONS, P299, DOI 10.1016/B978-0-12-813677-5.00011-0; Velickovic P, 2018, ARXIV 171010903; Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918; Wu F, 2019, PR MACH LEARN RES, V97; Wu Yonghui, 2016, GOOGLES NEURAL MACHI; Xu K, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8350934; Xu KYL, 2018, PR MACH LEARN RES, V80; Yang Z, 2016, PR MACH LEARN RES, V48; Zhang MH, 2018, AAAI CONF ARTIF INTE, P4438; Zhou DY, 2004, ADV NEUR IN, V16, P321; Zou DM, 2020, APPL COMPUT HARMON A, V49, P1046, DOI 10.1016/j.acha.2019.06.003	55	36	36	45	55	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2022	44	7					3496	3507		10.1109/TPAMI.2021.3054830	http://dx.doi.org/10.1109/TPAMI.2021.3054830			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1V0WH	33497331	Green Submitted			2022-12-18	WOS:000805820500013
J	Tian, ZT; Zhao, HS; Shu, M; Yang, ZC; Li, RY; Jia, JY				Tian, Zhuotao; Zhao, Hengshuang; Shu, Michelle; Yang, Zhicheng; Li, Ruiyu; Jia, Jiaya			Prior Guided Feature Enrichment Network for Few-Shot Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Few-shot segmentation; few-shot learning; semantic segmentation; scene understanding		State-of-the-art semantic segmentation methods require sufficient labeled data to achieve good results and hardly work on unseen classes without fine-tuning. Few-shot segmentation is thus proposed to tackle this problem by learning a model that quickly adapts to new classes with a few labeled support samples. Theses frameworks still face the challenge of generalization ability reduction on unseen classes due to inappropriate use of high-level semantic information of training classes and spatial inconsistency between query and support targets. To alleviate these issues, we propose the Prior Guided Feature Enrichment Network (PFENet). It consists of novel designs of (1) a training-free prior mask generation method that not only retains generalization power but also improves model performance and (2) Feature Enrichment Module (FEM) that overcomes spatial inconsistency by adaptively enriching query features with support features and prior masks. Extensive experiments on PASCAL-5(i) and COCO prove that the proposed prior generation method and FEM both improve the baseline method significantly. Our PFENet also outperforms state-of-the-art methods by a large margin without efficiency loss. It is surprising that our model even generalizes to cases without labeled support samples.	[Tian, Zhuotao; Zhao, Hengshuang; Jia, Jiaya] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Peoples R China; [Shu, Michelle] Johns Hopkins Univ, Baltimore, MD 21218 USA; [Yang, Zhicheng; Li, Ruiyu] SmartMore, Shenzhen 518057, Guangdong, Peoples R China	Chinese University of Hong Kong; Johns Hopkins University	Zhao, HS (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Peoples R China.	tianzhuotao@gmail.com; hengshuangzhao@gmail.com; mshu1@jhu.edu; cosnozc@gmail.com; royliruiyu@gmail.com; leojia@cse.cuhk.edu.hk						Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Berg A.C., 2015, ARXIV150604579; Cai Q, 2018, PROC CVPR IEEE, P4080, DOI 10.1109/CVPR.2018.00429; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709; Dong Nanqing, 2018, BMVC; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Finn C, 2017, PR MACH LEARN RES, V70; Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326; Ghiasi G, 2016, LECT NOTES COMPUT SC, V9907, P519, DOI 10.1007/978-3-319-46487-9_32; Gidaris S, 2018, PROC CVPR IEEE, P4367, DOI 10.1109/CVPR.2018.00459; Hariharan B, 2017, IEEE I CONF COMP VIS, P3037, DOI 10.1109/ICCV.2017.328; Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu T, 2019, AAAI CONF ARTIF INTE, P8441; Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069; Kato N, 2019, IEEE INT CONF COMP V, P1363, DOI 10.1109/ICCVW.2019.00172; Nguyen K, 2019, IEEE I CONF COMP VIS, P622, DOI 10.1109/ICCV.2019.00071; Krahenbuhl P., 2011, ADV NEURAL INF PROCE, V24, P109; Li X, 2020, PROC CVPR IEEE, P2866, DOI 10.1109/CVPR42600.2020.00294; Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162; Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P52; Mikolov Tomas., 2013, ADV NEURAL INF PROCE, V2, P3111, DOI DOI 10.5555/2999792.2999959; Rakelly Kate, 2018, FEW SHOT SEGMENTATIO; Rakelly Kate, 2018, ICLR WORKSH; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Shaban Amirreza, 2017, ARXIV170903410, DOI 10.5244/C.31.167; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Siam M, 2019, IEEE I CONF COMP VIS, P5248, DOI 10.1109/ICCV.2019.00535; Snell J., 2017, ADV NEURAL INFORM PR, P4077; Sun K., 2020, ARXIV PREPRINT ARXIV; Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584; Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vinyals O., 2016, P 30 INT C NEUR INF, P3637, DOI 10.5555/3157382.3157504; Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686; Wang KX, 2019, IEEE I CONF COMP VIS, P9196, DOI 10.1109/ICCV.2019.00929; Wang XL, 2018, PROC CVPR IEEE, P6857, DOI 10.1109/CVPR.2018.00717; Wang YX, 2018, PROC CVPR IEEE, P7278, DOI 10.1109/CVPR.2018.00760; Yu F., 2016, P ICLR 2016; Yuan Y., 2018, ARXIV180900916; Zhang C, 2019, IEEE I CONF COMP VIS, P9586, DOI 10.1109/ICCV.2019.00968; Zhang C, 2019, PROC CVPR IEEE, P5212, DOI 10.1109/CVPR.2019.00536; Zhang H, 2019, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2019.00064; Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747; Zhang HG, 2019, PROC CVPR IEEE, P2765, DOI 10.1109/CVPR.2019.00288; Zhang Xiaolin, 2018, ARXIV181009091; Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17; Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179	54	36	36	24	54	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					1050	1065		10.1109/TPAMI.2020.3013717	http://dx.doi.org/10.1109/TPAMI.2020.3013717			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS	32750843	Green Submitted			2022-12-18	WOS:000740006100036
J	Huang, SJ; Gao, W; Zhou, ZH				Huang, Sheng-Jun; Gao, Wei; Zhou, Zhi-Hua			Fast Multi-Instance Multi-Label Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-instance multi-label learning; fast; key instance; sub-concepts	RECOGNITION; NETWORKS	In many real-world tasks, particularly those involving data objects with complicated semantics such as images and texts, one object can be represented by multiple instances and simultaneously be associated with multiple labels. Such tasks can be formulated as multi-instance multi-label learning (MIML) problems, and have been extensively studied during the past few years. Existing MIML approaches have been found useful in many applications; however, most of them can only handle moderate-sized data. To efficiently handle large data sets, in this paper we propose the MIMLfast approach, which first constructs a low-dimensional subspace shared by all labels, and then trains label specific linear models to optimize approximated ranking loss via stochastic gradient descent. Although the MIML problem is complicated, MIMLfast is able to achieve excellent performance by exploiting label relations with shared space and discovering sub-concepts for complicated labels. Experiments show that the performance of MIMLfast is highly competitive to state-of-the-art techniques, whereas its time cost is much less. Moreover, our approach is able to identify the most representative instance for each label, and thus providing a chance to understand the relation between input patterns and output label semantics.	[Huang, Sheng-Jun; Gao, Wei; Zhou, Zhi-Hua] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China; [Huang, Sheng-Jun] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Jiangsu, Peoples R China	Nanjing University; Nanjing University of Aeronautics & Astronautics	Zhou, ZH (corresponding author), Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.	huangsj@nuaa.edu.cn; gaow@lamda.nju.edu.cn; zhouzh@lamda.nju.edu.cn			National Key R&D Program of China [2018YFB1004300]; NSFC [61751306, 61503182, 61503179]; Jiangsu SF [BK20150754, BK20150586]; Collaborative Innovation Center of Novel Software Technology and Industrialization	National Key R&D Program of China; NSFC(National Natural Science Foundation of China (NSFC)); Jiangsu SF; Collaborative Innovation Center of Novel Software Technology and Industrialization	The authors would like to thank the associate editor and reviewers for helpful comments and suggestions. This research was partially supported by National Key R&D Program of China (2018YFB1004300), NSFC (61751306, 61503182, 61503179), Jiangsu SF (BK20150754, BK20150586) and Collaborative Innovation Center of Novel Software Technology and Industrialization.	Aggarwal A, 2017, AAAI CONF ARTIF INTE, P1698; Andrews S., 2002, NIPS, V2, P561; Ben-David S., 2012, INT C MACH LEARN INT C MACH LEARN, P83; Bi W., 2011, P 28 INT C MACH LEAR, P17; Blockeel H., 2005, P 22 INT C MACH LEAR, P57, DOI DOI 10.1145/1102351.1102359; Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16; Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009; Briggs F., 2012, P 18 ACM SIGKDD INT, P534, DOI DOI 10.1145/2339530.2339616; Nguyen CT, 2014, AAAI CONF ARTIF INTE, P2013; Clare A., 2001, EUR C PRINC DAT MIN, V2168, P42; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97; Feng J, 2017, AAAI CONF ARTIF INTE, P1884; FREY PW, 1991, MACH LEARN, V6, P161, DOI 10.1023/A:1022606404104; Furnkranz J, 2008, MACH LEARN, V73, P133, DOI 10.1007/s10994-008-5064-8; Grtner T., 2002, P 19 INT C MACH LEAR, P179; Huang S., 2012, KDD, P525, DOI DOI 10.1145/2339530.2339615; Huang Sheng Jun, 2012, P 26 AAAI C ART INT, P949; Huang SJ, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1886; Huang SJ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P946; Huang SJ, 2014, AAAI CONF ARTIF INTE, P1868; Kwok JT, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P901; Li H, 2009, INT CONF DAT MIN WOR, P164, DOI 10.1109/ICDMW.2009.46; Li YX, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1445; Li YF, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P104, DOI 10.1109/CISP.2012.6469882; Ma LR, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-016-9020-4; Maron O., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P341; Nam Jinseok, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8725, P437, DOI 10.1007/978-3-662-44851-9_28; Nam Nguyen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P384, DOI 10.1109/ICDM.2010.109; Pei YL, 2014, PATTERN RECOGN LETT, V37, P107, DOI 10.1016/j.patrec.2013.07.002; Pham AT, 2017, IEEE T PATTERN ANAL, V39, P2381, DOI 10.1109/TPAMI.2017.2647944; Pham AT, 2015, PR MACH LEARN RES, V37, P2427; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Tsoumakas G, 2011, IEEE T KNOWL DATA EN, V23, P1079, DOI 10.1109/TKDE.2010.164; Usunier Nicolas, 2009, ICML; Wang Jun, 2000, ICML, P1119; Weston Jason, 2011, 22 INT JOINT C ART I; Winn J, 2005, IEEE I CONF COMP VIS, P1800; Xie M.-K., 2018, P 32 AAAI C ART INT, P946; Yang H, 2017, PROC CVPR IEEE, P5996, DOI 10.1109/CVPR.2017.635; Yang S. H., 2009, ADV NEURAL INFORM PR, P2143; Yuan HN, 2013, IEEE T KNOWL DATA EN, V25, P2900, DOI 10.1109/TKDE.2012.245; Zha XY, 2008, IEEE SYMP COMP COMMU, P1, DOI 10.1109/WiCom.2008.2129; Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019; Zhang ML, 2018, FRONT COMPUT SCI-CHI, V12, P191, DOI 10.1007/s11704-017-7031-7; Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39; Zhang ML, 2010, PROC INT C TOOLS ART, P207, DOI 10.1109/ICTAI.2010.102; Zhang ML, 2009, NEUROCOMPUTING, V72, P3951, DOI 10.1016/j.neucom.2009.07.008; Zhang Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1839490.1839495; Zhou Z.H., 2007, NIPS 19, P1609, DOI DOI 10.1016/J.PATCOG.2006.12.019; Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106; Zhou ZH, 2012, ARTIF INTELL, V176, P2291, DOI 10.1016/j.artint.2011.10.002; Zhu Y, 2017, AAAI CONF ARTIF INTE, P2977	56	36	38	2	44	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2019	41	11					2614	2627		10.1109/TPAMI.2018.2861732	http://dx.doi.org/10.1109/TPAMI.2018.2861732			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD2XM	30072313	Green Submitted			2022-12-18	WOS:000489838200006
J	Cakir, F; He, K; Bargal, SA; Sclaroff, S				Cakir, Fatih; He, Kun; Bargal, Sarah Adel; Sclaroff, Stan			Hashing with Mutual Information	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hashing; deep learning; nearest neighbor retrieval; mutual information	BINARY-CODES; QUANTIZATION	Binary vector embeddings enable fast nearest neighbor retrieval in large databases of high-dimensional objects, and play an important role in many practical applications, such as image and video retrieval. We study the problem of learning binary vector embeddings under a supervised setting, also known as hashing. We propose a novel supervised hashing method based on optimizing an information-theoretic quantity, mutual information. We show that optimizing mutual information can reduce ambiguity in the induced neighborhood structure in the learned Hamming space, which is essential in obtaining high retrieval performance. To this end, we optimize mutual information in deep neural networks with minibatch stochastic gradient descent, with a formulation that maximally and efficiently utilizes available supervision. Experiments on four image retrieval benchmarks, including ImageNet, confirm the effectiveness of our method in learning high-quality binary embeddings for nearest neighbor retrieval.	[Cakir, Fatih] FirstFuel Software, Lexington, MA 02420 USA; [He, Kun] Facebook Real Labs, Redmond, WA 98052 USA; [Bargal, Sarah Adel; Sclaroff, Stan] Boston Univ, Dept Comp Sci, 111 Cummington St, Boston, MA 02215 USA	Facebook Inc; Boston University	Cakir, F (corresponding author), FirstFuel Software, Lexington, MA 02420 USA.; He, K (corresponding author), Facebook Real Labs, Redmond, WA 98052 USA.	fcakirs@gmail.com; kun.he@oculus.com; sbargal@bu.edu; sclaroff@bu.edu		Bargal, Sarah/0000-0003-3157-0412; He, Kun/0000-0002-0828-0794; Sclaroff, Stanley/0000-0002-0711-4313	BU IGNITION award; US NSF [1029430]	BU IGNITION award; US NSF(National Science Foundation (NSF))	This research was supported in part by a BU IGNITION award, US NSF grant 1029430, and gifts from NVIDIA. (Fatih Cakir and Kun He contributed equally to this work.)	Andoni A, 2015, ACM S THEORY COMPUT, P793, DOI 10.1145/2746539.2746553; Cakir F, 2017, IEEE I CONF COMP VIS, P437, DOI 10.1109/ICCV.2017.55; Cakir F, 2015, IEEE I CONF COMP VIS, P1044, DOI 10.1109/ICCV.2015.125; Cao ZJ, 2017, IEEE I CONF COMP VIS, P5609, DOI 10.1109/ICCV.2017.598; Carreira-Perpinan MA, 2015, PROC CVPR IEEE, P557, DOI 10.1109/CVPR.2015.7298654; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Cheng J, 2014, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2014.8; Chua Tat-Seng, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646452; Dai B, 2017, PR MACH LEARN RES, V70; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dean T, 2013, PROC CVPR IEEE, P1814, DOI 10.1109/CVPR.2013.237; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Ding K, 2015, IEEE I CONF COMP VIS, P1098, DOI 10.1109/ICCV.2015.131; Gao LL, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P903, DOI 10.1145/2733373.2806360; Ge TZ, 2014, LECT NOTES COMPUT SC, V8695, P250, DOI 10.1007/978-3-319-10584-0_17; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Gong YC, 2015, PROC CVPR IEEE, P19, DOI 10.1109/CVPR.2015.7298596; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; Han J., 2010, ENCY MACHINE LEARNIN; Haveliwala T. H., 2000, P WEBDB WORKSH; He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Krizhevsky A., 2007, TECH REP, V1, P7; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466; Kulis Brian, 2009, ADV NEURAL INFORM PR, P1042; Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947; Li W., 2016, INT JOINT C ARTIFICI, P1711; Li X, 2013, PROC CVPR IEEE, P2419, DOI 10.1109/CVPR.2013.313; Lin GS, 2017, INT J COMPUT VISION, V123, P287, DOI 10.1007/s11263-016-0984-4; Lin GS, 2014, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2014.253; Lin GS, 2013, IEEE I CONF COMP VIS, P2552, DOI 10.1109/ICCV.2013.317; Lin K, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301269; Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1017/S1368980013002176, 10.1109/PLASMA.2013.6634954]; Lin RS, 2010, PROC CVPR IEEE, P848, DOI 10.1109/CVPR.2010.5540129; Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862; Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227; Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912; Liu X, 2014, PROC CVPR IEEE, P57, DOI 10.1109/CVPR.2014.15; Norouzi M., 2011, INT C MACHINE LEARNI, P353; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887; Shen FM, 2017, IEEE T MULTIMEDIA, V19, P2022, DOI 10.1109/TMM.2017.2699863; Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598; Song JK, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P827, DOI 10.1145/2733373.2806341; Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Do TT, 2016, LECT NOTES COMPUT SC, V9909, P219, DOI 10.1007/978-3-319-46454-1_14; Triantafillou E, 2017, ADV NEUR IN, V30; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Ustinova E., 2016, ADV NEURAL INFORM PR, V29, P4170; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572; Wang Avery, 2003, ISMIR, P7; Wang J., 2010, ICML, P1127; Wang J, 2017, IEEE INFOCOM SER, DOI 10.1007/s12083-017-0556-6; Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48; Wang QF, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3911; Wang QF, 2014, LECT NOTES COMPUT SC, V8690, P425, DOI 10.1007/978-3-319-10605-2_28; Wang X., 2016, P AS C COMP VIS, P70; Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824; Xia RK, 2014, AAAI CONF ARTIF INTE, P2156; Yisong Yue, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P271; Zhang D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P18; Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315; Zhang ZM, 2016, PROC CVPR IEEE, P1487, DOI 10.1109/CVPR.2016.165; Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763; Zhu H, 2016, AAAI CONF ARTIF INTE, P2415; Zhuang BH, 2016, PROC CVPR IEEE, P5955, DOI 10.1109/CVPR.2016.641	71	36	37	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2019	41	10					2424	2437		10.1109/TPAMI.2019.2914897	http://dx.doi.org/10.1109/TPAMI.2019.2914897			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD1VC	31059428	Green Submitted			2022-12-18	WOS:000489763000011
J	Pan, JS; Ren, WQ; Hu, Z; Yang, MH				Pan, Jinshan; Ren, Wenqi; Hu, Zhe; Yang, Ming-Hsuan			Learning to Deblur Images with Exemplars	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image deblurring; face image; exemplar-based; edge prediction; deep edge	KERNEL ESTIMATION	Human faces are one interesting object class with numerous applications. While significant progress has been made in the generic deblurring problem, existing methods are less effective for blurry face images. The success of the state-of-the-art image deblurring algorithms stems mainly from implicit or explicit restoration of salient edges for kernel estimation. However, existing methods are less effective as only few edges can be restored from blurry face images for kernel estimation. In this paper, we address the problem of deblurring face images by exploiting facial structures. We propose a deblurring algorithm based on an exemplar dataset without using coarse-to-fine strategies or heuristic edge selections. In addition, we develop a convolutional neural network to restore sharp edges from blurry images for deblurring. Extensive experiments against the state-of-the-art methods demonstrate the effectiveness of the proposed algorithm for deblurring face images. In addition, we show that the proposed algorithms can be applied to image deblurring for other object classes.	[Pan, Jinshan] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China; [Ren, Wenqi] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China; [Hu, Zhe] Hikvis Res Amer, Santa Clara, CA 95054 USA; [Yang, Ming-Hsuan] Univ Calif Merced, Sch Engn, Merced, CA 95344 USA	Nanjing University of Science & Technology; Chinese Academy of Sciences; Institute of Information Engineering, CAS; University of California System; University of California Merced	Yang, MH (corresponding author), Univ Calif Merced, Sch Engn, Merced, CA 95344 USA.	sdluran@gmail.com; rwq.renwenqi@gmail.com; zhe.hu.66@gmail.com; mhyang@ucmerced.edu	Yang, Ming-Hsuan/AAE-7350-2019; Pan, Jinshan/AAO-2258-2021; Yang, Ming-Hsuan/T-9533-2019; Hu, Zhe/AAE-7207-2021	Yang, Ming-Hsuan/0000-0003-4848-2304; 	National Science Foundation CAREER [1149783]; National Key Research and Development Program [2016YFB1001001]; NSFC [61522203, 61732007, 61772275]; National Ten Thousand Talent Program of China (Young Top-Notch Talent)	National Science Foundation CAREER(National Science Foundation (NSF)); National Key Research and Development Program; NSFC(National Natural Science Foundation of China (NSFC)); National Ten Thousand Talent Program of China (Young Top-Notch Talent)	This work is supported in part by National Science Foundation CAREER Grant 1149783, National Key Research and Development Program (No. 2016YFB1001001), NSFC (No. 61522203, 61732007 and 61772275), National Ten Thousand Talent Program of China (Young Top-Notch Talent). Jinshan Pan, Wenqi Ren, and Zhe Hu contributed equally to this work.	Anwar S, 2015, IEEE I CONF COMP VIS, P495, DOI 10.1109/ICCV.2015.64; Cai JF, 2012, IEEE T IMAGE PROCESS, V21, P562, DOI 10.1109/TIP.2011.2164413; Cao XC, 2015, IEEE T IMAGE PROCESS, V24, P1302, DOI 10.1109/TIP.2015.2400217; Cho HJ, 2012, LECT NOTES COMPUT SC, V7576, P524, DOI 10.1007/978-3-642-33715-4_38; Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491; Cho TS, 2011, PROC CVPR IEEE, P241, DOI 10.1109/CVPR.2011.5995479; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; Goldstein A, 2012, LECT NOTES COMPUT SC, V7576, P622, DOI 10.1007/978-3-642-33715-4_45; Gross R., 2008, P IEEE INT C AUT FAC, P1; HaCohen Y, 2013, IEEE I CONF COMP VIS, P2384, DOI 10.1109/ICCV.2013.296; He KM, 2010, LECT NOTES COMPUT SC, V6311, P1; He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]; Hu Z, 2014, PROC CVPR IEEE, P3382, DOI 10.1109/CVPR.2014.432; Hu Z, 2012, LECT NOTES COMPUT SC, V7576, P59, DOI 10.1007/978-3-642-33715-4_5; Joshi N, 2008, PROC CVPR IEEE, P3823; Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521; Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; Michaeli T, 2014, LECT NOTES COMPUT SC, V8691, P783, DOI 10.1007/978-3-319-10578-9_51; Nair V, 2010, P 27 INT C MACHINE L, P807; Nishiyama M, 2011, IEEE T PATTERN ANAL, V33, P838, DOI 10.1109/TPAMI.2010.203; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180; Pan JS, 2014, PROC CVPR IEEE, P2901, DOI 10.1109/CVPR.2014.371; Ren JS., 2015, ADV NEURAL INF PROCE, V1, P901; Schmidt U, 2013, PROC CVPR IEEE, P604, DOI 10.1109/CVPR.2013.84; Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418; Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672; Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677; Sun LX, 2013, PART FIBRE TOXICOL, V10, DOI 10.1186/1743-8977-10-43; Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50; Xu L., 2014, INT C NEUR INF PROC, V27, P1790; Xu L, 2015, PR MACH LEARN RES, V37, P1669; Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147; Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208; Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157; Yitzhaky Y, 1998, J OPT SOC AM A, V15, P1512, DOI 10.1364/JOSAA.15.001512; Zhang HC, 2011, IEEE I CONF COMP VIS, P770, DOI 10.1109/ICCV.2011.6126315; Zhong L, 2013, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2013.85; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014; Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278	44	36	38	3	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2019	41	6					1412	1425		10.1109/TPAMI.2018.2832125	http://dx.doi.org/10.1109/TPAMI.2018.2832125			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HW9UU	29994046	Green Submitted			2022-12-18	WOS:000467037000010
J	Zhou, WG; Li, HQ; Sun, J; Tian, Q				Zhou, Wengang; Li, Houqiang; Sun, Jian; Tian, Qi			Collaborative Index Embedding for Image Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image retrieval; inverted index; index embedding; SIFT; CNN feature	OBJECT RETRIEVAL; QUANTIZATION; CODEBOOK; FEATURES; SEARCH	In content-based image retrieval, SIFT feature and the feature from deep convolutional neural network (CNN) have demonstrated promising performance. To fully explore both visual features in a unified framework for effective and efficient retrieval, we propose a collaborative index embedding method to implicitly integrate the index matrices of them. We formulate the index embedding as an optimization problem from the perspective of neighborhood sharing and solve it with an alternating index update scheme. After the iterative embedding, only the embedded CNN index is kept for on-line query, which demonstrates significant gain in retrieval accuracy, with very economical memory cost. Extensive experiments have been conducted on the public datasets with million-scale distractor images. The experimental results reveal that, compared with the recent state-of-the-art retrieval algorithms, our approach achieves competitive accuracy performance with less memory overhead and efficient query computation.	[Zhou, Wengang; Li, Houqiang] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei 230027, Anhui, Peoples R China; [Sun, Jian] Megvii Technol Inc, Beijing 100190, Peoples R China; [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA	Chinese Academy of Sciences; University of Science & Technology of China, CAS; University of Texas System; University of Texas at San Antonio (UTSA)	Zhou, WG (corresponding author), Univ Sci & Technol China, Dept Elect Engn & Informat Sci, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei 230027, Anhui, Peoples R China.	zhwg@ustc.edu.cn; lihq@ustc.edu.cn; sunjian@megvii.com; qitian@cs.utsa.edu			973 Program [2015CB351803]; NSFC [61325009, 61390514, 61472378, 61632019, 61429201]; Natural Science Foundation of Anhui Province [1508085MF109]; Fundamental Research Funds for the Central Universities; ARO [W911NF-15-1-0290]; NEC Laboratories of America; Blippar	973 Program(National Basic Research Program of China); NSFC(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Anhui Province(Natural Science Foundation of Anhui Province); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); ARO; NEC Laboratories of America; Blippar	This work was supported in part to Prof. Houqiang Li by 973 Program under contract No. 2015CB351803, NSFC under contract No. 61325009 and No. 61390514, in part to Dr. Wengang Zhou by NSFC under contract No. 61472378 and No. 61632019, the Natural Science Foundation of Anhui Province under contract No. 1508085MF109, and the Fundamental Research Funds for the Central Universities, and in part to Dr. Qi Tian by ARO grant W911NF-15-1-0290 and Faculty Research Gift Awards by NEC Laboratories of America and Blippar. This work was supported in part by NSFC under contract No. 61429201. Houqiang Li and Qi Tian are the corresponding authors.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2016, P ACM INT C MULT; [Anonymous], 2015, PROC CVPR IEEE; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Cao Y, 2011, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2011.5995460; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; He JF, 2012, PROC CVPR IEEE, P3005, DOI 10.1109/CVPR.2012.6248030; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024; Horster E., 2008, P 16 ACM INT C MULT, P643; Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jegou H, 2010, IEEE T PATTERN ANAL, V32, P2, DOI 10.1109/TPAMI.2008.285; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Li W, 2015, IEEE T MULTIMEDIA, V17, P967, DOI 10.1109/TMM.2015.2428996; Liu Z, 2016, IEEE T CIRC SYST VID, V26, P375, DOI 10.1109/TCSVT.2015.2409693; Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P2047, DOI 10.1109/TIP.2014.2312283; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Nister David, 2006, CVPR, P2161, DOI DOI 10.1109/CVPR.2006.264; Paulin M, 2015, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2015.19; Qin DF, 2011, PROC CVPR IEEE, P777, DOI 10.1109/CVPR.2011.5995373; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Shen XH, 2012, PROC CVPR IEEE, P3013, DOI 10.1109/CVPR.2012.6248031; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Sun S., 2015, ACM T MULTIM COMPUT, V12, P1; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948; Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244; Wu P., 2013, PROC 21 ACM INT C MU, P153, DOI [10.1145/2502081.2502112, DOI 10.1145/2502081.2502112]; Wu Z, 2009, PROC CVPR IEEE, P25, DOI 10.1109/CVPRW.2009.5206566; Xie LX, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P3, DOI 10.1145/2671188.2749289; Xie LX, 2015, IEEE T IMAGE PROCESS, V24, P4287, DOI 10.1109/TIP.2015.2432673; Yandex Artem Babenko, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1269, DOI 10.1109/ICCV.2015.150; Zhang L, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2490823; Zhang ST, 2015, IEEE T PATTERN ANAL, V37, P803, DOI 10.1109/TPAMI.2014.2346201; Zhang ST, 2012, LECT NOTES COMPUT SC, V7573, P660, DOI 10.1007/978-3-642-33709-3_47; Zhang SL, 2015, IEEE T PATTERN ANAL, V37, P2573, DOI 10.1109/TPAMI.2015.2417573; Zhang SL, 2015, IEEE T MULTIMEDIA, V17, P1969, DOI 10.1109/TMM.2015.2478055; Zhang SL, 2013, IEEE I CONF COMP VIS, P1673, DOI 10.1109/ICCV.2013.210; Zhang X, 2012, PROC CVPR IEEE, P2058, DOI 10.1109/CVPR.2012.6247910; Zhang X, 2009, IEEE I CONF COMP VIS, P1103, DOI 10.1109/ICCV.2009.5459354; Zheng L, 2016, INT J COMPUT VISION, V120, P1, DOI 10.1007/s11263-016-0889-2; Zheng L, 2014, PROC CVPR IEEE, P1947, DOI 10.1109/CVPR.2014.250; Zheng L, 2013, PROC CVPR IEEE, P1626, DOI 10.1109/CVPR.2013.213; Zhou W., 2010, P ACM INT C MULT, P511; Zhou WG, 2016, IEEE T PATTERN ANAL, V38, P159, DOI 10.1109/TPAMI.2015.2430329; Zhou WG, 2015, IEEE T IMAGE PROCESS, V24, P967, DOI 10.1109/TIP.2015.2389624; Zhou WG, 2014, IEEE T MULTIMEDIA, V16, P601, DOI 10.1109/TMM.2014.2301979	56	36	37	4	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2018	40	5					1154	1166		10.1109/TPAMI.2017.2676779	http://dx.doi.org/10.1109/TPAMI.2017.2676779			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GB2RB	28278457				2022-12-18	WOS:000428901200011
J	Tian, S; Yin, XC; Su, Y; Hao, HW				Tian, Shu; Yin, Xu-Cheng; Su, Ya; Hao, Hong-Wei			A Unified Framework for Tracking Based Text Detection and Recognition from Web Videos	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video text extraction; text tracking; tracking based text detection; tracking based text recognition; embedded captions	READING TEXT; IMAGES; SEGMENTATION; EXTRACTION	Video text extraction plays an important role for multimedia understanding and retrieval. Most previous research efforts are conducted within individual frames. A few of recent methods, which pay attention to text tracking using multiple frames, however, do not effectively mine the relations among text detection, tracking and recognition. In this paper, we propose a generic Bayesian-based framework of Tracking based Text Detection And Recognition (T(2)DAR) from web videos for embedded captions, which is composed of three major components, i.e., text tracking, tracking based text detection, and tracking based text recognition. In this unified framework, text tracking is first conducted by tracking-by-detection. Tracking trajectories are then revised and refined with detection or recognition results. Text detection or recognition is finally improved with multi-frame integration. Moreover, a challenging video text (embedded caption text) database (USTB-VidTEXT) is constructed and publicly available. A variety of experiments on this dataset verify that our proposed approach largely improves the performance of text detection and recognition from web videos.	[Tian, Shu; Su, Ya] Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Dept Comp Sci & Technol, Beijing 100083, Peoples R China; [Yin, Xu-Cheng] Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Dept Comp Sci & Technol, Beijing Key Lab Mat Sci Knowledge Engn, Beijing 100083, Peoples R China; [Hao, Hong-Wei] Chinese Acad Sci, Res Ctr Digital Technol, Inst Automat, Beijing 100190, Peoples R China	University of Science & Technology Beijing; University of Science & Technology Beijing; Chinese Academy of Sciences; Institute of Automation, CAS	Yin, XC (corresponding author), Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Dept Comp Sci & Technol, Beijing Key Lab Mat Sci Knowledge Engn, Beijing 100083, Peoples R China.	shutian@ustb.edu.cn; xuchengyin@ustb.edu.cn; suyaj@ustb.edu.cn; hongwei.hao@ia.ac.cn		Yin, Xucheng/0000-0003-0023-0220	National Natural Science Foundation of China [61473036]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The authors are grateful to the Associate Editor and the anonymous reviewers for their constructive comments. The research was partly supported by National Natural Science Foundation of China (61473036). This work is dedicated to the beloved memory of Prof. Hong-Wei Hao with great respect, a great researcher, a nice teacher and a forever mentor. Xu-Cheng Yin is the corresponding author.	Chen DT, 2004, PATTERN RECOGN, V37, P595, DOI 10.1016/j.patcog.2003.06.001; Chen XR, 2004, PROC CVPR IEEE, P366; Elagouni K., 2011, P ACM INT C MULT RET, P23; Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Gomez L, 2014, INT C PATT RECOG, P3110, DOI 10.1109/ICPR.2014.536; Goto Hideaki, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P141, DOI 10.1109/ICDAR.2009.102; Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19; Hua XS, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P397; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jung K, 2004, PATTERN RECOGN, V37, P977, DOI 10.1016/j.patcog.2003.10.012; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; Kim KI, 2003, IEEE T PATTERN ANAL, V25, P1631, DOI 10.1109/TPAMI.2003.1251157; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Lee JJ, 2011, PROC INT CONF DOC, P429, DOI 10.1109/ICDAR.2011.93; Li HP, 2000, IEEE T IMAGE PROCESS, V9, P147, DOI 10.1109/83.817607; Li HP, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P21, DOI 10.1109/MMSP.1998.738907; Li HP, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P19; Liang J., 2005, International Journal on Document Analysis and Recognition, V7, P84, DOI 10.1007/s10032-004-0138-z; Lienhart R, 2002, IEEE T CIRC SYST VID, V12, P256, DOI 10.1109/76.999203; Lienhart R, 1996, P SOC PHOTO-OPT INS, V2666, P180, DOI 10.1117/12.234741; Lienhart R, 2000, MULTIMEDIA SYST, V8, P69, DOI 10.1007/s005300050006; Mi C., 2005, P ICICSP, P678, DOI DOI 10.1109/ICICS.2005.1689133; Minetto R, 2011, IEEE IMAGE PROC, P505, DOI 10.1109/ICIP.2011.6116563; Mita T, 2001, PROC INT CONF DOC, P1089, DOI 10.1109/ICDAR.2001.953954; Na YN, 2010, LECT NOTES COMPUT SC, V6297, P392, DOI 10.1007/978-3-642-15702-8_36; Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097; Pan YF, 2011, IEEE T IMAGE PROCESS, V20, P800, DOI 10.1109/TIP.2010.2070803; Nguyen PX, 2014, IEEE WINT CONF APPL, P776, DOI 10.1109/WACV.2014.6836024; Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748; Rong Xuejian, 2014, P IEEE INT C MULT EX, P1; Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296; Shim JC, 1998, INT C PATT RECOG, P618, DOI 10.1109/ICPR.1998.711219; Shiratori H, 2006, INT C PATT RECOG, P1050; Shu Tian, 2016, IJCAI, P2647; Tanaka M., 2008, P 19 INT C PATT REC, P1; Tanaka M, 2007, PROC INT CONF DOC, P1178; Phan TQ, 2013, PROC INT CONF DOC, P589, DOI 10.1109/ICDAR.2013.122; Vermaak J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1110; Wang BK, 2013, PROC SPIE, V8664, DOI 10.1117/12.2009441; Wang GH, 2008, INT C PATT RECOG, P3466; Wang RR, 2004, INT C PATT RECOG, P449; Wang Zhen, 2010, Proceedings of the 2010 2nd International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC 2010), P174, DOI 10.1109/IHMSC.2010.50; Wolf C, 2002, INT C PATT RECOG, P1037, DOI 10.1109/ICPR.2002.1048482; Wolf C, 2006, INT J DOC ANAL RECOG, V8, P280, DOI 10.1007/s10032-006-0014-0; Xi J., 2001, P IEEE INT C MULT EX, P873; Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765; Yi CC, 2011, IEEE T IMAGE PROCESS, V20, P2594, DOI 10.1109/TIP.2011.2126586; Yin XC, 2016, IEEE T IMAGE PROCESS, V25, P2752, DOI 10.1109/TIP.2016.2554321; Yin XC, 2015, IEEE T PATTERN ANAL, V37, P1930, DOI 10.1109/TPAMI.2014.2388210; Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182; Zhou JC, 2007, INTERNATIONAL CONFERENCE ON MACHINE VISION 2007, PROCEEDINGS, P119, DOI 10.1109/ICMV.2007.4469284; Zuo ZY, 2015, PROC INT CONF DOC, P66, DOI 10.1109/ICDAR.2015.7333727	54	36	37	5	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2018	40	3					542	554		10.1109/TPAMI.2017.2692763	http://dx.doi.org/10.1109/TPAMI.2017.2692763			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FV3KC	28422680				2022-12-18	WOS:000424465900003
J	Ferrer, MA; Diaz, M; Carmona-Duarte, C; Morales, A				Ferrer, Miguel A.; Diaz, Moises; Carmona-Duarte, Cristina; Morales, Aythami			A Behavioral Handwriting Model for Static and Dynamic Signature Synthesis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Biometric recognition; on-line and off-line synthetic generation; signature verification; motor equivalence theory; kinematic theory of human movement	RAPID HUMAN MOVEMENTS; KINEMATIC THEORY; VERIFICATION; REPRESENTATION; DISEASE	The synthetic generation of static handwritten signatures based on motor equivalence theory has been recently proposed for biometric applications. Motor equivalence divides the human handwriting action into an effector dependent cognitive level and an effector independent motor level. The first level has been suggested by others as an engram, generated through a spatial grid, and the second has been emulated with kinematic filters. Our paper proposes a development of this methodology in which we generate dynamic information and provide a unified comprehensive synthesizer for both static and dynamic signature synthesis. The dynamics are calculated by lognormal sampling of the 8-connected continuous signature trajectory, which includes, as a novelty, the pen-ups. The forgery generation imitates a signature by extracting the most perceptually relevant points of the given genuine signature and interpolating them. The capacity to synthesize both static and dynamic signatures using a unique model is evaluated according to its ability to adapt to the static and dynamic signature inter-and intra-personal variability. Our highly promising results suggest the possibility of using the synthesizer in different areas beyond the generation of unlimited databases for biometric training.	[Ferrer, Miguel A.; Diaz, Moises; Carmona-Duarte, Cristina] Univ Las Palmas Gran Canaria, Inst Univ Desarrollo Tecnol & Innovac Comunicac, Las Palmas Gran Canaria 35001, Spain; [Morales, Aythami] Univ Autonoma Madrid, ATVS Biometr Res Grp, E-28049 Madrid, Spain	Universidad de Las Palmas de Gran Canaria; Autonomous University of Madrid	Ferrer, MA (corresponding author), Univ Las Palmas Gran Canaria, Inst Univ Desarrollo Tecnol & Innovac Comunicac, Las Palmas Gran Canaria 35001, Spain.	mferrer@idetic.eu; mdiaz@idetic.eu; ccarmona@idetic.eu; aythami.morales@uam.es	Morales, Aythami/L-2529-2013; Ferrer, Miguel A A/L-3863-2013; Moreno, Aythami/ABF-8166-2021; Diaz, Moises/L-3637-2013; Ferrer, Miguel/AFU-8286-2022; Carmona-Duarte, Cristina/E-9031-2010	Morales, Aythami/0000-0002-7268-4785; Ferrer, Miguel A A/0000-0002-2924-1225; Diaz, Moises/0000-0003-3878-3867; Carmona-Duarte, Cristina/0000-0002-4441-6652	Spanish government's MINECO [TEC2012-38630-C04-02]; European Union FEDER; Universidad de Las Palmas de Gran Canaria; Spanish MINECO [JCI-2012-12357]	Spanish government's MINECO(Spanish Government); European Union FEDER(European Commission); Universidad de Las Palmas de Gran Canaria; Spanish MINECO(Spanish Government)	This study was funded by the Spanish government's MINECO TEC2012-38630-C04-02 research project and European Union FEDER M.D and C.C. are supported by the fellowship program of Universidad de Las Palmas de Gran Canaria. A.M. is supported by a JdC contract by the Spanish MINECO (JCI-2012-12357).	Alewijnse LC, 2009, P 14 BIENN C INT GRA, P6; Bird C, 2010, FORENSIC SCI INT, V195, P103, DOI 10.1016/j.forsciint.2009.12.001; Blankers Vivian L., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1403, DOI 10.1109/ICDAR.2009.216; BRAULT JJ, 1993, IEEE T PATTERN ANAL, V15, P953, DOI 10.1109/34.232079; Diaz M, 2015, PROC INT CONF DOC, P631, DOI 10.1109/ICDAR.2015.7333838; Diaz-Cabrera Moises, 2014, Advances in Digital Handwritten Signature Processing: A Human Artefact for e-Society, P111; Diaz-Cabrera M, 2014, INT CONF FRONT HAND, P482, DOI 10.1109/ICFHR.2014.87; Diaz-Cabrera M, 2014, INT CONF FRONT HAND, P61, DOI 10.1109/ICFHR.2014.18; Djioua M, 2009, IEEE T PATTERN ANAL, V31, P2060, DOI 10.1109/TPAMI.2008.264; Eichhorn TE, 1996, MOVEMENT DISORD, V11, P289, DOI 10.1002/mds.870110313; Farina D, 2000, J ELECTROMYOGR KINES, V10, P337, DOI 10.1016/S1050-6411(00)00025-0; Ferrer M. A., 2013, P IEEE INT CARN C SE, P116; Ferrer MA, 2005, IEEE T PATTERN ANAL, V27, P993, DOI 10.1109/TPAMI.2005.125; Ferrer MA, 2013, 6 IAPR INT C BIOM IC, P1, DOI DOI 10.1109/ICB.2013.6612969; Ferrer MA, 2015, IEEE T PATTERN ANAL, V37, P667, DOI 10.1109/TPAMI.2014.2343981; Ferrer MA, 2012, IEEE T INF FOREN SEC, V7, P966, DOI 10.1109/TIFS.2012.2190281; Fierrez J, 2010, PATTERN ANAL APPL, V13, P235, DOI 10.1007/s10044-009-0151-4; Fischer A, 2014, INT CONF FRONT HAND, P222, DOI 10.1109/ICFHR.2014.45; Fischer A, 2015, PROC INT CONF DOC, P241, DOI 10.1109/ICDAR.2015.7333760; Frias-Martinez E, 2006, ENG APPL ARTIF INTEL, V19, P693, DOI 10.1016/j.engappai.2005.12.006; Galbally Javier, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1295, DOI 10.1109/ICDAR.2009.38; Galbally J, 2015, PATTERN RECOGN, V48, P2921, DOI 10.1016/j.patcog.2015.03.019; Galbally J, 2012, PATTERN RECOGN, V45, P2622, DOI 10.1016/j.patcog.2011.12.007; Galbally J, 2012, PATTERN RECOGN, V45, P2610, DOI 10.1016/j.patcog.2011.12.011; Gandadhar G., 2006, THESIS; Guyon I., 1996, P 5 INT WORKSH FRONT, P309; Hafting T, 2005, NATURE, V436, P801, DOI 10.1038/nature03721; Impedovo D, 2008, IEEE T SYST MAN CY C, V38, P609, DOI 10.1109/TSMCC.2008.923866; Ivonin L, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124519; Jain A. K., 2011, INTRO BIOMETRICS; Kawato M, 1999, CURR OPIN NEUROBIOL, V9, P718, DOI 10.1016/S0959-4388(99)00028-8; Kholmatov A, 2005, PATTERN RECOGN LETT, V26, P2400, DOI 10.1016/j.patrec.2005.04.017; Kholmatov A, 2009, PATTERN ANAL APPL, V12, P227, DOI 10.1007/s10044-008-0118-x; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lin ZC, 2007, PATTERN RECOGN, V40, P2097, DOI 10.1016/j.patcog.2006.11.024; Marcelli A, 2013, P 2 WORKSH AUT FOR H, P6, DOI DOI 10.HTTP://CEUR-WS.ORG/VOL-1022/; Marcelli A, 2013, LECT NOTES COMPUT SC, V8157, P673, DOI 10.1007/978-3-642-41184-7_68; Midic U., 2014, AUTOMATIC GENERATION, P1; Neils-Strunjas J, 2006, J SPEECH LANG HEAR R, V49, P1313, DOI 10.1044/1092-4388(2006/094); O'Reilly C., 2012, 2012 11th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA), P787, DOI 10.1109/ISSPA.2012.6310660; O'Reilly C, 2011, HUM MOVEMENT SCI, V30, P792, DOI 10.1016/j.humov.2010.07.010; O'Reilly C, 2009, PATTERN RECOGN, V42, P3324, DOI 10.1016/j.patcog.2008.10.017; Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078; PLAMONDON R, 1995, BIOL CYBERN, V72, P295, DOI 10.1007/BF00202785; PLAMONDON R, 1995, BIOL CYBERN, V72, P309, DOI 10.1007/BF00202786; Plamondon R, 2003, BIOL CYBERN, V89, P126, DOI 10.1007/s00422-003-0407-9; Plamondon R, 1998, BIOL CYBERN, V78, P133, DOI 10.1007/s004220050420; Plamondon R, 2014, PATTERN RECOGN LETT, V35, P225, DOI 10.1016/j.patrec.2012.06.004; Ploog H, 2013, HANDWRITING PSYCHOL; Popel DV, 2007, SER MACH PERCEPT ART, V67, P31; Rabasse C, 2008, IEEE T SYST MAN CY B, V38, P691, DOI 10.1109/TSMCB.2008.918575; REJMANGREENE M, 2005, BIOMETRIC SYSTEMS TE, P335; Sae-Bae N, 2014, IEEE T INF FOREN SEC, V9, P933, DOI 10.1109/TIFS.2014.2316472; Thomas AO, 2009, PATTERN RECOGN, V42, P3365, DOI 10.1016/j.patcog.2008.12.018; Wing AM, 2000, CURR BIOL, V10, pR245, DOI 10.1016/S0960-9822(00)00375-4; Yeung DY, 2004, LECT NOTES COMPUT SC, V3072, P16	57	36	36	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2017	39	6					1041	1053		10.1109/TPAMI.2016.2582167	http://dx.doi.org/10.1109/TPAMI.2016.2582167			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EU5RR	27333600				2022-12-18	WOS:000401091200001
J	Badrinarayanan, V; Budvytis, I; Cipolla, R				Badrinarayanan, Vijay; Budvytis, Ignas; Cipolla, Roberto			Semi-Supervised Video Segmentation Using Tree Structured Graphical Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semi-supervised video segmentation; label propagation; mixture of trees graphical model; tree-structured video models; structured variational inference		We present a novel patch-based probabilistic graphical model for semi-supervised video segmentation. At the heart of our model is a temporal tree structure that links patches in adjacent frames through the video sequence. This permits exact inference of pixel labels without resorting to traditional short time window-based video processing or instantaneous decision making. The input to our algorithm is labeled key frame(s) of a video sequence and the output is pixel-wise labels along with their confidences. We propose an efficient inference scheme that performs exact inference over the temporal tree, and optionally a per frame label smoothing step using loopy BP, to estimate pixel-wise labels and their posteriors. These posteriors are used to learn pixel unaries by training a Random Decision Forest in a semi-supervised manner. These unaries are used in a second iteration of label inference to improve the segmentation quality. We demonstrate the efficacy of our proposed algorithm using several qualitative and quantitative tests on both foreground/background and multiclass video segmentation problems using publicly available and our own datasets.	[Badrinarayanan, Vijay; Budvytis, Ignas; Cipolla, Roberto] Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England	University of Cambridge	Badrinarayanan, V (corresponding author), Univ Cambridge, Dept Engn, Trumpington St, Cambridge CB2 1PZ, England.	vb292@eng.cam.ac.uk; ib255@eng.cam.ac.uk; cipolla@eng.cam.ac.uk		Cipolla, Roberto/0000-0002-8999-2151				Ayvaci A, 2012, INT J COMPUT VISION, V97, P322, DOI 10.1007/s11263-011-0490-7; Badrinarayanan V., 2010, P IEEE C COMP VIS PA; Bai X, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531376; Bishop CM, 2006, PATTERN RECOGNITION; Boykov Y., 1999, P 7 IEEE INT C COMP; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Brostow G., 2008, P 10 EUR C COMP VI 1; Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005; Brox T., 2010, P 11 EUR C COMP VI 5; Budvytis I., 2010, P BRIT MACH VIS C; Budvytis I, 2011, PROC CVPR IEEE; Chen A. Y. C., 2010, Proceedings of 2010 Western New York Image Processing Workshop (WNYIPW), P14, DOI 10.1109/WNYIPW.2010.5649773; Cheung V., 2005, P IEEE C COMP VIS PA; Chockalingam P, 2009, P 12 IEEE INT C COMP; Chuang YY, 2002, ACM T GRAPHIC, V21, P243, DOI 10.1145/566570.566572; Cipoll Roberto, 2008, PROC CVPR IEEE, P1; Criminisil A, 2011, FOUND TRENDS COMPUT, V7, P81, DOI [10.1561/0600000035, 10.1501/0000000035]; Fathi A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.78; Grundmann M., 2010, P IEEE C COMP VIS PA; Hinton GE, 2010, PHILOS T R SOC B, V365, P177, DOI 10.1098/rstb.2009.0200; Jojic N., 2003, P 9 IEEE INT C COMP; Kannan A., 2006, P 20 ANN C NEUR INF, V19; Kohli P, 2005, IEEE I CONF COMP VIS, P922; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Lee Y. J., 2011, P IEEE INT C COMP VI; Lezama J., 2011, P IEEE C COMP VIS PA; Li Y, 2005, ACM T GRAPHIC, V24, P595, DOI 10.1145/1073204.1073234; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Saul L. K., 1996, P C NEUR INF PROC SY; Settles B., 2010, 1648 U WISC MAD DEP, DOI DOI 10.1016/J.MATLET.2010.11.072; Sudderth E. B., 2008, P ADV NEUR INF PROC, P1585; Tsai D., 2010, P BRIT MACH VIS C; Vazquez-Reina A., 2010, P 11 EUR C COMP VI 5; Vezhnevets A., 2012, P IEEE C COMP VIS PA; Wang C., 2009, P 12 IEEE INT C COMP; Yan R, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P516; Zhu Xiaojin, 2002, TECHNICAL REPORT, P1	38	36	41	2	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2013	35	11					2751	2764		10.1109/TPAMI.2013.54	http://dx.doi.org/10.1109/TPAMI.2013.54			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	223SU	24051733	Green Accepted, Green Submitted			2022-12-18	WOS:000324830900014
J	Carpineto, C; Romano, G				Carpineto, Claudio; Romano, Giovanni			Consensus Clustering Based on a New Probabilistic Rand Index with Application to Subtopic Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Consensus clustering; Rand index; probabilistic Rand index; search results clustering; subtopic retrieval	PARTITIONS; ACCUMULATION; ENSEMBLES	We introduce a probabilistic version of the well-known Rand Index (RI) for measuring the similarity between two partitions, called Probabilistic Rand Index (PRI), in which agreements and disagreements at the object-pair level are weighted according to the probability of their occurring by chance. We then cast consensus clustering as an optimization problem of the PRI value between a target partition and a set of given partitions, experimenting with a simple and very efficient stochastic optimization algorithm. Remarkable performance gains over input partitions as well as over existing related methods are demonstrated through a range of applications, including a new use of consensus clustering to improve subtopic retrieval.	[Carpineto, Claudio; Romano, Giovanni] Fdn Ugo Bordoni, I-00161 Rome, Italy	Ugo Bordoni Foundation	Carpineto, C (corresponding author), Fdn Ugo Bordoni, Viale Policlin 147, I-00161 Rome, Italy.	carpinet@fub.it; romano@fub.it						Azimi J, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P992; Bansal N, 2002, ANN IEEE SYMP FOUND, P238, DOI 10.1109/SFCS.2002.1181947; BARTHELEMY J. P., 1995, DIMACS SERIES DISCRE, V19, P3; Bekkerman R, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P99; Ben-Hur Asa, 2002, Pac Symp Biocomput, P6; Bernardini A, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 1, P206; Bonizzoni P, 2008, J COMPUT SYST SCI, V74, P671, DOI 10.1016/j.jcss.2007.06.024; Campello RJGB, 2007, PATTERN RECOGN LETT, V28, P833, DOI 10.1016/j.patrec.2006.11.010; Carpineto C, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P170; Carpineto C, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1541880.1541884; Carpineto C, 2009, J AM SOC INF SCI TEC, V60, P877, DOI 10.1002/asi.21036; Caruana R, 2006, IEEE DATA MINING, P107; Cristofor D, 2002, J UNIVERS COMPUT SCI, V8, P153; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Dimitriadou E, 2002, INT J PATTERN RECOGN, V16, P901, DOI 10.1142/S0218001402002052; Fern XZ., 2008, STAT ANAL DATA MIN, V1, P128, DOI [10.1002/sam.10008, DOI 10.1002/SAM.10008]; Filkov V, 2003, PROC INT C TOOLS ART, P418, DOI 10.1109/TAI.2003.1250220; Fred ALN, 2002, INT C PATT RECOG, P276, DOI 10.1109/ICPR.2002.1047450; Gionis A., 2007, ACM T KNOWLEDGE DISC, V1; Goder A, 2008, SIAM PROC S, P109; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011; Leisch F., 1999, WORKING PAPERS SFB W, V51; Li T., 2008, P SIAM INT C DAT MIN, P789; Liu G., 1968, INTRO COMBINATORIAL; Meila M., 2005, PROC INT C MACHINE L, P577, DOI DOI 10.1145/1102351.1102424; Nguyen X. V., 2009, P 26 ANN INT C MACHI, P1073, DOI [10.1145/1553374.1553511, DOI 10.1145/1553374.1553511]; Osinski S, 2005, IEEE INTELL SYST, V20, P48, DOI 10.1109/MIS.2005.38; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Schutze H., 2008, INTRO INFORM RETRIEV, V39; Strehl A., 2003, Journal of Machine Learning Research, V3, P583, DOI 10.1162/153244303321897735; Topchy A, 2005, IEEE T PATTERN ANAL, V27, P1866, DOI 10.1109/TPAMI.2005.237; Topchy A, 2004, SIAM PROC S, P379; Topchy A, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P331; Unnikrishnan R, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P394; van Rijsbergen K. J., 1979, INFORM RETRIEVAL; Vega-Pons S, 2010, PATTERN RECOGN, V43, P2712, DOI 10.1016/j.patcog.2010.03.001; Wakabayashi Y, 1998, RESENHAS IME USP, V3, P323; Wang P, 2010, LECT NOTES ARTIF INT, V6323, P435, DOI 10.1007/978-3-642-15939-8_28; Wang X, 2009, PATTERN RECOGN, V42, P668, DOI 10.1016/j.patcog.2008.09.013; [No title captured]	43	36	38	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2012	34	12					2315	2326		10.1109/TPAMI.2012.80	http://dx.doi.org/10.1109/TPAMI.2012.80			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	021VO	22450816				2022-12-18	WOS:000309913700003
J	Gualdi, G; Prati, A; Cucchiara, R				Gualdi, Giovanni; Prati, Andrea; Cucchiara, Rita			Multistage Particle Windows for Fast and Accurate Object Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Efficient object detection; pedestrian detection; coarse-to-fine search refinement	PEDESTRIAN DETECTION; CLASSIFICATION; CASCADES; FEATURES	The common paradigm employed for object detection is the sliding window (SW) search. This approach generates grid-distributed patches, at all possible positions and sizes, which are evaluated by a binary classifier: The tradeoff between computational burden and detection accuracy is the real critical point of sliding windows; several methods have been proposed to speed up the search such as adding complementary features. We propose a paradigm that differs from any previous approach since it casts object detection into a statistical-based search using a Monte Carlo sampling for estimating the likelihood density function with Gaussian kernels. The estimation relies on a multistage strategy where the proposal distribution is progressively refined by taking into account the feedback of the classifiers. The method can be easily plugged into a Bayesian-recursive framework to exploit the temporal coherency of the target objects in videos. Several tests on pedestrian and face detection, both on images and videos, with different types of classifiers (cascade of boosted classifiers, soft cascades, and SVM) and features (covariance matrices, Haar-like features, integral channel features, and histogram of oriented gradients) demonstrate that the proposed method provides higher detection rates and accuracy as well as a lower computational burden w.r.t. sliding window detection.	[Gualdi, Giovanni; Cucchiara, Rita] Univ Modena & Reggio Emilia, Dept Informat Engn, I-41125 Modena, Italy; [Prati, Andrea] Univ Modena & Reggio Emilia, Dept Engn Sci & Methods, I-42122 Reggio Emilia, Italy	Universita di Modena e Reggio Emilia; Universita di Modena e Reggio Emilia	Gualdi, G (corresponding author), Univ Modena & Reggio Emilia, Dept Informat Engn, I-41125 Modena, Italy.	giovanni.gualdi@unimore.it; andrea.prati@unimore.it; rita.cucchiara@unimore.it	Prati, Andrea/B-7440-2014; Cucchiara, Rita/L-3006-2015	Prati, Andrea/0000-0002-1211-529X; Cucchiara, Rita/0000-0002-2239-283X	European Commission-Directorate-General Justice, Freedom, and Security [JLS/2009/CIPS/AG/C1-028]; Regione Emilia-Romagna; Bridge129 SpA	European Commission-Directorate-General Justice, Freedom, and Security; Regione Emilia-Romagna(Regione Emilia Romagna); Bridge129 SpA	This work is within the project THIS (JLS/2009/CIPS/AG/C1-028), with the support of the Prevention, Preparedness, and Consequence Management of Terrorism, and other Security-related Risks Programme European Commission-Directorate-General Justice, Freedom, and Security. This project is also partially funded by Regione Emilia-Romagna (PRRIITT funding scheme) and Bridge129 SpA. The authors want to deeply thank Piotr Dollar from Caltech for his help in experimenting with the FPDW classifier.	Arenas M, 2008, LECT NOTES COMPUT SC, V5001, P449; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; Brubaker SC, 2008, INT J COMPUT VISION, V77, P65, DOI 10.1007/s11263-007-0060-1; Brubaker SC, 2006, LECT NOTES COMPUT SC, V3951, P325; Butko Nicholas J., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2751, DOI 10.1109/CVPRW.2009.5206540; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33; Dinh T. B., 2006, P INT C RES INN VIS, P139; Dollar P., 2009, P BRIT MACH VIS C; Dollar P., 2010, P BRIT MACH VIS C, DOI [10.5244/C.24.68, DOI 10.5244/C.24.68]; Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260; Ess A, 2009, IEEE T PATTERN ANAL, V31, P1831, DOI 10.1109/TPAMI.2009.109; Everingham M., 2006, P WORKSH EUR C COMP; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Felzenszwalb P., 2010, P IEEE C COMP VIS PA; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Fleuret F, 2001, INT J COMPUT VISION, V41, P85, DOI 10.1023/A:1011113216584; FREUND Y, 1996, INT C MACH LEARN, V156, P148; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Froba B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P91, DOI 10.1109/AFGR.2004.1301514; Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7; Gualdi G., 2009, P ACM IEEE INT C DIS; Han B., 2004, P IEEE CS C COMP VIS; Han B, 2008, IEEE T PATTERN ANAL, V30, P1186, DOI 10.1109/TPAMI.2007.70771; Han B, 2009, IEEE T PATTERN ANAL, V31, P919, DOI 10.1109/TPAMI.2008.134; Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5; Hota R.N., 2010, COMPUTE 10 P 3 ANN A, P1; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7; Lampert CH, 2009, IEEE T PATTERN ANAL, V31, P2129, DOI 10.1109/TPAMI.2009.144; Lanz O, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P317, DOI 10.1109/ICIAP.2007.4362798; Lehmann A., 2009, P IEEE INT C COMP VI; Lienhart R, 2003, LECT NOTES COMPUT SC, V2781, P297; Martin A, 1997, P 5 EUR SPEECH, V4, P1895; Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571; Munder S, 2006, IEEE T PATTERN ANAL, V28, P1863, DOI 10.1109/TPAMI.2006.217; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2; Olshen R., 1984, CLASSIFICATION REGRE; Ong EJ, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P889; Opelt A, 2006, IEEE T PATTERN ANAL, V28, P416, DOI 10.1109/TPAMI.2006.54; Paisitkriangkcrai S, 2008, IEEE T CIRC SYST VID, V18, P1140, DOI 10.1109/TCSVT.2008.928213; Pedersoli M, 2010, LECT NOTES COMPUT SC, V6316, P280; Philomin V., 2000, P EUR C COMP VIS, P134; Ponce J, 2006, LECT NOTES COMPUT SC, V4170, P29; Sabzmeydani P, 2007, PROC CVPR IEEE, P1251; Tao J., 2008, P WORKSH VIS SURV; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589; Verschae R, 2008, MACH VISION APPL, V19, P85, DOI 10.1007/s00138-007-0084-0; Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; VIOLA P, 2001, NEURAL INFORM PROCES, V14, P1311; Wohler C, 1999, IEEE T NEURAL NETWOR, V10, P1531, DOI 10.1109/72.809100; Wojek C., 2008, P DAGM S PATT REC; Wojek C, 2008, LECT NOTES COMPUT SC, V5096, P82, DOI 10.1007/978-3-540-69321-5_9; Wu J., 2005, P INT C MACH LEARN, P988; ZHANG L, 2007, P 29 ANN COGN SCI C; Zhang WF, 2007, PR IEEE COMP DESIGN, P10; Zhang WZ, 2009, SCI CHINA SER F, V52, P236, DOI 10.1007/s11432-009-0034-8; Zhang ZQ, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P184, DOI 10.1109/ACV.2002.1182179; Zhu Qiang, 2006, CVPR, DOI DOI 10.1109/CVPR.2006.119	66	36	41	1	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2012	34	8					1589	1604		10.1109/TPAMI.2011.247	http://dx.doi.org/10.1109/TPAMI.2011.247			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	957UE	22184258				2022-12-18	WOS:000305188500011
J	Kukelova, Z; Bujnak, M; Pajdla, T				Kukelova, Zuzana; Bujnak, Martin; Pajdla, Tomas			Polynomial Eigenvalue Solutions to Minimal Problems in Computer Vision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Structure from motion; relative camera pose; minimal problems; polynomial eigenvalue problems	RELATIVE POSE; MOTION; MODEL	We present a method for solving systems of polynomial equations appearing in computer vision. This method is based on polynomial eigenvalue solvers and is more straightforward and easier to implement than the state-of-the-art Grobner basis method since eigenvalue problems are well studied, easy to understand, and efficient and robust algorithms for solving these problems are available. We provide a characterization of problems that can be efficiently solved as polynomial eigenvalue problems (PEPs) and present a resultant-based method for transforming a system of polynomial equations to a polynomial eigenvalue problem. We propose techniques that can be used to reduce the size of the computed polynomial eigenvalue problems. To show the applicability of the proposed polynomial eigenvalue method, we present the polynomial eigenvalue solutions to several important minimal relative pose problems.	[Kukelova, Zuzana; Pajdla, Tomas] Czech Tech Univ, Ctr Machine Percept, Dept Cybernet, Fac Elect Engn, Prague 12135 2, Czech Republic	Czech Technical University Prague	Kukelova, Z (corresponding author), Czech Tech Univ, Ctr Machine Percept, Dept Cybernet, Fac Elect Engn, Karlovo Namesti 13, Prague 12135 2, Czech Republic.	kukelova@cmp.felk.cvut.cz; martin@solvergenerator.com; pajdla@cmp.felk.cvut.cz	Pajdla, Tomas/K-7954-2013; Kukelova, Zuzana/AAM-9096-2020; Kukelova, Zuzana/M-7938-2016; Kukelova, Zuzana/GXG-1671-2022	Pajdla, Tomas/0000-0001-6325-0072; Kukelova, Zuzana/0000-0002-1916-8829; Kukelova, Zuzana/0000-0002-1916-8829	EC [FP7-SPACE-241523 PRoViScout]; Czech Government [MSM6840770038]	EC(European CommissionEuropean Commission Joint Research Centre); Czech Government	This work has been supported by EC project FP7-SPACE-241523 PRoViScout and by The Czech Government under the research program MSM6840770038.	[Anonymous], 1996, REC; Bai Zhaojun, 2000, TEMPLATES SOLUTION A; Bujnak M., 2009, P 12 IEEE INT C COMP; Bujnak M., 2008, P IEEE C COMP VIS PA; Bujnak M., 2010, P 10 AS C COMP VIS; Byrod M., 2007, P 11 IEEE INT C COMP; Cox D. A., 2005, USING ALGEBRAIC GEOM, V185; FADDEEV DK, 1963, COMPUTATIONAL METHOD; FAUGERAS OD, 1990, INT J COMPUT VISION, V4, P225, DOI 10.1007/BF00054997; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fitzgibbon A., 2001, P IEEE CS C COMP VIS; GEYER C, 2007, P IEEE C COMP VIS PA; H Li, 2005, P OMNIVISION; Hartley R., 2003, MULTIPLE VIEW GEOMET; Hook D., 1990, GRAPHICS GEMS, P416; Josephson K., 2009, P IEEE C COMP VIS PA; Kruppa E., 1913, SITZ BER AKAD WIS MN, V122, P1939; Kukelova Z., 2007, P IEEE C COMP VIS PA; Kukelova Z., 2008, P 19 BRIT MACH VIS C; Kukelova Z., 2008, P 10 EUR C COMP VIS; Kukelova Z, 2011, IEEE T PATTERN ANAL, V33, P2410, DOI 10.1109/TPAMI.2011.86; Kukelova Z, 2010, COMPUT VIS IMAGE UND, V114, P234, DOI 10.1016/j.cviu.2008.11.008; Li HD, 2006, INT C PATT RECOG, P630; Li HD, 2006, LECT NOTES COMPUT SC, V3954, P200; Li X, 2008, P 10 EUR C COMP VIS; MANOCHA D, 1993, J SYMB COMPUT, V15, P99, DOI 10.1006/jsco.1993.1009; MANOCHA D, 1994, IEEE COMPUT GRAPH, V14, P46, DOI 10.1109/38.267470; Martinec D., 2007, P IEEE C COMP VIS PA; Micusik B, 2003, PROC CVPR IEEE, P485; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; Nister D., 2007, P IEEE C COMP VIS PA; Press WH., 2002, NUMERICAL RECIPES C, V2; Snavely N., 2008, P IEEE C COMP VIS PA; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Stetter HJ., 2004, NUMERICAL POLYNOMIAL; Stewenius H, 2005, PROC CVPR IEEE, P789; Stewenius H., 2005, P WORKSH OMN VIS; Stewenius H, 2006, ISPRS J PHOTOGRAMM, V60, P284, DOI 10.1016/j.isprsjprs.2006.03.005; Urbanek M., 2001, P 3 INT C 3 D DIG IM; Wallack A., 1998, ISSAC 98. Proceedings of the 1998 International Symposium on Symbolic and Algebraic Computation, P244, DOI 10.1145/281508.281626	40	36	40	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2012	34	7					1381	1393		10.1109/TPAMI.2011.230	http://dx.doi.org/10.1109/TPAMI.2011.230			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	943PZ	22144525				2022-12-18	WOS:000304138300010
J	Meng, GF; Pan, CH; Xiang, SM; Duan, JY; Zheng, NN				Meng, Gaofeng; Pan, Chunhong; Xiang, Shiming; Duan, Jiangyong; Zheng, Nanning			Metric Rectification of Curved Document Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Document image analysis; imaging geometry; geometric correction; shape-from-X; mesh warping	SHAPE; RESTORATION	In this paper, we propose a metric rectification method to restore an image from a single camera-captured document image. The core idea is to construct an isometric image mesh by exploiting the geometry of page surface and camera. Our method uses a general cylindrical surface (GCS) to model the curved page shape. Under a few proper assumptions, the printed horizontal text lines are shown to be line convergent symmetric. This property is then used to constrain the estimation of various model parameters under perspective projection. We also introduce a paraperspective projection to approximate the nonlinear perspective projection. A set of close-form formulas is thus derived for the estimate of GCS directrix and document aspect ratio. Our method provides a straightforward framework for image metric rectification. It is insensitive to camera positions, viewing angles, and the shapes of document pages. To evaluate the proposed method, we implemented comprehensive experiments on both synthetic and real-captured images. The results demonstrate the efficiency of our method. We also carried out a comparative experiment on the public CBDAR2007 data set. The experimental results show that our method outperforms the state-of-the-art methods in terms of OCR accuracy and rectification errors.	[Meng, Gaofeng; Pan, Chunhong; Xiang, Shiming; Duan, Jiangyong] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China; [Zheng, Nanning] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS; Xi'an Jiaotong University	Meng, GF (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Zhongguancun E Rd 95, Beijing 100190, Peoples R China.	gfmeng@nlpr.ia.ac.cn; chpan@nlpr.ia.ac.cn; smxiang@nlpr.ia.ac.cn; jyduan@nlpr.ia.ac.cn; nnzheng@mail.xjtu.edu.cn			National Natural Science Foundation of China [61005036, 60873161, 60975037, 90920008]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The authors would like to thank the anonymous reviewers and editor who provided many valuable comments and suggestions. This work is supported by the Projects (Grant No. 61005036, 60873161, 60975037, and 90920008) of the National Natural Science Foundation of China.	ABATZOGLOU T, 1982, J OPTIMIZ THEORY APP, V36, P163, DOI 10.1007/BF00933827; Bajcsy R., 1973, P 3 INT JOINT C ART, P572; BARNARD ST, 1983, ARTIF INTELL, V21, P435, DOI 10.1016/S0004-3702(83)80021-6; Basu S, 2007, PATTERN RECOGN, V40, P1825, DOI 10.1016/j.patcog.2006.10.002; Brown MS, 2007, IEEE T PATTERN ANAL, V29, P1904, DOI 10.1109/TPAMI.2007.1118; Brown MS, 2006, IEEE T IMAGE PROCESS, V15, P1544, DOI 10.1109/TIP.2006.871082; Brown MS, 2004, IEEE T PATTERN ANAL, V26, P1295, DOI 10.1109/TPAMI.2004.87; Brown MS, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P367, DOI 10.1109/ICCV.2001.937649; Bukhari SS, 2009, P 3 INT WORKSH CAM B, P34; Cao HG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P228, DOI 10.1109/ICCV.2003.1238346; Courteille F, 2007, MACH VISION APPL, V18, P301, DOI 10.1007/s00138-006-0062-y; Fu B., 2007, P 2 INTERNATIONALWOR, P63; Fujimoto K, 2007, PROC INT CONF DOC, P267; Gatos B, 2007, PROC INT CONF DOC, P989; Gumerov N, 2004, LECT NOTES COMPUT SC, V3023, P482; Kanungo T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P730, DOI 10.1109/ICDAR.1993.395633; Koo HI, 2009, IEEE T IMAGE PROCESS, V18, P1551, DOI 10.1109/TIP.2009.2019301; Levenshtein V. I, 1966, SOV PHYS DOKL, V10, P707; Li ZL, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON MANAGEMENT SCIENCE AND ENGINEERING, P337; Liang J, 2005, PROC CVPR IEEE, P338; Liang J, 2008, IEEE T PATTERN ANAL, V30, P591, DOI 10.1109/TPAMI.2007.70724; Liebowitz D, 1998, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1998.698649; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu SJ, 2006, INT C PATT RECOG, P971; Lu SJ, 2005, IMAGE VISION COMPUT, V23, P541, DOI 10.1016/j.imavis.2005.01.003; Masalovitch A., 2007, P INT WORKSH CAM BAS, P45; Ohta T.I., 1981, P INT JOINT C ART IN, P746; Pilu M, 2001, PROC CVPR IEEE, P67; Schneider DC, 2007, PROC INT CONF DOC, P113; Shafait F, 2007, 2 INT WORKSH CAM BAS, P181; Shafait F, 2011, IEEE T PATTERN ANAL, V33, P846, DOI 10.1109/TPAMI.2010.194; Sun MX, 2005, IEEE I CONF COMP VIS, P1117; Tan CL, 2006, IEEE T PATTERN ANAL, V28, P195, DOI 10.1109/TPAMI.2006.40; Tsoi Yau-Chat, 2007, P IEEE C COMP VIS PA, P1; Tsoi YC, 2004, PROC CVPR IEEE, P240; Ulges A, 2005, PROC INT CONF DOC, P1001, DOI 10.1109/ICDAR.2005.90; Wada T, 1997, INT J COMPUT VISION, V24, P125, DOI 10.1023/A:1007906904009; Wolberg G, 1998, VISUAL COMPUT, V14, P360, DOI 10.1007/s003710050148; Zhang L, 2008, IEEE T PATTERN ANAL, V30, P728, DOI 10.1109/TPAMI.2007.70831; Zhang L, 2009, PATTERN RECOGN, V42, P2961, DOI 10.1016/j.patcog.2009.03.025; Zhang WF, 2007, PR IEEE COMP DESIGN, P10; Zhang Z, 2004, PROC CVPR IEEE, P10; Zhang Z, 2003, PROC INT CONF DOC, P589	43	36	40	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2012	34	4					707	722		10.1109/TPAMI.2011.151	http://dx.doi.org/10.1109/TPAMI.2011.151			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	896PO	21808093				2022-12-18	WOS:000300581700007
J	Pernkopf, F; Wohlmayr, M; Tschiatschek, S				Pernkopf, Franz; Wohlmayr, Michael; Tschiatschek, Sebastian			Maximum Margin Bayesian Network Classifiers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian network classifier; discriminative learning; discriminative classifiers; large margin training; missing features; convex relaxation		We present a maximum margin parameter learning algorithm for Bayesian network classifiers using a conjugate gradient (CG) method for optimization. In contrast to previous approaches, we maintain the normalization constraints on the parameters of the Bayesian network during optimization, i.e., the probabilistic interpretation of the model is not lost. This enables us to handle missing features in discriminatively optimized Bayesian networks. In experiments, we compare the classification performance of maximum margin parameter learning to conditional likelihood and maximum likelihood learning approaches. Discriminative parameter learning significantly outperforms generative maximum likelihood estimation for naive Bayes and tree augmented naive Bayes structures on all considered data sets. Furthermore, maximizing the margin dominates the conditional likelihood approach in terms of classification performance in most cases. We provide results for a recently proposed maximum margin optimization approach based on convex relaxation [1]. While the classification results are highly similar, our CG-based optimization is computationally up to orders of magnitude faster. Margin-optimized Bayesian network classifiers achieve classification performance comparable to support vector machines (SVMs) using fewer parameters. Moreover, we show that unanticipated missing feature values during classification can be easily processed by discriminatively optimized Bayesian network classifiers, a case where discriminative classifiers usually require mechanisms to complete unknown feature values in the data first.	[Pernkopf, Franz; Wohlmayr, Michael; Tschiatschek, Sebastian] Graz Univ Technol, Lab Signal Proc & Speech Commun, Dept Elect Engn, A-8010 Graz, Austria	Graz University of Technology	Pernkopf, F (corresponding author), Graz Univ Technol, Lab Signal Proc & Speech Commun, Dept Elect Engn, Inffeldgasse 16C, A-8010 Graz, Austria.	pernkopf@tugraz.at; michael.wohlmayr@tugraz.at; tschiatschek@tugraz.at		Tschiatschek, Sebastian/0000-0002-2592-0108	Austrian Science Fund [P22488-N23, S10610]; Austrian Science Fund (FWF) [P 22488] Funding Source: researchfish	Austrian Science Fund(Austrian Science Fund (FWF)); Austrian Science Fund (FWF)(Austrian Science Fund (FWF))	The authors thank the anonymous reviewers for useful comments that improved the quality of the paper. Thanks to Jeff Bilmes for discussions and support in writing this paper. This work was supported by the Austrian Science Fund (Project number P22488-N23) and (Project number S10610).	Acid S, 2005, MACH LEARN, V59, P213, DOI 10.1007/s10994-005-0473-4; Amestoy P., 2000, LECT NOTES COMPUTER, P122; [Anonymous], [No title captured]; Bartlett PL, 2006, J AM STAT ASSOC, V101, P138, DOI 10.1198/016214505000000907; Biegler LT, 2009, COMPUT CHEM ENG, V33, P575, DOI 10.1016/j.compchemeng.2008.08.006; Bilmes JA., 2000, P 16 C UNC ART INT, P38; Bishop, 1995, NEURAL NETWORKS PATT; Bishop C.M, 2006, PATTERN RECOGN; Boyd S, 2004, CONVEX OPTIMIZATION; Chapelle O, 2007, NEURAL COMPUT, V19, P1155, DOI 10.1162/neco.2007.19.5.1155; Collobert R., 2006, P 23 INT C MACHINE L, P201, DOI DOI 10.1145/1143844.1143870.; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; COWELL RG, 1999, PROBABILISTIC NETWOR; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; FAYYAD UM, 1993, P 13 INT JOINT C ART, P1022; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GOPALAKRISHNAN PS, 1991, IEEE T INFORM THEORY, V37, P107, DOI 10.1109/18.61108; Greiner R, 2005, MACH LEARN, V59, P297, DOI 10.1007/s10994-005-0469-0; Grossman D, 2004, P 21 INT C MACHINE L, P361; Guo Y., 2005, UNCERTAINTY ARTIFICI, P233; Heigold G., 2008, INT C MACH LEARN ICM, P384; HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732; Keogh EJ, 1999, ARTIFICIAL INTELLIGENCE AND STATISTICS 99, PROCEEDINGS, P225; Lamel L., 1986, P US DEF ADV RES PRO; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Pernkopf F, 2005, PATTERN RECOGN, V38, P1, DOI 10.1016/j.patcog.2004.05.012; Pernkopf F., 2010, MAXIMUM MARGIN BAYES; Pernkopf F., 2008, P INT S ART INT MATH; Pernkopf F., 2011, STOCHASTIC MARGIN BA; Pernkopf F., 2008, SPEECH COMMUN, V143, P123; Pernkopf F, 2010, LECT NOTES ARTIF INT, V6323, P50, DOI 10.1007/978-3-642-15939-8_4; Pernkopf F, 2010, J MACH LEARN RES, V11, P2323; Pernkopf F, 2009, LECT NOTES ARTIF INT, V5782, P221, DOI 10.1007/978-3-642-04174-7_15; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Roos T, 2005, MACH LEARN, V59, P267; Schluter R, 2001, SPEECH COMMUN, V34, P287, DOI 10.1016/S0167-6393(00)00035-2; Scholkopf B., 2001, LEARNING KERNELS SUP; Sha F, 2007, INT CONF ACOUST SPEE, P313; Vapnik V.N, 1998, STAT LEARNING THEORY; Wachter A, 2006, MATH PROGRAM, V106, P25, DOI 10.1007/s10107-004-0559-y; WETTIG H, 2003, P 18 INT JOINT C ART, P491; Woodland PC, 2002, COMPUT SPEECH LANG, V16, P25, DOI 10.1006/csla.2001.0182	43	36	41	2	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2012	34	3					521	532		10.1109/TPAMI.2011.149	http://dx.doi.org/10.1109/TPAMI.2011.149			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	880CH	21808086				2022-12-18	WOS:000299381600008
J	Grady, L				Grady, Leo			Minimal Surfaces Extend Shortest Path Segmentation Methods to 3D	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D image segmentation; minimal surfaces; shortest paths; Dijkstra's algorithm; boundary operator; total unimodularity; linear programming; minimum-cost circulation network flow	MAXIMUM CUT; LIVE-WIRE; GRAPH	Shortest paths have been used to segment object boundaries with both continuous and discrete image models. Although these techniques are well defined in 2D, the character of the path as an object boundary is not preserved in 3D. An object boundary in three dimensions is a 2D surface. However, many different extensions of the shortest path techniques to 3D have been previously proposed in which the 3D object is segmented via a collection of shortest paths rather than a minimal surface, leading to a solution which bears an uncertain relationship to the true minimal surface. Specifically, there is no guarantee that a minimal path between points on two closed contours will lie on the minimal surface joining these contours. We observe that an elegant solution to the computation of a minimal surface on a cellular complex (e.g., a 3D lattice) was given by Sullivan [47]. Sullivan showed that the discrete minimal surface connecting one or more closed contours may be found efficiently by solving a Minimum-cost Circulation Network Flow (MCNF) problem. In this work, we detail why a minimal surface properly extends a shortest path (in the context of a boundary) to three dimensions, present Sullivan's solution to this minimal surface problem via an MCNF calculation, and demonstrate the use of these minimal surfaces on the segmentation of image data.	Siemens Corp Res, Dept Imaging & Visualizat, E Princeton, NJ 08540 USA	Siemens AG	Grady, L (corresponding author), Siemens Corp Res, Dept Imaging & Visualizat, 755 Coll Rd, E Princeton, NJ 08540 USA.	leo.grady@siemens.com						Aoshima K., 1977, SIAM Journal on Computing, V6, P86, DOI 10.1137/0206007; Appleton B, 2006, IEEE T PATTERN ANAL, V28, P106, DOI 10.1109/TPAMI.2006.12; Ardon R, 2005, LECT NOTES COMPUT SC, V3757, P520, DOI 10.1007/11585978_34; Ardon R, 2006, INT J COMPUT VISION, V69, P127, DOI 10.1007/sM263-006-6850-z; ARMSTRONG CJ, 2006, P VOL GRAPH SEPT, V22, P661; Biggs N., 1993, ALGEBRAIC GRAPH THEO; Bitter I, 2001, IEEE T VIS COMPUT GR, V7, P195, DOI 10.1109/2945.942688; Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; BOYKOV Y, 2003, P INT C COMP VIS OCT, V1; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Briggs AJ, 2004, INT J ROBOT RES, V23, P717, DOI 10.1177/0278364904045467; Buehler C, 2002, LECT NOTES COMPUT SC, V2352, P885; Cohen LD, 1997, INT J COMPUT VISION, V24, P57, DOI 10.1023/A:1007922224810; Cohen LD, 2001, PROC CVPR IEEE, P102; Falcao AX, 1998, GRAPH MODEL IM PROC, V60, P233, DOI 10.1006/gmip.1998.0475; Falcao AX, 2000, MED IMAGE ANAL, V4, P389, DOI 10.1016/S1361-8415(00)00023-2; Ford Jr LR, 1957, NAV RES LOG, V4, P47, DOI 10.1002/nav.3800040109; Ford L. R. J., 1962, FLOWS NETWORKS; Forrest J., 2004, CLP USER GUIDE; Goldberg AV, 1990, ALGORITHMS COMBINATO, P101; GRADY L, 2006, P IEEE C COMP VIS PA, V1, P69; Hadlock F., 1975, SIAM Journal on Computing, V4, P221, DOI 10.1137/0204019; HAMARNEH G, 2005, P SPIE MED IMAGING O, P1597; Hilton P. J., 1960, HOMOLOGY THEORY; KNAPP M, 2004, J WSCG, V12, P229; KOLMOGOROV V, 2005, MSRT2005117; Kolmogorov V, 2007, IEEE T PATTERN ANAL, V29, P1274, DOI 10.1109/TPAMI.2007.1031; KONIG S, 2005, P SPIE MED IMAGING 2, P1674; LEFSCHETZ S, 1942, AM MATH SOC COLLOQ B, P27; Li K, 2006, IEEE T PATTERN ANAL, V28, P119, DOI 10.1109/TPAMI.2006.19; MATTIUSSI C, 2000, ADV IMAG ELECT PHYS, P1; Morgan F., 2000, GEOMETRIC MEASURE TH, V3; Mortensen EN, 1998, GRAPH MODEL IM PROC, V60, P349, DOI 10.1006/gmip.1998.0480; OKADA S, 1955, P IRE, V43, P1527; Papadimitriou C.H., 1998, COMBINATORIAL OPTIMI, VUnabridged edition; Porter SV, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P460, DOI 10.1109/ICIAP.2003.1234093; Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763; SALAH Z, 2005, P WORKSH BILDV MED I, P158; Schenk A, 2001, PROC SPIE, V4322, P1357, DOI 10.1117/12.431015; SCHENK A, 2000, P 3 INT C MED IM COM, P186; SESHU S, 1955, P IRE, V43, P342; Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; SHIH WK, 1990, IEEE T COMPUT, V39, P694, DOI 10.1109/12.53581; Sullivan J.M., 1990, THESIS PRINCETON U; Sun CM, 2002, IMAGE VISION COMPUT, V20, P981, DOI 10.1016/S0262-8856(02)00112-9; TONTI E., 1996, GRAVITATION ELECTROM, P281; TRUEMPER K, 1978, SIAM J APPL MATH, V35, P328, DOI 10.1137/0135027; TSITSIKLIS JN, 1995, IEEE T AUTOMAT CONTR, V40, P1528, DOI 10.1109/9.412624; Zomorodian A. J., 2005, C MO AP C M, DOI 10.1017/cbo9780511546945; [No title captured]	52	36	37	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2010	32	2					321	334		10.1109/TPAMI.2008.289	http://dx.doi.org/10.1109/TPAMI.2008.289			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	532IT	20075461				2022-12-18	WOS:000272741500010
J	Ververidis, D; Kotropoulos, C				Ververidis, Dimitrios; Kotropoulos, Constantine, Sr.			Information Loss of the Mahalanobis Distance in High Dimensions: Application to Feature Selection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayes classifier; Gaussian distribution; Mahalanobis distance; feature selection; cross validation	SAMPLE-SIZE; PATTERN-RECOGNITION; CLASSIFICATION	When an infinite training set is used, the Mahalanobis distance between a pattern measurement vector of dimensionality D and the center of the class it belongs to is distributed as a chi(2) with D degrees of freedom. However, the distribution of Mahalanobis distance becomes either Fisher or Beta depending on whether cross validation or resubstitution is used for parameter estimation in finite training sets. The total variation between chi(2) and Fisher, as well as between chi(2) and Beta, allows us to measure the information loss in high dimensions. The information loss is exploited then to set a lower limit for the correct classification rate achieved by the Bayes classifier that is used in subset feature selection.	[Ververidis, Dimitrios; Kotropoulos, Constantine, Sr.] Aristotle Univ Thessaloniki, Dept Informat, GR-54124 Thessaloniki, Greece	Aristotle University of Thessaloniki	Ververidis, D (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Univ Campus,Box 451, GR-54124 Thessaloniki, Greece.	jimver@otenet.gr; costas@aiia.csd.auth.gr	Kotropoulos, Constantine/AAI-2364-2019; Kotropoulos, Constantine L/B-7928-2010	Kotropoulos, Constantine/0000-0001-9939-7930; Kotropoulos, Constantine L/0000-0001-9939-7930; Ververidis, Dimitrios/0000-0001-7799-6502				Abramowitz M., 1972, HDB MATH FUNCTIONS, V10; Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Anderson T. W, 1984, INTRO MULTIVARIATE S; Corless RM, 1996, ADV COMPUT MATH, V5, P329, DOI 10.1007/BF02124750; Devijver PA, 1982, PATTERN RECOGNITION; Ding Chris, 2005, Journal of Bioinformatics and Computational Biology, V3, P185, DOI 10.1142/S0219720005001004; Duda R.O., 1973, J ROYAL STAT SOC SER; FOLEY DH, 1972, IEEE T INFORM THEORY, V18, P618, DOI 10.1109/TIT.1972.1054863; FUKUNAGA K, 1989, IEEE T PATTERN ANAL, V11, P873, DOI 10.1109/34.31448; GORMAN RP, 1988, NEURAL NETWORKS, V1, P75, DOI 10.1016/0893-6080(88)90023-8; HIGHLEYMAN WH, 1962, AT&T TECH J, V41, P723, DOI 10.1002/j.1538-7305.1962.tb02426.x; Hoffsis GF, 1996, COMP CONT EDUC PRACT, V18, P7; Kononenko I, 1997, APPL INTELL, V7, P39, DOI 10.1023/A:1008280620621; Liese F, 2006, IEEE T INFORM THEORY, V52, P4394, DOI 10.1109/TIT.2006.881731; Papoulis A, 2002, PROBABILITY RANDOM V, V4th; Pearson RL, 2000, J AIR WASTE MANAGE, V50, P175, DOI 10.1080/10473289.2000.10463998; PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9; Raudys S, 2001, IEEE T PATTERN ANAL, V23, P233, DOI 10.1109/34.908975; RAUDYS S, 1980, IEEE T PATTERN ANAL, V2, P243; Raudys S, 1997, IEEE T PATTERN ANAL, V19, P667, DOI 10.1109/34.601254; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Van der Heijden F., 2004, CLASSIFICATION PARAM; Vapnik V.N, 1998, STAT LEARNING THEORY; Ververidis D., 2006, P EUR SIGN PROC C; Ververidis D, 2008, SIGNAL PROCESS, V88, P2956, DOI 10.1016/j.sigpro.2008.07.001; Ververidis D, 2008, IEEE T SIGNAL PROCES, V56, P2797, DOI 10.1109/TSP.2008.917350; Womack BD, 1999, IEEE T SPEECH AUDI P, V7, P668, DOI 10.1109/89.799692	27	36	38	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2009	31	12					2275	2281		10.1109/TPAMI.2009.84	http://dx.doi.org/10.1109/TPAMI.2009.84			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	511BY	19834146				2022-12-18	WOS:000271140100013
J	Stahl, JS; Wang, S				Stahl, Joachim S.; Wang, Song			Globally optimal grouping for symmetric closed boundaries by combining boundary and region information	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						perceptual organization; edge grouping; boundary detection; boundary symmetry; edge detection; graph models	SHAPE; SEGMENTATION; ORGANIZATION; EXTRACTION; CONTOURS; AXES	Many natural and man-made structures have a boundary that shows a certain level of bilateral symmetry, a property that plays an important role in both human and computer vision. In this paper, we present a new grouping method for detecting closed boundaries with symmetry. We first construct a new type of grouping token in the form of symmetric trapezoids by pairing line segments detected from the image. A closed boundary can then be achieved by connecting some trapezoids with a sequence of gap-filling quadrilaterals. For such a closed boundary, we define a unified grouping cost function in a ratio form: the numerator reflects the boundary information of proximity and symmetry, and the denominator reflects the region information of the enclosed area. The introduction of the region-area information in the denominator is able to avoid a bias toward shorter boundaries. We then develop a new graph model to represent the grouping tokens. In this new graph model, the grouping cost function can be encoded by carefully designed edge weights, and the desired optimal boundary corresponds to a special cycle with a minimum ratio-form cost. We finally show that such a cycle can be found in polynomial time using a previous graph algorithm. We implement this symmetry-grouping method and test it on a set of synthetic data and real images. The performance is compared to two previous grouping methods that do not consider symmetry in their grouping cost functions.	[Stahl, Joachim S.; Wang, Song] Univ S Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA	University of South Carolina; University of South Carolina System; University of South Carolina Columbia	Stahl, JS (corresponding author), Univ S Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA.	stahlj@engr.sc.edu; songwang@engr.sc.edu		Wang, Song/0000-0003-4152-5295				Ahuja R. K., 1993, NETWORK FLOWS THEORY; Alter T, 1998, INT J COMPUT VISION, V27, P51, DOI 10.1023/A:1007953729443; Amir A, 1998, IEEE T PATTERN ANAL, V20, P168, DOI 10.1109/34.659934; [Anonymous], 1985, PERCEPTUAL ORG VISUA; BARDY MJ, 1984, AIM757 MASS I TECHN; BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; Cornelius H., 2006, P C COMP VIS PATT RE, P191; Elder JH, 2003, IEEE T PATTERN ANAL, V25, P661, DOI 10.1109/TPAMI.2003.1201818; ELDER JH, 1996, P 4 EUR C COMP VIS, P399; Forsyth David A, 2012, COMPUTER VISION MODE; GUPTA A, 2005, P IEEE INT C IM PROC, V3, P133; Guy G, 1996, INT J COMPUT VISION, V20, P113, DOI 10.1007/BF00144119; Heijmans HJAM, 1998, IEEE T PATTERN ANAL, V20, P980, DOI 10.1109/34.713363; HUTTENLOCHER DP, 1992, INT J COMPUT VISION, V8, P7, DOI 10.1007/BF00126398; Jacobs DW, 1996, IEEE T PATTERN ANAL, V18, P23, DOI 10.1109/34.476008; Kanizsa G., 1979, ORG VISION; KOVESI PD, 2007, MATLAB FUNCTIONS COM; Lazebnik S., 2004, P BRIT MACH VIS C, V2, P959, DOI DOI 10.5244/C.18.98; Leyton M., 1992, SYMMETRY CAUSALITY; Liu TL, 1998, INT C PATT RECOG, P994, DOI 10.1109/ICPR.1998.711856; Loy G, 2006, LECT NOTES COMPUT SC, V3952, P508; Mahamud S, 2003, IEEE T PATTERN ANAL, V25, P433, DOI 10.1109/TPAMI.2003.1190570; MOHAN R, 1992, IEEE T PATTERN ANAL, V14, P616, DOI 10.1109/34.141553; OGNIEWICZ RL, 1995, PATTERN RECOGN, V28, P343, DOI 10.1016/0031-3203(94)00105-U; Prasad VSN, 2004, IEEE T IMAGE PROCESS, V13, P1559, DOI 10.1109/TIP.2004.837564; Saber E, 1998, PATTERN RECOGN LETT, V19, P669, DOI 10.1016/S0167-8655(98)00044-0; Sarkar S, 1996, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.1996.517115; Shen DG, 1999, IEEE T PATTERN ANAL, V21, P466, DOI 10.1109/34.765657; Shroff H, 1999, IEEE T IMAGE PROCESS, V8, P1388, DOI 10.1109/83.791964; Siddiqi K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P828, DOI 10.1109/ICCV.1999.790307; Stahl JS, 2005, IEEE I CONF COMP VIS, P946; STAHL JS, 2006, P IEEE C COMP VIS PA, V1, P1030; Tenenbaum Jay M, 1983, HUMAN MACHINE VISION, P481; TERZOPOULOS D, 1987, INT J COMPUT VISION, V1, P211, DOI 10.1007/BF00127821; Tuytelaars T, 2003, IEEE T PATTERN ANAL, V25, P418, DOI 10.1109/TPAMI.2003.1190569; Ullman S., 1988, P 2 INT C COMP VIS, P321, DOI DOI 10.1109/CCV.1988.590008; Wang S, 2005, IEEE T PATTERN ANAL, V27, P546, DOI 10.1109/TPAMI.2005.84; Wang S, 2007, INT J COMPUT VISION, V71, P337, DOI 10.1007/s11263-006-8427-2; Williams F., 1996, DRUG DELIV, V3, P81, DOI 10.3109/10717549609031177; ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508; ZHU SC, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P465	42	36	43	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2008	30	3					395	411		10.1109/TPAMI.2007.1186	http://dx.doi.org/10.1109/TPAMI.2007.1186			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	250FT	18195435	Green Published			2022-12-18	WOS:000252286100003
J	Simonson, KM; Drescher, SM; Tanner, FR				Simonson, Katherine M.; Drescher, Steven M., Jr.; Tanner, Franklin R.			A statistics-based approach to binary image registration with uncertainty analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						registration; edge and feature detection; nonparametric statistics; uncertainty; "fuzzy," and probabilistic reasoning; image processing and computer vision	EDGE; PERFORMANCE; ERROR	A new technique is described for the registration of edge-detected images. While an extensive literature exists on the problem of image registration, few of the current approaches include a well-defined measure of the statistical confidence associated with the solution. Such a measure is essential for many autonomous applications, where registration solutions that are dubious (involving poorly focused images or terrain that is obscured by clouds) must be distinguished from those that are reliable ( based on clear images of highly structured scenes). The technique developed herein utilizes straightforward edge pixel matching to determine the "best" among a class of candidate translations. A well-established statistical procedure, the McNemar test, is then applied to identify which other candidate solutions are not significantly worse than the best solution. This allows for the construction of confidence regions in the space of the registration parameters. The approach is validated through a simulation study and examples are provided of its application in numerous challenging scenarios. While the algorithm is limited to solving for two-dimensional translations, its use in validating solutions to higher-order (rigid body, affine) transformation problems is demonstrated.	Sandia Natl Labs, Albuquerque, NM 87185 USA	United States Department of Energy (DOE); Sandia National Laboratories	Simonson, KM (corresponding author), Sandia Natl Labs, POB 5800,Mail Stop 1208, Albuquerque, NM 87185 USA.	kmsimon@sandia.gov; sdresch@sandia.gov; frtanne@sandia.gov	Simonson, Katherine/AAG-5394-2021					Basu M, 2002, IEEE T SYST MAN CY C, V32, P252, DOI 10.1109/TSMCC.2002.804448; BENNETT BM, 1970, BIOMETRICS, V26, P339, DOI 10.2307/2529083; Bickel P.J., 1977, MATH STAT; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; CANNY JF, 1986, IEEE T PATTERN ANAL, V8, P334; DRESCHER SM, 2005, THESIS U NEW MEXICO; Erturk S, 2001, ELECTRON LETT, V37, P1217, DOI 10.1049/el:20010729; Everitt B.S., 1977, ANAL CONTINGENCY TAB; Fitzpatrick JM, 2001, IEEE T MED IMAGING, V20, P917, DOI 10.1109/42.952729; GONZALEZ AI, 2005, UNPUB IMAGESIFTER IN; GREGORICH DT, 2003, IEEE T GEOSCIENCE RE, V41; Heath M, 1998, COMPUT VIS IMAGE UND, V69, P38, DOI 10.1006/cviu.1997.0587; Heath MD, 1997, IEEE T PATTERN ANAL, V19, P1338, DOI 10.1109/34.643893; Kenney CS, 2003, IEEE T PATTERN ANAL, V25, P1437, DOI 10.1109/TPAMI.2003.1240118; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996; Nandy P, 2004, PROC SPIE, V5425, P197, DOI 10.1117/12.541409; Nguyen TB, 2000, PATTERN RECOGN LETT, V21, P805, DOI 10.1016/S0167-8655(00)00045-3; Pope P, 2003, PROC SPIE, V5093, P294, DOI 10.1117/12.485702; Silvey S.D., 1975, REPRINTING MONOGRAPH; SIMONSON KM, 2005, SAND20053118; van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P359, DOI 10.1098/rspb.1998.0303; VENKATESH S, 1992, CVGIP-GRAPH MODEL IM, V54, P23, DOI 10.1016/1049-9652(92)90031-R; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	25	36	40	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2007	29	1					112	125		10.1109/TPAMI.2007.250603	http://dx.doi.org/10.1109/TPAMI.2007.250603			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	104VI	17108387				2022-12-18	WOS:000241988300009
J	Chen, YQ; Rui, Y; Huang, TS				Chen, Yunqiang; Rui, Yong; Huang, Thomas S.			Multicue HMM-UKF for real-time contour tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						parametric contour; HMM; unscented Kalman filters; joint probabilistic matching		We propose an HMM model for contour detection based on multiple visual cues in spatial domain and improve it by joint probabilistic matching to reduce background clutter. It is further integrated with unscented Kalman filter to exploit object dynamics in nonlinear systems for robust contour tracking.	Siemens Corp Res, Princeton, NJ 08540 USA; Microsoft Res, Redmond, WA 98052 USA; Univ Illinois, Beckman Inst, Urbana, IL 61801 USA	Siemens AG; Microsoft; University of Illinois System; University of Illinois Urbana-Champaign	Chen, YQ (corresponding author), Siemens Corp Res, 755 Coll Rd,E, Princeton, NJ 08540 USA.	yunqiang.chen@siemens.com; yongrui@microsoft.com; huang@ifp.uiuc.edu						AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681; Anderson B. D. O., 1979, OPTIMAL FILTERING; Bradski G.R., 1998, COMPUTER VISION FACE; BRICHFIELD S, 1998, P IEEE COMP VIS PATT, P232; Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761; GEIGER D, 1995, IEEE T PATTERN ANAL, V17, P294, DOI 10.1109/34.368194; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Julier SJ, 2004, P IEEE, V92, P401, DOI 10.1109/JPROC.2003.823141; Lafferty J., 2001, CONDITIONAL RANDOM F; Murphy K. P., 1999, P 15 C UNC ART INT; Rasmussen C, 1998, PROC CVPR IEEE, P16, DOI 10.1109/CVPR.1998.698582; Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI [10.1109/MASSP.1986.1165342, 10.1002/0471250953.bia03as18]; Sullivan J, 2001, INT J COMPUT VISION, V44, P111, DOI 10.1023/A:1011818912717; VERMAAK J, 2001, P IEEE INT C AC SPEE	14	36	38	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2006	28	9					1525	1529		10.1109/TPAMI.2006.190	http://dx.doi.org/10.1109/TPAMI.2006.190			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	062NC	16929738				2022-12-18	WOS:000238950800015
J	Lucas, SM; Reynolds, TJ				Lucas, SM; Reynolds, TJ			Learning Deterministic Finite Automata with a smart state labeling evolutionary algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						grammatical inference; finite state automata; random hill climber; evolutionary algorithm		Learning a Deterministic Finite Automaton ( DFA) from a training set of labeled strings is a hard task that has been much studied within the machine learning community. It is equivalent to learning a regular language by example and has applications in language modeling. In this paper, we describe a novel evolutionary method for learning DFA that evolves only the transition matrix and uses a simple deterministic procedure to optimally assign state labels. We compare its performance with the Evidence Driven State Merging ( EDSM) algorithm, one of the most powerful known DFA learning algorithms. We present results on random DFA induction problems of varying target size and training set density. We also study the effects of noisy training data on the evolutionary approach and on EDSM. On noise free data, we find that our evolutionary method outperforms EDSM on small sparse data sets. In the case of noisy training data, we find that our evolutionary method consistently outperforms EDSM, as well as other significant methods submitted to two recent competitions.	Univ Essex, Dept Comp Sci, Colchester CO4 3SQ, Essex, England	University of Essex	Lucas, SM (corresponding author), Univ Essex, Dept Comp Sci, Wivenhoe Pk, Colchester CO4 3SQ, Essex, England.	sml@essex.ac.uk; reynt@essex.ac.uk		Lucas, Simon/0000-0002-3180-7451				ANGELINE PJ, 1994, IEEE T NEURAL NETWOR, V5, P54, DOI 10.1109/72.265960; Beyer HG, 1994, EVOL COMPUT, V2, P381, DOI 10.1162/evco.1994.2.4.381; Cicchello O, 2002, LECT NOTES ARTIF INT, V2484, P37; CICCHELLO O, 2002, J MACHINE LEARNING R, V4, P603; Dupont P., 1994, Grammatical Inference and Applications. Second International Colloquium, ICGI-94 Proceedings, P25; DUPONT P, 1994, P GRAMM INF APPL 2 I, P236; GILES CL, 1990, ADV NEURAL INFORM PR, V0002, P00380; GOMEX J, 2004, P GEN EV COMP C; Juille H, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P776; Kearns M., 1989, Proceedings of the Twenty First Annual ACM Symposium on Theory of Computing, P433, DOI 10.1145/73007.73049; LANG K, 1998, TR98139; Lang K. J., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P45, DOI 10.1145/130385.130390; LANG KJ, 2005, GOWACHIN SERVER; LANGAAS K, 1998, P 6 EUR C MATH OIL R, P1; LANKHORST M, 1995, CSR9502; Lucas S., 1994, Proceedings of the First IEEE Conference on Evolutionary Computation. IEEE World Congress on Computational Intelligence (Cat. No.94TH0650-2), P130, DOI 10.1109/ICEC.1994.350028; LUCAS S, 2004, P GEN EV COMP C; Lucas SM, 2003, IEEE C EVOL COMPUTAT, P351, DOI 10.1109/CEC.2003.1299597; LUCAS SM, 2003, P 6 EUR C GEN PROGR, P130; Luke S, 1999, GECCO-99: PROCEEDINGS OF THE GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P1098; Mitchell M., 1994, ADV NEURAL INFORM PR, V6, P51; Mitchell M., 1998, INTRO GENETIC ALGORI; Oliveira AL, 1998, STRING PROCESSING AND INFORMATION RETRIEVAL - PROCEEDINGS, P81, DOI 10.1109/SPIRE.1998.712986; ONCINA J, 1992, S MACH PERC, V1, P49; PITT L, 1993, J ACM, V40, P95, DOI 10.1145/138027.138042; SCHACHTMAN TR, 1992, BEHAV PROCESS, V26, P1, DOI 10.1016/0376-6357(92)90027-B; SEBBAN M, 2004, P GEN EV COMP C; SEBBAN M, 2003, P INT C MACH LEARN I; Tomita M., 1982, P 4 ANN C COGN SCI S, P105; Trakhtenbrot B.A., 1973, FINITE AUTOMATA; WATROUS RL, 1992, ADV NEUR IN, V4, P309; WYARD P, 1991, P 4 INT C GEN ALG, P514	32	36	51	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2005	27	7					1063	1074		10.1109/TPAMI.2005.143	http://dx.doi.org/10.1109/TPAMI.2005.143			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	925AQ	16013754				2022-12-18	WOS:000229024300006
J	Helzer, A; Barzohar, M; Malah, D				Helzer, A; Barzohar, M; Malah, D			Stable fitting of 2D curves and 3D surfaces by implicit polynomials	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						implicit polynomials; zero-set sensitivity; curve and surface fitting; stable fitting	RECOGNITION	This work deals with fitting 2D and 3D implicit polynomials (IPs) to 2D curves and 3D surfaces, respectively. The zero-set of the polynomial is determined by the IP coefficients and describes the data. The polynomial fitting algorithms proposed in this paper aim at reducing the sensitivity of the polynomial to coefficient errors. Errors in coefficient values may be the result of numerical calculations, when solving the fitting problem or due to coefficient quantization. It is demonstrated that the effect of reducing this sensitivity also improves the fitting tightness and stability of the proposed two algorithms in fitting noisy data, as compared to existing algorithms like the well-known 3L and gradient-one algorithms. The development of the proposed algorithms is based on an analysis of the sensitivity of the zero-set to small coefficient changes and on minimizing a bound on the maximal error for one algorithm and minimizing the error variance for the second. Simulation results show that the proposed algorithms provide a significant reduction in fitting errors, particularly when fitting noisy data of complex shapes with high order polynomials, as compared to the performance obtained by the above mentioned existing algorithms.	Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Helzer, A (corresponding author), Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.	amir_helzer@hotmail.com; meirb@visionsense.com; malah@ee.technion.ac.il	Malah, David/D-2802-2009					BAJAJ C, 1993, ACM T GRAPHIC, V12, P327, DOI 10.1145/159730.159734; BARZOHAR M, 1994, P IAPR INT C PATT RE, V1, P205; Blane MM, 2000, IEEE T PATTERN ANAL, V22, P298, DOI 10.1109/34.841760; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233; Forsyth D. A., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P476, DOI 10.1109/ICCV.1993.378177; Helzer A, 2000, 21ST IEEE CONVENTION OF THE ELECTRICAL AND ELECTRONIC ENGINEERS IN ISRAEL - IEEE PROCEEDINGS, P384, DOI 10.1109/EEEI.2000.924441; Helzer A, 2000, INT C PATT RECOG, P290, DOI 10.1109/ICPR.2000.903542; HELZER A, 2000, THESIS TECHNION ISRA; Keren D, 1999, IEEE T PATTERN ANAL, V21, P31, DOI 10.1109/34.745731; LEI Z, 1996, P IEEE C COMP VIS PA; Lei ZB, 1998, IEEE T PATTERN ANAL, V20, P212, DOI 10.1109/34.659942; ODEN C, 2001, P 3 INT C AUD VID BA; SEDERBERG TW, 1984, COMPUT VISION GRAPH, V28, P72, DOI 10.1016/0734-189X(84)90140-3; Subrahmonia J, 1996, IEEE T PATTERN ANAL, V18, P505, DOI 10.1109/34.494640; Tarel JP, 2000, IEEE T PATTERN ANAL, V22, P663, DOI 10.1109/34.865183; TAREL JP, 1998, P INT C IM PROC OCT; Tasdizen T, 2000, IEEE T IMAGE PROCESS, V9, P405, DOI 10.1109/83.826778; Tasdizen T, 2000, INT C PATT RECOG, P225, DOI 10.1109/ICPR.2000.905308; TAUBIN G, 1994, IEEE T PATTERN ANAL, V16, P287, DOI 10.1109/34.276128; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273	20	36	39	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2004	26	10					1283	1294		10.1109/TPAMI.2004.91	http://dx.doi.org/10.1109/TPAMI.2004.91			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	844EM	15641716				2022-12-18	WOS:000223140200004
J	Liao, XJ; Carin, L				Liao, XJ; Carin, L			Application of the theory of optimal experiments to adaptive electromagnetic-induction sensing of buried targets	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						optimal experiment; sensing; adaptive processing		A mobile electromagnetic-induction (EMI) sensor is considered for detection and characterization of buried conducting and/or ferrous targets. The sensor may be placed on a robot and, here, we consider design of an optimal adaptive-search strategy. A frequency-dependent magnetic-dipole model is used to characterize the target at EMI frequencies. The goal of the search is accurate characterization of the dipole-model parameters, denoted by the vector Theta; the target position and orientation are a subset of Theta. The sensor position and operating frequency are denoted by the parameter vector p and a measurement is represented by the pair (p, O), where O denotes the observed data. The parameters p are fixed for a given measurement, but, in the context of a sequence of measurements p may be changed adaptively. In a locally optimal sequence of measurements, we desire the optimal sensor parameters, p(N+1) for estimation of Theta, based on the previous measurements (p(n), O-n)(n=1,N). The search strategy is based on the theory of optimal experiments, as discussed in detail and demonstrated via several numerical examples.	Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA	Duke University	Liao, XJ (corresponding author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.	xjliao@ee.duke.edu; lcarin@ee.duke.edu		Carin, Lawrence/0000-0001-6277-7948				ABDELSAMAD AA, 1999, P 1999 INT C IM PROC, V3, P862; Carin L, 2001, IEEE T GEOSCI REMOTE, V39, P1206, DOI 10.1109/36.927442; CASTANON DA, 1995, IEEE T SYST MAN CYB, V25, P1130, DOI 10.1109/21.391293; Chernoff H., 1972, SEQUENTIAL ANAL OPTI; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; Fedorov V.V., 1972, THEORY OPTIMAL EXPT; Geng N, 1999, IEEE T GEOSCI REMOTE, V37, P347, DOI 10.1109/36.739068; Kastella K, 1997, IEEE T SYST MAN CY A, V27, P112, DOI 10.1109/3468.553230; Kay S. M., 1993, FUNDAMENTALS STAT SI; LINDLEY DV, 1956, ANN MATH STAT, V27, P986, DOI 10.1214/aoms/1177728069; MACKAY DJC, 1992, NEURAL COMPUT, V4, P590, DOI 10.1162/neco.1992.4.4.590; SIMMONS JA, 1989, COGNITION, V33, P155, DOI 10.1016/0010-0277(89)90009-7; Whaite P, 1997, IEEE T PATTERN ANAL, V19, P193, DOI 10.1109/34.584097; WRIGHT MH, 1997, PRACTICAL OPTIMIZATI; Zhang Y, 2003, IEEE T GEOSCI REMOTE, V41, P1005, DOI 10.1109/TGRS.2003.810922	15	36	36	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2004	26	8					961	972		10.1109/TPAMI.2004.38	http://dx.doi.org/10.1109/TPAMI.2004.38			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	827BE	15641727	Green Submitted			2022-12-18	WOS:000221872400001
J	Kim, IJ; Kim, JH				Kim, IJ; Kim, JH			Statistical character structure modeling and its application to handwritten Chinese character recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						character recognition; statistical character structure modeling; model-driven stroke extraction; selective matching; heuristic search		This paper proposes a statistical character structure modeling method. It represents each stroke by the distribution of the feature points. The character structure is represented by the joint distribution of the component strokes. In the proposed model, the stroke relationship is effectively reflected by the statistical dependency. It can represent all kinds of stroke relationship effectively in a systematic way. Based on the character representation, a stroke neighbor selection method is also proposed. It measures the importance of a stroke relationship by the mutual information among the strokes. With such a measure, the important neighbor relationships are selected by the nth order probability approximation method. The neighbor selection algorithm reduces the complexity significantly because we can reflect only some important relationships instead of all existing relationships. The proposed character modeling method was applied to a handwritten Chinese character recognition system. Applying a model-driven stroke extraction algorithm that cooperates with a selective matching algorithm, the proposed system is better than conventional structural recognition systems in analyzing degraded images. The effectiveness of the proposed methods was visualized by the experiments. The proposed method successfully detected and reflected the stroke relationships that seemed intuitively important. The overall recognition rate was 98.45 percent, which confirms the effectiveness of the proposed methods.	Inzisoft Co Ltd, Seoul 135920, South Korea; Korea Adv Inst Sci & Technol, Dept Comp Sci, Taejon 305701, South Korea	Korea Advanced Institute of Science & Technology (KAIST)	Kim, IJ (corresponding author), Inzisoft Co Ltd, 7F Sambong Bldg,720-20 Yeoksamdong, Seoul 135920, South Korea.		Kim, Jin Hyung/C-1923-2011					CHEN LH, 1990, PATTERN RECOGN, V23, P1189, DOI 10.1016/0031-3203(90)90115-2; Cheng FH, 1998, PATTERN RECOGN, V31, P401, DOI 10.1016/S0031-3203(97)00053-8; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; CHRIS KY, 1998, P 11 INT C PATT REC, P1130; DUDA RO, 1973, PATTERN CLASSIFICATI, P337; HAN DH, 1998, J KOREA INFORMATIO B, V25, P1381; Kang HJ, 1997, ENG APPL ARTIF INTEL, V10, P379, DOI 10.1016/S0952-1976(97)00020-1; Kim HY, 2001, PATTERN RECOGN, V34, P187, DOI 10.1016/S0031-3203(99)00222-8; KIM HY, 2000, P 4 CHAR REC WORKSH, P123; LEE HJ, 1992, PATTERN RECOGN, V25, P543, DOI 10.1016/0031-3203(92)90052-K; Lewis PM., 1959, INF CONTROL, V2, P214, DOI 10.1016/S0019-9958(59)90207-4; Liu C.L., 1998, P 6 INT WORKSH FRONT, P547; Liu CL, 2001, PATTERN RECOGN, V34, P2339, DOI 10.1016/S0031-3203(00)00165-5; MOON TK, 2003, INFORMATION THEORY L; MYCHKA D, 2003, S BOULDER GUIDE SPAT; Nagasaki T., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P229, DOI 10.1109/ICDAR.1999.791766; YAMADA H, 1990, PATTERN RECOGN, V23, P1023, DOI 10.1016/0031-3203(90)90110-7; Zhang XH, 1983, PATTERN RECOGN LETT, V1, P259, DOI 10.1016/0167-8655(83)90035-1	18	36	40	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2003	25	11					1422	1436		10.1109/TPAMI.2003.1240117	http://dx.doi.org/10.1109/TPAMI.2003.1240117			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	733NG					2022-12-18	WOS:000186006800008
J	van Wyk, MA; Durrani, TS; van Wyk, BJ				van Wyk, MA; Durrani, TS; van Wyk, BJ			A RKHS interpolator-based graph matching algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						graph matching; attributed relational graphs; reproducing kernel Hilbert space theory; combinatorial optimization; neural networks; pattern matching; image processing	RELAXATION LABELING PROCESSES; PATTERN-RECOGNITION; PROBABILISTIC RELAXATION; DISCRETE RELAXATION; EM ALGORITHM; INVARIANT; SUBGRAPH	In this paper, we present a novel algorithm for performing attributed graph matching. This algorithm is derived from a generalized framework for describing functionally expanded interpolators [1] which is based on the theory of reproducing kernel Hilbert spaces. The algorithm incorporates a general approach to a wide class of graph matching problems based on attributed graphs, allowing the structure of the graphs to be based on multiple sets of attributes. No assumption is made about the adjacency structure of the graphs to be matched.	Rand Afrikaans Univ, Cybernet Lab, ZA-2006 Gauteng, South Africa; Univ Strathclyde, Dept Elect & Elect Engn, Glasgow G1 1XW, Lanark, Scotland	University of Johannesburg; University of Strathclyde	van Wyk, MA (corresponding author), Rand Afrikaans Univ, Cybernet Lab, POB 524,Auckland Pk, ZA-2006 Gauteng, South Africa.			Van Wyk, Barend/0000-0002-2222-4393				Allen R, 1997, IEEE T PARALL DISTR, V8, P490, DOI 10.1109/71.598276; ALMOHAMAD HA, 1991, APPL MATH MODEL, V15, P216, DOI 10.1016/0307-904X(91)90011-D; ALMOHAMAD HA, 1993, IEEE T PATTERN ANAL, V15, P522, DOI 10.1109/34.211474; Bunke H, 1998, PATTERN RECOGN LETT, V19, P255, DOI 10.1016/S0167-8655(97)00179-7; Bunke H, 1997, INT J PATTERN RECOGN, V11, P169, DOI 10.1142/S0218001497000081; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; Cochocki A., 1993, NEURAL NETWORKS OPTI; Cross ADJ, 1998, IEEE T PATTERN ANAL, V20, P1236, DOI 10.1109/34.730557; Cross ADJ, 1997, PATTERN RECOGN, V30, P953, DOI 10.1016/S0031-3203(96)00123-9; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; De Figueiredo RJ., 1993, NONLINEAR FEEDBACK C; Depiero F, 1996, PATTERN RECOGN, V29, P1031, DOI 10.1016/0031-3203(95)00140-9; ESHERA MA, 1984, IEEE T SYST MAN CYB, V14, P398, DOI 10.1109/TSMC.1984.6313232; Finch AM, 1998, PATTERN RECOGN, V31, P1777, DOI 10.1016/S0031-3203(98)00010-7; Garey M., 1979, GUIDE NP COMPLETENES; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; HALMOS PR, 1964, MEASURE THEORY; Haykin S., 2014, ADAPTIVE FILTER THEO, V5th ed.; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; KITCHEN L, 1980, IEEE T SYST MAN CYB, V10, P96; KITCHEN L, 1979, IEEE T SYST MAN CYB, V9, P869; LI JT, 1994, IEEE T KNOWL DATA EN, V6, P559; LI SZ, 1992, PATTERN RECOGN, V25, P583, DOI 10.1016/0031-3203(92)90075-T; LU SY, 1984, IEEE T PATTERN ANAL, V6, P249, DOI 10.1109/TPAMI.1984.4767511; Luenberger D. G., 1969, OPTIMIZATION VECTOR; MATULA DW, 1968, SIAM REV, V10, P273; MJOLSNESS E, 1990, NEURAL NETWORKS, V3, P651, DOI 10.1016/0893-6080(90)90055-P; Mjolsness E, 1989, NEURAL COMPUT, V1, P218, DOI 10.1162/neco.1989.1.2.218; Noble B., 1988, APPL LINEAR ALGEBRA; Papadimitriou C. H., 1982, COMBINATORIAL OPTIMI; PELEG S, 1980, IEEE T PATTERN ANAL, V2, P362, DOI 10.1109/TPAMI.1980.4767035; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; PELILLO M, 1994, IEEE T PATTERN ANAL, V16, P933, DOI 10.1109/34.310691; PENG MK, 1995, INT J ELEC ENG EDUC, V32, P31, DOI 10.1177/002072099503200104; RANGARAJAN A, 1994, IEEE INT C NEUR NETW, V7, P4629; REYNER SW, 1977, SIAM J COMPUT, V6, P730, DOI 10.1137/0206053; SASHA D, 1994, IEEE T SYST MAN CYB, V24, P668; Shams S, 1995, NEURAL NETWORKS, V8, P1439, DOI 10.1016/0893-6080(95)00065-8; SHAPIRO LG, 1981, IEEE T PATTERN ANAL, V3, P504, DOI 10.1109/TPAMI.1981.4767144; Simic PD, 1991, NEURAL COMPUT, V3, P268, DOI 10.1162/neco.1991.3.2.268; TSAI WH, 1983, IEEE T SYST MAN CYB, V13, P48, DOI 10.1109/TSMC.1983.6313029; TSAI WH, 1979, IEEE T SYST MAN CYB, V9, P757, DOI 10.1109/TSMC.1979.4310127; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; Van den Bout D E, 1990, IEEE Trans Neural Netw, V1, P192, DOI 10.1109/72.80231; van Wyk M.A., 2001, PROBLEMS APPL MATH C, P67; van Wyk MA, 2000, IEEE T SIGNAL PROCES, V48, P3559, DOI 10.1109/78.887048; VANWYK BJ, 2000, P 3 EUR DSP C ED RES; VANWYK BJ, 2000, P INT WORKSH MULT DE, P280; VANWYK MA, 1999, P PRASA WORKSH NOV; VANWYK MA, 1997, CHAOS ELECT SERIES M, V2; VONDERMALSBURG C, 1988, NEURAL NETWORKS, V1, P141, DOI 10.1016/0893-6080(88)90016-0; Williams ML, 1997, PATTERN RECOGN LETT, V18, P1275, DOI 10.1016/S0167-8655(97)00117-7; Wilson RC, 1997, IEEE T PATTERN ANAL, V19, P634, DOI 10.1109/34.601251; Wilson RC, 1996, PATTERN RECOGN LETT, V17, P263, DOI 10.1016/0167-8655(95)00115-8; You M., 1984, P ICPR, P316; YU SS, 1992, PATTERN RECOGN, V25, P197, DOI 10.1016/0031-3203(92)90101-N	56	36	36	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2002	24	7					988	995		10.1109/TPAMI.2002.1017624	http://dx.doi.org/10.1109/TPAMI.2002.1017624			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	566UF					2022-12-18	WOS:000176446100010
J	Chesi, G; Garulli, A; Vicino, A; Cipolla, R				Chesi, G; Garulli, A; Vicino, A; Cipolla, R			Estimating the fundamental matrix via constrained least-squares: A convex approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						stereo vision; fundamental matrix; convex optimization; linear matrix inequality		In this paper, a new method for the estimation of the fundamental matrix from point correspondences is presented, The minimization of the algebraic error is performed while taking explicitly into account the rank-two constraint on the fundamental matrix. It is shown how this nonconvex optimization problem can be solved avoiding local minima by using recently developed convexification techniques. The obtained estimate of the fundamental matrix turns out to be more accurate than the one provided by the linear criterion, where the rank constraint of the matrix is imposed after its computation by setting the smallest singular value to zero. This suggests that the proposed estimate can be used to initialize nonlinear criteria, such as the distance to epipolar lines and the gradient criterion, in order to obtain a more accurate estimate of the fundamental matrix.	Univ Siena, Dipartimento Ingn Informaz, I-53100 Siena, Italy; Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England	University of Siena; University of Cambridge	Chesi, G (corresponding author), Univ Siena, Dipartimento Ingn Informaz, Via Roma,56, I-53100 Siena, Italy.	chesi@dii.unisi.it; garulli@dii.unisi.it; vicino@dii.unisi.it; cipolla@eng.cam.ac.uk	Arandjelović, Ognjen/V-5255-2019; Chesi, Graziano/C-1575-2009	Arandjelović, Ognjen/0000-0002-9314-194X; Chesi, Graziano/0000-0003-4214-4224; GARULLI, Andrea/0000-0002-4174-073X; Cipolla, Roberto/0000-0002-8999-2151; VICINO, Antonio/0000-0002-7969-4054				Boyd S., 1994, SIAM; Chesi G, 1999, LECT NOTES CONTR INF, V245, P359; DERICHE R, 1994, P 3 EUR C COMP VIS; FAUGERAS O, 1995, J OPT SOC AM A, V12, P465, DOI 10.1364/JOSAA.12.000465; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; HARTLEY RI, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1064; Hartley RI, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P469, DOI 10.1109/ICCV.1998.710760; Luong QT, 1997, INT J COMPUT VISION, V22, P261, DOI 10.1023/A:1007982716991; Luong QT, 1996, INT J COMPUT VISION, V17, P43, DOI 10.1007/BF00127818; Nesterov YuE., 1993, INTERIOR POINT POLYN; Torr PHS, 1997, MACH VISION APPL, V9, P321, DOI 10.1007/s001380050051; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561	13	36	38	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2002	24	3					397	401		10.1109/34.990139	http://dx.doi.org/10.1109/34.990139			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	524WM		Green Submitted			2022-12-18	WOS:000174035900008
J	Rushing, JA; Ranganath, HS; Hinke, TH; Graves, SJ				Rushing, JA; Ranganath, HS; Hinke, TH; Graves, SJ			Using association rules as texture features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						texture; segmentation; association rules; data mining	IMAGE SEGMENTATION; DISCRIMINATION; CLASSIFICATION; FILTERS	A new type of texture feature based on association rules is proposed in this paper. Association rules have been used in applications such as market basket analysis to capture relationships present among items in large data sets. It is shown that association rules can be adapted to capture frequently occurring local structures in images. Association rules capture both structural and statistical information, and automatically identifies the structures that occur most frequently and relationships that have significant discriminative power. Methods for classification and segmentation of textured images using association rules as texture features are described. Simulation results using images consisting of man made and natural textures show that association rule features perform well compared to other widely used texture features. It is shown that association rule features can distinguish texture pairs with identical first, second, and third order statistics, and texture pairs that are not easily discriminable visually.	Intel Corp, Santa Clara, CA 95052 USA; Univ Alabama, Dept Comp Sci, Huntsville, AL 35899 USA; NASA, Ames Res Ctr, Moffett Field, CA 94035 USA; Univ Alabama, Informat Technol & Syst Ctr, Huntsville, AL 35899 USA	Intel Corporation; University of Alabama System; University of Alabama Huntsville; National Aeronautics & Space Administration (NASA); NASA Ames Research Center; University of Alabama System; University of Alabama Huntsville	Rushing, JA (corresponding author), Intel Corp, 2200 Miss Coll Blvd, Santa Clara, CA 95052 USA.	john.a.rushing@intel.com; ranganat@cs.uah.edu; thinke@mail.arc.nasa.gov; sgraves@itsc.uah.edu						AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415; Azencott R, 1997, IEEE T PATTERN ANAL, V19, P148, DOI 10.1109/34.574796; BIGUN J, 1994, IEEE T PATTERN ANAL, V16, P80, DOI 10.1109/34.273714; BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668; BIGUN J, 1993, PATTERN RECOGN LETT, V14, P573, DOI 10.1016/0167-8655(93)90108-P; CAELLI T, 1978, BIOL CYBERN, V29, P201, DOI 10.1007/BF00337276; CHAUDHURI BB, 1995, IEEE T PATTERN ANAL, V17, P72, DOI 10.1109/34.368149; CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641; CHU A, 1990, PATTERN RECOGN LETT, V11, P415, DOI 10.1016/0167-8655(90)90112-F; Duda R.O., 1973, J ROYAL STAT SOC SER; FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594; Gonzalez R C, 1992, DIGITAL IMAGE PROCES; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HOUTSMA M, 1995, PROC INT CONF DATA, P25, DOI 10.1109/ICDE.1995.380413; Jain AK, 1996, IEEE T PATTERN ANAL, V18, P195, DOI 10.1109/34.481543; JULESZ B, 1986, BIOL CYBERN, V54, P247; Lent B., 1997, P 13 INT C DAT ENG; LI W, 1996, SPIE NONLINEAR IMAGE, V7, P24; LONNESTAD T, 1992, P 11 IAPR INT C PATT, V3, P676; SCHROETER P, 1995, PATTERN RECOGN, V28, P695, DOI 10.1016/0031-3203(94)00133-7; Srikant R., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining, P67; Toivonen H, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P134; WU C, 1994, SPIE NEURAL STOCHAST, V3, P86	23	36	38	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2001	23	8					845	858		10.1109/34.946988	http://dx.doi.org/10.1109/34.946988			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	460AH					2022-12-18	WOS:000170283300005
J	Pena, JM; Lozano, JA; Larranaga, P; Inza, I				Pena, JM; Lozano, JA; Larranaga, P; Inza, I			Dimensionality reduction in unsupervised learning of conditional Gaussian networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						data clustering; conditional Gaussian networks; feature selection; edge exclusion tests	FEATURE SUBSET-SELECTION; EM ALGORITHM; MODELS	This paper introduces a novel enhancement for unsupervised learning of conditional Gaussian networks that benefits from feature selection. Our proposal is based on the assumption that, in the absence of labels reflecting the cluster membership of each case of the database, those features that exhibit low correlation with the rest of the features can be considered irrelevant for the learning process. Thus, we suggest performing this process using only the relevant features. Then, every irrelevant feature is added to the learned model to obtain an explanatory model for the original database which is our primary goal. A simple and, thus, efficient measure to assess the relevance of the features for the learning process is presented. Additionally, the form of this measure allows us to calculate a relevance threshold to automatically identify the relevant features. The experimental results reported for synthetic and real-world databases show the ability of our proposal to distinguish between relevant and irrelevant features and to accelerate learning; however, still obtaining good explanatory models for the original database.	Univ Basque Country, Dept Comp Sci & Artificial Intelligence, Intelligent Syst Grp, E-20080 Donostia San Sebastian, Spain	University of Basque Country	Pena, JM (corresponding author), Univ Basque Country, Dept Comp Sci & Artificial Intelligence, Intelligent Syst Grp, POB 649, E-20080 Donostia San Sebastian, Spain.	ccbpepaj@si.ehu.es	Lozano, Jose A. A/F-5120-2010; Larranaga, Pedro/F-9293-2013	Lozano, Jose A. A/0000-0002-4683-8111; Larranaga, Pedro/0000-0003-0652-9872; INZA CANO, INAKI/0000-0003-4674-1755				Anderberg MR, 1973, CLUSTER ANAL APPL; BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201; Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1023/A:1022649401552; DAHS M, 1997, P 9 IEEE INT C TOOLS, P532; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; DEVANEY M, 1997, P 14 INT C MACH LEAR; Doak J., 1992, CSE9218 U CAL DEP CO; Duda R.O., 1973, J ROYAL STAT SOC SER; FISHER D, 1993, J INTELL INF SYST, V2, P5; Fisher D. H., 1987, Machine Learning, V2, P139, DOI 10.1007/BF00114265; Friedman N, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1277; FRIEDMAN N, 1998, P 14 C UNC ART INT, P129; GEIGER D, 1995, P 10 C UNC ART INT, P235; Geiger D., 1994, MSRTR9410 MICR RES; GOOD IJ, 1952, J ROY STAT SOC B, V14, P107; Hartigan J.A., 1975, CLUSTERING ALGORITHM; Heckerman D, 1995, MSRTR9554 MICR RES; Inza I, 2000, ARTIF INTELL, V123, P157, DOI 10.1016/S0004-3702(00)00052-7; John G.H., 1994, MACHINE LEARNING P 1, DOI 10.1016/B978-1-55860-335-6.50023-4; Kaufman L., 2009, FINDING GROUPS DATA; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; LARRANAGA P, 2001, ESTIMATION DISTRIBUT; Lauritzen S.L., 1996, OXFORD STAT SCI SERI, V17, P298; LAURITZEN SL, 1992, J AM STAT ASSOC, V87, P1098, DOI 10.2307/2290647; LAURITZEN SL, 1989, ANN STAT, V17, P31, DOI 10.1214/aos/1176347003; Liu H, 1998, FEATURE EXTRACTION C, DOI 10. 1007/978-1-4615-5725-8; MCLAGHLAN GJ, 1997, ALGORITHM EXTENSIONS; Meila M, 1998, ADV NEUR IN, V10, P584; MEILA M, 1998, P 14 C UNC ART INT, P386; MEILA M, 1999, THESIS MIT CAMBRIDGE; Merz C.J., 1997, UCI REPOSITORY MACHI; Olshen R., 1984, CLASSIFICATION REGRE; Pena JM, 2000, PATTERN RECOGN LETT, V21, P779, DOI 10.1016/S0167-8655(00)00038-6; PENA JM, 2001, IN PRESS INT J APPRO; PENA JM, 2000, LEARNING CONDITIONAL; Smith PWF, 1998, NATO ADV SCI I D-BEH, V89, P555; Talavera L, 1999, MACHINE LEARNING, PROCEEDINGS, P389; Talavera L., 2000, Intelligent Data Analysis, V4, P19; Thiesson B., 1998, P 14 C UNC ART INT, P504; WETTSCHERECK D, 1995, P 1 INT C CAS BAS RE; Whittaker J., 1990, GRAPHICAL MODELS APP	42	36	36	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2001	23	6					590	603		10.1109/34.927460	http://dx.doi.org/10.1109/34.927460			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	438DC					2022-12-18	WOS:000169037600004
J	Qjidaa, H; Radouane, L				Qjidaa, H; Radouane, L			Robust line fitting in a noisy image by the method of moments	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						line fitting; outliers; inliers; underlying p.d.f.; Legendre moments; maximum entropy principle; clustering	RECONSTRUCTION; SET	The standard least squared distance method of fitting a line to a set of data points is known to be unreliable when the random noise in the input is significant compared with the data correlated to the line itself. Here, we present a new statistical clustering method based on Legendre moment theory and maximum entropy principle for line fitting in a noisy image. We propose a new approach for estimating the underlying probability density function (p.d.f.) of the data set. The p.d.f, is expanded in terms of Legendre polynomials by means of the Legendre moments. The order of the expansion is selected according to the maximum entropy principle (M.E.P.). Then, the points corresponding to the maxima of the p.d.f. will be the true points of the line to be extracted by a chaining algorithm. This approach is directly generalized to multidimensional data. The proposed algorithm was successfully applied to real and simulated noisy line images, with comparison to some well-known methods.	Fac Sci, Dept Phys, LESSI, Fes 30000, Morocco	Sidi Mohamed Ben Abdellah University of Fez	Qjidaa, H (corresponding author), Fac Sci, Dept Phys, LESSI, BP 1796, Fes 30000, Morocco.			Hassan, qjidaa/0000-0003-4505-5243; QJIDAA, Hassan/0000-0003-3067-878X				ABUMOSTAFA YS, 1985, IEEE T PATTERN ANAL, V7, P46, DOI 10.1109/TPAMI.1985.4767617; Cover T., 1988, IEEE T INFORMATION T, V2, P27; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; GERARDO B, 1994, IEEE T PATTERN ANAL, V16, P954; Huber P., 1981, ROBUST STAT; Jaynes E.T., 1982, P IEEE, V70; JOLION JM, 1991, IEEE T PATTERN ANAL, V13, P791, DOI 10.1109/34.85669; KIRYATI N, 1992, IEEE T PATTERN ANAL, V14, P496, DOI 10.1109/34.126810; Li G., 1985, ROBUST REGRESSION EX; Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554; LO CH, 1989, IEEE T PATTERN ANAL, V11, P1053, DOI 10.1109/34.42836; Meer P., 1990, P DARPA IM UND WORKS, P231; ROBERT C, 1991, MODELES STAT LA COLL; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913; THRIFT PR, 1983, COMPUT VISION GRAPH, V21, P383, DOI 10.1016/S0734-189X(83)80050-4; WEISS I, 1989, IEEE T PATTERN ANAL, V11, P325, DOI 10.1109/34.21801; YU XM, 1994, IEEE T PATTERN ANAL, V16, P530, DOI 10.1109/34.291443; ZHUANG XH, 1991, IEEE T SIGNAL PROCES, V39, P1478, DOI 10.1109/78.136565	19	36	38	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1999	21	11					1216	1223		10.1109/34.809115	http://dx.doi.org/10.1109/34.809115			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	259YG					2022-12-18	WOS:000083921100011
J	Zhu, SC				Zhu, SC			Stochastic jump-diffusion process for computing medial axes in Markov random fields	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						medial axis transform; jump-diffusion process; energy minimization; Markov random field		This paper proposes a statistical framework for computing medial axes of 2D shapes. In this paper, the computation of medial axes is posed as a statistical inference problem not as a mathematical transform. This paper contributes to three aspects in computing medial axes. 1) Prior knowledge is adopted for axes and junctions so that axes around junctions are regularized. 2) Multiple interpretations of axes are possible, each being assigned a probability. 3) A novel stochastic jump-diffusion process is proposed for estimating both axes and junctions in Markov random fields. We argue that the stochastic algorithm for computing medial axes is compatible with existing algorithms for image segmentation, such as region growing [31], snake [7], and region competition [26]. Thus, our method provides a new direction for computing medial axes from texture images. Experiments are demonstrated on both synthetic and real 2D shapes. This algorithm has been successfully applied to shape learning and sampling in a companion paper [30].	Ohio State Univ, Dept Comp & Informat Sci, Columbus, OH 43210 USA	University System of Ohio; Ohio State University	Zhu, SC (corresponding author), Ohio State Univ, Dept Comp & Informat Sci, Columbus, OH 43210 USA.							BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; BRADY J, 1984, INT J ROBOTICS REG, V3; Crowley J, 1984, IEEE T PATTERN ANAL, V6; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; GRENANDER U, 1994, J ROYAL STAT SOC B, V56, P97; KASS M, 1987, P INT C COMP VIS ICC; KELLEY MF, 1995, TRCIM9412 MCGILL U; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; KOVACS I, 1994, NATURE; LEE TS, 1996, P 5 INT C COMP NEUR; LEYMARIC F, 1992, IEEE T PATTERN ANAL, V14; Leyton M., 1992, SYMMETRY CAUSALITY M; LI S, 1992, P INT VIS C OCT; Li S., 1995, MARKOV RANDOM FIELD, P1; LIU T, 1998, P INT C COMP VIS BOM; MAVATIA R, 1977, ARTIF INTELL, V8, P77; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; Ogniewicz R. L., 1993, DISCRETE VORONOI SKE; SAPIRO G, 1998, P INT C COMP VIS BOM; SIDDIQI K, 1998, P INT C COMP VIS BOM; TARI S, 1998, P INT C COMP VIS BOM; TSAO YF, 1984, COMPUTER VISION GRAP, V25, P384; WRIGHT M, 1995, IMAGE VISION COMPUTI; Zhu SC, 1999, IEEE T PATTERN ANAL, V21, P1170, DOI 10.1109/34.809110; ZHU SC, 1997, IEEE T PATTERN ANAL, V19; ZHU SC, 1996, INT J COMPUTER VISIO, V20; ZHU SC, 1996, IEEE T PATTERN ANAL, V18; ZHU SC, 1998, P INT C COMP VIS PAT; ZUCKER SW, 1976, COMPUTER VISION GRAP, V5	31	36	39	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1999	21	11					1158	1169		10.1109/34.809109	http://dx.doi.org/10.1109/34.809109			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	259YG					2022-12-18	WOS:000083921100005
J	Huttenlocher, DP; Lilien, RH; Olson, CF				Huttenlocher, DP; Lilien, RH; Olson, CF			View-based recognition using an eigenspace approximation to the Hausdorff measure	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						model-based recognition; Hausdorff matching; subspace methods; image matching	PARTIALLY OCCLUDED OBJECTS	View-based recognition methods, such as those using eigenspace techniques, have been successful for a number of recognition tasks. Such approaches, however, are somewhat limited in their ability to recognize objects that are partly hidden from view or occur against cluttered backgrounds. In order to address these limitations, we have developed a view matching technique based on an eigenspace approximation to the generalized Hausdorff measure. This method achieves the compact storage and fast indexing that are the main advantages of eigenspace view matching techniques, while also being tolerant of partial occlusion and background clutter. The method applies to binary feature maps, such as intensity edges, rather than directly to intensity images.	Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA; Dartmouth Coll, Sudikoff Lab 6211, Hanover, NH 03755 USA; NASA, JPL, Pasadena, CA 91109 USA	Cornell University; Dartmouth College; National Aeronautics & Space Administration (NASA); NASA Jet Propulsion Laboratory (JPL)	Huttenlocher, DP (corresponding author), Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA.	dph@cs.cornell.edu; ryan.h.lilien@dartmouth.edu; olson@robotics.jpl.nasa.gov						HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Krumm J, 1996, PROC CVPR IEEE, P55, DOI 10.1109/CVPR.1996.517053; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Ohba K, 1997, IEEE T PATTERN ANAL, V19, P1043, DOI 10.1109/34.615453; PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814; RUCKLIDGE WJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P457, DOI 10.1109/ICCV.1995.466904; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758; YOSHIMURA S, 1994, P 1994 IEEE RSJ GI I, V3, P2086	8	36	40	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1999	21	9					951	955		10.1109/34.790437	http://dx.doi.org/10.1109/34.790437			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	234TZ					2022-12-18	WOS:000082501600013
J	Zhang, ZY				Zhang, ZY			On the optimization criteria used in two-view motion analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion analysis; multiple-view geometry; 3D reconstruction; optimization criteria; algorithmic comparison; structure from motion; uncalibrated images	EPIPOLAR GEOMETRY; AFFINE; RECOVERY; IMAGES	The three best-known criteria in two-view motion analysis are based, respectively, on the distances between points and their corresponding epipolar lines, on the gradient-weighted epipolar errors, and on the distances between points and the reprojections of their reconstructed points. The last one has a better statistical interpretation, but is, however, significantly slower than the first two. In this paper. I show that, given a reasonable initial guess of the epipolar geometry, the last two criteria are equivalent when the epipoles are at infinity and differ from each other only a little even when the epipoles are in the image, as shown experimentally. The first two criteria are equivalent only when the epipoles are at infinity and when the observed object/scene has the same scale in the two images. This suggests that the second criterion is sufficient in practice because of its computational efficiency. Experiments with several thousand computer simulations and four sets of real data confirm the analysis. The result is valid for both calibrated and uncalibrated images.	Microsoft Res, Redmond, WA 98052 USA	Microsoft	Zhang, ZY (corresponding author), Microsoft Res, 1 Microsoft Way, Redmond, WA 98052 USA.							AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965; FAUGERAS O, 1995, J OPT SOC AM A, V12, P465, DOI 10.1364/JOSAA.12.000465; FAUGERAS OD, 1992, P 2 EUR C COMP VIS S, P563; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Hartley R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P761, DOI 10.1109/CVPR.1992.223179; HARTLEY R, 1993, LECT NOTES COMPUTER, V825, P237; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; HUANG TS, 1994, P IEEE, V82, P252, DOI 10.1109/5.265351; Kanatani K., 1996, STAT OPTIMIZATION GE; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Luong QT, 1996, INT J COMPUT VISION, V17, P43, DOI 10.1007/BF00127818; LUONG QT, 1992, THESIS U PARIS SUD C; OLIENSIS J, 1998, MULTIFRAME STRUCTURE; Reid ID, 1996, INT J COMPUT VISION, V18, P41, DOI 10.1007/BF00126139; SHAPIRO LS, 1995, INT J COMPUT VISION, V16, P147, DOI 10.1007/BF01539553; Stein GP, 1997, PROC CVPR IEEE, P602, DOI 10.1109/CVPR.1997.609387; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074; Xu A., 2018, KINETIC THEORY, DOI [10.1007/978-94-015-8668-9, DOI 10.1007/978]; Zhang TS, 1996, MATER LETT, V27, P161, DOI 10.1016/0167-577X(95)00276-6; ZHANG Z, 1996, INT C PATT REC VIENN, V1, P407; ZHANG Z, 1997, P 15 INT J C ART INT, P1502; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4	24	36	46	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1998	20	7					717	729		10.1109/34.689302	http://dx.doi.org/10.1109/34.689302			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZY930					2022-12-18	WOS:000074677200004
J	Liu, WY; Dori, D				Liu, WY; Dori, D			Incremental arc segmentation algorithm and its evaluation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						arc segmentation; vectorization; performance evaluation; graphics recognition		We present an incremental are segmentation algorithm, which recovers the vectorized are fragments obtained by the vectorization of a piece of are image in a stepwise fashion. Due to proper threshold selection and consistent checking of cocircularity of the assumed are pieces, the algorithm accurately constructs arcs from the vector input. Nearly 200 synthetic arcs, ranging in radius from five to 50 pixels, in open angle from 1/8 pi to 2 pi, and in thickness from one to nine pixels, are used in the experiments and evaluation. Parts of six real drawings. containing about 200 arcs, are also processed. The algorithm works well for are segments greater than 10 pixels in radius, pi/4 in angle, and one pixel in width.	Technion Israel Inst Technol, Fac Ind Engn & Management, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Liu, WY (corresponding author), Technion Israel Inst Technol, Fac Ind Engn & Management, IL-32000 Haifa, Israel.		LIU, Wenyin/C-1345-2012					ASADA H, 1986, IEEE T PATTERN ANAL, V8, P1; DORI D, 1995, IEEE T PATTERN ANAL, V17, P1057, DOI 10.1109/34.473231; HALLARD DH, 1981, PATTERN RECOGN, V13, P111; LIU W, 1996, P 13 INT C PATT REC, V3, P808; LIU W, 1995, P 1 INT WORKSH GRAPH, P53; LIU W, 1996, P 2 IAPR WORKSH DOC, P241; Liu WY, 1997, MACH VISION APPL, V9, P240, DOI 10.1007/s001380050045	7	36	39	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1998	20	4					424	431		10.1109/34.677280	http://dx.doi.org/10.1109/34.677280			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZP214					2022-12-18	WOS:000073729200009
J	Tang, YY; Ma, H; Liu, JM; Li, BF; Xi, DH				Tang, YY; Ma, H; Liu, JM; Li, BF; Xi, DH			Multiresolution analysis in extraction of reference lines from documents with gray level background	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document analysis; wavelets; two-dimensional multiresolution analysis; wavelet decomposition algorithm; sub-image; compactly supported orthonormal wavelets	ORTHONORMAL BASES; DECOMPOSITION; WAVELETS	Based on wavelets, a new theoretical method has been developed to process multi-gray level documents. In this method, two-dimensional multiresolution analysis, wavelet decomposition algorithm, and compactly supported orthonormal wavelets are used to transform a document image into sub-images. According to these sub-images, the reference lines of a multi-gray level document can be extracted, and knowledge about the geometric structure of the document can be acquired. Particularly, this approach is more efficient to process form documents with gray level background. Experiments indicate that this new method can be applied to process documents with promising results.	CONCORDIA UNIV,CTR PATTERN RECOGNIT & MACHINE INTELLIGENCE,MONTREAL,PQ H3G 1M8,CANADA; SICHUAN UNIV,DEPT MATH,CHENGDU 610064,SICHUAN,PEOPLES R CHINA; HONG KONG BAPTIST UNIV,DEPT COMP STUDIES,KOWLOON,HONG KONG; SICHUAN UNIV,DEPT COMP SCI,CHENGDU 610064,SICHUAN,PEOPLES R CHINA	Concordia University - Canada; Sichuan University; Hong Kong Baptist University; Sichuan University	Tang, YY (corresponding author), HONG KONG BAPTIST UNIV,DEPT COMP STUDIES,WATERLOO RD,KOWLOON,HONG KONG.							AGHAJAN HK, 1994, IEEE T PATTERN ANAL, V16, P1057, DOI 10.1109/34.334386; [Anonymous], 1993, IEEE T SIGNAL PROCES, V41, P3213; AUSLANDER L, 1990, SIGNAL PROCESSING, V1; Chui C.K., 1992, INTRO WAVELETS; CHUI CK, 1991, 249 CAT TEX A M U; CHUI CK, 1992, SPRINGER SERIES INFO, V26; CHUI CK, 1991, 250 CAT TEX A M U; CHUI CK, 1991, SPRINGER SERIES INFO, V17; DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199; DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705; GROSSMANN A, 1984, SIAM J MATH ANAL, V15, P723, DOI 10.1137/0515056; HAAR A, 1910, MATH ANN, V69, P227; MALLAT S, 1992, IEEE T INFORM THEORY, V38, P617, DOI 10.1109/18.119727; MALLAT S, 1991, WAVELETS THEIR APPL; Mallat S.G., 1988, THESIS U PENNSYLVANI; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; MALLAT SG, 1989, T AM MATH SOC, V315, P69, DOI 10.2307/2001373; Meyer Y., 1986, SEMINAIRE EDP; Oppenheim A.V., 1989, DISCRETE TIME SIGNAL; ROSENFELD A, 1984, SPRINGER SERIES INFO, V12; SZU HH, 1994, P SOC PHOTO-OPT INS, P2242; TANG YY, 1995, IEEE T SYST MAN CYB, V25, P738, DOI 10.1109/21.376488; TANG YY, 1994, IEEE T KNOWL DATA EN, V6, P3, DOI 10.1109/69.273022; YANG YY, IN PRESS P 17 INT C	24	36	39	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1997	19	8					921	926		10.1109/34.608296	http://dx.doi.org/10.1109/34.608296			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XT987					2022-12-18	WOS:A1997XT98700012
J	Yang, MCK; Lee, JS				Yang, MCK; Lee, JS			Hough transform modified by line connectivity and line thickness	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hough transform; line detection; pattern recognition; likelihood principle; pixel connectivity	CURVE DETECTION; PICTURES	A modified Hough transform based on a likelihood principle of connectivity and thickness is proposed for line detection. It makes short as well as thick line segments easier to detect in a noisy image. Certain desirable properties of the new method are justified by theory and simulations.	USN, RES LAB, WASHINGTON, DC 20375 USA; NATL TSING HUA UNIV, DEPT ELECT ENGN, HSINCHU, TAIWAN	United States Department of Defense; United States Navy; Naval Research Laboratory; National Tsing Hua University	Yang, MCK (corresponding author), UNIV FLORIDA, DEPT STAT, GAINESVILLE, FL 32611 USA.							ANTIQUZZAMAN M, 1992, IEEE T PATTERN ANAL, V14, P1090; COHEN M, 1977, PATTERN RECOGN, V9, P95, DOI 10.1016/0031-3203(77)90020-6; Cressie N, 1991, STAT SPATIAL DATA; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Guy G, 1996, INT J COMPUT VISION, V20, P113, DOI 10.1007/BF00144119; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; KALVIAINEN H, 1995, IMAGE VISION COMPUT, V13, P239, DOI 10.1016/0262-8856(95)99713-B; Kalviainen H., 1995, Theory and Applications of Image Analysis II. Selected Paper from the 9th Scandinavian Conference on Image Analysis, P15; LEAVERS VF, 1993, CVGIP-IMAG UNDERSTAN, V58, P250, DOI 10.1006/ciun.1993.1041; LEUNG DNK, 1993, PATTERN RECOGN LETT, V14, P181, DOI 10.1016/0167-8655(93)90070-T; LI HF, 1989, PATTERN RECOGN, V22, P697, DOI 10.1016/0031-3203(89)90006-X; LI HW, 1986, COMPUT VISION GRAPH, V36, P139, DOI 10.1016/0734-189X(86)90073-3; LIANG P, 1991, J ROBOTIC SYST, V8, P841, DOI 10.1002/rob.4620080607; Princen J., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P92, DOI 10.1109/CVPR.1989.37833; REY MT, 1990, IEEE T GEOSCI REMOTE, V28, P561; RISSE T, 1989, COMPUT VISION GRAPH, V46, P327, DOI 10.1016/0734-189X(89)90036-4; ROM H, 1993, IEEE T PATTERN ANAL, V15, P973, DOI 10.1109/34.254054; SHAASHUA A, 1988, P 2 INT C COMP VIS, P321, DOI DOI 10.1109/CCV.1988.590008; VANVEEN TM, 1981, PATTERN RECOGN, V14, P137, DOI 10.1016/0031-3203(81)90055-8; WILLIAMS LR, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P408, DOI 10.1109/ICCV.1995.466910; XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z; YANG YCK, 1996, 529 U FLOR DEP STAT; YUEN SYK, 1993, IMAGE VISION COMPUT, V11, P295, DOI 10.1016/0262-8856(93)90007-4	23	36	46	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1997	19	8					905	910		10.1109/34.608293	http://dx.doi.org/10.1109/34.608293			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XT987					2022-12-18	WOS:A1997XT98700009
J	Weinshall, D; Werman, M				Weinshall, D; Werman, M			On view likelihood and stability	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						generic views; characteristic views; canonical views; view likelihood; view stability; object recognition; 3D reconstruction; Bayesian vision	RECOGNITION; DISTANCES	We define two measures on views: view likelihood and view stability. View likelihood measures the probability that a certain view of a given 3D object is observed; it may be used to identity typical, or ''characteristic,'' views. View stability measures how little the image changes as the viewpoint is slightly perturbed; it may be used to identify ''generic'' views. Both definitions are shown to be identical up to the prior probability of camera orientations, and determined by the 2D metric used to compare images. We analytically derive the stability and likelihood measures for two feature-based 2D metrics, where the most stable and most likely view is shown to be the flattest view of the 3D shape. Incorporating view likelihood or stability in 3D object recognition and 3D reconstruction increases the chance of robust performance. In particular, we propose to use these measures to enhance 3D object recognition and 3D reconstruction algorithms, by adding a second step where the most likely solution is selected among all feasible solutions. These applications are demonstrated using simulated and real images.			Weinshall, D (corresponding author), HEBREW UNIV JERUSALEM,INST COMP SCI,IL-91904 JERUSALEM,ISRAEL.							ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; ATTNEAVE F, 1956, PSYCHOL BULL, V53, P452, DOI 10.1037/h0044049; Basri R, 1996, IEEE T PATTERN ANAL, V18, P465, DOI 10.1109/34.491630; BENARIE J, 1990, IEEE T PATTERN ANAL, V12, P760, DOI 10.1109/34.57667; BINFORD TO, 1993, IMAGE UNDERSTANDING, P819; BULTHOFF HH, 1987, 1ST P INT C COMP VIS, P295; BURNS JB, 1993, IEEE T PATTERN ANAL, V15, P51, DOI 10.1109/34.184774; CHAKRAVARTY I, 1982, P SOC PHOTO-OPT INST, V336, P37, DOI 10.1117/12.933609; DICKINSON SJ, 1992, IEEE T PATTERN ANAL, V14, P174, DOI 10.1109/34.121788; FREEMAN WT, 1993, P 4 INT C COMP VIS B, P347; GDALYAHU Y, 1996, P 4 EUR C COMP VIS C; HILDRETH EC, 1990, PERCEPT PSYCHOPHYS, V48, P19, DOI 10.3758/BF03205008; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; Kanatani Kenichi, 1990, GROUP THEORETICAL ME, P4; Lamdan Y., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P238, DOI 10.1109/CCV.1988.589995; Rigoutsos I., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P180, DOI 10.1109/CVPR.1993.340991; Tenenbaum Jay M, 1983, HUMAN MACHINE VISION, P481; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; Weinshall D., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P220, DOI 10.1109/CVPR.1993.340986; WERMAN M, 1995, IEEE T PATTERN ANAL, V17, P810, DOI 10.1109/34.400572	21	36	39	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1997	19	2					97	108		10.1109/34.574783	http://dx.doi.org/10.1109/34.574783			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WK728		Green Submitted			2022-12-18	WOS:A1997WK72800001
J	HU, XP; AHUJA, N				HU, XP; AHUJA, N			MATCHING POINT FEATURES WITH ORDERED GEOMETRIC, RIGIDITY, AND DISPARITY CONSTRAINTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						DISPARITY; FEATURE DETECTION; GEOMETRIC CONSISTENCY; MATCHING; MULTIRESOLUTION; POINT FEATURES; RIGIDITY	OPTICAL-FLOW; RECOGNITION; MOTION	This correspondence presents a matching algorithm for obtaining feature point correspondences across images containing rigid objects undergoing different motions. First point features are detected using newly developed feature detectors. Then a variety of constraints are applied starting with simplest and following with more informed ones. First, an intensity-based matching algorithm is applied to the feature points to obtain unique point correspondences. This is followed by the application of a sequence of newly developed heuristic tests involving geometry, rigidity, and disparity. The geometric tests match two-dimensional geometrical relationships among the feature points, the rigidity test enforces the three dimensional rigidity of the object, and the disparity test ensures that no matched feature point in an image could be rematched with another feature, if reassigned another disparity value associated with another matched pair or an assumed match on the epipolar line. The computational complexity is proportional to the numbers of detected feature points in the two images. Experimental results with indoor and outdoor images are presented, which show that the algorithm yields only correct matches for scenes containing rigid objects.	DEPT ELECT & COMP ENGN,URBANA,IL 61801; BECKMAN INSTRUMENTS INC,URBANA,IL 61801		HU, XP (corresponding author), SUN MICROSYST COMP CORP,2550 GARCIA AVE,MT VIEW,CA 94043, USA.							ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; BEAUDET PR, 1978, P INT JOINT C PATTER, P573; Beveridge J. R., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P18, DOI 10.1109/ICPR.1990.118058; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Cheng C.-L., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P173, DOI 10.1109/ICPR.1990.118084; Cohen L., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P416, DOI 10.1109/CVPR.1989.37880; Costa M. S., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P233, DOI 10.1109/ICPR.1990.118101; DERICHE R, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P66; FLYNN PJ, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P263; Gonzalez R.C., 1977, DIGITAL IMAGE PROCES; Grimson W. E. L., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P218, DOI 10.1109/CCV.1988.589993; GRIMSON WEL, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P644; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; GRIMSON WEL, 1987, 1ST P INT C COMP VIS, P93; GU WK, 1987, IEEE T PATTERN ANAL, V9, P390, DOI 10.1109/TPAMI.1987.4767921; HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709; HOFF W, 1987, 1ST P INT C COMP VIS, P284; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Hsieh Y. C., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P136, DOI 10.1109/ICPR.1990.118079; HU X, 1994, INT J PATTERN RECOGN, V8; HU X, 1993, P SPIE C APPLICAT AR; HU X, 1992, P INT JOINT C PATT R, V1, P655; HU X, 1993, THESIS U ILLINOIS UR; KIM WY, 1991, IEEE T PATTERN ANAL, V13, P224, DOI 10.1109/34.75511; Kitchen L, 1982, PATTERN RECOGN LETT, V1, P95, DOI 10.1016/0167-8655(82)90020-4; LAMDAN Y, 1988, JUN P CVPR C ANN ARB, P335; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; Marr D., 1982, VISION; Moravec H., 1977, P 5 INT JOINT C ART, VVolume 1, P584; Moravec H.P., 1979, P 6 INT JOINT C ART, P598; PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077; Rattarangsi A., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P923, DOI 10.1109/ICPR.1990.118242; RODRIGUEZ JJ, 1990, IEEE T PATTERN ANAL, V12, P1138, DOI 10.1109/34.62603; SALARI V, 1990, IEEE T PATTERN ANAL, V12, P87, DOI 10.1109/34.41387; SETHI IK, 1987, IEEE T PATTERN ANAL, V9, P56, DOI 10.1109/TPAMI.1987.4767872; SINGH A, 1990, COMPUT VISION GRAPH, V51, P54, DOI 10.1016/S0734-189X(05)80062-3; WANG XJ, 1990, P INT JOINT C PATTER, P285; WENG J, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P200; WENG J, 1988, DEC P INT C COMP VIS, P64; ZUNIGA OA, 1983, P COMPUT VISION PATT, V7, P30; [No title captured]	42	36	45	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1994	16	10					1041	1049		10.1109/34.329004	http://dx.doi.org/10.1109/34.329004			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PM827					2022-12-18	WOS:A1994PM82700009
J	KANATANI, K				KANATANI, K			UNBIASED ESTIMATION AND STATISTICAL-ANALYSIS OF 3-D RIGID MOTION FROM 2 VIEWS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ERROR ANALYSIS; ESTIMATION; MODEL OF NOISE; STATISTICAL BIAS; 3-D MOTION; UNBIASED ESTIMATION	3-DIMENSIONAL MOTION; KALMAN FILTER; CAMERA ROTATION; STEREO IMAGES; NOISY IMAGES; PARAMETERS; SEQUENCE; UNIQUENESS; ALGORITHMS; OBJECTS	The problem of estimating 3-D rigid motion from point correspondences over two views is formulated as nonlinear least-squares optimization, and the statistical behaviors of the errors in the solution are analyzed by introducing a realistic model of noise described in terms of the covariance matrices of ''N-vectors.'' It is shown that the least-squares solution based on the epipolar constraint is statistically biased. The geometry of this bias is described in both quantitative and qualitative terms. Finally, an unbiased estimation scheme is presented, and random number simulations are conducted to observe its effectiveness.			KANATANI, K (corresponding author), GUNMA UNIV, DEPT COMP SCI, MAEBASHI, GUNMA 371, JAPAN.							AISBETT J, 1990, IEEE T PATTERN ANAL, V12, P1092, DOI 10.1109/34.61709; ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; BROIDA TJ, 1991, IEEE T PATTERN ANAL, V13, P497, DOI 10.1109/34.87338; BROIDA TJ, 1990, IEEE T AERO ELEC SYS, V26, P639, DOI 10.1109/7.55557; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; BROIDA TJ, 1989, J OPT SOC AM A, V6, P879, DOI 10.1364/JOSAA.6.000879; FAUGERAS OD, 1990, INT J COMPUT VISION, V4, P225, DOI 10.1007/BF00054997; HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P1310, DOI 10.1109/34.41368; JERIAN C, 1990, IEEE T PATTERN ANAL, V12, P1150, DOI 10.1109/34.62604; JERIAN CP, 1991, IEEE T SYST MAN CYB, V21, P572, DOI 10.1109/21.97478; KANATANI K, 1988, COMPUT VISION GRAPH, V41, P28, DOI 10.1016/0734-189X(88)90115-6; KANATANI K, 1991, CVGIP-IMAG UNDERSTAN, V54, P333, DOI 10.1016/1049-9660(91)90034-M; KANATANI K, IN PRESS GEOMETRIC C; Kanatani Kenichi, 1990, GROUP THEORETICAL ME, P4; KANATANI KI, 1988, IEEE T PATTERN ANAL, V10, P131, DOI 10.1109/34.3879; KANATANI KI, 1987, COMPUT VISION GRAPH, V39, P328, DOI 10.1016/S0734-189X(87)80185-8; LEE CH, 1991, CVGIP-IMAG UNDERSTAN, V54, P325, DOI 10.1016/1049-9660(91)90033-L; LEE S, 1991, CVGIP-IMAG UNDERSTAN, V54, P244, DOI 10.1016/1049-9660(91)90066-X; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LONGUETHIGGINS HC, 1988, P ROY SOC LOND A MAT, V418, P1, DOI 10.1098/rspa.1988.0071; MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032; NAGEL HH, 1981, COMPUTER, V14, P29, DOI 10.1109/C-M.1981.220560; Netravali A. N., 1989, International Journal of Imaging Systems and Technology, V1, P78, DOI 10.1002/ima.1850010110; PHILIP J, 1991, IEEE T PATTERN ANAL, V13, P61, DOI 10.1109/34.67631; PORRILL J, 1990, IMAGE VISION COMPUT, V8, P37, DOI 10.1016/0262-8856(90)90054-9; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; SPETSAKIS M, 1991, INT J COMPUT VISION, V6, P245, DOI 10.1007/BF00115698; SPETSAKIS ME, 1988, DEC P INT C COMP VIS, P449; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; YOUNG GSJ, 1990, IEEE T PATTERN ANAL, V12, P735, DOI 10.1109/34.57666; ZHUANG X, 1989, COMPUT VISION GRAPH, V46, P175, DOI 10.1016/0734-189X(89)90167-9; ZHUANG XH, 1986, J OPT SOC AM A, V3, P1492, DOI 10.1364/JOSAA.3.001492	37	36	36	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1993	15	1					37	50		10.1109/34.184773	http://dx.doi.org/10.1109/34.184773			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KH085					2022-12-18	WOS:A1993KH08500003
J	PENTLAND, A				PENTLAND, A			PHOTOMETRIC MOTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ALBEDO REFLECTANCE RECOVERY; MOTION ANALYSIS; PROCESSING; MOTION PSYCHOPHYSICS; OPTICAL FLOW; REFLECTANCE MODELING; STRUCTURE FROM MOTION; 3-D SHAPE RECOVERY	MODELS	Optical flow algorithms typically assume that a surface point's imaged intensity does not change with motion and that geometric distortion of the projected surface shape is the dominant effect of motion. Often, however, the situation is precisely the opposite: Photometric motion, the change in a point's imaged intensity as a consequence of object motion, can easily dominate the other effects of motion. Photometric changes can therefore lead to severe errors in shape recovery if not correctly accounted for. In this paper, it will be shown that photometric motion may be used to obtain a closed-form solution for both surface shape and reflectance, and how this solution may be used to enhance the performance of geometrically based structure-from-motion algorithms is discussed. A simple biological mechanism that accomplishes the recovery of both shape and reflectance is demonstrated.	MIT,DEPT CIVIL ENGN,CAMBRIDGE,MA 02138; MIT,NEC COMP & COMMUN CAREER DEV CHAIR,CAMBRIDGE,MA 02138	Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT)	PENTLAND, A (corresponding author), MIT,MEDIA LAB,VIS & MODELING GRP,CAMBRIDGE,MA 02138, USA.							ADELSON E, UNPUB WIENER FILTERI; ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; DAUGMAN J, 1980, VISION RES, V20, P846; HILDRETH EC, 1984, PROC R SOC SER B-BIO, V221, P189, DOI 10.1098/rspb.1984.0030; HORN BKP, 1988, INT J COMPUT VISION, V2, P51, DOI 10.1007/BF00836281; HORN BKP, 1990, INT J COMPUT VISION, V5, P37, DOI 10.1007/BF00056771; HORN BKP, 1978, MIT AI490 MEM; KUBE P, 1988, IEEE T PATTERN ANAL, V10, P704, DOI 10.1109/34.6779; PENTLAND A, 1990, SPATIAL VISION, V4, P165; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P107, DOI 10.1007/BF00127812; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P153, DOI 10.1007/BF00127815; PENTLAND AP, 1982, J OPT SOC AM, V72, P448, DOI 10.1364/JOSA.72.000448; VERRI A, 1987, 1ST P INT C COMP VIS, P171; WATSON AB, 1985, J OPT SOC AM A, V2, P322, DOI 10.1364/JOSAA.2.000322; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479	16	36	38	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1991	13	9					879	890		10.1109/34.93807	http://dx.doi.org/10.1109/34.93807			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GJ180					2022-12-18	WOS:A1991GJ18000003
J	WANG, YP; PAVLIDIS, T				WANG, YP; PAVLIDIS, T			OPTIMAL CORRESPONDENCE OF STRING SUBSEQUENCES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									SUNY STONY BROOK, DEPT COMP SCI, STONY BROOK, NY 11794 USA	State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook								ABE K, 1982, 6TH P INT C PATT REC, P172; ABRAHAMSON K, 1987, SIAM J COMPUT, V16, P1039, DOI 10.1137/0216067; AHO AV, 1989, HDB THEORETICAL COMP; AHO AV, 1976, J ACM, V32, P1; Ballard D.H., 1982, COMPUTER VISION; BARNARD ST, 1982, COMPUT SURV, V14, P553, DOI 10.1145/356893.356896; BURR DJ, 1980, IEEE INT JOINT C PAT, P223; DAN HZ, 1989, PATTERN RECOGN LETT, V9, P117, DOI 10.1016/0167-8655(89)90044-5; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; DEMORI R, 1985, IEEE T PATTERN ANAL, V7, P56, DOI 10.1109/TPAMI.1985.4767618; DOWLING GR, 1974, 2ND P INT JOINT C PA, P249; EILAMTZOREFF T, 1988, THEOR COMPUT SCI, V60, P231, DOI 10.1016/0304-3975(88)90112-0; FU KS, 1982, SYNTACTIC PATTERN RE; HALL PAV, 1980, COMPUT SURV, V12, P381, DOI 10.1145/356827.356830; Hopcroft J.E., 1969, FORMAL LANGUAGES THE; Horn B., 1986, ROBOT VISION, P1; JULESZ B, 1971, F CYCLOPEAN PERCEPTI; KIM YC, 1985, COMPUT VISION PATTER, P289; Kruskal J.B., 1983, TIME WARPS STRING ED; KRUSKAL JB, 1983, TIME WARPS STRING ED, pCH4; LLOYD SA, 1986, PATTERN RECOGN LETT, V4, P273, DOI 10.1016/0167-8655(86)90008-5; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; Marr D., 1982, VISION; MORGAN HL, 1970, COMMUN ACM, V13, P90, DOI 10.1145/362007.362033; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; PAVLIDIS T, 1979, IEEE T PATTERN ANAL, V1, P307, DOI 10.1109/TPAMI.1979.4766928; SAVIR D, 1975, IBM SYST J, V1, P16; SCHWARTZ JT, 1987, INT J ROBOT RES, V6, P29, DOI 10.1177/027836498700600203; WAGNER RA, 1974, COMMUN ACM, V17, P265, DOI 10.1145/360980.360995; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; WANG YP, 1988, BAR CODE RECOGNITION; 1982, UPC SYMBOL SPECIFICA	33	36	39	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1990	12	11					1080	1087		10.1109/34.61707	http://dx.doi.org/10.1109/34.61707			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EH557					2022-12-18	WOS:A1990EH55700005
J	GROSKY, WI; TAMBURINO, LA				GROSKY, WI; TAMBURINO, LA			A UNIFIED APPROACH TO THE LINEAR CAMERA CALIBRATION-PROBLEM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									USAF,DIV SYST AVION,WRIGHT PATTERSON AFB,OH 45433	United States Department of Defense; United States Air Force; US Air Force Research Laboratory	GROSKY, WI (corresponding author), WAYNE STATE UNIV,DEPT COMP SCI,DETROIT,MI 48202, USA.							DIJAK JT, 1984, AFWAL TR841105 TECH; DIJAK JT, 1985, 1985 P IEEE NAT AER, P1382; Duda R.O., 1973, J ROYAL STAT SOC SER; FAIG W, 1975, PHOTOGRAMM ENG REM S, V41, P1479; GANAPATHY S, 1984, P INT C ROBOTICS, P130; Golub G.H., 2013, MATRIX COMPUTATIONS, P357; POSDAMER JL, 1982, COMPUT VISION GRAPH, V18, P1, DOI 10.1016/0146-664X(82)90096-X; SOBEL I, 1974, ARTIF INTELL, V5, P185, DOI 10.1016/0004-3702(74)90029-0; STRAT TM, 1984, OCT P IMAG UND WORKS, P254; TSAI R, 1986, JUN P INT C COMP VIS, P364	10	36	42	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1990	12	7					663	671		10.1109/34.56209	http://dx.doi.org/10.1109/34.56209			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DK894					2022-12-18	WOS:A1990DK89400006
J	GRIMSON, WEL				GRIMSON, WEL			ON THE RECOGNITION OF CURVED OBJECTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											GRIMSON, WEL (corresponding author), MIT, ARTIFICIAL INTELLIGENCE LAB, 545 TECHNOL SQ, CAMBRIDGE, MA 02139 USA.							ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; AYACHE NJ, 1982, 6TH P INT C PATT REC; BAIRD H, 1986, MODEL BASED IMAGE MB; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Barrow H. G., 1971, Machine Intelligence Volume 6, P377; BERZINS V, 1984, COMPUT VISION GRAPH, V27, P195, DOI 10.1016/S0734-189X(84)80043-2; BHANU B, 1984, IEEE T PATTERN ANAL, V6; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; BOLLES RC, 1986, INT J ROBOT RES, V5, P3, DOI 10.1177/027836498600500301; BROWSE RA, 1987, IEEE T PATTERN ANAL, V9, P779, DOI 10.1109/TPAMI.1987.4767984; CHEN PC, 1979, COMPUT VISION GRAPH, V10, P172, DOI 10.1016/0146-664X(79)90049-2; CLEMENS DT, 1986, THESIS MITT DEP ELEC; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; DRUMHELLER M, 1987, IEEE T PATTERN ANAL, V9, P325, DOI 10.1109/TPAMI.1987.4767907; DRUMHELLER M, 1984, THESIS MIT; ETTINGER GJ, 1987, THESIS MIT; FAUGERAS OD, 1983, 8TH P INT JOINT C AR, P996; FAUGERAS OD, 1983, P CVPR 83; FREUDER EC, 1982, J ACM, V29, P24, DOI 10.1145/322290.322292; FREUDER EC, 1978, COMMUN ACM, V21, P958, DOI 10.1145/359642.359654; GASTON PC, 1984, IEEE T PATTERN ANAL, V6, P257, DOI 10.1109/TPAMI.1984.4767518; GOAD C, 1983, P DARPA IMAGE UNDERS; GRIMSON WEL, 1986, IEEE J ROBOT AUTOM, V2, P196, DOI 10.1109/JRA.1986.1087057; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; GRIMSON WEL, 1986, J ACM, V33, P658, DOI 10.1145/6490.6492; HARALICK RM, 1980, ARTIF INTELL, V14, P263, DOI 10.1016/0004-3702(80)90051-X; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; HOROWITZ SL, 1976, J ACM, V23, P368, DOI 10.1145/321941.321956; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; KALVIN A, 1986, INT J ROBOT RES, V5, P38, DOI 10.1177/027836498600500403; KNOLL TF, 1986, IEEE T ROBOTIC AUTOM, V2, P3, DOI 10.1109/JRA.1986.1087031; LOWE DG, 1986, 3 DIMENSIONAL OBJECT, P62; MACKWORTH AK, 1977, ARTIF INTELL, V8, P99, DOI 10.1016/0004-3702(77)90007-8; MACKWORTH AK, 1985, ARTIF INTELL, V25, P65, DOI 10.1016/0004-3702(85)90041-4; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MARTIN WN, 1979, PATTERN RECOGN, V11, P169, DOI 10.1016/0031-3203(79)90004-9; MCKEE JW, 1977, IEEE T COMPUT, V26, P790, DOI 10.1109/TC.1977.1674917; MERLIN PM, 1975, IEEE T COMPUT, VC 24, P96, DOI 10.1109/T-C.1975.224087; MONTANAR.U, 1974, INFORM SCIENCES, V7, P95, DOI 10.1016/0020-0255(74)90008-5; MURRAY DW, 1987, IMAGE VISION COMPUT, V5, P85, DOI 10.1016/0262-8856(87)90032-1; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; PERKINS WA, 1980, 5TH P INT JOINT C PA, P260; POLLARD SB, 1987, IMAGE VISION COMPUT, V5, P73, DOI 10.1016/0262-8856(87)90030-8; RUTKOWSKI WS, 1982, COMPUT VISION GRAPH, V19, P111, DOI 10.1016/0146-664X(82)90103-4; RUTKOWSKI WS, 1981, IEEE T PATTERN ANAL, V3, P368, DOI 10.1109/TPAMI.1981.4767123; SCHWARTZ JT, 1987, INT J ROBOT RES, V6, P29, DOI 10.1177/027836498700600203; SKLANSKY J, 1978, IEEE T COMPUT, V27, P923, DOI 10.1109/TC.1978.1674971; STOCKMAN G, 1984, TR84002 MICH STAT U; TURNEY JL, 1985, IEEE T PATTERN ANAL, V7, P410, DOI 10.1109/TPAMI.1985.4767680; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19	52	36	36	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1989	11	6					632	643		10.1109/34.24797	http://dx.doi.org/10.1109/34.24797			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	U6749		Green Submitted			2022-12-18	WOS:A1989U674900008
J	SELIM, SZ; ISMAIL, MA				SELIM, SZ; ISMAIL, MA			ON THE LOCAL OPTIMALITY OF THE FUZZY ISODATA CLUSTERING-ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV WINDSOR,SCH COMP SCI,WINDSOR N9B 3P4,ONTARIO,CANADA	University of Windsor	SELIM, SZ (corresponding author), UNIV PETR & MINERALS,DEPT SYST ENGN,DHAHRAN 31261,SOUTH AFRICA.		Selim, Shokri Z/F-8743-2014	Selim, Shokri Z/0000-0002-1239-5471				Bazaraa M.S., 1979, NONLINEAR PROGRAMMIN; BAZARAA MS, 1976, LECTURE NOTES EC MAT; BEZDEK J, 1980, IEEE T PATTERN ANAL, V2; Bezdek J.C., 1973, FUZZY MATH PATTERN C; Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046; SELIM SZ, 1984, IEEE T PATTERN ANAL, V6; Zangwill W., 1969, NONLINEAR PROGRAMMIN	7	36	38	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1986	8	2					284	288		10.1109/TPAMI.1986.4767783	http://dx.doi.org/10.1109/TPAMI.1986.4767783			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	A1073	21869348				2022-12-18	WOS:A1986A107300017
J	CHENG, Y; FU, KS				CHENG, Y; FU, KS			CONCEPTUAL CLUSTERING IN KNOWLEDGE ORGANIZATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											CHENG, Y (corresponding author), PURDUE UNIV,SCH ELECT ENGN,ADV AUTOMAT RES LAB,W LAFAYETTE,IN 47907, USA.							Brachman R.J., 1979, ASS NETWORKS REPRESE, P3, DOI 10.1016/B978-0-12-256380-5.50007-4; CHARNIAK E, 1983, P NAT C ARTIFICIAL I, P70; DIDAY E, 1980, DIGITAL PATTERN RECO; FEINSTEIN AR, 1973, YALE J BIOL MED, V46, P264; FEINSTEIN AR, 1973, YALE J BIOL MED, V46, P212; GOLDSTEIN IP, 1979, ARTIFICIAL INTELLIGE, V1, P255; GOMEZ F, 1981, IEEE T SYST MAN CYB, V11, P34, DOI 10.1109/TSMC.1981.4308576; ISHIZUKA M, 1981, TREE8133 PURD U DEP; LENAT DB, 1984, ARTIF INTELL, V23, P269, DOI 10.1016/0004-3702(84)90016-X; Michalski R. S, 1983, MACHINE LEARNING; POLITAKIS P, 1984, ARTIF INTELL, V22, P23, DOI 10.1016/0004-3702(84)90024-9; Winston P. H., 1984, ARTIFICIAL INTELLIGE; WINSTON PH, 1978, ARTIF INTELL, V10, P147, DOI 10.1016/S0004-3702(78)80010-1; 1978, NEIKEXUE, V1	14	36	36	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	5					592	598		10.1109/TPAMI.1985.4767706	http://dx.doi.org/10.1109/TPAMI.1985.4767706			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AQH94	21869296				2022-12-18	WOS:A1985AQH9400010
J	MUTCH, KM; THOMPSON, WB				MUTCH, KM; THOMPSON, WB			ANALYSIS OF ACCRETION AND DELETION AT BOUNDARIES IN DYNAMIC SCENES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MINNESOTA,DEPT COMP SCI,MINNEAPOLIS,MN 55455	University of Minnesota System; University of Minnesota Twin Cities	MUTCH, KM (corresponding author), ARIZONA STATE UNIV,DEPT COMP SCI,TEMPE,AZ 85287, USA.							BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; CLOCKSIN WF, 1980, PERCEPTION, V9, P253, DOI 10.1068/p090253; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; JAIN R, 1979, COMPUT VISION GRAPH, V11, P13, DOI 10.1016/0146-664X(79)90074-1; JAIN R, 1981, IEEE T PATTERN ANAL, V3, P489, DOI 10.1109/TPAMI.1981.4767143; KAPLAN GA, 1969, PERCEPT PSYCHOPHYS, V6, P193, DOI 10.3758/BF03207015; KAPLAN GA, 1968, THESIS CORNELL U ITH; NAKAYAMA K, 1974, PERCEPTION, V3, P63, DOI 10.1068/p030063; POTTER JL, 1977, COMPUT VISION GRAPH, V6, P558, DOI 10.1016/S0146-664X(77)80016-6; THOMPSON WB, 1980, IEEE T PATTERN ANAL, V2, P543, DOI 10.1109/TPAMI.1980.6447701; THOMPSON WB, 1984, 846 U MINN COMP SCI; THOMPSON WB, 1981, COMPUT           AUG; THOMPSON WB, 1982, 2ND NAT C ART INT	13	36	36	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	2					133	138		10.1109/TPAMI.1985.4767638	http://dx.doi.org/10.1109/TPAMI.1985.4767638			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ACP84	21869252				2022-12-18	WOS:A1985ACP8400001
J	VICKERS, AL; MODESTINO, JW				VICKERS, AL; MODESTINO, JW			A MAXIMUM-LIKELIHOOD APPROACH TO TEXTURE CLASSIFICATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											VICKERS, AL (corresponding author), RENSSELAER POLYTECH INST,DEPT ELECT COMP & SYST ENGN,TROY,NY 12181, USA.							BRODATZ P, 1956, TEXTURE PHOTOGRAPHIC; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; MODESTINO JW, 1981, IEEE T PATTERN ANAL, V3, P557, DOI 10.1109/TPAMI.1981.4767148; PAPOULIS A, 1965, PROBABILITY RANDOM V, pCH11; PRATT WK, 1978, DIGITAL IMAGE PROCES, pCH12; Van Trees H., 2013, DETECTION ESTIMATION	7	36	36	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	1					61	68		10.1109/TPAMI.1982.4767197	http://dx.doi.org/10.1109/TPAMI.1982.4767197			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MY534	21869005				2022-12-18	WOS:A1982MY53400011
J	Ding, J; Xue, N; Xia, GS; Bai, X; Yang, W; Yang, MY; Belongie, S; Luo, JB; Datcu, M; Pelillo, M; Zhang, LP				Ding, Jian; Xue, Nan; Xia, Gui-Song; Bai, Xiang; Yang, Wen; Yang, Michael Ying; Belongie, Serge; Luo, Jiebo; Datcu, Mihai; Pelillo, Marcello; Zhang, Liangpei			Object Detection in Aerial Images: A Large-Scale Benchmark and Challenges	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection; Earth; Libraries; Codes; Task analysis; Software algorithms; Software; Object detection; remote sensing; aerial images; oriented object detection; benchmark dataset	SCENE TEXT DETECTION; ROTATION-INVARIANT; VEHICLE DETECTION; TARGET DETECTION	In he past decade, object detection has achieved significant progress in natural images but not in aerial images, due to the massive variations in the scale and orientation of objects caused by the bird's-eye view of aerial images. More importantly, the lack of large-scale benchmarks has become a major obstacle to the development of object detection in aerial images (ODAI). In this paper, we present a large-scale Dataset of Object deTection in Aerial images (DOTA) and comprehensive baselines for ODAI. The proposed DOTA dataset contains 1,793,658 object instances of 18 categories of oriented-bounding-box annotations collected from 11,268 aerial images. Based on this large-scale and well-annotated dataset, we build baselines covering 10 state-of-the-art algorithms with over 70 configurations, where the speed and accuracy performances of each model have been evaluated. Furthermore, we provide a code library for ODAI and build a website for evaluating different algorithms. Previous challenges run on DOTA have attracted more than 1300 teams worldwide. We believe that the expanded large-scale DOTA dataset, the extensive baselines, the code library and the challenges can facilitate the designs of robust algorithms and reproducible research on the problem of object detection in aerial images.	[Ding, Jian; Xia, Gui-Song; Yang, Wen; Zhang, Liangpei] Wuhan Univ, State Key Lab LIESMARS, Wuhan 430079, Hubei, Peoples R China; [Xue, Nan] Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Sch Comp Sci & Inst Artificial Intelligence, Wuhan 430072, Hubei, Peoples R China; [Xia, Gui-Song] Natl Engn Res Ctr Multimedia Software, Sch Comp Sci, Wuhan, Peoples R China; [Xia, Gui-Song] Natl Engn Res Ctr Multimedia Software, Inst Artificial Intelligence, Wuhan, Peoples R China; [Bai, Xiang] Huazhong Univ Sci & Technol, Sch Elect Informat, Wuhan 430072, Hubei, Peoples R China; [Yang, Wen] Wuhan Univ, Sch Elect Informat, Wuhan 430072, Hubei, Peoples R China; [Yang, Michael Ying] Univ Twente, Fac Geoinformat Sci & Earth Observat ITC, NL-7522 NB Enschede, Netherlands; [Belongie, Serge] Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA; [Belongie, Serge] Cornell Tech, Ithaca, NY 14853 USA; [Luo, Jiebo] Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA; [Datcu, Mihai] German Aerosp Ctr DLR, Remote Sensing Technol Inst, NRW, D-82234 Cologne, Germany; [Datcu, Mihai] Univ POLITEHN Bucharest UPB, Bucharest 060042, Romania; [Pelillo, Marcello] Ca Foscari Univ Venice, DAIS, Venice, Italy	Wuhan University; Wuhan University; Huazhong University of Science & Technology; Wuhan University; University of Twente; Cornell University; University of Rochester; Helmholtz Association; German Aerospace Centre (DLR); Universita Ca Foscari Venezia	Xia, GS (corresponding author), Wuhan Univ, State Key Lab LIESMARS, Wuhan 430079, Hubei, Peoples R China.; Xia, GS (corresponding author), Natl Engn Res Ctr Multimedia Software, Sch Comp Sci, Wuhan, Peoples R China.; Xia, GS (corresponding author), Natl Engn Res Ctr Multimedia Software, Inst Artificial Intelligence, Wuhan, Peoples R China.	jian.ding@whu.edu.cn; xuenan@whu.edu.cn; guisong.xia@whu.edu.cn; xbai@hust.edu.cn; yangwen@whu.edu.cn; michael.yang@utwente.nl; sjb344@cornell.edu; jluo@cs.rochester.edu; mihai.datcu@dlr.de; pelillo@unive.it; zlp62@whu.edu.cn	Xue, Nan/HCI-0300-2022	Yang, Wen/0000-0002-3263-8768; Yang, Michael Ying/0000-0002-0649-9987; Datcu, Mihai/0000-0002-3477-9687; Luo, Jiebo/0000-0002-4516-9729; Belongie, Serge/0000-0002-0388-5217; Xia, Gui-Song/0000-0001-7660-6090; Pelillo, Marcello/0000-0001-8992-9243; Bai, Xiang/0000-0002-3449-5940	NSFC [61922065, 61771350, 41820104006]; National Post-Doctoral Program for Innovative Talents [BX20200248]; CNCS-UEFISCDI within PNCDI III [PN-III-P4-ID-PCE-2020-2120]	NSFC(National Natural Science Foundation of China (NSFC)); National Post-Doctoral Program for Innovative Talents; CNCS-UEFISCDI within PNCDI III(Consiliul National al Cercetarii Stiintifice (CNCS)Unitatea Executiva pentru Finantarea Invatamantului Superior, a Cercetarii, Dezvoltarii si Inovarii (UEFISCDI))	This work was supported by the NSFC projects under Grants 61922065, 61771350, and 41820104006. The work of Nan Xue was supported by National Post-Doctoral Program for Innovative Talents under Grant BX20200248. The work of Mihai Datcu was supported by the CNCS-UEFISCDI, project number PN-III-P4-ID-PCE-2020-2120, within PNCDI III.	Benedek C, 2012, IEEE T PATTERN ANAL, V34, P33, DOI 10.1109/TPAMI.2011.94; Buyu Li, 2019, Arxiv, DOI arXiv:1906.07155; Chao Peng, 2017, Arxiv, DOI arXiv:1711.07264; Chen K., 2020, ARXIV; Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511; Chen Y, 2019, J MACH LEARN RES, V20; Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622; Cheng G, 2014, ISPRS J PHOTOGRAMM, V98, P119, DOI 10.1016/j.isprsjprs.2014.10.002; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; de Oca AMM, 2017, IEEE J-STARS, V10, P2462, DOI 10.1109/JSTARS.2017.2697003; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Ding J, 2019, PROC CVPR IEEE, P2844, DOI 10.1109/CVPR.2019.00296; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Girshick R., 2014, PROC IEEE C COMPUT V; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Haibin Ling, 2018, Arxiv, DOI arXiv:1804.07437; Han JM, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3062048; He K., 2017, IEEE INT C COMP VIS, P2961; He YH, 2019, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2019.00300; Heitz G, 2008, LECT NOTES COMPUT SC, V5302, P30, DOI 10.1007/978-3-540-88682-2_4; Hsieh MR, 2017, IEEE I CONF COMP VIS, P4165, DOI 10.1109/ICCV.2017.446; Huang C, 2007, IEEE T PATTERN ANAL, V29, P671, DOI 10.1109/TPAMI.2007.1011; Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351; Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z; LaLonde R, 2018, PROC CVPR IEEE, P4003, DOI 10.1109/CVPR.2018.00421; Lam D., 2018, ARXIV; Li C., 2019, P IEEE CVF C COMP VI, P20; Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023; Li W, 2021, IEEE T IMAGE PROCESS, V30, P4599, DOI 10.1109/TIP.2021.3073319; Liao MH, 2018, PROC CVPR IEEE, P5909, DOI 10.1109/CVPR.2018.00619; Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu K, 2015, IEEE GEOSCI REMOTE S, V12, P1938, DOI 10.1109/LGRS.2015.2439517; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Liu ZK, 2017, IEEE IMAGE PROC, P900; Liu ZK, 2016, IEEE GEOSCI REMOTE S, V13, P1074, DOI 10.1109/LGRS.2016.2565705; Long Y, 2017, IEEE T GEOSCI REMOTE, V55, P2486, DOI 10.1109/TGRS.2016.2645610; Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020; Moranduzzo T, 2014, IEEE T GEOSCI REMOTE, V52, P6356, DOI 10.1109/TGRS.2013.2296351; Mundhenk TN, 2016, LECT NOTES COMPUT SC, V9907, P785, DOI 10.1007/978-3-319-46487-9_48; Pan Xingjia, 2020, P IEEE CVF C COMP VI, P11207, DOI DOI 10.1109/CVPR42600.2020.01122; Pang JM, 2019, IEEE T GEOSCI REMOTE, V57, P5512, DOI 10.1109/TGRS.2019.2899955; Papadopoulos DP, 2017, IEEE I CONF COMP VIS, pCP38, DOI 10.1109/ICCV.2017.528; Porway J, 2010, INT J COMPUT VISION, V88, P254, DOI 10.1007/s11263-009-0306-1; Razakarivony S, 2016, J VIS COMMUN IMAGE R, V34, P187, DOI 10.1016/j.jvcir.2015.11.002; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Reilly V, 2010, LECT NOTES COMPUT SC, V6313, P186; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Sadgrove EJ, 2018, COMPUT IND, V98, P183, DOI 10.1016/j.compind.2018.03.014; Shermeyer J, 2021, IEEE WINT CONF APPL, P207, DOI 10.1109/WACV48630.2021.00025; Shi XP, 2018, PROC CVPR IEEE, P2295, DOI 10.1109/CVPR.2018.00244; Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Uzkent B, 2020, IEEE WINT CONF APPL, P1813, DOI 10.1109/WACV45572.2020.9093447; Wang FF, 2018, PROC CVPR IEEE, P1381, DOI 10.1109/CVPR.2018.00150; Wang JW, 2021, IEEE T GEOSCI REMOTE, V59, P4307, DOI 10.1109/TGRS.2020.3010051; Wang JW, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11242930; Wang XD, 2019, PROC CVPR IEEE, P7281, DOI 10.1109/CVPR.2019.00746; Waqas Zamir S., 2019, P IEEE CVF C COMP VI, P28; Weir N, 2019, IEEE I CONF COMP VIS, P992, DOI 10.1109/ICCV.2019.00108; Wikipedia contributors, 2020, GROUND SAMPL DIST; Wu Y., 2019, DETECTRON2; Wu Z., 2019, PROC BRITISHMACH VIS; Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418; Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Xu YC, 2021, IEEE T PATTERN ANAL, V43, P1452, DOI 10.1109/TPAMI.2020.2974745; Xue Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P677, DOI 10.1007/978-3-030-58598-3_40; Yang F, 2019, IEEE I CONF COMP VIS, P8310, DOI 10.1109/ICCV.2019.00840; Yang MY, 2019, PHOTOGRAMM ENG REM S, V85, P297, DOI 10.14358/PERS.85.4.297; Yang MY, 2018, IEEE IMAGE PROC, P3079, DOI 10.1109/ICIP.2018.8451454; Yang S, 2016, PROC CVPR IEEE, P5525, DOI 10.1109/CVPR.2016.596; Yang X, 2019, IEEE I CONF COMP VIS, P8231, DOI 10.1109/ICCV.2019.00832; You QZ, 2016, AAAI CONF ARTIF INTE, P308; Zhang H, 2020, INT CONF ACOUST SPEE, P1888, DOI 10.1109/ICASSP40776.2020.9053738; Zhang YL, 2019, IEEE T GEOSCI REMOTE, V57, P5535, DOI 10.1109/TGRS.2019.2900302; Zhang ZC, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11202417; Zhou Bolei, 2014, ADV NEURAL INFORM PR, P7, DOI DOI 10.5555/2968826.2968881; Zhou YZ, 2017, PROC CVPR IEEE, P4961, DOI 10.1109/CVPR.2017.527; Zhu HG, 2015, IEEE IMAGE PROC, P3735, DOI 10.1109/ICIP.2015.7351502; Zhu YX, 2020, IEEE T GEOSCI REMOTE, V58, P7247, DOI 10.1109/TGRS.2020.2981203; Zou ZX, 2018, IEEE T IMAGE PROCESS, V27, P1100, DOI 10.1109/TIP.2017.2773199	91	35	35	19	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2022	44	11					7778	7796		10.1109/TPAMI.2021.3117983	http://dx.doi.org/10.1109/TPAMI.2021.3117983			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	5C5UY	34613910	Green Submitted, Green Published			2022-12-18	WOS:000864325900038
J	Sun, G; Cong, Y; Dong, JH; Liu, YY; Ding, ZM; Yu, HB				Sun, Gan; Cong, Yang; Dong, Jiahua; Liu, Yuyang; Ding, Zhengming; Yu, Haibin			What and How: Generalized Lifelong Spectral Clustering via Dual Memory	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Lifelong machine learning; spectral clustering; deep transfer learning; neural networks		Spectral clustering (SC) has become one of the most widely-adopted clustering algorithms, and been successfully applied into various applications. We in this work explore the problem of spectral clustering in a lifelong learning framework termed as Generalized Lifelong Spectral Clustering (GL(2)SC). Different from most current studies, which concentrate on a fixed spectral clustering task set and cannot efficiently incorporate a new clustering task, the goal of our work is to establish a generalized model for new spectral clustering tasks by "What" and "How" to lifelong learn from past tasks. In respect of "what to lifelong learn", our GL(2)SC framework contains a dual memory mechanism with a deep orthogonal factorization manner: an orthogonal basis memory stores hidden and hierarchical clustering centers among learned tasks, and a feature embedding memory captures deep manifold representation common across multiple related tasks. When learning a new clustering task, the intuition here for "how to lifelong learn" is that GL(2)SC can transfer intrinsic knowledge from dual memory mechanism to obtain task-specific encoding matrix. Then the encoding matrix can redefine the dual memory over time to provide maximal benefits when learning future tasks, and reversely maximize performance for past tasks. To achieve this, we propose an alternative optimization formulation with convergence guarantee for solving our GL(2)SC model. To the end, empirical comparisons on several benchmark datasets show the effectiveness of our GL(2)SC, in comparison with several state-of-the-art clustering models.	[Sun, Gan; Cong, Yang; Dong, Jiahua; Liu, Yuyang; Yu, Haibin] Chinese Acad Sci, Shenyang Inst Automat, Inst Robot, State Key Lab Robot, Shenyang 110016, Peoples R China; [Sun, Gan; Cong, Yang; Dong, Jiahua; Liu, Yuyang; Yu, Haibin] Chinese Acad Sci, Shenyang Inst Automat, Inst Intelligent Mfg, State Key Lab Robot, Shenyang 110016, Peoples R China; [Dong, Jiahua; Liu, Yuyang] Univ Chinese Acad Sci, Beijing 100049, Peoples R China; [Ding, Zhengming] Tulane Univ, Dept Comp Sci, New Orleans, LA 70118 USA	Chinese Academy of Sciences; Shenyang Institute of Automation, CAS; Chinese Academy of Sciences; Shenyang Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Tulane University	Cong, Y (corresponding author), Chinese Acad Sci, Shenyang Inst Automat, Inst Robot, State Key Lab Robot, Shenyang 110016, Peoples R China.; Cong, Y (corresponding author), Chinese Acad Sci, Shenyang Inst Automat, Inst Intelligent Mfg, State Key Lab Robot, Shenyang 110016, Peoples R China.	sungan1412@gmail.com; congyang81@gmail.com; dongjiahua1995@gmail.com; liuyuyang@sia.cn; zding1@tulane.edu; yhb@sia.cn			National Key Research and Development Program of China [2019YFB1310300]; National Nature Science Foundation of China [62003336, 61821005, 61722311]; National Postdoctoral Innovative Talents Support Program [BX20200353]; Nature Foundation of Liaoning Province of China [2020-KF-11-01]	National Key Research and Development Program of China; National Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Postdoctoral Innovative Talents Support Program; Nature Foundation of Liaoning Province of China	This work was supported by the National Key Research and Development Program of China (2019YFB1310300), National Nature Science Foundation of China under Grant (62003336, 61821005, and 61722311), National Postdoctoral Innovative Talents Support Program (BX20200353), and Nature Foundation of Liaoning Province of China under Grant (2020-KF-11-01).	Ammar HB, 2014, PR MACH LEARN RES, V32, P1206; Ammar HB, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3345; Chahhou M, 2014, IEEE T PATTERN ANAL, V36, P1687, DOI 10.1109/TPAMI.2013.2297314; Chen ZY, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P750; Dong JH, 2020, PROC CVPR IEEE, P4022, DOI 10.1109/CVPR42600.2020.00408; Dong JH, 2019, IEEE I CONF COMP VIS, P10711, DOI 10.1109/ICCV.2019.01081; Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109; Hinton G., 2015, ARXIV150302531; Isele D., 2016, P 25 INT JOINT C ART, P1620; Isele D, 2018, AAAI CONF ARTIF INTE, P3302; Kang Z, 2018, AAAI CONF ARTIF INTE, P3366; Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Li J, 2022, IEEE T NEUR NET LEAR, V33, P1119, DOI 10.1109/TNNLS.2020.3040379; Li J, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2145; Li ZQ, 2015, PROC CVPR IEEE, P1356, DOI 10.1109/CVPR.2015.7298741; Li ZZ, 2016, LECT NOTES COMPUT SC, V9908, P614, DOI 10.1007/978-3-319-46493-0_37; Liu BY, 2019, IEEE ROBOT AUTOM LET, V4, P4555, DOI 10.1109/LRA.2019.2931179; Liu W, 2015, PROC CVPR IEEE, P3707, DOI 10.1109/CVPR.2015.7298994; Lomonaco V., 2017, ARXIV170503550, V78, P17; Manton JH, 2002, IEEE T SIGNAL PROCES, V50, P635, DOI 10.1109/78.984753; Ng AY, 2002, ADV NEUR IN, V14, P849; Pentina A., 2015, ADV NEURAL INFORM PR, V1, P1540; Rannen A, 2017, IEEE I CONF COMP VIS, P1329, DOI 10.1109/ICCV.2017.148; Ruvolo P., 2013, P 30 INT C MACHINE L, P507; Sanderson M, 2010, NAT LANG ENG, V16, P100, DOI 10.1017/S1351324909005129; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Sun G, 2020, AAAI CONF ARTIF INTE, V34, P5867; Sun G, 2022, IEEE T NEUR NET LEAR, V33, P1467, DOI 10.1109/TNNLS.2020.3042500; Sun G, 2021, IEEE T NEUR NET LEAR, V32, P139, DOI 10.1109/TNNLS.2020.2977497; Sun G, 2018, AAAI CONF ARTIF INTE, P4107; Sun G, 2019, IEEE T SMART GRID, V10, P1834, DOI 10.1109/TSG.2017.2778428; Sun G, 2018, 2018 9TH IEEE INTERNATIONAL CONFERENCE ON BIG KNOWLEDGE (ICBK), P91, DOI 10.1109/ICBK.2018.00020; Sun G, 2019, IEEE T CYBERNETICS, V49, P3168, DOI 10.1109/TCYB.2018.2841046; Huy TN, 2013, KNOWL INF SYST, V36, P251, DOI 10.1007/s10115-012-0550-5; Thrun S., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P489; Thrun Sebastian, 2012, EXPLANATION BASED NE, V357; Wang QQ, 2021, IEEE T MULTIMEDIA, V23, P3483, DOI 10.1109/TMM.2020.3025666; Wang QQ, 2021, IEEE T IMAGE PROCESS, V30, P305, DOI 10.1109/TIP.2020.3036717; Wenhao Jiang, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P789, DOI 10.1007/978-3-642-33486-3_50; Yang Y, 2015, IEEE T CYBERNETICS, V45, P1069, DOI 10.1109/TCYB.2014.2344015; Yoo SJ, 2016, PROC INT CONF DATA, P637, DOI 10.1109/ICDE.2016.7498277; Yoon Jaehong, 2017, ARXIV170801547; Zhang JW, 2010, AAAI CONF ARTIF INTE, P655; Zhang JW, 2011, NEUROCOMPUTING, V74, P1720, DOI 10.1016/j.neucom.2011.02.004; Zhang X., 2016, PROC INT JOINT C ART, P2357; Zhang XC, 2015, ACM T KNOWL DISCOV D, V10, DOI 10.1145/2747879; Zhang XT, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3132; Zhang XT, 2017, NEUROCOMPUTING, V251, P145, DOI 10.1016/j.neucom.2017.04.029; Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7; Zhou Q, 2016, IEEE T PATTERN ANAL, V38, P266, DOI 10.1109/TPAMI.2015.2452911; Zhu XF, 2017, AAAI CONF ARTIF INTE, P2963	52	35	35	6	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2022	44	7					3895	3908		10.1109/TPAMI.2021.3058852	http://dx.doi.org/10.1109/TPAMI.2021.3058852			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1V0WH	33571090				2022-12-18	WOS:000805820500040
J	Yang, X; Deng, C; Liu, TL; Tao, DC				Yang, Xu; Deng, Cheng; Liu, Tongliang; Tao, Dacheng			Heterogeneous Graph Attention Network for Unsupervised Multiple-Target Domain Adaptation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Feature extraction; Adaptation models; Training; Task analysis; Machine learning; Data models; Heterogeneous graph learning; multiple-target domain adaptation; graph attention network		Domain adaptation, which transfers the knowledge from label-rich source domain to unlabeled target domains, is a challenging task in machine learning. The prior domain adaptation methods focus on pairwise adaptation assumption with a single source and a single target domain, while little work concerns the scenario of one source domain and multiple target domains. Applying pairwise adaptation methods to this setting may be suboptimal, as they fail to consider the semantic association among multiple target domains. In this work we propose a deep semantic information propagation approach in the novel context of multiple unlabeled target domains and one labeled source domain. Our model aims to learn a unified subspace common for all domains with a heterogeneous graph attention network, where the transductive ability of the graph attention network can conduct semantic propagation of the related samples among multiple domains. In particular, the attention mechanism is applied to optimize the relationships of multiple domain samples for better semantic transfer. Then, the pseudo labels of the target domains predicted by the graph attention network are utilized to learn domain-invariant representations by aligning labeled source centroid and pseudo-labeled target centroid. We test our approach on four challenging public datasets, and it outperforms several popular domain adaptation methods.	[Yang, Xu; Deng, Cheng] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China; [Liu, Tongliang; Tao, Dacheng] Univ Sydney, Fac Engn, Sch Comp Sci, 6 Cleveland St, Darlington, NSW 2008, Australia	Xidian University; University of Sydney	Deng, C (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.; Liu, TL (corresponding author), Univ Sydney, Fac Engn, Sch Comp Sci, 6 Cleveland St, Darlington, NSW 2008, Australia.	xuyang.xd@gmail.com; chdeng.xd@gmail.com; tongliang.liu@sydney.edu.au; dacheng.tao@sydney.edu.au		Yang, Xu/0000-0002-0405-6816; Deng, Cheng/0000-0003-2620-3247	National Key R&D Program of China [2017YFE0104100, 2016YFE0200400]; National Natural Science Foundation of China [62071361]; Australian Research Council [DE-190101473]	National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Australian Research Council(Australian Research Council)	This work was supported in part by the National Key R&D Program of China under Grants 2017YFE0104100 and 2016YFE0200400, in part by the National Natural Science Foundation of China under Grant 62071361, and in part by Australian Research Council Project DE-190101473.	Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4; Bruna J, 2013, PROC INT C LEARN REP; Dang ZY, 2020, PROC CVPR IEEE, P6657, DOI 10.1109/CVPR42600.2020.00669; Deng C, 2020, IEEE T MULTIMEDIA, V22, P885, DOI 10.1109/TMM.2019.2934833; Duan LX, 2012, PROC CVPR IEEE, P1338, DOI 10.1109/CVPR.2012.6247819; Ganin Y, 2016, J MACH LEARN RES, V17; Ganin Y, 2015, PR MACH LEARN RES, V37, P1180; Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36; Gholami B, 2020, IEEE T IMAGE PROCESS, V29, P3993, DOI 10.1109/TIP.2019.2963389; Hamilton WL, 2017, ADV NEUR IN, V30; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hoffman J, 2018, PR MACH LEARN RES, V80; Hou CA, 2016, IEEE T IMAGE PROCESS, V25, P5552, DOI 10.1109/TIP.2016.2609820; Kipf TN, 2016, P INT C LEARN REPR; Kouw WM, 2021, IEEE T PATTERN ANAL, V43, P766, DOI 10.1109/TPAMI.2019.2945942; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li D, 2018, AAAI CONF ARTIF INTE, P3490; Li D, 2017, IEEE I CONF COMP VIS, P5543, DOI 10.1109/ICCV.2017.591; Li LM, 2019, IEEE T PATTERN ANAL, V41, P2724, DOI 10.1109/TPAMI.2018.2866846; Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167; Long M, 2016, PROCEEDINGS OF SYMPOSIUM OF POLICING DIPLOMACY AND THE BELT & ROAD INITIATIVE, 2016, P136; Long MS, 2015, PR MACH LEARN RES, V37, P97; Long MS, 2017, PR MACH LEARN RES, V70; Luo Z., 2017, P NIPS, P165; Motiian S., 2017, ADV NEURAL INF PROCE, V30, P1; Motiian S, 2017, IEEE I CONF COMP VIS, P5716, DOI 10.1109/ICCV.2017.609; Netzer Y., 2011, READING DIGITS NATUR; Peng XC, 2019, PR MACH LEARN RES, V97; Peng XC, 2019, IEEE I CONF COMP VIS, P1406, DOI 10.1109/ICCV.2019.00149; Piratla V., ARXIV200312815, V2020; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392; Saito Kuniaki, 2017, ARXIV171101575; Sun LA, 2011, IEEE T PATTERN ANAL, V33, P194, DOI 10.1109/TPAMI.2010.160; Tzeng E., 2014, ARXIV PREPRINT ARXIV; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; Velickovi Petar, 2017, ARXIV171010903; Venkateswara H, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1295, DOI 10.1145/2733373.2806334; Wei K, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P551; Wei K, 2019, IEEE I CONF COMP VIS, P3740, DOI 10.1109/ICCV.2019.00384; Xie SA, 2018, PR MACH LEARN RES, V80; Xu JL, 2014, IEEE T PATTERN ANAL, V36, P2367, DOI 10.1109/TPAMI.2014.2327973; Xu RJ, 2018, PROC CVPR IEEE, P3964, DOI 10.1109/CVPR.2018.00417; Yan HL, 2017, PROC CVPR IEEE, P945, DOI 10.1109/CVPR.2017.107; Yang X, 2019, PROC CVPR IEEE, P4061, DOI 10.1109/CVPR.2019.00419; Zhang C., 2014, ARXIV14010376; Zhang X., 2015, ARXIV150300591	48	35	35	46	82	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					1992	2003		10.1109/TPAMI.2020.3026079	http://dx.doi.org/10.1109/TPAMI.2020.3026079			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	32966212				2022-12-18	WOS:000764815300025
J	Pei, HB; Yang, B; Liu, JM; Chang, KCC				Pei, Hongbin; Yang, Bo; Liu, Jiming; Chang, Kevin Chen-Chuan			Active Surveillance via Group Sparse Bayesian Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Epidemic dynamics; diffusion; sensor deployment; dynamical systems; automatic relevance determination	SENSOR PLACEMENT; GAUSSIAN-PROCESSES; SELECTION; IDENTIFICATION; ALGORITHMS; INFLUENZA	The key to the effective control of a diffusion system lies in how accurately we could predict its unfolding dynamics based on the observation of its current state. However, in the real-world applications, it is often infeasible to conduct a timely and yet comprehensive observation due to resource constraints. In view of such a practical challenge, the goal of this work is to develop a novel computational method for performing active observations, termed active surveillance, with limited resources. Specifically, we aim to predict the dynamics of a large spatio-temporal diffusion system based on the observations of some of its components. Towards this end, we introduce a novel measure, the y value, that enables us to identify the key components by means of modeling a sentinel network with a row sparsity structure. Having obtained a theoretical understanding of the y value, we design a backward-selection sentinel network mining algorithm (SNMA) for deriving the sentinel network via group sparse Bayesian learning. In order to be practically useful, we further address the issue of scalability in the computation of SNMA, and moreover, extend SNMA to the case of a non-linear dynamical system that could involve complex diffusion mechanisms. We show the effectiveness of SNMA by validating it using both synthetic datasets and five real-world datasets. The experimental results are appealing, which demonstrate that SNMA readily outperforms the state-of-the-art methods.	[Pei, Hongbin; Yang, Bo] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China; [Pei, Hongbin; Yang, Bo] Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engineer, Changchun 130012, Jilin, Peoples R China; [Liu, Jiming] Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Peoples R China; [Chang, Kevin Chen-Chuan] Univ Illinois, Dept Comp Sci, Champaign, IL 61820 USA	Jilin University; Jilin University; Hong Kong Baptist University; University of Illinois System; University of Illinois Urbana-Champaign	Yang, B (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.; Yang, B (corresponding author), Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engineer, Changchun 130012, Jilin, Peoples R China.	peihb15@mails.jlu.edu.cn; ybo@jlu.edu.cn; jiming@comp.hkbu.edu.hk; kcchang@illinois.edu		Chang, Kevin Chen-Chuan/0000-0003-0997-6803; Reis, AlessanRSS/0000-0001-8486-7469	National Natural Science Foundation of China [61876069]; Jilin Province Key Scientific and Technological Research and Development Project [20180201067GX, 20180201044GX]; Jilin Province Natural Science Foundation [20200201036JC]; University Science and Technology Research Plan Project of Jilin Province [JJKH20190156KJ]; Research Grants Council of Hong Kong Special Administrative Region [RGC/HKBU12201318, RGC/HKBU12202220]; National Science Foundation [IIS 16-19302, IIS 16-33755]; Zhejiang University ZJU Research [083650]; Futurewei Technologies [HF2017060011, 094013]; UIUC OVCR CCIL Planning [434S34]; UIUC CSBS Small Grant [434C8U]; IBM-Illinois Center for Cognitive Computing Systems Research (C3SR); China Scholarships Council [201806170202]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Jilin Province Key Scientific and Technological Research and Development Project; Jilin Province Natural Science Foundation; University Science and Technology Research Plan Project of Jilin Province; Research Grants Council of Hong Kong Special Administrative Region(Hong Kong Research Grants Council); National Science Foundation(National Science Foundation (NSF)); Zhejiang University ZJU Research; Futurewei Technologies; UIUC OVCR CCIL Planning; UIUC CSBS Small Grant; IBM-Illinois Center for Cognitive Computing Systems Research (C3SR)(International Business Machines (IBM)); China Scholarships Council	This work was supported by the National Natural Science Foundation of China under Grant 61876069, the Jilin Province Key Scientific and Technological Research and Development Project under Grants 20180201067GX and 20180201044GX, Jilin Province Natural Science Foundation under Grant 20200201036JC, University Science and Technology Research Plan Project of Jilin Province under Grant JJKH20190156KJ, Research Grants Council of Hong Kong Special Administrative Region under Grants RGC/HKBU12201318 and RGC/HKBU12202220, National Science Foundation IIS 16-19302 and IIS 16-33755, Zhejiang University ZJU Research 083650, Futurewei Technologies HF2017060011 and 094013, UIUC OVCR CCIL Planning Grant 434S34, UIUC CSBS Small Grant 434C8U, IBM-Illinois Center for Cognitive Computing Systems Research (C3SR), and China Scholarships Council under scholarship 201806170202. Any opinions, findings, and conclusions or recommendations expressed in this publication are those of the author(s) and do not necessarily reflect the views of the funding agencies. A preliminary version of this work was published in AAAI18[6]. The authors are also very grateful to the anonymous reviewers for their constructive comments, which further improved the quality of the work.	[Anonymous], 2010, SUMMARY REPORT SURVE; ATKINSON AC, 1988, INT STAT REV, V56, P99, DOI 10.2307/1403635; Bishop C.M, 2006, PATTERN RECOGN; Brunton SL, 2016, P NATL ACAD SCI USA, V113, P3932, DOI 10.1073/pnas.1517384113; Chen Y, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P43; Chepuri SP, 2015, IEEE SIGNAL PROC LET, V22, P544, DOI 10.1109/LSP.2014.2363731; Cohen K, 2006, COMPUT FLUIDS, V35, P103, DOI 10.1016/j.compfluid.2004.11.002; Couvreur C, 2000, SIAM J MATRIX ANAL A, V21, P797, DOI 10.1137/S0895479898332928; Cressie N, STAT SPATIAL DATA; Crooks G. E, 2009, LOGISTIC APPROXIMATI; Du R, 2013, IEEE GLOB COMM CONF, P30, DOI 10.1109/GLOCOM.2013.6831043; Du R, 2015, IEEE T VEH TECHNOL, V64, P273, DOI 10.1109/TVT.2014.2321010; Frenzel L. E, 2016, HDB SERIAL COMMUNICA; Gerardo-Giorda L, 2013, J R SOC INTERFACE, V10, DOI 10.1098/rsif.2013.0418; Gomez-Rodriguez M, 2012, ACM T KNOWL DISCOV D, V5, DOI 10.1145/2086737.2086741; Jarrah AS, 2007, ADV APPL MATH, V39, P477, DOI 10.1016/j.aam.2006.08.004; Jiang CY, 2019, IEEE T SIGNAL PROCES, V67, P2249, DOI 10.1109/TSP.2019.2903017; Jiang CY, 2016, IEEE T SIGNAL PROCES, V64, P5595, DOI 10.1109/TSP.2016.2573767; Joshi S, 2009, IEEE T SIGNAL PROCES, V57, P451, DOI 10.1109/TSP.2008.2007095; Krause A., 2007, P INT C MACH LEARN, P449, DOI [10.1145/1273496.1273553, DOI 10.1145/1273496.1273553]; Krause A, 2008, J MACH LEARN RES, V9, P235; Liu SH, 2019, IEEE T IND INFORM, V15, P5033, DOI 10.1109/TII.2019.2895469; Liu SH, 2018, IEEE T SIGNAL PROCES, V66, P2153, DOI 10.1109/TSP.2018.2806351; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.448; Maragakis P, 2008, J CHEM PHYS, V129, DOI 10.1063/1.2937892; Meier L, 2008, J R STAT SOC B, V70, P53, DOI 10.1111/j.1467-9868.2007.00627.x; Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975; Pei HB, 2018, AAAI CONF ARTIF INTE, P800; Polgreen PM, 2009, AM J EPIDEMIOL, V170, P1300, DOI 10.1093/aje/kwp270; Ranieri J, 2014, IEEE T SIGNAL PROCES, V62, P1135, DOI 10.1109/TSP.2014.2299518; Ranieri J, 2012, DES AUT CON, P636; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Rusu C, 2018, IEEE T SIGNAL PROCES, V66, P528, DOI 10.1109/TSP.2017.2773429; Rusu C, 2017, EUR SIGNAL PR CONF, P1415, DOI 10.23919/EUSIPCO.2017.8081442; Shamaiah M, 2010, IEEE DECIS CONTR P, P2572, DOI 10.1109/CDC.2010.5717225; Sridhar A, 2010, ICCAD-IEEE ACM INT, P463, DOI 10.1109/ICCAD.2010.5653749; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Wallinga J, 2010, P NATL ACAD SCI USA, V107, P923, DOI 10.1073/pnas.0908491107; Wang HB, 2004, IPSN '04: THIRD INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING IN SENSOR NETWORKS, P36; Wipf DP, 2007, IEEE T SIGNAL PROCES, V55, P3704, DOI 10.1109/TSP.2007.894265; Wu JT, 2010, CLIN INFECT DIS, V51, P1184, DOI 10.1086/656740; Yang B, 2017, IEEE T PATTERN ANAL, V39, P1532, DOI 10.1109/TPAMI.2016.2605095; YAO L, 1993, AIAA J, V31, P1922, DOI 10.2514/3.11868; Zhang CH, 2012, STAT SCI, V27, P576, DOI 10.1214/12-STS399; Zhang ZL, 2013, IEEE T SIGNAL PROCES, V61, P2009, DOI 10.1109/TSP.2013.2241055; Zhang ZL, 2012, INT CONF ACOUST SPEE, P3345, DOI 10.1109/ICASSP.2012.6288632; Zhang ZL, 2011, IEEE J-STSP, V5, P912, DOI 10.1109/JSTSP.2011.2159773; Zheng Y, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1436, DOI 10.1145/2487575.2488188; Zhou YB, 2014, ADV NEUR IN, V27	49	35	35	16	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1133	1148		10.1109/TPAMI.2020.3023092	http://dx.doi.org/10.1109/TPAMI.2020.3023092			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32915724				2022-12-18	WOS:000752018000006
J	Li, YF; Guo, LZ; Zhou, ZH				Li, Yu-Feng; Guo, Lan-Zhe; Zhou, Zhi-Hua			Towards Safe Weakly Supervised Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Weakly supervised learning; safe; semi-supervised learning; domain adaptation; multi-instance learning; label noise learning	UNLABELED DATA; INSTANCE; CLASSIFIER; NOISE	In this paper, we study weakly supervised learning where a large amount of data supervision is not accessible. This includes i) incomplete supervision, where only a small subset of labels is given, such as semi-supervised learning and domain adaptation; ii) inexact supervision, where only coarse-grained labels are given, such as multi-instance learning and iii) inaccurate supervision, where the given labels are not always ground-truth, such as label noise learning. Unlike supervised learning which typically achieves performance improvement with more labeled examples, weakly supervised learning may sometimes even degenerate performance with more weakly supervised data. Such deficiency seriously hinders the deployment of weakly supervised learning to real tasks. It is thus highly desired to study safe weakly supervised learning, which never seriously hurts performance. To this end, we present a generic ensemble learning scheme to derive a safe prediction by integrating multiple weakly supervised learners. We optimize the worst-case performance gain and lead to a maximin optimization. This brings multiple advantages to safe weakly supervised learning. First, for many commonly used convex loss functions in classification and regression, it is guaranteed to derive a safe prediction under a mild condition. Second, prior knowledge related to the weight of the base weakly supervised learners can be flexibly embedded. Third, it can be globally and efficiently addressed by simple convex quadratic or linear program. Finally, it is in an intuitive geometric interpretation with the least square loss. Extensive experiments on various weakly supervised learning tasks, including semi-supervised learning, domain adaptation, multi-instance learning and label noise learning demonstrate our effectiveness.	[Li, Yu-Feng; Guo, Lan-Zhe; Zhou, Zhi-Hua] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China	Nanjing University	Li, YF (corresponding author), Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.	liuf@lamda.nju.edu.cn; guolz@lamda.nju.edu.cn; zhouzh@lamda.nju.edu.cn			National Key RAMP;D Program of China [2018YFB1004300]; National Natural Science Foundation of China [61772262]	National Key RAMP;D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The authors want to thank the associate editor and reviewers for helpful comments and suggestions. This research was supported by the National Key R&D Program of China (2018YFB1004300) and the National Natural Science Foundation of China (61772262). Yu-Feng Li and Lan-Zhe Guo contribute equally to this work.	Andrews S., 2002, NIPS, V2, P561; Argyriou A, 2008, LECT NOTES ARTIF INT, V5211, P71, DOI 10.1007/978-3-540-87479-9_23; Bakker B, 2004, J MACH LEARN RES, V4, P83, DOI 10.1162/153244304322765658; Balsubramani A., 2015, COLT, V21, P211; BATES JM, 1969, OPER RES QUART, V20, P451, DOI 10.2307/3008764; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Bonilla EV., 2008, ADV NEURAL INF PROCE, V20, P153, DOI DOI 10.5555/2981562.2981582; Bootkrajang Jakramate, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P143, DOI 10.1007/978-3-642-33460-3_15; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Briggs F., 2012, P 18 ACM SIGKDD INT, P534, DOI DOI 10.1145/2339530.2339616; Carbonneau MA, 2018, PATTERN RECOGN, V77, P329, DOI 10.1016/j.patcog.2017.10.009; Carbonneau MA, 2016, INT C PATT RECOG, P3639, DOI 10.1109/ICPR.2016.7900199; Censor Y., 1997, PARALLEL OPTIMIZATIO; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chapelle O., 2006, IEEE T NEURAL NETWOR, V20, P542; Chawla N, 2005, J ARTIF INTELL RES, V23, P331, DOI 10.1613/jair.1509; Dai W., 2007, PROC INT C MACH LEAR, P193, DOI [10.1145/1273496.1273521, DOI 10.1145/1273496.1273521]; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Fan LW, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9207-9; Frenay B, 2014, IEEE T NEUR NET LEAR, V25, P845, DOI 10.1109/TNNLS.2013.2292894; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; GABA A, 1992, MANAGE SCI, V38, P913, DOI 10.1287/mnsc.38.7.913; Ge L, 2014, STAT ANAL DATA MIN, V7, P254, DOI 10.1002/sam.11217; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Guo LZ, 2018, AAAI CONF ARTIF INTE, P3126; Hastie T, 2009, ELEMENTS STAT LEARNI; Hickey RJ, 1996, ARTIF INTELL, V82, P157, DOI 10.1016/0004-3702(94)00094-8; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Lang Ken, 1995, MACHINE LEARNING P; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Li L., 2012, PROC AAAI C ARTIF IN, P998; Li YF, 2019, FRONT COMPUT SCI-CHI, V13, P669, DOI 10.1007/s11704-019-8452-2; Li YF, 2016, AAAI CONF ARTIF INTE, P1816; Li YF, 2017, AAAI CONF ARTIF INTE, P2217; Manwani N, 2013, IEEE T CYBERNETICS, V43, P1146, DOI 10.1109/TSMCB.2012.2223460; Miller DJ, 1997, ADV NEUR IN, V9, P571; Mooney R.J., 2007, P NAT C ART INT, V7, P608, DOI DOI 10.5555/1619645.1619743; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Rahmani Rouhollah, 2005, P 7 ACM SIGMM INT WO, P227, DOI DOI 10.1145/1101826.1101863; Raina R., 2007, LEARNING, P759, DOI DOI 10.1145/1273496.1273592; Ray S, 2005, P 22 INT C MACHINE L, P697, DOI DOI 10.1145/1102351.1102439; Rosasco L, 2004, NEURAL COMPUT, V16, P1063, DOI 10.1162/089976604773135104; Rosenstein M., 2005, P NIPS WORKSH IND TR; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Wang DY, 2000, ACTA POLYM SIN, P111; Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079; Xu X, 2004, LECT NOTES ARTIF INT, V3056, P272; Xue G.-R., 2008, P 31 ANN INT ACM SIG, P627, DOI DOI 10.1145/1390334.1390441; Yan K, 2018, IEEE T CYBERNETICS, V48, P288, DOI 10.1109/TCYB.2016.2633306; Yarowsky David, 1995, ACL, P2, DOI [10.3115/981658.981684, DOI 10.3115/981658.981684]; Yuille AL, 2003, NEURAL COMPUT, V15, P915, DOI 10.1162/08997660360581958; Zhang C, 2006, ADV NEURAL INFORM PR, P1417; Zhang Q, 2002, ADV NEUR IN, V14, P1073; Zhou Z.-H., 2009, ANN INT C MACH LEARN, P1249, DOI DOI 10.1145/1553374.1553534; Zhou ZH, 2005, LECT NOTES ARTIF INT, V3809, P92; Zhou ZH., 2012, ENSEMBLE METHODS FDN, DOI [10.1201/b12207, DOI 10.1201/B12207]; Zhou ZH, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P908; Zhou ZH, 2007, KNOWL INF SYST, V11, P155, DOI 10.1007/s10115-006-0029-3; Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106; Zhu X., 2003, INT C MACH LEARN	63	35	36	20	85	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2021	43	1					334	346		10.1109/TPAMI.2019.2922396	http://dx.doi.org/10.1109/TPAMI.2019.2922396			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PC7WN	31199253				2022-12-18	WOS:000597206900022
J	Farrugia, RA; Guillemot, C				Farrugia, Reuben A.; Guillemot, Christine			Light Field Super-Resolution Using a Low-Rank Prior and Deep Convolutional Neural Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Spatial resolution; Cameras; Image restoration; Matrix decomposition; Sparse matrices; Light fields; Deep convolutional neural networks; light field; low-rank matrix approximation; super-resolution	RESOLUTION; REMOVAL	Light field imaging has recently known a regain of interest due to the availability of practical light field capturing systems that offer a wide range of applications in the field of computer vision. However, capturing high-resolution light fields remains technologically challenging since the increase in angular resolution is often accompanied by a significant reduction in spatial resolution. This paper describes a learning-based spatial light field super-resolution method that allows the restoration of the entire light field with consistency across all angular views. The algorithm first uses optical flow to align the light field and then reduces its angular dimension using low-rank approximation. We then consider the linearly independent columns of the resulting low-rank model as an embedding, which is restored using a deep convolutional neural network (DCNN). The super-resolved embedding is then used to reconstruct the remaining views. The original disparities are restored using inverse warping where missing pixels are approximated using a novel light field inpainting algorithm. Experimental results show that the proposed method outperforms existing light field super-resolution algorithms, achieving PSNR gains of 0.23 dB over the second best performing method. The performance is shown to be further improved using iterative back-projection as a post-processing step.	[Farrugia, Reuben A.] Univ Malta, Dept Commun & Comp Engn, MSD-2080 Msida, Malta; [Guillemot, Christine] Inst Natl Rech Informat & Automat, F-35042 Rennes, France	University of Malta	Farrugia, RA (corresponding author), Univ Malta, Dept Commun & Comp Engn, MSD-2080 Msida, Malta.	reuben.farrugia@um.edu.mt; christine.guillemot@intria.fr	Farrugia, Reuben A/J-8170-2014	Farrugia, Reuben A/0000-0001-8106-9891; Guillemot, Christine/0000-0003-1604-967X	EU H2020 Research and Innovation Programme [694122]	EU H2020 Research and Innovation Programme	This project has been supported in part by the EU H2020 Research and Innovation Programme under grant agreement No 694122 (ERC advanced grant CLIM).	[Anonymous], [No title captured]; [Anonymous], [No title captured]; Ao HB, 2015, LECT NOTES COMPUT SC, V9314, P601, DOI 10.1007/978-3-319-24075-6_58; Bishop TE, 2012, IEEE T PATTERN ANAL, V34, P972, DOI 10.1109/TPAMI.2011.168; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Dansereau DG, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2665074; Dansereau DG, 2013, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2013.137; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Farrugia RA, 2017, IEEE J-STSP, V11, P1058, DOI 10.1109/JSTSP.2017.2747127; Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271; Glorot X., 2010, P 13 INT C ART INT S, P249, DOI DOI 10.1.1/207.2059; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; Gul MSK, 2018, IEEE T IMAGE PROCESS, V27, P2146, DOI 10.1109/TIP.2018.2794181; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Hu YL, 2016, PROC CVPR IEEE, P5704, DOI 10.1109/CVPR.2016.615; IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L; Jiang XR, 2017, IEEE J-STSP, V11, P1132, DOI 10.1109/JSTSP.2017.2747078; Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Levin A, 2008, LECT NOTES COMPUT SC, V5305, P88, DOI 10.1007/978-3-540-88693-8_7; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Li Y, 2015, IEEE I CONF COMP VIS, P4006, DOI 10.1109/ICCV.2015.456; Liang CK, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2665075; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Mitra K., 2012, IEEE C COMP VIS PATT, P22; Ng R., 2005, COMPUT SCI TECH REP, V2, P1; Peleg T, 2014, IEEE T IMAGE PROCESS, V23, P2569, DOI 10.1109/TIP.2014.2305844; Peng YG, 2010, PROC CVPR IEEE, P763, DOI 10.1109/CVPR.2010.5540138; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Seitz SM, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P17, DOI 10.1109/ICCV.1998.710696; Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241; Wang TC, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073614; Wang YW, 2017, IEEE T VIS COMPUT GR, V23, P2357, DOI 10.1109/TVCG.2016.2628743; Wanner S, 2014, IEEE T PATTERN ANAL, V36, P606, DOI 10.1109/TPAMI.2013.147; Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259; Wu GC, 2017, PROC CVPR IEEE, P1638, DOI 10.1109/CVPR.2017.178; Wu GC, 2017, IEEE J-STSP, V11, P926, DOI 10.1109/JSTSP.2017.2747126; Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098; Yoon Y, 2017, IEEE SIGNAL PROC LET, V24, P848, DOI 10.1109/LSP.2017.2669333; Yoon Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P57, DOI 10.1109/ICCVW.2015.17; Zhang FL, 2017, IEEE T VIS COMPUT GR, V23, P1561, DOI 10.1109/TVCG.2016.2532329; Zhang K, 2016, IEEE SIGNAL PROC LET, V23, P102, DOI 10.1109/LSP.2015.2504121	43	35	35	5	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2020	42	5					1162	1175		10.1109/TPAMI.2019.2893666	http://dx.doi.org/10.1109/TPAMI.2019.2893666			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LA0ZT	30668462	Green Submitted			2022-12-18	WOS:000523685800011
J	Tang, P; Wang, CY; Wang, XG; Liu, WY; Zeng, WJ; Wang, JD				Tang, Peng; Wang, Chunyu; Wang, Xinggang; Liu, Wenyu; Zeng, Wenjun; Wang, Jingdong			Object Detection in Videos by High Quality Object Linking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection in videos; object linking	NETWORKS	Compared with object detection in static images, object detection in videos is more challenging due to degraded image qualities. An effective way to address this problem is to exploit temporal contexts by linking the same object across video to form tubelets and aggregating classification scores in the tubelets. In this paper, we focus on obtaining high quality object linking results for better classification. Unlike previous methods that link objects by checking boxes between neighboring frames, we propose to link in the same frame. To achieve this goal, we extend prior methods in following aspects: (1) a cuboid proposal network that extracts spatio-temporal candidate cuboids which bound the movement of objects; (2) a short tubelet detection network that detects short tubelets in short video segments; (3) a short tubelet linking algorithm that links temporally-overlapping short tubelets to form long tubelets. Experiments on the ImageNet VID dataset show that our method outperforms both the static image detector and the previous state of the art. In particular, our method improves results by 8.8 percent over the static image detector for fast moving objects.	[Tang, Peng; Wang, Xinggang; Zeng, Wenjun; Wang, Jingdong] Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430073, Hubei, Peoples R China; [Wang, Chunyu; Liu, Wenyu] Microsoft Res, Beijing 100080, Peoples R China	Huazhong University of Science & Technology; Microsoft	Tang, P (corresponding author), Huazhong Univ Sci & Technol, Sch Elect Informat & Commun, Wuhan 430073, Hubei, Peoples R China.	pengtang@hust.edu.cn; chnuwa@microsoft.com; xgwang@hust.edu.cn; liuwy@hust.edu.cn; wezeng@microsoft.com; jingdw@microsoft.com	Liu, Wenyu/AAG-1426-2019; Wang, Jingdong/E-9920-2017	Liu, Wenyu/0000-0002-4582-7488; Wang, Jingdong/0000-0002-4888-4445; Wang, Chunyu/0000-0002-9400-9107	National Natural Science Foundation of China [61733007, 61572207, 61876212]; Hubei Scientific and Technical Innovation Key Project; Program for HUST Academic Frontier Youth Team; CCF-Tencent Open Research Fund	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Hubei Scientific and Technical Innovation Key Project; Program for HUST Academic Frontier Youth Team; CCF-Tencent Open Research Fund	This work was supported by National Natural Science Foundation of China (No. 61733007, No. 61572207, No. 61876212), Hubei Scientific and Technical Innovation Key Project, the Program for HUST Academic Frontier Youth Team, and CCF-Tencent Open Research Fund.	[Anonymous], 2015, ICLR; [Anonymous], 2016, INT C LEARN REPR; Bertasius G, 2018, LECT NOTES COMPUT SC, V11216, P342, DOI 10.1007/978-3-030-01258-8_21; Byungjae Lee, 2016, Computer Vision - ECCV 2016 Workshops. Proceedings: LNCS 9914, P68, DOI 10.1007/978-3-319-48881-3_6; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Gkioxari G, 2015, PROC CVPR IEEE, P759, DOI 10.1109/CVPR.2015.7298676; Han Wei, 2016, ARXIV160208465; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Hou R, 2017, IEEE I CONF COMP VIS, P5823, DOI 10.1109/ICCV.2017.620; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Kalogeiton V, 2017, IEEE I CONF COMP VIS, P4415, DOI 10.1109/ICCV.2017.472; Kang K, 2017, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2017.101; Kang K, 2016, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2016.95; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Peng XJ, 2016, LECT NOTES COMPUT SC, V9908, P744, DOI 10.1007/978-3-319-46493-0_45; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Saha S, 2017, IEEE I CONF COMP VIS, P4424, DOI 10.1109/ICCV.2017.473; Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89; Simonyan K, 2015, 3 INT C LEARN REPR I; Singh G, 2017, IEEE I CONF COMP VIS, P3657, DOI 10.1109/ICCV.2017.393; Tang P, 2017, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2017.326; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357; Wang SY, 2018, LECT NOTES COMPUT SC, V11217, P557, DOI 10.1007/978-3-030-01261-8_33; Zhang ZS, 2018, PROC CVPR IEEE, P5813, DOI 10.1109/CVPR.2018.00609; Zhou K, 2016, DESTECH TRANS COMP; Zhu XZ, 2017, IEEE I CONF COMP VIS, P408, DOI 10.1109/ICCV.2017.52; Zhu XZ, 2017, PROC CVPR IEEE, P4141, DOI 10.1109/CVPR.2017.441	42	35	35	11	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2020	42	5					1272	1278		10.1109/TPAMI.2019.2910529	http://dx.doi.org/10.1109/TPAMI.2019.2910529			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LA0ZT	30990176	Green Submitted			2022-12-18	WOS:000523685800019
J	Qian, XL; Fu, YW; Xiang, T; Jiang, YG; Xue, XY				Qian, Xuelin; Fu, Yanwei; Xiang, Tao; Jiang, Yu-Gang; Xue, Xiangyang			Leader-Based Multi-Scale Attention Deep Architecture for Person Re-Identification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Cameras; Task analysis; Computer architecture; Computational modeling; Adaptation models; Clothing; Person re-identification; multi-scale deep learning; self-attention; domain generalization	NETWORK	Person re-identification (re-id) aims to match people across non-overlapping camera views in a public space. This is a challenging problem because the people captured in surveillance videos often wear similar clothing. Consequently, the differences in their appearance are typically subtle and only detectable at particular locations and scales. In this paper, we propose a deep re-id network (MuDeep) that is composed of two novel types of layers - a multi-scale deep learning layer, and a leader-based attention learning layer. Specifically, the former learns deep discriminative feature representations at different scales, while the latter utilizes the information from multiple scales to lead and determine the optimal weightings for each scale. The importance of different spatial locations for extracting discriminative features is learned explicitly via our leader-based attention learning layer. Extensive experiments are carried out to demonstrate that the proposed MuDeep outperforms the state-of-the-art on a number of benchmarks and has a better generalization ability under a domain generalization setting.	[Fu, Yanwei] Fudan Univ, Sch Data Sci, Shanghai Key Lab Intelligent Informat Proc, Shanghai 200082, Peoples R China; [Qian, Xuelin; Jiang, Yu-Gang; Xue, Xiangyang] Fudan Univ, Sch Comp Sci, Shanghai Key Lab Intelligent Informat Proc, Shanghai 200082, Peoples R China; [Xiang, Tao] Univ Surrey, Sch Elect & Elect Engn, Guildford GU2 7XH, Surrey, England	Fudan University; Fudan University; University of Surrey	Jiang, YG (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai Key Lab Intelligent Informat Proc, Shanghai 200082, Peoples R China.	xlqian15@fudan.edu.cn; yanweifu@fudan.edu.cn; txiang@surrey.ac.uk; ygj@fudan.edu.cn; xyxue@fudan.edu.cn		Qian, Xuelin/0000-0001-8049-7288; Fu, Yanwei/0000-0002-6595-6893; Xue, Xiangyang/0000-0002-4897-9209	NSFC [61702108, 61622204, 61572138]; STCSM Project [16JC1420400]; Shanghai Municipal Science and Technology Major Projects [2017SHZDZX01, 2018SHZDZX01]; ZJLab	NSFC(National Natural Science Foundation of China (NSFC)); STCSM Project(Science & Technology Commission of Shanghai Municipality (STCSM)); Shanghai Municipal Science and Technology Major Projects; ZJLab	This work was supported in part by NSFC Projects (61702108, 61622204, 61572138), STCSM Project (16JC1420400), Shanghai Municipal Science and Technology Major Projects (2017SHZDZX01, 2018SHZDZX01) and ZJLab. Xuelin Qian and Yanwei Fu contributed equally to this work.	Ahmed E., 2015, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2015.7299016; Bai S, 2017, AAAI CONF ARTIF INTE, P1281; Bai X, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107036; Bak S, 2017, PROC CVPR IEEE, P1571, DOI 10.1109/CVPR.2017.171; Berclaz J, 2008, LECT NOTES COMPUT SC, V5304, P112, DOI 10.1007/978-3-540-88690-7_9; Chan AB, 2009, IEEE I CONF COMP VIS, P545, DOI 10.1109/ICCV.2009.5459191; Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225; Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142; Chen L, 2018, 2018 11TH INTERNATIONAL WORKSHOP ON HUMAN FRIENDLY ROBOTICS (HFR), P54, DOI 10.1109/HFR.2018.8633487; Chen SZ, 2016, IEEE T IMAGE PROCESS, V25, P2353, DOI 10.1109/TIP.2016.2545929; Chen Weihua, 2017, AAAI, V1, P3; Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304; Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149; Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dikmen Mert, 2010, P AS C COMP VIS, P501; Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005; Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926; Gao MF, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1077; Ge Weina, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2913, DOI 10.1109/CVPRW.2009.5206621; Geng M., 2016, ARXIV161105244; Gong S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0084391; Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21; Guillaumin M, 2009, IEEE I CONF COMP VIS, P498, DOI 10.1109/ICCV.2009.5459197; Guo YL, 2018, PROC CVPR IEEE, P2335, DOI 10.1109/CVPR.2018.00248; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Hermans Alexander, 2017, ARXIV170307737; Hirzer M, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P203, DOI 10.1109/AVSS.2012.55; Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56; Khamis S, 2015, LECT NOTES COMPUT SC, V8927, P134, DOI 10.1007/978-3-319-16199-0_10; Kostinger Martin, 2012, CVPR, DOI DOI 10.1109/CVPR.2012.6247939; Kviatkovsky I, 2013, IEEE T PATTERN ANAL, V35, P1622, DOI 10.1109/TPAMI.2012.246; Layne R., 2013, P 4 ACM IEEE INT WOR, P25; Li JX, 2018, INT C COMP SUPP COOP, P365; Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046; Li W., 2013, LNCS, V7724, P31, DOI [10.1007/978-3-642-37331-2, DOI 10.1007/978-3-642-37331-2]; Li W, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2194; Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27; Li X, 2015, IEEE I CONF COMP VIS, P3765, DOI 10.1109/ICCV.2015.429; Li Z., 2014, P IEEE C COMP VIS PA, P3610; Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832; Lin Y., 2017, ABS170307220 CORR; Lin Z., 2017, ARXIV PREPRINT ARXIV; Lisanti G., 2014, P INT C DISTRIBUTED, P1, DOI DOI 10.1145/2659021.2659036; Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055; Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762; Liu J, 2016, BIOMED SIGNAL PROCES, V24, P19, DOI 10.1016/j.bspc.2015.09.004; Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46; Ma LY, 2014, IEEE T IMAGE PROCESS, V23, P3656, DOI 10.1109/TIP.2014.2331755; Mao CJ, 2018, AAAI CONF ARTIF INTE, P7243; Martinel N, 2016, LECT NOTES COMPUT SC, V9908, P858, DOI 10.1007/978-3-319-46493-0_52; Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152; Mensink T, 2007, 2007 FIRST ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P170; Mermillod Martial, 2005, Brain Cogn, V57, P151, DOI 10.1016/j.bandc.2004.08.035; Mittal A., 2016, ADV NEURAL INFORM PR, P2675; Musel B, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038493; Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794; PARKER DM, 1992, PERCEPTION, V21, P147, DOI 10.1068/p210147; Parker DM, 1996, J EXP PSYCHOL HUMAN, V22, P1448, DOI 10.1037/0096-1523.22.6.1448; Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146; Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40; Qian XL, 2017, IEEE I CONF COMP VIS, P5409, DOI 10.1109/ICCV.2017.577; Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2; SCHYNS PG, 1994, PSYCHOL SCI, V5, P195, DOI 10.1111/j.1467-9280.1994.tb00500.x; Shen C, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1942, DOI 10.1145/3123266.3123452; Shen YT, 2018, LECT NOTES COMPUT SC, V11219, P508, DOI 10.1007/978-3-030-01267-0_30; Shi H., 2015, ABS151107545 CORR; Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44; Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562; Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427; Sun Y., 2017, ABS171109349 CORR; Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Tao DP, 2013, IEEE T CIRC SYST VID, V23, P1675, DOI 10.1109/TCSVT.2013.2255413; Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48; Vaswani A., 2017, ADV NEURAL INFORM PR, V30; Vuilleumier P, 2003, NAT NEUROSCI, V6, P624, DOI 10.1038/nn1057; Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144; Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552; Wang X., 2008, P IEEE C COMP VIS PA, P1; Wang XJ, 2016, IEEE T CIRC SYST VID, V26, P1447, DOI 10.1109/TCSVT.2015.2450331; Wang Y, 2018, PROC CVPR IEEE, P8042, DOI 10.1109/CVPR.2018.00839; Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016; Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140; Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1; Xu HC, 2017, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/aa7a3e; Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507; Yang HJ, 2018, COMPLEXITY, DOI 10.1155/2018/6457354; Yi D., 2014, ABS14074979 CORR; Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199; Yu HX, 2017, IEEE I CONF COMP VIS, P994, DOI 10.1109/ICCV.2017.113; Yu R, 2018, LECT NOTES COMPUT SC, V11220, P196, DOI 10.1007/978-3-030-01270-0_12; Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139; Zhang Xuan, 2017, ARXIV171108184; Zhang Y., 2016, P IJCAI, P3545; Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454; Zhang  Z., 2014, P EUR C COMP VIS WOR, P122; Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349; Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26; Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; Zheng L., 2017, ABS170107732 CORR; Zheng L., 2016, ARXIV; Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133; Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138; Zheng Z., 2018, TOMCCAP, V14; Zheng Z., 2017, ABS170700408 CORR; Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405; Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541; Zhong Zhun, 2017, PROC CVPR IEEE, P1318, DOI DOI 10.1109/CVPR.2017.389	114	35	37	4	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2020	42	2					371	385		10.1109/TPAMI.2019.2928294	http://dx.doi.org/10.1109/TPAMI.2019.2928294			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KE2KB	31329547	Green Submitted			2022-12-18	WOS:000508386100010
J	Oron, S; Dekel, T; Xue, TF; Freeman, WT; Avidan, S				Oron, Shaul; Dekel, Tali; Xue, Tianfan; Freeman, William T.; Avidan, Shai			Best-Buddies Similarity-Robust Template Matching Using Mutual Nearest Neighbors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Best buddies; mutual nearest neighbors; template matching; point set similarity; non-rigid matching	INVARIANT; TRACKING; BRIGHTNESS; ROTATION; COLOR	We propose a novel method for template matching in unconstrained environments. Its essence is the Best-Buddies Similarity (BBS), a useful, robust, and parameter-free similarity measure between two sets of points. BBS is based on counting the number of Best-Buddies Pairs (BBPs)-pairs of points in source and target sets that are mutual nearest neighbours, i.e., each point is the nearest neighbour of the other. BBS has several key features that make it robust against complex geometric deformations and high levels of outliers, such as those arising from background clutter and occlusions. We study these properties, provide a statistical analysis that justifies them, and demonstrate the consistent success of BBS on a challenging real-world dataset while using different types of features.	[Oron, Shaul; Avidan, Shai] Tel Aviv Univ, Dept Elect Engn, IL-69102 Tel Aviv, Israel; [Dekel, Tali; Xue, Tianfan; Freeman, William T.] MIT, Comp Sci & Artificial Intelligence Lab, Google, 77 Massachusetts Ave, Cambridge, MA 02139 USA	Tel Aviv University; Google Incorporated; Massachusetts Institute of Technology (MIT)	Oron, S (corresponding author), Tel Aviv Univ, Dept Elect Engn, IL-69102 Tel Aviv, Israel.	shauloro@post.tau.ac.il; tdekel@google.com; tfxue@mit.edu; billf@mit.edu; avidan@eng.tau.ac.il	Xue, Tianfan/AAG-5546-2019		Israel Science Foundation [1917/2015]; National Science Foundation Robust Intelligence Reconstructive Recognition [1212849]; Shell Research	Israel Science Foundation(Israel Science Foundation); National Science Foundation Robust Intelligence Reconstructive Recognition; Shell Research	This work was supported in part by an Israel Science Foundation grant 1917/2015, National Science Foundation Robust Intelligence 1212849 Reconstructive Recognition, and a grant from Shell Research.	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881; Baumberg A, 2000, PROC CVPR IEEE, P774, DOI 10.1109/CVPR.2000.855899; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Chen JH, 2003, IEEE T SIGNAL PROCES, V51, P230, DOI 10.1109/TSP.2002.806551; Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761; Dekel T, 2015, PROC CVPR IEEE, P2021, DOI 10.1109/CVPR.2015.7298813; Delvinioti A, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P321; Elboher E, 2013, IEEE T IMAGE PROCESS, V22, P3062, DOI 10.1109/TIP.2013.2257811; Forssen Per-Erik, 2007, P IEEE INT C COMP VI, P1, DOI DOI 10.1109/ICCV.2007.4409025; Hel-Or Y, 2014, IEEE T PATTERN ANAL, V36, P317, DOI 10.1109/TPAMI.2013.138; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Huawen Liu, 2010, Proceedings 2010 9th International Conference on Grid and Cloud Computing (GCC 2010), P52, DOI 10.1109/GCC.2010.23; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Jegou H, 2007, CVPR, P1, DOI DOI 10.1109/CVPR.2007.382970; Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880; Kim HY, 2007, LECT NOTES COMPUT SC, V4872, P100; Korman S, 2013, PROC CVPR IEEE, P2331, DOI 10.1109/CVPR.2013.302; Li T.t., 2015, INT C YOUNG COMP SCI, P276; Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Olson CF, 2002, IEEE T PATTERN ANAL, V24, P853, DOI 10.1109/TPAMI.2002.1008392; Oron S, 2015, INT J COMPUT VISION, V111, P213, DOI 10.1007/s11263-014-0740-6; Ouyang WL, 2012, IEEE T PATTERN ANAL, V34, P127, DOI 10.1109/TPAMI.2011.106; Ozaki K, 2011, P 15 C COMPUTATIONAL, P154; Pele O, 2008, IEEE T PATTERN ANAL, V30, P1427, DOI 10.1109/TPAMI.2007.70794; Perdoch M., 2007, P 11 IEEE INT C COMP, P1; Perez P, 2002, LECT NOTES COMPUT SC, V2350, P661; Pomeranz D, 2011, PROC CVPR IEEE, P9, DOI 10.1109/CVPR.2011.5995331; Qin DF, 2011, PROC CVPR IEEE, P777, DOI 10.1109/CVPR.2011.5995373; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Shechtman E, 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383198; Shin B. G., 2007, P INT C CONTR AUT SY, P6; Sibiryakov A, 2011, PROC CVPR IEEE, P1417, DOI 10.1109/CVPR.2011.5995391; Simakov D., 2008, 2008 IEEE CVPR, P1; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Snedegor G., 2010, STAT METHODS; Tian YD, 2012, INT J COMPUT VISION, V98, P279, DOI 10.1007/s11263-011-0509-0; Tsai DM, 2002, PATTERN RECOGN LETT, V23, P191, DOI 10.1016/S0167-8655(01)00099-X; Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182; Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312	43	35	39	6	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2018	40	8					1799	1813		10.1109/TPAMI.2017.2737424	http://dx.doi.org/10.1109/TPAMI.2017.2737424			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GL6DT	28796608	Green Published, hybrid, Green Submitted			2022-12-18	WOS:000437271100002
J	Wang, T; Ling, HB				Wang, Tao; Ling, Haibin			Gracker: A Graph-Based Planar Object Tracker	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual tracking; keypoint; graph matching; pose estimation		Matching-based algorithms have been commonly used in planar object tracking. They often model a planar object as a set of keypoints, and then find correspondences between keypoint sets via descriptor matching. In previous work, unary constraints on appearances or locations are usually used to guide the matching. However, these approaches rarely utilize structure information of the object, and are thus suffering from various perturbation factors. In this paper, we proposed a graph-based tracker, named Gracker, which is able to fully explore the structure information of the object to enhance tracking performance. We model a planar object as a graph, instead of a simple collection of keypoints, to represent its structure. Then, we reformulate tracking as a sequential graph matching process, which establishes keypoint correspondence in a geometric graph matching manner. For evaluation, we compare the proposed Gracker with state-of-the-art planar object trackers on three benchmark datasets: two public ones and a newly collected one. Experimental results show that Gracker achieves robust tracking results against various environmental variations, and outperforms other algorithms in general on the datasets.	[Wang, Tao] Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Mining, Beijing 100044, Peoples R China; [Ling, Haibin] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China; [Ling, Haibin] HiScene Informat Technol, Meitu HiScene Lab, Shanghai 201210, Peoples R China	Beijing Jiaotong University; South China University of Technology	Ling, HB (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China.	twang@bjtu.edu.cn; hbling@temple.edu		Ling, Haibin/0000-0003-4094-8413	China National Key Research and Development Plan [2016YFB1001200]; National Nature Science Foundation of China [61673048, 61672088, 61671048, 61472028, 61528204, 61502026, 61370060]; Fundamental Research Funds for the Central universities [2017JBZ108]; HiScene Information Technologies	China National Key Research and Development Plan; National Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central universities(Fundamental Research Funds for the Central Universities); HiScene Information Technologies	This work is supported by China National Key Research and Development Plan (Grant No. 2016YFB1001200), the National Nature Science Foundation of China (nos. 61673048, 61672088, 61671048, 61472028, 61528204, 61502026 and 61370060), the Fundamental Research Funds for the Central universities (2017JBZ108), and a Research Grant from HiScene Information Technologies.	Adam A., 2006, IEEE C COMP VIS PATT; [Anonymous], 2012, LNCS, DOI DOI 10.1007/978-3-642-33765-9_51; Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bouachir W, 2014, IEEE WINT CONF APPL, P877, DOI 10.1109/WACV.2014.6836011; Cai ZW, 2014, IEEE T IMAGE PROCESS, V23, P5497, DOI 10.1109/TIP.2014.2364919; Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56; Cehovin L, 2013, IEEE T PATTERN ANAL, V35, P941, DOI 10.1109/TPAMI.2012.145; Cho M, 2010, LECT NOTES COMPUT SC, V6315, P492; Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221; Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490; Dowson N, 2008, IEEE T PATTERN ANAL, V30, P180, DOI 10.1109/TPAMI.2007.70757; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Foggia P, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414500013; Gauglitz S, 2011, INT J COMPUT VISION, V94, P335, DOI 10.1007/s11263-011-0431-5; Grabner H, 2006, IEEE C COMP VIS PATT, P260; Grabner M, 2007, PROC CVPR IEEE, P200; Hare S, 2012, PROC CVPR IEEE, P1894, DOI 10.1109/CVPR.2012.6247889; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Holzer S, 2012, LECT NOTES COMPUT SC, V7572, P470, DOI 10.1007/978-3-642-33718-5_34; Hua G, 2006, IEEE COMP SOC C COMP, V2006, P650; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809; Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79; Kwon J, 2014, IEEE T PATTERN ANAL, V36, P625, DOI 10.1109/TPAMI.2013.170; LEE DT, 1980, INT J COMPUT INF SCI, V9, P219, DOI 10.1007/BF00977785; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188; Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542; Lin Chen, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4429, DOI 10.1109/ICRA.2017.7989512; Liu ZY, 2014, IEEE T PATTERN ANAL, V36, P1258, DOI 10.1109/TPAMI.2013.223; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Malis E, 2004, IEEE INT CONF ROBOT, P1843, DOI 10.1109/ROBOT.2004.1308092; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Nebehay G, 2014, IEEE WINT CONF APPL, P862, DOI 10.1109/WACV.2014.6836013; NejhumShahed S. M., 2008, IEEE C COMP VIS PATT, P1; Ozuysal M, 2010, IEEE T PATTERN ANAL, V32, P448, DOI 10.1109/TPAMI.2009.23; Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275; Roy A, 2015, IEEE INT CONF ROBOT, P2448, DOI 10.1109/ICRA.2015.7139526; Takacs G, 2010, PROC CVPR IEEE, P934, DOI 10.1109/CVPR.2010.5540116; Tan DJ, 2014, PROC CVPR IEEE, P1202, DOI 10.1109/CVPR.2014.157; Tang F, 2008, IEEE T CIRC SYST VID, V18, P1064, DOI 10.1109/TCSVT.2008.927106; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Wagner D, 2010, IEEE T VIS COMPUT GR, V16, P355, DOI 10.1109/TVCG.2009.99; Wang T, 2016, AAAI CONF ARTIF INTE, P3625; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Yang M, 2009, IEEE T PATTERN ANAL, V31, P1195, DOI 10.1109/TPAMI.2008.146; Zaslavskiy M, 2009, IEEE T PATTERN ANAL, V31, P2227, DOI 10.1109/TPAMI.2008.245; Zhang L, 2013, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2013.240; Zhou F, 2013, PROC CVPR IEEE, P2922, DOI 10.1109/CVPR.2013.376	53	35	36	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2018	40	6					1494	1501		10.1109/TPAMI.2017.2716350	http://dx.doi.org/10.1109/TPAMI.2017.2716350			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GE9BK	28641246				2022-12-18	WOS:000431524700016
J	Ramisa, A; Yan, F; Moreno-Noguer, F; Mikolajczyk, K				Ramisa, Arnau; Yan, Fei; Moreno-Noguer, Francesc; Mikolajczyk, Krystian			BreakingNews: Article Annotation by Image and Text Processing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						News dataset; story illustration; geolocation; caption generation; vision and text	GENERATION; ENGINE; SCENE	Building upon recent Deep Neural Network architectures, current approaches lying in the intersection of Computer Vision and Natural Language Processing have achieved unprecedented breakthroughs in tasks like automatic captioning or image retrieval. Most of these learning methods, though, rely on large training sets of images associated with human annotations that specifically describe the visual content. In this paper we propose to go a step further and explore the more complex cases where textual descriptions are loosely related to the images. We focus on the particular domain of news articles in which the textual content often expresses connotative and ambiguous relations that are only suggested but not directly inferred from images. We introduce an adaptive CNN architecture that shares most of the structure for multiple tasks including source detection, article illustration and geolocation of articles. Deep Canonical Correlation Analysis is deployed for article illustration, and a new loss function based on Great Circle Distance is proposed for geolocation. Furthermore, we present BreakingNews, a novel dataset with approximately 100K news articles including images, text and captions, and enriched with heterogeneous meta-data (such as GPS coordinates and user comments). We show this dataset to be appropriate to explore all aforementioned problems, for which we provide a baseline performance using various Deep Learning architectures, and different representations of the textual and visual features. We report very promising results and bring to light several limitations of current state-of-the-art in this kind of domain, which we hope will help spur progress in the field.	[Ramisa, Arnau; Moreno-Noguer, Francesc] CSIC UPC, Inst Robot & Informat Ind, Barcelona 08028, Spain; [Yan, Fei] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England; [Mikolajczyk, Krystian] Imperial Coll London, Dept Elect & Elect Engn, London SW7 2AZ, England	Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Institut de Robotica i Informatica Industrial (IRII); Universitat Politecnica de Catalunya; University of Surrey; Imperial College London	Moreno-Noguer, F (corresponding author), CSIC UPC, Inst Robot & Informat Ind, Barcelona 08028, Spain.	aramisa@iri.upc.edu; f.yan@surrey.ac.uk; fmoreno@iri.upc.edu; k.mikolajczyk@imperial.ac.uk			MINECO project RobInstruct [TIN2014-58178-R]; Spanish State Research Agency through the Maria de Maeztu Seal of Excellence [IRI MDM-2016-0656]; ERA-net CHISTERA project [VISEN PCIN-2013-047]; EPSRC [EP/K01904X/2, EP/N007743/1]; Engineering and Physical Sciences Research Council [EP/K01904X/2, EP/N007743/1] Funding Source: researchfish	MINECO project RobInstruct; Spanish State Research Agency through the Maria de Maeztu Seal of Excellence(Spanish Government); ERA-net CHISTERA project; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was partly funded by the MINECO project RobInstruct TIN2014-58178-R, by the Spanish State Research Agency through the Maria de Maeztu Seal of Excellence to IRI MDM-2016-0656, and by the ERA-net CHISTERA project VISEN PCIN-2013-047. Fei Yan and Krystian Mikolajczyk were funded by EPSRC EP/K01904X/2 Visen and EP/N007743/1 FACER2VM projects. The authors would like to thank Nvidia for the hardware donation under the GPU grant program and Blaz Novak for his help with the IJS Newsfeed. Arnau Ramisa and Fei Yan contributed equally.	Andrew Galen, 2013, ICML; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2015, CORR; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Barnard K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P408, DOI 10.1109/ICCV.2001.937654; Cao L, 2009, P 17 ACM INT C MULT, P125; Chang A., 2014, P WORKSH INT LANG LE, P14; Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610; Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856; Coelho Filipe, 2012, Advances in Information Retrieval. Proceedings of the 34th European Conference on IR Research (ECIR 2012), P329, DOI 10.1007/978-3-642-28997-2_28; Collobert R, 2011, J MACH LEARN RES, V12, P2493; Coyne B, 2001, COMP GRAPH, P487, DOI 10.1145/383259.383316; Crandall David J, 2009, P INT C WORLD WID WE, DOI DOI 10.1145/1526709.1526812; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Denkowski Michael, 2014, P 9 WORKSH STAT MACH, P376, DOI DOI 10.3115/V1/W14-3348; Ding J., 2000, P 26 INT C VER LARG, P545; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Douze M, 2011, PROC CVPR IEEE, P745, DOI 10.1109/CVPR.2011.5995595; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754; Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2; Feng Y., 2010, HUMAN LANGUAGE TECHN, P831; Feng YS, 2013, IEEE T PATTERN ANAL, V35, P797, DOI 10.1109/TPAMI.2012.118; Gobron S, 2010, VISUAL COMPUT, V26, P505, DOI 10.1007/s00371-010-0446-x; Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Hays James, 2008, CVPR, DOI DOI 10.1109/CVPR.2008.4587784; Hermann K., 2014, P INT C LEARN REPR; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hollink L., 2016, 10 INT C LANG RES EV; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Huang CJ, 2013, CONF TECHNOL APPL, P67, DOI 10.1109/TAAI.2013.26; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jiang Y, 2016, MULTIMEDIA SYST, V22, P5, DOI 10.1007/s00530-014-0371-3; Jingna Mao, 2015, 2015 IEEE Biomedical Circuits and Systems Conference (BioCAS), P1, DOI 10.1109/BioCAS.2015.7348279; Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494; Joshi D, 2006, ACM T MULTIM COMPUT, V2, P68, DOI 10.1145/1126004.1126008; Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062; Kalogerakis E, 2009, IEEE I CONF COMP VIS, P253, DOI 10.1109/ICCV.2009.5459259; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kim Y., 2014, P 2014 C EMPIRICAL M, DOI [10.3115/v1/D14-1181, DOI 10.3115/V1/D14-1181]; Kiros R., 2015, TACL; Koppel M, 2011, LANG RESOUR EVAL, V45, P83, DOI 10.1007/s10579-009-9111-2; Kovashka A, 2015, INT J COMPUT VISION, V115, P185, DOI 10.1007/s11263-015-0814-0; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar N, 2008, LECT NOTES COMPUT SC, V5305, P340, DOI 10.1007/978-3-540-88693-8_25; Li Z, 2011, P 19 ACM INT C MULT, P133; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Malinowski M., 2014, ADV NEURAL INFORM PR, V27, P1682; Mardia K.V., 1979, MULTIVARIATE ANAL; Mikolov T., 2013, ARXIV; Mikolov Tomas., 2013, ADV NEURAL INFORM PR, P3111, DOI DOI 10.1162/JMLR.2003.3.4-5.951; Narayanan A, 2012, P IEEE S SECUR PRIV, P300, DOI 10.1109/SP.2012.46; Novak Blaz, 2012, P 15 INT INF SCI C I, P431; Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2; Ordonez V, 2016, INT J COMPUT VISION, V119, P46, DOI 10.1007/s11263-015-0840-y; Ordonez Vicente, 2011, ADV NEURAL INFORM PR, P1143; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pennington Jeffrey., 2014, P 2014 C EMP METH NA, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]; Perlin K., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P205, DOI 10.1145/237170.237258; Quattoni A., 2016, P C N AM CHAPT ASS C, P552; Le Q, 2014, PR MACH LEARN RES, V32, P1188; Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.1002/ACP.3140; Rasiwasia N, 2007, IEEE T MULTIMEDIA, V9, P923, DOI 10.1109/TMM.2007.900138; Serdyukov P, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P484, DOI 10.1145/1571941.1572025; SOCHER R, 2010, PROC CVPR IEEE, P966, DOI DOI 10.1109/CVPR.2010.5540112; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Stamatatos E, 2009, J AM SOC INF SCI TEC, V60, P538, DOI 10.1002/asi.21001; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; VEDANTAM R, 2015, PROC CVPR IEEE, P4566, DOI DOI 10.1109/CVPR.2015.7299087; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541; Weyand T., 2016, P EUR C COMP VIS; Wing B.P., 2011, P 49 ANN M ASS COMP, P955; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966; Young P., 2014, P TACL, V2, P67, DOI 10.1162/tacl_a_00166; Yu LC, 2015, IEEE I CONF COMP VIS, P2461, DOI 10.1109/ICCV.2015.283; Zhiyu W, 2014, ACM T MULTIM COMPUT, V34, P1, DOI [10.1145/2661331, DOI 10.1145/2661331]; Zhou Bolei, 2014, ADV NEURAL INFORM PR, P7, DOI DOI 10.5555/2968826.2968881; Zhou Youjie, 2012, P 20 ACM INT C MULTI, P741; Zitnick CL, 2013, IEEE I CONF COMP VIS, P1681, DOI 10.1109/ICCV.2013.211	86	35	35	0	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2018	40	5					1072	1085		10.1109/TPAMI.2017.2721945	http://dx.doi.org/10.1109/TPAMI.2017.2721945			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GB2RB	28682246	Green Submitted			2022-12-18	WOS:000428901200005
J	Mao, Q; Wang, L; Tsang, IW; Sun, YJ				Mao, Qi; Wang, Li; Tsang, Ivor W.; Sun, Yijun			Principal Graph and Structure Learning Based on Reversed Graph Embedding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Principal curve; principal graph; structure learning	FRAMEWORK; TOPOLOGY; PROFILE; CURVES	Many scientific datasets are of high dimension, and the analysis usually requires retaining the most important structures of data. Principal curve is a widely used approach for this purpose. However, many existing methods work only for data with structures that are mathematically formulated by curves, which is quite restrictive for real applications. A few methods can overcome the above problem, but they either require complicated human-made rules for a specific task with lack of adaption flexibility to different tasks, or cannot obtain explicit structures of data. To address these issues, we develop a novel principal graph and structure learning framework that captures the local information of the underlying graph structure based on reversed graph embedding. As showcases, models that can learn a spanning tree or a weighted undirected l(1) graph are proposed, and a new learning algorithm is developed that learns a set of principal points and a graph structure from data, simultaneously. The new algorithm is simple with guaranteed convergence. We then extend the proposed framework to deal with large-scale data. Experimental results on various synthetic and six real world datasets show that the proposed method compares favorably with baselines and can uncover the underlying structure correctly.	[Mao, Qi] HERE Co, Chicago, IL 60606 USA; [Wang, Li] Univ Illinois, Dept Math Stat & Comp Sci, Chicago, IL 60607 USA; [Tsang, Ivor W.] Univ Technol Sydney, Ctr Artificial Intelligence, Ultimo, NSW 2007, Australia; [Sun, Yijun] SUNY Buffalo, Dept Microbiol & Immunol, Buffalo, NY 14228 USA	University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital; University of Technology Sydney; State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Mao, Q (corresponding author), HERE Co, Chicago, IL 60606 USA.	qimao.here@gmail.com; liwang8@uic.edu; ivor.tsang@uts.edu.au; yijunsun@buffalo.edu	Sun, Yijun/F-9698-2017	Tsang, Ivor/0000-0001-8095-4637	ARC Future Fellowship [FT130100746]; ARC grant [LP150100671]; NATIONAL INSTITUTE OF ALLERGY AND INFECTIOUS DISEASES [R01AI125982] Funding Source: NIH RePORTER	ARC Future Fellowship(Australian Research Council); ARC grant(Australian Research Council); NATIONAL INSTITUTE OF ALLERGY AND INFECTIOUS DISEASES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Allergy & Infectious Diseases (NIAID))	Ivor W. Tsang is supported by the ARC Future Fellowship FT130100746 and ARC grant LP150100671.	Andersen E., 2000, HIGH PERFORMANCE OPT, P197, DOI DOI 10.1007/978-1-4757-3216-0_8; Belkin M, 2002, ADV NEUR IN, V14, P585; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Carlsson G, 2009, B AM MATH SOC, V46, P255, DOI 10.1090/S0273-0979-09-01249-X; Carreira-Perpinan M.A., 2015, ARXIV150300687; Chen X., 2011, P AAAI C ARTIFICIAL, DOI 10.1109/TCYB.2014.2358564; Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Cheung M., 2008, MINIMUM COST SPANNIN; Creighton CJ, 2012, BIOL-TARGETS THER, V6, P289, DOI 10.2147/BTT.S29923; Curtis C, 2012, NATURE, V486, P346, DOI 10.1038/nature10983; Dey TK, 2013, DISCRETE COMPUT GEOM, V49, P46, DOI 10.1007/s00454-012-9463-z; Elhamifar Ehsan, 2011, ADV NEURAL INF PROCE, V24, P3; ERWIN E, 1992, BIOL CYBERN, V67, P47, DOI 10.1007/BF00201801; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; Ge X., 2011, ADV NEURAL INF PROCE, V24, P837; Gorban A, 2005, COMPUTING, V75, P359, DOI 10.1007/s00607-005-0122-6; Gorban A, 2007, APPL MATH LETT, V20, P382, DOI 10.1016/j.aml.2006.04.022; Gorban A. N., 2009, P HDB RES MACH LEARN, P28; Gorban A. N., 2001, P ART NEUR NETW ENG, V11, P363; Gorban AN, 2010, INT J NEURAL SYST, V20, P219, DOI 10.1142/S0129065710002383; Greaves M, 2012, NATURE, V481, P306, DOI 10.1038/nature10762; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; Hein, 2009, ADV NEURAL INFORM PR, P1025; Jebara T., 2009, P 26 ANN INT C MACHI, P441, DOI [10.1145/1553374.1553432, DOI 10.1145/1553374.1553432]; Kegl B, 2002, IEEE T PATTERN ANAL, V24, P59, DOI 10.1109/34.982884; Kegl B, 2000, IEEE T PATTERN ANAL, V22, P281, DOI 10.1109/34.841759; Kegl B., 1999, THESIS; Kohonen T, 1997, SELF ORGANIZING MAPS; Kruskal J. B., 1958, P AM MATH SOC, V7, P48; Kumar S, 2012, J MACH LEARN RES, V13, P981; Lake BM, 2010, COGNITION IN FLUX, P778; LOWE M, 1993, THEOR COMPUT SCI, V109, P181, DOI 10.1016/0304-3975(93)90068-5; Mao Q., 2010, P 26 C UNC ART INT, P350; Mao Q., 2015, P 2015 SIAM INT C DA, P792, DOI [10.1137/1.9781611974010.89, DOI 10.1137/1.9781611974010.89]; Mao Q, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P765, DOI 10.1145/2783258.2783309; Mao Q, 2017, MACH LEARN, V106, P627, DOI 10.1007/s10994-016-5602-8; Miao DQ, 2007, PATTERN RECOGN LETT, V28, P2184, DOI 10.1016/j.patrec.2007.07.001; NAGL M, 1976, COMPUTING, V16, P113, DOI 10.1007/BF02241984; Nicolau M, 2011, P NATL ACAD SCI USA, V108, P7265, DOI 10.1073/pnas.1102826108; Ozertem U, 2008, INT CONF ACOUST SPEE, P1893, DOI 10.1109/ICASSP.2008.4518004; Ozertem U, 2011, J MACH LEARN RES, V12, P1249; Parker JS, 2009, J CLIN ONCOL, V27, P1160, DOI 10.1200/JCO.2008.18.1370; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Russell S. J, 2002, ADV NEURAL INFORM PR, P12, DOI DOI 10.5555/2968618.2968683; Sandilya S, 2002, IEEE T INFORM THEORY, V48, P2789, DOI 10.1109/TIT.2002.802614; Singh G., 2007, PRESENTED AT THE EUR; Smola AJ, 2001, J MACH LEARN RES, V1, P179, DOI 10.1162/15324430152748227; Song L., 2007, ICML, P815; Sun YJ, 2014, GENOME BIOL, V15, DOI 10.1186/s13059-014-0440-0; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tibshirani R., 1992, Statistics and Computing, V2, P183, DOI 10.1007/BF01889678; Wagstaff K., 2001, ICML, V1, P577, DOI DOI 10.1109/TPAMI.2002.1017616; Wang L, 2017, AAAI CONF ARTIF INTE, P2703; WEINBERGER KQ, 2006, AAAI 06, V2, P1683; Witten DM, 2010, J AM STAT ASSOC, V105, P713, DOI 10.1198/jasa.2010.tm09415; Yan DH, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P907; Zhuang JF, 2011, J MACH LEARN RES, V12, P1313	59	35	37	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2017	39	11					2227	2241		10.1109/TPAMI.2016.2635657	http://dx.doi.org/10.1109/TPAMI.2016.2635657			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FI5MO	28114001	Green Published, Green Accepted			2022-12-18	WOS:000412028600009
J	Saurer, O; Vasseur, P; Boutteau, R; Demonceaux, C; Pollefeys, M; Fraundorfer, F				Saurer, Olivier; Vasseur, Pascal; Boutteau, Remi; Demonceaux, Cedric; Pollefeys, Marc; Fraundorfer, Friedrich			Homography Based Egomotion Estimation with a Common Direction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; egomotion estimation; homography estimation; structure-from-motion	VISION; MOTION	In this paper, we explore the different minimal solutions for egomotion estimation of a camera based on homography knowing the gravity vector between calibrated images. These solutions depend on the prior knowledge about the reference plane used by the homography. We then demonstrate that the number of matched points can vary from two to three and that a direct closed-form solution or a Grobner basis based solution can be derived according to this plane. Many experimental results on synthetic and real sequences in indoor and outdoor environments show the efficiency and the robustness of our approach compared to standard methods.	[Saurer, Olivier; Pollefeys, Marc] Swiss Fed Inst Technol, Comp Vis & Geometry Grp, Dept Comp Sci, Zurich, Switzerland; [Vasseur, Pascal] Univ Rouen, LITIS, Rouen, France; [Boutteau, Remi] ESIGELEC, IRSEEM, Rouen, France; [Demonceaux, Cedric] Univ Bourgogne, UMR CNRS 6306, Le2i, Dijon, France; [Fraundorfer, Friedrich] Graz Univ Technol, Inst Comp Graph & Vis, Graz, Austria	Swiss Federal Institutes of Technology Domain; ETH Zurich; Universite de Rouen Normandie; Universite de Bourgogne; Graz University of Technology	Saurer, O (corresponding author), Swiss Fed Inst Technol, Comp Vis & Geometry Grp, Dept Comp Sci, Zurich, Switzerland.	saurero@inf.ethz.ch; pascal.vasseur@univ-rouen.fr; remi.boutteau@esigelec.fr; cedric.demonceaux@u-bourgogne.fr; marc.pollefeys@inf.ethz.ch; fraundorfer@icg.tugraz.at	Demonceaux, Cédric/S-5643-2017; Pollefeys, Marc/I-7607-2013; Boutteau, Rémi/U-7674-2019	Demonceaux, Cédric/0000-0001-6916-1273; Boutteau, Rémi/0000-0003-1078-5043	Project ANR Blanc International [DrAACaR-ANR-11-IS03-0003]; Google Award	Project ANR Blanc International(French National Research Agency (ANR)); Google Award(Google Incorporated)	This work has been partially supported by Project ANR Blanc International DrAACaR-ANR-11-IS03-0003 and a Google Award. The authors also thank the anonymous reviewers for their useful discussions and constructive comments.	Bazin JC, 2010, COMPUT VIS IMAGE UND, V114, P254, DOI 10.1016/j.cviu.2009.04.006; Bazin JC, 2013, IEEE T PATTERN ANAL, V35, P1565, DOI 10.1109/TPAMI.2012.264; Bazin JC, 2012, INT J ROBOT RES, V31, P63, DOI 10.1177/0278364911421954; Corke P, 2004, J ROBOTIC SYST, V21, P43, DOI 10.1002/rob.10127; Coughlan J.M., 1999, P ICCV, V2, P941, DOI DOI 10.1109/ICCV.1999.790349; Cox D., 2007, UNDERGRADUATE TEXTS; Domke J, 2006, IEEE INT CONF ROBOT, P2053, DOI 10.1109/ROBOT.2006.1642007; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fraundorfer F, 2010, LECT NOTES COMPUT SC, V6314, P269, DOI 10.1007/978-3-642-15561-1_20; Furukawa Y, 2009, IEEE I CONF COMP VIS, P80, DOI 10.1109/ICCV.2009.5459145; Furukawa Y, 2009, PROC CVPR IEEE, P1422, DOI 10.1109/CVPRW.2009.5206867; Gim Hee Lee, 2011, IEEE International Conference on Robotics and Automation, P3139; Hartley R., 2004, ROBOTICA; Kalantari M, 2011, J MATH IMAGING VIS, V39, P259, DOI 10.1007/s10851-010-0234-2; Kneip L., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P4546, DOI 10.1109/ICRA.2011.5980127; Kukelova Z, 2008, LECT NOTES COMPUT SC, V5304, P302, DOI 10.1007/978-3-540-88690-7_23; Lee DC, 2009, PROC CVPR IEEE, P2136, DOI 10.1109/CVPRW.2009.5206872; Li B, 2013, IEEE INT C INT ROBOT, P1595, DOI 10.1109/IROS.2013.6696562; Lobo J, 2003, IEEE T PATTERN ANAL, V25, P1597, DOI 10.1109/TPAMI.2003.1251152; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Martinelli A, 2014, INT J COMPUT VISION, V106, P138, DOI 10.1007/s11263-013-0647-7; Naroditsky O, 2012, IEEE T PATTERN ANAL, V34, P818, DOI 10.1109/TPAMI.2011.226; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; Oreifej O, 2011, IEEE INT CONF ROBOT, P1159; Ortin D, 2001, ROBOTICA, V19, P331, DOI 10.1017/S0263574700003143; Rothermel D. F. M., 2014, P LC3D WORKSH; Saurer O., 2012, P VIC WORKSH IROS; Saurer O., 2014, P AS C COMP VIS, P288; Scaramuzza D, 2011, INT J COMPUT VISION, V95, P74, DOI 10.1007/s11263-011-0441-3; Schonberger J.L., 2014, INT ARCH PHOTOGRAMME, VXL-3, P305, DOI DOI 10.5194/ISPRSARCHIVES-XL-3-305-2014; Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773; Troiani C., 2013, P 6 EUR C MOB ROB; Troiani C, 2014, IEEE INT CONF ROBOT, P5530, DOI 10.1109/ICRA.2014.6907672; Troiani C, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P13, DOI 10.1109/ECMR.2013.6698813; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Vieville T., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P591, DOI 10.1109/ICCV.1993.378157; Weiss S, 2011, IEEE INT CONF ROBOT	37	35	35	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	2					327	341		10.1109/TPAMI.2016.2545663	http://dx.doi.org/10.1109/TPAMI.2016.2545663			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8HZ	27019476	Green Published			2022-12-18	WOS:000395553400009
J	Lopez, MB; Boutellaa, E; Hadid, A				Lopez, Miguel Bordallo; Boutellaa, Elhocine; Hadid, Abdenour			Comments on the "Kinship Face in the Wild" Data Sets	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Kinship verification; face recognition; biometrics		The Kinship Face in the Wild data sets, recently published in TPAMI, are currently used as a benchmark for the evaluation of kinship verification algorithms. We recommend that these data sets are no longer used in kinship verification research unless there is a compelling reason that takes into account the nature of the images. We note that most of the image kinship pairs are cropped from the same photographs. Exploiting this cropping information, competitive but biased performance can be obtained using a simple scoring approach, taking only into account the nature of the image pairs rather than any features about kin information. To illustrate our motives, we provide classification results utilizing a simple scoring method based on the image similarity of both images of a kinship pair. Using simply the distance of the chrominance averages of the images in the Lab color space without any training or using any specific kin features, we achieve performance comparable to state-of-the-art methods. We provide the source code to prove the validity of our claims and ensure the repeatability of our experiments.	[Lopez, Miguel Bordallo] Univ Oulu, Ctr Machine Vis & Signal Anal CMVS, SF-90100 Oulu, Finland; [Boutellaa, Elhocine] CDTA, Algiers, Algeria; [Boutellaa, Elhocine; Hadid, Abdenour] Univ Oulu, CMVS, SF-90100 Oulu, Finland; [Hadid, Abdenour] Northwestern Polytech Univ, Sch Elect & Informat, Xian, Shaanxi, Peoples R China	University of Oulu; Centre for the Development of Advanced Technologies (CDTA); University of Oulu; Northwestern Polytechnical University	Lopez, MB (corresponding author), Univ Oulu, Ctr Machine Vis & Signal Anal CMVS, SF-90100 Oulu, Finland.	miguelbl@ee.oulu.fi; eboutell@ee.oulu.fi; hadid@ee.oulu.fi	Bordallo Lopez, Miguel/G-1685-2013	Bordallo Lopez, Miguel/0000-0002-5707-9085				Dehghan A, 2014, PROC CVPR IEEE, P1757, DOI 10.1109/CVPR.2014.227; Dhall Abhinav, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163151; Dibeklioglu H, 2013, IEEE I CONF COMP VIS, P1497, DOI 10.1109/ICCV.2013.189; Dong J, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P157, DOI 10.1109/VCIP.2014.7051528; Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590; Guo YH, 2014, INT C PATT RECOG, P4287, DOI 10.1109/ICPR.2014.735; Lu J., 2014, P IEEE ACM DES AUT C, P1; Lu JM, 2015, AER ADV ENG RES, V39, P1; Lu JW, 2013, IEEE I CONF COMP VIS, P329, DOI 10.1109/ICCV.2013.48; Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134; Shao M., 2011, PROC CVPR WORKSHOPS, P60, DOI DOI 10.1109/CVPRW.2011.5981801; Wang XL, 2014, IEEE IMAGE PROC, P5017, DOI 10.1109/ICIP.2014.7026016; Yan HB, 2015, IEEE T CYBERNETICS, V45, P2535, DOI 10.1109/TCYB.2014.2376934; Yan HB, 2014, IEEE T INF FOREN SEC, V9, P1169, DOI 10.1109/TIFS.2014.2327757	14	35	37	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2016	38	11					2342	2344		10.1109/TPAMI.2016.2522416	http://dx.doi.org/10.1109/TPAMI.2016.2522416			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DZ6AW	26829776				2022-12-18	WOS:000385945000016
J	Yu, MY; Shao, L; Zhen, XT; He, XF				Yu, Mengyang; Shao, Ling; Zhen, Xiantong; He, Xiaofei			Local Feature Discriminant Projection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dimensionality reduction; local feature; image-to-class distance; fisher vector; image classification	IMAGE; REPRESENTATION	In this paper, we propose a novel subspace learning algorithm called Local Feature Discriminant Projection (LFDP) for supervised dimensionality reduction of local features. LFDP is able to efficiently seek a subspace to improve the discriminability of local features for classification. We make three novel contributions. First, the proposed LFDP is a general supervised subspace learning algorithm which provides an efficient way for dimensionality reduction of large-scale local feature descriptors. Second, we introduce the Differential Scatter Discriminant Criterion (DSDC) to the subspace learning of local feature descriptors which avoids the matrix singularity problem. Third, we propose a generalized orthogonalization method to impose on projections, leading to a more compact and less redundant subspace. Extensive experimental validation on three benchmark datasets including UIUC-Sports, Scene-15 and MIT Indoor demonstrates that the proposed LFDP outperforms other dimensionality reduction methods and achieves state-of-the-art performance for image classification.	[Yu, Mengyang; Shao, Ling] Northumbria Univ, Dept Comp Sci & Digital Technol, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England; [Zhen, Xiantong] Univ Western Ontario, Dept Med Biophys, London, ON N6A 4V2, Canada; [He, Xiaofei] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China	Northumbria University; Western University (University of Western Ontario); Zhejiang University	Yu, MY (corresponding author), Northumbria Univ, Dept Comp Sci & Digital Technol, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England.	m.y.yu@ieee.org; ling.shao@ieee.org; zhenxt@gmail.com; xiaofeihe@cad.zju.edu.cn	Shao, Ling/D-3535-2011	Shao, Ling/0000-0002-8264-6117	Northumbria University; National Natural Science Foundation of China [61528106]	Northumbria University; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by Northumbria University and in part by National Natural Science Foundation of China under Grant 61528106. The corresponding author is Ling Shao.	Belkin M, 2002, ADV NEUR IN, V14, P585; Bengio Y, 2004, ADV NEUR IN, V16, P177; Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598; Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945; Cai HP, 2011, IEEE T PATTERN ANAL, V33, P338, DOI 10.1109/TPAMI.2010.89; DUCHENE J, 1988, IEEE T PATTERN ANAL, V10, P978, DOI 10.1109/34.9121; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Geng B, 2012, IEEE T PATTERN ANAL, V34, P1227, DOI 10.1109/TPAMI.2012.57; Golub Gene H., 2013, MATRIX COMPUTATION, V3; He X., 2003, P NIPS, P1; He XF, 2005, IEEE I CONF COMP VIS, P1208; Hua G, 2007, IEEE I CONF COMP VIS, P229; Jaakkola TS, 1999, ADV NEUR IN, V11, P487; Ke Y, 2004, PROC CVPR IEEE, P506; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496; Lee H, 2016, ADV NEURAL INFORM PR, V19; Li LJ, 2007, IEEE I CONF COMP VIS, P345; Li LJ, 2014, INT J COMPUT VISION, V107, P20, DOI 10.1007/s11263-013-0660-x; Liu BD, 2014, LECT NOTES COMPUT SC, V8690, P600, DOI 10.1007/978-3-319-10605-2_39; Liu L., 2014, P ADV NEUR INF PROC, V27, P1143; Liu L, 2015, ADV SOC SCI EDUC HUM, V22, P1, DOI 10.1109/APMC.2015.7412943; Liu L, 2015, IEEE T IMAGE PROCESS, V24, P956, DOI 10.1109/TIP.2015.2390975; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Perronnin F., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383266; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Sadeghi F, 2012, LECT NOTES COMPUT SC, V7576, P228, DOI 10.1007/978-3-642-33715-4_17; Shao L, 2016, INT J COMPUT VISION, V118, P115, DOI 10.1007/s11263-015-0861-6; Shao L, 2014, IEEE T NEUR NET LEAR, V25, P1359, DOI 10.1109/TNNLS.2013.2293418; Simonyan K, 2014, IEEE T PATTERN ANAL, V36, P1573, DOI 10.1109/TPAMI.2014.2301163; Sugiyama M., 2006, P INT C MACH LEAR IC, P905, DOI DOI 10.1145/1143844.1143958; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; van der Maaten L. J., 2009, 2009005 TILB U TILB; Wang X., 2013, P INT C MACHINE LEAR, P846; Wang ZX, 2010, LECT NOTES COMPUT SC, V6311, P706, DOI 10.1007/978-3-642-15549-9_51; Xiaodong Zheng, 2014, 2014 IEEE PES General Meeting: Conference & Exposition, DOI 10.1109/PESGM.2014.6938965; Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757; Yu M., 2015, IEEE T PATTERN ANAL, DOI [10.1109/TPAMI.2015.2499125, DOI 10.1109/TPAMI.2015.2499125]; Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P3241, DOI 10.1109/TIP.2014.2328894; Zhang TH, 2008, LECT NOTES COMPUT SC, V5302, P725, DOI 10.1007/978-3-540-88682-2_55; Zhen X, 2015, PROC CVPR IEEE, P1211, DOI 10.1109/CVPR.2015.7298725; Zhu F, 2014, INT J COMPUT VISION, V109, P42, DOI 10.1007/s11263-014-0703-y	46	35	36	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2016	38	9					1908	1914		10.1109/TPAMI.2015.2497686	http://dx.doi.org/10.1109/TPAMI.2015.2497686			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DT4EK	26552074	Green Accepted			2022-12-18	WOS:000381432700015
J	Eynard, D; Kovnatsky, A; Bronstein, MM; Glashoff, K; Bronstein, AM				Eynard, Davide; Kovnatsky, Artiom; Bronstein, Michael M.; Glashoff, Klaus; Bronstein, Alexander M.			Multimodal Manifold Analysis by Simultaneous Diagonalization of Laplacians	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Joint diagonalization; multimodal data; manifold alignment; manifold learning; Laplace-Beltrami operator; dimensionality reduction; diffusion distances; multimodal clustering		We construct an extension of spectral and diffusion geometry to multiple modalities through simultaneous diagonalization of Laplacian matrices. This naturally extends classical data analysis tools based on spectral geometry, such as diffusion maps and spectral clustering. We provide several synthetic and real examples of manifold learning, object classification, and clustering, showing that the joint spectral geometry better captures the inherent structure of multi-modal data. We also show the relation of many previous approaches for multimodal manifold analysis to our framework.	[Eynard, Davide; Kovnatsky, Artiom; Bronstein, Michael M.; Glashoff, Klaus] Univ Lugano USI, Fac Informat, Inst Computat Sci, Lugano, Switzerland; [Bronstein, Michael M.; Bronstein, Alexander M.] Intel, Perceptual Comp Grp, Petah Tiqwa, Israel; [Bronstein, Alexander M.] Tel Aviv Univ, Sch Elect Engn, IL-69978 Tel Aviv, Israel	Universita della Svizzera Italiana; Intel Corporation; Tel Aviv University	Eynard, D (corresponding author), Univ Lugano USI, Fac Informat, Inst Computat Sci, Lugano, Switzerland.	davide.eynard@usi.ch; artiom.kovnatsky@usi.ch; michael.bronstein@usi.ch; klaus.glashoff@math.uni-hamburg.de; bron@eng.tau.ac.il			ERC [307047, 335491]	ERC(European Research Council (ERC)European Commission)	The work of D. Eynard, A. Kovnatsky, M. M. Bronstein, and K. Glashoff was supported by the ERC Starting Grant No. 307047. The work of A. M. Bronstein was supported by the ERC Starting Grant No. 335491. M. M. Bronstein is the corresponding author of the article.	Alameda-Pineda X., 2011, P INT C MULT INT; Alpaydin E, 1998, KYBERNETIKA, V34, P369; Amini M. R., 2009, P NEUR INF PROC SYST; [Anonymous], P CIVR; Bekkerman R., 2007, P COMP VIS PATT REC; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bronstein M. M., 2013, ARXIV13076549; Bronstein M. M., 2013, ARXIV13123035; Bronstein M. M., 2010, P COMP VIS PATT REC; BUNSEGERSTNER A, 1993, SIAM J MATRIX ANAL A, V14, P927, DOI 10.1137/0614062; Cai X., 2011, P COMP VIS PATT REC; Cardoso J.-F., 1994, 94D023 TEL PAR SIGN; Cardoso JF, 1996, SIAM J MATRIX ANAL A, V17, P161, DOI 10.1137/S0895479893259546; CARDOSO JF, 1993, IEE PROC-F, V140, P362, DOI 10.1049/ip-f-2.1993.0054; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006; Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7426, DOI 10.1073/pnas.0500334102; de Sa V. R., 2005, P ICML WORKSH LEARN; Ding C., 2001, P C DAT MIN; Dong X., 2013, ARXIV13032221; Eynard D., 2012, ARXIV12092295; Glashoff K., 2013, LINEAR ALGEBRA APPL, V439, P2503; HOCHBAUM DS, 1985, MATH OPER RES, V10, P180, DOI 10.1287/moor.10.2.180; Jacobi C., 1846, J REINE ANGEW MATH, V1846, P51, DOI DOI 10.1515/CR11.1846.30.51; Kidron E., 2005, P COMP VIS PATT REC; Kovnatsky A, 2013, COMPUT GRAPH FORUM, V32, P439, DOI 10.1111/cgf.12064; Kumar A., 2011, P NEUR INF PROC SYST; Lee D.D., 2005, P ANN C UNC ART INT; Levy B., 2006, P SHAP MOD INT; Lin H., 1997, FIELDS I COMMUN, V13, P193; Liu J., 2013, P SDM; MA C, 2008, P ICASSP; McFee B, 2011, J MACH LEARN RES, V12, P491; Nadler B., 2005, P NEUR INF PROC SYST; Ng A.Y., 2001, P NEUR INF PROC SYST; Ovsjanikov M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185526; Perona P., 2004, P NEUR INF PROC SYST; Pinto N., 2009, UCSD MIT CALTECH 101; Rahbar K., 2000, P ICA; Rasiwasia N., 2010, P INT C MATH; Rong GD, 2008, VISUAL COMPUT, V24, P787, DOI 10.1007/s00371-008-0260-x; SCHONEMA.PH, 1966, PSYCHOMETRIKA, V31, P1, DOI 10.1007/BF02289451; Schutze H., 2008, INTRO INFORM RETRIEV, V39; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Tang W., 2009, P DAT MIN; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wang C, 2008, P 25 INT C MACH LEAR, P1120, DOI DOI 10.1145/1390156.1390297; Wardetzky M., 2008, DISCRETE DIFFERENTIA, P275, DOI DOI 10.1007/978-3-7643-8621-4; Weiss Y., 2008, P NEUR INF PROC SYST; Wen ZW, 2013, MATH PROGRAM, V142, P397, DOI 10.1007/s10107-012-0584-1; Weston J, 2010, MACH LEARN, V81, P21, DOI 10.1007/s10994-010-5198-3; Yeredor A, 2002, IEEE T SIGNAL PROCES, V50, P1545, DOI 10.1109/TSP.2002.1011195; ZIEHE A, 2005, THESIS	52	35	35	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2015	37	12					2505	2517		10.1109/TPAMI.2015.2408348	http://dx.doi.org/10.1109/TPAMI.2015.2408348			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CW2OK	26539854				2022-12-18	WOS:000364831700012
J	Naghibi, T; Hoffmann, S; Pfister, B				Naghibi, Tofigh; Hoffmann, Sarah; Pfister, Beat			A Semidefinite Programming Based Search Strategy for Feature Selection with Mutual Information Measure	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature selection; mutual information; convex objective; approximation ratio	ALGORITHM; CUT	Feature subset selection, as a special case of the general subset selection problem, has been the topic of a considerable number of studies due to the growing importance of data-mining applications. In the feature subset selection problem there are two main issues that need to be addressed: (i) Finding an appropriate measure function than can be fairly fast and robustly computed for high-dimensional data. (ii) A search strategy to optimize the measure over the subset space in a reasonable amount of time. In this article mutual information between features and class labels is considered to be the measure function. Two series expansions for mutual information are proposed, and it is shown that most heuristic criteria suggested in the literature are truncated approximations of these expansions. It is well-known that searching the whole subset space is an NP-hard problem. Here, instead of the conventional sequential search algorithms, we suggest a parallel search strategy based on semidefinite programming (SDP) that can search through the subset space in polynomial time. By exploiting the similarities between the proposed algorithm and an instance of the maximum-cut problem in graph theory, the approximation ratio of this algorithm is derived and is compared with the approximation ratio of the backward elimination method. The experiments show that it can be misleading to judge the quality of a measure solely based on the classification accuracy, without taking the effect of the non-optimum search strategy into account.	[Naghibi, Tofigh; Hoffmann, Sarah; Pfister, Beat] Swiss Fed Inst Technol, Comp Engn & Networks Lab, Zurich, Switzerland	Swiss Federal Institutes of Technology Domain; ETH Zurich	Naghibi, T (corresponding author), Swiss Fed Inst Technol, Comp Engn & Networks Lab, Zurich, Switzerland.	naghibi@tik.ee.ethz.ch; hoffmann@tik.ee.ethz.ch; pfister@tik.ee.ethz.ch			Swiss National Science Foundation (SNSF)	Swiss National Science Foundation (SNSF)(Swiss National Science Foundation (SNSF))	This work was partly supported by Swiss National Science Foundation (SNSF).	Abramson N., 1963, INFORM THEORY CODING; Aha D. W., 1996, LEARNING DATA ARTIFI; Asahiro Y, 2000, J ALGORITHM, V34, P203, DOI 10.1006/jagm.1999.1062; Balagani KS, 2010, IEEE T PATTERN ANAL, V32, P1342, DOI 10.1109/TPAMI.2010.62; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Bogachev V. I., 2007, MEASURE THEORY; Boyd S, 2004, CONVEX OPTIMIZATION; Brown G., 2009, JMLR WORKSH C P AIST, V5, P49; Brown G, 2012, J MACH LEARN RES, V13, P27; Ciarelli P. M., 2010, Proceedings of the 2010 Eleventh Brazilian Symposium on Neural Networks (SBRN 2010), P182, DOI 10.1109/SBRN.2010.39; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; Doak J., 1992, U CALIFORNIA DAVIS, V105; Fano R. M., 1961, TRANSMISSION INFORM; Frank A., UCI MACHINE LEARNING; Frenay B., 2012, P EUR S ART NEUR NET, P120; FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051; FRIEZE AM, 1983, DISCRETE APPL MATH, V5, P89, DOI 10.1016/0166-218X(83)90018-5; Goemans MX, 1995, J ACM, V42, P1115, DOI 10.1145/227683.227684; Grippo L, 2012, MATH PROGRAM, V136, P353, DOI 10.1007/s10107-012-0593-0; Gurban M., 2009, THESIS STI LAUSANNE; HAN TS, 1980, INFORM CONTROL, V46, P26, DOI 10.1016/S0019-9958(80)90478-7; HELLMAN ME, 1970, IEEE T INFORM THEORY, V16, P368, DOI 10.1109/TIT.1970.1054466; Hollander M., 2014, NONPARAMETRIC STAT M; Hu BG, 2014, IEEE T NEUR NET LEAR, V25, P249, DOI 10.1109/TNNLS.2013.2274799; Karger D, 2001, SIAM PROC S, P392; Killian BJ, 2007, J CHEM PHYS, V127, DOI 10.1063/1.2746329; Kohavi R., 1996, THESIS U STANFORD ST; Kwak N, 2002, IEEE T NEURAL NETWOR, V13, P143, DOI 10.1109/72.977291; Lofberg J., 2004, 2004 IEEE International Symposium on Computer Aided Control Systems Design (IEEE Cat. No.04TH8770), P284, DOI 10.1109/CACSD.2004.1393890; McGill WJ, 1954, T IRE PROF GROUP INF, V4, P93, DOI [10.1109/TIT.1954.1057469, DOI 10.1109/TIT.1954.1057469)]; Meyer P., 2006, USE VARIABLE COMPLEM; Naghibi T, 2013, INT CONF ACOUST SPEE, P3273, DOI 10.1109/ICASSP.2013.6638263; NARENDRA P, 1977, IEEE T COMPUT, V26, P917, DOI 10.1109/TC.1977.1674939; Neumann J, 2004, LECT NOTES COMPUT SC, V3175, P212; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159; POLJAK S, 1995, J GLOBAL OPTIM, V7, P51, DOI 10.1007/BF01100205; RAGHAVAN P, 1988, J COMPUT SYST SCI, V37, P130, DOI 10.1016/0022-0000(88)90003-7; Reza F M, 1961, INTRO INFORM THEORY; Rodriguez-Lujan I, 2010, J MACH LEARN RES, V11, P1491; Srivastav A., 1998, APPROXIMATION ALGORI; VAFAIE H, 1993, FIFTH INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE, TAI '93, PROCEEDINGS, P356, DOI 10.1109/TAI.1993.633981; YEUNG RW, 1991, IEEE T INFORM THEORY, V37, P466, DOI 10.1109/18.79902; Zhao XY, 2010, SIAM J OPTIMIZ, V20, P1737, DOI 10.1137/080718206	43	35	38	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2015	37	8					1529	1541		10.1109/TPAMI.2014.2372791	http://dx.doi.org/10.1109/TPAMI.2014.2372791			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CM3ON	26352993	Green Submitted			2022-12-18	WOS:000357591900001
J	Chen, JH; Tang, L; Liu, J; Ye, JP				Chen, Jianhui; Tang, Lei; Liu, Jun; Ye, Jieping			A Convex Formulation for Learning a Shared Predictive Structure from Multiple Tasks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multitask learning; shared predictive structure; alternating structure optimization; accelerated projected gradient		In this paper, we consider the problem of learning from multiple related tasks for improved generalization performance by extracting their shared structures. The alternating structure optimization (ASO) algorithm, which couples all tasks using a shared feature representation, has been successfully applied in various multitask learning problems. However, ASO is nonconvex and the alternating algorithm only finds a local solution. We first present an improved ASO formulation (iASO) for multitask learning based on a new regularizer. We then convert iASO, a nonconvex formulation, into a relaxed convex one (rASO). Interestingly, our theoretical analysis reveals that rASO finds a globally optimal solution to its nonconvex counterpart iASO under certain conditions. rASO can be equivalently reformulated as a semidefinite program (SDP), which is, however, not scalable to large datasets. We propose to employ the block coordinate descent (BCD) method and the accelerated projected gradient (APG) algorithm separately to find the globally optimal solution to rASO; we also develop efficient algorithms for solving the key subproblems involved in BCD and APG. The experiments on the Yahoo webpages datasets and the Drosophila gene expression pattern images datasets demonstrate the effectiveness and efficiency of the proposed algorithms and confirm our theoretical analysis.	[Chen, Jianhui] GE Global Res, San Ramon, CA 94583 USA; [Tang, Lei] Walmart Labs, San Bruno, CA 94066 USA; [Liu, Jun] Siemens Corp Res, Princeton, NJ 08540 USA; [Ye, Jieping] Arizona State Univ, Dept Comp Sci & Engn, Sch Comp Informat & Decis Syst Engn, Ira A Fulton Sch Engn, Tempe, AZ 85287 USA; [Ye, Jieping] Arizona State Univ, Ctr Evolutionary Med & Informat, Biodesign Inst, Tempe, AZ 85287 USA	General Electric; Wal-Mart Stores Inc; Siemens AG; Arizona State University; Arizona State University-Tempe; Arizona State University; Arizona State University-Tempe	Chen, JH (corresponding author), GE Global Res, 2623 Camino Ramon,Suite 500,Bishop Ranch 3, San Ramon, CA 94583 USA.	jchen@ge.com; leitang@acm.org; jun-liu@siemens.com; jieping.ye@asu.edu			US National Science Foundation (NSF) [IIS-0612069, IIS-0812551, CCF-0811790, IIS-0953662, CCF-1025177]; NIH [R01-HG002516]; NGA [HM1582-08-1-0016]; NATIONAL HUMAN GENOME RESEARCH INSTITUTE [R01HG002516] Funding Source: NIH RePORTER; NATIONAL LIBRARY OF MEDICINE [R01LM010730] Funding Source: NIH RePORTER	US National Science Foundation (NSF)(National Science Foundation (NSF)); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NGA; NATIONAL HUMAN GENOME RESEARCH INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Human Genome Research Institute (NHGRI)); NATIONAL LIBRARY OF MEDICINE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Library of Medicine (NLM))	This work was supported by US National Science Foundation (NSF) IIS-0612069, IIS-0812551, CCF-0811790, IIS-0953662, CCF-1025177, NIH R01-HG002516, and NGA HM1582-08-1-0016.	Ando R.K., 2007, P 2 BIOCREATIVE CHAL; Ando RK, 2005, J MACH LEARN RES, V6, P1817; Argyriou A., 2006, P ADV NEUR INF PROC; Argyriou A., 2007, P ADV NEUR INF PROC; Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8; Bach F, 2012, OPTIMIZATION FOR MACHINE LEARNING, P19; Bakker B, 2003, J MACHINE LEARNING R, V4, P83; Baxter J, 2000, J ARTIF INTELL RES, V12, P149, DOI 10.1613/jair.731; Bi J., 2008, P EUR C MACH LEARN; Bishop CM, 2006, PATTERN RECOGNITION; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; BRUCKER P, 1984, OPER RES LETT, V3, P163, DOI 10.1016/0167-6377(84)90010-5; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chapelle O, 2011, MACH LEARN, V85, P149, DOI 10.1007/s10994-010-5231-6; Chen J., 2010, P 16 ACM SIGKDD INT; Evgeniou T, 2005, J MACH LEARN RES, V6, P615; Evgeniou T., 2004, P ACM SIGKDD INT C K; Fowlkes CC, 2008, CELL, V133, P364, DOI 10.1016/j.cell.2008.01.053; Golub G. H., 2012, MATRIX COMPUTATIONS; Hastie T, 2009, ELEMENTS STAT LEARNI; Heisele B., 2001, P ADV NEUR INF PROC; Jacob L., 2008, P ADV NEUR INF PROC; Jebara T., 2004, P INT C MACH LEARN; Ji S., 2009, P 15 ACM SIGKDD INT; Ji S., 2009, P INT C MACH LEARN; Lai EC, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-7-r42; Lawrence N.D., 2004, P INT C MACH LEARN; Lecuyer E, 2007, CELL, V131, P174, DOI 10.1016/j.cell.2007.08.003; Lewis D.D., 1991, P SPEECH NAT LANG WO; Li J, 2010, INT J COMPUT VISION, V90, P150, DOI 10.1007/s11263-010-0354-6; Liu J., 2009, SLEP SPARSE LEARNING; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Nemirovski A., 1995, EFFICIENT METHODS CO; Nesterov, 1998, INTRO LECT CONVEX PR; Obozinski G., 2006, P ICML WORKSH STRUCT; OVERTON ML, 1993, MATH PROGRAM, V62, P321, DOI 10.1007/BF01585173; Pong TK, 2010, SIAM J OPTIMIZ, V20, P3465, DOI 10.1137/090763184; Quattoni A., 2007, P IEEE C COMP VIS PA; Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835; Schwaighofer A., 2004, P ADV NEUR INF PROC; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Thrun S., 1996, P INT C MACH LEARN; Ueda N., 2002, P ADV NEUR INF PROC; Xue Y, 2007, J MACH LEARN RES, V8, P35; Yu K., 2005, P INT C MACH LEARN; Yu S., 2007, P INT C MACH LEARN; Zhang J., 2005, P ADV NEUR INF PROC; Zhou J., 2011, P ADV NEUR INF PROC; Zhou J., 2012, MALSAR MULTITASK LEA	53	35	37	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2013	35	5					1025	1038		10.1109/TPAMI.2012.189	http://dx.doi.org/10.1109/TPAMI.2012.189			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	106EZ	23520249	Green Accepted			2022-12-18	WOS:000316126800001
J	Li, HS; Huang, XL; He, L				Li, Hongsheng; Huang, Xiaolei; He, Lei			Object Matching Using a Locally Affine Invariant and Linear Programming Techniques	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature matching; object matching; locally affine invariant; linear programming	ALGORITHM; SCALE	In this paper, we introduce a new matching method based on a novel locally affine-invariant geometric constraint and linear programming techniques. To model and solve the matching problem in a linear programming formulation, all geometric constraints should be able to be exactly or approximately reformulated into a linear form. This is a major difficulty for this kind of matching algorithm. We propose a novel locally affine-invariant constraint which can be exactly linearized and requires a lot fewer auxiliary variables than other linear programming-based methods do. The key idea behind it is that each point in the template point set can be exactly represented by an affine combination of its neighboring points, whose weights can be solved easily by least squares. Errors of reconstructing each matched point using such weights are used to penalize the disagreement of geometric relationships between the template points and the matched points. The resulting overall objective function can be solved efficiently by linear programming techniques. Our experimental results on both rigid and nonrigid object matching show the effectiveness of the proposed algorithm.	[Li, Hongsheng] SW Univ Finance & Econ, Dept Comp Sci, Chengdu 610000, Sichuan, Peoples R China; [Huang, Xiaolei] Lehigh Univ, Dept Comp Sci & Engn, Bethlehem, PA 18015 USA; [He, Lei] Lib Congress, Digital Convers Serv, Potomac, MD 20854 USA	Southwestern University of Finance & Economics - China; Lehigh University	Li, HS (corresponding author), SW Univ Finance & Econ, Dept Comp Sci, 555 Liutai Ave, Chengdu 610000, Sichuan, Peoples R China.	lihongsheng@gmail.com; xih206@lehigh.edu; lehe@loc.gov		Huang, Sharon Xiaolei/0000-0003-2338-6535				[Anonymous], 2006, CMU HOUS DAT SET; [Anonymous], 2006, CMU HOT DAT SET; [Anonymous], 2012, LPSOLVE; [Anonymous], 2009, MYTHOLOGICAL CREATUR; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Berg AC, 2005, PROC CVPR IEEE, P26; Boyd S, 2004, CONVEX OPTIMIZATION; Caelli T, 2004, IEEE T PATTERN ANAL, V26, P515, DOI 10.1109/TPAMI.2004.1265866; Caetano TS, 2006, IEEE T PATTERN ANAL, V28, P1646, DOI 10.1109/TPAMI.2006.207; Caetano TS, 2009, IEEE T PATTERN ANAL, V31, P1048, DOI 10.1109/TPAMI.2009.28; Carcassoni M, 2003, PATTERN RECOGN, V36, P193, DOI 10.1016/S0031-3203(02)00054-7; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Cour Timothee, 2006, ADV NEURAL INFORM PR, DOI DOI 10.7551/MITPRESS/7503.003.0044; Cross ADJ, 1998, IEEE T PATTERN ANAL, V20, P1236, DOI 10.1109/34.730557; Duchenne O., 2009, P IEEE C COMP VIS PA; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Jiang H., 2009, P IEEE C COMP VIS PA; Jiang H, 2007, IEEE T PATTERN ANAL, V29, P959, DOI 10.1109/TPAMI.2007.1048; Jiang H, 2011, PROC CVPR IEEE; Kittler J., 1989, International Journal of Pattern Recognition and Artificial Intelligence, V3, P29, DOI 10.1142/S021800148900005X; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Leordeanu M., 2009, P IEEE C COMP VIS PA; LI SZ, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P866, DOI 10.1109/CVPR.1994.323915; Liu H., 2010, P IEEE C COMP VIS PA; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Messmer BT, 1998, IEEE T PATTERN ANAL, V20, P493, DOI 10.1109/34.682179; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Pelillo M, 1999, NEURAL COMPUT, V11, P1933, DOI 10.1162/089976699300016034; Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4_37; Rosenfeld A., 1982, DIGITAL PICTURE PROC; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Schellewald C., 2004, THESIS U MANNHEIN; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; SHAPIRO LS, 1992, IMAGE VISION COMPUT, V10, P283, DOI 10.1016/0262-8856(92)90043-3; Torki M., 2010, P IEEE C COMP VIS PA; Torresani L., 2008, P EUR C COMP VIS; van Wyk MA, 2002, IEEE T PATTERN ANAL, V24, P988, DOI 10.1109/TPAMI.2002.1017624; Wang H., 2004, P INT WORKSH ADV STR; Wilson RC, 1997, IEEE T PATTERN ANAL, V19, P634, DOI 10.1109/34.601251; Zass R., 2008, P IEEE C COMP VIS PA; Zheng Y., 2011, P INT C INF PROC MED	44	35	36	0	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2013	35	2					411	424		10.1109/TPAMI.2012.99	http://dx.doi.org/10.1109/TPAMI.2012.99			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	057JX	22529322	Green Submitted			2022-12-18	WOS:000312560600013
J	Vig, E; Dorr, M; Martinetz, T; Barth, E				Vig, Eleonora; Dorr, Michael; Martinetz, Thomas; Barth, Erhardt			Intrinsic Dimensionality Predicts the Saliency of Natural Dynamic Scenes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computational models of vision; video analysis; computer vision; spatiotemporal saliency; eye movement prediction; intrinsic dimension; visual attention; interest point detection	VISUAL-ATTENTION; OBJECT RECOGNITION; EYE-MOVEMENTS; MODEL; IMAGE	Since visual attention-based computer vision applications have gained popularity, ever more complex, biologically inspired models seem to be needed to predict salient locations (or interest points) in naturalistic scenes. In this paper, we explore how far one can go in predicting eye movements by using only basic signal processing, such as image representations derived from efficient coding principles, and machine learning. To this end, we gradually increase the complexity of a model from simple single-scale saliency maps computed on grayscale videos to spatiotemporal multiscale and multispectral representations. Using a large collection of eye movements on high-resolution videos, supervised learning techniques fine-tune the free parameters whose addition is inevitable with increasing complexity. The proposed model, although very simple, demonstrates significant improvement in predicting salient locations in naturalistic videos over four selected baseline models and two distinct data labeling scenarios.	[Vig, Eleonora; Martinetz, Thomas; Barth, Erhardt] Univ Lubeck, Inst Neuro & Bioinformat, D-23538 Lubeck, Germany; [Dorr, Michael] Harvard Univ, Sch Med, Dept Ophthalmol, Schepens Eye Res Inst, Boston, MA 02114 USA	University of Lubeck; Harvard University; Harvard Medical School; Schepens Eye Research Institute	Vig, E (corresponding author), Univ Lubeck, Inst Neuro & Bioinformat, Ratzeburger Allee 160, D-23538 Lubeck, Germany.	vig@inb.uni-luebeck.de; michael.dorr@schepens.harvard.edu; martinetz@inb.uni-luebeck.de; barth@inb.uni-luebeck.de		Dorr, Michael/0000-0002-7879-7908	European Commission [IST-C-033816]	European Commission(European CommissionEuropean Commission Joint Research Centre)	The authors would like to thank Karl Gegenfurtner; data was collected in his laboratory at the Department of Psychology of Giessen University and is available at [42] and www.inb.uni-luebeck.de/tools-demos/gaze. Their research has received funding from the European Commission within the project GazeCom (contract no. IST-C-033816, see www.gazecom.eu) of the 6th Framework Programme. All views expressed herein are those of the authors alone; the European Community is not liable for any use made of the information.	[Anonymous], 2006, NIPS; Avraham T, 2010, IEEE T PATTERN ANAL, V32, P693, DOI 10.1109/TPAMI.2009.53; BARTH E, 1993, CVGIP-GRAPH MODEL IM, V55, P428, DOI 10.1006/cgip.1993.1033; Barth E, 2000, OPT EXPRESS, V7, P155, DOI 10.1364/OE.7.000155; Boccignone G, 2005, IEEE T CIRC SYST VID, V15, P365, DOI 10.1109/TCSVT.2004.842603; Bohme M, 2006, NEUROCOMPUTING, V69, P1996, DOI 10.1016/j.neucom.2005.11.019; Dickinson SJ, 1997, COMPUT VIS IMAGE UND, V67, P239, DOI 10.1006/cviu.1997.0532; Dorr M, 2010, J VISION, V10, DOI 10.1167/10.10.28; Elazary L, 2008, J VISION, V8, DOI 10.1167/8.3.3; Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27; Gao DS, 2009, NEURAL COMPUT, V21, P239, DOI 10.1162/neco.2009.11-06-391; Geisler WS, 1998, P SOC PHOTO-OPT INS, V3299, P294, DOI 10.1117/12.320120; Gkioulekas I., 2010, P IEEE INT C IM PROC; Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969; Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L, 2001, J ELECTRON IMAGING, V10, P161, DOI 10.1117/1.1333677; Itti L, 2009, VISION RES, V49, P1295, DOI 10.1016/j.visres.2008.09.007; Jahne B., 1999, HDB COMPUTER VISION; Judd T., 2009, P IEEE INT C COMP VI; Kienzle W, 2007, ADV NEURAL INFORM PR, P689; Kienzle W, 2007, LECT NOTES COMPUT SC, V4713, P405; KOCH C, 1985, HUM NEUROBIOL, V4, P219; Krieger G, 2000, SPATIAL VISION, V13, P201, DOI 10.1163/156856800741216; Labusch K, 2009, NEUROCOMPUTING, V72, P1547, DOI 10.1016/j.neucom.2008.11.027; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86; Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70; Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112; Mota C, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P917, DOI 10.1109/ICIP.2001.958644; MOTA C, 2006, MICCAI WORKSH BIOPH, P93; Mota C., 2000, DYNAMISCHE PERZEPTIO, V9, P175; Ninassi A., 2007, P IEEE INT C IM PROC, V2, P169, DOI DOI 10.1109/ICIP.2007.4379119; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Reinagel P, 1999, NETWORK-COMP NEURAL, V10, P341, DOI 10.1088/0954-898X/10/4/304; Rutishauser U, 2004, PROC CVPR IEEE, P37; Santella A., 2006, Conference on Human Factors in Computing Systems. CHI2006, P771; Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40; Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; Tseng PH, 2009, J VISION, V9, DOI 10.1167/9.7.4; Vig E, 2011, COGN COMPUT, V3, P79, DOI 10.1007/s12559-010-9061-4; Vig E, 2010, LECT NOTES COMPUT SC, V6354, P52, DOI 10.1007/978-3-642-15825-4_6; Vig E, 2009, SPATIAL VISION, V22, P397, DOI 10.1163/156856809789476065; Yarbus A. L., 1967, EYE MOVEMENTS VISION, P171; ZETZSCHE C, 1990, VISION RES, V30, P1111, DOI 10.1016/0042-6989(90)90120-A; Zetzsche Christof, 1993, P109; Zhang L., 2009, P 31 ANN COGN SCI C; Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32	51	35	36	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2012	34	6					1080	1091		10.1109/TPAMI.2011.198	http://dx.doi.org/10.1109/TPAMI.2011.198			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	927OE	22516647				2022-12-18	WOS:000302916600004
J	Noulas, A; Englebienne, G; Krose, BA				Noulas, Athanasios; Englebienne, Gwenn; Krose, Ben J. A.			Multimodal Speaker Diarization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Speaker diarization; dynamic Bayesian networks; audiovisual fusion		We present a novel probabilistic framework that fuses information coming from the audio and video modality to perform speaker diarization. The proposed framework is a Dynamic Bayesian Network (DBN) that is an extension of a factorial Hidden Markov Model (fHMM) and models the people appearing in an audiovisual recording as multimodal entities that generate observations in the audio stream, the video stream, and the joint audiovisual space. The framework is very robust to different contexts, makes no assumptions about the location of the recording equipment, and does not require labeled training data as it acquires the model parameters using the Expectation Maximization (EM) algorithm. We apply the proposed model to two meeting videos and a news broadcast video, all of which come from publicly available data sets. The results acquired in speaker diarization are in favor of the proposed multimodal framework, which outperforms the single modality analysis results and improves over the state-of-the-art audio-based speaker diarization.	[Noulas, Athanasios; Englebienne, Gwenn; Krose, Ben J. A.] Univ Amsterdam, Amsterdam, Netherlands	University of Amsterdam	Noulas, A (corresponding author), Univ Amsterdam, Amsterdam, Netherlands.	noulas@gmail.com; G.Englebienne@uva.nl; b.j.a.krose@science.uva.nl						Anguera X, 2006, LECT NOTES COMPUT SC, V4299, P248; BAKIS R, 1997, P SPEECH REC WORKSH, P67; Barzelay Z., 2007, P IEEE CS C COMP VIS; Bayes T., 1763, M F R S PHIL T R SOC, V53, P370, DOI [10.1098/rstl.1763.0053, DOI 10.1098/RSTL.1763.0053]; Beal M.J., 2002, P EUR C COMP VIS; Carletta Jean, 2006, ELRA NEWSL, V11, P3; Checka N, 2004, P IEEE INT C AC SPEE; Chen SS, 1998, INT CONF ACOUST SPEE, P645, DOI 10.1109/ICASSP.1998.675347; Chen YQ, 2004, P IEEE, V92, P485, DOI 10.1109/JPROC.2003.823146; Cutler R., 2002, P 10 ACM INT C MULT; Dance C., 2004, P EUR C COMP VIS INT; Darrell T, 2000, LECT NOTES COMPUT SC, V1948, P32; Delacourt P, 2000, SPEECH COMMUN, V32, P111, DOI 10.1016/S0167-6393(00)00027-3; Fiscus JG, 2008, LECT NOTES COMPUT SC, V4625, P373; Fisher J. W., 2000, ADV NEURAL INFORM PR, P772; Fisher JW, 2002, LECT NOTES COMPUT SC, V2352, P592; Gangadharaiah R., 2004, P IEEE INT C AC SPEE; Gatica-Perez D., 2004, 66 IDIAPRR; Gauvain J.-L., 1998, ICSLP, P1335; Ghahramani Z., 1997, MACHINE LEARNING; Hershey J., 1999, NEURAL INFORM PROCES, P813, DOI [10.5555/3009657.3009772, DOI 10.5555/3009657.3009772]; Iyengar G, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P329; Kidron E, 2005, PROC CVPR IEEE, P88; MOORE D, 2002, 07 IDIAPCOM; Mori K, 2001, INT CONF ACOUST SPEE, P413, DOI 10.1109/ICASSP.2001.940855; Nock HJ, 2004, COMMUN ACM, V47, P51, DOI 10.1145/962081.962105; Noulas A., 2010, THESIS U AMSTERDAM; Noulas A., 2006, P ACM C MULTIMODAL I, P201; Noulas A.K., 2007, P JOINT WORKSH MULT; Noulas AK, 2008, LECT NOTES COMPUT SC, V5237, P98, DOI 10.1007/978-3-540-85853-9_9; Pelecanos J., 2001, P INT SPEECH COMM AS; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Reynolds D.A., 2010, P IEEE INT C AC SPEE, P953; VIOLA P, 2001, P 2 INT WORKSH STAT; Wooters C, 2008, LECT NOTES COMPUT SC, V4625, P509; Yamaguchi M., 2005, P 9 EUR C SPEECH COM, P613	36	35	38	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2012	34	1					79	93		10.1109/TPAMI.2011.47	http://dx.doi.org/10.1109/TPAMI.2011.47			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	848RB	21383401				2022-12-18	WOS:000297069900006
J	Hasinoff, SW; Kutulakos, KN				Hasinoff, Samuel W.; Kutulakos, Kiriakos N.			Light-Efficient Photography	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computational photography; computer vision; computer graphics; shape-from-focus	DEPTH	In this paper, we consider the problem of imaging a scene with a given depth of field at a given exposure level in the shortest amount of time possible. We show that by 1) collecting a sequence of photos and 2) controlling the aperture, focus, and exposure time of each photo individually, we can span the given depth of field in less total time than it takes to expose a single narrower-aperture photo. Using this as a starting point, we obtain two key results. First, for lenses with continuously variable apertures, we derive a closed-form solution for the globally optimal capture sequence, i.e., that collects light from the specified depth of field in the most efficient way possible. Second, for lenses with discrete apertures, we derive an integer programming problem whose solution is the optimal sequence. Our results are applicable to off-the-shelf cameras and typical photography conditions, and advocate the use of dense, wide-aperture photo sequences as a light-efficient alternative to single-shot, narrow-aperture photography.	[Hasinoff, Samuel W.] Toyota Technol Inst, Chicago, IL 60637 USA; [Kutulakos, Kiriakos N.] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada	Toyota Technological Institute - Chicago; University of Toronto	Hasinoff, SW (corresponding author), Toyota Technol Inst, 6045 S Kenwood Ave,Rm 529, Chicago, IL 60637 USA.	hasinoff@ttic.edu; kyros@cs.toronto.edu			Natural Sciences and Engineering Research Council of Canada; Ontario Premier's Research Excellence Award	Natural Sciences and Engineering Research Council of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)CGIAR); Ontario Premier's Research Excellence Award	This work was supported in part by the Natural Sciences and Engineering Research Council of Canada under the RGPIN and EQPEQ programs, and by an Ontario Premier's Research Excellence Award.	Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718; Aizawa K, 2000, IEEE T CIRC SYST VID, V10, P323, DOI 10.1109/76.825731; [Anonymous], 1999, NUMERICAL OPTIMIZATI; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Bishop T. E., 2009, P INT C COMP PHOT; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Cathey WT, 2002, APPL OPTICS, V41, P6080, DOI 10.1364/AO.41.006080; Chaudhuri S, 2005, J OPT SOC AM A, V22, P2357, DOI 10.1364/JOSAA.22.002357; Debevec P., 1997, P ACM SIGGRAPH 1997, DOI [DOI 10.1145/258734.258884, 10.1145/258734.258884]; Farid H, 1998, J OPT SOC AM A, V15, P1777, DOI 10.1364/JOSAA.15.001777; Favaro P, 2003, PROC CVPR IEEE, P579; Georgiev T., 2006, RENDERING TECHNIQUES, V21, P263, DOI DOI 10.2312/EGWR/EGSR06/263-272; Hasinoff S., 2009, P INT C COMP VIS, P1; Hasinoff S.W., 2010, P IEEE C COMP VIS PA; Hasinoff SW, 2007, IEEE I CONF COMP VIS, P550; Hasinoff SW, 2006, LECT NOTES COMPUT SC, V3951, P620; Hausler G., 1972, OPT COMMUN, V6, P38; HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126; Hiura S, 1998, PROC CVPR IEEE, P953, DOI 10.1109/CVPR.1998.698719; KROTKOV E, 1987, INT J COMPUT VISION, V1, P223, DOI 10.1007/BF00127822; LEVIN A, 2008, P EUR C COMP VIS, V4, P88; Levin A., 2009, P ACM SIGGRAPH; Levin A., 2007, P ACM SIGGRAPH; LEVIN A, 2009, MITCSAILTR2009019; Levoy M, 2006, ACM T GRAPHIC, V25, P924, DOI 10.1145/1141911.1141976; Lumsdaine A., 2009, P INT C COMP PHOT; NAGAHARA H, 2008, P EUR C COMP VIS, V4, P60; NG R, 2005, P SIGGRAPH, P735; Ng R., 2005, THESIS STANFORD U; Ogden J. M., 1985, RCA ENG, V30, P4; PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940; Raskar R, 2006, ACM T GRAPHIC, V25, P795, DOI 10.1145/1141911.1141957; Schechner YY, 2000, INT J COMPUT VISION, V39, P141, DOI 10.1023/A:1008175127327; TELLEEN J, 2007, P EUROGRAPHICS, P591; VEERARAGHAVAN A, 2007, P ACM SIGGRAPH; Watanabe M, 1998, INT J COMPUT VISION, V27, P203, DOI 10.1023/A:1007905828438; WELFORD WT, 1960, J OPT SOC AM, V50, P749, DOI 10.1364/JOSA.50.000749; WILLSON RG, 1994, J OPT SOC AM A, V11, P2946, DOI 10.1364/JOSAA.11.002946; Yuan L., 2007, P ACM SIGGRAPH; ZOMET A, 2006, P IEEE C COMP VIS PA, V1, P339; 2011, TECHNICAL INNOVATION; 2011, CANON LENS SPECIFICA	43	35	37	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2011	33	11					2203	2214		10.1109/TPAMI.2011.62	http://dx.doi.org/10.1109/TPAMI.2011.62			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	820MM	21422486	Green Submitted			2022-12-18	WOS:000294910000007
J	Zhu, L; Chen, YH; Yuille, A				Zhu, Long (Leo); Chen, Yuanhao; Yuille, Alan			Learning a Hierarchical Deformable Template for Rapid Deformable Object Parsing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hierarchy; shape representation; object parsing; segmentation; shape matching; structured learning		In this paper, we address the tasks of detecting, segmenting, parsing, and matching deformable objects. We use a novel probabilistic object model that we call a hierarchical deformable template (HDT). The HDT represents the object by state variables defined over a hierarchy (with typically five levels). The hierarchy is built recursively by composing elementary structures to form more complex structures. A probability distribution-a parameterized exponential model-is defined over the hierarchy to quantify the variability in shape and appearance of the object at multiple scales. To perform inference-to estimate the most probable states of the hierarchy for an input image-we use a bottom-up algorithm called compositional inference. This algorithm is an approximate version of dynamic programming where approximations are made (e. g., pruning) to ensure that the algorithm is fast while maintaining high performance. We adapt the structure-perceptron algorithm to estimate the parameters of the HDT in a discriminative manner (simultaneously estimating the appearance and shape parameters). More precisely, we specify an exponential distribution for the HDT using a dictionary of potentials, which capture the appearance and shape cues. This dictionary can be large and so does not require handcrafting the potentials. Instead, structure-perceptron assigns weights to the potentials so that less important potentials receive small weights (this is like a "soft" form of feature selection). Finally, we provide experimental evaluation of HDTs on different visual tasks, including detection, segmentation, matching (alignment), and parsing. We show that HDTs achieve state-of-the-art performance for these different tasks when evaluated on data sets with groundtruth (and when compared to alternative algorithms, which are typically specialized to each task).	[Zhu, Long (Leo)] MIT, Cambridge, MA 02139 USA; [Chen, Yuanhao] Univ Sci & Technol China, Dept Automat, Hefei 230026, Peoples R China; [Yuille, Alan] Univ Calif Los Angeles, Los Angeles, CA 90095 USA	Massachusetts Institute of Technology (MIT); Chinese Academy of Sciences; University of Science & Technology of China, CAS; University of California System; University of California Los Angeles	Zhu, L (corresponding author), MIT, 32-D462 CSAIL MIT,32 Vassar St, Cambridge, MA 02139 USA.	leozhu@csail.mit.edu; yhchen4@ustc.edu; yuille@stat.ucla.edu		Yuille, Alan L./0000-0001-5207-9249	US National Science Foundation (NSF) [0413214]; W.M. Keck Foundation	US National Science Foundation (NSF)(National Science Foundation (NSF)); W.M. Keck Foundation(W.M. Keck Foundation)	The authors gratefully acknowledge the support from the US National Science Foundation (NSF) with grant number 0413214 and the W. M. Keck Foundation. They thank YingNian Wu and Zhuowen Tu for helpful discussions and the anonymous reviewers for feedback that greatly helped to improve the clarity of the paper.	Amit Y, 2004, IEEE T PATTERN ANAL, V26, P1606, DOI 10.1109/TPAMI.2004.111; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BORENSTEIN E, 2002, P EUR C COMP VIS ECC, V2, P109; Borenstein E., 2006, CVPR, V1, P969, DOI DOI 10.1109/CVPR.2006.276; Chen H., 2006, PROC IEEE COMPUT SCI, V1, P943; CHEN Y, 2007, P C NEUR INF PROC SY; Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733; Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1; COLLINS M, 2004, P 42 ANN M ASS COMP, P111; Collins Michael, 2001, P 40 ANN M ASS COMP, P263; COOTES TF, 1998, P EUR C COMP VIS, V2, P484; Coughlan J, 2000, COMPUT VIS IMAGE UND, V78, P303, DOI 10.1006/cviu.2000.0842; COUGHLAN J, 2002, ECCV, V3, P453; COUR T, 2007, P IEEE C COMP VIS PA; Felzenszwalb P., 2007, P IEEE C COMP VIS PA; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144; Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062; FUKUSHIMA K, 1988, NEURAL NETWORKS, V1, P119, DOI 10.1016/0893-6080(88)90014-7; JIN Y, 2006, P IEEE C COMP VIS PA, V2, P2145; Kumar MP, 2005, PROC CVPR IEEE, P18; Leibe B., 2004, EUROPEAN C COMPUTER, P17; LEVIN A, 2006, P EUR C COMP VIS, V4, P581; Li H, 2005, J COMPUT SCI TECH-CH, V20, P849, DOI 10.1007/s11390-005-0849-8; Li SZ, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P324, DOI 10.1109/AFGR.2002.1004174; MARSZALEK M, 2007, P IEEE C COMP VIS PA, P1; REN X, 2005, P C NEUR INF PROC SY; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Serre T, 2005, PROC CVPR IEEE, P994; Sharon E, 2000, PROC CVPR IEEE, P70, DOI 10.1109/CVPR.2000.855801; SHOTTON J, 2006, P EUR C COMP VIS, V1, P1, DOI DOI 10.1007/11744023_; Shotton J, 2008, IEEE T PATTERN ANAL, V30, P1270, DOI 10.1109/TPAMI.2007.70772; Tu Z, 2008, IEEE T MED IMAGING, V27, P495, DOI 10.1109/TMI.2007.908121; Tu ZW, 2004, LECT NOTES COMPUT SC, V3023, P195; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Viola P, 2002, ADV NEUR IN, V14, P1311; Winn J, 2005, IEEE I CONF COMP VIS, P756; Yuille AL, 2001, INT J COMPUT VISION, V41, P9, DOI 10.1023/A:1011156931605; ZHENG S, 2007, P IEEE C COMP VIS PA; Zhu L., 2008, P IEEE C COMP VIS PA; ZHU L, 2006, P C NEUR INF PROC SY, P1617; ZHU L, 2005, P C NEUR INF PROC SY	42	35	37	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2010	32	6					1029	1043		10.1109/TPAMI.2009.65	http://dx.doi.org/10.1109/TPAMI.2009.65			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	583JU	20431129	Green Submitted, Green Published			2022-12-18	WOS:000276671900006
J	Bissacco, A; Chiuso, A; Soatto, S				Bissacco, Alessandro; Chiuso, Alessandro; Soatto, Stefano			Classification and recognition of dynamical models: The role of phase, independent components, kernels, and optimal transport	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						system identification; blind deconvolution; nonminimum phase; distance; kernel; Hammerstein models; optimal transport; Wasserstein models; non-Gaussian models; learning; time series; higher order statistics	SUBSPACE IDENTIFICATION; ARMA PROCESSES; SYSTEMS; ALGORITHMS; INPUTS	We address the problem of performing decision tasks and, in particular, classification and recognition in the space of dynamical models in order to compare time series of data. Motivated by the application of recognition of human motion in image sequences, we consider a class of models that include linear dynamics, both stable and marginally stable ( periodic), both minimum and nonminimum phases, driven by non-Gaussian processes. This requires extending existing learning and system identification algorithms to handle periodic modes and nonminimum-phase behavior while taking into account higher order statistics of the data. Once a model is identified, we define a kernel-based cord distance between models, which includes their dynamics, their initial conditions, and input distribution. This is made possible by a novel kernel defined between two arbitrary (non-Gaussian) distributions, which is computed by efficiently solving an optimal transport problem. We validate our choice of models, inference algorithm, and distance on the tasks of human motion synthesis ( sample paths of the learned models) and recognition (nearest-neighbor classification in the computed distance). However, our work can be applied more broadly where one needs to compare historical data while taking into account periodic trends, nonminimum-phase behavior, and non-Gaussian input distributions.	Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 91104 USA; Univ Padua, Dipartimento Tecn & Gest Sistemi Ind, I-36100 Vicenza, Italy	University of California System; University of California Los Angeles; University of Padua	Bissacco, A (corresponding author), Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 91104 USA.	bissacco@cs.ucla.edu; chiuso@dei.unipd.it; soatto@cs.ucla.edu		CHIUSO, ALESSANDRO/0000-0002-4410-6101				Bauer D, 2005, AUTOMATICA, V41, P359, DOI 10.1016/j.automatica.2004.11.012; Bauer D, 2002, J ECONOMETRICS, V111, P47, DOI 10.1016/S0304-4076(02)00119-7; BISSACCO A, 2006, CLASSIFICATION RECON; Blaschke T, 2004, IEEE T SIGNAL PROCES, V52, P1250, DOI 10.1109/TSP.2004.826173; Boumahdi M, 1996, SIGNAL PROCESS, V48, P205, DOI 10.1016/0165-1684(95)00136-0; Brockett R. W., 1970, FINITE DIMENSIONAL L; Chiuso A, 2004, AUTOMATICA, V40, P575, DOI 10.1016/j.automatica.2003.11.009; CHIUSO A, 1999, P 14 IFAC WORLD C, V1, P241; Chiuso A, 2006, IEEE T AUTOMAT CONTR, V51, P1299, DOI 10.1109/TAC.2006.878703; CICHOCKI A, 2003, ADAPTIVE BLIND SIGNA; COCH KD, 2000, P INT S MATH THEORY; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; Cuzzolin F., 2006, P IEEE C COMP VIS PA; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; ERIKSSON A, 1994, IEEE T SIGNAL PROCES, V42, P586, DOI 10.1109/78.277850; Goethals I, 2005, IEEE T AUTOMAT CONTR, V50, P1509, DOI 10.1109/TAC.2005.856647; Golub G. H., 1989, MATRIX COMPUTATION; GROSS R, 2001, CMU MOTION BODY; Hinich M.J., 1982, J TIME SER ANAL, V3, P169, DOI DOI 10.1111/J.1467-9892.1982.TB00339.X; Horn R. A., 1986, MATRIX ANAL; Kristensson M, 2001, IEEE T SIGNAL PROCES, V49, P2962, DOI 10.1109/78.969505; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; LEVINE J, 1987, SIAM J CONTROL OPTIM, V25, P1430, DOI 10.1137/0325079; Lind P, 1996, ACTA MED AUST, V23, P69; LINDQUIST A, 1991, J MATH SYSTEMS ESTIM, V1, P241; Ljung L., 1997, SYSTEM IDENTIFICATIO; MALLOWS CL, 1972, ANN MATH STAT, V43, P508, DOI 10.1214/aoms/1177692631; Martin RJ, 2000, IEEE T SIGNAL PROCES, V48, P1164, DOI 10.1109/78.827549; Mazzaro MC, 2005, IEEE T PATTERN ANAL, V27, P1820, DOI 10.1109/TPAMI.2005.210; Mourjopoulos J., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P1858; MULLHAUPT P, 1998, P 37 IEEE C DEC CONT; PAPOULIS A, 1985, IEEE T ACOUST SPEECH, V33, P933, DOI 10.1109/TASSP.1985.1164637; Picci G, 1996, SIGNAL PROCESS, V52, P145, DOI 10.1016/0165-1684(96)00050-3; ROY R, 1986, IEEE T ACOUST SPEECH, V34, P1340, DOI 10.1109/TASSP.1986.1164935; SAISAN P, 2004, P 8 EUR C COMP VIS; Schmidt R., 1981, THESIS STANFORD U; Schoelkopf B., 2002, LEARNING KERNELS; Soderstron T, 1989, SYSTEM IDENTIFICATIO; SWAMI A, 1994, IEEE T SIGNAL PROCES, V42, P898, DOI 10.1109/78.285653; Van Overschee P., 1996, SUBSPACE IDENTIFICAT; VANOVERSCHEE P, 1993, AUTOMATICA, V29, P649, DOI 10.1016/0005-1098(93)90061-W; VISHWANATHAN S, 2005, INT J COMP VISION; [No title captured]	45	35	36	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2007	29	11					1958	1972		10.1109/TPAMI.2007.1101	http://dx.doi.org/10.1109/TPAMI.2007.1101			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	208UE	17848777				2022-12-18	WOS:000249343900007
J	Phillips, PJ; Bowyer, KW; Flynn, PJ				Phillips, P. Jonathon; Bowyer, Kevin W.; Flynn, Patrick J.			Comments on the CASIA version 1.0 iris data set	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						iris recognition; biometrics		We note that the images in the CASIA version 1.0 iris data set have been edited so that the pupil area is replaced by a circular region of uniform intensity. We recommend that this data set no longer be used in iris biometrics research unless there is a compelling reason that takes into account the nature of the images. In addition, based on our experience with the Iris Challenge Evaluation ( ICE) 2005 technology development project, we make recommendations for reporting results of iris recognition experiments.	Natl Inst Stand & Technol, Gaithersburg, MD 20899 USA; Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA	National Institute of Standards & Technology (NIST) - USA; University of Notre Dame	Phillips, PJ (corresponding author), Natl Inst Stand & Technol, 100 Bur Dr, Gaithersburg, MD 20899 USA.	jonathon@nist.gov; kwb@cse.nd.edu; flynn@nd.edu	Flynn, Patrick J/J-3388-2013	Flynn, Patrick J/0000-0002-5446-114X; Bowyer, Kevin/0000-0002-7562-4390				BOWYER KW, 2006, SURVEY IRIS IMAGE AN; Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145; PHILLIPS PJ, 2006, TEST DIRECTORS ICE 2; TAN T, 2006, COMMUNICATION; 2007, CHINESE ACAD SCI; CHINESE ACAD SCI	6	35	35	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2007	29	10					1869	1870		10.1109/TPAMI.2007.1137	http://dx.doi.org/10.1109/TPAMI.2007.1137			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	199LA	17699931	Green Submitted			2022-12-18	WOS:000248696100016
J	Passalis, G; Kakadiaris, IA; Theoharis, T				Passalis, Georgios; Kakadiaris, Ioannis A.; Theoharis, Theoharis			Intraclass retrieval of nonrigid 3D objects: Application to face recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						information search and retrieval; face and gesture recognition	SURFACES; GEOMETRY	As the size of the available collections of 3D objects grows, database transactions become essential for their management with the key operation being retrieval (query). Large collections are also precategorized into classes so that a single class contains objects of the same type (e.g., human faces, cars, four-legged animals). It is shown that general object retrieval methods are inadequate for intraclass retrieval tasks. We advocate that such intraclass problems require a specialized method that can exploit the basic class characteristics in order to achieve higher accuracy. A novel 3D object retrieval method is presented which uses a parameterized annotated model of the shape of the class objects, incorporating its main characteristics. The annotated subdivision-based model is fitted onto objects of the class using a deformable model framework, converted to a geometry image and transformed into the wavelet domain. Object retrieval takes place in the wavelet domain. The method does not require user interaction, achieves high accuracy, is efficient for use with large databases, and is suitable for nonrigid object classes. We apply our method to the face recognition domain, one of the most challenging intraclass retrieval tasks. We used the Face Recognition Grand Challenge v2 database, yielding an average verification rate of 95.2 percent at 10(-3) false accept rate. The latest results of our work can be found at http://www.cbl.uh.edu/UR8D/.	Univ Athens, Dept Informat & Telecommun, Athens 15784, Greece; Univ Houston, Dept Comp Sci, Computat Biomed Lab, Houston, TX 77204 USA	National & Kapodistrian University of Athens; University of Houston System; University of Houston	Passalis, G (corresponding author), Univ Athens, Dept Informat & Telecommun, TYPA Bldg, Athens 15784, Greece.	passalis@di.uoa.gr; ioannisk@uh.edu; theotheo@di.uoa.gr	Theoharis, Theoharis/AAN-2555-2020	Kakadiaris, Ioannis/0000-0002-0591-1079				Ankerst M, 1999, LECT NOTES COMPUT SC, V1651, P207; [Anonymous], 1987, ACM SIGGRAPH COMPUTE, DOI [10.1145/37402.37427, DOI 10.1145/37402.37427]; [Anonymous], 2006, FACE RECOGNITION VEN; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BHAGAVATULA R, 2005, P 4 IEEE WORKSH AUT; Blanz V, 2005, PROC CVPR IEEE, P454; Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005; Bowyer KW, 2004, INT C PATT RECOG, P358, DOI 10.1109/ICPR.2004.1334126; CATMULL E, 1978, COMPUT AIDED DESIGN, V10, P350, DOI 10.1016/0010-4485(78)90110-0; CHANG K, 2003, P ACM WORKSH MULT US, P25; Chang K., 2005, P IEEE WORKSH FAC RE; Chang KI, 2005, IEEE T PATTERN ANAL, V27, P619, DOI 10.1109/TPAMI.2005.70; Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669; DOO D, 1978, COMPUT AIDED DESIGN, V10, P356, DOI 10.1016/0010-4485(78)90111-2; Farkas LG, 1994, ANTHROPOMETRY HEAD F; Finkel R. A., 1974, Acta Informatica, V4, P1, DOI 10.1007/BF00288933; Frome A, 2004, LECT NOTES COMPUT SC, V3023, P224; Gu X., 2003, EUR S GEOM PROC, P127; Gu XF, 2002, ACM T GRAPHIC, V21, P355; Heo J., 2005, P IEEE COMP SOC C CO, P9; Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282; HLAVATY T, 2003, P SEM GEOM GRAPH TEA; Kakadiaris IA, 2005, PROC CVPR IEEE, P1022; Kakadiaris IA, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P505, DOI 10.1109/ICDSP.2002.1028138; KAKADIARIS IA, 2002, P BRIT MACH VIS C SE, P303; KAZHDAN M, 2003, S GEOM PROC, P167; KAZHDAN M, 2004, THESIS PRINCETON U; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; KLINGER A, 1971, OPTIMIZING METHODS S, P303; KRUGER T, 2003, P 4 EUR WORKSH IM AN, P391; Laga H, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P490; Liu XM, 2005, PROC CVPR IEEE, P502; Loop C., 1987, SMOOTH SUBDIVISION S; Mandal C, 1997, VISUALIZATION '97 - PROCEEDINGS, P371, DOI 10.1109/VISUAL.1997.663905; MANDAL C, 1998, THESIS U FLORIDA; Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648; Papaioannou G, 2002, IEEE T PATTERN ANAL, V24, P114, DOI 10.1109/34.982888; PASSALIS G, 2005, P IEEE WORKSH FAC RE; PASSALIS G, 2004, THESIS U HOUSTON; PHILLIPS P, 2003, FRVT 2002 OVERVIEW S; Phillips PJ, 2005, PROC CVPR IEEE, P947; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Phillips PJ, 2000, COMPUTER, V33, P56, DOI 10.1109/2.820040; Praun E, 2003, ACM T GRAPHIC, V22, P340, DOI 10.1145/882262.882274; Siarry P, 1997, ACM T MATH SOFTWARE, V23, P209, DOI 10.1145/264029.264043; Stollnitz E.J., 1996, WAVELETS COMPUTER GR; Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609; Terzopoulos D., 1988, Visual Computer, V4, P306, DOI 10.1007/BF01908877; Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vajramushti N., 2004, P 6 ACM SIGMM INT WO, P189; Vranic D., 2004, THESIS U LEIPZIG; VRANIC D, 2004, CONTENT BASED CLASSI; YAN P, 2005, P 4 IEEE WORKSH AUT; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; ZORIN D, 2000, P ACM SIGGRAPH COURS; 2006, MATHWORLD	57	35	37	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2007	29	2					218	229		10.1109/TPAMI.2007.37	http://dx.doi.org/10.1109/TPAMI.2007.37			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	116TV	17170476				2022-12-18	WOS:000242826900004
J	Yang, L				Yang, L			Building k edge-disjoint spanning trees of minimum total length for isometric data embedding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						data embedding; dimensionality reduction; manifold learning; minimum spanning tree; neighborhood graph		Isometric data embedding requires construction of a neighborhood graph that spans all data points so that geodesic distance between any pair of data points could be estimated by distance along the shortest path between the pair on the graph. This paper presents an approach for constructing k-edge-connected neighborhood graphs. It works by finding k-edge-disjoint spanning trees the sum of whose total lengths is a minimum. Experiments show that it outperforms the nearest neighbor approach for geodesic distance estimation.	Western Michigan Univ, Dept Comp Sci, Kalamazoo, MI 49008 USA	Western Michigan University	Yang, L (corresponding author), Western Michigan Univ, Dept Comp Sci, Kalamazoo, MI 49008 USA.	li.yang@wmich.edu						Balasubramanian M, 2002, SCIENCE, V295; Cox T.F., 2001, MULTIDIMENSIONAL SCA, V2nd; Demartines P, 1997, IEEE T NEURAL NETWOR, V8, P148, DOI 10.1109/72.554199; Garay M., 1979, COMPUTERS INTRACTABI; Kruskal J. B., 1956, P AM MATH SOC, V7, P48, DOI [DOI 10.1090/S0002-9939-1956-0078686-7, 10.2307/2033241]; Lee JH, 2000, 2000 IEEE/LEOS INTERNATIONAL CONFERENCE ON OPTICAL MEMS, P13, DOI 10.1109/OMEMS.2000.879604; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Yang L, 2004, INT C PATT RECOG, P196; ZHA H, 2003, P 20 INT C MACH LEAR, P864	12	35	48	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2005	27	10					1680	1683						4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	953OM	16238003				2022-12-18	WOS:000231086700016
J	Liu, JZ; Tang, XO				Liu, JZ; Tang, XO			Evolutionary search for faces from line drawings	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						three-dimensional object reconstruction; face identification; genetic algorithms; line drawing; minimal edge face phenomenon; simulated annealing	WIRE FRAMES; 3D OBJECT; RECONSTRUCTION; IDENTIFICATION; SOLIDS	Single 2D line drawing is a straightforward method to illustrate 3D objects. The faces of an object depicted by a line drawing give very useful information for the reconstruction of its 3D geometry. Two recently proposed methods for face identification from line drawings are based on two steps: finding a set of circuits that may be faces and searching for real faces from the set according to some criteria. The two steps, however, involve two combinatorial problems. The number of the circuits generated in the first step grows exponentially with the number of edges of a line drawing. These circuits are then used as the input to the second combinatorial search step. When dealing with objects having more faces, the combinatorial explosion prevents these methods from finding solutions within feasible time. This paper proposes a new method to tackle the face identification problem by a variable-length genetic algorithm with a novel heuristic and geometric constraints incorporated for local search. The hybrid GA solves the two combinatorial problems simultaneously. Experimental results show that our algorithm can find the faces of a line drawing having more than 30 faces much more efficiently. In addition, simulated annealing for solving the face identification problem is also implemented for comparison.	Chinese Univ Hong Kong, Dept Informat Engn, Shatin, Hong Kong, Peoples R China	Chinese University of Hong Kong	Liu, JZ (corresponding author), Chinese Univ Hong Kong, Dept Informat Engn, Shatin, Hong Kong, Peoples R China.	jzliu@ie.cuhk.edu.hk; xtang@ie.cuhk.edu.hk	Tang, Xiaoou/G-6509-2012					Ablameyko S, 1999, COMPUT CONTROL ENG J, V10, P277, DOI 10.1049/cce:19990606; AGARWAL SC, 1992, COMPUT AIDED DESIGN, V24, P123, DOI 10.1016/0010-4485(92)90032-6; Chartrand G., 1993, APPL ALGORITHMIC GRA; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; Cooper MC, 2001, INT J COMPUT VISION, V43, P75, DOI 10.1023/A:1011166601983; COOPER MC, 1993, IMAGE VISION COMPUT, V11, P82, DOI 10.1016/0262-8856(93)90074-Q; Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191; Dowsland KA, 1993, MODERN HEURISTIC TEC, P20; DUTTON RD, 1983, COMPUT GRAPH, V7, P143, DOI 10.1016/0097-8493(83)90004-3; GANTER MA, 1983, COMPUTER MECH ENG, V2, P40; Gen M., 2000, GENETIC ALGORITHMS E; GOLDBERG DE, 1989, GENET ALGORITHMS SEA; Hanrahan P. M., 1982, Computer Graphics, V16, P77, DOI 10.1145/965145.801265; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; HOJNICKI JS, 1988, COMPUTERS MECH E MAR, P19; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; Kuo MH, 1998, COMPUT AIDED DESIGN, V30, P517, DOI 10.1016/S0010-4485(98)00006-2; LECLERC YG, 1992, INT J COMPUT VISION, V9, P113, DOI 10.1007/BF00129683; LEQUETTE R, 1988, COMPUT AIDED DESIGN, V20, P171, DOI 10.1016/0010-4485(88)90273-4; Lipson H, 1996, COMPUT AIDED DESIGN, V28, P651, DOI 10.1016/0010-4485(95)00081-X; LIU J, 2003, EFFICIENT SEARCH FAC; Liu JZ, 2002, IEEE T PATTERN ANAL, V24, P1579, DOI 10.1109/TPAMI.2002.1114850; Liu JZ, 2001, IEEE T PATTERN ANAL, V23, P1106; MALIK J, 1987, INT J COMPUT VISION, V1, P73, DOI 10.1007/BF00128527; Man K-F, 1999, GENETIC ALGORITHMS C; Mantyla M., 1988, INTRODUCTION; MARILL T, 1991, INT J COMPUT VISION, V6, P147, DOI 10.1007/BF00128154; MARKOWSKY G, 1980, IBM J RES DEV, V24, P582, DOI 10.1147/rd.245.0582; Michalewicz Z., 1996, GENETIC ALGORITHMS D, V3rd; Piquer A, 2003, WSCG'2003, VOL 11, NO 3, CONFERENCE PROCEEDINGS, P504; REINGOLD EM, 1977, COMBINATORIAL ALGORI; Shpitalni M, 1996, IEEE T PATTERN ANAL, V18, P1000, DOI 10.1109/34.541409; SUGIHARA K, 1984, IEEE T PATTERN ANAL, V6, P578, DOI 10.1109/TPAMI.1984.4767571; Turner A, 2000, COMPUT GRAPH-UK, V24, P869, DOI 10.1016/S0097-8493(00)00089-3; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19	35	35	38	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2005	27	6					861	872		10.1109/TPAMI.2005.119	http://dx.doi.org/10.1109/TPAMI.2005.119			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	915TR	15943419	Green Submitted			2022-12-18	WOS:000228334700003
J	Sagawa, R; Nishino, K; Ikeuchi, K				Sagawa, R; Nishino, K; Ikeuchi, K			Adaptively merging large-scale range data with reflectance properties	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						adaptive integration of range images; laser reflectance strength; nearest-neighbor search	REGISTRATION; SET	In this paper, we tackle the problem of geometric and photometric modeling of large intricately shaped objects. Typical target objects we consider are cultural heritage objects. When constructing models of such objects, we are faced with several important issues that have not been addressed in the past-issues that mainly arise due to the large amount of data that has to be handled. We propose two novel approaches to efficiently handle such large amounts of data: A highly adaptive algorithm for merging range images and an adaptive nearest-neighbor search to be used with the algorithm. We construct an integrated mesh model of the target object in adaptive resolution, taking into account the geometric and/or photometric attributes associated with the range images. We use surface curvature for the geometric attributes and (laser) reflectance values for the photometric attributes. This adaptive merging framework leads to a significant reduction in the necessary amount of computational resources. Furthermore, the resulting adaptive mesh models can be of great use for applications such as texture mapping, as we will briefly demonstrate. Additionally, we propose an additional test for the k-d tree nearest-neighbor search algorithm. Our approach successfully omits back-tracking, which is controlled adaptively depending on the distance to the nearest neighbor. Since the main consumption of computational cost lies in the nearest-neighbor search, the proposed algorithm leads to a significant speed-up of the whole merging process. In this paper, we present the theories and algorithms of our approaches with pseudo code and apply them to several real objects, including large-scale cultural assets.	Osaka Univ, Inst Sci & Ind Res, Ibaraki, Osaka 5670047, Japan; Columbia Univ, Dept Comp Sci, New York, NY 10027 USA; Univ Tokyo, Inst Ind Sci, Meguro Ku, Tokyo 1538505, Japan	Osaka University; Columbia University; University of Tokyo	Sagawa, R (corresponding author), Osaka Univ, Inst Sci & Ind Res, 8-1 Mihogaoka, Ibaraki, Osaka 5670047, Japan.	sagawa@am.sanken.osaka-u.ac.jp; kon@cs.columbia.edu; ki@cvl.iis.u-tokyo.ac.jp						BERALDIN JA, 2002, P 8 INT C VIRT SYST; Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643; Bernardini F, 2002, IEEE COMPUT GRAPH, V22, P59, DOI 10.1109/38.974519; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; CALIFANO A, 1994, IEEE T PATTERN ANAL, V16, P373, DOI 10.1109/34.277591; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; Dorai C., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P770, DOI 10.1109/ICPR.1996.546128; EGGERT D, 1996, 804 U ED DEP ART INT; Foley J.D., 1995, COMPUTER GRAPHICS PR; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; Frisken SF, 2000, COMP GRAPH, P249, DOI 10.1145/344779.344899; Garland M., 1998, P IEEE VIS, P2; Gibson SFF, 1998, IEEE SYMPOSIUM ON VOLUME VISUALIZATION, P23, DOI 10.1109/SVV.1998.729581; Greenspan M, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P442, DOI 10.1109/IM.2003.1240280; Guttman A., 1984, SIGMOD Record, V14, P47, DOI 10.1145/971697.602266; Hilton A., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P117, DOI 10.1007/BFb0015528; Hoppe H., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P59, DOI 10.1109/VISUAL.1999.809869; Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216; HOPPE H, 1992, P SIGGRAPH 92, P71, DOI DOI 10.1145/133994.134011; Huber DF, 2003, IMAGE VISION COMPUT, V21, P637, DOI 10.1016/S0262-8856(03)00060-X; IKEUCHI K, 2000, P IEEE 1 PAC RIM C M; Johnson AE, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P121, DOI 10.1109/IM.1997.603857; Kurazume R., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P99; LAVALLEE S, 1995, IEEE T PATTERN ANAL, V17, P378, DOI 10.1109/34.385980; Levoy M, 2000, COMP GRAPH, P131, DOI 10.1145/344779.344849; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; Miyazaki D, 2000, VSMM 2000: 6TH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA, P138; Neugebauer P, 1997, 1997 INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P130, DOI 10.1109/SMA.1997.634890; NEUGEBAUER PJ, 1999, P EUROGRAPHICS 99, P245; NIELSON GM, 1991, VISUALIZATION 91, P83; Nishino K., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P454; Nishino K., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P618, DOI 10.1109/CVPR.1999.787003; Pulli K, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P205, DOI 10.1109/IM.1997.603867; Pulli K., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P160, DOI 10.1109/IM.1999.805346; Sagawa R, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P410, DOI 10.1109/IM.2003.1240276; Sagawa R, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P79, DOI 10.1109/IM.2003.1240235; Sagawa R, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P79, DOI 10.1109/IRDS.2002.1041366; SAGAWA R, 2001, P 2001 IEEE RSJ INT, V1, P577; SAGAWA R, 2003, THESIS U TOKYO; SAMET H, 1984, COMPUT SURV, V16, P187, DOI 10.1145/356924.356930; Sethian J., 1996, LEVEL SET METHODS; Shekhar R, 1996, IEEE VISUAL, P335, DOI 10.1109/VISUAL.1996.568127; SHU RB, 1995, VISUAL COMPUT, V11, P202; SOUCY M, 1995, IEEE T PATTERN ANAL, V17, P344, DOI 10.1109/34.385982; STAMOS I, 2001, P 8 INT C COMP VIS; STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785; Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241; WHEELER MD, 1995, IEEE T PATTERN ANAL, V17, P252, DOI 10.1109/34.368190; WHEELER MD, 1998, P INT C COMP VIS JAN; Whitaker RT, 1998, INT J COMPUT VISION, V29, P203, DOI 10.1023/A:1008036829907; Wolfson HJ, 1997, IEEE COMPUT SCI ENG, V4, P10, DOI 10.1109/99.641604; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149; Zhao HK, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P194, DOI 10.1109/VLSM.2001.938900; [No title captured]; 2004, STANFORD 3D SCANNING	58	35	35	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2005	27	3					392	405		10.1109/TPAMI.2005.46	http://dx.doi.org/10.1109/TPAMI.2005.46			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	887IW	15747794				2022-12-18	WOS:000226300200008
J	Han, F; Tu, ZW; Zhu, SC				Han, F; Tu, ZW; Zhu, SC			Range image segmentation by an effective jump-diffusion method	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						energy minimization; jump-diffusion; range segmentation; Markov chain Monte Carlo; data clustering; edge detection; Hough transform; change point detection		This paper presents an effective jump-diffusion method for segmenting a range image and its associated reflectance image in the Bayesian framework. The algorithm works on complex real-world scenes (indoor and outdoor), which consist of an unknown number of objects (or surfaces) of various sizes and types, such as planes, conics, smooth surfaces, and cluttered objects (like trees and bushes). Formulated in the Bayesian framework, the posterior probability is distributed over a solution space with a countable number of subspaces of varying dimensions. The algorithm simulates Markov chains with both reversible jumps and stochastic diffusions to traverse the solution space. The reversible jumps realize the moves between subspaces of different dimensions, such as switching surface models and changing the number of objects. The stochastic Langevin equation realizes diffusions within each subspace. To achieve effective computation, the algorithm precomputes some importance proposal probabilities over multiple scales through Hough transforms, edge detection, and data clustering. The latter are used by the Markov chains for fast mixing. The algorithm is tested on 100 1D simulated data sets for performance analysis on both accuracy and speed. Then, the algorithm is applied to three data sets of range images under the same parameter setting. The results are satisfactory in comparison with manual segmentations.	Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA; Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA	University of California System; University of California Los Angeles; University of California System; University of California Los Angeles	Han, F (corresponding author), Univ Calif Los Angeles, Dept Comp Sci, 8130 Math Sci Bldg,Box 951554, Los Angeles, CA 90095 USA.	hanf@cs.ucla.edu; ztu@stat.ucla.edu; sczhu@stat.ucla.edu						AKAIKE H, 1978, ANN I STAT MATH, V30, P9, DOI 10.1007/BF02480194; ARMAN F, 1993, P CVGIP IM UND, V57, P373; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148; Bubna K, 2000, COMPUT VIS IMAGE UND, V80, P215, DOI 10.1006/cviu.2000.0871; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416; COX IJ, 1993, INT J COMPUT VISION, V11, P5, DOI 10.1007/BF01420590; Dell'Acqua F, 2002, IEEE T PATTERN ANAL, V24, P569, DOI 10.1109/34.993564; FLYNN PJ, 1988, P COMP VIS PATT REC; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GEMAN S, 1986, SIAM J CONTROL OPTIM, V24, P1031, DOI 10.1137/0324060; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; GREEN TJ, 1992, OPT ENG, V31, P2343, DOI 10.1117/12.59955; GREEN TJ, 1994, OPT ENG, V33, P865, DOI 10.1117/12.160880; GRENANDER U, 1994, J ROYAL STAT SOC B, V56; HOFFMAN R, 1987, IEEE T PATTERN ANAL, V9, P608, DOI 10.1109/TPAMI.1987.4767955; Hoover A, 1996, IEEE T PATTERN ANAL, V18, P673, DOI 10.1109/34.506791; HUANG JG, 2000, P COMP VIS PATT REC; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Krishnapuram R., 1992, Journal of Mathematical Imaging and Vision, V2, P351, DOI 10.1007/BF00121878; LECLERC YG, 1992, INT J COMPUT VISION, V9, P113, DOI 10.1007/BF00129683; LEONARDIS A, 1995, INT J COMPUT VISION, V14, P253, DOI 10.1007/BF01679685; LUO QM, 2001, THESIS OHIO STATE U; MACIUCA R, 2003, P INT WORKSH STAT CO; Marshall D, 2001, IEEE T PATTERN ANAL, V23, P304, DOI 10.1109/34.910883; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Nitzberg M., 1993, LECT NOTES COMPUTER, V662; PHILLIPS DB, 1995, MARKOV CHAIN MONTE C, pCH3; Powell MW, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P286, DOI 10.1109/ICCV.1998.710732; Rissanen Jorma, 1989, STOCHASTIC COMPLEXIT; Stamos I, 2002, COMPUT VIS IMAGE UND, V88, P94, DOI 10.1006/cviu.2002.0963; TIERNEY L, 1994, ANN STAT, V22, P1701, DOI 10.1214/aos/1176325750; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; UMASUTHAN M, 1996, IEE P VISION IMAGE S, V143; Zhang Z., 1995, PARAMETER ESTIMATION; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343; [No title captured]	39	35	38	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2004	26	9					1138	1153		10.1109/TPAMI.2004.70	http://dx.doi.org/10.1109/TPAMI.2004.70			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	837CM	15742890	Green Submitted			2022-12-18	WOS:000222605100004
J	Akgul, YS; Kambhamettu, C				Akgul, YS; Kambhamettu, C			A coarse-to-fine deformable contour optimization framework	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						deformable models; deformable model energy optimization; coarse-to-fine optimization; dynamic programming; spatiotemporal contour tracking	MODELS; TRACKING; IMAGES	This paper introduces a novel coarse-to-fine, deformable, contour optimization framework, which is composed of two main components. The first component uses scale-space and information theories to produce a coarser representation of the input image to be used in a coarse-to-fine optimization scheme. The employment of information theory ensures that maximal image information is propagated to the coarse images and employment of scale spaces provides a mechanism to change the image coarseness locally based on the deformable contour model definition. The second component of this framework uses a novel combination of dynamic programming and gradient descent methods to optimize the contour energy on coarser representations and then use the obtained coarse contour positions in finer optimizations. The motivation in using a combination of dynamic programming and gradient descent method is to take advantage of each methods efficiency and avoid their drawbacks. In order to verify the performance of this framework, we constructed a deformable contour model for the spatiotemporal tracking of closed contours and optimized the model energy under this framework. Experiments on this system performed using synthetic images and real world echocardiographic sequences demonstrated the effectiveness and practicality of this framework.	Cognex Corp, Core Vis Technol Grp, Natick, MA 01760 USA; Univ Delaware, Dept Comp & Informat Sci, Newark, DE 19716 USA	University of Delaware	Akgul, YS (corresponding author), Cognex Corp, Core Vis Technol Grp, 1 Vis Dr, Natick, MA 01760 USA.	Yusuf.Akgul@cognex.com; chandra@cis.udel.edu	Akgul, Yusuf Sinan/AAK-5933-2021	Akgul, Yusuf/0000-0001-8501-4812				Akgul YS, 1999, LECT NOTES COMPUT SC, V1682, P410; Akgul YS, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P109, DOI 10.1109/ACV.1998.732866; Akgul YS, 1998, PROC CVPR IEEE, P298, DOI 10.1109/CVPR.1998.698623; AKGUL YS, 1999, IEEE COMPUTER VISION, V2, P465; AKGUL YS, 2000, THESIS U DELAWARE; AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681; Chalana V, 1997, IEEE T MED IMAGING, V16, P642, DOI 10.1109/42.640755; Chandran S, 1998, IEEE T PATTERN ANAL, V20, P546, DOI 10.1109/34.682184; COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675; Dias JMB, 1996, IEEE T MED IMAGING, V15, P25, DOI 10.1109/42.481438; Dubuisson-Jolly MP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P414, DOI 10.1109/ICCV.1998.710752; GEIGER D, 1995, IEEE T PATTERN ANAL, V17, P294, DOI 10.1109/34.368194; GEIGER D, 1993, COMPUTER VISION PATT, P47; Hammoude A, 1998, COMPUT MED IMAG GRAP, V22, P181, DOI 10.1016/S0895-6111(98)00024-X; IVINS J, 1995, IMAGE VISION COMPUT, V13, P431, DOI 10.1016/0262-8856(95)99730-O; Jacob G, 2002, IEEE T MED IMAGING, V21, P226, DOI 10.1109/42.996341; JAGERSAND M, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P195, DOI 10.1109/ICCV.1995.466786; Jain R., 1995, MACHINE VISION; Kass M., 1987, International Journal of Computer Vision, V1, P321, DOI 10.1007/BF00133570; KLINGER A, 1971, OPTIMIZING METHODS S; Koster ASE, 1997, COMPUT VIS IMAGE UND, V65, P382, DOI 10.1006/cviu.1996.0490; LAI KF, 1995, IEEE T PATTERN ANAL, V17, P1084, DOI 10.1109/34.473235; Lindeberg T., 1994, SCALE SPACE THEORY C; Musse O, 2001, IEEE T IMAGE PROCESS, V10, P1081, DOI 10.1109/83.931102; Niessen WJ, 1996, PROCEEDINGS OF THE IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, P263, DOI 10.1109/MMBIA.1996.534078; Niessen WJ, 1997, COMPUT VIS IMAGE UND, V66, P233, DOI 10.1006/cviu.1997.0614; Park JY, 2001, COMPUT GRAPH-UK, V25, P421, DOI 10.1016/S0097-8493(01)00066-8; Raphael C, 2001, IEEE T PATTERN ANAL, V23, P1379, DOI 10.1109/34.977562; RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153; Sharon E, 2001, PROC CVPR IEEE, P469; Tsap LV, 2000, PROC CVPR IEEE, P422, DOI 10.1109/CVPR.2000.854870; Vincken KL, 1996, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.1996.517048; Wei GQ, 2001, PROC CVPR IEEE, P954; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729	39	35	37	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2003	25	2					174	186		10.1109/TPAMI.2003.1177150	http://dx.doi.org/10.1109/TPAMI.2003.1177150			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	637NX					2022-12-18	WOS:000180519800003
J	Hammah, RE; Curran, JH				Hammah, RE; Curran, JH			Validity measures for the fuzzy cluster analysis of orientations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fuzzy cluster analysis; cluster analysis; cluster validity index; cluster performance measure; cluster validity indices; cluster performance measures; discontinuities; orientations; spherical data; directional data	ALGORITHM	Fuzzy K-means clustering can be applied to the automatic identification of sets in discontinuity data after suitable adaptation of the algorithm. To establish the number of clusters in a data set, modified versions of the validity measures of Gath and Geva, Xie-Beni and Fukuyama-Sugeno are presented in this paper.	Rocsci Inc, Toronto, ON M4E 3B5, Canada; Univ Toronto, Dept Civil Engn, Toronto, ON M5S 1A4, Canada	University of Toronto	Hammah, RE (corresponding author), Rocsci Inc, 31 Balsam Ave, Toronto, ON M4E 3B5, Canada.							Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; DIEDERICHS M, 1996, DIPS USERS GUIDE VER; GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473; Hammah RE, 1999, ROCK MECH ROCK ENG, V32, P1, DOI 10.1007/s006030050041; Hammah RE, 1998, INT J ROCK MECH MIN, V35, P889, DOI 10.1016/S0148-9062(98)00011-4; HARRISON JP, 1992, P ISRM S EUR 92, P25; PAL NR, 1995, IEEE T FUZZY SYST, V3, P370, DOI 10.1109/91.413225; SHANLEY RJ, 1974, 8624 USBM; WATSON GS, 1966, J GEOL, V74, P786, DOI 10.1086/627211; XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677; [No title captured]	11	35	36	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2000	22	12					1467	1472		10.1109/34.895981	http://dx.doi.org/10.1109/34.895981			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	383UR					2022-12-18	WOS:000165901900010
J	Pless, R; Brodsky, T; Aloimonos, Y				Pless, R; Brodsky, T; Aloimonos, Y			Detecting independent motion: The statistics of temporal continuity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						independent motion; normal flow; tracking; video mosaic; stable feature frame; airborne visual surveillance		We consider a problem central in aerial visual surveillance applications-detection and tracking of small, independently moving objects in long and noisy video sequences. We directly use spatiotemporal image intensity gradient measurements to compute an exact model of background motion. This allows the creation of accurate mosaics over many frames, and the definition of a constraint violation function which acts as an indicator of independent motion. A novel temporal integration method maintains confidence measures over long subsequences without computing the optic flow, requiring object models, or using a Kalman filter. The mosaic acts as a stable feature frame. allowing precise localization of the independently moving objects We present a statistical analysis of the effects of image noise on the constraint violation measure and find a good match between the predicted probability distribution function and the measured sample frequencies in a test sequence.	Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA; Philips Res, Briarcliff Manor, NY 10510 USA	University System of Maryland; University of Maryland College Park; Philips; Philips Research	Pless, R (corresponding author), Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA.	pless@cfar.umd.edu; tomas.brodsky@philips.com; yiannis@cfar.umd.edu	Aloimonos, Yiannis/AAI-2969-2020; Pless, Robert B/I-4698-2013	Aloimonos, Yiannis/0000-0002-8152-4281; 				COHEN I, 1998, P IEEE IM UND WORKSH, P217; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321; Fujiyoshi H, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P15, DOI 10.1109/ACV.1998.732852; HANSEN M, 1994, P ARPA IM UND WORKSH, P457; Horn B., 1986, ROBOT VISION, P1; IRANI M, 1992, LECT NOTES COMPUT SC, V588, P282; LAVEST JM, 1993, IEEE T ROBOTIC AUTOM, V9, P196, DOI 10.1109/70.238283; MANN S, 1995, IEEE T IMAGE PROCESS, V6; NELSON RC, 1991, INT J COMPUT VISION, V7, P33, DOI 10.1007/BF00130488; Shum HY, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P953, DOI 10.1109/ICCV.1998.710831; SMITH SM, 1995, IEEE T PATTERN ANAL, V17, P814, DOI 10.1109/34.400573; Torr PHS, 1998, PHILOS T R SOC A, V356, P1321, DOI 10.1098/rsta.1998.0224; TORR PHS, 1994, P 3 EUR C COMP VIS, P328; Vieville T, 1996, COMPUT VIS IMAGE UND, V64, P128, DOI 10.1006/cviu.1996.0049	14	35	40	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2000	22	8					768	773		10.1109/34.868679	http://dx.doi.org/10.1109/34.868679			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	354GN					2022-12-18	WOS:000089321500004
J	Stone, HS; Le Moigne, J; McGuire, M				Stone, HS; Le Moigne, J; McGuire, M			The translation sensitivity of wavelet-based registration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image registration; image search; wavelet transform; correlation; low-pass filter; high-pass filter; Haar wavelet; Daubechies wavelet; multiresolution search	TRANSFORM; IMAGERY	This paper studies the effects of image translation on wavelet-based image registration. The main result is that the normalized correlation coefficients of low-pass Haar and Daubechies wavelet subbands are essentially insensitive to translations for features larger than twice the wavelet blocksize. The third-level low-pass subbands produce a correlation peak that varies with translation from 0.7 and 1.0 with an average in excess of 0.9. Translation sensitivity is limited to the high-pass subband and even this subband is potentially useful. The correlation peak for high-pass subbands derived from first and second-level low-pass subbands ranges from about 0.0 to 1.0 with an average of about 0.5 for Daubechies and 0.7 for Haar. We use a mathematical model to develop these results, and confirm them on real data.	NEC Res Inst, Princeton, NJ 08540 USA; NASA, Goddard Space Flight Ctr, Appl Informat SCi Branch CS, Greenbelt, MD 20771 USA; MIT, Cambridge, MA 02139 USA	NEC Corporation; National Aeronautics & Space Administration (NASA); NASA Goddard Space Flight Center; Massachusetts Institute of Technology (MIT)	Stone, HS (corresponding author), NEC Res Inst, 4 Independence Way, Princeton, NJ 08540 USA.							ALLEN RL, 1993, IEEE T SIGNAL PROCES, V41, P3536, DOI 10.1109/78.258092; Alliney S, 1996, PATTERN RECOGN, V29, P131, DOI 10.1016/0031-3203(95)00070-4; Anuta PE., 1970, IEEE T GEOSCI ELECTR, V8, P353, DOI [10.1109/tge.1970.271435, DOI 10.1109/TGE.1970.271435]; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; CASASENT D, 1992, APPL OPTICS, V31, P6255, DOI 10.1364/AO.31.006255; Casasent D, 1996, P SOC PHOTO-OPT INS, V2762, P244, DOI 10.1117/12.235996; CASASENT DP, 1994, OPT ENG, V33, P1757, DOI 10.1117/12.171567; COHEN I, 1995, P 20 IEEE INT C AC S, P1081; Corvi M., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P224, DOI 10.1109/ICIP.1995.537621; CRACKNELL AP, 1989, INT J REMOTE SENS, V10, P661, DOI 10.1080/01431168908903907; DEVEREUX BJ, 1990, INT J REMOTE SENS, V11, P2237, DOI 10.1080/01431169008955172; DJAMDJI JP, 1993, PHOTOGRAMM ENG REM S, V59, P645; FIORE PD, 1995, P INT C IM PROC OCT, V3, P220; Khosravi M, 1996, IEEE T IMAGE PROCESS, V5, P1060, DOI 10.1109/83.503921; Kuglin C. D., 1975, Proceedings of the 1975 International Conference on Cybernetics and Society, P163; Le Moigne J., 1995, P 1995 INT GEOSC REM, P1011; LEMOIGNE J, UNPUB IEEE T GEOSCIE; LEMOIGNE J, 1994, P SPIE OE AEROSP APR, P432; LI HH, 1996, P SPIE AER WAV APPL, V3, P524; LIANG J, 1996, P 1996 IEEE DIG SIGN, P69; Reddy BS, 1996, IEEE T IMAGE PROCESS, V5, P1266, DOI 10.1109/83.506761; SAITO N, 1993, IEEE T SIGNAL PROCES, V41, P3584, DOI 10.1109/78.258102; SIMONCELLI EP, 1992, IEEE T INFORM THEORY, V38, P587, DOI 10.1109/18.119725; Stone HS, 1999, IEEE T SIGNAL PROCES, V47, P97, DOI 10.1109/78.738243; Strang G., 1996, WAVELETS FILTER BANK; WONG RY, 1978, COMPUT VISION GRAPH, V8, P16, DOI 10.1016/S0146-664X(78)80028-8; Zheng Q, 1993, IEEE T IMAGE PROCESS, V2, P311, DOI 10.1109/83.236535	27	35	43	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1999	21	10					1074	1081		10.1109/34.799911	http://dx.doi.org/10.1109/34.799911			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	248DB		Green Submitted			2022-12-18	WOS:000083259100008
J	Clouard, R; Elmoataz, A; Porquet, C; Revenu, M				Clouard, R; Elmoataz, A; Porquet, C; Revenu, M			Borg: A knowledge-based system for automatic generation of image processing programs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image processing; artificial intelligence; knowledge-based systems; composition of image processing programs; supervision of a library of programs	EXPERT SYSTEM; VISION	This article deals with the design of a system that automates the generation of image processing applications. Users describe tasks to perform on images and the system constructs a specific plan, which, after being executed, should yield the desired results. Our approach of this problem belongs to the more general category of systems for the supervision of a library of operators. The generation of an application is here considered as the dynamic building of chains of image processing through the selection, parameter tuning and scheduling of existing operators. To develop such a system, we suggest to use a knowledge-rich resolution model and to integrate seven design rules. The Borg system has been developed following these prescriptions. It hinges on hierarchical, opportunistic and incremental planning by means of knowledge sources of the Blackboard model, which enable to take into account planning, evaluation and knowledge acquisition issues.	IMAGE, GREYC, F-14050 Caen, France	Universite de Caen Normandie	Clouard, R (corresponding author), IMAGE, GREYC, 6 Blvd Marechal Juin, F-14050 Caen, France.	regis.clouard@greyc.ismra.fr; abder.elmoataz@greyc.ismra.fr; christine.porquet@greyc.ismra.fr; marinette.revenu@greyc.ismra.fr						Bachimont B., 1992, CONTROLE SYSTEMES BA; BODINGTON R, 1995, P INT WORKSH KNOWL B, P100; BOUCHER A, 1996, P 13 IAPR INT C PATT, V3, P558; CAREL D, 1989, THESIS U RENNES FRAN; CHARLEBOIS D, 1997, THESIS U OTTAWA CANA; CHARROUX B, 1995, P 9 SCAND C IM AN UP, P671; Chien SA, 1996, IEEE T PATTERN ANAL, V18, P854, DOI 10.1109/34.531806; CLEMENT V, 1993, CVGIP-IMAG UNDERSTAN, V57, P164; CLOUARD R, 1995, P INT WORKSH DES COO, P298; CLOUARD R, 1995, P INT WORKSH KNOWL B, P137; Crevier D, 1997, COMPUT VIS IMAGE UND, V67, P161, DOI 10.1006/cviu.1996.0520; Dejean P, 1996, PROCEEDINGS OF THE IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P66, DOI 10.1109/IAI.1996.493728; Draper BA, 1996, P IEEE, V84, P1625, DOI 10.1109/5.542412; ELMOATAZ A, 1992, P INT C IM PROC ITS, P385; ELMOATAZ A, 1990, THESIS U CAEN FRANCE; GONG LG, 1995, IEEE T PATTERN ANAL, V17, P997, DOI 10.1109/34.464563; HAYESROTH B, 1985, ARTIF INTELL, V26, P251, DOI 10.1016/0004-3702(85)90063-3; LANSKY A, 1995, P 1995 AAAI SPRING S, P67; LIEDTKE CE, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P375, DOI 10.1109/ICPR.1992.201579; Marr D., 1982, VISION COMPUTATIONAL; MATSUYAMA T, 1989, COMPUT VISION GRAPH, V48, P22, DOI 10.1016/0734-189X(89)90103-5; MOISAN S, 1995, P INT WORKSH KNOWL B, P109; NAZIF AM, 1984, IEEE T PATTERN ANAL, V6, P555, DOI 10.1109/TPAMI.1984.4767570; NII HP, 1989, BLACKBOARD ARCHITECT, pR19; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; RASURE J, 1994, EXPT ENV COMPUTER VI, P1; Sakaue K., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P189; Simon H.A., 2019, SCI ARTIFICIAL; Tanaka T., 1988, Proceedings of the International Workshop on Artificial Intelligence for Industrial Applications: IEEE AI '88 (Cat. No.88CH2529-6), P267, DOI 10.1109/AIIA.1988.13304; THONNAT M, 1995, P INT WORKSH KNOWL B, P4; TORIU T, 1987, FUJITSU SCI TECH J, V23, P111; VANDENELST J, 1996, THESIS U NICE FRANCE	32	35	39	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1999	21	2					128	144		10.1109/34.748822	http://dx.doi.org/10.1109/34.748822			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	167NL		Green Submitted			2022-12-18	WOS:000078639900003
J	Heijmans, HJAM; Tuzikov, AV				Heijmans, HJAM; Tuzikov, AV			Similarity and symmetry measures for convex shapes using Minkowski addition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						similarity measure; symmetry measure; convex set; Minkowski addition; Brunn-Minkowski inequality	IMAGES; AXES; RECOGNITION; OPERATIONS; OBJECTS; CURVES	This paper is devoted to similarity and symmetry measures for convex shapes whose definition is based on Minkowski addition and the Brunn-Minkowski inequality. This means, in particular, that these measures are region-based, in contrast to most of the literature, where one considers contour-based measures. All measures considered in this paper are invariant under translations; furthermore, they can be chosen to be invariant under rotations, multiplications, reflections, or the class of affine transformations. It is shown that the mixed volume of a convex polygon and a rotation of another convex polygon over an angle theta is a piecewise concave function of theta. This and other results of a similar nature form the basis for the development of efficient algorithms for the computation of the given measures. Various results obtained in this paper are illustrated by experimental data. Although the paper deals exclusively with the two-dimensional case, many of the theoretical results carry over almost directly to higher-dimensional spaces.	CWI, Ctr Math & Comp Sci, NL-1090 GB Amsterdam, Netherlands; Acad Sci Republ Belarus, Inst Engn Cybernet, Minsk 220012, BELARUS	National Academy of Sciences of Belarus (NASB); United Institute of Informatics Problems of the National Academy of Sciences of Belarus	Heijmans, HJAM (corresponding author), CWI, Ctr Math & Comp Sci, POB 94079, NL-1090 GB Amsterdam, Netherlands.	henkh@cwi.nl; tuzikov@mpen.bas-net.by	Tuzikov, Alexander V./AGX-5875-2022; Rohlf, F J/A-8710-2008	Tuzikov, Alexander V./0000-0001-5970-4852; 				ALLGOWER EL, 1986, MATH COMPUT, V46, P171, DOI 10.1090/S0025-5718-1986-0815838-7; ARKIN EM, 1991, IEEE T PATTERN ANAL, V13, P209, DOI 10.1109/34.75509; ATALLAH MJ, 1985, IEEE T COMPUT, V34, P663, DOI 10.1109/TC.1985.1676605; Ballard D.H., 1982, COMPUTER VISION; CHAM TJ, 1995, IMAGE VISION COMPUT, V13, P439, DOI 10.1016/0262-8856(95)99731-F; CHETVERIKOV D, 1992, PATTERN RECOGN LETT, V13, P669, DOI 10.1016/0167-8655(92)90123-H; CHUI CK, 1970, P AM MATH SOC, V26, P480, DOI 10.2307/2037364; DEVALCOU.BA, 1966, ISRAEL J MATH, V4, P65, DOI 10.1007/BF02937452; FOURNEL T, 1992, ACTA STEREOL, V11, P279; FRIEDBERG SA, 1986, COMPUT VISION GRAPH, V34, P138, DOI 10.1016/S0734-189X(86)80055-X; GHOSH PK, 1993, COMPUT GRAPH, V17, P357, DOI 10.1016/0097-8493(93)90023-3; Ghosh PK, 1996, J MATH IMAGING VIS, V6, P199, DOI 10.1007/BF00119839; Goldstein H., 2000, CLASSICAL MECH; Grunbaum B., 1963, P S PURE MATHEMATICS, V7, P233; GRUNBAUM B., 1967, CONVEX POLYTOPES; Hadwiger H., 1957, VORLESUNGEN INHALT O; Heijmans H., 1994, MORPHOLOGICAL IMAGE; HEIJMANS HJA, 1996, BSR9610 CWI; HONG J, 1988, P 2 INT C COMP VIS, P489; Horn B., 1986, ROBOT VISION, P1; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Kanatani Kenichi, 1990, GROUP THEORETICAL ME, P4; KUHL FP, 1982, COMPUT VISION GRAPH, V18, P236, DOI 10.1016/0146-664X(82)90034-X; LN CC, 1987, IEEE T PATTERN ANAL, V9, P696; MAROLA G, 1989, IEEE T PATTERN ANAL, V11, P104, DOI 10.1109/34.23119; MASUDA T, 1993, PATTERN RECOGN, V26, P1245, DOI 10.1016/0031-3203(93)90209-F; MATHERON G, 1988, IMAGE ANAL MATH MORP, V2, P359; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; PEI SC, 1995, IMAGE VISION COMPUT, V13, P711, DOI 10.1016/0262-8856(95)98753-G; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; Rosenfeld A., 1982, DIGITAL PICTURE PROC; SCHNEIDER R, 1993, CONVEX BODIES BRUNNM; SCHWARTZ JT, 1987, INT J ROBOT RES, V6, P29, DOI 10.1177/027836498700600203; Shubnikov A., 1974, SYMMETRY SCI ART; TSAI WH, 1991, PATTERN RECOGN, V24, P95, DOI 10.1016/0031-3203(91)90080-O; Van Otterloo P.J., 1988, THESIS DELFT U TECHN; WERMAN M, 1995, IEEE T PATTERN ANAL, V17, P810, DOI 10.1109/34.400572; ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949; [No title captured]	40	35	36	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1998	20	9					980	993		10.1109/34.713363	http://dx.doi.org/10.1109/34.713363			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	117AX					2022-12-18	WOS:000075758500006
J	Lu, ZY				Lu, ZY			Detection of text regions from digital engineering drawings	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document image analysis; engineering drawings; text segmentation; pattern recognition; image processing	EXTRACTION	An algorithm for text/graphics separation is presented in this paper. The basic principle of the algorithm is to erase nontext regions from mixed text and graphics engineering drawings, rather than extract text regions directly. This algorithm can be used to extract both Chinese and Western characters, dimensions, and symbols and has few limitations on the kind of engineering drawings and noise level. It is robust to text-graphics touching, text fonts, and written orientations.	Xidian Univ, Inst Telecommun Engn, Grp 102, Xian 710071, Peoples R China	Xidian University	Lu, ZY (corresponding author), Xidian Univ, Inst Telecommun Engn, Grp 102, Xian 710071, Peoples R China.							DORI D, 1995, PREPR INT WORKSH GRA; FETCHER LA, 1988, IEEE T PATTERN ANAL, V10, P910; LAI CP, 1994, IEEE T PATTERN ANAL, V16, P848, DOI 10.1109/34.308483; LYSAK DB, 1991, P ICDAR; WAHL FM, 1982, COMPUT VISION GRAPH, V20, P375, DOI 10.1016/0146-664X(82)90059-4; YAMADA H, 1991, PATTERN RECOGN, V24, P479, DOI 10.1016/0031-3203(91)90015-W; YING DN, 1991, P CAD GRAPHICS HANGZ, V478	7	35	48	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1998	20	4					431	439		10.1109/34.677283	http://dx.doi.org/10.1109/34.677283			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZP214					2022-12-18	WOS:000073729200010
J	Dorai, C; Jain, AK				Dorai, C; Jain, AK			Shape spectrum based view grouping and matching of 3D free-form objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						free-form objects; sculpted surfaces; 3D object representation; COSMOS; shape spectrum; clustering; view matching	ASPECT GRAPH; VISION	We address the problem of constructing view aspects of 3D free-form objects for efficient matching during recognition. We introduce a novel View representation based on ''shape spectrum'' features, and propose a general and powerful technique for organizing multiple views of objects of complex shape and geometry into compact and homogeneous clusters. Our view grouping technique obviates the need for surface segmentation anti edge detection. Experiments on 6,400 synthetically generated views of 20 free-form objects and 100 real range images of 10 sculpted objects demonstrate the good performance of our shape spectrum based model View selection technique.	MICHIGAN STATE UNIV, DEPT COMP SCI, E LANSING, MI 48824 USA	Michigan State University	Dorai, C (corresponding author), IBM CORP, TJ WATSON RES CTR, POB 704, YORKTOWN HTS, NY 10598 USA.							Besl P J., 1990, MACHINE VISION 3 DIM, P25; BURNS JB, 1988, P 1988 DARPA IM UND, P711; CHEN SS, 1990, INST PHYS CONF SER, P77; DICKINSON SJ, 1992, IEEE T PATTERN ANAL, V14, P174, DOI 10.1109/34.121788; DORAI C, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1024, DOI 10.1109/ICCV.1995.466822; DORAI C, 1996, THESIS MICHIGAN STAT; EGGERT D, 1993, IEEE T PATTERN ANAL, V15, P109, DOI 10.1109/34.192483; EGGERT DW, 1993, IEEE T PATTERN ANAL, V15, P1114, DOI 10.1109/34.244674; Gigus Z., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P30, DOI 10.1109/CCV.1988.589969; HANSEN C, 1989, IEEE T PATTERN ANAL, V11, P1181, DOI 10.1109/34.42856; IKEUCHI K, 1987, INT J COMPUT VISION, V1, P145, DOI 10.1007/BF00123163; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; KRIEGMAN DJ, 1989, P IEEE WORKSH INT 3, P116; PLANTINGA H, 1990, INT J COMPUT VISION, V5, P137, DOI 10.1007/BF00054919; SENGUPTA K, 1995, IEEE T PATTERN ANAL, V17, P321, DOI 10.1109/34.385984; STEWMAN JH, 1987, IEEE WORKSHOP COMPUT, P123; SWAIN M, 1988, P DARPA IMAGE UNDERS, P690	18	35	36	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1997	19	10					1139	1146		10.1109/34.625116	http://dx.doi.org/10.1109/34.625116			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YB678					2022-12-18	WOS:A1997YB67800009
J	ROCHA, J; PAVLIDIS, T				ROCHA, J; PAVLIDIS, T			CHARACTER-RECOGNITION WITHOUT SEGMENTATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CHARACTER RECOGNITION WITHOUT SEGMENTATION; BROKEN CHARACTER RECOGNITION; TOUCHING CHARACTER RECOGNITION; HOMEOMORPHIC SUBGRAPH MATCHING; RELATIVE NEIGHBORHOOD GRAPH	RELATIVE NEIGHBORHOOD GRAPH; SET	A segmentation-free approach to OCR is presented as part of a knowledge based word interpretation model. This new method is based on the recognition of subgraphs homeomorphic to previously defined prototypes of characters [16]. Gaps are. identified as potential parts of characters by implementing a variant of the notion of relative neighborhood used in computational perception. In the system, each subgraph of strokes that matches a previously defined character prototype is recognized anywhere in the word even if it corresponds to a broken character or to a character touching another one. The characters are detected in the order defined by the matching quality. Each subgraph:that is recognized is introduced as a node in a directed net that compiles different alternatives of interpretation of the features in the feature graph. A path in the net represents a consistent succession of characters in the word. The method allows the recognition of characters that overlap or that are underlined. A final search for the optimal path under certain criteria gives the best interpretation of the word features. The character recognized uses a flexible matching between the features and a flexible grouping of the individual features to be matched. Broken characters are recognized by looking for gaps between features that may he interpreted as part of a character. Touching characters are recognized because the matching allows nonmatched adjacent strokes. The recognition results of this system for over 24,000 printed numeral characters belonging to a USPS database and on some hand-printed words confirmed the method's high robustness level.	SUNY STONY BROOK,DEPT COMP SCI,STONY BROOK,NY 11794	State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	ROCHA, J (corresponding author), UNIV ILLES BALEARS,DEPT MATEMAT INFORMAT 1,E-07075 PALMA DE MALLORCA,SPAIN.		Rocha, Jairo/K-9850-2014	Rocha, Jairo/0000-0002-8810-7376				[Anonymous], 1985, PERCEPTUAL ORG VISUA; BERTHOD M, 1980, 5TH P INT C PATT REC, P723; CASEY RG, 1982, 6TH INT C P R MUN, P1023; EDELMAN S, 1990, INT J COMPUT VISION, V5, P303, DOI 10.1007/BF00126503; EDELSBRUNNER H, 1983, IEEE T INFORM THEORY, V29, P551, DOI 10.1109/TIT.1983.1056714; FUJISAWA H, 1992, IEEE P           JUL, P1079; GILLOUX M, 1994, NATO ADV SCI INST SE, V124, P264; GOVINDARAJU V, 1992, COMMUNICATION; HU J, 1992, NOV IEEE WORKSH APPL, P56; HULL JJ, 1983, IEEE T PATTERN ANAL, V5, P384, DOI 10.1109/TPAMI.1983.4767408; Kirkpatrick DG, 1985, MACHINE INTELLIGENCE, V2, P217; LECOLINET E, 1991, 1ST P INT C DOC AN R, P740; OHMORI K, 1993, 3RD P INT WORKSH FRO, P242; Okamoto M., 1991, INT C DOC AN REC, P242; Radke JD, 1988, SHAPE SET POINTS, P105; ROCHA J, 1994, IEEE T PATTERN ANAL, V16, P393, DOI 10.1109/34.277592; SAKODA WJ, 1993, FEB SPIE S EL IM TEC, P21; SCHURMANN J, 1992, P IEEE, V80, P1101, DOI 10.1109/5.156473; SUPOWIT KJ, 1983, J ACM, V30, P428, DOI 10.1145/2402.322386; TORIWAKI J, 1988, COMPUTATIONAL MORPHO, P207; Toussaint G. T., 1988, COMPUTATIONAL MORPHO, P229; TOUSSAINT GT, 1980, PATTERN RECOGN, V12, P261, DOI 10.1016/0031-3203(80)90066-7; Tsujimoto S., 1991, 1ST INT C DOC AN REC, P701	23	35	36	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1995	17	9					903	909		10.1109/34.406657	http://dx.doi.org/10.1109/34.406657			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RR989					2022-12-18	WOS:A1995RR98900008
J	WORRING, M; SMEULDERS, AWM				WORRING, M; SMEULDERS, AWM			DIGITIZED CIRCULAR ARCS - CHARACTERIZATION AND PARAMETER-ESTIMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CIRCULAR ARCS; PARAMETER ESTIMATION; CURVATURE; PRECISION; DIGITIZATION	DISCRETE REPRESENTATION; STRAIGHT-LINES; DIGITAL DISKS; CURVATURE; RECOGNITION; CIRCLES; SHAPES	The digitization of a circular are causes an inherent loss of geometrical information. Arcs with slightly different local curvature or position may lead to exactly the same digital pattern, In this paper we give a characterization of all centers and radii of circular arcs yielding the same digitization pattern, The radius of the arcs varies over the set, However, only one curvature or radius estimate can be assigned to the digital pattern, We derive an optimal estimator and give expressions for the bound on the precision of estimation, This bound due to digitization is the deterministic equivalent of the Cramer/Rao bound known from parameter estimation theory, Consider the estimation of the local curvature and local radius of a smooth object, Typically such parameters are estimated by moving a window along the digital boundary. Methods in Literature show a poor precision in estimating curvature values, relative errors of over 40% are often found [34], From the definition of curvature it follows that locally the curve can be considered a circular are and hence the method presented in this paper can be applied to the pattern in the window giving estimates with optimal precision and a measure for the remaining error, On the practical side we present examples of the residual error due to the discrete grid, The estimation of the radius or curvature of a circular are at random position with an estimation window containing 10 points (coded with nine Freemancodes) has a relative deviation exceeding 2%, For a full disk the deviation is below 1% when the radius r exceeds four grid units, The presented method is particularly useful for problems where some prior knowledge on the distribution of radii is known and where there is a noise-free sampling.			WORRING, M (corresponding author), UNIV AMSTERDAM,DEPT COMP SCI,KRUISLAAN 403,1098 SJ AMSTERDAM,NETHERLANDS.							ANDERSON IM, 1984, IEEE T PATTERN ANAL, V6, P27, DOI 10.1109/TPAMI.1984.4767472; ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; BERENSTEIN CA, 1987, COMPUT VISION GRAPH, V40, P334, DOI 10.1016/S0734-189X(87)80146-9; BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302; DORST L, 1984, IEEE T PATTERN ANAL, V6, P450, DOI 10.1109/TPAMI.1984.4767550; DORST L, 1986, IEEE T PATTERN ANAL, V8, P276, DOI 10.1109/TPAMI.1986.4767781; DORST L, 1987, COMPUT VISION GRAPH, V40, P311, DOI 10.1016/S0734-189X(87)80145-7; DUNCAN JS, 1991, IEEE T MED IMAGING, V10, P307, DOI 10.1109/42.97580; FISK S, 1986, IEEE T PATTERN ANAL, V8, P554, DOI 10.1109/TPAMI.1986.4767821; GROEN FCA, 1977, COMPUTER GRAPHICS IM, V7, P391; HAVELOCK DI, 1989, IEEE T PATTERN ANAL, V11, P1065, DOI 10.1109/34.42837; HUNG SHY, 1985, IEEE T PATTERN ANAL, V7, P203, DOI 10.1109/TPAMI.1985.4767644; KIM CE, 1984, IEEE T PATTERN ANAL, V6, P372, DOI 10.1109/TPAMI.1984.4767531; KOPLOWITZ J, 1989, IEEE T PATTERN ANAL, V11, P611, DOI 10.1109/34.24795; Kulpa Z., 1977, COMPUTER GRAPHICS IM, V6, P434, DOI [10.1016/S0146-664X(77)80021-X, DOI 10.1016/S0146-664X(77)80021-X]; LANDAU UM, 1987, COMPUT VISION GRAPH, V38, P317, DOI 10.1016/0734-189X(87)90116-2; Lipkin BS, 1970, PICTURE PROCESSING P, P241; MCILROY MD, 1985, AT&T TECH J, V64, P481, DOI 10.1002/j.1538-7305.1985.tb00359.x; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; NAKAMURA A, 1984, COMPUT VISION GRAPH, V26, P242, DOI 10.1016/0734-189X(84)90187-7; OROURKE J, 1986, DISCRETE COMPUT GEOM, V1, P105, DOI 10.1007/BF02187688; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; PROFFITT D, 1979, COMPUT VISION GRAPH, V10, P318, DOI 10.1016/S0146-664X(79)80041-6; Rosenfeld A., 1982, DIGITAL PICTURE PROC; Selby SM, 1975, STANDARD MATH TABLES; SMEULDERS SWM, 1988, PATTERN RECOGN, V7, P91; STRUIK DJ, 1984, LECTURES CLASSICAL D; THOMAS SM, 1989, COMPUTER VISION GRAP, V45; VANDENBOS A, 1982, PARAMETER ESTIMATION; VOSEPOEL AM, 1992, P ICPR IMAGE SPEECH; VOSSEPOEL AM, 1982, COMPUTER GRAPHICS IM, V10, P347; WORRING M, 1993, CVGIP-IMAG UNDERSTAN, V58, P366, DOI 10.1006/ciun.1993.1048; WORRING M, 1993, THESIS U AMSTERDAM; WORRING M, 1992, P ICPR IMAGE SPEECH	34	35	36	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1995	17	6					587	598		10.1109/34.387505	http://dx.doi.org/10.1109/34.387505			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QZ940		Green Submitted			2022-12-18	WOS:A1995QZ94000004
J	HUANG, WC; GOLDGOF, DB				HUANG, WC; GOLDGOF, DB			ADAPTIVE-SIZE MESHES FOR RIGID AND NONRIGID SHAPE-ANALYSIS AND SYNTHESIS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						ADAPTIVE-SIZE MESHES; FINITE ELEMENT METHOD; NONRIGID MOTION ANALYSIS; PHYSICALLY-BASED MODELING; 3-D SURFACE RECONSTRUCTION		This paper presents a new physically based modeling method that uses adaptive-size meshes to model surfaces of rigid and nonrigid objects. The initial model uses a priori determined mesh size. However, the mesh size increases or decreases dynamically during surface reconstruction to locate nodes near surface areas of interest (like high curvature points) and to optimize the fitting error. Further, presented with the multiple 3-D data frames, the mesh size varies as the data surface undergoes the nonrigid motion. This model is used to reconstruct 3-D surfaces, analyze the nonrigid motion, track the corresponding points in nonrigid motion, and create graphic animation and visualization. The proposed method was tested on real range data, on simulated nonrigid motion, and on real data of the left ventricular (LV) motion.			HUANG, WC (corresponding author), UNIV S FLORIDA,DEPT COMP SCI & ENGN,TAMPA,FL 33620, USA.		Goldgof, Dmitry/ABF-1366-2020					Cohen L. D., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P587, DOI 10.1109/ICCV.1990.139601; HUANG WC, 1992, JUN P IEEE C COMP VI, P833; Kass M., 1988, INT J COMPUT VISION, V1, P321; Metaxas D., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P337, DOI 10.1109/CVPR.1991.139712; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; Press WH, 1988, NUMERICAL RECIPES C; ROBB RA, 1983, P IEEE, V71, P308, DOI 10.1109/PROC.1983.12589; Terzopoulos D., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P70, DOI 10.1109/CVPR.1991.139663; TERZOPOULOS D, 1987, INT J COMPUT VISION, V1, P211, DOI 10.1007/BF00127821; Wang Y. F., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P300, DOI 10.1109/ICCV.1990.139536	10	35	37	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1993	15	6					611	616		10.1109/34.216732	http://dx.doi.org/10.1109/34.216732			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LF257					2022-12-18	WOS:A1993LF25700011
J	KARINTHI, RR; NAU, D				KARINTHI, RR; NAU, D			AN ALGEBRAIC APPROACH TO FEATURE INTERACTIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ALGEBRAIC STRUCTURES; AUTOMATED MANUFACTURING; CONCURRENT ENGINEERING DESIGN; FEATURE EXTRACTION; GEOMETRIC REASONING; SOLID MODELING	BOUNDARY	Various approaches have been proposed to provide communication between CAD systems and process planning systems, including automated feature extraction, design by features, and human-supervised feature extraction. Regardless of which approach is used, a major problem is that due to geometric interactions among features, there may be several equally valid sets of manufacturable features describing the same part, and different sets of features may differ in their manufacturability. Thus, to produce a good process plan-or, in some cases, even to produce a process plan at all-it may be necessary to interpret the part as a different set of features than the one initially obtained from the CAD model. This paper proposes a way to address this problem, based on an algebra of features. Given a set of features describing a machinable part, other equally valid interpretations of the part can be produced by performing operations in the algebra. This will enable automated process planning systems (such as [39]) to examine these interpretations in order to see which one is most appropriate for use in manufacturing. The feature algebra has been implemented for a restricted domain and integrated with the Protosolid [42] solid modeling system and the EFHA process planning system [39].	W VIRGINIA UNIV,CONCURRENT ENGN RES CTR,MORGANTOWN,WV 26506; UNIV MARYLAND,DEPT COMP SCI,SYST RES CTR,COLLEGE PK,MD 20742; UNIV MARYLAND,INST ADV COMP STUDIES,COLLEGE PK,MD 20742	West Virginia University; University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park	KARINTHI, RR (corresponding author), W VIRGINIA UNIV,DEPT STAT & COMP SCI,MORGANTOWN,WV 26506, USA.							Agoston M, 1976, ALGEBRAIC TOPOLOGY 1; [Anonymous], 1980, PRINCIPLES ARTIFICIA; BROOKS SL, 1987, BDX6133768 BEND KANS; BROWN P, 1987, 19TH P CIRP INT SEM, P111; DEFLORIANI L, 1989, IEEE T PATTERN ANAL, V11, P785, DOI 10.1109/34.31442; DONG X, 1988, 3RD P INT C COMP AID; FULKS W, 1969, ADV CALCULUS INTRO A; GUPTA S, IN PRESS MULTIPLE FE; Hartquist E. E., 1985, PADL 2 USERS MANUAL; HAYES C, 1987, 6TH P NAT C ART INT, P224; HENDERSON MR, 1984, THESIS PURDUE U W LA; HUMMEL KE, 1989, JUL ASME INT COMP EN; IDE NC, 1987, THESIS U MARYLAND CO; JOSHI S, 1988, COMPUT AIDED DESIGN, V20, P58, DOI 10.1016/0010-4485(88)90050-4; KARINTHI R, 1990, THESIS U MARYLAND CO; KARINTHI RR, 1989, 11TH P INT JOINT C A, P1219; KARINTHI RR, 1989, JUL P ASME INT COMP; KRAMER T, 1987, DESIGN PROTOCOL PART; KUMAR B, 1988, THESIS U MARYLAND CO; Kuratowski K., 1976, SET THEORY; KYPRIANOU LK, 1980, THESIS U CAMBRIDGE; Luby S. C., 1986, Computers in Mechanical Engineering, V5, P25; MAEDA Y, 1988, 7 NATL C ART INT AAI, P105; Mendelson B., 1975, INTRO TOPOLOGY, V3rd; NAU DS, 1988, AUG P AM ASS ART INT, P1; NAU DS, 1987, TI TECHNICAL J   WIN, P39; Pinter C.C., 1982, BOOK ABSTRACT ALGEBR; PRATT MJ, 1987, JUL ADV TOP SOL MOD; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; REQUICHA AAG, 1985, P IEEE, V73, P30, DOI 10.1109/PROC.1985.13108; REQUICHA AG, 1977, TM28 U ROCH TECH REP; REQUICHA AG, 1978, TM27A U ROCH TECH RE; ROGERS M, 1989, R89GM02 CAM I INC TE; Serra J, 1982, IMAGE ANAL MATH MORP; SHAH J, 1989, R89GM01 CAM I INC TE; Simmons G.F., 1963, INTRO TOPOLOGY MODER; SRINIVASAN R, 1987, DEC P WINT ANN M AM, P229; TENENBAUM JM, 1989, MAR P AAAI SPRING S; THOMPSON S, 1989, THESIS U MARYLAND; VAGUL M, 1985, 1985 P ASME C COMP E; VANDENBRANDE JH, 1990, THESIS U ROCHESTER; VANECEK G, 1989, THESIS U MARYLAND CO; WOO TC, 1982, P C CAD CAM TECHNOL	43	35	37	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1992	14	4					469	484		10.1109/34.126807	http://dx.doi.org/10.1109/34.126807			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HL193		Green Submitted			2022-12-18	WOS:A1992HL19300005
J	DAS, M; PAULIK, MJ; LOH, NK				DAS, M; PAULIK, MJ; LOH, NK			A BIVARIATE AUTOREGRESSIVE MODELING TECHNIQUE FOR ANALYSIS AND CLASSIFICATION OF PLANAR SHAPES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											DAS, M (corresponding author), OAKLAND UNIV,CTR ROBOT & ADV AUTOMAT,ROCHESTER,MI 48309, USA.							[Anonymous], 1976, TIME SERIES ANAL; AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; Ballard D.H., 1982, COMPUTER VISION; Bennett R., 1979, SPATIAL TIME SERIES; CHELLAPPA R, 1984, IEEE T PATTERN ANAL, V6, P102, DOI 10.1109/TPAMI.1984.4767482; DAS M, TRCRAA8804 OAKL U CT; DUBOIS SR, 1986, IEEE T PATTERN ANAL, V8, P55, DOI 10.1109/TPAMI.1986.4767752; Duda R.O., 1973, J ROYAL STAT SOC SER; DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; FREEMAN H, 1969, IEEE T SYST SCI CYB, VSSC5, P70, DOI 10.1109/TSSC.1969.300247; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; Gantmacher F. R., 1977, THEORY MATRICES; GONZALEZ RC, 1985, DIGITAL IMAGE PROCES; GRATTOROLA A, 1985, P SPIE, V594, P204; GUPTA L, 1987, PATTERN RECOGN, V20, P267, DOI 10.1016/0031-3203(87)90001-X; KALVIN A, 1986, INT J ROBOT RES, V5, P38, DOI 10.1177/027836498600500403; KASHYAP RL, 1981, IEEE T INFORM THEORY, V27, P627, DOI 10.1109/TIT.1981.1056390; KOCH MW, 1987, IEEE T PATTERN ANAL, V9, P483, DOI 10.1109/TPAMI.1987.4767936; Levine M., 1985, VISION MAN MACHINE; LIN CC, 1987, IEEE T PATTERN ANAL, V9, P686, DOI 10.1109/TPAMI.1987.4767963; Ljung L., 1987, SYSTEM IDENTIFICATIO; PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029; PAVLIDIS T, 1987, ALGORITHMS GRAPHICS; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; SCHWARTZ JT, 1987, INT J ROBOT RES, V6, P29, DOI 10.1177/027836498700600203; Sebestyen G., 1962, DECISION MAKING PROC, V227, P413; SINGER PF, 1985, JUN P C VIS PATT REC, P479; SINGER PF, 1983, JUN IEEE P COMP SOC, P146; STRANG G, 1980, LINEAR ALGEBRA ITS A; YOU Z, 1984, COMPUT VISION GRAPH, V28, P185, DOI 10.1016/S0734-189X(84)80021-3; ZHAN CT, 1972, IEEE T COMPUT, V21, P269	32	35	35	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1990	12	1					97	103		10.1109/34.41389	http://dx.doi.org/10.1109/34.41389			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CG247					2022-12-18	WOS:A1990CG24700011
J	CHIEN, CH; AGGARWAL, JK				CHIEN, CH; AGGARWAL, JK			MODEL CONSTRUCTION AND SHAPE-RECOGNITION FROM OCCLUDING CONTOURS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV TEXAS,COMP & VIS RES CTR,AUSTIN,TX 78712	University of Texas System; University of Texas Austin								AGGARWAL JK, 1981, PROGR PATTERN RECOGN, V1, P377; ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; BARROW HG, 1981, ARTIF INTELL, V17, P75, DOI 10.1016/0004-3702(81)90021-7; BENARIE J, 1986, JUN P CVPR86 MIAM BE, P456; BESL PJ, 1985, COMPUT SURV, V17, P75, DOI 10.1145/4078.4081; BRADY M, 1984, IEEE T PATTERN ANAL, V6, P288, DOI 10.1109/TPAMI.1984.4767521; CHIEN CH, 1986, COMPUT VISION GRAPH, V36, P100, DOI 10.1016/S0734-189X(86)80031-7; CHIEN CH, 1984, COMPUT VISION GRAPH, V26, P331, DOI 10.1016/0734-189X(84)90217-2; CHIEN CH, 1986, JUN P CVPR86 MIAM BE, P250; CHIEN CH, IN PRESS COMPUT VISI; CHIEN CH, 1987, THESIS U TEXAS AUSTI; CLINE AK, 1981, CNA168 U TEX DEP COM; DAVIS LS, 1982, COMMUN ACM, V15, P11; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FISHER RB, 1983, 8TH INT JOINT C PATT, P989; FUAGERAS OD, 1986, P INT C COMP VIS PAT, P15; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; GOAD C, 1986, PIXELS PREDICATES; Horn Berthold K. P., 1975, PSYCHOL COMPUTER VIS, P115; JACKINS CL, 1980, COMPUT VISION GRAPH, V14, P249, DOI 10.1016/0146-664X(80)90055-6; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5; KENDER JR, 1980, THESIS CARNEGIE MELL; Klinger A., 1976, COMPUT VISION GRAPH, V5, P68, DOI [10.1016/S0146-664X(76)80006-8, DOI 10.1016/S0146-664X(76)80006-8]; LOWE DG, 1986, TR202 NEW YORK U COM; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARTIN WN, 1983, IEEE T PATTERN ANAL, V5, P150, DOI 10.1109/TPAMI.1983.4767367; MEAGHER D, 1982, COMPUT VISION GRAPH, V19, P129, DOI 10.1016/0146-664X(82)90104-6; MEAGHER DJR, THESIS RENSSELAER PO; Requicha A. A. G., 1980, Computing Surveys, V12, P437, DOI 10.1145/356827.356833; SAMET H, 1980, P IJCPR 80, P36; SCHWEIKERT DG, 1966, J MATH PHYS CAMB, V45, P312, DOI 10.1002/sapm1966451312; STEVEN K, 1979, THESIS MIT DEP ELEC; WALLACE TP, 1980, COMPUT VISION GRAPH, V13, P99, DOI 10.1016/S0146-664X(80)80035-9; WANG YF, 1984, IEEE T PATTERN ANAL, V6, P513, DOI 10.1109/TPAMI.1984.4767556; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9; WOODHAM RJ, 1979, P IJCAI, V79, P413; YAU MM, 1983, COMMUN ACM, V26, P504, DOI 10.1145/358150.358158	37	35	37	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1989	11	4					372	389		10.1109/34.19034	http://dx.doi.org/10.1109/34.19034			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	T9100					2022-12-18	WOS:A1989T910000003
J	KHOTANZAD, A; CHEN, JY				KHOTANZAD, A; CHEN, JY			UNSUPERVISED SEGMENTATION OF TEXTURED IMAGES BY EDGE-DETECTION IN MULTIDIMENSIONAL FEATURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									CHUNG SHAN INST SCI & TECHNOL, TAIPEI, TAIWAN	Chung-Shan Institute of Science & Technology	KHOTANZAD, A (corresponding author), SO METHODIST UNIV, DEPT ELECT ENGN, IMAGE PROC & ANAL LAB, DALLAS, TX 75275 USA.							BRODATZ P, 1956, TEXTURE PHOTOGRAPHIC; CHEN PC, 1983, IEEE T PATTERN ANAL, V5, P64, DOI 10.1109/TPAMI.1983.4767346; COGGINS JM, 1985, PATTERN RECOGN LETT, V3, P195, DOI 10.1016/0167-8655(85)90053-4; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; GONZALEZ RC, 1977, DIGITAL IMAGE PROCES, P119; GOOL LV, 1985, COMPUTER VISION GRAP, V29, P336; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; Kashyap R. L., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P1202; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; KASHYAP RL, 1981, PROGR PATTERN RECOGN, V1, P149; KHOTANZAD A, 1987, IEEE T SYST MAN CYB, V17, P1087, DOI 10.1109/TSMC.1987.6499322; KHOTANZAD A, 1987, UNSUPERVISED SEGMENT; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2, P232; THOMPSON WB, 1977, IEEE T COMPUT, V26, P272, DOI 10.1109/TC.1977.1674818; TRIENDL E, 1980, 5TH P IEEE INT C PAT, P1100; UNSER M, 1986, IEEE T PATTERN ANAL, V8, P118, DOI 10.1109/TPAMI.1986.4767760	16	35	40	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1989	11	4					414	421		10.1109/34.19038	http://dx.doi.org/10.1109/34.19038			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	T9100					2022-12-18	WOS:A1989T910000007
J	FISK, S				FISK, S			SEPARATING POINT SETS BY CIRCLES, AND THE RECOGNITION OF DIGITAL DISKS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											FISK, S (corresponding author), BOWDOIN COLL,DEPT MATH,BRUNSWICK,ME 04011, USA.							Kim C. E., 1984, 16 ANN ACM S THEOR C, P117; KIM CE, 1982, IEEE T PATTERN ANAL, V4, P618, DOI 10.1109/TPAMI.1982.4767315; KIM CE, 1984, IEEE T PATTERN ANAL, V6; NAKAMURA A, COMPUT VISION GRAPHI, V26, P242; OROURKE J, 1986, UNPUB DISCRETE COMPU; Shamos MI, 1978, THESIS YALE U NEW HA	6	35	35	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1986	8	4					554	556		10.1109/TPAMI.1986.4767821	http://dx.doi.org/10.1109/TPAMI.1986.4767821			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	C7400					2022-12-18	WOS:A1986C740000016
J	ARGENTIERO, P; CHIN, R; BEAUDET, P				ARGENTIERO, P; CHIN, R; BEAUDET, P			AN AUTOMATED APPROACH TO THE DESIGN OF DECISION TREE CLASSIFIERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									BUSINESS & TECHNOL SYST INC, SEABROOK, MD 20801 USA; NASA, GODDARD SPACE FLIGHT CTR, GREENBELT, MD 20771 USA	National Aeronautics & Space Administration (NASA); NASA Goddard Space Flight Center								ARGENTIERO P, 1980, 1980 P S MACH PROC R; BOULLION TL, 1975, PATTERN RECOGN, V7, P139, DOI 10.1016/0031-3203(75)90024-2; DECELL HP, 1979, PATTERN RECOGN, V11, P55, DOI 10.1016/0031-3203(79)90029-3; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; KULKARNI A, 1976, 3RD P IJCPR COR; KULKARNI A, 1978, IEEE T COMPUT, V27; MEREMBECK B, 1979, JUN P S MACH PROC RE; MOBASSERI BG, 1979, IEEE T SYST MAN CYB, V9, P660; MUI JK, 1980, IEEE T PATTERN ANAL, V2, P429, DOI 10.1109/TPAMI.1980.6592364; WAHL PW, 1977, BIOMETRICS, V33, P479, DOI 10.2307/2529362; WU C, 1974, LARS090174 PURD U NO; SIGMA 2 STUDY CAPABI	12	35	36	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	1					51	57		10.1109/TPAMI.1982.4767195	http://dx.doi.org/10.1109/TPAMI.1982.4767195			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MY534	21869002	Green Submitted			2022-12-18	WOS:A1982MY53400009
J	BHANU, B; FAUGERAS, OD				BHANU, B; FAUGERAS, OD			SEGMENTATION OF IMAGES HAVING UNIMODAL DISTRIBUTIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV SO CALIF,DEPT ELECT ENGN,LOS ANGELES,CA 90007; UNIV SO CALIF,INST IMAGE PROC,LOS ANGELES,CA 90007	University of Southern California; University of Southern California				Bhanu, Bir/0000-0001-8971-6416				BERTHOD M, 8TH P WORLD COMP C T, P695; BHANU B, 1980, USCIPI960 U SO CAL I; FAUGERAS OD, 1981, IEEE T PATTERN ANAL, V3, P412, DOI 10.1109/TPAMI.1981.4767127; FEKETE G, 1979, 796 U MAR DEP COMP S; HELLAND AR, 1980, APR P IM UND WORKSH, P176; JAIN AK, 1980, IEEE T PATTERN ANAL, V2, P232, DOI 10.1109/TPAMI.1980.4767010; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; OHLANDER R, 1978, COMPUT VISION GRAPH, V8, P313, DOI 10.1016/0146-664X(78)90060-6; PELEG S, 1978, IEEE T SYST MAN CYB, V8, P555; PELEG S, 1980, IEEE T PATTERN ANAL, V2, P362, DOI 10.1109/TPAMI.1980.4767035; ROSENFELD A, 1978, IEEE T SYST MAN CYB, V8, P300; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; ROSENFELD A, 1979, APR P DARPA IM UND W, P14; WESZKA JS, 1978, COMPUT VISION GRAPH, V7, P259, DOI 10.1016/0146-664X(78)90116-8	14	35	35	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	4					408	419		10.1109/TPAMI.1982.4767273	http://dx.doi.org/10.1109/TPAMI.1982.4767273			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NT735	21869056				2022-12-18	WOS:A1982NT73500008
J	KOPLOWITZ, J				KOPLOWITZ, J			ON THE PERFORMANCE OF CHAIN CODES FOR QUANTIZATION OF LINE DRAWINGS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											KOPLOWITZ, J (corresponding author), CLARKSON COLL TECHNOL,DEPT ELECT & COMP ENGN,POTSDAM,NY 13676, USA.							DUDA RO, 1973, PATTERN CLASSIFICATI, P368; Freeman H., 1961, IRE T ELECT COMPUTER, VEC-10, P260, DOI DOI 10.1109/TEC.1961.5219197; Freeman H., 1974, COMPUT SURV, V6, P58, DOI DOI 10.1145/356625.356627; GROEN FCA, 1978, COMPUT VISION GRAPH, V7, P391, DOI 10.1016/S0146-664X(78)80005-7; Kendall MG, 1963, GEOMETRICAL PROBABIL; KOPLOWITZ J, 1976, OCT P CAN C COMM POW; KOPLOWITZ J, 1979, JUN IEEE INT S INF T; Santal LA., 1953, INTRO INTEGRAL GEOME, V1198; Solomon Herbert, 1978, GEOMETRIC PROBABILIT	9	35	35	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	2					180	185		10.1109/TPAMI.1981.4767075	http://dx.doi.org/10.1109/TPAMI.1981.4767075			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MN968	21868932				2022-12-18	WOS:A1981MN96800007
J	GEVINS, AS				GEVINS, AS			PATTERN-RECOGNITION OF HUMAN-BRAIN ELECTRICAL POTENTIALS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Review											GEVINS, AS (corresponding author), UNIV CALIF SAN FRANCISCO, LANGLEY PORTER NEUROPSYCHIAT INST, EEG SYST LAB, SAN FRANCISCO, CA 94143 USA.							ADEY WR, 1969, ATTENTION NEUROPHYSI, P194; Agrawala AK, 1977, MACHINE RECOGNITION; Anderson T.W, 1958, INTRO MULTIVARIATE S; Andrews H. C., 1972, INTRO MATH TECHNIQUE; [Anonymous], 1975, APPL MULTIPLE REGRES, DOI 10.4324/9780203774441.; [Anonymous], [No title captured]; ARNOLDS D, 1978, R19781 I MED PHYS OR; BARLOW JS, 1979, IEEE T BIO-MED ENG, V26, P377, DOI 10.1109/TBME.1979.326416; BEATTY J, 1977, 14 OFF NAV RES PHYSL; Berger H, 1929, ARCH PSYCHIAT NERVEN, V87, P527, DOI 10.1007/BF01797193; BERKHOUT J, 1968, IEEE T BIO-MED ENG, VBM15, P165, DOI 10.1109/TBME.1968.4502560; BERKHOUT J, 1969, ELECTROEN CLIN NEURO, V27, P457, DOI 10.1016/0013-4694(69)90186-2; BOWLING PS, 1978, IEEE T BIO-MED ENG, V25, P12, DOI 10.1109/TBME.1978.326371; BRILLINGER DR, 1978, BIOL CYBERN, V31, P141, DOI 10.1007/BF00336999; Callaway E, 1978, EVENT RELATED BRAIN; CARRIE JRG, 1971, BIOMEDICAL COMPUTING, V2, P251; CHAPMAN RM, 1978, BRAIN LANG, V5, P195, DOI 10.1016/0093-934X(78)90018-4; CHEN CH, 1973, STATISTICAL PATTERN; CHILDERS DG, 1977, P IEEE, V65, P611, DOI 10.1109/PROC.1977.10540; CLARK DL, 1973, ANESTHESIOLOGY, V38, P564, DOI 10.1097/00000542-197306000-00011; COGER RW, 1976, P SAN DIEGO BIOMEDIC, V15, P279; COHEN BA, 1977, MED BIOL ENG COMPUT, V15, P513, DOI 10.1007/BF02442278; COHEN J, 1969, STATISTICAL POWER AN; COOPER R, 1965, ELECTROEN CLIN NEURO, V18, P217, DOI 10.1016/0013-4694(65)90088-X; Cooper R., 1974, EEG TECHNOLOGY, V2nd ed; Cover T. M., 1976, 3rd International Joint Conference on Pattern Recognition, P245; COVER TM, 1974, IEEE T SYST MAN CYB, VSMC4, P116, DOI 10.1109/TSMC.1974.5408535; CREUTZFELDT O, 1974, NEURONAL GENERATIO C, V2; CREUTZFELDT OD, 1966, ELECTROEN CLIN NEURO, V20, P1, DOI 10.1016/0013-4694(66)90136-2; DANIEL RS, 1965, PSYCHOPHYSIOLOGY, V2, P146, DOI 10.1111/j.1469-8986.1965.tb03259.x; DASILVA HL, 1973, ELECTROEN CLIN NEURO, V35, P627; DEECKE L, 1976, BIOL CYBERN, V23, P99, DOI 10.1007/BF00336013; DEFAYOLLE M, 1974, ELECTROEN CLIN NEURO, V36, P319, DOI 10.1016/0013-4694(74)90176-X; DELUCCHI MR, 1962, ELECTROEN CLIN NEURO, V14, P191, DOI 10.1016/0013-4694(62)90028-7; DESMEDT J, 1975, PROGR CLIN NEUROPHYS; DIXON WJ, 1969, INTRO STATISTICAL AN; DOLCE G, 1975, CEAN COMPUTERIZED EE, P157; DOLCE G, 1975, CEAN COMPUTERIZED EE; DONCHIN E, 1966, IEEE T BIO-MED ENG, VBM13, P131, DOI 10.1109/TBME.1966.4502423; DONCHIN E, 1970, ELECTROEN CLIN NEURO, V29, P429, DOI 10.1016/0013-4694(70)90060-X; DONCHIN E, 1975, ELECTROEN CLIN NEURO, V38, P51, DOI 10.1016/0013-4694(75)90210-2; Donchin E., 1969, AVERAGE EVOKED POTEN, P199, DOI [10.1037/13016-005, DOI 10.1037/13016-005]; DONCHIN E, 1977, LATERALIZATION NERVO, P339, DOI DOI 10.1016/B978-0-12-325750-5.50026-9; DOYLE JC, 1974, PSYCHOPHYSIOLOGY, V11, P567, DOI 10.1111/j.1469-8986.1974.tb01116.x; DUBES RC, 1970, 13 INT SCI REP; DUMERMUTH G, 1970, IEEE T ACOUST SPEECH, VAU18, P404, DOI 10.1109/TAU.1970.1162144; DUMERMUTH G, 1967, MED BIOL ENG, V5, P319, DOI 10.1007/BF02479095; DYMOND AM, 1975, 28TH ACEMB; ELUL R, 1969, SCIENCE, V164, P328, DOI 10.1126/science.164.3877.328; Elul R, 1971, Int Rev Neurobiol, V15, P227; ELUL R, 1972, SYNCHRONIZATION EEG, P59; FENWICK PBC, 1967, BIOMED COMPUT, V2, P281; FINK M, PHARMACOKINETICS PSY; FINK M, 1977, EEG INFORMATICS DIDA, P301; FOLEY DH, 1972, IEEE T INFORM THEORY, V18, P618, DOI 10.1109/TIT.1972.1054863; FREEMAN W, 1979, J CYBERN INFORM SCI; Freeman WJ, 1975, MASS ACTION NERVOUS; FREEMAN WJ, UNPUBLISHED; FREEMAN WJ, 1978, CONT CLIN NEUROPHYSI, P9; FRIBERG S, 1976, QUANTITATIVE ANAL ST, P289; FU KS, 1968, SEQUENTIAL MACHINES; FUKUNAGA K, 1970, IEEE T COMPUT, VC 19, P311, DOI 10.1109/T-C.1970.222918; Gasser T., 1977, EEG INFORMATICS DIDA, P37; GERSCH W, 1977, COMPUT BIOMED RES, V10, P113, DOI 10.1016/0010-4809(77)90029-5; GERSCH W, 1970, Mathematical Biosciences, V7, P205, DOI 10.1016/0025-5564(70)90049-0; GERSCH W, 1979, SCIENCE, V205, P193, DOI 10.1126/science.451587; GERSCH W, 1977, COMPUT BIOMED RES, V10, P297, DOI 10.1016/0010-4809(77)90044-1; GERSCH W, UNPUBLISHED; GERSCH W, 1980, COMPUT BIOMED RE APR; GEVINS A, UNPUBLISHED; GEVINS AS, 1979, ELECTROEN CLIN NEURO, V47, P704, DOI 10.1016/0013-4694(79)90297-9; GEVINS AS, 1979, SCIENCE, V203, P665, DOI 10.1126/science.760212; GEVINS AS, 1977, ELECTROEN CLIN NEURO, V43, P31, DOI 10.1016/0013-4694(77)90192-4; GEVINS AS, 1975, P IEEE, V63, P1382, DOI 10.1109/PROC.1975.9966; GEVINS AS, 1977, ELECTROEN CLIN NEURO, V42, P267, DOI 10.1016/0013-4694(77)90035-9; GEVINS AS, 1979, ELECTROEN CLIN NEURO, V47, P693, DOI 10.1016/0013-4694(79)90296-7; GEVINS AS, 1980, ELECTRODIAGNOSIS CLI, P118; GEVINS AS, 1980, CRC CRITICAL REV BIO; Gibbs, 1951, ATLAS ELECTROENCEPHA, V1; Gibbs F.A., 1964, ATLAS ELECTROENCEPHA, V3; Gibbs FA., 1952, ATLAS ELECTROENCEPHA, VII; GIESE D, 1979, IEEE T SYST MAN  SEP; GINN HE, 1975, KIDNEY INT, V7, pS357; Glaser E., 1976, PRINCIPLES NEUROBIOL; GLASS A, 1969, ELECTROEN CLIN NEURO, V26, P538; GLOOR P, 1969, ELECTROENCEPH CL S28; Goff W., 1978, EVENT RELATED BRAIN, P1; GOMER F, 1979, MDCE2046 MC DOUGL AS; Gonzalez RC, 1978, SYNTACTIC PATTERN RE; GOTMAN J, 1973, ELECTROEN CLIN NEURO, V35, P225, DOI 10.1016/0013-4694(73)90233-2; GOTMAN J, 1975, ELECTROEN CLIN NEURO, V38, P623, DOI 10.1016/0013-4694(75)90163-7; GRAY HL, 1972, GENERALIZED JACKKNIF, P115; HANLEY J, 1968, NATURE, V220, P879, DOI 10.1038/220879a0; HAWKES CH, 1973, ELECTROEN CLIN NEURO, V34, P197, DOI 10.1016/0013-4694(73)90048-5; HERNING R, UNPUBLISHED; HILLYARD SA, 1973, SCIENCE, V182, P177, DOI 10.1126/science.182.4108.177; HILLYARD SA, 1978, EVENT RELATED BRAIN, P223, DOI DOI 10.1016/B978-0-12-155150-6.50016-X; HJORTH B, 1970, ELECTROEN CLIN NEURO, V29, P306, DOI 10.1016/0013-4694(70)90143-4; HOCKING RR, 1976, BIOMETRICS, V32, P1, DOI 10.2307/2529336; HORST RL, 1980, ELECTROEN CLIN NEURO, V48, P113, DOI 10.1016/0013-4694(80)90298-9; HOSEK RS, 1978, IEEE T BIO-MED ENG, V25, P405, DOI 10.1109/TBME.1978.326337; HUBER PJ, 1971, IEEE T ACOUST SPEECH, VAU19, P78, DOI 10.1109/TAU.1971.1162163; INBAR G, 1975, SIGNAL ANAL PATTERN; INGVAR DH, 1975, BRAIN WORK; IRWIN P, 1975, QUANTITATIVE ANAL EE, P379; ISAKSSON A, 1975, 95 ROYAL I TECHN TEC; ISAKSSON A, 1977, 117 ROYAL I TECHN TE; ISAKSSON A, 1975, 96 ROYAL I TECHN TEC; ISAKSSON A, 1977, 120 ROYAL I TECHN TE; ITIL TM, 1979, PHARMAKOPSYCH NEURO, V12, P4, DOI 10.1055/s-0028-1094590; ITIL TM, 1979, PSYCHIAT J U OTTAWA, V4, P45; ITIL TM, 1972, PHARMAKOPSYCH NEURO, V5, P225, DOI 10.1055/s-0028-1094352; ITIL TM, 1974, PSYCHOTROPIC DRUGS H; JENDEN DJ, 1972, BIOMETRICS, V28, P73, DOI 10.2307/2528962; JENNRICH R, 1977, STATISTICAL METHODS, V3; John E. R., 1977, FUNCTIONAL NEUROSCIE, VII; John E R, 1978, EVENT RELATED BRAIN, P93, DOI 10.1016/B978-0-12-155150-6.50010-9; JOHN ER, 1964, ANN NY ACAD SCI, V112, P362, DOI 10.1111/j.1749-6632.1964.tb26761.x; JOHN ER, 1977, SCIENCE, V196, P1393, DOI 10.1126/science.867036; JOHN ER, 1977, PSYCHOPATHOLOGY BRAI, P291; JOHNSON L, 1969, ELECTROEN CLIN NEURO, V26, P361, DOI 10.1016/0013-4694(69)90086-8; JONES RH, 1972, 5TH P HAW INT C SYST, P18; KAVANAGH RN, 1976, ELECTROEN CLIN NEURO, V40, P633, DOI 10.1016/0013-4694(76)90138-3; KELLAWAY P, 1976, QUANTITATIVE ANAL ST; Klemm W R, 1976, Prog Neurobiol, V6, P23, DOI 10.1016/0301-0082(76)90005-8; Kooi K., 1978, FUNDAMENTALS ELECTRO; KORNHUBER HH, 1964, PFLUG ARCH EUR J PHY, V281, P52; KORNHUBER HH, 1979, 5TH INT S EL POT REL; LACHIN JM, 1974, PSYCHOPHYSIOLOGY, V11, P703, DOI 10.1111/j.1469-8986.1974.tb01139.x; LARSEN LE, 1970, ELECTROEN CLIN NEURO, V28, P459, DOI 10.1016/0013-4694(70)90271-3; LARSEN LE, 1969, IEEE T BIO-MED ENG, VBM16, P23, DOI 10.1109/TBME.1969.4502599; LEADER HS, 1967, ELECTROEN CLIN NEURO, V23, P566, DOI 10.1016/0013-4694(67)90025-9; LEHMANN D, 1975, CEAN COMPUTERIZED EE, P102; LEISSNER P, 1970, ELECTROEN CLIN NEURO, V29, P392, DOI 10.1016/0013-4694(70)90047-7; Livanov M.N., 1977, SPATIAL ORG CEREBRAL; LUBIN A, 1970, AGRESSOLOGIE, V10, P593; MARTIN WB, 1972, ELECTROEN CLIN NEURO, V32, P417, DOI 10.1016/0013-4694(72)90009-0; MATEJCEK M, 1975, QUANTITATIVE ANAL EE; MATHIEU M, 1975, QUANTITATIVE ANAL EE, P475; MATOUSEK M, 1973, ELECTROEN CLIN NEURO, V35, P603, DOI 10.1016/0013-4694(73)90213-7; Matousek M., 1973, AUTOMATION CLIN ELEC, P75; MATOUSEK M, 1973, HDB ELECTROENCEPHA A, V5, P61; MCEWEN JA, 1975, IEEE T BIO-MED ENG, VBM22, P299, DOI 10.1109/TBME.1975.324448; MCEWEN JA, 1975, THESIS U BRIT COLUMB; Meisel W., 1972, COMPUTER ORIENTED AP; Mendel J. M., 1970, ADAPTIVE LEARNING PA; Mountcastle V.B., 1979, NEUROSCIENCE 4 STUDY, P21; MUCCIARDI AM, 1974, PSYCHOTROPIC DRUGS H, P351; MUCCIARDI AN, 1971, IEEE T COMPUT, VC 20, P1023, DOI 10.1109/T-C.1971.223398; MUNDYCASTLE AC, 1957, ELECTROEN CLIN NEURO, V9, P643, DOI 10.1016/0013-4694(57)90085-8; Nilsson N., 1965, LEARNING MACHINES; OTTO D, 1979, NEW PERSPECTIVES ERP; PFURTSCHELLER G, 1975, ELECTROEN CLIN NEURO, V38, P93, DOI 10.1016/0013-4694(75)90215-1; PLONSEY R, 1977, P IEEE, V65, P601, DOI 10.1109/PROC.1977.10539; RAO CR, 1952, ADV STATISTICAL METH; RAO CR, 1965, LINEAR STATISTICAL I; Rechtschaffen A., 1973, MANUAL STANDARDIZED; Regan D, 1972, EVOKED POTENTIALS PS; REMOND A, 1977, EEG INFORMATICS DIDA; REMOND A, 1971, HDB ELECTROENCEPHALO; Ritter W., 1978, EVENT RELATED BRAIN, P349, DOI [10.1016/b978-0-12-155150-6.50019-5, DOI 10.1016/B978-0-12-155150-6.50019-5]; RUCHKIN DS, 1964, ANN NY ACAD SCI, V115, P799; RUSH S, 1969, IEEE T BIO-MED ENG, VBM16, P15, DOI 10.1109/TBME.1969.4502598; SALTZBERG B, 1959, IRE WESCON CONV REC, V8, P35; SAMPSON P, 1967, BMD BIOMEDICAL COMPU; SCHENK G, 1975, QUANTITATIVE ANAL EE, P337; SCHNEIDER M, 1974, IEEE T BIO-MED ENG, VBM21, P52, DOI 10.1109/TBME.1974.324363; SENCAJ RW, 1979, MED BIOL ENG COMPUT, V17, P391, DOI 10.1007/BF02443829; SHAPIRO DM, 1974, PSYCHOTROPIC DRUGS H, P327; SIMON O, 1977, ELECTROEN CLIN NEURO, V42, P48, DOI 10.1016/0013-4694(77)90150-X; SKLAR B, 1973, IEEE T BIO-MED ENG, VBM20, P20, DOI 10.1109/TBME.1973.324247; SQUIRES KC, 1976, SCIENCE, V193, P1142, DOI 10.1126/science.959831; SQUIRES KC, 1976, ELECTROEN CLIN NEURO, V41, P449, DOI 10.1016/0013-4694(76)90056-0; STARR A, 1978, EVENT RELATED BRAIN, P155; Stearns S. D., 1976, 3rd International Joint Conference on Pattern Recognition, P71; STONE M, 1977, J R STAT SOC B, V39, P44, DOI 10.1111/j.2517-6161.1977.tb01603.x; SUTTON S, 1965, SCIENCE, V150, P1187, DOI 10.1126/science.150.3700.1187; Szentagothai J, 1978, ARCHITECTONICS CEREB, P77; SZENTAGOTHAI J, 1977, CEREBRAL CORRELATES, P131; THATCHER R, 1979, EVOKED BRAIN POTENTI, P143; Tou JT, 1974, PATTERN RECOGN; VANDIS H, 1979, ELECTROEN CLIN NEURO, V47, P87, DOI 10.1016/0013-4694(79)90035-X; VANNESS J, 1979, TECHNOMETRICS, V21, P119, DOI 10.2307/1268588; VANNESS JW, 1976, TECHNOMETRICS, V18, P175, DOI 10.2307/1267520; VANROTTERDAM A, 1970, IEEE T BIO-MED ENG, VBM17, P268, DOI 10.1109/TBME.1970.4502744; VIDAL J, 1972, 5TH P HAW INT C SYST, P255; VIDAL JJ, 1977, P IEEE, V65, P633, DOI 10.1109/PROC.1977.10542; Viglione S. S., 1970, Adaptive, learning, and pattern recognition systems: theory and applications, P115; VIGLIONE SS, 1973, G4775P MDAC MCD DOUG; WALTER DO, 1967, ELECTROEN CLIN NEURO, V22, P22, DOI 10.1016/0013-4694(67)90005-3; WALTER DO, 1963, EXP NEUROL, V8, P155, DOI 10.1016/0014-4886(63)90042-6; WALTER DO, 1966, ELECTROEN CLIN NEURO, V20, P224, DOI 10.1016/0013-4694(66)90087-3; WALTER WG, 1964, NATURE, V203, P380, DOI 10.1038/203380a0; WRIGHT SC, 1976, ESLR738 MIT EL SYST; YEAGER CL, 1972, COMPUTER CLASSIFICAT; YUNCK T, UNPUBLISHED; YUNCK TP, 1977, THESIS YALE U; ZETTERBERG L, 1978, CONT CLIN NEUROPHYSI, P19; ZETTERBERG L H, 1969, Mathematical Biosciences, V5, P227, DOI 10.1016/0025-5564(69)90044-3; Zetterberg L H, 1977, Adv Biol Med Phys, V16, P41; [No title captured]; [No title captured]; [No title captured]	203	35	36	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	5					383	404		10.1109/TPAMI.1980.6592360	http://dx.doi.org/10.1109/TPAMI.1980.6592360			22	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KW185					2022-12-18	WOS:A1980KW18500002
J	Clough, JR; Byrne, N; Oksuz, I; Zimmer, VA; Schnabel, JA; King, AP				Clough, James R.; Byrne, Nicholas; Oksuz, Ilkay; Zimmer, Veronika A.; Schnabel, Julia A.; King, Andrew P.			A Topological Loss Function for Deep-Learning Based Image Segmentation Using Persistent Homology	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image segmentation; Topology; Shape; Training; Loss measurement; Neural networks; Network topology; Segmentation; persistent homology; topology; medical imaging; convolutional neural networks		We introduce a method for training neural networks to perform image or volume segmentation in which prior knowledge about the topology of the segmented object can be explicitly provided and then incorporated into the training process. By using the differentiable properties of persistent homology, a concept used in topological data analysis, we can specify the desired topology of segmented objects in terms of their Betti numbers and then drive the proposed segmentations to contain the specified topological features. Importantly this process does not require any ground-truth labels, just prior knowledge of the topology of the structure being segmented. We demonstrate our approach in four experiments: one on MNIST image denoising and digit recognition, one on left ventricular myocardium segmentation from magnetic resonance imaging data from the UK Biobank, one on the ACDC public challenge dataset and one on placenta segmentation from 3-D ultrasound. We find that embedding explicit prior knowledge in neural network segmentation tasks is most beneficial when the segmentation task is especially challenging and that it can be used in either a semi-supervised or post-processing context to extract a useful training gradient from images without pixelwise labels.	[Clough, James R.; Byrne, Nicholas; Oksuz, Ilkay; Zimmer, Veronika A.; Schnabel, Julia A.; King, Andrew P.] Kings Coll London, Sch Biomed Engn & Imaging Sci, London WC2R 2LS, England; [Oksuz, Ilkay] Istanbul Tech Univ, Comp Engn Dept, TR-34467 Istanbul, Turkey	University of London; King's College London; Istanbul Technical University	Clough, JR (corresponding author), Kings Coll London, Sch Biomed Engn & Imaging Sci, London WC2R 2LS, England.	james.clough@kcl.ac.uk; nicholas.byrne@kcl.ac.uk; ilkay.oksuz@kcl.ac.uk; veronika.zimmer@kcl.ac.uk; julia.schnabel@kcl.ac.uk; andrew.king@kcl.ac.uk	; Byrne, Nicholas/D-3255-2018; Zimmer, Veronika/D-8081-2014; oksuz, ilkay/I-8364-2014	Clough, James/0000-0002-9135-0545; Byrne, Nicholas/0000-0003-3401-9570; Zimmer, Veronika/0000-0002-5093-5854; King, Andrew/0000-0002-9965-7015; oksuz, ilkay/0000-0001-6478-0534; Schnabel, Julia Anne/0000-0001-6107-3009	EPSRC programme Grant 'SmartHeart' [EP/P001009/1]; Wellcome Trust IEH Award [102431]; Wellcome EPSRC Centre forMedical Engineering at School of Biomedical Engineering and Imaging Sciences, Kings College London [WT 203148/Z/16/Z]; National Institute for Health Research (NIHR) Biomedical Research Centre at Guys and St ThomasNHSFoundation Trust and Kings College London	EPSRC programme Grant 'SmartHeart'(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Wellcome Trust IEH Award; Wellcome EPSRC Centre forMedical Engineering at School of Biomedical Engineering and Imaging Sciences, Kings College London(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); National Institute for Health Research (NIHR) Biomedical Research Centre at Guys and St ThomasNHSFoundation Trust and Kings College London	This work was supported by the EPSRC programme Grant `SmartHeart' (EP/P001009/1), the Wellcome Trust IEH Award [102431], the Wellcome EPSRC Centre forMedical Engineering at School of Biomedical Engineering and Imaging Sciences, Kings College London (WT 203148/Z/16/Z) and by the National Institute for Health Research (NIHR) Biomedical Research Centre at Guys and St ThomasNHSFoundation Trust and Kings College London. This research has been conducted using the UK Biobank Resource under Application Numbers 17806 and 40119. The authors would like to thank NVIDIA for kindly donating theQuadro P6000 GPU used in this research.	[Anonymous], 2015, GUDHI USER REFERENCE; Assaf R, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON ADVANCES IN BIOMEDICAL ENGINEERING (ICABME), P93; Bendich P, 2016, ANN APPL STAT, V10, P198, DOI 10.1214/15-AOAS886; Bernard O, 2018, IEEE T MED IMAGING, V37, P2514, DOI 10.1109/TMI.2018.2837502; Bruel-Gabrielsson R, 2020, PR MACH LEARN RES, V108, P1553; Byrne Nick, 2019, Smart Ultrasound Imaging and Perinatal, Preterm and Paediatric Image Analysis. First International Workshop, SUSI 2019 and 4th International Workshop, PIPPI 2019. Held in Conjunction with MICCAI 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11798), P181, DOI 10.1007/978-3-030-32875-7_20; Byrne N, 2016, JRSM CARDIOVASC DIS, V5, P1, DOI 10.1177/2048004016645467; Charlier J, 2019, 2019 6TH SWISS CONFERENCE ON DATA SCIENCE (SDS), P87, DOI 10.1109/SDS.2019.000-1; Chen C, 2019, PR MACH LEARN RES, V89; Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49; Clough JR, 2019, LECT NOTES COMPUT SC, V11492, P16, DOI 10.1007/978-3-030-20351-1_2; Edelsbrunner H, 2000, ANN IEEE SYMP FOUND, P454; Edelsbrunner H, 2008, CONTEMP MATH, V453, P257; Fraz MM, 2012, COMPUT METH PROG BIO, V108, P407, DOI 10.1016/j.cmpb.2012.03.009; Ganaye PA, 2018, LECT NOTES COMPUT SC, V11072, P595, DOI 10.1007/978-3-030-00931-1_68; Gao Mingchen, 2013, Inf Process Med Imaging, V23, P184, DOI 10.1007/978-3-642-38868-2_16; Hofer CD, 2019, PR MACH LEARN RES, V97; Hu XL, 2019, ADV NEUR IN, V32; Jaejun Yoo, 2016, Arxiv, DOI arXiv:1611.06391; Kohl SAA, 2018, ADV NEUR IN, V31; Koltun V, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472; LeCun Y., 2010, MNIST HANDWRITTEN DI; Lee MCH, 2019, IEEE T MED IMAGING, V38, P2596, DOI 10.1109/TMI.2019.2905990; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7; Mosinska A, 2018, PROC CVPR IEEE, P3136, DOI 10.1109/CVPR.2018.00331; Oktay O, 2018, IEEE T MED IMAGING, V37, P384, DOI 10.1109/TMI.2017.2743464; Otter N, 2017, EPJ DATA SCI, V6, DOI 10.1140/epjds/s13688-017-0109-5; Petersen SE, 2016, J CARDIOVASC MAGN R, V18, DOI 10.1186/s12968-016-0227-4; Pizer SM, 2003, INT J COMPUT VISION, V55, P85, DOI 10.1023/A:1026313132218; Qaiser T, 2016, PROCEDIA COMPUT SCI, V90, P119, DOI 10.1016/j.procs.2016.07.033; Rieck B., 2019, P INT C LEARN REPR; Ronneberger O., 2015, P MED IM COMP ASS IN, P234, DOI DOI 10.1007/978-3-319-24574-4_28; Segonne F, 2007, IEEE T MED IMAGING, V26, P518, DOI 10.1109/TMI.2006.887364; Simonyan K., 2015, VERY DEEP CONVOLUTIO; Sizemore AE, 2019, NETW NEUROSCI, V3, P656, DOI 10.1162/netn_a_00073; Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28; Vukicevic M, 2017, JACC-CARDIOVASC IMAG, V10, P171, DOI 10.1016/j.jcmg.2016.12.001; Wagner H., 2012, TOPOLOGICAL METHODS, P91, DOI DOI 10.1007/978-3-642-23175-9_7; Wenjia Bai, 2017, Medical Image Computing and Computer-Assisted Intervention, MICCAI 2017. 20th International Conference. Proceedings: LNCS 10434, P253, DOI 10.1007/978-3-319-66185-8_29; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179	42	34	34	9	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2022	44	12					8766	8778		10.1109/TPAMI.2020.3013679	http://dx.doi.org/10.1109/TPAMI.2020.3013679			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	6A4XX	32886606	Green Submitted, hybrid, Green Published			2022-12-18	WOS:000880661400019
J	Laga, H; Jospin, LV; Boussaid, F; Bennamoun, M				Laga, Hamid; Jospin, Laurent Valentin; Boussaid, Farid; Bennamoun, Mohammed			A Survey on Deep Learning Techniques for Stereo-Based Depth Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Estimation; Videos; Deep learning; Three-dimensional displays; Australia; Training; Pipelines; CNN; deep learning; 3D reconstruction; stereo matching; multi-view stereo; disparity estimation; feature leaning; feature matching		Estimating depth from RGB images is a long-standing ill-posed problem, which has been explored for decades by the computer vision, graphics, and machine learning communities. Among the existing techniques, stereo matching remains one of the most widely used in the literature due to its strong connection to the human binocular system. Traditionally, stereo-based depth estimation has been addressed through matching hand-crafted features across multiple images. Despite the extensive amount of research, these traditional techniques still suffer in the presence of highly textured areas, large uniform regions, and occlusions. Motivated by their growing success in solving various 2D and 3D vision problems, deep learning for stereo-based depth estimation has attracted a growing interest from the community, with more than 150 papers published in this area between 2014 and 2019. This new generation of methods has demonstrated a significant leap in performance, enabling applications such as autonomous driving and augmented reality. In this paper, we provide a comprehensive survey of this new and continuously growing field of research, summarize the most commonly used pipelines, and discuss their benefits and limitations. In retrospect of what has been achieved so far, we also conjecture what the future may hold for deep learning-based stereo for depth estimation research.	[Laga, Hamid] Murdoch Univ, Informat Technol Discipline, Murdoch, WA 6150, Australia; [Laga, Hamid] Univ South Australia, Phen & Bioinformat Res Ctr, Adelaide, SA 5000, Australia; [Jospin, Laurent Valentin; Boussaid, Farid; Bennamoun, Mohammed] Univ Western Australia, Perth, WA 6009, Australia	Murdoch University; University of South Australia; University of Western Australia	Laga, H (corresponding author), Murdoch Univ, Informat Technol Discipline, Murdoch, WA 6150, Australia.; Laga, H (corresponding author), Univ South Australia, Phen & Bioinformat Res Ctr, Adelaide, SA 5000, Australia.	H.Laga@murdoch.edu.au; laurent.jospin@research.uwa.edu.au; farid.boussaid@uwa.edu.au; mohammed.bennamoun@uwa.edu.au	Bennamoun, Mohammed/C-2789-2013	Bennamoun, Mohammed/0000-0002-6603-3257; Jospin, Laurent Valentin/0000-0001-5395-1967; BOUSSAID, FARID/0000-0001-7250-7407	Murdoch University's Vice Chancellor's Small Steps of Innovation Funding Program; Australian Research Council [DP150100294, DP150104251]	Murdoch University's Vice Chancellor's Small Steps of Innovation Funding Program; Australian Research Council(Australian Research Council)	We would like to thank all the authors of the reference papers who have made their codes and datasets publicly available. This work was supported in part by Murdoch University's Vice Chancellor's Small Steps of Innovation Funding Program, and by the Australian Research Council (Grants DP150100294 and DP150104251).	Aanaes H, 2016, INT J COMPUT VISION, V120, P153, DOI 10.1007/s11263-016-0902-9; Ahmadi A, 2016, IEEE IMAGE PROC, P1629, DOI 10.1109/ICIP.2016.7532634; Atapour-Abarghouei A, 2018, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2018.00296; Bai M, 2016, LECT NOTES COMPUT SC, V9910, P154, DOI 10.1007/978-3-319-46466-4_10; Balntas Vassileios, 2016, ARXIV160105030; Barron JT, 2019, PROC CVPR IEEE, P4326, DOI 10.1109/CVPR.2019.00446; Batsos K, 2018, PROC CVPR IEEE, P2060, DOI 10.1109/CVPR.2018.00220; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44; Chabra R, 2019, PROC CVPR IEEE, P11778, DOI 10.1109/CVPR.2019.01206; Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567; Chen CR, 2019, IEEE I CONF COMP VIS, P8996, DOI 10.1109/ICCV.2019.00909; Chen ZY, 2015, IEEE I CONF COMP VIS, P972, DOI 10.1109/ICCV.2015.117; Cheng XJ, 2018, LECT NOTES COMPUT SC, V11220, P108, DOI 10.1007/978-3-030-01270-0_7; Choi S, 2018, P IEEE C COMP VIS PA, P276; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Duggal S, 2019, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2019.00448; Eigen D, 2014, ADV NEUR IN, V27; Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304; Finn C, 2017, PR MACH LEARN RES, V70; Fischer P, 2014, ARXIV14055769; Flynn J, 2016, PROC CVPR IEEE, P5515, DOI 10.1109/CVPR.2016.595; Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214; Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45; Gast J, 2018, PROC CVPR IEEE, P3369, DOI 10.1109/CVPR.2018.00355; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Geyer Jakob, 2020, A2D2 AUDI AUTONOMOUS; Gidaris S, 2017, PROC CVPR IEEE, P7187, DOI 10.1109/CVPR.2017.760; Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699; Guo XY, 2019, PROC CVPR IEEE, P3268, DOI 10.1109/CVPR.2019.00339; Haeusler R, 2013, PROC CVPR IEEE, P305, DOI 10.1109/CVPR.2013.46; Han XF, 2015, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2015.7298948; Hartmann W, 2017, IEEE I CONF COMP VIS, P1595, DOI 10.1109/ICCV.2017.176; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; Hou YX, 2019, IEEE I CONF COMP VIS, P2651, DOI 10.1109/ICCV.2019.00274; Hu XY, 2012, IEEE T PATTERN ANAL, V34, P2121, DOI 10.1109/TPAMI.2012.46; Huang PH, 2018, PROC CVPR IEEE, P2821, DOI 10.1109/CVPR.2018.00298; Huang XY, 2020, IEEE T PATTERN ANAL, V42, P2702, DOI 10.1109/TPAMI.2019.2926463; Hutter F, AUTOMATED MACHINE LE; Ilg E, 2018, LECT NOTES COMPUT SC, V11216, P626, DOI 10.1007/978-3-030-01258-8_38; Imran Saif, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12438, DOI 10.1109/CVPR.2019.01273; Jeon J, 2018, LECT NOTES COMPUT SC, V11220, P438, DOI 10.1007/978-3-030-01270-0_26; Ji MQ, 2017, IEEE I CONF COMP VIS, P2326, DOI 10.1109/ICCV.2017.253; Jie ZQ, 2018, PROC CVPR IEEE, P3838, DOI 10.1109/CVPR.2018.00404; Kar A., 2017, ADV NEURAL INFORM PR; Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17; Khamis S, 2018, LECT NOTES COMPUT SC, V11219, P596, DOI 10.1007/978-3-030-01267-0_35; Khan SU, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27515-w; Knobelreiter P, 2017, PROC CVPR IEEE, P1456, DOI 10.1109/CVPR.2017.159; Koltun V, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472; Kulkarni TD, 2015, ADV NEUR IN, V28; Kumar BGV, 2016, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2016.581; Kundu JN, 2018, PROC CVPR IEEE, P2656, DOI 10.1109/CVPR.2018.00281; Kuznietsov Y, 2017, PROC CVPR IEEE, P2215, DOI 10.1109/CVPR.2017.238; Lee JH, 2018, PROC CVPR IEEE, P330, DOI 10.1109/CVPR.2018.00042; Leroy V, 2018, LECT NOTES COMPUT SC, V11213, P796, DOI 10.1007/978-3-030-01240-3_48; Li B, 2015, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2015.7298715; Li ZQ, 2018, PROC CVPR IEEE, P2041, DOI 10.1109/CVPR.2018.00218; Liang ZF, 2018, PROC CVPR IEEE, P2811, DOI 10.1109/CVPR.2018.00297; Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283; Liu H, 2019, PROCEEDINGS OF THE THIRD INTERNATIONAL SYMPOSIUM - EDUCATIONAL RESEARCH AND EDUCATIONAL TECHNOLOGY, 2019, P3; Liu SF, 2017, ADV NEUR IN, V30; Luo Keyang, 2019, P IEEE INT C COMP VI; Luo WJ, 2016, PROC CVPR IEEE, P5695, DOI 10.1109/CVPR.2016.614; Mayer N, 2018, INT J COMPUT VISION, V126, P942, DOI 10.1007/s11263-018-1082-6; Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438; Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925; Nie GY, 2019, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2019.00340; Pang JH, 2018, PROC CVPR IEEE, P2070, DOI 10.1109/CVPR.2018.00221; Pang JH, 2017, IEEE INT CONF COMP V, P878, DOI 10.1109/ICCVW.2017.108; Park E, 2017, PROC CVPR IEEE, P702, DOI 10.1109/CVPR.2017.82; Park H, 2017, IEEE SIGNAL PROC LET, V24, P1788, DOI 10.1109/LSP.2016.2637355; Park MG, 2015, PROC CVPR IEEE, P101, DOI 10.1109/CVPR.2015.7298605; Paschalidou D, 2018, PROC CVPR IEEE, P3897, DOI 10.1109/CVPR.2018.00410; Perriollat M, 2011, INT J COMPUT VISION, V95, P124, DOI 10.1007/s11263-010-0352-8; Poggi M, 2018, IEEE INT C INT ROBOT, P5848, DOI 10.1109/IROS.2018.8593814; Poggi M, 2017, IEEE I CONF COMP VIS, P5238, DOI 10.1109/ICCV.2017.559; Poggi M, 2017, PROC CVPR IEEE, P4541, DOI 10.1109/CVPR.2017.483; Poggi M, 2016, INT CONF 3D VISION, P509, DOI 10.1109/3DV.2016.61; Poggi Matteo, 2016, BMVC; Pollefeys M, 2016, BRIT MACH VIS C BMVC; Qi XJ, 2018, PROC CVPR IEEE, P283, DOI 10.1109/CVPR.2018.00037; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3; Schonberger JL, 2018, LECT NOTES COMPUT SC, V11217, P758, DOI 10.1007/978-3-030-01261-8_45; Schops T, 2017, PROC CVPR IEEE, P2538, DOI 10.1109/CVPR.2017.272; Seki A, 2017, PROC CVPR IEEE, P6640, DOI 10.1109/CVPR.2017.703; Shaked A, 2017, PROC CVPR IEEE, P6901, DOI 10.1109/CVPR.2017.730; Shi XJ, 2015, ADV NEUR IN, V28; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22; Song X, 2019, LECT NOTES COMPUT SC, V11365, P20, DOI 10.1007/978-3-030-20873-8_2; Spyropoulos A, 2014, PROC CVPR IEEE, P1621, DOI 10.1109/CVPR.2014.210; Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773; Sukhbaatar S, 2015, P INT C LEARN REPR; Sun X, 2014, PATTERN RECOGN LETT, V49, P201, DOI 10.1016/j.patrec.2014.07.010; Tatarchenko M, 2016, LECT NOTES COMPUT SC, V9911, P322, DOI 10.1007/978-3-319-46478-7_20; Tonioni A, 2019, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2019.00028; Tonioni A, 2019, PROC CVPR IEEE, P9653, DOI 10.1109/CVPR.2019.00989; Tonioni A, 2020, IEEE T PATTERN ANAL, V42, P2396, DOI 10.1109/TPAMI.2019.2940948; Tonioni A, 2017, IEEE I CONF COMP VIS, P1614, DOI 10.1109/ICCV.2017.178; Tosi F, 2018, LECT NOTES COMPUT SC, V11210, P323, DOI 10.1007/978-3-030-01231-1_20; Tulyakov S, 2018, ADV NEUR IN, V31; Tulyakov S, 2017, IEEE I CONF COMP VIS, P1348, DOI 10.1109/ICCV.2017.150; Ummenhofer B, 2017, PROC CVPR IEEE, P5622, DOI 10.1109/CVPR.2017.596; Vijayanarasimhan Sudheendra, 2017, ARXIV170407804; Wang KX, 2018, INT CONF 3D VISION, P248, DOI 10.1109/3DV.2018.00037; Wang R, 2017, IEEE ICC; Wang XL, 2015, PROC CVPR IEEE, P539, DOI 10.1109/CVPR.2015.7298652; Wang Y, 2019, IEEE INT CONF ROBOT, P5893, DOI 10.1109/ICRA.2019.8794003; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wannenwetsch AS, 2017, IEEE I CONF COMP VIS, P1182, DOI 10.1109/ICCV.2017.133; Won C., 2020, IEEE T PATTERN ANAL, P1, DOI [10.1109/TPAMI.2020.2992497, DOI 10.1109/TPAMI.2020.2992497]; Won C, 2019, IEEE I CONF COMP VIS, P8986, DOI 10.1109/ICCV.2019.00908; Wu ZY, 2019, IEEE I CONF COMP VIS, P7483, DOI 10.1109/ICCV.2019.00758; Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458; Xie C.-W., 2018, VORTEX POOLING IMPRO; Xue YZ, 2019, IEEE I CONF COMP VIS, P4311, DOI 10.1109/ICCV.2019.00441; Yang GS, 2019, PROC CVPR IEEE, P5510, DOI 10.1109/CVPR.2019.00566; Yang GR, 2019, PROC CVPR IEEE, P899, DOI 10.1109/CVPR.2019.00099; Yang GR, 2018, LECT NOTES COMPUT SC, V11211, P660, DOI 10.1007/978-3-030-01234-2_39; Yang Jimei, 2015, NIPS; Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3_47; Yao Y, 2019, PROC CVPR IEEE, P5520, DOI 10.1109/CVPR.2019.00567; Ye X, 2017, IEEE ACCESS, V5, p18 745; Yin ZC, 2019, PROC CVPR IEEE, P6037, DOI 10.1109/CVPR.2019.00620; Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255; Yu JJ, 2016, LECT NOTES COMPUT SC, V9915, P3, DOI 10.1007/978-3-319-49409-8_1; Yu LD, 2018, AAAI CONF ARTIF INTE, P7517; Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064; Zbontar J, 2016, J MACH LEARN RES, V17; Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767; Zhang FH, 2019, PROC CVPR IEEE, P185, DOI 10.1109/CVPR.2019.00027; Zhang Yinda, 2018, ECCV, P784; Zhang ZY, 2018, PATTERN RECOGN, V83, P430, DOI 10.1016/j.patcog.2018.05.016; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhao SS, 2019, PROC CVPR IEEE, P9780, DOI 10.1109/CVPR.2019.01002; Zheng CX, 2018, LECT NOTES COMPUT SC, V11211, P798, DOI 10.1007/978-3-030-01234-2_47; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179; Zhong YR, 2018, LECT NOTES COMPUT SC, V11206, P104, DOI 10.1007/978-3-030-01216-8_7; Zhong Yiran, 2017, ARXIV170900930; Zhou C, 2017, IEEE I CONF COMP VIS, P1576, DOI 10.1109/ICCV.2017.174; Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700; Zhou TH, 2016, PROC CVPR IEEE, P117, DOI 10.1109/CVPR.2016.20; Zhou TH, 2016, LECT NOTES COMPUT SC, V9908, P286, DOI 10.1007/978-3-319-46493-0_18; Zhou XY, 2017, IEEE I CONF COMP VIS, P398, DOI 10.1109/ICCV.2017.51	151	34	35	96	158	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					1738	1764		10.1109/TPAMI.2020.3032602	http://dx.doi.org/10.1109/TPAMI.2020.3032602			27	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33079659	Green Submitted			2022-12-18	WOS:000764815300009
J	Tang, C; Liu, XW; Zheng, X; Li, WQ; Xiong, J; Wang, LZ; Zomaya, A; Longo, A				Tang, Chang; Liu, Xinwang; Zheng, Xiao; Li, Wanqing; Xiong, Jian; Wang, Lizhe; Zomaya, Albert; Longo, Antonella			DeFusionNET: Defocus Blur Detection via Recurrently Fusing and Refining Discriminative Multi-Scale Deep Features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Neural networks; Semantics; Image edge detection; Fuses; Task analysis; Machine learning; Defocus blur detection; multi-scale features; feature fusing; channel attention	MAP ESTIMATION; SINGLE-IMAGE; NETWORK	Albeit great success has been achieved in image defocus blur detection, there are still several unsolved challenges, e.g., interference of background clutter, scale sensitivity and missing boundary details of blur regions. To deal with these issues, we propose a deep neural network which recurrently fuses and refines multi-scale deep features (DeFusionNet) for defocus blur detection. We first fuse the features from different layers of FCN as shallow features and semantic features, respectively. Then, the fused shallow features are propagated to deep layers for refining the details of detected defocus blur regions, and the fused semantic features are propagated to shallow layers to assist in better locating blur regions. The fusion and refinement are carried out recurrently. In order to narrow the gap between low-level and high-level features, we embed a feature adaptation module before feature propagating to exploit the complementary information as well as reduce the contradictory response of different feature layers. Since different feature channels are with different extents of discrimination for detecting blur regions, we design a channel attention module to select discriminative features for feature refinement. Finally, the output of each layer at last recurrent step are fused to obtain the final result. We collect a new dataset consists of various challenging images and their pixel-wise annotations for promoting further study. Extensive experiments on two commonly used datasets and our newly collected one are conducted to demonstrate both the efficacy and efficiency of DeFusionNet.	[Tang, Chang; Wang, Lizhe] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China; [Liu, Xinwang; Zheng, Xiao] Natl Univ Def Technol, Sch Comp Sci, Changsha 410073, Peoples R China; [Zheng, Xiao] Peng Cheng Lab, Shenzhen 518066, Peoples R China; [Li, Wanqing] Univ Wollongong, Sch Comp & Informat Technol, Keiraville, NSW 2500, Australia; [Xiong, Jian] Southwestern Univ Finance & Econ, Sch Business Adm, Chengdu 611130, Sichuan, Peoples R China; [Zomaya, Albert] Univ Sydney, Sch Informat Technol, Camperdown, NSW 2006, Australia; [Longo, Antonella] Univ Salento, Dept Innovat Engn, I-73100 Lecce, Italy	China University of Geosciences; National University of Defense Technology - China; Peng Cheng Laboratory; University of Wollongong; Southwestern University of Finance & Economics - China; University of Sydney; University of Salento	Liu, XW; Zheng, X (corresponding author), Natl Univ Def Technol, Sch Comp Sci, Changsha 410073, Peoples R China.	tangchang@cug.edu.cn; xinwangliu@nudt.edu.cn; endozheng@gmail.com; wanqing@uow.edu.au; xiongjian2017@swufe.edu.cn; Lizhe.Wang@gmail.com; albert.zomaya@sydney.edu.au; antonella.longo@unisalento.it	Zomaya, Albert Y./G-9697-2017; Tang, Chang/AAU-8995-2020; Longo, Antonella/A-5335-2009; Wang, Lizhe/L-7453-2014	Zomaya, Albert Y./0000-0002-3090-1059; Tang, Chang/0000-0002-6515-7696; Longo, Antonella/0000-0002-6902-0160; Wang, Lizhe/0000-0003-2766-0845; LIU, Xinwang/0000-0001-9066-1475; Li, Wanqing/0000-0002-4427-2687	National Natural Science Foundation of China [61701451, 61773392, 61901205, U1711266, 41925007]; Opening Fund of Key Laboratory of Geological Survey and Evaluation of Ministry of Education [GLAB2020ZR18]; Fundamental Research Funds for the Central Universities	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Opening Fund of Key Laboratory of Geological Survey and Evaluation of Ministry of Education; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	The authors would like to thank the anonymous reviewers for their constructive comments for improving this paper and also like to thank NVIDIA Corporation for the donation of a Titan Xp GPU card and a Titan V GPU card used for this research.. This work was supported by the National Natural Science Foundation of China (No. 61701451, 61773392, 61901205, U1711266, and 41925007) and the Opening Fund of Key Laboratory of Geological Survey and Evaluation of Ministry of Education (No. GLAB2020ZR18) and the Fundamental Research Funds for the Central Universities.	Bac S, 2007, COMPUT GRAPH FORUM, V26, P571, DOI 10.1111/j.1467-8659.2007.01080.x; Couzinie-Devy F, 2013, PROC CVPR IEEE, P1075, DOI 10.1109/CVPR.2013.143; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301; Golestaneh SA, 2017, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2017.71; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Hu XW, 2018, AAAI CONF ARTIF INTE, P6943; Huang R, 2018, NEUROCOMPUTING, V285, P154, DOI 10.1016/j.neucom.2018.01.041; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jin KH, 2017, IEEE T IMAGE PROCESS, V26, P4509, DOI 10.1109/TIP.2017.2713099; Kang K, 2016, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2016.95; Kim B, 2018, COMPUT GRAPH FORUM, V37, P277, DOI 10.1111/cgf.13567; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lee J, 2019, PROC CVPR IEEE, P12214, DOI 10.1109/CVPR.2019.01250; Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007; Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826; Liu RT, 2008, PROC CVPR IEEE, P954; Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P5155, DOI 10.1109/TIP.2018.2847421; Masia B., 2011, P S IB COMP GRAF, V5; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Pang YW, 2016, IEEE T CYBERNETICS, V46, P2220, DOI 10.1109/TCYB.2015.2472478; Park J, 2017, PROC CVPR IEEE, P2760, DOI 10.1109/CVPR.2017.295; Purohit K, 2018, IEEE IMAGE PROC, P2202, DOI 10.1109/ICIP.2018.8451765; Qi YK, 2019, IEEE T PATTERN ANAL, V41, P1116, DOI 10.1109/TPAMI.2018.2828817; Saad E, 2016, IEEE T IMAGE PROCESS, V25, P3141, DOI 10.1109/TIP.2016.2555702; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shi JP, 2015, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2015.7298665; Shi JP, 2014, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2014.379; Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Su B., 2011, P 19 ACM INT C MULT, P1397; Sun C, 2018, PROC CVPR IEEE, P8962, DOI 10.1109/CVPR.2018.00934; Tai YW, 2009, IEEE IMAGE PROC, P1797, DOI 10.1109/ICIP.2009.5414620; Tang C., 2019, PROC IEEECVF C COMPU, P2700; Tang C, 2020, AAAI CONF ARTIF INTE, V34, P12063; Tang C, 2021, IEEE T MULTIMEDIA, V23, P624, DOI 10.1109/TMM.2020.2985541; Tang C, 2017, IEEE SIGNAL PROC LET, V24, P490, DOI 10.1109/LSP.2016.2620162; Tang C, 2017, DIGIT SIGNAL PROCESS, V63, P10, DOI 10.1016/j.dsp.2016.10.009; Tang C, 2016, IEEE SIGNAL PROC LET, V23, P1652, DOI 10.1109/LSP.2016.2611608; Tang C, 2013, OPT LETT, V38, P1706, DOI 10.1364/OL.38.001706; Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974; Wang X, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P467, DOI 10.1109/CISP.2008.371; Wei Zhang, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1947, DOI 10.1109/ICCVW.2009.5457520; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Xu GD, 2017, IEEE I CONF COMP VIS, P5381, DOI 10.1109/ICCV.2017.574; Yan RM, 2016, IEEE T IMAGE PROCESS, V25, P1910, DOI 10.1109/TIP.2016.2535273; Yi X, 2016, IEEE T IMAGE PROCESS, V25, P1626, DOI 10.1109/TIP.2016.2528042; Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199; Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206; Zhang SH, 2018, PROC CVPR IEEE, P6586, DOI 10.1109/CVPR.2018.00689; Zhang W, 2012, IEEE T IMAGE PROCESS, V21, P873, DOI 10.1109/TIP.2011.2162739; Zhang Y, 2013, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2013.145; Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI [10.1007/978-3-030-01234-2_18, 10.1007/978-3-030-01240-3_22]; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhao WD, 2019, PROC CVPR IEEE, P8897, DOI 10.1109/CVPR.2019.00911; Zhao WD, 2020, IEEE T IMAGE PROCESS, V29, P1356, DOI 10.1109/TIP.2019.2942505; Zhao WD, 2020, IEEE T PATTERN ANAL, V42, P1884, DOI 10.1109/TPAMI.2019.2906588; Zhao WD, 2018, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2018.00325; Zhu X, 2013, IEEE T IMAGE PROCESS, V22, P4879, DOI 10.1109/TIP.2013.2279316; Zhuo SJ, 2011, PATTERN RECOGN, V44, P1852, DOI 10.1016/j.patcog.2011.03.009	61	34	34	22	50	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					955	968		10.1109/TPAMI.2020.3014629	http://dx.doi.org/10.1109/TPAMI.2020.3014629			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS	32759080				2022-12-18	WOS:000740006100030
J	Luvizon, DC; Picard, D; Tabia, H				Luvizon, Diogo C.; Picard, David; Tabia, Hedi			Multi-Task Deep Learning for Real-Time 3D Human Pose Estimation and Action Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pose estimation; Three-dimensional displays; Two dimensional displays; Task analysis; Heating systems; Visualization; Skeleton; Human action recognition; human pose estimation; multitask deep learning; neural networks		Human pose estimation and action recognition are related tasks since both problems are strongly dependent on the human body representation and analysis. Nonetheless, most recent methods in the literature handle the two problems separately. In this article, we propose a multi-task framework for jointly estimating 2D or 3D human poses from monocular color images and classifying human actions from video sequences. We show that a single architecture can be used to solve both problems in an efficient way and still achieves state-of-the-art or comparable results at each task while running with a throughput of more than 100 frames per second. The proposed method benefits from high parameters sharing between the two tasks by unifying still images and video clips processing in a single pipeline, allowing the model to be trained with data from different categories simultaneously and in a seamlessly way. Additionally, we provide important insights for end-to-end training the proposed multi-task model by decoupling key prediction parts, which consistently leads to better accuracy on both tasks. The reported results on four datasets (MPII, Human3.6M, Penn Action and NTU RGB+D) demonstrate the effectiveness of our method on the targeted tasks. Our source code and trained weights are publicly available at https://github.com/dluvizon/deephar.	[Luvizon, Diogo C.] SAMSUNG Res Inst, BR-13097104 Campinas, SP, Brazil; [Picard, David] Univ Gustave Eiffel, CNRS, Ecole Ponts, LIGM,IMAGINE, F-77455 Marne La Vallee, France; [Tabia, Hedi] Univ Paris Saclay, Univ Evry, IBISC, F-91025 Evry, France	Centre National de la Recherche Scientifique (CNRS); Ecole des Ponts ParisTech; Universite Gustave-Eiffel; ESIEE Paris; UDICE-French Research Universities; Universite Paris Saclay	Luvizon, DC (corresponding author), SAMSUNG Res Inst, BR-13097104 Campinas, SP, Brazil.	diogo.luvizon@ensea.fr; david.picard@enpc.fr; hedi.tabia@univ-evry.fr	Picard, David/AAV-8841-2021	Picard, David/0000-0002-6296-4222	Brazilian National Council for Scientific and Technological Development (CNPq) [233342/2014-1]	Brazilian National Council for Scientific and Technological Development (CNPq)(Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ))	This work was partially supported by the Brazilian National Council for Scientific and Technological Development (CNPq) -Grant 233342/2014-1.	Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471; Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754; Baradel F., 2017, ABS170310106 CORR; Baradel F, 2018, PROC CVPR IEEE, P469, DOI 10.1109/CVPR.2018.00056; Belagiannis V, 2015, IEEE I CONF COMP VIS, P2830, DOI 10.1109/ICCV.2015.324; Bulat A, 2016, LECT NOTES COMPUT SC, V9911, P717, DOI 10.1007/978-3-319-46478-7_44; Cao CQ, 2018, IEEE T CYBERNETICS, V48, P1095, DOI 10.1109/TCYB.2017.2756840; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512; Chen CH, 2017, PROC CVPR IEEE, P5759, DOI 10.1109/CVPR.2017.610; Chen Y, 2017, IEEE I CONF COMP VIS, P1221, DOI 10.1109/ICCV.2017.137; Cheron G, 2015, IEEE I CONF COMP VIS, P3218, DOI 10.1109/ICCV.2015.368; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Chou CJ, 2018, ASIAPAC SIGN INFO PR, P17, DOI 10.23919/APSIPA.2018.8659538; Choutas V, 2018, PROC CVPR IEEE, P7024, DOI 10.1109/CVPR.2018.00734; Chu X, 2017, PROC CVPR IEEE, P5669, DOI 10.1109/CVPR.2017.601; Dantone M, 2013, PROC CVPR IEEE, P3041, DOI 10.1109/CVPR.2013.391; Du WB, 2017, IEEE I CONF COMP VIS, P3745, DOI 10.1109/ICCV.2017.402; Gkioxari G, 2016, LECT NOTES COMPUT SC, V9908, P728, DOI 10.1007/978-3-319-46493-0_44; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010; Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3; Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248; Iqbal U, 2018, LECT NOTES COMPUT SC, V11215, P125, DOI 10.1007/978-3-030-01252-6_8; Iqbal U, 2017, IEEE INT CONF AUTOMA, P438, DOI 10.1109/FG.2017.61; Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396; Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486; Kokkinos I, 2017, PROC CVPR IEEE, P5454, DOI 10.1109/CVPR.2017.579; Lifshitz I, 2016, LECT NOTES COMPUT SC, V9906, P246, DOI 10.1007/978-3-319-46475-6_16; Liu J, 2017, PROC CVPR IEEE, P3671, DOI 10.1109/CVPR.2017.391; Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50; Liu MY, 2018, PROC CVPR IEEE, P1159, DOI 10.1109/CVPR.2018.00127; Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019; Luvizon Diogo C., 2019, Computers & Graphics, V85, P15, DOI 10.1016/j.cag.2019.09.002; Luvizon DC, 2018, PROC CVPR IEEE, P5137, DOI 10.1109/CVPR.2018.00539; Luvizon DC, 2017, PATTERN RECOGN LETT, V99, P13, DOI 10.1016/j.patrec.2017.02.001; Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288; Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Nie BX, 2015, PROC CVPR IEEE, P1293, DOI 10.1109/CVPR.2015.7298734; Ning GH, 2018, IEEE T MULTIMEDIA, V20, P1246, DOI 10.1109/TMM.2017.2762010; Pavlakos G, 2017, PROC CVPR IEEE, P1263, DOI 10.1109/CVPR.2017.139; Pfister T, 2015, LECT NOTES COMPUT SC, V9003, P538, DOI 10.1007/978-3-319-16865-4_35; Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533; Pishchulin L, 2013, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2013.82; Popa AI, 2017, PROC CVPR IEEE, P4714, DOI 10.1109/CVPR.2017.501; Rafi U., 2016, P C BRIT MACH VIS C, V1; Sarafianos N, 2016, COMPUT VIS IMAGE UND, V152, P1, DOI 10.1016/j.cviu.2016.09.002; Shahroudy A, 2018, IEEE T PATTERN ANAL, V40, P1045, DOI 10.1109/TPAMI.2017.2691321; Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115; Song SJ, 2017, AAAI CONF ARTIF INTE, P4263; Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584; Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33; Sun X, 2017, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2017.284; Tekin B., 2016, ABS161105708 CORR; Tome D, 2017, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR.2017.603; Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; Varol Gul, 2018, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2712608; Wang DG, 2018, LECT NOTES COMPUT SC, V11213, P457, DOI 10.1007/978-3-030-01240-3_28; Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511; Yang W, 2018, PROC CVPR IEEE, P5255, DOI 10.1109/CVPR.2018.00551; Yang W, 2017, IEEE I CONF COMP VIS, P1290, DOI 10.1109/ICCV.2017.144; Yao A, 2012, INT J COMPUT VISION, V100, P16, DOI 10.1007/s11263-012-0532-9; Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4_28; Zhang WY, 2013, IEEE I CONF COMP VIS, P2248, DOI 10.1109/ICCV.2013.280; Zhou XW, 2019, IEEE T PATTERN ANAL, V41, P901, DOI 10.1109/TPAMI.2018.2816031; Zolfaghari M, 2017, IEEE I CONF COMP VIS, P2923, DOI 10.1109/ICCV.2017.316; Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x	70	34	35	11	53	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG 1	2021	43	8					2752	2764		10.1109/TPAMI.2020.2976014	http://dx.doi.org/10.1109/TPAMI.2020.2976014			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TF2YV	32091993	Green Submitted			2022-12-18	WOS:000670578800017
J	Yang, QZ; Wu, AC; Zheng, WS				Yang, Qize; Wu, Ancong; Zheng, Wei-Shi			Person Re-Identification by Contour Sketch Under Moderate Clothing Change	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clothing; Cameras; Feature extraction; Image color analysis; Shape; Reliability; Visualization; Person re-identification; clothing change	RECOGNITION; NETWORK	Person re-identification (re-id), the process of matching pedestrian images across different camera views, is an important task in visual surveillance. Substantial development of re-id has recently been observed, and the majority of existing models are largely dependent on color appearance and assume that pedestrians do not change their clothes across camera views. This limitation, however, can be an issue for re-id when tracking a person at different places and at different time if that person (e.g., a criminal suspect) changes his/her clothes, causing most existing methods to fail, since they are heavily relying on color appearance, and thus, they are inclined to match a person to another person wearing similar clothes. In this work, we call the person re-id under clothing change the "cross-clothes person re-id." In particular, we consider the case when a person only changes his clothes moderately as a first attempt at solving this problem based on visible light images; that is, we assume that a person wears clothes of a similar thickness, and thus the shape of a person would not change significantly when the weather does not change substantially within a short period of time. We perform cross-clothes person re-id based on a contour sketch of person image to take advantage of the shape of the human body instead of color information for extracting features that are robust to moderate clothing change. To select/sample more reliable and discriminative curve patterns on a body contour sketch, we introduce a learning-based spatial polar transformation (SPT) layer in the deep neural network to transform contour sketch images for extracting reliable and discriminant convolutional neural network (CNN) features in a polar coordinate space. An angle-specific extractor (ASE) is applied in the following layers to extract more fine-grained discriminant angle-specific features. By varying the sampling range of the SPT, we develop a multistream network for aggregating multi-granularity features to better identify a person. Due to the lack of a large-scale dataset for cross-clothes person re-id, we contribute a new dataset that consists of 33,698 images from 221 identities. Our experiments illustrate the challenges of cross-clothes person re-id and demonstrate the effectiveness of our proposed method.	[Yang, Qize; Wu, Ancong] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510275, Peoples R China; [Wu, Ancong] Minist Educ, Guangdong Prov Key Lab Machine Intelligence & Adv, Guangzhou 510275, Peoples R China; [Zheng, Wei-Shi] Sun Yat Sen Univ, Sch Data & Comp Sci, Key Lab Machine Intelligence & Adv Comp, Minist Educ, Guangzhou 510275, Peoples R China; [Zheng, Wei-Shi] Peng Cheng Lab, Shenzhen 518005, Peoples R China	Sun Yat Sen University; Sun Yat Sen University; Peng Cheng Laboratory	Zheng, WS (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Key Lab Machine Intelligence & Adv Comp, Minist Educ, Guangzhou 510275, Peoples R China.	yangqz@mail2.sysu.edu.cn; wuancong@mail2.sysu.edu.cn; wszheng@ieee.org		Wu, Ancong/0000-0002-7969-3190	National Key Research and Development Program of China [2016YF B1001002]; NSFC [U1811461]; Guangdong Province Science and Technology Innovation Leading Talents [2016TX 03X157]; Guangdong NSF Project [2018B030312002]; Guangzhou Research Project [201902010037]	National Key Research and Development Program of China; NSFC(National Natural Science Foundation of China (NSFC)); Guangdong Province Science and Technology Innovation Leading Talents; Guangdong NSF Project; Guangzhou Research Project	This work was supported partially by the National Key Research and Development Program of China (2016YF B1001002), NSFC (U1811461), Guangdong Province Science and Technology Innovation Leading Talents (2016TX 03X157), Guangdong NSF Project (No. 2018B030312002) and Guangzhou Research Project (201902010037). The principal investigator for this project is Wei-Shi Zheng.	Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016; Amos Brandon, 2016, CMUCS16118; BBC, 2012, BBC; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257; Carlos E., 2018, P INT C LEARN REPR; Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142; Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709; Chen P, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P620; Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304; Chen YC, 2018, IEEE T PATTERN ANAL, V40, P392, DOI 10.1109/TPAMI.2017.2666805; Cheng Z., 2018, ARXIV PREPRINT ARXIV; China.org.cn, 2012, SER KILL ZHOU KEH DE; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Gray D., 2007, IEEE INT WORKSH PERF, V3, P1; Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21; Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38; Haque A, 2016, PROC CVPR IEEE, P1229, DOI 10.1109/CVPR.2016.138; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56; Huang G.B., 2008, WORKSH FAC REAL LIF; Jaderberg M, 2015, ADV NEUR IN, V28; Karianakis N, 2018, LECT NOTES COMPUT SC, V11209, P737, DOI 10.1007/978-3-030-01228-1_44; Kostinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kviatkovsky I, 2013, IEEE T PATTERN ANAL, V35, P1622, DOI 10.1109/TPAMI.2012.246; Li W., 2013, LNCS, V7724, P31, DOI [10.1007/978-3-642-37331-2, DOI 10.1007/978-3-642-37331-2]; Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243; Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27; Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463; Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832; Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46; Lorenzo-Navarro J., 2012, P INT WORKSH AMB ASS, P200; Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41; Makihara Y, 2017, PROC CVPR IEEE, P6786, DOI 10.1109/CVPR.2017.718; Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987; Munaro M, 2014, ADV COMPUT VIS PATT, P161, DOI 10.1007/978-1-4471-6296-4_8; Muramatsu D, 2015, IEEE T IMAGE PROCESS, V24, P140, DOI 10.1109/TIP.2014.2371335; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Pang L, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P609, DOI 10.1145/3240508.3240606; Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129; Song JF, 2017, IEEE I CONF COMP VIS, P5552, DOI 10.1109/ICCV.2017.592; Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25; Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30; Sutskever I., 2013, P 30 INT C MACH LEAR, P1139, DOI DOI 10.1007/S00287-015-0911-Z; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144; Wang TQ, 2016, IEEE T PATTERN ANAL, V38, P2501, DOI 10.1109/TPAMI.2016.2522418; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Wikipedia, 2019, ZHOU KEH; Wolberg G, 2000, IEEE IMAGE PROC, P493, DOI 10.1109/ICIP.2000.901003; Wu AC, 2020, INT J COMPUT VISION, V128, P1765, DOI 10.1007/s11263-019-01290-1; Wu AC, 2017, IEEE I CONF COMP VIS, P5390, DOI 10.1109/ICCV.2017.575; Wu AC, 2017, IEEE T IMAGE PROCESS, V26, P2588, DOI 10.1109/TIP.2017.2675201; Wu Zifeng, 2017, IEEE T PATTERN ANAL, V39, P209; Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Xie XH, 2010, PATTERN RECOGN, V43, P4177, DOI 10.1016/j.patcog.2010.06.019; Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226; Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507; Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35; Yaser S., OPENPOSE; Yin J, 2020, INT J COMPUT VISION, V128, P1654, DOI 10.1007/s11263-019-01259-0; Yu HX, 2020, IEEE T PATTERN ANAL, V42, P956, DOI 10.1109/TPAMI.2018.2886878; Yu Q, 2016, PROC CVPR IEEE, P799, DOI 10.1109/CVPR.2016.93; Yuan K, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1121; Zhang H, 2016, PROC CVPR IEEE, P1105, DOI 10.1109/CVPR.2016.125; Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139; Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103; Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133; Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531; Zheng WS, 2016, IEEE T PATTERN ANAL, V38, P591, DOI 10.1109/TPAMI.2015.2453984; Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138; Zheng Wei-Shi, 2009, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.23.23; Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405; Zokai S, 2005, IEEE T IMAGE PROCESS, V14, P1422, DOI 10.1109/TIP.2005.854501	79	34	37	11	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2021	43	6					2029	2046		10.1109/TPAMI.2019.2960509	http://dx.doi.org/10.1109/TPAMI.2019.2960509			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SA8YQ	31869783	Green Submitted			2022-12-18	WOS:000649590200015
J	Sun, YF; Zheng, L; Li, YL; Yang, Y; Tian, Q; Wang, SJ				Sun, Yifan; Zheng, Liang; Li, Yali; Yang, Yi; Tian, Qi; Wang, Shengjin			Learning Part-based Convolutional Features for Person Re-Identification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pose estimation; Training; Feature extraction; Deep learning; Semantics; Sun; Labeling; Person re-identification; part-based convolutional baseline; part refinement	NETWORK	Part-level features offer fine granularity for pedestrian image description. In this article, we generally aim to learn discriminative part-informed feature for person re-identification. Our contribution is two-fold. First, we introduce a general part-level feature learning method, named Part-based Convolutional Baseline (PCB). Given an image input, it outputs a convolutional descriptor consisting of several part-level features. PCB is general in that it is able to accommodate several part partitioning strategies, including pose estimation, human parsing and uniform part partitioning. In experiment, we show that the learned descriptor has a significantly higher discriminative ability than the global descriptor. Second, based on PCB, we propose refined part pooling (RPP), which allows the parts to be more precisely located. Our idea is that pixels within a well-located part should be similar to each other while being dissimilar with pixels from other parts. We call it within-part consistency. When a pixel-wise feature vector in a part is more similar to some other part, it is then an outlier, indicating inappropriate partitioning. RPP re-assigns these outliers to the parts they are closest to, resulting in refined parts with enhanced within-part consistency. RPP requires no part labels and is trained in a weakly supervised manner. Experiment confirms that RPP allows PCB to gain another round of performance boost. For instance, on the Market-1501 dataset, we achieve (77.4+4.2) percent mAP and (92.3+1.5) percent rank-1 accuracy, a competitive performance with the state of the art.	[Sun, Yifan; Li, Yali; Wang, Shengjin] Tsinghua Univ, Beijing 100084, Peoples R China; [Zheng, Liang] Australian Natl Univ, Canberra, ACT 0200, Australia; [Yang, Yi] Univ Technol Sydney, Ultimo, NSW 2007, Australia; [Tian, Qi] Univ Texas San Antonio, San Antonio, TX 78249 USA	Tsinghua University; Australian National University; University of Technology Sydney; University of Texas System; University of Texas at San Antonio (UTSA)	Sun, YF (corresponding author), Tsinghua Univ, Beijing 100084, Peoples R China.	sunyf15@mail.tsinghua.org.cn; liangzheng06@gmail.com; liyali13@tsinghua.edu.cn; yee.i.yang@gmail.com; Qi.Tian@utsa.edu; wgsgj@tsinghua.edu.cn	yang, yang/GWB-9426-2022; yang, yang/HGT-7999-2022; Yang, Yi/B-9273-2017; yang, yang/GVT-5210-2022	Yang, Yi/0000-0002-0512-880X; 	National Natural Science Foundation of China [61771288]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the National Natural Science Foundation of China under Grant No. 61771288.	Barbosa I. B., 2017, ARXIV170103153; Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304; Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68; Dai JF, 2016, ADV NEUR IN, V29; Das A, 2014, LECT NOTES COMPUT SC, V8690, P330, DOI 10.1007/978-3-319-10605-2_22; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110; Diba A, 2016, PROC CVPR IEEE, P3557, DOI 10.1109/CVPR.2016.387; Felzenszwalb P, 2008, PROC CVPR IEEE, P1984; Geng M., 2016, ARXIV161105244; Gheissari N., 2006, P IEEE C COMP VIS PA, V2, P1528, DOI DOI 10.1109/CVPR.2006.223; Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715; Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hermans Alexander, 2017, ARXIV, P1; Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3; Jose C, 2016, LECT NOTES COMPUT SC, V9909, P875, DOI 10.1007/978-3-319-46454-1_53; Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117; Karanam S., 2016, ARXIV160509653; Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782; Li SM, 2016, INT C PATT RECOG, P3856, DOI 10.1109/ICPR.2016.7900236; Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046; Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243; Li W, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2194; Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27; Li Y, 2017, INT J COMPUT VISION, V121, P344, DOI 10.1007/s11263-016-0945-y; Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Ma AJ, 2013, IEEE I CONF COMP VIS, P3567, DOI 10.1109/ICCV.2013.443; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Prosser B. J., 2010, PROC BRIT MACH VIS C, P6, DOI DOI 10.5244/C.24.21; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2; Sohn K, 2016, ADV NEUR IN, V29; Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427; Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30; Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Tuytelaars T., 2016, P EUR C COMP VIS; Ustinova E., 2015, ARXIV151205300; Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016; Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279; Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511; Wu L, 2019, IEEE T MULTIMEDIA, V21, P1412, DOI 10.1109/TMM.2018.2877886; Wu Y, 2019, IEEE T IMAGE PROCESS, V28, P2872, DOI 10.1109/TIP.2019.2891895; Wu Z., 2018, ABS181107487 CORR; Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140; Xu K, 2015, PR MACH LEARN RES, V37, P2048; [张宇栋 Zhang Yudong], 2017, [中国安全科学学报, China Safety Science Journal（CSSJ）], V27, P25; Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349; Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26; Zheng L., 2017, MAGENT MANY AGENT RE; Zheng L., 2016, ARXIV; Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133; Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138; Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599; Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405; Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389; Zhu FQ, 2017, IEEE T IMAGE PROCESS, V26, P4806, DOI 10.1109/TIP.2017.2695101	66	34	34	11	47	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					902	917		10.1109/TPAMI.2019.2938523	http://dx.doi.org/10.1109/TPAMI.2019.2938523			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE6IS	31502963				2022-12-18	WOS:000616309900011
J	Liang, ZF; Guo, YL; Feng, YL; Chen, W; Qiao, LB; Zhou, L; Zhang, JF; Liu, HZ				Liang, Zhengfa; Guo, Yulan; Feng, Yiliu; Chen, Wei; Qiao, Linbo; Zhou, Li; Zhang, Jianfeng; Liu, Hengzhu			Stereo Matching Using Multi-Level Cost volume and Multi-Scale Feature Constancy	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo matching; disparity estimation; depth estimation; cost volume; feature constancy		For CNNs based stereo matching methods, cost volumes play an important role in achieving good matching accuracy. In this paper, we present an end-to-end trainable convolution neural network to fully use cost volumes for stereo matching. Our network consists of three sub-modules, i.e., shared feature extraction, initial disparity estimation, and disparity refinement. Cost volumes are calculated at multiple levels using the shared features, and are used in both initial disparity estimation and disparity refinement sub-modules. To improve the efficiency of disparity refinement, multi-scale feature constancy is introduced to measure the correctness of the initial disparity in feature space. These sub-modules of our network are tightly-coupled, making it compact and easy to train. Moreover, we investigate the problem of developing a robust model to perform well across multiple datasets with different characteristics. We achieve this by introducing a two-stage finetuning scheme to gently transfer the model to target datasets. Specifically, in the first stage, the model is finetuned using both a large synthetic dataset and the target datasets with a relatively large learning rate, while in the second stage the model is trained using only the target datasets with a small learning rate. The proposed method is tested on several benchmarks including the Middlebury 2014, KITTI 2015, ETH3D 2017, and SceneFlow datasets. Experimental results show that our method achieves the state-of-the-art performance on all the datasets. The proposed method also won the 1st prize on the Stereo task of Robust Vision Challenge 2018.	[Liang, Zhengfa] Natl Key Lab Sci & Technol Blind Signal Proc, Chengdu 610041, Sichuan, Peoples R China; [Guo, Yulan] Sun Yat Sen Univ, Sch Elect & Commun Engn, Guangzhou 510275, Guangdong, Peoples R China; [Guo, Yulan] Natl Univ Def Technol NUDT, Coll Elect Sci & Technol, Changsha 410073, Hunan, Peoples R China; [Feng, Yiliu; Chen, Wei; Qiao, Linbo; Zhou, Li; Zhang, Jianfeng; Liu, Hengzhu] Natl Univ Def Technol, Coll Comp, Changsha 410073, Hunan, Peoples R China	Sun Yat Sen University; National University of Defense Technology - China; National University of Defense Technology - China	Guo, YL (corresponding author), Sun Yat Sen Univ, Sch Elect & Commun Engn, Guangzhou 510275, Guangdong, Peoples R China.	liangzhengfa10@nudt.edu.cn; yulan.guo@nudt.edu.cn; fengyiliu11@nudt.edu.cn; chenwei@nudt.edu.cn; qiao.linbo@nudt.edu.cn; zhouli06@nudt.edu.cn; jianfengzhang@nudt.edu.cn; hengzhuliu@nudt.edu.cn	Guo, Yulan/E-7102-2014	Guo, Yulan/0000-0001-7051-841X	National Natural Science Foundation of China [61602499, 61471371]; National Postdoctoral Program for Innovative Talents [BX201600172]; China Postdoctoral Science Foundation [2017M610114]; Fundamental Research Funds for the Central Universities [18lgzd06]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Postdoctoral Program for Innovative Talents; China Postdoctoral Science Foundation(China Postdoctoral Science Foundation); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	This work was partially supported by the National Natural Science Foundation of China (Nos. 61602499 and 61471371), the National Postdoctoral Program for Innovative Talents (No. BX201600172), China Postdoctoral Science Foundation (No. 2017M610114), and Fundamental Research Funds for the Central Universities (No. 18lgzd06). Zhengfa Liang and Yulan Guo contributed equally to this work and are co-first authors.	Adelson E.H., 1984, RCA ENG, V29, P33; Batsos K, 2018, PROC CVPR IEEE, P2060, DOI 10.1109/CVPR.2018.00220; Batsos K, 2018, INT CONF 3D VISION, P238, DOI 10.1109/3DV.2018.00036; Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14; Bolles R., 1993, P 6 INT S ROB RES PI, P165; Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512; Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Cipolla R, 2014, INT J COMPUT VISION, V110, P241, DOI 10.1007/s11263-014-0772-y; Collins RT, 1996, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.1996.517097; Elad M, 2002, IEEE T IMAGE PROCESS, V11, P1141, DOI 10.1109/TIP.2002.801126; GALLAGHER NC, 1981, IEEE T ACOUST SPEECH, V29, P1136, DOI 10.1109/TASSP.1981.1163708; Geiger A, 2011, LECT NOTES COMPUT SC, V6492, P25, DOI 10.1007/978-3-642-19315-6_3; Gidaris S, 2017, PROC CVPR IEEE, P7187, DOI 10.1109/CVPR.2017.760; Guney F, 2015, PROC CVPR IEEE, P4165, DOI 10.1109/CVPR.2015.7299044; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; Ilg E, 2018, LECT NOTES COMPUT SC, V11216, P626, DOI 10.1007/978-3-030-01258-8_38; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jie ZQ, 2018, PROC CVPR IEEE, P3838, DOI 10.1109/CVPR.2018.00404; Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17; Khamis S., 2018, EUR C COMP VIS ECCV, P8; Kingma D.P, P 3 INT C LEARNING R; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Li LC, 2018, IEEE T CIRC SYST VID, V28, P679, DOI 10.1109/TCSVT.2016.2628782; Li LC, 2017, APPL OPTICS, V56, P3411, DOI 10.1364/AO.56.003411; Liang ZF, 2018, PROC CVPR IEEE, P2811, DOI 10.1109/CVPR.2018.00297; Liu C, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON SMART CITY AND SYSTEMS ENGINEERING (ICSCSE), P849, DOI 10.1109/ICSCSE.2018.00183; Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lu CH, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111844; LUO WJ, 2016, PROC CVPR IEEE, P5695, DOI DOI 10.1109/CVPR.2016.614; Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438; Menze Moritz, 2015, CVPR; Pang JH, 2017, IEEE INT CONF COMP V, P878, DOI 10.1109/ICCVW.2017.108; Park H, 2017, IEEE SIGNAL PROC LET, V24, P1788, DOI 10.1109/LSP.2016.2637355; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977; Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3; Schonberger JL, 2018, LECT NOTES COMPUT SC, V11217, P758, DOI 10.1007/978-3-030-01261-8_45; Schops T, 2017, PROC CVPR IEEE, P2538, DOI 10.1109/CVPR.2017.272; Seki A, 2017, PROC CVPR IEEE, P6640, DOI 10.1109/CVPR.2017.703; Shaked A, 2017, PROC CVPR IEEE, P6901, DOI 10.1109/CVPR.2017.730; Smolyanskiy N, 2018, IEEE COMPUT SOC CONF, P1120, DOI 10.1109/CVPRW.2018.00147; Song X, 2019, LECT NOTES COMPUT SC, V11365, P20, DOI 10.1007/978-3-030-20873-8_2; Taniai T, 2018, IEEE T PATTERN ANAL, V40, P2725, DOI 10.1109/TPAMI.2017.2766072; Tulyakov S, 2018, ADV NEUR IN, V31; Yamaguchi K, 2014, LECT NOTES COMPUT SC, V8693, P756, DOI 10.1007/978-3-319-10602-1_49; Yan TM, 2019, IEEE T IMAGE PROCESS, V28, P3885, DOI 10.1109/TIP.2019.2903318; Yang GR, 2018, LECT NOTES COMPUT SC, V11211, P660, DOI 10.1007/978-3-030-01234-2_39; Ye XQ, 2017, IEEE ACCESS, V5, P18745, DOI 10.1109/ACCESS.2017.2754318; Zbontar J, 2016, J MACH LEARN RES, V17; Zhang C, 2015, IEEE I CONF COMP VIS, P2057, DOI 10.1109/ICCV.2015.238; Zhang K, 2009, IEEE T CIRC SYST VID, V19, P1073, DOI 10.1109/TCSVT.2009.2020478	54	34	35	8	52	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2021	43	1					300	315		10.1109/TPAMI.2019.2928550	http://dx.doi.org/10.1109/TPAMI.2019.2928550			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PC7WN	31329107				2022-12-18	WOS:000597206900020
J	Ren, DW; Zuo, WM; Zhang, D; Zhang, L; Yang, MH				Ren, Dongwei; Zuo, Wangmeng; Zhang, David; Zhang, Lei; Yang, Ming-Hsuan			Simultaneous Fidelity and Regularization Learning for Image Restoration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image restoration; blind deconvolution; rain streak removal; task-driven learning	MINIMIZATION; ALGORITHM	Most existing non-blind restoration methods are based on the assumption that a precise degradation model is known. As the degradation process can only be partially known or inaccurately modeled, images may not be well restored. Rain streak removal and image deconvolution with inaccurate blur kernels are two representative examples of such tasks. For rain streak removal, although an input image can be decomposed into a scene layer and a rain streak layer, there exists no explicit formulation for modeling rain streaks and the composition with scene layer. For blind deconvolution, as estimation error of blur kernel is usually introduced, the subsequent non-blind deconvolution process does not restore the latent image well. In this paper, we propose a principled algorithm within the maximum a posterior framework to tackle image restoration with a partially known or inaccurate degradation model. Specifically, the residual caused by a partially known or inaccurate degradation model is spatially dependent and complexly distributed. With a training set of degraded and ground-truth image pairs, we parameterize and learn the fidelity term for a degradation model in a task-driven manner. Furthermore, the regularization term can also be learned along with the fidelity term, thereby forming a simultaneous fidelity and regularization learning model. Extensive experimental results demonstrate the effectiveness of the proposed model for image deconvolution with inaccurate blur kernels, deconvolution with multiple degradations and rain streak removal.	[Ren, Dongwei] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China; [Ren, Dongwei; Zhang, Lei] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China; [Zuo, Wangmeng] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China; [Zuo, Wangmeng] Peng Cheng Lab, Shenzhen 518055, Peoples R China; [Zhang, David] Chinese Univ Hong Kong, Sch Sci & Engn, Shenzhen 518172, Peoples R China; [Yang, Ming-Hsuan] Univ Calif Merced, Sch Engn, Merced, CA 95344 USA	Tianjin University; Hong Kong Polytechnic University; Harbin Institute of Technology; Peng Cheng Laboratory; Chinese University of Hong Kong, Shenzhen; University of California System; University of California Merced	Zuo, WM (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.	rendongweihit@gmail.com; cswmzuo@gmail.com; csdzhang@comp.polyu.edu.hk; cslzhang@comp.polyu.edu.hk; mhyang@ucmerced.edu	; Yang, Ming-Hsuan/T-9533-2019	Zuo, Wangmeng/0000-0002-3330-783X; Ren, Dongwei/0000-0002-0965-6810; Zhang, Lei/0000-0002-2078-4215; Yang, Ming-Hsuan/0000-0003-4848-2304	National Natural Scientific Foundation of China (NSFC) [61671182, 61801326]; Hong Kong RGC GRF grant [PolyU 152124/15E]; US National Science Foundation CAREER Grant [1149783]	National Natural Scientific Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Hong Kong RGC GRF grant; US National Science Foundation CAREER Grant(National Science Foundation (NSF))	This work is supported in part by National Natural Scientific Foundation of China (NSFC) under grant (61671182 and 61801326), Hong Kong RGC GRF grant (PolyU 152124/15E), and US National Science Foundation CAREER Grant No.1149783.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Bracewell R., 1986, FOURIER TRANSFORM IT; Cao XY, 2015, IEEE I CONF COMP VIS, P1493, DOI 10.1109/ICCV.2015.175; Chambolle A, 2004, J MATH IMAGING VIS, V20, P89; Chen PX, 2015, PROC CVPR IEEE, P1284, DOI 10.1109/CVPR.2015.7298733; Chen XA, 2016, PROC CVPR IEEE, P5213, DOI 10.1109/CVPR.2016.563; Chen YL, 2013, IEEE I CONF COMP VIS, P1968, DOI 10.1109/ICCV.2013.247; Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743; Chen YJ, 2015, PROC CVPR IEEE, P5261, DOI 10.1109/CVPR.2015.7299163; Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Eigen D, 2013, IEEE I CONF COMP VIS, P633, DOI 10.1109/ICCV.2013.84; Eriksson A, 2010, PROC CVPR IEEE, P771, DOI 10.1109/CVPR.2010.5540139; Fanello SR, 2014, PROC CVPR IEEE, P1709, DOI 10.1109/CVPR.2014.221; Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186; Getreuer P., 2018, P IEEE INT C COMP PH, P1; Goldstein A, 2012, LECT NOTES COMPUT SC, V7576, P622, DOI 10.1007/978-3-642-33715-4_45; Gong Z, 2014, MULTISCALE MODEL SIM, V12, P458, DOI 10.1137/130904533; Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366; Heide F., 2013, ACM T GRAPHIC, V32, P5; Hong Y, 2017, IEEE INT C BIOINFORM, P1357; Ji H, 2012, IEEE T IMAGE PROCESS, V21, P1624, DOI 10.1109/TIP.2011.2171699; Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90; Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kingma D.P, P 3 INT C LEARNING R; Krishnan D., 2009, ADV NEURAL INFORM PR, V22, P1033; Lefkimmiatis S, 2018, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR.2018.00338; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299; Luo Y, 2015, IEEE I CONF COMP VIS, P3397, DOI 10.1109/ICCV.2015.388; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Meng DY, 2013, IEEE I CONF COMP VIS, P1337, DOI 10.1109/ICCV.2013.169; Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82; Nah S., 2017, CVPR, P3; Pan JS, 2019, IEEE T PATTERN ANAL, V41, P1412, DOI 10.1109/TPAMI.2018.2832125; Pan JS, 2017, IEEE T PATTERN ANAL, V39, P342, DOI 10.1109/TPAMI.2016.2551244; Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180; Perrone D, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.114; Ren WQ, 2016, IEEE T IMAGE PROCESS, V25, P3426, DOI 10.1109/TIP.2016.2571062; Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6; Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375; Schmidt U, 2016, IEEE T PATTERN ANAL, V38, P677, DOI 10.1109/TPAMI.2015.2441053; Schmidt U, 2014, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2014.349; Schmidt U, 2013, PROC CVPR IEEE, P604, DOI 10.1109/CVPR.2013.84; Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672; Su S., 2017, CVPR, V2, P6; Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853; Vasu S, 2018, PROC CVPR IEEE, P3272, DOI 10.1109/CVPR.2018.00345; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435; Whyte O, 2014, INT J COMPUT VISION, V110, P185, DOI 10.1007/s11263-014-0727-3; Wright Y., 2009, ADV NEURAL INFORM PR, V22, DOI DOI 10.5555/2984093.2984326; Wu XJ, 2014, INT CONF MEAS, P55, DOI 10.1109/ICMTMA.2014.20; Xiao L, 2016, LECT NOTES COMPUT SC, V9907, P734, DOI 10.1007/978-3-319-46487-9_45; Xu J, 2016, IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS: CYBERSECURITY AND BIG DATA, P79, DOI 10.1109/ISI.2016.7745447; Xu L., 2014, INT C NEUR INF PROC, V27, P1790; Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157; Yuan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360673; Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300; Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206; Zhu FY, 2016, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2016.52; Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278; Zuo WM, 2016, IEEE T IMAGE PROCESS, V25, P1751, DOI 10.1109/TIP.2016.2531905	64	34	34	3	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2021	43	1					284	299		10.1109/TPAMI.2019.2926357	http://dx.doi.org/10.1109/TPAMI.2019.2926357			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PC7WN	31283494	Green Submitted			2022-12-18	WOS:000597206900019
J	Tjaden, H; Schwanecke, U; Schomer, E; Cremers, D				Tjaden, Henning; Schwanecke, Ulrich; Schoemer, Elmar; Cremers, Daniel			A Region-Based Gauss-Newton Approach to Real-Time Monocular Multiple Object Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pose estimation; tracking; image segmentation; region-based; optimization; dataset	SEGMENTATION; COLOR	We propose an algorithm for real-time 6DOF pose tracking of rigid 3D objects using a monocular RGB camera. The key idea is to derive a region-based cost function using temporally consistent local color histograms. While such region-based cost functions are commonly optimized using first-order gradient descent techniques, we systematically derive a Gauss-Newton optimization scheme which gives rise to drastically faster convergence and highly accurate and robust tracking performance. We furthermore propose a novel complex dataset dedicated for the task of monocular object pose tracking and make it publicly available to the community. To our knowledge, it is the first to address the common and important scenario in which both the camera as well as the objects are moving simultaneously in cluttered scenes. In numerous experiments-including our own proposed dataset-we demonstrate that the proposed Gauss-Newton approach outperforms existing approaches, in particular in the presence of cluttered backgrounds, heterogeneous objects and partial occlusions.	[Tjaden, Henning] RheinMain Univ Appl Sci, Comp Vis & MixedReal Grp, D-65197 Wiesbaden, Germany; [Schwanecke, Ulrich] RheinMain Univ Appl Sci, Comp Graph & Vis, D-65197 Wiesbaden, Germany; [Schoemer, Elmar] Johannes Gutenberg Univ Mainz, Comp Graph & Computat Geometry, D-55122 Mainz, Germany; [Cremers, Daniel] Tech Univ Munich, D-80333 Munich, Germany	Johannes Gutenberg University of Mainz; Technical University of Munich	Tjaden, H (corresponding author), RheinMain Univ Appl Sci, Comp Vis & MixedReal Grp, D-65197 Wiesbaden, Germany.	henning.tjaden@hs-rm.de; ulrich.schwanecke@hs-rm.de; schoemer@uni-mainz.de; cremers@tum.de		Schwanecke, Ulrich/0000-0002-0093-3922	Federal Ministry for Economic Affairs and Energy (BMWi); ERC	Federal Ministry for Economic Affairs and Energy (BMWi)(Federal Ministry for Economic Affairs and Energy (BMWi)); ERC(European Research Council (ERC)European Commission)	Part of this work was funded by the Federal Ministry for Economic Affairs and Energy (BMWi). We thank Stefan Hinterstoisser and Karl Pauwels for letting us re-use their 3D models for our dataset. DC was supported by the ERC Consolidator Grant 3DReloaded.	[Anonymous], 2014, ACCV; Bibby C, 2008, LECT NOTES COMPUT SC, V5303, P831, DOI 10.1007/978-3-540-88688-4_61; Brachmann E, 2016, PROC CVPR IEEE, P3364, DOI 10.1109/CVPR.2016.366; Brox T, 2010, IEEE T PATTERN ANAL, V32, P402, DOI 10.1109/TPAMI.2009.32; Choi C, 2013, IEEE INT C INT ROBOT, P1084, DOI 10.1109/IROS.2013.6696485; Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1; Crivellaro A, 2018, IEEE T PATTERN ANAL, V40, P1465, DOI 10.1109/TPAMI.2017.2708711; Dambreville S, 2008, LECT NOTES COMPUT SC, V5303, P169, DOI 10.1007/978-3-540-88688-4_13; Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577; Felzenszwalb P.F., 2012, THEORY COMPUT, V8, P415, DOI DOI 10.4086/TOC.2012.V008A019; Garon M, 2018, LECT NOTES COMPUT SC, V11215, P608, DOI 10.1007/978-3-030-01252-6_36; Hexner J, 2016, INT J COMPUT VISION, V118, P95, DOI 10.1007/s11263-015-0873-2; Hinterstoisser S., 2012, LNCS; Hinterstoisser S., 2018, P ECCV WORKSH REC 6D; Hinterstoisser S, 2007, IEEE I CONF COMP VIS, P1372; Kehl W, 2017, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2017.169; Kehl W, 2017, PROC CVPR IEEE, P465, DOI 10.1109/CVPR.2017.57; Kiyoung Kim, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P193, DOI 10.1109/ISMAR.2010.5643569; Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611; Lebeda K, 2017, IEEE T IMAGE PROCESS, V26, P4378, DOI 10.1109/TIP.2017.2675343; Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001; Ma Y., 2005, INVITATION 3 D VISIO; Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103; Pauwels K, 2013, PROC CVPR IEEE, P2347, DOI 10.1109/CVPR.2013.304; Prisacariu VA, 2012, INT J COMPUT VISION, V98, P335, DOI 10.1007/s11263-011-0514-3; Prisacariu VA, 2015, IEEE T VIS COMPUT GR, V21, P557, DOI 10.1109/TVCG.2014.2355207; Rad M, 2017, IEEE I CONF COMP VIS, P3848, DOI 10.1109/ICCV.2017.413; Ren CY, 2017, INT J COMPUT VISION, V124, P80, DOI 10.1007/s11263-016-0978-2; Rosenhahn B, 2007, INT J COMPUT VISION, V73, P243, DOI [10.1007/s11263-006-9965-3, 10.1007/S11263-006-9965-3]; Rosten E, 2005, IEEE I CONF COMP VIS, P1508; Schmaltz C, 2012, MACH VISION APPL, V23, P557, DOI 10.1007/s00138-010-0317-5; Seo BK, 2014, IEEE T VIS COMPUT GR, V20, P99, DOI 10.1109/TVCG.2013.94; Tan DJ, 2017, IEEE T VIS COMPUT GR, V23, P2399, DOI 10.1109/TVCG.2017.2734539; Tejani A, 2014, LECT NOTES COMPUT SC, V8694, P462, DOI 10.1007/978-3-319-10599-4_30; Tjaden H, 2017, IEEE I CONF COMP VIS, P124, DOI 10.1109/ICCV.2017.23; Tjaden H, 2016, LECT NOTES COMPUT SC, V9908, P423, DOI 10.1007/978-3-319-46493-0_26; Vacchetti L, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P48, DOI 10.1109/ISMAR.2004.24; Wagner D, 2010, IEEE T VIS COMPUT GR, V16, P355, DOI 10.1109/TVCG.2009.99; Whelan T., 2015, ROBOTICS SCI SYSTEMS; Wu PC, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P186, DOI 10.1109/ISMAR-Adjunct.2017.62; Zhao S, 2014, IEEE IMAGE PROC, P486, DOI 10.1109/ICIP.2014.7025097	41	34	38	3	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2019	41	8					1797	1812		10.1109/TPAMI.2018.2884990	http://dx.doi.org/10.1109/TPAMI.2018.2884990			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IG2BD	30530354	Green Submitted			2022-12-18	WOS:000473598800002
J	Lin, K; Lu, JW; Chen, CS; Zhou, J; Sun, MT				Lin, Kevin; Lu, Jiwen; Chen, Chu-Song; Zhou, Jie; Sun, Ming-Ting			Unsupervised Deep Learning of Compact Binary Descriptors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Binary descriptors; unsupervised learning; deep learning; convolutional neural networks	ITERATIVE QUANTIZATION; PROCRUSTEAN APPROACH; IMAGE DESCRIPTORS; FEATURES; CODES; HASH	Binary descriptors have been widely used for efficient image matching and retrieval. However, most existing binary descriptors are designed with hand-craft sampling patterns or learned with label annotation provided by datasets. In this paper, we propose a new unsupervised deep learning approach, called DeepBit, to learn compact binary descriptor for efficient visual object matching. We enforce three criteria on binary descriptors which are learned at the top layer of the deep neural network: 1) minimal quantization loss, 2) evenly distributed codes and 3) transformation invariant bit. Then, we estimate the parameters of the network through the optimization of the proposed objectives with a back-propagation technique. Extensive experimental results on various visual recognition tasks demonstrate the effectiveness of the proposed approach. We further demonstrate our proposed approach can be realized on the simplified deep neural network, and enables efficient image matching and retrieval speed with very competitive accuracies.	[Lin, Kevin; Sun, Ming-Ting] Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA; [Lu, Jiwen; Zhou, Jie] Tsinghua Univ, Beijing Res Ctr Informat Sci & Technol BNRist, Dept Automat, State Key Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China; [Chen, Chu-Song] Acad Sinica, Inst Informat Sci, Taipei 11529, Taiwan	University of Washington; University of Washington Seattle; Tsinghua University; Academia Sinica - Taiwan	Lin, K (corresponding author), Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.	kvlin@uw.edu; lujiwen@tsinghua.edu.cn; song@iis.sinica.edu.tw; jzhou@tsinghua.edu.cn; mts@uw.edu	Lin, Kevin/AAL-5205-2020; Lu, Jiwen/C-5291-2009	Lin, Kevin/0000-0001-8944-1336; Lu, Jiwen/0000-0002-6121-5529	National Key Research and Development Program of China [2017YFA0700802]; Ministry of Science 929 and Technology of Taiwan [MOST 105-2218-E-001-006]; National Natural Science Foundation of China [U1713214, 61672306]	National Key Research and Development Program of China; Ministry of Science 929 and Technology of Taiwan; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by the National Key Research and Development Program of China under Grant 2017YFA0700802, in part by the Ministry of Science 929 and Technology of Taiwan under ContractMOST 105-2218-E-001-006, and in part by the National Natural Science Foundation of China under Grant U1713214 and Grant 61672306.	Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715; Andoni A, 2006, ANN IEEE SYMP FOUND, P459; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2005, THESIS MIT CAMBRIDGE; Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38; Balntas V., 2016, ARXIV160105030, P1; Balntas V, 2015, PROC CVPR IEEE, P2367, DOI 10.1109/CVPR.2015.7298850; Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3; Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54; Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56; Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dosovitskiy A, 2016, IEEE T PATTERN ANAL, V38, P1734, DOI 10.1109/TPAMI.2015.2496141; Duan YQ, 2017, PROC CVPR IEEE, P4857, DOI 10.1109/CVPR.2017.516; Fan B, 2014, IEEE T IMAGE PROCESS, V23, P2583, DOI 10.1109/TIP.2014.2317981; Fernando B, 2014, INT J COMPUT VISION, V108, P186, DOI 10.1007/s11263-014-0700-1; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; Grauman K., 2013, MACHINE LEARNING COM, P49, DOI [DOI 10.1007/978-3-642-28661-2_3, 10.1007/978-3-642-28661-2_3]; Han XF, 2015, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2015.7298948; HUANG C, 2016, PROC CVPR IEEE, P5175, DOI DOI 10.1109/CVPR.2016.559; Iandola F.N., 2016, ARXIV; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar BGV, 2016, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2016.581; Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947; Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542; Lin KV, 2016, PROC CVPR IEEE, P1183, DOI 10.1109/CVPR.2016.133; Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862; Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561; Mopuri KR, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301273; Nilsback M-E., 2006, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2006., DOI 10.1109/CVPR.2006.42]; Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47; Nister David, 2006, CVPR, P2161, DOI DOI 10.1109/CVPR.2006.264; Ozdemir B., 2016, P BRIT MACH VIS C; Paulin M, 2015, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2015.19; Philbin J, 2008, PROC CVPR IEEE, P2285; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006; Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Do TT, 2016, LECT NOTES COMPUT SC, V9909, P219, DOI 10.1007/978-3-319-46454-1_14; Tian YR, 2017, PROC CVPR IEEE, P6128, DOI 10.1109/CVPR.2017.649; Trzcinski T, 2015, IEEE T PATTERN ANAL, V37, P597, DOI 10.1109/TPAMI.2014.2343961; Trzcinski T, 2013, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2013.370; Trzcinski T, 2012, LECT NOTES COMPUT SC, V7572, P228, DOI 10.1007/978-3-642-33718-5_17; Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948; Wang J, 2017, IEEE INFOCOM SER, DOI 10.1007/s12083-017-0556-6; Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976; Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994; Weiss Y., 2008, NIPS, P1753; Xia RK, 2014, AAAI CONF ARTIF INTE, P2156; Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345; Yang HF, 2018, IEEE T PATTERN ANAL, V40, P437, DOI 10.1109/TPAMI.2017.2666812; Yang X, 2014, IEEE T PATTERN ANAL, V36, P188, DOI 10.1109/TPAMI.2013.150; ZAGORUYKO S, 2015, 2015 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2015.7299064; Zbontar J, 2016, J MACH LEARN RES, V17; Zhang ZM, 2016, PROC CVPR IEEE, P1487, DOI 10.1109/CVPR.2016.165; Zheng L, 2014, IEEE T IMAGE PROCESS, V23, P3368, DOI 10.1109/TIP.2014.2330763; 2014, IEEE T IMAGE PROCESS, V23, P3671, DOI DOI 10.1109/TIP.2014.2330794	72	34	36	3	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2019	41	6					1501	1514		10.1109/TPAMI.2018.2833865	http://dx.doi.org/10.1109/TPAMI.2018.2833865			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HW9UU	29993880				2022-12-18	WOS:000467037000016
J	Georgoulis, S; Rematas, K; Ritschel, T; Gavves, E; Fritz, M; Van Gool, L; Tuytelaars, T				Georgoulis, Stamatios; Rematas, Konstantinos; Ritschel, Tobias; Gavves, Efstratios; Fritz, Mario; Van Gool, Luc; Tuytelaars, Tinne			Reflectance and Natural Illumination from Single-Material Specular Objects Using Deep Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Reflectance maps; intrinsic images; reflectance; natural illumination; specular shading; convolutional neural networks	IMAGE; SHAPE	In this paper, we present a method that estimates reflectance and illumination information from a single image depicting a single-material specular object from a given class under natural illumination. We follow a data-driven, learning-based approach trained on a very large dataset, but in contrast to earlier work we do not assume one or more components (shape, reflectance, or illumination) to be known. We propose a two-step approach, where we first estimate the object's reflectance map, and then further decompose it into reflectance and illumination. For the first step, we introduce a Convolutional Neural Network (CNN) that directly predicts a reflectance map from the input image itself, as well as an indirect scheme that uses additional supervision, first estimating surface orientation and afterwards inferring the reflectance map using a learning-based sparse data interpolation technique. For the second step, we suggest a CNN architecture to reconstruct both Phong reflectance parameters and high-resolution spherical illumination maps from the reflectance map. We also propose new datasets to train these CNNs. We demonstrate the effectiveness of our approach for both steps by extensive quantitative and qualitative evaluation in both synthetic and real data as well as through numerous applications, that show improvements over the state-of-the-art.	[Georgoulis, Stamatios; Van Gool, Luc; Tuytelaars, Tinne] Katholieke Univ Leuven, ESAT PSI iMinds, B-9052 Ghent, Belgium; [Van Gool, Luc] Swiss Fed Inst Technol, CH-8092 Zurich, Switzerland; [Rematas, Konstantinos] Univ Washington, Seattle, WA 98195 USA; [Ritschel, Tobias] UCL, London WC1E 6BT, England; [Gavves, Efstratios] Univ Amsterdam, NL-012 WX Amsterdam, Netherlands; [Fritz, Mario] Max Planck Inst Informat, D-66123 Saarbrucken, Germany	IMEC; KU Leuven; Swiss Federal Institutes of Technology Domain; ETH Zurich; University of Washington; University of Washington Seattle; University of London; University College London; University of Amsterdam; Max Planck Society	Georgoulis, S (corresponding author), Katholieke Univ Leuven, ESAT PSI iMinds, B-9052 Ghent, Belgium.	stam.georgoulis@esat.kuleuven.be; krematas@cs.washington.edu; t.ritschel@ucl.ac.uk; egavves@uva.nl; mfritz@mpi-inf.mpg.de; vangool@vision.ee.ethz.ch; tinne.tuytelaars@esat.kuleuven.be	Gavves, Efstratios/AAA-6992-2019; Tuytelaars, Tinne/B-4319-2015	Tuytelaars, Tinne/0000-0003-3307-9723; Gavves, Efstratios/0000-0001-8947-1332	Toyota Research Institute; FWO [G086617N]	Toyota Research Institute; FWO(FWO)	This work was supported by Toyota Research Institute and FWO project "Structure from Semantics" (#G086617N). S. Georgoulis and K. Rematas contributed equally to this work.	[Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712; Barrow H., 1978, COMPUT VIS SYST, V2; BELL S., 2014, ACM T GRAPHICS SIGGR, V33, P4; Chan D, 2008, P WORKSH MULT MULT S; Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778; Debevec P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P189, DOI 10.1145/280814.280864; Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191; Dosovitskiy A, 2015, PROC CVPR IEEE, P1538, DOI 10.1109/CVPR.2015.7298761; Dror RO, 2001, PROC CVPR IEEE, P164; Dror RO, 2001, P SOC PHOTO-OPT INS, V4299, P231, DOI 10.1117/12.429494; Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304; Eigen David, 2014, NEURIPS; Georgoulis S., 2014, P 2 INT C 3D VIS, P167; Georgoulis S., 2016, ARXIV161109325; Georgoulis S, 2015, IEEE I CONF COMP VIS, P3559, DOI 10.1109/ICCV.2015.406; Haber T, 2009, PROC CVPR IEEE, P627, DOI 10.1109/CVPRW.2009.5206753; Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642; Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158; Horn B.K.P., 1989, SHAPE SHADING; HORN BKP, 1979, APPL OPTICS, V18, P1770, DOI 10.1364/AO.18.001770; Johnson M. K., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2553, DOI 10.1109/CVPR.2011.5995510; Kajiya J.T., 1986, SIGGRAPH, P143, DOI [DOI 10.1145/15922.15902, 10.1145/15886.15902, DOI 10.1145/15886.15902]; Kersten D, 2004, ANNU REV PSYCHOL, V55, P271, DOI 10.1146/annurev.psych.55.090902.142005; Khan EA, 2006, ACM T GRAPHIC, V25, P654, DOI 10.1145/1141911.1141937; Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239547, 10.1145/1276377.1276497]; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kulkarni T. D., 2014, P 28 INT C NEUR INF, P2539; Lee H., 2009, P ANN INT C MACH LEA, P609; Li B, 2015, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2015.7298715; Li YY, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818071; Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152; Lombardi S, 2016, IEEE T PATTERN ANAL, V38, P129, DOI 10.1109/TPAMI.2015.2430318; Lombardi S, 2012, LECT NOTES COMPUT SC, V7577, P582, DOI 10.1007/978-3-642-33783-3_42; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Matusik W, 2003, ACM T GRAPHIC, V22, P759, DOI 10.1145/882262.882343; Narihira T, 2015, IEEE I CONF COMP VIS, P2992, DOI 10.1109/ICCV.2015.342; Narihira T, 2015, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2015.7298915; NICODEMUS FE, 1965, APPL OPTICS, V4, P767, DOI DOI 10.1364/AO.4.000767; PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839; Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575; Rematas K, 2017, IEEE T PATTERN ANAL, V39, P1576, DOI 10.1109/TPAMI.2016.2601093; Rematas K, 2014, PROC CVPR IEEE, P3898, DOI 10.1109/CVPR.2014.498; Richter SR, 2015, PROC CVPR IEEE, P1128, DOI 10.1109/CVPR.2015.7298716; Romeiro F, 2008, LECT NOTES COMPUT SC, V5305, P859, DOI 10.1007/978-3-540-88693-8_63; Romeiro F, 2010, LECT NOTES COMPUT SC, V6311, P45, DOI 10.1007/978-3-642-15549-9_4; Sloan P.-P. J., 2001, GRAPHICS INTERFACE, P143; Spencer S, 2011, ZBRUSH CHARACTER CRE, V2nd; Tang Y, 2012, P 29 INT C MACH LEAR, P1623; Wang XL, 2015, PROC CVPR IEEE, P539, DOI 10.1109/CVPR.2015.7298652; Wang Z, 2003, CONF REC ASILOMAR C, P1398; Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; Zhou TH, 2015, IEEE I CONF COMP VIS, P3469, DOI 10.1109/ICCV.2015.396; Zhukov S., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P45	55	34	37	2	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2018	40	8					1932	1947		10.1109/TPAMI.2017.2742999	http://dx.doi.org/10.1109/TPAMI.2017.2742999			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GL6DT	28841552	Green Submitted			2022-12-18	WOS:000437271100011
J	Ham, B; Cho, M; Schmid, C; Ponce, J				Ham, Bumsub; Cho, Minsu; Schmid, Cordelia; Ponce, Jean			Proposal Flow: Semantic Correspondences from Object Proposals	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantic flow; object proposals; scene alignment; dense scene correspondence	LOCATION; MODELS	Finding image correspondences remains a challenging problem in the presence of intra-class variations and large changes in scene layout. Semantic flow methods are designed to handle images depicting different instances of the same object or scene category. We introduce a novel approach to semantic flow, dubbed proposal flow, that establishes reliable correspondences using object proposals. Unlike prevailing semantic flow approaches that operate on pixels or regularly sampled local regions, proposal flow benefits from the characteristics of modern object proposals, that exhibit high repeatability at multiple scales, and can take advantage of both local and geometric consistency constraints among proposals. We also show that the corresponding sparse proposal flow can effectively be transformed into a conventional dense flow field. We introduce two new challenging datasets that can be used to evaluate both general semantic flow techniques and region-based approaches such as proposal flow. We use these benchmarks to compare different matching algorithms, object proposals, and region features within proposal flow, to the state of the art in semantic flow. This comparison, along with experiments on standard datasets, demonstrates that proposal flow significantly outperforms existing semantic flow methods in various settings.	[Ham, Bumsub] Yonsei Univ, Sch Elect & Elect Engn, Seoul 03722, South Korea; [Cho, Minsu] POSTECH, Dept Comp Sci & Engn, Pohang 790784, Gyeongsangbuk D, South Korea; [Schmid, Cordelia] Inria Grenoble Rhone Alpes, Lab Jean Kuntzmann, Thoth Project Team, F-38041 Grenoble, France; [Ponce, Jean] PSL Res Univ, Ecole Normale Super, F-75005 Paris, France; [Ponce, Jean] INRIA, F-75005 Paris, France	Yonsei University; Pohang University of Science & Technology (POSTECH); UDICE-French Research Universities; Communaute Universite Grenoble Alpes; Institut National Polytechnique de Grenoble; Universite Grenoble Alpes (UGA); Centre National de la Recherche Scientifique (CNRS); Inria; UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS); Inria	Ham, B (corresponding author), Yonsei Univ, Sch Elect & Elect Engn, Seoul 03722, South Korea.	mimo@yonsei.ac.kr; mscho@postech.ac.kr; cordelia.schmid@inria.fr; jean.ponce@ens.fr	Cho, Minsu/AAR-6323-2020	HAM, BUMSUB/0000-0002-3443-8161	ERC; Institut Universitaire de France; National Research Foundation of Korea (NRF) grant - Korea government (MSIP) [2017R1C1B2005584]	ERC(European Research Council (ERC)European Commission); Institut Universitaire de France; National Research Foundation of Korea (NRF) grant - Korea government (MSIP)	This work was supported in part by ERC grants Video-World and Allegro, and the Institut Universitaire de France. The work of B. Ham was supported in part by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIP) (No. 2017R1C1B2005584). Part of this work was done while B. Ham and M. Cho were with Inria, Paris.	Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Bai M, 2016, LECT NOTES COMPUT SC, V9910, P154, DOI 10.1007/978-3-319-46466-4_10; Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Bristow H, 2015, IEEE I CONF COMP VIS, P4024, DOI 10.1109/ICCV.2015.458; Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54; Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44; Carreira J, 2015, PROC CVPR IEEE, P2937, DOI 10.1109/CVPR.2015.7298912; CHANDRASEKARAN R, 1989, MATH PROGRAM, V44, P293, DOI 10.1007/BF01587094; Chen XJ, 2014, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2014.254; Cho M, 2015, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2015.7298724; Cho MS, 2013, IEEE I CONF COMP VIS, P25, DOI 10.1109/ICCV.2013.11; Cho M, 2012, PROC CVPR IEEE, P398, DOI 10.1109/CVPR.2012.6247701; Choy Christopher, 2016, ADV NEURAL INFORM PR, V6; Cinbis RG, 2014, PROC CVPR IEEE, P2409, DOI 10.1109/CVPR.2014.309; Dai JF, 2015, IEEE I CONF COMP VIS, P1635, DOI 10.1109/ICCV.2015.191; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Donato G, 2002, LECT NOTES COMPUT SC, V2352, P21; Duchenne O, 2011, IEEE I CONF COMP VIS, P1792, DOI 10.1109/ICCV.2011.6126445; Felzenszwalb P, 2008, PROC CVPR IEEE, P1984; Fletcher P. T., 2008, P 2008 IEEE C COMPUT, P1; Forsyth D., 2011, COMPUTER VISION MODE; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; HaCohen Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964965; Ham B, 2016, PROC CVPR IEEE, P3475, DOI 10.1109/CVPR.2016.378; Ham B, 2015, PROC CVPR IEEE, P4823, DOI 10.1109/CVPR.2015.7299115; Han Kai, 2017, CORR; Han XF, 2015, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2015.7298948; Han YC, 2017, PROCEEDINGS OF THE 2017 IEEE VIS ARTS PROGRAM (VISAP); Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; Hassner T, 2012, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2012.6247842; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; HORN BKP, 1993, ARTIF INTELL, V59, P81, DOI 10.1016/0004-3702(93)90173-9; Hosang Jan, 2016, IEEE Trans Pattern Anal Mach Intell, V38, P814, DOI 10.1109/TPAMI.2015.2465908; Hur J, 2015, PROC CVPR IEEE, P1392, DOI 10.1109/CVPR.2015.7298745; Jiang H, 2015, PROC CVPR IEEE, P3358, DOI 10.1109/CVPR.2015.7298957; Kanazawa A, 2016, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2016.354; Kemelmacher-Shlizerman I, 2012, PROC CVPR IEEE, P1792, DOI 10.1109/CVPR.2012.6247876; Kim J, 2013, PROC CVPR IEEE, P2307, DOI 10.1109/CVPR.2013.299; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Learned-Miller EG, 2006, IEEE T PATTERN ANAL, V28, P236, DOI 10.1109/TPAMI.2006.34; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Lin YL, 2014, LECT NOTES COMPUT SC, V8692, P466, DOI 10.1007/978-3-319-10593-2_31; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131; Long J.L., 2014, P C NEUR INF PROC SY, V27, P1601; LOPUHAA HP, 1991, ANN STAT, V19, P229, DOI 10.1214/aos/1176347978; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maji S, 2009, PROC CVPR IEEE, P1038, DOI 10.1109/CVPRW.2009.5206693; Manen S, 2013, IEEE I CONF COMP VIS, P2536, DOI 10.1109/ICCV.2013.315; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; Paulin M, 2015, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2015.19; Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282; Qiu WC, 2014, IEEE WINT CONF APPL, P1112, DOI 10.1109/WACV.2014.6835734; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Revaud J, 2016, INT J COMPUT VISION, V120, P300, DOI 10.1007/s11263-016-0908-3; Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372; Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253; Sevilla-Lara L, 2016, PROC CVPR IEEE, P3889, DOI 10.1109/CVPR.2016.422; Sibson R, 1981, INTERPRETING MULTIVA, P21, DOI DOI 10.1007/3-540-26772-7_8; Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22; Tang K, 2014, PROC CVPR IEEE, P1464, DOI 10.1109/CVPR.2014.190; Taniai T, 2016, PROC CVPR IEEE, P4246, DOI 10.1109/CVPR.2016.460; Tau M, 2016, IEEE T PATTERN ANAL, V38, P875, DOI 10.1109/TPAMI.2015.2474356; Trulls E, 2013, PROC CVPR IEEE, P2890, DOI 10.1109/CVPR.2013.372; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Wah Catherine, 2011, CALTECH UCSD BIRDS 2; Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175; Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101; Yang HS, 2014, PROC CVPR IEEE, P3406, DOI 10.1109/CVPR.2014.435; Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261; Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064; Zhou TH, 2016, PROC CVPR IEEE, P117, DOI 10.1109/CVPR.2016.20; Zhou TH, 2015, PROC CVPR IEEE, P1191, DOI 10.1109/CVPR.2015.7298723; Zhou XW, 2015, IEEE I CONF COMP VIS, P4032, DOI 10.1109/ICCV.2015.459; Zhu G, 2016, PROC CVPR IEEE, P943, DOI 10.1109/CVPR.2016.108; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	83	34	34	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2018	40	7					1711	1725		10.1109/TPAMI.2017.2724510	http://dx.doi.org/10.1109/TPAMI.2017.2724510			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GI3TS	28708543	Green Submitted			2022-12-18	WOS:000434294800013
J	Lu, CW; Lin, D; Jia, JY; Tang, CK				Lu, Cewu; Lin, Di; Jia, Jiaya; Tang, Chi-Keung			Two-Class Weather Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Weather understanding; image classification; structure SVM	SCENE; RECOGNITION; SHAPE	Given a single outdoor image, we propose a collaborative learning approach using novel weather features to label the image as either sunny or cloudy. Though limited, this two-class classification problem is by no means trivial given the great variety of outdoor images captured by different cameras where the images may have been edited after capture. Our overall weather feature combines the data-driven convolutional neural network (CNN) feature and well-chosen weather-specific features. They work collaboratively within a unified optimization framework that is aware of the presence (or absence) of a given weather cue during learning and classification. In this paper we propose a new data augmentation scheme to substantially enrich the training data, which is used to train a latent SVM framework to make our solution insensitive to global intensity transfer. Extensive experiments are performed to verify our method. Compared with our previous work and the sole use of a CNN classifier, this paper improves the accuracy up to 7-8 percent. Our weather image dataset is available together with the executable of our classifier.	[Lu, Cewu] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China; [Lin, Di] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Guangdong, Peoples R China; [Jia, Jiaya] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China; [Tang, Chi-Keung] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China	Shanghai Jiao Tong University; Shenzhen University; Chinese University of Hong Kong; Hong Kong University of Science & Technology	Lu, CW (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.	lucewu06@gmail.com; ande.lin1988@gmail.com; leojia@cse.cuhk.edu.hk; cktang@cse.ust.hk	Jia, Jiaya/I-3251-2012		Research Grants Council of the Hong Kong Special Administrative Region [413113, 619313, 412911]; National Natural Science Foundation of China (NSFC) [61133009]	Research Grants Council of the Hong Kong Special Administrative Region(Hong Kong Research Grants Council); National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC))	The research was supported by the Research Grants Council of the Hong Kong Special Administrative Region (Project nos. 413113, 619313 and 412911). It was also partly supported by the National Natural Science Foundation of China (NSFC) key project No. 61133009. Di Lin is the corresponding author of this paper.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; [Anonymous], 2009, P ACM INT C IM VID R; Baccouche Moez, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P29, DOI 10.1007/978-3-642-25446-8_4; Baltenberger R, 2016, P IEEE WINT C APPL C, P1; BOUREAU YL, 2010, PROC CVPR IEEE, P2559, DOI DOI 10.1109/CVPR.2010.5539963; Chu WT, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P137, DOI 10.1109/BigMM.2016.9; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Derpanis KG, 2012, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2012.6247815; Elhoseiny M, 2015, IEEE IMAGE PROC, P3349, DOI 10.1109/ICIP.2015.7351424; Glasner D, 2015, IEEE I CONF COMP VIS, P3997, DOI 10.1109/ICCV.2015.455; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]; Islam M., 2013, P IEEE C COMP VIS PA, V6, P2; Jacobs N, 2013, PROC CVPR IEEE, P1344, DOI 10.1109/CVPR.2013.177; Juneja M, 2013, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2013.124; Kang HW, 2011, IEEE I CONF COMP VIS, P762, DOI 10.1109/ICCV.2011.6126314; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Katsura H, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2974; Kim G., 2009, ADV NEURAL INFORM PR, P961; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kurihata H, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P205; Laffont PY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601101; Lalonde JF, 2012, INT J COMPUT VISION, V98, P123, DOI 10.1007/s11263-011-0501-8; LALONDE JF, 2010, P 11 EUR C COMP VI 2, V6312, P322; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Lee YJ, 2010, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2010.5540237; Levin A., 2006, IEEE C COMP VIS PATT; Li L.-J., 2010, NEURAL INFORM PROCES, P1378; Li L.-J., 2012, TRENDS TOPICS COMPUT, V6553, P57, DOI DOI 10.1007/978-3-642-35749-7; Li QN, 2013, PROC CVPR IEEE, P851, DOI 10.1109/CVPR.2013.115; Lin D, 2015, PROC CVPR IEEE, P1666, DOI 10.1109/CVPR.2015.7298775; Lin D, 2014, PROC CVPR IEEE, P3726, DOI 10.1109/CVPR.2014.476; Lin M., 2014, INT C LEARN REPRESEN; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu CW, 2014, PROC CVPR IEEE, P3718, DOI 10.1109/CVPR.2014.475; Lu CW, 2013, PROC CVPR IEEE, P415, DOI 10.1109/CVPR.2013.60; Lu CW, 2014, IEEE T IMAGE PROCESS, V23, P837, DOI 10.1109/TIP.2013.2287602; MURTAGH F, 1983, COMPUT J, V26, P354, DOI 10.1093/comjnl/26.4.354; Narasimhan SG, 2003, PROC CVPR IEEE, P665; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383; Parizi SN, 2012, PROC CVPR IEEE, P2775, DOI 10.1109/CVPR.2012.6248001; PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009; Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537; Roser M, 2008, IEEE INT VEH SYM, P480; Russell B. C., 2006, P IEEE C COMP VIS PA, V2, P1605; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Sadeghi F, 2012, LECT NOTES COMPUT SC, V7576, P228, DOI 10.1007/978-3-642-33715-4_17; Shen L, 2009, PROC CVPR IEEE, P1850, DOI 10.1109/CVPRW.2009.5206732; Shroff N, 2010, PROC CVPR IEEE, P1911, DOI 10.1109/CVPR.2010.5539864; Singh S, 2012, LECT NOTES COMPUT SC, V7573, P73, DOI 10.1007/978-3-642-33709-3_6; Tao L., 2009, P ACM SIGGRAPH; Todorovic S, 2008, IEEE T PATTERN ANAL, V30, P2158, DOI 10.1109/TPAMI.2008.24; Volokitin A., 2016, P IEEE C COMP VIS PA, P63; Wang JY, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P452, DOI 10.1109/ICCVW.2013.66; WANG JJ, 2010, PROC CVPR IEEE, P3360, DOI DOI 10.1109/CVPR.2010.5540018; Workman S, 2015, COMPUT VIS IMAGE UND, V134, P116, DOI 10.1016/j.cviu.2014.10.002; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Yan XS, 2009, LECT NOTES COMPUT SC, V5553, P390; Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757; Yao BP, 2012, PROC CVPR IEEE, P3466, DOI 10.1109/CVPR.2012.6248088; Zhang N., 2015, CORR, Vabs/ 1511. 07063; Zhang Z, 2015, IEEE IMAGE PROC, P4396, DOI 10.1109/ICIP.2015.7351637; Zheng YC, 2012, PROCEEDINGS OF THE 7TH EURO-ASIA CONFERENCE ON ENVIRONMENT AND CSR: TOURISM, MICE, HOSPITALITY MANAGEMENT AND EDUCATION SESSION, PT I, P172	66	34	34	1	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2017	39	12					2510	2524		10.1109/TPAMI.2016.2640295	http://dx.doi.org/10.1109/TPAMI.2016.2640295			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL6ZQ	28113309	Green Submitted			2022-12-18	WOS:000414395400014
J	Wei, P; Zhao, YB; Zheng, NN; Zhu, SC				Wei, Ping; Zhao, Yibiao; Zheng, Nanning; Zhu, Song-Chun			Modeling 4D Human-Object Interactions for Joint Event Segmentation, Recognition, and Object Localization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human-object interaction; object affordance; event recognition; sequence segmentation; object localization	AFFORDANCES; GEOMETRY	In this paper, we present a 4D human-object interaction (4DHOI) model for solving three vision tasks jointly: i) event segmentation from a video sequence, ii) event recognition and parsing, and iii) contextual object localization. The 4DHOI model represents the geometric, temporal, and semantic relations in daily events involving human-object interactions. In 3D space, the interactions of human poses and contextual objects are modeled by semantic co-occurrence and geometric compatibility. On the time axis, the interactions are represented as a sequence of atomic event transitions with coherent objects. The 4DHOI model is a hierarchical spatial-temporal graph representation which can be used for inferring scene functionality and object affordance. The graph structures and parameters are learned using an ordered expectation maximization algorithm which mines the spatial-temporal structures of events from RGB-D video samples. Given an input RGB-D video, the inference is performed by a dynamic programming beam search algorithm which simultaneously carries out event segmentation, recognition, and object localization. We collected a large multiview RGB-D event dataset which contains 3,815 video sequences and 383,036 RGB-D frames captured by three RGB-D cameras. The experimental results on three challenging datasets demonstrate the strength of the proposed method.	[Wei, Ping; Zheng, Nanning] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Peoples R China; [Wei, Ping] Univ Calif Los Angeles, Los Angeles, CA 90095 USA; [Zhao, Yibiao; Zhu, Song-Chun] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA	Xi'an Jiaotong University; University of California System; University of California Los Angeles; University of California System; University of California Los Angeles	Wei, P (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Peoples R China.; Wei, P (corresponding author), Univ Calif Los Angeles, Los Angeles, CA 90095 USA.	pingwei.pw@gmail.com; yibiao.zhao@stat.ucla.edu; nnzheng@mail.xjtu.edu.cn; sczhu@stat.ucla.edu			NSFC [61231018, 61503297]; 973 Program of China [2012CB316402]; ONR MURI [N00014-10-10933]; DARPA MSEE [FA 8650-11-1-7149]	NSFC(National Natural Science Foundation of China (NSFC)); 973 Program of China(National Basic Research Program of China); ONR MURI(MURIOffice of Naval Research); DARPA MSEE	Ping Wei and Nanning Zheng thank the support of grants: Key Program of NSFC 61231018, NSFC 61503297, and 973 Program of China 2012CB316402. Yibiao Zhao and Song-Chun Zhu thank the support of ONR MURI N00014-10-10933 and DARPA MSEE FA 8650-11-1-7149.	Aksoy EE, 2011, INT J ROBOT RES, V30, P1229, DOI 10.1177/0278364911410459; Ali A, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P28, DOI 10.1109/EVENT.2001.938863; Bargi A., 2012, IEEE COMP SOC C COMP, P1; Bishop Ch.M., 2006, PATTERN RECOGNIT MAC; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Delaitre V, 2012, LECT NOTES COMPUT SC, V7577, P284, DOI 10.1007/978-3-642-33783-3_21; Desai C, 2011, INT J COMPUT VISION, V95, P1, DOI 10.1007/s11263-011-0439-x; Fouhey DF, 2014, INT J COMPUT VISION, V110, P259, DOI 10.1007/s11263-014-0710-z; Furukawa Y, 2009, PROC CVPR IEEE, P1422, DOI 10.1109/CVPRW.2009.5206867; Gall J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1969, DOI 10.1109/CVPR.2011.5995582; Gibson JJ., 1977, PERCEIVING ACTING KN, P67, DOI DOI 10.2307/1421838; Grabner H, 2011, PROC CVPR IEEE, P1529, DOI 10.1109/CVPR.2011.5995327; Gupta A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1961, DOI 10.1109/CVPR.2011.5995448; Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83; Kim VG, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601117; Kjellstrom H, 2011, COMPUT VIS IMAGE UND, V115, P81, DOI 10.1016/j.cviu.2010.08.002; Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446; Lai KV, 2012, IEEE INT CONF ROBOT, P1330, DOI 10.1109/ICRA.2012.6225316; Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273; Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359; Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557; Minh Hoai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3265, DOI 10.1109/CVPR.2011.5995470; Moore D. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P80, DOI 10.1109/ICCV.1999.791201; Mualler M., 2006, P 2006 ACM SIGGRAPH, P137; Murphy K, 2006, LECT NOTES COMPUT SC, V4170, P382; Ng AY, 2002, ADV NEUR IN, V14, P849; Norman D., 1988, DESIGN EVERYDAY THIN; Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007; Packer B, 2012, PROC CVPR IEEE, P1378, DOI 10.1109/CVPR.2012.6247824; Pei MT, 2013, COMPUT VIS IMAGE UND, V117, P1369, DOI 10.1016/j.cviu.2012.12.003; Platt JC, 2000, ADV NEUR IN, P61; Prest A., 2011, RT0411; Prest A, 2012, IEEE T PATTERN ANAL, V34, P601, DOI 10.1109/TPAMI.2011.158; Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986; Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806; Sahin E, 2007, ADAPT BEHAV, V15, P447, DOI 10.1177/1059712307084689; Shi QF, 2011, INT J COMPUT VISION, V93, P22, DOI 10.1007/s11263-010-0384-0; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Steedman M., 2002, P 24 ANN M COGN SCI, P834; Stoffregen TA, 2003, ECOL PSYCHOL, V15, P115, DOI 10.1207/S15326969ECO1502_2; Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591; Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808; Tillmann C, 2003, COMPUT LINGUIST, V29, P97, DOI 10.1162/089120103321337458; Turvey M. T., 1992, Ecological Psychology, V4, P173, DOI 10.1207/s15326969eco0403_3; Vo NN, 2014, PROC CVPR IEEE, P2641, DOI 10.1109/CVPR.2014.338; Wang J., 2012, P AS C MACH LEARN, P491; Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180; Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198; Wei P, 2013, IEEE I CONF COMP VIS, P3272, DOI 10.1109/ICCV.2013.406; Wei P, 2013, IEEE I CONF COMP VIS, P3136, DOI 10.1109/ICCV.2013.389; Worgotter F, 2013, IEEE T AUTON MENT DE, V5, P117, DOI 10.1109/TAMD.2012.2232291; Wu J, 2007, PROCEEDINGS OF THE 2007 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATIONS AND LOGISTICS, AND INFORMATICS, P7, DOI 10.1109/SOLI.2007.4383891; Yang L, 2013, INT J COMPUT VISION, V105, P1, DOI 10.1007/s11263-013-0629-9; Yang YZ, 2013, PROC CVPR IEEE, P2563, DOI 10.1109/CVPR.2013.331; Yao BP, 2012, IEEE T PATTERN ANAL, V34, P1691, DOI 10.1109/TPAMI.2012.67; Yao BZ, 2014, IEEE T PATTERN ANAL, V36, P436, DOI 10.1109/TPAMI.2013.144; Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPR.2009.5206671, 10.1109/CVPRW.2009.5206671]; Zhao YB, 2013, PROC CVPR IEEE, P3119, DOI 10.1109/CVPR.2013.401; Zheng B, 2013, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2013.402; Zhou F, 2013, IEEE T PATTERN ANAL, V35, P582, DOI 10.1109/TPAMI.2012.137; Zhu SC, 2006, FOUND TRENDS COMPUT, V2, P259, DOI 10.1561/0600000018	63	34	35	4	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2017	39	6					1165	1179		10.1109/TPAMI.2016.2574712	http://dx.doi.org/10.1109/TPAMI.2016.2574712			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	EU5RR	27254859				2022-12-18	WOS:000401091200009
J	Akhtar, N; Shafait, F; Mian, A				Akhtar, Naveed; Shafait, Faisal; Mian, Ajmal			Discriminative Bayesian Dictionary Learning for Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian sparse representation; discriminative dictionary learning; supervised learning; classification	FACE RECOGNITION; K-SVD; SPARSE REPRESENTATION; ALGORITHM	We propose a Bayesian approach to learn discriminative dictionaries for sparse representation of data. The proposed approach infers probability distributions over the atoms of a discriminative dictionary using a finite approximation of Beta Process. It also computes sets of Bernoulli distributions that associate class labels to the learned dictionary atoms. This association signifies the selection probabilities of the dictionary atoms in the expansion of class-specific data. Furthermore, the non-parametric character of the proposed approach allows it to infer the correct size of the dictionary. We exploit the aforementioned Bernoulli distributions in separately learning a linear classifier. The classifier uses the same hierarchical Bayesian model as the dictionary, which we present along the analytical inference solution for Gibbs sampling. For classification, a test instance is first sparsely encoded over the learned dictionary and the codes are fed to the classifier. We performed experiments for face and action recognition; and object and scene-category classification using five public datasets and compared the results with state-of-the-art discriminative sparse representation approaches. Experiments show that the proposed Bayesian approach consistently outperforms the existing approaches.	[Akhtar, Naveed; Mian, Ajmal] Univ Western Australia, Sch Comp Sci & Software Engn, 35 Stirling Highway, Crawley, WA 6009, Australia; [Shafait, Faisal] Natl Univ Sci & Technol, Sch Elect Engn & Comp Sci, Islamabad, Pakistan	University of Western Australia; National University of Sciences & Technology - Pakistan	Akhtar, N (corresponding author), Univ Western Australia, Sch Comp Sci & Software Engn, 35 Stirling Highway, Crawley, WA 6009, Australia.	navid.915@gmail.com; faisal.shafait@uwa.edu.au; ajmal.mian@uwa.edu.au	AKHTAR, NAVEED/AAT-1283-2020	AKHTAR, NAVEED/0000-0003-3406-673X; Mian, Ajmal/0000-0002-5206-3842	ARC [DP110102399]	ARC(Australian Research Council)	This research was supported by ARC Grant DP110102399.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Akhtar N, 2015, PROC CVPR IEEE, P3631, DOI 10.1109/CVPR.2015.7298986; Akhtar N, 2015, IEEE T GEOSCI REMOTE, V53, P2157, DOI 10.1109/TGRS.2014.2356556; Akhtar N, 2014, LECT NOTES COMPUT SC, V8695, P63, DOI 10.1007/978-3-319-10584-0_5; Andrews R, 2014, ROUT ST PUBL MANAGE, V15, P47; Beal M.J, 2003, THESIS; Bishop C.M, 2006, PATTERN RECOGN; Bobin J, 2007, IEEE T IMAGE PROCESS, V16, P2675, DOI 10.1109/TIP.2007.907073; Bryt O, 2008, J VIS COMMUN IMAGE R, V19, P270, DOI 10.1016/j.jvcir.2008.03.001; Cai TT, 2011, IEEE T INFORM THEORY, V57, P4680, DOI 10.1109/TIT.2011.2146090; Candes E.J., 2006, P INT C MATHEMATICIA, P1433, DOI DOI 10.4171/022-3/69; Castrodad A, 2012, INT J COMPUT VISION, V100, P1, DOI 10.1007/s11263-012-0534-7; COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354; Damianou Andreas C, 2012, P INT C MACH LEARN, P145; Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Elad M., 2008, CS200808 TECHN; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1; Engan K, 1999, INT CONF ACOUST SPEE, P2443, DOI 10.1109/ICASSP.1999.760624; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Golub GH, 1999, SIAM J MATRIX ANAL A, V21, P185, DOI 10.1137/S0895479897326432; Griffin Gregory, 2007, CALTECH 256 OBJECT C; Guha T, 2012, IEEE T PATTERN ANAL, V34, P1576, DOI 10.1109/TPAMI.2011.253; Huang K., 2006, ADV NEURAL INFORM PR, P609, DOI DOI 10.7551/MITPRESS/7503.001.0001; Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88; Jiang ZL, 2012, PROC CVPR IEEE, P3418, DOI 10.1109/CVPR.2012.6248082; Lazebnik S., 2007, P IEEE C COMP VIS PA, P2169; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Lian XC, 2010, LECT NOTES COMPUT SC, V6314, P157, DOI 10.1007/978-3-642-15561-1_12; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu CC, 2014, LECT NOTES COMPUT SC, V8692, P119, DOI 10.1007/978-3-319-10593-2_9; Mairal J., 2008, P IEEE C COMP VIS PA, V2, P1, DOI DOI 10.1109/CVPR.2008.4587652; Mairal J., 2009, ADV NEURAL INFORM PR, P1033; Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828; Mairal J, 2012, IEEE T PATTERN ANAL, V34, P791, DOI 10.1109/TPAMI.2011.156; Mairal J, 2010, J MACH LEARN RES, V11, P19; Mallat S., 1999, WAVELET TOUR SIGNAL, DOI 10.1016/B978-012466606-1/50008-8; MARTINEZ AM, 1998, 24 PURD U COMP VIS C; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Paisley J, 2009, P 26 ANN INT C MACH, P777, DOI [10.1145/1553374.1553474, DOI 10.1145/1553374.1553474]; PHAM D.-S., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587408; Qiu Q, 2011, IEEE I CONF COMP VIS, P707, DOI 10.1109/ICCV.2011.6126307; Ramirez I, 2010, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR.2010.5539964; Rodriguez F., 2007, TECH REP; Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727; Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806; Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899; Shen L, 2013, PROC CVPR IEEE, P383, DOI 10.1109/CVPR.2013.56; Sprechmann P, 2010, INT CONF ACOUST SPEE, P2042, DOI 10.1109/ICASSP.2010.5494985; Sun YB, 2014, IEEE T IMAGE PROCESS, V23, P3816, DOI 10.1109/TIP.2014.2331760; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tropp JA, 2006, SIGNAL PROCESS, V86, P572, DOI 10.1016/j.sigpro.2005.05.030; Wang DH, 2014, PATTERN RECOGN, V47, P885, DOI 10.1016/j.patcog.2013.08.004; Wang HR, 2012, PATTERN RECOGN, V45, P3902, DOI 10.1016/j.patcog.2012.04.024; WANG JJ, 2010, PROC CVPR IEEE, P3360, DOI DOI 10.1109/CVPR.2010.5540018; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Wu YN, 2010, INT J COMPUT VISION, V90, P198, DOI 10.1007/s11263-009-0287-0; Yang JC, 2010, PROC CVPR IEEE, P3517, DOI 10.1109/CVPR.2010.5539958; Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757; Yang M, 2014, PROC CVPR IEEE, P4138, DOI 10.1109/CVPR.2014.527; Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8; Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393; Yang M, 2010, LECT NOTES COMPUT SC, V6316, P448, DOI 10.1007/978-3-642-15567-3_33; Yang M, 2010, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2010.5652363; Zhang H, 2006, 2006 IEEE COMP SOC C, P2126, DOI [10.1109/CVPR.2006.301, DOI 10.1109/CVPR.2006.301]; Zhang Q.Z.Q., 2010, PROC CVPR IEEE, DOI [10.1109/CVPR.2010.5539989, DOI 10.1109/CVPR.2010.5539989]; Zhou M, 2009, ADV NEURAL INFORM PR, P2295; Zhou N, 2012, PROC CVPR IEEE, P3490, DOI 10.1109/CVPR.2012.6248091	71	34	34	1	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2016	38	12					2374	2388		10.1109/TPAMI.2016.2527652	http://dx.doi.org/10.1109/TPAMI.2016.2527652			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EC2WJ	26886965	Green Submitted			2022-12-18	WOS:000387984700003
J	Aldoma, A; Tombari, F; Di Stefano, L; Vincze, M				Aldoma, Aitor; Tombari, Federico; Di Stefano, Luigi; Vincze, Markus			A Global Hypothesis Verification Framework for 3D Object Recognition in Clutter	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	27th IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 23-28, 2014	Columbus, OH	Comp Vis Fdn, IEEE, IEEE Comp Soc		3D object recognition; hypothesis verification; correspondence grouping; scene understanding	FEATURES; IMAGES	Pipelines to recognize 3D objects despite clutter and occlusions usually end up with a final verification stage whereby recognition hypotheses are validated or dismissed based on how well they explain sensor measurements. Unlike previous work, we propose a Global Hypothesis Verification (GHV) approach which regards all hypotheses jointly so as to account for mutual interactions. GHV provides a principled framework to tackle the complexity of our visual world by leveraging on a plurality of recognition paradigms and cues. Accordingly, we present a 3D object recognition pipeline deploying both global and local 3D features as well as shape and color. Thereby, and facilitated by the robustness of the verification process, diverse object hypotheses can be gathered and weak hypotheses need not be suppressed too early to trade sensitivity for specificity. Experiments demonstrate the effectiveness of our proposal, which significantly improves over the state-of-art and attains ideal performance (no false negatives, no false positives) on three out of the six most relevant and challenging benchmark datasets.	[Aldoma, Aitor; Vincze, Markus] Vienna Univ Technol, Grp ACIN Vision4Robot, A-1060 Vienna, Austria; [Tombari, Federico; Di Stefano, Luigi] Univ Bologna, CVLAB Grp DISI, Bologna, Italy	Technische Universitat Wien; University of Bologna	Aldoma, A (corresponding author), Vienna Univ Technol, Grp ACIN Vision4Robot, A-1060 Vienna, Austria.	aldoma@acin.tuwien.ac.at; federico.tombari@unibo.it; luigi.distefano@unibo.it; vincze@acin.tuwien.ac.at						Aldoma A, 2013, IEEE INT CONF ROBOT, P2104, DOI 10.1109/ICRA.2013.6630859; Aldoma Aitor, 2012, Pattern Recognition. Proceedings Joint 34th DAGM and 36th OAGM Symposium, P113, DOI 10.1007/978-3-642-32717-9_12; Aldoma A, 2012, LECT NOTES COMPUT SC, V7574, P511, DOI 10.1007/978-3-642-33712-3_37; Bariya P, 2012, INT J COMPUT VISION, V99, P232, DOI 10.1007/s11263-012-0526-7; Bariya P, 2010, PROC CVPR IEEE, P1657, DOI 10.1109/CVPR.2010.5539774; Drost Bertram, 2010, 2010 IEEE COMP SOC C, DOI DOI 10.1109/CVPR.2010.5540108; GLOVER F, 1986, COMPUT OPER RES, V13, P563, DOI 10.1016/0305-0548(86)90050-X; Glover J, 2013, IEEE INT C INT ROBOT, P2158, DOI 10.1109/IROS.2013.6696658; Gonzalez R. C., 2006, DIGITAL IMAGE PROCES; Guo YL, 2014, IEEE T PATTERN ANAL, V36, P2270, DOI 10.1109/TPAMI.2014.2316828; Hinterstoisser S., 2012, LNCS; Hinterstoisser S, 2012, IEEE T PATTERN ANAL, V34, P876, DOI 10.1109/TPAMI.2011.206; Holz D., 2012, ICRA WORKSH SEM PERC; Johnson AE, 1998, IMAGE VISION COMPUT, V16, P635, DOI 10.1016/S0262-8856(98)00074-2; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mian AS, 2006, IEEE T PATTERN ANAL, V28, P1584, DOI 10.1109/TPAMI.2006.213; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Papazov C, 2011, LECT NOTES COMPUT SC, V6492, P135, DOI 10.1007/978-3-642-19315-6_11; Papon J, 2013, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR.2013.264; Richtsfeld A, 2012, IEEE INT C INT ROBOT, P4791, DOI 10.1109/IROS.2012.6385661; Taati B, 2011, COMPUT VIS IMAGE UND, V115, P681, DOI 10.1016/j.cviu.2010.11.021; Tang J, 2012, IEEE INT CONF ROBOT, P3467, DOI 10.1109/ICRA.2012.6224891; Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26; Tomita E, 2006, THEOR COMPUT SCI, V363, P28, DOI 10.1016/j.tcs.2006.06.015; Ulrich M, 2012, IEEE T PATTERN ANAL, V34, P1902, DOI 10.1109/TPAMI.2011.266; Xie Z, 2013, IEEE INT C INT ROBOT, P2214, DOI 10.1109/IROS.2013.6696666	28	34	35	2	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2016	38	7					1383	1396		10.1109/TPAMI.2015.2491940	http://dx.doi.org/10.1109/TPAMI.2015.2491940			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	DO6MH	26485476				2022-12-18	WOS:000377897100009
J	Ngo, DT; Ostlund, J; Fua, P				Dat Tien Ngo; Oestlund, Jonas; Fua, Pascal			Template-Based Monocular 3D Shape Recovery Using Laplacian Meshes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deformable surfaces; monocular shape recovery; Laplacian formalism		We show that by extending the Laplacian formalism, which was first introduced in the Graphics community to regularize 3D meshes, we can turn the monocular 3D shape reconstruction of a deformable surface given correspondences with a reference image into a much better-posed problem. This allows us to quickly and reliably eliminate outliers by simply solving a linear least squares problem. This yields an initial 3D shape estimate, which is not necessarily accurate, but whose 2D projections are. The initial shape is then refined by a constrained optimization problem to output the final surface reconstruction. Our approach allows us to reduce the dimensionality of the surface reconstruction problem without sacrificing accuracy, thus allowing for real-time implementations.	[Dat Tien Ngo; Oestlund, Jonas; Fua, Pascal] Ecole Polytech Fed Lausanne, CH-1015 Lausanne, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Ngo, DT (corresponding author), Ecole Polytech Fed Lausanne, CH-1015 Lausanne, Switzerland.	dat.ngo@epfl.ch; jonas.ostlund@epfl.ch; pascal.fua@epfl.ch		Fua, Pascal/0000-0002-6702-9970	Swiss National Science Foundation	Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission)	This work was supported in part by the Swiss National Science Foundation. The authors wish to thank Prof. L. Smith and his team at Washington State University for the baseball data and the many discussions we had on this topic.	Alcantarilla PF, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.133; Bartoli A, 2012, PROC CVPR IEEE, P2026, DOI 10.1109/CVPR.2012.6247906; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Botsch M., 2006, VISION MODELING VISU, P357; Brunet F., 2010, P AS C COMP VIS, P433; Collins T, 2014, LECT NOTES COMPUT SC, V8692, P325, DOI 10.1007/978-3-319-10593-2_22; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Del Bue A, 2011, IEEE I CONF COMP VIS, P675, DOI 10.1109/ICCV.2011.6126303; Dimitrijevic M, 2004, PROC CVPR IEEE, P1034; Ecker A, 2008, LECT NOTES COMPUT SC, V5302, P127, DOI 10.1007/978-3-540-88682-2_11; Fayad J, 2010, LECT NOTES COMPUT SC, V6314, P297, DOI 10.1007/978-3-642-15561-1_22; Fua P., 2010, EPFLREPORT150790; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Garg R, 2013, PROC CVPR IEEE, P1272, DOI 10.1109/CVPR.2013.168; Gumerov N, 2004, LECT NOTES COMPUT SC, V3023, P482; Ilic S, 2002, LECT NOTES COMPUT SC, V2351, P704; Jacobson A., 2011, P ACM SIGGRAPH, P959; Liang J, 2005, PROC CVPR IEEE, P338; Lowe D., 2004, INT J COMPUT VISION, V20, P761; Malti A, 2013, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2013.200; Moreno-Noguer F, 2010, LECT NOTES COMPUT SC, V6313, P370; Moreno-Noguer F, 2009, PROC CVPR IEEE, P1842, DOI 10.1109/CVPRW.2009.5206758; Ostlund J, 2012, LECT NOTES COMPUT SC, V7574, P412, DOI 10.1007/978-3-642-33712-3_30; Ozuysal M, 2010, IEEE T PATTERN ANAL, V32, P448, DOI 10.1109/TPAMI.2009.23; Perriollat M, 2013, COMPUT ANIMAT VIRT W, V24, P457, DOI 10.1002/cav.1478; Perriollat M, 2011, INT J COMPUT VISION, V95, P124, DOI 10.1007/s11263-010-0352-8; Pilet J, 2008, INT J COMPUT VISION, V76, P109, DOI 10.1007/s11263-006-0017-9; Pizarro D, 2012, INT J COMPUT VISION, V97, P54, DOI 10.1007/s11263-011-0452-0; Tran QH, 2012, LECT NOTES COMPUT SC, V7575, P274, DOI 10.1007/978-3-642-33765-9_20; Russell C., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3009, DOI 10.1109/CVPR.2011.5995383; Salzmann M., 2010, DEFORMABLE SURFACE 3; Salzmann M, 2008, LECT NOTES COMPUT SC, V5305, P581, DOI 10.1007/978-3-540-88693-8_43; Salzmann M, 2007, IEEE I CONF COMP VIS, P1578; Salzmann M, 2011, IEEE T PATTERN ANAL, V33, P931, DOI 10.1109/TPAMI.2010.158; Shen S., 2009, P AS C COMP VIS, P36; Sorkine Olga., 2004, P EUR ACM SIGGRAPH S, P175; Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; WHITE R, 2006, COMPUTER VISION PATT, V2, P1809; Zhu, 2007, P C COMP VIS PATT RE, P1	40	34	34	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2016	38	1					172	187		10.1109/TPAMI.2015.2435739	http://dx.doi.org/10.1109/TPAMI.2015.2435739			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CY8OW	26656585	Green Submitted			2022-12-18	WOS:000366669200013
J	Ouyang, WL; Zeng, XY; Wang, XG				Ouyang, Wanli; Zeng, Xingyu; Wang, Xiaogang			Single-Pedestrian Detection Aided by Two-Pedestrian Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Part based model; discriminative model; pedestrian detection; object detection; human detection; contextual information	PARTIALLY OCCLUDED HUMANS; OBJECT DETECTION; BAYESIAN COMBINATION; PICTORIAL STRUCTURES; HISTOGRAMS; MULTIPLE; CONTEXT; MODEL	In this paper, we address the challenging problem of detecting pedestrians who appear in groups. A new approach is proposed for single-pedestrian detection aided by two-pedestrian detection. A mixture model of two-pedestrian detectors is designed to capture the unique visual cues which are formed by nearby pedestrians but cannot be captured by single-pedestrian detectors. A probabilistic framework is proposed to model the relationship between the configurations estimated by single-and two-pedestrian detectors, and to refine the single-pedestrian detection result using two-pedestrian detection. The two-pedestrian detector can integrate with any single-pedestrian detector. Twenty-five state-of-the-art single-pedestrian detection approaches are combined with the two-pedestrian detector on three widely used public datasets: Caltech, TUD-Brussels, and ETH. Experimental results show that our framework improves all these approaches. The average improvement is 9 percent on the Caltech-Test dataset, 11 percent on the TUD-Brussels dataset and 17 percent on the ETH dataset in terms of average miss rate. The lowest average miss rate is reduced from 37 to 32 percent on the Caltech-Test dataset, from 55 to 50 percent on the TUD-Brussels dataset and from 43 to 38 percent on the ETH dataset.	[Ouyang, Wanli; Zeng, Xingyu; Wang, Xiaogang] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China	Chinese University of Hong Kong	Ouyang, WL (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.	wlouyang@ee.cuhk.edu.hk; xyzeng@ee.cuhk.edu.hk; xgwang@ee.cuhk.edu.hk	Ouyang, Wanli/I-7135-2018	Ouyang, Wanli/0000-0002-9163-2761	Research Grants Council of Hong Kong [CUHK 417011, CUHK 419412]; Shenzhen Basic Research Program [JCYJ20130402113127496]; Guangdong Innovative Research Team Program [201001D0104648280]	Research Grants Council of Hong Kong(Hong Kong Research Grants Council); Shenzhen Basic Research Program; Guangdong Innovative Research Team Program	The authors would like to thank anonymous reviewers for their constructive comments, Siyu Tang and Bernt Schiele from the Max Planck Institut Informatik for providing their source code and constructive comments. This work was supported by the General Research Fund sponsored by the Research Grants Council of Hong Kong (Project No. CUHK 417011 and CUHK 419412), Shenzhen Basic Research Program (JCYJ20130402113127496) and Guangdong Innovative Research Team Program (No. 201001D0104648280).	Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754; [Anonymous], IEEE C COMP VIS PATT; Bar-Hillel A, 2010, LECT NOTES COMPUT SC, V6314, P127, DOI 10.1007/978-3-642-15561-1_10; Barinova O, 2010, PROC CVPR IEEE, P2233, DOI 10.1109/CVPR.2010.5539905; Benenson R, 2013, PROC CVPR IEEE, P3666, DOI 10.1109/CVPR.2013.470; Bergtholdt Martin, 2010, International Journal of Computer Vision, V87, P93, DOI 10.1007/s11263-009-0209-1; Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/cvpr.2008.4587586; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Bourdev L, 2010, LECT NOTES COMPUT SC, V6316, P168, DOI 10.1007/978-3-642-15567-3_13; Chen G, 2013, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2013.235; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33; Dean T, 2013, PROC CVPR IEEE, P1814, DOI 10.1109/CVPR.2013.237; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Desai C, 2012, LECT NOTES COMPUT SC, V7575, P158, DOI 10.1007/978-3-642-33765-9_12; Desai C, 2009, IEEE I CONF COMP VIS, P229, DOI 10.1109/ICCV.2009.5459256; Ding YY, 2012, PROC CVPR IEEE, P2895, DOI 10.1109/CVPR.2012.6248016; Divvala SK, 2009, PROC CVPR IEEE, P1271, DOI 10.1109/CVPRW.2009.5206532; Dollar P, 2009, BRIT MACHINE VISION, DOI [10.5244/C.23.91, DOI 10.5244/C.23.91]; Dollar P., 2010, P BRIT MACH VIS C, DOI [10.5244/C.24.68, DOI 10.5244/C.24.68]; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Dollar P, 2012, LECT NOTES COMPUT SC, V7573, P645, DOI 10.1007/978-3-642-33709-3_46; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Enzweiler M, 2011, IEEE T IMAGE PROCESS, V20, P2967, DOI 10.1109/TIP.2011.2142006; Enzweiler M, 2010, PROC CVPR IEEE, P990, DOI 10.1109/CVPR.2010.5540111; Enzweiler M, 2010, PROC CVPR IEEE, P982, DOI 10.1109/CVPR.2010.5540110; Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260; Ess A, 2007, IEEE I CONF COMP VIS, P2065; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Galleguillos C, 2010, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2010.5540223; Gavrila DM, 1998, INT C PATT RECOG, P439, DOI 10.1109/ICPR.1998.711175; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Geronimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122; Girshick R., 2011, ADV NEURAL INFORM PR, V24, P442; Hare AP, 1962, HDB SMALL GROUP RES; Hoiem D., 2008, P IEEE C COMP VIS PA, V80, P2137; Leibe B, 2005, PROC CVPR IEEE, P878; Leibe B., 2004, EUROPEAN C COMPUTER, P17; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Li CC, 2011, IEEE I CONF COMP VIS, P511, DOI 10.1109/ICCV.2011.6126282; Li HS, 2014, IEEE T PATTERN ANAL, V36, P2407, DOI 10.1109/TPAMI.2014.2324568; Lin Z, 2008, LECT NOTES COMPUT SC, V5305, P423, DOI 10.1007/978-3-540-88693-8_31; Lin Z, 2007, IEEE I CONF COMP VIS, P2301; Luo P, 2014, PROC CVPR IEEE, P899, DOI 10.1109/CVPR.2014.120; Maji Subhransu, 2008, CVPR, DOI DOI 10.1109/CVPR.2008.4587630; Meng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3401, DOI 10.1109/CVPR.2011.5995698; Mikolajczyk K., 2006, P CVPR, V1, P26, DOI DOI 10.1109/CVPR.2006.202]; Moussaid M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010047; Munder S, 2006, IEEE T PATTERN ANAL, V28, P1863, DOI 10.1109/TPAMI.2006.217; Ng AY, 2002, ADV NEUR IN, V14, P849; Norouzi M, 2009, PROC CVPR IEEE, P2727; Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009; Ouyang W., 2014, ARXIV14093505; Ouyang WL, 2014, PROC CVPR IEEE, pCP32, DOI 10.1109/CVPR.2014.299; Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257; Ouyang WL, 2013, PROC CVPR IEEE, P3222, DOI 10.1109/CVPR.2013.414; Ouyang WL, 2012, PROC CVPR IEEE, P3258, DOI 10.1109/CVPR.2012.6248062; Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689; Park D, 2013, PROC CVPR IEEE, P2882, DOI 10.1109/CVPR.2013.371; Park D, 2010, LECT NOTES COMPUT SC, V6314, P241, DOI 10.1007/978-3-642-15561-1_18; Pedersoli M, 2011, PROC CVPR IEEE, P1353, DOI 10.1109/CVPR.2011.5995668; Pepik B, 2013, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2013.422; Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188; Sabzmeydani P, 2007, PROC CVPR IEEE, P1251; Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711; Schwartz WR, 2009, IEEE I CONF COMP VIS, P24, DOI 10.1109/ICCV.2009.5459205; Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465; Shet V.D., 2007, P IEEE C COMP VIS PA, P1; Song Z, 2011, PROC CVPR IEEE, P1585, DOI 10.1109/CVPR.2011.5995330; Sun M, 2011, IEEE I CONF COMP VIS, P723, DOI 10.1109/ICCV.2011.6126309; Tang SY, 2013, IEEE I CONF COMP VIS, P1049, DOI 10.1109/ICCV.2013.134; Tang SY, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.9; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183; Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Walk S, 2010, PROC CVPR IEEE, P1030, DOI 10.1109/CVPR.2010.5540102; Wang M, 2012, PROC CVPR IEEE, P3274, DOI 10.1109/CVPR.2012.6248064; Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207; Wang Y, 2011, PROC CVPR IEEE, P1705, DOI 10.1109/CVPR.2011.5995519; Wojek C, 2008, LECT NOTES COMPUT SC, V5096, P82, DOI 10.1007/978-3-540-69321-5_9; Wojek C, 2009, PROC CVPR IEEE, P794, DOI 10.1109/CVPRW.2009.5206638; Wu B, 2005, IEEE I CONF COMP VIS, P90; Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7; Wu B, 2009, INT J COMPUT VISION, V82, P185, DOI 10.1007/s11263-008-0194-9; Yan JJ, 2014, PROC CVPR IEEE, P2497, DOI 10.1109/CVPR.2014.320; Yan JJ, 2013, PROC CVPR IEEE, P3033, DOI 10.1109/CVPR.2013.390; Yan JJ, 2012, PROC CVPR IEEE, P3124, DOI 10.1109/CVPR.2012.6248045; Yang Y, 2012, PROC CVPR IEEE, P3522, DOI 10.1109/CVPR.2012.6248095; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Yao BP, 2010, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2010.5540235; Zeng XY, 2013, IEEE I CONF COMP VIS, P121, DOI 10.1109/ICCV.2013.22; Zeng XY, 2014, LECT NOTES COMPUT SC, V8691, P472, DOI 10.1007/978-3-319-10578-9_31; Zhu L, 2010, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2010.5540096; Zhu Qiang, 2006, CVPR, DOI DOI 10.1109/CVPR.2006.119	97	34	35	4	63	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2015	37	9					1875	1889		10.1109/TPAMI.2014.2377734	http://dx.doi.org/10.1109/TPAMI.2014.2377734			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CO5RQ	26353133				2022-12-18	WOS:000359216600011
J	Flusser, J; Suk, T; Boldys, J; Zitova, B				Flusser, Jan F; Suk, Tomas; Boldys, Jiri; Zitova, Barbara			Projection Operators and Moment Invariants to Image Blurring	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Blurred image; N-fold rotation symmetry; projection operators; image moments; moment invariants; blur invariants; object recognition	PATTERN-RECOGNITION; MOTION BLUR; REGISTRATION; ROTATION; CONVOLUTION; SIMILARITY; SIGNALS; POINTS	In this paper we introduce a new theory of blur invariants. Blur invariants are image features which preserve their values if the image is convolved by a point-spread function (PSF) of a certain class. We present the invariants to convolution with an arbitrary N-fold symmetric PSF, both in Fourier and image domain. We introduce a notion of a primordial image as a canonical form of all blur-equivalent images. It is defined in spectral domain by means of projection operators. We prove that the moments of the primordial image are invariant to blur and we derive recursive formulae for their direct computation without actually constructing the primordial image. We further prove they form a complete set of invariants and show how to extent their invariance also to translation, rotation and scaling. We illustrate by simulated and real-data experiments their invariance and recognition power. Potential applications of this method are wherever one wants to recognize objects on blurred images.	[Flusser, Jan F; Suk, Tomas; Boldys, Jiri; Zitova, Barbara] Acad Sci Czech Republ, Inst Informat Theory & Automat, CR-18208 Prague 8, Czech Republic	Czech Academy of Sciences; Institute of Information Theory & Automation of the Czech Academy of Sciences	Flusser, J (corresponding author), Acad Sci Czech Republ, Inst Informat Theory & Automat, Pod Vodarenskou Vezi 4, CR-18208 Prague 8, Czech Republic.	flusser@utia.cas.cz; suk@utia.cas.cz; boldys@centrum.cz; zitova@utia.cas.cz	Zitova, Barbara/H-1871-2014; Flusser, Jan/F-6209-2014	Flusser, Jan/0000-0003-3747-9214	Czech Science Foundation [P103/11/1552, GA13-29225S]	Czech Science Foundation(Grant Agency of the Czech Republic)	The authors express their gratitude to the Czech Science Foundation for financial support of this work under the grants No. P103/11/1552 and GA13-29225S. They also would like to thank Dr. Filip Sroubek for providing the test images for the experiment with registration, Dr. Jaroslav Kautsky for his advice concerning numerical implementation of moments, Matteo Pedone for the discussion about matching accuracy evaluation, and a former Ph.D student Michal Breznicky for discussion and suggestions regarding projection operators.	[Anonymous], 2011, 2011 8 INT C INF COM, DOI DOI 10.1109/ICICS.2011.6174265; Bentoutou Y, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P419, DOI 10.1109/ICDSP.2007.4288608; Bentoutou Y, 2005, IEEE T GEOSCI REMOTE, V43, P2127, DOI 10.1109/TGRS.2005.853187; Bentoutou Y, 2005, IEEE T NUCL SCI, V52, P238, DOI 10.1109/TNS.2004.843120; Bentoutou Y, 2005, COMPUT VIS IMAGE UND, V97, P30, DOI 10.1016/j.cviu.2004.07.002; Bentoutou Y, 2002, PATTERN RECOGN, V35, P2853, DOI 10.1016/S0031-3203(02)00016-X; Boldys J, 2008, J MATH IMAGING VIS, V32, P227, DOI 10.1007/s10851-008-0091-4; Campisi P., 2007, BLIND IMAGE DECONVOL; Candocia FM, 2004, PATTERN RECOGN LETT, V25, P437, DOI 10.1016/j.patrec.2003.11.006; Chen BJ, 2011, IEEE T IMAGE PROCESS, V20, P345, DOI 10.1109/TIP.2010.2062195; Chen GS, 2012, SENSOR ACTUAT A-PHYS, V176, P27, DOI 10.1016/j.sna.2011.12.056; DECASTRO E, 1987, IEEE T PATTERN ANAL, V9, P700, DOI 10.1109/TPAMI.1987.4767966; Flusser J, 1996, IEEE T IMAGE PROCESS, V5, P533, DOI 10.1109/83.491327; FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H; FLUSSER J, 1995, PATTERN RECOGN, V28, P1723, DOI 10.1016/0031-3203(95)00034-W; Flusser J, 2004, INT C PATT RECOG, P11, DOI 10.1109/ICPR.2004.1333967; Flusser J, 2003, IEEE T PATTERN ANAL, V25, P234, DOI 10.1109/TPAMI.2003.1177154; Flusser J., 1999, IEEE 1999 International Geoscience and Remote Sensing Symposium. IGARSS'99 (Cat. No.99CH36293), P1262, DOI 10.1109/IGARSS.1999.774598; Flusser J, 1998, IEEE T PATTERN ANAL, V20, P590, DOI 10.1109/34.683773; Flusser J, 2000, J MATH IMAGING VIS, V13, P101, DOI 10.1023/A:1026519929823; Flusser J, 1999, INT J PATTERN RECOGN, V13, P1123, DOI 10.1142/S021800149900063X; Flusser J., 2009, MOMENTS MOMENT INVAR; Flusser J., 2014, BIOSYST ENG, V110, P198; FLUSSER J, 1996, COMP SUPPL, V11, P37; Flusser J, 2006, IEEE T IMAGE PROCESS, V15, P3784, DOI 10.1109/TIP.2006.884913; Flusser J, 2013, SENSOR ACTUAT A-PHYS, V198, P113, DOI 10.1016/j.sna.2013.04.035; Galigekere RR, 2006, OPT ENG, V45, DOI 10.1117/1.2222245; Gopalan R, 2012, IEEE T PATTERN ANAL, V34, P1220, DOI 10.1109/TPAMI.2012.15; Guan BQ, 2005, PATTERN RECOGN LETT, V26, P2450, DOI 10.1016/j.patrec.2005.05.002; Hilbert D., 1993, THEORY ALGEBRAIC INV; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Hu SX, 2007, INT C WAVEL ANAL PAT, P376, DOI 10.1109/ICWAPR.2007.4420697; Ji H., 2008, IEEE C COMP VIS PATT, P1; Ji HJ, 2009, INT CONF ACOUST SPEE, P1941, DOI 10.1109/ICASSP.2009.4959990; Jiming L., 2012, ADV INFORM SCI SERV, V4, P116; Kadir A., 2011, SIGNAL IMAGE PROCESS, V2, P1; Kautsky J, 2011, IEEE T IMAGE PROCESS, V20, P3606, DOI 10.1109/TIP.2011.2159235; Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36; Li LB, 2008, LECT NOTES COMPUT SC, V5227, P90; Li LB, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 3, PROCEEDINGS, P515, DOI 10.1109/ICNC.2008.326; Li Y., 2003, SPIE, V5253; Liu J, 2005, PATTERN RECOGN LETT, V26, P1128, DOI 10.1016/j.patrec.2004.10.007; Liu ZX, 2011, INT J REMOTE SENS, V32, P3649, DOI 10.1080/01431161003762371; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu JY, 1999, IEICE T FUND ELECTR, VE82A, P1450; Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002; Mahdian B, 2007, ADV INTEL SOFT COMPU, V45, P187; Makaremi I, 2012, IEEE T IMAGE PROCESS, V21, P996, DOI 10.1109/TIP.2011.2168415; Makaremi I, 2010, PATTERN RECOGN, V43, P3950, DOI 10.1016/j.patcog.2010.07.020; Novotny P, 2013, BIOSYST ENG, V115, P444, DOI 10.1016/j.biosystemseng.2013.04.007; Ojansivu V., 2009, THESIS OULU U OULU; Ojansivu V, 2008, LECT NOTES COMPUT SC, V5112, P527, DOI 10.1007/978-3-540-69812-8_52; Ojansivu V, 2007, IEEE SIGNAL PROC LET, V14, P449, DOI 10.1109/LSP.2006.891338; Palaniappan R., 2010, P INT POSTGR C ENG O; Pauwels EJ, 2009, ENG APPL ARTIF INTEL, V22, P26, DOI 10.1016/j.engappai.2008.04.017; Pedone M, 2013, IEEE T IMAGE PROCESS, V22, P3676, DOI 10.1109/TIP.2013.2268972; Peng Z, 2011, BIOSYST ENG, V110, P198, DOI 10.1016/j.biosystemseng.2011.08.003; Qian Li, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P1517, DOI 10.1109/CISP.2011.6100441; REISS TH, 1991, IEEE T PATTERN ANAL, V13, P830, DOI 10.1109/34.85675; Shen XJ, 2004, IEICE T FUND ELECTR, VE87A, P1798; Sroubek F, 2005, IEEE T IMAGE PROCESS, V14, P874, DOI 10.1109/TIP.2005.849322; Stern A, 2002, APPL OPTICS, V41, P2164, DOI 10.1364/AO.41.002164; Suk T, 2003, PATTERN RECOGN, V36, P2895, DOI 10.1016/S0031-3203(03)00187-0; Suk T, 2012, PATTERN RECOGN, V45, P4279, DOI 10.1016/j.patcog.2012.05.012; Tang SY, 2007, 2007 IEEE/ICME INTERNATIONAL CONFERENCE ON COMPLEX MEDICAL ENGINEERING, VOLS 1-4, P1715, DOI 10.1109/ICCME.2007.4382041; Wang SG, 2007, PATTERN RECOGN LETT, V28, P1029, DOI 10.1016/j.patrec.2006.12.019; Wang XF, 2008, APPL MATH COMPUT, V205, P916, DOI 10.1016/j.amc.2008.05.108; Wee CY, 2007, IET COMPUT VIS, V1, P66, DOI 10.1049/iet-cvi:20070016; Xiao B, 2012, PATTERN RECOGN, V45, P314, DOI 10.1016/j.patcog.2011.06.017; Xiubin Dai, 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology (PSIVT), P300, DOI 10.1109/PSIVT.2010.57; Xiubin Dai, 2010, Proceedings of the 2010 International Conference on Information and Automation (ICIA 2010), P1793, DOI 10.1109/ICINFA.2010.5512207; Yani Zhang, 2000, FLAIRS-2000. Proceedings of the Thirteenth International Florida Artificial Intelligence Research Society Conference, P76; Yuefang Gao, 2007, 2007 1st International Conference on Bioinformatics and Biomedical Engineering, P531; Zhang H, 2010, IEEE T IMAGE PROCESS, V19, P596, DOI 10.1109/TIP.2009.2036702; Zhang Y, 2000, IMAGE VISION COMPUT, V18, P959, DOI 10.1016/S0262-8856(00)00038-X; Zhang YI, 2002, PATTERN RECOGN, V35, P211, DOI 10.1016/S0031-3203(01)00018-8; Zhang YN, 2000, PATTERN RECOGN LETT, V21, P425, DOI 10.1016/S0167-8655(00)00014-3; Zhang ZW, 2013, IEEE T IMAGE PROCESS, V22, P3145, DOI 10.1109/TIP.2013.2259840; Zhao P., 2011, REV SCI INSTRUM, V82, P1; Zhong SH, 2013, IEEE T IMAGE PROCESS, V22, P4301, DOI 10.1109/TIP.2013.2271851; Zhu HQ, 2010, PATTERN ANAL APPL, V13, P309, DOI 10.1007/s10044-009-0159-9; Zitova B, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P329; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9; Zitova B, 1999, PATTERN RECOGN LETT, V20, P199, DOI 10.1016/S0167-8655(98)00135-4; Zitova B., 2000, INVARIANTS PATTERN R, P23; Zuo X., 2010, P 3 INT C MACH VIS, P183	87	34	38	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2015	37	4					786	802		10.1109/TPAMI.2014.2353644	http://dx.doi.org/10.1109/TPAMI.2014.2353644			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CD6QF	26353294				2022-12-18	WOS:000351213400007
J	Hensman, J; Rattray, M; Lawrence, ND				Hensman, James; Rattray, Magnus; Lawrence, Neil D.			Fast Nonparametric Clustering of Structured Time-Series	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Variational Bayes; Gaussian processes; structured time series; gene expression	GENE-EXPRESSION; VARIATIONAL INFERENCE; MODELS	In this publication, we combine two Bayesian nonparametric models: the Gaussian Process (GP) and the Dirichlet Process (DP). Our innovation in the GP model is to introduce a variation on the GP prior which enables us to model structured time-series data, i.e., data containing groups where we wish to model inter-and intra-group variability. Our innovation in the DP model is an implementation of a new fast collapsed variational inference procedure which enables us to optimize our variational approximation significantly faster than standard VB approaches. In a biological time series application we show how our model better captures salient features of the data, leading to better consistency with existing biological classifications, while the associated inference algorithm provides a significant speed-up over EM-based variational inference.	[Hensman, James; Lawrence, Neil D.] Univ Sheffield, Dept Comp Sci, Sheffield S10 2TN, S Yorkshire, England; [Hensman, James; Lawrence, Neil D.] Univ Sheffield, Sheffield Inst Translat Neurosci, Sheffield S10 2TN, S Yorkshire, England; [Rattray, Magnus] Univ Manchester, Fac Life Sci, Manchester, Lancs, England	University of Sheffield; University of Sheffield; University of Manchester	Hensman, J (corresponding author), Univ Sheffield, Dept Comp Sci, Sheffield S10 2TN, S Yorkshire, England.	james.hensman@sheffield.ac.uk; magnus.rattray@manchester.ac.uk; n.lawrence@sheffield.ac.uk	Rattray, Magnus/B-4393-2009; Rattray, Magnus/AAE-3297-2021	Rattray, Magnus/0000-0001-8196-5565; Rattray, Magnus/0000-0001-8196-5565; Hensman, James/0000-0002-4989-3589; Lawrence, Neil/0000-0001-9258-1030	BBSRC [BB/H018123/2] Funding Source: UKRI; MRC [MR/K022016/1, MR/K022016/2] Funding Source: UKRI; Biotechnology and Biological Sciences Research Council [BB/H018123/2] Funding Source: researchfish; Medical Research Council [MR/K022016/1, MR/K022016/2] Funding Source: Medline	BBSRC(UK Research & Innovation (UKRI)Biotechnology and Biological Sciences Research Council (BBSRC)); MRC(UK Research & Innovation (UKRI)Medical Research Council UK (MRC)); Biotechnology and Biological Sciences Research Council(UK Research & Innovation (UKRI)Biotechnology and Biological Sciences Research Council (BBSRC)); Medical Research Council(UK Research & Innovation (UKRI)Medical Research Council UK (MRC))		Amari S, 1998, NEURAL COMPUT, V10, P251, DOI 10.1162/089976698300017746; Behseta S, 2005, BIOMETRIKA, V92, P419, DOI 10.1093/biomet/92.2.419; Blei DM, 2006, BAYESIAN ANAL, V1, P121, DOI 10.1214/06-BA104; Cooke EJ, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-399; Dunson D. B., 2010, BAYESIAN NONPARAMETR; Durrande N., 2013, ARXIV13037090; Gossan N, 2013, ARTHRITIS RHEUM-US, V65, P2334, DOI 10.1002/art.38035; Hensman J., 2012, ADV NEURAL INFORM PR, V25, P2888; Hensman J., 2012, BMC BIOINFORMA UNPUB; Hoffman MD, 2013, J MACH LEARN RES, V14, P1303; Honkela A, 2010, J MACH LEARN RES, V11, P3235; Honkela A, 2010, P NATL ACAD SCI USA, V107, P7793, DOI 10.1073/pnas.0914285107; Jain S, 2004, J COMPUT GRAPH STAT, V13, P158, DOI 10.1198/1061860043001; Kalaitzis AA, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-180; Kalinka AT, 2010, NATURE, V468, P811, DOI 10.1038/nature09634; King NJ, 2006, LECT NOTES COMPUT SC, V4212, P270; Kurihara K, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2796; Kuusela Mikael, 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P1688, DOI 10.1109/IJCNN.2009.5178726; Lazaro-Gredilla M., 2011, P INT C MACH LEARN M, P841; Lazaro-Gredilla M, 2012, PATTERN RECOGN, V45, P1386, DOI 10.1016/j.patcog.2011.10.004; Medvedovic M, 2004, BIOINFORMATICS, V20, P1222, DOI 10.1093/bioinformatics/bth068; Park S, 2010, JMLR WORKSH CONF PRO, V13, P95; Rasmussen CE, 2002, ADV NEUR IN, V14, P881; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Rasmussen CE, 2000, ADV NEUR IN, V12, P554; Sato M, 2001, NEURAL COMPUT, V13, P1649, DOI 10.1162/089976601750265045; Stegle O, 2010, J COMPUT BIOL, V17, P355, DOI 10.1089/cmb.2009.0175; Sung J, 2008, IEEE T PATTERN ANAL, V30, P2236, DOI 10.1109/TPAMI.2008.157; Teh Y. W., 2007, P ADV NEUR INF PROC, P1353; Ueda N, 2000, J VLSI SIG PROC SYST, V26, P133, DOI 10.1023/A:1008155703044	30	34	35	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2015	37	2					383	393		10.1109/TPAMI.2014.2318711	http://dx.doi.org/10.1109/TPAMI.2014.2318711			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VD	26353249	Green Submitted, Green Accepted, Bronze			2022-12-18	WOS:000349625500014
J	Qiu, Q; Patel, VM; Chellappa, R				Qiu, Qiang; Patel, Vishal M.; Chellappa, Rama			Information-Theoretic Dictionary Learning for Image Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dictionary learning; information theory; mutual information; entropy; image classification	FACE RECOGNITION; SPARSE; REPRESENTATION; ALGORITHMS	We present a two-stage approach for learning dictionaries for object classification tasks based on the principle of information maximization. The proposed method seeks a dictionary that is compact, discriminative, and generative. In the first stage, dictionary atoms are selected from an initial dictionary by maximizing the mutual information measure on dictionary compactness, discrimination and reconstruction. In the second stage, the selected dictionary atoms are updated for improved reconstructive and discriminative power using a simple gradient ascent algorithm on mutual information. Experiments using real data sets demonstrate the effectiveness of our approach for image classification tasks.	[Qiu, Qiang] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA; [Patel, Vishal M.; Chellappa, Rama] Univ Maryland, UMIACS, Ctr Automat Res, College Pk, MD 20742 USA	Duke University; University System of Maryland; University of Maryland College Park	Qiu, Q (corresponding author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.	qiang.qiu@duke.edu; pvishalm@umiacs.umd.edu; rama@umiacs.umd.edu	Chellappa, Rama/B-6573-2012; Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/AAJ-1504-2020		MURI from the Office of Naval Research [N00014-10-1-0934]	MURI from the Office of Naval Research	The work was partially supported by a MURI from the Office of Naval Research under the Grant N00014-10-1-0934.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Bishop C.M, 2006, PATTERN RECOGN; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Elad M, 2010, P IEEE, V98, P972, DOI 10.1109/JPROC.2009.2037655; Etemad K, 1998, IEEE T IMAGE PROCESS, V7, P1453, DOI 10.1109/83.718485; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; HELLMAN ME, 1970, IEEE T INFORM THEORY, V16, P368, DOI 10.1109/TIT.1970.1054466; Huang K., 2007, NEUR INF PROC SYST V; Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354; Kapur J. N., 1994, MEASURES INFORM THEI; Kokiopoulou E, 2008, IEEE T MULTIMEDIA, V10, P806, DOI 10.1109/TMM.2008.922806; Krause A, 2008, J MACH LEARN RES, V9, P235; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Mairal J., 2008, NEUR INF PROC SYST V; Mairal J., 2008, P IEEE C COMP VIS PA, V2, P1, DOI DOI 10.1109/CVPR.2008.4587652; Mairal J, 2012, IEEE T PATTERN ANAL, V34, P791, DOI 10.1109/TPAMI.2011.156; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Patel V. M., 2011, AS C PATT REC BEIJ C; Patel VM, 2012, IEEE T INF FOREN SEC, V7, P954, DOI 10.1109/TIFS.2012.2189205; PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465; Qiu Q, 2011, IEEE I CONF COMP VIS, P707, DOI 10.1109/ICCV.2011.6126307; Rodriguez F., 2007, 2213 U MINN; Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551; Torkkola K., 2003, Journal of Machine Learning Research, V3, P1415, DOI 10.1162/153244303322753742; Tropp JA, 2006, SIGNAL PROCESS, V86, P572, DOI 10.1016/j.sigpro.2005.05.030; Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793; van Gemert Jan C., 2008, Computer Vision. Proceedings 10th European Conference on Computer Vision, ECCV 2008, P696, DOI 10.1007/978-3-540-88690-7_52; Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757; Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286; Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989	33	34	34	0	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2014	36	11					2173	2184		10.1109/TPAMI.2014.2316824	http://dx.doi.org/10.1109/TPAMI.2014.2316824			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR6OI	26353059	Green Submitted			2022-12-18	WOS:000343702400005
J	Gonen, M; Kaski, S				Goenen, Mehmet; Kaski, Samuel			Kernelized Bayesian Matrix Factorization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Automatic relevance determination; biological interaction networks; large margin learning; matrix factorization; multilabel classification; multiple kernel learning; multiple output regression; variational approximation	ALGORITHM; NETWORKS	We extend kernelized matrix factorization with a full-Bayesian treatment and with an ability to work with multiple side information sources expressed as different kernels. Kernels have been introduced to integrate side information about the rows and columns, which is necessary for making out-of-matrix predictions. We discuss specifically binary output matrices but extensions to real-valued matrices are straightforward. We extend the state of the art in two key aspects: (i) A full-conjugate probabilistic formulation of the kernelized matrix factorization enables an efficient variational approximation, whereas full-Bayesian treatments are not computationally feasible in the earlier approaches. (ii) Multiple side information sources are included, treated as different kernels in multiple kernel learning which additionally reveals which side sources are informative. We then show that the framework can also be used for supervised and semi-supervised multilabel classification and multi-output regression, by considering samples and outputs as the domains where matrix factorization operates. Our method outperforms alternatives in predicting drug-protein interactions on two data sets. On multilabel classification, our algorithm obtains the lowest Hamming losses on 10 out of 14 data sets compared to five state-of-the-art multilabel classification algorithms. We finally show that the proposed approach outperforms alternatives in multi-output regression experiments on a yeast cell cycle data set.	[Goenen, Mehmet] Sage Bionetworks, Seatle, WA 98109 USA; [Kaski, Samuel] Aalto Univ, Dept Informat & Comp Sci, HIIT, Espoo 00076, Finland; [Kaski, Samuel] Univ Helsinki, Dept Comp Sci, Helsinki 00014, Finland	Aalto University; University of Helsinki	Gonen, M (corresponding author), Sage Bionetworks, Seatle, WA 98109 USA.	mehmet.gonen@sagebase.org; samuel.kaski@aalto.fi	Gönen, Mehmet/O-7322-2015; Kaski, Samuel/B-6684-2008	Gönen, Mehmet/0000-0002-2483-075X; Kaski, Samuel/0000-0003-1925-9154	Integrative Cancer Biology Program of the National Cancer Institute [1U54CA149237]; Academy of Finland [140057]; Academy of Finland (Finnish Centre of Excellence in Computational Inference Research COIN) [251170]; NATIONAL CANCER INSTITUTE [U54CA149237] Funding Source: NIH RePORTER	Integrative Cancer Biology Program of the National Cancer Institute(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI)); Academy of Finland(Academy of Finland); Academy of Finland (Finnish Centre of Excellence in Computational Inference Research COIN); NATIONAL CANCER INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI))	This work was financially supported by the Integrative Cancer Biology Program of the National Cancer Institute (grant no 1U54CA149237) and the Academy of Finland (grant no 140057 and Finnish Centre of Excellence in Computational Inference Research COIN, grant no 251170). Most of this work has been done while the first author was working at the Helsinki Institute for Information Technology HIIT, Department of Information and Computer Science, Aalto University.	Agarwal D., 2010, P 3 ACM INT C WEB SE, P91, DOI DOI 10.1145/1718487.1718499; Agarwal D, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P19; ALBERT JH, 1993, J AM STAT ASSOC, V88, P669, DOI 10.2307/2290350; [Anonymous], 2010, ADV NEURAL INFORM PR; [Anonymous], 2008, P 25 INT C MACH LEAR; [Anonymous], 2012, P 29 INT C MACHINE L; Beal M.J., 2003, VARIATIONAL ALGORITH; Ben-Hur A, 2005, BIOINFORMATICS, V21, pI38, DOI 10.1093/bioinformatics/bti1016; Blei, 2011, P 17 ACM SIGKDD INT, P448, DOI DOI 10.1145/2020408.2020480; Chu Wei, 2007, P ADV NEUR INF PROC, P289; Chun H, 2010, J R STAT SOC B, V72, P3, DOI 10.1111/j.1467-9868.2009.00723.x; Cruciani G, 2000, EUR J PHARM SCI, V11, pS29, DOI 10.1016/S0928-0987(00)00162-7; Damoulas T, 2008, BIOINFORMATICS, V24, P1264, DOI 10.1093/bioinformatics/btn112; Duran A, 2008, J CHEM INF MODEL, V48, P1813, DOI 10.1021/ci800037t; Elisseeff A, 2002, ADV NEUR IN, V14, P681; Filippone M, 2013, MACH LEARN, V93, P93, DOI 10.1007/s10994-013-5388-x; Girolami M., 2005, P 22 INT C MACH LEAR, P241, DOI DOI 10.1145/1102351.1102382; Gonen M, 2012, BIOINFORMATICS, V28, P2304, DOI 10.1093/bioinformatics/bts360; Gonen M, 2011, J MACH LEARN RES, V12, P2211; Hanhuai Shan, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P1025, DOI 10.1109/ICDM.2010.116; Khan SA, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-112; Lawrence N.D., 2009, P 26 ANN INT C MACHI, P601, DOI DOI 10.1145/1553374.1553452; Lawrence N. D., 2005, NIPS, P753; Lee TI, 2002, SCIENCE, V298, P799, DOI 10.1126/science.1075090; Luttinen J., 2009, ADV NEURAL INFORM PR, P1177; Ma H., 2008, NEUROCOMPUTING, P931; Menon AK, 2011, LECT NOTES ARTIF INT, V6912, P437, DOI 10.1007/978-3-642-23783-6_28; Miller Kurt T., 2009, NONPARAMETRIC LATENT, P1276; Murray I., 2010, ADV NEURAL INFORM PR, V23, P1732, DOI DOI 10.5555/2997046.2997089; Neal RM., 1996, BAYESIAN LEARNING NE, P29; Park S., 2013, PROC 23 INT JOINT C, P1593; Salakhutdinov R., 2007, ADV NEURAL INF PROCE, V20, P1257; Schmidt Mikkel N, 2008, Comput Intell Neurosci, P361705, DOI 10.1155/2008/361705; Schmidt MN, 2009, P INT C MACH LEARN, V26, P921; Scholkopf B., 2001, LEARNING KERNELS SUP; Schu┬lkopf B., 2004, KERNEL METHODS COMPU; Spellman PT, 1998, MOL BIOL CELL, V9, P3273, DOI 10.1091/mbc.9.12.3273; Srebro N., 2004, THESIS; Tan VYF, 2013, IEEE T PATTERN ANAL, V35, P1592, DOI 10.1109/TPAMI.2012.240; Tang L, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1255; Williams CKI, 1996, ADV NEUR IN, V8, P514; Yamanishi Y, 2009, ADV NEURAL INFORM PR, P1841; Yamanishi Y, 2008, BIOINFORMATICS, V24, pI232, DOI 10.1093/bioinformatics/btn162; Yamanishi Y, 2010, BIOINFORMATICS, V26, pi246, DOI 10.1093/bioinformatics/btq176; Yoo J, 2011, LECT NOTES ARTIF INT, V6913, P537, DOI 10.1007/978-3-642-23808-6_35; Zhang L, 2011, PALGR MAC SER INT PO, P13; Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019; Zhang W., 2012, P 22 INT JOINT C ART, P1615; Zheng FH, 2012, PROCEEDINGS OF 2012 INTERNATIONAL CONFERENCE ON PUBLIC ADMINISTRATION (8TH), VOL III, P403	51	34	34	2	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2014	36	10					2047	2060		10.1109/TPAMI.2014.2313125	http://dx.doi.org/10.1109/TPAMI.2014.2313125			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AP3MX	26352634	Green Submitted, hybrid			2022-12-18	WOS:000341981300011
J	Scheirer, WJ; Anthony, SE; Nakayama, K; Cox, DD				Scheirer, Walter J.; Anthony, Samuel E.; Nakayama, Ken; Cox, David D.			Perceptual Annotation: Measuring Human Vision to Improve Computer Vision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Machine learning; psychology; visual recognition; face detection; support vector machines; regularization; citizen science; psychophysics; psychometrics	FACE RECOGNITION	For many problems in computer vision, human learners are considerably better than machines. Humans possess highly accurate internal recognition and learning mechanisms that are not yet understood, and they frequently have access to more extensive training data through a lifetime of unbiased experience with the visual world. We propose to use visual psychophysics to directly leverage the abilities of human subjects to build better machine learning systems. First, we use an advanced online psychometric testing platform to make new kinds of annotation data available for learning. Second, we develop a technique for harnessing these new kinds of information-"perceptual annotations"-for support vector machines. A key intuition for this approach is that while it may remain infeasible to dramatically increase the amount of data and high-quality labels available for the training of a given system, measuring the exemplar-by-exemplar difficulty and pattern of errors of human annotators can provide important information for regularizing the solution of the system at hand. A case study for the problem face detection demonstrates that this approach yields state-of-the-art results on the challenging FDDB data set.	[Scheirer, Walter J.; Cox, David D.] Harvard Univ, Sch Engn & Appl Sci, Dept Mol & Cellular Biol, Cambridge, MA 02138 USA; [Scheirer, Walter J.; Anthony, Samuel E.; Nakayama, Ken; Cox, David D.] Harvard Univ, Ctr Brain Sci, Cambridge, MA 02138 USA; [Anthony, Samuel E.; Nakayama, Ken] Harvard Univ, Dept Psychol, Cambridge, MA 02138 USA	Harvard University; Harvard University; Harvard University	Scheirer, WJ (corresponding author), Harvard Univ, Sch Engn & Appl Sci, Dept Mol & Cellular Biol, Cambridge, MA 02138 USA.	wscheirer@fas.harvard.edu; santhony@wjh.harvard.edu; ken@wjh.harvard.edu; davidcox@fas.harvard.edu	Cox, David/C-4888-2008	Cox, David/0000-0002-2189-9743	NIH [R01 EY01363]; US National Science Foundation (NSF) IIS Award [0963668]	NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); US National Science Foundation (NSF) IIS Award(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This work was supported by NIH Grant R01 EY01363, US National Science Foundation (NSF) IIS Award #0963668 and a gift from the Intel Corporation. Walter J. Scheirer and Samuel E. Anthony contributed equally to this work.	Bengio Y., 2007, LARGE SCALE KERNEL M; Biswas A., 2012, P IEEE C COMP VIS PA; Chandler J, 2014, BEHAV RES METHODS, V46, P112, DOI 10.3758/s13428-013-0365-7; Chen DM, 2010, IEEE T NEURAL NETWOR, V21, P1680, DOI 10.1109/TNN.2010.2060353; Collobert R., 2006, P 23 INT C MACH LEAR; Dalal N., 2005, HISTOGRAMS ORIENTED; Deng J., 2013, P IEEE C COMP VIS PA; DiCarlo JJ, 2007, TRENDS COGN SCI, V11, P333, DOI 10.1016/j.tics.2007.06.010; Duchaine B, 2006, NEUROPSYCHOLOGIA, V44, P576, DOI 10.1016/j.neuropsychologia.2005.07.001; Ganchev K, 2010, J MACH LEARN RES, V11, P2001; Garrido L, 2008, J NEUROPSYCHOL, V2, P119, DOI 10.1348/174866407X246843; Germine L, 2012, PSYCHON B REV, V19, P847, DOI 10.3758/s13423-012-0296-9; Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500; Jain V., 2011, P IEEE C COMP VIS PA; Jain V.., 2010, FDDB BENCHMARK FACE; Kanwisher N, 1997, J NEUROSCI, V17, P4302; Koestinger M., 2011, ICCV WORKSH, DOI [10.1109/ICCVW.2011.6130513, DOI 10.1109/ICCVW.2011.6130513]; Kunapuli G., 2009, P ADV NEUR INF PROC; Kunapuli G., 2011, P 25 C NEUR INF PROC; Li J, 2011, P IEEE INT C COMP VI; O'Toole A. J., 2008, P 8 IEEE INT C AUT F; O'Toole AJ, 2007, IEEE T PATTERN ANAL, V29, P1642, DOI 10.1109/TPAMI.2007.1107; O'Toole AJ, 2012, ACM T APPL PERCEPT, V9, DOI 10.1145/2355598.2355599; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Pinto N., 2011, P IEEE INT C AUT FAC; Pitcher D, 2011, EXP BRAIN RES, V209, P481, DOI 10.1007/s00221-011-2579-1; Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983; Qi G.-J., 2008, P IEEE C COMP VIS PA; Settles B., 2012, ACTIVE LEARNING; Settles Burr, 2008, P ADV NEUR INF PROC; Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093; Small K, 2011, P 28 INT C MACH LEAR; SMOLA AJ, 1998, THESIS TU BERLIN; Subburaman V., 2010, P WORKSH FAC DET EUR; Valenza E, 1996, J EXP PSYCHOL HUMAN, V22, P892, DOI 10.1037/0096-1523.22.4.892; VALIANT LG, 1984, COMMUN ACM, V27, P1134, DOI 10.1145/1968.1972; Vedaldi A., 2008, P INT C MULT; Vig E., 2012, P 12 EUR C COMP VI 7; VIJAYANARASIMHA.S, 2010, P IEEE C COMP VIS PA; Vijayanarasimhan S., 2009, P IEEE C COMP VIS PA; VIJAYANARASIMHAN S., 2011, P IEEE C COMP VIS PA; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Welinder P., 2010, P 24 ANN C NEUR INF	43	34	34	4	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2014	36	8					1679	1686		10.1109/TPAMI.2013.2297711	http://dx.doi.org/10.1109/TPAMI.2013.2297711			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	AM9HN	26353347	Green Published			2022-12-18	WOS:000340191900015
J	Ranzato, M; Mnih, V; Susskind, JM; Hinton, GE				Ranzato, Marc'Aurelio; Mnih, Volodymyr; Susskind, Joshua M.; Hinton, Geoffrey E.			Modeling Natural Images Using Gated MRFs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gated MRF; natural images; deep learning; unsupervised learning; density estimation; energy-based model; Boltzmann machine; factored 3-way model; generative model; object recognition; denoising; facial expression recognition	DEEP BELIEF; GAUSSIANS; OBJECT; SCENE; SET	This paper describes a Markov Random Field for real-valued image modeling that has two sets of latent variables. One set is used to gate the interactions between all pairs of pixels, while the second set determines the mean intensities of each pixel. This is a powerful model with a conditional distribution over the input that is Gaussian, with both mean and covariance determined by the configuration of latent variables, which is unlike previous models that were restricted to using Gaussians with either a fixed mean or a diagonal covariance matrix. Thanks to the increased flexibility, this gated MRF can generate more realistic samples after training on an unconstrained distribution of high-resolution natural images. Furthermore, the latent variables of the model can be inferred efficiently and can be used as very effective descriptors in recognition tasks. Both generation and discrimination drastically improve as layers of binary latent variables are added to the model, yielding a hierarchical model called a Deep Belief Network.	[Ranzato, Marc'Aurelio; Mnih, Volodymyr; Hinton, Geoffrey E.] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada; [Susskind, Joshua M.] Univ Calif San Diego, Machine Percept Lab, La Jolla, CA 92093 USA	University of Toronto; University of California System; University of California San Diego	Ranzato, M (corresponding author), Univ Toronto, Dept Comp Sci, 6 Kings Coll Rd, Toronto, ON M5S 3G4, Canada.	ranzato@cs.toronto.edu			NSERC; CFI; CIFAR	NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC)); CFI(Canada Foundation for Innovation); CIFAR(Canadian Institute for Advanced Research (CIFAR))	The research was funded by Grants from NSERC, CFI, and CIFAR and by gifts from Google and Microsoft.	[Anonymous], 2004, PROC IEEE C COMPUT V; [Anonymous], 2007, P 6 ACM INT C IM VID; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148; Buades A., 2005, P IEEE COMP VIS PATT; Carreira-Perpignan M. A., 2005, P INT WORKSH ART INT; Ciresan D., 2011, P 28 INT JOINT C ART; Dabov K., 2006, P SPIE ELECT IMAGING; Dailey MN, 2002, J COGNITIVE NEUROSCI, V14, P1158, DOI 10.1162/089892902760807177; Dalal N., 2005, HISTOGRAMS ORIENTED; Deng J., 2009, 2009 IEEE C COMP VIS, P248, DOI [DOI 10.1109/CVPR.2009.5206848, 10.1109/CVPR.2009.5206848]; DiCarlo JJ, 2012, NEURON, V73, P415, DOI 10.1016/j.neuron.2012.01.010; Elad M., 2006, P IEEE C COMP VIS PA; Fasel I, 2005, COMPUT VIS IMAGE UND, V98, P182, DOI 10.1016/j.cviu.2004.07.014; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gregor K., 2010, ARXIV10060448; Hinton G., 2011, P INT C ART NEUR NET; Hinton G., 2001, P 17 C UNC ART INT; Hinton G., 1999, P 9 INT C ART NEUR N; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hyvarinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71; Jarrett K., 2009, P IEEE INT C COMP VI; Karklin Y, 2009, NATURE, V457, P83, DOI 10.1038/nature07481; Koster U., 2007, P 17 INT C ART NEUR; Krizhevsky A., 2009, LEARNING MULTIPLE L; Lazebnik S., 2006, P IEEE C COMP VIS PA; Le Q., 2010, P ADV NEUR INF PROC; Le QV, 2011, PROC CVPR IEEE; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee H., 2009, P 26 ANN INT C MACHI; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MACKAY DJC, 1999, MAXIMUM LIKELIHOOD C; Mairal J., 2009, P IEEE INT C COMP VI; Memisevic R, 2010, NEURAL COMPUT, V22, P1473, DOI 10.1162/neco.2010.01-09-953; Murray I., 2009, P ADV NEUR INF PROC; Neal RM., 1996, BAYESIAN LEARNING NE, P29; Ng A.Y, 2007, SELF TAUGHT LEARNING, DOI [10.1145/1273496.1273592, DOI 10.1145/1273496.1273592]; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Osindero S., 2008, P ADV NEUR INF PROC; Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640; Ranzato M., 2010, P IEEE C COMP VIS PA; Ranzato M., 2010, P ADV NEUR INF PROC; Ranzato M., 2007, CVPR; Ranzato M., 2010, P C ART INT STAT; Ranzato M., 2009, THESIS; Ranzato M, 2011, PROC CVPR IEEE; ROTH S, 2005, P IEEE C COMP VIS PA; SCHMIDT U, 2010, P IEEE C COMP VIS PA; Sejnowski T., 1986, P AIP C NEUR NETW CO; Simoncelli EP, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P431, DOI 10.1016/B978-012119792-6/50089-9; Susskind J. M., 2010, TECHNICAL REPORT; Taylor G., 2007, P ADV NEUR INF PROC; Teh YW, 2004, J MACH LEARN RES, V4, P1235; Theis L, 2011, J MACH LEARN RES, V12, P3071; Tieleman T., 2008, P INT C MACH LEARN; Tieleman T., 2009, P INT C MACH LEARN; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Vincent P., 2008, P INT C MACH LEARN; Wainwright M., 2000, P ADV NEUR INF PROC; WEISS Y, 2007, P IEEE C COMP VIS PA; Welling M., 2003, P ADV NEUR INF PROC; Welling M., 2005, P ADV NEUR INF PROC; Welling M., 2002, P INT C ART NEUR NET; Williams CKI, 2002, NEURAL COMPUT, V14, P1169, DOI 10.1162/089976602753633439; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Young G, 1940, PSYCHOMETRIKA, V5, P47, DOI 10.1007/BF02288560; Zhu SC, 1997, IEEE T PATTERN ANAL, V19, P1236, DOI 10.1109/34.632983; Zontak Maria, 2011, P IEEE C COMP VIS PA	71	34	37	0	67	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2013	35	9					2206	2222		10.1109/TPAMI.2013.29	http://dx.doi.org/10.1109/TPAMI.2013.29			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	186GB	23868780	Green Submitted			2022-12-18	WOS:000322029000012
J	Lelore, T; Bouchara, F				Lelore, Thibault; Bouchara, Frederic			FAIR: A Fast Algorithm for Document Image Restoration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image enhancement; image edge detection; image segmentation; image processing; image restoration	BINARIZATION	We present, in this paper, the FAIR algorithm: a fast algorithm for document image restoration. This algorithm has been submitted to different contests where it showed good performance in comparison to the state of the art. In addition, this method is scale invariant and fast enough to be used in real-time applications. The method is based on a double-threshold edge detection approach that makes it possible to detect small details while remaining robust against noise. The performance of the proposition is evaluated on several types of degraded document images where considerable background noise or variation in contrast and illumination exist.	[Lelore, Thibault; Bouchara, Frederic] Southern Univ Toulon Var, LSIS Lab, F-83957 La Garde, France	UDICE-French Research Universities; Aix-Marseille Universite	Lelore, T (corresponding author), Southern Univ Toulon Var, LSIS Lab, Ave Univ,BP 20132, F-83957 La Garde, France.	thibault.lelore@gmail.com; bouchara@univ-tln.fr						[Anonymous], 2010, GOOGL GOGGL; [Anonymous], 2008, FIN 9 0; Bai Hong-tao, 2009, 2009 WRI World Congress on Computer Science and Information Engineering (CSIE 2009), P651, DOI 10.1109/CSIE.2009.491; Bernsen J., 1986, P 8 INT C PATT REC, P1251; Block M, 2009, THIRD INTERNATIONAL CONFERENCE ON DIGITAL SOCIETY: ICDS 2009, PROCEEDINGS, P294, DOI 10.1109/ICDS.2009.45; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Cao R., 2000, P 4 IAPR INT WORKSH, P147; Chen Q, 2008, PATTERN RECOGN, V41, P1254, DOI 10.1016/j.patcog.2007.09.007; Chung KL, 2009, APPL MATH COMPUT, V212, P396, DOI 10.1016/j.amc.2009.02.061; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Fabrizio J, 2009, IEEE IMAGE PROC, P2373, DOI 10.1109/ICIP.2009.5413435; Fang M, 2009, ISIP: 2009 INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING, PROCEEDINGS, P109; Gatos B, 2006, PATTERN RECOGN, V39, P317, DOI 10.1016/j.patcog.2005.09.010; Gatos B, 2011, INT J DOC ANAL RECOG, V14, P35, DOI 10.1007/s10032-010-0115-7; Gatos B., 2011, P 11 INT C DOC AN RE; Geelen B., 2009, P ACM IEEE C DISTR S, P1; Hawick KA, 2010, PARALLEL COMPUT, V36, P655, DOI 10.1016/j.parco.2010.07.002; He LF, 2009, PATTERN RECOGN, V42, P1977, DOI 10.1016/j.patcog.2008.10.013; Howe NR, 2013, INT J DOC ANAL RECOG, V16, P247, DOI 10.1007/s10032-012-0192-x; Kuk JG, 2008, IEEE IMAGE PROC, P2612, DOI 10.1109/ICIP.2008.4712329; Lelore Thibault, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P551, DOI 10.1109/ICDAR.2009.117; Li Y, 2005, PROC INT CONF DOC, P575; Lu SJ, 2010, INT J DOC ANAL RECOG, V13, P303, DOI 10.1007/s10032-010-0130-8; Niblack W., 1986, ADV COMPUTER GRAPHIC; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Paredes R., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P733, DOI 10.1109/ICFHR.2010.119; Pratikakis I., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P727, DOI 10.1109/ICFHR.2010.118; Pratikakis I., 2012, P INT C FRONT HANDWR; Ramirez-Ortegon MA, 2010, PATTERN RECOGN, V43, P1233, DOI 10.1016/j.patcog.2009.11.006; Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2; Sauvola J., 1999, MEDIATEAM DOCUMENT D; Shafait F., 2008, DOCUMENT RECOGNITION, V6815, P6; Su BL, 2011, PROC INT CONF DOC, P22, DOI 10.1109/ICDAR.2011.14; WILCOXON F, 1946, J ECON ENTOMOL, V39, P269, DOI 10.1093/jee/39.2.269; Yuan-Kai Huo, 2010, 2010 International Conference on Image Analysis and Signal Processing (IASP 2010), P371, DOI 10.1109/IASP.2010.5476095	35	34	34	1	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2013	35	8					2039	2048		10.1109/TPAMI.2013.63	http://dx.doi.org/10.1109/TPAMI.2013.63			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	164AP	23787351	Green Submitted			2022-12-18	WOS:000320381400017
J	Zeng, J; Cheung, WK; Liu, JM				Zeng, Jia; Cheung, William K.; Liu, Jiming			Learning Topic Models by Belief Propagation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Latent Dirichlet allocation; topic models; belief propagation; message passing; factor graph; Bayesian networks; Markov random fields; hierarchical Bayesian models; Gibbs sampling; variational Bayes	EM	Latent Dirichlet allocation (LDA) is an important hierarchical Bayesian model for probabilistic topic modeling, which attracts worldwide interest and touches on many important applications in text mining, computer vision and computational biology. This paper represents the collapsed LDA as a factor graph, which enables the classic loopy belief propagation (BP) algorithm for approximate inference and parameter estimation. Although two commonly used approximate inference methods, such as variational Bayes (VB) and collapsed Gibbs sampling (GS), have gained great success in learning LDA, the proposed BP is competitive in both speed and accuracy, as validated by encouraging experimental results on four large-scale document datasets. Furthermore, the BP algorithm has the potential to become a generic scheme for learning variants of LDA-based topic models in the collapsed space. To this end, we show how to learn two typical variants of LDA-based topic models, such as author-topic models (ATM) and relational topic models (RTM), using BP based on the factor graph representations.	[Zeng, Jia] Soochow Univ, Sch Comp Sci & Technol, Suzhou 215006, Peoples R China; [Cheung, William K.; Liu, Jiming] Hong Kong Baptist Univ, Dept Comp Sci, Kowloon Tong, Hong Kong, Peoples R China	Soochow University - China; Hong Kong Baptist University	Zeng, J (corresponding author), Soochow Univ, Sch Comp Sci & Technol, Suzhou 215006, Peoples R China.	j.zeng@ieee.org; william@comp.hkbu.edu.hk; jiming@comp.hkbu.edu.hk		Cheung, William Kwok Wai/0000-0002-7428-2050; Liu, Jiming/0000-0002-8669-9064	NSFC [61003154]; Natural Science Foundation of the Jiangsu Higher Education Institutions of China [12KJA520004]; Baidu; Research Grant Council of the Hong Kong Special Administrative Region, China [HKBU210410]	NSFC(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of the Jiangsu Higher Education Institutions of China(National Natural Science Foundation of China (NSFC)); Baidu; Research Grant Council of the Hong Kong Special Administrative Region, China(Hong Kong Research Grants Council)	This work is supported by the NSFC (Grant No. 61003154), the Natural Science Foundation of the Jiangsu Higher Education Institutions of China (Grant No. 12KJA520004), and a grant from Baidu to Jia Zeng, and the General Research Fund (HKBU210410) from the Research Grant Council of the Hong Kong Special Administrative Region, China to William K. Cheung.	Asuncion A., 2009, P 25 C UNCERTAINTY A, P27, DOI DOI 10.1080/10807030390248483; Asuncion A.U., 2010, P ICML WORKSH TOP MO; Bishop CM, 2006, PATTERN RECOGNITION; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Buntine W, 2002, LECT NOTES ARTIF INT, V2430, P23; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chang J, 2010, ANN APPL STAT, V4, P124, DOI 10.1214/09-AOAS309; Chang Jonathan., 2009, P 22 INT C NEURAL IN, P288, DOI DOI 10.5555/2984093.2984126; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Eisenstein J., 2010, TECHNICAL REPORT; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; Heinrich G., 2008, PARAMETER ESTIMATION; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Jia Zeng, 2010, Proceedings 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology (WI-IAT), P366, DOI 10.1109/WI-IAT.2010.20; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; McCallum AK, 2000, INFORM RETRIEVAL, V3, P127, DOI 10.1023/A:1009953814988; Minka T., 2002, P 18 C UNCERTAINTY A, P352; Porteous I., 2008, P 14 ACM SIGKDD INT, P569; Pruteanu-Malinici I, 2010, IEEE T PATTERN ANAL, V32, P996, DOI 10.1109/TPAMI.2009.125; Ramage D., 2009, P 2009 C EMP METH NA, V1, P248, DOI DOI 10.3115/1699510.1699543; Rosen-Zvi M., 2004, P 20 C UNC ART INT, P487, DOI DOI 10.5555/1036843.1036902; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Tappen MF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P900; Teh Y. W., 2007, P ADV NEUR INF PROC, P1353; Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87; Welling M., 2004, NEURAL INF PROCESS S, V17, P1481; Winn J, 2005, J MACH LEARN RES, V6, P661; Zeng J., 2011, ARXIV11095370V1CSCV; Zeng J, 2008, PATTERN RECOGN, V41, P3636, DOI 10.1016/j.patcog.2008.06.006; Zeng J, 2008, IEEE T FUZZY SYST, V16, P747, DOI 10.1109/TFUZZ.2007.905916; Zeng J, 2008, IEEE T PATTERN ANAL, V30, P767, DOI 10.1109/TPAMI.2007.70734; Zeng J, 2006, IEEE T FUZZY SYST, V14, P454, DOI 10.1109/TFUZZ.2006.876366; Zeng J, 2012, J MACH LEARN RES, V13, P2233; Zeng J, 2009, IEEE DATA MINING, P1070, DOI 10.1109/ICDM.2009.88; Zhai K., 2011, ARXIV11073765V1CSAI; Zhu SF, 2009, BIOINFORMATICS, V25, P1944, DOI 10.1093/bioinformatics/btp338	39	34	45	0	56	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2013	35	5					1121	1134		10.1109/TPAMI.2012.185	http://dx.doi.org/10.1109/TPAMI.2012.185			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	106EZ	23520254	Green Submitted			2022-12-18	WOS:000316126800008
J	Alush, A; Goldberger, J				Alush, Amir; Goldberger, Jacob			Ensemble Segmentation Using Efficient Integer Linear Programming	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image segmentation; ensemble segmentation; integer linear programming; correlation clustering; EM algorithm	IMAGE; ALGORITHM	We present a method for combining several segmentations of an image into a single one that in some sense is the average segmentation in order to achieve a more reliable and accurate segmentation result. The goal is to find a point in the "space of segmentations" which is close to all the individual segmentations. We present an algorithm for segmentation averaging. The image is first oversegmented into superpixels. Next, each segmentation is projected onto the superpixel map. An instance of the EM algorithm combined with integer linear programming is applied on the set of binary merging decisions of neighboring superpixels to obtain the average segmentation. Apart from segmentation averaging, the algorithm also reports the reliability of each segmentation. The performance of the proposed algorithm is demonstrated on manually annotated images from the Berkeley segmentation data set and on the results of automatic segmentation algorithms.	[Alush, Amir; Goldberger, Jacob] Bar Ilan Univ, Fac Engn, IL-52900 Ramat Gan, Israel	Bar Ilan University	Alush, A (corresponding author), Bar Ilan Univ, Fac Engn, IL-52900 Ramat Gan, Israel.	amiralush@gmail.com; goldbej@eng.biu.ac.il						ARBELAEZ P, 2009, P IEEE C COMP VIS PA; Bansal N, 2004, MACH LEARN, V56, P89, DOI 10.1023/B:MACH.0000033116.57574.95; Ben-Dor A, 1999, J COMPUT BIOL, V6, P281, DOI 10.1089/106652799318274; CHRISTOUDIAS C, 2002, P INT C PATT REC; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; COUR T, 2005, P IEEE C COMP VIS PA; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Donmez P, 2009, P 15 ACM SIGKDD INT; Elsner Micha, 2009, P WORKSH INT LIN PRO, P19; Freixenet J., 2002, P EUR C COMP VIS; HOPCROFT J, 1973, COMMUN ACM, V16, P372, DOI 10.1145/362248.362272; Maire Michael, 2008, P IEEE C COMP VIS PA; Malisiewicz T., 2007, P BRIT MACH VIS C; Martin D., 2001, P IEEE INT C COMP VI; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; MEILA M, 2005, P 22 INT C MACH LEAR; Mignotte M, 2010, IEEE T IMAGE PROCESS, V19, P1610, DOI 10.1109/TIP.2010.2044965; Ng V, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P104; Pantofaru C., 2008, P EUR C COMP VIS; PeterWelinder Steve Branson, 2010, P NIPS, V23, P1; Rabinovich A., 2006, P IEEE C COMP VIS PA; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Rao S.R., 2009, P 9 AS C COMP VIS; Raykar V.C., 2009, P INT C MACH LEARN; Russell B. C., 2006, P IEEE C COMP VIS PA; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Singh V, 2010, MACH LEARN, V79, P177, DOI 10.1007/s10994-009-5158-y; Smyth P., 1995, Advances in Neural Information Processing Systems 7, P1085; Sorokin A., 2008, P IEEE CS C COMP VIS; Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; Wang HZ, 2010, IEEE T PATTERN ANAL, V32, P619, DOI 10.1109/TPAMI.2009.199; Warfield SK, 2004, IEEE T MED IMAGING, V23, P903, DOI 10.1109/TMI.2004.828354; Whitehill J., 2009, ADV NEURAL INFORM PR, P2035; Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005	35	34	34	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2012	34	10					1966	1977		10.1109/TPAMI.2011.280	http://dx.doi.org/10.1109/TPAMI.2011.280			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	988WY	22213764				2022-12-18	WOS:000307522700008
J	Sabater, N; Almansa, A; Morel, JM				Sabater, Neus; Almansa, Andres; Morel, Jean-Michel			Meaningful Matches in Stereovision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo vision; block matching; number of false alarms (NFA); a contrario detection		This paper introduces a statistical method to decide whether two blocks in a pair of images match reliably. The method ensures that the selected block matches are unlikely to have occurred "just by chance." The new approach is based on the definition of a simple but faithful statistical background model for image blocks learned from the image itself. A theorem guarantees that under this model, not more than a fixed number of wrong matches occurs (on average) for the whole image. This fixed number (the number of false alarms) is the only method parameter. Furthermore, the number of false alarms associated with each match measures its reliability. This a contrario block-matching method, however, cannot rule out false matches due to the presence of periodic objects in the images. But it is successfully complemented by a parameterless self-similarity threshold. Experimental evidence shows that the proposed method also detects occlusions and incoherent motions due to vehicles and pedestrians in nonsimultaneous stereo.	[Sabater, Neus] CALTECH, Pasadena, CA 91125 USA; [Almansa, Andres] Telecom ParisTech, CNRS LTCI, F-75013 Paris, France; [Morel, Jean-Michel] CNRS CMLA, ENS Cachan, F-94235 Cachan, France	California Institute of Technology; Centre National de la Recherche Scientifique (CNRS); IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; Universite Paris Saclay	Sabater, N (corresponding author), CALTECH, MC 100-23,1200 E Calif Blvd, Pasadena, CA 91125 USA.	neussabater@gmail.com; andres.almansa@telecom.paristech.fr; jean-michel.morel@cmla.ens-cachan.fr	Morel, Jean-Michel/I-1012-2012; Almansa, Andres/A-4152-2008	Almansa, Andres/0000-0001-8196-1329; Morel, Jean-Michel/0000-0002-6108-897X	FREEDOM [ANR07-JCJC-0048-01]; Callisto [ANR-09-CORD-003]; ECOS Sud [U06E01]; STIC Amsud [11STIC-01 - MMVPSCV]	FREEDOM; Callisto; ECOS Sud; STIC Amsud	The authors thank Pascal Getreuer for helpful comments on this work. This work was partially supported by the following projects: FREEDOM (ANR07-JCJC-0048-01), Callisto (ANR-09-CORD-003), ECOS Sud U06E01, and STIC Amsud (11STIC-01 - MMVPSCV). Neus Sabater was with ENS Cachan, CMLA, France, when the paper was written.	[Anonymous], 1985, PERCEPTUAL ORG VISUA; Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603; Burrus N, 2009, PATTERN RECOGN, V42, P1520, DOI 10.1016/j.patcog.2009.01.003; Cao F., 2004, Computing and Visualization in Science, V7, P3, DOI 10.1007/s00791-004-0123-6; Cao F., 2008, THEORY SHAPE IDENTIF; Delon J, 2007, J MATH IMAGING VIS, V28, P209, DOI 10.1007/s10851-007-0001-1; Desolneux A., 2007, GESTALT THEORY IMAGE, VVolume 34; Egnal G, 2002, IEEE T PATTERN ANAL, V24, P1127, DOI 10.1109/TPAMI.2002.1023808; Eruhimov V., 2010, STEREO MATCH CPP SAM; Forstmann S., 2004, P CVPR WORKSH REAL T, P29, DOI [10.1109/CVPR.2004.154, DOI 10.1109/CVPR.2004.154]; GRIMSON WEL, 1991, IEEE T PATTERN ANAL, V13, P1201, DOI 10.1109/34.106994; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Igual L, 2007, INVERSE PROBL IMAG, V1, P319; Ishikawa H, 2003, IEEE T PATTERN ANAL, V25, P1333, DOI 10.1109/TPAMI.2003.1233908; Kang SB, 2001, PROC CVPR IEEE, P103; Klaus A, 2006, INT C PATT RECOG, P15; Kolmogorov V., 2005, MATH MODELS COMPUTER; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828; Manduchi R., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P26, DOI 10.1109/ICIAP.1999.797566; Mikolajczyk K, 2003, PROC CVPR IEEE, P257; Mittal A, 2004, PROC CVPR IEEE, P302; Moisan L, 2004, INT J COMPUT VISION, V57, P201, DOI 10.1023/B:VISI.0000013094.38752.54; Mordohai P, 2006, IEEE T PATTERN ANAL, V28, P968, DOI 10.1109/TPAMI.2006.129; Muse P., 2003, Traitement du Signal, V20, P279; Muse P, 2006, INT J COMPUT VISION, V69, P295, DOI 10.1007/s11263-006-7546-0; Nee G, 2008, LECT NOTES COMPUT SC, V5342, P350, DOI 10.1007/978-3-540-89689-0_39; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; Patwardhan KA, 2008, IEEE T PATTERN ANAL, V30, P746, DOI 10.1109/TPAMI.2007.70843; Pock T, 2008, LECT NOTES COMPUT SC, V5304, P792, DOI 10.1007/978-3-540-88690-7_59; RABIN J, 2008, P INT C PATT REC; Robin A., 2009, 200915 MAP5 U PAR DE; SABATER N, 2010, P IEEE INT C IM PROC; Sara R, 2002, LECT NOTES COMPUT SC, V2352, P900; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Schmid C, 2000, INT J COMPUT VISION, V40, P199, DOI 10.1023/A:1008135310502; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; Tomasi C, 1998, IEEE T PATTERN ANAL, V20, P333, DOI 10.1109/34.667890; Veksler O, 2003, PROC CVPR IEEE, P689; Veksler O, 2002, INT J COMPUT VISION, V47, P247, DOI 10.1023/A:1014506211316; YANG Q, 2006, CVPR, P2347	42	34	34	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2012	34	5					930	942		10.1109/TPAMI.2011.207	http://dx.doi.org/10.1109/TPAMI.2011.207			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	911VJ	22442122	Green Submitted			2022-12-18	WOS:000301747400008
J	Chen, YN; Han, CC; Wang, CT; Fan, KC				Chen, Ying-Nong; Han, Chin-Chuan; Wang, Cheng-Tzu; Fan, Kuo-Chin			Face Recognition Using Nearest Feature Space Embedding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; nearest feature line; nearest feature space; Fisher criterion; Laplacianface	NONPARAMETRIC DISCRIMINANT-ANALYSIS; PCA; CLASSIFICATION; REDUCTION; FRAMEWORK	Face recognition algorithms often have to solve problems such as facial pose, illumination, and expression (PIE). To reduce the impacts, many researchers have been trying to find the best discriminant transformation in eigenspaces, either linear or nonlinear, to obtain better recognition results. Various researchers have also designed novel matching algorithms to reduce the PIE effects. In this study, a nearest feature space embedding (called NFS embedding) algorithm is proposed for face recognition. The distance between a point and the nearest feature line (NFL) or the NFS is embedded in the transformation through the discriminant analysis. Three factors, including class separability, neighborhood structure preservation, and NFS measurement, were considered to find the most effective and discriminating transformation in eigenspaces. The proposed method was evaluated by several benchmark databases and compared with several state-of-the-art algorithms. According to the compared results, the proposed method outperformed the other algorithms.	[Chen, Ying-Nong; Fan, Kuo-Chin] Natl Cent Univ, Dept Comp Sci & Informat Engn, Jhongli 32001, Taoyuan County, Taiwan; [Han, Chin-Chuan] Natl United Univ, Dept Comp Sci & Informat Engn, Miaoli City 36003, Taiwan; [Wang, Cheng-Tzu] Natl Taipei Univ Educ, Dept Comp Sci, Taipei 106, Taiwan	National Central University; National United University; National Taipei University of Education	Chen, YN (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, 300 Jhongda Rd, Jhongli 32001, Taoyuan County, Taiwan.	93542021@cc.ncu.edu.tw; cchan@nuu.edu.tw; ctwang@tea.ntue.edu.tw; kcfan@csie.ncu.edu.tw	Fan, K/GXH-3734-2022; Han, Chin-Chuan/B-2642-2012	, YingNong/0000-0002-5448-9900	National Science Council [NSC 97-2221-E-239 -023 -MY2]; DOIT, MOEA, Taiwan [98-EC-17-A-02-S1-032]	National Science Council(Ministry of Science and Technology, Taiwan); DOIT, MOEA, Taiwan(Ministry of Economic Affairs, Taiwan)	The authors thank Professor Stan Z. Li and the anonymous reviewers for providing valuable comments which considerably improved the quality of this paper. The work was supported by the National Science Council under grant no. NSC 97-2221-E-239 -023 -MY2, and by the Technology Development Program for Academia of DOIT, MOEA, Taiwan under grant no. 98-EC-17-A-02-S1-032.	Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Belkin M, 2002, ADV NEUR IN, V14, P585; Bressan M, 2003, PATTERN RECOGN LETT, V24, P2743, DOI 10.1016/S0167-8655(03)00117-X; Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945; Cevikalp H, 2005, IEEE T PATTERN ANAL, V27, P4, DOI 10.1109/TPAMI.2005.9; Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9; Chien JT, 2008, IEEE T PATTERN ANAL, V30, P606, DOI 10.1109/TPAMI.2007.70715; Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644, DOI 10.1109/TPAMI.2002.1114855; Cramer J.S., 2003, ORIGINS LOGISTIC REG; Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724; Fortuna J, 2004, PATTERN RECOGN, V37, P1117, DOI 10.1016/j.patcog.2003.11.009; Geng X, 2008, IEEE T NEURAL NETWOR, V19, P1354, DOI 10.1109/TNN.2008.2000275; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Hu HF, 2008, PATTERN RECOGN, V41, P2045, DOI 10.1016/j.patcog.2007.10.029; Jiang XD, 2008, IEEE T PATTERN ANAL, V30, P383, DOI 10.1109/TPAMI.2007.70708; Li JB, 2008, INFORM SCIENCES, V178, P1825, DOI 10.1016/j.ins.2007.12.001; Li SZ, 2000, IEEE T PATTERN ANAL, V22, P1335, DOI 10.1109/34.888719; Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575; Li SZ, 1998, PROC CVPR IEEE, P839, DOI 10.1109/CVPR.1998.698702; Li ZF, 2009, IEEE T PATTERN ANAL, V31, P755, DOI 10.1109/TPAMI.2008.174; Liu YH, 2007, IEEE T NEURAL NETWOR, V18, P178, DOI 10.1109/TNN.2006.883013; Loog M, 2001, IEEE T PATTERN ANAL, V23, P762, DOI 10.1109/34.935849; Lotlikar R, 2000, IEEE T PATTERN ANAL, V22, P623, DOI 10.1109/34.862200; Lu JM, 2007, IEEE T NEURAL NETWOR, V18, P150, DOI 10.1109/TNN.2006.884678; LUETTIN J, 1998, DMI PERCEPTUAL ARTIF; Olivetti & Oracle Research Laboratory, 1994, OL OR RES LAB FAC DA; Park BG, 2005, IEEE T PATTERN ANAL, V27, P1982, DOI 10.1109/TPAMI.2005.243; Rajagopalan AN, 2005, IEEE T IMAGE PROCESS, V14, P832, DOI 10.1109/TIP.2005.847288; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; STRANG G, 1997, LINEAR ALGEBRA GEODE, P165; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TURK M, 1991, COMPUTER VISION PATT, P586; Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57; Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097; Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008; ZHA H, 2003, P 20 INT C MACH LEAR, P864; Zhang TP, 2008, IEEE T IMAGE PROCESS, V17, P574, DOI 10.1109/TIP.2008.918957	40	34	40	2	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2011	33	6					1073	1086		10.1109/TPAMI.2010.197	http://dx.doi.org/10.1109/TPAMI.2010.197			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	750DE	21079273				2022-12-18	WOS:000289524000001
J	Sznitman, R; Jedynak, B				Sznitman, Raphael; Jedynak, Bruno			Active Testing for Face Detection and Localization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Active testing; face detection; visual search; coarse-to-fine search; face localization	MODEL	We provide a novel search technique which uses a hierarchical model and a mutual information gain heuristic to efficiently prune the search space when localizing faces in images. We show exponential gains in computation over traditional sliding window approaches, while keeping similar performance levels.	[Sznitman, Raphael] Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA; [Jedynak, Bruno] Johns Hopkins Univ, Ctr Imaging Sci JHU, Baltimore, MD 21218 USA; [Jedynak, Bruno] Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD 21218 USA; [Jedynak, Bruno] Univ Sci & Technol Lille, Lab Math Paul Painleve, Lille, France; [Jedynak, Bruno] Univ Sci & Technol Lille, Inst Univ Technol, Lille, France	Johns Hopkins University; Johns Hopkins University; Johns Hopkins University; Universite de Lille - ISITE; Universite de Lille; Universite de Lille - ISITE; Universite de Lille	Sznitman, R (corresponding author), Johns Hopkins Univ, Dept Comp Sci, CSEB Room 136,3400 N Charles St, Baltimore, MD 21218 USA.	sznitman@jhu.edu; bruno.jedynak@jhu.edu	jedynak, bruno m/A-8198-2009		US National Institutes of Health [1 R01 EB 007969-01]; Duncan Fund for the Advancement of Statistics Research [08-19]; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [R01EB007969] Funding Source: NIH RePORTER	US National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Duncan Fund for the Advancement of Statistics Research; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB))	Funding for this research was provided in part by US National Institutes of Health Grant 1 R01 EB 007969-01 and the Duncan Fund for the Advancement of Statistics Research, Award 08-19.	Amit Y, 1999, NEURAL COMPUT, V11, P1691, DOI 10.1162/089976699300016197; BELLE V, 2008, P INT C PATT REC; Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/cvpr.2008.4587586; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Ding LY, 2010, IEEE T PATTERN ANAL, V32, P2022, DOI 10.1109/TPAMI.2010.28; Everingham M., 2010, PASCAL VISUAL OBJECT; Fleuret F, 2001, INT J COMPUT VISION, V41, P85, DOI 10.1023/A:1011113216584; Fleuret F, 2008, J MACH LEARN RES, V9, P2549; Garcia C, 2004, IEEE T PATTERN ANAL, V26, P1408, DOI 10.1109/TPAMI.2004.97; Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006; GEMAN D, 1993, 2155 INRIA; Hastie T, 2009, ELEMENTS STAT LEARNI; *INT, OP OP SOURC COMP VIS; Jiang XD, 2008, IEEE T PATTERN ANAL, V30, P383, DOI 10.1109/TPAMI.2007.70708; LATORRE FD, 2007, P INT C COMP VIS; LI P, 2009, P IEEE C COMP VIS PA; Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Osadchy M, 2007, J MACH LEARN RES, V8, P1197; Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310; Rowley HA, 1996, ADV NEUR IN, V8, P875; SCHNEIDERMAN H, 2000, FRONTAL FACE IMAGES; Schneiderman H., 2004, P IEEE C COMP VIS PA; Shahabudeen S., 2007, MTSIEEE OCEANS 2007, P1; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Weber M., 1999, FRONTAL FACE DATASET; Yan S, 2008, PR IEEE COMP DESIGN, P142, DOI 10.1109/ICCD.2008.4751853; Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPR.2009.5206671, 10.1109/CVPRW.2009.5206671]	28	34	36	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2010	32	10					1914	1920		10.1109/TPAMI.2010.106	http://dx.doi.org/10.1109/TPAMI.2010.106			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	639US	20479494	Green Published, Green Submitted			2022-12-18	WOS:000281000700016
J	Cho, TS; Avidan, S; Freeman, WT				Cho, Taeg Sang; Avidan, Shai; Freeman, William T.			The Patch Transform	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image models; statistical; applications; image-based rendering	TEXTURE SYNTHESIS; JIGSAW PUZZLES	The patch transform represents an image as a bag of overlapping patches sampled on a regular grid. This representation allows users to manipulate images in the patch domain, which then seeds the inverse patch transform to synthesize modified images. Possible modifications include the spatial locations of patches, the size of the output image, or the pool of patches from which an image is reconstructed. When no modifications are made, the inverse patch transform reduces to solving a jigsaw puzzle. The inverse patch transform is posed as a patch assignment problem on a Markov random field (MRF), where each patch should be used only once and neighboring patches should fit to form a plausible image. We find an approximate solution to the MRF using loopy belief propagation, introducing an approximation that encourages the solution to use each patch only once. The image reconstruction algorithm scales well with the total number of patches through label pruning. In addition, structural misalignment artifacts are suppressed through a patch jittering scheme that spatially jitters the assigned patches. We demonstrate the patch transform and its effectiveness on natural images.	[Cho, Taeg Sang; Freeman, William T.] MIT, CSAIL, Cambridge, MA 02139 USA; [Avidan, Shai] Tel Aviv Univ, Tel Aviv, Israel	Massachusetts Institute of Technology (MIT); Tel Aviv University	Cho, TS (corresponding author), MIT, CSAIL, 32 Vassar St,32D-466, Cambridge, MA 02139 USA.	taegsang@mit.edu; shai.avidan@gmail.com; billf@mit.edu			ONR-MURI [N00014-06-1-0734]; Shell Research; Samsung Scholarship Foundation	ONR-MURI(MURIOffice of Naval Research); Shell Research; Samsung Scholarship Foundation(Samsung)	This research is partially funded by ONR-MURI grant N00014-06-1-0734 and by Shell Research. This work was partially completed while Taeg Sang Cho was an intern at Adobe Systems. Taeg Sang Cho is partially supported by the Samsung Scholarship Foundation. The authors would like to thank Myung Jin Choi, Ce Liu, Anat Levin, and Hyun Sung Chang for fruitful discussions. They would also like to thank Flickr for images.	AGRAWAL A, 2006, P EUR C COMP VIS; Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461; Bertalmio M., 2000, ACM T GRAPHICS; BISHOP CM, 2003, P C NEUR INF PROC SY; BONET JD, 1997, ACM T GRAPHICS; BROWN BJ, 2008, P ACM SIGGRAPH; Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218; CHO TS, 2008, P IEEE C COMP VIS PA; CHUNG MG, 1998, P INT C SIGN PROC; Coughlan J. M., 2002, P EUR C COMP VIS; Criminisi A., 2003, P IEEE C COMP VIS PA; Demaine ED, 2007, GRAPH COMBINATOR, V23, P195, DOI 10.1007/s00373-007-0713-4; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; EFROS AA, 2001, P ACM SIGGRAPH; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; JOJIC N, 2003, P IEEE INT C COMP VI; KANNAN A, 2006, ADV NEURAL INFORM PR, V19; Koller D, 2006, B COMMISSIONE ARCHEO; KOLLER D, 1998, P ANN C UNC ART INT; Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239547, 10.1145/1276377.1276497]; KUMAR MP, 2006, P EUR C COMP VIS; KWATRA V, 2003, P ACM SIGGRAPH; Lalonde JF, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239454, 10.1145/1276377.1276381]; LASSERRE J, 2007, P IEEE C COMP VIS PA; Leitao HCD, 2002, IEEE T PATTERN ANAL, V24, P1239, DOI 10.1109/TPAMI.2002.1033215; Levin Anat, 2007, P IEEE C COMP VIS PA; LEVISON M, 1967, MACHINE TRANSLATION, P173; Liang L, 2001, ACM T GRAPHIC, V20, P127, DOI 10.1145/501786.501787; MORTENSEN EN, 1995, ACM T GRAPHICS; Nielsen TR, 2008, PATTERN RECOGN LETT, V29, P1924, DOI 10.1016/j.patrec.2008.05.027; PECHAUD M, 2007, MED IMAGE COMPUTING; Perez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269; Ramanarayanan G, 2007, IEEE T VIS COMPUT GR, V13, P167, DOI 10.1109/TVCG.2007.4; ROTHER C, 2006, ACM T GRAPHICS; SIMAKOV D, 2008, P IEEE C COMP VIS PA; Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509; SUN J, 2005, P ACM SIGGRAPH; WANG CS, 2000, THESIS MIT; Wang JW, 2005, I C COMP SYST APPLIC; WEXLER Y, 2004, P IEEE C COMP VIS PA; Yedidia J., 2003, EXPLORING ARTIFICIAL, V8, P236; ZHAO YX, 2007, P 2007 WSEAS INT C C; Zhu LJ, 2008, IEEE T PATTERN ANAL, V30, P1, DOI 10.1109/TPAMI.2007.1163	44	34	34	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2010	32	8					1489	1501		10.1109/TPAMI.2009.133	http://dx.doi.org/10.1109/TPAMI.2009.133			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	611XQ	20558879	Green Published			2022-12-18	WOS:000278858600010
J	Ferrara, M; Arnold, G; Stuff, M				Ferrara, Matthew; Arnold, Gregory; Stuff, Mark			Shape and Motion Reconstruction from 3D-to-1D Orthographically Projected Data via Object-Image Relations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Geometric invariants; object-image relation; factorization method; shape from motion; orthographic projection; moving-target imaging		This paper describes an invariant-based shape-and motion reconstruction algorithm for 3D-to-1D orthographically projected range data taken from unknown viewpoints. The algorithm exploits the object-image relation that arises in echo-based range data and represents a simplification and unification of previous work in the literature. Unlike one proposed approach, this method does not require uniqueness constraints, which makes its algorithmic form independent of the translation removal process (centroid removal, range alignment, etc.). The new algorithm, which simultaneously incorporates every projection and does not use an initialization in the optimization process, requires fewer calculations and is more straightforward than the previous approach. Additionally, the new algorithm is shown to be the natural extension of the approach developed by Tomasi and Kanade for 3D-to-2D orthographically projected data and is applied to a realistic inverse synthetic aperture radar imaging scenario, as well as experiments with varying amounts of aperture diversity and noise.	[Ferrara, Matthew; Arnold, Gregory] USAF, Res Lab, Dayton, OH 45433 USA; [Stuff, Mark] Michigan Tech Res Inst, Ann Arbor, MI 48105 USA	United States Department of Defense; United States Air Force; Michigan Technological University	Ferrara, M (corresponding author), USAF, Res Lab, 2241 Avion Circle, Dayton, OH 45433 USA.	matthew.ferrara@afrl.af.mil; gregory.arnold@afrl.af.mil; mastuff@mtu.edu			AFOSR	AFOSR(United States Department of DefenseAir Force Office of Scientific Research (AFOSR))	This work was supported in part by the AFOSR laboratory tasks under the direction of Arje Nachman and Jon Sjogren, as well as AFRL Sensors Directorate 6.2 project funding. The authors would like to thank Margaret Cheney, Vince Velten, Peter Stiller, Kirk Sturtz, and Rob Williams for reviewing earlier drafts of this paper. The views expressed in this article are those of the authors and do not reflect the official policy of the US Air Force, US Department of Defense, or the US Government.	Arnold G, 2006, MODEL SIMUL SCI ENG, P253; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Fienup JR, 2001, IEEE T AERO ELEC SYS, V37, P794, DOI 10.1109/7.953237; Golub G.H., 2013, MATRIX COMPUTATIONS, P357; JAKOWATZ CV, 1995, IEEE T IMAGE PROCESS, V4, P699, DOI 10.1109/83.382506; Lawson C. L., 1974, SOLVING LEAST SQUARE; Morita T, 1997, IEEE T PATTERN ANAL, V19, P858, DOI 10.1109/34.608289; Stuff MA, 2003, MULTIDIM SYST SIGN P, V14, P161, DOI 10.1023/A:1022229326812; TOMASI C, 1991, CMUCS91105; Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298; Whitaker RT, 2002, IEEE T PATTERN ANAL, V24, P1372, DOI 10.1109/TPAMI.2002.1039208	11	34	44	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2009	31	10					1906	1912		10.1109/TPAMI.2008.294	http://dx.doi.org/10.1109/TPAMI.2008.294			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	483VK	19696458				2022-12-18	WOS:000268996500014
J	Shen, YP; Foroosh, H				Shen, Yuping; Foroosh, Hassan			View-Invariant Action Recognition from Point Triplets	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						View invariance; homology; pose transition; action recognition; action alignment	HUMAN MOVEMENT; MOTION; FLOW	We propose a new view-invariant measure for action recognition. For this purpose, we introduce the idea that the motion of an articulated body can be decomposed into rigid motions of planes defined by triplets of body points. Using the fact that the homography induced by the motion of a triplet of body points in two identical pose transitions reduces to the special case of a homology, we use the equality of two of its eigenvalues as a measure of the similarity of the pose transitions between two subjects, observed by different perspective cameras and from different viewpoints. Experimental results show that our method can accurately identify human pose transitions and actions even when they include dynamic timeline maps, and are obtained from totally different viewpoints with different unknown camera parameters.	[Shen, Yuping; Foroosh, Hassan] Univ Cent Florida, Sch EECS, Orlando, FL 32816 USA	State University System of Florida; University of Central Florida	Shen, YP (corresponding author), Univ Cent Florida, Sch EECS, 4000 Cent Florida Blvd, Orlando, FL 32816 USA.	ypshen@cs.ucf.edu; foroosh@cs.ucf.edu			Electronic Arts - Tiburon	Electronic Arts - Tiburon	This project was in part supported by Electronic Arts - Tiburon.	Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744; Ahmad M, 2006, INT C PATT RECOG, P263; [Anonymous], 2007, 2007 IEEE C COMP VIS; Blank M, 2005, IEEE I CONF COMP VIS, P1395; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Cuzzolin F., 2006, P 2006 IEEE COMP SOC, V2, P1701; Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; GRITAI A, 2004, P INT C PATT REC, V2; Hartley R., 2004, ROBOTICA; JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378; Laptev I, 2005, IEEE I CONF COMP VIS, P816; Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; Parameswaran V, 2006, INT J COMPUT VISION, V66, P83, DOI 10.1007/s11263-005-3671-4; PARAMESWARAN V, 2003, P IEEE COMP VIS PATT, V2; Pavlovic V., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P94, DOI 10.1109/ICCV.1999.791203; PRITCHETT P, 1998, P EUR WORKSH 3D STRU, P78; Ramanan D, 2005, PROC CVPR IEEE, P1194; Ramanan D, 2005, PROC CVPR IEEE, P271; Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748; REHG JM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P612, DOI 10.1109/ICCV.1995.466882; SCHULDT C, 2004, P INT C PATT REC, V3; Semple J., 1979, ALGEBRAIC PROJECTIVE; SHEIKH Y, 2005, P IEEE INT C COMP VI, V1; Sullivan J, 2002, LECT NOTES COMPUT SC, V2350, P629; Syeda-Mahmood T, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P64, DOI 10.1109/EVENT.2001.938868; Van Gool L, 1998, IMAGE VISION COMPUT, V16, P21, DOI 10.1016/S0262-8856(97)00046-2; VIEVILLE T, 1993, 2054 INRIA; Wang FL, 2003, CHINESE LAW GOV, V36, P3, DOI 10.2753/CLG0009-460936043; Wang J, 2006, EXP THERM FLUID SCI, V30, P473, DOI 10.1016/j.expthermflusci.2005.09.005; Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013; YILMAZ A, 2005, P IEEE C COMP VIS PA, V1; Yimaz A, 2006, COMPUT VIS IMAGE UND, V104, P221, DOI 10.1016/j.cviu.2006.07.012; Zatsiorsky VM, 2002, KINEMATICS HUMAN MOT; Zelnik-Manor L, 2002, IEEE T PATTERN ANAL, V24, P214, DOI 10.1109/34.982901; Zhang Z, 2001, COMPUT VIS IMAGE UND, V82, P174, DOI 10.1006/cviu.2001.0909; Zhu GY, 2006, LECT NOTES COMPUT SC, V3979, P89	38	34	37	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2009	31	10					1898	1905		10.1109/TPAMI.2009.41	http://dx.doi.org/10.1109/TPAMI.2009.41			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	483VK	19696457				2022-12-18	WOS:000268996500013
J	Tardif, JP; Sturm, P; Trudeau, M; Roy, S				Tardif, Jean-Philippe; Sturm, Peter; Trudeau, Martin; Roy, Sebastien			Calibration of Cameras with Radially Symmetric Distortion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Calibration; omnidirectional vision; fisheye; catadioptric camera	WIDE-ANGLE; MODEL	We present algorithms for plane-based calibration of general radially distorted cameras. By this, we understand cameras that have a distortion center and an optical axis such that the projection rays of pixels lying on a circle centered on the distortion center form a right viewing cone centered on the optical axis. The camera is said to have a single viewpoint (SVP) if all such viewing cones have the same apex (the optical center); otherwise, we speak of NSVP cases. This model encompasses the classical radial distortion model [5], fisheyes, and most central or noncentral catadioptric cameras. Calibration consists in the estimation of the distortion center, the opening angles of all viewing cones, and their optical centers. We present two approaches of computing a full calibration from dense correspondences of a single or multiple planes with known euclidean structure. The first one is based on a geometric constraint linking viewing cones and their intersections with the calibration plane (conic sections). The second approach is a homography-based method. Experiments using simulated and a broad variety of real cameras show great stability. Furthermore, we provide a comparison with Hartley-Kang's algorithm [12], which, however, cannot handle such a broad variety of camera configurations, showing similar performance.	[Tardif, Jean-Philippe] Univ Penn, Dept Comp & Informat Sci, Philadelphia, PA 19104 USA; [Sturm, Peter] INRIA Grenoble Rhone Alpes, F-38330 Montbonnot St Martin, France; [Trudeau, Martin] Mercer, Montreal, PQ H3A 3T5, Canada; [Roy, Sebastien] Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3T 1J4, Canada	University of Pennsylvania; Universite de Montreal	Tardif, JP (corresponding author), Univ Penn, Dept Comp & Informat Sci, Levine Hall L402,3330 Walnut St, Philadelphia, PA 19104 USA.	tardifj@seas.upenn.edu; Peter.Sturm@inrialpes.fr; martin.trudeau@mercer.com; roys@iro.umontreal.ca			French ANR; Natural Sciences and Engineering Research Council of Canada	French ANR(French National Research Agency (ANR)); Natural Sciences and Engineering Research Council of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)CGIAR)	Jean-Philippe Tardif and Peter Sturm gratefully acknowledge the support of the French ANR under Project CAVIAR. Funding was also provided to Jean-Philippe Tardif by the Natural Sciences and Engineering Research Council of Canada. The authors would like to thank the reviewers for useful comments.	Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364; BARRETO JP, 2004, P OMNIVIS, P151; BOEHM W, 1994, GEOMETRIC CONCEPTS G; BROWN DC, 1971, PHOTOGRAMM ENG, V37, P855; CHAMPLEBOUX G, 1992, 1992 IEEE INTERNATIONAL CONF ON ROBOTICS AND AUTOMATION : PROCEEDINGS, VOLS 1-3, P1552; Claus D, 2005, PROC CVPR IEEE, P213; Devernay F, 2001, MACH VISION APPL, V13, P14, DOI 10.1007/PL00013269; GEYER C, 2000, EUR C COMP VIS DUBL, V29, P159; Gremban K. D., 1988, Proceedings of the 1988 IEEE International Conference on Robotics and Automation (Cat. No.88CH2555-1), P562, DOI 10.1109/ROBOT.1988.12111; Grossberg MD, 2005, INT J COMPUT VISION, V61, P119, DOI 10.1023/B:VISI.0000043754.56350.10; Hartley R, 2007, IEEE T PATTERN ANAL, V29, P1309, DOI 10.1109/TPAMI.2007.1147; Kannala J, 2006, IEEE T PATTERN ANAL, V28, P1335, DOI 10.1109/TPAMI.2006.153; Lin SS, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P102, DOI 10.1109/ICCV.2001.937610; Micusik B, 2006, IEEE T PATTERN ANAL, V28, P1135, DOI 10.1109/TPAMI.2006.151; Salvi J, 2004, PATTERN RECOGN, V37, P827, DOI 10.1016/j.patcog.2003.10.002; STEVENSON D, 1995, 9507 TR U IOW; STRZEBONSKI A, 2008, CYLINDRICAL ALGEBRAI; STURM P, 2004, P ECCV, V2, P1; Sturm P., 1999, P IEEE C COMP VIS PA, P432, DOI DOI 10.1109/CVPR.1999.786974; Sturz AV, 2000, CRIT REV PLANT SCI, V19, P1, DOI 10.1016/S0735-2689(01)80001-0; Swaminathan R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P2, DOI 10.1109/ICCV.2001.937581; Tardif JP, 2006, LECT NOTES COMPUT SC, V3954, P186; Tardif JP, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P22, DOI 10.1109/3DIM.2005.11; TARDIF JP, 2008, CALIBRATION CAMERAS; TARDIF JP, 2007, P CVPR, P1; TARDIF JP, 2005, P IEEE INT WORKSH OM, P44; Thirthala S, 2005, PROC CVPR IEEE, P321; THIRTHALA S, 2010, P 10 IEEE INT C COMP, P1539; Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718; 2008, INTEL OPEN SOURCE CO	31	34	41	4	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2009	31	9					1552	1566		10.1109/TPAMI.2008.202	http://dx.doi.org/10.1109/TPAMI.2008.202			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	462QD	19574618	Green Submitted			2022-12-18	WOS:000267369800002
J	Liu, QH; Liao, XJ; Li, H; Stack, JR; Carin, L				Liu, Qiuhua; Liao, Xuejun; Li, Hui; Stack, Jason R.; Carin, Lawrence			Semisupervised Multitask Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multitask learning; Bayesian; Dirichlet process; semisupervised	MULTIPLE TASKS; CLASSIFICATION	Context plays an important role when performing classification and, in this paper, we examine context from two perspectives. First, the classification of items within a single task is placed within the context of distinct concurrent or previous classification tasks (multiple distinct data collections). This is referred to as multitask learning (MTL) and is implemented here in a statistical manner, using a simplified form of the Dirichlet process. In addition, when performing many classification tasks one has simultaneous access to all unlabeled data that must be classified and, therefore, there is an opportunity to place the classification of any one feature vector within the context of all unlabeled feature vectors; this is referred to as semisupervised learning. In this paper, we integrate MTL and semisupervised learning into a single framework, thereby exploiting two forms of contextual information. Results are presented on a "toy" example to demonstrate the concept, and the algorithm is also applied to three real data sets.	[Liu, Qiuhua; Liao, Xuejun; Carin, Lawrence] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA; [Li, Hui] Innovat Grp Inc, Durham, NC 27703 USA; [Stack, Jason R.] One Liberty Ctr, Off Naval Res, Arlington, VA 22203 USA	Duke University; United States Department of Defense; United States Navy	Liu, QH (corresponding author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.	ql@ece.duke.edu; xjliao@ece.duke.edu; hli@siginnovations.com; jason.stack@navy.mil; lcarin@ece.duke.edu		Carin, Lawrence/0000-0001-6277-7948				Ando RK, 2005, J MACH LEARN RES, V6, P1817; BAXTER J, 1995, P WORKSH COMP LEARN; Baxter  Jonathan, 2000, J ARTIFICIAL INTELLI; BELKIN M, 2004, P ANN C LEARN THEOR; BLACKWELL D, 1973, ANN STAT, V1, P353, DOI 10.1214/aos/1176342372; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Burr D, 2005, J AM STAT ASSOC, V100, P242, DOI 10.1198/016214504000001024; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chapelle O., 2006, IEEE T NEURAL NETW, V20, P542; Cortes C., 2004, P ADV NEUR INF PROC; Dominici F, 1997, J AGR BIOL ENVIR ST, V2, P294; Evgeniou T, 2005, J MACH LEARN RES, V6, P615; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; GANESALINGAM S, 1989, APPL STAT-J ROY ST C, V38, P455, DOI 10.2307/2347733; Glass G. V., 1976, ED RES, V5; Gould NIM, 2003, UNIVERSITEXT, P109; HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747; Hinton G. E., 1986, PARALLEL DISTRIBUTED, V1, DOI DOI 10.1234/12345678; Hoff PD, 2003, 421 U WASH STAT DEP; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; JORDAN MI, 1996, P ADV NEURAL INFORM; KRISHNAPURAM B, 2005, P ADV NEURAL INFORM; Lawrence Neil D., 2004, P 21 INT C MACH LEAR, DOI DOI 10.1145/-10111330.1015382.; LIU Q, 2007, P IEEE INT C AC SPEE; LIU Q, 2007, P ADV NEURAL INFORM; MACKAY DJC, 2003, INFORM THEORY INF LE; Mallick BK, 1997, BIOMETRIKA, V84, P697, DOI 10.1093/biomet/84.3.697; Mukhopadhyay S, 1997, J AM STAT ASSOC, V92, P633, DOI 10.2307/2965710; Muller P, 2004, J R STAT SOC B, V66, P735, DOI 10.1111/j.1467-9868.2004.05564.x; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; Scholkopf B., 2001, LEARNING KERNELS SUP; STACK JR, 2007, P SPIE DEF SEC S, V6553, P1; SZUMMER M, 2002, P ADV NEURAL INFORM; Thrun Sebastian, 1996, P 13 INT C MACH LEAR P 13 INT C MACH LEAR; TIPPING M, 2000, ADV NEUR INF PROC SY; Xue Y, 2007, J MACH LEARN RES, V8, P35; Yu K., 2005, P 22 INT C MACH LEAR; YU K, 2004, P 27 ANN INT ACM SIG; Yu K, 2003, P 19 C UNC ART INT; ZHANG J, 2006, P ADV NEURAL INFORM; Zhang Y, 2004, IEEE T GEOSCI REMOTE, V42, P2535, DOI 10.1109/TGRS.2004.836270; Zhu X., 2003, INT C MACH LEARN	42	34	37	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2009	31	6					1074	1086		10.1109/TPAMI.2008.296	http://dx.doi.org/10.1109/TPAMI.2008.296			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	431YF	19372611				2022-12-18	WOS:000265100000009
J	Hernandez-Lobato, D; Martinez-Munoz, G; Suarez, A				Hernandez-Lobato, Daniel; Martinez-Munoz, Gonzalo; Suarez, Alberto			Statistical Instance-Based Pruning in Ensembles of Independent Classifiers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Ensemble learning; bagging; random forests; ensemble pruning; instance-based pruning; Polya urn		The global prediction of a homogeneous ensemble of classifiers generated in independent applications of a randomized learning algorithm on a fixed training set is analyzed within a Bayesian framework. Assuming that majority voting is used, it is possible to estimate with a given confidence level the prediction of the complete ensemble by querying only a subset of classifiers. For a particular instance that needs to be classified, the polling of ensemble classifiers can be halted when the probability that the predicted class will not change when taking into account the remaining votes is above the specified confidence level. Experiments on a collection of benchmark classification problems using representative parallel ensembles, such as bagging and random forests, confirm the validity of the analysis and demonstrate the effectiveness of the instance-based ensemble pruning method proposed.	[Hernandez-Lobato, Daniel; Martinez-Munoz, Gonzalo; Suarez, Alberto] Univ Autonoma Madrid, Dept Comp Sci, Escuela Politecn Super, Canto Blanco 28049, Spain	Autonomous University of Madrid	Hernandez-Lobato, D (corresponding author), Univ Autonoma Madrid, Dept Comp Sci, Escuela Politecn Super, C Francisco Tomas & Valiente 11, Canto Blanco 28049, Spain.	daniel.hernandez@uam.es; gonzalo.martinez@uam.es; alberto.suarez@uam.es	Martínez-Muñoz, Gonzalo/K-7269-2012; Hernández-Lobato, Daniel/E-8337-2012; Suárez, Alberto/D-6293-2011	Martínez-Muñoz, Gonzalo/0000-0002-6125-6056; Hernández-Lobato, Daniel/0000-0001-5845-437X; Suárez, Alberto/0000-0003-4534-0909	Spanish Ministerio de Educacion y Ciencia [TIN2007-66862-C0202]; Consejeria de Educacion de la Comunidad de Madrid	Spanish Ministerio de Educacion y Ciencia(Spanish Government); Consejeria de Educacion de la Comunidad de Madrid	The authors would like to acknowledge support from the Spanish Ministerio de Educacion y Ciencia under project TIN2007-66862-C0202 and D. Hernandez-Lobato acknowledges support from Consejeria de Educacion de la Comunidad de Madrid.	Abramowitz M., 1970, HDB MATH FUNCTIONS F; Asuncion A, 2007, UCI MACHINE LEARNING; Banfield RE, 2007, IEEE T PATTERN ANAL, V29, P173, DOI 10.1109/TPAMI.2007.250609; Bishop C., 2006, RECOGNITION MACHINE; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Breiman L, 1996, 460 U CAL STAT DEP; Buhlmann P, 2003, RECENT ADVANCES AND TRENDS IN NONPARAMETRIC STATISTICS, P19, DOI 10.1016/B978-044451378-6/50002-8; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941; Esposito R., 2003, P 18 INT JOINT C ART, P499; Fan W, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P146; Freund Y., 1995, COMPUTATIONAL LEARNI, V904, P23, DOI [10.1007/3-540-59119-2_166, DOI 10.1007/3-540-59119-2_166]; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Hedenfalk I, 2001, NEW ENGL J MED, V344, P539, DOI 10.1056/NEJM200102223440801; JOHNSON N. L., 1997, DISCRETE MULTIVARIAT; Lam L, 1997, IEEE T SYST MAN CY A, V27, P553, DOI 10.1109/3468.618255; Martinez-Munoz G, 2005, PATTERN RECOGN, V38, P1483, DOI 10.1016/j.patcog.2005.02.020; Rodriguez JJ, 2006, IEEE T PATTERN ANAL, V28, P1619, DOI 10.1109/TPAMI.2006.211; Schapire RE, 1998, ANN STAT, V26, P1651; Wang H., 2003, P 9 ACM SIGKDD INT C, P226, DOI DOI 10.1145/956750.956778	21	34	36	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2009	31	2					364	369		10.1109/TPAMI.2008.204	http://dx.doi.org/10.1109/TPAMI.2008.204			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	385XL	19110500				2022-12-18	WOS:000261846800013
J	Sundaresan, A; Chellappa, R				Sundaresan, Aravind; Chellappa, Rama			Model-driven segmentation of articulating humans in Laplacian Eigenspace	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition	JUN 17-22, 2007	Minneapolis, MN	IEEE, hp invent, INI-GraphicsNet, VIOSO		pattern recognition; image processing; computer vision; segmentation; graph-theoretic methods; region growing; partitioning; object recognition		We propose a general approach using Laplacian Eigenmaps and a graphical model of the human body to segment 3D voxel data of humans into different articulated chains. In the bottom-up stage, the voxels are transformed into a high-dimensional (6D or less) Laplacian Eigenspace (LE) of the voxel neighborhood graph. We show that the LE is effective at mapping voxels on long articulated chains to nodes on smooth 1D curves that can be easily discriminated, and we prove these properties using representative graphs. We fit 1D splines to voxels belonging to different articulated chains such as the limbs, head, and trunk, and we determine the boundary between splines by thresholding the spline fit error, which is high at junctions. A top-down probabilistic approach is then used to register the segmented chains, utilizing both their mutual connectivity and their individual properties such as length and thickness. Our approach enables us to deal with complex poses such as those where the limbs form loops. We use the segmentation results to automatically estimate the human body models. Although we use human subjects in our experiments, the method is fairly general and can be applied to voxel-based registration of any articulated object, which is composed of long chains. We present results on real and synthetic data that illustrate the usefulness of this approach.	[Sundaresan, Aravind] SRI Int, Ctr Artificial Intelligence, Menlo Pk, CA 94025 USA; [Chellappa, Rama] Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA	SRI International; University System of Maryland; University of Maryland College Park	Sundaresan, A (corresponding author), SRI Int, Ctr Artificial Intelligence, 333 Ravenswood Ave, Menlo Pk, CA 94025 USA.	aravind@ai.sri.com; rama@cfar.umd.edu	Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/B-6573-2012; Chellappa, Rama/AAJ-1504-2020					Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744; [Anonymous], 2004, P OPTICAL SENSING; BADLER NI, 1993, SIMULATING HUMANS; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Black M. J., 2006, CS0608 BROWN U; BROSTOW GJ, 2004, P ECCV 04, V3, P66; Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309; Cheung GKM, 2003, PROC CVPR IEEE, P77; Choi Byoung Young, 1997, Yonsei Medical Journal, V38, P79; Chu CW, 2003, PROC CVPR IEEE, P475; Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; CORAZZA S, 2005, P 20 C INT SOC BIOM; Cox T.F., 1994, MULTIDIMENSIONAL SCA; De Mendonca MC, 2000, AM J PHYS ANTHROPOL, V112, P39, DOI 10.1002/(SICI)1096-8644(200005)112:1<39::AID-AJPA5>3.0.CO;2-#; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; KAKADIARIS IA, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P618, DOI 10.1109/ICCV.1995.466881; Krahnstoever N, 2004, PROC CVPR IEEE, P894; Mikic Ivana, 2003, INT J COMPUTER VISIO, V53; Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897; Mohar B., 1991, GRAPH THEORY COMBINA, V2, P12; Mori G, 2002, LECT NOTES COMPUT SC, V2352, P666; MUNDERMANN L, 2005, P 20 C INT SOC BIOM; Mundermann L., 2007, P IEEE C COMP VIS PA; NADLER B, 2005, P C NEUR INF PROC SY; Ozaslan A, 2003, FORENSIC SCI INT, V132, P40, DOI 10.1016/S0379-0738(02)00425-5; Ramanan D, 2003, PROC CVPR IEEE, P467; Ren XF, 2005, IEEE I CONF COMP VIS, P824; ROHR K, 1997, HUMAN MOVEMENT ANAL; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Sundaresan A, 2006, LECT NOTES COMPUT SC, V3852, P131; Sundaresan A, 2006, INT C PATT RECOG, P92; Sundaresan A, 2006, LECT NOTES COMPUT SC, V4069, P78; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319	36	34	34	1	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2008	30	10					1771	1785		10.1109/TPAMI.2007.70823	http://dx.doi.org/10.1109/TPAMI.2007.70823			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	336DQ	18703830				2022-12-18	WOS:000258344900008
J	Carneiro, G; Jepson, AD				Carneiro, Gustavo; Jepson, Allan D.			Flexible spatial configuration of local image features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						local image feature; feature clustering; visual object recognition; wide baseline matching; long-range matching	OBJECT RECOGNITION; SHAPE; APPEARANCE; RECOVERY; MODEL	Local image features have been designed to be informative and repeatable under rigid transformations and illumination deformations. Even though current state-of-the- art local image features present a high degree of repeatability, their local appearance alone usually does not bring enough discriminative power to support a reliable matching, resulting in a relatively high number of mismatches in the correspondence set formed during the data association procedure. As a result, geometric filters, commonly based on global spatial configuration, have been used to reduce this number of mismatches. However, this approach presents a trade- off between the effectiveness to reject mismatches and the robustness to nonrigid deformations. In this paper, we propose two geometric filters, based on a semilocal spatial configuration of local features, that are designed to be robust to nonrigid deformations and to rigid transformations, without compromising its efficacy to reject mismatches. We compare our methods to the Hough transform, which is an efficient and effective mismatch rejection step based on the global spatial configuration of features. In these comparisons, our methods are shown to be more effective in the task of rejecting mismatches for rigid transformations and nonrigid deformations at comparable time complexity figures. Finally, we demonstrate how we can integrate these methods in a probabilistic recognition system such that the final verification step uses not only the similarity between features but also their semilocal configuration.	Siemens Corporate Res, Integrated Data Syst Dept, Princeton, NJ 08540 USA; Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3H5, Canada	Siemens AG; University of Toronto	Carneiro, G (corresponding author), Siemens Corporate Res, Integrated Data Syst Dept, 755 Coll Rd E, Princeton, NJ 08540 USA.	gustavo.carneiro@siemens.com; jepson@cs.utoronto.ca	Carneiro, Victor/C-7016-2015	Carneiro, Victor/0000-0002-7536-9422; Carneiro, Gustavo/0000-0002-5571-6220				AGARWAL S, 2002, P ECCV, P113; Amit Y, 1999, NEURAL COMPUT, V11, P1691, DOI 10.1162/089976699300016197; BARROW HG, 1971, MACHINE INTELLIGENCE, V6; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Berg A., 2005, P IEEE C COMP VIS PA; Boyer K.L., 2000, PERCEPTUAL ORG ARTIF; BROOKS RA, 1983, IEEE T PATTERN ANAL, V5, P140, DOI 10.1109/TPAMI.1983.4767366; CARNEIRO G, 2003, P IEEE C COMP VIS PA; CARNEIRO G, 2004, P 17 IEEE INT C PATT; CARNEIRO G, 2004, P IEEE C COMP VIS PA; Carneiro G., 2005, P IEEE C COMP VIS PA; Chris H., 1988, P 4 ALVEY VISION C, P189; CHUM O, 2003, P 8 COMP VIS WINT WO; DICKINSON SJ, 1992, IEEE T PATTERN ANAL, V14, P174, DOI 10.1109/34.121788; Felzenszwalb PF, 2000, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.2000.854739; Fergus R., 2003, P IEEE C COMP VIS PA; FERRARI V, 2004, P 8 EUR C COMP VIS; Fleet DJ, 1992, MEASUREMENT IMAGE VE; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Huang CY, 1997, PROC CVPR IEEE, P877, DOI 10.1109/CVPR.1997.609431; Huet B, 2002, PATTERN RECOGN, V35, P1895, DOI 10.1016/S0031-3203(01)00172-8; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; LOWE D, 1999, P 7 INT C COMP VIS, P1550; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; Lowe DG, 2001, P IEEE C COMP VIS PA; MIKOLAJCZYK K, 2003, P 14 BRIT MACH VIS C; MORTENSEN E, 2005, P IEEE C COMP VIS PA; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; PILET J, 2005, P IEEE C COMP VIS PA; Pope AR, 2000, INT J COMPUT VISION, V40, P149, DOI 10.1023/A:1026502202780; Pritchett P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P754, DOI 10.1109/ICCV.1998.710802; Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2383, P186; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Schmid C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P485, DOI 10.1109/CVPR.1999.784725; Shokoufandeh A, 2002, LECT NOTES COMPUT SC, V2352, P759; Shokoufandeh A, 1999, IMAGE VISION COMPUT, V17, P445, DOI 10.1016/S0262-8856(98)00124-3; SIVIC J, 2004, P 8 EUR C COMP VIS; Tell D, 2000, LECT NOTES COMPUT SC, V1842, P814; TELL D, 2002, P 7 EUR C COMP VIS C, P68; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; Tuytelaars T, 2000, P 11 BRIT MACH VIS C; WEBR M, 2000, P 6 EUR C COMP VIS, P18; Yu S., 2002, NEURAL INFORM PROCES; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4	45	34	39	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2007	29	12					2089	2104		10.1109/TPAMI.2007.1126	http://dx.doi.org/10.1109/TPAMI.2007.1126			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	219LY	17934220	Green Submitted			2022-12-18	WOS:000250087900003
J	Rav-Acha, A; Pritch, Y; Lischinski, D; Peleg, S				Rav-Acha, Alex; Pritch, Yael; Lischinski, Dani; Peleg, Shmuel			Dynamosaicing: Mosaicing of dynamic scenes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						video mosaicing; dynamic scene; video editing; graph cuts; panoramic mosaicing; time manipulations; space-time volume	IMAGE	This paper explores the manipulation of time in video editing, which allows us to control the chronological time of events. These time manipulations include slowing down ( or postponing) some dynamic events while speeding up ( or advancing) others. When a video camera scans a scene, aligning all the events to a single time interval will result in a panoramic movie. Time manipulations are obtained by first constructing an aligned space-time volume from the input video, and then sweeping a continuous 2D slice ( time front) through that volume, generating a new sequence of images. For dynamic scenes, aligning the input video frames poses an important challenge. We propose to align dynamic scenes using a new notion of "dynamics constancy," which is more appropriate for this task than the traditional assumption of " brightness constancy." Another challenge is to avoid visual seams inside moving objects and other visual artifacts resulting from sweeping the space-time volumes with time fronts of arbitrary geometry. To avoid such artifacts, we formulate the problem of finding optimal time front geometry as one of finding a minimal cut in a 4D graph, and solve it using max-flow methods.	Hebrew Univ Jerusalem, Sch Engn & Comp Sci, IL-91904 Jerusalem, Israel	Hebrew University of Jerusalem	Rav-Acha, A (corresponding author), Hebrew Univ Jerusalem, Sch Engn & Comp Sci, Ross Bldg, IL-91904 Jerusalem, Israel.	alexis@cs.huji.ac.il; yaelpri@cs.huji.ac.il; danix@cs.huji.ac.il; peleg@cs.huji.ac.il	Peleg, Shmuel/B-7454-2011	Peleg, Shmuel/0000-0002-4468-2619; Lischinski, Dani/0000-0002-6191-0361				Agarwala A, 2005, ACM T GRAPHIC, V24, P821, DOI 10.1145/1073204.1073268; Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718; Bar-Joseph Z, 2001, IEEE T VIS COMPUT GR, V7, P120, DOI 10.1109/2945.928165; Barron J. L., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P236, DOI 10.1109/CVPR.1992.223269; BERGEN JR, 1992, P EUR C COMP VIS, P237; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; DORETTO G, 2003, P WORKSH TEXTURES, P25; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; Fitzgibbon AW, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P662, DOI 10.1109/ICCV.2001.937584; FREEMAN WT, 2003, P C COMP VIS PATT RE, V2, P151; Hsu S, 2002, IEEE COMPUT GRAPH, V22, P44, DOI 10.1109/38.988746; Irani M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P959, DOI 10.1109/ICCV.1998.710832; Irani M, 1996, SIGNAL PROCESS-IMAGE, V8, P327, DOI 10.1016/0923-5965(95)00055-0; KLEIN A, 2001, MSRTR200145 MICR RES; KOLMOGOROV V, 2002, P EUR C COMP VIS ECC, P65; Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264; Lombaert H, 2005, IEEE I CONF COMP VIS, P259; Peleg S, 2001, IEEE T PATTERN ANAL, V23, P279, DOI 10.1109/34.910880; Peleg S, 2000, IEEE T PATTERN ANAL, V22, P1144, DOI 10.1109/34.879794; RAVACHA A, 2005, P WORKSH DYN VIS ICC; RAVACHA A, 2005, P C COMP VIS PATT RE; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Uyttendaele M, 2001, PROC CVPR IEEE, P509; Vidal R, 2005, PROC CVPR IEEE, P516; Weiss Y, 2001, IEEE T INFORM THEORY, V47, P736, DOI 10.1109/18.910585; Wexler Y, 2004, PROC CVPR IEEE, P120; WEXLER Y, 2005, P INT C COMP VIS OCT; Zomet A, 2003, IEEE T PATTERN ANAL, V25, P741, DOI 10.1109/TPAMI.2003.1201823	30	34	41	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2007	29	10					1789	1801		10.1109/TPAMI.2007.1091	http://dx.doi.org/10.1109/TPAMI.2007.1091			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	199LA	17699923				2022-12-18	WOS:000248696100008
J	Li, H; Yezzi, A				Li, Hua; Yezzi, Anthony			Local or global minima: Flexible dual-front active contours	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						active contours; curve evolution; dual front evolution; morphological dilation; local minima; global minima; minimal path technique; level set methods; fast sweeping methods; image segmentation	LEVEL SET METHOD; IMAGE SEGMENTATION; MODEL; IMPLEMENTATION; ALGORITHMS; REGION; APPROXIMATIONS; EXTRACTION; GRADIENT; SNAKES	Most variational active contour models are designed to find local minima of data-dependent energy functionals with the hope that reasonable initial placement of the active contour will drive it toward a "desirable" local minimum as opposed to an undesirable configuration due to noise or complex image structure. As such, there has been much research into the design of complex region-based energy functionals that are less likely to yield undesirable local minima when compared to simpler edge-based energy functionals whose sensitivity to noise and texture is significantly worse. Unfortunately, most of these more "robust" region-based energy functionals are applicable to a much narrower class of imagery compared to typical edge-based energies due to stronger global assumptions about the underlying image data. Devising new implementation algorithms for active contours that attempt to capture more global minimizers of already proposed image-based energies would allow us to choose an energy that makes sense for a particular class of energy without concern over its sensitivity to local minima. Such implementations have been proposed for capturing global minima. However, sometimes the completely-global minimum is just as undesirable as a minimum that is too local. In this paper, we propose a novel, fast, and flexible dual front implementation of active contours, motivated by minimal path techniques and utilizing fast sweeping algorithms, which is easily manipulated to yield minima with variable "degrees" of localness and globalness. By simply adjusting the size of active regions, the ability to gracefully move from capturing minima that are more local (according to the initial placement of the active contour/surface) to minima that are more global allows this model to more easily obtain "desirable" minimizers (which often are neither the most local nor the most global). Experiments on various 2D and 3D images and comparisons with some active contour models and region-growing methods are also given to illustrate the properties of this model and its performance in a variety of segmentation applications.	Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA	University System of Georgia; Georgia Institute of Technology	Li, H (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.	hua.li@ece.gatech.edu; ayezzi@ece.gatech.edu	Yezzi, Anthony/AAB-4235-2020		NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE [R01NS037747] Funding Source: NIH RePORTER; NINDS NIH HHS [R01NS037747] Funding Source: Medline	NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Neurological Disorders & Stroke (NINDS)); NINDS NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Neurological Disorders & Stroke (NINDS))		Aboutanos GB, 1999, IEEE T BIO-MED ENG, V46, P1346, DOI 10.1109/10.797995; ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098; ARDON R, 2003, P 2 IEEE WORKSH VAR, P233; Bajaj C, 2003, J STRUCT BIOL, V144, P132, DOI 10.1016/j.jsb.2003.09.037; Boue M, 1999, SIAM J NUMER ANAL, V36, P667, DOI 10.1137/S0036142997323521; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Cocosco C.A., 1997, NEUROIMAGE, V5, P425, DOI DOI 10.1016/S1053-8119(97)80018-3; Cohen LD, 1997, INT J COMPUT VISION, V24, P57, DOI 10.1023/A:1007922224810; Cohen LD, 1996, PROC CVPR IEEE, P666, DOI 10.1109/CVPR.1996.517144; COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675; Cohen LD, 2001, J MATH IMAGING VIS, V14, P225, DOI 10.1023/A:1011281928379; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; Davatzikos C, 1996, IEEE T MED IMAGING, V15, P785, DOI 10.1109/42.544496; Dawood M, 2004, LECT NOTES COMPUT SC, V3212, P544; Deschamps T, 2001, MED IMAGE ANAL, V5, P281, DOI 10.1016/S1361-8415(01)00046-9; Deschamps T., 2001, THESIS U PARIS DAUPH; Dupuis P, 1994, ANN APPL PROBAB, V4, P287, DOI 10.1214/aoap/1177005063; Erdem CE, 2003, IEEE T CIRC SYST VID, V13, P310, DOI 10.1109/TCSVT.2003.811361; GEORGOULOAS G, 2002, P 2 HELL C ART INT A, P399; GIBOU F, 2005, P 4 ANN HAW INT C ST, P281; Giraldi GA, 2000, PROCEEDINGS OF THE FIFTH JOINT CONFERENCE ON INFORMATION SCIENCES, VOLS 1 AND 2, pA103; Goldenberg R, 2002, IEEE T MED IMAGING, V21, P1544, DOI 10.1109/TMI.2002.806594; Goldenberg R, 2001, IEEE T IMAGE PROCESS, V10, P1467, DOI 10.1109/83.951533; GUNN SR, 1994, P BRIT MACH VIS C YO, P305; Helmsen J, 1996, P SOC PHOTO-OPT INS, V2726, P253, DOI 10.1117/12.240959; Jehan-Besson S, 2003, INT J COMPUT VISION, V53, P45, DOI 10.1023/A:1023031708305; Kao CY, 2004, J COMPUT PHYS, V196, P367, DOI 10.1016/j.jcp.2003.11.007; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Li H, 2005, LECT NOTES COMPUT SC, V3765, P335; Li H, 2004, LECT NOTES COMPUT SC, V3216, P103; MACDONALD D, 1998, P 1 INT C MED IM COM, P650; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; Malladi R, 1996, IEEE T IMAGE PROCESS, V5, P1554, DOI 10.1109/83.541425; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; Munoz X, 2003, PATTERN RECOGN LETT, V24, P375, DOI 10.1016/S0167-8655(02)00262-3; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Paragios N, 2002, J VIS COMMUN IMAGE R, V13, P249, DOI 10.1006/jvci.2001.0475; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153; ROUY E, 1992, SIAM J NUMER ANAL, V29, P867, DOI 10.1137/0729053; SAMSON C, 1999, P INT C SCAL SPAC TH, P306; Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591; Sifakis E, 2001, SIGNAL PROCESS-IMAGE, V16, P963, DOI 10.1016/S0923-5965(00)00056-4; TEK H, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P156, DOI 10.1109/ICCV.1995.466792; Teo PC, 1997, IEEE T MED IMAGING, V16, P852, DOI 10.1109/42.650881; Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033; Tsai YHR, 2003, SIAM J NUMER ANAL, V41, P673, DOI 10.1137/S0036142901396533; Tsai YHR, 2002, J COMPUT PHYS, V178, P175, DOI 10.1006/jcph.2002.7028; TSITSIKLIS JN, 1995, IEEE T AUTOMAT CONTR, V40, P1528, DOI 10.1109/9.412624; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; XU C, 1998, P INT C MED IM COMP, P481; Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186; Xu N, 2003, PROC CVPR IEEE, P46; Yatziv L, 2006, J COMPUT PHYS, V212, P393, DOI 10.1016/j.jcp.2005.08.005; Yezzi A, 1997, IEEE T MED IMAGING, V16, P199, DOI 10.1109/42.563665; Yezzi A, 2002, J VIS COMMUN IMAGE R, V13, P195, DOI 10.1006/jvci.2001.0500; YEZZI A, 1999, P INT C IM PROC, V2, P1; ZENG X, 1999, IEEE T MED IMAGING, V18, P100; Zhao HK, 2005, MATH COMPUT, V74, P603; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	64	34	37	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2007	29	1					1	14		10.1109/TPAMI.2007.250595	http://dx.doi.org/10.1109/TPAMI.2007.250595			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	104VI	17108379	Green Submitted			2022-12-18	WOS:000241988300001
J	Tsin, YH; Kang, SB; Szeliski, R				Tsin, YH; Kang, SB; Szeliski, R			Stereo matching with linear superposition of layers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						stereo matching; layer extraction; reflection; transparency; plane sweep		In this paper, we address stereo matching in the presence of a class of non-Lambertian effects, where image formation can be modeled as the additive superposition of layers at different depths. The presence of such effects makes it impossible for traditional stereo vision algorithms to recover depths using direct color matching-based methods. We develop several techniques to estimate both depths and colors of the component layers. Depth hypotheses are enumerated in pairs, one from each layer, in a nested plane sweep. For each pair of depth hypotheses, matching is accomplished using spatial-temporal differencing. We then use graph cut optimization to solve for the depths of both layers. This is followed by an iterative color update algorithm which we proved to be convergent. Our algorithm recovers depth and color estimates for both synthetic and real image sequences.	Siemens Corp Res, Princeton, NJ 08540 USA; Microsoft Corp, Redmond, WA 98502 USA	Siemens AG; Microsoft	Tsin, YH (corresponding author), Siemens Corp Res, 755 Coll Rd E, Princeton, NJ 08540 USA.	yanghai.tsin@siemens.com; sbkang@microsoft.com; szeliski@microsoft.com						BERGEN JR, 1992, IEEE T PATTERN ANAL, V14, P886, DOI 10.1109/34.161348; BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; BRONSTEIN AM, 2003, P 4 INT S ICA BSS AP; Collins RT, 1996, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.1996.517097; DARRELL T, 1995, IEEE T PATTERN ANAL, V17, P474, DOI 10.1109/34.391395; FARID H, 1999, P CVPR, V1, P262; HARTLEY RI, 2000, MULTIPLE VIEW GEOME; Horn B., 1986, ROBOT VISION, P1; IRANI M, 1992, LECT NOTES COMPUT SC, V588, P282; Ju SX, 1996, PROC CVPR IEEE, P307, DOI 10.1109/CVPR.1996.517090; Kang SB, 2001, PROC CVPR IEEE, P103; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; LEVIN A., 2002, ADV NEURAL INFORM PR; Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Schechner Y. Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P814, DOI 10.1109/ICCV.1999.790305; Schechner YY, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1061, DOI 10.1109/ICCV.1998.710848; Schechner YY, 2000, PROC CVPR IEEE, P38, DOI 10.1109/CVPR.2000.855796; Shizawa M., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P164, DOI 10.1109/WVM.1991.212811; SHIZAWA M, 1994, INT C PATT RECOG, P321, DOI 10.1109/ICPR.1994.576288; Shizawa M., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P447, DOI 10.1109/ICCV.1993.378182; SHIZAWA M, 1990, P 10 INT C PATT REC, V1, P274; Singh M, 2002, PSYCHOL REV, V109, P492, DOI 10.1037//0033-295X.109.3.492; Swaminathan R, 2002, LECT NOTES COMPUT SC, V2350, P508; Szeliski R, 2000, PROC CVPR IEEE, P246, DOI 10.1109/CVPR.2000.855826; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981	30	34	37	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2006	28	2					290	301		10.1109/TPAMI.2006.42	http://dx.doi.org/10.1109/TPAMI.2006.42			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	991OY	16468624				2022-12-18	WOS:000233824500010
J	Gizatdinova, Y; Surakka, V				Gizatdinova, Y; Surakka, V			Feature-based detection of facial landmarks from neutral and expressive facial images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computing methodologies; image processing and computer vision; segmentation; edge and feature detection	RECOGNITION	Feature-based method for detecting landmarks from facial images was designed. The method was based on extracting oriented edges and constructing edge maps at two resolution levels. Edge regions with characteristic edge pattern formed landmark candidates. The method ensured invariance to expressions while detecting eyes. Nose and mouth detection was deteriorated by happiness and disgust.	Tampere Univ, Res Grp Emot Social & Comp, Tampere Unit Comp Human Interact, Dept Comp Sci, FIN-33014 Tampere, Finland; Tampere Univ Hosp, Dept Clin Neurophysiol, FIN-33521 Tampere, Finland	Tampere University; Tampere University; Tampere University Hospital	Gizatdinova, Y (corresponding author), Tampere Univ, Res Grp Emot Social & Comp, Tampere Unit Comp Human Interact, Dept Comp Sci, FIN-33014 Tampere, Finland.	ig74400@cs.uta.fi; Veikko.Surakka@uta.fi		Surakka, Veikko/0000-0003-3986-0713				Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905; Ekman P., 1989, HDB SOCIAL PSYCHOPHY, P143; Ekman P., 2002, FACIAL ACTION CODING; Ekman P., 2002, FACIAL ACTION CODING; Ekman P., 1975, PICTURES FACIAL AFFE; Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232; FRIDLUND AJ, 1991, BIOL PSYCHOL, V32, P3, DOI 10.1016/0301-0511(91)90003-Y; GOLOVAN A, 2000, P 2 ALL RUSS SCI C N, V1, P166; HJELMAS E, 2001, J COMPUTER VISION IM, V83, P235; Liu YX, 2003, COMPUT VIS IMAGE UND, V91, P138, DOI 10.1016/S1077-3142(03)00078-X; PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814; Schneiderman H, 1998, PROC CVPR IEEE, P45, DOI 10.1109/CVPR.1998.698586; SHAPOSHNIKOV D, 2002, J NEUROCOMPUTERS DES, V7, P21; SOBOTTKA K, 1996, P 13 INT C PATT REC, V3, P421; Surakka V, 1998, INT J PSYCHOPHYSIOL, V29, P23, DOI 10.1016/S0167-8760(97)00088-3; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; YACOOB Y, 1995, P INT WORKSH AUT FAC, P278; YANG GZ, 1994, PATTERN RECOGN, V27, P53, DOI 10.1016/0031-3203(94)90017-5; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883	20	34	35	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2006	28	1					135	139		10.1109/TPAMI.2006.10	http://dx.doi.org/10.1109/TPAMI.2006.10			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	982OR	16402625				2022-12-18	WOS:000233172000011
J	Ghosh, A; Petkov, N				Ghosh, A; Petkov, N			Robustness of shape descriptors to incomplete contour representations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						contour; COIL; deletion; depletion; distance multiset; Gollin; incompleteness; ICR test; MPEG-7; object recognition; occlusion; psychophysics; shape; shape context	PLANAR CURVES; RECOGNITION; SIMILARITY; DISTANCE; FIELD	With inspiration from psychophysical researches of the human visual system, we propose a novel aspect and a method for performance evaluation of contour-based shape recognition algorithms regarding their robustness to incompleteness of contours. We use complete contour representations of objects as a reference (training) set. Incomplete contour representations of the same objects are used as a test set. The performance of an algorithm is reported using the recognition rate as a function of the percentage of contour retained. We call this evaluation procedure the ICR test. We consider three types of contour incompleteness, viz. segment-wise contour deletion, occlusion, and random pixel depletion. As an illustration, the robustness of two shape recognition algorithms to contour incompleteness is evaluated. These algorithms use a shape context and a distance multiset as local shape descriptors. Qualitatively, both algorithms mimic human visual perception in the sense that recognition performance monotonously increases with the degree of completeness and that they perform best in the case of random depletion and worst in the case of occluded contours. The distance multiset method performs better than the shape context method in this test framework.	Univ Groningen, Inst Math & Comp Sci, NL-9700 AV Groningen, Netherlands	University of Groningen	Ghosh, A (corresponding author), Univ Groningen, Inst Math & Comp Sci, POB 800, NL-9700 AV Groningen, Netherlands.	anarta@cs.rug.nl; petkov@cs.rug.nl						ALOIMONOS J, 1988, P IEEE, V76, P899, DOI 10.1109/5.5964; Bartolini I, 2005, IEEE T PATTERN ANAL, V27, P142, DOI 10.1109/TPAMI.2005.21; Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1; BELKASIM SO, 1991, PATTERN RECOGN, V24, P1117, DOI 10.1016/0031-3203(91)90140-Z; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154; BRADY M, 1983, HUMAN MACHINE VISION, P39; BURT PJ, 1988, P IEEE, V76, P1006, DOI 10.1109/5.5971; Chihman V, 2004, PERCEPTION, V33, P76; Chuang GCH, 1996, IEEE T IMAGE PROCESS, V5, P56, DOI 10.1109/83.481671; Cross ADJ, 1998, IEEE T PATTERN ANAL, V20, P1236, DOI 10.1109/34.730557; DAVIS LS, 1986, HDB PATTERN RECOGNIT, P233; FOREMAN N, 1987, PERCEPTION, V16, P543, DOI 10.1068/p160543; Gavrila DM, 1998, INT C PATT RECOG, P439, DOI 10.1109/ICPR.1998.711175; GOLLIN ES, 1960, PERCEPT MOTOR SKILL, V11, P289; GOSHTASBY A, 1985, IEEE T PATTERN ANAL, V7, P738, DOI 10.1109/TPAMI.1985.4767734; Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P1274, DOI 10.1109/TIP.2003.816010; Grigorescu C, 2004, IMAGE VISION COMPUT, V22, P609, DOI 10.1016/j.imavis.2003.12.004; Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P729, DOI 10.1109/TIP.2003.814250; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Huttenlocher DP, 1999, IEEE T PATTERN ANAL, V21, P951, DOI 10.1109/34.790437; KOENDERINK JJ, 1978, BIOL CYBERN, V30, P157, DOI 10.1007/BF00337144; Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802; LATECKI LJ, 1998, P IEEE C COMP VIS PA, P424; Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820; PAPADIMITROIOU C, 1982, COMBINATORIAL OPTIMI; PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029; PELEG S, 1981, IEEE T PATTERN ANAL, V3, P208, DOI 10.1109/TPAMI.1981.4767082; PETKOV N, 2003, 2003907 U GRON I MAT; Petrakis EGM, 2002, IEEE T PATTERN ANAL, V24, P1501, DOI 10.1109/TPAMI.2002.1046166; PROKOP RJ, 1992, CVGIP-GRAPH MODEL IM, V54, P438, DOI 10.1016/1049-9652(92)90027-U; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; Shelepin Y, 2004, PERCEPTION, V33, P85; Veltkamp R., 1999, UUCS199927	37	34	38	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2005	27	11					1793	1804		10.1109/TPAMI.2005.225	http://dx.doi.org/10.1109/TPAMI.2005.225			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	963SN	16285377	Green Submitted			2022-12-18	WOS:000231826300009
J	Suk, T; Flusser, J				Suk, T; Flusser, J			Projective moment invariants	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						projective transform; moment invariants; object recognition	PATTERN-RECOGNITION; IMAGE-ANALYSIS; ROTATION	The paper is devoted to the moment invariants with respect to projective transform. It has been a common belief that such invariants do not exist. We show that projective moment invariants exist in a form of infinite series containing moments with positive as well as negative indices.	Acad Sci Czech Republ, Inst Informat Theory & Automat, CR-18208 Prague 8, Czech Republic	Czech Academy of Sciences; Institute of Information Theory & Automation of the Czech Academy of Sciences	Suk, T (corresponding author), Acad Sci Czech Republ, Inst Informat Theory & Automat, CR-18208 Prague 8, Czech Republic.	suk@utia.cas.cz; flusser@utia.cas.cz	Suk, Tomas/H-3073-2014; Flusser, Jan/F-6209-2014	Flusser, Jan/0000-0003-3747-9214				ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698, DOI 10.1109/TPAMI.1984.4767594; ASTROM K, 1995, IEEE T PATTERN ANAL, V17, P77, DOI 10.1109/34.368148; BELKASIM SO, 1991, PATTERN RECOGN, V24, P1117, DOI 10.1016/0031-3203(91)90140-Z; Flusser J, 2000, PATTERN RECOGN, V33, P1405, DOI 10.1016/S0031-3203(99)00127-2; FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H; Flusser J, 1998, IEEE T PATTERN ANAL, V20, P590, DOI 10.1109/34.683773; Flusser J, 1999, INT J PATTERN RECOGN, V13, P1123, DOI 10.1142/S021800149900063X; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109; LENZ R, 1994, PATTERN RECOGN, V27, P1523, DOI 10.1016/0031-3203(94)90130-9; Mindru F, 2004, COMPUT VIS IMAGE UND, V94, P3, DOI 10.1016/j.cviu.2003.10.011; Mundy J., 1992, GEOMETRIC INVARIANCE; RAO NSV, 1992, IEEE T ROBOTIC AUTOM, V8, P480, DOI 10.1109/70.149946; Reiss T.H., 1993, RECOGNIZING PLANAR O; REISS TH, 1991, IEEE T PATTERN ANAL, V13, P830, DOI 10.1109/34.85675; ROTHWELL CA, 1994, P INT C COMP VIS, P573; ROTHWELL CA, 1992, P 2 EUR C COMP VIS, P757; Suk T, 1996, PATTERN RECOGN, V29, P361, DOI 10.1016/0031-3203(94)00094-8; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913; VANGOOL L, 1995, IMAGE VISION COMPUT, V13, P259, DOI 10.1016/0262-8856(95)99715-D; VANGOOL L, 1996, P 4 EUR C COMP VIS C, P642; Voss K., 1995, ADAPTIVE MODELS INVA; WEISS I, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P394, DOI 10.1109/ICPR.1992.202007; WEISS I, 1988, P IMAGE UNDERSTANDIN, P1125; Zhang YI, 2002, PATTERN RECOGN, V35, P211, DOI 10.1016/S0031-3203(01)00018-8	26	34	35	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2004	26	10					1364	U3		10.1109/TPAMI.2004.89	http://dx.doi.org/10.1109/TPAMI.2004.89			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	844EM	15641722				2022-12-18	WOS:000223140200010
J	Bartoli, A; Sturm, P				Bartoli, A; Sturm, P			Nonlinear estimation of the fundamental matrix with minimal parameters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						structure-from-motion; bundle adjustment; minimal parameterization; fundamental matrix		The purpose of this paper is to give a very simple method for nonlinearly estimating the fundamental matrix using the minimum number of seven parameters. Instead of minimally parameterizing it, we rather update what we call its orthonormal representation, which is based on its singular value decomposition. We show how this method can be used for efficient bundle adjustment of point features seen in two views. Experiments on simulated and real data show that this implementation performs better than others in terms of computational cost, i.e., convergence is faster, although methods based on minimal parameters are more likely to fall into local minima than methods based on redundant parameters.	INRIA Rhone Alpes, F-38334 Saint Ismier, France		Bartoli, A (corresponding author), INRIA Rhone Alpes, 655 Ave Europe, F-38334 Saint Ismier, France.	Adrien.Bartoli@inria.fr; Peter.Sturm@inria.fr						ATKINSON KB, 1996, CLOSE RANGE PHOTOGRA; BARTOLI A, 2001, P 8 INT C COMP VIS V, V1, P593; BARTOLI A, 2001, 4236 INRIA; BARTOLI A, 2002, P 7 EUR C COMP VIS, V2, P340; Hartley R. I., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), P1064, DOI 10.1109/ICCV.1995.466816; HARTLEY RI, 1994, IEEE T PATTERN ANAL, V16, P1036, DOI 10.1109/34.329005; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P1310, DOI 10.1109/34.41368; KANATANI K, 2001, IEEE T INFORMATION T, V47; Levenberg K., 1944, Q APPL MATH, V2, P164, DOI 10.1090/qam/10666; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Luong QT, 1996, COMPUT VIS IMAGE UND, V64, P193, DOI 10.1006/cviu.1996.0055; Luong QT, 1996, INT J COMPUT VISION, V17, P43, DOI 10.1007/BF00127818; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P2; MCLAUCHLAN PF, 1999, P MULT WORKSH; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; STUELPNA.J, 1964, SIAM REV, V6, P422, DOI 10.1137/1006093; Torr P., 2000, COMPUTER VISION IMAG, V78; Torr PHS, 1998, COMPUT VIS IMAGE UND, V71, P312, DOI 10.1006/cviu.1997.0559; Triggs B., 2000, P INT WORKSH VIS ALG; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Wild C.J., 1989, NONLINEAR REGRESSION; Zhang Z, 2001, COMPUT VIS IMAGE UND, V82, P174, DOI 10.1006/cviu.2001.0909; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561	24	34	37	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2004	26	3					426	432		10.1109/TPAMI.2004.1262342	http://dx.doi.org/10.1109/TPAMI.2004.1262342			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	773WZ	15376890	Green Submitted			2022-12-18	WOS:000188949400014
J	Matsakis, P; Keller, JM; Sjahputera, O; Marjamaa, J				Matsakis, P; Keller, JM; Sjahputera, O; Marjamaa, J			The use of force histograms for affine-invariant relative position description	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						affine transformations; force histograms; spatial relations; descriptors; invariants; computer vision	PATTERN-RECOGNITION; SIMILARITY RETRIEVAL; REPRESENTATION; IMAGES	Affine invariant descriptors have been widely used for recognition of objects regardless of their position, size, and orientation in space. Examples of color, texture, and shape descriptors abound in the literature. However, many tasks in computer vision require looking not only at single objects or regions in images but also at their spatial relationships. In an earlier work, we showed that the relative position of two objects can be quantitatively described by a histogram of forces. Here, we study how affine transformations affect this descriptor. The position of an object with respect to another changes when the objects are affine transformed. We analyze the link between 1) the applied affinity, 2) the relative position before transformation (described through a force histogram), and 3) the relative position after transformation. We show that any two of these elements allow the third one to be recovered. Moreover, it is possible to determine whether (or how well) two relative positions are actually related through an affine transformation. If they are not, the affinity that best approximates the unknown transformation can be retrieved, and the quality of the approximation assessed.	Univ Guelph, Dept Comp & Informat Sci, Guelph, ON N1G 2W1, Canada; Univ Missouri, Dept Comp Engn & Comp Sci, Columbia, MO 65211 USA; Boeing Co, St Louis, MO USA	University of Guelph; University of Missouri System; University of Missouri Columbia; Boeing	Matsakis, P (corresponding author), Univ Guelph, Dept Comp & Informat Sci, Guelph, ON N1G 2W1, Canada.	matsakis@cis.uoguelph.ca; Keller@missouri.edu; osb1e@tnizzou.edu; jonathon.e.marjamaa@boeing.com						ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206; Aschwanden P., 1992, ROBUST COMPUTER VISI, P268; BURKHARDT H, 1992, P INV REC ESPRIT WOR; CHANDLER DE, 1992, MICROSC RES TECHNIQ, V22, P1, DOI 10.1002/jemt.1070220102; Cheng Y, 1996, COMPUT VIS IMAGE UND, V63, P197, DOI 10.1006/cviu.1996.0014; COHEN FS, 1995, IEEE T IMAGE PROCESS, V4, P1, DOI 10.1109/83.350818; Cutnell J. D., 2001, PHYSICS, V5; Dutta S., 1991, International Journal of Approximate Reasoning, V5, P307, DOI 10.1016/0888-613X(91)90015-E; ESHERA MA, 1986, IEEE T PATTERN ANAL, V8, P604, DOI 10.1109/TPAMI.1986.4767835; FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P222, DOI 10.1109/91.236554; LEE SY, 1992, PATTERN RECOGN, V25, P305, DOI 10.1016/0031-3203(92)90112-V; LEVITT TS, 1990, ARTIF INTELL, V44, P305, DOI 10.1016/0004-3702(90)90027-W; LI B, 1994, P 12 IAPR INT C PATT, V1, P352; Matsakis P, 1999, IEEE T PATTERN ANAL, V21, P634, DOI 10.1109/34.777374; Matsakis P, 2002, STUD FUZZ SOFT COMP, V106, P99; Matsakis P, 2000, INT C PATT RECOG, P451, DOI 10.1109/ICPR.2000.906109; Matsakis P, 2001, IEEE T SYST MAN CY B, V31, P573, DOI 10.1109/3477.938261; MATSAKIS P, 1998, THESIS I RECHERCHE I; Medasani S., 1999, FUZZ-IEEE'99. 1999 IEEE International Fuzzy Systems. Conference Proceedings (Cat. No.99CH36315), P1251, DOI 10.1109/FUZZY.1999.790081; MINDRU F, 1999, IEEE C COMP VIS PATT, V1, P368; MIYAJIMA K, 1994, FUZZY SET SYST, V65, P225, DOI 10.1016/0165-0114(94)90021-3; Mokhtarian F, 2002, PATTERN RECOGN, V35, P31, DOI 10.1016/S0031-3203(01)00040-1; PAPPIS CP, 1993, FUZZY SET SYST, V56, P171, DOI 10.1016/0165-0114(93)90141-4; Petrakis EGM, 2002, IMAGE VISION COMPUT, V20, P59, DOI 10.1016/S0262-8856(01)00077-4; REISS TH, 1991, IEEE T PATTERN ANAL, V13, P830, DOI 10.1109/34.85675; Rothe I, 1996, IEEE T PATTERN ANAL, V18, P366, DOI 10.1109/34.491618; Santini S, 1999, IEEE T PATTERN ANAL, V21, P871, DOI 10.1109/34.790428; Schaffalitzky F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P636, DOI 10.1109/ICCV.2001.937686; SHARMA J, 1995, P INT S SPAT DAT; Shyu CR, 2001, PROC CVPR IEEE, P603; Skubic M, 2003, AUTON ROBOT, V14, P51, DOI 10.1023/A:1020927503616; SWAIN MJ, 1990, P IM UND WORKSH, P623; WANG SS, 1994, PATTERN RECOGN, V27, P1735, DOI 10.1016/0031-3203(94)90090-6; WANG XZ, 1995, FUZZY SET SYST, V73, P259, DOI 10.1016/0165-0114(94)00308-T; Yang ZW, 1999, IEEE T PATTERN ANAL, V21, P804, DOI 10.1109/34.784312; Zhao DM, 1997, PATTERN RECOGN, V30, P895, DOI 10.1016/S0031-3203(96)00126-4	39	34	36	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2004	26	1					1	18		10.1109/TPAMI.2004.1261075	http://dx.doi.org/10.1109/TPAMI.2004.1261075			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	752LF	15382682				2022-12-18	WOS:000187161400001
J	Metaxas, DN; Kakadiaris, IA				Metaxas, DN; Kakadiaris, IA			Elastically adaptive deformable models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						adaptive elastic parameters; deformable models; shape estimation; physics-based modeling; Kalman filter	NONRIGID MOTION; SHAPE; REGULARIZATION; CONSTRAINTS; PARAMETERS; RECOVERY; IMAGES	We present a novel technique for the automatic adaptation of a deformable model's elastic parameters within a Kalman filter framework for shape estimation applications The novelty of the technique is that the model's elastic parameters are not constant, but spatio-temporally varying. The variation of the elastic parameters depends on the distance of the model from the data and the rate of change of this distance. Each pass of the algorithm uses physics-based modeling techniques to iteratively adjust both the geometric and the elastic degrees of freedom of the model in response to forces that are computed from the discrepancy between the model and the data. By augmenting the state equations of an extended Kalman filter to incorporate these additional variables, we are able to significantly improve the quality of the shape estimation. Therefore, the model's elastic parameters are always initialized to the same value and they are subsequently modified depending on the data and the noise distribution. We present results demonstrating the effectiveness of our method for both two-dimensional and three-dimensional data.	Rutgers State Univ, Div Comp & Informat Sci, Piscataway, NJ 08854 USA; Univ Houston, Dept Comp Sci, Houston, TX 77204 USA	Rutgers State University New Brunswick; University of Houston System; University of Houston	Metaxas, DN (corresponding author), Rutgers State Univ, Div Comp & Informat Sci, 110 Frelinghuysen Rd, Piscataway, NJ 08854 USA.	dnm@cs.rutgers.edu; ioannisk@uh.edu		Kakadiaris, Ioannis/0000-0002-0591-1079				BLAKE A, 1994, P ACM SIGGRAPH, P185; BOLLE RM, 1991, IEEE T PATTERN ANAL, V13, P1, DOI 10.1109/34.67626; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; CHAKRABORTY A, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P846, DOI 10.1109/ICCV.1995.466849; DELINGETTE H, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P856, DOI 10.1109/CVPR.1994.323913; Dickmanns E.D., 1988, MACH VISION APPL, V1, P241; Fua P, 1997, COMPUT VIS IMAGE UND, V65, P148, DOI 10.1006/cviu.1996.0568; Gelb A., 1974, APPL OPTIMAL ESTIMAT; Grewal M, 1993, KALMAN FILTERING THE; HUANG WC, 1993, IEEE T PATTERN ANAL, V15, P611, DOI 10.1109/34.216732; Kakadiaris I, 1997, COMPUT VIS IMAGE UND, V65, P129, DOI 10.1006/cviu.1996.0580; Kakadiaris I, 2000, IEEE T PATTERN ANAL, V22, P1453, DOI 10.1109/34.895978; Kakadiaris IA, 1998, INT J COMPUT VISION, V30, P191, DOI 10.1023/A:1008071332753; KAKADIARIS IA, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P618, DOI 10.1109/ICCV.1995.466881; KAKADIARIS IA, 1996, THESIS U PENN PHILAD; Kass M., 1987, International Journal of Computer Vision, V1, P321, DOI 10.1007/BF00133570; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LARSEN OV, 1995, P INT C COMP AN IM P, P106; LARSEN OV, 1995, P 8 INT C IM AN PROC, P37; LEE D, 1988, IEEE T PATTERN ANAL, V10, P822, DOI 10.1109/34.9105; Mandal C, 1998, LECT NOTES COMPUT SC, V1496, P753, DOI 10.1007/BFb0056262; Mandal C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P805, DOI 10.1109/ICCV.1998.710810; MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032; MCINERNEY T, 1995, COMPUT MED IMAG GRAP, V19, P69, DOI 10.1016/0895-6111(94)00040-9; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; METAXAS D, 1997, INT COMP VIS OCT, V25, P42; METAXAS D, 1996, P 4 EUR C COMP VIS A, V2, P550; METAXAS DN, 1996, PHYSICS BASED DEFORM; Montaud A, 1998, J I ENERGY, V71, P2; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P730, DOI 10.1109/34.85661; SAMADANI R, 1991, P SPIE GEOM METH COM; Sclaroff S, 2001, IEEE T PATTERN ANAL, V23, P475, DOI 10.1109/34.922706; Shen DG, 2000, IEEE T PATTERN ANAL, V22, P906, DOI 10.1109/34.868689; SINGH A, 1998, DEFORMABLE MODELS ME; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; SPARR G, 1994, P 4 EUR C COMP VIS C, P471; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; TERZOPOULOS D, 1987, INT J COMPUT VISION, V1, P211, DOI 10.1007/BF00127821; Vasilescu M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P829, DOI 10.1109/CVPR.1992.223247; Vemuri B C, 1997, Med Image Anal, V1, P343, DOI 10.1016/S1361-8415(97)85006-2; VEMURI BC, 1994, ACM T GRAPHIC, V13, P177, DOI 10.1145/176579.176583; VEMURI BC, 1993, IEEE T PATTERN ANAL, V15, P668, DOI 10.1109/34.221168; Vemuri BC, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P427, DOI 10.1109/ICCV.1998.710754; Wahba G., 1990, SPLINE MODELS OBSERV; WANG YF, 1992, IEEE T PATTERN ANAL, V14, P572, DOI 10.1109/34.134061; WHITAKER RT, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P822, DOI 10.1109/ICCV.1995.466853; WHITTEN G, 1993, IEEE T PATTERN ANAL, V15, P797; Xu CY, 1998, SIGNAL PROCESS, V71, P131, DOI 10.1016/S0165-1684(98)00140-6; ZHOU L, 2001, GRAPH MODELS, V63, P1; Zienkiewicz OC, 1977, FINITE ELEMENT METHO; [No title captured]	58	34	34	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2002	24	10					1310	1321		10.1109/TPAMI.2002.1039203	http://dx.doi.org/10.1109/TPAMI.2002.1039203			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	596ZF					2022-12-18	WOS:000178196300002
J	Watanabe, T; Sugawara, K; Sugihara, H				Watanabe, T; Sugawara, K; Sugihara, H			A new pattern representation scheme using data compression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multimedia; pattern; analysis; categorization; recognition; feature space; compression ratio; generality; VQ	SHAPE; CLASSIFICATION; SEGMENTATION; RECOGNITION; IMAGES; MODEL; RELAXATION	We propose a new pattern representation scheme based on data compression, or PRDC, for media data analysis. PRDC is composed of two parts, an encoder that translates input data into a text and a set of text compressors to generate a compression ratio vector (CV). The CV is used as a feature of the input data. By preparing a set of media-specific encoders, PRDC becomes widely applicable. Analysis tasks, both categorization (class formation) and recognition (classification), can be realized using CVs. After a mathematical discussion on the realizability of PRDC, the wide applicability of this scheme is demonstrated through automatic categorization and/or recognition of music, voice, genome, handwritten sketches, and color images.	Univ Electrocommun, Grad Sch Informat Syst, Chofu, Tokyo 1828585, Japan	University of Electro-Communications - Japan	Watanabe, T (corresponding author), Univ Electrocommun, Grad Sch Informat Syst, 1-5-1 Chofu Ga Oka, Chofu, Tokyo 1828585, Japan.							ALT FL, 1962, J ACM, V9, P240, DOI 10.1145/321119.321122; Bandyopadhyay S, 2001, IEEE T GEOSCI REMOTE, V39, P303, DOI 10.1109/36.905238; Baraldi A, 2001, IEEE T GEOSCI REMOTE, V39, P994, DOI 10.1109/36.921417; CHAITIN GJ, 1987, ALGORITHMIC INFORMAT; CHANG SK, 1987, IEEE T PATTERN ANAL, V9, P413, DOI 10.1109/TPAMI.1987.4767923; Clarke R. J., 1995, DIGITAL COMPRESSION; Duvdevani-Bar S, 1999, INT J COMPUT VISION, V33, P201, DOI 10.1023/A:1008102413960; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GERSHO A, 1997, VECTOR QUANTIZATION; GIBSON JD, 1998, DIGITAL COMPRESSION; GRUEN A., 1995, AUTOMATIC EXTRACTION; HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7; HE Y, 1991, IEEE T PATTERN ANAL, V13, P1172, DOI 10.1109/34.103276; Hopcroft John E., 1979, INTRO AUTOMATA THEOR; IMPEDOVO S, 1994, NATO ASI SERIES, V124; KARTIKEYAN B, 1989, IEEE T PATTERN ANAL, V11, P977, DOI 10.1109/34.35501; KIM WY, 1991, IEEE T PATTERN ANAL, V13, P224, DOI 10.1109/34.75511; Koch C., 1989, METHODS NEURONAL MOD; KOHONEN T, 1995, SELF ROG MAPS; Kolmogorov A. N., 1968, International Journal of Computer Mathematics, V2, P157, DOI 10.1080/00207166808803030; KONDOU K, 1997, J IPSJ, V38, P2468; KORFHAGE R, 1997, INFORMATION STORAGE; LAFACE P, 1990, NATO ASI SERIES, V75; Leighton F.T., 1992, INTRO PARALLEL ALGOR; LEMPEL A, 1976, IEEE T INFORM THEORY, V22, P75, DOI 10.1109/TIT.1976.1055501; Lersch JR, 1996, P SOC PHOTO-OPT INS, V2758, P10, DOI 10.1117/12.243215; LIPMAN DJ, 1985, SCIENCE, V227, P1435, DOI 10.1126/science.2983426; MATHIEU C, 1992, P SOC PHOTO-OPT INS, V1652, P14, DOI 10.1117/12.59407; Melgani F, 2000, IEEE T GEOSCI REMOTE, V38, P287, DOI 10.1109/36.823921; OHTA Y, 1989, KNOWLEDGE BASED INTE; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; PERL J, 1986, ARTIF INTELL, V29, P241; RABINAR L, 1993, FUNDAMENTALS SPEECH; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RECHARDS JA, 1999, REMOTE SENSING DIGIT; ROSENFELD A, 1986, DIGITAL PICTURE PROC; SHINADA T, 2001, P CVIM, V2001, P25; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; Solberg AHS, 1996, IEEE T GEOSCI REMOTE, V34, P100, DOI 10.1109/36.481897; SUGAWARA K, 2001, P 6 INT S ART LIF RO, P246; TAKEI J, 1981, CAPITAL TOKYO OBSERV; TON JC, 1991, IEEE T GEOSCI REMOTE, V29, P222, DOI 10.1109/36.73663; UCHIYAMA T, 1994, IEEE T PATTERN ANAL, V16, P1197, DOI 10.1109/34.387488; WATANABE T, 2000, P MVA2000 NOV, P596; Worthington PL, 2001, IEEE T PATTERN ANAL, V23, P535, DOI 10.1109/34.922711; YOSHIDA T, 1994, IEEE T GEOSCI REMOTE, V32, P1103, DOI 10.1109/36.312899; YOUNG TY, 1986, HDB PATTERN RECOGNIT; ZIV J, 1977, IEEE T INFORM THEORY, V23, P337, DOI 10.1109/TIT.1977.1055714	51	34	34	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2002	24	5					579	590		10.1109/34.1000234	http://dx.doi.org/10.1109/34.1000234			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	544XU					2022-12-18	WOS:000175187800002
J	Zhou, L; Kambhamettu, C; Goldgof, DB; Palaniappan, K; Hasler, AF				Zhou, L; Kambhamettu, C; Goldgof, DB; Palaniappan, K; Hasler, AF			Tracking nonrigid motion and structure from 2D satellite cloud images without correspondences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nonrigid objects; structure estimation; image motion estimation; fluid models	TROPICAL CYCLONE; WIND FIELDS; FLUID-FLOW; SEQUENCE	Tracking both structure and motion of nonrigid objects from monocular images is an important problem in vision. In this paper, a hierarchical method which integrates local analysis (that recovers small details) and global analysis (that appropriately limits possible nonrigid behaviors) is developed to recover dense depth values and nonrigid motion from a sequence of 2D satellite cloud images without any prior knowledge of point correspondences. This problem is challenging not only due to the absence of correspondence information but also due to the lack of depth cues in the 2D cloud images (scaled orthographic projection). In our method, the cloud images are segmented into several small regions and local analysis is performed for each region. A recursive algorithm is proposed to integrate local analysis with appropriate global fluid model constraints, based on which a structure and motion analysis system, SMAS, is developed. We believe that this is the first reported system in estimating dense structure and nonrigid motion under scaled orthographic views using fluid model constraints. Experiments on cloud image sequences captured by meteorological satellites (GOES-8 and GOES-9) have been performed using our system, along with their validation and analyses. Both structure and 3D motion correspondences are estimated to subpixel accuracy. Our results are very encouraging and have many potential applications in earth and space sciences, especially in cloud models for weather prediction.	Univ Delaware, Dept Comp & Informat Sci, VIMS Lab, Newark, DE 19716 USA; Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA; Univ Missouri, Dept Comp Engn & Comp Sci, Multimedia Commun & Visualizat Lab, Columbia, MO 65211 USA; NASA, Goddard Space Flight Ctr, Atmospheres Lab, Greenbelt, MD 20771 USA	University of Delaware; State University System of Florida; University of South Florida; University of Missouri System; University of Missouri Columbia; National Aeronautics & Space Administration (NASA); NASA Goddard Space Flight Center	Zhou, L (corresponding author), Univ Delaware, Dept Comp & Informat Sci, VIMS Lab, Newark, DE 19716 USA.	lzhou@cis.udel.edu; chandra@cis.udel.edu; goldgof@csee.usf.edu; palani@cecs.missouri.edu	Palaniappan, Kannappan/A-3231-2008; Goldgof, Dmitry/ABF-1366-2020					AGGARWAL JK, 1975, IEEE T COMPUT, V24, P966, DOI 10.1109/T-C.1975.224102; CHELLAPPA R, 1999, P INT C IM PROC S1, pP26; EMIN EM, 1999, P IEEE CS INT C COMP, P620; FORD RM, 1995, GRAPH MODEL IM PROC, V57, P462, DOI 10.1006/gmip.1995.1040; FUJITA T, 1968, 71 U CHIC DEP GEOPH, P25; Hasler AF, 1998, B AM METEOROL SOC, V79, P2483, DOI 10.1175/1520-0477(1998)079<2483:HRWFWT>2.0.CO;2; HASLER AF, 1981, B AM METEOROL SOC, V62, P194, DOI 10.1175/1520-0477(1981)062<0194:SOFGSA>2.0.CO;2; HASLER AF, 1986, J CLIM APPL METEOROL, V25, P709, DOI 10.1175/1520-0450(1986)025<0709:HSAWFF>2.0.CO;2; HASLER AF, 1983, MONTHLY WEATHER REV, V111, P1949; HASLER AF, 1990, WEATHER SATELLITES S, P231; JORGENSEN DP, 1984, J ATMOS SCI, V41, P1268, DOI 10.1175/1520-0469(1984)041<1268:MACSCO>2.0.CO;2; Kambhamettu C., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P43, DOI 10.1109/ISCV.1995.476975; Kambhamettu C, 2001, 17TH INTERNATIONAL CONFERENCE ON INTERACTIVE INFORMATION AND PROCESSING SYSTEMS (IIPS) FOR METEOROLOGY, OCEANOGRAPHY, AND HYDROLOGY, P318; Kambhamettu C, 1996, P SOC PHOTO-OPT INS, V2812, P122, DOI 10.1117/12.254061; KAMBHAMETTU C, 1994, HDB PATTERN RECOGNIT, V2, P405; KAMBHAMETTU CS, 1994, THESIS U S FLORIDA; Leese J.A., 1971, J APPL METEOR, V10, P118, DOI [10.1175/1520-0450(1971)0102.0.CO;2, DOI 10.1175/1520-0450(1971)0102.0.CO;2]; Maurizot M, 1998, PROC CVPR IEEE, P184, DOI 10.1109/CVPR.1998.698607; MINNIS P, 1990, MON WEATHER REV, V118, P2426, DOI 10.1175/1520-0493(1990)118<2426:TOFICC>2.0.CO;2; Palaniappan K, 1996, 10TH INTERNATIONAL PARALLEL PROCESSING SYMPOSIUM - PROCEEDINGS OF IPPS '96, P864, DOI 10.1109/IPPS.1996.508193; PALANIAPPAN K, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P659, DOI 10.1109/ICCV.1995.466773; PALANIAPPAN K, 1998, P SPIE PAR DISTR MET, V2, P958; PERRY AE, 1987, ANNU REV FLUID MECH, V19, P125, DOI 10.1146/annurev.fluid.19.1.125; PHILLIPS DR, 1972, J APPL METEOROL, V11, P752; RODGERS EB, 1983, MON WEATHER REV, V111, P1599, DOI 10.1175/1520-0493(1983)111<1599:ASSTTE>2.0.CO;2; SMITH EA, 1972, IEEE T COMPUT, VC 21, P715, DOI 10.1109/T-C.1972.223574; Velden CS, 1997, B AM METEOROL SOC, V78, P173, DOI 10.1175/1520-0477(1997)078<0173:UTWDFG>2.0.CO;2; Velden CS, 1996, METEOROL ATMOS PHYS, V60, P37, DOI 10.1007/BF01029784; VELDEN CS, 1998, MONTHLY WEATHER REV; WENG JY, 1987, IEEE T PATTERN ANAL, V9, P370, DOI 10.1109/TPAMI.1987.4767920; Wildes RP, 2000, COMPUT VIS IMAGE UND, V80, P246, DOI 10.1006/cviu.2000.0874; YOUNG GSJ, 1990, IEEE T PATTERN ANAL, V12, P735, DOI 10.1109/34.57666; ZHOU L, 1998, P IND C COMP VIS GRA, P285; ZHOU L, 1999, COMPUTER VISION PATT, V2, P280; ZHOU L, 2001, THESIS U DELAWARE	35	34	37	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2001	23	11					1330	1336						7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	491KV					2022-12-18	WOS:000172108300009
J	van de Weijer, J; van Vliet, LJ; Verbeek, PW; van Ginkel, M				van de Weijer, J; van Vliet, LJ; Verbeek, PW; van Ginkel, M			Curvature estimation in oriented patterns using curvilinear models applied to gradient vector fields	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						oriented patterns; anisotropy; curvature; confidence measures; curvilinear models; gradient vector fields	IMAGES; FLOW	Curved oriented patterns are dominated by high frequencies and exhibit zero gradients on ridges and valleys. Existing curvature estimators fail here. The characterization of curved oriented patterns based on translation invariance lacks an estimation of local curvature and yields a biased curvature-dependent confidence measure. Using parameterized curvilinear models we measure the amount of local gradient energy along the model gradient as a function of model curvature. Minimizing the residual energy yields a closed-form solution for the local curvature estimate and the corresponding confidence measure. We show that simple curvilinear models are applicable in the analysis of a wide variety of curved oriented patterns.	Univ Amsterdam, ISIS Grp, Fac Sci, NL-1098 SJ Amsterdam, Netherlands; Delft Univ Technol, Fac Appl Phys, Pattern Recognit Grp, NL-2628 CJ Delft, Netherlands	University of Amsterdam; Delft University of Technology	van de Weijer, J (corresponding author), Univ Amsterdam, ISIS Grp, Fac Sci, Kruislaan 403, NL-1098 SJ Amsterdam, Netherlands.	joostw@wins.uva.nl; L.J.vanVliet@ph.tn.tudelft.nl; P.W.Verbeek@ph.tn.tudelft.nl; michael@ph.tn.tudelft.nl	van de Weijer, Joost/A-1643-2009; van Vliet, Lucas/E-1678-2012	van de Weijer, Joost/0000-0002-9656-9706; van Vliet, Lucas/0000-0001-7018-726X				BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668; Bigun J, 1997, COMPUT VIS IMAGE UND, V68, P290, DOI 10.1006/cviu.1997.0556; BIGUN J, 1995, J VIS COMMUN IMAGE R, V6, P154, DOI 10.1006/jvci.1995.1014; Breton P, 1996, PROC CVPR IEEE, P782, DOI 10.1109/CVPR.1996.517161; HAGLUND L., 1992, ADAPTIVE MULTIDIMENS; HANSEN O, 1992, PATTERN RECOGN LETT, V13, P253, DOI 10.1016/0167-8655(92)90076-C; Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996; KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0; KNUTSSON H, 1993, P 8 SCAND C IM PROC; Maio D, 1997, IEEE T PATTERN ANAL, V19, P27, DOI 10.1109/34.566808; Van Vliet L. J., 1993, Proceedings of the 8th Scandinavian Conference on Image Analysis, P1403; van Vliet LJ, 1995, P 1 ANN C ADV SCH CO, P442; VANGINKEL M, 1999, P 11 SCAND C IM AN S; VANGINKEL M, 1998, P 4 C ADV SCH COMP I, P173; Verbeek PW, 1998, INT C PATT RECOG, P528, DOI 10.1109/ICPR.1998.711197; VERBEEK PW, 1985, PATTERN RECOGN LETT, V3, P287, DOI 10.1016/0167-8655(85)90009-1; WORRING M, 1993, CVGIP-IMAG UNDERSTAN, V58, P366, DOI 10.1006/ciun.1993.1048	17	34	36	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2001	23	9					1035	1042		10.1109/34.955116	http://dx.doi.org/10.1109/34.955116			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	470RP		Green Submitted			2022-12-18	WOS:000170885200009
J	Kaban, A; Girolami, M				Kaban, A; Girolami, M			A combined latent class and trait model for the analysis and visualization of discrete data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						latent trait model; generative model; nonlinear mapping; topographic mapping; independent component analysis; clustering		We present a general framework for data analysis and visualization by means of topographic organization and clustering. Imposing distributional assumptions on the assumed underlying latent factors makes the proposed model suitable for both visualization and clustering. The system noise will be modeled in parametric form, as a member of the exponential family of distributions and this allows us to deal with different (continuous or discrete) types of observables in a unified framework. In this paper, we focus on discrete case formulations which, contrary to self organizing methods for continuous data, imply variants of Bregman divergencies as measures of dissimilarity between data and reference points and, also, define the matching nonlinear relation between latent and observable variables. Therefore, the trait variant of the model can be seen as a data-driven noisy nonlinear Independent Component Analysis, which is capable of revealing meaningful structure in the multivariate observable data and visualizing it in two dimensions. The class variant (which performs the clustering) of our model performs data-driven parametric mixture modeling. The combined (trait and class) model along with the associated estimation procedures allows us to interpret the visualization result, in the sense of a topographic ordering. One important application of this work is the discovery of underlying semantic structure in text-based documents. Experimental results on various subsets of the 20-News groups text corpus and binary coded digits data are given by way of demonstration.	Univ Paisley, Sch Informat & Commun Technol, Paisley PA1 2BE, Renfrew, Scotland	University of West Scotland	Kaban, A (corresponding author), Univ Paisley, Sch Informat & Commun Technol, Paisley PA1 2BE, Renfrew, Scotland.	ata.kaban@wpmail.paisley.ac.uk; mark.girolami@wpmail.paisley.ac.uk		Girolami, Mark/0000-0003-3008-253X				Amari S.-i., 1985, DIFFERENTIAL GEOMETR, V28; BARNDORFFNIELSE.O, 1978, INFORMATION EXPONENT; BELOUCHRANI A, 1994, P EUSIPCO, V2, P768; Bishop C., 1995, NEURAL NETWORKS PATT, P215; Bishop CM, 1998, NEUROCOMPUTING, V21, P203, DOI 10.1016/S0925-2312(98)00043-5; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; CHEESEMAN P, 1988, P 5 INT C MACH LEARN; Cheeseman P., 1996, ADV KNOWLEDGE DISCOV; Church K. W., 1995, NAT LANG ENG, V1, P163, DOI [10.1017/S1351324900000139, DOI 10.1017/S1351324900000139]; Cover T. M., 1991, ELEMENTS INFORMATION, P25; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, P148, DOI 10.1145/288627.288651; Dunmur AP, 1999, STATISTICS AND NEURAL NETWORKS, P165; Girolami M, 1998, IEEE T NEURAL NETWOR, V9, P1495, DOI 10.1109/72.728398; GIROLAMI M, 2000, P EUR S ART NEUR NET, P1; GIROLAMI M, 2000, P BCS INF RETR SPEC, P194; Girolami M., 2000, ADV INDEPENDENT COMP; Girolami M., 1999, SELF ORG NEURAL NETW; Good IJ., 1965, ESTIMATION PROBABILI; Heckerman D., 1998, MSRTR9806; HOFMANN T, 2000, P ADV NEUR INF PROC; HOFMANN T, J INTELLIGENT DATA A; Hyvarinen A, 1999, IEEE T NEURAL NETWOR, V10, P626, DOI 10.1109/72.761722; KABAN A, 2000, P 2 INT WORKSH IND C, P435; KABAN A, 2000, P 15 INT C PATT REC, V2, P748; KOHAVI R, 1997, P EUR C MACH LEARN; Kohonen T., 1995, SELF ORG MAPS, V30, DOI 10.1007/978-3-642-97610-0; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; LEWIS DD, 1992, SPEECH AND NATURAL LANGUAGE, P212; LEWIS DD, 1998, EUR C MACH LEARN, P4; MacKay DJC, 1996, FUND THEOR, V70, P259; MACKAY DJC, 1995, NUCL INSTRUM METH A, V354, P73, DOI 10.1016/0168-9002(94)00931-7; McCallum A., 1998, AAAI 98 WORKSHOP LEA, V752, P41, DOI DOI 10.1109/TSMC.1985.6313426; MCCULLLAGH P, 1985, GEN LINEAR MODELS; MCLACHLAN GT, 1907, EM ALGORITHM EXTENSI; Moustaki I, 1996, BRIT J MATH STAT PSY, V49, P313, DOI 10.1111/j.2044-8317.1996.tb01091.x; Nigam K., 1999, MACH LEARN, P1; Pajunen P, 1997, 1997 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, P1994, DOI 10.1109/ICNN.1997.614205; Peot MA, 1996, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P414; Roweis S, 1999, NEURAL COMPUT, V11, P305, DOI 10.1162/089976699300016674; SAHAMI M, 1998, THESIS STANFORD U; Sammel MD, 1997, J ROY STAT SOC B MET, V59, P667, DOI 10.1111/1467-9868.00090; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Tipping ME, 1999, ADV NEUR IN, V11, P592; VAITHYANATHAN S, 1999, P ADV NEUR INF PROC; Vinokourov A, 2000, INT C PATT RECOG, P182, DOI 10.1109/ICPR.2000.906043; Wallace D. L., 1984, APPL BAYESIAN CLASSI; Yang HH, 2000, ADV NEUR IN, V12, P687; Yang YM, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P42, DOI 10.1145/312624.312647	49	34	34	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2001	23	8					859	872		10.1109/34.946989	http://dx.doi.org/10.1109/34.946989			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	460AH		Green Submitted			2022-12-18	WOS:000170283300006
J	Tang, CK; Medioni, G; Lee, MS				Tang, CK; Medioni, G; Lee, MS			N-dimensional tensor voting and application to epipolar geometry estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						tensor; hyperplane inference; epipolar geometry; matching; robust estimation	INFERENCE; SPARSE	We address the problem of epipolar geometry estimation efficiently and effectively, by formulating it as one of hyperplane inference from a sparse and noisy point set in an 8D space. Given a set of noisy point correspondences in two images of a static scene without correspondences, even in the presence of moving objects, our method extracts good matches and rejects outliers. The methodology is novel and unconventional, since, unlike most other methods optimizing certain scalar, objective functions, our approach does not involve initialization or any iterative search in the parameter space. Therefore, it is free of the problem of local optima or poor convergence. Further, since no search is involved, it is unnecessary to impose simplifying assumption (such as affine camera or local planar homography) to the scene being analyzed for reducing the search complexity. Subject to the general epipolar constraint only, we detect wrong matches by a novel computation scheme, 8D Tensor Voting, which is an instance of the more general N-dimensional Tensor Voting framework. In essence, the input set of matches is first transformed into a sparse 8D point set. Dense, 8D tensor kernels are then used to vote for the most salient hyperplane that captures all inliers inherent in the input. With this filtered set of matches, the normalized Eight-Point Algorithm can be used to estimate the fundamental matrix accurately. By making use of efficient data structure and locality, our method is both time and space efficient despite the higher dimensionality. We demonstrate the general usefulness of our method using example image pairs for aerial image analysis, with widely different views, and from nonstatic 3D scenes (e.g., basketball game in an indoor stadium). Each example contains a considerable number of wrong matches.	Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China; Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA; Philips Res USA, Briarcliff Manor, NY 10510 USA	Hong Kong University of Science & Technology; University of Southern California; Philips; Philips Research	Tang, CK (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.	cktang@cs.ust.hk; medioni@iris.usc.edu; Mi-Suen.Lee@Philips.com						Allgower E. L., 1991, Computer-Aided Geometric Design, V8, P305, DOI 10.1016/0167-8396(91)90018-7; Chai JX, 1998, PATTERN RECOGN LETT, V19, P829, DOI 10.1016/S0167-8655(98)00032-4; Guy G, 1997, IEEE T PATTERN ANAL, V19, P1265, DOI 10.1109/34.632985; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; Nielson G. M., 1991, Proceedings Visualization '91 (Cat. No.91CH3046-0), P83, DOI 10.1109/VISUAL.1991.175782; Tang CK, 1998, IEEE T PATTERN ANAL, V20, P1206, DOI 10.1109/34.730555; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561; [No title captured]; [No title captured]; [No title captured]; [No title captured]	14	34	39	2	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2001	23	8					829	844		10.1109/34.946987	http://dx.doi.org/10.1109/34.946987			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	460AH					2022-12-18	WOS:000170283300004
J	de Vel, O; Aeberhard, S				de Vel, O; Aeberhard, S			Line-based face recognition under varying pose	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						face recognition; line-based algorithm; classification accuracy; varying pose; real-time performance	NEURAL-NETWORK; FEATURES	Much research in human face recognition involves fronto-parallel face images, constrained rotations in and out of the plane, and operates under strict imaging conditions such as controlled illumination and limited facial expressions. Face recognition using multiple views in the viewing sphere is a more difficult task since face rotations out of the imaging plane can introduce occlusion of facial structures. In this paper, we propose a novel image-based face recognition algorithm that uses a set of random rectilinear line segments of 2D face image views as the underlying image representation, together with a nearest-neighbor classifier as the line matching scheme. The combination of 1D line segments exploits the inherent coherence in one or more 2D face image views in the viewing sphere. The algorithm achieves high generalization recognition rates for rotations both in and out of the plane, is robust to scaling, and is compulationally efficient. Results show that the classification accuracy of the algorithm is superior compared with benchmark algorithms and is able to recognize test views in quasi-real-time.	Def Sci & Technol Org, Div Informat Technol, Salisbury, SA 5108, Australia; James Cook Univ N Queensland, Dept Comp Sci, Townsville, Qld 4811, Australia	Defence Science & Technology; James Cook University	de Vel, O (corresponding author), Def Sci & Technol Org, Div Informat Technol, POB 1500, Salisbury, SA 5108, Australia.							ACHERMANN B, 1996, IAM96002 U BERN I IN; AEBERHARD S, 1994, PATTERN RECOGN, V27, P1065, DOI 10.1016/0031-3203(94)90145-7; BARON RJ, 1981, INT J MAN MACH STUD, V15, P137, DOI 10.1016/S0020-7373(81)80001-6; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; Brunelli R, 1997, IMAGE VISION COMPUT, V15, P741, DOI 10.1016/S0262-8856(97)00024-3; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; DEVEL O, 1999, IN PRESS IMAGE VISIO; DEVEL O, 1997, 9709 J COOK U DEP CO; EDELMAN S, 1992, LECT NOTES COMPUT SC, V588, P787; KANADE T, 1973, PICTURE PROCESSING C; Lavine D., 1981, P IEEE C PATT REC IM, P49; Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195; Lin SH, 1997, IEEE T NEURAL NETWOR, V8, P114, DOI 10.1109/72.554196; OLLIVETTI, OLIVETTI ORACLE RES; Ranganath S, 1997, PATTERN RECOGN, V30, P1615, DOI 10.1016/S0031-3203(96)00184-7; Samaria F., 1994, P 2 IEEE WORKSH APPL; SAMARIA FS, 1994, THESIS U CAMBRIDGE C; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; VALENTIN D, 1994, PATTERN RECOGN, V27, P1209, DOI 10.1016/0031-3203(94)90006-X; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; YOU Z, 1984, COMPUT VISION GRAPH, V28, P185, DOI 10.1016/S0734-189X(84)80021-3; Zhang J, 1997, P IEEE, V85, P1423, DOI 10.1109/5.628712	23	34	35	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1999	21	10					1081	1088		10.1109/34.799912	http://dx.doi.org/10.1109/34.799912			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	248DB					2022-12-18	WOS:000083259100009
J	Marchand, E; Chaumette, F				Marchand, E; Chaumette, F			Active vision for complete scene reconstruction and exploration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D reconstruction; scene exploration; purposive and active vision; perception strategies	SYSTEM	This paper deals with the 3D structure estimation and exploration of static scenes using active vision. Our method is based on the structure from controlled motion approach that constrains camera motions to obtain an optimal estimation of the 3D structure of a geometrical primitive. Since this approach involves to gaze on the considered primitive, we have developed perceptual strategies able to perform a succession of robust estimations. This leads to a gaze planning strategy that mainly uses a representation of known and unknown areas as a basis for selecting viewpoints. This approach ensures a reconstruction as complete as possible of the scene.	INRIA Rennes, IRISA, Vista Project, F-35042 Rennes, France		Marchand, E (corresponding author), INRIA Rennes, IRISA, Vista Project, Campus Beaulieu, F-35042 Rennes, France.	marchand@irisa.fr; chaumett@irisa.fr	Marchand, Eric/AAF-2809-2019; Francois, Chaumette/AAH-1481-2021	Marchand, Eric/0000-0001-7096-5236; Francois, Chaumette/0000-0002-1238-4385				ALOIMONOS J, 1987, INT J COMPUT VISION, V1, P333; ALOIMONOS J, 1990, 10TH P INT C PATT RE, V1, P346; Amanatides J., 1987, EUROGRAPHICS, V87, P3; BAJCSY R, 1988, P IEEE, V76, P996, DOI 10.1109/5.5968; BALL SB, 1991, ORGAN BEHAV HUM DEC, V48, P1, DOI 10.1016/0749-5978(91)90002-B; BLAKE A, 1994, ACTIVE VISION; Chaumette F, 1996, IEEE T PATTERN ANAL, V18, P492, DOI 10.1109/34.494639; Connolly C., 1985, 1985 IEEE INT C ROBO, P432; COWAN CK, 1988, IEEE T PATTERN ANAL, V10, P407, DOI 10.1109/34.3905; ESPIAU B, 1992, IEEE T ROBOTIC AUTOM, V8, P313, DOI 10.1109/70.143350; Hager GD, 1998, COMPUT VIS IMAGE UND, V69, P23, DOI 10.1006/cviu.1997.0586; KUTULAKOS KN, 1994, P IEEE INT C ROB AUT, V2, P1365; MARCHAND E, 1996, P IEEE RSJ INT C INT, V3, P1083; MARCHAND E, 1997, P IEEE INT C ROB AUT, V1, P743; MARCHAND E, 1998, 1156 IRISA INRIA; MAVER J, 1993, IEEE T PATTERN ANAL, V15, P417, DOI 10.1109/34.211463; NELSON BJ, 1995, INT J ROBOT RES, V14, P255, DOI 10.1177/027836499501400304; TARABANIS KA, 1995, IEEE T ROBOTIC AUTOM, V11, P86, DOI 10.1109/70.345940; TARABANIS KA, 1995, IEEE T ROBOTIC AUTOM, V11, P72, DOI 10.1109/70.345939; TRIGGS B, 1995, P IEEE INT C ROB AUT, V2, P1732; VAILLANT R, 1990, P 1 EUR C COMP VIS E, P454; WHAITE P, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P339, DOI 10.1109/CVPR.1994.323849; WIXSON L, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P800, DOI 10.1109/CVPR.1994.323902	23	34	36	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1999	21	1					65	72		10.1109/34.745736	http://dx.doi.org/10.1109/34.745736			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	163DZ		Green Published			2022-12-18	WOS:000078388900009
J	Ben-Arie, J; Wang, ZQ				Ben-Arie, J; Wang, ZQ			Pictorial recognition of objects employing affine invariance in the frequency domain	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						affine invariant recognition; model-based segmentation; affine invariant spectral signatures (AISS); multidimensional indexing; Gabor kernels	MOMENT INVARIANTS	This paper describes an efficient approach to pose invariant pictorial object recognition employing spectral signatures of image patches that correspond to object surfaces which are roughly planar. Based on Singular Value Decomposition (SVD), the affine transform is decomposed into slant, tilt, swing, scale, and 2D translation. Unlike previous log-polar representations which were not invariant to slant (i.e., foreshortening only in one direction), our log-log sampling configuration in the frequency domain yields complete affine invariance. The images are preprocessed by a novel model-based segmentation scheme that detects and segments objects that are affine-similar to members of a model set of basic geometric shapes. The segmented objects are then recognized by their signatures using multidimensional indexing in a pictorial dataset represented in the frequency domain. Experimental results with a dataset of 26 models show 100 percent recognition rates in a wide range of 3D pose parameters and imaging degradations: 0-360 degrees swing and tilt, 0-82 degrees of slant (more than 1:7 foreshortening), more than three octaves in scale change, window-limited translation, high noise levels (0 dB), and significantly reduced resolution (1:5).	Univ Illinois, Dept EECS, Chicago, IL 60607 USA	University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital	Ben-Arie, J (corresponding author), Univ Illinois, Dept EECS, M-C 154,851 S Morgan St, Chicago, IL 60607 USA.	bearie@eecs.uic.edu						ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; BENARIE J, 1996, P 1996 IEEE INT C SP, V6, P3470; BENARIE J, 1996, P ARPA IM UND WORKSH, P1277; BENARIE J, 1997, 1997 IEEE COMP SOC C; BENARIE J, 1996, P IAPR IEEE INT C PA, V1, P672; BIEDERMAN I, 1987, COMPUTATIONAL PROCES; BLACK MJ, 1996, P EUR C COMP VIS, P329; BUHMANN J, 1992, NEURAL NETWORKS SIGN, P121; CALIFANO A, 1994, IEEE T PATTERN ANAL, V16, P373, DOI 10.1109/34.277591; CASASENT D, 1976, APPL OPTICS, V15, P1795, DOI 10.1364/AO.15.001795; CIPOLLA R, 1992, INT J COMPUT VISION, V9, P83, DOI 10.1007/BF00129682; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; Edwards J, 1997, PROC CVPR IEEE, P533, DOI 10.1109/CVPR.1997.609377; FLUSSER J, 1994, PATTERN RECOGN LETT, V15, P433, DOI 10.1016/0167-8655(94)90092-2; FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H; HECHTNIELSEN R, 1994, P ARPA IM UND WORKSH, P889; MOGHADDAM B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P786, DOI 10.1109/ICCV.1995.466858; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; RAO RPN, 1995, ARTIF INTELL, V78, P461, DOI 10.1016/0004-3702(95)00026-7; Rao RPN, 1997, PROC CVPR IEEE, P540, DOI 10.1109/CVPR.1997.609378; RAO RPN, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P24, DOI 10.1109/ICCV.1995.466929; SCHWARTZ J, 1988, P IEEE C COMP VIS PA, P335; SEIBERT M, 1992, IEEE T PATTERN ANAL, V14, P107, DOI 10.1109/34.121784; Tieng QM, 1997, IEEE T PATTERN ANAL, V19, P846, DOI 10.1109/34.608288; WANG Z, 1997, P 1997 IEEE INT C IM; WECHSLER H, 1990, COMPUTATIONAL VISION; WU X, 1994, P ARPA IM UND WORKSH, P505	28	34	38	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1998	20	6					604	618		10.1109/34.683774	http://dx.doi.org/10.1109/34.683774			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZV807					2022-12-18	WOS:000074343300003
J	Borra, S; Sarkar, S				Borra, S; Sarkar, S			A framework for performance characterization of intermediate-level grouping modules	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						perceptual organization; performance evaluation; analysis of variance; ANOVA; experimental vision; intermediate level computer vision; feature grouping; performance characterization	PERCEPTUAL ORGANIZATION; DETECTION ALGORITHMS	We present five performance measures to evaluate grouping modules in the context of constrained search and indexing based object recognition. Using these measures, we demonstrate a sound experimental framework, based on statistical ANOVA tests, to compare and contrast three edge based organization modules, namely, those of Etemadi et al., Jacobs, and Sarkar-Boyer in the domain of aerial objects using 50 images. With adapted parameters, the Jacobs module performs overall the best for constraint based recognition. For fixed parameters, the Sarkar-Boyer module is the best in terms of recognition accuracy and indexing speedup, Etemadi et al.'s module performs equally well with fixed and adapted parameters while the Jacobs module is most sensitive to fixed and adapted parameter choices. The overall performance ranking of the modules is Jacobs, Sarkar-Boyer, and Etemadi et al.	UNIV S FLORIDA,DEPT COMP SCI & ENGN,TAMPA,FL 33620	State University System of Florida; University of South Florida			Sarkar, Sudeep/ABD-7629-2021; Sarkar, Sudeep/A-8213-2009	Sarkar, Sudeep/0000-0001-7332-4207; Sarkar, Sudeep/0000-0001-7332-4207				Barron J. L., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P236, DOI 10.1109/CVPR.1992.223269; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CLEMENS DT, 1991, IEEE T PATTERN ANAL, V13, P1007, DOI 10.1109/34.99235; ETEMADI A, 1991, P BRIT MACH VIS C, P119; GRIMSON WEL, 1991, IEEE T PATTERN ANAL, V13, P920, DOI 10.1109/34.93810; HARALICK RM, 1994, CVGIP-IMAG UNDERSTAN, V60, P245, DOI 10.1006/cviu.1994.1055; Jacobs DW, 1996, IEEE T PATTERN ANAL, V18, P23, DOI 10.1109/34.476008; KANUNGO T, 1995, IEEE T IMAGE PROCESS, V4, P1667, DOI 10.1109/83.475516; KEPPEL G, 1991, DESIGN ANAL; MOHAN R, 1992, IEEE T PATTERN ANAL, V14, P616, DOI 10.1109/34.141553; Nair D., 1995, INT C IM PROC; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; Palmer PL, 1996, COMPUT VIS IMAGE UND, V63, P476, DOI 10.1006/cviu.1996.0036; SARKAR S, 1993, IEEE T PATTERN ANAL, V15, P256, DOI 10.1109/34.204907; SARKAR S, 1991, CVGIP-IMAG UNDERSTAN, V54, P224, DOI 10.1016/1049-9660(91)90065-W; ZHANG R, 1994, P COMP VIS PATT REC, P377	16	34	35	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1997	19	11					1306	1312		10.1109/34.632991	http://dx.doi.org/10.1109/34.632991			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YG585					2022-12-18	WOS:A1997YG58500013
J	Gokmen, M; Jain, AK				Gokmen, M; Jain, AK			lambda tau-space representation of images and generalized edge detector	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						edge detection; surface reconstruction; image representation; scale space; regularization	REGULARIZATION	An image and surface representation based on regularization theory is introduced in this paper. This representation is based on a hybrid model derived from the physical membrane and plate models. The representation, called the lambda tau-representation, has two dimensions; one dimension represents smoothness or scale while the other represents the continuity of the image or surface. It contains images/surfaces sampled both in scale space and the weighted Sobolev space of continuous functions. Thus, this new representation can be viewed as an extension of the well-known scale space representation. We have experimentally shown that the proposed hybrid model results in improved results compared to the two extreme constituent models, i.e., the membrane and the plate models. Based on this hybrid model, a generalized edge detector (GED) which encompasses most of the well-known edge detectors under a common framework is developed. The existing edge detectors can be obtained from the generalized edge detector by simply specifying the values of two parameters, one of which controls the shape of the filter (tau) and the other controls the scale of the filter (lambda). By sweeping the values of these two parameters continuously, one can generate an edge representation in the lambda tau space, which is very useful for developing a goal-directed edge detection scheme for a specific task. The proposed representation and the edge detector have been evaluated qualitatively and quantitatively on several different types of image data such as intensity, range, and stereo images.	MICHIGAN STATE UNIV, DEPT COMP SCI, E LANSING, MI 48824 USA	Michigan State University	Gokmen, M (corresponding author), ISTANBUL TECH UNIV, FAC ELECT & ELECT, DEPT COMP SCI, TR-80626 ISTANBUL, TURKEY.		Gokmen, Muhittin/C-2171-2015					BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9, P726, DOI 10.1109/TPAMI.1987.4767980; BERTERO M, 1987, 824 MIT AI LAB; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CANNY JF, 1983, 720 MIT AI LAB; DERICHE R, 1987, UST P INT C COMP VIS, P501; GOKMEN M, 1993, IEEE T PATTERN ANAL, V15, P492, DOI 10.1109/34.211469; Gokmen M., 1992, Proceedings. 11th IAPR International Conference on Pattern Recognition. Vol.III. Conference C: Image, Speech and Signal Analysis, P307, DOI 10.1109/ICPR.1992.201986; GOKMEN M, 1990, THESIS U PITTSBURGH; GRIMSON WEL, 1981, IMAGES SURFACES COMP; HADAMARD J, 1923, LECTURES CAUCHYS PRO; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; POGGIO T, 1985, 833 MIT AI LAB; SARKAR S, 1991, IEEE T PATTERN ANAL, V13, P1154, DOI 10.1109/34.103275; SARKAR S, 1991, CVGIP-IMAG UNDERSTAN, V54, P224, DOI 10.1016/1049-9660(91)90065-W; Shen J., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P109; Szeliski R., 1989, Computer Graphics, V23, P51, DOI 10.1145/74334.74338; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; Tikhonov A.N., 1977, SOLUTION ILL POSED P; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; Whitten G., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P210, DOI 10.1109/ICCV.1990.139521; WILLIAMS DJ, 1990, COMPUT VISION GRAPH, V51, P256, DOI 10.1016/0734-189X(90)90003-E; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729	25	34	34	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1997	19	6					545	563		10.1109/34.601227	http://dx.doi.org/10.1109/34.601227			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XG302					2022-12-18	WOS:A1997XG30200001
J	Bangham, JA; Chardaire, P; Pye, CJ; Ling, PD				Bangham, JA; Chardaire, P; Pye, CJ; Ling, PD			Multiscale nonlinear decomposition: The sieve decomposition theorem	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mathematical morphology; median filters; ordinal filters; rank; granularity; granulometry	REPRESENTATION; FILTERS; SHAPE	Sieves decompose one dimensional bounded functions, e.g., f to a sequence of increasing scale granule functions, (d(m))(m=1)(R) that represent the information in a manner that is analogous to the pyramid of wavelets obtained by linear decomposition. Sieves based on sequences of increasing scale open-closings with flat structuring elements (M and N filters) map f to {d} and the recomposition. consisting of adding up all the granule functions, maps {d} to f. Experiments show that a more general property exists such that {(d) over cap} maps to (f) over cap and back to {<(d) over cap>}, where the granule functions {(d) over cap}, are obtained from {(d) over cap} by applying any operator alpha consisting of changing the amplitudes of some granules, including zero, without changing their signs. in other words, the set of granule function vectors produced by the decomposition is closed under the operation alpha. An analytical proof of this property is presented. This property means that filters are useful in the context of feature recognition and, in addition, opens the way for an analysis of the noise resistance of sieves.			Bangham, JA (corresponding author), UNIV E ANGLIA,SCH INFORMAT SYST,NORWICH NR4 7TJ,NORFOLK,ENGLAND.							BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; Bangham J. A., 1990, Communication, Control and Signal Processing. Proceedings of the 1990 Bilkent International Conference on New Trends in Communication, Control and Signal Processing, P1591; BANGHAM JA, 1993, IEEE T SIGNAL PROCES, V41, P31, DOI 10.1109/TSP.1993.193125; BANGHAM JA, 1996, IN PRESS IEEE T IMAG; BANGHAM JA, 1996, LECT NOTES COMPUTER, V1064, P18; BANGHAM JA, 1994, P ELISIPCO; BANGHAM JA, 1988, ANAL BIOCHEM, V174, P694; BANGHAM JA, 1994, SIGNAL PROCESSING; BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; CHEN MH, 1989, IEEE T PATTERN ANAL, V11, P694, DOI 10.1109/34.192464; GABBOUJ M, 1992, P IEEE WORKSH VIS SI, P37; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; Marr D., 1982, VISION; MATHERON G., 1975, RANDOM SETS INTEGRAL; PYE CJ, 1993, IMAGE PROCESSING THE; SALEMBIER P, 1992, SIGNAL PROCESS, V27, P205, DOI 10.1016/0165-1684(92)90008-K; SERRA J, 1993, P SOC PHOTO-OPT INS, V2030, P65, DOI 10.1117/12.146672; SERRA J, 1992, P SPIE C VIS COMM IM, V1818, P620; Serra J., 1982, IMAGE ANAL MATH MORP, pChap11; Serra J, 1988, IMAGE ANAL MATH MORP; STERNBERG SR, 1986, COMPUT VISION GRAPH, V35, P333, DOI 10.1016/0734-189X(86)90004-6; WICKERHAUSER RR, 1992, IEEE T INFORMATION T, V38, P713; ZHANG Z, 1993, IEEE T SIGNAL PROCES, V41; ZHUANG X, 1987, IEEE T PATTERN ANAL, V9, P532	26	34	35	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1996	18	5					529	539		10.1109/34.494642	http://dx.doi.org/10.1109/34.494642			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL691					2022-12-18	WOS:A1996UL69100005
J	Zerroug, M; Nevatia, R				Zerroug, M; Nevatia, R			Three-dimensional descriptions based on the analysis of the invariant and quasi-invariant properties of some curved-axis generalized cylinders	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape description; generalized cylinders; invariants; quasi-invariants; segmentation; grouping	RECOGNITION; CONTOURS; OBJECTS; IMAGE; VIEW	We address the recovery of object-level 3-D descriptions of some classes of curved-axis generalized cylinders. For this, the first part of the paper analyzes the projective properties of two common generic shapes, planar right constant generalized cylinders (PRCGCs) and circular planar right generalized cylinders (circular PRGCs). The properties we analyze include new geometric invariant and quasi-invariant properties of the orthographic projection of the above shapes and a useful classification of their structural properties as functions of their pose. The second part of the paper describes an implemented system which detects and recovers PRCGCs and circular PRGCs from an intensity image in the presence of noise, surface markings, shadows, and partial occlusion. The methods exploit the projective properties to hypothesize and verify relevant curved-axis objects, thus explicitly using the three-dimensionality of the objects and of the desired descriptions. This work extends past work on the recovery of volumetric shapes from an intensity image by addressing new primitives, deriving new properties and by developing a system that recovers them from an intensity image. We demonstrate our method on several real intensity images.			Zerroug, M (corresponding author), UNIV SO CALIF,INST ROBOT & INTELLIGENT SYST,POWELL HALL 204,LOS ANGELES,CA 90089, USA.							BENARIE J, 1990, IEEE T PATTERN ANAL, V12, P760, DOI 10.1109/34.57667; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Binford T.O., 1971, IEEE C SYST CONTR MI; BINFORD TO, 1993, P DARPA IM UND WORKS, P819; BINFORD TO, 1987, P AAAI UNC WORKSH; BROOKS RA, 1983, IEEE T PATTERN ANAL, V5, P140, DOI 10.1109/TPAMI.1983.4767366; BURNS JB, 1993, IEEE T PATTERN ANAL, V15, P51, DOI 10.1109/34.184774; GROSS A, 1990, P IM UND WORKSH PENN, P557; HORAUD R, 1988, ARTIF INTELL, V37, P333, DOI 10.1016/0004-3702(88)90059-8; Huang Q., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P104, DOI 10.1109/CVPR.1993.340972; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; Koenderink J., 1990, SOLID SHAPE; Liu J., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P123, DOI 10.1109/CVPR.1993.341000; MALIK J, 1987, INT J COMPUT VISION, V1, P73, DOI 10.1007/BF00128527; Millman R.S., 1977, ELEMENTS DIFFERENTIA; MOHAN R, 1992, IEEE T PATTERN ANAL; Mundy J., 1992, GEOMETRIC INVARIANCE; NALWA VS, 1989, IEEE T PATTERN ANAL, V11, P1117, DOI 10.1109/34.42842; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; PILLOW N, 1994, P BRIT MACH VIS C; PONCE J, 1989, IEEE T PATTERN ANAL, V11, P951, DOI 10.1109/34.35498; PONCE J, 1987, INT J COMPUT VISION, V1, P195, DOI 10.1007/BF00127820; PONCE J, 1988, P IMAGE UNDERSTANDIN, P1074; RAO K, INT J COMPUTER VISIO; RICHETIN M, 1991, IEEE T PATTERN ANAL, V13, P185, DOI 10.1109/34.67647; SAINTMARC P, 1990, P EURO C COMPUT VISI, P604; SATO H, 1993, CVGIP-IMAG UNDERSTAN, V57, P346, DOI 10.1006/ciun.1993.1023; SHAFER SA, 1983, CS083105 CARN MELL U; Ulupinar F., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P674, DOI 10.1109/CVPR.1991.139777; Ulupinar F., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P582, DOI 10.1109/ICCV.1990.139600; ULUPINAR F, 1993, IEEE T PATTERN ANAL, V15, P3, DOI 10.1109/34.184771; Zerroug M., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P96, DOI 10.1109/CVPR.1993.340973; ZERROUG M, 1994, INT C PATT RECOG, P678; ZERROUG M, 1994, INT C PATT RECOG, P108; ZERROUG M, 1994, THESIS U SO CALIFORN; ZERROUG M, IN PRESS INT J COMPU; ZERROUG M, 1994, P EUR C COMP VIS STO, P319; ZERROUG M, 1994, LECT NOTES COMPUTER, V825	38	34	35	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1996	18	3					237	253		10.1109/34.485553	http://dx.doi.org/10.1109/34.485553			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UA455					2022-12-18	WOS:A1996UA45500002
J	JIA, XG; NIXON, MS				JIA, XG; NIXON, MS			EXTENDING THE FEATURE VECTOR FOR AUTOMATIC FACE RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						AUTOMATIC FACE RECOGNITION; FEATURE EXTRACTION; FEATURE VECTOR	TEMPLATES	Many features can be used to describe a human face but few have been used in combination. Extending the feature vector using orthogonal sets of measurements can reduce the variance of a matching measure, to improve discrimination capability. This paper investigates how different features can be used for discrimination, alone or when integrated into an extended feature vector. This study concentrates on improving feature definition and extraction from a frontal view image, incorporating and extending established measurements. These form an extended feature vector based on four feature sets: geometric (distance) measurements, the eye region, the outline contour, and the profile. The profile, contour, and eye region are described by the Walsh power spectrum, normalized Fourier descriptors, and normalized moments, respectively. Although there is some correlation between the geometrical measures and the other sets, their bases (distance, shape description, sequency, and statistics) are orthogonal and hence appropriate for this research. A database of face images was analyzed using two matching measures which were developed to control differently the contributions of elements of the feature sets. The match was evaluated for both measures for the separate feature sets and for the extended feature vector. Results demonstrated that no feature set alone was sufficient for recognition whereas the extended feature vector could discriminate between subjects sucessfully.	UNIV SOUTHAMPTON,DEPT ELECTR & COMP SCI,SOUTHAMPTON SO9 5NH,HANTS,ENGLAND	University of Southampton	JIA, XG (corresponding author), HARBIN INST TECHNOL,SCH ASTRONAUT,HARBIN 150006,PEOPLES R CHINA.		Nixon, Mark S/F-7406-2014	Nixon, Mark/0000-0002-9174-5934				BISCHEL M, 1994, CVGIP-IMAG UNDERSTAN, V59, P54; BLEDSOE W, 1966, RPI22 PAN RES I TECH; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; BUHR R, 1986, NTZ ARCH, V8, P245; CRAW I, 1987, PATTERN RECOGN LETT, V5, P183, DOI 10.1016/0167-8655(87)90039-0; CRAW I, 1992, JAN IEE C MACH STOR; CRAW I, 1991, SEP P BMVC 91 GLASG, P367; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; DAVIES G, 1981, PRESS SERIES COGNITI; GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926; HARMON LD, 1981, PATTERN RECOGN, V13, P97, DOI 10.1016/0031-3203(81)90008-X; JIA XG, 1994, PATTERN RECOGN LETT, V15, P551, DOI 10.1016/0167-8655(94)90015-9; KAUFMAN GJ, 1976, IEEE T SYST MAN CYB, V6, P113, DOI 10.1109/TSMC.1976.5409181; Kaya Y., 1972, FRONTIERS PATTERN RE, V1, P265; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; MANNAERT H, 1990, 13 P APPL DIG P SPIE, V1349, P227; Meyer S., 1975, DATA ANAL SCI ENG; Nixon M., 1985, Proceedings of the SPIE - The International Society for Optical Engineering, V575, P279; RICCIA G, 1977, 1977 P CARNH C CRIM, P145; Sakai T., 1972, 1st USA-Japan Computer Conference Proceedings, P55; SAMAL A, 1992, PATTERN RECOGN, V25, P65, DOI 10.1016/0031-3203(92)90007-6; SPACEK LA, 1986, IMAGE VISION COMPUT, V4, P43, DOI 10.1016/0262-8856(86)90007-7; STRINGA L, 1993, APPL ARTIF INTELL, V7, P365, DOI 10.1080/08839519308949995; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; TURK M, 1989, P INTELLIGENT ROBOTS, V1, P22; WONG KH, 1989, MAY P IEEE ICASSP 89, P1638; WU CJ, 1990, PATTERN RECOGN, V23, P255, DOI 10.1016/0031-3203(90)90013-B; YUILLE AL, 1991, J COGNITIVE NEUROSCI, V3, P59, DOI 10.1162/jocn.1991.3.1.59	28	34	39	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1995	17	12					1167	1176		10.1109/34.476509	http://dx.doi.org/10.1109/34.476509			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TJ275					2022-12-18	WOS:A1995TJ27500004
J	YUAN, XB				YUAN, XB			A MECHANISM OF AUTOMATIC 3D OBJECT MODELING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						SPATIAL REASONING; AUTOMATIC PROCESSING; GAUSSIAN SPHERE; OBJECT RECONSTRUCTION; COMPUTER VISION; SURFACE VISIBILITY; OCCLUSIONS; VIEW PLANNING	VIEW	The symbolic representation of 3D objects is the fundamental knowledge for computer systems to understand the environment. This knowledge is usually assumed to exist in a computer but can also be acquired by accumulating spatial features extracted from sensory inputs at different viewing directions. This paper first investigates surface visibility and, then, after introducing mass vector chains (MVC), discusses the relationship between MVC and the spatial closure of object models. An automatic modeling mechanism is established with the observation that the boundary of an object is closed only if the MVC of its model is closed or, alternatively, the tail-to-head vector of an unclosed MVC estimates the visible direction of the missing surfaces. Experimental results and an algorithm are also given at the end.			YUAN, XB (corresponding author), MEM UNIV NEWFOUNDLAND,DEPT COMP SCI,ST JOHNS,NF A1B 3X5,CANADA.							ALOIMONOS J, 1988, ADV COMPUTER VISION, V1, P115; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; CHRISTENSEN HI, 1993, INT J PRAI, V7; FOLEY J, 1992, COMPUTER GRAPHICS PR; Green W. B, 1989, DIGITAL IMAGE PROCES; HORN BKP, 1984, P IEEE, V72, P1656; JAIN R, 1990, ANAL INTERPRETATION, P1; KENDER JR, 1980, P DARPA IMAGE UNDERS, P157; KUTULAKOS KN, 1994, INT J COMPUTER VISIO, V12, P331; MAVER J, 1993, IEEE T PATTERN ANAL, V15, P417, DOI 10.1109/34.211463; Nalwa V. S., 1993, GUIDED TOUR COMPUTER; NISHIDA H, 1993, IEEE T PATTERN ANAL, V15, P1298, DOI 10.1109/34.250847; VEMURI BC, 1993, IEEE T PATTERN ANAL, V15, P668, DOI 10.1109/34.221168; WILKES D, 1992, IEEE C COMPUT VISION, P136; YUAN X, 1992, THESIS U ALBERTA CAN; ZHANG SJ, 1993, IEEE T PATTERN ANAL, V15, P531, DOI 10.1109/34.216723	16	34	37	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1995	17	3					307	311		10.1109/34.368196	http://dx.doi.org/10.1109/34.368196			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QM090					2022-12-18	WOS:A1995QM09000008
J	ALTER, TD				ALTER, TD			3-D POSE FROM 3 POINTS USING WEAK-PERSPECTIVE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note							IMAGE	This correspondence discusses computing the pose of a model from three matching point pairs under weak-perspective projection. A new approach to the problem that is motivated geometrically is described. Like previous methods, the method here involves solving a biquadratic equation, but here the biquadratic's solutions, comprised of an actual and a false solution, are interpreted graphically. The final equations take a new form, which leads to a simple expression for the image position of any unmatched model point.			ALTER, TD (corresponding author), MIT,ARTIFICIAL INTELLIGENCE LAB,545 TECHNOL SQ,CAMBRIDGE,MA 02139, USA.							ALTER TD, 1992, MIT TR1410 ART INT L; COSTA M, 1990, 6TH P ISR C AI, P35; CYGANSKI D, 1988, ADV COMPUTER VISION, V3; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GRAUSTEIN WC, 1930, INTRO HIGHER GEOMETR; GRIMSON WEL, 1992, P IEEE C COMPUT VISI; Horn B. K. P., 1987, J OPT SOC AM, V4; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; JACOBS D, 1991, IEEE C COMP VIS PATT, P269; KANADE T, 1983, HUMAN MACHINE VISION; Lamdan Y., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P22, DOI 10.1109/CVPR.1991.139655; LAMDAN Y, 1988, JUN P CVPR C ANN ARB, P335; LINNAINMAA S, 1988, IEEE T PATTERN ANAL, V10, P634, DOI 10.1109/34.6772; RIGOUTSOS I, 1991, 8TH ISR C ART INT CO; Roberts L., 1965, MACHINE PERCEPTION 3; THOMPSON DW, 1987, IEEE J ROBOTIC AUTOM, P208; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; [No title captured]	18	34	38	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1994	16	8					802	808		10.1109/34.308475	http://dx.doi.org/10.1109/34.308475			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PB475					2022-12-18	WOS:A1994PB47500005
J	HUSSAIN, B; KABUKA, MR				HUSSAIN, B; KABUKA, MR			A NOVEL FEATURE RECOGNITION NEURAL-NETWORK AND ITS APPLICATION TO CHARACTER-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter							PATTERN-RECOGNITION; NEOCOGNITRON; ALGORITHM; MODEL	This paper presents a Feature Recognition Network for pattern recognition that learns the patterns by remembering their different segments. The base algorithm for this network is a Boolean net algorithm that we developed during our past research. Simulation results show that the network can recognize patterns after significant noise, deformation, translation and even scaling. The network is compared to existing popular networks used for the same purpose, especially Neocognitron. The network is also analyzed as regards to interconnection complexity and information storage/retrieval.			HUSSAIN, B (corresponding author), UNIV MIAMI,DEPT ELECT & COMP ENGN,CORAL GABLES,FL 33124, USA.							ABUMOSTAFA YS, 1988, NEURAL INFORMATION P, P1; ARBIB MA, 1989, J PARALLEL DISTR COM, V6, P185, DOI 10.1016/0743-7315(89)90059-2; BLOCK HD, 1962, REV MOD PHYS, V34, P135, DOI 10.1103/RevModPhys.34.135; BRADY ML, 1989, IEEE T CIRCUITS SYST, V36, P665, DOI 10.1109/31.31314; CADZOW JA, 1976, IEEE T ACOUST SPEECH, V24, P349, DOI 10.1109/TASSP.1976.1162844; CARPENTER G, 1986, AAAS S SERIES; CHIN RT, 1988, COMPUT VISION GRAPH, V41, P346, DOI 10.1016/0734-189X(88)90108-9; Duda R.O., 1973, J ROYAL STAT SOC SER; ELLEITHY N, 1987, 1987 P IEEE ICNN SAN, P469; FAHNER G, 1990, JUN INT JOINT C NEUR, V3, P193; FUKUSHIMA K, 1983, IEEE T SYST MAN CYB, V13, P826, DOI 10.1109/TSMC.1983.6313076; FUKUSHIMA K, 1982, PATTERN RECOGN, V15, P455, DOI 10.1016/0031-3203(82)90024-3; Fukushima K., 1991, IEEE T NEURAL NETWOR, V2; GALLAGHER RG, 1968, INFORMATION THEORY R; GLORIOSO RM, 1980, ENG INTELLIGENT SYST, P318; GROSSBERG S, 1986, ADAPTIVE BRAIN, V1; HABIB M, 1988, P 1988 INT S CIRC SY, P491; HOPFIELD JJ, 1986, SCIENCE, V233, P625, DOI 10.1126/science.3755256; HOPFIELD JJ, 1984, P NATL ACAD SCI-BIOL, V81, P3088, DOI 10.1073/pnas.81.10.3088; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837; HUEBEL DH, 1965, J NEUROPHYSIOL, V28, P229; HUSSAIN B, 1992, 1992 SPEIS INT S OPT; JOHNSON RC, 1988, COGNIZERS NEURAL NET; KING SY, 1989, J PARALLEL DISTRIBUT, V6, P358; Kohonen Teuvo, 1984, SELF ORG ASS MEMORY; KOLLIAS S, 1989, IEEE T CIRCUITS SYST, V36, P1092, DOI 10.1109/31.192419; Lippman R. P., 1987, IEEE ASSP MAGAZI APR, P4; MINNIX JI, 1990, JUN INT JOINT C NEUR, V1, P395; Minsky M., 1969, PERCEPTRONS; MORASHITA I, 1972, CYBERN, V11, P154; ROSENBLATT F, 1959, PRINCIPLES NEURODYNA; Rumelhart D. E., 1988, PARALLEL DISTRIBUTED; SCHWARTZ T, 1989, SEP IEEE VID C NEUR; SKLANSKY J, 1981, PATTERN CLASSIFIERS; SUNG C, 1990, JUN INT JOINT NEUR N, V3, P753; VANDENBOUT DE, 1989, IEEE T CIRCUITS SYST, V36, P732, DOI 10.1109/31.31321; WERBOS P, 1988, P IEEE INT C NEURAL; WERBOS P, 1987, IEEE T SYST MAN CYBE, V17; WIDROW B, 1988, IEEE COMPUTER    MAR, P25; WINTER RG, 1988, 2ND P IEEE INT C NEU, V1, P401	41	34	35	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1994	16	1					98	106		10.1109/34.273711	http://dx.doi.org/10.1109/34.273711			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MV733					2022-12-18	WOS:A1994MV73300011
J	HECKERMAN, D; HORVITZ, E; MIDDLETON, B				HECKERMAN, D; HORVITZ, E; MIDDLETON, B			AN APPROXIMATE NONMYOPIC COMPUTATION FOR VALUE OF INFORMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						BELIEF NETWORKS; DECISION THEORY; NONMYOPIC; PROBABILITY; VALUE OF INFORMATION		Value-of-information analyses provide a means for selecting the next best observation to make and for determining whether it is better to gather additional information or to act immediately. Determining the next best test to perform. given uncertainty about the state of the world. requires a consideration of the value of making all possible sequences of observations. In practice, decision analysts and expert-system designers have avoided the intractability of exact computation of the value of information by relying on a myopic assumption that only one additional test will be performed, even when there is an opportunity to make a large number of observations. We present an alternative to the myopic analysis. In particular, we present an approximate method for computing the value of information of a set of tests, which exploits the statistical properties of large samples. The approximation is linear in the number of tests, in contrast with the exact computation, which is exponential in the number or tests. The approach is not as general as is a complete nonmyopic analysis, in which all possible sequences of observations are considered. In addition, the approximation is limited to specific classes of dependencies among evidence and to binary hypothesis and decision variables. Nonetheless, as we demonstrate with a simple application. the approach can offer an improvement over the myopic analysis.	MICROSOFT RES CTR,REDMOND,WA 98052; ROCKWELL INT CORP,CTR SCI,PALO ALTO LAB,PALO ALTO,CA 94301; STANFORD UNIV,MED CTR,MED INFORMAT SECT,STANFORD,CA 94305	Rockwell Collins; Stanford University	HECKERMAN, D (corresponding author), UNIV CALIF LOS ANGELES,DEPT COMP SCI,LOS ANGELES,CA 90024, USA.		Middleton, Blackford/B-7304-2018	Middleton, Blackford/0000-0002-1819-1234				Albers WA, 1980, SOC RISK ASSESSMENT, P89, DOI 10.1007/978-1-4899-0445-4_5; BILLINGSLEY P, 1968, CONVERGENCE PROBABIL, pCH4; BONISSONE P, 1990, UNCERTAINTY ARTIFICI, V6, P159; Cooper G.F., 1991, 7 C UNC ART INT, P86; GORRY GA, 1968, COMPUT BIOMED RES, V1, P490, DOI 10.1016/0010-4809(68)90016-5; GORRY GA, 1973, AM J MED, V55, P473, DOI 10.1016/0002-9343(73)90204-0; HECKERMAN D, 1985, KSL8964 STANF U MED; HECKERMAN DE, 1992, METHOD INFORM MED, V31, P90; HECKERMAN DE, 1990, 6TH P C UNC ART INT, P82; HECKERMAN DE, 1991, PROBABILISTIC SIMILI; HOWARD RA, 1967, IEEE T SYST SCI CYB, VSSC3, P54, DOI 10.1109/TSSC.1967.300108; MCNEIL BJ, 1982, NEW ENGL J MED, V306, P1259, DOI 10.1056/NEJM198205273062103; NATHWANI BN, 1990, HUM PATHOL, V21, P11, DOI 10.1016/0046-8177(90)90071-C; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4	14	34	35	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1993	15	3					292	298		10.1109/34.204912	http://dx.doi.org/10.1109/34.204912			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KT658		Green Submitted			2022-12-18	WOS:A1993KT65800011
J	TSAY, YT; TSAI, WH				TSAY, YT; TSAI, WH			ATTRIBUTED STRING MATCHING BY SPLIT-AND-MERGE FOR ONLINE CHINESE CHARACTER-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CHARACTER RECOGNITION; ONLINE CHINESE CHARACTER RECOGNITION; STRING MATCHING	HANDWRITTEN CHARACTERS; ONLINE RECOGNITION	Consecutive strokes of Chinese characters tend to be connected in fast writing, and this causes a problem for most stroke-based recognition approaches. In this correspondence, we propose a recognition scheme to recognize cursive Chinese characters under the constraint of correct stroke writing orders. The proposed recognition scheme consists of two phases: candidate character selection and detailed matching. In the former phase, an input script with N strokes is used to split the strokes of each reference character into N corresponding parts. In the latter phase, the connected input strokes are broken into multiple strokes under the guidance of candidate characters. In both phases, dynamic programming is employed for stroke or character matching. Good experimental results prove the feasibility of the proposed approach for cursive Chinese character recognition.	NATL CHIAO TUNG UNIV,DEPT COMP & INFORMAT SCI,HSINCHU,TAIWAN	National Yang Ming Chiao Tung University	TSAY, YT (corresponding author), YUAN ZE INST TECHNOL,DEPT COMP & ENGN SCI,TAOYUAN,TAIWAN.							ARAKAWA H, 1983, PATTERN RECOGN, V16, P9, DOI 10.1016/0031-3203(83)90003-1; CHEN KJ, 1988, INT J PATTERN RECOGN, V2, P139; HANAKI SI, 1980, PATTERN RECOGN, V12, P421, DOI 10.1016/0031-3203(80)90018-7; HSU CC, 1986, COMPUT PROCESSING CH, V2, P198; Ishigaki K., 1988, 1988 International Conference on Computer Processing of Chinese and Oriental Languages. Proceedings, P141; MORISHITA T, 1988, IJPRAI, V2, P181; NAKAGAWA M, 1982, 6TH P ICPR, P776; ODAKA K, 1982, IEEE T SYST MAN CYB, V12, P898; SHIAU SL, 1988, 1988 P INT C COMP PR, P76; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669; TSAI WH, 1985, IEEE T PATTERN ANAL, V7, P453, DOI 10.1109/TPAMI.1985.4767684; TSAY YT, 1988, THESIS NATIONAL CHIA; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; Wakahara T., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P1065; YHAP EF, 1981, IBM J RES DEV, V25, P187, DOI 10.1147/rd.252.0187	15	34	35	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1993	15	2					180	185						6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KL910					2022-12-18	WOS:A1993KL91000010
J	SNYDER, MA				SNYDER, MA			ON THE MATHEMATICAL FOUNDATIONS OF SMOOTHNESS CONSTRAINTS FOR THE DETERMINATION OF OPTICAL-FLOW AND FOR SURFACE RECONSTRUCTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						MINIMIZATION TECHNIQUES; MOTION ANALYSIS; OPTICAL FLOW; SMOOTHNESS CONSTRAINTS; TENSOR ANALYSIS		Gradient-based approaches to the computation of optical flow often use a minimization technique incorporating a smoothness constraint on the optical flow field. In this paper, we derive the most general form of such a smoothness constraint that is quadratic in first derivatives of the flow field and quadratic in first or second derivatives of the grey-level image intensity function based on three simple assumptions about the smoothness constraint: 1) It must be expressed in a form that is independent of the choice of Cartesian coordinate system in the image, 2) it must be positive definite, and 3) it must not couple different components of the optical flow. We show that there are essentially only four such constraints; any smoothness constraint satisfying 1), 2), or 3) must be a linear combination of these four, possibly multiplied by certain quantities invariant under a change in the Cartesian coordinate system. Beginning with the three assumptions mentioned above, we mathematically demonstrate that all the best-known smoothness constraints appearing in the literature are special cases of this general form and, in particular, that the "weight matrix" introduced by Nagel is essentially (modulo invariant quantities) the only physically plausible such constraint. We also note that the results of Brady and Horn on "rotationally symmetric" performance measures for surface reconstruction are simple corollaries of our main results and, in fact, that such performance measures are invariant under the larger group of transformations consisting of rigid motions of the plane.	WELLESLEY COLL,PHYS,WELLESLEY,MA 02181	Wellesley College	SNYDER, MA (corresponding author), UNIV MASSACHUSETTS,DEPT COMP & INFORMAT SCI,COMP VIS RES LAB,AMHERST,MA 01003, USA.							ANANDAN P, 1987, 1ST P INT C COMP VIS; ANANDAN P, 1985, COINS8538 U MASS TEC; ANANDAN P, COMMUNICATION; BRADY M, 1983, COMPUT VISION GRAPH, V22, P70, DOI 10.1016/0734-189X(83)90096-8; Do Carmo M.P., 2016, DIFFERENTIAL GEOMETR, Vsecond; GRIMSON WEL, 1981, IMAGES SURFACES; HILDRETH E, 1983, MEASUREMENT VISUAL M; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1987, ROBUST DIRECT METHOD; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Nagel H.-H., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P459, DOI 10.1142/S0218001488000273; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NAGEL HH, 1987, ARTIF INTELL, V33, P299, DOI 10.1016/0004-3702(87)90041-5; NAGEL HH, 1983, AUG P INT JOINT C AR, P945; SCHUNCK BG, 1984, NAT C ARTIFICIAL INT; SCHUNCK BG, 1984, P INT C PATT RECOGNI; SNYDER MA, 1991, MATH F SMOOTHNESS CO; SNYDER MA, 1989, COINS8905 U MASS TEC; THORPE JA, 1979, ELEMENTARY TOPICS DI; [No title captured]	20	34	37	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1991	13	11					1105	1114		10.1109/34.103272	http://dx.doi.org/10.1109/34.103272			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GN338					2022-12-18	WOS:A1991GN33800001
J	BRESLER, Y; FESSLER, JA; MACOVSKI, A				BRESLER, Y; FESSLER, JA; MACOVSKI, A			A BAYESIAN-APPROACH TO RECONSTRUCTION FROM INCOMPLETE PROJECTIONS OF A MULTIPLE OBJECT 3D DOMAIN	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									STANFORD UNIV,DEPT ELECT ENGN,INFORMAT SYST LAB,STANFORD,CA 94305; UNIV ILLINOIS,COORDINATED SCI LAB,URBANA,IL 61821	Stanford University; University of Illinois System; University of Illinois Urbana-Champaign				Bresler, Yoram/0000-0002-9738-1094				[Anonymous], 1980, PRINCIPLES ARTIFICIA; Ballard D.H., 1982, COMPUTER VISION; BARSHALOM Y, 1978, IEEE T AUTOMAT CONTR, V23, P618, DOI 10.1109/TAC.1978.1101790; BINFORD TO, 1971, DEC IEEE C SYST CONT; BLOCH P, 1983, P IEEE, V71, P351, DOI 10.1109/PROC.1983.12593; Bresler Y., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P455; BRESLER Y, 1987, IEEE T ACOUST SPEECH, V35, P1139, DOI 10.1109/TASSP.1987.1165270; Bresler Y., 1988, Machine Vision and Applications, V1, P115, DOI 10.1007/BF01212276; BRESLER Y, 1984, JUL P IEEE INT S MED, P251; BRESLER Y, 1985, THESIS STANFORD U; BRUCKSTEIN AM, 1985, IEEE T ACOUST SPEECH, V33, P1357, DOI 10.1109/TASSP.1985.1164725; DEANS SR, 1984, RADON TRANSFORM SOME; Duda R.O., 1973, J ROYAL STAT SOC SER; EDELSTEIN WA, 1983, J COMPUT ASSIST TOMO, V7, P391, DOI 10.1097/00004728-198306000-00001; FEDER M, 1988, IEEE T ACOUST SPEECH, V36, P477, DOI 10.1109/29.1552; FERGUSON TS, 1967, MATH STATISTICS DECI, P208; FIGUEIREDO RJ, 1983, IEEE T ACOUST SPEECH, V31, P1084; FLETCHER R, 1987, PRACTICAL METHODS OP, V2nd, P18; GORDON R, 1974, INT REV CYTOL, V38, P111, DOI 10.1016/S0074-7696(08)60925-0; HANSON KM, 1983, J OPT SOC AM, V73, P1501, DOI 10.1364/JOSA.73.001501; Herman G, 1980, IMAGE RECONSTRUCTION; HOULT DI, 1976, J MAGN RESON, V24, P71, DOI 10.1016/0022-2364(76)90233-X; KAK AC, 1979, P IEEE, V67, P1245, DOI 10.1109/PROC.1979.11440; KWAKERNAAK H, 1980, AUTOMATICA, V16, P367, DOI 10.1016/0005-1098(80)90021-7; LENSTRA JK, 1979, 1977 DISCR OPT P, P121; LICHTENSTEIN MG, 1968, IEEE T INFORM THEORY, V14, P288, DOI 10.1109/TIT.1968.1054120; LOUIS AK, 1983, P IEEE, V71, P379, DOI 10.1109/PROC.1983.12596; MOREFIELD CL, 1977, IEEE T AUTOMAT CONTR, V22, P302, DOI 10.1109/TAC.1977.1101500; MUNK W, 1979, DEEP-SEA RES, V26, P123, DOI 10.1016/0198-0149(79)90073-6; NILLSON NJ, 1961, IRE T INFORM THEORY, V11, P245; PADBERG MW, 1979, 1977 DISCR OPT P, P265; PIERCE JF, 1968, MANAGE SCI, V15, P191, DOI 10.1287/mnsc.15.3.191; PIERCE JF, 1973, MANAGE SCI, V19, P528, DOI 10.1287/mnsc.19.5.528; Powell MJ., 1973, MATH PROGRAM, V4, P193, DOI [DOI 10.1007/BF01584660, 10.1007/BF01584660]; RA JB, 1981, MAY P IEEE, V69, P668; RANGAYYAN RM, 1984, DEC P IEEE INT C COM; RANGAYYAN RM, 1984, AUG TOP M IND APPL C; RAUCH HE, 1965, AIAA J, V3, P1445, DOI 10.2514/3.3166; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; ROSSI DJ, 1984, IEEE T ACOUST SPEECH, V32, P886, DOI 10.1109/TASSP.1984.1164405; Sage AP, 1971, ESTIMATION THEORY AP; SELFRIDGE PG, 1981, COMPUT VISION GRAPH, V15, P265, DOI 10.1016/0146-664X(81)90059-9; SHMUELI K, 1981, SEP SPIE C DIG RAD; SLUMP CH, 1982, COMPUT VISION GRAPH, V18, P18, DOI 10.1016/0146-664X(82)90097-1; SUHL U, 1982, EVALUATING MATH PROG; Taha H., 1975, INTEGER PROGRAMMING; TOYODA Y, 1975, MANAGE SCI B-APPL, V21, P1417, DOI 10.1287/mnsc.21.12.1417; UDUPA JK, 1983, P IEEE, V71, P420, DOI 10.1109/PROC.1983.12599; Van Trees H., 2013, DETECTION ESTIMATION; Wall J. E.  Jr., 1981, Stochastics, V5, P1, DOI 10.1080/17442508108833172; WAX M, 1985, IEEE T ACOUST SPEECH, V33, P387, DOI 10.1109/TASSP.1985.1164557; ZISKIND I, 1987, APR P IEEE INT C AC; [No title captured]	53	34	41	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1989	11	8					840	858		10.1109/34.31446	http://dx.doi.org/10.1109/34.31446			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AH079					2022-12-18	WOS:A1989AH07900005
J	NI, LM; JAIN, AK				NI, LM; JAIN, AK			A VLSI SYSTOLIC ARCHITECTURE FOR PATTERN CLUSTERING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											NI, LM (corresponding author), MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48824, USA.							Ackland B., 1981, 8th Annual Symposium on Computer Architecture, P197; ANDERBERG MR, 1973, CLUSTER ANAL APPLICA; BISWAS G, 1981, IEEE T PATTERN ANAL, V3, P701, DOI 10.1109/TPAMI.1981.4767175; BLASHFIELF RK, 1982, HDB STATISTICS, V2, P245; BRYANT J, 1979, PATTERN RECOGN, V11, P115, DOI 10.1016/0031-3203(79)90057-8; BUDNIK P, 1971, IEEE T COMPUT, VC 20, P1566, DOI 10.1109/T-C.1971.223171; COLEMAN GB, 1979, P IEEE, V67, P773, DOI 10.1109/PROC.1979.11327; DUBES R, 1976, PATTERN RECOGN, V8, P247, DOI 10.1016/0031-3203(76)90045-5; DUBES R, 1980, ADV COMPUT, V19, P113; Fu K. S., 1968, SEQUENTIAL METHODS P, V240, P241; HE Q, 1982, 1982 P INT C CHIN LA, P144; HWANG K, 1981, ADV COMPUT, V20, P115; HWANG K, 1983, COMPUTER, P51; HWANG K, 1982, IEEE T COMPUT, V31; Kung H. T., 1981, VLSI Systems and Computations. CMU Conference on VLSI Systems and Computations, P255; KUNG HT, 1982, COMPUTER, V15, P37, DOI 10.1109/MC.1982.1653825; KUNG HT, 1979, 1978 SPARS MATR P, P256; LU SY, 1977, IEEE T COMPUT, V26, P1268, DOI 10.1109/TC.1977.1674788; NI LM, 1983, 6TH P INT S COMP AR, P144; NI LM, 1983, 1983 P INT C PAR PRO, P537; STOCKMAN G, 1982, IEEE T PATTERN ANAL, V4, P229, DOI 10.1109/TPAMI.1982.4767240; [No title captured]; 1978, REFERENCE MANUAL SER	23	34	35	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	1					80	89		10.1109/TPAMI.1985.4767620	http://dx.doi.org/10.1109/TPAMI.1985.4767620			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	ABF09	21869242				2022-12-18	WOS:A1985ABF0900007
J	HO, CS				HO, CS			PRECISION OF DIGITAL VISION SYSTEMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIMAT INC,DANBURY,CT 06810									COXETER W, 1969, INTRO GEOMETRY; HILL JW, 1980, DIMENSIONAL MEASUREM; HUA LK, 1975, INTRO NUMBER THEORY	3	34	40	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	6					593	601		10.1109/TPAMI.1983.4767448	http://dx.doi.org/10.1109/TPAMI.1983.4767448			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RV488	21869145				2022-12-18	WOS:A1983RV48800005
J	KIM, CE				KIM, CE			3-DIMENSIONAL DIGITAL LINE SEGMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											KIM, CE (corresponding author), WASHINGTON STATE UNIV,DEPT COMP SCI,PULLMAN,WA 99164, USA.							Arcelli C., 1975, Computer Graphics and Image Processing, V4, P339, DOI 10.1016/0146-664X(75)90003-9; GAAFAR M, 1977, COMPUTER GRAPHICS IM, V6, P361; Graham R. L., 1972, Information Processing Letters, V1, P132, DOI 10.1016/0020-0190(72)90045-2; HERMAN GT, 1978, COMPUT VISION GRAPH, V7, P130, DOI 10.1016/S0146-664X(78)80018-5; HODES L, 1970, SIAM J APPL MATH, V19, P477, DOI 10.1137/0119048; KIM CE, 1982, IEEE T PATTERN ANAL, V4, P149, DOI 10.1109/TPAMI.1982.4767221; KIM CE, 1982, IEEE T PATTERN ANAL, V4, P612, DOI 10.1109/TPAMI.1982.4767314; KIM CE, 1981, IEEE T PATTERN ANAL, V3, P617, DOI 10.1109/TPAMI.1981.4767162; LIU HK, 1977, COMPUT VISION GRAPH, V6, P123, DOI 10.1016/S0146-664X(77)80008-7; MONTANARI GU, 1970, J ACM, V17, P348, DOI 10.1145/321574.321588; MORGENTHALER DG, 1981, THESIS U MARYLAND; REDDY DR, 1978, CMUCS78113; ROSENFELD A, 1974, IEEE T COMPUT, VC 23, P1264, DOI 10.1109/T-C.1974.223845; ROSENFELD A, 1970, J ACM, V17, P146, DOI 10.1145/321556.321570; ROSENFELD A, 1980, TR936 U MAR COMP SCI; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SKLANSKY J, 1970, PATTERN RECOGN, V2, P3, DOI 10.1016/0031-3203(70)90037-3; SKLANSKY J, 1972, IEEE T COMPUT, VC 21, P1355, DOI 10.1109/T-C.1972.223507; TSAO YF, UNPUB COMPUT GRAPHIC; Zucker S. W., 1979, Proceedings of the 1979 IEEE Computer Society Conference on Pattern Recognition and Image Processing, P162	20	34	34	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	2					231	234		10.1109/TPAMI.1983.4767379	http://dx.doi.org/10.1109/TPAMI.1983.4767379			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QJ974	21869108				2022-12-18	WOS:A1983QJ97400016
J	FAUGERAS, OD; PRICE, KE				FAUGERAS, OD; PRICE, KE			SEMANTIC DESCRIPTION OF AERIAL IMAGES USING STOCHASTIC LABELING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV SO CALIF,INST IMAGE PROC,LOS ANGELES,CA 90007; UNIV SO CALIF,DEPT ELECT ENGN,LOS ANGELES,CA 90007	University of Southern California; University of Southern California								BARROW HG, 1975, AICSRI108 TECH NOT; BERTHOD M, 1980, 8TH WORLD COMP C; FAUGERAS O, 1979, AUG P IEEE C PATT RE, P318; FAUGERAS OD, 1981, JUL IEEE T PATT AN M, V3, P412; KITCHEN L, 1980, IEEE T SYST MAN CYB, V10, P96; KITCHEN L, 1979, IEEE T SYST MAN CYB, V9, P869; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; NEVATIA R, UNPUBLISHED; OHLANDER R, 1978, COMPUT VISION GRAPH, V8, P313, DOI 10.1016/0146-664X(78)90060-6; PRICE K, 1979, IEEE T PATTERN ANAL, V1, P110, DOI 10.1109/TPAMI.1979.4766884; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; RUBIN S, 1978, THESIS CARNEGIEMELLO; SMITH D, 1979, NOV P IMAG UND WORKS, P42; ULLMAN S, 1979, COMPUT VISION GRAPH, V10, P115, DOI 10.1016/0146-664X(79)90045-5	14	34	34	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	6					633	642		10.1109/TPAMI.1981.4767164	http://dx.doi.org/10.1109/TPAMI.1981.4767164			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MR996	21868983				2022-12-18	WOS:A1981MR99600003
J	KANAL, LN				KANAL, LN			PROBLEM-SOLVING MODELS AND SEARCH STRATEGIES FOR PATTERN-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											KANAL, LN (corresponding author), UNIV MARYLAND, DEPT COMP SCI, PATTERN ANAL LAB, COLLEGE PK, MD 20742 USA.							AHO AV, 1972, SIAM J COMPUT, V4; BAKER JK, 1975, IEEE T ACOUST SPEECH, VAS23, P24, DOI 10.1109/TASSP.1975.1162650; BANERJI RB, 1968, PATTERN RECOGN, V1, P63, DOI 10.1016/0031-3203(68)90014-9; BANERJI RB, 1971, PATTERN RECOGN, V3, P409, DOI 10.1016/0031-3203(71)90030-6; BARCLAYADAMS J, 1976, MATH BIOSCI, V32, P177; CHANG LL, 1971, ARTIF INTELL, V2, P117; COHEN BL, 1977, ARTIF INTELL, V9, P223, DOI 10.1016/0004-3702(77)90023-6; COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; DASARATHY BV, 1977, 1977 P INT C CYB SOC, P630; DUDA RO, 1977, DEV COMPUTER BASED C; DUDA RO, 1976, SRI124 STANF RES I A; EARLEY JC, 1970, COMMUN ASS COMPUT MA, V12, P94; FAHLMAN S, 1973, MIT57 AI LAB WORK PA; Feldman J.A., 1977, COGNITIVE SCI, V1, P158, DOI 10.1207/s15516709cog0102_2; FRIEDMAN J, 1975, SLACPUB1573 STANF LI; Fu K.S., 1974, MATH SCI ENG; Fu K. S., 1968, SEQUENTIAL METHODS P, V240, P241; FUKUNAGA K, 1974, IEEE T COMPUT, V24; Fuller S. H., 1973, ANAL ALPHA BETA PRUN; GELPERIN D, 1977, ARTIF INTELL, V8, P69, DOI 10.1016/0004-3702(77)90005-4; GOLOMB S, 1975, J ASSOC COMPUT MACH, V12, P516; HALL PAV, 1973, COMMUN ACM, V16, P444, DOI 10.1145/362280.362302; HARLOW CA, 1973, IEEE T COMPUT, VC 22, P678, DOI 10.1109/TC.1973.5009135; HARRIS LR, 1974, ARTIF INTELL, V5, P217, DOI 10.1016/0004-3702(74)90014-9; Hart P.E., 1972, ACM SIGART B, V37, P28, DOI DOI 10.1145/1056777.1056779; HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136; HOROWITZ SL, 1975, COMMUN ASS COMPUT MA, V18; KANAL L, 1974, IEEE T INFORM THEORY, V20, P697, DOI 10.1109/TIT.1974.1055306; KANAL L, 1977, IEEE SYST MAN CYBERN; KANAL LN, 1976, P IEEE INT S INFORM; Knuth D. E., 1971, Acta Informatica, V1, P14, DOI 10.1007/BF00264289; KNUTH DE, 1975, ARTIF INTELL, V6, P293, DOI 10.1016/0004-3702(75)90019-3; KOHLER WH, 1974, J ACM, V21, P140, DOI 10.1145/321796.321808; KULKARNI AV, 1976, TR469 U MAR COMP SCI; KULKARNI AV, 1978, 4TH P INT JOINT C PA; KULKARNI AV, 1976, 3RD P INT JOINT C PA; KULKARNI AV, 1976, THESIS U MARYLAND; LEDLEY RS, 1966, AFIPS C P SJCC, P411; Lemmer J. F., 1977, Proceedings of the International Conference on Cybernetics and Society, P612; LEMMER JF, 1977, TR505 U MAR DEP COMP; LENAT DB, 1978, ARTIF INTELL, V9, P257; LEVI G, 1976, ARTIF INTELL, V7, P243, DOI 10.1016/0004-3702(76)90006-0; LU SY, 1976, TREE769 PURD U SCH E; LYON G, 1974, COMMUN ACM, V17, P3, DOI 10.1145/360767.360771; MARR D, 1977, ARTIF INTELL, V9, P37, DOI 10.1016/0004-3702(77)90013-3; MARTELLI A, 1977, ARTIF INTELL, V8, P1, DOI 10.1016/0004-3702(77)90002-9; MCDERMOTT DV, 1974, CONNIVER REFERENCE M; MEISEL WS, 1973, IEEE T COMPUT, VC 22, P93, DOI 10.1109/T-C.1973.223603; MICHALSKI RS, 1975, MULTIPLE VALUED LOGI; MILLER PL, 1973, MIT503 LINC LAB TECH; NADLER M, 1971, IEEE T COMPUT, VC 20, P1598, DOI 10.1109/T-C.1971.223180; NEWBORN MM, 1977, ARTIF INTELL, V8, P137, DOI 10.1016/0004-3702(77)90017-0; Nilsson N.J., 1971, PROBLEM SOLVING METH; PAVLIDIS T, 1976, PATTERN RECOGNITION; POHL I, 1970, ARTIF INTELL, V1, P193, DOI 10.1016/0004-3702(70)90007-X; REASON CC, 1976, 90 U TOR DEP COMP SC; REDDY DR, 1973, 3RD P INT JOINT C AR, P185; RIEGER C, 1976, ARTIFICIAL INTEL JAN; SACERDOTI ED, 1975, 109 STANF RES I ART; SHORTLIFFE EH, 1974, AIM251 STANF U ART I; Shortliffe EH., 1975, MATH BIOSCI, V23, P351, DOI [10.1016/0025-5564(75)90047-4, DOI 10.1016/0025-5564(75)90047-4]; STALLMAN RM, 1977, ARTIFICIAL INTELLIGE, V9; STARKS SA, 1977, 1977 P C INF SCI SYS; STOCKMAN G, 1976, COMMUN ACM, V19, P688, DOI 10.1145/360373.360378; STOCKMAN G, 1974, 2ND P INT JOINT C PA; STOCKMAN G, 1977, THESIS U MARYLAND; STOCKMAN G, 1973, 1ST P INT JOINT C PA; STOCKMAN G, UNPUBLISHED; STOCKMAN G, 1977, TR538 U MAR COMP SCI; STOCKMAN G, 1977, 1977 P INT C CYB SOC, P601; SUSSMAN GJ, 1973, AITR297 MIT; VANDERBRUG GJ, 1976, INFORM SCIENCES, V11, P279, DOI 10.1016/0020-0255(76)90009-8; VANDERBRUG GJ, 1975, COMMUN ACM, V18, P107, DOI 10.1145/360666.360672; WALKER DE, 1974, IEEE S SPEECH RECOGN; WU C, 1975, REEE7517 PURD U SCH	75	34	34	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	2					193	201		10.1109/TPAMI.1979.4766905	http://dx.doi.org/10.1109/TPAMI.1979.4766905			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HA304	21868848				2022-12-18	WOS:A1979HA30400009
J	Chen, XY; Sun, LJ				Chen, Xinyu; Sun, Lijun			Bayesian Temporal Factorization for Multidimensional Time Series Prediction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Time series analysis; Data models; Bayes methods; Spatiotemporal phenomena; Tensors; Reactive power; Probabilistic logic; Time series prediction; missing data imputation; low rank; matrix; tensor factorization; vector autoregression (VAR); Bayesian inference; Markov chain Monte Carlo (MCMC)	DECOMPOSITION; MODELS	Large-scale and multidimensional spatiotemporal data sets are becoming ubiquitous in many real-world applications such as monitoring urban traffic and air quality. Making predictions on these time series has become a critical challenge due to not only the large-scale and high-dimensional nature but also the considerable amount of missing data. In this paper, we propose a Bayesian temporal factorization (BTF) framework for modeling multidimensional time series-in particular spatiotemporal data-in the presence of missing values. By integrating low-rank matrix/tensor factorization and vector autoregressive (VAR) process into a single probabilistic graphical model, this framework can characterize both global and local consistencies in large-scale time series data. The graphical model allows us to effectively perform probabilistic predictions and produce uncertainty estimates without imputing those missing values. We develop efficient Gibbs sampling algorithms for model inference and model updating for real-time prediction and test the proposed BTF framework on several real-world spatiotemporal data sets for both missing data imputation and multi-step rolling prediction tasks. The numerical experiments demonstrate the superiority of the proposed BTF approaches over existing state-of-the-art methods.	[Chen, Xinyu] Polytech Montreal, Dept Civil Geol & Min Engn, Montreal, PQ H3T 1J4, Canada; [Sun, Lijun] McGill Univ, Dept Civil Engn, Montreal, PQ H3A 0C3, Canada; [Sun, Lijun] Interuniv Res Ctr Enterprise Networks Logist & Tr, Montreal, PQ H3T 1J4, Canada	Universite de Montreal; Polytechnique Montreal; McGill University; Universite de Montreal	Sun, LJ (corresponding author), McGill Univ, Dept Civil Engn, Montreal, PQ H3A 0C3, Canada.	chenxy346@gmail.com; lijun.sun@mcgill.ca	Sun, Lijun/E-8170-2015	Sun, Lijun/0000-0001-9488-0712; Chen, Xinyu/0000-0001-6208-7744	Natural Sciences and Engineering Research Council (NSERC); Fonds de recherche du Quebec-Nature et technologies (FRQNT); Canada Foundation for Innovation (CFI) John R. Evans Leaders Fund; IVADO Fundamental Research Project; Institute for Data Valorization (IVADO)	Natural Sciences and Engineering Research Council (NSERC)(Natural Sciences and Engineering Research Council of Canada (NSERC)); Fonds de recherche du Quebec-Nature et technologies (FRQNT); Canada Foundation for Innovation (CFI) John R. Evans Leaders Fund; IVADO Fundamental Research Project; Institute for Data Valorization (IVADO)	This work was supported in part by the Natural Sciences and Engineering Research Council (NSERC) Discovery Grant, in part by the Fonds de recherche du Quebec-Nature et technologies (FRQNT) New University Researchers Start-up Program, in part by the Canada Foundation for Innovation (CFI) John R. Evans Leaders Fund, and in part by the IVADO Fundamental Research Project. Xinyu Chen would like to thank the Institute for Data Valorization (IVADO) for providing PhD scholarship. The numerical experiment of this study is available at https://github.com/xinychen/transdim.	Adams R. P., 2010, P UNC ART INT, P1; Aguilar O, 2000, J BUS ECON STAT, V18, P338, DOI 10.2307/1392266; Anava O, 2015, PR MACH LEARN RES, V37, P2191; Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374; Athanasopoulos G, 2021, FORECASTING PRINCIPL, Vthird; Bahadori M.T., 2014, P 27 INT C NEURAL IN, V2, P3491; Bishop CM, 1999, ADV NEUR IN, V11, P382; Cai YJ, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P79, DOI 10.1145/2783258.2783348; Che ZP, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24271-9; Chen C, 2001, TRANSPORT RES REC, P96; Chen XY, 2019, TRANSPORT RES C-EMER, V104, P66, DOI 10.1016/j.trc.2019.03.003; Chen XY, 2019, TRANSPORT RES C-EMER, V98, P73, DOI 10.1016/j.trc.2018.11.003; Chen Z., 2005, NAVIGATION CHING J C, P1; Cun-hui Zhang, 2020, Arxiv, DOI arXiv:1905.07530; Damianou A., 2011, ADV NEURAL INFORM PR, P2510; Deng DX, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1525, DOI 10.1145/2939672.2939860; Dit-Yan Yeung, 2018, Arxiv, DOI arXiv:1808.06865; Faloutsos C, 2018, PROC VLDB ENDOW, V11, P2102, DOI 10.14778/3229863.3229878; Gopalan P, 2014, JMLR WORKSH CONF PRO, V33, P275; Gultekin S, 2019, IEEE T SIGNAL PROCES, V67, P1223, DOI 10.1109/TSP.2018.2889982; Jing PG, 2019, IEEE T CYBERNETICS, V49, P2385, DOI 10.1109/TCYB.2018.2832085; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Koop Gary, 2009, Foundations and Trends in Econometrics, V3, P267, DOI 10.1561/0800000013; Lawrence ND, 2004, ADV NEUR IN, V16, P329; Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39; Luttinen J., 2009, ADV NEURAL INFORM PR, P1177; Luttinen J, 2012, NEURAL PROCESS LETT, V36, P189, DOI 10.1007/s11063-012-9230-4; Nguyen TV, 2014, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P643; Rangapuram SS, 2018, ADV NEUR IN, V31; Rao N., 2015, PROC 28 INT C NEURAL, P2107, DOI DOI 10.5555/2969442.2969475; Rogers M., 2013, ADV NEURAL INF PROCE, V26, P2634; Salakhutdinov R., 2008, P ICML HELS FINL, P880, DOI [10.1145/13901561390267, DOI 10.1145/13901561390267, 10.1145/1390156.1390267]; Schein A, 2016, PR MACH LEARN RES, V48; Stock JH, 2016, HBK ECON, P415, DOI 10.1016/bs.hesmac.2016.04.002; Sun JZ, 2014, IEEE T SIGNAL PROCES, V62, P3499, DOI 10.1109/TSP.2014.2326618; Sun LJ, 2016, TRANSPORT RES B-METH, V91, P511, DOI 10.1016/j.trb.2016.06.011; Takeuchi K, 2017, IEEE DATA MINING, P1105, DOI 10.1109/ICDM.2017.146; Tan HC, 2016, IEEE T INTELL TRANSP, V17, P2123, DOI 10.1109/TITS.2015.2513411; Wang J.M., 2005, ADV NEURAL INFORM PR, P1441, DOI [10.5555/2976248.2976429, DOI 10.5555/2976248.2976429]; Wang YY, 2019, PR MACH LEARN RES, V97; West M., 1989, BAYESIAN FORECASTING, DOI 10.1007/978-1-4757-9365-9; Xiong L., 2010, P SDM COL OH, P211; Yaguang Li, 2018, SIGSPATIAL Special, V10, P3, DOI 10.1145/3231541.3231544; Yokota T, 2016, IEEE T SIGNAL PROCES, V64, P5423, DOI 10.1109/TSP.2016.2586759; Yu Hsiang-Fu, 2016, ADV NEURAL INFORM PR, P847; Zhao J, 2016, J MACH LEARN RES, V17, P1; Zhao J, 2016, IEEE T INTELL TRANSP, V17, P2014, DOI 10.1109/TITS.2016.2515105; Zhao QB, 2016, IEEE T NEUR NET LEAR, V27, P736, DOI 10.1109/TNNLS.2015.2423694; Zhao QB, 2015, IEEE T PATTERN ANAL, V37, P1751, DOI 10.1109/TPAMI.2015.2392756; Zheng FH, 2012, PROCEEDINGS OF 2012 INTERNATIONAL CONFERENCE ON PUBLIC ADMINISTRATION (8TH), VOL III, P403	50	33	33	30	45	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					4659	4673		10.1109/TPAMI.2021.3066551	http://dx.doi.org/10.1109/TPAMI.2021.3066551			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33729926	Green Submitted			2022-12-18	WOS:000836666600016
J	Wang, WG; Shen, JB; Lu, XK; Hoi, SCH; Ling, HB				Wang, Wenguan; Shen, Jianbing; Lu, Xiankai; Hoi, Steven C. H.; Ling, Haibin			Paying Attention to Video Object Pattern Understanding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visualization; Object segmentation; Motion segmentation; Task analysis; Annotations; Biological system modeling; Image segmentation; Video object pattern understanding; unsupervised video object segmentation; top-down visual attention; video salient object detection	SPATIOTEMPORAL SALIENCY DETECTION; VISUAL-ATTENTION; DETECTION MODEL; BOTTOM-UP; SEGMENTATION; SCENE	This paper conducts a systematic study on the role of visual attention in video object pattern understanding. By elaborately annotating three popular video segmentation datasets (DAVIS) with dynamic eye-tracking data in the unsupervised video object segmentation (UVOS) setting. For the first time, we quantitatively verified the high consistency of visual attention behavior among human observers, and found strong correlation between human attention and explicit primary object judgments during dynamic, task-driven viewing. Such novel observations provide an in-depth insight of the underlying rationale behind video object pattens. Inspired by these findings, we decouple UVOS into two sub-tasks: UVOS-driven Dynamic Visual Attention Prediction (DVAP) in spatiotemporal domain, and Attention-Guided Object Segmentation (AGOS) in spatial domain. Our UVOS solution enjoys three major advantages: 1) modular training without using expensive video segmentation annotations, instead, using more affordable dynamic fixation data to train the initial video attention module and using existing fixation-segmentation paired static/image data to train the subsequent segmentation module; 2) comprehensive foreground understanding through multi-source learning; and 3) additional interpretability from the biologically-inspired and assessable attention. Experiments on four popular benchmarks show that, even without using expensive video object mask annotations, our model achieves compelling performance compared with state-of-the-arts and enjoys fast processing speed (10 fps on a single GPU). Our collected eye-tracking data and algorithm implementations have been made publicly available athttps://github.com/wenguanwang/AGS.	[Wang, Wenguan; Shen, Jianbing] Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China; [Wang, Wenguan] Swiss Fed Inst Technol, CH-8092 Zurich, Switzerland; [Shen, Jianbing; Lu, Xiankai] Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates; [Hoi, Steven C. H.] Singapore Management Univ, Sch Informat Syst, Singapore 178902, Singapore; [Hoi, Steven C. H.] Salesforce Res Asia, Singapore 038985, Singapore; [Ling, Haibin] SUNY Stony Brook, Dept Comp Sci, Strony Brook, NY 11794 USA	Beijing Institute of Technology; Swiss Federal Institutes of Technology Domain; ETH Zurich; Singapore Management University; Salesforce; State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	Shen, JB (corresponding author), Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.; Shen, JB (corresponding author), Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates.	wenguanwang.ai@gmail.com; shenjianbingcg@gmail.com; carrierlxk@gmail.com; stevenhoi@gmail.com; hling@cs.stonybrook.edu	Wang, Wenguan/AAA-5782-2022	Wang, Wenguan/0000-0002-0802-9567; Ling, Haibin/0000-0003-4094-8413	Beijing Natural Science Foundation [4182056]; CCF-Tencent Open Fund; Tencent AI Lab Rhino-Bird Focused Research Program; Zhijiang Lab's International Talent Fund for Young Professionals; Joint Building Program of Beijing Municipal Education Commission; Yahoo Faculty Research and Engagement Program Award; Amazon AWS Machine Learning Research Award	Beijing Natural Science Foundation(Beijing Natural Science Foundation); CCF-Tencent Open Fund; Tencent AI Lab Rhino-Bird Focused Research Program; Zhijiang Lab's International Talent Fund for Young Professionals; Joint Building Program of Beijing Municipal Education Commission; Yahoo Faculty Research and Engagement Program Award; Amazon AWS Machine Learning Research Award	This work was supported in part by the Beijing Natural Science Foundation under Grant 4182056, the CCF-Tencent Open Fund, Tencent AI Lab Rhino-Bird Focused Research Program, Zhijiang Lab's International Talent Fund for Young Professionals, and the Joint Building Program of Beijing Municipal Education Commission. Prof. Haibin Ling was supported in part by the Yahoo Faculty Research and Engagement Program Award, and the Amazon AWS Machine Learning Research Award. A preliminary version of this work has appeared in CVPR 2019 [1].	Alvarez GA, 2007, J VISION, V7, DOI 10.1167/7.13.14; [Anonymous], 2006, NIPS; Bahdanau Dzmitry, 2015, NEURAL MACHINE TRANS; Borji A, 2015, IEEE T IMAGE PROCESS, V24, P742, DOI 10.1109/TIP.2014.2383320; Borji A, 2013, VISION RES, V91, P62, DOI 10.1016/j.visres.2013.07.016; Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89; Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21; Brutzer S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1937, DOI 10.1109/CVPR.2011.5995508; Caelles Sergi, 2019, ARXIV190500737; Chen DY, 2013, IEEE T MULTIMEDIA, V15, P1616, DOI 10.1109/TMM.2013.2267725; Chen L.-C., 2017, RETHINKING ATROUS CO; Chen L, 2015, IEEE T MULTIMEDIA, V17, P2225, DOI 10.1109/TMM.2015.2481711; Cheng JC, 2017, IEEE I CONF COMP VIS, P686, DOI 10.1109/ICCV.2017.81; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Einhauser W, 2008, J VISION, V8, DOI 10.1167/8.2.2; Faktor A., 2014, P BMVC, V2, P8; Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875; Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P3910, DOI 10.1109/TIP.2014.2336549; Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613; Frackowiak RSJ, 2004, HUMAN BRAIN FUNCTION; Fragkiadaki K, 2015, PROC CVPR IEEE, P4083, DOI 10.1109/CVPR.2015.7299035; Fragkiadaki K, 2012, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2012.6247883; Gao D., 2005, ADV NEURAL INFORM PR, P481; Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969; Hadizadeh H, 2012, IEEE T IMAGE PROCESS, V21, P898, DOI 10.1109/TIP.2011.2165292; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; Hayman E, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P67; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563; Hou X., 2009, ADV NEURAL INFORM PR, P681; Hou XD, 2007, PROC CVPR IEEE, P2280; Hu YT, 2018, LECT NOTES COMPUT SC, V11205, P813, DOI 10.1007/978-3-030-01246-5_48; Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38; IRANI M, 1994, INT J COMPUT VISION, V12, P5, DOI 10.1007/BF01420982; Irani M, 1998, IEEE T PATTERN ANAL, V20, P577, DOI 10.1109/34.683770; Itti L, 2005, VIS COGN, V12, P1093, DOI 10.1080/13506280444000661; Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jain SD, 2017, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2017.228; Jang WD, 2016, PROC CVPR IEEE, P696, DOI 10.1109/CVPR.2016.82; Jiang L, 2018, LECT NOTES COMPUT SC, V11218, P625, DOI 10.1007/978-3-030-01264-9_37; Judd T., 2012, TECHNICAL REPORT; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Katsuki F, 2014, NEUROSCIENTIST, V20, P509, DOI 10.1177/1073858413514136; Keuper M, 2015, IEEE I CONF COMP VIS, P3271, DOI 10.1109/ICCV.2015.374; Kim W, 2011, IEEE T CIRC SYST VID, V21, P446, DOI 10.1109/TCSVT.2011.2125450; KOCH C, 1985, HUM NEUROBIOL, V4, P219; Koh YJ, 2017, PROC CVPR IEEE, P7417, DOI 10.1109/CVPR.2017.784; Krahenbuhl P., 2011, ADV NEURAL INF PROCE, V24, P109; Lai QX, 2020, IEEE T IMAGE PROCESS, V29, P1113, DOI 10.1109/TIP.2019.2936112; Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86; Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471; Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273; Li GB, 2018, PROC CVPR IEEE, P3243, DOI 10.1109/CVPR.2018.00342; Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58; Li SY, 2018, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2018.00683; Li SY, 2018, LECT NOTES COMPUT SC, V11207, P215, DOI 10.1007/978-3-030-01219-9_13; Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43; Liu Z, 2017, IEEE T CIRC SYST VID, V27, P2527, DOI 10.1109/TCSVT.2016.2595324; Liu Z, 2014, IEEE T CIRC SYST VID, V24, P1522, DOI 10.1109/TCSVT.2014.2308642; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374; Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22; Luiten J, 2019, LECT NOTES COMPUT SC, V11364, P565, DOI 10.1007/978-3-030-20870-7_35; Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698; Ma TY, 2012, PROC CVPR IEEE, P670, DOI 10.1109/CVPR.2012.6247735; Mahadevan V., 2012, P INT C NEUR INF PRO, P1664; Mathe S, 2015, IEEE T PATTERN ANAL, V37, P1408, DOI 10.1109/TPAMI.2014.2366154; Mital PK, 2011, COGN COMPUT, V3, P5, DOI 10.1007/s12559-010-9074-z; Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242; Ochs P, 2011, IEEE I CONF COMP VIS, P1583, DOI 10.1109/ICCV.2011.6126418; Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71; Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065; Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27; Ramakanth SA, 2014, PROC CVPR IEEE, P376, DOI 10.1109/CVPR.2014.55; Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15; Shao D, 2018, LECT NOTES COMPUT SC, V11213, P202, DOI 10.1007/978-3-030-01240-3_13; Shi XJ, 2015, ADV NEUR IN, V28; Siam M, 2019, IEEE INT CONF ROBOT, P50, DOI 10.1109/ICRA.2019.8794254; Sinclair D., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P366, DOI 10.1109/ICCV.1993.378191; Song HM, 2018, LECT NOTES COMPUT SC, V11215, P744, DOI 10.1007/978-3-030-01252-6_44; Taylor B, 2015, PROC CVPR IEEE, P4268, DOI 10.1109/CVPR.2015.7299055; Tokmakov P, 2019, INT J COMPUT VISION, V127, P282, DOI 10.1007/s11263-018-1122-2; Tokmakov P, 2017, IEEE I CONF COMP VIS, P4491, DOI 10.1109/ICCV.2017.480; Tokmakov P, 2017, PROC CVPR IEEE, P531, DOI 10.1109/CVPR.2017.64; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; Tsai YH, 2016, LECT NOTES COMPUT SC, V9908, P760, DOI 10.1007/978-3-319-46493-0_46; Vazquez-Reina A, 2010, LECT NOTES COMPUT SC, V6315, P268, DOI 10.1007/978-3-642-15555-0_20; Ventura C, 2019, PROC CVPR IEEE, P5272, DOI 10.1109/CVPR.2019.00542; Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683; Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433; Wang W, 2019, ARXIV190409146; Wang WG, 2020, IEEE T PATTERN ANAL, V42, P1913, DOI 10.1109/TPAMI.2019.2905607; Wang WG, 2021, IEEE T PATTERN ANAL, V43, P220, DOI 10.1109/TPAMI.2019.2924417; Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933; Wang WG, 2019, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2019.00318; Wang WG, 2019, IEEE T PATTERN ANAL, V41, P1531, DOI 10.1109/TPAMI.2018.2840724; Wang WG, 2018, PROC CVPR IEEE, P4271, DOI 10.1109/CVPR.2018.00449; Wang WG, 2019, IEEE T PATTERN ANAL, V41, P985, DOI 10.1109/TPAMI.2018.2819173; Wang WG, 2018, IEEE T CIRC SYST VID, V28, P1727, DOI 10.1109/TCSVT.2017.2701279; Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612; Wang Wenguan, 2018, IEEE Trans Image Process, V27, P38, DOI 10.1109/TIP.2017.2754941; Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005; Wang WG, 2017, IEEE T VIS COMPUT GR, V23, P2014, DOI 10.1109/TVCG.2016.2600594; Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013; Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961; WOLFE JM, 1989, J EXP PSYCHOL HUMAN, V15, P419, DOI 10.1037/0096-1523.15.3.419; Xiao FY, 2016, PROC CVPR IEEE, P933, DOI 10.1109/CVPR.2016.107; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407; Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10; Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87; Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32; Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31; Zhou F, 2014, PROC CVPR IEEE, P3358, DOI 10.1109/CVPR.2014.429	122	33	33	3	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2021	43	7					2413	2428		10.1109/TPAMI.2020.2966453	http://dx.doi.org/10.1109/TPAMI.2020.2966453			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL3FK	31940522	Green Accepted			2022-12-18	WOS:000692540900018
J	Zhou, P; Lu, CY; Feng, JS; Lin, ZC; Yan, SC				Zhou, Pan; Lu, Canyi; Feng, Jiashi; Lin, Zhouchen; Yan, Shuicheng			Tensor Low-Rank Representation for Data Recovery and Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dictionaries; Noise measurement; Data analysis; Clustering algorithms; Task analysis; Face; Tensor low-rank representation; low-rank tensor recovery; tensor data clustering	FACE RECOGNITION; DECOMPOSITIONS; MATRICES; MODELS	Multi-way or tensor data analysis has attracted increasing attention recently, with many important applications in practice. This article develops a tensor low-rank representation (TLRR) method, which is the first approach that can exactly recover the clean data of intrinsic low-rank structure and accurately cluster them as well, with provable performance guarantees. In particular, for tensor data with arbitrary sparse corruptions, TLRR can exactly recover the clean data under mild conditions; meanwhile TLRR can exactly verify their true origin tensor subspaces and hence cluster them accurately. TLRR objective function can be optimized via efficient convex programing with convergence guarantees. Besides, we provide two simple yet effective dictionary construction methods, the simple TLRR (S-TLRR) and robust TLRR (R-TLRR), to handle slightly and severely corrupted data respectively. Experimental results on two computer vision data analysis tasks, image/video recovery and face clustering, clearly demonstrate the superior performance, efficiency and robustness of our developed method over state-of-the-arts including the popular LRR and SSC methods.	[Zhou, Pan; Feng, Jiashi] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore, Singapore; [Lu, Canyi] Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA USA; [Lin, Zhouchen] Peking Univ, Sch EECS, Key Lab Machine Percept MoE, Beijing, Peoples R China; [Yan, Shuicheng] YITU Tech, Shanghai, Peoples R China	National University of Singapore; Carnegie Mellon University; Peking University	Lin, ZC (corresponding author), Peking Univ, Sch EECS, Key Lab Machine Percept MoE, Beijing, Peoples R China.	pzhou@u.nus.edu; canyilu@gmail.com; elefjia@nus.edu.sg; zlin@pku.edu.cn; eleyans@nus.edu.sg	Feng, Jiashi/AGX-6209-2022; Yan, Shuicheng/HCI-1431-2022		NUS IDS [R-263-000-C67-646]; ECRA [R-263-000-C87-133]; MOE Tier-II [R-263-000-D17-112]; AI.SG [AI.SG R-263-000-D97-490]; NSF China [61625301, 61731018]; Major Scientific Research Project of Zhejiang Lab [2019KB0AC01]; Zhejiang Lab [2019KB0AB02]; Beijing Academy of Artificial Intelligence	NUS IDS; ECRA; MOE Tier-II; AI.SG; NSF China(National Natural Science Foundation of China (NSFC)); Major Scientific Research Project of Zhejiang Lab; Zhejiang Lab; Beijing Academy of Artificial Intelligence	Jiashi Feng was partially supported by NUS IDS R-263-000-C67-646, ECRA R-263-000-C87-133, MOE Tier-II R-263-000-D17-112 and AI.SG R-263-000-D97-490. Z. Lin is supported by NSF China (grant no.s 61625301 and 61731018), Major Scientific Research Project of Zhejiang Lab (grant no. 2019KB0AC01), Zhejiang Lab (grant no. 2019KB0AB02), and Beijing Academy of Artificial Intelligence.	Candes E., 2011, J ACM, V58; Cui Y., 2013, PLOS ONE, V8; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Fu YF, 2016, IEEE T NEUR NET LEAR, V27, P2120, DOI 10.1109/TNNLS.2016.2553155; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Goldfarb D, 2014, SIAM J MATRIX ANAL A, V35, P225, DOI 10.1137/130905010; Gross D, 2011, IEEE T INFORM THEORY, V57, P1548, DOI 10.1109/TIT.2011.2104999; He K., 2016, PROC IEEE C COMPUTER, P770, DOI DOI 10.1109/CVPR.2016.90; Hillar C., 2013, J ACM, V60; Huang B., 2014, OPTIM ONLINE, V4252; Kiers HAL, 2000, J CHEMOMETR, V14, P105, DOI 10.1002/1099-128X(200005/06)14:3<105::AID-CEM582>3.0.CO;2-I; Kilmer ME, 2013, SIAM J MATRIX ANAL A, V34, P148, DOI 10.1137/110837711; Kilmer ME, 2011, LINEAR ALGEBRA APPL, V435, P641, DOI 10.1016/j.laa.2010.09.020; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Landsberg J., 2012, TENSORS GEOMETRY APP; Lang CY, 2012, IEEE T IMAGE PROCESS, V21, P1327, DOI 10.1109/TIP.2011.2169274; Lee H., 2007, ADV NEURAL INF PROCE, P801; Lin Z., 2011, PROC INT 25 C NEURAL, P612, DOI DOI 10.1007/S11263-013-0611-6; Liu G., 2016, IEEE T PATTERN ANAL, V35, P171; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu GC, 2011, IEEE I CONF COMP VIS, P1615, DOI 10.1109/ICCV.2011.6126422; Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39; Lu C., 2018, IEEE T PATTERN ANAL, V35, P208; Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26; Lu CY, 2016, PROC CVPR IEEE, P5249, DOI 10.1109/CVPR.2016.567; Mahoney MW, 2009, P NATL ACAD SCI USA, V106, P697, DOI [10.1073/pnas.0803205105, 10.1073/pnas.0803205106]; Manning C., 2010, INTRO INFORM RETRIEV; Martin D., 2001, P ICCV, P416, DOI DOI 10.1109/ICCV.2001.937655; Mu C, 2014, PR MACH LEARN RES, V32, P73; Phillips J.J., 2005, PROC CVPR IEEE, V1, P947, DOI DOI 10.1109/CVPR.2005.268; Romera-Paredes B., P C NEUTR INF PROC S, P2967; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Song Z., 2019, P 30 ANN ACM SIAM S, P2772, DOI DOI 10.1137/1.9781611975482.172; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464; Vinh NX, 2010, J MACH LEARN RES, V11, P2837; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yan JY, 2006, LECT NOTES COMPUT SC, V3954, P94; Yin M, 2016, IEEE T PATTERN ANAL, V38, P504, DOI 10.1109/TPAMI.2015.2462360; You C, 2016, PROC CVPR IEEE, P3928, DOI 10.1109/CVPR.2016.426; Zhang CQ, 2015, IEEE I CONF COMP VIS, P1582, DOI 10.1109/ICCV.2015.185; Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34; Zhang ZM, 2014, PROC CVPR IEEE, P3842, DOI 10.1109/CVPR.2014.485; Zhou P., NEUROCOMPUTING, V273, P414; Zhou P, 2018, IEEE T IMAGE PROCESS, V27, P1152, DOI 10.1109/TIP.2017.2762595; Zhou P, 2017, PROC CVPR IEEE, P3938, DOI 10.1109/CVPR.2017.419; Zhou P, 2017, IEEE T IMAGE PROCESS, V26, P1173, DOI 10.1109/TIP.2016.2623487; Zhou P, 2016, IEEE T NEUR NET LEAR, V27, P1080, DOI 10.1109/TNNLS.2015.2436951	48	33	34	7	55	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2021	43	5					1718	1732		10.1109/TPAMI.2019.2954874	http://dx.doi.org/10.1109/TPAMI.2019.2954874			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RJ3YD	31751228				2022-12-18	WOS:000637533800017
J	Zhao, WD; Zhao, F; Wang, D; Lu, HC				Zhao, Wenda; Zhao, Fan; Wang, Dong; Lu, Huchuan			Defocus Blur Detection via Multi-Stream Bottom-Top-Bottom Network	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Image edge detection; Streaming media; Semantics; Clutter; Image restoration; Deep learning; Defocus blur detection; multi-stream bottom-top-bottom network; cascaded DBD map residual learning	MAP ESTIMATION; IMAGE	Defocus blur detection (DBD) is aimed to estimate the probability of each pixel being in-focus or out-of-focus. This process has been paid considerable attention due to its remarkable potential applications. Accurate differentiation of homogeneous regions and detection of low-contrast focal regions, as well as suppression of background clutter, are challenges associated with DBD. To address these issues, we propose a multi-stream bottom-top-bottom fully convolutional network (BTBNet), which is the first attempt to develop an end-to-end deep network to solve the DBD problems. First, we develop a fully convolutional BTBNet to gradually integrate nearby feature levels of bottom to top and top to bottom. Then, considering that the degree of defocus blur is sensitive to scales, we propose multi-stream BTBNets that handle input images with different scales to improve the performance of DBD. Finally, a cascaded DBD map residual learning architecture is designed to gradually restore finer structures from the small scale to the large scale. To promote further study and evaluation of the DBD models, we construct a new database of 1100 challenging images and their pixel-wise defocus blur annotations. Experimental results on the existing and our new datasets demonstrate that the proposed method achieves significantly better performance than other state-of-the-art algorithms.	[Zhao, Wenda; Wang, Dong; Lu, Huchuan] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Peoples R China; [Zhao, Fan] Chinese Acad Sci, Dalian Inst Chem Phys, Dalian 116024, Peoples R China	Dalian University of Technology; Chinese Academy of Sciences; Dalian Institute of Chemical Physics, CAS	Zhao, WD (corresponding author), Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Peoples R China.	zhaowenda@dlut.edu.cn; zhaofan@dicp.ac.cn; wdice@dlut.edu.cn; lhchuan@dlut.edu.cn			National Natural Science Foundation of China [61801077, 61872056, 61771088, 61725202]; China Postdoctoral Science Foundation [2017M611221]; Fundamental Research Funds for the Central Universities [DUT16RC (3)077, DUT2017TB04, DUT18JC30, DUT17TD03]; CCF-Tencent Open Fund	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); China Postdoctoral Science Foundation(China Postdoctoral Science Foundation); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); CCF-Tencent Open Fund	This work was supported by National Natural Science Foundation of China under Grant Nos. 61801077, 61872056, 61771088, 61725202, the China Postdoctoral Science Foundation under Grant No. 2017M611221, and the Fundamental Research Funds for the Central Universities under Grant Nos. DUT16RC (3)077, DUT2017TB04, DUT18JC30 and DUT17TD03. This work was also sponsored by CCF-Tencent Open Fund.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Bac S, 2007, COMPUT GRAPH FORUM, V26, P571, DOI 10.1111/j.1467-8659.2007.01080.x; Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396; Couzinie-Devy F, 2013, PROC CVPR IEEE, P1075, DOI 10.1109/CVPR.2013.143; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301; Golestaneh S., 2017, P IEEE C COMP VIS PA, P5800; Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90; Kang K, 2016, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2016.95; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Levin A, 2008, IEEE T PATTERN ANAL, V30, P1699, DOI 10.1109/TPAMI.2008.168; Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079; Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Mao LM, 2008, I C WIREL COMM NETW, P10001; Pan JS, 2019, IEEE T PATTERN ANAL, V41, P1412, DOI 10.1109/TPAMI.2018.2832125; Pang JH, 2017, IEEE INT CONF COMP V, P878, DOI 10.1109/ICCVW.2017.108; Pang YW, 2016, IEEE T CYBERNETICS, V46, P2220, DOI 10.1109/TCYB.2015.2472478; Park J, 2017, PROC CVPR IEEE, P2760, DOI 10.1109/CVPR.2017.295; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Saad E, 2016, IEEE T IMAGE PROCESS, V25, P3141, DOI 10.1109/TIP.2016.2555702; Schaefer G., 2003, STORAGE RETRIEVAL ME, V33, P1; Shen XY, 2015, IEEE I CONF COMP VIS, P3406, DOI 10.1109/ICCV.2015.389; Shi JP, 2015, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2015.7298665; Shi JP, 2014, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2014.379; Su B., 2011, P 19 ACM INT C MULT, P1397; Sun C, 2018, PROC CVPR IEEE, P8962, DOI 10.1109/CVPR.2018.00934; Tai YW, 2009, IEEE IMAGE PROC, P1797, DOI 10.1109/ICIP.2009.5414620; Tang C, 2016, IEEE SIGNAL PROC LET, V23, P1652, DOI 10.1109/LSP.2016.2611608; Tang C, 2013, OPT LETT, V38, P1706, DOI 10.1364/OL.38.001706; Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974; Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Xu GD, 2017, IEEE I CONF COMP VIS, P5381, DOI 10.1109/ICCV.2017.574; Yi X, 2016, IEEE T IMAGE PROCESS, V25, P1626, DOI 10.1109/TIP.2016.2528042; Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206; Zhang XX, 2016, J VIS COMMUN IMAGE R, V35, P257, DOI 10.1016/j.jvcir.2016.01.002; Zhang Y, 2013, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2013.145; Zhao JF, 2013, SIGNAL IMAGE VIDEO P, V7, P1173, DOI 10.1007/s11760-012-0381-6; Zhao WD, 2018, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2018.00325; Zhu X, 2013, IEEE T IMAGE PROCESS, V22, P4879, DOI 10.1109/TIP.2013.2279316; Zhuo SJ, 2011, PATTERN RECOGN, V44, P1852, DOI 10.1016/j.patcog.2011.03.009	48	33	36	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG. 1	2020	42	8					1884	1897		10.1109/TPAMI.2019.2906588	http://dx.doi.org/10.1109/TPAMI.2019.2906588			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MF5XR	30908190				2022-12-18	WOS:000545415400006
J	Trigeorgis, G; Nicolaou, MA; Schuller, BW; Zafeiriou, S				Trigeorgis, George; Nicolaou, Mihalis A.; Schuller, Bjorn W.; Zafeiriou, Stefanos			Deep Canonical Time Warping for Simultaneous Alignment and Representation Learning of Sequences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Time warping; CCA; LDA; DCCA; DDA; deep learning; shared representations; DCTW	RECOGNITION	Machine learning algorithms for the analysis of time-series often depend on the assumption that utilised data are temporally aligned. Any temporal discrepancies arising in the data is certain to lead to ill-generalisable models, which in turn fail to correctly capture properties of the task at hand. The temporal alignment of time-series is thus a crucial challenge manifesting in a multitude of applications. Nevertheless, the vast majority of algorithms oriented towards temporal alignment are either applied directly on the observation space or simply utilise linear projections-thus failing to capture complex, hierarchical non-linear representations that may prove beneficial, especially when dealing with multi-modal data (e.g., visual and acoustic information). To this end, we present Deep Canonical Time Warping (DCTW), a method that automatically learns non-linear representations of multiple time-series that are (i) maximally correlated in a shared subspace, and (ii) temporally aligned. Furthermore, we extend DCTW to a supervised setting, where during training, available labels can be utilised towards enhancing the alignment process. By means of experiments on four datasets, we show that the representations learnt significantly outperform state-of-the-art methods in temporal alignment, elegantly handling scenarios with heterogeneous feature sets, such as the temporal alignment of acoustic and visual information.	[Trigeorgis, George; Schuller, Bjorn W.; Zafeiriou, Stefanos] Imperial Coll London, Dept Comp, London SW7 2RH, England; [Nicolaou, Mihalis A.] Goldsmiths Univ London, Dept Comp, London WC1E 7HU, England; [Zafeiriou, Stefanos] Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu 90014, Finland	Imperial College London; University of London; Goldsmiths University London; University of Oulu	Trigeorgis, G (corresponding author), Imperial Coll London, Dept Comp, London SW7 2RH, England.	g.trigeorgis@imperial.ac.uk; m.nicolaou@gold.ac.uk; bjoern.schuller@imperial.ac.uk; s.zafeiriou@imperial.ac.uk	Trigeorgis, George/Y-8208-2019	Schuller, Bjorn/0000-0002-6478-8699	Department of Computing, Imperial College London; EPSRC [EP/J017787/1 (4D-FAB)]; FiDiPro program of Tekes [1849/31/2015]; European Community [645378]; EPSRC [EP/J017787/1, EP/H016988/1, EP/N007743/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [EP/J017787/1, EP/H016988/1, EP/N007743/1] Funding Source: researchfish	Department of Computing, Imperial College London; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); FiDiPro program of Tekes; European Community(European Commission); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	George Trigeorgis is a recipient of the fellowship of the Department of Computing, Imperial College London, and this work was partially funded by it. The work of Stefanos Zafeiriou was partially funded by the EPSRC project EP/J017787/1 (4D-FAB), as well as by the FiDiPro program of Tekes (project number: 1849/31/2015). The work of Bjorn W. Schuller was partially funded by the European Community's Horizon 2020 Framework Programme under grant agreement No. 645378 (ARIA-VALUSPA). We also thank the NVIDIA Corporation for donating a Titan X GPU used in this work. The responsibility lies with the authors.	Aach J, 2001, BIOINFORMATICS, V17, P495, DOI 10.1093/bioinformatics/17.6.495; Andrew G., 2013, INT C MACH LEARN, p1247?1255; [Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Bach F. R., 2005, 688 U CAL DEP STAT; Bach FR, 2008, J MACH LEARN RES, V9, P1019; Bruderlin A., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P97, DOI 10.1145/218380.218421; Caspi Y, 2002, INT J COMPUT VISION, V48, P39, DOI 10.1023/A:1014803327923; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420; De la Torre F, 2012, IEEE T PATTERN ANAL, V34, P1041, DOI 10.1109/TPAMI.2011.184; Dorfer M., 2016, ICLR; Duchi J, 2011, J MACH LEARN RES, V12, P2121; Fukunaga K., 2013, INTRO STAT PATTERN R; Gong D, 2011, IEEE I CONF COMP VIS, P571, DOI 10.1109/ICCV.2011.6126290; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Gorelick L, 2006, IEEE T PATTERN ANAL, V28, P1991, DOI 10.1109/TPAMI.2006.253; Hasan Mohammed A., 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P1128, DOI 10.1109/IJCNN.2009.5178958; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hsu E, 2005, ACM T GRAPHIC, V24, P1082, DOI 10.1145/1073204.1073315; JUANG BH, 1984, AT&T TECH J, V63, P1213, DOI 10.1002/j.1538-7305.1984.tb00034.x; Kazemi V., 2014, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2014.241; Kim Y, 2013, INT CONF ACOUST SPEE, P3687, DOI 10.1109/ICASSP.2013.6638346; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Maas A.L., 2013, P INT C MACH LEARN, V30; Mardia KV, 1979, MULTIVARIATE ANAL; Maurer CR, 2003, IEEE T PATTERN ANAL, V25, P265, DOI 10.1109/TPAMI.2003.1177156; Ngiam J., 2011, P INT C MACH LEARN; Nielsen AA, 2002, IEEE T IMAGE PROCESS, V11, P293, DOI 10.1109/83.988962; Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424; Patterson EK, 2002, INT CONF ACOUST SPEE, P2017; Peters J, 2017, ADAPT COMPUT MACH LE; Rabiner L., 1993, FUNDAMENTALS SPEECH, V103; SALVADOR S, 2004, P KDD WORKSH MIN TEM; Shariat S, 2011, IEEE I CONF COMP VIS, P2572, DOI 10.1109/ICCV.2011.6126545; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Trigeorgis G, 2016, PROC CVPR IEEE, P5110, DOI 10.1109/CVPR.2016.552; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vu H., 2012, P 26 AAAI C ART INT, V26, P1155; Wang AR, 2014, LECT NOTES COMPUT SC, V8693, P453, DOI 10.1007/978-3-319-10602-1_30; Westbury J., 1990, J ACOUST SOC AM, V88, pS56, DOI DOI 10.1121/1.20290; Zhou F., 2009, ADV NEURAL INFORM PR, V22, P2286; Zhou F, 2016, IEEE T PATTERN ANAL, V38, P279, DOI 10.1109/TPAMI.2015.2414429; Zhou F, 2012, PROC CVPR IEEE, P1282, DOI 10.1109/CVPR.2012.6247812	44	33	33	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2018	40	5					1128	1138		10.1109/TPAMI.2017.2710047	http://dx.doi.org/10.1109/TPAMI.2017.2710047			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GB2RB	28613160	Green Submitted, Green Accepted			2022-12-18	WOS:000428901200009
J	Liu, LQ; Wang, P; Shen, CH; Wang, L; van den Hengel, A; Wang, C; Shen, HT				Liu, Lingqiao; Wang, Peng; Shen, Chunhua; Wang, Lei; van den Hengel, Anton; Wang, Chao; Shen, Heng Tao			Compositional Model Based Fisher Vector Coding for Image Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fisher vector coding; sparse coding; hybrid sparse coding; convolutional networks; generic image classification	ACTION RECOGNITION; DICTIONARY	Deriving from the gradient vector of a generative model of local features, Fisher vector coding (FVC) has been identified as an effective coding method for image classification. Most, if not all, FVC implementations employ the Gaussian mixture model (GMM) as the generative model for local features. However, the representative power of a GMM can be limited because it essentially assumes that local features can be characterized by a fixed number of feature prototypes, and the number of prototypes is usually small in FVC. To alleviate this limitation, in this work, we break the convention which assumes that a local feature is drawn from one of a few Gaussian distributions. Instead, we adopt a compositional mechanism which assumes that a local feature is drawn from a Gaussian distribution whose mean vector is composed as a linear combination of multiple key components, and the combination weight is a latent random variable. In doing so we greatly enhance the representative power of the generative model underlying FVC. To implement our idea, we design two particular generative models following this compositional approach. In our first model, the mean vector is sampled from the subspace spanned by a set of bases and the combination weight is drawn from a Laplace distribution. In our second model, we further assume that a local feature is composed of a discriminative part and a residual part. As a result, a local feature is generated by the linear combination of discriminative part bases and residual part bases. The decomposition of the discriminative and residual parts is achieved via the guidance of a pre-trained supervised coding method. By calculating the gradient vector of the proposed models, we derive two new Fisher vector coding strategies. The first is termed Sparse Coding-based Fisher Vector Coding (SCFVC) and can be used as the substitute of traditional GMM based FVC. The second is termed Hybrid Sparse Coding-based Fisher vector coding (HSCFVC) since it combines the merits of both pre-trained supervised coding methods and FVC. Using pre-trained Convolutional Neural Network (CNN) activations as local features, we experimentally demonstrate that the proposed methods are superior to traditional GMM based FVC and achieve state-of-the-art performance in various image classification tasks.	[Liu, Lingqiao; Wang, Peng; Shen, Chunhua; van den Hengel, Anton] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Wang, Lei; Wang, Chao] Univ Wollongong, Sch Comp & Informat Technol, Wollongong, NSW 2522, Australia; [Shen, Heng Tao] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 610051, Sichuan, Peoples R China	University of Adelaide; University of Wollongong; University of Electronic Science & Technology of China	Liu, LQ (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.	lingqiao.liu@adelaide.edu.au; peng.wang@adelaide.edu.au; chunhua.shen@adelaide.edu.au; leiw@uow.edu.au; anton.vandenhengel@adelaide.edu.au; chaow@uow.edu.au; shenhengtao@hotmail.com	Shen, Heng Tao/ABD-5331-2021; WANG, Peng/AHD-1399-2022; wang, peng/AAH-2781-2020; Wang, Lei/D-9079-2013; Wang, Lei/AAL-9684-2020	Wang, Lei/0000-0002-0961-0441; van den Hengel, Anton/0000-0003-3027-8364; Wang, Peng/0000-0002-5397-9115; liu, lingqiao/0000-0003-3584-795X	Australian Research Council [FT120100969]; National Nature Science Foundation of China [61632007]	Australian Research Council(Australian Research Council); National Nature Science Foundation of China(National Natural Science Foundation of China (NSFC))	C. Shen's participation was in part supported by Australian Research Council Future Fellowship (FT120100969). H. T. Shen's participation was in part supported by National Nature Science Foundation of China (61632007). L. Liu and P. Wang contributed equally to this work. C. Shen is the corresponding author.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207; Azizpour H., 2014, P IEEE C COMP VIS PA, P36; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Cimpoi M., 2015, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2015.7299007; Cinbis RG, 2016, IEEE T PATTERN ANAL, V38, P1084, DOI 10.1109/TPAMI.2015.2484342; Cinbis RG, 2012, PROC CVPR IEEE, P2184, DOI 10.1109/CVPR.2012.6247926; Coates Adam, 2011, P 28 INT C MACH LEAR, P921; Dixit M, 2015, PROC CVPR IEEE, P2974, DOI 10.1109/CVPR.2015.7298916; Doersch Carl, 2013, NIPS; Donahue J, 2014, PR MACH LEARN RES, V32; Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Jaakkola TS, 1999, ADV NEUR IN, V11, P487; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354; Juneja M, 2013, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2013.124; Krapac J, 2011, IEEE I CONF COMP VIS, P1487, DOI 10.1109/ICCV.2011.6126406; Lazebnik S, 2009, IEEE T PATTERN ANAL, V31, P1294, DOI 10.1109/TPAMI.2008.138; Lee H., 2007, ADV NEURAL INF PROCE, P801; Li Y, 2015, PROC CVPR IEEE, P971, DOI 10.1109/CVPR.2015.7298699; Lian XC, 2010, LECT NOTES COMPUT SC, V6314, P157, DOI 10.1007/978-3-642-15561-1_12; Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170; Liu L., 2014, P ADV NEUR INF PROC, V27, P1143; Liu LQ, 2015, PROC CVPR IEEE, P4749, DOI 10.1109/CVPR.2015.7299107; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Perronnin F, 2007, PROC CVPR IEEE, P2272; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136; Simonyan K., 2013, NEURAL INFORM PROCES, P163; Sydorov V, 2014, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2014.182; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang X., 2013, P INT C MACHINE LEAR, P846; Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685; Yang JC, 2010, PROC CVPR IEEE, P3517, DOI 10.1109/CVPR.2010.5539958; Yoo D., 2014, FISHER KERNEL DEEP N; Yu Kai, 2010, ICML, P1215; Zhang N, 2013, IEEE I CONF COMP VIS, P729, DOI 10.1109/ICCV.2013.96; Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54; Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11	45	33	35	0	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2017	39	12					2335	2348		10.1109/TPAMI.2017.2651061	http://dx.doi.org/10.1109/TPAMI.2017.2651061			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL6ZQ	28092518	Green Submitted			2022-12-18	WOS:000414395400002
J	Shi, XS; Guo, ZH; Nie, FP; Yang, L; You, JE; Tao, DC				Shi, Xiaoshuang; Guo, Zhenhua; Nie, Feiping; Yang, Lin; You, Jane; Tao, Dacheng			Two-Dimensional Whitening Reconstruction for Enhancing Robustness of Principal Component Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Two-dimensional whitening reconstruction; preprocessing; PCA; robustness	FACE-RECOGNITION; SPARSE-REPRESENTATION; PCA; EIGENFACES	Principal component analysis (PCA) is widely applied in various areas, one of the typical applications is in face. Many versions of PCA have been developed for face recognition. However, most of these approaches are sensitive to grossly corrupted entries in a 2D matrix representing a face image. In this paper, we try to reduce the influence of grosses like variations in lighting, facial expressions and occlusions to improve the robustness of PCA. In order to achieve this goal, we present a simple but effective unsupervised preprocessing method, two-dimensional whitening reconstruction (TWR), which includes two stages: 1) A whitening process on a 2D face image matrix rather than a concatenated 1D vector; 2) 2D face image matrix reconstruction. TWR reduces the pixel redundancy of the internal image, meanwhile maintains important intrinsic features. In this way, negative effects introduced by gross-like variations are greatly reduced. Furthermore, the face image with TWR preprocessing could be approximate to a Gaussian signal, on which PCA is more effective. Experiments on benchmark face databases demonstrate that the proposed method could significantly improve the robustness of PCA methods on classification and clustering, especially for the faces with severe illumination changes.	[Shi, Xiaoshuang; Yang, Lin] Univ Florida, J Crayton Pruitt Family Dept Biomed Engn, Gainesville, FL 32611 USA; [Guo, Zhenhua] Tsinghua Univ, Grad Sch Shenzhen, Shenzhen, Peoples R China; [Nie, Feiping] Northwestern Polytech Univ, Ctr Opt Imagery Anal & Learning, Xian, Peoples R China; [You, Jane] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China; [Tao, Dacheng] Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, Sydney, NSW 2007, Australia; [Tao, Dacheng] Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW 2007, Australia	State University System of Florida; University of Florida; Tsinghua University; University Town of Shenzhen; Tsinghua Shenzhen International Graduate School; Northwestern Polytechnical University; Hong Kong Polytechnic University; University of Technology Sydney; University of Technology Sydney	Shi, XS (corresponding author), Univ Florida, J Crayton Pruitt Family Dept Biomed Engn, Gainesville, FL 32611 USA.	sxs_1234@163.com; zhenhua.guo@sz.tsinghua.edu.cn; feipingnie@gmail.com; lin.yang@bme.ufl.edu; csyjia@comp.polyu.edu.hk; dacheng.tao@uts.edu.au	/AAD-1578-2020; Nie, Feiping/B-3039-2012	You, Jane/0000-0002-8181-4836; Nie, Feiping/0000-0002-0871-6519	Natural Science Foundation of China (NSFC) [61527808]; Shenzhen oversea high talent innovation fund [KQCX20140521161756231]; NIH (USA) [R01 AR065479-02]; Australian Research Council [FT-130101457, DP-140102164]; NATIONAL INSTITUTE OF ARTHRITIS AND MUSCULOSKELETAL AND SKIN DISEASES [R01AR065479] Funding Source: NIH RePORTER	Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Shenzhen oversea high talent innovation fund; NIH (USA)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Australian Research Council(Australian Research Council); NATIONAL INSTITUTE OF ARTHRITIS AND MUSCULOSKELETAL AND SKIN DISEASES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Arthritis & Musculoskeletal & Skin Diseases (NIAMS))	This work is supported by the Natural Science Foundation of China (NSFC) No. 61527808, Shenzhen oversea high talent innovation fund (Grant No. KQCX20140521161756231), NIH (USA) R01 AR065479-02, Australian Research Council Projects FT-130101457 and DP-140102164. The authors thank Graduate School at Shenzhen, Tsinghua University for the help and assistance.	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Alter O, 2000, P NATL ACAD SCI USA, V97, P10101, DOI 10.1073/pnas.97.18.10101; Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287; Bartlett MS, 1998, P SOC PHOTO-OPT INS, V3299, P528, DOI 10.1117/12.320144; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; Cai D, 2007, IEEE DATA MINING, P73, DOI 10.1109/ICDM.2007.89; Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6; COTTRELL GW, 1990, INTERNATIONAL NEURAL NETWORK CONFERENCE, VOLS 1 AND 2, P322; Ding C., 2006, PROC INT C MACH LEAR, P281, DOI DOI 10.1145/1143844.1143880; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Grudin MA, 2000, PATTERN RECOGN, V33, P1161, DOI 10.1016/S0031-3203(99)00104-1; He R, 2014, IEEE T PATTERN ANAL, V36, P261, DOI 10.1109/TPAMI.2013.102; Joliffe I. T., 1986, PRINCIPAL COMPONENT; Kiby M, 2010, IEEE T PATTERN ANAL, V98, P1031; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Martinez A.M., 2003, AR FACE DATABASE; Meytlis M, 2007, IEEE T PATTERN ANAL, V29, P1262, DOI 10.1109/TPAMI.2007.1033; Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128; Nie FP, 2014, PR MACH LEARN RES, V32, P1062; Pentland A, 2000, IEEE T PATTERN ANAL, V22, P107, DOI 10.1109/34.824823; Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70; Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wang YM, 2015, IEEE WINT CONF APPL, P542, DOI 10.1109/WACV.2015.78; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Wright Y., 2009, ADV NEURAL INFORM PR, V22, DOI DOI 10.5555/2984093.2984326; Xie XH, 2011, IEEE T IMAGE PROCESS, V20, P1807, DOI 10.1109/TIP.2010.2097270; Xu J, 2014, COGN COMPUT, V6, P608, DOI 10.1007/s12559-014-9252-5; Yang J, 2005, IEEE I CONF COMP VIS, P198; Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097; Yang J., 2014, 140520141207 ARXIV, V1405, P1207; Yang J, 2007, IEEE T SYST MAN CY B, V37, P1015, DOI [10.1109/TSMCB.2006.891541, 10.1109/TSMCB.2007.891541]; Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393; Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277; Zhao Q, 2014, PR MACH LEARN RES, V32, P55	46	33	33	3	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2016	38	10					2130	2136		10.1109/TPAMI.2015.2501810	http://dx.doi.org/10.1109/TPAMI.2015.2501810			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DX2YV	26595910	Green Accepted			2022-12-18	WOS:000384240600016
J	Tennakoon, RB; Bab-Hadiashar, A; Cao, ZW; Hoseinnezhad, R; Suter, D				Tennakoon, Ruwan B.; Bab-Hadiashar, Alireza; Cao, Zhenwei; Hoseinnezhad, Reza; Suter, David			Robust Model Fitting Using Higher Than Minimal Subset Sampling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Model fitting; robust statistics; hypothesis generation; data segmentation; higher than minimal subset sampling	SEGMENTATION; MOTION; ALGORITHM; CONSENSUS	Identifying the underlying model in a set of data contaminated by noise and outliers is a fundamental task in computer vision. The cost function associated with such tasks is often highly complex, hence in most cases only an approximate solution is obtained by evaluating the cost function on discrete locations in the parameter (hypothesis) space. To be successful at least one hypothesis has to be in the vicinity of the solution. Due to noise hypotheses generated by minimal subsets can be far from the underlying model, even when the samples are from the said structure. In this paper we investigate the feasibility of using higher than minimal subset sampling for hypothesis generation. Our empirical studies showed that increasing the sample size beyond minimal size (p), in particular up to p + 2, will significantly increase the probability of generating a hypothesis closer to the true model when subsets are selected from inliers. On the other hand, the probability of selecting an all inlier sample rapidly decreases with the sample size, making direct extension of existing methods unfeasible. Hence, we propose a new computationally tractable method for robust model fitting that uses higher than minimal subsets. Here, one starts from an arbitrary hypothesis (which does not need to be in the vicinity of the solution) and moves until either a structure in data is found or the process is re-initialized. The method also has the ability to identify when the algorithm has reached a hypothesis with adequate accuracy and stops appropriately, thereby saving computational time. The experimental analysis carried out using synthetic and real data shows that the proposed method is both accurate and efficient compared to the state-of-the-art robust model fitting techniques.	[Tennakoon, Ruwan B.; Bab-Hadiashar, Alireza; Hoseinnezhad, Reza] RMIT Univ, Sch Aerosp Mech & Mfg Engn, Melbourne, Vic 3001, Australia; [Cao, Zhenwei] Swinburne Univ Technol, Fac Sci Engn & Technol, Hawthorn, Vic 3122, Australia; [Suter, David] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia	Royal Melbourne Institute of Technology (RMIT); Swinburne University of Technology; University of Adelaide	Tennakoon, RB; Bab-Hadiashar, A; Hoseinnezhad, R (corresponding author), RMIT Univ, Sch Aerosp Mech & Mfg Engn, Melbourne, Vic 3001, Australia.; Cao, ZW (corresponding author), Swinburne Univ Technol, Fac Sci Engn & Technol, Hawthorn, Vic 3122, Australia.; Suter, D (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.	ruwan.tennakoon@rmit.edu.au; abh@rmit.edu.au; zcao@swin.edu.au; reza.hoseinnezhad@rmit.edu.au; dsuter@cs.adelaide.edu.au	Tennakoon, Ruwan/GQA-6488-2022; Hoseinnezhad, Reza/U-9792-2017; TENNAKOON, RUWAN/T-3151-2019; Bab-Hadiashar, Alireza/A-9157-2010; HOSEINNEZHAD, REZA/AAA-3823-2020	Tennakoon, Ruwan/0000-0001-8909-5728; Hoseinnezhad, Reza/0000-0001-9525-1467; Bab-Hadiashar, Alireza/0000-0002-6192-2303; HOSEINNEZHAD, REZA/0000-0001-9525-1467; Cao, Zhenwei/0000-0002-6910-7346; Suter, David/0000-0001-6306-3023	Australian Research Council (ARC)	Australian Research Council (ARC)(Australian Research Council)	This research was partly supported under Australian Research Council (ARC) Linkage Projects funding scheme.	Agarwal S, 2005, PROC CVPR IEEE, P838; Bab-Hadiashar Alireza, 2008, 2008 Digital Image Computing: Techniques and Applications, P1, DOI 10.1109/DICTA.2008.10; Bab-Hadiashar A, 1999, ROBOTICA, V17, P649, DOI 10.1017/S0263574799001812; Chen HF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P878, DOI 10.1109/ICCV.2003.1238441; Chin TJ, 2010, LECT NOTES COMPUT SC, V6315, P533, DOI 10.1007/978-3-642-15555-0_39; Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236; Delong A, 2012, INT J COMPUT VISION, V96, P1, DOI 10.1007/s11263-011-0437-z; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Fan LX, 2009, LECT NOTES COMPUT SC, V5876, P252; Hartley R., 2003, MULTIPLE VIEW GEOMET; Hesami R, 2010, COMPUT VIS IMAGE UND, V114, P475, DOI 10.1016/j.cviu.2009.12.004; Hevia-Montiel N, 2007, P ANN INT IEEE EMBS, P2102, DOI 10.1109/IEMBS.2007.4352736; Hoseinnezhad R, 2010, J MATH IMAGING VIS, V37, P66, DOI 10.1007/s10851-010-0193-7; Jin Yu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2041, DOI 10.1109/CVPR.2011.5995608; Lara-Alvarez C, 2009, LECT NOTES COMPUT SC, V5856, P918, DOI 10.1007/978-3-642-10268-4_108; Liu H., 2010, ADV NEURAL INFORM PR, P1414; Liu HR, 2012, PROC CVPR IEEE, P574, DOI 10.1109/CVPR.2012.6247723; Lucena M, 2010, MULTIMED TOOLS APPL, V49, P371, DOI 10.1007/s11042-009-0376-7; Poling B, 2014, INT J COMPUT VISION, V108, P165, DOI 10.1007/s11263-013-0694-0; Qi L., 1999, APPL OPTIMIZAT, V30, P121; Rousseeuw P.J., 2005, ROBUST REGRESSION OU, V589; Schindler K, 2006, IEEE T PATTERN ANAL, V28, P983, DOI 10.1109/TPAMI.2006.130; Stewart CV, 1997, IEEE T PATTERN ANAL, V19, P818, DOI 10.1109/34.608280; Sugaya Y, 2004, LECT NOTES COMPUT SC, V3247, P13; Toldo R, 2008, LECT NOTES COMPUT SC, V5302, P537, DOI 10.1007/978-3-540-88682-2_41; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; Tron R, 2007, PROC CVPR IEEE, P41, DOI 10.1109/cvpr.2007.382974; Pham TT, 2012, PROC CVPR IEEE, P710, DOI 10.1109/CVPR.2012.6247740; Wong HS, 2011, IEEE I CONF COMP VIS, P1044, DOI 10.1109/ICCV.2011.6126350	29	33	35	2	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2016	38	2					350	362		10.1109/TPAMI.2015.2448103	http://dx.doi.org/10.1109/TPAMI.2015.2448103			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DD5UI	26761739				2022-12-18	WOS:000369989600012
J	Xue, JH; Hall, P				Xue, Jing-Hao; Hall, Peter			Why Does Rebalancing Class-Unbalanced Data Improve AUC for Linear Discriminant Analysis?	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						AUC; class imbalance; class rebalancing; linear discriminant analysis; oversampling; ROC; undersampling	COVARIANCE MATRICES; CLASSIFICATION; COMBINATIONS; AREA	Many established classifiers fail to identify the minority class when it is much smaller than the majority class. To tackle this problem, researchers often first rebalance the class sizes in the training dataset, through oversampling the minority class or undersampling the majority class, and then use the rebalanced data to train the classifiers. This leads to interesting empirical patterns. In particular, using the rebalanced training data can often improve the area under the receiver operating characteristic curve (AUC) for the original, unbalanced test data. The AUC is a widely-used quantitative measure of classification performance, but the property that it increases with rebalancing has, as yet, no theoretical explanation. In this note, using Gaussian-based linear discriminant analysis (LDA) as the classifier, we demonstrate that, at least for LDA, there is an intrinsic, positive relationship between the rebalancing of class sizes and the improvement of AUC. We show that the largest improvement of AUC is achieved, asymptotically, when the two classes are fully rebalanced to be of equal sizes.	[Xue, Jing-Hao] UCL, Dept Stat Sci, London WC1E 6BT, England; [Hall, Peter] Univ Melbourne, Dept Math & Stat, Melbourne, Vic 3010, Australia	University of London; University College London; University of Melbourne	Xue, JH (corresponding author), UCL, Dept Stat Sci, Mortimer St, London WC1E 6BT, England.	jinghao.xue@ucl.ac.uk; halpstat@ms.unimelb.edu.au		Xue, Jing-Hao/0000-0003-1174-610X	Royal Society of London	Royal Society of London(Royal Society of London)	This work was partly supported by an International Travel Grant to J.-H. Xue from the Royal Society of London. Thanks to the University of Melbourne for hosting J.-H. Xue's sabbatical in 2012. Thanks to the reviewers for their constructive comments leading to Sections 4.4, 4.5 and 5.	Breiman L., 2017, CLASSIFICATION REGRE; Chawla NV, 2004, ACM SIGKDD EXPLOR NE, V6, P1, DOI [DOI 10.1145/1007730.1007733, 10.1145/1007730.1007733]; Elkan C., 2001, INT JOINT C ART INT, V17, P973, DOI DOI 10.5555/1642194.1642224; GILBERT ES, 1969, BIOMETRICS, V25, P505, DOI 10.2307/2528902; Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831; HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747; Harrell F. E., 2001, REGRESSION MODELING; He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239; Liu AY, 2005, STAT MED, V24, P37, DOI 10.1002/sim.1922; Ma S, 2008, BRIEF BIOINFORM, V9, P392, DOI 10.1093/bib/bbn027; MARKS S, 1974, J AM STAT ASSOC, V69, P555, DOI 10.2307/2285696; Pepe MS., 2003, STAT EVALUATION MEDI; SU JQ, 1993, J AM STAT ASSOC, V88, P1350; Van Hulse J, 2009, DATA KNOWL ENG, V68, P1513, DOI 10.1016/j.datak.2009.08.005; Weiss G., 2004, SIGKDD EXPLOR NEWSL, V6, P7, DOI DOI 10.1145/1007730.1007734; Weiss GM, 2003, J ARTIF INTELL RES, V19, P315, DOI 10.1613/jair.1199; Xie JG, 2007, PATTERN RECOGN, V40, P557, DOI 10.1016/j.patcog.2006.01.009; Xue JH, 2008, PATTERN RECOGN, V41, P1558, DOI 10.1016/j.patcog.2007.11.008	18	33	38	2	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2015	37	5					1109	1112		10.1109/TPAMI.2014.2359660	http://dx.doi.org/10.1109/TPAMI.2014.2359660			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CF4PS	26353332	Green Published, hybrid			2022-12-18	WOS:000352533000016
J	Dantone, M; Gall, J; Leistner, C; Van Gool, L				Dantone, Matthias; Gall, Juergen; Leistner, Christian; Van Gool, Luc			Body Parts Dependent Joint Regressors for Human Pose Estimation in Still Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human pose estimation; fashion; random forest; regression; classification	PICTORIAL STRUCTURES; FLEXIBLE MIXTURES; OBJECT DETECTION; TREE MODELS; CONSTRAINTS	In this work, we address the problem of estimating 2d human pose from still images. Articulated body pose estimation is challenging due to the large variation in body poses and appearances of the different body parts. Recent methods that rely on the pictorial structure framework have shown to be very successful in solving this task. They model the body part appearances using discriminatively trained, independent part templates and the spatial relations of the body parts using a tree model. Within such a framework, we address the problem of obtaining better part templates which are able to handle a very high variation in appearance. To this end, we introduce parts dependent body joint regressors which are random forests that operate over two layers. While the first layer acts as an independent body part classifier, the second layer takes the estimated class distributions of the first one into account and is thereby able to predict joint locations by modeling the interdependence and co-occurrence of the parts. This helps to overcome typical ambiguities of tree structures, such as self-similarities of legs and arms. In addition, we introduce a novel data set termed FashionPose that contains over 7; 000 images with a challenging variation of body part appearances due to a large variation of dressing styles. In the experiments, we demonstrate that the proposed parts dependent joint regressors outperform independent classifiers or regressors. The method also performs better or similar to the state-of-the-art in terms of accuracy, while running with a couple of frames per second.	[Dantone, Matthias; Van Gool, Luc] Swiss Fed Inst Technol, Comp Vis Lab, Zurich, Switzerland; [Gall, Juergen] Univ Bonn, Comp Vis Grp, Bonn, Germany; [Leistner, Christian] Microsoft, Vienna, Austria	Swiss Federal Institutes of Technology Domain; ETH Zurich; University of Bonn	Dantone, M (corresponding author), Swiss Fed Inst Technol, Comp Vis Lab, Zurich, Switzerland.	dantone@vision.ee.ethz.ch; gall@iai.uni-bonn.de; vangool@vision.ee.ethz.ch			ERC Grant (VarCity); EC [FP7-ICT-248873, FP7-ICT-249858]; CTI [12618.1 PFES-ES]; DFG [GA 1927/1-1]	ERC Grant (VarCity); EC(European CommissionEuropean Commission Joint Research Centre); CTI; DFG(German Research Foundation (DFG))	The authors acknowledge financial support from the ERC Grant (VarCity), the EC Projects RADHAR (FP7-ICT-248873) and TANGO (FP7-ICT-249858), the CTI Project (12618.1 PFES-ES), and the DFG Emmy Noether Program (GA 1927/1-1).	Amit Y, 1997, IEEE T PATTERN ANAL, V19, P1300, DOI 10.1109/34.632990; Andriluka M, 2012, INT J COMPUT VISION, V99, P259, DOI 10.1007/s11263-011-0498-z; Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754; Bergtholdt M, 2010, INT J COMPUT VISION, V87, P93, DOI 10.1007/s11263-009-0209-1; Bo LF, 2010, INT J COMPUT VISION, V87, P28, DOI 10.1007/s11263-008-0204-y; Bourdev L, 2010, LECT NOTES COMPUT SC, V6316, P168, DOI 10.1007/978-3-642-15567-3_13; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Burenius M, 2013, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2013.464; Cipoll Roberto, 2008, PROC CVPR IEEE, P1; Cootes TF, 2012, LECT NOTES COMPUT SC, V7578, P278, DOI 10.1007/978-3-642-33786-4_21; Criminisi A., 2013, DECISION FORESTCOM; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dantone M, 2013, PROC CVPR IEEE, P3041, DOI 10.1109/CVPR.2013.391; Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976; Eichner M, 2012, INT J COMPUT VISION, V99, P190, DOI 10.1007/s11263-012-0524-9; Eichner M., 2012, P AS COMP VIS C, P138; Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70; Girshick R, 2011, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2011.6126270; Gkioxari G, 2013, PROC CVPR IEEE, P3342, DOI 10.1109/CVPR.2013.429; Glocker B, 2012, LECT NOTES COMPUT SC, V7575, P870, DOI 10.1007/978-3-642-33765-9_62; Holt B., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1196, DOI 10.1109/ICCVW.2011.6130386; Jiang H., 2008, P IEEE C COMP VIS PA; Johnson S, 2011, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR.2011.5995318; Johnson Sam, 2010, BMVC, DOI [10.5244/C.24.12, DOI 10.5244/C.24.12]; Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198; Keskin C, 2012, LECT NOTES COMPUT SC, V7577, P852, DOI 10.1007/978-3-642-33783-3_61; Lehrmann AM, 2013, IEEE I CONF COMP VIS, P1281, DOI 10.1109/ICCV.2013.162; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Liu YB, 2013, IEEE T PATTERN ANAL, V35, P2720, DOI 10.1109/TPAMI.2013.47; Moeslund TB, 2011, VISUAL ANAL HUMANS L, V1st; Muller J., 2010, P 1 ACM INT WORKSH A; Narasimhan S.G., 2012, ECCV; Pedro F. F., 2010, PAMI, V32, P1627, DOI [10.1109/TPAMI.2009.167, DOI 10.1109/TPAMI.2009.167]; Pishchulin L., 2013, P IEEE INT C COMP VI; Pishchulin L, 2013, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2013.82; Pishchulin L, 2012, PROC CVPR IEEE, P3178, DOI 10.1109/CVPR.2012.6248052; Ramanan D., 2006, NIPS, P1129; Razavi N, 2012, LECT NOTES COMPUT SC, V7574, P312, DOI 10.1007/978-3-642-33712-3_23; Ren XF, 2005, IEEE I CONF COMP VIS, P824; Rogez G, 2008, PROC CVPR IEEE, P2142; Rogez G, 2012, INT J COMPUT VISION, V99, P25, DOI 10.1007/s11263-012-0516-9; Ronfard R, 2002, LECT NOTES COMPUT SC, V2353, P700; Sangineto E, 2012, LECT NOTES COMPUT SC, V7573, P273, DOI 10.1007/978-3-642-33709-3_20; Sapp B, 2010, PROC CVPR IEEE, P422, DOI 10.1109/CVPR.2010.5540182; SHOTTON J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI DOI 10.1109/TPAMI.2012.241; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Sigal L., 2006, PROC IEEE C COMPUT V, P2041; Singh VK, 2010, LECT NOTES COMPUT SC, V6313, P314; Sun M, 2012, PROC CVPR IEEE, P1616, DOI 10.1109/CVPR.2012.6247854; Sun M, 2011, IEEE I CONF COMP VIS, P723, DOI 10.1109/ICCV.2011.6126309; Tang D., 2013, P IEEE INT C COMP VI; Tang DH, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.58; Tian TP, 2010, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2010.5540227; Tran D, 2010, LECT NOTES COMPUT SC, V6314, P227, DOI 10.1007/978-3-642-15561-1_17; Wang F, 2013, P INT JOINT C ART IN, P2510; Wang F, 2013, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2013.83; Wang Y, 2008, LECT NOTES COMPUT SC, V5304, P710, DOI 10.1007/978-3-540-88690-7_53; Wang Y, 2011, PROC CVPR IEEE, P1705, DOI 10.1109/CVPR.2011.5995519; Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101; Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Zhu XX, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.80; Zuffi S, 2012, PROC CVPR IEEE, P3546, DOI 10.1109/CVPR.2012.6248098	67	33	33	2	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2014	36	11					2131	2143		10.1109/TPAMI.2014.2318702	http://dx.doi.org/10.1109/TPAMI.2014.2318702			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR6OI	26353056	Green Submitted			2022-12-18	WOS:000343702400002
J	Abiantun, R; Prabhu, U; Savvides, M				Abiantun, Ramzi; Prabhu, Utsav; Savvides, Marios			Sparse Feature Extraction for Pose-Tolerant Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; pose tolerance; sparse feature extraction; 3D generic elastic models		Automatic face recognition performance has been steadily improving over years of research, however it remains significantly affected by a number of factors such as illumination, pose, expression, resolution and other factors that can impact matching scores. The focus of this paper is the pose problem which remains largely overlooked in most real-world applications. Specifically, we focus on one-to-one matching scenarios where a query face image of a random pose is matched against a set of gallery images. We propose a method that relies on two fundamental components: (a) A 3D modeling step to geometrically correct the viewpoint of the face. For this purpose, we extend a recent technique for efficient synthesis of 3D face models called 3D Generic Elastic Model. (b) A sparse feature extraction step using subspace modeling and l(1)-minimization to induce pose-tolerance in coefficient space. This in return enables the synthesis of an equivalent frontal-looking face, which can be used towards recognition. We show significant performance improvements in verification rates compared to commercial matchers, and also demonstrate the resilience of the proposed method with respect to degrading input quality. We find that the proposed technique is able to match non-frontal images to other non-frontal images of varying angles.	[Abiantun, Ramzi; Prabhu, Utsav; Savvides, Marios] Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Abiantun, R (corresponding author), Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.							Abiantun R., 2011, P IEEE WORKSH APPL C, P212; Abiantun R, 2007, INT CONF ACOUST SPEE, P1257; Biswas S, 2013, IEEE T PATTERN ANAL, V35, P3037, DOI 10.1109/TPAMI.2013.68; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Blanz V, 2005, PROC CVPR IEEE, P454; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Chen S. S., 1995, THESIS STANFORD U ST; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Fukui K, 2005, SPRINGER TRAC ADV RO, V15, P192; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; GOSHTASBY A, 1986, PATTERN RECOGN, V19, P459, DOI 10.1016/0031-3203(86)90044-0; Gross R, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P3, DOI 10.1109/AFGR.2002.1004122; Gross R., 2008, P IEEE INT C AUT FAC, P1; Heo J., 2009, THESIS CARNEGIE MELL; Leo M. J., 2011, 2011 3rd International Conference on Trendz in Information Sciences & Computing (TISC), P40, DOI 10.1109/TISC.2011.6169081; Liu XM, 2005, PROC CVPR IEEE, P502; MAHALANOBIS A, 1987, APPL OPTICS, V26, P3633, DOI 10.1364/AO.26.003633; Mitra S, 2006, IEEE T INF FOREN SEC, V1, P350, DOI 10.1109/TIFS.2006.879301; Phillips P. J., 1996, ARLTR995; Prabhu U, 2011, IEEE T PATTERN ANAL, V33, P1952, DOI 10.1109/TPAMI.2011.123; Prince SJD, 2008, IEEE T PATTERN ANAL, V30, P970, DOI 10.1109/TPAMI.2008.48; SACKEIM HA, 1978, NEUROPSYCHOLOGIA, V16, P473, DOI 10.1016/0028-3932(78)90070-2; SACKEIM HA, 1978, SCIENCE, V202, P434, DOI 10.1126/science.705335; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wen Yi Zhao, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P285, DOI 10.1109/AFGR.2000.840648; Xie C., 2005, P IEEE COMP SOC C CO, V3, P153; Yang A. Y., 2010, COMPUT RES REPOS JUL, Vabs/1007.3753; Zhang X, 2009, PATTERN RECOGN, V42, P2876, DOI 10.1016/j.patcog.2009.04.017	30	33	34	0	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2014	36	10					2061	2073		10.1109/TPAMI.2014.2313124	http://dx.doi.org/10.1109/TPAMI.2014.2313124			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AP3MX	26352635				2022-12-18	WOS:000341981300012
J	Wang, DY; Hoi, SCH; He, Y; Zhu, J; Mei, T; Luo, J				Wang, Dayong; Hoi, Steven C. H.; He, Ying; Zhu, Jianke; Mei, Tao; Luo, Jiebo			Retrieval-Based Face Annotation by Weak Label Regularized Local Coordinate Coding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face annotation; content-based image retrieval; machine learning; label refinement; web facial images; weak label	IMAGE ANNOTATION; RECOGNITION	Auto face annotation, which aims to detect human faces from a facial image and assign them proper human names, is a fundamental research problem and beneficial to many real-world applications. In this work, we address this problem by investigating a retrieval-based annotation scheme of mining massive web facial images that are freely available over the Internet. In particular, given a facial image, we first retrieve the top n similar instances from a large-scale web facial image database using content-based image retrieval techniques, and then use their labels for auto annotation. Such a scheme has two major challenges: 1) how to retrieve the similar facial images that truly match the query, and 2) how to exploit the noisy labels of the top similar facial images, which may be incorrect or incomplete due to the nature of web images. In this paper, we propose an effective Weak Label Regularized Local Coordinate Coding (WLRLCC) technique, which exploits the principle of local coordinate coding by learning sparse features, and employs the idea of graph-based weak label regularization to enhance the weak labels of the similar facial images. An efficient optimization algorithm is proposed to solve the WLRLCC problem. Moreover, an effective sparse reconstruction scheme is developed to perform the face annotation task. We conduct extensive empirical studies on several web facial image databases to evaluate the proposed WLRLCC algorithm from different aspects. The experimental results validate its efficacy. We share the two constructed databases "WDB" (714,454 images of 6,025 people) and "ADB" (126,070 images of 1,200 people) with the public. To further improve the efficiency and scalability, we also propose an offline approximation scheme (AWLRLCC) which generally maintains comparable results but significantly reduces the annotation time.	[Wang, Dayong; Hoi, Steven C. H.; He, Ying] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; [Zhu, Jianke] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Zhejiang, Peoples R China; [Mei, Tao] Microsoft Res Asia, Beijing 100080, Peoples R China; [Luo, Jiebo] Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Zhejiang University; Microsoft; Microsoft Research Asia; University of Rochester	Wang, DY (corresponding author), Nanyang Technol Univ, Sch Comp Engn, N4-02a-08, Singapore 639798, Singapore.	s090023@ntu.edu.sg; chhoi@ntu.edu.sg; yhe@ntu.edu.sg; jkzhu@zju.edu.cn; tmei@microsoft.com; jluo@cs.rochester.edu	He, Ying/A-3708-2011; HOI, Steven C. H./A-3736-2011; Luo, Jiebo/AAI-7549-2020; Mei, Tao/GQZ-0596-2022	He, Ying/0000-0002-6749-4485; Mei, Tao/0000-0002-5990-7307; Wang, Dayong/0000-0002-5904-6156; Hoi, Steven/0000-0002-4584-3453; Luo, Jiebo/0000-0002-4516-9729	Singapore MOE [RG33/11]; Microsoft Research grant; IDM National Research Foundation (NRF) [MDA/IDM/2012/8/8-2 VOL 01]; Fundamental Research Funds for the Central Universities	Singapore MOE(Ministry of Education, Singapore); Microsoft Research grant(Microsoft); IDM National Research Foundation (NRF); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	This work was supported in part by Singapore MOE Tier-1 research grant (RG33/11), Microsoft Research grant, and IDM National Research Foundation (NRF) Research grant (MDA/IDM/2012/8/8-2 VOL 01). Jianke Zhu was supported by Fundamental Research Funds for the Central Universities.	Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469; [Anonymous], 2009, 26 ANN INT C MACH LE, DOI DOI 10.1145/1553374.1553459; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Berg T.L., 2006, P ADV NEUR INF PROC, P264; Berg T.L., 2006, 2006 IEEE COMP SOC C, V2, P1463, DOI DOI 10.1109/CVPR.2006.57; Berg TL, 2004, PROC CVPR IEEE, P848; Cao ZM, 2010, PROC CVPR IEEE, P2707, DOI 10.1109/CVPR.2010.5539992; Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61; Choi JY, 2011, IEEE T MULTIMEDIA, V13, P14, DOI 10.1109/TMM.2010.2087320; Cui JY, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P367; Dong W., 2008, P 17 ACM C INF KNOWL, P669, DOI DOI 10.1145/1458082.1458172; Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97; Elhamifar E., 2012, CORR; Fergus R, 2005, IEEE I CONF COMP VIS, P1816; Guillaumin M, 2012, INT J COMPUT VISION, V96, P64, DOI 10.1007/s11263-011-0447-x; Hanbury A, 2008, J VISUAL LANG COMPUT, V19, P617, DOI 10.1016/j.jvlc.2008.01.002; Hoi SCH, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823752; Hoi SCH, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1508850.1508854; Holub Alex, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563068; Hoyer P.O., 2002, CORR; Huang GB, 2007, 07 UMASS TR; Jain A. K., 2011, HDB FACE RECOGNITION, V1; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Le DD, 2008, IEEE DATA MINING, P383, DOI 10.1109/ICDM.2008.47; Liu J., 2009, SLEP SPARSE LEARNING; Mensink T., 2008, P EUR C COMP VIS E 2, P86; Ozcan M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.29; Ozkan D., 2006, 2006 IEEE COMP SOC C, P1477; Page Lawrence, 1999, TECHNICAL REPORT; Rui XG, 2007, P 15 ACM INT C MULT, P585, DOI DOI 10.1145/1291233.1291378; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40; Sun YY, 2010, AAAI CONF ARTIF INTE, P593; Tang J., 2011, ACM T INTEL SYST TEC, P14, DOI [10.1145/1899412.1899418, DOI 10.1145/1899412.1899418]; Wang Changhu, 2006, P 14 ANN ACM INT C M, P647, DOI DOI 10.1145/1180639.1180774; Wang D., 2013, P 36 INT ACM SIGIR C; Wang D., 2012, IEEE T KNOWL DATA EN, V99, P1; Wang DY, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P535; Wang Dayong, 2012, P 21 ACM INT C INF K, P1392; Wang G, 2010, LECT NOTES COMPUT SC, V6315, P169, DOI 10.1007/978-3-642-15555-0_13; Wright J, 2010, IEEE T INFORM THEORY, V56, P3540, DOI 10.1109/TIT.2010.2048473; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Wu F., 2010, P INT C MULT, P15, DOI DOI 10.1145/1873951.1873957; Wu P., 2011, P 4 ACM INT C WEB SE, P197, DOI [DOI 10.1145/1935826.1935865, 10.1145/1935826.1935865]; Wu Z, 2010, PROC CVPR IEEE, P3469, DOI 10.1109/CVPR.2010.5539976; Xia H, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P55, DOI 10.1145/2348283.2348294; Yu K., 2009, P ADV NEUR INF PROC, P2259; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; Zhu JK, 2008, IEEE T MULTIMEDIA, V10, P86, DOI 10.1109/TMM.2007.911245; Zhu JK, 2009, IEEE I CONF COMP VIS, P1265, DOI 10.1109/ICCV.2009.5459325; Zhu Xiaojin., 2003, P ICLR, P912	51	33	34	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2014	36	3					550	563		10.1109/TPAMI.2013.145	http://dx.doi.org/10.1109/TPAMI.2013.145			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AA9YX	24457510	Green Published			2022-12-18	WOS:000331450100012
J	Liu, C; Gu, JW				Liu, Chao; Gu, Jinwei			Discriminative Illumination: Per-Pixel Classification of Raw Materials Based on Optimal Projections of Spectral BRDF	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computational illumination; appearance modeling; material classification		Classifying raw, unpainted materials-metal, plastic, ceramic, fabric, and so on-is an important yet challenging task for computer vision. Previous works measure subsets of surface spectral reflectance as features for classification. However, acquiring the full spectral reflectance is time consuming and error-prone. In this paper, we propose to use coded illumination to directly measure discriminative features for material classification. Optimal illumination patterns-which we call "discriminative illumination"-are learned from training samples, after projecting to which the spectral reflectance of different materials are maximally separated. This projection is automatically realized by the integration of incident light for surface reflection. While a single discriminative illumination is capable of linear, two-class classification, we show that multiple discriminative illuminations can be used for nonlinear and multiclass classification. We also show theoretically that the proposed method has higher signal-to-noise ratio than previous methods due to light multiplexing. Finally, we construct an LED-based multispectral dome and use the discriminative illumination method for classifying a variety of raw materials, including metal (aluminum, alloy, steel, stainless steel, brass, and copper), plastic, ceramic, fabric, and wood. Experimental results demonstrate its effectiveness.	[Liu, Chao; Gu, Jinwei] Rochester Inst Technol, Ctr Imaging Sci, Rochester, NY 14623 USA	Rochester Institute of Technology	Liu, C (corresponding author), Rochester Inst Technol, Ctr Imaging Sci, CAR 76-3262,54 Lomb Mem Dr, Rochester, NY 14623 USA.	cxl8762@rit.edu; jwgu@cis.rit.edu			NYSP2I; US National Science Foundation (NSF) [IIS-1257163]	NYSP2I; US National Science Foundation (NSF)(National Science Foundation (NSF))	The authors thank Profs. Oliver Cossairt, Shree K. Nayar, and Gabrielle Gaustad for the helpful discussions, as well as suggestions from anonymous reviewers. This work was supported by a grant from NYSP2I and US National Science Foundation (NSF) IIS-1257163.	Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Chen H, 1998, INT J COMPUT VISION, V28, P73, DOI 10.1023/A:1008054731537; Cula OG, 2004, INT J COMPUT VISION, V59, P33, DOI 10.1023/B:VISI.0000020670.05764.55; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Gama J., 2007, MACH LEARN, V41, P315; Gesing A., 2003, P TMS ANN M AUT ALL; GHOSH A, 2007, P IEEE INT C COMP VI; Hendrik J., 1997, INT J ENV CONSCIOUS, V6, p[37, 1]; Ho S., 2000, P 17 INT S AUT ROB C, P1; Hwang J.Y., 2006, J MINER MAT CHARACT, V5, P47, DOI [DOI 10.4236/JMMCE.2006.51003, 10.4236/jmmce.2006.51003]; Hyde MW, 2011, IEEE T GEOSCI REMOTE, V49, P264, DOI 10.1109/TGRS.2010.2053547; Hyde MW, 2010, OPT LETT, V35, P3601, DOI 10.1364/OL.35.003601; Ibrahim A, 2010, OPT ENG, V49, DOI 10.1117/1.3430606; J Gu, 2012, P IEEE C COMP VIS PA; Jehle M., 2010, P 32 DAGM C PATT REC; Khan SS, 2010, LECT NOTES ARTIF INT, V6206, P188; Landy M.S., 1991, COMPUTATIONAL MODELS; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Ma W., 2007, P EUR S REND; Mannan M.A., 2010, P INT S VIS COMP; Matusik W, 2003, ACM T GRAPHIC, V22, P759, DOI 10.1145/882262.882343; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; Nayar SK, 2006, ACM T GRAPHIC, V25, P935, DOI 10.1145/1141911.1141977; Neifeld MA, 2003, APPL OPTICS, V42, P3379, DOI 10.1364/AO.42.003379; Neifeld MA, 2007, J OPT SOC AM A, V24, pB25, DOI 10.1364/JOSAA.24.000B25; Ngan A, 2005, EUR S REND, V2, P117, DOI DOI 10.2312/EGWR/EGSR05/117-126; Nicodemus F.E., 1992, NATL BUREAU STANDARD, V160, P94; Nishino K, 2009, IEEE I CONF COMP VIS, P476, DOI 10.1109/ICCV.2009.5459255; Orun AB, 2003, PATTERN RECOGN LETT, V24, P1589, DOI 10.1016/S0167-8655(02)00398-7; Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199; Salamati N., 2009, P IS T SID 17 COL IM; Schechner Y.Y., 2003, P IEEE INT C COMP VI; Schechner YY, 2007, IEEE T PATTERN ANAL, V29, P1339, DOI 10.1109/TPAMI.2007.1151; Schlesinger M. E., 2000, ALUMINUM RECYCLING; Sun DW, 2008, FOOD SCI TECHNOL-INT, P1; Tian GY, 2007, OPT LASER ENG, V45, P131, DOI 10.1016/j.optlaseng.2006.03.005; Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4; Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182; Viola Paul, 2001, PROC CVPR IEEE; Wang O., 2009, P IEEE C COMP VIS PA; WOLFF LB, 1990, IEEE T PATTERN ANAL, V12, P1059, DOI 10.1109/34.61705	43	33	37	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2014	36	1					86	98		10.1109/TPAMI.2013.110	http://dx.doi.org/10.1109/TPAMI.2013.110			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	265PV	24231868				2022-12-18	WOS:000327965100008
J	Wu, H; Appia, V; Yezzi, A				Wu, Hao; Appia, Vikram; Yezzi, Anthony			Numerical Conditioning Problems and Solutions for Nonparametric i.i.d. Statistical Active Contours	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Active contour; nonparametric region-based model; bounded gradient flow; conditioning ratio; clutter; adaptive global-to-local strategy; localizing scale	RANDOM-FIELD MODELS; IMAGE SEGMENTATION; REGION COMPETITION; RELAXATION; STRATEGIES	In this paper, we propose an active contour model based on nonparametric independent and identically distributed (i.i.d.) statistics of the image that can segment an image without any a priori information about the intensity distributions of the region of interest or the background. This is not, however, the first active contour model proposed to solve the segmentation problem under these same assumptions. In contrast to prior active contour models based on nonparametric i.i.d. statistics, we do not formulate our optimization criterion according to any distance measure between estimated probability densities inside and outside the active contour. Instead, treating the segmentation problem as a pixel-wise classification problem, we formulate an active contour to minimize the unbiased pixel-wise average misclassification probability (AMP). This not only simplifies the problem by avoiding the need to arbitrarily select among many sensible distance measures to measure the difference between the probability densities estimated inside and outside the active contour, but it also solves a numerical conditioning problem that arises with such prior active contour models. As a result, the AMP model exhibits faster convergence with higher accuracy and robustness when compared to active contour models previously formulated to solve the same nonparametric i.i.d. statistical segmentation problem via probability distances. To discuss this improved numerical behavior more precisely, we introduce the notion of "conditioning ratio" and demonstrate that the proposed AMP active contour is numerically better conditioned (i.e., exhibits a much smaller conditioning ratio) than prior probability distance-based active contours.	[Wu, Hao] Shanghai Jiao Tong Univ, Shanghai 200240, Peoples R China; [Appia, Vikram; Yezzi, Anthony] Georgia Inst Technol, Atlanta, GA 30308 USA	Shanghai Jiao Tong University; University System of Georgia; Georgia Institute of Technology	Wu, H (corresponding author), Shanghai Jiao Tong Univ, 1-308 SEIEE Bldg,800 Dongchuan Rd, Shanghai 200240, Peoples R China.	tclzwill@gmail.com; vikram.appia@gatech.edu; ayezzi@ece.gatech.edu	Yezzi, Anthony/AAB-4235-2020					ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098; Adam A, 2009, IEEE T PATTERN ANAL, V31, P1708, DOI 10.1109/TPAMI.2009.21; Bhattacharyya A., 1943, BULL CALCUTTA MATH S, V35, P99; Brejl M, 2000, IEEE T MED IMAGING, V19, P973, DOI 10.1109/42.887613; Brox T, 2009, INT J COMPUT VISION, V84, P184, DOI 10.1007/s11263-008-0153-5; CASELLES V, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P694, DOI 10.1109/ICCV.1995.466871; Cavallaro A, 2005, IEEE T CIRC SYST VID, V15, P575, DOI 10.1109/TCSVT.2005.844447; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; CHAN TF, 2005, P ICIP 2005 GEN IT, P121, DOI DOI 10.1109/ICIP.2005.1529702; Darolti C, 2008, IEEE T IMAGE PROCESS, V17, P2275, DOI 10.1109/TIP.2008.2006443; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Gdalyahu Y, 2001, IEEE T PATTERN ANAL, V23, P1053, DOI 10.1109/34.954598; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gokcay E, 2002, IEEE T PATTERN ANAL, V24, P158, DOI 10.1109/34.982897; GRAYSON MA, 1987, J DIFFER GEOM, V26, P285; Hathaway RJ, 2000, IEEE T FUZZY SYST, V8, P576, DOI 10.1109/91.873580; Jenssen R., 2005, ADV NEURAL INFORM PR, P625; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855; Kim JM, 2005, IEEE T IMAGE PROCESS, V14, P1486, DOI 10.1109/TIP.2005.854442; Krishnamachari S, 1997, IEEE T IMAGE PROCESS, V6, P251, DOI 10.1109/83.551696; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611; Lellmann J, 2009, IEEE I CONF COMP VIS, P646, DOI 10.1109/ICCV.2009.5459176; LIE WN, 1995, IEEE T IMAGE PROCESS, V4, P1036, DOI 10.1109/83.392347; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; Michailovich O, 2007, IEEE T IMAGE PROCESS, V16, P2787, DOI 10.1109/TIP.2007.908073; Mory B, 2007, LECT NOTES COMPUT SC, V4485, P214; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; Ni K, 2009, INT J COMPUT VISION, V84, P97, DOI 10.1007/s11263-009-0234-0; PANJWANI DK, 1995, IEEE T PATTERN ANAL, V17, P939, DOI 10.1109/34.464559; Paragios N, 2002, J VIS COMMUN IMAGE R, V13, P249, DOI 10.1006/jvci.2001.0475; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Phumeechanya S, 2010, P INT C IM PROC, P654; Pock T, 2009, PROC CVPR IEEE, P810, DOI 10.1109/CVPRW.2009.5206604; RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Sundaramoorthi G, 2010, PROC CVPR IEEE, P2855, DOI 10.1109/CVPR.2010.5540020; Unal G, 2005, INT J COMPUT VISION, V62, P199, DOI 10.1007/s11263-005-4880-6; Yezzi A, 2002, J VIS COMMUN IMAGE R, V13, P195, DOI 10.1006/jvci.2001.0500; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	41	33	35	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2013	35	6					1298	1311		10.1109/TPAMI.2012.207	http://dx.doi.org/10.1109/TPAMI.2012.207			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	129QV	23599049				2022-12-18	WOS:000317857900003
J	Sznitman, R; Richa, R; Taylor, RH; Jedynak, B; Hager, GD				Sznitman, Raphael; Richa, Rogerio; Taylor, Russell H.; Jedynak, Bruno; Hager, Gregory D.			Unified Detection and Tracking of Instruments during Retinal Microsurgery	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Unified object detection and tracking; active testing; instrument tracking; adaptive sensing; retinal microsurgery	FACE DETECTION; PROPAGATION	Methods for tracking an object have generally fallen into two groups: tracking by detection and tracking through local optimization. The advantage of detection-based tracking is its ability to deal with target appearance and disappearance, but it does not naturally take advantage of target motion continuity during detection. The advantage of local optimization is efficiency and accuracy, but it requires additional algorithms to initialize tracking when the target is lost. To bridge these two approaches, we propose a framework for unified detection and tracking as a time-series Bayesian estimation problem. The basis of our approach is to treat both detection and tracking as a sequential entropy minimization problem, where the goal is to determine the parameters describing a target in each frame. To do this we integrate the Active Testing (AT) paradigm with Bayesian filtering, and this results in a framework capable of both detecting and tracking robustly in situations where the target object enters and leaves the field of view regularly. We demonstrate our approach on a retinal tool tracking problem and show through extensive experiments that our method provides an efficient and robust tracking solution.	[Sznitman, Raphael] EPFL IC ISIM CVLAB, CH-1015 Lausanne, Switzerland; [Richa, Rogerio; Taylor, Russell H.; Jedynak, Bruno; Hager, Gregory D.] Johns Hopkins Univ, Baltimore, MD 21218 USA	Johns Hopkins University	Sznitman, R (corresponding author), EPFL IC ISIM CVLAB, BC 309 Batiment BC,Stn 14, CH-1015 Lausanne, Switzerland.	raphael.sznitman@epfl.ch; richa@jhu.edu; rht@jhu.edu; bruno.jedynak@jhu.edu; hager@jhu.edu	Taylor, Russell H./A-3268-2010	Sznitman, Raphael/0000-0001-6791-4753	US National Institutes of Health [R01 EB 007969-01]; Johns Hopkins University; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [R01EB007969] Funding Source: NIH RePORTER	US National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Johns Hopkins University(Johns Hopkins University); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB))	Funding for this research was provided in part by US National Institutes of Health Grant R01 EB 007969-01 and internal Johns Hopkins University funds. The authors would like to thank Dr. Jim Handa, MD, and Dr. Peter Gehlbach, MD, for their insightful help. Marcin Balicki and Kevin Olds are credited for the development of the phantom eye used.	Aldavert D, 2010, PROC CVPR IEEE, P1046, DOI 10.1109/CVPR.2010.5540098; Andriluka M, 2008, PROC CVPR IEEE, P1873, DOI 10.1109/CVPR.2008.4587583; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Bernier O, 2009, COMPUT VIS IMAGE UND, V113, P29, DOI 10.1016/j.cviu.2008.07.001; Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/cvpr.2008.4587586; Breitenstein MD, 2009, IEEE I CONF COMP VIS, P1515, DOI 10.1109/ICCV.2009.5459278; Burschka D, 2005, ROBOT AUTON SYST, V52, P5, DOI 10.1016/j.robot.2005.03.013; Casals A, 1996, IEEE INT CONF ROBOT, P895, DOI 10.1109/ROBOT.1996.503886; Climent J., 2004, ELECT LETT COMPUTER, V4, P21, DOI DOI 10.5565/REV/ELCVIA.70; Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; Dewan M., 2002, P 7 INT C MED IM COM, P49; Doignon C., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P3394; Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006; Hager G.D., 1990, TASK DIRECTED SENSOR; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Kalman RE., 1960, T ASME J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; Kazanzides P., 2010, P INT C MED IM COMP; McKenna S. J., 2005, P IM VIS COMP NZ C; NejhumShahed S. M., 2008, IEEE C COMP VIS PATT, P1; Pakkanen J, 2004, NEURAL PROCESS LETT, V20, P199, DOI 10.1007/s11063-004-2156-8; Peng NS, 2005, PATTERN RECOGN LETT, V26, P605, DOI 10.1016/j.patrec.2004.08.023; Pezzementi Z, 2009, IEEE INT CONF ROBOT, P1225; Richa Rogerio, 2011, Information Processing in Computer-Assisted Interventions. Proceedings of the Second International Conference, IPCAI 2011, P55, DOI 10.1007/978-3-642-21504-9_6; Richa R, 2011, IEEE INT C INT ROBOT, P2953, DOI 10.1109/IROS.2011.6048295; Sznitman Raphael, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1222, DOI 10.1109/ICCVW.2009.5457469; Sznitman R, 2011, LECT NOTES COMPUT SC, V6891, P1, DOI 10.1007/978-3-642-23623-5_1; Sznitman R, 2010, LECT NOTES COMPUT SC, V6363, P465; Sznitman R, 2010, IEEE T PATTERN ANAL, V32, P1914, DOI 10.1109/TPAMI.2010.106; Thrun S., 2005, PROBABILISTIC ROBOTI; Tonet O., 2005, P SURG 05, V5, P221; Toyama K, 1999, INT J COMPUT VISION, V35, P45, DOI 10.1023/A:1008159011682; Uecker D., 1995, J IMAGE GUIDED SURG, V22, P429; Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183; Verma RC, 2003, IEEE T PATTERN ANAL, V25, P1215, DOI 10.1109/TPAMI.2003.1233896; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Voros S, 2007, INT J ROBOT RES, V26, P1173, DOI 10.1177/0278364907083395; Wang Y., 1998, COMPUTERIZED MED IMA, V1, P308; Wei G, 2004, IEEE T BIO-MED ENG, V51, P1811, DOI 10.1109/TBME.2004.831532; Wei GQ, 1997, IEEE ENG MED BIOL, V16, P40, DOI 10.1109/51.566151; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355	41	33	36	2	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2013	35	5					1263	1273		10.1109/TPAMI.2012.209	http://dx.doi.org/10.1109/TPAMI.2012.209			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	106EZ	23520263				2022-12-18	WOS:000316126800018
J	Shah, M; Marchand, M; Corbeil, J				Shah, Mohak; Marchand, Mario; Corbeil, Jacques			Feature Selection with Conjunctions of Decision Stumps and Learning from Microarray Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Microarray data classification; risk bounds; feature selection; gene identification	SUPPORT VECTOR MACHINE; GENE-EXPRESSION; BREAST-CANCER; CLASS PREDICTION; CLASSIFICATION; ESTROGEN; TRANSCRIPTION; BRCA1; CELLS; TUMOR	One of the objectives of designing feature selection learning algorithms is to obtain classifiers that depend on a small number of attributes and have verifiable future performance guarantees. There are few, if any, approaches that successfully address the two goals simultaneously. To the best of our knowledge, such algorithms that give theoretical bounds on the future performance have not been proposed so far in the context of the classification of gene expression data. In this work, we investigate the premise of learning a conjunction (or disjunction) of decision stumps in Occam's Razor, Sample Compression, and PAC-Bayes learning settings for identifying a small subset of attributes that can be used to perform reliable classification tasks. We apply the proposed approaches for gene identification from DNA microarray data and compare our results to those of the well-known successful approaches proposed for the task. We show that our algorithm not only finds hypotheses with a much smaller number of genes while giving competitive classification accuracy but also having tight risk guarantees on future performance, unlike other approaches. The proposed approaches are general and extensible in terms of both designing novel algorithms and application to other domains.	[Shah, Mohak] Accenture, Chicago, IL 60601 USA; [Marchand, Mario] Univ Laval, Dept Comp Sci & Software Engn, Ste Foy, PQ G1V 0A6, Canada; [Corbeil, Jacques] Univ Laval, Fac Med, Infect Dis Res Ctr, Quebec City, PQ G1V 4G2, Canada	Accenture; Laval University; Laval University	Shah, M (corresponding author), Accenture, 161 N Clark St, Chicago, IL 60601 USA.	mohak.shah@accenture.com; Mario.Marchand@ift.ulaval.ca; Jacques.Corbeil@crchul.ulaval.ca	Corbeil, Jacques/AAW-9739-2020	Corbeil, Jacques/0000-0002-9973-2740; Marchand, Mario/0000-0002-7078-7393	National Science and Engineering Research Council (NSERC) of Canada [122405]; Canadian Institutes of Health Research; Canada Research Chair in Medical Genomics	National Science and Engineering Research Council (NSERC) of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)); Canadian Institutes of Health Research(Canadian Institutes of Health Research (CIHR)); Canada Research Chair in Medical Genomics(Canada Research Chairs)	This work was supported by the National Science and Engineering Research Council (NSERC) of Canada (Discovery Grant No. 122405 to Mario Marchand), the Canadian Institutes of Health Research (operating grant to Jacques Corbell), and the Canada Research Chair in Medical Genomics to Jacques Corbell.	Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699; Blum A, 2003, LECT NOTES ARTIF INT, V2777, P344, DOI 10.1007/978-3-540-45167-9_26; BLUMER A, 1987, INFORM PROCESS LETT, V24, P377, DOI 10.1016/0020-0190(87)90114-1; Chow ML, 2001, PHYSIOL GENOMICS, V5, P99, DOI 10.1152/physiolgenomics.2001.5.2.99; Driscoll B, 1999, AM J PHYSIOL-LUNG C, V276, pL679, DOI 10.1152/ajplung.1999.276.4.L679; Eisen MB, 1999, METHOD ENZYMOL, V303, P179; Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906; Garber ME, 2001, P NATL ACAD SCI USA, V98, P13784, DOI 10.1073/pnas.241500798; Germain P., 2009, P ADV NEUR INF PROC, P603; Germain P., 2009, P 26 ANN INT C MACH; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Gusterson BA, 2005, BREAST CANCER RES, V7, P143, DOI 10.1186/bcr1041; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; HAUSSLER D, 1988, ARTIF INTELL, V36, P177, DOI 10.1016/0004-3702(88)90002-1; Heap GA, 2009, BMC MED GENOMICS, V2, DOI 10.1186/1755-8794-2-1; Hiwatari M, 2003, ONCOGENE, V22, P2851, DOI 10.1038/sj.onc.1206389; Huang HL, 2007, BIOSYSTEMS, V90, P516, DOI 10.1016/j.biosystems.2006.12.003; Kawai H, 2002, ONCOGENE, V21, P7730, DOI 10.1038/sj.onc.1205971; Kuzmin D, 2007, J MACH LEARN RES, V8, P2047; Langford J, 2005, J MACH LEARN RES, V6, P273; LAWRENCE HJ, 1992, BLOOD, V80, P2445; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lipshutz RJ, 1999, NAT GENET, V21, P20, DOI 10.1038/4447; Ma YX, 2005, ONCOGENE, V24, P1831, DOI 10.1038/sj.onc.1208190; Marchand M, 2005, J MACH LEARN RES, V6, P427; Marchand M, 2003, J MACH LEARN RES, V3, P723, DOI 10.1162/jmlr.2003.3.4-5.723; Marchand M., 2005, ADV NEURAL INFORMATI, V17, P881; Masaki T, 2003, HEPATOLOGY, V37, P534, DOI 10.1053/jhep.2003.50112; McAllester DA, 1999, MACH LEARN, V37, P355, DOI 10.1023/A:1007618624809; McAllester DA, 2003, MACH LEARN, V51, P5, DOI 10.1023/A:1021840411064; Moggs JG, 2005, J MOL ENDOCRINOL, V34, P535, DOI 10.1677/jme.1.01677; Noble CL, 2008, GUT, V57, P1398, DOI 10.1136/gut.2008.148395; Pomeroy SL, 2002, NATURE, V415, P436, DOI 10.1038/415436a; Ravikumar P., 2009, P ADV NEUR INF PROC, P1329; Seeger M., 2002, J MACHINE LEARNING R, P233; Shah M, 2011, IEEE ACM T COMPUT BI, V8, P14, DOI 10.1109/TCBB.2009.51; Song L, 2007, BIOINFORMATICS, V23, pI490, DOI 10.1093/bioinformatics/btm216; Su Y, 2003, BIOINFORMATICS, V19, P1578, DOI 10.1093/bioinformatics/btg179; Tian E, 2003, NEW ENGL J MED, V349, P2483, DOI 10.1056/NEJMoa030847; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tibshirani R, 2003, STAT SCI, V18, P104, DOI 10.1214/ss/1056397488; Wainwright MJ, 2009, IEEE T INFORM THEORY, V55, P5728, DOI 10.1109/TIT.2009.2032816; Wang LP, 2007, IEEE ACM T COMPUT BI, V4, P40, DOI 10.1109/TCBB.2007.1006; West M, 2001, P NATL ACAD SCI USA, V98, P11462, DOI 10.1073/pnas.201162998; Witten I.H., 2005, P DATA MINING LAS VE, P4; Zhang T, 2005, ANN STAT, V33, P1538, DOI 10.1214/009053605000000255; Zhang T., 2009, NEURAL INFORM PROCES, P1921	49	33	36	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2012	34	1					174	186		10.1109/TPAMI.2011.82	http://dx.doi.org/10.1109/TPAMI.2011.82			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	848RB	21576745	Green Submitted			2022-12-18	WOS:000297069900012
J	Liu, JZ; Chen, Y; Tang, XO				Liu, Jianzhuang; Chen, Yu; Tang, Xiaoou			Decomposition of Complex Line Drawings with Hidden Lines for 3D Planar-Faced Manifold Object Reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D reconstruction; divide and conquer; internal face; line drawing; manifold	OPTIMIZATION-BASED RECONSTRUCTION; SHAPE; IDENTIFICATION	Three-dimensional object reconstruction from a single 2D line drawing is an important problem in computer vision. Many methods have been presented to solve this problem, but they usually fail when the geometric structure of a 3D object becomes complex. In this paper, a novel approach based on a divide-and-conquer strategy is proposed to handle the 3D reconstruction of a planar-faced complex manifold object from its 2D line drawing with hidden lines visible. The approach consists of four steps: 1) identifying the internal faces of the line drawing, 2) decomposing the line drawing into multiple simpler ones based on the internal faces, 3) reconstructing the 3D shapes from these simpler line drawings, and 4) merging the 3D shapes into one complete object represented by the original line drawing. A number of examples are provided to show that our approach can handle 3D reconstruction of more complex objects than previous methods.	[Liu, Jianzhuang; Tang, Xiaoou] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China; [Liu, Jianzhuang; Tang, Xiaoou] Chinese Acad Sci, Shenzhen Inst Adv Technol, Beijing 100864, Peoples R China; [Chen, Yu] Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England	Chinese University of Hong Kong; Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS; University of Cambridge	Liu, JZ (corresponding author), Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China.	jzliu@ie.cuhk.edu.hk; yc301@cam.ac.uk; xtang@ie.cuhk.edu.hk	Tang, Xiaoou/G-6509-2012		Natural Science Foundation of China [60975029, 61070148]; Research Grants Council of the Hong Kong SAR, China [CUHK 415408]; Shenzhen Bureau of Science Technology & Information, China [JC200903180635A]	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Research Grants Council of the Hong Kong SAR, China(Hong Kong Research Grants Council); Shenzhen Bureau of Science Technology & Information, China	This work was supported by grants from Natural Science Foundation of China (No. 60975029, 61070148), the Research Grants Council of the Hong Kong SAR, China (Project No. CUHK 415408), and the Shenzhen Bureau of Science Technology & Information, China (No. JC200903180635A).	AGARWAL SC, 1992, COMPUT AIDED DESIGN, V24, P123, DOI 10.1016/0010-4485(92)90032-6; Armstrong M.A., 1983, BASIC TOPOLOGY; Bagali S., 1995, Proceedings. Third Symposium on Solid Modeling and Applications, P339, DOI 10.1145/218013.218083; Cao LL, 2008, IEEE T PATTERN ANAL, V30, P507, DOI 10.1109/TPAMI.2007.1185; Cao LL, 2005, IEEE I CONF COMP VIS, P272; CHEN Y, 2007, P IEEE INT C COMP VI; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; Company P, 2005, COMPUT GRAPH-UK, V29, P892, DOI 10.1016/j.cag.2005.09.007; Company P, 2004, COMPUT GRAPH-UK, V28, P955, DOI 10.1016/j.cag.2004.08.007; Cooper MC, 2008, IEEE T PATTERN ANAL, V30, P741, DOI 10.1109/TPAMI.2007.70835; Cooper MC, 2007, INT J COMPUT VISION, V73, P195, DOI 10.1007/s11263-006-9783-7; Cooper MC, 2005, INT J COMPUT VISION, V64, P69, DOI 10.1007/s11263-005-1087-9; Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; LaCourse D.E., 1995, HDB SOLID MODELING; LECLERC YG, 1992, INT J COMPUT VISION, V9, P113, DOI 10.1007/BF00129683; Li HB, 2005, LECT NOTES COMPUT SC, V3519, P363; Lipson H, 1996, COMPUT AIDED DESIGN, V28, P651, DOI 10.1016/0010-4485(95)00081-X; Liu JZ, 2008, IEEE T PATTERN ANAL, V30, P315, DOI 10.1109/TPAMI.2007.1172; Liu JZ, 2005, IEEE T PATTERN ANAL, V27, P861, DOI 10.1109/TPAMI.2005.119; Liu JZ, 2002, IEEE T PATTERN ANAL, V24, P1579, DOI 10.1109/TPAMI.2002.1114850; Liu JZ, 2001, IEEE T PATTERN ANAL, V23, P1106; MARILL T, 1991, INT J COMPUT VISION, V6, P147, DOI 10.1007/BF00128154; Ortiz S, 2004, COMPUTER, V37, P24, DOI 10.1109/MC.2004.72; PIQUER A, 2003, P 5 IAPR INT WORKSH, P182; Ros L, 2002, IEEE T PATTERN ANAL, V24, P456, DOI 10.1109/34.993554; Shimodaira H, 2006, IEEE T PATTERN ANAL, V28, P612, DOI 10.1109/TPAMI.2006.67; Shimshoni I, 1997, COMPUT VIS IMAGE UND, V65, P296, DOI 10.1006/cviu.1996.0569; Shoji K, 2001, PROC CVPR IEEE, P90; Shpitalni M, 1996, IEEE T PATTERN ANAL, V18, P1000, DOI 10.1109/34.541409; SUGIHARA K, 1984, ARTIF INTELL, V23, P59, DOI 10.1016/0004-3702(84)90005-5; SUGIHARA K, 1984, IEEE T PATTERN ANAL, V6, P578, DOI 10.1109/TPAMI.1984.4767571; Sugihara K., 1986, MACHINE INTERPRETATI; TANG X., 2006, P 14 ANN ACM INT C M, P105; Turner A, 2000, COMPUT GRAPH-UK, V24, P869, DOI 10.1016/S0097-8493(00)00089-3; VARLEY PAC, 2002, P 7 ACM S SOL MOD AP, P180; VARLEY PAC, 2000, P 1 UK KOR WORKSH GE, P113; [No title captured]	38	33	39	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2011	33	1					3	15		10.1109/TPAMI.2010.49	http://dx.doi.org/10.1109/TPAMI.2010.49			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	681AC	21088315				2022-12-18	WOS:000284277600001
J	Kim, J; Scott, CD				Kim, JooSeuk; Scott, Clayton D.			L-2 Kernel Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Kernel methods; sparse classifiers; integrated squared error; difference of densities; SMO algorithm		Nonparametric kernel methods are widely used and proven to be successful in many statistical learning problems. Well-known examples include the kernel density estimate (KDE) for density estimation and the support vector machine (SVM) for classification. We propose a kernel classifier that optimizes the L-2 or integrated squared error (ISE) of a "difference of densities." We focus on the Gaussian kernel, although the method applies to other kernels suitable for density estimation. Like a support vector machine (SVM), the classifier is sparse and results from solving a quadratic program. We provide statistical performance guarantees for the proposed L-2 kernel classifier in the form of a finite sample oracle inequality and strong consistency in the sense of both ISE and probability of error. A special case of our analysis applies to a previously introduced ISE-based method for kernel density estimation. For dimensionality greater than 15, the basic L-2 kernel classifier performs poorly in practice. Thus, we extend the method through the introduction of a natural regularization parameter, which allows it to remain competitive with the SVM in high dimensions. Simulation results for both synthetic and real-world data are presented.	[Kim, JooSeuk; Scott, Clayton D.] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA	University of Michigan System; University of Michigan	Kim, J (corresponding author), Univ Michigan, Dept Elect Engn & Comp Sci, 1301 Beal Ave, Ann Arbor, MI 48109 USA.	stannum@umich.edu; clayscot@umich.edu			US National Science Foundation (NSF) [CCF-0830490]	US National Science Foundation (NSF)(National Science Foundation (NSF))	The authors would like to thank the anonymous reviewers for several constructive comments. This work was supported in part by US National Science Foundation (NSF) Grant CCF-0830490.	Bennett KP, 2000, MACH LEARN, V41, P295, DOI 10.1023/A:1007600130808; BERRY DA, 1996, BAYESIAN ANAL STAT E; Bunea F, 2007, LECT NOTES COMPUT SC, V4539, P530, DOI 10.1007/978-3-540-72927-3_38; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; CRISP D, 1999, P NEUR INF PROC SYST, V12; Di Marzio M, 2005, STAT COMPUT, V15, P113, DOI 10.1007/s11222-005-6203-8; Girolami M, 2003, IEEE T PATTERN ANAL, V25, P1253, DOI 10.1109/TPAMI.2003.1233899; Gretton A, 2005, J MACH LEARN RES, V6, P2075; HALL P, 1988, BIOMETRIKA, V75, P541, DOI 10.2307/2336605; He C, 2004, PATTERN RECOGN LETT, V25, P1389, DOI 10.1016/j.patrec.2004.05.004; HEATHCOTE CR, 1977, BIOMETRIKA, V64, P255, DOI 10.2307/2335691; JENSSEN R, 2004, P IEEE WORKSH MACH L; KIM D, 1995, THESIS VIRGINIA POLY; KIM J, 2007, P IEEE WORKSH STAT S; KIM J, 2008, P ADV NEUR INF PROC, V21; MEINICKE P, 2002, ADV NEURAL INFORM PR, V15, P985; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; PAULSON AS, 1975, BIOMETRIKA, V62, P163, DOI 10.2307/2334499; PELCKMANS K, 2007, P ADV NEUR INF PROC, V20; PLATT JC, 2001, MSRTR9814; RIGOLLET PH, 2004, LINEAR CONVEX AGGREG; SCHECHUK JR, 1994, MSRTR9814; Scholkopf B., 2002, LEARNING KERNELS; Scott DW, 2001, TECHNOMETRICS, V43, P274, DOI 10.1198/004017001316975880; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; TURLACH BA, 1993, 9317 CORE U CATH LOU; Wand M.P., 1995, KERNEL SMOOTHING; WOLVERTON CT, 1969, IEEE T INFORM THEORY, V15, P258, DOI 10.1109/TIT.1969.1054295	29	33	46	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2010	32	10					1822	1831		10.1109/TPAMI.2009.188	http://dx.doi.org/10.1109/TPAMI.2009.188			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	639US	20724759				2022-12-18	WOS:000281000700008
J	Moghaddam, RF; Cheriet, M				Moghaddam, Reza Farrahi; Cheriet, Mohamed			A Variational Approach to Degraded Document Enhancement	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Variational framework; PDE-based image processing; document enhancement; bleed-through effect	NOISE REMOVAL; SCALE-SPACE; WAVELET; SEGMENTATION; OPTIMIZATION; ALGORITHM	The goal of this paper is to correct bleed-through in degraded documents using a variational approach. The variational model is adapted using an estimated background according to the availability of the verso side of the document image. Furthermore, for the latter case, a more advanced model based on a global control, the flow field, is introduced. The solution of each resulting model is obtained using wavelet shrinkage or a time-stepping scheme, depending on the complexity and nonlinearity of the models. When both sides of the document are available, the proposed model uses the reverse diffusion process for the enhancement of double-sided document images. The results of experiments with real and synthesized samples are promising. The proposed model, which is robust with respect to noise and complex background, can also be applied to other fields of image processing.	[Moghaddam, Reza Farrahi] Univ Quebec, Ecole Technol Super, Synchromedia Lab Multimedia Commun Telepresence, Montreal, PQ H3C 1K3, Canada; [Cheriet, Mohamed] Univ Quebec, Ecole Technol Super, Automat Engn Dept, Montreal, PQ H3C 1K3, Canada	University of Quebec; Ecole de Technologie Superieure - Canada; University of Quebec Montreal; University of Quebec; Ecole de Technologie Superieure - Canada; University of Quebec Montreal	Moghaddam, RF (corresponding author), Univ Quebec, Ecole Technol Super, Synchromedia Lab Multimedia Commun Telepresence, 1100 Notre Dame W, Montreal, PQ H3C 1K3, Canada.	reza.farrahi-moghaddam.1@ens.etsmtl.ca; mohamed.cheriet@etsmtl.ca	Farrahi Moghaddam, Reza/E-7843-2015	Farrahi Moghaddam, Reza/0000-0002-3046-1305	NSERC of Canada; FQRNT	NSERC of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)); FQRNT(FQRNT)	The authors would like to thank the NSERC of Canada and FQRNT for their financial support. They would also like to thank Mr. Nicola Nobile of CENPARMI at Concordia University for providing the OCR results.	Berkefeld T, 2001, EXP ASTRON, V11, P1, DOI 10.1023/A:1011107301138; BIOUCASDIAS J, 2006, P IEEE INT C AC SPEE; Boykov Y, 2006, LECT NOTES COMPUT SC, V3953, P409, DOI 10.1007/11744078_32; Chambolle A, 2004, J MATH IMAGING VIS, V20, P89; Chambolle A, 2001, IEEE T IMAGE PROCESS, V10, P993, DOI 10.1109/83.931093; Chambolle A, 1998, IEEE T IMAGE PROCESS, V7, P319, DOI 10.1109/83.661182; CHEN L, 2006, P ASA CSSA SSSA INT, P294; CHERIET M, 2008, P INT WORKSH SIGN PR; Cichocki A., 2007, ICALAB MATLAB TOOLBO; DASILVA JMM, 2008, J UNIVERS COMPUT SCI, V14, P299; Deriche R., 1996, 2697 INRIA; Dobrosotskaya JA, 2008, IEEE T IMAGE PROCESS, V17, P657, DOI 10.1109/TIP.2008.919367; DON HS, 2001, INT J DOC ANAL RECOG, V4, P131; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; Dubois E, 2005, ARCHIVING 2005, FINAL PROGRAM AND PROCEEDINGS, P170; Dubois E, 2001, PICS 2001: IMAGE PROCESSING, IMAGE QUALITY, IMAGE CAPTURE, SYSTEMS CONFERENCE, PROCEEDINGS, P177; Dumitrescu B, 2008, IEEE SIGNAL PROC LET, V15, P146, DOI 10.1109/LSP.2007.913609; Effati S, 2006, APPL MATH COMPUT, V172, P305, DOI 10.1016/j.amc.2005.02.005; Franke K., 2001, International Journal on Document Analysis and Recognition, V3, P218, DOI 10.1007/PL00013565; FRANKE K, 2006, P INT WORKSH FRONT H; Gerace I, 2004, LECT NOTES COMPUT SC, V3195, P954; *GOOGL, 2007, BOOK SEARCH DAT; Hu XL, 2006, IEEE T NEURAL NETWOR, V17, P1487, DOI 10.1109/TNN.2006.879774; Huang SW, 2003, WSCG'2003, VOL 11, NO 3, CONFERENCE PROCEEDINGS, P520; KANUNGO T, 1996, THESIS U WASHINGTON; Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343; Kirby RC, 2006, ACM T MATH SOFTWARE, V32, P417, DOI 10.1145/1163641.1163644; KNOX KT, 1997, Patent No. 5646744; Leedham G, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P244, DOI 10.1109/IWFHR.2002.1030917; Lorenz D., 2004, VARIATIONAL DENOISIN; Malgouyres F, 2002, IEEE T IMAGE PROCESS, V11, P1450, DOI 10.1109/TIP.2002.806241; Malgouyres F, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P57, DOI 10.1109/VLSM.2001.938882; *MATHW INC, MATLAB VERS 7 5 0; MEIJUN S, 2005, P INT C COMP GRAPH I, P317; MEYER Y, 1995, WAVELETS OPERATORS, V37; Moghaddam R.F., 2008, P INT C FRONT HANDW, P204; Moghaddam RF, 2009, INT J DOC ANAL RECOG, V11, P183, DOI 10.1007/s10032-008-0076-2; Monteil J, 1999, IEEE T PATTERN ANAL, V21, P940, DOI 10.1109/34.790435; Mrazek P, 2003, LECT NOTES COMPUT SC, V2695, P101; Mukhopadhyay S, 2003, IEEE T IMAGE PROCESS, V12, P533, DOI 10.1109/TIP.2003.810757; Nishida H, 2002, INT C PATT RECOG, P65, DOI 10.1109/ICPR.2002.1047796; Oja E, 2006, IEEE T NEURAL NETWOR, V17, P1370, DOI 10.1109/TNN.2006.880980; OPHIR B, 2007, P INT C IM PROC ICIP, V3, P233; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Roth K, 2008, EUR J SOIL SCI, V59, P125, DOI 10.1111/j.1365-2389.2007.00986.x; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Rudin W., 1986, REAL COMPLEX ANAL, V3; Salerno E, 2007, INT J DOC ANAL RECOG, V9, P79, DOI 10.1007/s10032-006-0028-7; Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194; Selesnick IW, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P573, DOI 10.1109/ICIP.2002.1039035; Sharma G, 2001, IEEE T IMAGE PROCESS, V10, P736, DOI 10.1109/83.918567; Tan CL, 2002, IEEE T PATTERN ANAL, V24, P1399, DOI 10.1109/TPAMI.2002.1039211; Tan CL, 2000, FIFTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P16, DOI 10.1109/WACV.2000.895397; TONAZZINI A, 2004, IMAGE ANAL RECOGNITI, V2, P241; Tonazzini A, 2007, INT J DOC ANAL RECOG, V10, P17, DOI 10.1007/s10032-006-0015-z; TRIEBEL H, 1992, THEORY FUNCTION SP 2, V84; TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P1191, DOI 10.1109/34.476511; Vaziri HH, 2002, J PETROL SCI ENG, V36, P71, DOI 10.1016/S0920-4105(02)00264-4; Voci F, 2004, IEEE SIGNAL PROC MAG, V21, P39, DOI 10.1109/MSP.2004.1296541; XIUJIN W, 2002, T TIANJIN U, V8, P1; Ye XY, 2001, IEEE T IMAGE PROCESS, V10, P1152, DOI 10.1109/83.935031; Yongxin S., 2003, J COMPUT AIDED GRAPH, V15, P667; Zhang Q, 1999, J VISUAL COMP ANIMAT, V10, P27, DOI 10.1002/(SICI)1099-1778(199901/03)10:1<27::AID-VIS194>3.0.CO;2-C; Zienkiewicz OC, 2005, FINITE ELEMENT METHOD FOR FLUID DYNAMICS, 6TH EDITION, P1	64	33	33	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2010	32	8					1347	1361		10.1109/TPAMI.2009.141	http://dx.doi.org/10.1109/TPAMI.2009.141			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	611XQ	20558870				2022-12-18	WOS:000278858600001
J	Ommer, B; Buhmann, JM				Ommer, Bjoern; Buhmann, Joachim M.			Learning the Compositional Nature of Visual Object Categories for Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image categorization; object recognition; compositionality; graphical models; visual learning	SEGMENTATION; SCALE	Real-world scene understanding requires recognizing object categories in novel visual scenes. This paper describes a composition system that automatically learns structured, hierarchical object representations in an unsupervised manner without requiring manual segmentation or manual object localization. A central concept for learning object models in the challenging, general case of unconstrained scenes, large intraclass variations, large numbers of categories, and lacking supervision information is to exploit the compositional nature of our (visual) world. The compositional nature of visual objects significantly limits their representation complexity and renders learning of structured object models statistically and computationally tractable. We propose a robust descriptor for local image parts and show how characteristic compositions of parts can be learned that are based on an unspecific part vocabulary shared between all categories. Moreover, a Bayesian network is presented that comprises all the compositional constituents together with scene context and object shape. Object recognition is then formulated as a statistical inference problem in this probabilistic model.	[Ommer, Bjoern] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA; [Buhmann, Joachim M.] ETH, Dept Comp Sci, CH-8092 Zurich, Switzerland	University of California System; University of California Berkeley; Swiss Federal Institutes of Technology Domain; ETH Zurich	Ommer, B (corresponding author), Univ Calif Berkeley, Dept Elect Engn & Comp Sci, 527 Soda Hall, Berkeley, CA 94720 USA.	ommer@eecs.berkeley.edu; jbuhmann@inf.ethz.ch	Buhmann, Joachim/AAU-4760-2020		Swiss National Science Foundation [200021-107636]	Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission)	This work was supported in part by the Swiss National Science Foundation under contract no. 200021-107636.	Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108; Amit Y, 1999, NEURAL COMPUT, V11, P1691, DOI 10.1162/089976699300016197; [Anonymous], 1985, PERCEPTUAL ORG VISUA; ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; Berg AC, 2005, PROC CVPR IEEE, P26; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; BORENSTEIN E., 2004, P IEEE C COMP VIS PA; BOSCH A., 2007, P IEEE INT C COMP VI; Bouchard G, 2005, PROC CVPR IEEE, P710; BURL M, 1998, P EUR C COMP VIS, P628; Csurka G., 2004, P EUR C COMP VIS WOR; Epshtein B, 2005, IEEE I CONF COMP VIS, P220; Everingham M., 2006, PASCAL VISUAL OBJECT; Fei-Fei L., 2004, P IEEE C COMP VIS PA; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Fergus R, 2005, IEEE I CONF COMP VIS, P1816; Fergus R, 2004, LECT NOTES COMPUT SC, V3021, P242; Fergus R, 2003, PROC CVPR IEEE, P264; Ferrari V, 2006, LECT NOTES COMPUT SC, V3953, P14, DOI 10.1007/11744078_2; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Geman S, 2002, Q APPL MATH, V60, P707, DOI 10.1090/qam/1939008; GRAUMAN K, 2006, MITCSAILTR2006020; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Holub AD, 2005, IEEE I CONF COMP VIS, P136; Jin Y., 2006, CVPR, V2, P2145; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Leibe B, 2004, LECT NOTES COMPUT SC, V3175, P145; LEIBE B, 2004, P EUR C COMP VIS WOR; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Mutch J, 2006, P IEEE C COMP VIS PA, P11, DOI [10.1109/CVPR.2006.200, DOI 10.1109/CVPR.2006.200]; OMMER B, 2005, P INT WORKSH EN MIN, P235; OMMER B, 2006, P EUR C COMP VIS, P316; OMMER B, 2006, P IEEE C COMP VIS PA; OPELT A, 2006, P C COMP VIS PATT RE, P3; Puzicha J, 1999, PATTERN RECOGN LETT, V20, P899, DOI 10.1016/S0167-8655(99)00056-2; Roth V, 2001, PROC CVPR IEEE, P1120; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Sivic J, 2005, IEEE I CONF COMP VIS, P370; Sudderth EB, 2005, IEEE I CONF COMP VIS, P1331; Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x; VELTKAMP RC, 2000, UUCS200034; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Weber M, 2000, LECT NOTES COMPUT SC, V1842, P18; Winkler G., 2003, IMAGE ANAL RANDOM FI; Zhang H, 2006, 2006 IEEE COMP SOC C, P2126, DOI [10.1109/CVPR.2006.301, DOI 10.1109/CVPR.2006.301]	50	33	35	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2010	32	3					501	516		10.1109/TPAMI.2009.22	http://dx.doi.org/10.1109/TPAMI.2009.22			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	543WG	20075474				2022-12-18	WOS:000273609600008
J	Wolf, C				Wolf, Christian			Document Ink Bleed-Through Removal with Two Hidden Markov Random Fields and a Single Observation Field	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Markov random fields; Bayesian estimation; graph cuts; document image restoration	ENERGY MINIMIZATION; RESTORATION; MODEL; SEPARATION	We present a new method for blind document bleed-through removal based on separate Markov Random Field (MRF) regularization for the recto and for the verso side, where separate priors are derived from the full graph. The segmentation algorithm is based on Bayesian Maximum a Posteriori (MAP) estimation. The advantages of this separate approach are the adaptation of the prior to the contents creation process (e. g., superimposing two handwritten pages), and the improvement of the estimation of the recto pixels through an estimation of the verso pixels covered by recto pixels; moreover, the formulation as a binary labeling problem with two hidden labels per pixels naturally leads to an efficient optimization method based on the minimum cut/maximum flow in a graph. The proposed method is evaluated on scanned document images from the 18th century, showing an improvement of character recognition results compared to other restoration methods.	[Wolf, Christian] Univ Lyon, CNRS, F-69621 Villeurbanne, France; [Wolf, Christian] Inst Natl Sci Appl, LIRIS, UMR 5205, F-69621 Villeurbanne, France	Centre National de la Recherche Scientifique (CNRS); Institut National des Sciences Appliquees de Lyon - INSA Lyon	Wolf, C (corresponding author), Univ Lyon, CNRS, Bat Jules Verne 20,Ave Albert Einstein, F-69621 Villeurbanne, France.	christian.wolf@liris.cnrs.fr						Baird H. S., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P62, DOI 10.1109/ICDAR.1993.395781; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BOUMAN CA, 1994, IEEE T IMAGE PROCESS, V3, P162, DOI 10.1109/83.277898; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Braathen B., 1993, MACHINE GRAPHICS VIS, V2, P39; Brown MS, 2004, IEEE T PATTERN ANAL, V26, P1295, DOI 10.1109/TPAMI.2004.87; Charbonnier P, 1997, IEEE T IMAGE PROCESS, V6, P298, DOI 10.1109/83.551699; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; Don H.S., 2000, I J DOC ANAL REC, V4, P131; Donaldson K., 2005, International Journal on Document Analysis and Recognition, V7, P159, DOI 10.1007/s10032-004-0139-y; DRIRA F, 2006, P 7 WORKSH DOC AN SY, P38; Dubois E, 2001, PICS 2001: IMAGE PROCESSING, IMAGE QUALITY, IMAGE CAPTURE, SYSTEMS CONFERENCE, PROCEEDINGS, P177; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x; Hammersley JM, 1968, MARKOV FIELDS UNPUB; Kanungo T., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P730, DOI 10.1109/ICDAR.1993.395633; Kato Z, 1996, GRAPH MODEL IM PROC, V58, P18, DOI 10.1006/gmip.1996.0002; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kumar S, 2006, INT J COMPUT VISION, V68, P179, DOI 10.1007/s11263-006-7007-9; Laferte JM, 2000, IEEE T IMAGE PROCESS, V9, P390, DOI 10.1109/83.826777; Lafferty J., 2001, CONDITIONAL RANDOM F; LEBOURGEOIS F, 2004, P 1 INT WORKSH DOC I; Leydier Y, 2004, INT C PATT RECOG, P494, DOI 10.1109/ICPR.2004.1334174; Li S. Z., 2001, COMP SCI W; Melgosa M, 2000, COLOR RES APPL, V25, P49, DOI 10.1002/(SICI)1520-6378(200002)25:1<49::AID-COL7>3.0.CO;2-4; Niblack W., 1986, ADV COMPUTER GRAPHIC; Nishida H, 2002, INT C PATT RECOG, P65, DOI 10.1109/ICPR.2002.1047796; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Sauvola J, 1997, PROC INT CONF DOC, P147, DOI 10.1109/ICDAR.1997.619831; SEZAN MI, 1990, OPT ENG, V29, P393, DOI 10.1117/12.55610; Sharma G, 2001, IEEE T IMAGE PROCESS, V10, P736, DOI 10.1109/83.918567; Tan CL, 2002, IEEE T PATTERN ANAL, V24, P1399, DOI 10.1109/TPAMI.2002.1039211; Tonazzini A, 2006, IEEE T IMAGE PROCESS, V15, P473, DOI 10.1109/TIP.2005.860323; Tonazzini A., 2004, International Journal on Document Analysis and Recognition, V7, P17, DOI 10.1007/s10032-004-0121-8; TONAZZINI A, 2005, P 13 EUR SIGN PROC C; TONAZZINI A, 2003, IJDAR, V6, P236; Tonazzini A, 2007, INT J DOC ANAL RECOG, V10, P17, DOI 10.1007/s10032-006-0015-z; TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P1191, DOI 10.1109/34.476511; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; Wang Q, 2003, PROC INT CONF DOC, P736; Wolf C, 2002, INT C PATT RECOG, P160, DOI 10.1109/ICPR.2002.1047819; ZHANG J, 1992, IEEE T SIGNAL PROCES, V40, P2570, DOI 10.1109/78.157297; Zhang L, 2008, IEEE T PATTERN ANAL, V30, P728, DOI 10.1109/TPAMI.2007.70831; Zheng QG, 2001, IEEE IMAGE PROC, P193, DOI 10.1109/ICIP.2001.958986	45	33	34	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2010	32	3					431	447		10.1109/TPAMI.2009.33	http://dx.doi.org/10.1109/TPAMI.2009.33			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	543WG	20075470	Green Submitted			2022-12-18	WOS:000273609600004
J	Horaud, R; Niskanen, M; Dewaele, G; Boyer, E				Horaud, Radu; Niskanen, Matti; Dewaele, Guillaume; Boyer, Edmond			Human Motion Tracking by Registering an Articulated Surface to 3D Points and Normals	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Model-based tracking; human motion capture; articulated implicit surface; shape from silhouettes; robust surface registration; expectation-maximization	SILHOUETTE; OBJECTS; SHAPE	We address the problem of human motion tracking by registering a surface to 3D data. We propose a method that iteratively computes two things: maximum likelihood estimates for both the kinematic and free-motion parameters of a kinematic human-body representation, as well as probabilities that the data are assigned either to a body part or to an outlier class. We introduce a new metric between observed points and normals on one side and a parameterized surface on the other side, the latter being defined as a blending over a set of ellipsoids. We claim that this metric is well suited when one deals with either visual-hull or visual-shape observations. We illustrate the method by tracking human motions using sparse visual-shape data (3D surface points and normals) gathered from imperfect silhouettes.	[Horaud, Radu; Dewaele, Guillaume; Boyer, Edmond] INRIA Grenoble Rhone Alpes, F-38330 Montonnot St Martin, France; [Niskanen, Matti] Univ Oulu, Elect & Informat Engn Dept, FIN-90014 Oulu, Finland	University of Oulu	Horaud, R (corresponding author), INRIA Grenoble Rhone Alpes, 655 Ave Europe, F-38330 Montonnot St Martin, France.	Radu.Horaud@inrialpes.fr; matti.niskanen@ee.oulu.fi; Guillaume.Dewaele@ens-lyon.fr; Edmond.Boyer@inrialpes.fr	Horaud, Radu/AAR-5982-2021	Horaud, Radu/0000-0001-5232-024X				Bishop C.M, 2006, PATTERN RECOGN; Boyer E, 2003, PROC CVPR IEEE, P695; BROSTOW GJ, 2004, P ECCV 04, V3, P66; Cheung KM, 2005, INT J COMPUT VISION, V63, P225, DOI 10.1007/s11263-005-6879-4; DEMIRDJIAN D, 2004, P EUR C COMP VIS, V3, P183; DEWAELE G, 2006, P 9 EUR C COMP VIS M, V3, P578; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; FRANCO JS, 2006, P 3 INT S 3D DAT PRO; Ilic S, 2007, INT J COMPUT VISION, V72, P159, DOI 10.1007/s11263-006-8595-0; Knossow D, 2008, INT J COMPUT VISION, V79, P247, DOI 10.1007/s11263-007-0116-2; Luo B, 2001, IEEE T PATTERN ANAL, V23, P1120, DOI 10.1109/34.954602; Plankers R, 2003, IEEE T PATTERN ANAL, V25, P1182, DOI 10.1109/TPAMI.2003.1227995; STARCK J, 2003, P 9 IEEE INT C COMP; Wells WM, 1997, INT J COMPUT VISION, V21, P63, DOI 10.1023/A:1007923522710	14	33	35	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2009	31	1					158	U4		10.1109/TPAMI.2008.108	http://dx.doi.org/10.1109/TPAMI.2008.108			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	372GI	19029553	Green Submitted			2022-12-18	WOS:000260889700013
J	Zhang, L; Zhang, Y; Tan, CL				Zhang, Li; Zhang, Yu; Tan, Chew Lim			An improved physically-based method for geometric restoration of distorted document images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						warped image restoration; geometric correction; physically-based modeling; numerical integration		In document digitization through camera-based systems, simple imaging setups often produce geometric distortions in the resultant 2D images because of the nonplanar geometric shapes of certain documents such as thick bound books, rolled, folded, or crumpled materials, etc. Previous work [1], [2], [3], [4] has demonstrated that arbitrary warped documents can be successfully restored by flattening a 3D scan of the document. These approaches use physically-based or relaxation-based techniques in their flattening process. While this has been demonstrated to be effective in rectifying the image content and improving OCR, these previous approaches have several limitations in terms of speed and stability. In this paper, we propose a distance-based penalty metric to replace the mass-spring model and introduce additional bending resistance and drag forces to improve the efficiency of the existing approaches. The use of Verlet integration and special plane collision handling schemes also help to achieve better stability without sacrificing efficiency. Experiments on various document images captured from books, brochures, and historical documents with arbitrary warpings have demonstrated large improvements over the existing approaches in terms of stability and efficiency.	[Zhang, Li; Tan, Chew Lim] Natl Univ Singapore, Sch Comp, Singapore 117543, Singapore; [Zhang, Yu] ASTAR, Inst High Performance Comp, Singapore 117528, Singapore	National University of Singapore; Agency for Science Technology & Research (A*STAR); A*STAR - Institute of High Performance Computing (IHPC)	Zhang, L (corresponding author), Natl Univ Singapore, Sch Comp, 3 Sci Dr 2, Singapore 117543, Singapore.	zhangli@comp.nus.edu.sg; zhangy@ihpc.a-star.edu.sg; tancl@comp.nus.edu.sg						Amano T, 2002, P SOC PHOTO-OPT INS, V4669, P250, DOI 10.1117/12.463448; BARAFF D, 1997, P ACM SIGGRAPH TUT N; Brown MS, 2005, PROC CVPR IEEE, P998; Brown MS, 2004, IEEE T PATTERN ANAL, V26, P1295, DOI 10.1109/TPAMI.2004.87; Brown MS, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P367, DOI 10.1109/ICCV.2001.937649; CHOI KJ, 2003, P EUROGRAPHICS, P187; Chua KB, 2005, PROC INT CONF DOC, P384, DOI 10.1109/ICDAR.2005.8; Farsiu S, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P291, DOI 10.1109/ICIP.2003.1246674; Iketani A, 2006, INT C PATT RECOG, P391; JAKOBSEN T, 2003, GAME DEV; Liang H, 2006, INT C PATT RECOG, P476; LIANG J, 2005, INT J DOC ANAL RECOG, V7, P83; Lin Y, 2005, IEEE I CONF COMP VIS, P662; *MIN, 3D DIG NONC LAS RANG; OLIVEIRA G, 2001, GAME DEV; PILU M, 2001, COMPUTER VISION PATT, V1, P67; PRESS WH, 1986, NUMERICAL RECIPES A; PROVOT X, 1995, GRAPH INTER, P147; Provot X., 1997, PROC COMPUT ANIMATIO, P177; SEALE W, 2004, P JOINT ACM IEEE C D, V1, P117; SUN M, 2005, P 10 IEEE INT C COMP, V2, P17; TANG YY, 1993, IEEE T SYST MAN CYB, V23, P155, DOI 10.1109/21.214774; TSOI YC, 2004, COMPUTER VISION PATT, V1, P240; Volino P, 2000, COMPUTER GRAPHICS INTERNATIONAL 2000, PROCEEDINGS, P257, DOI 10.1109/CGI.2000.852341; VOLINO P, 1994, COMPUT GRAPH FORUM, V13, pC155, DOI 10.1111/1467-8659.1330155; WITKIN A, 2001, P ACM SIGGRAPH COURS; WITKIN A, 1997, P ACM SIGGRAPH; Yamashita A, 2004, INT C PATT RECOG, P482, DOI 10.1109/ICPR.2004.1334171; ZHANG L, 2007, P 22 C ART INT; Zhang Z, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P977, DOI 10.1109/ICIP.2002.1039138	30	33	33	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2008	30	4					728	734		10.1109/TPAMI.2007.70831	http://dx.doi.org/10.1109/TPAMI.2007.70831			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	262FY	18276976				2022-12-18	WOS:000253135600014
J	Sanguinetti, G				Sanguinetti, Guido			Dimensionality reduction of clustered data sets	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						dimensionality reduction; clustering; discriminant analysis; probabilistic algorithms	PRINCIPAL COMPONENT ANALYSIS	We present a novel probabilistic latent variable model to perform linear dimensionality reduction on data sets which contain clusters. We prove that the maximum likelihood solution of the model is an unsupervised generalization of linear discriminant analysis. This provides a completely new approach to one of the most established and widely used classification algorithms. The performance of the model is then demonstrated on a number of real and artificial data sets.	Univ Sheffield, Dept Comp Sci, Sheffield S1 4DP, S Yorkshire, England	University of Sheffield	Sanguinetti, G (corresponding author), Univ Sheffield, Dept Comp Sci, 211 Portobello St, Sheffield S1 4DP, S Yorkshire, England.	guido@dcs.shef.ac.uk						Bishop C.M, 2006, PATTERN RECOGN; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Bishop CM, 1998, IEEE T PATTERN ANAL, V20, P281, DOI 10.1109/34.667885; BISHOP CM, 1999, P ADV NEUR INF PROC; DASGUPTA S, 1999, P 40 ANN IEEE S FDN; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Girolami M, 2004, BIOINFORMATICS, V20, P3021, DOI 10.1093/bioinformatics/bth354; GIROLAMI M, 2001, INDEPENDENT COMPONEN; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Lawrence N, 2005, J MACH LEARN RES, V6, P1783; Sanguinetti G, 2005, BIOINFORMATICS, V21, P3748, DOI 10.1093/bioinformatics/bti617; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Welling M., 2003, P ADV NEUR INF PROC	15	33	34	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2008	30	3					535	540		10.1109/TPAMI.2007.70819	http://dx.doi.org/10.1109/TPAMI.2007.70819			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	250FT	18195446	Green Accepted			2022-12-18	WOS:000252286100014
J	Lu, SJ; Tan, CL				Lu Shijian; Tan, Chew Lim			Script and language identification in noisy and degraded document images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document analysis; shape; script identification; language identification; clustering; classification; association rules	TEXTURE	This paper reports an identification technique that detects scripts and languages of noisy and degraded document images. In the proposed technique, scripts and languages are identified through the document vectorization, which converts each document image into a document vector that characterizes the shape and frequency of the contained character or word images. Document images are vectorized by using vertical component cuts and character extremum points, which are both tolerant to the variation in text fonts and styles, noise, and various types of document degradation. For each script or language under study, a script or language template is first constructed through a training process. Scripts and languages of document images are then determined according to the distances between converted document vectors and the preconstructed script and language templates. Experimental results show that the proposed technique is accurate, easy for extension, and tolerant to noise and various types of document degradation.	Natl Univ Singapore, Sch Comp, Dept Comp Sci, Singapore 117543, Singapore	National University of Singapore	Lu, SJ (corresponding author), Natl Univ Singapore, Sch Comp, Dept Comp Sci, 3 Sci Dr 2, Singapore 117543, Singapore.	lusj@comp.nus.edu.sg; tancl@comp.nus.edu.sg	Lu, Shijian/AAU-4831-2021	Lu, Shijian/0000-0002-6766-2506				Busch A, 2005, IEEE T PATTERN ANAL, V27, P1720, DOI 10.1109/TPAMI.2005.227; Cavnar W. B., 1994, P 3 ANN S DOC AN INF, P1, DOI DOI 10.1.1.53.9367; Ding J, 1997, PROC INT CONF DOC, P1023, DOI 10.1109/ICDAR.1997.620664; Dunning Ted, 1994, STAT IDENTIFICATION; Elgammal A. M., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P1100, DOI 10.1109/ICDAR.2001.953956; Hochberg J., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P378, DOI 10.1109/ICDAR.1995.599017; Hochberg J, 1997, IEEE T PATTERN ANAL, V19, P176, DOI 10.1109/34.574802; Jain AK, 1996, PATTERN RECOGN, V29, P743, DOI 10.1016/0031-3203(95)00131-X; KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870; Lee D. S., 1996, P IAPR WORKSH DOC AN, P76; Lu S., 1999, P NAT C ART INT, V21, P769; LU S, 2006, P 6 IAPR WORKSH DOC, P232; Nobile N, 1997, PROC INT CONF DOC, P258, DOI 10.1109/ICDAR.1997.619852; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Pal U, 2002, IMAGE VISION COMPUT, V20, P945, DOI 10.1016/S0262-8856(02)00101-4; Ronse C, 1984, CONNECTED COMPONENTS; Spitz AL, 1997, IEEE T PATTERN ANAL, V19, P235, DOI 10.1109/34.584100; SUEN CY, 1998, P INT C ADV PATT REC, P297; Tan TN, 1998, IEEE T PATTERN ANAL, V20, P751, DOI 10.1109/34.689305; TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P312, DOI 10.1109/34.368197	20	33	34	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2008	30	1					14	24		10.1109/TPAMI.2007.1158	http://dx.doi.org/10.1109/TPAMI.2007.1158			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	229YW	18000321				2022-12-18	WOS:000250843500002
J	Mordohai, P; Medioni, G				Mordohai, P; Medioni, G			Stereo using monocular cues within the tensor voting framework	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						stereo; occlusion; pixel correspondence; computer vision; perceptual organization; tensor voting	ALGORITHM; SURFACE; INFERENCE; WINDOW	We address the fundamental problem of matching in two static images. The remaining challenges are related to occlusion and lack of texture. Our approach addresses these difficulties within a perceptual organization framework, considering both binocular and monocular cues. Initially, matching candidates for all pixels are generated by a combination of matching techniques. The matching candidates are then embedded in disparity space, where perceptual organization takes place in 3D neighborhoods and, thus, does not suffer from problems associated with scanline or image neighborhoods. The assumption is that correct matches produce salient, coherent surfaces, while wrong ones do not. Matching candidates that are consistent with the surfaces are kept and grouped into smooth layers. Thus, we achieve surface segmentation based on geometric and not photometric properties. Surface overextensions, which are due to occlusion, can be corrected by removing matches whose projections are not consistent in color with their neighbors of the same surface in both images. Finally, the projections of the refined surfaces on both images are used to obtain disparity hypotheses for unmatched pixels. The final disparities are selected after a second tensor voting stage, during which information is propagated from more reliable pixels to less reliable ones. We present results on widely used benchmark stereo pairs.	Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA; Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90083 USA	University of North Carolina; University of North Carolina Chapel Hill; University of Southern California	Mordohai, P (corresponding author), Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA.	mordohai@cs.unc.edu; medioni@iris.usc.edu	Mordohai, Philippos/B-8480-2008					Agrawal M, 2004, PROC CVPR IEEE, P66; Belhumeur P. N., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P506, DOI 10.1109/CVPR.1992.223143; Belhumeur PN, 1996, INT J COMPUT VISION, V19, P237, DOI 10.1007/BF00055146; Birchfield S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P489, DOI 10.1109/ICCV.1999.791261; Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269; Birchfield S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1073, DOI 10.1109/ICCV.1998.710850; Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603; Cox IJ, 1996, COMPUT VIS IMAGE UND, V63, P542, DOI 10.1006/cviu.1996.0040; GEIGER D, 1995, INT J COMPUT VISION, V14, P211, DOI 10.1007/BF01679683; Goulermas JY, 2003, IEEE T EVOLUT COMPUT, V7, P482, DOI 10.1109/TEVC.2003.817460; HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709; Hong L, 2004, PROC CVPR IEEE, P74; Intille S. S., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P179, DOI 10.1007/BFb0028349; ISHIKAWA H, 1998, P EUR C COMP VIS, V1, P232; KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690; Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; Lee MS, 2002, IEEE T PATTERN ANAL, V24, P824, DOI 10.1109/TPAMI.2002.1008388; Lee MS, 1998, PROC CVPR IEEE, P346, DOI 10.1109/CVPR.1998.698629; LIN M, 2003, P IEEE C COMP VIS PA, V1, P710; LUO A, 1995, INT J COMPUT VISION, V15, P171, DOI 10.1007/BF01451740; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; Medioni G., 2000, COMPUTATIONAL FRAMEW; MORDOHAI P, 2004, P EUR C COMP VIS, P588; Ogale AS, 2004, PROC CVPR IEEE, P568; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; Okutomi M, 2002, INT J COMPUT VISION, V47, P261, DOI 10.1023/A:1014510328154; Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763; Sara R, 1997, PROC CVPR IEEE, P852, DOI 10.1109/CVPR.1997.609427; SARA R, 2002, P EUR C COMP VIS, V3, P900; Scharstein D, 1998, INT J COMPUT VISION, V28, P155, DOI 10.1023/A:1008015117424; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Scharstein D, 2003, PROC CVPR IEEE, P195; Sun J, 2005, PROC CVPR IEEE, P399; Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509; Szeliski R, 2002, LECT NOTES COMPUT SC, V2351, P525; Tang CK, 1998, IEEE T PATTERN ANAL, V20, P1206, DOI 10.1109/34.730555; Tao H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P532, DOI 10.1109/ICCV.2001.937562; Tappen MF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P900; Veksler O, 2003, PROC CVPR IEEE, P556; Wei YC, 2004, PROC CVPR IEEE, P106; Zhang Y, 2002, LECT NOTES COMPUT SC, V2351, P556; Zhengyou Zhang, 2001, 3D Structure from Images - SMILE 2000. Second European Workshop on 3D Structure from Multiple Images of Large-Scale Environments. Revised Papers (Lecture Notes in Computer Science Vol.2018), P68; Zitnick CL, 2000, IEEE T PATTERN ANAL, V22, P675, DOI 10.1109/34.865184	46	33	40	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2006	28	6					968	982		10.1109/TPAMI.2006.129	http://dx.doi.org/10.1109/TPAMI.2006.129			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	031WB	16724590				2022-12-18	WOS:000236734400010
J	Vazquez, C; Mitiche, A; Laganiere, R				Vazquez, C; Mitiche, A; Laganiere, R			Joint multiregion segmentation and parametric estimation of image motion by basis function representation and level set evolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion estimation; motion segmentation; basis function representation of motion; parametric motion model; curve evolution; level sets	ACTIVE CONTOURS; VIDEO	The purpose of this study is to investigate a variational method for joint segmentation and parametric estimation of image motion by basis function representation of motion and level set evolution. The functional contains three terms. One term is of classic regularization to bias the solution toward a segmentation with smooth boundaries. A second term biases the solution toward a segmentation with boundaries which coincide with motion discontinuities, following a description of motion discontinuities by a function of the image spatio-temporal variations. The third term refers to region information and measures conformity of the parametric representation of the motion of each region of segmentation to the image spatio-temporal variations. The components of motion in each region of segmentation are represented as functions in a space generated by a set of basis functions. The coefficients of the motion components considered combinations of the basis functions are the parameters of representation. The necessary conditions for a minimum of the functional, which are derived taking into consideration the dependence of the motion parameters on segmentation, lead to an algorithm which condenses to concurrent curve evolution, implemented via level sets, and estimation of the parameters by least squares within each region of segmentation. The algorithm and its implementation are verified on synthetic and real images using a basis of cosine transforms.	Commun Res Ctr, Ottawa, ON K2H 8S2, Canada; Univ Quebec, INRS EMT, Inst Natl Rech Sci, Montreal, PQ H5A 1K6, Canada; Univ Ottawa, Sch Informat Technol & Engn, Fac Engn, Ottawa, ON K1N 6N5, Canada	Communications Research Centre Canada; University of Quebec; Institut national de la recherche scientifique (INRS); University of Quebec Montreal; University of Ottawa	Vazquez, C (corresponding author), Commun Res Ctr, 3701 Carling Ave,POB 11490,Stn H, Ottawa, ON K2H 8S2, Canada.	carlos.vazquez@crc.ca; mitiche@emt.inrs.ca; laganiere@site.uottawa.ca	Laganiere, Robert/H-9138-2013	Laganiere, Robert/0000-0001-9475-8151; Vazquez, Carlos/0000-0003-2161-8507				Altunbasak Y, 2003, IEEE T IMAGE PROCESS, V12, P395, DOI 10.1109/TIP.2003.809012; Aubert G, 2003, SIAM J APPL MATH, V63, P2128, DOI 10.1137/S0036139902408928; Aubert G., 2002, MATH PROBLEMS IMAGE; Bergeron C, 1991, IEEE T CIRC SYST VID, V1, P72, DOI 10.1109/76.109148; Borshukov GD, 1997, IEEE T IMAGE PROCESS, V6, P1591, DOI 10.1109/83.641420; BROX T, 2004, P 8 EUR C COMP VIS, V4, P25; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Chang MM, 1997, IEEE T IMAGE PROCESS, V6, P1326, DOI 10.1109/83.623196; Cremers D, 2003, LECT NOTES COMPUT SC, V2695, P599; Cremers D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P886; DERICHE R, 1995, P 2 AS C COMP VIS AC, V2, P290; Diehl N., 1991, Signal Processing: Image Communication, V3, P23, DOI 10.1016/0923-5965(91)90028-Z; Dufaux F., 1994, Journal of Visual Communication and Image Representation, V5, P356, DOI 10.1006/jvci.1994.1034; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Kaup A, 1999, IEEE T CIRC SYST VID, V9, P5, DOI 10.1109/76.744271; Mallat S., 1999, WAVELET TOUR SIGNAL; Mansouri AR, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P50, DOI 10.1109/MOTION.2002.1182213; Mansouri AR, 2003, IEEE T IMAGE PROCESS, V12, P201, DOI 10.1109/TIP.2002.807582; MANSOURI AR, 2003, P IEEE INT C IM PROC; MANSOURI AR, 2004, P IEEE INT C IM PROC; Mitiche A, 2003, ROBOT AUTON SYST, V43, P39, DOI 10.1016/S0921-8890(03)00002-2; MITICHE A, 1994, COMPUTATIONAL ANAL V; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029; Odobez JM, 1998, SIGNAL PROCESS, V66, P143, DOI 10.1016/S0165-1684(98)00003-6; SANDBERG B, 2002, 0239 CAM U CAL; Sethian J. A., 1999, LEVEL SET METHODS FA; Stiller C, 1999, IEEE SIGNAL PROC MAG, V16, P70, DOI 10.1109/79.774934; Vazquez C, 2004, IEEE IMAGE PROC, P549; VAZQUEZ C, 2004, P REC FORM INT ART R; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165; ZHU S, 1997, NEURAL COMPUTATION, V9; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	34	33	33	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2006	28	5					782	793		10.1109/TPAMI.2006.97	http://dx.doi.org/10.1109/TPAMI.2006.97			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	020CO	16640263	Green Submitted			2022-12-18	WOS:000235885700009
J	Hsieh, PF; Wang, DS; Hsu, CW				Hsieh, PF; Wang, DS; Hsu, CW			A linear feature extraction for multiclass classification problems based on class mean and covariance discriminant information	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						dimensionality reduction; linear feature extraction; discriminant analysis; classification error estimation; linear discriminant analysis; Bhattacharyya distance	DIMENSIONALITY REDUCTION; FEATURE-SELECTION	A parametric linear feature extraction method is proposed for multiclass classification. The skeleton of the proposed method consists of two types of schemes that are complementary to each other with regard to the discriminant information used. The approximate pairwise accuracy criterion (aPAC) and the common-mean feature extraction (CMFE) are chosen to exploit the discriminant information about class mean and about class covariance, respectively. Choosing aPAC rather than the linear discriminant analysis (LDA) can also resolve the problem of overemphasized large distances introduced by LDA, while maintaining other decent properties of LDA. To alleviate the suboptimum problem caused by a direct cascading of the two different types of schemes, there should be a mechanism for sorting and merging features based on their effectiveness. Usage of a sample-based classification error estimation for evaluation of effectiveness of features usually costs a lot of computational time. Therefore, we develop a fast spanning-tree-based parametric classification accuracy estimator as an intermediary for the aPAC and CMFE combination. The entire framework is parametric-based. This avoids paying a costly price in computation, which normally happens to the sample-based approach. Our experiments have shown that the proposed method can achieve a satisfactory performance on real data as well as simulated data.	Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 701, Taiwan; Altek Co, Taipei 114, Taiwan	National Cheng Kung University	Hsieh, PF (corresponding author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 701, Taiwan.	pfhsieh@mail.ncku.edu.tw; dswang@altek.com.tw						Bruce LM, 2002, IEEE T GEOSCI REMOTE, V40, P2331, DOI 10.1109/TGRS.2002.804721; Carreira-Perpinan MA, 2000, IEEE T PATTERN ANAL, V22, P1318, DOI 10.1109/34.888716; Choi E, 2001, IEEE T GEOSCI REMOTE, V39, P521, DOI 10.1109/36.911110; Etemad K, 1998, IEEE T IMAGE PROCESS, V7, P1453, DOI 10.1109/83.718485; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; HSIEHPF, 1998, P IEEE INT GEOSC REM, V4, P2050; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; Kaewpijit S, 2003, IEEE T GEOSCI REMOTE, V41, P863, DOI 10.1109/TGRS.2003.810712; Kuo BC, 2002, IEEE T GEOSCI REMOTE, V40, P2486, DOI 10.1109/TGRS.2002.805088; Lee C, 2000, IEEE T GEOSCI REMOTE, V38, P1471, DOI 10.1109/36.843045; LEE CH, 1993, IEEE T PATTERN ANAL, V15, P388, DOI 10.1109/34.206958; Lee HM, 2001, IEEE T SYST MAN CY B, V31, P426, DOI 10.1109/3477.931536; Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13; Loog M, 2001, IEEE T PATTERN ANAL, V23, P762, DOI 10.1109/34.935849; LOOG M, 1999, WBBM REP SER, V44; Lotlikar R, 2000, PATTERN RECOGN, V33, P185, DOI 10.1016/S0031-3203(99)00053-9; Mallet Y, 1997, IEEE T PATTERN ANAL, V19, P1058, DOI 10.1109/34.625106; Pal NR, 1998, IEEE T NEURAL NETWOR, V9, P1142, DOI 10.1109/72.728358; Pittner S, 1999, IEEE T PATTERN ANAL, V21, P83, DOI 10.1109/34.745739; RAO CR, 1948, J ROY STAT SOC B, V10, P159; THAWONMAS R, 1997, IEEE T SYST MAN CYB, V29, P1196	22	33	35	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2006	28	2					223	235		10.1109/TPAMI.2006.26	http://dx.doi.org/10.1109/TPAMI.2006.26			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	991OY	16468619				2022-12-18	WOS:000233824500005
J	Luo, JB; Boutell, M				Luo, JB; Boutell, M			Automatic image orientation detection via confidence-based integration of low-level and semantic cues	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image orientation; semantic cues; low-level cues; Bayesian networks; probabilistic inference; classification confidence	PHOTOGRAPHIC IMAGES	Automatic image orientation detection for natural images is a useful, yet challenging research topic. Humans use scene context and semantic object recognition to identify the correct image orientation. However, it is difficult for a computer to perform the task in the same way because current object recognition algorithms are extremely limited in their scope and robustness. As a result, existing orientation detection methods were built upon low-level vision features such as spatial distributions of color and texture. Discrepant detection rates have been reported for these methods in the literature. We have developed a probabilistic approach to image orientation detection via confidence-based integration of low-level and semantic cues within a Bayesian framework. Our current accuracy is 90 percent for unconstrained consumer photos, impressive given the findings of a psychophysical study conducted recently. The proposed framework is an attempt to bridge the gap between computer and human vision systems and is applicable to other problems involving semantic scene content understanding.	Eastman Kodak Co, Res & Dev Labs, Rochester, NY 14650 USA; Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA	Eastman Kodak; University of Rochester	Luo, JB (corresponding author), Eastman Kodak Co, Res & Dev Labs, Rochester, NY 14650 USA.	jiebo.luo@kodak.com; boutell@cs.rochester.edu	Luo, Jiebo/AAI-7549-2020	Luo, Jiebo/0000-0002-4516-9729				Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1023/A:1022649401552; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; DUIN RPW, 2002, P INT C PATT REC; GOODWIN R, 1997, Patent No. 5642443; Luo JB, 2002, IEEE T IMAGE PROCESS, V11, P201, DOI 10.1109/83.988954; Luo JB, 2004, IMAGE VISION COMPUT, V22, P227, DOI 10.1016/j.imavis.2003.09.012; Luo JB, 2003, SPATIAL VISION, V16, P429, DOI 10.1163/156856803322552757; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; SCHNEIDERMAN H, 2000, CMURITR0006; Scholkopf B., 1999, ADV KERNEL METHODS S; SEGUR R, 2000, P IS T IM PROC IM QU; SINGHAL A, 2003, P IEEE INT C COMP VI; Smith JR, 1999, COMPUT VIS IMAGE UND, V75, P165, DOI 10.1006/cviu.1999.0771; TAX D, 2002, P INT C PATT REC; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Vailaya A, 2002, IEEE T IMAGE PROCESS, V11, P746, DOI 10.1109/TIP2002.801590; VAILAYA A, 2000, P SPIE, V3972; Wang Yongmei, 2001, P IEEE WORKSH CONT B	20	33	36	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2005	27	5					715	726		10.1109/TPAMI.2005.96	http://dx.doi.org/10.1109/TPAMI.2005.96			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	905LI	15875793				2022-12-18	WOS:000227569300005
J	Bressan, M; Vitria, J				Bressan, M; Vitria, J			On the selection and classification of independent features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						feature selection; divergence; independent component analysis; naive Bayes		This paper is focused on the problems of feature selection and classification when classes are modeled by statistically independent features. We show that, under the assumption of class-conditional independence, the class separability measure of divergence is greatly simplified, becoming a sum of unidimensional divergences, providing a feature selection criterion where no exhaustive search is required. Since the hypothesis of independence is infrequently met in practice, we also provide a framework making use of class-conditional Independent Component Analyzers where this assumption can be held on stronger grounds. Divergence and the Bayes decision scheme are adapted to this class-conditional representation. An algorithm that integrates the proposed representation, feature selection technique, and classifier is presented. Experiments on artificial, benchmark, and real-world data illustrate our technique and evaluate its performance.	Univ Autonoma Barcelona, Dept Informat, CVC, Bellaterra 08193, Spain	Autonomous University of Barcelona	Bressan, M (corresponding author), Univ Autonoma Barcelona, Dept Informat, CVC, Bellaterra 08193, Spain.	marco@cvc.uab.es; jordi@cvc.uab.es	Vitrià, Jordi/AAF-9668-2020; Vitria, Jordi/C-7072-2008	Vitrià, Jordi/0000-0003-1484-539X; Vitria, Jordi/0000-0003-1484-539X				BELL A, 1999, NEURAL COMPUT, V11, P1739; Bressan M, 2001, PROC CVPR IEEE, P1004; Cardoso JF, 1996, ISCAS 96: 1996 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - CIRCUITS AND SYSTEMS CONNECTING THE WORLD, VOL 2, P93, DOI 10.1109/ISCAS.1996.540360; Choi JW, 2000, ENDOCR RES, V26, P1; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; *COR CORP, 1990, COR STOCK PHOT LIB; DAWID AP, 1979, J ROY STAT SOC B MET, V41, P1; DECELL H, 1972, P PURD U C MACH PROC, V1; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Hyvarinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71; Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797; KULLBACK S, 1968, INFORMATION THEORY S; Lee TW, 2000, IEEE T PATTERN ANAL, V22, P1078, DOI 10.1109/34.879789; LEWIS DD, 1998, P 10 EUR C MACH LEAR, P4; MARILL T, 1963, IEEE T INFORM THEORY, V9, P11, DOI 10.1109/TIT.1963.1057810; MISKIN J, 2000, THESIS SELWYN COLL C; Newman C. B. D., 1998, UCI REPOSITORY MACHI; SIMPSON EH, 1951, J ROY STAT SOC B, V13, P238; TRUNK GV, 1979, IEEE T PATTERN ANAL, V1, P306, DOI 10.1109/TPAMI.1979.4766926; YANG YM, 2002, J INTELLIGENT INFORM	22	33	37	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2003	25	10					1312	1317		10.1109/TPAMI.2003.1233904	http://dx.doi.org/10.1109/TPAMI.2003.1233904			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	723ZE					2022-12-18	WOS:000185460800010
J	Peng, HC; Long, F; Chi, ZR				Peng, HC; Long, F; Chi, ZR			Document image recognition based on template matching of Component Block Projections	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document image recognition; template matching; component block projection		Document Image Recognition (DIR), a very useful technique in office automation and digital library applications, is to find the most similar template for any input document image in a prestored template document image data set. Existing methods use both local features and global layout information. In this paper, we propose a novel algorithm based on the global matching of Component Block Projections (CBP), which are the concatenated directional projection vectors of the component blocks of a document image. Compared to those existing methods, CBP-based template-matching methods possess two major advantages: 1) The spatial relationship among the component blocks of a document image is better represented, hence a very high matching accuracy can be obtained even for a large template set and seriously distorted input images; and 2) the effective matching distance of each template and the triangle inequality are proposed to significantly reduce the computational cost. Our experimental results confirm these advantages and show that the CBP-based template-matching methods are very suitable for DIR applications.	Univ Calif Berkeley, Lawrence Berkeley Lab, MERSC Div, Berkeley, CA 94720 USA; Johns Hopkins Univ, Sch Med, Dept Radiol, Ctr Biomed Image Comp, Baltimore, MD 21287 USA; Duke Univ, Med Ctr, Durham, NC 27710 USA; Hong Kong Polytech Univ, Dept Elect & Informat Engn, Ctr Multimedia Signal Proc, Hong Kong, Hong Kong, Peoples R China	United States Department of Energy (DOE); Lawrence Berkeley National Laboratory; University of California System; University of California Berkeley; Johns Hopkins University; Duke University; Hong Kong Polytechnic University	Peng, HC (corresponding author), Univ Calif Berkeley, Lawrence Berkeley Lab, MERSC Div, 1 Cyclotron Rd,MS 50F, Berkeley, CA 94720 USA.	hpeng@lbl.gov; long@neuro.dtike.edu; enzheru@polyu.edu.hk	Peng, Hanchuan/A-1798-2011	Chi, Zheru/0000-0003-0714-8713				Adjeroh DA, 2001, IEEE T IMAGE PROCESS, V10, P36, DOI 10.1109/83.892441; Braunmuller B, 2001, IEEE T KNOWL DATA EN, V13, P79, DOI 10.1109/69.908982; Cesarini F, 1998, IEEE T PATTERN ANAL, V20, P730, DOI 10.1109/34.689303; Cheng YT, 2000, J MICROELECTROMECH S, V9, P3, DOI 10.1109/84.825770; Doermann D, 1997, PROC INT CONF DOC, P314, DOI 10.1109/ICDAR.1997.619863; Fan KC, 1998, INT C PATT RECOG, P1098, DOI 10.1109/ICPR.1998.711885; FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297; HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417; HU J, 1999, P 5 INT C DOC AN REC, P285; Hull J. J., 1998, International Journal on Document Analysis and Recognition, V1, P37; Lopresti D. P., 2000, International Journal on Document Analysis and Recognition, V2, P186, DOI 10.1007/s100320050005; PENG H, 2000, P 2000 INT WORKSH MU, P203; PENG H, 2000, P 2000 INT WORKSH MU, P197; Peng HC, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P601, DOI 10.1109/ICIP.2000.899505; Peng HC, 2001, PATTERN RECOGN LETT, V22, P1033, DOI 10.1016/S0167-8655(01)00049-6; Puzicha J., 1999, P IEEE INT C COMP VI, P1165, DOI DOI 10.1109/ICCV.1999.790412; Safari R, 1997, IEEE T IMAGE PROCESS, V6, P1337, DOI 10.1109/83.623198; Shimotsuji S., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P793, DOI 10.1109/ICPR.1996.547277; TSENG L, 1997, P 4 INT C DOC AN REC, V1, P71; WATANABE T, 1995, IEEE T PATTERN ANAL, V17, P432, DOI 10.1109/34.385976	20	33	37	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2003	25	9					1188	1192		10.1109/TPAMI.2003.1227996	http://dx.doi.org/10.1109/TPAMI.2003.1227996			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	715MX					2022-12-18	WOS:000184977300015
J	Avidan, S; Shashua, A				Avidan, S; Shashua, A			Threading fundamental matrices	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						structure-form-motion; multiview geometry	AFFINE; MOTION; VISION	We present a new function that operates on Fundamental matrices across a sequence of views. The operation, we calf "threading", connects two consecutive Fundamental matrices using the trifocal tensor as the connecting thread. The threading operation guarantees that consecutive camera matrices are consistent with a unique 3D model, without ever recovering a 3D model. Applications include recovery of camera ego-motion from a sequence of views, image stabilization (plane stabilization) across a sequence, and multiview image-based rendering.	Hebrew Univ Jerusalem, Inst Comp Sci, IL-91904 Jerusalem, Israel	Hebrew University of Jerusalem	Avidan, S (corresponding author), Hebrew Univ Jerusalem, Inst Comp Sci, IL-91904 Jerusalem, Israel.	avidan@cs.huji.ac.il; shashua@cs.huji.ac.il						AVIDAN S, 1998, 3D STRUCT MULT IM LA; Beardsley PA, 1997, INT J COMPUT VISION, V23, P235, DOI 10.1023/A:1007923216416; FAUGERAS O, 1995, J OPT SOC AM A, V12, P465, DOI 10.1364/JOSAA.12.000465; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; IRANI M, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P454, DOI 10.1109/CVPR.1994.323866; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; ROUSSO B, 1996, P IEEE C COMP VIS PA; SHASHUA A, 1995, IEEE T PATTERN ANAL, V17, P779, DOI 10.1109/34.400567; SHASHUA A, 1997, ALGEBRAIC FRAMES PER; SHASHUA A, 1996, P EUR C COMP VIS APR; SHI J, 1994, P IEEE C COMP VIS PA, P593, DOI DOI 10.1109/CVPR.1994.323794; Sturm P., 1996, P EUR C COMP VIS; Vieville T, 1996, INT J COMPUT VISION, V17, P7, DOI 10.1007/BF00127817; ZELNIKMANOR L, 1999, P IEEE C COMP VIS PA	15	33	43	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2001	23	1					73	77		10.1109/34.899947	http://dx.doi.org/10.1109/34.899947			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	390VA					2022-12-18	WOS:000166316700006
J	Bajcsy, P; Ahuja, N				Bajcsy, P; Ahuja, N			Location- and density-based hierarchical clustering using similarity analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						point patterns; clustering; hierarchy of clusters; spatially interleaved clusters; density-based clustering; location-based clustering	ALGORITHM; TEXTURE; IMAGES	This paper presents a new approach to hierarchical clustering of point patterns. Two algorithms for hierarchical location- and density-based clustering are developed. Each method groups points such that maximum intracluster similarity and intercluster dissimilarity are achieved for point locations or point separations. Performance of the clustering methods is compared with four other methods. The approach is applied to a two-step texture analysis, where points represent centroid and average color of the regions in image segmentation.	Cognex Corp, Acumen Prod Grp, Portland, OR 97062 USA; Univ Illinois, Urbana, IL 61801 USA	University of Illinois System; University of Illinois Urbana-Champaign	Bajcsy, P (corresponding author), Cognex Corp, Acumen Prod Grp, 7352 SW Durham Rd, Portland, OR 97062 USA.			Bajcsy, Peter/0000-0002-6968-2615				AHUJA N, 1983, PATTERN MODELS; BAJCSY P, 1996, P 13 INT C PATT REC, VB, P96; BLOSTEIN D, 1989, IEEE T PATTERN ANAL, V11, P1233, DOI 10.1109/34.41363; Duda R.O., 1973, J ROYAL STAT SOC SER; Everitt B., 1993, CLUSTER ANAL, V3rd; Fotheringham AS, 1996, GEOGR ANAL, V28, P200; Getis A., 1978, MODELS SPATIAL PROCE; GOWDA KC, 1978, PATTERN RECOGN, V10, P105; HANAIZUMI H, 1995, IEEE T INSTRUM MEAS, V44, P759, DOI 10.1109/19.387326; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Kendall M., 1951, ADV THEORY STAT, V2; NADLER M, 1993, PATTERN RECOGNITION; Sneath PHA, 1973, NUMERICAL TAXONOMY P; TUCERYAN M, 1990, IEEE T PATTERN ANAL, V12, P211, DOI 10.1109/34.44407; WONG YF, 1993, IEEE T GEOSCI REMOTE, V31, P634, DOI 10.1109/36.225530; ZAHN CT, 1971, IEEE T COMPUT, VC 20, P68, DOI 10.1109/T-C.1971.223083	16	33	34	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1998	20	9					1011	1015		10.1109/34.713365	http://dx.doi.org/10.1109/34.713365			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	117AX					2022-12-18	WOS:000075758500008
