PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	Kong, Y; Tao, ZQ; Fu, Y				Kong, Yu; Tao, Zhiqiang; Fu, Yun			Adversarial Action Prediction Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Action prediction; action recognition; sequential context; variational autoencoder; adversarial learning		Different from after-the-fact action recognition, action prediction task requires action labels to be predicted from partially observed videos containing incomplete action executions. It is challenging because these partial videos have insufficient discriminative information, and their temporal structure is damaged. We study this problem in this paper, and propose an efficient and powerful deep network for learning representative and discriminative features for action prediction. Our approach exploits abundant sequential context information in full videos to enrich the feature representations of partial videos. This information is encoded in latent representations using a variational autoencoder (VAE), which are encouraged to be progress-invariant. Decoding such latent representations using another VAE, we can reconstruct missing information in the features extracted from partial videos. An adversarial learning scheme is adopted to differentiate the reconstructed features from the features directly extracted from full videos in order to well align their distributions. A multi-class classifier is also used to encourage the features to be discriminative. Our network jointly learns features and classifiers, and generates the features particularly optimized for action prediction. Extensive experimental results on UCF101, Sports-1M and BIT datasets demonstrate that our approach remarkably outperforms state-of-the-art methods, and shows significant speedup over these methods. Results also show that actions differ in their prediction characteristics; some actions can be correctly predicted even though only the beginning 10% portion of videos is observed.	[Kong, Yu] Rochester Inst Technol, B Thomas Golisano Coll Comp & Informat Sci, Rochester, NY 14623 USA; [Kong, Yu; Tao, Zhiqiang; Fu, Yun] Northeastern Univ, Dept ECE, Boston, MA 02115 USA; [Fu, Yun] Northeastern Univ, Coll CIS, Boston, MA 02115 USA	Rochester Institute of Technology; Northeastern University; Northeastern University	Kong, Y (corresponding author), Rochester Inst Technol, B Thomas Golisano Coll Comp & Informat Sci, Rochester, NY 14623 USA.; Kong, Y (corresponding author), Northeastern Univ, Dept ECE, Boston, MA 02115 USA.	yu.kong@rit.edu; zqtao@ece.neu.edu; yunfu@ece.neu.edu		Fu, Yun/0000-0002-5098-2853	NSF IIS [1651902]; U.S. Army Research Office [W911NF-17-1-0367]	NSF IIS(National Science Foundation (NSF)); U.S. Army Research Office	This research is supported in part by the NSF IIS Award 1651902 and U.S. Army Research Office Award W911NF-17-1-0367.	Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110; [Anonymous], [No title captured]; [Anonymous], 2016, P INT C LEARN REPR; [Anonymous], 2018, P IEEE C COMP VIS PA; [Anonymous], 2018, P IEEE C COMP VIS PA; [Anonymous], [No title captured]; [Anonymous], 2018, P IEEE C COMP VIS PA; Cao Y, 2013, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2013.343; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Chen M., 2012, ARXIV12064683; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714; Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Kingma D.P., 2014, P 2 INT C LEARN REPR, DOI DOI 10.1093/BIOINFORMATICS/BTAA169; Kitani KM, 2012, LECT NOTES COMPUT SC, V7575, P201, DOI 10.1007/978-3-642-33765-9_15; Kong Y, 2017, PROC CVPR IEEE, P3662, DOI 10.1109/CVPR.2017.390; Kong Y, 2016, IEEE T PATTERN ANAL, V38, P1844, DOI 10.1109/TPAMI.2015.2491928; Kong Y, 2014, LECT NOTES COMPUT SC, V8693, P596, DOI 10.1007/978-3-319-10602-1_39; Kong Y, 2014, IEEE T PATTERN ANAL, V36, P1775, DOI 10.1109/TPAMI.2014.2303090; Lan T, 2014, LECT NOTES COMPUT SC, V8691, P689, DOI 10.1007/978-3-319-10578-9_45; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Letham B, 2013, MACH LEARN, V93, P357, DOI 10.1007/s10994-013-5356-5; Li Kang, 2014, IEEE Trans Pattern Anal Mach Intell, V36, P1644, DOI 10.1109/TPAMI.2013.2297321; Ma SG, 2016, PROC CVPR IEEE, P1942, DOI 10.1109/CVPR.2016.214; Hoai M, 2012, PROC CVPR IEEE, P2863, DOI 10.1109/CVPR.2012.6248012; Ni BB, 2015, PROC CVPR IEEE, P3698, DOI 10.1109/CVPR.2015.7298993; Pei MT, 2011, IEEE I CONF COMP VIS, P487, DOI 10.1109/ICCV.2011.6126279; Raptis M, 2013, PROC CVPR IEEE, P2650, DOI 10.1109/CVPR.2013.342; Rudin Cynthia, 2011, P 24 ANN C LEARN THE, V19, P615; Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349; Schindler K, 2008, PROC CVPR IEEE, P3025; Simonyan K, 2014, ADV NEUR IN, V27; Singh G, 2017, IEEE I CONF COMP VIS, P3657, DOI 10.1109/ICCV.2017.393; Soomro K., 2012, COMPUT SCI; Tian YC, 2013, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2013.341; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vondrick C, 2016, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.2016.18; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2; Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059; Wu BX, 2014, PROC CVPR IEEE, P2609, DOI 10.1109/CVPR.2014.334; Yang Y, 2012, LECT NOTES COMPUT SC, V7574, P722, DOI 10.1007/978-3-642-33712-3_52; Zhou Y, 2015, PROC CVPR IEEE, P3323, DOI 10.1109/CVPR.2015.7298953; Zhou YP, 2015, IEEE I CONF COMP VIS, P4498, DOI 10.1109/ICCV.2015.511; Zhu WJ, 2016, PROC CVPR IEEE, P1991, DOI 10.1109/CVPR.2016.219	50	18	18	1	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2020	42	3					539	553		10.1109/TPAMI.2018.2882805	http://dx.doi.org/10.1109/TPAMI.2018.2882805			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LC5KN	30475711				2022-12-18	WOS:000525365300002
J	Kayabol, K				Kayabol, Koray			Approximate Sparse Multinomial Logistic Regression for Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Logistics; Hyperspectral imaging; Approximation algorithms; Taylor series; Standards; Estimation; Convergence; Sparse multinomial logistic regression; softmax; hyperspectral images; classification		We propose a new learning rule for sparse multinomial logistic regression (SMLR). The new rule is the generalization of the one proposed in the pioneering work by Krishnapuram et al. In our proposed method, the parameters of SMLR are iteratively estimated from log-posterior by using some approximations. The proposed update rule provides a faster convergence compared to the state-of the-art methods used for SMLR parameter estimation. The estimated parameters are tested on the pixel-based classification of hyperspectral images. The experimental results on real hyperspectral images show that the classification accuracy of proposed method is also better than those of the state-of-the-art methods.	[Kayabol, Koray] Gebze Tech Univ, Dept Elect Engn, TR-41400 Kocaeli, Turkey	Gebze Technical University	Kayabol, K (corresponding author), Gebze Tech Univ, Dept Elect Engn, TR-41400 Kocaeli, Turkey.	koray.kayabol@gtu.edu.tr			Scientific and Technological Research Council of Turkey (TUBITAK) [114E535]	Scientific and Technological Research Council of Turkey (TUBITAK)(Turkiye Bilimsel ve Teknolojik Arastirma Kurumu (TUBITAK))	The author would like to thank David Landgrebe and Paolo Gamba for providing hyperspectral data sets, and Jun Li and Jose M. Bioucas-Dias for providing their codes online. This work is supported by Scientific and Technological Research Council of Turkey (TUBITAK) under Project No. 114E535.	Bioucas-Dias J., 2009, LOGISTIC REGRESSION; Bishop C.M, 2006, PATTERN RECOGN; BOHNING D, 1992, ANN I STAT MATH, V44, P197, DOI 10.1007/bf00048682; BOHNING D, 1988, ANN I STAT MATH, V40, P641, DOI 10.1007/BF00049423; Borges JS, 2006, LECT NOTES COMPUT SC, V4142, P700; Borges JS, 2011, IEEE T GEOSCI REMOTE, V49, P2151, DOI 10.1109/TGRS.2010.2097268; Goodfellow I., 2016, DEEP LEARNING; Krishnapuram B, 2005, IEEE T PATTERN ANAL, V27, P957, DOI 10.1109/TPAMI.2005.127; Lange K, 2000, J COMPUT GRAPH STAT, V9, P1, DOI 10.2307/1390605; Li J, 2011, IEEE T GEOSCI REMOTE, V49, P3947, DOI 10.1109/TGRS.2011.2128330; Quarteroni A., 2000, NUMERICAL MATH; SHOR NZ, 1985, MINIMIZATION METHODS	12	18	20	3	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2020	42	2					490	493		10.1109/TPAMI.2019.2904062	http://dx.doi.org/10.1109/TPAMI.2019.2904062			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KE2KB	30869609				2022-12-18	WOS:000508386100018
J	Kacem, A; Daoudi, M; Ben Amor, B; Berretti, S; Alvarez-Paiva, JC				Kacem, Anis; Daoudi, Mohamed; Ben Amor, Boulbaba; Berretti, Stefano; Alvarez-Paiva, Juan Carlos			A Novel Geometric Framework on Gram Matrix Trajectories for Human Behavior Understanding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Trajectory; Manifolds; Three-dimensional displays; Shape; Emotion recognition; Skeleton; Covariance matrices; Landmark configurations; gram matrices; riemannian geometry; symmetric positive semidefinite manifolds; grassmann manifold; action recognition; emotion recognition from body movements; facial expression recognition	POSITIVE SEMIDEFINITE MATRICES; RATE-INVARIANT ANALYSIS; RIEMANNIAN-MANIFOLDS; RECOGNITION; TIME; PARTS	In this paper, we propose a novel space-time geometric representation of human landmark configurations and derive tools for comparison and classification. We model the temporal evolution of landmarks as parametrized trajectories on the Riemannian manifold of positive semidefinite matrices of fixed-rank. Our representation has the benefit to bring naturally a second desirable quantity when comparing shapes-the spatial covariance-in addition to the conventional affine-shape representation. We derived then geometric and computational tools for rate-invariant analysis and adaptive re-sampling of trajectories, grounding on the Riemannian geometry of the underlying manifold. Specifically, our approach involves three steps: (1) landmarks are first mapped into the Riemannian manifold of positive semidefinite matrices of fixed-rank to build time-parameterized trajectories; (2) a temporal warping is performed on the trajectories, providing a geometry-aware (dis-)similarity measure between them; (3) finally, a pairwise proximity function SVM is used to classify them, incorporating the (dis-)similarity measure into the kernel function. We show that such representation and metric achieve competitive results in applications as action recognition and emotion recognition from 3D skeletal data, and facial expression recognition from videos. Experiments have been conducted on several publicly available up-to-date benchmarks.	[Kacem, Anis; Daoudi, Mohamed; Ben Amor, Boulbaba] Univ Lille, IMT Lille Douai, Lille, France; [Kacem, Anis] CNRS, UMR 9189, CRIStAL Lab, 3DSAM Res Team, Lille, France; [Daoudi, Mohamed] CNRS, UMR 9189, CRIStAL Lab, Image Grp, Lille, France; [Ben Amor, Boulbaba] CNRS, UMR 9189, CRIStAL Lab, Lille, France; [Berretti, Stefano] Univ Florence, I-50121 Florence, Italy; [Alvarez-Paiva, Juan Carlos] Univ Lille, Math, F-59655 Villeneuve Dascq, France; [Alvarez-Paiva, Juan Carlos] CNRS, UMR 8524, Painleve Lab, F-59655 Villeneuve Dascq, France	IMT - Institut Mines-Telecom; IMT Nord Europe; Universite de Lille - ISITE; Universite de Lille; Centre National de la Recherche Scientifique (CNRS); Universite de Lille - ISITE; Centrale Lille; Universite de Lille; Centre National de la Recherche Scientifique (CNRS); Universite de Lille - ISITE; Centrale Lille; Universite de Lille; Centre National de la Recherche Scientifique (CNRS); Universite de Lille - ISITE; Centrale Lille; Universite de Lille; University of Florence; Universite de Lille - ISITE; Universite de Lille; Centre National de la Recherche Scientifique (CNRS); CNRS - National Institute for Mathematical Sciences (INSMI)	Kacem, A (corresponding author), Univ Lille, IMT Lille Douai, Lille, France.; Kacem, A (corresponding author), CNRS, UMR 9189, CRIStAL Lab, 3DSAM Res Team, Lille, France.	mohamed.daoudi@imt-lille-douai.fr; boulbaba.benamor@imt-lille-douai.fr; anis.kacem@imt-lille-douai.fr; stefano.berretti@unifi.it; juan-carlos.alvarez-paiva@math.univ-lille1.fr	Ben Amor, Boulbaba/K-7066-2018; Daoudi, Mohammed/H-5935-2013	Ben Amor, Boulbaba/0000-0002-4176-9305; Berretti, Stefano/0000-0003-1219-4386; kacem, anis/0000-0003-0640-9862; Daoudi, Mohammed/0000-0003-4219-7860	PIA, ANR [ANR-11-EQPX-0023]	PIA, ANR(French National Research Agency (ANR))	We thank Professor Yvonne Delevoye for fruitful discussions on emotion from 3D human dynamics. This work has been partially supported by PIA, ANR (grant ANR-11-EQPX-0023).	Abdelkader MF, 2011, COMPUT VIS IMAGE UND, V115, P439, DOI 10.1016/j.cviu.2010.10.006; Anirudh R, 2017, IEEE T PATTERN ANAL, V39, P922, DOI 10.1109/TPAMI.2016.2564409; [Anonymous], COMPUT VIS IMAGE UND; [Anonymous], 2009, GEOMETRY CUTS METRIC; Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240; Bagheri M, 2016, 2016 INTERNATIONAL CONFERENCE ON SMART GREEN TECHNOLOGY IN ELECTRICAL AND INFORMATION SYSTEMS (ICSGTEIS), P10, DOI 10.1109/ICSGTEIS.2016.7885758; Begelfor E., 2006, 2006 IEEE COMPUTER S, V2, P2087, DOI DOI 10.1109/CVPR.2006.50; Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257; Berretti S, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3182179; Bonnabel S, 2009, SIAM J MATRIX ANAL A, V31, P1055, DOI 10.1137/080731347; Cavazza J, 2016, INT C PATT RECOG, P408, DOI 10.1109/ICPR.2016.7899668; Chang C.-C., 2011, ACM T INTEL SYST TEC, V2, P1, DOI [10.1145/1961189.1961199, DOI 10.1145/1961189.1961199]; Cuturi M., 2011, P 28 INT C MACH LEAR, P929; Daoudi M, 2017, LECT NOTES COMPUT SC, V10484, P550, DOI 10.1007/978-3-319-68560-1_49; Devanne M, 2015, IEEE T CYBERNETICS, V45, P1340, DOI 10.1109/TCYB.2014.2350774; Dhall A, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P371, DOI 10.1145/2522848.2531749; Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26; Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714; Elaiwat S, 2016, PATTERN RECOGN, V49, P152, DOI 10.1016/j.patcog.2015.07.006; Graepel T, 1999, ADV NEUR IN, V11, P438; Gudmundsson S, 2008, IEEE IJCNN, P2772, DOI 10.1109/IJCNN.2008.4634188; Hicheur H., 2013, MODELING SIMULATION, P71, DOI [DOI 10.1007/978-3-642-36368-9_, 10.1007/978-3-642-36368-9_6, DOI 10.1007/978-3-642-36368-9_6]; HIGHAM NJ, 1986, SIAM J SCI STAT COMP, V7, P1160, DOI 10.1137/0907079; Hu JF, 2016, LECT NOTES COMPUT SC, V9905, P280, DOI 10.1007/978-3-319-46448-0_17; Hu JF, 2015, PROC CVPR IEEE, P5344, DOI 10.1109/CVPR.2015.7299172; Huang WB, 2016, PROC CVPR IEEE, P3938, DOI 10.1109/CVPR.2016.427; Ioannidou A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3042064; Jain S., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1642, DOI 10.1109/ICCVW.2011.6130446; Jayasumana S, 2015, IEEE T PATTERN ANAL, V37, P2464, DOI 10.1109/TPAMI.2015.2414422; Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341; Kacem A, 2017, IEEE I CONF COMP VIS, P3199, DOI 10.1109/ICCV.2017.345; Ke QH, 2017, IEEE SIGNAL PROC LET, V24, P731, DOI 10.1109/LSP.2017.2690339; Klaser A., 2008, SPATIO TEMPORAL DESC, DOI 10.5244/C.22.99; Kobayashi S., 1963, FDN DIFFERENTIAL GEO, VVolume 1; Li BL, 2012, PROC CVPR IEEE, P1362, DOI 10.1109/CVPR.2012.6247822; Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50; Liu MY, 2015, LECT NOTES COMPUT SC, V9006, P143, DOI 10.1007/978-3-319-16817-3_10; Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226; Liu Z, 2016, IMAGE VISION COMPUT, V55, P93, DOI 10.1016/j.imavis.2016.04.004; Lucey P., 2010, P IEEE COMP SOC C CO, P94, DOI [10.1109/CVPRW.2010.5543262, DOI 10.1109/CVPRW.2010.5543262]; Matikainen Pyry, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P514, DOI 10.1109/ICCVW.2009.5457659; Meyer G, 2011, J MACH LEARN RES, V12, P593; Porikli Fatih, 2016, 2016 IEEE TRANSP EL, P1; Salvadora S, 2007, INTELL DATA ANAL, V11, P561, DOI 10.3233/IDA-2007-11508; Sariyanidi E, 2017, IEEE T IMAGE PROCESS, V26, P1965, DOI 10.1109/TIP.2017.2662237; Scovanner P., 2007, ACM MM, P357; Seidenari L, 2013, IEEE COMPUT SOC CONF, P479, DOI 10.1109/CVPRW.2013.77; Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115; Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381; Slama R, 2015, PATTERN RECOGN, V48, P556, DOI 10.1016/j.patcog.2014.08.011; Song SJ, 2017, AAAI CONF ARTIF INTE, P4263; Su JY, 2014, PROC CVPR IEEE, P620, DOI 10.1109/CVPR.2014.86; Su JY, 2014, ANN APPL STAT, V8, P530, DOI 10.1214/13-AOAS701; Taheri S., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P306, DOI 10.1109/FG.2011.5771415; Turaga P, 2011, IEEE T PATTERN ANAL, V33, P2273, DOI 10.1109/TPAMI.2011.52; Valstar M., 2010, P 3 INT WORKSH EMOTI, P65; Vandereycken B, 2009, 2009 IEEE/SP 15TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING, VOLS 1 AND 2, P389, DOI 10.1109/SSP.2009.5278558; Veeraraghavan A, 2006, 2006 IEEE COMPUTER S, V1, P959; Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460; Vemulapalli R, 2016, PROC CVPR IEEE, P4471, DOI 10.1109/CVPR.2016.484; Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82; Venkataraman V, 2016, IEEE T PATTERN ANAL, V38, P2531, DOI 10.1109/TPAMI.2016.2533388; Wang CY, 2016, PROC CVPR IEEE, P2639, DOI 10.1109/CVPR.2016.289; Wang L, 2015, IEEE I CONF COMP VIS, P4570, DOI 10.1109/ICCV.2015.519; Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965; Wang ZH, 2013, PROC CVPR IEEE, P3422, DOI 10.1109/CVPR.2013.439; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yun Kiwon, 2012, 2012 IEEE COMP SOC C, P28; Zafeiriou L, 2016, PROC CVPR IEEE, P3382, DOI 10.1109/CVPR.2016.368; Zhang SY, 2017, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2017.24; Zhang XK, 2016, PROC CVPR IEEE, P4498, DOI 10.1109/CVPR.2016.487; Zhang YP, 2012, IEEE VTS VEH TECHNOL; Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110; Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002; Zhong L, 2012, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR.2012.6247974; Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885	76	18	19	2	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2020	42	1					1	14		10.1109/TPAMI.2018.2872564	http://dx.doi.org/10.1109/TPAMI.2018.2872564			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JV3VQ	30281437	Green Submitted			2022-12-18	WOS:000502294300001
J	Wang, YH; Xu, C; Xu, C; Tao, DC				Wang, Yunhe; Xu, Chang; Xu, Chao; Tao, Dacheng			Packing Convolutional Neural Networks in the Frequency Domain	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CNN compression; discrete cosine transform; frequency domain speed-up; DCT bases		Deep convolutional neural networks (CNNs) are successfully used in a number of applications. However, their storage and computational requirements have largely prevented their widespread use on mobile devices. Here we present a series of approaches for compressing and speeding up CNNs in the frequency domain, which focuses not only on smaller weights but on all the weights and their underlying connections. By treating convolution filters as images, we decompose their representations in the frequency domain as common parts (i.e., cluster centers) shared by other similar filters and their individual private parts (i.e., individual residuals). A large number of low-energy frequency coefficients in both parts can be discarded to produce high compression without significantly compression romising accuracy. Furthermore, we explore a data-driven method for removing redundancies in both spatial and frequency domains, which allows us to discard more useless weights by keeping similar accuracies. After obtaining the optimal sparse CNN in the frequency domain, we relax the computational burden of convolution operations in CNNs by linearly combining the convolution responses of discrete cosine transform (DCT) bases. The compression and speed-up ratios of the proposed algorithm are thoroughly analyzed and evaluated on benchmark image datasets to demonstrate its superiority over state-of-the-art methods.	[Wang, Yunhe; Xu, Chao] Peking Univ, Key Lab Machine Percept, Minist Educ, Sch EECS, Beijing 100871, Peoples R China; [Wang, Yunhe; Xu, Chao] Peking Univ, Cooperat Medianet Innovat Ctr, Sch EECS, Beijing 100871, Peoples R China; [Xu, Chang; Tao, Dacheng] Univ Sydney, Fac Engn & Informat Technol, Sch Informat Technol, UBTech Sydney Artificial Intelligence Ctr, J12,6 Cleveland, Darlington, NSW 2008, Australia	Peking University; Peking University; University of Sydney	Xu, C (corresponding author), Univ Sydney, Fac Engn & Informat Technol, Sch Informat Technol, UBTech Sydney Artificial Intelligence Ctr, J12,6 Cleveland, Darlington, NSW 2008, Australia.	yunhe.wang@huawei.com; c.xu@sydney.edu.au; xuchao@cis.pku.edu.cn; dacheng.tao@sydney.edu.au	Xu, Chang/AAG-9337-2019	Xu, Chang/0000-0002-4756-0609	National Natural Science Foundation of China [NSFC 61375026, 2015BAF15B00]; Australian Research Council [FL-170100117, DE-180101438, DP-180103424, LP-150100671]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Australian Research Council(Australian Research Council)	This work was supported in part by National Natural Science Foundation of China under Grant NSFC 61375026 and 2015BAF15B00, and in part by Australian Research Council Projects: FL-170100117, DE-180101438, DP-180103424, and LP-150100671.	AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784; [Anonymous], 1989, ADV NEURAL INFORM PR; Arora S, 2014, PR MACH LEARN RES, V32; Bagherinezhad H, 2017, PROC CVPR IEEE, P860, DOI 10.1109/CVPR.2017.98; Bell N, 2009, STUDENTS GUIDE TO THE MA TESOL, P1; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Courbariaux M., 2015, ADV NEURAL INFORM PR, P3123, DOI DOI 10.1109/TWC.2016.2633262; Denil M., 2013, ADV NEURAL INFORM PR, P2148, DOI DOI 10.5555/2999792.2999852; Dentinel Zarembaw, 2014, NEURIPS, P1269; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Figurnov Mikhail, 2016, NEURIPS; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Gong Yunchao, 2014, ARXIV14126115; Han S., 2016, P 4 INT C LEARN REPR, P1; Han Song, 2015, ADV NEURAL INFORM PR, P1135, DOI DOI 10.5555/2969239.2969366; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Hubara I, 2016, ADV NEUR IN, V29; HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898; Hwang K, 2014, IEEE WRK SIG PRO SYS, P174; Jaderberg Max, 2014, P BRIT MACH VIS C, P2, DOI DOI 10.5244/C.28.88; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Kim Y., 2016, ICLR; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lin Z., 2011, PROC INT 25 C NEURAL, P612, DOI DOI 10.1007/S11263-013-0611-6; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lu HY, 2015, PROC CVPR IEEE, P806, DOI 10.1109/CVPR.2015.7298681; Lyu HL, 2015, CHIN CONT DECIS CONF, P2885; Mahendran A, 2016, INT J COMPUT VISION, V120, P233, DOI 10.1007/s11263-016-0911-8; MAIRAL J., 2009, P 26 ANN INT C MACH, P689, DOI [10.1145/1553374.1553463, DOI 10.1145/1553374.1553463]; Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rippel Oren, 2015, ARXIV150603767; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Stork D.G., 1993, ADV NEURAL INF PROCE, P164; Sudorgin SA, 2015, CHEMICAL AND BIOCHEMICAL TECHNOLOGY: MATERIALS, PROCESSING, AND RELIABILITY, P1; Sun Y., 2014, ADV NEURAL INFORM PR, P1988; Szegedy C., 2016, P IEEE C COMP VIS PA, P2818, DOI DOI 10.1109/CVPR.2016.308; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Vanhoucke V., 2011, P ADV NEUR INF PROC, P1; Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412; WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089; Wan L., 2013, P INT C MACHINE LEAR, P1058; Wang J, 2016, INT J MOD PHYS B, V30, DOI 10.1142/S0217979215502537; Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929; Wen W, 2016, ADV NEUR IN, V29; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Xu L., 2014, INT C NEUR INF PROC, V27, P1790; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53	52	18	19	2	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2019	41	10					2495	2510		10.1109/TPAMI.2018.2857824	http://dx.doi.org/10.1109/TPAMI.2018.2857824			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD1VC	30028693	Green Accepted			2022-12-18	WOS:000489763000016
J	Wang, CY; Wang, YZ; Lin, ZC; Yuille, AL				Wang, Chunyu; Wang, Yizhou; Lin, Zhouchen; Yuille, Alan L.			Robust 3D Human Pose Estimation from Single Images or Video Sequences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D human pose estimation; sparse basis; anthropometric constraints; L-1- norm penalty function	ARTICULATED OBJECTS; BODY POSE; TRACKING	We propose a method for estimating 3D human poses from single images or video sequences. The task is challenging because: (a) many 3D poses can have similar 2D pose projections which makes the lifting ambiguous, and (b) current 2D joint detectors are not accurate which can cause big errors in 3D estimates. We represent 3D poses by a sparse combination of bases which encode structural pose priors to reduce the lifting ambiguity. This prior is strengthened by adding limb length constraints. We estimate the 3D pose by minimizing an L-1 norm measurement error between the 2D pose and the 3D pose because it is less sensitive to inaccurate 2D poses. We modify our algorithm to output K 3D pose candidates for an image, and for videos, we impose a temporal smoothness constraint to select the best sequence of 3D poses from the candidates. We demonstrate good results on 3D pose estimation from static images and improved performance by selecting the best 3D pose from the K proposals. Our results on video sequences also show improvements (over static images) of roughly 15%.	[Wang, Chunyu; Wang, Yizhou; Lin, Zhouchen] Peking Univ, Sch EECS, MOE, Key Lab Machine Percept, Beijing 100871, Peoples R China; [Wang, Yizhou; Lin, Zhouchen] Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Shanghai 200240, Peoples R China; [Yuille, Alan L.] Johns Hopkins Univ, Baltimore, MD 21218 USA	Peking University; Shanghai Jiao Tong University; Johns Hopkins University	Wang, YZ (corresponding author), Peking Univ, Sch EECS, MOE, Key Lab Machine Percept, Beijing 100871, Peoples R China.; Wang, YZ (corresponding author), Shanghai Jiao Tong Univ, Cooperat Medianet Innovat Ctr, Shanghai 200240, Peoples R China.	wangchunyu@pku.edu.cn; Yizhou.Wang@pku.edu.cn; zlin@pku.edu.cn; alan.yuille@jhu.edu		Yuille, Alan L./0000-0001-5207-9249	National Basic Research Program of China (973 Program) [2015CB351800]; National Natural Science Foundation (NSF) of China [61625201, 61527804]; 973 Program [2015CB352502]; NSF of China [61625301, 61731018]; Qualcomm; Microsoft Research Asia; Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/ Interior Business Center (DOI/IBC) [D17PC00345]	National Basic Research Program of China (973 Program)(National Basic Research Program of China); National Natural Science Foundation (NSF) of China(National Natural Science Foundation of China (NSFC)); 973 Program(National Basic Research Program of China); NSF of China(National Natural Science Foundation of China (NSFC)); Qualcomm; Microsoft Research Asia(Microsoft); Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/ Interior Business Center (DOI/IBC)	Y. Wang was supported by National Basic Research Program of China (973 Program) (grant no. 2015CB351800), National Natural Science Foundation (NSF) of China (grant nos. 61625201 and 61527804). Z. Lin was supported by 973 Program (grant no. 2015CB352502), NSF of China (grant nos. 61625301 and 61731018), Qualcomm, and Microsoft Research Asia. A. Yuille was supported by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/ Interior Business Center (DOI/IBC) contract number D17PC00345.	Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21; Akhter I, 2015, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2015.7298751; Barron C, 2000, PROC CVPR IEEE, P669, DOI 10.1109/CVPR.2000.855884; Batra D, 2012, LECT NOTES COMPUT SC, V7576, P1, DOI 10.1007/978-3-642-33715-4_1; Bo LF, 2010, INT J COMPUT VISION, V87, P28, DOI 10.1007/s11263-008-0204-y; Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34; CAMPBELL LW, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P624, DOI 10.1109/ICCV.1995.466880; Dantone M, 2013, PROC CVPR IEEE, P3041, DOI 10.1109/CVPR.2013.391; Daubney B, 2011, PROC CVPR IEEE, P1321, DOI 10.1109/CVPR.2011.5995502; Elgammal A, 2004, PROC CVPR IEEE, P681; Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468; Ferrari V, 2009, LECT NOTES COMPUT SC, V5604, P128, DOI 10.1007/978-3-642-03061-1_7; Grant M., 2013, CVX MATLAB SOFTWARE; Huber P. J., 2011, ROBUST STAT; Ioffe S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P690, DOI 10.1109/ICCV.2001.937589; Ionescu C, 2014, PROC CVPR IEEE, P1661, DOI 10.1109/CVPR.2014.215; Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248; Kazemi V, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.6; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; LEE HJ, 1985, COMPUT VISION GRAPH, V30, P148, DOI 10.1016/0734-189X(85)90094-5; Lee MW, 2004, PROC CVPR IEEE, P334; Li SJ, 2015, IEEE I CONF COMP VIS, P2848, DOI 10.1109/ICCV.2015.326; Li SJ, 2015, LECT NOTES COMPUT SC, V9004, P332, DOI 10.1007/978-3-319-16808-1_23; Lin Z., 2011, PROC INT 25 C NEURAL, P612, DOI DOI 10.1007/S11263-013-0611-6; Lin ZC, 2015, MACH LEARN, V99, P287, DOI 10.1007/s10994-014-5469-5; MAIRAL J., 2009, P 26 ANN INT C MACH, P689, DOI [10.1145/1553374.1553463, DOI 10.1145/1553374.1553463]; Meltzer T, 2005, IEEE I CONF COMP VIS, P428; Mori G, 2006, IEEE T PATTERN ANAL, V28, P1052, DOI 10.1109/TPAMI.2006.149; Morris DD, 2003, INT J ROBOT RES, V22, P393, DOI 10.1177/0278364903022006004; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Park D, 2011, IEEE I CONF COMP VIS, P2627, DOI 10.1109/ICCV.2011.6126552; Pons-Moll G., 2011, VISUAL ANAL HUMANS, P139, DOI [10.1007/978-0-85729-997-0_9, DOI 10.1007/978-0-85729-997-0_9]; Pons-Moll G, 2014, PROC CVPR IEEE, P2345, DOI 10.1109/CVPR.2014.300; Popa AI, 2017, PROC CVPR IEEE, P4714, DOI 10.1109/CVPR.2017.501; Ramakrishna V, 2012, LECT NOTES COMPUT SC, V7575, P573, DOI 10.1007/978-3-642-33765-9_41; Ramanan D, 2005, PROC CVPR IEEE, P271; Safonova A, 2004, ACM T GRAPHIC, V23, P514, DOI 10.1145/1015706.1015754; Sapp B, 2011, PROC CVPR IEEE, P1281, DOI 10.1109/CVPR.2011.5995607; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; SIGAL L, 2006, CS0608 BROWN U; Simo-Serra E, 2013, PROC CVPR IEEE, P3634, DOI 10.1109/CVPR.2013.466; Simo-Serra E, 2012, PROC CVPR IEEE, P2673, DOI 10.1109/CVPR.2012.6247988; Sminchisescu C, 2004, PROC CVPR IEEE, P608; Sminchisescu C, 2005, INT J COMPUT VISION, V61, P81, DOI 10.1023/B:VISI.0000042935.43630.46; Sminchisescu C, 2003, PROC CVPR IEEE, P69; Taylor CJ, 2000, PROC CVPR IEEE, P677, DOI 10.1109/CVPR.2000.855885; Tekin B., 2015, ARXIV150408200; Valmadre J, 2010, LECT NOTES COMPUT SC, V6313, P467; Wang CY, 2014, PROC CVPR IEEE, P2369, DOI 10.1109/CVPR.2014.303; Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Wei XLK, 2009, IEEE I CONF COMP VIS, P1873, DOI 10.1109/ICCV.2009.5459415; Yacoob Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P120, DOI 10.1109/ICCV.1998.710709; Yadollahpour  P., 2011, P WORKSH DISCR OPT M, P1; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Yasin H, 2016, PROC CVPR IEEE, P4948, DOI 10.1109/CVPR.2016.535; Zhou XW, 2016, PROC CVPR IEEE, P4966, DOI 10.1109/CVPR.2016.537	57	18	18	2	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2019	41	5					1227	1241		10.1109/TPAMI.2018.2828427	http://dx.doi.org/10.1109/TPAMI.2018.2828427			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HS1FL	29993907				2022-12-18	WOS:000463607400015
J	Deng, WH; Hu, JN; Guo, J				Deng, Weihong; Hu, Jiani; Guo, Jun			Compressive Binary Patterns: Designing a Robust Binary Face Descriptor with Random-Field Eigenfilters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face Recognition; local binary patterns; binary code learning; face descriptor	RECOGNITION; CLASSIFICATION; VERIFICATION; REPRESENTATION; INFORMATION; TRANSFORMS; HISTOGRAM; MODEL; SCALE	A binary descriptor typically consists of three stages: image filtering, binarization, and spatial histogram. This paper first demonstrates that the binary code of the maximum-variance filtering responses leads to the lowest bit error rate under Gaussian noise. Then, an optimal eigenfilter bank is derived from a universal assumption on the local stationary random field. Finally, compressive binary patterns (CBP) is designed by replacing the local derivative filters of local binary patterns (LBP) with these novel random-field eigenfilters, which leads to a compact and robust binary descriptor that characterizes the most stable local structures that are resistant to image noise and degradation. A scattering-like operator is subsequently applied to enhance the distinctiveness of the descriptor. Surprisingly, the results obtained from experiments on the FERET, LFW, and PaSC databases show that the scattering CBP (SCBP) descriptor, which is handcrafted by only 6 optimal eigenfilters under restrictive assumptions, outperforms the state-of-the-art learning-based face descriptors in terms of both matching accuracy and robustness. In particular, on probe images degraded with noise, blur, JPEG compression, and reduced resolution, SCBP outperforms other descriptors by a greater than 10 percent accuracy margin.	[Deng, Weihong; Hu, Jiani; Guo, Jun] Beijing Univ Posts & Telecommun, Pattern Recognit & Intelligent Syst Lab, Sch Informat & Commun Engn, Beijing 100876, Peoples R China	Beijing University of Posts & Telecommunications	Deng, WH (corresponding author), Beijing Univ Posts & Telecommun, Pattern Recognit & Intelligent Syst Lab, Sch Informat & Commun Engn, Beijing 100876, Peoples R China.	whdeng@bupt.edu.cn; jnhu@bupt.edu.cn; guojun@bupt.edu.cn	Deng, Wei/GWC-9207-2022	Deng, Weihong/0000-0001-5952-6996	National Natural Science Foundation of China [61573068, 61471048, 61375031, 61532006]; Beijing Nova Program [Z161100004916088]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Nova Program(Beijing Municipal Science & Technology Commission)	This work was partially supported by the National Natural Science Foundation of China under Grant Nos. 61573068, 61471048, 61375031, and 61532006, and Beijing Nova Program under Grant No. Z161100004916088.	AACH T, 1995, SIGNAL PROCESS, V45, P173, DOI 10.1016/0165-1684(95)00049-J; ADE F, 1983, SIGNAL PROCESS, V5, P451, DOI 10.1016/0165-1684(83)90008-7; Ahonen T, 2007, P FINN SIGN PROC S, V2007, P1; Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Ahonen T, 2009, PATTERN RECOGN LETT, V30, P368, DOI 10.1016/j.patrec.2008.10.012; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Arashloo S. R., 2013, P IEEE 6 INT C BIOM, P1, DOI DOI 10.1109/BTAS.2013.6712721; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Beveridge J. R., 2013, BIOM THEOR APPL SYST, P1, DOI DOI 10.1109/BTAS.2013.6712704; Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230; Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222; Cao Q, 2013, IEEE I CONF COMP VIS, P2408, DOI 10.1109/ICCV.2013.299; Cao ZM, 2010, PROC CVPR IEEE, P2707, DOI 10.1109/CVPR.2010.5539992; Carreira-Perpinan MA, 2015, PROC CVPR IEEE, P557, DOI 10.1109/CVPR.2015.7298654; Chan CH, 2013, IEEE T PATTERN ANAL, V35, P1164, DOI 10.1109/TPAMI.2012.199; Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625; Chen D, 2012, LECT NOTES COMPUT SC, V7574, P566, DOI 10.1007/978-3-642-33712-3_41; Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; De la Torre F, 2000, INT C PATT RECOG, P1106, DOI 10.1109/ICPR.2000.903739; Deng WH, 2018, IEEE T PATTERN ANAL, V40, P2513, DOI 10.1109/TPAMI.2017.2757923; Deng WH, 2017, PATTERN RECOGN, V68, P260, DOI 10.1016/j.patcog.2017.03.024; Deng WH, 2014, PATTERN RECOGN, V47, P3738, DOI 10.1016/j.patcog.2014.06.020; Deng WH, 2014, IEEE T PATTERN ANAL, V36, P1275, DOI 10.1109/TPAMI.2013.194; Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30; Deng WH, 2010, PATTERN RECOGN, V43, P2210, DOI 10.1016/j.patcog.2009.12.026; Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338; Gopalan R, 2012, IEEE T PATTERN ANAL, V34, P1220, DOI 10.1109/TPAMI.2012.15; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242; Huang GB, 2012, PROC CVPR IEEE, P2518, DOI 10.1109/CVPR.2012.6247968; Huang Gary B, 2014, 14003 U MASS AMH DEP, V14, P1; Hussain S. U., 2012, BRIT MACH VIS C, P11; Jiang XD, 2007, PATTERN RECOGN, V40, P705, DOI 10.1016/j.patcog.2006.04.028; Kannala J, 2012, INT C PATT RECOG, P1363; Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112; Lei Z, 2011, IEEE T IMAGE PROCESS, V20, P247, DOI 10.1109/TIP.2010.2060207; Li HA, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON MANAGEMENT SCIENCE AND MANAGEMENT INNOVATION, P17; Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828; Lilei Zheng, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163085; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032; Low CY, 2019, IEEE T CIRC SYST VID, V29, P115, DOI 10.1109/TCSVT.2017.2761829; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359; Majumdar A, 2017, IEEE T PATTERN ANAL, V39, P1273, DOI 10.1109/TPAMI.2016.2569436; Melekhov I, 2017, LECT NOTES COMPUT SC, V10118, P638, DOI 10.1007/978-3-319-54526-4_46; Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974; Nguyen Hieu V., 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P709, DOI 10.1007/978-3-642-19309-5_55; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Parkhi Omkar M., 2015, BRIT MACH VIS C; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Pinto Nicolas, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2591, DOI 10.1109/CVPRW.2009.5206605; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; Ren JF, 2015, IEEE SIGNAL PROC LET, V22, P2373, DOI 10.1109/LSP.2015.2481435; Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976; Satpathy A, 2014, IEEE T IMAGE PROCESS, V23, P287, DOI 10.1109/TIP.2013.2264677; Seo HJ, 2011, IEEE T INF FOREN SEC, V6, P1275, DOI 10.1109/TIFS.2011.2159205; Simonyan K., 2013, P BRIT MACH VIS C, V5, P11; Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645; Tola E., 2008, P 2008 IEEE C COMP V, P1, DOI DOI 10.1109/CVPR.2008.4587673; Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77; UNSER M, 1986, SIGNAL PROCESS, V11, P61, DOI 10.1016/0165-1684(86)90095-2; van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154; Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230; Yi D, 2013, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2013.454; Ying YM, 2012, J MACH LEARN RES, V13, P1; Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064; Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882; Zhang WC, 2005, IEEE I CONF COMP VIS, P786	74	18	20	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2019	41	3					758	767		10.1109/TPAMI.2018.2800008	http://dx.doi.org/10.1109/TPAMI.2018.2800008			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HK7LA	29994561				2022-12-18	WOS:000458168800017
J	Joo, K; Oh, TH; Kim, J; Kweon, IS				Joo, Kyungdon; Oh, Tae-Hyun; Kim, Junsik; Kweon, In So			Robust and Globally Optimal Manhattan Frame Estimation in Near Real Time	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Manhattan frame; rotation estimation; branch-and-bound; scene understanding; video stabilization; line clustering; vanishing point estimation	CONSENSUS; MAXIMIZATION; SPACE	Most man-made environments, such as urban and indoor scenes, consist of a set of parallel and orthogonal planar structures. These structures are approximated by the Manhattan world assumption, in which notion can be represented as a Manhattan frame (MF). Given a set of inputs such as surface normals or vanishing points, we pose an MF estimation problem as a consensus set maximization that maximizes the number of inliers over the rotation search space. Conventionally, this problem can be solved by a branch-and-bound framework, which mathematically guarantees global optimality. However, the computational time of the conventional branch-and-bound algorithms is rather far from real-time. In this paper, we propose a novel bound computation method on an efficient measurement domain for MF estimation, i.e., the extended Gaussian image (EGI). By relaxing the original problem, we can compute the bound with a constant complexity, while preserving global optimality. Furthermore, we quantitatively and qualitatively demonstrate the performance of the proposed method for various synthetic and real-world data. We also show the versatility of our approach through three different applications: extension to multiple MF estimation, 3D rotation based video stabilization, and vanishing point estimation (line clustering).	[Joo, Kyungdon; Kim, Junsik; Kweon, In So] Korea Adv Inst Sci & Technol, Sch Elect & Comp Engn, Daejeon 34051, South Korea; [Oh, Tae-Hyun] MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA	Korea Advanced Institute of Science & Technology (KAIST); Massachusetts Institute of Technology (MIT)	Kweon, IS (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect & Comp Engn, Daejeon 34051, South Korea.	kdjoo369@gmail.com; thoh.mit.edu@gmail.com; mibastro@gmail.com; iskweon@kaist.ac.kr	; Oh, Tae-Hyun/D-7854-2016	Kim, Junsik/0000-0003-2555-5232; Oh, Tae-Hyun/0000-0003-0468-1571	Technology Innovation Program [201710069072]; Ministry of Trade, Industry & Energy (MOTIE, Korea)	Technology Innovation Program; Ministry of Trade, Industry & Energy (MOTIE, Korea)	The authors appreciate helpful discussion and comments from Prof. Jinwoo Shin and Gilwoo Lee. This work was supported by the Technology Innovation Program (No. 201710069072) funded By the Ministry of Trade, Industry & Energy (MOTIE, Korea). Prof. In So Kweon is the corresponding author of this work.	[Anonymous], 2007, NOTES EE364B; Balakrishnan V., 1991, International Journal of Robust and Nonlinear Control, V1, P295, DOI 10.1002/rnc.4590010404; BARNARD ST, 1983, ARTIF INTELL, V21, P435, DOI 10.1016/S0004-3702(83)80021-6; Bazin JC, 2014, LECT NOTES COMPUT SC, V8690, P803, DOI 10.1007/978-3-319-10605-2_52; Bazin JC, 2012, PROC CVPR IEEE, P638, DOI 10.1109/CVPR.2012.6247731; Bazin JC, 2012, INT J ROBOT RES, V31, P63, DOI 10.1177/0278364911421954; Bazin Jean-Charles, 2012, P AS C COMP VIS, P2; Bustos AP, 2014, PROC CVPR IEEE, P3930, DOI 10.1109/CVPR.2014.502; Changchang Wu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3057, DOI 10.1109/CVPR.2011.5995552; Chin TJ, 2017, IEEE T PATTERN ANAL, V39, P758, DOI 10.1109/TPAMI.2016.2631531; Choi WG, 2013, PROC CVPR IEEE, P33, DOI 10.1109/CVPR.2013.12; Coughlan J.M., 1999, P ICCV, V2, P941, DOI DOI 10.1109/ICCV.1999.790349; Del Pero L, 2012, PROC CVPR IEEE, P2719, DOI 10.1109/CVPR.2012.6247994; Denis P., 2008, EFFICIENT EDGE BASED; Eigen David, 2014, NEURIPS; Endres F, 2012, IEEE INT CONF ROBOT, P1691, DOI 10.1109/ICRA.2012.6225199; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fisher N.I., 1995, STAT ANAL CIRCULAR D, DOI DOI 10.1017/CBO9780511564345; Furukawa Y, 2009, PROC CVPR IEEE, P1422, DOI 10.1109/CVPRW.2009.5206867; Ghanem B, 2015, PROC CVPR IEEE, P3772, DOI 10.1109/CVPR.2015.7299001; Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23; Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79; Hajek B, 2015, RANDOM PROCESSES FOR ENGINEERS, P1; Hartley RI, 2009, INT J COMPUT VISION, V82, P64, DOI 10.1007/s11263-008-0186-9; Hedau V, 2010, LECT NOTES COMPUT SC, V6316, P224, DOI 10.1007/978-3-642-15567-3_17; Hedau V, 2009, IEEE I CONF COMP VIS, P1849, DOI 10.1109/ICCV.2009.5459411; Heller J, 2012, PROC CVPR IEEE, P1608, DOI 10.1109/CVPR.2012.6247853; HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073; Horst R., 2013, GLOBAL OPTIMIZATION; Jia C, 2014, IEEE T SIGNAL PROCES, V62, P3293, DOI 10.1109/TSP.2014.2325795; Joo K, 2016, PROC CVPR IEEE, P1763, DOI 10.1109/CVPR.2016.195; Joo K, 2013, IEEE IMAGE PROC, P2158, DOI 10.1109/ICIP.2013.6738445; Kosecka J, 2002, LECT NOTES COMPUT SC, V2353, P476; LAWLER EL, 1966, OPER RES, V14, P699, DOI 10.1287/opre.14.4.699; Lee DC, 2009, PROC CVPR IEEE, P2136, DOI 10.1109/CVPRW.2009.5206872; Li HD, 2009, IEEE I CONF COMP VIS, P1074, DOI 10.1109/ICCV.2009.5459398; Makadia A., 2006, P IEEE C COMP VIS PA, V1, P1297, DOI DOI 10.1109/CVPR.2006.122; Ramalingam S, 2013, IEEE I CONF COMP VIS, P497, DOI 10.1109/ICCV.2013.67; Rosten E, 2005, IEEE I CONF COMP VIS, P1508; Schobel A, 2010, J GLOBAL OPTIM, V48, P473, DOI 10.1007/s10898-009-9502-3; Scholz D., 2011, DETERMINISTIC GLOBAL; Scholz D, 2013, J GLOBAL OPTIM, V57, P771, DOI 10.1007/s10898-012-9961-9; Schwing AG, 2012, LECT NOTES COMPUT SC, V7577, P299, DOI 10.1007/978-3-642-33783-3_22; Schwing AG, 2012, PROC CVPR IEEE, P2815, DOI 10.1109/CVPR.2012.6248006; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Sinha SN, 2009, IEEE I CONF COMP VIS, P1881, DOI 10.1109/ICCV.2009.5459417; Snyder J.P., 1987, MAP PROJECTIONS WORK, V1395; Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655; Song SR, 2014, LECT NOTES COMPUT SC, V8694, P634, DOI 10.1007/978-3-319-10599-4_41; Straub J, 2018, IEEE T PATTERN ANAL, V40, P235, DOI 10.1109/TPAMI.2017.2662686; Straub J, 2015, IEEE INT C INT ROBOT, P1913, DOI 10.1109/IROS.2015.7353628; Straub J, 2014, PROC CVPR IEEE, P3770, DOI 10.1109/CVPR.2014.488; Tardif JP, 2009, IEEE I CONF COMP VIS, P1250, DOI 10.1109/ICCV.2009.5459328; Taylor Camillo J., 2013, 2012 Robotics: Science and Systems, P401; ULRICH G, 1984, J R STAT SOC C-APPL, V33, P158; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wildenauer H, 2012, PROC CVPR IEEE, P2831, DOI 10.1109/CVPR.2012.6248008; Xu YL, 2013, PROC CVPR IEEE, P1376, DOI 10.1109/CVPR.2013.181; Zhai MH, 2016, PROC CVPR IEEE, P5657, DOI 10.1109/CVPR.2016.610; Zhang CX, 2010, LECT NOTES COMPUT SC, V6314, P708, DOI 10.1007/978-3-642-15561-1_51; Zhang LL, 2016, INT J COMPUT VISION, V117, P111, DOI 10.1007/s11263-015-0854-5; Zhou HZ, 2015, IEEE T VEH TECHNOL, V64, P1364, DOI 10.1109/TVT.2015.2388780	63	18	18	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2019	41	3					682	696		10.1109/TPAMI.2018.2799944	http://dx.doi.org/10.1109/TPAMI.2018.2799944			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HK7LA	29993475	Green Submitted			2022-12-18	WOS:000458168800012
J	Finlayson, G; Gong, H; Fisher, RB				Finlayson, Graham; Gong, Han; Fisher, Robert B.			Color Homography: Theory and Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Color homography; illumination estimation; color correction; color indexing; color transfer	SPECTRAL REFLECTANCE; LINEAR-MODELS; ALGORITHM; SURFACE	Images of co-planar points in 3-dimensional space taken from different camera positions are a homography apart. Homographies are at the heart of geometric methods in computer vision and are used in geometric camera calibration, 3D reconstruction, stereo vision and image mosaicking among other tasks. In this paper we show the surprising result that homographies are the apposite tool for relating image colors of the same scene when the capture conditions-illumination color, shading and device-change. Three applications of color homographies are investigated. First, we show that color calibration is correctly formulated as a homography problem. Second, we compare the chromaticity distributions of an image of colorful objects to a database of object chromaticity distributions using homography matching. In the color transfer problem, the colors in one image are mapped so that the resulting image color style matches that of a target image. We show that natural image color transfer can be re-interpreted as a color homography mapping. Experiments demonstrate that solving the color homography problem leads to more accurate calibration, improved color-based object recognition, and we present a new direction for developing natural color transfer algorithms.	[Finlayson, Graham; Gong, Han] Univ East Anglia, Sch Comp Sci, Norwich NR4 7TJ, East Anglia, England; [Fisher, Robert B.] Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Midlothian, Scotland	University of East Anglia; University of Edinburgh	Gong, H (corresponding author), Univ East Anglia, Sch Comp Sci, Norwich NR4 7TJ, East Anglia, England.	g.finlayson@uea.ac.uk; gong@fedoraproject.org; rbf@inf.ed.aclik		Fisher, Robert B/0000-0001-6860-9371	EPSRC; EPSRC [EP/M00189X/1, EP/M001768/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [EP/M001768/1, EP/M00189X/1] Funding Source: researchfish	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was supported by EPSRC Grant EP/M001768/1. We also acknowledge Prof. Roberto Cipolla (University of Cambridge) and Prof. Mark Drew (Simon Fraser University) for their useful discussion on this work. We would like to thank EPSRC for funding this project.	Anderson M., 1995, P 4 COL IM C, P238; Bajcsy R., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P785, DOI 10.1109/ICPR.1990.118217; Barron JT, 2015, IEEE I CONF COMP VIS, P379, DOI 10.1109/ICCV.2015.51; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Beigpour S, 2014, IEEE T IMAGE PROCESS, V23, P83, DOI 10.1109/TIP.2013.2286327; Berens J, 2000, INT C PATT RECOG, P206, DOI 10.1109/ICPR.2000.905304; Berwick D, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P165, DOI 10.1109/ICCV.1998.710714; Bianco S, 2011, LECT NOTES COMPUT SC, V6626, P245, DOI 10.1007/978-3-642-20404-3_19; Boyadzhiev I, 2012, ACM TOG SIGGRAPH ASI, V31; Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3; Cho JW, 2007, I S WORLD WIREL MOBI, P1; DREW MS, 1992, CVGIP-IMAG UNDERSTAN, V56, P139, DOI 10.1016/1049-9660(92)90036-3; Finalyson G., 2016, PROGR COLOUR STUD; Finlayson G, 2003, ELEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING - SYSTEMS, TECHNOLOGIES, APPLICATIONS, P170; Finlayson G. D., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P475, DOI 10.1007/BFb0055685; Finlayson G. D., 2016, COL IM C, V0, P310; FINLAYSON GD, 1994, J OPT SOC AM A, V11, P1553, DOI 10.1364/JOSAA.11.001553; Finlayson GD, 2015, COLOR RES APPL, V40, P232, DOI 10.1002/col.21889; Finlayson GD, 2015, IEEE T IMAGE PROCESS, V24, P1460, DOI 10.1109/TIP.2015.2405336; FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770; Funt B, 2003, IEEE IMAGE PROC, P481; Funt B, 2014, COLOR RES APPL, V39, P540, DOI 10.1002/col.21849; FUNT BV, 1993, IEEE T PATTERN ANAL, V15, P1319, DOI 10.1109/34.250838; FUNT BV, 1995, IEEE T PATTERN ANAL, V17, P522, DOI 10.1109/34.391390; Gefen S, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P744; Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60; Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3; Gijsenij A, 2012, IEEE T IMAGE PROCESS, V21, P697, DOI 10.1109/TIP.2011.2165219; Gong H., 2016, P BRIT MACH VIS C; Harris C. G., 1988, P 4 ALV VIS C, V15, P10, DOI [10.5244/C.2.23, DOI 10.5244/C.2.23]; Hartley R., 2004, ROBOTICA; HEALEY G, 1991, IMAGE VISION COMPUT, V9, P333, DOI 10.1016/0262-8856(91)90038-Q; Hubel P., 2003, U. S. Patent, Patent No. [No. 20030194125, 20030194125]; HUBEL PM, 1998, P COL MULT C, P97; Hwang Y, 2014, PROC CVPR IEEE, P3342, DOI 10.1109/CVPR.2014.427; Kim SJ, 2012, IEEE T PATTERN ANAL, V34, P2289, DOI 10.1109/TPAMI.2012.58; Kokaram A., 2007, 4 EUR C VIS MED PROD, P1, DOI DOI 10.1049/CP:20070055; KONDEPUDY R, 1994, J OPT SOC AM A, V11, P3037, DOI 10.1364/JOSAA.11.003037; Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239547, 10.1145/1276377.1276497]; LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108; Lenz R., 1999, 1999 IEEE Third Workshop on Multimedia Signal Processing (Cat. No.99TH8451), P103, DOI 10.1109/MMSP.1999.793805; LOOP CT, 1999, CVPR, P1125; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MALONEY LT, 1986, J OPT SOC AM A, V3, P1673, DOI 10.1364/JOSAA.3.001673; MARIMONT DH, 1992, J OPT SOC AM A, V9, P1905, DOI 10.1364/JOSAA.9.001905; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; McCamy C. S., 1976, Journal of Applied Photographic Engineering, V2, P95; Minagawa A, 2012, INT C PATT RECOG, P1912; Nguyen RMH, 2014, COMPUT GRAPH FORUM, V33, P319, DOI 10.1111/cgf.12500; Niblack W., 1993, SPIE P SERIES; NOVAK CL, 1994, J OPT SOC AM A, V11, P3020, DOI 10.1364/JOSAA.11.003020; Ohno Y., 1997, C IM C, V1997, P301; Paris S, 2006, LECT NOTES COMPUT SC, V3954, P568; PARKKINEN JPS, 1989, J OPT SOC AM A, V6, P318, DOI 10.1364/JOSAA.6.000318; Pitie F, 2007, COMPUT VIS IMAGE UND, V107, P123, DOI 10.1016/j.cviu.2006.11.011; Pouli Tania, 2010, P 8 INT S NONPH AN R, P81, DOI DOI 10.1145/1809939.1809949; Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Thomos N, 2006, IEEE T IMAGE PROCESS, V15, P54, DOI 10.1109/TIP.2005.860338; Tominaga S., 1997, Systems and Computers in Japan, V28, P8, DOI 10.1002/(SICI)1520-684X(19971130)28:13<8::AID-SCJ2>3.0.CO;2-T; Torr PH, 1999, P INT WORKSH VIS ALG, P278, DOI DOI 10.1007/3-540-44480-7_19; VRHEL MJ, 1992, COLOR RES APPL, V17, P328, DOI 10.1002/col.5080170507; Vrhel MJ, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P181, DOI 10.1109/ICIP.1998.723453; WANDELL BA, 1987, IEEE T PATTERN ANAL, V9, P2, DOI 10.1109/TPAMI.1987.4767868; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wyszecki G., 2000, COLOR SCI CONCEPTS M, V2nd; Yu GS, 2011, IMAGE PROCESS ON LIN, V1, P11, DOI 10.5201/ipol.2011; Zhang T, 2001, SIAM J MATRIX ANAL A, V23, P534, DOI 10.1137/S0895479899352045; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718; Zickler T., 2009, P BRIT MACH VIS C, V1, P4	70	18	20	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2019	41	1					20	33		10.1109/TPAMI.2017.2760833	http://dx.doi.org/10.1109/TPAMI.2017.2760833			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HD3QX	29990184	hybrid, Green Accepted, Green Submitted			2022-12-18	WOS:000452434800003
J	Zhao, RQ; Wang, Y; Martinez, AM				Zhao, Ruiqi; Wang, Yan; Martinez, Aleix M.			A Simple, Fast and Highly-Accurate Algorithm to Recover 3D Shape from 2D Landmarks on a Single Image	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D modeling and reconstruction; fine-grained reconstruction; 3D shape from a single 2D image; deep learning		Three-dimensional shape reconstruction of 2D landmark points on a single image is a hallmark of human vision, but is a task that has been proven difficult for computer vision algorithms. We define a feed-forward deep neural network algorithm that can reconstruct 3D shapes from 2D landmark points almost perfectly (i.e., with extremely small reconstruction errors), even when these 2D landmarks are from a single image. Our experimental results show an improvement of up to two-fold over state-of-the-art computer vision algorithms; 3D shape reconstruction error (measured as the Procrustes distance between the reconstructed shape and the ground-truth) of human faces is < .004, cars is .0022, human bodies is .022, and highly-deformable flags is .0004. Our algorithm was also a top performer at the 2016 3D Face Alignment in the Wild Challenge competition (done in conjunction with the European Conference on Computer Vision, ECCV) that required the reconstruction of 3D face shape from a single image. The derived algorithm can be trained in a couple hours and testing runs at more than 1,000 frames/s on an i7 desktop. We also present an innovative data augmentation approach that allows us to train the system efficiently with small number of samples. And the system is robust to noise (e.g., imprecise landmark points) and missing data (e.g., occluded or undetected landmark points).	[Zhao, Ruiqi; Wang, Yan; Martinez, Aleix M.] Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43210 USA	University System of Ohio; Ohio State University	Martinez, AM (corresponding author), Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43210 USA.	zhao.823@osu.edu; wang.9021@osu.edu; aleix@ece.osu.edu		Martinez, Aleix/0000-0002-4745-4953	National Institutes of Health [R01 DC 014498]; Human Frontier Science Program [RGP0036/2016]; NATIONAL EYE INSTITUTE [R01EY020834] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERS [R01DC014498] Funding Source: NIH RePORTER	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Human Frontier Science Program(Human Frontier Science Program); NATIONAL EYE INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI)); NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Deafness & Other Communication Disorders (NIDCD))	Research supported by the National Institutes of Health, grant R01 DC 014498 and the Human Frontier Science Program, grant RGP0036/2016.	Akhter I, 2015, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2015.7298751; Akhter I, 2011, IEEE T PATTERN ANAL, V33, P1442, DOI 10.1109/TPAMI.2010.201; Bartoli A, 2013, PROC CVPR IEEE, P1514, DOI 10.1109/CVPR.2013.199; Bastien F., 2012, ADV NEUR INF P SYST; Bengio Y, 1996, ADV NEUR IN, V8, P395; Chen Y, 2010, LECT NOTES COMPUT SC, V6313, P300; Chollet F., 2015, KERAS; Dame A, 2013, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2013.170; Ding LY, 2010, IEEE T PATTERN ANAL, V32, P2022, DOI 10.1109/TPAMI.2010.28; Fayad J, 2011, IEEE I CONF COMP VIS, P431, DOI 10.1109/ICCV.2011.6126272; Gotardo PFU, 2011, IEEE I CONF COMP VIS, P802, DOI 10.1109/ICCV.2011.6126319; Gotardo PFU, 2011, IEEE T PATTERN ANAL, V33, P2051, DOI 10.1109/TPAMI.2011.50; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Hamsici OC, 2012, LECT NOTES COMPUT SC, V7575, P260, DOI 10.1007/978-3-642-33765-9_19; Hartley R., 2003, MULTIPLE VIEW GEOMET; Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248; Jeni Laszlo A., 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163142; Kar A, 2015, PROC CVPR IEEE, P1966, DOI 10.1109/CVPR.2015.7298807; Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49; Lin YL, 2014, LECT NOTES COMPUT SC, V8692, P466, DOI 10.1007/978-3-319-10593-2_31; Martinez AM, 2017, CURR DIR PSYCHOL SCI, V26, P263, DOI 10.1177/0963721417698535; Martinez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382; MoCap, CARN MELL U GRAPH LA; Ramakrishna V, 2012, LECT NOTES COMPUT SC, V7575, P573, DOI 10.1007/978-3-642-33765-9_41; Ramanan D., 2007, ADV NEURAL INFORM PR, V19, P1129; Russell C., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3009, DOI 10.1109/CVPR.2011.5995383; RUSSELL C, 2014, P EUR C COMPUT VIS, V8695, P583; Salzmann M., 2008, IEEE C COMP VIS PATT, P1; Urtasun R, 2005, IEEE I CONF COMP VIS, P403; Vicente S, 2014, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2014.13; White R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239485; Yin L., 2008, AUTOMATIC FACE GESTU, V08, P1, DOI DOI 10.1109/AFGR.2008.4813324; Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002; [张醒 Zhang Xing], 2013, [火工品, Initiators & Pyrotechnics], P1; Zhao RQ, 2016, LECT NOTES COMPUT SC, V9914, P590, DOI 10.1007/978-3-319-48881-3_41; Zhou XW, 2017, IEEE T PATTERN ANAL, V39, P1648, DOI 10.1109/TPAMI.2016.2605097; Zhou XW, 2016, PROC CVPR IEEE, P4966, DOI 10.1109/CVPR.2016.537; Zhou XW, 2015, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2015.7299074; Zhu ML, 2015, IEEE I CONF COMP VIS, P927, DOI 10.1109/ICCV.2015.112	39	18	19	0	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2018	40	12					3059	3066		10.1109/TPAMI.2017.2772922	http://dx.doi.org/10.1109/TPAMI.2017.2772922			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GZ4HL	29990100	Green Submitted, Green Accepted			2022-12-18	WOS:000449355500020
J	Yin, X; Liu, XM; Chen, J; Kramer, DM				Yin, Xi; Liu, Xiaoming; Chen, Jin; Kramer, David M.			Joint Multi-Leaf Segmentation, Alignment, and Tracking for Fluorescence Plant Videos	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Plant phenotyping; Arabidopsis; leaf segmentation; alignment; tracking; multi-object; Chamfer matching	CHLOROPHYLL FLUORESCENCE; ROSETTE PLANTS; IMAGE-ANALYSIS; GROWTH; LEAVES	This paper proposes a novel framework for fluorescence plant video processing. The plant research community is interested in the leaf-level photosynthetic analysis within a plant. A prerequisite for such analysis is to segment all leaves, estimate their structures, and track them over time. We identify this as a joint multi-leaf segmentation, alignment, and tracking problem. First, leaf segmentation and alignment are applied on the last frame of a plant video to find a number of well-aligned leaf candidates. Second, leaf tracking is applied on the remaining frames with leaf candidate transformation from the previous frame. We form two optimization problems with shared terms in their objective functions for leaf alignment and tracking respectively. A quantitative evaluation framework is formulated to evaluate the performance of our algorithm with four metrics. Two models are learned to predict the alignment accuracy and detect tracking failure respectively in order to provide guidance for subsequent plant biology analysis. The limitation of our algorithm is also studied. Experimental results show the effectiveness, efficiency, and robustness of the proposed method.	[Yin, Xi; Liu, Xiaoming] Michigan State Univ, Comp Sci & Engn, E Lansing, MI 48824 USA; [Chen, Jin] Univ Kentucky, Dept Comp Sci, Dept Internal Med, Lexington, KY 40506 USA; [Chen, Jin; Kramer, David M.] Michigan State Univ, MSU DOE Plant Biol Lab, E Lansing, MI 48824 USA	Michigan State University; University of Kentucky; Michigan State University	Yin, X (corresponding author), Michigan State Univ, Comp Sci & Engn, E Lansing, MI 48824 USA.	yinxi.whu@gmail.com; liuxm@cse.msu.edu; jinchen@msu.edu; kramerd8@msu.edu	Kramer, David/B-9588-2016	Kramer, David/0000-0003-2181-6888	U.S. Department of Energy (DOE), Office of Science, Basic Energy Sciences (BES) [DE-FG02-91ER20021]; MSU AgBioResearch; John A. Hannah endowment	U.S. Department of Energy (DOE), Office of Science, Basic Energy Sciences (BES)(United States Department of Energy (DOE)); MSU AgBioResearch; John A. Hannah endowment	This work was supported by the U.S. Department of Energy (DOE), Office of Science, Basic Energy Sciences (BES) under Award number DE-FG02-91ER20021 using instrumentation at the MSU Center for Advanced Algal and Plant Phenotyping (CAAPP), which is supported by MSU AgBioResearch and the John A. Hannah endowment.	Aksoy EE, 2015, COMPUT ELECTRON AGR, V110, P78, DOI 10.1016/j.compag.2014.10.020; [Anonymous], 2014, LEAF SEGMENTATION CH; [Anonymous], 2013, ACM T GRAPHIC, DOI DOI 10.1145/2461912.2461952; [Anonymous], 2015, ARABIDOPSIS INFORM R; Barrow HG, 1977, P 5 INT JOINT C ART; Boros E, 2002, DISCRETE APPL MATH, V123, P155, DOI 10.1016/S0166-218X(01)00336-5; Cerutti Guillaume, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P202; Cerutti G, 2013, IEEE IMAGE PROC, P1471, DOI 10.1109/ICIP.2013.6738302; Cerutti G, 2013, COMPUT VIS IMAGE UND, V117, P1482, DOI 10.1016/j.cviu.2013.07.003; Chen SQ, 2012, IMAGE VISION COMPUT, V30, P1032, DOI 10.1016/j.imavis.2012.09.005; Chene Y, 2012, COMPUT ELECTRON AGR, V82, P122, DOI 10.1016/j.compag.2011.12.007; CRAMA Y, 1990, DISCRETE APPL MATH, V29, P171, DOI 10.1016/0166-218X(90)90142-Y; Cruz JA, 2016, MACH VISION APPL, V27, P735, DOI 10.1007/s00138-015-0734-6; De Vylder J, 2011, LECT NOTES COMPUT SC, V6930, P75; Dellen B, 2015, IEEE ACM T COMPUT BI, V12, P1470, DOI 10.1109/TCBB.2015.2404810; Fiorani F, 2013, ANNU REV PLANT BIOL, V64, P267, DOI 10.1146/annurev-arplant-050312-120137; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Greenham K, 2015, PLANT METHODS, V11, DOI 10.1186/s13007-015-0075-5; Hartmann A, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-148; Jansen M, 2009, FUNCT PLANT BIOL, V36, P902, DOI 10.1071/FP09095; Kaul S, 2000, NATURE, V408, P796, DOI 10.1038/35048692; Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36; Leibe B, 2005, PROC CVPR IEEE, P878; Li X., 2012, 2 INT C FUT COMP ED, P215; Li Y., 2013, ACM T GRAPHIC, V32, P6; Lim E, 2002, IEEE IMAGE PROC, P469; Liu X., 2008, CVPR, P1; Liu XM, 2009, IEEE T PATTERN ANAL, V31, P1941, DOI 10.1109/TPAMI.2008.238; Minervini M, 2015, IEEE SIGNAL PROC MAG, V32, P126, DOI 10.1109/MSP.2015.2405111; Mouine S., 2012, P 2 ACM INT C MULT R, P49; Nasrollahi K, 2008, LECT NOTES COMPUT SC, V5372, P10, DOI 10.1007/978-3-540-89991-4_2; Nedbal L, 2004, ADV PHOTO RESPIRAT, V19, P389; Pape JM, 2015, LECT NOTES COMPUT SC, V8928, P61, DOI 10.1007/978-3-319-16220-1_5; Quan L, 2006, ACM T GRAPHIC, V25, P599, DOI 10.1145/1141911.1141929; Scharr H., 2014, FZJ201403837 IMT I A; Scharr H, 2016, MACH VISION APPL, V27, P585, DOI 10.1007/s00138-015-0737-3; Teng CH, 2009, LECT NOTES COMPUT SC, V5627, P937, DOI 10.1007/978-3-642-02611-9_92; Tessmer OL, 2013, BMC SYST BIOL, V7, DOI 10.1186/1752-0509-7-S6-S17; Trachsel S, 2011, PLANT SOIL, V341, P75, DOI 10.1007/s11104-010-0623-8; Wang XF, 2008, APPL MATH COMPUT, V205, P916, DOI 10.1016/j.amc.2008.05.108; Wilson LM, 2004, PLANT CELL, V16, P2719, DOI 10.1105/tpc.104.025700; Yin X, 2014, IEEE IMAGE PROC, P408, DOI 10.1109/ICIP.2014.7025081; Yin X, 2014, IEEE WINT CONF APPL, P437; Zhang X, 2012, G3-GENES GENOM GENET, V2, P29, DOI 10.1534/g3.111.001487	44	18	18	0	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2018	40	6					1411	1423		10.1109/TPAMI.2017.2728065	http://dx.doi.org/10.1109/TPAMI.2017.2728065			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GE9BK	28715326	Green Submitted, hybrid			2022-12-18	WOS:000431524700010
J	Dehghan, A; Shah, M				Dehghan, Afshin; Shah, Mubarak			Binary Quadratic Programing for Online Tracking of Hundreds of People in Extremely Crowded Scenes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multiple object tracking; crowd tracking; high density crowd; quadratic programing; Frank-Wolfe optimization		Multi-object tracking has been studied for decades. However, when it comes to tracking pedestrians in extremely crowded scenes, we are limited to only few works. This is an important problem which gives rise to several challenges. Pre-trained object detectors fail to localize targets in crowded sequences. This consequently limits the use of data-association based multi-target tracking methods which rely on the outcome of an object detector. Additionally, the small apparent target size makes it challenging to extract features to discriminate targets from their surroundings. Finally, the large number of targets greatly increases computational complexity which in turn makes it hard to extend existing multi-target tracking approaches to high-density crowd scenarios. In this paper, we propose a tracker that addresses the aforementioned problems and is capable of tracking hundreds of people efficiently. We formulate online crowd tracking as Binary Quadratic Programing. Our formulation employs target's individual information in the form of appearance and motion as well as contextual cues in the form of neighborhood motion, spatial proximity and grouping, and solves detection and data association simultaneously. In order to solve the proposed quadratic optimization efficiently, where state-of art commercial quadratic programing solvers fail to find the solution in a reasonable amount of time, we propose to use the most recent version of the Modified Frank Wolfe algorithm, which takes advantage of SWAP-steps to speed up the optimization. We show that the proposed formulation can track hundreds of targets efficiently and improves state-of-art results by significant margins on eleven challenging high density crowd sequences.	[Dehghan, Afshin; Shah, Mubarak] Univ Cent Florida, Dept Ctr Res Comp Vis, Orlando, FL 32816 USA	State University System of Florida; University of Central Florida	Dehghan, A (corresponding author), Univ Cent Florida, Dept Ctr Res Comp Vis, Orlando, FL 32816 USA.	adehghan@cs.ucf.edu; shah@crcv.ucf.edu		Shah, Mubarak/0000-0001-6172-5572	Qatar National Research Fund (Qatar Foundation) [NPRP 7-1711-1-312]	Qatar National Research Fund (Qatar Foundation)	This work was made possible by NPRP grant number NPRP 7-1711-1-312 from the Qatar National Research Fund (a member of Qatar Foundation). The statements made herein are solely the responsibility of the authors.	Ali S, 2008, LECT NOTES COMPUT SC, V5303, P1, DOI 10.1007/978-3-540-88688-4_1; Andersen E., 2000, HIGH PERFORMANCE OPT, P197, DOI DOI 10.1007/978-1-4757-3216-0_8; ANDRIYENKO A, 2010, P 11 EUR C COMP, V6311, P466; [Anonymous], 2014, P AS C COMP VIS; [Anonymous], 2013, NY TIMES; Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159; Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21; Breitenstein MD, 2009, IEEE I CONF COMP VIS, P1515, DOI 10.1109/ICCV.2009.5459278; Chen XJ, 2014, PROC CVPR IEEE, P1242, DOI 10.1109/CVPR.2014.162; Collins RT, 2012, PROC CVPR IEEE, P1744, DOI 10.1109/CVPR.2012.6247870; Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; DEHGHAN A, 2015, PROC CVPR IEEE, P4091, DOI DOI 10.1109/CVPR.2015; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Frank M., 1956, NAVAL RES LOGISTICS, V3, P95, DOI [DOI 10.1002/NAV.3800030109, 10.1002/nav.3800030109]; GUELAT J, 1986, MATH PROGRAM, V35, P110, DOI 10.1007/BF01589445; Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Hubbard B., 2015, HAJJ STAMPEDE NEARME; Idrees H, 2014, IMAGE VISION COMPUT, V32, P14, DOI 10.1016/j.imavis.2013.10.006; Jaggi M., 2013, P 30 INT C MACHINE L, P427; Joulin A, 2014, LECT NOTES COMPUT SC, V8694, P253, DOI 10.1007/978-3-319-10599-4_17; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Kratz L, 2012, LECT NOTES COMPUT SC, V7575, P558, DOI 10.1007/978-3-642-33765-9_40; Kratz L, 2010, PROC CVPR IEEE, P693, DOI 10.1109/CVPR.2010.5540149; Kumar KCA, 2013, IEEE I CONF COMP VIS, P2000, DOI 10.1109/ICCV.2013.250; Kuo CH, 2010, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2010.5540148; Lacoste-Julien S., 2013, P 30 INT C MACH LEAR, P53; Lacoste-Julien S, 2015, ADV NEURAL INFORM PR, V28, P496; Li Z, 2008, INT C WAVEL ANAL PAT, P1, DOI 10.1109/ICWAPR.2008.4635740; Nancuef R, 2014, INFORM SCIENCES, V285, P66, DOI 10.1016/j.ins.2014.03.059; Park M., 2008, P IEEE C COMP VIS PA, P1; Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260; PELLEGRINI S, 2010, P ECCV, V6311, P452; Qin Z, 2012, PROC CVPR IEEE, P1972, DOI 10.1109/CVPR.2012.6247899; Rodriguez M, 2009, IEEE I CONF COMP VIS, P1389, DOI 10.1109/ICCV.2009.5459301; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shu G, 2012, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2012.6247879; Smeulders A. W. M., 2014, IEEE T PATTERN ANAL, V37, DOI DOI 10.1109/TPAMI.2013.230; Solera F, 2016, IEEE T PATTERN ANAL, V38, P995, DOI 10.1109/TPAMI.2015.2470658; Thomas A, 2007, IEEE I CONF COMP VIS, P23; YU SI, 2016, PROC CVPR IEEE, P3871, DOI DOI 10.1109/CVPR.2016.420; Zhang L, 2013, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2013.240	53	18	18	2	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2018	40	3					568	581		10.1109/TPAMI.2017.2687462	http://dx.doi.org/10.1109/TPAMI.2017.2687462			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FV3KC	28358675	Green Submitted			2022-12-18	WOS:000424465900005
J	Silberer, C; Ferrari, V; Lapata, M				Silberer, Carina; Ferrari, Vittorio; Lapata, Mirella			Visually Grounded Meaning Representations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cognitive simulation; computer vision; distributed representations; concept learning; connectionism and neural nets; natural language processing	FEATURE PRODUCTION NORMS; SEMANTIC MEMORY; LARGE SET; MODEL; LANGUAGE; NETWORK; OBJECTS	In this paper we address the problem of grounding distributional representations of lexical meaning. We introduce a new model which uses stacked autoencoders to learn higher-level representations from textual and visual input. The visual modality is encoded via vectors of attributes obtained automatically from images. We create a new large-scale taxonomy of 600 visual attributes representing more than 500 concepts and 700 K images. We use this dataset to train attribute classifiers and integrate their predictions with text-based distributional models of word meaning. We evaluate our model on its ability to simulate word similarity judgments and concept categorization. On both tasks, our model yields a better fit to behavioral data compared to baselines and related models which either rely on a single modality or do not make use of attribute-based input.	[Silberer, Carina; Ferrari, Vittorio; Lapata, Mirella] Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Midlothian, Scotland; [Silberer, Carina; Lapata, Mirella] Inst Language Cognit & Computat, Edinburgh EH8 9AB, Midlothian, Scotland; [Ferrari, Vittorio] Inst Percept Act & Behav, Edinburgh EH8 9AB, Midlothian, Scotland	University of Edinburgh	Silberer, C (corresponding author), Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Midlothian, Scotland.; Silberer, C (corresponding author), Inst Language Cognit & Computat, Edinburgh EH8 9AB, Midlothian, Scotland.	vittoferrari@gmail.com; mlap@inf.ed.ac.uk						Agirre E., 2007, P 4 INT WORKSH SEM E, P7; ANDERSON JR, 1991, PSYCHOL REV, V98, P409, DOI 10.1037/0033-295X.98.3.409; Andrew G., 2013, INT C MACH LEARN, p1247?1255; Andrews M, 2009, PSYCHOL REV, V116, P463, DOI 10.1037/a0016261; [Anonymous], 2012, HDB PSYCHOL; Barbu Eduard, 2008, P ESSLLI WORKSH DIST, P9; Baroni M, 2010, COGNITIVE SCI, V34, P222, DOI 10.1111/j.1551-6709.2009.01068.x; Barsalou LW, 2008, ANNU REV PSYCHOL, V59, P617, DOI 10.1146/annurev.psych.59.103006.093639; Bengio Y., 2007, P ADV NEUR INF PROC, V19, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Biemann Chris, 2006, P 1 WORKSH GRAPH BAS, P73, DOI DOI 10.3115/1654758.1654774; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Borga M., 2001, CANONICAL CORRELATIO; Bruni E., 2011, P GEMS 2011 WORKSH G, P22; Bruni E., 2013, P 51 ANN M ASS COMP, P187; Bruni E, 2014, J ARTIF INTELL RES, V49, P1, DOI 10.1613/jair.4135; Bruni Elia, 2012, P 50 ANN M ASS COMP, V1, P136, DOI DOI 10.1109/ICRA.2016.7487801; Collobert R, 2011, J MACH LEARN RES, V12, P2493; Cree GS, 1999, COGNITIVE SCI, V23, P371, DOI 10.1207/s15516709cog2303_4; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Devereux B. J., 2010, RES LANGUAG IN PRESS, V7, P137, DOI [DOI 10.1007/S11168-010-9068-8, 10.1007/s11168-010-9068-8]; Duan K, 2012, PROC CVPR IEEE, P3474, DOI 10.1109/CVPR.2012.6248089; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; FARAH MJ, 1991, J EXP PSYCHOL GEN, V120, P339, DOI 10.1037/0096-3445.120.4.339; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Fellbaum Christiane, 1998, WORDNET ELECT DATABA; Feng Y., 2010, 2010 ANN C N AM CHAP, P91; Ferrari Vittorio, 2007, NIPS; Finkelstein L, 2002, ACM T INFORM SYST, V20, P116, DOI 10.1145/503104.503110; Fountain T., 2011, P 33 ANN C COGN SCI, P255; Fountain T, 2010, COGNITION IN FLUX, P1916; Frermann L., 2014, P 14 C EUR CHAPT ASS, P249, DOI [10.3115/v1/E14-1027, DOI 10.3115/V1/E14-1027]; Frome Andrea, 2013, NEURIPS; Glenberg AM, 2002, PSYCHON B REV, V9, P558, DOI 10.3758/BF03196313; Griffiths TL, 2007, PSYCHOL REV, V114, P211, DOI 10.1037/0033-295X.114.2.211; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Harris Z.S, 1970, DISTRIBUTIONAL STRUC, P775; Hill Felix, 2014, EMNLP, DOI [10.3115/v1/D14-1032, DOI 10.3115/V1/D14-1032]; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HINTON GE, 1991, PSYCHOL REV, V98, P74, DOI 10.1037/0033-295X.98.1.74; Hsu A. S., 2012, P 34 ANN C COGN SCI, P485; Huang J, 2013, INT CONF ACOUST SPEE, P7596, DOI 10.1109/ICASSP.2013.6639140; Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353; Johns BT, 2012, TOP COGN SCI, V4, P103, DOI 10.1111/j.1756-8765.2011.01176.x; Jones MichaelN., 2015, OXFORD HDB MATH COMP, P232, DOI DOI 10.1093/OXFORDHB/9780199957996.013.11; Jones R., 2006, P 15 INT C WORLD WID, P387, DOI DOI 10.1145/1135777.1135835; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kelly C., 2010, P NAACL HLT 2010 1 W, P61; Kiela D., 2014, EMNLP, P36, DOI DOI 10.3115/V1/D14-1005; Kiros R., 2014, DEEP LEARN REPR LEAR; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Landau B, 1998, TRENDS COGN SCI, V2, P19, DOI 10.1016/S1364-6613(97)01111-X; Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211; Lazaridou A., 2015, P 2015 C N AM CHAPTE, P153, DOI DOI 10.3115/V1/N15-1016; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mao J., 2014, DEEP CAPTIONING MULT; MCKINLEY SC, 1995, J EXP PSYCHOL HUMAN, V21, P128, DOI 10.1037/0096-1523.21.1.128; McRae K, 2005, BEHAV RES METHODS, V37, P547, DOI 10.3758/BF03192726; Mikolov T., 2013, P 2013 C N AM CHAPTE, P746, DOI DOI 10.3109/10826089109058901; Mikolov Tomas., 2013, ADV NEURAL INF PROCE, V2, P3111, DOI DOI 10.5555/2999792.2999959; MILLER GA, 1991, LANG COGNITIVE PROC, V6, P1, DOI 10.1080/01690969108406936; Nelson D. L., 1998, U S FLOR WORD ASS RH; Ngiam J, 2011, P 28 INT C MACH LEAR, V28, P689, DOI DOI 10.5555/3104482.3104569; Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222; OSHERSON DN, 1991, COGNITIVE SCI, V15, P251, DOI 10.1207/s15516709cog1502_3; Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998; Patwardhan S., 2006, P EACL 2006 WORKSH M, P1; Ranzato M., 2008, P 25 INT C MACHINE L, P792, DOI DOI 10.1145/1390156.1390256; Regier T., 1996, HUMAN SEMANTIC POTEN; Rogers TT, 2004, PSYCHOL REV, V111, P205, DOI 10.1037/0033-295X.111.1.205; Roller S., 2013, 2013 C EMPIRICAL MET, P1146; Rumelhart DE, 1985, TECHNICAL REPORT, DOI 10.1016/b978-1-4832-1446-7.50035-2; Salton G., 1986, INTRO MODERN INFORM; Sanborn A., 2006, P 28 ANN C COGNITIVE, P726; Schutze H., 2008, INTRO INFORM RETRIEV, V39; Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283; Silberer C, 2012, P 2012 JOINT C EMP M, P1423; Silberer C., 2013, P 51 ANN M ASS COMP, P572; Socher R., 2014, J T ASS COMPUT LINGU, V2, P207, DOI DOI 10.1162/TACL_A_00177; Socher Richard, 2013, NEURIPS; Sohn K., 2014, P 27 INT C NEURAL IN, V2, P2141; Srivastava N, 2014, J MACH LEARN RES, V15, P2949; Srivastava Nitish, 2012, ADV NEURAL INFORM PR, P2222, DOI DOI 10.1109/CVPR.2013.49; Szumlanski S, 2013, ACL, P890; Thompson-Schill SL, 1998, J MEM LANG, V38, P440, DOI 10.1006/jmla.1997.2559; Turney PD, 2010, J ARTIF INTELL RES, V37, P141, DOI 10.1613/jair.2934; Vincent P., 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Vinson DP, 2008, BEHAV RES METHODS, V40, P183, DOI 10.3758/BRM.40.1.183; Von Ahn Luis, 2004, P SIGCHI C HUM FACT, P319, DOI DOI 10.1145/985692.985733; Westermann G, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0391; Wu P., 2013, PROC 21 ACM INT C MU, P153, DOI [10.1145/2502081.2502112, DOI 10.1145/2502081.2502112]; Yih W.-T., 2013, P 51 ANN M ASS COMP, P1744	96	18	19	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2017	39	11					2284	2297		10.1109/TPAMI.2016.2635138	http://dx.doi.org/10.1109/TPAMI.2016.2635138			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	FI5MO	28114000	Green Accepted			2022-12-18	WOS:000412028600013
J	Lu, JB; Li, Y; Yang, HS; Min, DB; Eng, WY; Do, MN				Lu, Jiangbo; Li, Yu; Yang, Hongsheng; Min, Dongbo; Eng, Weiyong; Do, Minh N.			PatchMatch Filter: Edge-Aware Filtering Meets Randomized Search for Visual Correspondence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Approximate nearest neighbor; edge-aware filtering; stereo matching; optical flow	OPTICAL-FLOW ESTIMATION; COST AGGREGATION; PROPAGATION; FIELDS	Though many tasks in computer vision can be formulated elegantly as pixel-labeling problems, a typical challenge discouraging such a discrete formulation is often due to computational efficiency. Recent studies on fast cost volume filtering based on efficient edge-aware filters provide a fast alternative to solve discrete labeling problems, with the complexity independent of the support window size. However, these methods still have to step through the entire cost volume exhaustively, which makes the solution speed scale linearly with the label space size. When the label space is huge or even infinite, which is often the case for (subpixel-accurate) stereo and optical flow estimation, their computational complexity becomes quickly unacceptable. Developed to search approximate nearest neighbors rapidly, the PatchMatch method can significantly reduce the complexity dependency on the search space size. But, its pixel-wise randomized search and fragmented data access within the 3D cost volume seriously hinder the application of efficient cost slice filtering. This paper presents a generic and fast computational framework for general multi-labeling problems called PatchMatch Filter (PMF). We explore effective and efficient strategies to weave together these two fundamental techniques developed in isolation, i.e., PatchMatch-based randomized search and efficient edge-aware image filtering. By decompositing an image into compact superpixels, we also propose superpixel-based novel search strategies that generalize and improve the original PatchMatch method. Further motivated to improve the regularization strength, we propose a simple yet effective cross-scale consistency constraint, which handles labeling estimation for large low-textured regions more reliably than a single-scale PMF algorithm. Focusing on dense correspondence field estimation in this paper, we demonstrate PMF's applications in stereo and optical flow. Our PMF methods achieve top-tier correspondence accuracy but run much faster than other related competing methods, often giving over 10-100 times speedup.	[Lu, Jiangbo; Li, Yu] Adv Digital Sci Ctr, Singapore 138632, Singapore; [Yang, Hongsheng] Google, Mountain View, CA 94043 USA; [Min, Dongbo] Chungnam Natl Univ, Daejeon 301747, South Korea; [Eng, Weiyong] Multimedia Univ, Cyberjaya 63000, Malaysia; [Do, Minh N.] Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA	Google Incorporated; Chungnam National University; Multimedia University; University of Illinois System; University of Illinois Urbana-Champaign	Lu, JB (corresponding author), Adv Digital Sci Ctr, Singapore 138632, Singapore.	jiangbo.lu@adsc.com.sg; li.yu@adsc.com.sg; yhs@google.com; dbmin@cnu.ac.kr; engweiyong@gmail.com; minhdo@illinois.edu	N., Minh/AAX-8498-2020; Eng, Wei Yong/V-1728-2019	N., Minh/0000-0001-5132-4986; Eng, Wei Yong/0000-0002-9744-2782; Lu, Jiangbo/0000-0002-0048-3140; LI, Yu/0000-0003-1865-8276	HCCS grant at ADSC from Singapore's A<SUP>star</SUP>STAR; Basic Science Research Program through the National Research Foundation of Korea(NRF) [2015R1D1A1A01061143]	HCCS grant at ADSC from Singapore's A<SUP>star</SUP>STAR; Basic Science Research Program through the National Research Foundation of Korea(NRF)	This study is supported by the HCCS grant at ADSC from Singapore's A<SUP>star</SUP>STAR. D. Min was supported by Basic Science Research Program through the National Research Foundation of Korea(NRF)(2015R1D1A1A01061143). Dongbo Min is the corresponding author.	Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Bailer C, 2015, IEEE I CONF COMP VIS, P4015, DOI 10.1109/ICCV.2015.457; Bao LC, 2014, PROC CVPR IEEE, P3534, DOI 10.1109/CVPR.2014.452; Barnes C, 2010, LECT NOTES COMPUT SC, V6313, P29; Besse F, 2014, INT J COMPUT VISION, V110, P2, DOI 10.1007/s11263-013-0653-9; Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Brox T, 2009, PROC CVPR IEEE, P41, DOI 10.1109/CVPRW.2009.5206697; Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chen ZY, 2013, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR.2013.316; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; He KM, 2012, PROC CVPR IEEE, P111, DOI 10.1109/CVPR.2012.6247665; He KM, 2010, LECT NOTES COMPUT SC, V6311, P1; Heise P, 2013, IEEE I CONF COMP VIS, P2360, DOI 10.1109/ICCV.2013.293; Kim J, 2013, PROC CVPR IEEE, P2307, DOI 10.1109/CVPR.2013.299; Korman S, 2011, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2011.6126421; Lei C, 2009, IEEE I CONF COMP VIS, P1562, DOI 10.1109/ICCV.2009.5459253; Leordeanu M, 2013, IEEE I CONF COMP VIS, P1721, DOI 10.1109/ICCV.2013.216; Li Y, 2015, IEEE I CONF COMP VIS, P4006, DOI 10.1109/ICCV.2015.456; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Lu JB, 2013, PROC CVPR IEEE, P1854, DOI 10.1109/CVPR.2013.242; Lu JB, 2012, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2012.6247705; Mei X, 2011, PROC CVPR IEEE, P1257; Min DB, 2014, IEEE T IMAGE PROCESS, V23, P5638, DOI 10.1109/TIP.2014.2366600; Min DB, 2011, IEEE I CONF COMP VIS, P1567, DOI 10.1109/ICCV.2011.6126416; Paris S, 2008, FOUND TRENDS COMPUT, V4, P1, DOI 10.1561/0600000020; Park J, 2011, IEEE I CONF COMP VIS, P1623, DOI 10.1109/ICCV.2011.6126423; Pradeep V, 2013, INT SYM MIX AUGMENT, P83, DOI 10.1109/ISMAR.2013.6671767; Revaud J, 2015, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR.2015.7298720; Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372; Sevilla-Lara L, 2014, LECT NOTES COMPUT SC, V8689, P423, DOI 10.1007/978-3-319-10590-1_28; Sun DQ, 2014, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2014.144; Sun DQ, 2014, INT J COMPUT VISION, V106, P115, DOI 10.1007/s11263-013-0644-x; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; Taniai T, 2014, PROC CVPR IEEE, P1613, DOI 10.1109/CVPR.2014.209; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175; Xu SB, 2015, IEEE T IMAGE PROCESS, V24, P2182, DOI 10.1109/TIP.2015.2416654; Yamaguchi K, 2013, PROC CVPR IEEE, P1862, DOI 10.1109/CVPR.2013.243; Yang HS, 2014, PROC CVPR IEEE, P3406, DOI 10.1109/CVPR.2014.435; Yang JL, 2015, PROC CVPR IEEE, P1019, DOI 10.1109/CVPR.2015.7298704; Yang QX, 2012, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2012.6247827; Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70; Zitnick C. L., 2007, INT J COMPUT VIS	47	18	20	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2017	39	9					1866	1879		10.1109/TPAMI.2016.2616391	http://dx.doi.org/10.1109/TPAMI.2016.2616391			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FC4WC	27740475				2022-12-18	WOS:000406840800013
J	Martin-Clemente, R; Zarzoso, V				Martin-Clemente, Ruben; Zarzoso, Vicente			On the Link Between L1-PCA and ICA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction or construction; interactive data exploration and discovery; independent component analysis; principal component analysis; L1-norm; multivariate statistics; feature representation; feature evaluation and selection	INDEPENDENT COMPONENT ANALYSIS; L1-NORM; ALGORITHMS	Principal component analysis (PCA) based on L1-norm maximization is an emerging technique that has drawn growing interest in the signal processing and machine learning research communities, especially due to its robustness to outliers. The present work proves that L1-norm PCA can perform independent component analysis (ICA) under the whitening assumption. However, when the source probability distributions fulfil certain conditions, the L1-norm criterion needs to be minimized rather than maximized, which can be accomplished by simple modifications on existing optimal algorithms for L1-PCA. If the sources have symmetric distributions, we show in addition that L1-PCA is linked to kurtosis optimization. A number of numerical experiments illustrate the theoretical results and analyze the comparative performance of different algorithms for ICA via L1-PCA. Although our analysis is asymptotic in the sample size, this equivalence opens interesting new perspectives for performing ICA using optimal algorithms for L1-PCA with guaranteed global convergence while inheriting the increased robustness to outliers of the L1-norm criterion.	[Martin-Clemente, Ruben] Univ Seville, Escuela Super Ingn, Dept Teoria Senal & Comunicac, Avda Descubrimientos S-N, Seville 41092, Spain; [Zarzoso, Vicente] Univ Nice Sophia Antipolis, CNRS, Lab I3S, UMR 7271, CS 40121, F-06903 Sophia Antipolis, France	University of Sevilla; Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; Universite Cote d'Azur	Martin-Clemente, R (corresponding author), Univ Seville, Escuela Super Ingn, Dept Teoria Senal & Comunicac, Avda Descubrimientos S-N, Seville 41092, Spain.	ruben@us.es; zarzoso@i3s.unice.fr	Martin-Clemente, Ruben/E-8977-2012	Martin-Clemente, Ruben/0000-0002-5905-7189	French National Research Agency [ANR-2010-JCJC-0303-01]; Spanish Ministry of Economy and Competitiveness [TEC2014-53103-P]	French National Research Agency(French National Research Agency (ANR)); Spanish Ministry of Economy and Competitiveness(Spanish Government)	This work is partially funded by the French National Research Agency under contract ANR-2010-JCJC-0303-01 "PERSIST" and the Spanish Ministry of Economy and Competitiveness under project TEC2014-53103-P "CMANS". The authors would like to thank the anonymous reviewers for their interesting comments and useful suggestions, which helped to improve the original version of this manuscript.	Allemand K, 2001, MATH PROGRAM, V91, P49, DOI 10.1007/s101070100233; Ben-Ameur W, 2011, DISCRETE APPL MATH, V159, P1689, DOI 10.1016/j.dam.2010.08.028; Brooks JP, 2013, COMPUT STAT DATA AN, V61, P83, DOI 10.1016/j.csda.2012.11.007; Chong E.K.P., 1996, INTRO OPTIMIZATION; Comon P, 2010, HANDBOOK OF BLIND SOURCE SEPARATION: INDEPENDENT COMPONENT ANALYSIS AND APPLICATIONS, P1; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; Cramer H., 1957, MATH METHODS STAT; DELFOSSE N, 1995, SIGNAL PROCESS, V45, P59, DOI 10.1016/0165-1684(95)00042-C; Ding C., 2006, PROC INT C MACH LEAR, P281, DOI DOI 10.1145/1143844.1143880; Ferrez JA, 2005, EUR J OPER RES, V166, P35, DOI 10.1016/j.ejor.2003.04.011; FRIEDMAN JH, 1987, J AM STAT ASSOC, V82, P249, DOI 10.2307/2289161; Hyvarinen A, 1998, SIGNAL PROCESS, V64, P301, DOI 10.1016/S0165-1684(97)00197-7; Hyvarinen A, 1999, IEEE T NEURAL NETWOR, V10, P626, DOI 10.1109/72.761722; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Karystinos GN, 2010, IEEE T INFORM THEORY, V56, P3581, DOI 10.1109/TIT.2010.2048450; Kundu Sandipan, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8028, DOI 10.1109/ICASSP.2014.6855164; Kwak N, 2009, PATTERN RECOGN, V42, P17, DOI 10.1016/j.patcog.2008.07.002; Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114; Leung KK, 2010, IEEE T INFORM THEORY, V56, P3343, DOI 10.1109/TIT.2010.2048457; Li XL, 2010, IEEE T SYST MAN CY B, V40, P1170, DOI 10.1109/TSMCB.2009.2035629; Markopoulos PP, 2014, IEEE T SIGNAL PROCES, V62, P5046, DOI 10.1109/TSP.2014.2338077; McCoy M, 2011, ELECTRON J STAT, V5, P1123, DOI 10.1214/11-EJS636; Meng DY, 2012, PATTERN RECOGN, V45, P487, DOI 10.1016/j.patcog.2011.07.009; Nikias C. L., 2003, HIGHER ORDER SPECTRA; Pang YW, 2010, IEEE T CIRC SYST VID, V20, P172, DOI 10.1109/TCSVT.2009.2020337; Tugnait JK, 1997, IEEE T SIGNAL PROCES, V45, P658, DOI 10.1109/78.558482; Wang HX, 2012, PATTERN RECOGN LETT, V33, P537, DOI 10.1016/j.patrec.2011.11.029; Wang HX, 2012, IEEE T BIO-MED ENG, V59, P653, DOI 10.1109/TBME.2011.2177523; Xu PC, 2013, RADIOENGINEERING, V22, P1194; Yu LB, 2012, INT CONF ACOUST SPEE, P1377, DOI 10.1109/ICASSP.2012.6288147; Zarzoso V, 2012, SIGNAL PROCESS, V92, P1779, DOI 10.1016/j.sigpro.2011.11.003; Zarzoso V, 2010, IEEE T NEURAL NETWOR, V21, P248, DOI 10.1109/TNN.2009.2035920	32	18	18	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2017	39	3					515	528		10.1109/TPAMI.2016.2557797	http://dx.doi.org/10.1109/TPAMI.2016.2557797			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EM8IP	27337712				2022-12-18	WOS:000395555100008
J	Sharma, G; Jurie, F; Schmid, C				Sharma, Gaurav; Jurie, Frederic; Schmid, Cordelia			Expanded Parts Model for Semantic Description of Humans in Still Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human analysis; attributes; actions; semantic description; image classification	HUMAN POSE ESTIMATION; AGE ESTIMATION; ACTION RECOGNITION; SPARSE; HISTOGRAMS; FEATURES; SCENE	We introduce an Expanded Parts Model (EPM) for recognizing human attributes (e.g., young, short hair, wearing suits) and actions (e.g., running, jumping) in still images. An EPM is a collection of part templates which are learnt discriminatively to explain specific scale-space regions in the images (in human centric coordinates). This is in contrast to current models which consist of a relatively few (i.e., a mixture of) 'average' templates. EPM uses only a subset of the parts to score an image and scores the image sparsely in space, i.e., it ignores redundant and random background in an image. To learn our model, we propose an algorithm which automatically mines parts and learns corresponding discriminative templates together with their respective locations from a large number of candidate parts. We validate our method on three recent challenging datasets of human attributes and actions. We obtain convincing qualitative and state-of-the-art quantitative results on the three datasets.	[Sharma, Gaurav] Max Planck Inst Informat, D-66123 Saarbrucken, Germany; [Jurie, Frederic] Univ Caen Basse Normandie, GREYC CNRS UMR 6072, F-14000 Caen, France; [Schmid, Cordelia] INRIA Grenoble, LEAR, Montbonnot St Martin, France	Max Planck Society; Centre National de la Recherche Scientifique (CNRS); Universite de Caen Normandie	Sharma, G (corresponding author), Max Planck Inst Informat, D-66123 Saarbrucken, Germany.	grvsharma@gmail.com; frederic.jurie@unicaen.fr; cordelia.schmid@inria.fr		IIT Hyderabad, EE Department/0000-0002-5880-4023	OSEO; French State agency for innovation; ANR [ANR-2010-CORD-103-06]; ERC advanced grant ALLEGRO	OSEO; French State agency for innovation; ANR(French National Research Agency (ANR)); ERC advanced grant ALLEGRO	This work was partly realized as part of the Quaero Programme, funded by OSEO, French State agency for innovation, by the ANR (grant reference ANR-2010-CORD-103-06) and by the ERC advanced grant ALLEGRO.	Adam A., 2006, IEEE C COMP VIS PATT; Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471; [Anonymous], 2015, P INT C LEARN REPR; [Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598; Bourdev L, 2011, IEEE I CONF COMP VIS, P1543, DOI 10.1109/ICCV.2011.6126413; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; BOUREAU YL, 2010, PROC CVPR IEEE, P2559, DOI DOI 10.1109/CVPR.2010.5539963; Chang KY, 2015, IEEE T IMAGE PROCESS, V24, P785, DOI 10.1109/TIP.2014.2387379; Charles J, 2014, INT J COMPUT VISION, V110, P70, DOI 10.1007/s11263-013-0672-6; Chen HZ, 2012, LECT NOTES COMPUT SC, V7574, P609, DOI 10.1007/978-3-642-33712-3_44; Crow F. C., 1984, Computers & Graphics, V18, P207; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dantone M, 2014, IEEE T PATTERN ANAL, V36, P2131, DOI 10.1109/TPAMI.2014.2318702; Delaitre V., 2011, ADV NEURAL INFORM PR, P1503; Delaitre V., 2010, P BRIT MACH VIS C; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Desai C, 2012, LECT NOTES COMPUT SC, V7575, P158, DOI 10.1007/978-3-642-33765-9_12; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Everingham M., 2012, PASCAL VISUAL OBJECT; Fan XC, 2015, PROC CVPR IEEE, P1347, DOI 10.1109/CVPR.2015.7298740; Fathi A, 2008, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2008.4587735; Fergus R, 2007, INT J COMPUT VISION, V71, P273, DOI 10.1007/s11263-006-8707-x; Fowlkes C., 2010, P IEEE COMP SOC C CO, P9; Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733; Guha T, 2012, IEEE T PATTERN ANAL, V34, P1576, DOI 10.1109/TPAMI.2011.253; Guo GD, 2014, PATTERN RECOGN, V47, P3343, DOI 10.1016/j.patcog.2014.04.018; Guo GD, 2012, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2012.6247972; Guo GD, 2009, IEEE I CONF COMP VIS, P1986, DOI 10.1109/ICCV.2009.5459438; Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83; Hussain S., 2010, P BRIT MACH VIS C; Jain M, 2014, PROC CVPR IEEE, P740, DOI 10.1109/CVPR.2014.100; Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Jia K, 2011, IEEE I CONF COMP VIS, P2391, DOI 10.1109/ICCV.2011.6126522; Joo J, 2013, IEEE I CONF COMP VIS, P721, DOI 10.1109/ICCV.2013.95; Juneja M, 2013, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2013.124; Khan FS, 2013, INT J COMPUT VISION, V105, P205, DOI 10.1007/s11263-013-0633-0; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Li CS, 2012, PROC CVPR IEEE, P2570, DOI 10.1109/CVPR.2012.6247975; Li L.-J., 2010, NEURAL INFORM PROCES, P1378; Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406; Liu D., 2012, J GUANGDONG IND U, V12, P12; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Ma SG, 2012, LECT NOTES COMPUT SC, V7585, P61, DOI 10.1007/978-3-642-33885-4_7; Mairal J, 2010, J MACH LEARN RES, V11, P19; Maji S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3177, DOI 10.1109/CVPR.2011.5995631; Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Oneata D, 2014, PROC CVPR IEEE, P2545, DOI 10.1109/CVPR.2014.326; Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222; Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383; Parizi SN, 2015, INT C LEARN REPR SAN; Perronnin F, 2012, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2012.6248090; Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188; Prest A, 2012, IEEE T PATTERN ANAL, V34, P601, DOI 10.1109/TPAMI.2011.158; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Rudovic O, 2013, IEEE T PATTERN ANAL, V35, P1357, DOI 10.1109/TPAMI.2012.233; Sabzmeydani P, 2007, PROC CVPR IEEE, P1251; Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465; Shao M, 2013, IEEE I CONF COMP VIS, P3631, DOI 10.1109/ICCV.2013.451; Sharma G, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.6; Sharma G, 2013, PROC CVPR IEEE, P652, DOI 10.1109/CVPR.2013.90; Sharma G, 2012, LECT NOTES COMPUT SC, V7578, P1, DOI 10.1007/978-3-642-33786-4_1; Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Singh S, 2012, LECT NOTES COMPUT SC, V7573, P73, DOI 10.1007/978-3-642-33709-3_6; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Sun J, 2013, IEEE I CONF COMP VIS, P3400, DOI 10.1109/ICCV.2013.422; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Thurau C., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587721; Tompson J.J., 2014, ADV NEURAL INF PROCE, P1799, DOI DOI 10.5555/2968826.2969027; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412; Vedaldi A, 2010, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2010.5539949; Veksler O, 2003, PROC CVPR IEEE, P556; Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82; Viola P., 2001, INT J COMPUT VISION, V4, P51; Wan SH, 2014, PATTERN RECOGN, V47, P1859, DOI 10.1016/j.patcog.2013.11.025; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; WANG JJ, 2010, PROC CVPR IEEE, P3360, DOI DOI 10.1109/CVPR.2010.5540018; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yan SY, 2012, LECT NOTES COMPUT SC, V7575, P473, DOI 10.1007/978-3-642-33765-9_34; Yang JC, 2010, LECT NOTES COMPUT SC, V6315, P113, DOI 10.1007/978-3-642-15555-0_9; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757; Yang WL, 2010, PROC CVPR IEEE, P2030, DOI 10.1109/CVPR.2010.5539879; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Yao BP, 2012, LECT NOTES COMPUT SC, V7575, P173, DOI 10.1007/978-3-642-33765-9_13; Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386; Yao BP, 2011, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR.2011.5995368; Yao BP, 2010, PROC CVPR IEEE, P9, DOI 10.1109/CVPR.2010.5540234; YAO BP, 2010, PROC CVPR IEEE, P17, DOI DOI 10.1109/CVPR.2010.5540235; Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212; Zhu X., 2012, P BRIT MACH VIS C; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	105	18	18	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2017	39	1					87	101		10.1109/TPAMI.2016.2537325	http://dx.doi.org/10.1109/TPAMI.2016.2537325			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EF6DP	26955016	Green Submitted			2022-12-18	WOS:000390421300009
J	Proenca, H; Neves, JC; Barra, S; Marques, T; Moreno, JC				Proenca, Hugo; Neves, Joao C.; Barra, Silvio; Marques, Tiago; Moreno, Juan C.			Joint Head Pose/Soft Label Estimation for Human Recognition In-The-Wild	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Soft biometrics; visual surveillance; homeland security; privacy-preserving recognition	POSE ESTIMATION; SOFT BIOMETRICS; FACE; BODY	Soft biometrics have been emerging to complement other traits and are particularly useful for poor quality data. In this paper, we propose an efficient algorithm to estimate human head poses and to infer soft biometric labels based on the 3D morphology of the human head. Starting by considering a set of pose hypotheses, we use a learning set of head shapes synthesized from anthropometric surveys to derive a set of 3D head centroids that constitutes a metric space. Next, representing queries by sets of 2D head landmarks, we use projective geometry techniques to rank efficiently the joint 3D head centroids/pose hypotheses according to their likelihood of matching each query. The rationale is that the most likely hypotheses are sufficiently close to the query, so a good solution can be found by convex energy minimization techniques. Once a solution has been found, the 3D head centroid and the query are assumed to have similar morphology, yielding the soft label. Our experiments point toward the usefulness of the proposed solution, which can improve the effectiveness of face recognizers and can also be used as a privacy-preserving solution for biometric recognition in public environments.	[Proenca, Hugo; Neves, Joao C.; Marques, Tiago; Moreno, Juan C.] Univ Beira Interior, Dept Comp Sci, IT Inst Telecomunicacoes, Covilha, Portugal; [Barra, Silvio] Univ Cagliari, Cagliari, Italy	Universidade da Beira Interior; University of Cagliari	Proenca, H (corresponding author), Univ Beira Interior, Dept Comp Sci, IT Inst Telecomunicacoes, Covilha, Portugal.	hugomcp@di.ubi.pt; jcneves@di.ubi.pt; silvio.barra@unica.it; tmarques@di.ubi.pt; jcmb@di.ubi.pt	Neves, João/G-6477-2016; Proença, Hugo/F-9499-2010; Barra, Silvio/J-8577-2019	Neves, João/0000-0003-0139-2213; Proença, Hugo/0000-0003-2551-8570; Barra, Silvio/0000-0003-4042-3000	FCT [UID/EEA/50008/2013]	FCT(Portuguese Foundation for Science and TechnologyEuropean Commission)	This work was supported by FCT project UID/EEA/50008/2013.	An KH, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P307, DOI 10.1109/IROS.2008.4650742; Arashloo S. R., 2013, P IEEE 6 INT C BIOM, P1, DOI DOI 10.1109/BTAS.2013.6712721; Ba S.O., 2005, P IEEE INT C MULT EX, P1330; Byrd RH, 1999, SIAM J OPTIMIZ, V9, P877, DOI 10.1137/S1052623497325107; Dass J, 2013, P 4 NAT C COMP VIS P, P1; Drosou A, 2012, IEEE SIGNAL PROC LET, V19, P833, DOI 10.1109/LSP.2012.2221701; Efraty B, 2011, P INT JOINT C BIOM O, P1; Eleftheriadis S, 2015, IEEE T IMAGE PROCESS, V24, P189, DOI 10.1109/TIP.2014.2375634; Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2; Heckathorn D., 1997, P ANN M AM SOC ASS T, P543; Heckathorn D., 1954, 52321 WRIGHT AIR DEV; Hewig J, 2008, J NONVERBAL BEHAV, V32, P67, DOI 10.1007/s10919-007-0043-5; Huang GB, 2007, IEEE I CONF COMP VIS, P237, DOI 10.1109/iccv.2007.4408858; Huang KS, 2004, INT C PATT RECOG, P965, DOI 10.1109/ICPR.2004.1334689; Jain AK, 2004, PROC SPIE, V5404, P561, DOI 10.1117/12.542890; Jain AK, 2009, IEEE IMAGE PROC, P37, DOI 10.1109/ICIP.2009.5413921; Jaiswal S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P370, DOI 10.1109/ICCVW.2013.56; Kim MG, 2012, J BIOMED BIOTECHNOL, DOI 10.1155/2012/614146; Koestinger M., 2011, ICCV WORKSH, DOI [10.1109/ICCVW.2011.6130513, DOI 10.1109/ICCVW.2011.6130513]; KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288; Krinidis M., 2009, IEEE T CIRCUITS SYST, V19, P161; Kruger N, 1997, IMAGE VISION COMPUT, V15, P665, DOI 10.1016/S0262-8856(97)00012-7; KWOLEK B, 2006, P GEOM MOD IM NEW TR, P203; Lagarias JC, 1998, SIAM J OPTIMIZ, V9, P112, DOI 10.1137/S1052623496303470; Li YM, 2004, IMAGE VISION COMPUT, V22, P413, DOI 10.1016/j.imavis.2003.12.005; Lucas T., 2015, INT J LEGAL MED, P1, DOI DOI 10.1007/S00414-015-1158-6; Lucey P., 2010, P IEEE COMP SOC C CO, P94, DOI [10.1109/CVPRW.2010.5543262, DOI 10.1109/CVPRW.2010.5543262]; Moreno-Noguer F, 2008, LECT NOTES COMPUT SC, V5303, P405, DOI 10.1007/978-3-540-88688-4_30; Moustakas K, 2010, IEEE SIGNAL PROC LET, V17, P367, DOI 10.1109/LSP.2010.2040927; Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106; Osadchy M, 2007, J MACH LEARN RES, V8, P1197; Park U, 2010, IEEE T INF FOREN SEC, V5, P406, DOI 10.1109/TIFS.2010.2049842; Rapp V., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P265, DOI 10.1109/FG.2011.5771409; Reid DA, 2013, HANDB STAT, V31, P327, DOI 10.1016/B978-0-444-53859-8.00013-8; Reid DA, 2014, IEEE T PATTERN ANAL, V36, P1216, DOI 10.1109/TPAMI.2013.219; Rice A, 2013, APPL COGNITIVE PSYCH, V27, P761, DOI 10.1002/acp.2969; Sanchez-Riera J, 2010, PROC CVPR IEEE, P1189, DOI 10.1109/CVPR.2010.5539831; Sherrah J, 2001, IMAGE VISION COMPUT, V19, P807, DOI 10.1016/S0262-8856(00)00096-2; Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77; Tome P, 2014, IEEE T INF FOREN SEC, V9, P464, DOI 10.1109/TIFS.2014.2299975; Tu JL, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P573; Wu J, 2008, PATTERN RECOGN, V41, P1138, DOI 10.1016/j.patcog.2007.07.017; Xiao J, 2004, PROC CVPR IEEE, P535; Young J. W., 1993, DOTFAAAM9310 OFF AV DOTFAAAM9310 OFF AV; Zhang CZ, 2002, IEEE T IMAGE PROCESS, V11, P1249, DOI 10.1109/TIP.2002.804277; Zhang X, 2009, PATTERN RECOGN, V42, P2876, DOI 10.1016/j.patcog.2009.04.017; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014; Zhu Z., 2006, 2006 IEEE COMP SOC C, V1, P681, DOI DOI 10.1109/CVPR.2006.259	48	18	18	1	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2016	38	12					2444	2456		10.1109/TPAMI.2016.2522441	http://dx.doi.org/10.1109/TPAMI.2016.2522441			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EC2WJ	27824583				2022-12-18	WOS:000387984700008
J	Najafi, A; Joudaki, A; Fatemizadeh, E				Najafi, Amir; Joudaki, Amir; Fatemizadeh, Emad			Nonlinear Dimensionality Reduction via Path-Based Isometric Mapping	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	27th IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 23-28, 2014	Columbus, OH	Comp Vis Fdn, IEEE, IEEE Comp Soc		Nonlinear dimensionality reduction; manifold learning; geodesic path; optimization criteria	COMPONENT ANALYSIS; EIGENMAPS	Nonlinear dimensionality reduction methods have demonstrated top-notch performance in many pattern recognition and image classification tasks. Despite their popularity, they suffer from highly expensive time and memory requirements, which render them inapplicable to large-scale datasets. To leverage such cases we propose a new method called " Path-Based Isomap". Similar to Isomap, we exploit geodesic paths to find the low-dimensional embedding. However, instead of preserving pairwise geodesic distances, the low-dimensional embedding is computed via a path-mapping algorithm. Due to the much fewer number of paths compared to number of data points, a significant improvement in time and memory complexity with a comparable performance is achieved. The method demonstrates state-of-the-art performance on well-known synthetic and real-world datasets, as well as in the presence of noise.	[Najafi, Amir; Joudaki, Amir; Fatemizadeh, Emad] Sharif Univ Technol, Dept Elect Engn, Biomed Signal & Image Proc Lab BiSIPL, Tehran, Iran	Sharif University of Technology	Najafi, A (corresponding author), Sharif Univ Technol, Dept Elect Engn, Biomed Signal & Image Proc Lab BiSIPL, Tehran, Iran.	najafi@ee.sharif.edu; joudaki@ce.sharif.edu; fatemizadeh@sharif.edu		Najafi, Amir/0000-0002-6680-0110				Balasubramanian M, 2002, SCIENCE, V295; Baraniuk RG, 2009, FOUND COMPUT MATH, V9, P51, DOI 10.1007/s10208-007-9011-z; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bernstein M., 2000, GRAPH APPROXIMATIONS; BERRY MW, 1992, INT J SUPERCOMPUT AP, V6, P13, DOI 10.1177/109434209200600103; Boothe P., 2007, P C NUM, P145; BORG I., 2005, MODERN MULTIDIMENSIO, P207; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006; De Silva Vin., 2004, SPARSE MULTIDIMENSIO; De Silva Vin, 2002, NIPS 02 P 15 INT C N, V15, P705, DOI DOI 10.5555/2968618.2968708; Demartines P, 1997, IEEE T NEURAL NETWOR, V8, P148, DOI 10.1109/72.554199; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100; Even Sh., 2011, GRAPH ALGORITHMS; Freifeld O, 2014, PROC CVPR IEEE, P1378, DOI 10.1109/CVPR.2014.179; Geng B, 2012, IEEE T PATTERN ANAL, V34, P1227, DOI 10.1109/TPAMI.2012.57; Gneiting T, 2012, STAT SCI, V27, P247, DOI 10.1214/11-STS370; Guo GD, 2011, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2011.5995404; Hegde C., 2012, PREPRINT; Henry E R, 2010, ESSENTIAL NUMERICAL, V210, P81, DOI 10.1016/0076-6879(92)10010-b; Hinton GE., 2002, NIPS, V15, P833; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Kohonen T, 2001, SPRINGER SERIES INFO, V30, P502; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lespinats S, 2009, NEUROCOMPUTING, V72, P2964, DOI 10.1016/j.neucom.2009.04.008; Li M, 2015, IEEE T NEUR NET LEAR, V26, P152, DOI 10.1109/TNNLS.2014.2359798; Lunga D, 2014, IEEE SIGNAL PROC MAG, V31, P55, DOI 10.1109/MSP.2013.2279894; OSSERMAN R, 1978, B AM MATH SOC, V84, P1182, DOI 10.1090/S0002-9904-1978-14553-4; PALLOTTINO S, 1984, NETWORKS, V14, P257, DOI 10.1002/net.3230140206; Platt J. C., 2005, P 10 INT WORKSH ART, P261; Rosman G, 2010, INT J COMPUT VISION, V89, P56, DOI 10.1007/s11263-010-0322-1; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saul LK, 2004, J MACH LEARN RES, V4, P119, DOI 10.1162/153244304322972667; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Seidl T., 1998, SIGMOD Record, V27, P154, DOI 10.1145/276305.276319; Talwalkar A, 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587670; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Timofte R, 2012, PROC CVPR IEEE, P2456, DOI 10.1109/CVPR.2012.6247960; van der Maaten LJP, 2009, 2009005 TICC TR MAAS; Wang C, 2008, P 25 INT C MACH LEAR, P1120, DOI DOI 10.1145/1390156.1390297; Wang Jianzhong, 2011, GEOMETRIC STRUCTURE, P221; Weinberger K. Q., 2006, AAAI, V6, P1683; Welling M., 2005, TECHNICAL REPORTS; Zha HY, 2009, SIAM REV, V51, P545, DOI 10.1137/060676829; Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154; Zhuo L, 2014, NEUROCOMPUTING, V141, P202, DOI 10.1016/j.neucom.2014.03.014	45	18	18	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2016	38	7							1452	10.1109/TPAMI.2015.2487981	http://dx.doi.org/10.1109/TPAMI.2015.2487981			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	DO6MH	26452249	Green Submitted			2022-12-18	WOS:000377897100014
J	Cherian, A; Morellas, V; Papanikolopoulos, N				Cherian, Anoop; Morellas, Vassilios; Papanikolopoulos, Nikolaos			Bayesian Nonparametric Clustering for Positive Definite Matrices	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Region covariances; Dirichlet process; nonparametric methods; positive definite matrices	KERNEL DENSITY-ESTIMATION; DIRICHLET PROCESSES; INFERENCE	Symmetric Positive Definite (SPD) matrices emerge as data descriptors in several applications of computer vision such as object tracking, texture recognition, and diffusion tensor imaging. Clustering these data matrices forms an integral part of these applications, for which soft-clustering algorithms (K-Means, expectation maximization, etc.) are generally used. As is well-known, these algorithms need the number of clusters to be specified, which is difficult when the dataset scales. To address this issue, we resort to the classical nonparametric Bayesian framework by modeling the data as a mixture model using the Dirichlet process (DP) prior. Since these matrices do not conform to the Euclidean geometry, rather belongs to a curved Riemannian manifold, existing DP models cannot be directly applied. Thus, in this paper, we propose a novel DP mixture model framework for SPD matrices. Using the log-determinant divergence as the underlying dissimilarity measure to compare these matrices, and further using the connection between this measure and the Wishart distribution, we derive a novel DPM model based on the Wishart-Inverse-Wishart conjugate pair. We apply this model to several applications in computer vision. Our experiments demonstrate that our model is scalable to the dataset size and at the same time achieves superior accuracy compared to several state-of-the-art parametric and nonparametric clustering algorithms.	[Cherian, Anoop] Australian Natl Univ, Australian Ctr Robot Vis, Canberra, ACT, Australia; [Morellas, Vassilios; Papanikolopoulos, Nikolaos] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN USA	Australian Centre for Robotic Vision; Australian National University; University of Minnesota System; University of Minnesota Twin Cities	Cherian, A (corresponding author), Australian Natl Univ, Australian Ctr Robot Vis, Canberra, ACT, Australia.; Morellas, V; Papanikolopoulos, N (corresponding author), Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN USA.	anoop.cherian@anu.edu.au; morellas@cs.umn.edu; npapas@cs.umn.edu			Honeywell; National Science Foundation [IIP-0934327, CNS-1039741, SMA-1028076, CNS-1338042, IIS-1427014, IIP-1439728, CNS-1514626]	Honeywell; National Science Foundation(National Science Foundation (NSF))	The authors would like to thank Prof. Arindam Banerjee (University of Minnesota) for many helpful discussions. This material is based upon work supported in part by Honeywell, and the National Science Foundation through grants #IIP-0934327, #CNS-1039741, #SMA-1028076, #CNS-1338042, #IIS-1427014, #IIP-1439728, and #CNS-1514626.	Alexander DC, 2001, IEEE T MED IMAGING, V20, P1131, DOI 10.1109/42.963816; Anderson T.W, 1958, INTRO MULTIVARIATE S; [Anonymous], 2010, BAYESIAN NONPARAMETR; [Anonymous], FDN INTELLIGENT SYST; ANTONIAK CE, 1974, ANN STAT, V2, P1152, DOI 10.1214/aos/1176342871; Arsigny V, 2006, MAGN RESON MED, V56, P411, DOI 10.1002/mrm.20965; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; Beal MJ, 2002, ADV NEUR IN, V14, P577; Belkin M, 2002, ADV NEUR IN, V14, P585; Bini D., 2011, P LIN ALG APPL, V438, P1700; BLACKWELL D, 1973, ANN STAT, V1, P353, DOI 10.1214/aos/1176342372; Blei DM, 2006, BAYESIAN ANAL, V1, P121, DOI 10.1214/06-BA104; Bouguila N, 2010, IEEE T NEURAL NETWOR, V21, P107, DOI 10.1109/TNN.2009.2034851; Bregman L. M., 1967, COMP MATH MATH PHYS+, V7, P200, DOI DOI 10.1016/0041-5553(67)90040-7; Caron F, 2008, IEEE T SIGNAL PROCES, V56, P71, DOI 10.1109/TSP.2007.900167; Cherian A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3417, DOI 10.1109/CVPR.2011.5995723; Davis J. V., 2007, ADV NEURAL INFORM PR, P337; de Luis-Garcia R, 2008, SIGNAL PROCESS, V88, P776, DOI 10.1016/j.sigpro.2007.09.019; Dhillon IS, 2007, SIAM J MATRIX ANAL A, V29, P1120, DOI 10.1137/060649021; Eaton M. L., 1983, MULTIVARIATE STAT VE; ESCOBAR MD, 1995, J AM STAT ASSOC, V90, P577, DOI 10.2307/2291069; FANO U, 1957, REV MOD PHYS, V29, P74, DOI 10.1103/RevModPhys.29.74; Ferguson T. S, 1983, RECENT ADV STAT, P287; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; Ferro-Famil L, 2001, IEEE T GEOSCI REMOTE, V39, P2332, DOI 10.1109/36.964969; Finetti B.D., 1972, PROBABILITY INDUCTIO; Forstner W., 1999, TECHNICAL REPORT; Goh A, 2008, 2008 IEEE C COMP VIS, P1; Griffiths T., 2004, P ADV NEUR INF PROC, P1; Harandi M. T., 2012, P EUR C COMP VIS; Harandi MT, 2014, LECT NOTES COMPUT SC, V8690, P17, DOI 10.1007/978-3-319-10605-2_2; Henry G, 2009, J MATH IMAGING VIS, V34, P235, DOI 10.1007/s10851-009-0145-2; Hidot S, 2010, PATTERN RECOGN LETT, V31, P2318, DOI 10.1016/j.patrec.2010.07.002; Ishwaran H, 2001, J AM STAT ASSOC, V96, P161, DOI 10.1198/016214501750332758; James W., 1961, P 4 BERKELEY S MATH, V1, P361, DOI DOI 10.1007/978-1-4612-0919-5; Jayasumana S, 2013, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2013.17; Kai Guo, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P188, DOI 10.1109/AVSS.2010.71; Kivinen JJ, 2007, IEEE I CONF COMP VIS, P329; Kottas A, 2008, BIOMETRICAL J, V50, P29, DOI 10.1002/bimj.200610375; KSHIRSAGAR AM, 1959, ANN MATH STAT, V30, P239, DOI 10.1214/aoms/1177706379; Kurihara K, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2796; Laws K. I., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238, P376; Leibe B, 2003, PROC CVPR IEEE, P409; Li LJ, 2010, INT J COMPUT VISION, V88, P147, DOI 10.1007/s11263-009-0265-6; Liang P., 2009, PROBABILISTIC GRAMMA; LIU JS, 1994, J AM STAT ASSOC, V89, P958, DOI 10.2307/2290921; Ma B., 2012, P BRIT MACH VIS C, P11; Manning C. D., 2008, INTRO INFORM RETRIEV, V1; Neal RM, 2000, J COMPUT GRAPH STAT, V9, P249, DOI 10.2307/1390653; Neyman J, 1933, PHILOS T R SOC LOND, V231, P289, DOI 10.1098/rsta.1933.0009; Ng A. Y., 2002, P ADV NEUR INF PROC, p[2, 849]; Pang YW, 2008, IEEE T CIRC SYST VID, V18, P989, DOI 10.1109/TCSVT.2008.924108; Pelletier B, 2005, STAT PROBABIL LETT, V73, P297, DOI 10.1016/j.spl.2005.04.004; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Porikli F, 2006, P IEEE COMP SOC C CO, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42; SETHURAMAN J, 1994, STAT SINICA, V4, P639; Shinohara Y, 2010, INT CONF ACOUST SPEE, P4326, DOI 10.1109/ICASSP.2010.5495661; Sivalingam R, 2010, LECT NOTES COMPUT SC, V6314, P722, DOI 10.1007/978-3-642-15561-1_52; Subbarao R, 2009, INT J COMPUT VISION, V84, P1, DOI 10.1007/s11263-008-0195-8; Sudderth E. B., 2006, THESIS MIT CAMBRIDGE; Torralba A., 2006, ADV NEURAL INFORM PR, P1297; Tosato D, 2010, LECT NOTES COMPUT SC, V6312, P378, DOI 10.1007/978-3-642-15552-9_28; Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589; Wagner Silke, 2007, COMP CLUSTERINGS OVE; Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965; Wang XG, 2011, NEUROIMAGE, V54, P290, DOI 10.1016/j.neuroimage.2010.07.050; West M, 1992, HYPERPARAMETER ESTIM; Xing EP, 2007, J COMPUT BIOL, V14, P267, DOI 10.1089/cmb.2006.0102; Zhang Z., 2010, J MACHINE LEARNING R, P980	72	18	21	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2016	38	5					862	874		10.1109/TPAMI.2015.2456903	http://dx.doi.org/10.1109/TPAMI.2015.2456903			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DJ4GZ	27046838	hybrid, Green Submitted			2022-12-18	WOS:000374164700003
J	He, XF; Zhang, CY; Zhang, LJ; Li, XL				He, Xiaofei; Zhang, Chiyuan; Zhang, Lijun; Li, Xuelong			A-Optimal Projection for Image Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dimensionality reduction; optimal design; image representation	REGRESSION; RETRIEVAL; REDUCTION	We consider the problem of image representation from the perspective of statistical design. Recent studies have shown that images are possibly sampled from a low dimensional manifold despite of the fact that the ambient space is usually very high dimensional. Learning low dimensional image representations is crucial for many image processing tasks such as recognition and retrieval. Most of the existing approaches for learning low dimensional representations, such as principal component analysis (PCA) and locality preserving projections (LPP), aim at discovering the geometrical or discriminant structures in the data. In this paper, we take a different perspective from statistical experimental design, and propose a novel dimensionality reduction algorithm called A-Optimal Projection (AOP). AOP is based on a linear regression model. Specifically, AOP finds the optimal basis functions so that the expected prediction error of the regression model can be minimized if the new representations are used for training the model. Experimental results suggest that the proposed approach provides a better representation and achieves higher accuracy in image retrieval.	[He, Xiaofei; Zhang, Chiyuan] Zhejiang Univ, Coll Comp Sci, State Key Lab CAD & CG, Hangzhou 310058, Zhejiang, Peoples R China; [Zhang, Lijun] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China; [Li, Xuelong] Chinese Acad Sci, Xian Inst Opt & Precis Mech, Ctr Opt IMagery Anal & Learning OPTIMAL, State key Lab Transient Opt & Photon, Xian 710119, Shaanxi, Peoples R China	Zhejiang University; Nanjing University; Chinese Academy of Sciences; Xi'an Institute of Optics & Precision Mechanics, CAS; State Key Laboratory of Transient Optics & Photonics	He, XF; Zhang, CY (corresponding author), Zhejiang Univ, Coll Comp Sci, State Key Lab CAD & CG, Hangzhou 310058, Zhejiang, Peoples R China.; Zhang, LJ (corresponding author), Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.; Li, XL (corresponding author), Chinese Acad Sci, Xian Inst Opt & Precis Mech, Ctr Opt IMagery Anal & Learning OPTIMAL, State key Lab Transient Opt & Photon, Xian 710119, Shaanxi, Peoples R China.	xiaofeihe@cad.zju.edu.cn; pluskid@gmail.com; zhanglj@lamda.nju.edu.cn; xuelong_li@opt.ac.cn	Li, Xuelong/ABF-3381-2020; li, xiang/GWM-6319-2022; Li, Xuelong/Z-3785-2019	Li, Xuelong/0000-0002-0019-4197	National Basic Research Program of China (973 Program) [2012CB316400]; National Program for Special Support of Top-Notch Young Professionals; National Natural Science Foundation of China [61233011, 61125203]	National Basic Research Program of China (973 Program)(National Basic Research Program of China); National Program for Special Support of Top-Notch Young Professionals; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by National Basic Research Program of China (973 Program) under Grant 2012CB316400, National Program for Special Support of Top-Notch Young Professionals, and National Natural Science Foundation of China under Grant 61233011 and Grant 61125203.	Aswani A, 2011, ANN STAT, V39, P48, DOI 10.1214/10-AOS823; Atkinson A., 2007, OPTIMUM EXPT DESIGNS, V34; Belkin M, 2002, ADV NEUR IN, V14, P585; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Boyd S, 2004, CONVEX OPTIMIZATION; Cai D., 2007, P IEEE INT C COMP VI, P1; Chen Yixin, 2003, P 5 ACM SIGMM INT WO, P193; Chung F., 1997, REGIONAL C SERIES MA, V92; GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9; Gordon S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P370; He X., 2004, P 12 ANN ACM INT C M, P17, DOI [10.1145/1027527.1027532, DOI 10.1145/1027527.1027532]; He XF, 2004, ADV NEUR IN, V16, P153; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Huijsmans DP, 2005, IEEE T PATTERN ANAL, V27, P245, DOI 10.1109/TPAMI.2005.30; JOLLIFFE IT, 1982, APPL STAT-J ROY ST C, V31, P300, DOI 10.2307/2348005; LI KC, 1991, J AM STAT ASSOC, V86, P316, DOI 10.2307/2290563; Li XL, 2008, IEEE T SYST MAN CY B, V38, P342, DOI 10.1109/TSMCB.2007.911536; Liu W., 2008, P 2008 INT C CONT BA, P119; Liu W, 2008, IEEE DATA MINING, P433, DOI 10.1109/ICDM.2008.101; Nilsson J., 2007, P INT C MACHINE LEAR, P697; Park J., 2008, P IEEE C COMP VIS PA, P1; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Tao DC, 2006, IEEE T MULTIMEDIA, V8, P716, DOI 10.1109/TMM.2005.861375; Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Yen-Yu Lin, 2005, 13th Annual ACM International Conference on Multimedia, P249, DOI 10.1145/1101149.1101193; Yu H., 2002, P INT C IM PROC ICIP, P24; Yu J., 2006, P 14 ANN ACM INT C M, P297; Zhang L., 2009, P 17 ACM INT C MULT, P45; Zhang L., 2010, P 18 ACM INT C MULT, P173	32	18	20	1	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2016	38	5					1009	1015		10.1109/TPAMI.2015.2439252	http://dx.doi.org/10.1109/TPAMI.2015.2439252			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DJ4GZ	26353361				2022-12-18	WOS:000374164700013
J	Biswas, SK; Milanfar, P				Biswas, Sujoy Kumar; Milanfar, Peyman			One Shot Detection with Laplacian Object and Fast Matrix Cosine Similarity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						One shot object detection; graph based dimensionality reduction; fourier transform; fast detection	FACE; DIMENSIONALITY; REPRESENTATION; CLASSIFICATION; KERNEL; SHAPE	One shot, generic object detection involves searching for a single query object in a larger target image. Relevant approaches have benefited from features that typically model the local similarity patterns. In this paper, we combine local similarity (encoded by local descriptors) with a global context (i.e., a graph structure) of pairwise affinities among the local descriptors, embedding the query descriptors into a low dimensional but discriminatory subspace. Unlike principal components that preserve global structure of feature space, we actually seek a linear approximation to the Laplacian eigenmap that permits us a locality preserving embedding of high dimensional region descriptors. Our second contribution is an accelerated but exact computation of matrix cosine similarity as the decision rule for detection, obviating the computationally expensive sliding window search. We leverage the power of Fourier transform combined with integral image to achieve superior runtime efficiency that allows us to test multiple hypotheses (for pose estimation) within a reasonably short time. Our approach to one shot detection is training-free, and experiments on the standard data sets confirm the efficacy of our model. Besides, low computation cost of the proposed (codebook-free) object detector facilitates rather straightforward query detection in large data sets including movie videos.	[Biswas, Sujoy Kumar; Milanfar, Peyman] Univ Calif Santa Cruz, Dept Elect Engn, Santa Cruz, CA 95064 USA	University of California System; University of California Santa Cruz	Biswas, SK; Milanfar, P (corresponding author), Univ Calif Santa Cruz, Dept Elect Engn, Santa Cruz, CA 95064 USA.	sbiswas@ucsc.edu; milanfar@soe.ucsc.edu	Milanfar, Peyman/B-2551-2009					Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108; [Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; [Anonymous], 2013, FINE GRAINED CLASSIF; Belkin M, 2002, ADV NEUR IN, V14, P585; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x; Biswas SK, 2014, IEEE IMAGE PROC, P4062, DOI 10.1109/ICIP.2014.7025825; Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/cvpr.2008.4587586; Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598; Calinski T, 2006, COMMUN STAT-SIMUL C, V35, P727, DOI 10.1080/03610910600716290; Chandrasekhar V., 2009, P IS T SPIE EL IM; Chatfield Ken, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P264, DOI 10.1109/ICCVW.2009.5457691; Chen DM, 2008, IEEE DATA COMPR CONF, P143, DOI 10.1109/DCC.2009.33; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deselaers T, 2010, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2010.5539775; Devernay F., 1995, RR2724 INRIA; Donahue J., 2013, INT C MACH LEARN; Dubout C, 2012, LECT NOTES COMPUT SC, V7574, P301, DOI 10.1007/978-3-642-33712-3_22; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; He XF, 2004, ADV NEUR IN, V16, P153; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; Imagenet, 2014, LARG SCAL VIS REC CH; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Kapoor A, 2006, LECT NOTES COMPUT SC, V3953, P302, DOI 10.1007/11744078_24; Lampert CH, 2009, IEEE I CONF COMP VIS, P987, DOI 10.1109/ICCV.2009.5459359; Lampert CH, 2009, IEEE T PATTERN ANAL, V31, P2129, DOI 10.1109/TPAMI.2009.144; Leibe B., 2011, SYNTHESIS LECT ARTIF, V5, P1, DOI [10. 2200/S00332ED1V01Y201103AIM011, DOI 10.2200/S00332ED1V01Y201103AIM011]; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mahoney MW, 2012, J MACH LEARN RES, V13, P2339; Maji S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2057, DOI 10.1109/CVPR.2011.5995630; Maji S., 2013, TECH REP; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mutch J, 2006, IEEE CVPR, V1, P11, DOI DOI 10.1109/CVPR.2006.200; Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; RODGERS JL, 1988, AM STAT, V42, P59, DOI 10.2307/2685263; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Seo HJ, 2011, IEEE T INF FOREN SEC, V6, P1275, DOI 10.1109/TIFS.2011.2159205; Seo HJ, 2011, IEEE T PATTERN ANAL, V33, P867, DOI 10.1109/TPAMI.2010.156; Seo HJ, 2010, IEEE T PATTERN ANAL, V32, P1688, DOI 10.1109/TPAMI.2009.153; Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15; Shechtman E, 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383198; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Sznitman R, 2010, IEEE T PATTERN ANAL, V32, P1914, DOI 10.1109/TPAMI.2010.106; Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330; TATSUOKA MM, 1988, MULTIVARIATE ANAL; Vasconcelos N, 2011, FOUND TRENDS SIGNAL, V5, P265, DOI 10.1561/2000000015; Vedaldi A, 2012, LECT NOTES COMPUT SC, V7573, P87, DOI 10.1007/978-3-642-33709-3_7; Wu B., 2007, PROC IEEE C COMPUT V, P1, DOI 10.1109/cvpr.2007.383042; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Yoo JC, 2009, CIRC SYST SIGNAL PR, V28, P819, DOI [10.1007/s00034-009-9130-7, 10.1007/S00034-009-9130-7]; Zhang H, 2006, 2006 IEEE COMP SOC C, P2126, DOI [10.1109/CVPR.2006.301, DOI 10.1109/CVPR.2006.301]	60	18	21	2	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2016	38	3					546	562		10.1109/TPAMI.2015.2453950	http://dx.doi.org/10.1109/TPAMI.2015.2453950			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE6JD	27046497				2022-12-18	WOS:000370738900010
J	Kolesov, I; Lee, J; Sharp, G; Vela, P; Tannenbaum, A				Kolesov, Ivan; Lee, Jehoon; Sharp, Gregory; Vela, Patricio; Tannenbaum, Allen			A Stochastic Approach to Diffeomorphic Point Set Registration with Landmark Constraints	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Point set; deformable registration; particle filter; simulated annealing; constrained optimization	ELASTIC REGISTRATION; IMAGE REGISTRATION; OPTIMIZATION; ALGORITHM	This work presents a deformable point set registration algorithm that seeks an optimal set of radial basis functions to describe the registration. A novel, global optimization approach is introduced composed of simulated annealing with a particle filter based generator function to perform the registration. It is shown how constraints can be incorporated into this framework. A constraint on the deformation is enforced whose role is to ensure physically meaningful fields (i.e., invertible). Further, examples in which landmark constraints serve to guide the registration are shown. Results on 2D and 3D data demonstrate the algorithm's robustness to noise and missing information.	[Kolesov, Ivan] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11790 USA; [Lee, Jehoon] Samsung Elect Co Ltd, Suwon, South Korea; [Sharp, Gregory] Massachusetts Gen Hosp, Dept Radiat Oncol, Boston, MA 02114 USA; [Vela, Patricio] Georgia Inst Technol, Dept Elect & Comp Engn, Atlanta, GA 30332 USA; [Tannenbaum, Allen] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11790 USA; [Tannenbaum, Allen] SUNY Stony Brook, Dept Appl Math, Stony Brook, NY 11790 USA	State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook; Samsung; Samsung Electronics; Harvard University; Massachusetts General Hospital; University System of Georgia; Georgia Institute of Technology; State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook; State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	Kolesov, I (corresponding author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11790 USA.; Lee, J (corresponding author), Samsung Elect Co Ltd, Suwon, South Korea.; Sharp, G (corresponding author), Massachusetts Gen Hosp, Dept Radiat Oncol, Boston, MA 02114 USA.; Vela, P (corresponding author), Georgia Inst Technol, Dept Elect & Comp Engn, Atlanta, GA 30332 USA.; Tannenbaum, A (corresponding author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11790 USA.; Tannenbaum, A (corresponding author), SUNY Stony Brook, Dept Appl Math, Stony Brook, NY 11790 USA.	ivan.kolesov@stonybrook.edu; jehoon.lee25@gmail.com; gcsharp@partners.org; pvela@gatech.edu; arobertan@cs.stonybrook.edu	Vela, Patricio/GNH-1840-2022	Vela, Patricio/0000-0002-6888-7002; Sharp, Gregory/0000-0001-8575-9611	National Center for Research Resources [P41-RR-013218]; National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health [P41-EB-015902]; NIH [R01 MH82918, 1U24CA18092401A1]; AFOSR [FA9550-12-1-0319, FA9550-15-1-0045]; NATIONAL CANCER INSTITUTE [U24CA180918] Funding Source: NIH RePORTER; NATIONAL CENTER FOR RESEARCH RESOURCES [P41RR013218] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [P41EB015902, U54EB005149] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF MENTAL HEALTH [R01MH082918] Funding Source: NIH RePORTER	National Center for Research Resources(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR)); National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); AFOSR(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); NATIONAL CANCER INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI)); NATIONAL CENTER FOR RESEARCH RESOURCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR)); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NATIONAL INSTITUTE OF MENTAL HEALTH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Mental Health (NIMH))	This project was supported by in part by grants from the National Center for Research Resources (P41-RR-013218) and the National Institute of Biomedical Imaging and Bioengineering (P41-EB-015902) of the National Institutes of Health. This work was also supported by NIH grants R01 MH82918 and 1U24CA18092401A1 as well as AFOSR grants FA9550-12-1-0319 and FA9550-15-1-0045.	Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116; Avants BB, 2008, MED IMAGE ANAL, V12, P26, DOI 10.1016/j.media.2007.06.004; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bhattacharyya A., 1943, BULL CALCUTTA MATH S, V35, P99; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3; Carreira-Perpinan MA, 2000, IEEE T PATTERN ANAL, V22, P1318, DOI 10.1109/34.888716; Chen Z., 2003, BAYESIAN FILTERING K; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Chui HL, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P190, DOI 10.1109/MMBIA.2000.852377; Del Moral P, 2006, J R STAT SOC B, V68, P411, DOI 10.1111/j.1467-9868.2006.00553.x; Fornefett M, 2001, IMAGE VISION COMPUT, V19, P87, DOI 10.1016/S0262-8856(00)00057-3; Glaunes J, 2004, PROC CVPR IEEE, P712; Grenander U, 2007, IEEE T MED IMAGING, V26, P648, DOI 10.1109/TMI.2006.891500; Guo H, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P924; Guo H, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P205, DOI 10.1007/0-387-28831-7_13; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Izard C, 2006, I S BIOMED IMAGING, P856; Ji CL, 2008, LECT NOTES COMPUT SC, V5199, P909; Jian B, 2005, IEEE I CONF COMP VIS, P1246; Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223; Jung HY, 2008, LECT NOTES COMPUT SC, V5303, P307, DOI 10.1007/978-3-540-88688-4_23; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kurtek S, 2013, COMPUT GRAPH FORUM, V32, P429, DOI 10.1111/cgf.12063; Locatelli M, 2000, J OPTIMIZ THEORY APP, V104, P121, DOI 10.1023/A:1004680806815; Loeckx D, 2004, LECT NOTES COMPUT SC, V3216, P639; Ma B, 2004, LECT NOTES COMPUT SC, V3216, P566; MEISTERS GH, 1963, DUKE MATH J, V30, P63, DOI 10.1215/S0012-7094-63-03008-4; Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46; Oleskiw TD, 2010, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2010.5540179; Park J, 1991, NEURAL COMPUT, V3, P246, DOI 10.1162/neco.1991.3.2.246; Peter A, 2006, I S BIOMED IMAGING, P1164; Rangarajan A, 1997, LECT NOTES COMPUT SC, V1230, P29; Robert C. P., 2005, SPRINGER TEXTS STAT; Rohr K, 2001, IEEE T MED IMAGING, V20, P526, DOI 10.1109/42.929618; Sandhu R, 2010, IEEE T PATTERN ANAL, V32, P1459, DOI 10.1109/TPAMI.2009.142; Tsin Y, 2004, LECT NOTES COMPUT SC, V3023, P558; VANDENELSEN PA, 1993, IEEE ENG MED BIOL, V12, P26, DOI 10.1109/51.195938; VANDERBILT D, 1984, J COMPUT PHYS, V56, P259, DOI 10.1016/0021-9991(84)90095-0; Vidal C, 2010, INT J COMPUT VISION, V88, P189, DOI 10.1007/s11263-009-0258-5; Wahba G., 1990, SPLINE MODELS OBSERV; Wang F, 2008, IEEE T PATTERN ANAL, V30, P2011, DOI 10.1109/TPAMI.2007.70829; Wassermann D, 2013, I S BIOMED IMAGING, P1042, DOI 10.1109/ISBI.2013.6556656; Zhou EL, 2008, 2008 WINTER SIMULATION CONFERENCE, VOLS 1-5, P647, DOI 10.1109/WSC.2008.4736125	45	18	19	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2016	38	2					238	251		10.1109/TPAMI.2015.2448102	http://dx.doi.org/10.1109/TPAMI.2015.2448102			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DD5UI	26761731	Green Accepted			2022-12-18	WOS:000369989600004
J	Liu, YJ				Liu, Yong-Jin			Semi-Continuity of Skeletons in Two-Manifold and Discrete Voronoi Approximation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						2D shape sequence; Voronoi skeleton; two-manifold; geodesic	MEDIAL-AXIS; SURFACES; SHAPE; RECONSTRUCTION; PATHS; MAPS	The skeleton of a 2D shape is an important geometric structure in pattern analysis and computer vision. In this paper we study the skeleton of a 2D shape in a two-manifold M, based on a geodesic metric. We present a formal definition of the skeleton S(Omega) for a shape Omega in M and show several properties that make S(Omega) distinct from its Euclidean counterpart in R-2. We further prove that for a shape sequence {Omega(i)} that converge to a shape Omega in M, the mapping Omega -> (S) over bar(Omega) is lower semi-continuous. A direct application of this result is that we can use a set P of sample points to approximate the boundary of a 2D shape Omega in M, and the Voronoi diagram of P inside Omega subset of M gives a good approximation to the skeleton S(Omega). Examples of skeleton computation in topography and brain morphometry are illustrated.	Tsinghua Univ, Dept Comp Sci & Technol, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China	Tsinghua University	Liu, YJ (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.	liuyongjin@tsinghua.edu.cn	Liu, Yong/GWQ-6163-2022		Natural Science Foundation of China [61322206, 61432003, 61272228]; National Basic Research Program of China [2011CB302202]	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China(National Basic Research Program of China)	The author thanks the editor and reviewers very much for their constructive comments that help improve this paper. The topographical data (Fig. 8) and sulci data (Fig. 10) are courtesy of US Geological Survey and Computational Functional Anatomy Lab at National University of Singapore. This work was supported by the Natural Science Foundation of China (61322206, 61432003, 61272228) and the National Basic Research Program of China (2011CB302202).	Aleksandrov A. D., 1967, INTRINSIC GEOMETRY S; Amenta N, 1999, DISCRETE COMPUT GEOM, V22, P481, DOI 10.1007/PL00009475; Attali D, 2007, P ACM S SOL PHYS MOD, P143; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; Boissonnat JD, 2001, COMP GEOM-THEOR APPL, V19, P155, DOI 10.1016/S0925-7721(01)00018-9; Chazal F, 2005, GRAPH MODELS, V67, P304, DOI 10.1016/j.gmod.2005.01.002; Chazal F, 2004, J DYN CONTROL SYST, V10, P149, DOI 10.1023/B:JODS.0000024119.38784.ff; Chazal F., 2004, P 9 ACM S SOL MOD AP, P243; Dey TK, 2000, COMP GEOM-THEOR APPL, V15, P229, DOI 10.1016/S0925-7721(99)00051-6; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; Keim DA, 2005, IEEE COMPUT GRAPH, V25, P60, DOI 10.1109/MCG.2005.64; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; Kimmel R, 2000, INT J COMPUT VISION, V39, P111, DOI 10.1023/A:1008171026419; Kimmel R, 1998, IEEE T ROBOTIC AUTOM, V14, P427, DOI 10.1109/70.678452; Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431; Lai R., 2010, THESIS U CALIFORNIA; Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738; Lieutier A, 2004, COMPUT AIDED DESIGN, V36, P1029, DOI 10.1016/j.cad.2004.01.011; Liu YJ, 2013, COMPUT AIDED DESIGN, V45, P695, DOI 10.1016/j.cad.2012.11.005; Liu YJ, 2013, INFORM PROCESS LETT, V113, P132, DOI 10.1016/j.ipl.2012.12.010; Liu YJ, 2011, IEEE T PATTERN ANAL, V33, P1502, DOI 10.1109/TPAMI.2010.221; Maekawa T, 1996, J MECH DESIGN, V118, P499, DOI 10.1115/1.2826919; Matheron G., 1975, RANDOM SETS INTEGRAL; Matheron G., 1988, IMAGE ANAL MATH MORP, V2, P217; MITCHELL JSB, 1987, SIAM J COMPUT, V16, P647, DOI 10.1137/0216045; Munkres J. R., 2000, TOPOLOGY, V2nd; Osher S., 2002, APPL MATH SCI, V44, P685; Serra J, 1982, IMAGE ANAL MATH MORP; Sethian J. A., 1999, LEVEL SET METHODS FA; Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591; Shi YG, 2008, IEEE T MED IMAGING, V27, P664, DOI 10.1109/TMI.2007.913279; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; Siddiqi K, 2008, COMPUT IMAGING VIS, V37, P1, DOI 10.1007/978-1-4020-8658-8; Siddiqi K, 2002, INT J COMPUT VISION, V48, P215, DOI 10.1023/A:1016376116653; Toga AW, 2003, NAT REV NEUROSCI, V4, P37, DOI 10.1038/nrn1009; Wolter F. E., 1993, 922 MIT DES LAB; WOLTER FE, 1985, THESIS TU BERLIN BER; Xu CX, 2015, IEEE T VIS COMPUT GR, V21, P822, DOI 10.1109/TVCG.2015.2407404	38	18	20	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2015	37	9					1938	1944		10.1109/TPAMI.2015.2430342	http://dx.doi.org/10.1109/TPAMI.2015.2430342			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CO5RQ	26353138				2022-12-18	WOS:000359216600016
J	Perret, B; Cousty, J; Tankyevych, O; Talbot, H; Passat, N				Perret, Benjamin; Cousty, Jean; Tankyevych, Olena; Talbot, Hugues; Passat, Nicolas			Directed Connected Operators: Asymmetric Hierarchies for Image Filtering and Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Mathematical morphology; connected operators; hierarchical image representation; antiextensive filtering; segmentation	FUZZY CONNECTEDNESS; FORESTING TRANSFORM; SCALE-SPACE; ALGORITHMS; TREE; REPRESENTATION; EXTRACTION; ADJACENCY; CUTS	Connected operators provide well-established solutions for digital image processing, typically in conjunction with hierarchical schemes. In graph-based frameworks, such operators basically rely on symmetric adjacency relations between pixels. In this article, we introduce a notion of directed connected operators for hierarchical image processing, by also considering non-symmetric adjacency relations. The induced image representation models are no longer partition hierarchies (i.e., trees), but directed acyclic graphs that generalize standard morphological tree structures such as component trees, binary partition trees or hierarchical watersheds. We describe how to efficiently build and handle these richer data structures, and we illustrate the versatility of the proposed framework in image filtering and image segmentation.	[Perret, Benjamin; Cousty, Jean; Talbot, Hugues] ESIEE Paris, Paris, France; [Perret, Benjamin; Cousty, Jean; Talbot, Hugues] Univ Paris Est Marne la Vallee, LIGM, Paris, France; [Tankyevych, Olena] Univ Paris Est Creteil, LISSI, Paris, France; [Passat, Nicolas] Univ Reims, CReSTIC, Reims, France	Universite Gustave-Eiffel; ESIEE Paris; Ecole des Ponts ParisTech; Universite Gustave-Eiffel; Universite Paris-Est-Creteil-Val-de-Marne (UPEC); Universite de Reims Champagne-Ardenne	Perret, B (corresponding author), ESIEE Paris, Paris, France.	b.perret@esiee.fr; j.cousty@esiee.fr; olena.tankyevych@u-pec.fr; h.talbot@esiee.fr; nicolas.passat@univ-reims.fr		Perret, Benjamin/0000-0003-0933-8342	French Agence Nationale de la Recherche [ANR-10-BLAN-0205, ANR-12-MONU-0010]	French Agence Nationale de la Recherche(French National Research Agency (ANR))	This work was funded with French Agence Nationale de la Recherche grant agreements ANR-10-BLAN-0205 and ANR-12-MONU-0010.	Alonso-Gonzalez A, 2013, P IEEE, V101, P723, DOI 10.1109/JPROC.2012.2205209; Berger C, 2007, IEEE IMAGE PROC, P1737; Bertrand G, 2005, J MATH IMAGING VIS, V22, P217, DOI 10.1007/s10851-005-4891-5; Bloch I, 1997, INT J UNCERTAIN FUZZ, V5, P615, DOI 10.1142/S0218488597000476; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5; Breen EJ, 1996, COMPUT VIS IMAGE UND, V64, P377, DOI 10.1006/cviu.1996.0066; Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024; Caldairou B, 2011, PATTERN RECOGN, V44, P1916, DOI 10.1016/j.patcog.2010.06.006; Carlinet Edwin, 2013, Mathematical Morphology and Its Applications to Signal and Image Processing. 11th International Symposium, ISMM 2013. Proceedings, P73, DOI 10.1007/978-3-642-38294-9_7; Chen LJ, 2000, INT J IMAG SYST TECH, V11, P243, DOI 10.1002/ima.1009; Cormen Thomas H, 2001, INTRO ALGORITHMS; Cousty Jean, 2013, Mathematical Morphology and Its Applications to Signal and Image Processing. 11th International Symposium, ISMM 2013. Proceedings, P86, DOI 10.1007/978-3-642-38294-9_8; Cousty J, 2011, LECT NOTES COMPUT SC, V6671, P272, DOI 10.1007/978-3-642-21569-8_24; Cousty J, 2009, IEEE T PATTERN ANAL, V31, P1362, DOI 10.1109/TPAMI.2008.173; Cousty J, 2010, IEEE T PATTERN ANAL, V32, P925, DOI 10.1109/TPAMI.2009.71; Dufour A, 2013, MED IMAGE ANAL, V17, P147, DOI 10.1016/j.media.2012.08.004; eraud T. G, 2013, LECT NOTES COMPUTER, P97; Falcao AX, 2004, IEEE T PATTERN ANAL, V26, P19, DOI 10.1109/TPAMI.2004.1261076; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Frangi AF, 1999, IEEE T MED IMAGING, V18, P946, DOI 10.1109/42.811279; Guigues L, 2006, INT J COMPUT VISION, V68, P289, DOI 10.1007/s11263-005-6299-0; Haeupler B, 2012, ACM T ALGORITHMS, V8, DOI 10.1145/2071379.2071382; Heijmans HJAM, 1999, COMPUT VIS IMAGE UND, V73, P99, DOI 10.1006/cviu.1998.0703; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Jones R, 1999, COMPUT VIS IMAGE UND, V75, P215, DOI 10.1006/cviu.1999.0777; Kiran BR, 2014, PATTERN RECOGN, V47, P12, DOI 10.1016/j.patcog.2013.05.012; KONG TY, 1989, COMPUT VISION GRAPH, V48, P357, DOI 10.1016/0734-189X(89)90147-3; Kurtz C, 2012, PATTERN RECOGN, V45, P685, DOI 10.1016/j.patcog.2011.07.017; Mattes J., 1999, LECT NOTES COMPUTER, V1568, P392; Mendonca AM, 2006, IEEE T MED IMAGING, V25, P1200, DOI 10.1109/TMI.2006.879955; Meyer F, 1999, LECT NOTES COMPUT SC, V1682, P187; Miranda PAV, 2014, IEEE T IMAGE PROCESS, V23, P389, DOI 10.1109/TIP.2013.2288867; Monasse P, 2000, J VIS COMMUN IMAGE R, V11, P224, DOI 10.1006/jvci.1999.0441; Naegel B., 2013, LECT NOTES COMPUTER, V7883, P350; Naegel B, 2010, PATTERN RECOGN LETT, V31, P1251, DOI 10.1016/j.patrec.2010.04.003; NAGAO M, 1979, COMPUT VISION GRAPH, V10, P195, DOI 10.1016/0146-664X(79)90001-7; Najman Laurent, 2013, Mathematical Morphology and Its Applications to Signal and Image Processing. 11th International Symposium, ISMM 2013. Proceedings, P135, DOI 10.1007/978-3-642-38294-9_12; Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254; Najman L, 2010, MATH MORPHOLOGY THEO; Najman L, 2006, IEEE T IMAGE PROCESS, V15, P3531, DOI 10.1109/TIP.2006.877518; Ouzounis GK, 2007, IEEE T PATTERN ANAL, V29, P990, DOI 10.1109/TPAMI.2007.1045; Ouzounis GK, 2011, LECT NOTES COMPUT SC, V6671, P108, DOI 10.1007/978-3-642-21569-8_10; Ouzounis GK, 2011, IEEE T PATTERN ANAL, V33, P224, DOI 10.1109/TPAMI.2010.74; Passat N, 2014, J MATH IMAGING VIS, V49, P37, DOI 10.1007/s10851-013-0438-3; Passat N, 2011, LECT NOTES COMPUT SC, V6671, P284, DOI 10.1007/978-3-642-21569-8_25; Passat N, 2011, PATTERN RECOGN, V44, P2539, DOI 10.1016/j.patcog.2011.03.025; Perret B., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4089, DOI 10.1109/ICPR.2010.994; Perret B, 2012, IEEE T IMAGE PROCESS, V21, P14, DOI 10.1109/TIP.2011.2161322; Perret B, 2011, LECT NOTES COMPUT SC, V6671, P85, DOI 10.1007/978-3-642-21569-8_8; Ronse C, 1998, J MATH IMAGING VIS, V8, P41, DOI 10.1023/A:1008210216583; Ronse C, 2014, PATTERN RECOGN LETT, V47, P120, DOI 10.1016/j.patrec.2014.03.020; ROSENFELD A, 1974, INFORM CONTROL, V26, P24, DOI 10.1016/S0019-9958(74)90696-2; ROSENFELD A, 1970, J ACM, V17, P146, DOI 10.1145/321556.321570; Rousseau F, 2010, MED IMAGE ANAL, V14, P594, DOI 10.1016/j.media.2010.04.005; Saha PK, 2001, COMPUT VIS IMAGE UND, V82, P42, DOI 10.1006/cviu.2000.0902; SALEMBIER P, 1995, IEEE T IMAGE PROCESS, V4, P1153, DOI 10.1109/83.403422; Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500; Salembier P, 2000, IEEE T IMAGE PROCESS, V9, P561, DOI 10.1109/83.841934; Salembier P, 2009, IEEE SIGNAL PROC MAG, V26, P136, DOI 10.1109/MSP.2009.934154; Serra J, 1998, J MATH IMAGING VIS, V9, P231, DOI 10.1023/A:1008324520475; Serra J, 1988, IMAGE ANAL MATH MORP; Serra J, 2012, IEEE J-STSP, V6, P739, DOI 10.1109/JSTSP.2012.2220120; SHARIR M, 1981, COMPUT MATH APPL, V7, P67, DOI 10.1016/0898-1221(81)90008-0; Singaraju D, 2008, PROC CVPR IEEE, P1105; Soille P, 2008, IEEE T PATTERN ANAL, V30, P1132, DOI 10.1109/TPAMI.2007.70817; Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627; Tankyevych O., 2013, LECT NOTES COMPUTER, V7883, P157; Tarjan R., 1972, SIAM Journal on Computing, V1, P146, DOI 10.1137/0201010; Udupa JK, 1996, GRAPH MODEL IM PROC, V58, P246, DOI 10.1006/gmip.1996.0021; Urbach ER, 2007, IEEE T PATTERN ANAL, V29, P272, DOI 10.1109/TPAMI.2007.28; Westenberg MA, 2007, IEEE T IMAGE PROCESS, V16, P2943, DOI 10.1109/TIP.2007.909317; Wilkinson M.H.F., 2001, P 4 INT C MED IM COM, V2208, P770, DOI DOI 10.1007/3-540-45468-3_92; Xu YC, 2012, INT C PATT RECOG, P485; Yongchao Xu, 2013, Mathematical Morphology and Its Applications to Signal and Image Processing. 11th International Symposium, ISMM 2013. Proceedings, P390, DOI 10.1007/978-3-642-38294-9_33	75	18	19	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2015	37	6					1162	1176		10.1109/TPAMI.2014.2366145	http://dx.doi.org/10.1109/TPAMI.2014.2366145			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CH9SR	26357340	Green Submitted			2022-12-18	WOS:000354377100004
J	Jia, ZY; Gallagher, AC; Saxena, A; Chen, TH				Jia, Zhaoyin; Gallagher, Andrew C.; Saxena, Ashutosh; Chen, Tsuhan			3D Reasoning from Blocks to Stability	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Segmentation; scene understanding; computer vision		Objects occupy physical space and obey physical laws. To truly understand a scene, we must reason about the space that objects in it occupy, and how each objects is supported stably by each other. In other words, we seek to understand which objects would, if moved, cause other objects to fall. This 3D volumetric reasoning is important for many scene understanding tasks, ranging from segmentation of objects to perception of a rich 3D, physically well-founded, interpretations of the scene. In this paper, we propose a new algorithm to parse a single RGB-D image with 3D block units while jointly reasoning about the segments, volumes, supporting relationships, and object stability. Our algorithm is based on the intuition that a good 3D representation of the scene is one that fits the depth data well, and is a stable, self-supporting arrangement of objects (i.e., one that does not topple). We design an energy function for representing the quality of the block representation based on these properties. Our algorithm fits 3D blocks to the depth values corresponding to image segments, and iteratively optimizes the energy function. Our proposed algorithm is the first to consider stability of objects in complex arrangements for reasoning about the underlying structure of the scene. Experimental results show that our stability-reasoning framework improves RGB-D segmentation and scene volumetric representation.	[Jia, Zhaoyin; Gallagher, Andrew C.; Chen, Tsuhan] Cornell Univ, Sch Elect & Comp Engn, Ithaca, NY 14850 USA; [Saxena, Ashutosh] Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA	Cornell University; Cornell University	Jia, ZY (corresponding author), Cornell Univ, Sch Elect & Comp Engn, Ithaca, NY 14850 USA.	zj32@cornell.edu; acg226@cornell.edu; asaxena@cs.cornell.edu; tc345@cornell.edu		Chen, Tsuhan/0000-0003-3951-7931	National Science Foundation (NSF) [DMS-0808864]; Qualcomm; NSF	National Science Foundation (NSF)(National Science Foundation (NSF)); Qualcomm; NSF(National Science Foundation (NSF))	The authors thank Daniel Jeng for useful discussions about stability reasoning. This work was supported in part by National Science Foundation (NSF) DMS-0808864 and Qualcomm, and by NSF Career award (to Saxena). This work was first presented at Computer Vision and Pattern Recognition (CVPR), 2013 as an oral.	Anand A, 2013, INT J ROBOT RES, V32, P19, DOI 10.1177/0278364912461538; [Anonymous], 2006, P 2006 IEEE COMP SOC, DOI DOI 10.1109/CVPR.2006.23; Arbelaez P, 2012, PROC CVPR IEEE, P3378, DOI 10.1109/CVPR.2012.6248077; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Bao SY, 2011, IMAGE VISION COMPUT, V29, P569, DOI 10.1016/j.imavis.2011.08.001; Baraff D., 1997, SIGGRAPH 97 COURSE N; Bleyer M, 2012, LECT NOTES COMPUT SC, V7576, P467, DOI 10.1007/978-3-642-33715-4_34; Brand M, 1997, COMPUT VIS IMAGE UND, V65, P192, DOI 10.1006/cviu.1996.0572; Brand M. E., 1995, P WORKSH PHYS BAS MO, P1; Chang CT, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019641; Chang J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2081, DOI 10.1109/CVPR.2011.5995333; Flint A, 2011, IEEE I CONF COMP VIS, P2228, DOI 10.1109/ICCV.2011.6126501; Fouhey DF, 2012, LECT NOTES COMPUT SC, V7576, P732, DOI 10.1007/978-3-642-33715-4_53; GOTTSCHALK S, 1996, TR96024 U N CAR DEP; Grabner H, 2011, PROC CVPR IEEE, P1529, DOI 10.1109/CVPR.2011.5995327; Gupta A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1961, DOI 10.1109/CVPR.2011.5995448; Gupta A, 2010, LECT NOTES COMPUT SC, V6314, P482, DOI 10.1007/978-3-642-15561-1_35; Hedau V, 2012, PROC CVPR IEEE, P2807; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; Jain A., 2013, ADV NEURAL INFORM PR, P575; Janoch A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1168, DOI 10.1109/ICCVW.2011.6130382; Jiang H, 2013, PROC CVPR IEEE, P2171, DOI 10.1109/CVPR.2013.282; Jiang Y., 2012, P INT C MACH LEARN, P1543; Jiang Y., 2013, P ROB SCI SYST, P144; Jiang Y, 2013, PROC CVPR IEEE, P2993, DOI 10.1109/CVPR.2013.385; Jiang Y, 2012, INT J ROBOT RES, V31, P1021, DOI 10.1177/0278364912438781; Koppula H., 2013, P ROB SCI SYST, P1; Koppula H., 2013, INT C MACHINE LEARNI, P792, DOI DOI 10.1177/0278364913478446; Koppula H. S., 2011, ADV NEURAL INFORM PR, P244; Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446; Lai K, 2011, IEEE INT CONF ROBOT, P1817; Lee D., 2010, P ADV NEUR INF PROC, P1288; Li CC, 2012, IEEE T PATTERN ANAL, V34, P1394, DOI 10.1109/TPAMI.2011.232; Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718; Lin C.-J., 2004, SIMPLE PROBABILISTIC; Ly DL, 2012, PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P967, DOI 10.1145/2330163.2330297; Maji S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2057, DOI 10.1109/CVPR.2011.5995630; MCCLOSKEY M, 1983, SCI AM, V248, P122, DOI 10.1038/scientificamerican0483-122; Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999; Roberts L, 1965, MACHINE PERCEPTION 3; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Saxena Ashutosh, 2005, ADV NEURAL INFORM PR; Silberman N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P601, DOI 10.1109/ICCVW.2011.6130298; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Stein A, 2007, IEEE I CONF COMP VIS, P110; Xiao J., 2012, ADV NEURAL INFORM PR, P755; Xiaofeng R., 2012, P ADV NEUR INF PROC, P584, DOI DOI 10.1634/THEONCOLOGIST.8-3-252; Zheng B, 2013, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2013.402; Zheng YY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185595	49	18	20	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2015	37	5					905	918		10.1109/TPAMI.2014.2359435	http://dx.doi.org/10.1109/TPAMI.2014.2359435			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CF4PS	26353317				2022-12-18	WOS:000352533000001
J	Schouten, TE; van den Broek, EL				Schouten, Theo E.; van den Broek, Egon L.			Fast Exact Euclidean Distance (FEED): A New Class of Adaptable Distance Transforms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fast exact euclidean distance (FEED); distance transform; distance transformation; Voronoi; computational complexity; adaptive; benchmark	LINEAR-TIME ALGORITHM; VORONOI DIAGRAMS; PROPAGATION; COMPUTE	A new unique class of foldable distance transforms of digital images (DT) is introduced, baptized: Fast exact euclidean distance (FEED) transforms. FEED class algorithms calculate the DT startingdirectly from the definition or rather its inverse. The principle of FEED class algorithms is introduced, followed by strategies for their efficient implementation. It is shown that FEED class algorithms unite properties of ordered propagation, raster scanning, and independent scanning DT. Moreover, FEED class algorithms shown to have a unique property: they can be tailored to the images under investigation. Benchmarks are conducted on both the Fabbri et al. data set and on a newly developed data set. Three baseline, three approximate, and three state-of-the-art DT algorithms were included, in addition to two implementations of FEED class algorithms. It illustrates that FEED class algorithms i) provide truly exact Euclidean DT; ii) do no suffer from disconnected Voronoi tiles, which is a unique feature for non-parallel but fast DT; iii) outperform any other approximate and exact Euclidean DT with its time complexity O(N), even after their optimization; and iv) are unequaled in that they can be adapted to the characteristics of the image class at hand.	[Schouten, Theo E.] Radboud Univ Nijmegen, ICIS, NL-6500 GL Nijmegen, Netherlands; [van den Broek, Egon L.] Univ Utrecht, Dept Informat & Comp Sci, NL-3508 TC Utrecht, Netherlands; [van den Broek, Egon L.] Univ Twente, NL-7500 AE Enschede, Netherlands; [van den Broek, Egon L.] Radboud Univ Nijmegen, Med Ctr Nijmegen, NL-6525 ED Nijmegen, Netherlands	Radboud University Nijmegen; Utrecht University; University of Twente; Radboud University Nijmegen	Schouten, TE (corresponding author), Radboud Univ Nijmegen, ICIS, POB 9010, NL-6500 GL Nijmegen, Netherlands.	ths@cs.ru.nl; vandenbroek@acm.org	Schouten, Theo E/H-2573-2012; van den Broek, Egon L./AAU-6646-2021	van den Broek, Egon L./0000-0002-2017-0141	Dutch NWO ToKeN project Eidetic [634.000.001]; Dutch national program COMMIT	Dutch NWO ToKeN project Eidetic; Dutch national program COMMIT	This publication was supported by both the Dutch NWO ToKeN project Eidetic (634.000.001) and the Dutch national program COMMIT. The authors gratefully acknowledge Andras Hajdu and Attila Fazekasl (University of Debrecen, Hungary) and Robin Strand and Gunilla Borgefors (Uppsala University, Sweden) for their helpful comments and suggestions on an earlier draft of this paper. They thank the two anonymous reviewers who provided them detailed feedback on an earlier version of this paper. This enabled them to improve this paper substantially. Additionally, they also thank Lynn Packwood (University of Twente, The Netherlands) for her careful proofreading.	BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; Borgefors G, 2003, DISCRETE APPL MATH, V125, P1, DOI 10.1016/S0166-218X(02)00220-2; BORGEFORS G, 1984, COMPUT VISION GRAPH, V27, P321, DOI 10.1016/0734-189X(84)90035-5; BREU H, 1995, IEEE T PATTERN ANAL, V17, P529, DOI 10.1109/34.391389; Ciesielski KC, 2011, J MATH IMAGING VIS, V39, P193, DOI 10.1007/s10851-010-0232-4; Coeurjolly D, 2007, IEEE T PATTERN ANAL, V29, P437, DOI 10.1109/TPAMI.2007.54; Coiras E, 1998, PATTERN RECOGN LETT, V19, P1111, DOI 10.1016/S0167-8655(98)00091-9; Cuisenaire O, 2006, PATTERN RECOGN, V39, P405, DOI 10.1016/j.patcog.2005.07.009; Cuisenaire O, 1999, COMPUT VIS IMAGE UND, V76, P163, DOI 10.1006/cviu.1999.0783; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; Fabbri R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1322432.1322434; Gao J, 2012, PHILOS T R SOC A, V370, P27, DOI 10.1098/rsta.2011.0215; Guan WG, 1998, IEEE T PATTERN ANAL, V20, P757, DOI 10.1109/34.689306; Hajdu A, 2004, DISCRETE MATH, V283, P101, DOI 10.1016/j.disc.2003.12.016; Hajdu A, 2008, PATTERN RECOGN LETT, V29, P813, DOI 10.1016/j.patrec.2008.01.001; Hirata T, 1996, INFORM PROCESS LETT, V58, P129, DOI 10.1016/0020-0190(96)00049-X; Jones MW, 2006, IEEE T VIS COMPUT GR, V12, P581, DOI 10.1109/TVCG.2006.56; KULPA Z, 1983, COMPUT VISION GRAPH, V24, P305, DOI 10.1016/0734-189X(83)90058-0; Lucet Y, 2009, IMAGE VISION COMPUT, V27, P37, DOI 10.1016/j.imavis.2006.10.011; Maurer CR, 2003, IEEE T PATTERN ANAL, V25, P265, DOI 10.1109/TPAMI.2003.1177156; Meijster A, 2000, COMP IMAG VIS, V18, P331; Miyazawa M, 2006, IEEE T PATTERN ANAL, V28, P1127, DOI 10.1109/TPAMI.2006.133; Moreland K, 2013, IEEE T VIS COMPUT GR, V19, P367, DOI 10.1109/TVCG.2012.133; Mukherjee J, 2011, PATTERN RECOGN LETT, V32, P824, DOI 10.1016/j.patrec.2011.01.010; Ogniewicz RL, 1995, PATTERN RECOGN, V28, P1839, DOI 10.1016/0031-3203(95)00059-3; Peyre G, 2009, FOUND TRENDS COMPUT, V5, DOI 10.1561/0600000029; ROSENFEL.A, 1966, J ACM, V13, P471; ROSENFELD A, 1968, PATTERN RECOGN, V1, P33, DOI 10.1016/0031-3203(68)90013-7; Schouten T, 2004, INT C PATT RECOG, P594, DOI 10.1109/ICPR.2004.1334599; Schouten T. E., 2008, P SOC PHOTO-OPT INS, V6811; Schouten TE, 2006, PROC SPIE, V6066, DOI 10.1117/12.643721; Sequeira RE, 1997, IEEE T PATTERN ANAL, V19, P1165, DOI 10.1109/34.625128; Shih FY, 2004, IEEE T IMAGE PROCESS, V13, P1078, DOI 10.1109/TIP.2004.826098; Shih FY, 2004, COMPUT VIS IMAGE UND, V93, P195, DOI 10.1016/j.cviu.2003.09.004; Strand R, 2011, THEOR COMPUT SCI, V412, P1350, DOI 10.1016/j.tcs.2010.10.027; van den Broek EL, 2008, PATTERN RECOGN LETT, V29, P1136, DOI 10.1016/j.patrec.2007.09.006; van den Broek E. L., 2005, IEE International Conference on Visual Information Engineering (VIE 2005) (CP No.509), P157, DOI 10.1049/cp:20050085; van den Broek Egon L., 2011, Recent Patents on Computer Science, V4, P1, DOI 10.2174/1874479611104010001; VINCENT L, 1989, SIGNAL PROCESS, V16, P365, DOI 10.1016/0165-1684(89)90031-5; Wingbermuehle JG, 2014, IEEE COMPUT ARCHIT L, V13, P45, DOI 10.1109/L-CA.2013.7; Ye Q.-Z., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P495, DOI 10.1109/ICPR.1988.28276; Zhang HH, 2013, ULTRASOUND MED BIOL, V39, P72, DOI 10.1016/j.ultrasmedbio.2012.08.019; Zhang Z, 2013, IEEE T MULTIMEDIA, V15, P106, DOI 10.1109/TMM.2012.2225040	44	18	18	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2014	36	11					2159	2172		10.1109/TPAMI.2014.25	http://dx.doi.org/10.1109/TPAMI.2014.25			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AR6OI	26353058	Bronze, Green Submitted			2022-12-18	WOS:000343702400004
J	Bergamo, A; Torresani, L				Bergamo, Alessandro; Torresani, Lorenzo			Classemes and Other Classifier-Based Features for Efficient Object Categorization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object categorization; image features; attributes	IMAGE; COMPACT; SCENE	This paper describes compact image descriptors enabling accurate object categorization with linear classification models, which offer the advantage of being efficient to both train and test. The shared property of our descriptors is the use of classifiers to produce the features of each image. Intuitively, these classifiers evaluate the presence of a set of basis classes inside the image. We first propose to train the basis classifiers as recognizers of a hand-selected set of object classes. We then demonstrate that better accuracy can be achieved by learning the basis classes as "abstract categories" collectively optimized as features for linear classification. Finally, we describe several strategies to aggregate the outputs of basis classifiers evaluated on multiple subwindows of the image in order to handle cases when the photo contains multiple objects and large amounts of clutter. We test our descriptors on challenging benchmarks of object categorization and detection, using a simple linear SVM as classifier. Our results are on par with those achieved by the best systems in these fields but are produced at orders of magnitude lower computational costs and using an image representation that is general and not specifically tuned for a predefined set of test classes.	[Bergamo, Alessandro; Torresani, Lorenzo] Dartmouth Coll, Dept Comp Sci, Hanover, NH 03755 USA	Dartmouth College	Bergamo, A (corresponding author), Dartmouth Coll, Dept Comp Sci, Hanover, NH 03755 USA.	aleb@cs.dartmouth.edu; lorenzo@cs.dartmouth.edu			Microsoft Research; US National Science Foundation (NSF) CAREER award [IIS-0952943]; NSF [CNS-1205521]	Microsoft Research(Microsoft); US National Science Foundation (NSF) CAREER award(National Science Foundation (NSF)NSF - Office of the Director (OD)); NSF(National Science Foundation (NSF))	The authors are grateful to Andrew Fitzgibbon for his contribution in the design of classemes and PICODES. The authors thank Martin Szummer for discussions and Chen Fang for programming help. This research was funded in part by Microsoft Research, US National Science Foundation (NSF) CAREER award IIS-0952943 and NSF award CNS-1205521.	Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; [Anonymous], 2007, PASCAL VISUAL OBJECT; Bengio Samy, 2010, ADV NEURAL INFORM PR, V1, P163, DOI [10.5555/2997189.2997208, DOI 10.5555/2997189.2997208]; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Berg A., 2010, LARGE SCALE VISUAL R; Bergamo A., 2011, NIPS, V24, P2088; Bergamo A, 2012, PROC CVPR IEEE, P3085, DOI 10.1109/CVPR.2012.6248040; Chapelle O., 2008, P AM STAT ASS; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng J, 2010, LECT NOTES COMPUT SC, V6315, P71, DOI 10.1007/978-3-642-15555-0_6; Deng Jia, 2011, ADV NEURAL INFORM PR, V1, P567, DOI [10.5555/2986459.2986523, DOI 10.5555/2986459.2986523]; Elfiky NM, 2012, IMAGE VISION COMPUT, V30, P492, DOI 10.1016/j.imavis.2012.04.002; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Gao TS, 2011, IEEE I CONF COMP VIS, P2072, DOI 10.1109/ICCV.2011.6126481; Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169; Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432; Griffin Gregory, 2007, CALTECH 256 OBJECT C; Harzallah H, 2009, IEEE I CONF COMP VIS, P237, DOI 10.1109/ICCV.2009.5459257; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Jia D, 2011, PROC CVPR IEEE, P785, DOI 10.1109/CVPR.2011.5995516; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Li L.-J., 2010, NEURAL INFORM PROCES, P1378; Lin YQ, 2011, PROC CVPR IEEE, P1689, DOI 10.1109/CVPR.2011.5995477; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maji S, 2009, IEEE I CONF COMP VIS, P40, DOI 10.1109/ICCV.2009.5459203; Ng AY, 2002, ADV NEUR IN, V14, P849; Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2; Platt JC, 2000, ADV NEUR IN, P61; Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537; Rastegari M, 2011, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2011.6126556; Sanchez J, 2011, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2011.5995504; Shechtman E, 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383198; Song Z, 2011, PROC CVPR IEEE, P1585, DOI 10.1109/CVPR.2011.5995330; Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wang G, 2009, IEEE I CONF COMP VIS, P428, DOI 10.1109/ICCV.2009.5459167; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970	44	18	18	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2014	36	10					1988	2001		10.1109/TPAMI.2014.2313111	http://dx.doi.org/10.1109/TPAMI.2014.2313111			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AP3MX	26352630	Green Submitted			2022-12-18	WOS:000341981300007
J	Courville, A; Desjardins, G; Bergstra, J; Bengio, Y				Courville, Aaron; Desjardins, Guillaume; Bergstra, James; Bengio, Yoshua			The Spike-and-Slab RBM and Extensions to Discrete and Sparse Data Distributions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature learning; unsupervised learning; restricted boltzmann machines; natural image modeling	EMERGENCE; PRODUCTS	The spike-and-slab restricted Boltzmann machine (ssRBM) is defined to have both a real-valued "slab" variable and a binary "spike" variable associated with each unit in the hidden layer. The model uses its slab variables to model the conditional covariance of the observation-thought to be important in capturing the statistical properties of natural images. In this paper, we present the canonical ssRBM framework together with some extensions. These extensions highlight the flexibility of the spike-and-slab RBM as a platform for exploring more sophisticated probabilistic models of high dimensional data in general and natural image data in particular. Here, we introduce the subspace-ssRBM focused on the task of learning invariant features. We highlight the behaviour of the ssRBM and its extensions through experiments with the MNIST digit recognition task and the CIFAR-10 object classification task.	[Courville, Aaron] Univ Montreal, Dept Comp Sci & Operat Res, Montreal, PQ, Canada; [Desjardins, Guillaume; Bengio, Yoshua] Univ Montreal, DIRO, Montreal, PQ H3T 1J4, Canada; [Bergstra, James] Univ Waterloo, Ctr Theoret Neurosci, Waterloo, ON N2L 3G1, Canada; [Bergstra, James] Harvard Univ, Cambridge, MA 02138 USA; [Bengio, Yoshua] Univ Montreal, Machine Learning Lab LISA, Montreal, PQ, Canada	Universite de Montreal; Universite de Montreal; University of Waterloo; Harvard University; Universite de Montreal	Courville, A (corresponding author), Univ Montreal, Dept Comp Sci & Operat Res, Montreal, PQ, Canada.	aaron.courville@umontreal.ca; desjagui@iro.umontreal.ca; james.bergstra@gmail.com; Yoshua.Bengio@umontreal.ca			NSERC; FQRNT; CIFAR; RQCHP; Compute Canada	NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC)); FQRNT(FQRNT); CIFAR(Canadian Institute for Advanced Research (CIFAR)); RQCHP; Compute Canada	The authors acknowledge NSERC, FQRNT, CIFAR, RQCHP and Compute Canada for their financial and computational support; and Chris Williams for pointing out the connection to the PoPPCA model. They also thank the anonymous reviewers for their valuable suggestions for improving the paper.	Bergstra J, 2012, J MACH LEARN RES, V13, P281; Bergstra J, 2011, NEURAL COMPUT, V23, P774, DOI 10.1162/NECO_a_00084; Cho K, 2010, P INT JOINT C NEUR N; Coates A., 2011, P ADV NEUR INF PROC; Coates A., 2011, P 28 INT C MACHINE L; COATES A, 2011, P 14 INT C ART INT S, P215; Courville A., 2011, P INT C MACH LEARN I; Desjardins G., 2010, P 13 INT C ART INT S, P145; GARRIGUES P, 2008, P ADV NEUR INF PROC; Goodfellow I., 2012, P 29 INT C MACH LEAR; Goodfellow I., 2013, P INT C MACH LEARN I; Hinton GE, 1998, NATO ADV SCI I D-BEH, V89, P479; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; HINTON GE, 2010, 2010003 U TOR; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hyvarinen A, 2000, NEURAL COMPUT, V12, P1705, DOI 10.1162/089976600300015312; Hyvarinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71; Kavukcuoglu K., 2009, P IEEE C COMP VIS PA; Kivinen J.J., 2012, P 15 INT C ART INT S; Kohonen T, 1996, BIOL CYBERN, V75, P281, DOI 10.1007/s004220050295; Krizhevsky A., 2009, LEARNING MULTIPLE LA; Krizhevsky A., 2010, CONVOLUTIONAL DEEP B; Le Q., 2010, P ADV NEUR INF PROC; Le Q.V., 2011, P IEEE C COMP VIS PA; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lowe D., 1999, P IEEE 7 INT C COMP; Lucke J., 2011, ARXIV11052493; Luo H., 2013, P INT C ART INT STAT; Manzagol P.-A., 2008, P 25 INT C MACH LEAR; Martens J., 2010, P INT C ART INT STAT; MITCHELL TJ, 1988, J AM STAT ASSOC, V83, P1023, DOI 10.2307/2290129; Mohamed S., 2011, ARXIV11061157; Nair V., 2010, P 27 INT C MACHINE L, P807, DOI DOI 10.5555/3104322.3104425; Neal RM, 1993, CRGTR931 U TOR DEP C; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Ranzato M., 2010, P ADV NEUR INF PROC; Ranzato M., 2010, P INT C ART INT STAT; Ranzato M.A., 2011, P IEEE C COMP VIS PA; Ranzato M, 2010, PROC CVPR IEEE, P2551, DOI 10.1109/CVPR.2010.5539962; Rifai Salah, 2011, ICML; Salakhutdinov R., 2010, P ADV NEUR INF PROC; Socher R., 2011, P INT C MACH LEARN I; Tieleman T., 2008, P 25 INT C MACHINE L, P1064, DOI DOI 10.1145/1390156.1390290; Titsias M.K., 2011, P ADV NEUR INF PROC; Welling M., 2003, P ADV NEUR INF PROC; Williams CKI, 2002, NEURAL COMPUT, V14, P1169, DOI 10.1162/089976602753633439; Younes L, 1998, STOCHASTICS STOCHAST, P177; Yu K., 2010, P INT C MACH LEARN I; Zhou M, 2009, ADV NEURAL INFORM PR, P2295	49	18	24	0	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2014	36	9					1874	1887		10.1109/TPAMI.2013.238	http://dx.doi.org/10.1109/TPAMI.2013.238			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9OE	26352238				2022-12-18	WOS:000340210100013
J	Chahhou, M; Moumoun, L; El Far, M; Gadi, T				Chahhou, Mohamed; Moumoun, Lahcen; El Far, Mohamed; Gadi, Taoufiq			Segmentation of 3D Meshes Using p-Spectral Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D mesh; segmentation; spectral clustering; Cheeger cuts; minima rule		In this paper, we propose a new approach to get the optimal segmentation of a 3D mesh as a human can perceive using the minima rule and spectral clustering. This method is fully unsupervised and provides a hierarchical segmentation via recursive cuts. We introduce a new concept of the adjacency matrix based on cognitive studies. We also introduce the use of one-spectral clustering which leads to the optimal Cheeger cut value.	[Chahhou, Mohamed; El Far, Mohamed] Univ Sidi Mohamed Ben Abdellah, Fac Sci Dhar Mahraz, Fes, Morroco, Morocco; [Moumoun, Lahcen; Gadi, Taoufiq] Univ Hassan Ier, Fac Sci & Technol, Settat, Morroco, Morocco	Sidi Mohamed Ben Abdellah University of Fez; Hassan First University of Settat	Chahhou, M (corresponding author), Univ Sidi Mohamed Ben Abdellah, Fac Sci Dhar Mahraz, Fes, Morroco, Morocco.	mchahhou@hotmail.com; lahcenm@gmail.com; elfar22@yahoo.fr; tgadi@itlearning.uh1.ac.ma		Gadi, Taoufiq/0000-0002-2174-5816				Agathos A, 2007, COMPUT AIDED DES APP, V4, P827, DOI DOI 10.1080/16864360.2007.10738515; Amghibech S, 2003, ARS COMBINATORIA, V67, P283; Attene M, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P14; Buhler T., 2009, P 26 ANN INT C MACH, P81, DOI DOI 10.1145/1553374.1553385; Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379; Golovinskiy A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409098; Hein M, 2010, ADV NEURAL INFORM PR, V1, P847; HOFFMAN D. D., 1987, READINGS COMPUTER VI, P227; Katz S, 2005, VISUAL COMPUT, V21, P649, DOI 10.1007/s00371-005-0344-9; Lai YK, 2008, SPM 2008: PROCEEDINGS OF THE ACM SOLID AND PHYSICAL MODELING SYMPOSIUM, P183; Lee Y, 2005, COMPUT AIDED GEOM D, V22, P444, DOI 10.1016/j.cagd.2005.04.002; Liu R, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P298; Mahalanobis, 1936, P NATL I SCI INDIA, V2, P49; Moumoun L., 2010, INT J ENG SCI TECHNO, V2, P3165; Shamir A, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P82; Shamir A, 2006, EUROGRAPHICS STARS, P137; Shapira L, 2008, VISUAL COMPUT, V24, P249, DOI 10.1007/s00371-007-0197-5; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shlafman S, 2002, COMPUT GRAPH FORUM, V21, P219, DOI 10.1111/1467-8659.00581; Szlam A., 2010, P 27 INT C MACH LEAR, P1039, DOI DOI 10.0RG/PAPERS/233.PDF; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Zhang Y, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P273	22	18	21	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2014	36	8					1687	1693		10.1109/TPAMI.2013.2297314	http://dx.doi.org/10.1109/TPAMI.2013.2297314			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM9HN	26353348				2022-12-18	WOS:000340191900016
J	Vijayanarasimhan, S; Jain, P; Grauman, K				Vijayanarasimhan, Sudheendra; Jain, Prateek; Grauman, Kristen			Hashing Hyperplane Queries to Near Points with Applications to Large-Scale Active Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article								We consider the problem of retrieving the database points nearest to a given hyperplane query without exhaustively scanning the entire database. For this problem, we propose two hashing-based solutions. Our first approach maps the data to 2-bit binary keys that are locality sensitive for the angle between the hyperplane normal and a database point. Our second approach embeds the data into a vector space where the euclidean norm reflects the desired distance between the original points and hyperplane query. Both use hashing to retrieve near points in sublinear time. Our first method's preprocessing stage is more efficient, while the second has stronger accuracy guarantees. We apply both to pool-based active learning: Taking the current hyperplane classifier as a query, our algorithm identifies those points (approximately) satisfying the well-known minimal distance-to-hyperplane selection criterion. We empirically demonstrate our methods' tradeoffs and show that they make it practical to perform active selection with millions of unlabeled points.	[Vijayanarasimhan, Sudheendra; Grauman, Kristen] Univ Texas Austin, Austin, TX 78712 USA; [Jain, Prateek] Microsoft Res, Machine Learning Grp, Bangalore, Karnataka, India	University of Texas System; University of Texas Austin; Microsoft	Vijayanarasimhan, S (corresponding author), Univ Texas Austin, 1 Univ Stn C0500, Austin, TX 78712 USA.	svnaras@cs.utexas.edu; prajain@microsoft.com; grauman@cs.utexas.edu			NSF CAREER [IIS-0747356]; DARPA CSSG; Luce Foundation	NSF CAREER(National Science Foundation (NSF)NSF - Office of the Director (OD)); DARPA CSSG(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); Luce Foundation	This work was supported in part by NSF CAREER IIS-0747356, DARPA CSSG, and the Luce Foundation.	Andoni A., 2009, P 20 ANN ACM SIAM S; ANDONI A, 2006, P S FDN COMP SCI FOC; [Anonymous], 2000, P 17 INT C MACH LEAR; [Anonymous], 2010, P IEEE C COMP VIS PA; Basri R, 2011, IEEE T PATTERN ANAL, V33, P266, DOI 10.1109/TPAMI.2010.110; Bordes A, 2005, J MACH LEARN RES, V6, P1579; Burr Settles, 2009, COMPUTER SCI TECHNIC; CAMPBELL C, 2000, P 17 INT C MACH LEAR; CHANG EY, 2005, IEEE T MULTIMEDIA; Charikar M., 2002, STOC; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Goemans MX, 1995, J ACM, V42, P1115, DOI 10.1145/227683.227684; INDYK P, 2003, P 3 INT WORKSH STAT; Jain P., 2010, P ADV NEUR INF PROC; Kannan R, 2008, FOUND TRENDS THEOR C, V4, P157, DOI 10.1561/0400000025; Krizhevsky A., 2009, LEARNING MULTIPLE LA; Kulis B., 2009, P IEEE INT C COMP VI; Liu W., 2012, P INT C MACH LEARN I; MAGEN A., 2002, P 6 INT WORKSH RAND; Panda N, 2006, MULTIMED TOOLS APPL, V31, P249, DOI 10.1007/s11042-006-0043-1; Salakhutdinov R, 2007, P SIGIR WORKSH INF R; Segal R, 2006, P C EM ANT; SHAKHNAROVICH G, 2003, P 9 IEEE INT C COMP; Smola Alex J, 2000, SPARSE GREEDY MATRIX; Tong S., 2000, P 17 INT C MACH LEAR; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; Vedaldi A., 2010, P IEEE C COMP VIS PA; Vedaldi A., 2009, P 12 IEEE INT C COMP; VIJAYANARASIMHAN S., 2011, P IEEE C COMP VIS PA; Warmuth MK, 2003, J CHEM INF COMP SCI, V43, P667, DOI 10.1021/ci025620t; Weiss Y., 2008, P ADV NEUR INF PROC; Zhao W., 2008, P 2 ANN INT WORKSH F	34	18	18	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2014	36	2					276	288		10.1109/TPAMI.2013.121	http://dx.doi.org/10.1109/TPAMI.2013.121			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	278OL	24356349				2022-12-18	WOS:000328899500006
J	Koppal, SJ; Gkioulekas, I; Young, T; Park, H; Crozier, KB; Barrows, GL; Zickler, T				Koppal, Sanjeev J.; Gkioulekas, Ioannis; Young, Travis; Park, Hyunsung; Crozier, Kenneth B.; Barrows, Geoffrey L.; Zickler, Todd			Toward Wide-Angle Microvision Sensors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computational sensors; micro/nano computer vision; optical templates; optical computing; micro/nano robotics	TRACKING	Achieving computer vision on microscale devices is a challenge. On these platforms, the power and mass constraints are severe enough for even the most common computations (matrix manipulations, convolution, etc.) to be difficult. This paper proposes and analyzes a class of miniature vision sensors that can help overcome these constraints. These sensors reduce power requirements through template-based optical convolution, and they enable a wide field-of-view within a small form through a refractive optical design. We describe the tradeoffs between the field-of-view, volume, and mass of these sensors and we provide analytic tools to navigate the design space. We demonstrate milliscale prototypes for computer vision tasks such as locating edges, tracking targets, and detecting faces. Finally, we utilize photolithographic fabrication tools to further miniaturize the optical designs and demonstrate fiducial detection onboard a small autonomous air vehicle.	[Koppal, Sanjeev J.; Gkioulekas, Ioannis; Park, Hyunsung; Crozier, Kenneth B.; Zickler, Todd] Harvard Univ, Cambridge, MA 02138 USA; [Gkioulekas, Ioannis; Zickler, Todd] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA	Harvard University; Harvard University	Koppal, SJ (corresponding author), Harvard Univ, 1350 Massachusetts Ave, Cambridge, MA 02138 USA.	sjkoppal@seas.harvard.edu	CROZIER, KENNETH/J-7143-2016	CROZIER, KENNETH/0000-0003-0947-001X	US National Science Foundation (NSF) [IIS-0926148]; US Office of Naval Research [N000140911022]; US Army Research Laboratory; US Army Research Office [54262-CI]; Harvard Nanoscale Science and Engineering Center (NSEC); NSF [NSF/PHY06-46094]; US Defense Advanced Research Projects Agency (DARPA) N/MEMS S&T Fundamentals program [N66001-10-1-4008]; Space and Naval Warfare Systems Center Pacific (SPAWAR); NSF	US National Science Foundation (NSF)(National Science Foundation (NSF)); US Office of Naval Research(Office of Naval Research); US Army Research Laboratory(United States Department of DefenseUS Army Research Laboratory (ARL)); US Army Research Office; Harvard Nanoscale Science and Engineering Center (NSEC); NSF(National Science Foundation (NSF)); US Defense Advanced Research Projects Agency (DARPA) N/MEMS S&T Fundamentals program; Space and Naval Warfare Systems Center Pacific (SPAWAR); NSF(National Science Foundation (NSF))	The project was supported by US National Science Foundation (NSF) Award IIS-0926148; US Office of Naval Research award N000140911022; the US Army Research Laboratory and the US Army Research Office under contract/grant number 54262-CI; the Harvard Nanoscale Science and Engineering Center (NSEC), which is supported by the NSF under grant no. NSF/PHY06-46094; and the US Defense Advanced Research Projects Agency (DARPA) N/MEMS S&T Fundamentals program under grant no. N66001-10-1-4008 issued by the Space and Naval Warfare Systems Center Pacific (SPAWAR). The authors thank James MacArthur for his help with electronics and Robert Wood for his broad support. Fabrication work was carried out at the Harvard Center for Nanoscale Systems, which is supported by the NSF.	Ababsa Fakhreddine, 2008, Journal of Multimedia, V3, P34, DOI 10.4304/jmm.3.4.34-41; Avidan S., 2001, P IEEE C COMP VIS PA; Bagherinia H., 2011, P IEEE COL PHOT COMP; Barrows G., 2002, P BRIST UAV C; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; Borrelli N. F., 1999, MICROOPTICS TECHNOLO; Brajovic V, 1998, IEEE J SOLID-ST CIRC, V33, P1199, DOI 10.1109/4.705358; CentEye and Inc, 2012, CENT WEBS; Chandrakasan A., 2006, P NSTI NAN C; Chari V., 2009, P BRIT MACH VIS C; Cho Y., 1998, P IEEE VIRT REAL ANN; Claus D., 2002, P INT S MIX AUGM REA; Collection, 2009, FLYING INSECTS ROBOT; Cossairt OS, 2011, J OPT SOC AM A, V28, P2540, DOI 10.1364/JOSAA.28.002540; Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730; Edge M., 1999, UNDERWATER PHOTOGRAP; Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301; Farabet C., 2009, P 5 IEEE WORKSH EMB; Gkioulekas I., 2011, P NEUR INF PROC SYST; Goodman J. W., 2005, MCGRAW HILL PHYS QUA; Gyselinckx B., 2006, P IEEE CUST INT CIRC, P13; Herzig H. P., 1999, MICROOPTICS ELEMENTS; Hiura S., 2009, P WORKSH OMN DIR VIS; Jeong KH, 2006, SCIENCE, V312, P557, DOI 10.1126/science.1123053; Karpelson M., 2009, P IEEE INT C ROB AUT; Kato H., 1999, P 2 IEEE ACM INT WOR; Ko HC, 2009, SMALL, V5, P2703, DOI 10.1002/smll.200900934; Koppal S.J., 2012, MICROVISION SENSORS; Krishnan G., 2009, P SPIE; Kumar N., 2009, P 12 IEEE INT C COMP; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Levin A., 2007, P ACM SIGGRAPH; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Mielenz KD, 1999, J RES NATL INST STAN, V104, P479, DOI 10.6028/jres.104.029; MIYAMOTO K, 1964, J OPT SOC AM, V54, P1060, DOI 10.1364/JOSA.54.001060; Mohan A., 2009, P ACM SIGGRAPH; Nayar SK, 2006, INT J COMPUT VISION, V70, P7, DOI 10.1007/s11263-005-3102-6; Ng R, 2005, ACM T GRAPHIC, V24, P735, DOI 10.1145/1073204.1073256; O'Toole M., 2010, P ACM SIGGR AS; Olson E, 2011, P ICRA; Pedrotti F., 2006, INTRO OPTICS; Rekimoto J., 2000, P 4 CAN C COMP ROB V; Sattar J., 2007, P 4 CAN C COMP ROB V; Shalev-Shwartz S., 2011, P NEUR INF PROC SYST; Steltz E, 2009, IEEE-ASME T MECH, V14, P1, DOI 10.1109/TMECH.2008.2005902; Swaminathan R., 2001, P 8 IEEE INT C COMP; Tang CM, 2004, WIRELESS SENSOR NETWORKS, P207; Tanida J, 2001, APPL OPTICS, V40, P1806, DOI 10.1364/AO.40.001806; Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055; Treibitz T., 2008, P IEEE C COMP VIS PA; Uttam S, 2009, OPT EXPRESS, V17, P1691, DOI 10.1364/OE.17.001691; VEERARAGHAVAN A, 2007, P ACM SIGGRAPH; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Volkel R, 2003, MICROELECTRON ENG, V67-8, P461, DOI 10.1016/S0167-9317(03)00102-3; WILHELM A, 2005, P IEEE INT C MECH AU; Wolf W, 2002, COMPUTER, V35, P48, DOI 10.1109/MC.2002.1033027; Wood R.W., 1911, PHYS OPTICS; Yu F.T.S., 1998, OPTICAL PATTERN RECO; ZHANG X, 2002, P 1 INT S MIX AUGM R; ZOMET A, 2006, P IEEE C COMP VIS PA; [No title captured]	61	18	18	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2013	35	12					2982	2996		10.1109/TPAMI.2013.22	http://dx.doi.org/10.1109/TPAMI.2013.22			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	245YV	24136435				2022-12-18	WOS:000326502200014
J	Ying, XH; Peng, K; Hou, YB; Guan, S; Kong, J; Zha, HB				Ying, Xianghua; Peng, Kun; Hou, Yongbo; Guan, Sheng; Kong, Jing; Zha, Hongbin			Self-Calibration of Catadioptric Camera with Two Planar Mirrors from Silhouettes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Self-calibration; circular points; silhouettes; catadioptric camera; planar mirrors	CIRCULAR MOTION; DYNAMIC SILHOUETTES; GEOMETRY; RECONSTRUCTION; CONSTRAINTS; SEQUENCES; PROFILES; POINTS; CURVE	If an object is interreflected between two planar mirrors, we may take an image containing both the object and its multiple reflections, i.e., simultaneously imaging multiple views of an object by a single pinhole camera. This paper emphasizes the problem of recovering both the intrinsic and extrinsic parameters of the camera using multiple silhouettes from one single image. View pairs among views in a single image can be divided into two kinds by the relationship between the two views in the pair: reflected by some mirror (real or virtual) and in a circular motion. Epipoles in the first kind of pairs can be easily determined from intersections of common tangent lines of silhouettes. Based on the projective properties of these epipoles, efficient methods are proposed to recover both the imaged circular points and the included angle between two mirrors. Epipoles in the second kind of pairs can be recovered simultaneously with the projection of intersection line between two mirrors by solving a simple 1D optimization problem using the consistency constraint of epipolar tangent lines. Fundamental matrices among views in a single image are all recovered. Using the estimated intrinsic and extrinsic parameters of the camera, a euclidean reconstruction can be obtained. Experiments validate the proposed approach.	[Ying, Xianghua; Hou, Yongbo; Guan, Sheng; Kong, Jing; Zha, Hongbin] Peking Univ, Key Lab Machine Percept, Minist Educ, Sch Elect Engn & Comp Sci,Ctr Informat Sci, Beijing 100871, Peoples R China; [Peng, Kun] Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA	Peking University; University of North Carolina; University of North Carolina Chapel Hill	Ying, XH (corresponding author), Peking Univ, Key Lab Machine Percept, Minist Educ, Sch Elect Engn & Comp Sci,Ctr Informat Sci, Beijing 100871, Peoples R China.	xhying@cis.pku.edu.cn; pengkun@cs.unc.edu; houyb@cis.pku.edu.cn; guansheng@cis.pku.edu.cn; kongjing@cis.pku.edu.cn; zha@cis.pku.edu.cn			NKBPRC 973 [2011CB302202]; NNSFC [61273283, 61075034, 91120004]; NHTRDP 863 [2009AA01Z329]	NKBPRC 973(National Basic Research Program of China); NNSFC(National Natural Science Foundation of China (NSFC)); NHTRDP 863	This work was supported in part by NKBPRC 973 Grant No. 2011CB302202, NNSFC Grant No. 61273283, NNSFC Grant No. 61075034, NNSFC Grant No. 91120004, and NHTRDP 863 Grant No. 2009AA01Z329.	Astrom K, 1999, INT J COMPUT VISION, V33, P51, DOI 10.1023/A:1008113231241; CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813; CIPOLLA R, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P269, DOI 10.1109/ICCV.1995.466775; Fitzgibbon A. W., 1998, P 3D STRUCT MULT IM, P721; Forbes K, 2006, LECT NOTES COMPUT SC, V3952, P165; Fujiyama Shinji, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P45, DOI 10.1109/ICPR.2010.20; Gluckman J, 2002, IEEE T PATTERN ANAL, V24, P224, DOI 10.1109/34.982902; Gurdjos P, 2006, LECT NOTES COMPUT SC, V3951, P238; Hartley R., 2003, MULTIPLE VIEW GEOMET; Hecht E, 1997, OPTICS; Hernandez C, 2007, IEEE T PATTERN ANAL, V29, P343, DOI 10.1109/TPAMI.2007.42; Huang P.-H., 2006, P IEEE C COMP VIS PA, V1, P379; Huang P.-H., 2008, P IEEE C COMP VIS PA, P24; Jiang G, 2004, IEEE T PATTERN ANAL, V26, P721, DOI 10.1109/TPAMI.2004.4; Jiang G, 2002, LECT NOTES COMPUT SC, V2350, P537; Joshi T, 1999, INT J COMPUT VISION, V31, P31, DOI 10.1023/A:1008042709602; Kim JS, 2005, IEEE T PATTERN ANAL, V27, P637, DOI 10.1109/TPAMI.2005.80; Kumar R., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587676; Lanman D, 2009, COMPUT VIS IMAGE UND, V113, P1107, DOI 10.1016/j.cviu.2009.03.016; Mariottini GL, 2009, IEEE INT CONF ROBOT, P1510, DOI 10.1109/ROBOT.2009.5152609; Mendonca PRS, 2001, IEEE T PATTERN ANAL, V23, P604, DOI 10.1109/34.927461; MITSUMOTO H, 1992, IEEE T PATTERN ANAL, V14, P941, DOI 10.1109/34.161352; PORRILL J, 1991, IMAGE VISION COMPUT, V9, P45, DOI 10.1016/0262-8856(91)90048-T; RIEGER JH, 1986, OPT LETT, V11, P123, DOI 10.1364/OL.11.000123; Rodrigues R, 2010, LECT NOTES COMPUT SC, V6314, P382, DOI 10.1007/978-3-642-15561-1_28; Semple J.G, 1952, ALGEBRAIC PROJECTIVE; Sinha SN, 2004, PROC CVPR IEEE, P195; Sturm P, 2006, LECT NOTES COMPUT SC, V3852, P21; Tan KH, 2004, IEEE T PATTERN ANAL, V26, P941, DOI 10.1109/TPAMI.2004.33; Vieville T., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P207; Wong KYK, 2008, IEEE T PATTERN ANAL, V30, P2243, DOI 10.1109/TPAMI.2008.169; Wong KYK, 2004, IEEE T IMAGE PROCESS, V13, P379, DOI 10.1109/TIP.2003.821113; Wu HHP, 2007, IEEE T CIRC SYST VID, V17, P686, DOI 10.1109/TCSVT.2007.896629; Ying XH, 2010, PROC CVPR IEEE, P1126, DOI 10.1109/CVPR.2010.5540088; Zhang H, 2009, IEEE T PATTERN ANAL, V31, P5, DOI 10.1109/TPAMI.2008.56; Zhang Z., 1999, P 7 IEEE INT C COMP, V1, P666, DOI DOI 10.1109/ICCV.1999.791289; Zhong H, 2006, INT C PATT RECOG, P715	37	18	21	0	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2013	35	5					1206	1220		10.1109/TPAMI.2012.195	http://dx.doi.org/10.1109/TPAMI.2012.195			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	106EZ	23520260				2022-12-18	WOS:000316126800014
J	Panagopoulos, A; Wang, CH; Samaras, D; Paragios, N				Panagopoulos, Alexandros; Wang, Chaohui; Samaras, Dimitris; Paragios, Nikos			Simultaneous Cast Shadows, Illumination and Geometry Inference Using Hypergraphs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Markov random fields; photometry; shading; image models	SINGLE; SEGMENTATION	The cast shadows in an image provide important information about illumination and geometry. In this paper, we utilize this information in a novel framework in order to jointly recover the illumination environment, a set of geometry parameters, and an estimate of the cast shadows in the scene given a single image and coarse initial 3D geometry. We model the interaction of illumination and geometry in the scene and associate it with image evidence for cast shadows using a higher order Markov Random Field (MRF) illumination model, while we also introduce a method to obtain approximate image evidence for cast shadows. Capturing the interaction between light sources and geometry in the proposed graphical model necessitates higher order cliques and continuous-valued variables, which make inference challenging. Taking advantage of domain knowledge, we provide a two-stage minimization technique for the MRF energy of our model. We evaluate our method in different datasets, both synthetic and real. Our model is robust to rough knowledge of geometry and inaccurate initial shadow estimates, allowing a generic coarse 3D model to represent a whole class of objects for the task of illumination estimation, or the estimation of geometry parameters to refine our initial knowledge of scene geometry, simultaneously with illumination estimation.	[Panagopoulos, Alexandros; Samaras, Dimitris] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA; [Wang, Chaohui; Paragios, Nikos] Ecole Cent Paris, Ctr Visual Comp, Chatenay Malabry, France; [Wang, Chaohui; Paragios, Nikos] INRIA Saclay Ile de France, Equipe GALEN, Orsay, France	State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook; UDICE-French Research Universities; Universite Paris Saclay	Panagopoulos, A (corresponding author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.	apanagop@cs.stonybrook.edu; chaohui.wang@ecp.fr; samaras@cs.stonybrook.edu; nikos.paragios@ecp.fr			US National Institutes of Health (NIH) [5R01EB7530-2, 1R01DA020949-01]; US National Science Foundation (NSF) [CNS-0627645, IIS-0916286, CNS-0721701, IIS-1111047]; European Research Council Starting Grant DIOCLES [ERC-STG-259112]; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [R01EB007530] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON DRUG ABUSE [R01DA020949] Funding Source: NIH RePORTER	US National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); US National Science Foundation (NSF)(National Science Foundation (NSF)); European Research Council Starting Grant DIOCLES; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NATIONAL INSTITUTE ON DRUG ABUSE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Drug Abuse (NIDA)European Commission)	This work was partially supported by US National Institutes of Health (NIH) grants 5R01EB7530-2, 1R01DA020949-01 and US National Science Foundation (NSF) grants CNS-0627645, IIS-0916286, CNS-0721701, IIS-1111047. Nikos Paragios's work was partially supported by the European Research Council Starting Grant DIOCLES (ERC-STG-259112).	Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5; Bray M, 2006, LECT NOTES COMPUT SC, V3952, P642; Dark Channel Prior Dehazing, 2015, PYTH IMPL SINGL IM H; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Finlayson D.M.S., 2009, INT J COMPUT VISION, V79, P13; Finlayson G.D., 2002, P EUR C COMP VIS; FISHER R, 1953, PROC R SOC LON SER-A, V217, P295, DOI 10.1098/rspa.1953.0064; Geman S., 1990, READINGS UNCERTAIN R, P452; Gonzalez R.C., 2006, DIGITAL IMAGE PROCES; Guo RQ, 2011, PROC CVPR IEEE; Hara K, 2005, IEEE T PATTERN ANAL, V27, P493, DOI 10.1109/TPAMI.2005.82; Ishikawa H., 2009, P IEEE C COMP VIS PA; Kim T, 2005, INT J IMAG SYST TECH, V15, P143, DOI 10.1002/ima.20047; Komodakis N., 2009, P IEEE C COMP VIS PA; Komodakis N, 2008, COMPUT VIS IMAGE UND, V112, P14, DOI 10.1016/j.cviu.2008.06.007; Lalonde J.F., 2009, P 12 IEEE INT C COMP; Lalonde J.F., 2010, P EUR C COMP VIS; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Li Y., 2003, P 9 IEEE INT C COMP; Panagopoulos A., 2010, P COL REFL IM COMP V; Panagopoulos A, 2011, PROC CVPR IEEE, P673, DOI 10.1109/CVPR.2011.5995585; Panagopoulos A, 2009, PROC CVPR IEEE, P651, DOI 10.1109/CVPRW.2009.5206665; Ramamoorthi R, 2005, IEEE T PATTERN ANAL, V27, P288, DOI 10.1109/TPAMI.2005.22; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Salvador E, 2004, COMPUT VIS IMAGE UND, V95, P238, DOI 10.1016/j.cviu.2004.03.008; Sato I, 2003, IEEE T PATTERN ANAL, V25, P290, DOI 10.1109/TPAMI.2003.1182093; Wang C., 2009, P 12 IEEE INT C COMP; Wang Y, 2003, GRAPH MODELS, V65, P185, DOI 10.1016/S1524-0703(03)00043-2; Yang Y., 1991, P IEEE C COMP VIS PA; Zhou W, 2008, IMAGE VISION COMPUT, V26, P415, DOI 10.1016/j.imavis.2006.12.003; Zhu JJ, 2010, PROC CVPR IEEE, P223, DOI 10.1109/CVPR.2010.5540209	31	18	19	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2013	35	2					437	449		10.1109/TPAMI.2012.110	http://dx.doi.org/10.1109/TPAMI.2012.110			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	057JX	22585101				2022-12-18	WOS:000312560600015
J	Wu, TP; Yeung, SK; Jia, JY; Tang, CK; Medioni, G				Wu, Tai-Pang; Yeung, Sai-Kit; Jia, Jiaya; Tang, Chi-Keung; Medioni, Gerard			A Closed-Form Solution to Tensor Voting: Theory and Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Tensor voting; closed-form solution; structure inference; parameter estimation; multiview stereo	SEGMENTATION	We prove a closed-form solution to tensor voting (CFTV): Given a point set in any dimensions, our closed-form solution provides an exact, continuous, and efficient algorithm for computing a structure-aware tensor that simultaneously achieves salient structure detection and outlier attenuation. Using CFTV, we prove the convergence of tensor voting on a Markov random field (MRF), thus termed as MRFTV, where the structure-aware tensor at each input site reaches a stationary state upon convergence in structure propagation. We then embed structure-aware tensor into expectation maximization (EM) for optimizing a single linear structure to achieve efficient and robust parameter estimation. Specifically, our EMTV algorithm optimizes both the tensor and fitting parameters and does not require random sampling consensus typically used in existing robust statistical techniques. We performed quantitative evaluation on its accuracy and robustness, showing that EMTV performs better than the original TV and other state-of-the-art techniques in fundamental matrix estimation for multiview stereo matching. The extensions of CFTV and EMTV for extracting multiple and nonlinear structures are underway.	[Wu, Tai-Pang] Hong Kong Appl Sci & Technol Res Inst ASTRI Co Lt, Enterprise & Consumer Elect ECE Grp, Bioinformat Ctr, Shatin, Hong Kong, Peoples R China; [Yeung, Sai-Kit] Singapore Univ Technol & Design, Singapore 128805, Singapore; [Jia, Jiaya] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China; [Tang, Chi-Keung] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China; [Medioni, Gerard] Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA	Hong Kong Applied Science & Technology Research Institute Company Limited (ASTRI); Singapore University of Technology & Design; Chinese University of Hong Kong; Hong Kong University of Science & Technology; University of Southern California	Wu, TP (corresponding author), Hong Kong Appl Sci & Technol Res Inst ASTRI Co Lt, Enterprise & Consumer Elect ECE Grp, Bioinformat Ctr, 3-F,2 Sci Pk W Ave,Hong Kong Sci Pk, Shatin, Hong Kong, Peoples R China.	tpwu@astri.org; saikit@sutd.edu.sg; leojia@cse.cuhk.edu.hk; cktang@cse.ust.hk; medioni@iris.usc.edu	Jia, Jiaya/I-3251-2012	Yeung, Sai-Kit/0000-0001-7974-0607	Hong Kong Research Grant Council (RGC) [412911]; RGC [619711]; Google;  [SRG ISTD 2011 016]	Hong Kong Research Grant Council (RGC)(Hong Kong Research Grants Council); RGC(Hong Kong Research Grants Council); Google(Google Incorporated); 	The authors would like to thank the Associate Editor and all of the anonymous reviewers. Special thanks to Reviewer 1 for his/her helpful and detailed comments throughout the review cycle. S.-K. Yeung was supported by the Start-up Research Grant: SRG ISTD 2011 016. J. Jia was supported by the Hong Kong Research Grant Council (RGC, grant no. 412911). C.-K. Tang was supported by RGC (grant no. 619711) and the Google Faculty Award on quasi dense 3D reconstruction.	Arya S., 2003, P ACM SIAM S DISCR A, P271; Bilmes JA, 1997, ICSITR97021; Chen HF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P878, DOI 10.1109/ICCV.2003.1238441; Chum O, 2008, IEEE T PATTERN ANAL, V30, P1472, DOI 10.1109/TPAMI.2007.70787; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Dahyot R, 2009, IEEE T PATTERN ANAL, V31, P1502, DOI 10.1109/TPAMI.2008.288; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Forsyth David A, 2012, COMPUTER VISION MODE; Franken E, 2006, LECT NOTES COMPUT SC, V3954, P228; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Georgescu B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P456; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; Hough, 1959, P INT C HIGH EN ACC, V590914, P554; Huber PJ, 1981, ROBUST STAT; Lee KM, 1998, IEEE T PATTERN ANAL, V20, P200, DOI 10.1109/34.659940; Lourakis M., 2004, 340 ICSFORTH; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MCLACHLAN GJ, 1997, EM ALGORITHMS EXTENS; Medioni G., 2000, COMPUTATIONAL FRAMEW; Meer P., 2004, EMERGING TOPICS COMP; Mordohai P, 2010, J MACH LEARN RES, V11, P411; Rousseeuw P. J., 1987, ROBUST REGRESSION OU; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; Sim Kristy, 2006, IEEE COMP SOC C COMP, P485; Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3; Subarao R., 2006, P WORKSH 25 YEARS RA; Tong WS, 2004, IEEE T PATTERN ANAL, V26, P1167, DOI 10.1109/TPAMI.2004.72; Wang HZ, 2004, IEEE T PATTERN ANAL, V26, P1459, DOI 10.1109/TPAMI.2004.109; Wu TP, 2010, PROC CVPR IEEE, P1482, DOI 10.1109/CVPR.2010.5539796	29	18	22	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2012	34	8					1482	1495		10.1109/TPAMI.2011.250	http://dx.doi.org/10.1109/TPAMI.2011.250			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	957UE	22184257	Green Submitted			2022-12-18	WOS:000305188500003
J	Perina, A; Cristani, M; Castellani, U; Murino, V; Jojic, N				Perina, Alessandro; Cristani, Marco; Castellani, Umberto; Murino, Vittorio; Jojic, Nebojsa			Free Energy Score Spaces: Using Generative Information in Discriminative Classifiers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hybrid generative/discriminative paradigm; variational free energy; classification	MODELS; SCENE; FRAMEWORK	A score function induced by a generative model of the data can provide a feature vector of a fixed dimension for each data sample. Data samples themselves may be of differing lengths (e. g., speech segments or other sequential data), but as a score function is based on the properties of the data generation process, it produces a fixed-length vector in a highly informative space, typically referred to as "score space." Discriminative classifiers have been shown to achieve higher performances in appropriately chosen score spaces with respect to what is achievable by either the corresponding generative likelihood-based classifiers or the discriminative classifiers using standard feature extractors. In this paper, we present a novel score space that exploits the free energy associated with a generative model. The resulting free energy score space (FESS) takes into account the latent structure of the data at various levels and can be shown to lead to classification performance that at least matches the performance of the free energy classifier based on the same generative model and the same factorization of the posterior. We also show that in several typical computer vision and computational biology applications the classifiers optimized in FESS outperform the corresponding pure generative approaches, as well as a number of previous approaches combining discriminating and generative models.	[Perina, Alessandro; Jojic, Nebojsa] Microsoft Res, Redmond, WA 98052 USA; [Perina, Alessandro; Cristani, Marco; Castellani, Umberto; Murino, Vittorio] Univ Verona, I-37135 Verona, Italy; [Cristani, Marco; Murino, Vittorio] Italian Inst Technol, I-16163 Genoa, Italy	Microsoft; University of Verona; Istituto Italiano di Tecnologia - IIT	Perina, A (corresponding author), Microsoft Res, 1 Microsoft Way, Redmond, WA 98052 USA.	alperina@microsoft.com; marco.cristani@univr.it; umberto.castellani@univr.it; jojic@microsoft.com	Cristani, Marco/I-5275-2012; Castellani, Umberto/H-5101-2013	Castellani, Umberto/0000-0002-6099-5682; Murino, Vittorio/0000-0002-8645-2328	FET within the EU under the SIMBAD [213250]	FET within the EU under the SIMBAD	The authors acknowledge financial support from the FET programme within the EU FP7, under the SIMBAD project (contract 213250).	Bicego M, 2003, LECT NOTES ARTIF INT, V2734, P86; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716; Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517; Bouchard Guillaume, 2004, 16 IASC INT S COMP S, P721; Chang D.-Q.Z.a.S.-F., 2006, P IEEE CS C COMP VIS, p2017 ; Deng Li., 2003, SPEECH PROCESSING DY; Epshteyn A, 2006, J ARTIF INTELL RES, V27, P25, DOI 10.1613/jair.1934; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Fergus R, 2003, PROC CVPR IEEE, P264; Frank A., 2010, UCI MACHINE LEARNING; Frey BJ, 2005, IEEE T PATTERN ANAL, V27, P1392, DOI 10.1109/TPAMI.2005.169; Fujino A, 2008, IEEE T PATTERN ANAL, V30, P424, DOI 10.1109/TPAMI.2007.70710; Ghahramani Z., 1997, CRGTR971 U CAMBR; Girolami M., 2003, P 26 ANN INT ACM SIG, P433, DOI [10.1145/860435.860537, DOI 10.1145/860435.860537]; HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831; Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649; Holub AD, 2005, IEEE I CONF COMP VIS, P136; Huang JC, 2007, BIOINFORMATICS, V23, pI212, DOI 10.1093/bioinformatics/btm217; Jaakkola T, 2000, ADV NEUR IN, V12, P470; Jaakkola TS, 1999, ADV NEUR IN, V11, P487; Jojic N., 2006, P IEEE COMP SOC C CO, V1, P117; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; KAPADIA S, 1998, THESIS U CAMBRIDGE; Kappen HJ, 2001, NEU INF PRO, P37; Lasserre J.A., 2006, IEEE COMP SOC C COMP, P87, DOI DOI 10.1109/CVPR.2006.227; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; MacKay D.J.C., 1997, BOOK ENSEMBLE LEARNI; McCallum A., 2006, P 21 NAT C ART INT 1, P433; Minka T., 2005, TR2005144 MIC RES CA; Neal R. M., 1999, LEARNING GRAPHICAL M, P355, DOI DOI 10.1007/978-94-011-5014-9; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Perina A., 2011, P 6 IAPR INT C PATT, P12; Perina A., 2009, ADV NEURAL INFORM PR, P1428; Perina A, 2010, IMAGE VISION COMPUT, V28, P927, DOI 10.1016/j.imavis.2009.11.007; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Raina R., 2004, P ADV NEURAL INFORM, V16, P12; Rosales R, 2006, INT J COMPUT VISION, V67, P251, DOI 10.1007/s11263-006-5165-4; Sminchisescu Cristian, 2006, P INT C COMP VIS PAT, P1743; Smith N, 2002, ADV NEUR IN, V14, P1197; Smith N., 2002, CUEDFINGENFTR412 U C; Subramanya A, 2007, INT CONF ACOUST SPEE, P225; Towell G. G., 1990, AAAI-90 Proceedings. Eighth National Conference on Artificial Intelligence, P861; Tsuda K, 2002, NEURAL COMPUT, V14, P2397, DOI 10.1162/08997660260293274; Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1; Weber C, 2006, NEURAL NETWORKS, V19, P339, DOI 10.1016/j.neunet.2005.10.004; Xiong Li, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2713, DOI 10.1109/CVPR.2011.5995584; Yakhenko O., 2007, RP NIPS WORKSH REPR	50	18	20	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2012	34	7					1249	1261		10.1109/TPAMI.2011.241	http://dx.doi.org/10.1109/TPAMI.2011.241			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	943PZ	22156097				2022-12-18	WOS:000304138300001
J	Damen, D; Hogg, D				Damen, Dima; Hogg, David			Detecting Carried Objects from Sequences of Walking Pedestrians	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Baggage detection; carried-objects detection; silhouette analysis; temporal templates; template matching; periodicity analysis	PEOPLE	This paper proposes a method for detecting objects carried by pedestrians, such as backpacks and suitcases, from video sequences. In common with earlier work [14], [16] on the same problem, the method produces a representation of motion and shape (known as a temporal template) that has some immunity to noise in foreground segmentations and phase of the walking cycle. Our key novelty is for carried objects to be revealed by comparing the temporal templates against view-specific exemplars generated offline for unencumbered pedestrians. A likelihood map of protrusions, obtained from this match, is combined in a Markov random field for spatial continuity, from which we obtain a segmentation of carried objects using the MAP solution. We also compare the previously used method of periodicity analysis to distinguish carried objects from other protrusions with using prior probabilities for carried-object locations relative to the silhouette. We have reimplemented the earlier state-of-the-art method [14] and demonstrate a substantial improvement in performance for the new method on the PETS2006 data set. The carried-object detector is also tested on another outdoor data set. Although developed for a specific problem, the method could be applied to the detection of irregularities in appearance for other categories of object that move in a periodic fashion.	[Damen, Dima] Univ Bristol, Dept Comp Sci, Bristol BS8 1UB, Avon, England; [Hogg, David] Univ Leeds, Sch Comp, Leeds LS2 9JT, W Yorkshire, England	University of Bristol; University of Leeds	Damen, D (corresponding author), Univ Bristol, Dept Comp Sci, Woodland Rd, Bristol BS8 1UB, Avon, England.	damen@cs.bris.ac.uk; d.c.hogg@leeds.ac.uk		Hogg, David/0000-0002-6125-9564; Damen, Dima/0000-0001-8804-6238				[Anonymous], 2007, PASCAL VISUAL OBJECT; BenAbdelkader C, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P378, DOI 10.1109/AFGR.2002.1004183; Bose B., 2004, P IEEE INT WORKSH PE; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Branca A, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P317, DOI 10.1109/ICIP.2002.1038969; Chuang CH, 2009, IEEE T CIRC SYST VID, V19, P911, DOI 10.1109/TCSVT.2009.2017415; Cutler R, 1998, INT C PATT RECOG, P495, DOI 10.1109/ICPR.1998.711189; Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681; Davis J., 1997, P IEEE INT C COMP VI; Dimitrijevic M, 2006, COMPUT VIS IMAGE UND, V104, P127, DOI 10.1016/j.cviu.2006.07.007; Ferryman J., 2006, P IEEE INT WORKSH PE; FOSSATI A, 2007, P IEEE C COMP VIS PA; Ghanem NM, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P536, DOI 10.1109/ICIAP.2007.4362833; Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683; Haritaoglu I., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P102, DOI 10.1109/ICCV.1999.791204; HARITAOGLU I, 1999, P IEEE WORKSH VIS SU; Hu WM, 2006, IEEE T PATTERN ANAL, V28, P663, DOI 10.1109/TPAMI.2006.80; Lee CS, 2006, LECT NOTES COMPUT SC, V4069, P315; Lv FJ, 2002, INT C PATT RECOG, P562, DOI 10.1109/ICPR.2002.1044793; Magee D., 2002, Proceedings of the Statistical Methods in Video Processing Workshop, P7; Nanda H, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P428, DOI 10.1109/IVS.2003.1212949; Pflugfelder R., 2005, P DIG IM COMP TECHN; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tao D., 2006, P IEEE CS C COMP VIS; Zhang ZX, 2008, IEEE IMAGE PROC, P1364, DOI 10.1109/ICIP.2008.4712017; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149	27	18	18	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2012	34	6					1056	1067		10.1109/TPAMI.2011.205	http://dx.doi.org/10.1109/TPAMI.2011.205			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	927OE	22516646	Green Submitted			2022-12-18	WOS:000302916600002
J	Stolpner, S; Kry, P; Siddiqi, K				Stolpner, Svetlana; Kry, Paul; Siddiqi, Kaleem			Medial Spheres for Shape Approximation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Medial axis; shape approximation; sphere-based representations		We study the problem of approximating a 3D solid with a union of overlapping spheres. In comparison with a state-of-the-art approach, our method offers more than an order of magnitude speedup and achieves a tighter approximation in terms of volume difference with the original solid while using fewer spheres. The spheres generated by our method are internal and tangent to the solid's boundary, which permits an exact error analysis, fast updates under local feature size preserving deformation, and conservative dilation. We show that our dilated spheres offer superior time and error performance in approximate separation distance tests than the state-of-the-art method for sphere set approximation for the class of (sigma, theta)-fat solids. We envision that our sphere-based approximation will also prove useful for a range of other applications, including shape matching and shape segmentation.	[Stolpner, Svetlana; Kry, Paul; Siddiqi, Kaleem] McGill Univ, Sch Comp Sci, Montreal, PQ H3A 2A7, Canada; [Stolpner, Svetlana; Kry, Paul; Siddiqi, Kaleem] McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada	McGill University; McGill University	Stolpner, S (corresponding author), McGill Univ, Sch Comp Sci, Rm 318,McConnell Engn Bldg,3480 Univ St, Montreal, PQ H3A 2A7, Canada.	sveta@cim.mcgill.ca; kry@cs.mcgill.ca; siddiqi@cim.mcgill.ca		Kry, Paul/0000-0003-4176-6857; Siddiqi, Kaleem/0000-0002-7347-9716				Aichholzer O, 2009, COMPUT GRAPH FORUM, V28, P1349, DOI 10.1111/j.1467-8659.2009.01512.x; Amenta N, 2001, COMP GEOM-THEOR APPL, V19, P127, DOI 10.1016/S0925-7721(01)00017-7; Bradshaw G, 2004, ACM T GRAPHIC, V23, P1, DOI 10.1145/966131.966132; Dey TK, 2004, ALGORITHMICA, V38, P179, DOI 10.1007/s00453-003-1049-y; Edelsbrunner H., 1993, P 9 ANN S COMP GEOM, P218; Foskey M., 2003, P 8 ACM S SOL MOD AP, P96, DOI DOI 10.1145/781606.781623; Garcia M, 2005, LECT NOTES COMPUT SC, V3804, P167; Gartner B, 1999, LECT NOTES COMPUT SC, V1643, P325; Hubbard PM, 1996, ACM T GRAPHIC, V15, P179, DOI 10.1145/231731.231732; LARSEN E, 1999, FAST PROXIMITY QUERI; Miklos B, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778838; QUINLAN S, 1994, IEEE INT CONF ROBOT, P3324, DOI 10.1109/ROBOT.1994.351059; RANJAN V, 1994, COMPUTER, V27, P28, DOI 10.1109/2.299408; Rusinkiewicz S, 2000, COMP GRAPH, P343, DOI 10.1145/344779.344940; Shamir A, 2003, J SHAPE MODEL, V9, P203; Sherbrooke EC, 1996, GRAPH MODEL IM PROC, V58, P574, DOI 10.1006/gmip.1996.0047; Siddiqi K, 2008, COMPUT IMAGING VIS, V37, P1, DOI 10.1007/978-1-4020-8658-8; Stolpner S., 2011, THESIS MCGILL U; Stolpner S, 2011, COMPUT VIS IMAGE UND, V115, P695, DOI 10.1016/j.cviu.2010.10.014; Stolpner S, 2009, 2009 6TH INTERNATIONAL SYMPOSIUM ON VORONOI DIAGRAMS (ISVD 2009), P171, DOI 10.1109/ISVD.2009.24; Wang R, 2006, VISUAL COMPUT, V22, P612, DOI 10.1007/s00371-006-0052-0; Yoshizawa S, 2007, COMPUT GRAPH FORUM, V26, P255, DOI 10.1111/j.1467-8659.2007.01047.x	23	18	19	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2012	34	6					1234	1240		10.1109/TPAMI.2011.254	http://dx.doi.org/10.1109/TPAMI.2011.254			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	927OE	22516653	Green Submitted			2022-12-18	WOS:000302916600016
J	Varol, A; Shaji, A; Salzmann, M; Fua, P				Varol, Aydin; Shaji, Appu; Salzmann, Mathieu; Fua, Pascal			Monocular 3D Reconstruction of Locally Textured Surfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deformable surfaces; shape recovery; shape from shading	STRUCTURE-FROM-MOTION; SHAPE	Most recent approaches to monocular nonrigid 3D shape recovery rely on exploiting point correspondences and work best when the whole surface is well textured. The alternative is to rely on either contours or shading information, which has only been demonstrated in very restrictive settings. Here, we propose a novel approach to monocular deformable shape recovery that can operate under complex lighting and handle partially textured surfaces. At the heart of our algorithm are a learned mapping from intensity patterns to the shape of local surface patches and a principled approach to piecing together the resulting local shape estimates. We validate our approach quantitatively and qualitatively using both synthetic and real data.	[Varol, Aydin; Shaji, Appu; Fua, Pascal] Ecole Polytech Fed Lausanne, IC, Comp Vis Lab, CH-1015 Lausanne, Switzerland; [Salzmann, Mathieu] NICTA, Canberra, ACT 2600, Australia	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Australian National University	Varol, A (corresponding author), Ecole Polytech Fed Lausanne, IC, Comp Vis Lab, Stn 14, CH-1015 Lausanne, Switzerland.	aydin.varol@epfl.ch; appu.shaji@epfl.ch; mathieu.salzmann@nicta.com.au; pascal.fua@epfl.ch		Fua, Pascal/0000-0002-6702-9970; Salzmann, Mathieu/0000-0002-8347-8637	Swiss National Science Foundation	Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission)	This work has been supported in part by the Swiss National Science Foundation. In addition, the authors would like to thank Fethallah Benmansour for providing the code for computing the geodesic distance on a triangulated surface, Thibaut Weise for letting them use his structured light 3D scanner system, and Jean-Denis Durou for providing the implementation of various Shape from Shaping methods online.	AANAES H, 2002, P VIS MOD DYN SCEN W; Ahmed A., 2006, P IEEE CS C COMP VIS; Akhter I., 2009, P IEEE C COMP VIS PA; Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611; Bertsekas D. P., 1999, NONLINEAR PROGRAM, V2nd; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bishop C.M, 2006, PATTERN RECOGN; Bornemann F, 2006, COMPUT VIS SCI, V9, P57, DOI 10.1007/s00791-006-0016-y; Brand M, 2005, PROC CVPR IEEE, P122; BREGLER C, 2000, P IEEE C COMP VIS PA; Collins T., 2010, P INT WORKSHOP VISIO, P339; Durou JD, 2008, COMPUT VIS IMAGE UND, V109, P22, DOI 10.1016/j.cviu.2007.09.003; Ecker A., 2008, P EUR C COMP VIS OCT; Falcone M., 1997, P INT C IM AN PROC; Fayad J., 2010, P 11 EUR C COMP VIS; Fayad J., 2009, P BRIT MACH VIS C; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P671, DOI 10.1109/34.85657; Gumerov N.A., 2004, P EUR C COMP VIS MAY; Han M, 2004, PROC CVPR IEEE, P864; Horn B.K.P., 1989, SHAPE SHADING; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; Kozera R, 1997, J MATH IMAGING VIS, V7, P123, DOI 10.1023/A:1008249420974; Kriegman D. J., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P399, DOI 10.1007/BFb0054755; Liang J, 2005, PROC CVPR IEEE, P338; Moreno-Noguer F., 2010, P EUR C COMP VIS SEP; Moreno-Noguer F., 2009, P IEEE C COMP VIS PA; NAYAR SK, 1991, INT J COMPUT VISION, V6, P173, DOI 10.1007/BF00115695; Olsen SI, 2008, J MATH IMAGING VIS, V31, P233, DOI 10.1007/s10851-007-0060-3; Oren M, 1997, INT J COMPUT VISION, V24, P105, DOI 10.1023/A:1007954719939; Perriollat M., 2007, P BENCOS WORKSH BENC; Perriollat M., 2008, P BRIT MACH VIS C; Rabaud V., 2009, P IEEE C COMP VIS PA; Rabaud V., 2008, P IEEE C COMP VIS PA; Ramamoorthi R., 2001, P ACM SIGGR; Salzmann M., 2008, P IEEE C COMP VIS PA; Salzmann M., 2007, P IEEE C COMP VIS PA; Salzmann M, 2011, IEEE T PATTERN ANAL, V33, P931, DOI 10.1109/TPAMI.2010.158; Samaras D, 1998, PROC CVPR IEEE, P322, DOI 10.1109/CVPR.1998.698626; Samaras D., 2000, P IEEE C COMP VIS PA; Shaji A., 2008, P IEEE CS C COMP VIS; Shen S., 2009, P AS C COMP VIS; Taylor J., 2010, P IEEE C COMP VIS PA; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; TSAI PS, 1994, IMAGE VISION COMPUT, V12, P487, DOI 10.1016/0262-8856(94)90002-7; Urtasun R., 2008, P IEEE C COMP VIS PA; Varol A., 2009, P INT C COMP VIS SEP; Weise T, 2007, P IEEE C COMP VIS PA; White R., 2006, P IEEE CS C COMP VIS; Xiao J, 2004, LECT NOTES COMPUT SC, V2034, P573; Zhang Z., 2004, P IEEE CS C COMP VIS; Zhu JK, 2008, LECT NOTES COMPUT SC, V5304, P766	52	18	19	3	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2012	34	6					1118	1130		10.1109/TPAMI.2011.196	http://dx.doi.org/10.1109/TPAMI.2011.196			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	927OE	22516648	Green Submitted			2022-12-18	WOS:000302916600007
J	Ben-Ezra, M; Lin, ZC; Wilburn, B; Zhang, W				Ben-Ezra, Moshe; Lin, Zhouchen; Wilburn, Bennett; Zhang, Wei			Penrose Pixels for Super-Resolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Super-resolution; Penrose tiling; CMOS sensor; CCD sensor	IMAGE; RECONSTRUCTION; RESOLUTION; LIMITS	We present a novel approach to reconstruction-based super-resolution that uses aperiodic pixel tilings, such as a Penrose tiling or a biological retina, for improved performance. To this aim, we develop a new variant of the well-known error back projection super-resolution algorithm that makes use of the exact detector model in its back projection operator for better accuracy. Pixels in our model can vary in shape and size, and there may be gaps between adjacent pixels. The algorithm applies equally well to periodic or aperiodic pixel tilings. We present analysis and extensive tests using synthetic and real images to show that our approach using aperiodic layouts substantially outperforms existing reconstruction-based algorithms for regular pixel arrays. We close with a discussion of the feasibility of manufacturing CMOS or CCD chips with pixels arranged in Penrose tilings.	[Ben-Ezra, Moshe; Lin, Zhouchen] Microsoft Res Asia, Beijing Sigma Ctr, Beijing 100190, Peoples R China; [Wilburn, Bennett] Refocus Imaging, Vienna, VA 22181 USA; [Zhang, Wei] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China	Microsoft; Microsoft Research Asia; Chinese University of Hong Kong	Ben-Ezra, M (corresponding author), Microsoft Res Asia, Beijing Sigma Ctr, 5F,49 Zhichun Rd, Beijing 100190, Peoples R China.	mosheb@microsoft.com; zhoulin@microsoft.com; bennett@stanfordalumni.org; zw009@ie.cuhk.edu.hk	Zhang, Wayne/GXM-6869-2022; Zhang, Wayne/AAY-7082-2021; Zhang, Wayne/AAF-3407-2019	Zhang, Wayne/0000-0002-8415-1062; Zhang, Wayne/0000-0002-8415-1062; 				Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; BARBE DF, 1980, CHARGE COUPLED DEVIC; Ben-Ezra M, 2005, IEEE T PATTERN ANAL, V27, P977, DOI 10.1109/TPAMI.2005.129; BENEZRA M, 2007, P ICCV, P1; Borman S., 1998, SPATIAL RESOLUTION E; Chen T, 2000, P SOC PHOTO-OPT INS, V3965, P451, DOI 10.1117/12.385463; DALY D, 2001, MICROLENS ARRAYS; Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118; Farsiu S, 2004, INT J IMAG SYST TECH, V14, P47, DOI 10.1002/ima.20007; FERGUS R, 2006, MIT COMPUTER SCI ART, V58, P1; Freeman W. T., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1182, DOI 10.1109/ICCV.1999.790414; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Gr?nbaum B., 1987, TILINGS PATTERNS; Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116; Hardie R, 2007, IEEE T IMAGE PROCESS, V16, P2953, DOI 10.1109/TIP.2007.909416; HORN RA, 1985, MATRIX ANAL, V1, P53401; IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L; LIN C, 2003, J MICROMECH MICROENG, V107, P775; Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081; Middleton L, 2001, IMAGE VISION COMPUT, V19, P1071, DOI 10.1016/S0262-8856(01)00067-1; Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207; Pendry JB, 2000, PHYS REV LETT, V85, P3966, DOI 10.1103/PhysRevLett.85.3966; PICKUP LC, 2007, ADV NEURAL INFORM PR, V19, P1089; Shcherback I, 2003, IEEE T ELECTRON DEV, V50, P12, DOI 10.1109/TED.2002.806966; Sibley T, 2000, AM MATH MON, V107, P251, DOI 10.2307/2589317; *STMICROELECTRONIC, 2009, STMICROELECTRONICS S; Takhar D., 2006, P IS T SPIE COMP IM; Tappen Marshall F, 2003, P 3 INT WORKSH STAT, P1; Zhao WY, 2002, LECT NOTES COMPUT SC, V2350, P599; 2011, HEXAGONAL IMAGE PROC	31	18	25	1	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2011	33	7					1370	1383		10.1109/TPAMI.2010.213	http://dx.doi.org/10.1109/TPAMI.2010.213			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	763QE	21135446				2022-12-18	WOS:000290574000007
J	Cheng, MM; Zhang, GX				Cheng, Ming-Ming; Zhang, Guo-Xin			Connectedness of Random Walk Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image segmentation; random walk; Laplace's equation; counterexample; connectednes		Connectedness of random walk segmentation is examined, and novel properties are discovered, by considering electrical circuits equivalent to random walks. A theoretical analysis shows that earlier conclusions concerning connectedness of random walk segmentation results are incorrect, and counterexamples are demonstrated.	[Cheng, Ming-Ming; Zhang, Guo-Xin] Tsinghua Univ, TNList, Beijing 100084, Peoples R China	Tsinghua University	Cheng, MM (corresponding author), Tsinghua Univ, TNList, FIT Bldg 3-523, Beijing 100084, Peoples R China.	chengmingvictor@gmail.com; zgx.net@gmail.com	Cheng, Ming-Ming/A-2527-2009	Cheng, Ming-Ming/0000-0001-5550-8758	National Basic Research Project of China [2006CB303106]; 863 Program of China [2009AA01Z327]; NSFC [60970100]	National Basic Research Project of China(National Basic Research Program of China); 863 Program of China(National High Technology Research and Development Program of China); NSFC(National Natural Science Foundation of China (NSFC))	This work was supported by the National Basic Research Project of China (NO. 2006CB303106), the 863 Program of China (NO. 2009AA01Z327), and NSFC (NO. 60970100).	Doyle P.G., 1984, CARUS MATH MONOGRAPH, V22, DOI 10.4169/j.ctt5hh804; Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233	2	18	20	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2011	33	1					200	202		10.1109/TPAMI.2010.138	http://dx.doi.org/10.1109/TPAMI.2010.138			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	681AC	20714017				2022-12-18	WOS:000284277600016
J	Ashraf, AB; Lucey, S; Chen, T				Ashraf, Ahmed Bilal; Lucey, Simon; Chen, Tsuhan			Reinterpreting the Application of Gabor Filters as a Manipulation of the Margin in Linear Support Vector Machines	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gabor filters; support vector machine; maximum margin; expression recognition		Linear filters are ubiquitously used as a preprocessing step for many classification tasks in computer vision. In particular, applying Gabor filters followed by a classification stage, such as a support vector machine (SVM), is now common practice in computer vision applications like face identity and expression recognition. A fundamental problem occurs, however, with respect to the high dimensionality of the concatenated Gabor filter responses in terms of memory requirements and computational efficiency during training and testing. In this paper, we demonstrate how the preprocessing step of applying a bank of linear filters can be reinterpreted as manipulating the type of margin being maximized within the linear SVM. This new interpretation leads to sizable memory and computational advantages with respect to existing approaches. The reinterpreted formulation turns out to be independent of the number of filters, thereby allowing the examination of the feature spaces derived from arbitrarily large number of linear filters, a hitherto untestable prospect. Further, this new interpretation of filter banks gives new insights, other than the often cited biological motivations, into why the preprocessing of images with filter banks, like Gabor filters, improves classification performance.	[Ashraf, Ahmed Bilal; Chen, Tsuhan] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA; [Lucey, Simon] CSIRO, Clayton, Vic, Australia	Carnegie Mellon University; Commonwealth Scientific & Industrial Research Organisation (CSIRO)	Ashraf, AB (corresponding author), Carnegie Mellon Univ, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	bilal@cmu.edu; simon.lucey@csiro.au; tsuhan@cmu.edu	Lucey, Simon/B-7556-2011; Lucey, Simon/HDO-1716-2022	Chen, Tsuhan/0000-0003-3951-7931				BARTLETT M, 2006, P 7 IEEE INT C AUT F; Bartlett MS, 2005, PROC CVPR IEEE, P568; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Cohn JF, 1999, PSYCHOPHYSIOLOGY, V36, P35, DOI 10.1017/S0048577299971184; DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; Ekman P., 2002, FACIAL ACTION CODING; Ekman P., 1978, FACIAL ACTION CODING; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; Kanade Takeo, 2000, P 4 IEEE INT C AUT F, P1, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]; Li ZF, 2009, IEEE T PATTERN ANAL, V31, P755, DOI 10.1109/TPAMI.2008.174; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; LUCEY S, 2006, P IEEE INT C COMP VI; Lucey S., 2007, FACE RECOGNITION BOO; Oppenheim A., 1997, SIGNALS SYSTEMS; SHIVASWAMY PK, 2008, P NEUR INF PROC SYST, V21; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235	21	18	22	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2010	32	7					1335	1341		10.1109/TPAMI.2010.75	http://dx.doi.org/10.1109/TPAMI.2010.75			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	595YC	20489236				2022-12-18	WOS:000277649100016
J	Huysmans, T; Sijbers, J; Verdonk, B				Huysmans, Toon; Sijbers, Jan; Verdonk, Brigitte			Automatic Construction of Correspondences for Tubular Surfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Point correspondence problem; statistical shape models; tubular structures; minimum description length; image segmentation; image shape analysis	PARAMETRIZATION; SEGMENTATION	Statistical shape modeling is an established technique and is used for a variety of tasks in medical image processing, such as image segmentation and analysis. A challenging task in the construction of a shape model is establishing a good correspondence across the set of training shapes. Especially for shapes of cylindrical topology, very little work has been done. This paper describes an automatic method to obtain a correspondence for a set of cylindrical shapes. The method starts from an initial correspondence which is provided by cylindrical parameterization. The quality of the obtained correspondence, measured in terms of the description length, is then improved by deforming the parameterizations using cylindrical b-spline deformations and by optimization of the spatial alignment of the shapes. In order to allow efficient gradient-guided optimization, an analytic expression is provided for the gradient of this quality measure with respect to the parameters of the parameterization deformation and the spatial alignment. A comparison is made between models obtained from the correspondences before and after the optimization. The results show that, in comparison with parameterization-based correspondences, this new method establishes correspondences that generate models with significantly increased performance in terms of reconstruction error, generalization ability, and specificity.	[Huysmans, Toon; Sijbers, Jan] Univ Antwerp, Dept Phys, CDE, B-2610 Antwerp, Belgium; [Verdonk, Brigitte] Univ Antwerp, CMI, Dept Math & Comp Sci, B-2020 Antwerp, Belgium	University of Antwerp; University of Antwerp	Huysmans, T (corresponding author), Univ Antwerp, Dept Phys, CDE, Univ Pl 1, B-2610 Antwerp, Belgium.	toon.huysmans@ua.ac.be; jan.sijbers@ua.ac.be; brigitte.verdonk@ua.ac.be	Sijbers, Jan/A-5531-2012; Sijbers, Jan/C-4214-2011; Sijbers, Jan/H-4324-2015	Sijbers, Jan/0000-0003-4225-2487; Sijbers, Jan/0000-0003-4225-2487; Sijbers, Jan/0000-0003-4225-2487; Huysmans, Toon/0000-0001-7053-6458	Institute for the Promotion of Innovation through Science and Technology in Flanders (IWT-Vlaanderen); Fund for Scientific Research (FWO)-Flanders, Belgium	Institute for the Promotion of Innovation through Science and Technology in Flanders (IWT-Vlaanderen)(Institute for the Promotion of Innovation by Science and Technology in Flanders (IWT)); Fund for Scientific Research (FWO)-Flanders, Belgium(FWO)	This work was financially supported by the Institute for the Promotion of Innovation through Science and Technology in Flanders (IWT-Vlaanderen) and the Fund for Scientific Research (FWO)-Flanders, Belgium. The thrombus data sets were kindly provided by Marleen de Bruijne and the Department of Vascular Surgery, University Medical Center Utrecht.	Bartels RH, 1987, INTRO SPLINES USE CO; Bookstein F. L., 1991, MORPHOMETRIC TOOLS L; BRECHBUHLER C, 1995, COMPUT VIS IMAGE UND, V61, P154, DOI 10.1006/cviu.1995.1013; Cates J, 2007, LECT NOTES COMPUT SC, V4584, P333; CATMULL E, 1978, COMPUT AIDED DESIGN, V10, P350, DOI 10.1016/0010-4485(78)90110-0; COOTES TF, 1994, IMAGE VISION COMPUT, V12, P355, DOI 10.1016/0262-8856(94)90060-4; David S, 2002, J SUSTAIN AGR, V21, P5, DOI 10.1300/J064v21n02_03; DAVIES RH, 2002, P EUR C COMP VIS 3, P3; de Bruijne M, 2004, MED IMAGE ANAL, V8, P127, DOI 10.1016/j.media.2004.01.001; de Bruijne M, 2003, LECT NOTES COMPUT SC, V2732, P136; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; Eck M, 1995, P 22 ANN C COMP GRAP, P173, DOI DOI 10.1145/218380.218440; Ericsson A., 2003, P BRIT MACH VIS C NO, V2, P93; Ferrer F, 2007, J HIGH ENERGY PHYS, DOI 10.1088/1126-6708/2007/11/003; Floater MS, 1997, COMPUT AIDED GEOM D, V14, P231, DOI 10.1016/S0167-8396(96)00031-3; Gotsman C, 2003, ACM T GRAPHIC, V22, P358, DOI 10.1145/882262.882276; Gu XF, 2004, IEEE T MED IMAGING, V23, P949, DOI 10.1109/TMI.2004.831226; Haker S, 2000, IEEE T MED IMAGING, V19, P665, DOI 10.1109/42.875181; Heimann T, 2005, LECT NOTES COMPUT SC, V3565, P566; Hong W., 2006, P 2006 ACM S SOL PHY, P85; HORKAEW P, 2003, P INT C INF PROC MED, P13; HORKAEW P, 2004, P 7 INT C MED IM COM, P217; HURDAL MK, 1999, P 2 INT C MED IM COM, P279; HUYSMANS T, 2005, J WSCG, V13, P97; HUYSMANS T, CYLINDRICAL IN PRESS; Huysmans T, 2006, LECT NOTES COMPUT SC, V4091, P84; Jin M, 2008, IEEE T VIS COMPUT GR, V14, P1030, DOI 10.1109/TVCG.2008.57; Jolliffe IT, 2002, ENCY STATIST BEHAV S, DOI [10.1007/0-387-22440-8_13, 10.1007/b98835]; Kelemen A, 1999, IEEE T MED IMAGING, V18, P828, DOI 10.1109/42.811260; Kotcheff A C, 1998, Med Image Anal, V2, P303; Lamecker H., 2002, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2002. 5th International Conference. Proceedings, Part II (Lecture Notes in Computer Science Vol.2489), P421; Lamecker H, 2004, P SOC PHOTO-OPT INS, V5370, P1341, DOI 10.1117/12.534145; Li X, 2008, IEEE T VIS COMPUT GR, V14, P805, DOI 10.1109/TVCG.2008.32; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; LLOYD I, 1997, NUMERICAL LINEAR ALG; LOECKX D, 2006, THESIS KATHOLIEKE U; Papadopoulo T, 2000, LECT NOTES COMPUT SC, V1842, P554; PAULSEN RR, 2002, P 5 INT C MED IM COM; Praun E, 2003, ACM T GRAPHIC, V22, P340, DOI 10.1145/882262.882274; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Styner M, 2005, P NATL ACAD SCI USA, V102, P4872, DOI 10.1073/pnas.0501117102; Styner MA, 2003, LECT NOTES COMPUT SC, V2732, P63; THODBERG HH, 2003, P INT C INF PROC MED; Zachow S, 2005, INT CONGR SER, V1281, P1238, DOI 10.1016/j.ics.2005.03.339	45	18	19	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2010	32	4					636	651		10.1109/TPAMI.2009.93	http://dx.doi.org/10.1109/TPAMI.2009.93			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	555XA	20224120				2022-12-18	WOS:000274548800006
J	Li, LL; Tan, CL				Li, Linlin; Tan, Chew Lim			Recognizing Planar Symbols with Severe Perspective Deformation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Symbol recognition; perspective deformation	RECOGNITION; CURVES; IMAGES	A common problem encountered in recognizing real-scene symbols is the perspective deformation. In this paper, a recognition method resistant to perspective deformation is proposed, based on Cross-Ratio Spectrum descriptor. This method shows good resistance to severe perspective deformation and good discriminating power to similar symbols.	[Li, Linlin; Tan, Chew Lim] Natl Univ Singapore, Sch Comp, Dept Comp Sci, Singapore 117417, Singapore	National University of Singapore	Li, LL (corresponding author), Natl Univ Singapore, Sch Comp, Dept Comp Sci, Comp 1,13 Comp Dr, Singapore 117417, Singapore.	lilinlin@comp.nus.edu.sg; tancl@comp.nus.edu.sg			IDM RD [R252-000-325-279]	IDM RD	This research is supported in part by IDM R&D grant R252-000-325-279. The authors thank Eamonn Keogh for his suggestions on DTW indexing.	Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426; CHEN X, 2004, P IEEE CS C COMP VIS; Clark P., 2002, International Journal on Document Analysis and Recognition, V4, P243, DOI 10.1007/s10032-001-0072-2; delaEscalera A, 1997, IEEE T IND ELECTRON, V44, P848, DOI 10.1109/41.649946; Jelinek D, 2001, IEEE T PATTERN ANAL, V23, P767, DOI 10.1109/34.935850; KEOGH E, 2004, P 8 INT C KNOWL DISC, P102; Li L., 2008, P 19 INT C PATT REC; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu SJ, 2006, INT C PATT RECOG, P1042; Lu SJ, 2005, IMAGE VISION COMPUT, V23, P541, DOI 10.1016/j.imavis.2005.01.003; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mundy J., 1992, GEOMETRIC INVARIANCE; Myers G. K., 2005, International Journal on Document Analysis and Recognition, V7, P147, DOI 10.1007/s10032-004-0133-4; Orrite C, 2004, COMPUT VIS IMAGE UND, V93, P34, DOI 10.1016/j.cviu.2003.09.005; Pilu M, 2001, PROC CVPR IEEE, P363; ROTHWELL CA, 1995, INT J COMPUT VISION, V16, P57, DOI 10.1007/BF01428193; Suk T, 2004, IEEE T PATTERN ANAL, V26, P1364, DOI 10.1109/TPAMI.2004.89; Suk T, 1996, PATTERN RECOGN, V29, P361, DOI 10.1016/0031-3203(94)00094-8; Wang KM, 1997, ANN STAT, V25, P1251; XU D, 2007, J INFORM COMPUTATION, V4; Yamaguchi T., 2005, International Journal on Document Analysis and Recognition, V7, P168, DOI 10.1007/s10032-004-0136-1	22	18	24	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2010	32	4					755	762		10.1109/TPAMI.2009.196	http://dx.doi.org/10.1109/TPAMI.2009.196			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	555XA	20224129				2022-12-18	WOS:000274548800015
J	Ji, SH; Watson, LT; Carin, L				Ji, Shihao; Watson, Layne T.; Carin, Lawrence			Semisupervised Learning of Hidden Markov Models via a Homotopy Method	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semisupervised learning; homotopy method; hidden Markov models (HMMs); supervised learning	ALGORITHM	Hidden Markov model (HMM) classifier design is considered for the analysis of sequential data, incorporating both labeled and unlabeled data for training; the balance between the use of labeled and unlabeled data is controlled by an allocation parameter lambda is an element of [0, 1), where lambda = 0 corresponds to purely supervised HMM learning (based only on the labeled data) and lambda = 1 corresponds to unsupervised HMM-based clustering (based only on the unlabeled data). The associated estimation problem can typically be reduced to solving a set of fixed-point equations in the form of a "natural-parameter homotopy." This paper applies a homotopy method to track a continuous path of solutions, starting from a local supervised solution (lambda = 0) to a local unsupervised solution (lambda = 1). The homotopy method is guaranteed to track with probability one from lambda = 0 to lambda = 1 if the lambda = 0 solution is unique; this condition is not satisfied for the HMM since the maximum likelihood supervised solution (lambda = 0) is characterized by many local optima. A modified form of the homotopy map for HMMs assures a track from lambda = 0 to lambda = 1. Following this track leads to a formulation for selecting lambda is an element of [0, 1) for a semisupervised solution and it also provides a tool for selection from among multiple local-optimal supervised solutions. The results of applying the proposed method to measured and synthetic sequential data verify its robustness and feasibility compared to the conventional EM approach for semisupervised HMM training.	[Ji, Shihao; Carin, Lawrence] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA; [Watson, Layne T.] Virginia Polytech Inst & State Univ, Dept Math & Comp Sci, Blacksburg, VA 24061 USA	Duke University; Virginia Polytechnic Institute & State University	Ji, SH (corresponding author), Duke Univ, Dept Elect & Comp Engn, Box 90291, Durham, NC 27708 USA.	shji@ece.duke.edu; ltw@cs.vt.edu; lcarin@ece.duke.edu		Carin, Lawrence/0000-0001-6277-7948; Ji, Shihao/0000-0002-3573-5379				Allgower E. L., 1990, NUMERICAL CONTINUATI; Bikel DM, 1999, MACH LEARN, V34, P211, DOI 10.1023/A:1007558221122; Birney E, 2001, IBM J RES DEV, V45, P449, DOI 10.1147/rd.453.0449; CHOW SN, 1978, MATH COMPUT, V32, P887, DOI 10.1090/S0025-5718-1978-0492046-9; CORDUNEANU A, 2002, P 18 ANN C UNC ART I; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; COZMAN FG, 2003, P 20 INT C MACH LEAR; CUTTING D, 1992, THIRD CONFERENCE ON APPLIED NATURAL LANGUAGE PROCESSING, P133; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229; Inoue M, 2003, IEEE T PATTERN ANAL, V25, P1570, DOI 10.1109/TPAMI.2003.1251150; Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Runkle PR, 1999, IEEE T SIGNAL PROCES, V47, P2035, DOI 10.1109/78.771050; Seeger M., 2010, LEARNING LABELED UNL; SHAHSHAHANI B, 1994, IEEE T GEOSCIENCE RE, V32; Verdu S., 1984, IEEE Transactions on Information Theory, VIT-30, P328, DOI 10.1109/TIT.1984.1056876; Watson LT, 1997, ACM T MATH SOFTWARE, V23, P514, DOI 10.1145/279232.279235; Zhu X., 2003, INT C MACH LEARN	20	18	18	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2009	31	2					275	287		10.1109/TPAMI.2008.71	http://dx.doi.org/10.1109/TPAMI.2008.71			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	385XL	19110493	Green Submitted			2022-12-18	WOS:000261846800006
J	Steinherz, T; Doermann, D; Rivlin, E; Intrator, N				Steinherz, Tal; Doermann, David; Rivlin, Ehud; Intrator, Nathan			Offline Loop Investigation for Handwriting Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Handwriting analysis; shape; contours	THINNING ALGORITHMS; LINE; RECOGNITION; INFORMATION; RECOVERY; ONLINE; IMAGES	Resolution of different types of loops in handwritten script presents a difficult task and is an important step in many classic word recognition systems, writer modeling, and signature verification. When processing a handwritten script, a great deal of ambiguity occurs when strokes overlap, merge, or intersect. This paper presents a novel loop modeling and contour-based handwriting analysis that improves loop investigation. We show excellent results on various loop resolution scenarios, including axial loop understanding and collapsed loop recovery. We demonstrate our approach for loop investigation on several realistic data sets of static binary images and compare with the ground truth of the genuine online signal.	[Steinherz, Tal; Intrator, Nathan] Tel Aviv Univ, Dept Comp Sci, IL-69978 Ramat Aviv, Israel; [Doermann, David] Univ Maryland, Inst Adv Comp Studies, College Pk, MD 20742 USA; [Rivlin, Ehud] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Tel Aviv University; University System of Maryland; University of Maryland College Park; Technion Israel Institute of Technology	Steinherz, T (corresponding author), Tel Aviv Univ, Dept Comp Sci, IL-69978 Ramat Aviv, Israel.	irital10@yahoo.com; doermann@umiacs.umd.edu; ehudr@cs.technion.ac.il; nin@tau.ac.il						Abuhaiba I. S. I., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P1157, DOI 10.1109/ICDAR.1995.602127; Abuhaiba ISI, 1996, PATTERN RECOGN, V29, P1161, DOI 10.1016/0031-3203(95)00142-5; Ben Amara N.E., 2003, IJDAR, V5, P195; BOCCIGNONE G, 1993, PATTERN RECOGN, V26, P409, DOI 10.1016/0031-3203(93)90168-V; BUNKE H, 1995, PATTERN RECOGN, V28, P1399, DOI 10.1016/0031-3203(95)00013-P; BUNKE H, 1994, INT C PATT RECOG, P383, DOI 10.1109/ICPR.1994.576948; Caesar T., 1993, P 3 INT WORKSH FRONT, P409; Chen SY, 2005, PROC INT CONF DOC, P1280; CHENG TS, 1990, P SPIE CHARACTER REC, P279; Doermann D, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P375, DOI 10.1109/IWFHR.2002.1030939; DOERMANN D, 1993, P INT WORKSH FRONT H, P41; DOERMANN DS, 1995, INT J COMPUT VISION, V15, P143, DOI 10.1007/BF01450853; DOERMANN DS, 1993, THESIS U MARYLAND; Francis B., 2004, EUROPEAN J CRIMINOLO, V1, P47, DOI DOI 10.1177/1477370804038707; Govindaraju V, 1996, PATTERN RECOGN LETT, V17, P537, DOI 10.1016/0167-8655(95)00125-5; GOVINDARAJU V, 1992, P US POSTAL SERVICE, P529; GUYON I, 1994, INT C PATT RECOG, P29, DOI 10.1109/ICPR.1994.576870; Han K, 1996, PATTERN RECOGN LETT, V17, P83, DOI 10.1016/0167-8655(95)00094-1; Hertel C, 2003, LECT NOTES COMPUT SC, V2688, P679; Hochberg J., 1999, International Journal on Document Analysis and Recognition, V2, P45, DOI 10.1007/s100320050036; JAEGER S, 2000, P INT WORKSH FRONT H, P291; JANG BK, 1990, IEEE T PATTERN ANAL, V12, P541, DOI 10.1109/34.56190; Kato Y, 2000, IEEE T PATTERN ANAL, V22, P938, DOI 10.1109/34.877517; LALLICAN PM, 2000, P 7 INT WORKSH FRONT, P303; LAM L, 1995, IEEE T PATTERN ANAL, V17, P914, DOI 10.1109/34.406659; LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346; Madhvanath S, 1999, IEEE T PATTERN ANAL, V21, P928, DOI 10.1109/34.790433; Meulenbroek RGJ, 1998, ACTA PSYCHOL, V100, P55, DOI 10.1016/S0001-6918(98)00025-0; Nalwa VS, 1997, P IEEE, V85, P215, DOI 10.1109/5.554220; Pervouchine V, 2005, PROC INT CONF DOC, P307, DOI 10.1109/ICDAR.2005.241; Pettier J. C., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P850, DOI 10.1109/ICDAR.1993.395604; Plamondon R, 1999, IEEE T IMAGE PROCESS, V8, P80, DOI 10.1109/83.736691; Plamondon R., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P262, DOI 10.1109/ICDAR.1993.395735; Plamondon R., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P1247, DOI 10.1142/S0218001493000613; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; Qiao Y, 2005, PROC INT CONF DOC, P227, DOI 10.1109/ICDAR.2005.25; RUMELHART DE, 1993, COMPUTATIONAL LEARNING & COGNITION, P177; Sabourin R, 1997, PROC INT CONF DOC, P661, DOI 10.1109/ICDAR.1997.620589; SABOURIN R, 1997, P BSDIA 97 CUR BRAZ, P84; Schomaker L., 1999, International Journal on Document Analysis and Recognition, V2, P13, DOI 10.1007/s100320050031; SIMON JC, 1992, P IEEE, V80, P1150, DOI 10.1109/5.156476; SIMON JC, 1991, INT J PATTERN RECOGN, V5, P77; Srihari SN, 2004, FIRST INTERNATIONAL WORKSHOP ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P188, DOI 10.1109/DIAL.2004.1263248; Steinherz T., 1999, International Journal on Document Analysis and Recognition, V2, P90, DOI 10.1007/s100320050040; Steinherz T, 2005, IEEE T PATTERN ANAL, V27, P669, DOI 10.1109/TPAMI.2005.94; STEINHERZ T, 2000, P INT WORKSH FRONT H, P529; Viard-Gaudin C., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P455, DOI 10.1109/ICDAR.1999.791823; Vinciarelli A, 2002, PATTERN RECOGN, V35, P1433, DOI 10.1016/S0031-3203(01)00129-7; VUURPIJL L, 1996, P 5 INT WORKSH FRONT, P29; WALTERS D, 1987, COMPUT VISION GRAPH, V37, P261, DOI 10.1016/S0734-189X(87)80005-1	50	18	18	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2009	31	2					193	209		10.1109/TPAMI.2008.68	http://dx.doi.org/10.1109/TPAMI.2008.68			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	385XL	19110488	Green Submitted, Green Published			2022-12-18	WOS:000261846800001
J	Zeng, J; Liu, ZQ				Zeng, Jia; Liu, Zhi-Qiang			Markov random field-based statistical character structure modeling for handwritten Chinese character recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Markov random fields; handwritten Chinese character recognition; statistical-structural character modeling	FEATURE-EXTRACTION; STROKE EXTRACTION; RELAXATION	This paper proposes a statistical-structural character modeling method based on Markov random fields (MRFs) for handwritten Chinese character recognition (HCCR). The stroke relationships of a Chinese character reflect its structure, which can be statistically represented by the neighborhood system and clique potentials within the MRF framework. Based on the prior knowledge of character structures, we design the neighborhood system that accounts for the most important stroke relationships. We penalize the structurally mismatched stroke relationships with MRFs using the prior clique potentials and derive the likelihood clique potentials from Gaussian mixture models, which encode the large variations of stroke relationships statistically. In the proposed HCCR system, we use the single-site likelihood clique potentials to extract many candidate strokes from character images and use the pair-site clique potentials to determine the best structural match between the input candidate strokes and the MRF-based character models by relaxation labeling. The experiments on the Korea Advanced Institute of Science and Technology (KAIST) character database demonstrate that MRFs can statistically model character structures, and work well in the HCCR system.	[Zeng, Jia] City Univ Hong Kong, Dept Elect Engn, Kowloon, Hong Kong, Peoples R China; [Liu, Zhi-Qiang] City Univ Hong Kong, Sch Creat Media, Kowloon, Hong Kong, Peoples R China	City University of Hong Kong; City University of Hong Kong	Zeng, J (corresponding author), City Univ Hong Kong, Dept Elect Engn, Tat Chee Ave 83, Kowloon, Hong Kong, Peoples R China.	j.zeng@ieee.org; zq.liu@cityu.edu.hk						BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Chang HH, 1999, IEEE T SYST MAN CY B, V29, P47, DOI 10.1109/3477.740165; Chellappa R, 1993, MARKOV RANDOM FIELDS; COWELL RG, 1999, PROBABILISTIC NETWOR; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Grenander U., 2007, PATTERN THEORY REPRE; Hammersley J.M., 1971, MARKOV FIELD FINITE; He XC, 2004, INT C PATT RECOG, P791, DOI 10.1109/ICPR.2004.1334377; HUANG XF, 1993, IEEE T PATTERN ANAL, V15, P838, DOI 10.1109/34.236243; Kang KW, 2004, IEEE T PATTERN ANAL, V26, P1185, DOI 10.1109/TPAMI.2004.74; Kato N, 1999, IEEE T PATTERN ANAL, V21, P258, DOI 10.1109/34.754617; Kim HY, 2001, PATTERN RECOGN, V34, P187, DOI 10.1016/S0031-3203(99)00222-8; Kim IJ, 2003, IEEE T PATTERN ANAL, V25, P1422, DOI 10.1109/TPAMI.2003.1240117; Kim IJ, 2002, PATTERN RECOGN, V35, P2259, DOI 10.1016/S0031-3203(01)00199-6; Li S. Z., 2001, COMP SCI W; Li SZ, 1997, J MATH IMAGING VIS, V7, P149, DOI 10.1023/A:1008253505953; Liu CL, 2004, IEEE T PATTERN ANAL, V26, P198, DOI 10.1109/TPAMI.2004.1262182; Liu CL, 2004, PATTERN RECOGN, V37, P265, DOI 10.1016/S0031-3203(03)00224-3; Liu CL, 2001, PATTERN RECOGN, V34, P601, DOI 10.1016/S0031-3203(00)00018-2; Liu CL, 2001, PATTERN RECOGN, V34, P2339, DOI 10.1016/S0031-3203(00)00165-5; Mumford David, 2002, PROC ICM 2002, VI, P401; Shi D, 2003, IEEE T PATTERN ANAL, V25, P277, DOI 10.1109/TPAMI.2003.1177158; Su YM, 2003, PATTERN RECOGN, V36, P635, DOI 10.1016/S0031-3203(02)00086-9; Tang YY, 1998, IEEE T PATTERN ANAL, V20, P556, DOI 10.1109/34.682186; Vecera SP, 1997, PERCEPT PSYCHOPHYS, V59, P1280, DOI 10.3758/BF03214214; Wang Q, 2000, INT C PATT RECOG, P347, DOI 10.1109/ICPR.2000.906084; Wang XW, 2005, PATTERN RECOGN, V38, P369, DOI 10.1016/j.patcog.2004.08.004; Weber M, 2000, LECT NOTES COMPUT SC, V1842, P18; Wong PK, 1998, IEEE T PATTERN ANAL, V20, P1016, DOI 10.1109/34.713366; Xiong Y, 2001, IEEE T PATTERN ANAL, V23, P774, DOI 10.1109/34.935851; Zeng J, 2005, PROC INT CONF DOC, P101; Zeng J, 2006, INT C PATT RECOG, P868; Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627	34	18	19	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2008	30	5					767	780		10.1109/TPAMI.2007.70734	http://dx.doi.org/10.1109/TPAMI.2007.70734			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	272SI	18369248				2022-12-18	WOS:000253879700002
J	Wang, JB; Athitsos, V; Sclaroff, S; Betke, M				Wang, Jingbin; Athitsos, Vassilis; Sclaroff, Stan; Betke, Margrit			Detecting objects of variable shape structure with hidden state shape models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object detection; shape modeling; probabilistic algorithms; dynamic programming	MARKOV-MODELS; RECOGNITION	This paper proposes a method for detecting object classes that exhibit variable shape structure in heavily cluttered images. The term "variable shape structure" is used to characterize object classes in which some shape parts can be repeated an arbitrary number of times, some parts can be optional, and some parts can have several alternative appearances. Hidden State Shape Models (HSSMs), a generalization of Hidden Markov Models (HMMs), are introduced to model object classes of variable shape structure using a probabilistic framework. A polynomial inference algorithm automatically determines object location, orientation, scale, and structure by finding the globally optimal registration of model states with the image features, even in the presence of clutter. Experiments with real images demonstrate that the proposed method can localize objects of variable shape structure with high accuracy. For the task of hand shape localization and structure identification, the proposed method is significantly more accurate than previously proposed methods based on chamfer-distance matching. Furthermore, by integrating simple temporal constraints, the proposed method gains speed-ups of more than an order of magnitude and produces highly accurate results in experiments on nonrigid hand motion tracking.	[Wang, Jingbin] Google Inc, Mountain View, CA 94043 USA; [Athitsos, Vassilis] Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA; [Sclaroff, Stan; Betke, Margrit] Boston Univ, Dept Comp Sci, Boston, MA 02215 USA	Google Incorporated; University of Texas System; University of Texas Arlington; Boston University	Wang, JB (corresponding author), Google Inc, 1600 Amphitheatre Pkwy,Bldg 43, Mountain View, CA 94043 USA.	jingbinw@cs.bu.edu; athitsos@uta.edu; sclaroff@cs.bu.edu; betke@cs.bu.edu	Athitsos, Vassilis/AAF-8496-2020					AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681; ARICA N, 2000, P I C PATT REC, V1, P1924; ATHITSOS V, 2006, P EUR C COMP VIS, V1, P121; Barrow HG, 1977, P 5 INT JOINT C ART; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bicego M, 2004, IEEE T PATTERN ANAL, V26, P281, DOI 10.1109/TPAMI.2004.1262200; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chen YM, 2002, INT J COMPUT VISION, V50, P315, DOI 10.1023/A:1020878408985; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Coughlan J, 2000, COMPUT VIS IMAGE UND, V78, P303, DOI 10.1006/cviu.2000.0842; COUGHLAN J, 2002, ECCV, V3, P453; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; FELZENSWALB PF, 2003, THESIS MASSACHUSETTS; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Felzenszwalb PF, 2005, IEEE T PATTERN ANAL, V27, P208, DOI 10.1109/TPAMI.2005.35; GALES MJF, 1993, CUEDFINFENGTR133 ENG; GEIGER D, 1995, IEEE T PATTERN ANAL, V17, P294, DOI 10.1109/34.368194; Han F, 2005, IEEE I CONF COMP VIS, P1778; HE Y, 1991, IEEE T PATTERN ANAL, V13, P1172, DOI 10.1109/34.103276; Ioffe S, 2001, INT J COMPUT VISION, V43, P45, DOI 10.1023/A:1011179004708; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LEVENTON ME, 2000, PROC CVPR IEEE, P316, DOI DOI 10.1109/CVPR.2000.855835; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7; MCINERNEY T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P840, DOI 10.1109/ICCV.1995.466850; Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571; Nain D, 2004, LECT NOTES COMPUT SC, V3216, P51; Ostendorf M, 1996, IEEE T SPEECH AUDI P, V4, P360, DOI 10.1109/89.536930; Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068; Prusinkiewicz P, 1990, ALGORITHMIC BEAUTY P; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Sebastian T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P755, DOI 10.1109/ICCV.2001.937602; Sidenbladh H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P709, DOI 10.1109/ICCV.2001.937696; Sigal L, 2004, ADV NEUR IN, V16, P1539; Thayananthan A, 2003, PROC CVPR IEEE, P127; Veltkamp RC, 2001, ADV PTRN RECOGNIT, P87; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang JB, 2006, MED IMAGE ANAL, V10, P530, DOI 10.1016/j.media.2006.05.003; Zhang JY, 2004, PROC CVPR IEEE, P342; Zhu SC, 1996, INT J COMPUT VISION, V20, P187	45	18	19	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2008	30	3					477	492		10.1109/TPAMI.2007.1178	http://dx.doi.org/10.1109/TPAMI.2007.1178			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	250FT	18195441				2022-12-18	WOS:000252286100009
J	Mahajan, D; Ramamoorthi, R; Curless, B				Mahajan, Dhruv; Ramamoorthi, Ravi; Curless, Brian			A theory of frequency domain invariants: Spherical harmonic identities for BRDF/lighting transfer and image consistency	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						frequency domain invariants; spherical harmonic identities; convolution; inverse rendering; relighting; tampering; image forensics	REFLECTANCE; STEREO	This paper develops a theory of frequency domain invariants in computer vision. We derive novel identities using spherical harmonics, which are the angular frequency domain analog to common spatial domain invariants such as reflectance ratios. These invariants are derived from the spherical harmonic convolution framework for reflection from a curved surface. Our identities apply in a number of canonical cases, including single and multiple images of objects under the same and different lighting conditions. One important case we consider is two different glossy objects in two different lighting environments. For this case, we derive a novel identity, independent of the specific lighting configurations or BRDFs, that allows us to directly estimate the fourth image if the other three are available. The identity can also be used as an invariant to detect tampering in the images. Although this paper is primarily theoretical, it has the potential to lay the mathematical foundations for two important practical applications. First, we can develop more general algorithms for inverse rendering problems, which can directly relight and change material properties by transferring the BRDF or lighting from another object or illumination. Second, we can check the consistency of an image to detect tampering or image splicing.	[Mahajan, Dhruv; Ramamoorthi, Ravi] Columbia Univ, Dept Comp Sci, New York, NY 10027 USA; [Curless, Brian] Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA	Columbia University; University of Washington; University of Washington Seattle	Mahajan, D (corresponding author), Columbia Univ, Dept Comp Sci, 450 Comp Sci Bldg,500 W 120 St, New York, NY 10027 USA.	dhruv@cs.columbia.edu; ravir@cs.columbia.edu; curless@cs.washington.edu						Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Basri R., 2001, P C COMP VIS PATT RE; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Davis JE, 2005, IEEE I CONF COMP VIS, P436; Gonzalez R. C., 2003, DIGITAL IMAGE PROCES; Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158; Jin HL, 2003, PROC CVPR IEEE, P171; Johnson M.K., 2005, P ACM MULTIMEDIA SEC, P1, DOI [DOI 10.1145/1073170.1073171, DOI 10.1145/0731701073171]; Lin ZC, 2005, PROC CVPR IEEE, P1087; MAHAJAN D, 2006, P EUR C COMP VIS, V4, P41; MALLICK S, 2006, P EUR C COMP VIS, V1, P550; Marschner SR, 2000, APPL OPTICS, V39, P2592, DOI 10.1364/AO.39.002592; Marschner SR, 1997, FIFTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS, AND APPLICATIONS, P262; Narasimhan SG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1387; Nayar SK, 1996, INT J COMPUT VISION, V17, P219, DOI 10.1007/BF00128232; NG T, 2004, P IEEE INT S CIRC SY; Oh BM, 2001, COMP GRAPH, P433; Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271; Ramantoorthi R, 2002, ACM T GRAPHIC, V21, P517, DOI 10.1145/566570.566611; RUSINKIEWICZ S, 1998, P EUR REND WORKSH; Sato I., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P875, DOI 10.1109/ICCV.1999.790314; Simakov D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1202; Sloan PP, 2002, ACM T GRAPHIC, V21, P527, DOI 10.1145/566570.566612; Wen Z, 2003, PROC CVPR IEEE, P158; Wiener N, 1942, EXTRAPOLATION INTERP; Zhang L, 2005, PROC CVPR IEEE, P209; Zhang L, 2002, J VISUAL COMP ANIMAT, V13, P225, DOI 10.1002/vis.291	28	18	19	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2008	30	2					197	213		10.1109/TPAMI.2007.1162	http://dx.doi.org/10.1109/TPAMI.2007.1162			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	240IC	18084053				2022-12-18	WOS:000251580300001
J	Xu, YL; Roy-Chowdhury, AK				Xu, Yilei; Roy-Chowdhury, Amit K.			Integrating motion, illumination, and structure in video sequences with applications in illumination-invariant tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion; illumination; reflectance; bilinear; 3D structure	FACE RECOGNITION; 3-D MOTION; IMAGE; SHAPE; GEOMETRY	In this paper, we present a theory for combining the effects of motion, illumination, 3D structure, albedo, and camera parameters in a sequence of images obtained by a perspective camera. We show that the set of all Lambertian reflectance functions of a moving object, at any position, illuminated by arbitrarily distant light sources, lies "close" to a bilinear subspace consisting of nine illumination variables and six motion variables. This result implies that, given an arbitrary video sequence, it is possible to recover the 3D structure, motion, and illumination conditions simultaneously using the bilinear subspace formulation. The derivation builds upon existing work on linear subspace representations of reflectance by generalizing it to moving objects. Lighting can change slowly or suddenly, locally or globally, and can originate from a combination of point and extended sources. We experimentally compare the results of our theory with ground truth data and also provide results on real data by using video sequences of a 3D face and the entire human body with various combinations of motion and illumination directions. We also show results of our theory in estimating 3D motion and illumination model parameters from a video sequence.	Univ Calif Riverside, Dept Elect Engn, Riverside, CA 92521 USA	University of California System; University of California Riverside	Xu, YL (corresponding author), Univ Calif Riverside, Dept Elect Engn, Riverside, CA 92521 USA.	yxu@ee.ucr.edu; amitrc@ee.ucr.edu	Xu, Yilei/F-5095-2012	Roy-Chowdhury, Amit/0000-0001-6690-9725				AZARBAYEJANI A, 1995, IEEE T PATTERN ANAL, V17, P562, DOI 10.1109/34.387503; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; BELHUMEUR P, 1996, P IEEE C COMP VIS PA; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; BROIDA TJ, 1990, IEEE T AERO ELEC SYS, V26, P639, DOI 10.1109/7.55557; Chiuso A, 2002, IEEE T PATTERN ANAL, V24, P523, DOI 10.1109/34.993559; DANIILIDIS K, 1990, IMAGE VISION COMPUT, V8, P297, DOI 10.1016/0262-8856(90)80006-F; FAUGERAS O, 2002, 3 DIMENSIONAL COMPUT; FERMULLER C, 2001, FDN IMAGE UNDERSTAND; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; FREEDMAN D, 2005, P C COMP VIS PATT RE; GROSS R, 2002, P GERM S PATT REC SE; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3; JACOBS D, 2005, P INT C COMP VIS; JIN H, 2001, P IEEE INT C COMP VI; Jin HL, 2005, INT J COMPUT VISION, V63, P175, DOI 10.1007/s11263-005-6876-7; LATHAUWER LD, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI DOI 10.1137/S0895479896305696; Lee K., 2003, P IEEE C COMP VIS PA; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Lepetit V., 2005, MONOCULAR MODEL BASE; MATTHEWS I, 2005, P INT C COMP VIS OCT; MOSES Y, 1993, THESIS WEIZMANN I SC; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Oliensis J, 2000, COMPUT VIS IMAGE UND, V80, P172, DOI 10.1006/cviu.2000.0869; OLIENSIS J, 1991, P SPIE C 1570 GEOM M; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P879, DOI 10.1109/34.93807; Qian G, 2001, J OPT SOC AM A, V18, P2982, DOI 10.1364/JOSAA.18.002982; Ramamoorthi R, 2004, ACM T GRAPHIC, V23, P1004, DOI 10.1145/1027411.1027416; RAMAMOORTHI R, 2004, P ACM SIGGRAPH, P475; RAMAMOORTHY R, 2001, J OPTICAL SOC AM A, V18; ROUCHOWDHURY AK, 2000, IEEE T IMAGE PRO AUG, P1057; Roy-Chowdhury AK, 2004, IEEE T IMAGE PROCESS, V13, P960, DOI 10.1109/TIP.2004.827240; ROYCHOWDHURY AK, 2003, INT J COMPUT VISION, V55, P27; Shashua A, 1997, INT J COMPUT VISION, V21, P99, DOI 10.1023/A:1007975506780; Shi J, 1994, P IEEE C COMP VIS PA; SIMAKOV D, 2003, P IEEE INT C COMP VI; Szeliski R., 1994, Journal of Visual Communication and Image Representation, V5, P10, DOI 10.1006/jvci.1994.1002; THORNBER K, 2001, 2001033 NEC; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; TORRESANI L, 2002, P IEEE EUR C COMP VI; VASILESCU M, 2005, P IEEE C COMP VIS PA; XU Y, 2005, P INT C COMP VIS OCT; YOUNG GSJ, 1992, IEEE T PATTERN ANAL, V14, P995, DOI 10.1109/34.159903; Zhang L, 2006, IEEE T PATTERN ANAL, V28, P351, DOI 10.1109/TPAMI.2006.53; ZHANG L, 2003, P 9 IEEE INT C COMP; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561; Zhou SK, 2005, J OPT SOC AM A, V22, P217, DOI 10.1364/JOSAA.22.000217; [No title captured]	52	18	18	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2007	29	5					793	806		10.1109/TPAMI.2007.1047	http://dx.doi.org/10.1109/TPAMI.2007.1047			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	145HK	17356200				2022-12-18	WOS:000244855700004
J	Osadchy, M; Jacobs, DW; Lindenbaum, M				Osadchy, Margarita; Jacobs, David W.; Lindenbaum, Michael			Surface dependent representations for illumination insensitive image comparison	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image comparison; illumination; Gaussian random surface; whitening	FACE RECOGNITION; REFLECTANCE; MODELS	We consider the problem of matching images to tell whether they come from the same scene viewed under different lighting conditions. We show that the surface characteristics determine the type of image comparison method that should be used. Previous work has shown the effectiveness of comparing the image gradient direction for surfaces with material properties that change rapidly in one direction. We show analytically that two other widely used methods, normalized correlation of small windows and comparison of multiscale oriented filters, essentially compute the same thing. Then, we show that for surfaces whose properties change more slowly, comparison of the output of whitening filters is most effective. This suggests that a combination of these strategies should be employed to compare general objects. We discuss indications that Gabor jets use such a mixed strategy effectively, and we propose a new mixed strategy. We validate our results on synthetic and real images.	Univ Haifa, Dept Comp Sci, IL-31905 Haifa, Israel; Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA; Univ Maryland, UMIACS, College Pk, MD 20742 USA; Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	University of Haifa; University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park; Technion Israel Institute of Technology	Osadchy, M (corresponding author), Univ Haifa, Dept Comp Sci, Mt Carmel, IL-31905 Haifa, Israel.	rita@cs.haifa.ac.il; djacobs@cs.umd.edu; mic@cs.technion.ac.il						Adler R. J., 1981, GEOMETRY RANDOM FIEL; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; BICHSEL M, 1991, THESIS ETH ZURICH; Bregler C, 1997, ADV NEUR IN, V9, P845; BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061; BRUNELLI R, 1994, 1499 MIT AI; Chen HF, 2000, PROC CVPR IEEE, P254, DOI 10.1109/CVPR.2000.855827; Cootes TF, 2001, PROC CVPR IEEE, P1114; Duda R.O., 2001, PATTERN CLASSIFICATI; FELZENSZWALB P, IN PRESS PICTORIAL S; FITCH AJ, 2002, P BMVC, V1, P133; Forsyth David A, 2012, COMPUTER VISION MODE; Freer S, 1998, PUBLIC MONEY MANAGE, V18, P3, DOI 10.1111/1467-9302.00130; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Gevers T, 2001, PROC CVPR IEEE, P18; Gonzalez R C, 1992, DIGITAL IMAGE PROCES; GREENSPAN H, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P222, DOI 10.1109/CVPR.1994.323833; Gross R, 2003, LECT NOTES COMPUT SC, V2688, P10; Haralick RM., 1992, COMPUTER ROBOT VISIO; Hond D., 1997, BMVC, P0; Jahne B, 1995, DIGITAL IMAGE PROCES, V3; Jain A. K., 1989, FUNDAMENTALS DIGITAL; JIAO F, 2003, P C COMP VIS PATT RE; Keren D, 2001, IEEE T PATTERN ANAL, V23, P747, DOI 10.1109/34.935848; KITTLER J, 2000, P BRIT MACH VIS C 20, V1, P42; Koenderink JJ, 2003, J OPT SOC AM A, V20, P1875, DOI 10.1364/JOSAA.20.001875; KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; Narasimhan SG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1387; Nayar SK, 1996, INT J COMPUT VISION, V17, P219, DOI 10.1007/BF00128232; Oren M, 1997, INT J COMPUT VISION, V24, P105, DOI 10.1023/A:1007954719939; Osadchy M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1512; Osadchy M, 2005, IEEE I CONF COMP VIS, P1721; OSADCHY M, 2004, P EUR C COMP VIS, P217; Papoulis A, 1991, PROBABILITY RANDOM V, V3rd; Phillips PJ, 1996, PATTERN RECOGN LETT, V17, P921, DOI 10.1016/0167-8655(96)00046-3; Pratt W. K., 1978, DIGITAL IMAGE PROCES; RAO RPN, 1995, ARTIF INTELL, V78, P461, DOI 10.1016/0004-3702(95)00026-7; RAVELA S, 2000, ADV INFORM RETRIEVAL; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964; Shashua A, 1997, INT J COMPUT VISION, V21, P99, DOI 10.1023/A:1007975506780; Slater D, 1996, IEEE T PATTERN ANAL, V18, P206, DOI 10.1109/34.481544; Trucco E., 1998, INTRO TECHNIQUES 3D; VANTREES HL, 1965, DETECTION ESTIMTIO 1; Varma M, 2004, PROC CVPR IEEE, P179; Wiskott L, 1999, INT SER COMPUTAT INT, P355; WISKOTT L, 1995, THESIS; WOLFF LB, 1994, J OPT SOC AM A, V11, P3090, DOI 10.1364/JOSAA.11.003090	51	18	18	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2007	29	1					98	111		10.1109/TPAMI.2007.250602	http://dx.doi.org/10.1109/TPAMI.2007.250602			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	104VI	17108386	Green Submitted			2022-12-18	WOS:000241988300008
J	Kim, YH; Kak, AC				Kim, Yeon-Ho; Kak, Avinash C.			Error analysis of robust optical flow estimation by least median of squares methods for the varying illumination model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						optical flow; robust estimation; varying illumination; least median of squares method; error analysis	COMPUTATION; REGRESSION; ALGORITHM	The apparent pixel motion in an image sequence, called optical flow, is a useful primitive for automatic scene analysis and various other applications of computer vision. In general, however, the optical flow estimation suffers from two significant problems: the problem of illumination that varies with time and the problem of motion discontinuities induced by objects moving with respect to either other objects or with respect to the background. Various integrated approaches for solving these two problems simultaneously have been proposed. Of these, those that are based on the LMedS (Least Median of Squares) appear to be the most robust. The goal of this paper is to carry out an error analysis of two different LMedS-based approaches, one based on the standard LMedS regression and the other using a modification thereof as proposed by us recently. While it is to be expected that the estimation accuracy of any approach would decrease with increasing levels of noise, for LMedS-like methods, it is not always clear as to how much of that decrease in performance can be attributed to the fact that only a small number of randomly selected samples is used for forming temporary solutions. To answer this question, our study here includes a baseline implementation in which all of the image data is used for forming motion estimates. We then compare the estimation errors of the two LMedS-based methods with the baseline implementation. Our error analysis demonstrates that, for the case of Gaussian noise, our modified LMedS approach yields better estimates at moderate levels of noise, but is outperformed by the standard LMedS method as the level of noise increases. For the case of salt-and-pepper noise, the modified LMedS method consistently performs better than the standard LMedS method.	Purdue Univ, Sch Elect & Comp Engn, Robot Vis Lab, W Lafayette, IN 47907 USA	Purdue University System; Purdue University; Purdue University West Lafayette Campus	Kim, YH (corresponding author), Purdue Univ, Sch Elect & Comp Engn, Robot Vis Lab, W Lafayette, IN 47907 USA.	yeonho@ecn.purdue.edu; kak@ecn.purdue.edu						AYER S, 1995, P INT C COMP VIS BOS, P583; Bab-Hadiashar A, 1998, INT J COMPUT VISION, V29, P59, DOI 10.1023/A:1008090730467; BARRON JL, 1994, INT J COMPUTER VISIO; Black MJ, 1993, P 4 INT C COMP VIS, P231, DOI DOI 10.1109/ICCV.1993.378214; BLACK MJ, 2000, COMPUTER VISION IMAG, V78; Cornelius N., 1983, P ACM SIGGRAPH SIGAR; GENNERT MA, 1987, 975 MIT; HARALICK RM, 1994, CVGIP-IMAG UNDERSTAN, V60, P245, DOI 10.1006/cviu.1994.1055; Haussecker HW, 2001, IEEE T PATTERN ANAL, V23, P661, DOI 10.1109/34.927465; HOLLAND PW, 1977, COMMUN STAT A-THEOR, V6, P813, DOI 10.1080/03610927708827533; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188; Kim Y. H., 2004, P BRIT MACH VIS C; Kim YH, 2005, IMAGE VISION COMPUT, V23, P365, DOI 10.1016/j.imavis.2004.05.010; LAI SH, 1999, P C COMP VIS PATT RE; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; McCane B, 2001, COMPUT VIS IMAGE UND, V84, P126, DOI 10.1006/cviu.2001.0930; Mukawa N, 1997, COMPUT VIS IMAGE UND, V66, P25, DOI 10.1006/cviu.1996.0500; MUKAWA N, 1989, P INT C IM PROC ICIP; NAGEL HH, 1987, ARTIF INTELL, V33, P299, DOI 10.1016/0004-3702(87)90041-5; Negahdaripour S, 1998, IEEE T PATTERN ANAL, V20, P961, DOI 10.1109/34.713362; NEGAHDARIPOUR S, 1993, P INT C COMP VIS; NESI P, 1995, COMPUT VIS IMAGE UND, V62, P59, DOI 10.1006/cviu.1995.1041; ODOBEZ JM, 1995, VISUAL COMMUN IM DEC, P348; Ong EP, 1999, INT J COMPUT VISION, V31, P51, DOI 10.1023/A:1008046826441; OTTE M, 1994, P 3 EUR C COMP VIS S, P51; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; SCHUNCK B, 1989, IEEE T PATTERN ANAL, V11; SCHUNCK BG, 1985, P C COMP VIS PATT RE; SHULMAN D, 1989, P IEEE WORKSH VIS MO; Stumpf P, 1911, Z PSYCHOL PHYSIOL SI, V59, P321; URAS S, 1988, BIOL CYBERN, V60, P79, DOI 10.1007/BF00202895	32	18	21	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2006	28	9					1418	1435		10.1109/TPAMI.2006.185	http://dx.doi.org/10.1109/TPAMI.2006.185			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	062NC	16929729	Green Submitted			2022-12-18	WOS:000238950800006
J	Bouchard, G; Celeux, G				Bouchard, G; Celeux, G			Selection of generative models in classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						generative classification; integrated likelihood; integrated conditional likelihood; classification entropy; cross-validated error rate; AIC and BIC criteria	DISCRIMINANT-ANALYSIS	This paper is concerned with the selection of a generative model for supervised classification. Classical criteria for model selection assess the fit of a model rather than its ability to produce a low classification error rate. A new criterion, the Bayesian Entropy Criterion (BEC), is proposed. This criterion takes into account the decisional purpose of a model by minimizing the integrated classification entropy. It provides an interesting alternative to the cross-validated error rate which is computationally expensive. The asymptotic behavior of the BEC criterion is presented. Numerical experiments on both simulated and real data sets show that BEC performs better than the BIC criterion to select a model minimizing the classification error rate and provides analogous performance to the cross-validated error rate.	Xerox Res Ctr Europe, F-38240 Meylan, France; Univ Paris 11, Dept Math, F-91405 Orsay, France	Xerox; UDICE-French Research Universities; Universite Paris Saclay	Bouchard, G (corresponding author), Xerox Res Ctr Europe, 6 Ch de Maupertuis, F-38240 Meylan, France.	Guillaume.Bouchard@xrce.xerox.com						AGARWAL S, 2002, P ECCV, P113; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Bensmail H, 1996, J AM STAT ASSOC, V91, P1743, DOI 10.2307/2291604; Bernardo J. M., 1994, BAYESIAN THEORY; Biernacki C, 2000, IEEE T PATTERN ANAL, V22, P719, DOI 10.1109/34.865189; Blei DM, 2002, ADV NEUR IN, V14, P601; BOUCHARD G, 2003, P CLASS DAT AN GROUP, P75; BOUCHARD G, 2005, P INT C COMP VIS PAT; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; Dorko G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P634; Fergus R, 2003, PROC CVPR IEEE, P264; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; GEISSER S, 1974, J AM STAT ASSOC, V74, P153; GOODMAN GL, 1999, P C INF DEC CONTR 99, P585; Greiner K, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P167; Gross D, 2004, PHYS WORLD, V17, P21; Hastie T, 1996, J ROY STAT SOC B MET, V58, P155; Hoeting JA, 1999, STAT SCI, V14, P382, DOI 10.1214/ss/1009212519; JEBARA T, 2001, THESIS MIT; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572; KONTKANEN P, 2001, P 17 C UNC ART INT S, P277; LAFFERTY J, 2001, P 18 INT C MACH LEAR, P96; LAUD PW, 1995, J ROY STAT SOC B MET, V57, P247; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mclachlan G., 2000, WILEY SER PROB STAT; Mclachlan GJ., 2005, DISCRIMINANT ANAL ST; Opelt A, 2004, LECT NOTES COMPUT SC, V3022, P71; Raftery AE, 1995, SOCIOL METHODOL, V25, P111, DOI 10.2307/271063; REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034; Ripley BD., 1996; Roeder K, 1997, J AM STAT ASSOC, V92, P894, DOI 10.2307/2965553; SCHULKOPF B, 2002, LEARNING KERNELS; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; YANAZAKI S, 2003, INT J NEURAL NETWORK, V16, P1029	37	18	18	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2006	28	4					544	554		10.1109/TPAMI.2006.82	http://dx.doi.org/10.1109/TPAMI.2006.82			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	011FK	16566504				2022-12-18	WOS:000235253300005
J	Perronnin, F; Dugelay, JL; Rose, K				Perronnin, F; Dugelay, JL; Rose, K			A probabilistic model of face mapping with local transformations and its application to person recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						biometrics; face recognition; image processing; hidden Markov model; distance	CLASSIFICATION; SUBSPACES	This paper proposes a new measure of " distance" between faces. This measure involves the estimation of the set of possible transformations between face images of the same person. The global transformation, which is assumed to be too complex for direct modeling, is approximated by a patchwork of local transformations, under a constraint imposing consistency between neighboring local transformations. The proposed system of local transformations and neighboring constraints is embedded within the probabilistic framework of a two- dimensional hidden Markov model. More specifically, we model two types of intraclass variabilities involving variations in facial expressions and illumination, respectively. The performance of the resulting method is assessed on a large data set consisting of four face databases. In particular, it is shown to outperform a leading approach to face recognition, namely, the Bayesian intra/ extrapersonal classifier.	Xerox Res Ctr Europe, Image Proc Grp, F-38240 Meylan, France; Inst Eurocom, Multimedia Commun Dept, F-06904 Sophia Antipolis, France; Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA	Xerox; University of California System; University of California Santa Barbara	Perronnin, F (corresponding author), Xerox Res Ctr Europe, Image Proc Grp, 6 Chemin Maupertuis, F-38240 Meylan, France.	Florent.Perronnin@xrce.xerox.com; jean-luc.dugelay@eurecom.fr; rose@ece.ucsb.edu	DUGELAY, Jean-Luc/ABE-7096-2021	DUGELAY, jean-luc/0000-0003-3151-4330				ABEND K, 1965, IEEE T INFORM THEORY, V11, P538, DOI 10.1109/TIT.1965.1053827; ACERO A, 1996, P IEEE INT C AC SPEE, V1, P342; Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229; Anastasakos T, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1137, DOI 10.1109/ICSLP.1996.607807; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Beveridge JR, 2001, PROC CVPR IEEE, P535; Beveridge R., 2003, CSU FACE IDENTIFICAT; Blackburn DM, 2001, FACE RECOGNITION VEN; BOCCHIERI E, 2000, P INT C SPOK LANG PR, V4, P179; Cardinaux F, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P825, DOI 10.1109/AFGR.2004.1301636; CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905; Droppo J, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P953; Duc B, 1999, IEEE T IMAGE PROCESS, V8, P504, DOI 10.1109/83.753738; Duda R.O., 2000, PATTERN CLASSIFICATI; Eickeler S, 2000, IMAGE VISION COMPUT, V18, P279, DOI 10.1016/S0262-8856(99)00055-4; ETEMAD K, 1996, P IEEE INT C AC SPEE, V4, P2148; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; GROSS R, 2001, P WORKSH EMP EV METH; Grudin MA, 2000, PATTERN RECOGN, V33, P1161, DOI 10.1016/S0031-3203(99)00104-1; HALLOULI K, 2002, P IEEE INT C PATT RE, V3, P147; Horn B., 1986, ROBOT VISION, P1; JAIN AK, 2004, IEEE T CIRCUITS SYST, V14; KAILATH AHS, 2000, LINEAR ESTIMATION; Kaufman L., 2009, FINDING GROUPS DATA; KUO SS, 1994, IEEE T PATTERN ANAL, V16, P842, DOI 10.1109/34.308482; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; Li J, 2000, IEEE T SIGNAL PROCES, V48, P517, DOI 10.1109/78.823977; LI SZ, 1994, P IEEE EUR C COMP VI, VB, P361; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Martinez A., 1998, 24 CVC, P24; MILLER C, 1997, P IEEE INT C IM PROC, V1, P181; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P780, DOI 10.1109/TPAMI.2002.1008384; Moghaddam B, 2001, IMAGE VISION COMPUT, V19, P235, DOI 10.1016/S0262-8856(00)00059-7; Moghaddam B, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P30, DOI 10.1109/AFGR.1998.670921; NEFIAN A, 1999, THESIS GEORGIA I TEC; Perronnin F, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P329; PERRONNIN F, 2004, P IEEE INT C AC SPEE; PHILLIPS P, 2003, DACE RECOGNITION VEN; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Prabhakar S., 2003, HDB FINGERPRINT RECO; PRABHAKAR S, 2001, THESIS MICHIGAN STAT; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; SAMARIA FS, 1994, THESIS U CAMBRIDGE C; Savvides M, 2003, LECT NOTES COMPUT SC, V2688, P549; SIM T, 2002, P IEEE INT C AUT FAC; SINGH R, 2003, P ICASSP, V1, P396; Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802; TEIXEIRA M, 2003, IMPLEMENTATION STUDY; TURK M, 1991, P IEEE C COMP VIS PA, P586, DOI DOI 10.1109/CVPR.1991.139758; VISSAC M, 1999, P IEEE WORKSH MULT S, P97; Wang XG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P679, DOI 10.1109/ICCV.2003.1238413; WENG JJ, 1999, BIOMETRICS PERSONAL; ZHAO W, 1999, THESIS U MARYLAND DE; 2004, HIDDEN MARKOV MODEL	57	18	19	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2005	27	7					1157	1171		10.1109/TPAMI.2005.130	http://dx.doi.org/10.1109/TPAMI.2005.130			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	925AQ	16013761				2022-12-18	WOS:000229024300013
J	Kang, KW; Kim, JH				Kang, KW; Kim, JH			Utilization of hierarchical, stochastic relationship modeling for Hangul character recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; handwritten character recognition; stochastic relationship modeling; hierarchical character representation; Hangul character recognition	HANDWRITTEN CHARACTERS; GRAPH REPRESENTATION; CHINESE CHARACTERS	In structural character recognition, a character is usually viewed as a set of strokes and the spatial relationships between them. Therefore, strokes and their relationships should be properly modeled for effective character representation. For this purpose, we propose a modeling scheme by which strokes as well as relationships are stochastically represented by utilizing the hierarchical characteristics of target characters. A character is defined by a multivariate random variable over the components and its probability distribution is learned from a training data set. To overcome difficulties of the learning due to the high order of the probability distribution (a problem of curse of dimensionality), the probability distribution is factorized and approximated by a set of lower-order probability distributions by applying the idea of relationship decomposition recursively to components and subcomponents. Based on the proposed method, a handwritten Hangul (Korean) character recognition system is developed. Recognition experiments conducted on a public database show the effectiveness of the proposed relationship modeling. The recognition accuracy increased by 5.5 percent in comparison to the most successful system ever reported.	Korea Adv Inst Sci & Technol, Dept Comp Sci, Taejon 305701, South Korea	Korea Advanced Institute of Science & Technology (KAIST)	Kang, KW (corresponding author), Korea Adv Inst Sci & Technol, Dept Comp Sci, 373-1 Gusong Dong, Taejon 305701, South Korea.	kwkang@ai.kaist.ac.kr; jkim@cs.kaist.ac.kr	Kim, Jin Hyung/C-1923-2011					CHEN LH, 1990, PATTERN RECOGN, V23, P1189, DOI 10.1016/0031-3203(90)90115-2; Cheng FH, 1998, PATTERN RECOGN, V31, P401, DOI 10.1016/S0031-3203(97)00053-8; Cho SJ, 2001, PROC INT CONF DOC, P86, DOI 10.1109/ICDAR.2001.953760; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; Favata JT, 1996, INT J IMAG SYST TECH, V7, P304, DOI 10.1002/(SICI)1098-1098(199624)7:4<304::AID-IMA5>3.0.CO;2-C; Foggia P, 1999, IMAGE VISION COMPUT, V17, P701, DOI 10.1016/S0262-8856(98)00146-2; FU KS, 1986, IEEE T PATTERN ANAL, V8, P313, DOI 10.1109/TPAMI.1986.4767794; Kang HJ, 1997, ENG APPL ARTIF INTEL, V10, P379, DOI 10.1016/S0952-1976(97)00020-1; KANG KW, 1998, P 3 IAPR WORKSH DOC, P326; KIM DI, 1998, P 6 INT WORKSH FRONT, P455; Kim HY, 2001, PATTERN RECOGN, V34, P187, DOI 10.1016/S0031-3203(99)00222-8; KIM LJ, 2000, P 4 INT WORKSH DOC A, P303; KIM SH, 1998, INT J COMPUTER PROCE, V12, P207; Krause PJ, 1998, KNOWL ENG REV, V13, P321, DOI 10.1017/S0269888998004019; LEE HJ, 1992, PATTERN RECOGN, V25, P543, DOI 10.1016/0031-3203(92)90052-K; Liu CL, 2001, PATTERN RECOGN, V34, P2339, DOI 10.1016/S0031-3203(00)00165-5; LU SW, 1991, PATTERN RECOGN, V24, P617, DOI 10.1016/0031-3203(91)90029-5; Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975; MURPHY KP, 1998, CSD98990 U CAL; Nishida H, 1996, COMPUT VIS IMAGE UND, V64, P248, DOI 10.1006/cviu.1996.0057; Park HS, 1996, PATTERN RECOGN, V29, P231, DOI 10.1016/0031-3203(95)00081-X; Park J, 2000, IEEE T PATTERN ANAL, V22, P400, DOI 10.1109/34.845383; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; TSAI WH, 1980, IEEE T SYST MAN CYB, V10, P873, DOI 10.1109/TSMC.1980.4308414; Wang Q, 2000, INT C PATT RECOG, P347, DOI 10.1109/ICPR.2000.906084; Zhang XH, 1983, PATTERN RECOGN LETT, V1, P259, DOI 10.1016/0167-8655(83)90035-1	28	18	23	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2004	26	9					1185	1196		10.1109/TPAMI.2004.74	http://dx.doi.org/10.1109/TPAMI.2004.74			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	837CM	15742893				2022-12-18	WOS:000222605100007
J	Hsu, RL; Jain, AK				Hsu, RL; Jain, AK			Generating discriminating cartoon faces using interacting snakes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	3rd International Workshop on Energy Minimization Methods in Computer Vision and Pattern Recognition	SEP 03-05, 2001	SOPHIA ANTIPOLIS, FRANCE	INRIA, Int Assoc Pattern Recognit, Conseil Gen Alpes Maritimes		active contours; snakes; gradient vector field; face recognition; semantic face graph; face modeling; face alignment; cartoon faces; caricatures	FACIAL IMAGE; RECOGNITION; REGION; CARICATURE	As a computational bridge between the high-level a priori knowledge of object shape and the low-level image data, active contours (or snakes) are useful models for the extraction of deformable objects. We propose an approach for manipulating multiple snakes iteratively, called interacting snakes, that minimizes the attraction energy functionals on both contours and enclosed regions of individual snakes and the repulsion energy functionals among multiple snakes that interact with each other. We implement the interacting snakes through explicit curve (parametric active contours) representation in the domain of face recognition. We represent human faces semantically via facial components such as eyes, mouth, face outline, and the hair outline. Each facial component is encoded by a closed (or open) snake that is drawn from a 3D generic face model. A collection of semantic facial components form a hypergraph, called semantic face graph, which employs interacting snakes to align the general facial topology onto the sensed face images. Experimental results show that a successful interaction among multiple snakes associated with facial components makes the semantic face graph a useful model for face representation, including cartoon faces and caricatures, and recognition.	Identix Inc, Res Grp, Jersey City, NJ 07302 USA; Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Michigan State University	Hsu, RL (corresponding author), Identix Inc, Res Grp, Jersey City, NJ 07302 USA.	Vincent.Hsu@identix.com; jain@cse.nisu.edu						Abe T, 2000, INT C PATT RECOG, P626, DOI 10.1109/ICPR.2000.905416; AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681; BRENNAN SE, 1985, LEONARDO, V18, P170, DOI 10.2307/1578048; Chalana V, 1996, IEEE T MED IMAGING, V15, P290, DOI 10.1109/42.500138; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Chesnaud C, 1999, IEEE T PATTERN ANAL, V21, P1145, DOI 10.1109/34.809108; Cox IJ, 1996, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.1996.517076; Goldenberg R, 2001, IEEE T IMAGE PROCESS, V10, P1467, DOI 10.1109/83.951533; Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242; HSU RL, 2001, IEEE INT C IMAGE PRO, V2, P693; IVINS J, 1994, P 5 BRIT MACH VIS C, V2, P377; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; MAURO R, 1992, MEM COGNITION, V20, P433, DOI 10.3758/BF03210927; Olstad B, 1996, IEEE T PATTERN ANAL, V18, P863, DOI 10.1109/34.537341; Pardo XM, 2001, IMAGE VISION COMPUT, V19, P461, DOI 10.1016/S0262-8856(00)00092-5; Penev PS, 1996, NETWORK-COMP NEURAL, V7, P477, DOI 10.1088/0954-898X/7/3/002; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; RHODES G, 1994, VIS COGN, V1, P257; TERZOPOULOS D, 1993, IEEE T PATTERN ANAL, V15, P569, DOI 10.1109/34.216726; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Uhl RG, 1996, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.1996.517132; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; ZHAO W, 2003, FACE RECOGNITION LIT; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	26	18	19	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2003	25	11					1388	1398		10.1109/TPAMI.2003.1240113	http://dx.doi.org/10.1109/TPAMI.2003.1240113			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	733NG					2022-12-18	WOS:000186006800004
J	Nicolescu, M; Medioni, G				Nicolescu, M; Medioni, G			Layered 4D representation and voting for grouping from motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion analysis; perceptual grouping; tensor voting	ALGORITHM; SMOOTHNESS; IMAGES; FIELDS	We address the problem of perceptual grouping from motion cues by formulating it as a motion layers inference from a sparse and noisy point set in a 4D space. Our approach is based on a layered 4D representation of data, and a voting scheme for token communication, within a tensor voting computational framework. Given two sparse sets of point tokens, the image position and potential velocity of each token are encoded into a 4D tensor. By enforcing the smoothness of motion through a voting process, the correct velocity is selected for each input point as the most salient token. An additional dense voting step allows for the inference of a dense representation in terms of pixel velocities, motion regions, and boundaries. Using a 4D space for this tensor voting approach is essential since it allows for a spatial separation of the points according to both their velocities and image coordinates. Unlike most other methods that optimize certain objective functions, our approach is noniterative and, therefore, does not suffer from local optima or poor convergence problems. We demonstrate our method with synthetic and real images, by analyzing several difficult cases-opaque and transparent motion, rigid and nonrigid motion, curves and surfaces in motion.	Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA; Univ So Calif, Integrated Media Syst Ctr, Los Angeles, CA 90089 USA	University of Southern California; University of Southern California	Nicolescu, M (corresponding author), Univ So Calif, Inst Robot & Intelligent Syst, Powell Hall 204,3737 Watt Way, Los Angeles, CA 90089 USA.	mnicoles@iris.usc.edu; medioni@iris.usc.edu						ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; AYER S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P777, DOI 10.1109/ICCV.1995.466859; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BERGEN JR, 1992, IEEE T PATTERN ANAL, V14, P886, DOI 10.1109/34.161348; Boykov Y, 1998, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.1998.698673; Darrell T., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P173, DOI 10.1109/WVM.1991.212810; DERICHE R, 1995, P 2 AS C COMP VIS AC, V2, P290; Fleet DJ, 1998, PROC CVPR IEEE, P274, DOI 10.1109/CVPR.1998.698620; Gaucher L., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P695, DOI 10.1109/ICCV.1999.790289; Gelgon M, 1997, PROC CVPR IEEE, P514, DOI 10.1109/CVPR.1997.609374; Ghosal S, 1996, IEEE T PATTERN ANAL, V18, P181, DOI 10.1109/34.481542; Guy G, 1997, IEEE T PATTERN ANAL, V19, P1265, DOI 10.1109/34.632985; HEEGER DJ, 1987, INT J COMPUT VISION, V1, P279, DOI 10.1007/BF00133568; HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HSU S, 1994, INT C PATT RECOG, P743, DOI 10.1109/ICPR.1994.576427; Irani M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P216, DOI 10.1109/CVPR.1992.223272; Jepson A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P760, DOI 10.1109/CVPR.1993.341161; KERVRANN C, 1995, IEEE T IMAGE PROCESS, V4, P856, DOI 10.1109/83.388090; Little J., 1988, P ICCV 88, P454; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; McLachlan G.J., 1988, MIXTURE MODELS INFER, V38; Medioni G., 2000, COMPUTATIONAL FRAMEW; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; Shi JB, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1154, DOI 10.1109/ICCV.1998.710861; SIMONCELLI EP, 1991, IEEE C COMP VIS PATT, P310, DOI 10.1109/CVPR.1991.139707; SINGH A, 1992, OPTICAL FLOW COMPUTA; Szeliski R, 2000, PROC CVPR IEEE, P246, DOI 10.1109/CVPR.2000.855826; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Weiss Y, 1997, PROC CVPR IEEE, P520, DOI 10.1109/CVPR.1997.609375; Wu YT, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P992, DOI 10.1109/ICCV.1998.710837	34	18	18	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2003	25	4					492	501		10.1109/TPAMI.2003.1190574	http://dx.doi.org/10.1109/TPAMI.2003.1190574			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	659BV					2022-12-18	WOS:000181758100009
J	Rueda, L; Oommen, BJ				Rueda, L; Oommen, BJ			On optimal pairwise linear classifiers for normal distributions: The two-dimensional case	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern classification; statistical pattern recognition; optimal Bayesian classification; linear classifiers	STATISTICAL CLASSIFIERS; DISCRIMINANT-ANALYSIS; SINGLE NEURON; SAMPLE-SIZE; EVOLUTION	Optimal Bayesian linear classifiers have been studied in the literature for many decades. In this paper, we demonstrate that all the known results consider only the scenario when the quadratic polynomial has coincident roots. Indeed, we present a complete analysis of the case when the optimal classifier between two normally distributed classes is pairwise and linear. To the best of our knowledge, this is a pioneering work for the use of such classifiers in any area of statistical Pattern Recognition (PR). We shall focus on some special cases of the normal distribution with nonequal covariance matrices. We determine the conditions that the mean vectors and covariance matrices have to satisfy in order to obtain the optimal pairwise linear classifier. As opposed to the state of the art, in all the cases discussed here, the linear classifier is given by a pair of straight lines, which is a particular case of the general equation of second degree. One of these cases is when we have two overlapping classes with equal means, which resolves the general case of the Minsky's paradox for the perceptron, We have also provided some empirical results, using synthetic data for the Minsky's paradox case, and demonstrated that the linear classifier achieves very good performance. Finally, we have tested our approach on real life data obtained from the UCI machine learning repository. The empirical results that we obtained show the superiority of our scheme over the traditional Fisher's discriminant classifier.	Carleton Univ, Sch Comp Sci, Ottawa, ON K1S 5B6, Canada	Carleton University	Rueda, L (corresponding author), Carleton Univ, Sch Comp Sci, 1125 Colonel By Dr, Ottawa, ON K1S 5B6, Canada.		Oommen, B. John/P-6323-2017	Oommen, B. John/0000-0002-5105-1575				Aladjem M, 1997, IEEE T PATTERN ANAL, V19, P187, DOI 10.1109/34.574805; BROWN J, 1950, ELEMENTS ANAL GEOMET; DEEBA E, 1997, INTERACTIVE LINEAR A; Duda R.O., 2000, PATTERN CLASSIFICATI; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; KRZANOWSKI WJ, 1995, J R STAT SOC C-APPL, V44, P101, DOI 10.2307/2986198; MALINA W, 1981, IEEE T PATTERN ANAL, V3, P611, DOI 10.1109/TPAMI.1981.4767154; MANGASARIAN OL, 1995, OPER RES, V43, P570, DOI 10.1287/opre.43.4.570; Minsky M., 1988, PERCEPTRONS; MURPHY O, 1992, NEURAL NETWORKS THEO, P263; Rao AV, 1999, IEEE T PATTERN ANAL, V21, P159, DOI 10.1109/34.748824; Raudys S, 1998, NEURAL NETWORKS, V11, P297, DOI 10.1016/S0893-6080(97)00136-6; Raudys S, 1998, NEURAL NETWORKS, V11, P283, DOI 10.1016/S0893-6080(97)00135-4; Raudys S, 1997, IEEE T PATTERN ANAL, V19, P667, DOI 10.1109/34.601254; RUEDA LG, 2000, TR0003 CARL U SCH CO; RUEDA LG, UNPUB OPTIMAL PAIRWI; Webb A., 1999, STAT PATTERN RECOGNI	17	18	19	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2002	24	2					274	280		10.1109/34.982905	http://dx.doi.org/10.1109/34.982905			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	516DC					2022-12-18	WOS:000173535700010
J	Wiles, CS; Maki, A; Matsuda, N				Wiles, CS; Maki, A; Matsuda, N			Hyperpatches for 3D model acquisition and tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pose estimation; model acquisition; model tracking; face analysis	SHAPE	Automatic 3D model acquisition and 3D tracking of simple objects under motion using a single camera is often difficult due to the sparsity of information from which to establish the model. We have developed an automatic scheme that first computes a simple pointalistic Euclidean model of the object and then enriches this model using hyperpatches. These hyperpatches contain information on both the orientation and intensity pattern variation of roughly planar patches on an object, This information allows both the spatial and intensity distortions of the projected patch to be modeled accurately under 3D object motion. Considering human tracking as a specific application, we show that hyperpatches can not only be computed automatically during model acquisition from a monocular image sequence, but that they are also extremely appropriate for the task of visual tracking.	Anthrop Technol, London W5 5EP, England; Toshiba Corp Res & Dev Ctr, Saiwai Ku, Kawasaki, Kanagawa 2128582, Japan; Jungle Inc, Chiyoda Ku, Tokyo 1020082, Japan	Toshiba Corporation	Wiles, CS (corresponding author), Anthrop Technol, Ealing Studios,Ealing Green, London W5 5EP, England.	charles@anthropics.com; atsuto.maki@toshiba.co.jp; natsuko@junglejapan.com						Azarbayejani A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P294, DOI 10.1109/CVPR.1993.340966; BASU S, 1996, P INT C PATT REC AUG; BEARDSLEY PA, 1996, P 4 EUR C COMP VIS; Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484; BLACK MJ, 1996, P EUR C COMP VIS, P329; CASCIA ML, 2000, IEEE T PATTERN ANAL, V22, P322; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Garding J, 1996, INT J COMPUT VISION, V17, P163, DOI 10.1007/BF00058750; Gee A, 1996, IMAGE VISION COMPUT, V14, P105, DOI 10.1016/0262-8856(95)01044-0; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Maki A, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1053, DOI 10.1109/ICCV.1998.710847; MOSES Y, 1994, P EUR C COMP VIS, P286; REHG JM, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P844, DOI 10.1109/ROBOT.1991.131693; REYNARD D, 1996, P 4 EUR C COMP VIS, P357; Shashua A, 1992, THESIS MIT; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Weinshall D., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P675, DOI 10.1109/ICCV.1993.378147	21	18	19	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2001	23	12					1391	1403		10.1109/34.977563	http://dx.doi.org/10.1109/34.977563			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	500NY					2022-12-18	WOS:000172634700005
J	Kahl, F; Heyden, A; Quan, L				Kahl, F; Heyden, A; Quan, L			Minimal projective reconstruction including missing data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						structure recovery; projective reconstruction; structure from motion; projective geometry; missing data	COMPUTATION; CAMERA; IMAGES; MOTION; POINTS; SHAPE	The minimal data necessary for projective reconstruction from image points is well-known when each object point is visible in all images. In this paper, we formulate and propose solutions to a new family of reconstruction problems for multiple images from minimal data, where there are missing points in some of the images. The ability to handle the minimal cases with missing data is of great theoretical and practical importance. It is unavoidable to use them to bootstrap robust estimation such as RANSAC and LMS algorithms and optimal estimation such as bundle adjustment. First, we develop a framework to parameterize the multiple view geometry needed to handle the missing data cases. Then, we present a solution to the minimal case of eight points in three images, where one different point is missing in each of the three images. We prove that there are, in general, as many as 11 solutions for this minimal case. Furthermore, all minimal cases with missing data for three and four images are catalogued. Finally, we demonstrate the method on both simulated and real images and show that the algorithms presented in this paper can be used for practical problems.	Univ Lund, Ctr Math Sci, SE-22100 Lund, Sweden; INRIA Rhone Alpes, F-38330 Montbonnot St Martin, France	Lund University	Kahl, F (corresponding author), Univ Lund, Ctr Math Sci, Box 118, SE-22100 Lund, Sweden.							ATKINSON KB, 1996, CLOSE RANGE PHOTOGRA; Carlsson S, 1998, INT J COMPUT VISION, V27, P227, DOI 10.1023/A:1007961913417; Cox D., 1992, IDEALS VARITIES ALGO; FAUGERAS OD, 1992, P 2 EUR C COMP VIS S, P563; FAUGERAS OD, 1990, 1157 INRIA; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Hartley R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P761, DOI 10.1109/CVPR.1992.223179; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HEYDEN A, 1999, INT C COMP VIS KERK, P350; HEYDEN A, 1995, THESIS LUND I TECHNO; Kahl F, 1999, INT J COMPUT VISION, V33, P163, DOI 10.1023/A:1008192713051; Ma Y, 2000, INT J COMPUT VISION, V38, P219, DOI 10.1023/A:1008143307025; MAYBANK SJ, 1992, INT J COMPUT VISION, V8, P123, DOI 10.1007/BF00127171; QUAN L, 1995, IEEE T PATTERN ANAL, V17, P34; QUAN L, 1995, P 5 INT C COMP VIS C, P926; Shashua A., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), P920, DOI 10.1109/ICCV.1995.466837; Sturm R., 1869, MATH ANN, V1, P533; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torr PHS, 1997, IMAGE VISION COMPUT, V15, P591, DOI 10.1016/S0262-8856(97)00010-3; Triggs B, 1997, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.1997.609388; Triggs B, 1997, IMAGE VISION COMPUT, V15, P617, DOI 10.1016/S0262-8856(97)00016-4; ZHANG ZY, 1994, ROBUST TECHNIQUE MAT	22	18	18	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2001	23	4					418	424		10.1109/34.917578	http://dx.doi.org/10.1109/34.917578			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	421MJ		Green Submitted			2022-12-18	WOS:000168067900008
J	Bennett, J; Khotanzad, A				Bennett, J; Khotanzad, A			Maximum likelihood estimation methods for multispectral random field image models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						maximum likelihood estimation; multispectral image models; color texture models; multispectral random fields; multispectral autoregressive models; multispectral Markov models	SPATIAL-INTERACTION; COLOR IMAGES	This work considers the problem of estimating parameters of multispectral random field (RF) image models using maximum likelihood (ML) methods. For images with an assumed Gaussian distribution. analytical results are developed for multispectral simultaneous autoregressive (MSAR) and Markov random field (MMRF) models which lead to practical procedures for calculating ML estimates. Although previous work has provided least squares methods for parameter estimation, the superiority of the ML method is evidenced by experimental results provided in this work. The effectiveness of multispectral RF models using ML estimates in modeling color texture images is also demonstrated.	So Methodist Univ, Dept Elect Engn, Dallas, TX 75275 USA	Southern Methodist University	Bennett, J (corresponding author), So Methodist Univ, Dept Elect Engn, Dallas, TX 75275 USA.							Bennett J, 1998, IEEE T PATTERN ANAL, V20, P327, DOI 10.1109/34.667889; BENNETT J, 1996, P IEEE INT C IM PROC, V3, P991; BENNETT JW, 1997, THESIS SO METH U DAL; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; CHELLAPPA R, 1985, IEEE T SYST MAN CYB, V15, P298, DOI 10.1109/TSMC.1985.6313361; GAGALOWICZ A, 1986, P INT C PATT REC PAR, P412; GONZALEZ R, 1992, DIGITAL IMAGE PROCES, P261; JACOBS DAH, 1977, STATE ART NUMERICAL, pCH3; Kashyap R. L., 1980, Proceedings of the 5th International Conference on Pattern Recognition, P1103; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; Katsaggelos AK, 1993, IEEE T IMAGE PROCESS, V2, P417, DOI 10.1109/83.236528; KHOTANZAD A, 1987, IEEE T SYST MAN CYB, V17, P1087, DOI 10.1109/TSMC.1987.6499322; LARIMORE WE, 1977, P IEEE, V65, P961, DOI 10.1109/PROC.1977.10593; PANJWANI DK, 1995, IEEE T PATTERN ANAL, V17, P939, DOI 10.1109/34.464559; *VIS MOD GROUP MIT, 1995, VIS TEXT VIST DAT; WHITTLE P, 1954, BIOMETRIKA, V41, P434	16	18	18	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1999	21	6					537	543		10.1109/34.771322	http://dx.doi.org/10.1109/34.771322			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	205KD					2022-12-18	WOS:000080819100004
J	Cass, TA				Cass, TA			Robust affine structure matching for 3D object recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object recognition; geometric feature matching; pose recovery; alignment method; affine structure; model indexing; computational geometry	IMAGE; POSE	We consider model-based object localization based on local geometric feature matching between the model and the image data. The method is based on geometric constraint analysis, working in transformation space. We present a formal method which guarantees finding all feasible matchings in polynomial time. From there we develop more computationally feasible algorithms based on conservative approximations of the formal method. Additionally, our formalism relates object localization affine model indexing, and structure from multiple views to one another.	Xerox Corp, Palo Alto Res Ctr, Palo Alto, CA 94304 USA	Xerox	Cass, TA (corresponding author), Xerox Corp, Palo Alto Res Ctr, 3333 Coyote Hill Rd, Palo Alto, CA 94304 USA.	cass@parc.xerox.com						ALT H, 1988, DISCRETE COMPUT GEOM, V3, P237, DOI 10.1007/BF02187910; ALTER TD, 1994, IEEE T PATTERN ANAL, V16, P802, DOI 10.1109/34.308475; ALTER TD, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P892, DOI 10.1109/CVPR.1994.323920; BAIRD HS, 1985, MODEL BASED IMAGE MA; BREUEL TM, 1990, 1259 AI MIT ART INT; Cass TA, 1997, INT J COMPUT VISION, V21, P37, DOI 10.1023/A:1007971405872; CASS TA, 1994, P INT C PATT REC JER, pA477; CASS TA, 1988, THESIS MIT; CASS TA, 1992, P EUR C COMP VIS; CASS TA, 1996, SPL96003P9610031 XER; CHEW L, 1992, IMPROVEMENTS GEOMETR, P343; CHEW L, 1993, P 5 CAN C COMP GEOM; COSTA M, 1990, P 6 ISR C AI, P35; ERIC W, 1990, 1250 AI MIT ART INT; ERIC W, 1987, IEEE T PATTERN ANAL, V9, P469; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Goodrich M. T., 1994, Proceedings of the Tenth Annual Symposium on Computational Geometry, P103, DOI 10.1145/177424.177572; HEFFERNAN P, 1994, COMPUTATIONAL GEOMET, V4; HOPCROFT MJ, 1995, THESIS CORNELL U; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; JACOBS D, 1992, THESIS MIT; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; Olson CF, 1997, INT J COMPUT VISION, V23, P131, DOI 10.1023/A:1007906812782; RIGOUTSOS I, 1995, COMPUT VIS IMAGE UND, V62, P11, DOI 10.1006/cviu.1995.1038; ROBERTS L, 1966, OPTICAL ELECTROOPTIC; RUCKLIDGE W, 1995, P INT C COMP VIS CAM; Thompson D. W., 1987, Proceedings of the 1987 IEEE International Conference on Robotics and Automation (Cat. No.87CH2413-3), P208; WELLS WM, 1993, AITR1398 MIT ART INT; WOLFSON HJ, 1992, ARTIF INT, P335	30	18	19	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1998	20	11					1265	1274		10.1109/34.730560	http://dx.doi.org/10.1109/34.730560			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	138TX					2022-12-18	WOS:000076990100012
J	Ng, WS; Lee, CK				Ng, WS; Lee, CK			Comment on using the uniformity measure for performance measure in image segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						thresholding; binarization; segmentation; evaluation; optimality measure	CORRELATION CRITERION; LEVEL	In this correspondence, we will point out that the image segmentation performance measure-the uniformity measure, which is suggested by Levine and Nazif [1]-is basically equivalent to the criterion measure proposed by Otsu [2].			Ng, WS (corresponding author), HONG KONG POLYTECH,DEPT ELECT ENGN,KOWLOON,HONG KONG.							BRINK AD, 1989, PATTERN RECOGN LETT, V9, P335, DOI 10.1016/0167-8655(89)90062-7; CSEKE I, 1990, PATTERN RECOGN LETT, V11, P709, DOI 10.1016/0167-8655(90)90105-B; Fukunage K., 1972, INTRO STAT PATTERN R, P260; GONZALEZ RC, 1992, DIGITAL IMAGE PROCES, P447; LEVINE MD, 1985, IEEE T PATTERN ANAL, V7, P155, DOI 10.1109/TPAMI.1985.4767640; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; WESZKA JS, 1978, IEEE T SYST MAN CYB, V8, P622, DOI 10.1109/TSMC.1978.4310038	8	18	22	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1996	18	9					933	934		10.1109/34.537347	http://dx.doi.org/10.1109/34.537347			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VK799					2022-12-18	WOS:A1996VK79900007
J	Wilfong, G; Sinden, F; Ruedisueli, L				Wilfong, G; Sinden, F; Ruedisueli, L			On-line recognition of handwritten symbols	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						pattern recognition; handwriting; on-line; symbol recognition; template matching		An on-line system for recognizing handwritten symbols from a user specified alphabet is described. When a symbol is subsequently written the system is required to recognize the symbol irrespective of the scale, orientation and position of the written symbol.	AT&T BELL LABS,RES,MURRAY HILL,NJ 07974	AT&T; Nokia Corporation; Nokia Bell Labs	Wilfong, G (corresponding author), BELL LABS LUCENT TECHNOL,MURRAY HILL,NJ 07974, USA.							BLONDER GE, 1991, CAPACITIVE MOMENT SE; BROWN MK, 1983, PATTERN RECOGN, V16, P447, DOI 10.1016/0031-3203(83)90049-3; Frishkopf L, 1961, INFORMATION THEORY, P300; Fujisaki T., 1991, International Journal of Pattern Recognition and Artificial Intelligence, V5, P123, DOI 10.1142/S0218001491000090; HU J, 1993, HANDWRITING RECOGNIT; Nicholas D., 1978, LIT BIBLIOMETRICS; ODAKA K, 1982, IEEE T SYST MAN CYB, V12, P898; TAPPERT CC, 1982, IBM J RES DEV, V26, P765, DOI 10.1147/rd.266.0765; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669; WAKAHARA T, 1988, P 9 INT C PATT REC N, P1133; ZIKAN K, 1989, THESIS STANFORD U	11	18	19	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1996	18	9					935	940		10.1109/34.537348	http://dx.doi.org/10.1109/34.537348			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VK799					2022-12-18	WOS:A1996VK79900008
J	Hamamoto, Y; Uchimura, S; Tomita, S				Hamamoto, Y; Uchimura, S; Tomita, S			On the behavior of artificial neural network classifiers in high-dimensional spaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						artificial neural networks; generalization error; dimensionality; training sample size; peaking phenomenon; 1-NN classifier; Parzen classifier	SAMPLE-SIZE	It is widely believed in the pattern recognition field that when a fixed number of training samples is used to design a classifier, the generalization error of the classifier tends to increase as the number of features gets large. In this paper, we will discuss the generalization error of the artificial neural network (ANN) classifiers in high-dimensional spaces, under a practical condition that the ratio of the training sample size to the dimensionality is small. Experimental results show that the generalization error of ANN classifiers seems much less sensitive to the feature size than 1-NN, Parzen and quadratic classifiers.	OSHIMA NATL COLL MARITIME TECHNOL, OSHIMA 74221, JAPAN		Hamamoto, Y (corresponding author), YAMAGUCHI UNIV, FAC ENGN, UBE, YAMAGUCHI 755, JAPAN.							AMARI S, 1992, NEURAL COMPUT, V4, P605, DOI 10.1162/neco.1992.4.4.605; BAUM EB, 1990, P EURASIP WORKSHOP N, P2; COHN D, 1992, NEURAL COMPUT, V4, P249, DOI 10.1162/neco.1992.4.2.249; Devijver PA, 1982, PATTERN RECOGNITION; Duda R.O., 1973, J ROYAL STAT SOC SER; Duin R. P. W., 1993, Proceedings of the 8th Scandinavian Conference on Image Analysis, P547; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634, DOI 10.1109/TPAMI.1987.4767958; FUKUNAGA K, 1989, IEEE T PATTERN ANAL, V11, P873, DOI 10.1109/34.31448; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P103, DOI 10.1109/TPAMI.1987.4767875; FUKUNAGA K, 1990, INTRO STATISTICAL PA; Huang W. Y., 1987, IEEE First International Conference on Neural Networks, P485; HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102; Jain A. K., 1988, Pattern Recognition and Artificial Intelligence. Towards an Integration. Proceedings of an International Workshop, P211; Jain A.K., 1982, HDB STAT, P835, DOI 10.1016/S0169-7161(82)02042-2; KANAL L, 1971, PATTERN RECOGN, V3, P238; KHOTANZAD A, 1991, ARTIFICIAL NEURAL NE, P109; KHOTANZAD A, 1988, P IEEE INT C NEUR NE, pI625; Lippman R. P., 1987, IEEE ASSP MAGAZI APR, P4; LIPPMANN RP, 1989, IEEE COMMUNICATI NOV, P47; Raudys S., 1993, Informatica, V4, P360; Raudys S., 1991, Informatica, V2, P434; RAUDYS S, 1991, ARTIFICIAL NEURAL NE, P33; RAUDYS S, 1994, PATTERN RECOGN, V4, P287; RAUDYS S, 1976, P 3 INT C PATT REC, P166; RAUDYS S, 1995, 9517 LAFORIA U PAR 6; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Rumelhart DE, 1986, PARALLEL DISTRIBUTED, V1-2; VANNESS J, 1980, PATTERN RECOGN, V12, P355, DOI 10.1016/0031-3203(80)90012-6	28	18	18	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1996	18	5					571	574		10.1109/34.494648	http://dx.doi.org/10.1109/34.494648			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL691					2022-12-18	WOS:A1996UL69100011
J	Fan, CM; Namazi, NM; Penafiel, PB				Fan, CM; Namazi, NM; Penafiel, PB			A new image motion estimation algorithm based on the EM technique	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image motion estimation; the maximum likelihood (ML) principle; the expectation-maximization (EM) algorithm; Kalman filtering; affine motion; additive white Gaussian noise		This paper focuses on the presentation and implementation of a new iterative algorithm for image motion coefficient estimation from noisy measurements based on the Expectation-Maximization (EM) technique. We also compare this algorithm with two other robust iterative algorithms. We represent the motion field by a (unitary) series expansion to obtain the motion coefficients, and show this characterization to have several virtues. First, an inherent property of motion, referred to as smoothness, is imposed. Second, the nonuniform motion estimation is reduced to the estimation of a few coefficients using the low-pass property of the motion. Finally, the motion estimation can be accomplished without the need for a motion model; in the events for which the motion model is completely unknown, the DCT representation is shown to be very effective in describing the true motion.			Fan, CM (corresponding author), CATHOLIC UNIV AMER, DEPT ELECT ENGN, WASHINGTON, DC 20064 USA.			Penafiel Verdu, Pablo/0000-0002-0641-5077				DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; EMMERT RA, 1973, P IEEE C MACH PROC R, P24; FEDER M, 1988, IEEE T ACOUST SPEECH, V36, P477, DOI 10.1109/29.1552; FUH CS, 1991, P IEEE C AC SPEECH S; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; KONRAD J, 1992, IEEE T PATTERN ANAL, V14, P910, DOI 10.1109/34.161350; MUSMANN HG, 1985, P IEEE, V73, P523, DOI 10.1109/PROC.1985.13183; Namazi N. M., 1994, NEW ALGORITHMS VARIA; Namazi NM, 1993, IEEE T IMAGE PROCESS, V2, P236, DOI 10.1109/83.217227; NAMAZI NM, 1990, IEEE T ACOUST SPEECH, V38, P364, DOI 10.1109/29.103075; NAMAZI NM, 1994, IEEE T IMAG PROC SEP, P678; NETRAVALI AN, 1979, AT&T TECH J, V58, P631, DOI 10.1002/j.1538-7305.1979.tb02238.x; SEZAN MI, 1993, MOTION ANAL IMAGE SE; SHALTAF S, 1992, PROCEEDINGS OF THE 35TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS 1 AND 2, P1324, DOI 10.1109/MWSCAS.1992.271096; Shaltaf S., 1992, THESIS MICHIGAN TU H; Singh A., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P36, DOI 10.1109/WVM.1991.212790; SINGH A, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2730, DOI 10.1109/ROBOT.1991.132044; STULLER J, 1983, COMPUT VISION GRAPH, V21, P169, DOI 10.1016/S0734-189X(83)80036-X; Webber WF., 1973, P IEEE C MACH PROC R, P1	19	18	20	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1996	18	3					348	352		10.1109/34.485564	http://dx.doi.org/10.1109/34.485564			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UA455					2022-12-18	WOS:A1996UA45500013
J	OLSON, CF				OLSON, CF			PROBABILISTIC INDEXING FOR OBJECT RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						OBJECT RECOGNITION; INDEXING; PROBABILISTIC ALGORITHMS; PROBABILISTIC PEAKING EFFECT; ALIGNMENT METHOD	IMAGES	Recent papers have indicated that indexing is a promising approach to fast model-based object recognition became it allows most of the possible matches between sets of image features and sets of model features to be quickly eliminated from consideration. This correspondence describes a system that is capable of indexing using sets of three points undergoing three-dimensional transformations and projection by taking advantage of the probabilistic peaking effect. To be able to index using sets of three points, we must allow false negatives. These are overcome by ensuring that we examine several correct hypotheses. The use of these techniques to speed up the alignment method is described. Results are Even on real and synthetic data.			OLSON, CF (corresponding author), CORNELL UNIV,DEPT COMP SCI,ITHACA,NY 14853, USA.							BENARIE J, 1990, IEEE T PATTERN ANAL, V12, P760, DOI 10.1109/34.57667; BINFORD TO, 1989, UNCERTAINTY ARTIFICI, V3, P73; BURNS JB, 1993, IEEE T PATTERN ANAL, V15, P51, DOI 10.1109/34.184774; CLEMENS DT, 1991, IEEE T PATTERN ANAL, V13, P1007, DOI 10.1109/34.99235; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Forstner<spacing Wolfgang, 1987, ISPRS INT C FAST PRO, P2; FORSTNER W, 1993, COMPUTER ROBOT VISIO, V2, pCH16; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233; GRIMSON W, 1992, P EUROPEAN C COMPUTE, P291; GRIMSON WEL, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P334; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; LAMDAN Y, 1988, JUN P CVPR C ANN ARB, P335; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; Olson C. F., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P387, DOI 10.1109/CVPR.1993.341101; OLSON CF, 1993, UCBCSD93733 U CAL BE; OLSON CF, 1994, 2ND P CAD BAS VIS WO, P2; Weiss I., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P115, DOI 10.1109/CVPR.1992.223218	17	18	18	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1995	17	5					518	522		10.1109/34.391391	http://dx.doi.org/10.1109/34.391391			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QW394					2022-12-18	WOS:A1995QW39400007
J	LAVALLE, SM; HUTCHINSON, SA				LAVALLE, SM; HUTCHINSON, SA			A BAYESIAN SEGMENTATION METHODOLOGY FOR PARAMETRIC IMAGE-MODELS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						STATISTICAL IMAGE SEGMENTATION; BAYESIAN METHODS; LIKELIHOODS; BAYES FACTOR; RANGE IMAGES; MARKOV RANDOM FIELD; TEXTURE SEGMENTATION	TEXTURE SEGMENTATION; RANGE IMAGES; RECOGNITION; RELAXATION; SURFACE; VISION; CHOICE; EDGE	Region-based image segmentation methods require some criterion for determining when to merge regions. This paper presents a novel approach by introducing a Bayesian probability of homogeneity in a general statistical context. Our approach does not require parameter estimation and is therefore particularly beneficial for cases in which estimation-based methods are most prone to error: when little information is contained in some of the regions and, therefore, parameter estimates are unreliable. We apply this formulation to three distinct parametric model families that have been used in past segmentation schemes: implicit polynomial surfaces, parametric polynomial surfaces, and Gaussian Markov random fields. We present results on a variety of real range and intensity images.	UNIV ILLINOIS,DEPT ELECTR & COMP ENGN,URBANA,IL 61801	University of Illinois System; University of Illinois Urbana-Champaign	LAVALLE, SM (corresponding author), UNIV ILLINOIS,BECKMAN INST ADV SCI & TECHNOL,405 N MATHEWS AVE,URBANA,IL 61801, USA.			hutchinson, seth/0000-0002-3949-6061				BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; BOLLE RM, 1986, IEEE T PATTERN ANAL, V8, P619, DOI 10.1109/TPAMI.1986.4767836; COHEN FS, 1992, CVGIP-GRAPH MODEL IM, V54, P239, DOI 10.1016/1049-9652(92)90054-2; COHEN FS, 1987, IEEE T PATTERN ANAL, V9, P195, DOI 10.1109/TPAMI.1987.4767895; DUBUF JMH, 1990, PATTERN RECOGN, V23, P291, DOI 10.1016/0031-3203(90)90017-F; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HARALICK RM, 1981, COMPUT VISION GRAPH, V15, P113, DOI 10.1016/0146-664X(81)90073-3; HOFFMAN R, 1987, IEEE T PATTERN ANAL, V9, P608, DOI 10.1109/TPAMI.1987.4767955; IKEUCHI K, 1989, COMPUT VISION GRAPH, V48, P50, DOI 10.1016/0734-189X(89)90104-7; JOLION JM, 1991, IEEE T PATTERN ANAL, V13, P791, DOI 10.1109/34.85669; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; KASS RE, 1992, J ROY STAT SOC B MET, V54, P129; LAVALLE SM, 1993, JUL P SPIE C STOCH M; LAVALLE SM, 1992, THESIS U ILLINOIS UR; LAVALLE SM, 1993, JUL P ANN C UNC ART; Leonardis A., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P121, DOI 10.1109/ICCV.1990.139508; Mirza M. J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P366, DOI 10.1109/CVPR.1992.223163; PANJWANI DK, 1993, JUN P IEEE C COMP VI, P776; PAVLIDIS T, 1990, IEEE T PATTERN ANAL, V12, P225, DOI 10.1109/34.49050; PETTIT LI, 1992, J AM STAT ASSOC, V87, P541, DOI 10.2307/2290288; Picard R. W., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P638, DOI 10.1109/CVPR.1993.341050; REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024; SABATA B, 1993, CVGIP-IMAG UNDERSTAN, V57, P373, DOI 10.1006/ciun.1993.1025; SILVERMAN JF, 1988, IEEE T PATTERN ANAL, V10, P482, DOI 10.1109/34.3912; SMITH AFM, 1980, J ROY STAT SOC B MET, V42, P213; SZELISKI R, 1990, INT J COMPUT VISION, V5, P271, DOI 10.1007/BF00126502; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; TUCERYAN M, 1990, IEEE T PATTERN ANAL, V12, P211, DOI 10.1109/34.44407; ZHANG J, 1990, IEEE T PATTERN ANAL, V12, P1009, DOI 10.1109/34.58873	32	18	19	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1995	17	2					211	217		10.1109/34.368166	http://dx.doi.org/10.1109/34.368166			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE825		Green Submitted			2022-12-18	WOS:A1995QE82500012
J	PARK, H; CHIN, RT				PARK, H; CHIN, RT			OPTIMAL DECOMPOSITION OF CONVEX MORPHOLOGICAL STRUCTURING ELEMENTS FOR 4-CONNECTED PARALLEL ARRAY PROCESSORS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article								A morphological operation using a large structuring element can be decomposed equivalently into a sequence of recursive operations, each using a smaller structuring element. However, an optimal decomposition of arbitrarily shaped structuring elements is yet to be found. In this paper, we have derived an optimal decomposition of a specific class of structuring elements-convex sets-for a specific type of machine-4-connected parallel array processors. The cost of morphological operation on 4-connected parallel array processors is the total number of 4-connected shifts required by the set of structuring elements. First, the original structuring element is decomposed into a set of prime factors, and then their locations are determined while minimizing the cost function. Proofs are presented to show the optimality of the decomposition. Examples of optimal decomposition are given and compared to an existing decomposition reported by Xu.	UNIV WISCONSIN,DEPT ELECT & COMP ENGN,MADISON,WI 53706	University of Wisconsin System; University of Wisconsin Madison			Chin, Roland Tai Hong/E-9856-2010					ABBOTT L, 1988, MACHINE VISION APPL, V1; CHEN MH, 1989, IEEE T PATTERN MACHI, V11; CYPHER R, 1989, IEEE T ACOUST SPEECH, V37; DANIELSSON PE, 1981, COMPUT           NOV; FREEMAN H, 1974, COMPUT SURVEYS, V6; GERRISTEN FA, 1983, COMPUTER STRUCTURES; GOUTSIAS J, 1989, JUN P IEEE C COMP VI; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9; JANG BK, 1990, IEEE T PATTERN ANAL, V12; LEE JSJ, 1987, IEEE J ROBOTICS AUTO, V3; Maragos P.A., 1986, IEEE T ACOUST SPEECH, V34; PITAS I, 1990, IEEE T PATTERN ANAL, V12; POTTER JL, 1983, COMPUT           JAN; PRESTON K, 1983, COMPUT           JAN; ROSENFELD A, 1983, COMPUT           JAN; SERRA J, 1988, IMAGE ANAL MATH MORP, V2, pCH17; SHIH FY, 1988, APR P IEEE INT C ROB; SHIH FY, 1988, JUN P IEEE C COMP VI; STERNBERG SR, 1983, COMPUT           JAN; XU J, 1991, IEEE T PATTERN ANAL, V13	20	18	20	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1994	16	3					304	313		10.1109/34.276129	http://dx.doi.org/10.1109/34.276129			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NF114					2022-12-18	WOS:A1994NF11400010
J	HASHLAMOUN, WA; VARSHNEY, PK; SAMARASOORIYA, VNS				HASHLAMOUN, WA; VARSHNEY, PK; SAMARASOORIYA, VNS			A TIGHT UPPER BOUND ON THE BAYESIAN PROBABILITY OF ERROR	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						ALI-SILVEY DISTANCE MEASURES; BAYESIAN DECISION SYSTEMS; DIVERGENCE; MINIMUM PROBABILITY OF ERROR; PROBABILITY OF ERROR BOUNDS; STATISTICAL PATTERN RECOGNITION		In this paper, we present a new upper bound on the minimum probability of error of Bayesian decision systems. This new bound is continuous everywhere and is shown to be tighter than several existing bounds such as the Bhattacharyya and the Bayesian bounds. Numerical results are also presented.	SYRACUSE UNIV,DEPT ELECT & COMP ENGN,SYRACUSE,NY 13244	Syracuse University	HASHLAMOUN, WA (corresponding author), BIRZEIT UNIV,DEPT ELECT ENGN,POB 14,W BANK,ISRAEL.							ALI SM, 1966, J ROY STAT SOC B, V28, P131; Ben-Bassat M., 1982, HDB STATISTICS, P773, DOI DOI 10.1016/S0169-7161(82)02038-0; BOEKEE DE, 1979, PATTERN RECOGN, V11, P353, DOI 10.1016/0031-3203(79)90047-5; CHEN CH, 1971, IEEE T COMPUT, VC 20, P1054, DOI 10.1109/T-C.1971.223402; CHEN CH, 1976, INFORM SCIENCES, V10, P159, DOI 10.1016/S0020-0255(76)90746-5; DEVIJVER PA, 1974, IEEE T COMPUT, VC 23, P70, DOI 10.1109/T-C.1974.223779; DEVORE JL, 1990, PROBABILITY STATISTI; DEVROYE L, 1981, ANN STAT, V9, P1320, DOI 10.1214/aos/1176345648; DJOUADI A, 1990, IEEE T PATTERN ANAL, V12, P92, DOI 10.1109/34.41388; Hashlamoun W. A., 1991, THESIS SYRACUSE U; HELLMAN ME, 1970, IEEE T INFORM THEORY, V16, P368, DOI 10.1109/TIT.1970.1054466; ITO T, 1972, MACH INTELL, V7, P369; JAIN AK, 1976, IEEE T SYST MAN CYBE; POOR HV, 1977, IEEE T COMMUN, V25, P893, DOI 10.1109/TCOM.1977.1093935; POOR HV, 1988, IEEE T INFORM THEORY, V34; TOUSSAINT GT, 1974, 2ND P INT JOINT C PA; VanTrees H., 1968, DETECTION ESTIMATION, V1	19	18	18	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1994	16	2					220	224		10.1109/34.273728	http://dx.doi.org/10.1109/34.273728			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NA631					2022-12-18	WOS:A1994NA63100010
J	VEGA, OE; YANG, YH				VEGA, OE; YANG, YH			SHADING LOGIC - A HEURISTIC APPROACH TO RECOVER SHAPE FROM SHADING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						EARLY VISION; REGULARIZATION; SHADING LOGIC; SHAPE-FROM-SHADING		Shape recovery from shading information is still, to a large extent, unsolved. Existing proposed techniques are mostly variational-based methods. The problem with the variational approaches is that the objective of the computation is unclear. As a result, once a variational scheme is obtained, there is little that can be done to improve the results. If weaknesses are found in the approach, the only way to improve the results is to return to the basic variational formulation and reformulate the problem. One commonly cited problem with this approach is that the solution surface may not necessarily be the desired one. In addition, many methods appear to be unstable even when the solution is nearby. Compounded with all these problems, there does not seem to be a systematic way to evaluate shape-from-shading algorithms. A heuristic-based algorithm known as the shading logic algorithm is proposed to recover shape from shading. The heuristics are derived based on the geometrical interpretation of the Brooks and Horn algorithm. Experimental evaluation was performed using synthesized objects, in particular, superquadrics. The advantage of using the superquadrics is that the shape of the objects can be varied incrementally and systematically. Despite the fact that the shading logic algorithm is heuristic based, experimental results show that the proposed algorithm has a better performance than the Brooks and Horn (B-H) algorithm. In addition, the proposed approach does not seem to suffer the stability problem common to most variational-based methods.			VEGA, OE (corresponding author), UNIV SASKATCHEWAN,DEPT COMPUTAT SCI,COMP VIS LAB,SASKATOON S7N 0W0,SASKATCHEWAN,CANADA.							Barr A. H., 1981, IEEE Computer Graphics and Applications, V1, P11, DOI 10.1109/MCG.1981.1673799; Brooks MJ, 1989, SHAPE SHADING; BROOKS MJ, 1985, AUG P INT JOINT C AR, P932; FERRIE F, 1988, IEEE T PATTERN ANAL, V11, P198; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1990, INT J COMPUT VISION, V5, P35; HORN BKP, 1984, COMPUT VISION GRAPH, V33, P144; LEYMARIE F, 1989, PROGR IMAGE ANAL PRO, P186; TANDRI S, 1990, PATTERN RECOGN LETT, V11, P637, DOI 10.1016/0167-8655(90)90017-V; VEGA OM, 1991, TR9110 U SASK DEP CO; WILLICK D, 1991, CVGIP-IMAG UNDERSTAN, V54, P206, DOI 10.1016/1049-9660(91)90063-U; ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658	12	18	22	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1993	15	6					592	597		10.1109/34.216728	http://dx.doi.org/10.1109/34.216728			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LF257					2022-12-18	WOS:A1993LF25700007
J	GOKMEN, M; LI, CC				GOKMEN, M; LI, CC			EDGE-DETECTION AND SURFACE RECONSTRUCTION USING REFINED REGULARIZATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						ADAPTIVE SMOOTHING; EDGE DETECTION; REGULARIZATION; SPATIAL CONTROL OF SMOOTHNESS; SURFACE RECONSTRUCTION; VARIATIONAL METHODS		The assumption of the smoothness constraint in the global sense using a fixed regularization parameter is one of the major problems of the algorithms based on regularization theory. Several nonstandard algorithms have been developed to overcome this problem by using a line process, but they suffer from the extensive computation required in minimizing the resulting nonconvex functionals. We present an edge detection and surface reconstruction algorithm in which the smoothness is controlled spatially over the image space. The values of parameters in the model are adaptively determined by an iterative refinement process, hence, the image-dependent parameters such as the optimum value of the regularization parameter or the filter size are eliminated. The algorithm starts with an oversmoothed regularized solution and iteratively refines the surface around discontinuities by using the structure exhibited in the error signal. The spatial control of smoothness is shown to resolve the conflict between detection and localization criteria of edge detection by smoothing the noise in continuous regions while preserving discontinuities. The performance or the algorithm is quantitatively and qualitatively evaluated on real and synthetic images, and it is compared with those or Marr-Hildreth and Canny edge detectors.	UNIV PITTSBURGH,DEPT ELECT ENGN,PITTSBURGH,PA 15261	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh	GOKMEN, M (corresponding author), ISTANBUL TECH UNIV,FAC ELECT & ELETR,ISTANBUL,TURKEY.		Gokmen, Muhittin/C-2171-2015					BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; GEIGER D, 1988, AI1078 MIT AI LAB ME; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GOKMEN M, 1991, JUN P IEEE C COMP VI, P215; GOKMEN M, 1990, 10TH P INT C PATT RE, P690; GOKMEN M, 1990, THESIS U PITTSBURGH; GRIMSON WEL, 1985, COMPUT VISION GRAPH, V30, P316, DOI 10.1016/0734-189X(85)90163-X; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; LEE D, 1988, IEEE T PATTERN ANAL, V10, P822, DOI 10.1109/34.9105; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; MUMFORD D, 1985, JUN P IEEE COMP VIS, P22; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; SHAH J, 1991, JUN C COMP VIS PATT, P202; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; Tikhonov A., 1977, SOLUTIONS ILL POSED; Tikhonov AN, 1963, SOV MATH DOKL, V4, P1624; WAHBA G, 1977, SIAM J NUMER ANAL, V14, P651, DOI 10.1137/0714044	20	18	21	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1993	15	5					492	499		10.1109/34.211469	http://dx.doi.org/10.1109/34.211469			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LB470					2022-12-18	WOS:A1993LB47000007
J	GOLDMAN, RP; CHARNIAK, E				GOLDMAN, RP; CHARNIAK, E			A LANGUAGE FOR CONSTRUCTION OF BELIEF NETWORKS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article								We describe a method for incrementally constructing belief networks, which are directed acyclic graph representations for probability distributions. We have developed a network-construction language (FRAIL3), which is similar to a forward-chaining language using data dependencies but has additional features for specifying distributions. A particularly important feature of this language is that it allows the user to conveniently specify conditional probability matrices using stereotyped models of intercausal interaction. Using FRAIL3, one can define parameterized classes of probabilistic models. These parameterized models make it possible to apply probabilistic reasoning to problems for which it is impractical to have a single large, static model.	ROCKWELL INT CORP,CTR SCI,PALO ALTO LAB,PALO ALTO,CA; BROWN UNIV,DEPT COMP SCI,PROVIDENCE,RI 02912	Rockwell Collins; Brown University	GOLDMAN, RP (corresponding author), TULANE UNIV,SCH ENGN,DEPT COMP SCI,NEW ORLEANS,LA 70118, USA.							ANDERSEN SK, 1989, 11TH P INT JONT C AR; Breese J. S., 1992, COMPUTATIONAL INTELL, V8, P624; CARROLL G, 1991, 7TH P C UNC ART INT, P69; CHARNIAK E, 1991, AI MAG, V12, P50; CHARNIAK E, 1991, 9TH P NAT C ART INT, P160; CHARNIAK E, 1991, 9TH P NAT C ART INT, P446; CHARNIAK E, 1989, 11TH P INT JOINT C A, P1074; CHARNIAK E, 1988, P 26 ANN M ASS COMP, P87; CHARNIAK E, IN PRESS ARTIFICIAL; CHARNIAK E, 1990, UNCERTAINTY ARTIFICI, V5, P343; CHAVEZ RM, 1989, 5TH P WORKSH UNC ART, P60; CHIN HL, 1987, 3RD P WORKSH UNC ART, P106; Cooper G. F., 1984, THESIS STANFORD U; COOPER GF, 1990, ARTIF INTELL, V42, P393, DOI 10.1016/0004-3702(90)90060-D; COUSINS SB, UNPUB CABEN COLLECTI; D'Ambrosio B., 1988, International Journal of Approximate Reasoning, V2, P29, DOI 10.1016/0888-613X(88)90004-7; DAMBROSIO B, 1990, UNCERTAINTY ARTIFICI, V4, P15; DEKLEER J, 1986, ARTIF INTELL, V28, P127, DOI 10.1016/0004-3702(86)90080-9; DOYLE J, 1979, ARTIF INTELL, V12, P231, DOI 10.1016/0004-3702(79)90008-0; FRYDENBERG M, 1989, 186 U AARH I MATH DE; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Goldman R. P., 1992, Statistics and Computing, V2, P105, DOI 10.1007/BF01889589; GOLDMAN RP, 1992, 8TH UNC ART INT P C, P104; GOLDMAN RP, 1990, CS9034 BROWN U COMP; GRENANDER U, 1983, TUTORIAL PATTERN THE; HORSCH MC, 1990, 6TH P C UNC ART INT, P155; JENSEN FV, 1988, R8825 U AALB I EL SY; JENSEN FV, 1989, R8915 U AALB I EL SY; Kanal, 1988, UNCERTAINTY ARTIFICI, P149, DOI DOI 10.1016/B978-0-444-70396-5.50019-4; KIM JH, 1983, 8TH P INT JOINT C AR, P190; LASKEY KB, 1988, 7TH P NAT C AM ART I, P210; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; LAURITZEN SL, 1988, R8821 U AALB I EL SY; MCALLESTER DA, 1982, REASONING UTILITY PA; McDermott D., 1985, INTRO ARTIFICIAL INT; Neapolitan R.E., 1990, PROBABILISTIC REASON; Norvig P., 1991, PARADIGMS ARTIFICIAL; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; SANTOS E, 1991, 7TH P C UNC AI, P339; Shachter R, 1989, 5TH P WORKSH UNC ART, P311; SHACHTER RD, 1986, OPER RES, V34, P871, DOI 10.1287/opre.34.6.871; SHIMONY S, 1991, 7TH P C UNC ART INT, P370; SHIMONY SE, 1990, 6TH P C UNC AI, P98; SPIEGELHALTER DJ, 1988, MAY P C INFL DIAGR D; SPIEGELHALTER DJ, 1990, WILEY SERIES PROBABI, P361; SRINIVAS S, 1989, IDEAL INFLUENCE DIAG; SRINIVAS S, 1990, 6TH P C UNC ART INT, P212; Verma T., 1990, READINGS UNCERTAIN R; Wellman M. P., 1992, Knowledge Engineering Review, V7, P35, DOI 10.1017/S0269888900006147	49	18	19	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1993	15	3					196	208		10.1109/34.204902	http://dx.doi.org/10.1109/34.204902			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	KT658					2022-12-18	WOS:A1993KT65800002
J	JI, LA; PIPER, J				JI, LA; PIPER, J			FAST HOMOTOPY - PRESERVING SKELETONS USING MATHEMATICAL MORPHOLOGY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						DILATION; DISTANCE TRANSFORMATION; EROSION; EUCLIDEAN DISTANCE; HOMOTOPY; INTERVAL CODING; MATHEMATICAL MORPHOLOGY; SHAPE; SKELETON; TOPOLOGY	THINNING ALGORITHMS; BINARY IMAGES; DIGITAL PICTURES; OPERATIONS	This paper describes two algorithms for skeletonization of 2-D binary images, each of which explicitly separates the two major aspects of skeletonization: 1) the identification of points critical to shape representation and 2) the identification of further points necessary to preserve homotopy. Sets of points critical to shape representation are found by eroding the original image I with a nested sequence of structuring elements E(i), where E0 = {O} and E(i) subset-of E(i+1), corresponding to a generalized distance transform. In a generalization of the "morphological skeleton," at each iteration, the set of shape-related points M(i) is defined to be I - E(i-1) \ (I - E(i)) + D, where D is a suitable small structuring element. Points needed in addition to those of M(i), in order to preserve homotopy, may be found at each iteration by a search restricted to the "shell" I - E(i-1), \ I - E(i). By choosing appropriate {E(i)} and D, either algorithm is capable of producing a variety of skeletons corresponding to different distance functions. It is proved that if E(i) + D subset-or-equal-to E(i+1), then the original image can be reconstructed from the skeleton. In the case of the first algorithm, there are few restrictions on the set of structuring elements. It uses a simple search strategy to find points whose removal would alter homotopy. Examples of its application illustrate shape, connectivity, thinness, and image reconstruction aspects of skeletonization. The second, faster, algorithm has a more constructional approach to finding points necessary for preserving homotopy, which limits it to a more restricted set of structuring elements than the first algorithm. However, it may still be used with a variety of distance functions including "city block," "chessboard," and "octagon" distances and a set of approximations to Euclidean distance where precision may be traded against computational cost. "Interval coding" of the binary images is used, resulting in computationally efficient implementations of mathematical morphology and Boolean functions, and performance data confirm that the second algorithm is amongst the fastest serial computer skeletonization algorithms.			JI, LA (corresponding author), WESTERN GEN HOSP,HUMAN GENET UNIT,MRC,PATTERN RECOGNIT & AUTOMAT SECT,EDINBURGH EH4 2XU,MIDLOTHIAN,SCOTLAND.							ARCELLI C, 1985, IEEE T PATTERN ANAL, V7, P464; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V11, P123, DOI 10.1016/0146-664X(79)90062-5; BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; BUTLER JW, 1963, DATA ACQUISITION PRO, P261; CHERRY C, 1963, P IEEE, V51, P1507, DOI 10.1109/PROC.1963.2620; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; DAVIES ER, 1981, PATTERN RECOGN, V14, P53, DOI 10.1016/0031-3203(81)90045-5; Dorst L., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P286; GROEN FCA, 1984, PATTERN RECOGN LETT, V2, P333, DOI 10.1016/0167-8655(84)90021-7; HARALICK RM, 1991, PATTERN RECOGN, V24, P69, DOI 10.1016/0031-3203(91)90117-N; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; Hilditch C J, 1983, IMAGE VISION COMPUT, V1, P115, DOI DOI 10.1016/0262-8856(83)90063-X; HILDITCH J, 1969, MACH INTELL, V4, P404; JANG BK, 1990, IEEE T PATTERN ANAL, V12, P541, DOI 10.1109/34.56190; JI L, 1989, PATTERN RECOGN LETT, V9, P201, DOI 10.1016/0167-8655(89)90055-X; JI L, 1991, TOPOLOGY PROOFS SKEL; MARAGOS PA, 1986, IEEE T ACOUST SPEECH, V34, P1228, DOI 10.1109/TASSP.1986.1164959; Matheron G., 1988, IMAGE ANAL MATH MORP, V2, P217; MEYER F, 1989, SIGNAL PROCESS, V16, P335, DOI 10.1016/0165-1684(89)90030-3; MEYER F, 1988, IMAGE ANAL MATH MORP, V2, P257; MOTTSMITH JC, 1970, PICTURE PROCESSING P, P267; PAVLIDIS T, 1980, COMPUT VISION GRAPH, V13, P142, DOI 10.1016/S0146-664X(80)80037-2; Piper J., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P1015, DOI 10.1109/ICPR.1988.28427; PIPER J, 1985, PATTERN RECOGN LETT, V3, P119, DOI 10.1016/0167-8655(85)90018-2; PIPER J, 1985, PATTERN RECOGN LETT, V3, P389, DOI 10.1016/0167-8655(85)90025-X; RAGNEMALM I, 1990, THESIS LINKOPING U L; RONSE C, 1984, RES STUDIES; ROSENFEL.A, 1966, J ACM, V13, P471; ROSENFELD A, 1970, J ACM, V17, P146, DOI 10.1145/321556.321570; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; Rutovitz D, 1968, PICTORIAL PATTERN RE, P105; SCHONFELD D, P SPIE VISUAL COMMUN, P138; Serra J, 1982, IMAGE ANAL MATH MORP; SMITH RW, 1987, PATTERN RECOGN, V20, P7, DOI 10.1016/0031-3203(87)90013-6; STEFANELLI R, 1971, J ACM, V18, P255, DOI 10.1145/321637.321646; VANVLIET LJ, 1988, PATTERN RECOGN LETT, V7, P27, DOI 10.1016/0167-8655(88)90041-4; Verwer B. J. H., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P137, DOI 10.1109/ICPR.1988.28189; Wang X, 1988, 9 INT C PATT REC, P1164; YOKOI S, 1981, IEEE T PATTERN ANAL, V4, P424; YOUNG IT, 1981, COMPUT GRAPHICS IMAG, V17, P198; ZHOU Z, 1989, P ICASSP, P1695	41	18	19	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1992	14	6					653	664		10.1109/34.141555	http://dx.doi.org/10.1109/34.141555			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HX546					2022-12-18	WOS:A1992HX54600005
J	ESPOSITO, F; MALERBA, D; SEMERARO, G				ESPOSITO, F; MALERBA, D; SEMERARO, G			CLASSIFICATION IN NOISY ENVIRONMENTS USING A DISTANCE MEASURE BETWEEN STRUCTURAL SYMBOLIC DESCRIPTIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						DISTANCE MEASURE; FLEXIBLE MATCHING; INCOMPLETE DESCRIPTIONS; LEARNING STRUCTURAL DESCRIPTIONS FROM EXAMPLES; LEARNING SYSTEMS; PATTERN CLASSIFICATION IN NOISY ENVIRONMENTS	PATTERN-RECOGNITION; GRAPHS	A definition of distance measure between structural descriptions, which is based on a probabilistic interpretation of the matching predicate, is proposed. It aims at coping with the problem of classification when noise causes both local and structural deformations. The distance measure is defined according to a top-down evaluation scheme: distance between disjunctions of conjuncts, conjunctions, and literals. At the lowest level, the similarity between a feature value in the pattern model (G) and the corresponding value in the observation (Ex) is defined as the probability of observing a greater distortion. The classification problem is approached by means of a multilayered framework in which the cases of single perfect match, no perfect match, and multiple perfect match are treated differently. Another possible application of the distance measure is in the field of concept acquisition. A plausible solution for the problem of completing the attribute and structure spaces, based on the probabilistic approach, is also given. Finally, both a comparison with other related works and an application in the domain of layout-based document recognition are illustrated.			ESPOSITO, F (corresponding author), UNIV BARI,DIPARTMENTO INFORMAT,I-70124 BARI,ITALY.		Semeraro, Giovanni/AAC-2156-2020; Malerba, Donato/H-3850-2012; Esposito, Floriana/M-6038-2019	Semeraro, Giovanni/0000-0001-6883-1853; Malerba, Donato/0000-0001-8432-4608; Esposito, Floriana/0000-0002-1075-3239				Ballard D.H., 1982, COMPUTER VISION; BARNETT V, 1973, COMP STATISTICAL INF; BERGADANO F, 1988, IEEE T PATTERN ANAL, V10, P555, DOI 10.1109/34.3917; Bobrow D., 1975, REPRESENTATION UNDER, P1; CHAN LS, 1972, J AM STAT ASSOC, V67, P473, DOI 10.2307/2284409; ESHERA MA, 1984, IEEE T SYST MAN CYB, V14, P398, DOI 10.1109/TSMC.1984.6313232; ESPOSITO F, 1990, 10TH P ICPR, P557; Garey M.R., 1979, COMPUTERS INTRACTABI; Hand D. J, 1981, WILEY SERIES PROBABI; HAYESROTH B, 1978, PATTERN DIRECTED INF, P333; KODRATOFF Y, 1988, IEEE T PATTERN ANAL, V10, P897, DOI 10.1109/34.9111; LARSON JB, 1977, THESIS U ILLINOIS DE; MICHALSKI RS, 1980, IEEE T PATTERN ANAL, V2, P349, DOI 10.1109/TPAMI.1980.4767034; MICHALSKI RS, 1987, 4TH P INT WORKSH MAC; MICHALSKI RS, 1974, 1974 P INT S MULT VA; MICHALSKI RS, 1969, 5 P INT S INF PROC F, V3; Michalski RS, 1986, AQ15 INDUCTIVE LEARN; MICHALSKI RS, 1982, MACHINE INTELLIGENCE; MICHALSKI RS, 1978, UIUCDCSR78867 U ILL; QUINLAN JR, 1986, MACHINE LEARNING ART, V2; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175; SHAPIRO LG, 1985, IEEE T PATTERN ANAL, V2, P90; STEPP R, 1984, UIUCDCSR841189 U ILL; STEPP RE, 1987, 4TH P INT WORKSH MAC; THOMASON MG, 1987, PATTERN RECOGNITION; TSAI WH, 1983, IEEE T SYST MAN CYB, V13, P48, DOI 10.1109/TSMC.1983.6313029; WINSTON PH, 1984, ARTIF INTELL, P391; WONG AKC, 1985, IEEE T PATTERN ANAL, V7, P599, DOI 10.1109/TPAMI.1985.4767707	28	18	18	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1992	14	3					390	402		10.1109/34.120333	http://dx.doi.org/10.1109/34.120333			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HF732		Green Submitted			2022-12-18	WOS:A1992HF73200008
J	CHOE, Y; KASHYAP, RL				CHOE, Y; KASHYAP, RL			3-D SHAPE FROM A SHADED AND TEXTURAL SURFACE IMAGE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						FRACTIONAL DIFFERENCING PERIODIC MODEL; ORTHOGRAPHICAL PROJECTION; SHAPE FROM SHADING; SHAPE-FROM-TEXTURE	LOCAL SHADING ANALYSIS; ORIENTATION	To recover 3-D structure from a natural scene image involving textures, neither the shape-from-shading nor the shape-from-texture analysis is enough because both radiance and texture information coexist within the surface of a natural scene. A new 3-D texture model is developed by considering the scene image as the superposition of a random texture image and a smooth shaded image. The whole image is analyzed using a patch-by-patch process. Each patch is assumed to be a tilted and slanted texture plane. A modified reflectance map function is applied to describe the deterministic part, and the fractional differencing periodic model is chosen to describe the random texture because of its good performance in texture synthesis and its ability to represent the coarseness and the pattern of the surface at the same time. An orthographical projection technique is developed to deal with this particular random model, which has a nonisotropically distributed texture pattern. For estimating the parameter, a hybrid method that uses both the least square and the maximum likelihood estimates is applied directly to the given intensity function. By using these paramters, the synthesized image is obtained and used to reconstruct the original image. The contribution of this research will be in combining shape-from-shading and shape-from-texture techniques to extract 3-D structure and texture pattern features from a single natural scene image that contains both shade and texture in it.	PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907	Purdue University System; Purdue University; Purdue University West Lafayette Campus								BOX GEP, 1969, TIME SERIES ANAL; Brillinger D.R., 1981, TIME SERIES DATA ANA; EOM KB, 1986, THESIS PURDUE U W LA; FERRIE FP, 1989, IEEE T PATTERN ANAL, V11, P198, DOI 10.1109/34.16715; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; Horn B.K.P., 1989, SHAPE SHADING; HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3; HOSKING JRM, 1981, BIOMETRIKA, V68, P165, DOI 10.1093/biomet/68.1.165; KANATANI K, 1984, ARTIF INTELL, V23, P213, DOI 10.1016/0004-3702(84)90010-9; KANG H, 1977, IEEE T CIRCUITS SYST, V24, P281; KASHYAP RL, 1989, IEEE T PATTERN ANAL, V11, P58, DOI 10.1109/34.23113; KASHYAP RL, 1984, IEEE T PATTERN ANAL, V6, P800, DOI 10.1109/TPAMI.1984.4767604; KASHYAP RL, 1988, J TIME SER ANAL, V9, P35; KASHYAP RL, 1986, HDB PATTERN RECOGNIT, P281; KENDER JR, 1979, 6 IJCAI TOK, P475; LEE CH, 1985, ARTIF INTELL, V26, P125, DOI 10.1016/0004-3702(85)90026-8; MANDELBROT BB, 1968, SIAM REV, V10, P422, DOI 10.1137/1010093; PENTLAND A, 1988, IEEE T PATTERN ANAL, V10, P704; PENTLAND AP, 1986, ARTIF INTELL, V29, P147, DOI 10.1016/0004-3702(86)90017-2; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P170, DOI 10.1109/TPAMI.1984.4767501; PENTLAND AP, 1982, J OPT SOC AM, V72, P448, DOI 10.1364/JOSA.72.000448; STEVENS KA, 1981, ARTIF INTELL, V18, P47; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9	24	18	20	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1991	13	9					907	919		10.1109/34.93809	http://dx.doi.org/10.1109/34.93809			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GJ180					2022-12-18	WOS:A1991GJ18000005
J	KROTKOV, E; HENRIKSEN, K; KORIES, R				KROTKOV, E; HENRIKSEN, K; KORIES, R			STEREO RANGING WITH VERGING CAMERAS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									UNIV PENN,GRASP LAB,PHILADELPHIA,PA 19104	University of Pennsylvania				Krotkov, Eric/0000-0001-9726-3920				AYACHE N, 1987, INT J COMPUT VISION, V1, P107, DOI 10.1007/BF00123161; BARNARD ST, 1982, COMPUT SURV, V14, P553, DOI 10.1145/356893.356896; BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808; DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067; FAUGERAS OD, 1986, JUN P IEEE C COMP VI, P15; HENRIKSEN K, 1986, 861010 U COP DEP COM; KROTKOV E, 1988, IEEE T ROBOTIC AUTOM, V4, P108, DOI 10.1109/56.782; KROTKOV E, 1987, INT J COMPUT VISION, V1, P223, DOI 10.1007/BF00127822; Krotkov EP, 1989, ACTIVE COMPUTER VISI; SUTHERLAND IE, 1974, P IEEE, V62, P453, DOI 10.1109/PROC.1974.9449; TSAI R, 1987, IEEE J ROBOTICS A RA, V3; YAKIMOVSKY Y, 1978, COMPUT VISION GRAPH, V7, P195, DOI 10.1016/0146-664X(78)90112-0	12	18	22	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1990	12	12					1200	1205		10.1109/34.62610	http://dx.doi.org/10.1109/34.62610			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EN500					2022-12-18	WOS:A1990EN50000009
J	FAHN, CS; WANG, JF; LEE, JY				FAHN, CS; WANG, JF; LEE, JY			AN ADAPTIVE REDUCTION PROCEDURE FOR THE PIECEWISE LINEAR-APPROXIMATION OF DIGITIZED-CURVES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											FAHN, CS (corresponding author), NATL CHENG KUNG UNIV,DEPT ELECT ENGN,CAD LAB,TAINAN 70101,TAIWAN.							BADII F, 1982, INT J SYST SCI, V13, P667, DOI 10.1080/00207728208926377; DUNHAM JG, 1986, IEEE T PATTERN ANAL, V8, P67, DOI 10.1109/TPAMI.1986.4767753; FAHN CS, 1989, THESIS NAT CHENG KUN; PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041; PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029; PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6; PAVLIDIS T, 1982, ALGORITHMS GRAPHICS, P281; Ramer U, 1972, COMPUT GRAPH IMAGE P, V1, P244, DOI [DOI 10.1016/S0146-664X(72)80017-0, 10.1016/S0146-664X(72)80017-0]; Reumann K., 1973, P INT COMP S, P467; ROBERGE J, 1985, COMPUT VISION GRAPH, V29, P168, DOI 10.1016/0734-189X(85)90117-3; SKLANSKY J, 1980, PATTERN RECOGN, V12, P327, DOI 10.1016/0031-3203(80)90031-X; WALL K, 1984, COMPUT VISION GRAPH, V28, P220, DOI 10.1016/S0734-189X(84)80023-7; WILLIAMS CM, 1978, COMPUT VISION GRAPH, V8, P286, DOI 10.1016/0146-664X(78)90055-2	13	18	23	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1989	11	9					967	973		10.1109/34.35499	http://dx.doi.org/10.1109/34.35499			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AM008					2022-12-18	WOS:A1989AM00800006
J	CYPHER, R; SANZ, JLC; SNYDER, L				CYPHER, R; SANZ, JLC; SNYDER, L			AN EREW PRAM ALGORITHM FOR IMAGE COMPONENT LABELING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									IBM CORP,ALMADEN RES CTR,DEPT COMP SCI,SAN JOSE,CA 95114	International Business Machines (IBM)	CYPHER, R (corresponding author), UNIV WASHINGTON,DEPT COMP SCI,SEATTLE,WA 98195, USA.							AGRAWAL A, 1987 P INT C PAR PRO, P783; AGRAWALA AK, 1977, COMPUT VISION GRAPH, V6, P538, DOI 10.1016/S0146-664X(77)80015-4; ATALLAH M, 1984, J COMPUT SYST SCI, V29, P330, DOI 10.1016/0022-0000(84)90003-5; Atallah M. J., 1985, 26th Annual Symposium on Foundations of Computer Science (Cat. No.85CH2224-4), P222, DOI 10.1109/SFCS.1985.53; COLE R, 1986, P 27 ANN IEEE S FDN, P478; CYPHER R, 1987 P INT C PAR PRO; CYPHER R, UNPUB PARALLEL ALGOR; CYPHER R, IN PRESS J ALGORITHM; CYPHER R, 1987 IEEE COMP SOC W; HIRSCHBERG DS, 1979, COMMUN ACM, V22, P461, DOI 10.1145/359138.359141; HUMMEL R, 1986, INTERMEDIATE LEVEL I, P101; HUMMEL R, 1985, IEEE COMP SOC WORKSH; HUNG Y, 1987, CARTR278 U MARYL CEN; KUMAR VKP, 1986 P INT C PAR PRO, P270; LIM Y, 1986, 8622 THINK MACH CORP; Miller G. L., 1985, 26th Annual Symposium on Foundations of Computer Science (Cat. No.85CH2224-4), P478, DOI 10.1109/SFCS.1985.43; MILLER R, 1987, SIAM J COMPUT, V16, P38, DOI 10.1137/0216004; MILLER R, 1985 P INT C PAR PRO, P697; NASSIMI D, 1980, SIAM J COMPUT, V9, P744, DOI 10.1137/0209058; Rosenfeld A., 1982, DIGITAL PICTURE PROC, V1; ROSENFELD A, 1983, IEEE COMPUT      JAN, P14; SANZ JL, 1987, IEEE T PATTERN ANAL; SHILOACH Y, 1982, J ALGORITHM, V3, P57, DOI 10.1016/0196-6774(82)90008-6; STOUT QF, 1985 IEEE COMP SOC W, P203; Tanimoto S. L., 1986, Intermediate-level image processing, P3; Tarjan R. E., 1984, 25th Annual Symposium on Foundations of Computer Science (Cat. No. 84CH2085-9), P12, DOI 10.1109/SFCS.1984.715896; VEILLON F, 1979, SIGNAL PROCESS, V1, P175, DOI 10.1016/0165-1684(79)90018-5; VISHKIN U, 1983, 69 NEW YORK U COMP S; WYLLIE JC, 1981, THESIS CORNELL U ITH	29	18	19	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1989	11	3					258	262		10.1109/34.21794	http://dx.doi.org/10.1109/34.21794			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	T3840					2022-12-18	WOS:A1989T384000005
J	DHOME, M; KASVAND, T				DHOME, M; KASVAND, T			POLYHEDRA RECOGNITION BY HYPOTHESIS ACCUMULATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											DHOME, M (corresponding author), UNIV CLERMONT FERRAND 2,ELECTR LAB,CEZEAUX,BP 45,F-63170 AUBIERE,FRANCE.							BAJCSY R, 1980, 5TH P INT C PATT REC, P1064; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BESL PJ, 1985, COMPUT SURV, V17, P75, DOI 10.1145/4078.4081; BOLLES RC, 1984, AUG P INT S ROB RES; BRADY M, 1985, 2ND P INT C ROB RES, P6; DHOME M, 1985, POLYHEDRA RECOGNITIO; DHOME M, 1985, JUN P PATT REC PRACT, V2; FAUGERAS OD, 1983, 8TH P INT JOINT C AR, P996; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; GRIMSON WEL, 1985, MAR P C ROB AUT ST L, P61; HAKALAHTI H, 1984, PATTERN RECOGN LETT, V2, P227, DOI 10.1016/0167-8655(84)90029-1; HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7; Hart P. E, 1973, PATTERN CLASSIFICATI; HEBERT M, 1982, 6TH P INT C PATT REC, P836; Henderson T.C., 1982, P WORKSHOP IND APPLI, P181; HENDERSON TC, 1984, PATTERN RECOGN LETT, V2, P235, DOI 10.1016/0167-8655(84)90030-8; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; ITTNER DJ, 1985, JUN P COMP VIS PATT, P119; KASVAND T, 1985, 4TH P CAN CADCAM ROB; OKA R, 1985, JUN P COMP VIS PATT, P470; OSHIMA M, 1983, IEEE T PATTERN ANAL, V5, P352; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; RIOUX M, 1984, APPL OPTICS, V23, P3837, DOI 10.1364/AO.23.003837; SILBERBERG TM, 1984, PATTERN RECOGN, V17, P621, DOI 10.1016/0031-3203(84)90015-3; SUGIHARA K, 1979, ARTIF INTELL, V12, P41, DOI 10.1016/0004-3702(79)90004-3; TANAKA HT, 1985, JUN P C COMP VIS PAT, P491; WONG AKC, 1985, JUN P COMP VIS PATT, P162	27	18	18	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1987	9	3					429	438		10.1109/TPAMI.1987.4767924	http://dx.doi.org/10.1109/TPAMI.1987.4767924			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	H0768	22516635				2022-12-18	WOS:A1987H076800007
J	MITCHELL, TM; STEINBERG, LI; SHULMAN, JS				MITCHELL, TM; STEINBERG, LI; SHULMAN, JS			A KNOWLEDGE-BASED APPROACH TO DESIGN	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									RUTGERS STATE UNIV,COMP SCI RES LAB,NEW BRUNSWICK,NJ 08903; RUTGERS STATE UNIV,CTR COMP AIDS IND PROD,NEW BRUNSWICK,NJ 08903	Rutgers State University New Brunswick; Rutgers State University New Brunswick	MITCHELL, TM (corresponding author), RUTGERS STATE UNIV,DEPT COMP SCI,AI VLSI PROJECT,NEW BRUNSWICK,NJ 08903, USA.							BROWN DC, 1984, SEP P IFIP WG5 2 WOR; DARRINGER JA, 1980, RC826834648 IBM CORP; FORGY C, 1977, 5TH P INT JOINT C AR, P933; KELLY VE, 1984, 21ST P DES AUT C, P419; KIM J, 1983, 1983 P NATL C ART IN, P197; KOWALSKI TJ, 1983, 20TH P DES AUT C, P479; MCDERMOTT J, 1982, ARTIF INTELL, V19, P39, DOI 10.1016/0004-3702(82)90021-2; MITCHELL T, 1984, AIVLSI16 RUTG U DEP; ROACH JA, 1984, 21ST P ACM IEEE DES, P405; Stefik M. J., 1980, THESIS STANFORD U ST; STEINBERG L, 1984, 21ST P ACM IEEE DES, P412; TONG C, 1985, THESIS STANFORD U ST; TONG C, 1984, ONTOLOGY DESIGNING C; VANMELLE W, 1980, STANCS80820 STANF U; WEISS S, 1979, EXPERT SYSTEM DEV CO	15	18	18	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	5					502	510		10.1109/TPAMI.1985.4767698	http://dx.doi.org/10.1109/TPAMI.1985.4767698			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AQH94	21869288				2022-12-18	WOS:A1985AQH9400002
J	BIRMAN, KP				BIRMAN, KP			RULE-BASED LEARNING FOR MORE ACCURATE ECG ANALYSIS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV CALIF BERKELEY,DEPT ELECT ENGN & COMP SCI,DIV COMP SCI,BERKELEY,CA 94720	University of California System; University of California Berkeley								ANDERSON CM, 1980, OCT P COMP CARD VA; BALZER R, 1980, 1ST P ANN C ART INT, P108; BELFORTE G, 1979, IEEE T BIO-MED ENG, V26, P125, DOI 10.1109/TBME.1979.326470; BIGGER JT, 1980, HEART DISEASE TXB CA, P630; BIRMAN KP, 1981, THESIS U CALIFORNIA; BIRMAN KP, 1978, P COMPUT CARDIOLOGY, P217; BONNER R E, 1970, P455; BRAGGREMSCHEL DA, 1980, OCT P COMP CARD VA; Brillinger D.R., 1981, TIME SERIES DATA ANA; Buchanan B. G., 1969, MACH INTELL, V4, P209; CLARK KW, 1980, OCT P COMP CARD VA; COX JR, 1968, IEEE T BIO-MED ENG, VBM15, P128, DOI 10.1109/TBME.1968.4502549; ENGELMORE RS, 1977, HPP772 STANF U HEUR; FU KS, 1975, IEEE T SYST MAN CYBE, V5; Harrison M. A., 1978, INTRO FORMAL LANGUAG; HAYESROTH F, 1978, PATTERN DIRECTED INF, P557; HORROWITZ S, 1975, COMMUN ASS COMPUT MA, V18, P281; JOSKOWICZ G, P COMPUT CARDIOLOGY, P277; KANAL LN, 1972, P IEEE, V60, P1200, DOI 10.1109/PROC.1972.8880; MEAD C, 1978, P COMPUT CARDIOLOGY, P343; NOLLE FM, 1972, THESIS WASHINGTON U; PAVLIDIS T, 1971, SOFTWARE ENG, V4, P203; STOCKMAN G, 1976, COMMUN ASS COMPUT MA, V19, P690; Winston PH, 1975, PSYCHOL COMPUTER VIS, P157	24	18	20	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	4					369	380		10.1109/TPAMI.1982.4767268	http://dx.doi.org/10.1109/TPAMI.1982.4767268			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NT735	21869051				2022-12-18	WOS:A1982NT73500003
J	GURARI, EM; WECHSLER, H				GURARI, EM; WECHSLER, H			ON THE DIFFICULTIES INVOLVED IN THE SEGMENTATION OF PICTURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV MINNESOTA, DEPT ELECT ENGN, MINNEAPOLIS, MN 55455 USA	University of Minnesota System; University of Minnesota Twin Cities	GURARI, EM (corresponding author), SUNY BUFFALO, DEPT COMP SCI, BUFFALO, NY 14260 USA.							[Anonymous], 1931, MONATSHEFTE MATH PHY, DOI DOI 10.1007/BF01700692; FAUGERAS OD, 1981, DIGITAL IMAGE PROCES; FOWLER R, 1980, TR800502 U WASH DEP; Garey M.R., 1979, GUIDE THEORY NP COMP; HANSON AR, 1981, DIGITAL IMAGE PROCES; HARALICK RM, 1980, IEEE T PATTERN ANAL, V2, P193, DOI 10.1109/TPAMI.1980.4767007; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; Hilbert D., 1902, B AM MATH SOC, V8, P437, DOI [DOI 10.1090/S0002-9904-1902-00923-3, 10.1090/S0002-9904-1902-00923-3]; HILBERT D, 1900, NACHRICHTEN KONIGLIC, P253; Hopcroft JE, 1978, INTRO AUTOMATA THEOR; Matijasevi Y V, 1970, DOKL AKAD NAUK, V29, P279; Pavlidis T., 1977, STRUCTURAL PATTERN R; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; TENEBAUM JM, 1978, SRI TR175 INT; WECHSLER H, 1980, SIGNAL PROCESS, V2, P271, DOI 10.1016/0165-1684(80)90024-9	16	18	18	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	3					304	306		10.1109/TPAMI.1982.4767247	http://dx.doi.org/10.1109/TPAMI.1982.4767247			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NN069	21869037				2022-12-18	WOS:A1982NN06900008
J	LEE, ET				LEE, ET			FUZZY TREE AUTOMATA AND SYNTACTIC PATTERN-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											LEE, ET (corresponding author), MEMPHIS STATE UNIV,DEPT MATH SCI,MEMPHIS,TN 38152, USA.							[Anonymous], 1975, FUZZY SETS THEIR APP, DOI DOI 10.1016/B978-0-12-775260-0.50021-9; CHANG SSL, 1972, IEEE T SYST MAN CYB, VSMC2, P30, DOI 10.1109/TSMC.1972.5408553; Chen C., 1976, PATTERN RECOGN; Fu K. S., 1971, J CYBERNETICS, V1, P31, DOI 10.1080/01969727108548630; Fu K.S., 1974, MATH SCI ENG; FU KS, 1973, IEEE T COMPUT, VC 22, P1087, DOI 10.1109/T-C.1973.223654; FU KS, 1975, DIGITAL PATTERN RECO; FU KS, 1976, SYNTACTIC METHODS PA; FU KS, 1979, PICTORIAL INFORMATIO; KIRSCH RA, 1964, IEEE T COMPUT, VEC13, P363, DOI 10.1109/PGEC.1964.263816; KROENKE D, 1977, DATABASE PROCESSING; Lee E. T., 1980, Pictorial information systems, P128; Lee E. T., 1972, Journal of Cybernetics, V2, P43, DOI 10.1080/01969727208545857; LEE ET, 1976, B MATH BIOL, V38, P505, DOI 10.1007/BF02459549; LEE ET, 1974, PATTERN RECOGN, V6, P47, DOI 10.1016/0031-3203(74)90007-7; LEE ET, 1975, IEEE T SYST MAN CYB, V5, P629; LEE ET, 1969, INFORM SCIENCES, V1, P421, DOI 10.1016/0020-0255(69)90025-5; LEE ET, 1972, THESIS U CALIFORNIA; LEE ET, 1976, NOV P S CURR PROBL I; LEE ET, 1977, POLICY ANAL INFORM S, V1, P113; LEE ET, 1977, POLICY ANAL INFORMAT, V1, P127; LEE ET, 1976, NOV P INT JOINT C PA, P8; Pavlidis T., 1977, STRUCTURAL PATTERN R; RABIN MO, 1959, IBM J RES DEV, V3, P114, DOI 10.1147/rd.32.0114; Rosenfeld A., 1976, DIGITAL PICTURE ANAL; ROSENFELD A, 1976, TR433 U MAR; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SKLANSKY J, 1975, TP7510 U CAL; THATCHER JW, 1970, P 4 ANN PRINC C INF, P263; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; 1978, 1978 P PATT REC IM P; [No title captured]	32	18	18	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	4					445	449		10.1109/TPAMI.1982.4767279	http://dx.doi.org/10.1109/TPAMI.1982.4767279			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NT735	21869062				2022-12-18	WOS:A1982NT73500014
J	TANG, GY				TANG, GY			A DISCRETE VERSION OF GREENS THEOREM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									SUNY BUFFALO,DEPT ELECT ENGN,BUFFALO,NY 14260	State University of New York (SUNY) System; State University of New York (SUNY) Buffalo								Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; KREYSZIG E, 1962, ADV ENG MATH, P313; MERRILL RD, 1973, COMMUN ACM, V16, P69, DOI 10.1145/361952.361956; ROSENFELD A, 1970, J ACM, V17, P146, DOI 10.1145/321556.321570; ROSENFELD A, 1973, J ACM, V20, P81, DOI 10.1145/321738.321745	5	18	23	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	3					242	249		10.1109/TPAMI.1982.4767241	http://dx.doi.org/10.1109/TPAMI.1982.4767241			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NN069	21869031				2022-12-18	WOS:A1982NN06900002
J	WALLACE, TP; MITCHELL, OR; FUKUNAGA, K				WALLACE, TP; MITCHELL, OR; FUKUNAGA, K			3-DIMENSIONAL SHAPE-ANALYSIS USING LOCAL SHAPE DESCRIPTORS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									PURDUE UNIV,SCH ELECT ENGN,INFORMAT & SIGNAL PROC LAB,W LAFAYETTE,IN 47907	Purdue University System; Purdue University; Purdue University West Lafayette Campus			Rohlf, F J/A-8710-2008					BRONS R, 1974, COMPUT GRAPHICS IMAG, V3, P48; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; DAVIS LS, 1977, IEEE T C, V26, P297; DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; Fu K.S., 1974, MATH SCI ENG; GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926; HOROWITZ SL, 1975, COMMUN ACM, V18, P281, DOI 10.1145/360762.360810; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; MCKEE JW, 1977, IEEE T COMPUT, V26, P790, DOI 10.1109/TC.1977.1674917; PAVLIDIS T, 1979, IEEE T PATTERN ANAL, V1, P2, DOI 10.1109/TPAMI.1979.4766870; PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041; PAVLIDIS T, 1973, IEEE T COMPUT, VC 22, P689, DOI 10.1109/TC.1973.5009136; PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6; PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681; RICHARD CW, 1974, IEEE T SYST MAN CYB, VSMC4, P371, DOI 10.1109/TSMC.1974.5408458; ROSENFELD A, 1974, IEEE T COMPUT, VC 23, P1264, DOI 10.1109/T-C.1974.223845; STOCKMAN G, 1976, COMMUN ACM, V19, P688, DOI 10.1145/360373.360378; WALLACE T, COMPUT GRAPHICS IMAG; WALLACE TP, 1979, THESIS PURDUE U W LA; WALLACE TP, 1979, AUG P IEEE PATT REC; YOU KC, 1979, IEEE T SYST MAN CYB, V9, P334, DOI 10.1109/TSMC.1979.4310222; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	24	18	18	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	3					310	323		10.1109/TPAMI.1981.4767104	http://dx.doi.org/10.1109/TPAMI.1981.4767104			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MN969	21868952				2022-12-18	WOS:A1981MN96900008
J	YACHIDA, M; IKEDA, M; TSUJI, S				YACHIDA, M; IKEDA, M; TSUJI, S			A PLAN-GUIDED ANALYSIS OF CINEANGIOGRAMS FOR MEASUREMENT OF DYNAMIC BEHAVIOR OF HEART WALL	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											YACHIDA, M (corresponding author), OSAKA UNIV,FAC ENGN SCI,DEPT CONTROL ENGN,OSAKA,JAPAN.							CHOW CK, 1972, FRONTIERS PATTERN RE; DEJONG LP, 1975, IEEE T BIO-MED ENG, VBM22, P230, DOI 10.1109/TBME.1975.324487; HARLOW CA, 1973, IEEE T COMPUT, VC 22, P678, DOI 10.1109/TC.1973.5009135; KANEKO T, 1973, IEEE T BIO-MED ENG, VBM20, P413, DOI 10.1109/TBME.1973.324213; KELLY M, 1970, 121 STANF U ART INT; MARTELLI A, 1976, COMMUN ACM, V19, P73, DOI 10.1145/359997.360004; MONTANARI U, 1971, COMMUN ACM, V14, P335, DOI 10.1145/362588.362594; RACKLEY CE, 1976, CIRCULATION, V54, P862, DOI 10.1161/01.CIR.54.6.862; TASTO M, 1974, IEEE T BIO-MED ENG, VBM21, P207, DOI 10.1109/TBME.1974.324383	9	18	18	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	6					537	543		10.1109/TPAMI.1980.6447700	http://dx.doi.org/10.1109/TPAMI.1980.6447700			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KS962					2022-12-18	WOS:A1980KS96200006
J	EKLUNDH, JO; ROSENFELD, A				EKLUNDH, JO; ROSENFELD, A			PEAK DETECTION USING DIFFERENCE OPERATORS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									NATL DEF RES INST,STOCKHOLM,SWEDEN									DAVIS LS, 1977, 568 U MAR COMP SCI C; EHRICH RW, 1976, IEEE T COMPUT, V25, P725, DOI 10.1109/TC.1976.1674681; EHRICH RW, UNPUBLISHED; EKLUNDH JO, 1978, 651 U MAR COMP SCI C; HOROWITZ SL, 1975, COMMUN ACM, V18, P281, DOI 10.1145/360762.360810; HOROWITZ SL, 1974, 2ND P INT JOINT C PA, P465; HOROWITZ SL, 1977, SYNTACTIC PATTERN RE, P31; LOZANOPEREZ T, 1975, AI329 MASS I TECH ME; PAVLIDIS T, 1973, IEEE T COMPUT, VC 22, P689, DOI 10.1109/TC.1973.5009136; PAVLIDIS T, 1971, SOFTWARE ENGINEERING, V2, P203; SANKAR PV, 1979, IEEE T PATTERN ANAL, V1, P73, DOI 10.1109/TPAMI.1979.4766877; STOCKMAN GC, 1976, COMMUN ASS COMPUT MA, V19, P638; STOCKMAN GC, 1977, 531 U MAR COMP SCI C; STOCKMAN GC, 1973, P INT JOINT C PATTER, P236	14	18	25	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	3					317	325		10.1109/TPAMI.1979.4766930	http://dx.doi.org/10.1109/TPAMI.1979.4766930			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC301	21868865				2022-12-18	WOS:A1979HC30100012
J	Luo, X; Wu, H; Wang, Z; Wang, JJ; Meng, DY				Luo, Xin; Wu, Hao; Wang, Zhi; Wang, Jianjun; Meng, Deyu			A Novel Approach to Large-Scale Dynamically Weighted Directed Network Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Tensors; Computational modeling; Numerical models; Data models; Convergence; Analytical models; Adaptation models; Dynamically weighted directed network; terminal interaction pattern analysis system; latent factorization of tensors; high dimensional and incomplete tensor; link prediction; representation learning; latent feature	FACTORIZATION; EFFICIENT; ALGORITHM; TENSORS; MODEL	A dynamically weighted directed network (DWDN) is frequently encountered in various big data-related applications like a terminal interaction pattern analysis system (TIPAS) concerned in this study. It consists of large-scale dynamic interactions among numerous nodes. As the involved nodes increase drastically, it becomes impossible to observe their full interactions at each time slot, making a resultant DWDN High Dimensional and Incomplete (HDI). An HDI DWDN, in spite of its incompleteness, contains rich knowledge regarding involved nodes' various behavior patterns. To extract such knowledge from an HDI DWDN, this paper proposes a novel Alternating direction method of multipliers (ADMM)-based Nonnegative Latent-factorization of Tensors (ANLT) model. It adopts three-fold ideas: a) building a data density-oriented augmented Lagrangian function for efficiently handling an HDI tensor's incompleteness and nonnegativity; b) splitting the optimization task in each iteration into an elaborately designed subtask series where each one is solved based on the previously solved ones following the ADMM principle to achieve fast convergence; and c) theoretically proving that its convergence is guaranteed with its efficient learning scheme. Experimental results on six DWDNs from real applications demonstrate that the proposed ANLT outperforms state-of-the-art models significantly in both computational efficiency and prediction accuracy for missing links of an HDI DWDN. Hence, this study proposes a novel and efficient approach to large-scale DWDN representation.	[Luo, Xin; Wu, Hao] Chongqing Univ Posts & Telecommun, Sch Comp Sci & Technol, Chongqing 400065, Peoples R China; [Luo, Xin; Wu, Hao] Chinese Acad Sci, Chongqing Inst Green & Intelligent Technol, Chongqing 400714, Peoples R China; [Wang, Zhi] Southwest Univ, Coll Comp & Informat Sci, Chongqing 400715, Peoples R China; [Wang, Jianjun] Southwest Univ, Sch Math & Stat, Chongqing 400715, Peoples R China; [Meng, Deyu] Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Shaanxi, Peoples R China; [Meng, Deyu] Macau Univ Sci & Technol, Fac Informat Technol, Macau 999078, Peoples R China	Chongqing University of Posts & Telecommunications; Chinese Academy of Sciences; Chongqing Institute of Green & Intelligent Technology, CAS; Southwest University - China; Southwest University - China; Xi'an Jiaotong University; Macau University of Science & Technology	Meng, DY (corresponding author), Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Shaanxi, Peoples R China.	luoxin21@gmail.com; wuhaoxy@cigit.ac.cn; chiw@swu.edu.cn; wjj@swu.edu.cn; dymeng@mail.xjtu.edu.cn		Wu, Hao/0000-0002-4138-1239	National Key R&D Program of China [2020YFA0713900]; National Natural Science Foundation of China [61772493]; Natural Science Foundation of Chongqing (China) [cstc2019jcyjjqX0013]; CAAIHuawei MindSpore Open Fund [CAAIXSJLJJ-2020-004B, CAAIXSJLJJ-2021-035A]; Pioneer Hundred Talents Program of Chinese Academy of Sciences; Macao Science and Technology Development Fund [061/2020/A2]	National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Chongqing (China)(Natural Science Foundation of Chongqing); CAAIHuawei MindSpore Open Fund; Pioneer Hundred Talents Program of Chinese Academy of Sciences; Macao Science and Technology Development Fund	This work was supported by the National Key R&D Program of China under Grant 2020YFA0713900, National Natural Science Foundation of China under Grant 61772493, Natural Science Foundation of Chongqing (China) under Grant cstc2019jcyjjqX0013, CAAIHuawei MindSpore Open Fund under Grants CAAIXSJLJJ-2020-004B and CAAIXSJLJJ-2021-035A, Pioneer Hundred Talents Program of Chinese Academy of Sciences, and Macao Science and Technology Development Fund under Grant 061/2020/A2.	Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99; Arute F, 2019, NATURE, V574, P505, DOI 10.1038/s41586-019-1666-5; Bhanu M, 2021, IEEE T INTELL TRANSP, V22, P3359, DOI 10.1109/TITS.2020.2984175; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Boyd S, 2004, CONVEX OPTIMIZATION; Butun E, 2020, IEEE T CYBERNETICS, V50, P4518, DOI 10.1109/TCYB.2019.2900495; Fan HY, 2021, IEEE T PATTERN ANAL, V44, P4125, DOI 10.1109/TPAMI.2021.3059313; Friedland S, 2014, IEEE T IMAGE PROCESS, V23, P4438, DOI 10.1109/TIP.2014.2348796; Gao SC, 2019, IEEE T NEUR NET LEAR, V30, P601, DOI 10.1109/TNNLS.2018.2846646; Gligorijevic V, 2019, IEEE T PATTERN ANAL, V41, P928, DOI 10.1109/TPAMI.2018.2821146; Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754; Guo SN, 2022, IEEE T KNOWL DATA EN, V34, P5415, DOI 10.1109/TKDE.2021.3056502; Hajinezhad D, 2016, INT CONF ACOUST SPEE, P4742, DOI 10.1109/ICASSP.2016.7472577; He XN, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P639, DOI 10.1145/3397271.3401063; Huang KM, 2014, IEEE T AUTOM SCI ENG, V11, P906, DOI 10.1109/TASE.2013.2297026; Ioannidis VN, 2021, IEEE T KNOWL DATA EN, V33, P909, DOI 10.1109/TKDE.2019.2941716; Ji YW, 2019, IEEE ACCESS, V7, P162950, DOI 10.1109/ACCESS.2019.2949814; Jiang SH, 2020, IEEE T PATTERN ANAL, V42, P1097, DOI 10.1109/TPAMI.2019.2894137; Jin C, 2017, PR MACH LEARN RES, V70; Koren Y, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P447; Li LX, 2014, IEEE T NEUR NET LEAR, V25, P1855, DOI 10.1109/TNNLS.2013.2296627; Li MZ, 2021, IEEE T COMPUT SOC SY, V8, P308, DOI 10.1109/TCSS.2021.3050397; Li S, 2018, IEEE ACCESS, V6, P77716, DOI 10.1109/ACCESS.2018.2883939; Liu YY, 2021, IEEE T PATTERN ANAL, V43, P4242, DOI 10.1109/TPAMI.2020.3000512; Liu YY, 2016, IEEE T NEUR NET LEAR, V27, P2551, DOI 10.1109/TNNLS.2015.2496858; Lu CY, 2020, IEEE T PATTERN ANAL, V42, P925, DOI 10.1109/TPAMI.2019.2891760; Luo X, 2021, IEEE-CAA J AUTOMATIC, V8, P402, DOI 10.1109/JAS.2020.1003396; Luo X, 2020, IEEE T KNOWL DATA EN, V34, P3958, DOI 10.1109/TKDE.2020.3033324; Luo X, 2020, IEEE T CYBERNETICS, V50, P1798, DOI 10.1109/TCYB.2019.2903736; Luo X, 2020, IEEE T CYBERNETICS, V50, P1844, DOI 10.1109/TCYB.2019.2894283; Luo X, 2018, IEEE T IND INFORM, V14, P2011, DOI 10.1109/TII.2017.2766528; Luo X, 2018, IEEE T CYBERNETICS, V48, P1216, DOI 10.1109/TCYB.2017.2685521; Lyu X, 2020, IEEE T PATTERN ANAL, V42, P2024, DOI 10.1109/TPAMI.2019.2907679; Malik O. A., 2021, PROC SIAM INT C DATA, P729; Martinez V, 2017, ACM COMPUT SURV, V49, DOI 10.1145/3012704; Massin R, 2017, IEEE T WIREL COMMUN, V16, P3940, DOI 10.1109/TWC.2017.2690419; Meng L, 2016, IEEE T NETW SCI ENG, V3, P32, DOI 10.1109/TNSE.2016.2523798; Narayanam R, 2011, IEEE T AUTOM SCI ENG, V8, P130, DOI 10.1109/TASE.2010.2052042; Newman MEJ, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.016131; Pareja A, 2020, AAAI CONF ARTIF INTE, V34, P5363; Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732; Seifikar M, 2020, IEEE T COMPUT SOC SY, V7, P308, DOI 10.1109/TCSS.2020.2964197; Sesum-Cavic V, 2020, IEEE TETCI, V4, P351, DOI 10.1109/TETCI.2019.2951813; Shen M, 2021, IEEE T INF FOREN SEC, V16, P2367, DOI 10.1109/TIFS.2021.3050608; Shi QQ, 2019, IEEE T NEUR NET LEAR, V30, P1803, DOI 10.1109/TNNLS.2018.2873655; Shi W, 2014, IEEE T SIGNAL PROCES, V62, P1750, DOI 10.1109/TSP.2014.2304432; Suto K, 2014, IEEE T EMERG TOP COM, V2, P292, DOI 10.1109/TETC.2014.2330517; Takacs G, 2009, J MACH LEARN RES, V10, P623; Tang JH, 2019, IEEE T PATTERN ANAL, V41, P2027, DOI 10.1109/TPAMI.2019.2906603; Todor A, 2013, IEEE ACM T COMPUT BI, V10, P970, DOI 10.1109/TCBB.2013.108; Wang H, 2017, IEEE T KNOWL DATA EN, V29, P2263, DOI 10.1109/TKDE.2017.2728527; Wang J, 2018, IEEE T CYBERNETICS, V48, P2620, DOI 10.1109/TCYB.2017.2747400; Wang QX, 2019, NEUROCOMPUTING, V367, P299, DOI 10.1016/j.neucom.2019.08.026; Wang SG, 2019, IEEE T SERV COMPUT, V12, P47, DOI 10.1109/TSC.2016.2584058; Weng YP, 2022, IEEE T KNOWL DATA EN, V34, P4257, DOI 10.1109/TKDE.2020.3036212; Wu CM, 2020, LECT NOTES COMPUT SC, V12396, P594, DOI 10.1007/978-3-030-61609-0_47; Wu H, 2022, IEEE T SERV COMPUT, V15, P1334, DOI 10.1109/TSC.2020.2988760; Xu LJ, 2017, COMPUT OPTIM APPL, V68, P333, DOI 10.1007/s10589-017-9913-x; Xu YY, 2012, FRONT MATH CHINA, V7, P365, DOI 10.1007/s11464-012-0194-5; Xuan Q, 2018, IEEE T CYBERNETICS, V48, P1420, DOI 10.1109/TCYB.2017.2696998; Yang Y, 2020, IEEE T PATTERN ANAL, V42, P521, DOI 10.1109/TPAMI.2018.2883941; Yao DR, 2021, IEEE T MED IMAGING, V40, P1279, DOI 10.1109/TMI.2021.3051604; Yuan Y, 2018, NEUROCOMPUTING, V275, P2019, DOI 10.1016/j.neucom.2017.10.040; Zhang P. Y., 2018, IEEE-CAA J AUTOMATIC, V5, P445; Zhang WC, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P585; Zhang W, 2020, IEEE T BROADCAST, V66, P66, DOI 10.1109/TBC.2019.2902818; Zhang YL, 2011, 22ND IEEE INTERNATIONAL SYMPOSIUM ON SOFTWARE RELIABILITY ENGINEERING (ISSRE), P210, DOI 10.1109/ISSRE.2011.17; Zhao QB, 2015, IEEE T PATTERN ANAL, V37, P1751, DOI 10.1109/TPAMI.2015.2392756; Zhiyuli A, 2019, IEEE T KNOWL DATA EN, V31, P1994, DOI 10.1109/TKDE.2018.2872602; Zhou LK, 2018, AAAI CONF ARTIF INTE, P571; Zhou P, 2021, IEEE T PATTERN ANAL, V43, P1718, DOI 10.1109/TPAMI.2019.2954874; Zhou T, 2009, EUR PHYS J B, V71, P623, DOI 10.1140/epjb/e2009-00335-8; Zhu LH, 2016, IEEE T KNOWL DATA EN, V28, P2765, DOI 10.1109/TKDE.2016.2591009	75	17	17	5	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2022	44	12					9756	9773		10.1109/TPAMI.2021.3132503	http://dx.doi.org/10.1109/TPAMI.2021.3132503			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	6A4XX	34898429				2022-12-18	WOS:000880661400086
J	Wang, RZ; Yan, JC; Yang, XK				Wang, Runzhong; Yan, Junchi; Yang, Xiaokang			Neural Graph Matching Network: Learning Lawler's Quadratic Assignment Problem With Extension to Hypergraph and Multiple-Graph Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pattern matching; Tensors; Splines (mathematics); Feature extraction; Peer-to-peer computing; Optimization; Measurement; Graph matching; deep learning; quadratic assignment problem; combinatorial optimization; graph neural networks	ALGORITHM	Graph matching involves combinatorial optimization based on edge-to-edge affinity matrix, which can be generally formulated as Lawler's quadratic assignment problem (QAP). This paper presents a QAP network directly learning with the affinity matrix (equivalently the association graph) whereby the matching problem is translated into a constrained vertex classification task. The association graph is learned by an embedding network for vertex classification, followed by Sinkhorn normalization and a cross-entropy loss for end-to-end learning. We further improve the embedding model on association graph by introducing Sinkhorn based matching-aware constraint, as well as dummy nodes to deal with unequal sizes of graphs. To our best knowledge, this is one of the first network to directly learn with the general Lawler's QAP. In contrast, recent deep matching methods focus on the learning of node/edge features in two graphs respectively. We also show how to extend our network to hypergraph matching, and matching of multiple graphs. Experimental results on both synthetic graphs and real-world images show its effectiveness. For pure QAP tasks on synthetic data and QAPLIB benchmark, our method can perform competitively and even surpass state-of-the-art graph matching and QAP solvers with notable less time cost. We provide a project homepage at http://thinklab.sjtu.edu.cn/project/NGM/index.html.	[Wang, Runzhong; Yan, Junchi; Yang, Xiaokang] Shanghai Jiao Tong Univ, AI Inst, Dept Comp Sci & Engn, MoE Key Lab Artificial Intelligence, Shanghai 200240, Peoples R China	Shanghai Jiao Tong University	Yan, JC (corresponding author), Shanghai Jiao Tong Univ, AI Inst, Dept Comp Sci & Engn, MoE Key Lab Artificial Intelligence, Shanghai 200240, Peoples R China.	runzhong.wang@sjtu.edu.cn; yanjunchi@sjtu.edu.cn; xkyang@sjtu.edu.cn	Wang, Runzhong/ABE-8710-2021	Wang, Runzhong/0000-0002-9566-738X	National Key Research and Development Program of China [2020AAA0107600]; ShanghaiMunicipal Science and Technology Major Project [2021SHZDZX0102]; NSFC [61972250, U19B2035]	National Key Research and Development Program of China; ShanghaiMunicipal Science and Technology Major Project; NSFC(National Natural Science Foundation of China (NSFC))	This work was supported in part by the National Key Research and Development Program of China under Grant 2020AAA0107600, in part by ShanghaiMunicipal Science and Technology Major Project under Grant 2021SHZDZX0102, and in part by the NSFC under Grants 61972250 and U19B2035.	Ba J., 2017, P 3 INT C LEARN REPR; Bai S, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107637; Bengio Y, 2021, EUR J OPER RES, V290, P405, DOI 10.1016/j.ejor.2020.07.063; Bernard F., 2019, PROC IEEE INT C COMP, V10, P283; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Burkard R., 2009, ASSIGNMENT PROBLEMS; Burkard RE, 1997, J GLOBAL OPTIM, V10, P391, DOI 10.1023/A:1008293323270; Caetano TS, 2009, IEEE T PATTERN ANAL, V31, P1048, DOI 10.1109/TPAMI.2009.28; Chen YX, 2014, PR MACH LEARN RES, V32, P100; Chertok M, 2010, IEEE T PATTERN ANAL, V32, P2205, DOI 10.1109/TPAMI.2010.51; Cho MS, 2013, IEEE I CONF COMP VIS, P25, DOI 10.1109/ICCV.2013.11; Cho M, 2010, LECT NOTES COMPUT SC, V6315, P492; Dai HJ, 2017, ADV NEUR IN, V30; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dokeroglu T, 2016, ENG APPL ARTIF INTEL, V52, P10, DOI 10.1016/j.engappai.2016.02.004; Duchenne O, 2011, IEEE T PATTERN ANAL, V33, P2383, DOI 10.1109/TPAMI.2011.110; EDWARDS CS, 1980, MATH PROGRAM STUD, V13, P35, DOI 10.1007/BFb0120905; Egozi A, 2013, IEEE T PATTERN ANAL, V35, P18, DOI 10.1109/TPAMI.2012.51; Erdogan G, 2007, COMPUT OPER RES, V34, P1085, DOI 10.1016/j.cor.2005.05.027; Feng YF, 2019, AAAI CONF ARTIF INTE, P3558; Fey M, 2018, PROC CVPR IEEE, P869, DOI 10.1109/CVPR.2018.00097; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Garey M. R., 1979, Computers and intractability. A guide to the theory of NP-completeness; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Hahn P, 1998, EUR J OPER RES, V108, P629, DOI 10.1016/S0377-2217(97)00063-5; Hahn PM, 2001, J INTELL MANUF, V12, P487, DOI 10.1023/A:1012252420779; Ionescu C, 2015, IEEE I CONF COMP VIS, P2965, DOI 10.1109/ICCV.2015.339; Jiang ZT, 2021, IEEE T PATTERN ANAL, V43, P3648, DOI 10.1109/TPAMI.2020.2989928; Kipf T. N., 2017, INT C LEARN REPR, DOI [DOI 10.1109/ICDM.2008.17, DOI 10.1109/ICDM.2019.00070]; KOOPMANS TC, 1957, ECONOMETRICA, V25, P53, DOI 10.2307/1907742; Kushinsky Y, 2019, SIAM J IMAGING SCI, V12, P716, DOI 10.1137/18M1196480; LAWLER EL, 1963, MANAGE SCI, V9, P586, DOI 10.1287/mnsc.9.4.586; Lee J, 2011, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2011.5995387; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Leordeanu M., 2009, NIPS; Leordeanu M, 2012, INT J COMPUT VISION, V96, P28, DOI 10.1007/s11263-011-0442-2; Leordeanu M, 2011, IEEE I CONF COMP VIS, P2274, DOI 10.1109/ICCV.2011.6126507; Liu ZY, 2012, IEEE T PATTERN ANAL, V34, P1451, DOI 10.1109/TPAMI.2012.45; Loiola EM, 2007, EUR J OPER RES, V176, P657, DOI 10.1016/j.ejor.2005.09.032; Maset E, 2017, IEEE I CONF COMP VIS, P4578, DOI 10.1109/ICCV.2017.489; Mena G, 2018, INT C LEARN REPR ICL; Nowak A, 2018, 2018 IEEE DATA SCIENCE WORKSHOP (DSW), P229; Pachauri D., 2013, ADV NEURAL INFORM PR, V26, P1860; Punnen AP, 2013, DISCRETE OPTIM, V10, P200, DOI 10.1016/j.disopt.2013.02.003; Ngoc QN, 2015, PROC CVPR IEEE, P5270, DOI 10.1109/CVPR.2015.7299164; Richard S. Zemel, 2011, Arxiv, DOI arXiv:1106.1925; Rolinek Michal, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P407, DOI 10.1007/978-3-030-58604-1_25; Santa Cruz R, 2019, IEEE T PATTERN ANAL, V41, P3100, DOI 10.1109/TPAMI.2018.2873701; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605; Serratosa F, 2011, LECT NOTES COMPUT SC, V6658, P152, DOI 10.1007/978-3-642-20844-7_16; Simonyan Karen, 2015, INT C LEARN REPR; Sutskever I., 2013, P 30 INT C MACH LEAR, P1139, DOI DOI 10.1007/S00287-015-0911-Z; Swoboda P, 2019, PROC CVPR IEEE, P11148, DOI 10.1109/CVPR.2019.01141; Tian Y, 2012, LECT NOTES COMPUT SC, V7574, P821, DOI 10.1007/978-3-642-33712-3_59; Torresani L, 2008, LECT NOTES COMPUT SC, V5303, P596, DOI 10.1007/978-3-540-88688-4_44; Wang QQ, 2018, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2018.00078; Wang Runzhong, 2020, IEEE Trans Pattern Anal Mach Intell, VPP, DOI 10.1109/TPAMI.2020.3005590; Wang RZ, 2019, IEEE I CONF COMP VIS, P3056, DOI 10.1109/ICCV.2019.00315; Wang T., 2020, P IEEE CVF C COMP VI, P7568; Wang T, 2018, IEEE T PATTERN ANAL, V40, P2853, DOI 10.1109/TPAMI.2017.2767591; Yan JC, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4988; Yan JC, 2013, IEEE I CONF COMP VIS, P1649, DOI 10.1109/ICCV.2013.207; Yan JC, 2018, IEEE T CYBERNETICS, V48, P765, DOI 10.1109/TCYB.2017.2655538; Yan JC, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P167, DOI 10.1145/2911996.2912035; Yan JC, 2016, IEEE T PATTERN ANAL, V38, P1228, DOI 10.1109/TPAMI.2015.2477832; Yan JC, 2015, PROC CVPR IEEE, P1520, DOI 10.1109/CVPR.2015.7298759; Yan JC, 2015, IEEE T IMAGE PROCESS, V24, P994, DOI 10.1109/TIP.2014.2387386; Yan JC, 2014, LECT NOTES COMPUT SC, V8689, P407, DOI 10.1007/978-3-319-10590-1_27; Yu T, 2020, PHYSIOL MOL BIOL PLA, V26, P409, DOI 10.1007/s12298-019-00736-7; Yu TS, 2018, LECT NOTES COMPUT SC, V11217, P142, DOI 10.1007/978-3-030-01261-8_9; Zanfir A, 2018, PROC CVPR IEEE, P2684, DOI 10.1109/CVPR.2018.00284; Zass R, 2008, PROC CVPR IEEE, P1221; Zhang Z, 2019, IEEE I CONF COMP VIS, P5086, DOI 10.1109/ICCV.2019.00519; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149; Zhou F, 2016, IEEE T PATTERN ANAL, V38, P1774, DOI 10.1109/TPAMI.2015.2501802; Zhou XW, 2015, IEEE I CONF COMP VIS, P4032, DOI 10.1109/ICCV.2015.459	76	17	18	3	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					5261	5279		10.1109/TPAMI.2021.3078053	http://dx.doi.org/10.1109/TPAMI.2021.3078053			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33961550	Green Submitted			2022-12-18	WOS:000836666600056
J	Davila, K; Setlur, S; Doermann, D; Kota, BU; Govindaraju, V				Davila, Kenny; Setlur, Srirangaraj; Doermann, David; Kota, Bhargava Urala; Govindaraju, Venu			Chart Mining: A Survey of Methods for Automated Chart Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Data mining; Image segmentation; Portable document format; Data visualization; Measurement; Layout; Chart survey; chart extraction; multi-panel chart segmentation; chart image classification; chart understanding; chart data extraction; chart datasets	FIGURE CLASSIFICATION; VISUAL INFORMATION; NEURAL-NETWORK; TEXT; RECOGNITION	Charts are useful communication tools for the presentation of data in a visually appealing format that facilitates comprehension. There have been many studies dedicated to chart mining, which refers to the process of automatic detection, extraction and analysis of charts to reproduce the tabular data that was originally used to create them. By allowing access to data which might not be available in other formats, chart mining facilitates the creation of many downstream applications. This paper presents a comprehensive survey of approaches across all components of the automated chart mining pipeline, such as (i) automated extraction of charts from documents; (ii) processing of multi-panel charts; (iii) automatic image classifiers to collect chart images at scale; (iv) automated extraction of data from each chart image, for popular chart types as well as selected specialized classes; (v) applications of chart mining; and (vi) datasets for training and evaluation, and the methods that were used to build them. Finally, we summarize the main trends found in the literature and provide pointers to areas for further research in chart mining.	[Davila, Kenny; Setlur, Srirangaraj; Doermann, David; Kota, Bhargava Urala; Govindaraju, Venu] Univ Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA	State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Davila, K (corresponding author), Univ Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA.	kennydav@buffalo.edu; setlur@buffalo.edu; doermann@buffalo.edu; buralako@buffalo.edu; govind@buffalo.edu		Davila, Kenny/0000-0001-6308-7113	National Science Foundation [1640867]	National Science Foundation(National Science Foundation (NSF))	This work was supported by the National Science Foundation under Grant No.1640867 (OAC/DMR). The authors would like to thank Fei Xu and Richard Zanibbi for their valuable comments.	Ahmetovic D, 2019, 16TH INTERNATIONAL WEB FOR ALL CONFERENCE (WEB4ALL), DOI 10.1145/3315002.3317560; Al-Dabbagh M. M, 2014, SCI WORLD J, V2014; Al-Zaidy RA, 2017, AAAI CONF ARTIF INTE, P4644; Almakky I, 2018, I S BIOMED IMAGING, P1134; Andrearczyk V, 2018, LECT NOTES COMPUT SC, V11018, P3, DOI 10.1007/978-3-319-98932-7_1; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Antani S, 2008, PROC SPIE, V6815, DOI 10.1117/12.766778; Apostolova E, 2013, J AM SOC INF SCI TEC, V64, P893, DOI 10.1002/asi.22810; Battle L, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174168; BERTIN J., 2011, SEMIOLOGY GRAPHICS D; Bhatia S, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2094072.2094075; Blostein D., 2000, P INT C THEOR APPL D, P7; Boschen F, 2018, MULTIMED TOOLS APPL, V77, P29475, DOI 10.1007/s11042-018-6162-7; Browuer William, 2008, Joint Conference on Digital Libraries (JCDL 2008), P276, DOI 10.1145/1378889.1378936; Burns R, 2013, UMAP WORKSH; Burns R., 2009, P ANN M COGN SCI SOC; Burns R, 2019, COMPUT INTELL-US, V35, P955, DOI 10.1111/coin.12227; Burns R, 2016, LECT NOTES COMPUT SC, V9781, P265, DOI 10.1007/978-3-319-42333-3_22; Carberry S., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P581, DOI 10.1145/1148170.1148270; Chagas P, 2018, IEEE IJCNN; Chakrabarti S, 2016, PLOS GENET, V12, DOI 10.1371/journal.pgen.1006089; Chandrashekaraiah TH, 2016, MATERIALS, V9, DOI 10.3390/ma9070594; Charbonnier J, 2018, LECT NOTES COMPUT SC, V10772, P797, DOI 10.1007/978-3-319-76941-7_78; CHARNIAK E, 1993, ARTIF INTELL, V64, P53, DOI 10.1016/0004-3702(93)90060-O; Chaudhry R, 2020, IEEE WINT CONF APPL, P3501, DOI 10.1109/WACV45572.2020.9093269; Chen Z, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P183, DOI 10.1145/2740908.2742831; Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810; Cheng BB, 2013, PROC INT CONF DOC, P693, DOI 10.1109/ICDAR.2013.142; Cheng BB, 2011, PROC SPIE, V7874, DOI 10.1117/12.873685; Chester D, 2005, LECT NOTES COMPUT SC, V3488, P660; Choi JO, 2019, COMPUT GRAPH FORUM, V38, P249, DOI 10.1111/cgf.13686; Choudhury S. R., 2016, P INT WORKSH SEM BIG, P1; Choudhury SR, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P667, DOI 10.1145/2740908.2741712; Choudhury SR, 2016, ACM-IEEE J CONF DIG, P277, DOI 10.1145/2910896.2925469; Choudhury SR, 2013, PROC INT CONF DOC, P135, DOI 10.1109/ICDAR.2013.34; Choudhury Sagnik Ray, 2015, GREC; Clark C, 2016, ACM-IEEE J CONF DIG, P143, DOI 10.1145/2910896.2910904; Cleveland W.S., 1985, ELEMENTS GRAPHING DA; Cliche M, 2017, LECT NOTES ARTIF INT, V10534, P135, DOI 10.1007/978-3-319-71249-9_9; Dai WJ, 2018, J VISUAL LANG COMPUT, V48, P101, DOI 10.1016/j.jvlc.2018.08.005; Davila Kenny, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1594, DOI 10.1109/ICDAR.2019.00203; de Herrera A. G. S., 2015, P CROSS LANG EV FOR, V1391; De P, 2018, IEEE INT ADV COMPUT, P20, DOI 10.1109/IADCC.2018.8692104; Demir Seniz, 2013, Computational Linguistics and Intelligent Text Processing. 14th International Conference, CICLing 2013. Proceedings, P501, DOI 10.1007/978-3-642-37247-6_40; DEMIR S, 2007, P INT C REC ADV NAT, P150; Demir S., 2010, P INT CROSS DISC C W; Demir S, 2012, COMPUT LINGUIST, V38, P527, DOI 10.1162/COLI_a_00091; Demir Seniz, 2008, INLG, P7; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Diwakar AS, 2009, IACSIT-SC 2009: INTERNATIONAL ASSOCIATION OF COMPUTER SCIENCE AND INFORMATION TECHNOLOGY - SPRING CONFERENCE, P186, DOI 10.1109/IACSIT-SC.2009.27; Dontcheva Mira, 2015, P 41 GRAPH INT C, P59; Elzer Stephanie, 2008, Proceedings of the Fourth IASTED International Conference on Telehealth and Assistive Technologies, P55; Elzer S, 2006, LECT NOTES COMPUT SC, V4045, P25; Ferres L, 2007, ASSETS'07: PROCEEDINGS OF THE NINTH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P67; Ferres L, 2013, ACM T COMPUT-HUM INT, V20, DOI 10.1145/2533682.2533683; Futrelle RP, 2003, PROC INT CONF DOC, P1007; Gao JL, 2012, IEEE IMAGE PROC, P2865, DOI 10.1109/ICIP.2012.6467497; Giannakopoulos T, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P1059, DOI 10.1145/2740908.2742024; Godfrey AJR, 2018, LECT NOTES COMPUT SC, V10896, P590, DOI 10.1007/978-3-319-94277-3_92; Greenbacker C. F., 2011, P WORKSH AUT SUMM DI, P41; Greenbacker C. F., 2011, P UCNLG EV LANG GEN, P23; Greenbacker C. F., 2011, P 2 WORKSH SPEECH LA, P52; Harper J, 2018, IEEE T VIS COMPUT GR, V24, P1274, DOI 10.1109/TVCG.2017.2659744; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hoque E, 2020, IEEE T VIS COMPUT GR, V26, P1236, DOI 10.1109/TVCG.2019.2934431; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang W., 2008, LNCS, V5046, P266, DOI [10.1007/978-3-540-88188-925, DOI 10.1007/978-3-540-88188-925]; Huang WH, 2007, PROC INT CONF DOC, P307; Huang WH, 2007, DOCENG'07: PROCEEDINGS OF THE 2007 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P9; Huang WH, 2004, IEEE IMAGE PROC, P2889; Huang WH, 2005, PROC INT CONF DOC, P580; i Saltiveri T. G., 2020, REV ASOCIACION INTER, V1, P59; Jessen M, 2019, DOCENG'19: PROCEEDINGS OF THE ACM SYMPOSIUM ON DOCUMENT ENGINEERING 2019, DOI 10.1145/3342558.3345396; Jobin KV, 2019, PROC INT CONF DOC, P74, DOI 10.1109/ICDARW.2019.00018; Jung D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6706, DOI 10.1145/3025453.3025957; Kafle K., 2020, PROC WACV, P1498; Kafle K, 2018, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2018.00592; Kallimani JS, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P382, DOI 10.1109/ICACCI.2013.6637202; Kanjanawattana Sarunya, 2016, Proceedings of the International Conferences on Internet Technologies and Society 2016 (ITS 2016), Educational Technologies (ICEduTech 2016), and Sustainability Technology and Education (STE 2016), P19; Kanjanawattana S, 2017, BRAIN-BROAD RES ARTI, V8, P5; Karthikeyani V., 2011, 2011 3rd International Conference on Electronics Computer Technology (ICECT 2011), P209, DOI 10.1109/ICECTECH.2011.5941888; Karthikeyani V., INT J COMPUT APPL, V39, P1; Kataria S., 2008, P 23 AAAI C ART INT, V2, P1169; Kaur A., 2011, INT J COMPUT SCI INF, V2, P1979; Kavasidis I., 2019, LECT NOTES COMPUT SC, P292, DOI DOI 10.1007/978-3-030-30645-8_27; Khan Muzammil, 2011, INT J COMPUTER APPL, V34, P1, DOI DOI 10.5120/4061-5722; Kim DH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376467; Kim D, 2011, J BIOMED INFORM, V44, P848, DOI 10.1016/j.jbi.2011.05.003; Kim E, 2018, ASSETS'18: PROCEEDINGS OF THE 20TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P143, DOI 10.1145/3234695.3236357; Kong N, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P31, DOI 10.1145/2556288.2557241; Kong N, 2012, IEEE T VIS COMPUT GR, V18, P2631, DOI 10.1109/TVCG.2012.229; Kota B. U., 2017, P INT WORKSH GRAPH R, P3; Koudijs MJ, 2005, PLOS GENET, V1, P223, DOI 10.1371/journal.pgen.0010019; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lagopoulos A, 2019, IEEE J BIOMED HEALTH, V23, P2230, DOI 10.1109/JBHI.2019.2902303; Lee PS, 2018, IEEE T BIG DATA, V4, P117, DOI 10.1109/TBDATA.2017.2689038; Lee SL, 2018, IET IMAGE PROCESS, V12, P1031, DOI 10.1049/iet-ipr.2017.0800; Li PY, 2019, BIOINFORMATICS, V35, P4381, DOI 10.1093/bioinformatics/btz228; Li Z, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P789; Li Z, 2015, DATA KNOWL ENG, V100, P191, DOI 10.1016/j.datak.2015.05.005; Liu X., ARXIV190611906, V2019; Liu Y, 2013, PROC SPIE, V8654, DOI 10.1117/12.2008467; Lopez LD, 2013, BMC SYST BIOL, V7, DOI 10.1186/1752-0509-7-S4-S8; Lu XN, 2009, INT J DOC ANAL RECOG, V12, P65, DOI 10.1007/s10032-009-0081-0; Lugo A, 2013, INT J ENV RES PUB HE, V10, P4418, DOI 10.3390/ijerph10094418; Ma KF, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419540016; Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1562, DOI 10.1109/TVCG.2018.2875702; Madan Spandan, 2018, ARXIV180710441; Mahadeva SK, 2013, NANOMATERIALS-BASEL, V3, P486, DOI 10.3390/nano3030486; Mahmood A, 2014, INT C INTEL HUM MACH, P376, DOI 10.1109/IHMSC.2014.192; Mansur D L, 1985, J Med Syst, V9, P163, DOI 10.1007/BF00996201; Marchewka A., IMAGE PROCESSING COM, V5, P263; Masaomi K., 2016, INT C ADV SEMANTIC P, P1; Mayhua A, 2018, SIBGRAPI, P142, DOI 10.1109/SIBGRAPI.2018.00025; Mei HH, 2018, J VISUAL LANG COMPUT, V44, P120, DOI 10.1016/j.jvlc.2017.10.001; Mendez GG, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4073, DOI 10.1145/2858036.2858435; Methani N., 2020, P IEEE CVF WINT C AP, P1527; Mishchenko A., 2011, 2011 Sixth International Conference on Digital Information Management, P115, DOI 10.1109/ICDIM.2011.6093320; Molla MKI, 2003, LECT NOTES COMPUT SC, V2690, P865; Moraes Gabriel, 2014, P 16 INT ACM SIGACCE, P83, DOI [10.1145/2661334.2661368, DOI 10.1145/2661334.2661368]; Morris David, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1438, DOI 10.1109/ICDAR.2019.00231; Nair RR, 2015, PROC INT CONF DOC, P796, DOI 10.1109/ICDAR.2015.7333871; Nikitin T, 2015, NANOMATERIALS-BASEL, V5, P614, DOI 10.3390/nano5020614; Pelka O., 2015, P WORK NOT CLEF TOUL; Po-Shen Lee, 2015, 4th International Conference on Pattern Recognition Applications and Methods (ICPRAM 2015). Proceedings, P79; Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193; Ponjavic J, 2009, PLOS GENET, V5, DOI 10.1371/journal.pgen.1000617; Praczyk PA, 2013, INFORM TECHNOL LIBR, V32, P25, DOI 10.6017/ital.v32i4.3670; Prasad VSN, 2007, INT WORK CONTENT MUL, P85; Purchase HC, 2014, J VISUAL LANG COMPUT, V25, P57, DOI 10.1016/j.jvlc.2013.11.004; Ramanathan T., 2018, ARXIV181210636; Ray Choudhury S., 2015, P 2015 ACM S DOC ENG, P47, DOI DOI 10.1109/WI-IAT.2015.17; Reddy VK, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS, VISION AND INFORMATION SECURITY (CGVIS), P190, DOI 10.1109/CGVIS.2015.7449920; Santosh K., 2015, P CROSS LANG EV FOR, V1391; Sanyal DK, 2019, MACHINE LEARNING IN BIO-SIGNAL ANALYSIS AND DIAGNOSTIC IMAGING, P247, DOI 10.1016/B978-0-12-816086-2.00010-2; Savva Manolis, 2011, P 24 ANN ACM S US IN, P393, DOI DOI 10.1145/2047196.2047247; Shao MY, 2006, LECT NOTES COMPUT SC, V3926, P231; Sharif A, 2018, CONSUM COMM NETWORK; Sharma M., 2019, P INT JOINT C NEUR N, P1; Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371; Shi XY, 2019, INT CONF ACOUST SPEE, P1343, DOI 10.1109/ICASSP.2019.8683824; Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307; Shukla S, 2008, INT J DOC ANAL RECOG, V11, P111, DOI 10.1007/s10032-008-0065-5; Siegel N, 2018, ACM-IEEE J CONF DIG, P223, DOI 10.1145/3197026.3197040; Siegel N, 2016, LECT NOTES COMPUT SC, V9911, P664, DOI 10.1007/978-3-319-46478-7_41; Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145; Svendsen J. P., 2015, THESIS U VICTORIA VI; Tang BB, 2016, SIGNAL PROCESS, V124, P156, DOI 10.1016/j.sigpro.2015.09.027; Taschwer M, 2018, MULTIMED TOOLS APPL, V77, P519, DOI 10.1007/s11042-016-4237-x; Tsutsui S, 2017, PROC INT CONF DOC, P533, DOI 10.1109/ICDAR.2017.93; uller H. M_, 2012, P SPIE MED IMAGING, V8319; Vassilieva N., 2013, Pattern Recognition and Image Analysis, V23, P139, DOI 10.1134/S1054661813010112; Wang X., 2015, P CROSS LANG EV FOR, V1391; Wijesinghe DB, 2017, IEEE INT CONF ADV LE, P243, DOI 10.1109/ICALT.2017.107; Wu Q, 2017, COMPUT VIS IMAGE UND, V163, P21, DOI 10.1016/j.cviu.2017.05.001; Wu RQ, 2009, J COMPUT SCI TECHNOL, V9, P58; Yan YS, 2016, INT J ENV RES PUB HE, V13, DOI 10.3390/ijerph13080794; Zhang JP, 2019, MED IMAGE ANAL, V54, P10, DOI 10.1016/j.media.2019.02.010; Zhou Y., 2001, 4 IAPR INT WORKSH GR, P482; Zhou YP, 2001, P SOC PHOTO-OPT INS, V4307, P333; Zou J, 2020, J ASSOC INF SCI TECH, V71, P1327, DOI 10.1002/asi.24334; Zou J, 2017, PROC INT CONF DOC, P753, DOI 10.1109/ICDAR.2017.128	163	17	17	6	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2021	43	11					3799	3819		10.1109/TPAMI.2020.2992028	http://dx.doi.org/10.1109/TPAMI.2020.2992028			21	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WA1JH	32365018				2022-12-18	WOS:000702649700009
J	Zadeh, SG; Schmid, M				Zadeh, Shekoufeh Gorgi; Schmid, Matthias			Bias in Cross-Entropy-Based Training of Deep Survival Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cross-entropy loss; deep recurrent survival analysis; deep survival network; model calibration; negative log-likelihood loss	PREDICTION MODELS	Over the last years, utilizing deep learning for the analysis of survival data has become attractive to many researchers. This has led to the advent of numerous network architectures for the prediction of possibly censored time-to-event variables. Unlike networks for cross-sectional data (used e.g., in classification), deep survival networks require the specification of a suitably defined loss function that incorporates typical characteristics of survival data such as censoring and time-dependent features. Here, we provide an in-depth analysis of the cross-entropy loss function, which is a popular loss function for training deep survival networks. For each time point t, the cross-entropy loss is defined in terms of a binary outcome with levels "event at or before t" and "event after t". Using both theoretical and empirical approaches, we show that this definition may result in a high prediction error and a heavy bias in the predicted survival probabilities. To overcome this problem, we analyze an alternative loss function that is derived fromthe negative log-likelihood function of a discrete time-to-event model. Weshow that replacing the cross-entropy loss by the negative log-likelihood loss results in much better calibrated prediction rules and also in an improved discriminatory power, as measured by the concordance index.	[Zadeh, Shekoufeh Gorgi] Univ Bonn, Dept Comp Sci, Endenicher Allee 19a, D-53115 Bonn, Germany; [Zadeh, Shekoufeh Gorgi; Schmid, Matthias] Univ Bonn, Med Fac, Dept Med Biometry Informat & Epidemiol, Venusberg Campus 1, D-53127 Bonn, Germany	University of Bonn; University of Bonn	Schmid, M (corresponding author), Univ Bonn, Med Fac, Dept Med Biometry Informat & Epidemiol, Venusberg Campus 1, D-53127 Bonn, Germany.	shekoufeh.gorgizadeh@imbie.uni-bonn.de; matthias.c.schmid@uni-bonn.de		Schmid, Matthias/0000-0002-0788-0317	German Research Foundation [SCHM 2966/2-1]	German Research Foundation(German Research Foundation (DFG))	The authors would like to thank Dr. Lothar Haberle (Department of Gynecology, Obstetrics and Mammology, University Hospital Erlangen, Germany) for valuable comments on the analysis of the SEER data. The support from the German Research Foundation (Grant SCHM 2966/2-1), is gratefully acknowledged. Shekoufeh Gorgi Zadeh and Matthias Schmid contributed equally to this article.	Bello GA, 2019, NAT MACH INTELL, V1, P95, DOI 10.1038/s42256-019-0019-2; Demler OV, 2015, STAT MED, V34, P1659, DOI 10.1002/sim.6428; FARAGGI D, 1995, STAT MED, V14, P73, DOI 10.1002/sim.4780140108; Gerds TA, 2013, STAT MED, V32, P2173, DOI 10.1002/sim.5681; Giunchiglia E, 2018, LECT NOTES COMPUT SC, V11141, P23, DOI 10.1007/978-3-030-01424-7_3; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947; HARRELL FE, 1984, STAT MED, V3, P143, DOI 10.1002/sim.4780030207; HARRELL FE, 1982, JAMA-J AM MED ASSOC, V247, P2543, DOI 10.1001/jama.247.18.2543; Katzman J. L., 2016, ARXIV160600931V1STAT ARXIV160600931V1STAT; Lee C, 2018, AAAI CONF ARTIF INTE, P2314; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038; Luck M., 2017, ARXIV170510245V1CSLG ARXIV170510245V1CSLG; Millar RB, 2011, STAT PRACT, P1, DOI 10.1002/9780470094846; Mitra B., 2017, ARXIV170501509V1CSIR ARXIV170501509V1CSIR; Mobadersany P, 2018, P NATL ACAD SCI USA, V115, pE2970, DOI 10.1073/pnas.1717139115; Mogensen UB, 2012, J STAT SOFTW, V50, P1; National Cancer Institute DCCPS Surveillance Research Program Surveillance Systems Branch, 2013, CAS DIAGN 1973 2010 CAS DIAGN 1973 2010; Naylor CD, 2018, JAMA-J AM MED ASSOC, V320, P1099, DOI 10.1001/jama.2018.11103; Rahmani H, 2018, IEEE T PATTERN ANAL, V40, P667, DOI 10.1109/TPAMI.2017.2691768; Ren K, 2019, AAAI CONF ARTIF INTE, P4798; Schmid M, 2012, STAT MED, V31, P2588, DOI 10.1002/sim.5464; Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418; Shakur H, 2010, LANCET, V376, P23, DOI 10.1016/S0140-6736(10)60835-5; Steyerberg EW, 2010, EPIDEMIOLOGY, V21, P128, DOI 10.1097/EDE.0b013e3181c30fb2; Tutz G, 2016, SPRINGER SER STAT, P1, DOI 10.1007/978-3-319-28158-2; Yin W., 2017, ARXIV170201923V1CSCL ARXIV170201923V1CSCL; Zhu XL, 2017, PROC CVPR IEEE, P6855, DOI 10.1109/CVPR.2017.725; Zhu XL, 2016, IEEE INT C BIOINFORM, P544, DOI 10.1109/BIBM.2016.7822579	30	17	17	4	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2021	43	9					3126	3137		10.1109/TPAMI.2020.2979450	http://dx.doi.org/10.1109/TPAMI.2020.2979450			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TU6DH	32149626				2022-12-18	WOS:000681124300021
J	Nguyen, CH; Mamitsuka, H				Nguyen, Canh Hao; Mamitsuka, Hiroshi			Learning on Hypergraphs With Sparsity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Noise measurement; Data models; Laplace equations; Additives; Machine learning; Computational modeling; Topology; Sparse learning; learning on hypergraphs; learning on graphs; sparsistency	MODEL SELECTION; REGRESSION	Hypergraph is a general way of representing high-order relations on a set of objects. It is a generalization of graph, in which only pairwise relations can be represented. It finds applications in various domains where relationships of more than two objects are observed. On a hypergraph, as a generalization of graph, one wishes to learn a smooth function with respect to its topology. A fundamental issue is to find suitable smoothness measures of functions on the nodes of a graph/hypergraph. We show a general framework that generalizes previously proposed smoothness measures and also generates new ones. To address the problem of irrelevant or noisy data, we wish to incorporate sparse learning framework into learning on hypergraphs. We propose sparsely smooth formulations that learn smooth functions and induce sparsity on hypergraphs at both hyperedge and node levels. We show their properties and sparse support recovery results. We conduct experiments to show that our sparsely smooth models are beneficial to learning irrelevant and noisy data, and usually give similar or improved performances compared to dense models.	[Nguyen, Canh Hao; Mamitsuka, Hiroshi] Kyoto Univ, Inst Chem Res, Kyoto 6110011, Japan; [Mamitsuka, Hiroshi] Aalto Univ, Dept Comp Sci, Espoo 02150, Finland	Kyoto University; Aalto University	Nguyen, CH (corresponding author), Kyoto Univ, Inst Chem Res, Kyoto 6110011, Japan.	canhhao@kuicr.kyoto-u.ac.jp; mami@kuicr.kyoto-u.ac.jp	; Mamitsuka, Hiroshi/R-1110-2016	Nguyen, Canh Hao/0000-0002-0274-5693; Maravelakis, Petros/0000-0002-7477-5947; Mamitsuka, Hiroshi/0000-0002-6607-5617	MEXT Kakenhi [16H02868, 19H04169, 18K11434]; JST ACCEL [JPMJAC1503]; VINIF [VINIF.2019. DA18]; Business Finland; Academy of Finland	MEXT Kakenhi(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)); JST ACCEL(Japan Science & Technology Agency (JST)); VINIF; Business Finland; Academy of Finland(Academy of Finland)	C. H. N. has been supported in part by MEXT Kakenhi (Grant number 18K11434) and VINIF (Grant number VINIF.2019. DA18). H. M. has been supported in part by JST ACCEL (Grant number JPMJAC1503), MEXT Kakenhi (Grant numbers 16H02868 and 19H04169), FiDiPro by Tekes (currently Business Finland) and AIPSE program by Academy of Finland.	Agarwal S., 2006, ICML, P17, DOI DOI 10.1145/1143844.1143847; [Anonymous], 2019, STAT LEARNING SPARSI; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Bu J., 2010, P INT C MULT, P391, DOI DOI 10.1145/1873951.1874005; Buhler T., 2009, P 26 ANN INT C MACH, P81, DOI DOI 10.1145/1553374.1553385; Chapelle O., 2010, SEMISUPERVISED LEARN; Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; Chung F., 1993, EXPANDING GRAPHS, P21; Cook DJ, 2006, MINING GRAPH DATA; De Raedt L., 2016, STAT RELATIONAL ARTI; Friedman J, 2007, ANN APPL STAT, V1, P302, DOI 10.1214/07-AOAS131; Getoor Lise, 2007, INTRO STAT RELATIONA; Hein M., 2013, P ADV NEUR INF PROC, V26; Jacob L., 2009, P 26 INT C MACH LEAR, P433, DOI DOI 10.1145/1553374.1553431; Kyng R., 2015, COLT, P1190; Lichman M, 2013, UCI MACHINE LEARNING; Loglisci C, 2016, J INTELL INF SYST, V46, P447, DOI 10.1007/s10844-015-0361-8; Ma Y, 2012, MANIFOLD LEARNING THEORY AND APPLICATIONS, P1; Newman M., 2010, NETWORKS INTRO; Ochs P, 2012, PROC CVPR IEEE, P614, DOI 10.1109/CVPR.2012.6247728; Olshen R., 1984, CLASSIFICATION REGRE; Rinaldo A, 2009, ANN STAT, V37, P2922, DOI 10.1214/08-AOS665; Sen P, 2008, AI MAG, V29, P93, DOI 10.1609/aimag.v29i3.2157; Sharpnack J., 2012, AISTATS JMLR WCP; Sun L., 2008, HYPERGRAPH SPECTRAL, P668, DOI [10.1145/1401890.1401971, DOI 10.1145/1401890.1401971]; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Pham T, 2017, AAAI CONF ARTIF INTE, P2485; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; von Luxburg U, 2014, J MACH LEARN RES, V15, P1751; Wainwright MJ, 2009, IEEE T INFORM THEORY, V55, P2183, DOI 10.1109/TIT.2009.2016018; Wang YX, 2015, JMLR WORKSH CONF PRO, V38, P1042; Weighill DA, 2015, PLOS COMPUT BIOL, V11, DOI 10.1371/journal.pcbi.1004079; Yuan M, 2006, J R STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Zhao P, 2006, J MACH LEARN RES, V7, P2541; Zhou D., 2006, ADV NEURAL INF PROCE, V19, P1601; Zhou Y., 2010, PROC 13 INT C ARTIF, P988; Zhu X, 2003, INT C MACH LEARN, P912; Zien JY, 1999, IEEE T COMPUT AID D, V18, P1389, DOI 10.1109/43.784130	39	17	17	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG 1	2021	43	8					2710	2722		10.1109/TPAMI.2020.2974746	http://dx.doi.org/10.1109/TPAMI.2020.2974746			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TF2YV	32086195	Green Submitted, Green Accepted, Green Published			2022-12-18	WOS:000670578800014
J	Hasan, I; Setti, F; Tsesmelis, T; Belagiannis, V; Amin, S; Del Bue, A; Cristani, M; Galasso, F				Hasan, Irtiza; Setti, Francesco; Tsesmelis, Theodore; Belagiannis, Vasileios; Amin, Sikandar; Del Bue, Alessio; Cristani, Marco; Galasso, Fabio			Forecasting People Trajectories and Head Poses by Jointly Reasoning on Tracklets and Vislets	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Magnetic heads; Forecasting; Trajectory; Correlation; Head; Predictive models; Visualization; LSTM; trajectory forecasting; RNN; head pose estimation; visual attention; gaze estimation	MODELS; PEDESTRIANS; RESOLUTION; TRACKING; PATH	In this article, we explore the correlation between people trajectories and their head orientations. We argue that people trajectory and head pose forecasting can be modelled as a joint problem. Recent approaches on trajectory forecasting leverage short-term trajectories (aka tracklets) of pedestrians to predict their future paths. In addition, sociological cues, such as expected destination or pedestrian interaction, are often combined with tracklets. In this article, we propose MiXing-LSTM (MX-LSTM) to capture the interplay between positions and head orientations (vislets) thanks to a joint unconstrained optimization of full covariance matrices during the LSTM backpropagation. We additionally exploit the head orientations as a proxy for the visual attention, when modeling social interactions. MX-LSTM predicts future pedestrians location and head pose, increasing the standard capabilities of the current approaches on long-term trajectory forecasting. Compared to the state-of-the-art, our approach shows better performances on an extensive set of public benchmarks. MX-LSTM is particularly effective when people move slowly, i.e., the most challenging scenario for all other models. The proposed approach also allows for accurate predictions on a longer time horizon.	[Hasan, Irtiza] Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates; [Setti, Francesco; Cristani, Marco] Univ Verona, Dept Comp Sci, I-37129 Verona, Italy; [Tsesmelis, Theodore; Del Bue, Alessio] Italian Inst Technol, I-16163 Genoa, Italy; [Tsesmelis, Theodore; Amin, Sikandar; Galasso, Fabio] Osram GmbH, D-80807 Munich, Germany; [Belagiannis, Vasileios] Ulm Univ, D-89081 Ulm, Germany	University of Verona; Istituto Italiano di Tecnologia - IIT; Osram; Sanofi-Aventis; Siemens AG; Siemens Germany; Ulm University	Hasan, I (corresponding author), Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates.	irtiza.hasan@incpetioniai.org; francesco.setti@univr.it; t.tsesmelis@osram.com; belagiannis@ieee.org; s.amin@osram.com; alessio.delbue@iit.it; marco.cristani@univr.it; f.galasso@osram.com		Setti, Francesco/0000-0002-0015-5534; Hasan, Irtiza/0000-0003-1547-3946; Del Bue, Alessio/0000-0002-2262-4872; CRISTANI, Marco/0000-0002-0523-6042	European Union [676455]; Italian Ministry of Education, Universities and Research (MIUR) [10066183]	European Union(European Commission); Italian Ministry of Education, Universities and Research (MIUR)(Ministry of Education, Universities and Research (MIUR))	This work was supported by the European Union's Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie Grant Agreement No. 676455, and has been partially supported by the projects of the Italian Ministry of Education, Universities and Research (MIUR) "Dipartimenti di Eccellenza 2018-2022" and PORFESR 2014-2020 Work Program (Action 1.1.4, Project No.10066183). This work was done when Dr. Irtizawas a PhD student atUniversity of Verona.	Abbeel P., 2004, P 21 INT C MACHINE L, P1; AKAIKE H, 1969, ANN I STAT MATH, V21, P243, DOI 10.1007/BF02532251; Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110; Alahi A, 2014, PROC CVPR IEEE, P2211, DOI 10.1109/CVPR.2014.283; Antonini G, 2006, INT J COMPUT VISION, V69, P159, DOI 10.1007/s11263-005-4797-0; Antonini G, 2006, TRANSPORT RES B-METH, V40, P667, DOI 10.1016/j.trb.2005.09.006; Ba SO, 2004, INT C PATT RECOG, P264, DOI 10.1109/ICPR.2004.1333754; Becker S., 2018, ECCV, P138; Becker S., 2018, ARXIV PREPRINT ARXIV; Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667; Bhattacharyya A, 2018, PROC CVPR IEEE, P4194, DOI 10.1109/CVPR.2018.00441; Boyd S, 2005, SIAM J MATRIX ANAL A, V27, P532, DOI 10.1137/040609902; Cherian A, 2013, IEEE T PATTERN ANAL, V35, P2161, DOI 10.1109/TPAMI.2012.259; Choi W, 2014, IEEE T PATTERN ANAL, V36, P1242, DOI 10.1109/TPAMI.2013.220; Choi W, 2012, LECT NOTES COMPUT SC, V7575, P215, DOI 10.1007/978-3-642-33765-9_16; Choy C. B., **DROPPED REF**, P336; Collins RT, 2001, P IEEE, V89, P1456, DOI 10.1109/5.959341; Coskun H, 2017, IEEE I CONF COMP VIS, P5525, DOI 10.1109/ICCV.2017.589; Davoudian N, 2012, LIGHTING RES TECHNOL, V44, P438, DOI 10.1177/1477153512437157; Dragan Anca D., 2011, IEEE International Conference on Robotics and Automation, P4582; Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714; Ferryman JM, 2000, INT J COMPUT VISION, V37, P187, DOI 10.1023/A:1008155721192; Fotios S, 2015, LIGHTING RES TECHNOL, V47, P149, DOI 10.1177/1477153514522473; Fotios S, 2015, LIGHTING RES TECHNOL, V47, P133, DOI 10.1177/1477153514522472; Foulsham T, 2011, VISION RES, V51, P1920, DOI 10.1016/j.visres.2011.07.002; Gourier N, 2007, LECT NOTES COMPUT SC, V4122, P270; Graves A, 2012, STUD COMPUT INTELL, V385, P5; Gregor K, 2015, PR MACH LEARN RES, V37, P1462; Gupta A, 2018, PROC CVPR IEEE, P2255, DOI 10.1109/CVPR.2018.00240; Hall E. T, 1990, HIDDEN DIMENSION; Hasan I, 2018, PROC CVPR IEEE, P6067, DOI 10.1109/CVPR.2018.00635; Hasan I, 2018, IEEE WINT CONF APPL, P1178, DOI 10.1109/WACV.2018.00134; Hasan I, 2017, IEEE IMAGE PROC, P2662; HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282; HIGHAM NJ, 1988, LINEAR ALGEBRA APPL, V103, P103, DOI 10.1016/0024-3795(88)90223-6; Huang SY, 2016, IEEE T IMAGE PROCESS, V25, P5892, DOI 10.1109/TIP.2016.2613686; Intriligator J, 2001, COGNITIVE PSYCHOL, V43, P171, DOI 10.1006/cogp.2001.0755; Jammalamadaka SR., 2001, STATISTICS, V5, DOI DOI 10.1111/J.1442-2050.2010.01169.X; Kalman RE., 1960, T ASME J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; Kitani KM, 2012, LECT NOTES COMPUT SC, V7575, P201, DOI 10.1007/978-3-642-33765-9_15; Kuderer M, 2012, ROBOT SCI SYST, V8; Leal-Taixe Laura, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P120, DOI 10.1109/ICCVW.2011.6130233; Lee D, 2015, IEEE I CONF COMP VIS, P1958, DOI 10.1109/ICCV.2015.227; Lee N., 2016, P 2016 IEEE WINT C A, P1, DOI DOI 10.1109/WACV.2016.7477732; Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x; Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50; Ma WC, 2017, PROC CVPR IEEE, P4636, DOI 10.1109/CVPR.2017.493; Mainprice J, 2016, IEEE T ROBOT, V32, P897, DOI 10.1109/TRO.2016.2581216; McCullagh P., 1989, GEN LINEAR MODELS; Hoai M, 2014, INT J COMPUT VISION, V107, P191, DOI 10.1007/s11263-013-0683-3; Morris BT, 2008, IEEE T CIRC SYST VID, V18, P1114, DOI 10.1109/TCSVT.2008.927109; Patla AE, 2003, EXP BRAIN RES, V148, P133, DOI 10.1007/s00221-002-1246-y; Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260; Pinheiro JC, 1996, STAT COMPUT, V6, P289, DOI 10.1007/BF00140873; Pourahmadi M, 2011, STAT SCI, V26, P369, DOI 10.1214/11-STS358; Priestley M. B., 1981, PROBABILITY MATH STA; Quinonero-Candela JQ, 2005, J MACH LEARN RES, V6, P1939; Reid I. D., 2009, P BRIT MACH VIS COMP, V2, P7; Robertson N, 2006, LECT NOTES COMPUT SC, V3952, P402; Robicquet A, 2016, LECT NOTES COMPUT SC, V9912, P549, DOI 10.1007/978-3-319-46484-8_33; Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349; Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41; Schnabel R. B., NUMERICAL METHODS UN; Srinivasaraghavan G., 2017, ARXIV PREPRINT ARXIV; Srivastava N, 2015, PR MACH LEARN RES, V37, P843; Stiefelhagen Rainer, 1999, LNCS, P2, DOI DOI 10.1007/3-540-48762-X_94; Su H., 2016, IJCAI 16 PROC 25 INT, P3469; Su H., 2017, P 26 INT JOINT C ART, P2772; Sun Lin E., 2018, 2018 International Applied Computational Electromagnetics Society Symposium - China (ACES), DOI 10.23919/ACESS.2018.8669117; Tosato D, 2013, IEEE T PATTERN ANAL, V35, P1972, DOI 10.1109/TPAMI.2012.263; Trautman Peter, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P797, DOI 10.1109/IROS.2010.5654369; Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008; van Bommel W. J. M., 1980, LIGHT DES ENG CTR; Vansteenkiste P, 2013, ACCIDENT ANAL PREV, V51, P222, DOI 10.1016/j.aap.2012.11.025; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167; Williams C. K, 2006, ADAPT COMPUT MACH LE, V2, P4; Williams CKI, 1998, NATO ADV SCI I D-BEH, V89, P599; Xing Z., 2008, P 2008 SIAM INT C DA, P644; Xue H, 2018, IEEE WINT CONF APPL, P1186, DOI 10.1109/WACV.2018.00135; Yamaguchi K, 2011, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2011.5995468; Yi S, 2015, PROC CVPR IEEE, P3488, DOI 10.1109/CVPR.2015.7298971; Ziebart B. D., 2008, AAAI, V8, P1433; Ziebart BD, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3931, DOI 10.1109/IROS.2009.5354147	85	17	17	3	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2021	43	4					1267	1278		10.1109/TPAMI.2019.2949414	http://dx.doi.org/10.1109/TPAMI.2019.2949414			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QT3YJ	31670663	Green Submitted			2022-12-18	WOS:000626525300012
J	Torii, A; Taira, H; Sivic, J; Pollefeys, M; Okutomi, M; Pajdla, T; Sattler, T				Torii, Akihiko; Taira, Hajime; Sivic, Josef; Pollefeys, Marc; Okutomi, Masatoshi; Pajdla, Tomas; Sattler, Torsten			Are Large-Scale 3D Models Really Necessary for Accurate Visual Localization?	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Solid modeling; Visualization; Cameras; Two dimensional displays; Databases; Pose estimation; Visual localization; image-based localization; place recognition; pose estimation; image retrieval	PLACE RECOGNITION; IMAGE	Accurate visual localization is a key technology for autonomous navigation. 3D structure-based methods employ 3D models of the scene to estimate the full 6 degree-of-freedom (DOF) pose of a camera very accurately. However, constructing (and extending) large-scale 3D models is still a significant challenge. In contrast, 2D image retrieval-based methods only require a database of geo-tagged images, which is trivial to construct and to maintain. They are often considered inaccurate since they only approximate the positions of the cameras. Yet, the exact camera pose can theoretically be recovered when enough relevant database images are retrieved. In this paper, we demonstrate experimentally that large-scale 3D models are not strictly necessary for accurate visual localization. We create reference poses for a large and challenging urban dataset. Using these poses, we show that combining image-based methods with local reconstructions results in a higher pose accuracy compared to state-of-the-art structure-based methods, albeight at higher run-time costs. We show that some of these run-time costs can be alleviated by exploiting known database image poses. Our results suggest that we might want to reconsider the need for large-scale 3D models in favor of more local models, but also that further research is necessary to accelerate the local reconstruction process.	[Torii, Akihiko; Taira, Hajime; Okutomi, Masatoshi] Tokyo Inst Technol, Sch Engn, Dept Syst & Control Engn, Tokyo 1528550, Japan; [Sivic, Josef] PSL Res Univ, Ecole Normale Super, Dept Informat, INRIA,WILLOW Project,ENS,CNRS,UMR 8548, F-75006 Paris, France; [Sivic, Josef; Pajdla, Tomas] Czech Tech Univ, Czech Inst Informat Robot & Cybernet, Prague 16000, Czech Republic; [Pollefeys, Marc] Swiss Fed Inst Technol, Dept Comp Sciene, CH-8092 Zurich, Switzerland; [Pollefeys, Marc] Microsoft, CH-8304 Wallisellen, Switzerland; [Sattler, Torsten] Chalmers Univ Technol, S-41296 Gothenburg, Sweden	Tokyo Institute of Technology; Centre National de la Recherche Scientifique (CNRS); Inria; UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS); Universite Paris Cite; Czech Technical University Prague; Swiss Federal Institutes of Technology Domain; ETH Zurich; Chalmers University of Technology	Torii, A (corresponding author), Tokyo Inst Technol, Sch Engn, Dept Syst & Control Engn, Tokyo 1528550, Japan.	torii@sc.e.titech.ac.jp; htaira@ok.ctrl.titech.ac.jp; Josef.Sivic@ens.fr; marc.pollefeys@inf.ethz.ch; mxo@sc.e.titech.ac.jp; pajdla@cvut.cz; torsat@chalmers.se	Pollefeys, Marc/I-7607-2013; Sattler, Torsten/AAM-3155-2021		EU-H2020 project LADIO [731970]; JSPS KAKENHI [15H05313, 17J05908]; ERC grant LEAP [336845]; CIFAR Learning in Machines Brains program; European Regional Development Fund under the project IMPACT [CZ.02.1.01/0.0/0.0/15_003/0000468]; Grant Agency of the CTU in Prague [SGS18/104/OHK3/1T/37]; Google Tango	EU-H2020 project LADIO; JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)); ERC grant LEAP; CIFAR Learning in Machines Brains program; European Regional Development Fund under the project IMPACT; Grant Agency of the CTU in Prague; Google Tango(Google Incorporated)	This work was partly supported by EU-H2020 project LADIO No. 731970, JSPS KAKENHI Grant Number 15H05313, 17J05908, ERC grant LEAP (no. 336845), CIFAR Learning in Machines & Brains program and European Regional Development Fund under the project IMPACT (reg. no. CZ.02.1.01/0.0/0.0/15_003/0000468), Grant Agency of the CTU in Prague project SGS18/104/OHK3/1T/37, and Google Tango.	Agarwal S., P CVPR WORKSHOPS, V1; Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148; Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/CVPR.2016.572, 10.1109/TPAMI.2017.2711011]; Arandjelovic R, 2015, LECT NOTES COMPUT SC, V9006, P188, DOI 10.1007/978-3-319-16817-3_13; Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Aubry M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2591009; Brachmann E, 2018, PROC CVPR IEEE, P4654, DOI 10.1109/CVPR.2018.00489; Brachmann E, 2017, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2017.267; Brahmbhatt S, 2018, PROC CVPR IEEE, P2616, DOI 10.1109/CVPR.2018.00277; Bujnak M, 2011, LECT NOTES COMPUT SC, V6492, P11, DOI 10.1007/978-3-642-19315-6_2; Camposeco F, 2019, PROC CVPR IEEE, P7645, DOI 10.1109/CVPR.2019.00784; Camposeco F, 2017, PROC CVPR IEEE, P6700, DOI 10.1109/CVPR.2017.709; Cao S, 2014, PROC CVPR IEEE, P461, DOI 10.1109/CVPR.2014.66; Cao S, 2013, PROC CVPR IEEE, P700, DOI 10.1109/CVPR.2013.96; Cavallari T, 2017, PROC CVPR IEEE, P218, DOI 10.1109/CVPR.2017.31; Changchang Wu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3057, DOI 10.1109/CVPR.2011.5995552; Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610; Choudhary S, 2012, LECT NOTES COMPUT SC, V7576, P130, DOI 10.1007/978-3-642-33715-4_10; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Chum O, 2011, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2011.5995601; Crandall D., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3001, DOI 10.1109/CVPR.2011.5995626; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gammeter S, 2009, IEEE I CONF COMP VIS, P614, DOI 10.1109/ICCV.2009.5459180; Gronat P, 2016, INT J COMPUT VISION, V118, P319, DOI 10.1007/s11263-015-0878-x; HARALICK RM, 1994, INT J COMPUT VISION, V13, P331, DOI 10.1007/BF02028352; Hartley R, 2013, INT J COMPUT VISION, V103, P267, DOI 10.1007/s11263-012-0601-0; Irschara Arnold, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2599, DOI 10.1109/CVPRW.2009.5206587; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Kendall A, 2017, PROC CVPR IEEE, P6555, DOI 10.1109/CVPR.2017.694; Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336; Kim HJ, 2017, PROC CVPR IEEE, P3251, DOI 10.1109/CVPR.2017.346; Knopp J, 2010, LECT NOTES COMPUT SC, V6311, P748, DOI 10.1007/978-3-642-15549-9_54; Kukelova Z, 2013, IEEE I CONF COMP VIS, P2816, DOI 10.1109/ICCV.2013.350; Li YP, 2012, LECT NOTES COMPUT SC, V7572, P15, DOI 10.1007/978-3-642-33718-5_2; Li YP, 2010, LECT NOTES COMPUT SC, V6312, P791; Lim H, 2012, PROC CVPR IEEE, P1043, DOI 10.1109/CVPR.2012.6247782; Liu L, 2017, IEEE I CONF COMP VIS, P2391, DOI 10.1109/ICCV.2017.260; Lynen S, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI; Massiceti Daniela, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5118, DOI 10.1109/ICRA.2017.7989598; Middelberg S, 2014, LECT NOTES COMPUT SC, V8690, P268, DOI 10.1007/978-3-319-10605-2_18; Mikulik A, 2015, LECT NOTES COMPUT SC, V9004, P118, DOI 10.1007/978-3-319-16808-1_9; Mishchuk Anastasiya, 2017, ADV NEURAL INFORM PR; Naseer Tayyab, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2614, DOI 10.1109/ICRA.2017.7989305; Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374; Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566; Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897; Sattler T, 2017, PROC CVPR IEEE, P6175, DOI 10.1109/CVPR.2017.654; Sattler T, 2017, IEEE T PATTERN ANAL, V39, P1744, DOI 10.1109/TPAMI.2016.2611662; Sattler T, 2016, PROC CVPR IEEE, P1582, DOI 10.1109/CVPR.2016.175; Sattler T, 2015, IEEE I CONF COMP VIS, P2102, DOI 10.1109/ICCV.2015.243; Sattler T, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.76; Sattler T, 2014, LECT NOTES COMPUT SC, V8692, P828, DOI 10.1007/978-3-319-10593-2_54; Savinov N, 2017, PROC CVPR IEEE, P3929, DOI 10.1109/CVPR.2017.418; Schindler Grant, 2007, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2007.383150; Schonberger JL, 2018, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR.2018.00721; Schonberger JL, 2017, LECT NOTES COMPUT SC, V10111, P321, DOI 10.1007/978-3-319-54181-5_21; Schonberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445; Schonberger JL, 2015, PROC CVPR IEEE, P5126, DOI 10.1109/CVPR.2015.7299148; Seo PH, 2018, LECT NOTES COMPUT SC, V11214, P544, DOI 10.1007/978-3-030-01249-6_33; Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377; Sibbing D, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P56, DOI 10.1109/3DV.2013.16; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3; Svarm L, 2017, IEEE T PATTERN ANAL, V39, P1455, DOI 10.1109/TPAMI.2016.2598331; Taira H, 2018, PROC CVPR IEEE, P7199, DOI 10.1109/CVPR.2018.00752; Toft C, 2018, LECT NOTES COMPUT SC, V11206, P391, DOI 10.1007/978-3-030-01216-8_24; Torii A., 2014, IPSJ T COMPUT VIS AP, V6, P58; Torii A, 2018, IEEE T PATTERN ANAL, V40, P257, DOI 10.1109/TPAMI.2017.2667665; Torii A, 2015, IEEE T PATTERN ANAL, V37, P2346, DOI 10.1109/TPAMI.2015.2409868; Valada A, 2018, IEEE INT CONF ROBOT, P6939; Valentin J, 2015, PROC CVPR IEEE, P4400, DOI 10.1109/CVPR.2015.7299069; Walch F, 2017, IEEE I CONF COMP VIS, P627, DOI 10.1109/ICCV.2017.75; Weyand T, 2016, LECT NOTES COMPUT SC, V9912, P37, DOI 10.1007/978-3-319-46484-8_3; Weyand T, 2013, IEEE I CONF COMP VIS, P3479, DOI 10.1109/ICCV.2013.432; Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25; Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4_28; Zamir AR, 2014, IEEE T PATTERN ANAL, V36, P1546, DOI 10.1109/TPAMI.2014.2299799; Zamir AR, 2010, LECT NOTES COMPUT SC, V6314, P255, DOI 10.1007/978-3-642-15561-1_19; Zeisl B, 2015, IEEE I CONF COMP VIS, P2704, DOI 10.1109/ICCV.2015.310; Zhang W, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P33, DOI 10.1109/3dpvt.2006.80; Zheng EL, 2015, IEEE I CONF COMP VIS, P2075, DOI 10.1109/ICCV.2015.240	84	17	17	4	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					814	829		10.1109/TPAMI.2019.2941876	http://dx.doi.org/10.1109/TPAMI.2019.2941876			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE6IS	31535984	Green Submitted			2022-12-18	WOS:000616309900005
J	Li, R; Johansen, JS; Ahmed, H; Ilyevsky, TV; Wilbur, RB; Bharadwaj, HM; Siskind, JM				Li, Ren; Johansen, Jared S.; Ahmed, Hamad; Ilyevsky, Thomas, V; Wilbur, Ronnie B.; Bharadwaj, Hari M.; Siskind, Jeffrey Mark			The Perils and Pitfalls of Block Design for EEG Classification Experiments	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object classification; EEG; neuroimaging		A recent paper [1] claims to classify brain processing evoked in subjects watching ImageNet stimuli as measured with EEG and to employ a representation derived from this processing to construct a novel object classifier. That paper, together with a series of subsequent papers [2], [3], [4], [5], [6], [7], [8], claims to achieve successful results on a wide variety of computer-vision tasks, including object classification, transfer learning, and generation of images depicting human perception and thought using brain-derived representations measured through EEG. Our novel experiments and analyses demonstrate that their results crucially depend on the block design that they employ, where all stimuli of a given class are presented together, and fail with a rapid-event design, where stimuli of different classes are randomly intermixed. The block design leads to classification of arbitrary brain states based on block-level temporal correlations that are known to exist in all EEG data, rather than stimulus-related activity. Because every trial in their test sets comes from the same block as many trials in the corresponding training sets, their block design thus leads to classifying arbitrary temporal artifacts of the data instead of stimulus-related activity. This invalidates all subsequent analyses performed on this data in multiple published papers and calls into question all of the reported results. We further show that a novel object classifier constructed with a random codebook performs as well as or better than a novel object classifier constructed with the representation extracted from EEG data, suggesting that the performance of their classifier constructed with a representation extracted from EEG data does not benefit from the brain-derived representation. Together, our results illustrate the far-reaching implications of the temporal autocorrelations that exist in all neuroimaging data for classification experiments. Further, our results calibrate the underlying difficulty of the tasks involved and caution against overly optimistic, but incorrect, claims to the contrary.	[Li, Ren; Johansen, Jared S.; Ahmed, Hamad; Ilyevsky, Thomas, V; Siskind, Jeffrey Mark] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA; [Wilbur, Ronnie B.; Bharadwaj, Hari M.] Purdue Univ, Dept Speech Language & Hearing Sci, W Lafayette, IN 47907 USA; [Wilbur, Ronnie B.] Purdue Univ, Dept Linguist, W Lafayette, IN 47907 USA; [Bharadwaj, Hari M.] Purdue Univ, Weldon Sch Biomed Engn, W Lafayette, IN 47907 USA	Purdue University System; Purdue University; Purdue University West Lafayette Campus; Purdue University System; Purdue University; Purdue University West Lafayette Campus; Purdue University System; Purdue University; Purdue University West Lafayette Campus; Purdue University System; Purdue University; Purdue University West Lafayette Campus	Siskind, JM (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.	tomo.blade.lee@hotmail.com; jjohanse@purdue.edu; ahmed90@purdue.edu; tilyevsk@purdue.edu; wilbur@purdue.edu; hbharadwaj@purdue.edu; qobi@purdue.edu	Bharadwaj, Hari/GPX-1969-2022	Bharadwaj, Hari/0000-0001-8685-9630; Johansen, Jared/0000-0002-9190-7892; Li, Ren/0000-0003-2998-7104	US National Science Foundation [1522954-IIS, 1734938-IIS]; Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/Interior Business Center (DOI/IBC) [D17PC00341]; Siemens Corporation, Corporate Technology	US National Science Foundation(National Science Foundation (NSF)); Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/Interior Business Center (DOI/IBC); Siemens Corporation, Corporate Technology	This work was supported, in part, by the US National Science Foundation under Grants 1522954-IIS and 1734938-IIS, by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/Interior Business Center (DOI/IBC) contract number D17PC00341, and by Siemens Corporation, Corporate Technology. Any opinions, findings, views, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views, official policies, or endorsements, either expressed or implied, of the sponsors. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes, notwithstanding any copyright notation herein.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Barbu A, 2014, LECT NOTES COMPUT SC, V8693, P612, DOI 10.1007/978-3-319-10602-1_40; Bashivan P., 2016, INT C LEARNING REPRE; Bigdely-Shamlo N, 2008, IEEE T NEUR SYS REH, V16, P432, DOI 10.1109/TNSRE.2008.2003381; Bullmore ET, 2001, HUM BRAIN MAPP, V12, P61, DOI 10.1002/1097-0193(200102)12:2<61::AID-HBM1004>3.0.CO;2-W; Carlson T. A., 2011, J VISION, V11, P10; Cecotti H, 2011, IEEE T PATTERN ANAL, V33, P433, DOI 10.1109/TPAMI.2010.125; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Craik A, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab0ab5; Dale AM, 1999, HUM BRAIN MAPP, V8, P109, DOI 10.1002/(SICI)1097-0193(1999)8:2/3<109::AID-HBM7>3.3.CO;2-N; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Du CY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1348, DOI 10.1145/3219819.3219957; Foster MSLSED., 2017, J MED LIBR ASSOC, P105, DOI [10.5195/JMLA.2017.88, DOI 10.5195/JMLA.2017.88, 10.5195/jmla.2017.88]; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gu Q., 2011, UAI 11, P266; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Kaneshiro B, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0135697; Kavasidis I, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1809, DOI 10.1145/3123266.3127907; Kingma D.P, P 3 INT C LEARNING R; Kumar P, 2018, PERS UBIQUIT COMPUT, V22, P185, DOI 10.1007/s00779-017-1083-4; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Linkenkaer-Hansen K, 2001, J NEUROSCI, V21, P1370; Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024; Marszaek M., 2009, CVPR, P2929, DOI DOI 10.1109/CVPR.2009.5206557; Palazzo S, 2017, IEEE I CONF COMP VIS, P3430, DOI 10.1109/ICCV.2017.369; Palazzo S., 2018, ARXIV181010974; Roy Y, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab260c; Simanova I, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0014465; Siskind JM, 2015, AAAI CONF ARTIF INTE, P4067; Spampinato C., 2016, ARXIV160900344; Stewart AX, 2014, J NEUROSCI METH, V228, P1, DOI 10.1016/j.jneumeth.2014.02.014; Stober S., 2015, COMPUT SCI; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tirupattur P, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P950, DOI 10.1145/3240508.3240641; Wang CM, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/5/056013	35	17	17	8	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2021	43	1					316	333		10.1109/TPAMI.2020.2973153	http://dx.doi.org/10.1109/TPAMI.2020.2973153			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PC7WN	33211652	hybrid			2022-12-18	WOS:000597206900021
J	Yu, SJ; Giraldo, LGS; Jenssen, R; Principe, JC				Yu, Shujian; Giraldo, Luis Gonzalo Sanchez; Jenssen, Robert; Principe, Jose C.			Multivariate Extension of Matrix-Based Renyi's alpha-Order Entropy Functional	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Renyi's alpha-order entropy functional; multivariate information quantities; feature selection	FEATURE-SELECTION; MUTUAL INFORMATION	The matrix-based Renyi's alpha-order entropy functional was recently introduced using the normalized eigenspectrum of a Hermitian matrix of the projected data in a reproducing kernel Hilbert space (RKHS). However, the current theory in the matrix-based Renyi's alpha-order entropy functional only defines the entropy of a single variable or mutual information between two random variables. In information theory and machine learning communities, one is also frequently interested in multivariate information quantities, such as the multivariate joint entropy and different interactive quantities among multiple variables. In this paper, we first define the matrix-based Renyi's alpha-order joint entropy among multiple variables. We then show how this definition can ease the estimation of various information quantities that measure the interactions among multiple variables, such as interactive information and total correlation. We finally present an application to feature selection to show how our definition provides a simple yet powerful way to estimate a widely-acknowledged intractable quantity from data. A real example on hyperspectral image (HSI) band selection is also provided.	[Yu, Shujian; Principe, Jose C.] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA; [Giraldo, Luis Gonzalo Sanchez] Univ Miami, Dept Comp Sci, Coral Gables, FL 33124 USA; [Jenssen, Robert] UiT Arctic Univ Norway, Dept Phys & Technol, N-9037 Tromso, Norway	State University System of Florida; University of Florida; University of Miami; UiT The Arctic University of Tromso	Yu, SJ (corresponding author), Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.	yusjlcy9011@ufl.edu; lgsanchez@cs.miami.edu; robert.jenssen@uit.no; principe@cnel.ufl.edu	principe, jose/N-8099-2014		U.S. ONR [N00014-18-1-2306]; DARPA [FA9453-18-1-0039]; Norwegian Research Council FRIPRO [239844]	U.S. ONR(Office of Naval Research); DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); Norwegian Research Council FRIPRO(Research Council of Norway)	This work was funded in part by the U.S. ONR under grant N00014-18-1-2306, in part by the DARPA under grant FA9453-18-1-0039, and in part by the Norwegian Research Council FRIPRO grant no. 239844 on developing the Next Generation Learning Machines.	BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; Beer, 2010, ARXIV10042515, DOI DOI 10.HTTPS://ARXIV.0RG/ABS/1004.2515; Bell AJ, 2003, P SOC PHOTO-OPT INS, V5102, P383; Bhatia R, 2006, AM MATH MON, V113, P221, DOI 10.2307/27641890; Brown G, 2012, J MACH LEARN RES, V13, P27; Brown IP, 2009, 2009 IEEE INTERNATIONAL ELECTRIC MACHINES & DRIVES CONFERENCE, VOLS 1-3, P49, DOI 10.1109/IEMDC.2009.5075182; Camps-Valls G, 2005, IEEE T GEOSCI REMOTE, V43, P1351, DOI 10.1109/TGRS.2005.846154; Camps-Valls G, 2014, IEEE SIGNAL PROC MAG, V31, P45, DOI 10.1109/MSP.2013.2279179; Demsar J, 2006, J MACH LEARN RES, V7, P1; Fano R. M., 1961, TRANSMISSION INFORM; Feng J, 2016, IEEE T GEOSCI REMOTE, V54, P6516, DOI 10.1109/TGRS.2016.2585961; Giraldo LGS, 2015, IEEE T INFORM THEORY, V61, P535, DOI 10.1109/TIT.2014.2370058; Guyon I., 2005, ADV NEURAL INFORM PR, V17, P545; Jakulin A., 2003, CS0308002 ARXIV; Jia S, 2012, IEEE J-STARS, V5, P531, DOI 10.1109/JSTARS.2012.2187434; Landgrebe D.A, 2005, SIGNAL THEORY METHOD, V29; LEWIS DD, 1992, SPEECH AND NATURAL LANGUAGE, P212; Li JD, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3136625; Lopez-Paz D., 2013, ADV NEURAL INFORM PR, V26, P1, DOI DOI 10.1214/A0S/1176345528; MacKay D. J. C., 2003, INFORM THEORY INFERE, P269; McGill WJ., 1954, PSYCHOMETRIKA, V19, P97, DOI 10.1007/BF02289159; Muller-Lennert M, 2013, J MATH PHYS, V54, DOI 10.1063/1.4838856; Nemenyi P. B., 1963, THESIS; Vinh NX, 2014, AAAI CONF ARTIF INTE, P2092; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159; Principe JC, 2010, INFORM SCI STAT, P1, DOI 10.1007/978-1-4419-1570-2; Renyi A., 1961, P 4 BERKELEY S MATH, V1; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Silverman B. W., 1986, DENSITY ESTIMATION S, V26; Timme N, 2014, J COMPUT NEUROSCI, V36, P119, DOI 10.1007/s10827-013-0458-4; Ver Steeg G., 2016, INT C MACHINE LEARNI, P164; Verdu S, 2015, 2015 INFORMATION THEORY AND APPLICATIONS WORKSHOP (ITA), P1, DOI 10.1109/ITA.2015.7308959; WATANABE S, 1960, IBM J RES DEV, V4, P66, DOI 10.1147/rd.41.0066; Yang HH, 2000, ADV NEUR IN, V12, P687; YEUNG RW, 1991, IEEE T INFORM THEORY, V37, P466, DOI 10.1109/18.79902; Yu CY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010113; Yu S., 2018, ARXIV180406537	39	17	17	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2020	42	11					2960	2966		10.1109/TPAMI.2019.2932976	http://dx.doi.org/10.1109/TPAMI.2019.2932976			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NX0AD	31395536				2022-12-18	WOS:000575381000016
J	Carletti, V; Greco, A; Percannella, G; Vento, M				Carletti, Vincenzo; Greco, Antonio; Percannella, Gennaro; Vento, Mario			Age from Faces in the Deep Learning Revolution	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Estimation; Deep learning; Face recognition; Training; Face detection; Age estimation; deep learning; face analysis; survey; review	NEURAL-NETWORKS; FEATURES; GENDER; CLASSIFICATION; DATABASE; IMAGES	Face analysis includes a variety of specific problems as face detection, person identification, gender and ethnicity recognition, just to name the most common ones; in the last two decades, significant research efforts have been devoted to the challenging task of age estimation from faces, as witnessed by the high number of published papers. The explosion of the deep learning paradigm, that is determining a spectacular increasing of the performance, is in the public eye; consequently, the number of approaches based on deep learning is impressively growing and this also happened for age estimation. The exciting results obtained have been recently surveyed on almost all the specific face analysis problems; the only exception stands for age estimation, whose last survey dates back to 2010 and does not include any deep learning based approach to the problem. This paper provides an analysis of the deep methods proposed in the last six years; these are analysed from different points of view: the network architecture together with the learning procedure, the used datasets, data preprocessing and augmentation, and the exploitation of additional data coming from gender, race and face expression. The review is completed by discussing the results obtained on public datasets, so as the impact of different aspects on system performance, together with still open issues.	[Carletti, Vincenzo; Greco, Antonio; Percannella, Gennaro; Vento, Mario] Univ Salerno, Dept Comp & Elect Engn & Appl Math, I-84084 Fisciano, SA, Italy	University of Salerno	Vento, M (corresponding author), Univ Salerno, Dept Comp & Elect Engn & Appl Math, I-84084 Fisciano, SA, Italy.	vcarletti@unisa.it; agreco@unisa.it; pergen@unisa.it; mvento@unisa.it		Percannella, Gennaro/0000-0002-1227-0353; Vento, Mario/0000-0002-2948-741X				Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Antipov G, 2017, PATTERN RECOGN, V72, P15, DOI 10.1016/j.patcog.2017.06.031; Antipov G, 2016, IEEE COMPUT SOC CONF, P801, DOI 10.1109/CVPRW.2016.105; Basak D, 2007, NEURAL INFORM PROCES, V11, P203, DOI DOI 10.1007/978-1-4302-5990-9_4; Bianco S, 2018, IEEE ACCESS, V6, P64270, DOI 10.1109/ACCESS.2018.2877890; Bin Iqbal MT, 2017, IEEE T INF FOREN SEC, V12, P2505, DOI 10.1109/TIFS.2017.2695456; Box G. E. P., 1992, QUALITY RELIABILITY, V8, P17, DOI DOI 10.1002/qre.4680080105; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230; Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020; Chang KY, 2015, IEEE T IMAGE PROCESS, V24, P785, DOI 10.1109/TIP.2014.2387379; Chen BC, 2014, LECT NOTES COMPUT SC, V8694, P768, DOI 10.1007/978-3-319-10599-4_49; Chen D, 2014, LECT NOTES COMPUT SC, V8694, P109, DOI 10.1007/978-3-319-10599-4_8; Chen J, 2015, SCI REP-UK, V5, DOI 10.1038/srep11438; Christian Szegedy, 2014, Arxiv, DOI arXiv:1312.6199; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cordella LP, 1999, PATTERN ANAL APPL, V2, P205, DOI 10.1007/s100440050029; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dantcheva A, 2016, IEEE T INF FOREN SEC, V11, P441, DOI 10.1109/TIFS.2015.2480381; Dehghan A, 2017, ARXIV170204280; Dhimar T, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2243, DOI 10.1109/WiSPNET.2016.7566541; Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089; Dollar D, 2009, DIR DEV, P1; Dong Y, 2016, NEUROCOMPUTING, V187, P4, DOI 10.1016/j.neucom.2015.09.115; Duan MX, 2018, IEEE T INF FOREN SEC, V13, P758, DOI 10.1109/TIFS.2017.2766583; Ebner NC, 2010, BEHAV RES METHODS, V42, P351, DOI 10.3758/BRM.42.1.351; Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646; Escalera S., 2016, P IEEE C COMP VIS PA, P1; Escalera S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P243, DOI 10.1109/ICCVW.2015.40; Feng SH, 2017, IEEE T MULTIMEDIA, V19, P136, DOI 10.1109/TMM.2016.2608786; Freund Y, 1996, P 13 INT C MACH LEAR, P148, DOI DOI 10.5555/3091696.3091715; Fu SY, 2014, IEEE T PATTERN ANAL, V36, P2483, DOI 10.1109/TPAMI.2014.2321570; Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36; Gallagher AC, 2009, PROC CVPR IEEE, P256, DOI 10.1109/CVPRW.2009.5206828; Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Glantz S., 2005, PRIMER BIOSTATISTICS, P126; Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280; Gurpinar F., 2016, P IEEE C COMP VIS PA, P80; Han H, 2018, IEEE T PATTERN ANAL, V40, P2597, DOI 10.1109/TPAMI.2017.2738004; Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; HEBDA B, 2016, FED CONF COMPUT SCI, P787, DOI DOI 10.15439/2016F472; Hou L., 2016, ARXIV161105916; Hou L, 2017, PR MACH LEARN RES, V54, P430; Howard A.G., 2017, MOBILENETS EFFICIENT; Hu ZZ, 2017, IEEE T IMAGE PROCESS, V26, P3087, DOI 10.1109/TIP.2016.2633868; Huang GS, 2007, 2007 7TH IEEE CONFERENCE ON NANOTECHNOLOGY, VOL 1-3, P7, DOI 10.1109/NANO.2007.4601129; Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126; Huerta I, 2015, PATTERN RECOGN LETT, V68, P239, DOI 10.1016/j.patrec.2015.06.006; Huo ZW, 2016, IEEE COMPUT SOC CONF, P722, DOI 10.1109/CVPRW.2016.95; Jun B, 2013, IEEE T PATTERN ANAL, V35, P1423, DOI 10.1109/TPAMI.2012.219; K. I. of Technology, 2011, BEF BENCHM FAC IM AN; Kazemi V., 2014, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2014.241; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Kuang ZH, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P338, DOI 10.1109/ICCVW.2015.52; Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553; Lapuschkin S, 2017, IEEE INT CONF COMP V, P1629, DOI 10.1109/ICCVW.2017.191; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352; Li HX, 2014, PROC CVPR IEEE, P1843, DOI 10.1109/CVPR.2014.238; Li HX, 2013, IEEE I CONF COMP VIS, P793, DOI 10.1109/ICCV.2013.103; Li K, 2017, PATTERN RECOGN, V66, P95, DOI 10.1016/j.patcog.2017.01.007; Li S., 2018, ARXIV180408348; Li SX, 2015, PROC CVPR IEEE, P222, DOI 10.1109/CVPR.2015.7298618; Lin HT, 2012, NEURAL COMPUT, V24, P1329, DOI 10.1162/NECO_a_00265; Liu H, 2019, IEEE T CIRC SYST VID, V29, P486, DOI 10.1109/TCSVT.2017.2782709; Liu H, 2018, IEEE T INF FOREN SEC, V13, P292, DOI 10.1109/TIFS.2017.2746062; Liu H, 2017, PATTERN RECOGN, V66, P82, DOI 10.1016/j.patcog.2016.10.026; Liu KH, 2015, IEEE T INF FOREN SEC, V10, P2408, DOI 10.1109/TIFS.2015.2462732; Liu XF, 2015, ADV METEOROL, V2015, DOI 10.1155/2015/950262; Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004; Lou ZY, 2018, IEEE T PATTERN ANAL, V40, P365, DOI 10.1109/TPAMI.2017.2679739; Lu JW, 2015, IEEE T IMAGE PROCESS, V24, P5356, DOI 10.1109/TIP.2015.2481327; Malli RC, 2016, IEEE COMPUT SOC CONF, P714, DOI 10.1109/CVPRW.2016.94; Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35; Mathias M, 2014, LECT NOTES COMPUT SC, V8692, P720, DOI 10.1007/978-3-319-10593-2_47; Meyers E, 2008, INT J COMPUT VISION, V76, P93, DOI 10.1007/s11263-007-0058-8; Microsoft, 2018, MICR PROJ OXF API; Minear M, 2004, BEHAV RES METH INS C, V36, P630, DOI 10.3758/BF03206543; Ng CB, 2015, PATTERN ANAL APPL, V18, P739, DOI 10.1007/s10044-015-0499-6; NIU ZX, 2016, PROC CVPR IEEE, P4920, DOI DOI 10.1109/CVPR.2016.532; Oro D., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P530, DOI 10.1109/ICCVW.2011.6130288; Osman OF, 2019, IEEE TETCI, V3, P271, DOI 10.1109/TETCI.2018.2864554; Ozbulak G, 2016, LECT NOTE INFORM, VP-260; Pandey A, 2015, 8th International Symposium on Visual Information Communication and Interaction (VINCI 2015), P109, DOI 10.1145/2801040.2801049; Qawaqneh Zakariya, 2017, ARXIV170901664; Quinonero-Candela JQ, 2005, J MACH LEARN RES, V6, P1939; Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233; Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137; Ranjana J. Shourie, 2015, 2015 40th International Conference on Infrared, Millimeter and Terahertz Waves (IRMMW-THz), P1, DOI 10.1109/IRMMW-THz.2015.7327917; Redmon J., 2017, PREPRINT; Redmon J, 2016, YOU ONLY LOOK ONCE U, DOI [DOI 10.1109/CVPR.2016.91, 10.1109/CVPR.2016.91]; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ren Y, 2016, IEEE COMPUT INTELL M, V11, P41, DOI 10.1109/MCI.2015.2471235; Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341; Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3; Rothe R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P252, DOI 10.1109/ICCVW.2015.41; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127; Sawant MM, 2019, IEEE ACCESS, V7, P9142, DOI 10.1109/ACCESS.2018.2889873; Shu XB, 2016, NEUROCOMPUTING, V208, P249, DOI 10.1016/j.neucom.2016.01.101; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Srinivas N, 2017, IEEE INT CONF AUTOMA, P953, DOI 10.1109/FG.2017.118; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Sun YL, 2018, IEEE T PATTERN ANAL, V40, P332, DOI 10.1109/TPAMI.2017.2669035; Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g; Taheri S, 2019, NEUROCOMPUTING, V329, P300, DOI 10.1016/j.neucom.2018.10.071; Tan ZC, 2018, IEEE T PATTERN ANAL, V40, P2610, DOI 10.1109/TPAMI.2017.2779808; Tsymbal A., 2003, Information Fusion, V4, P87, DOI 10.1016/S1566-2535(03)00004-6; Uricar M, 2016, IEEE COMPUT SOC CONF, P730, DOI 10.1109/CVPRW.2016.96; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wan J, 2018, IEEE T CYBERNETICS, V48, P2531, DOI 10.1109/TCYB.2017.2741998; Wang F, 2017, IEEE INT CONF AUTOMA, P173, DOI 10.1109/FG.2017.30; Wang JW, 2013, 2013 IEEE 10TH INTERNATIONAL CONFERENCE ON AND 10TH INTERNATIONAL CONFERENCE ON AUTONOMIC AND TRUSTED COMPUTING (UIC/ATC) UBIQUITOUS INTELLIGENCE AND COMPUTING, P17, DOI 10.1109/UIC-ATC.2013.19; Wang SZ, 2016, IEEE T CYBERNETICS, V46, P827, DOI 10.1109/TCYB.2015.2416321; Wang XL, 2015, IEEE WINT CONF APPL, P534, DOI 10.1109/WACV.2015.77; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wu Y.Q, 2017, IEEE T SYST MAN CYBE; Xing JH, 2017, PATTERN RECOGN, V66, P106, DOI 10.1016/j.patcog.2017.01.005; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943; Yan JJ, 2014, IMAGE VISION COMPUT, V32, P790, DOI 10.1016/j.imavis.2013.12.004; Yan S, 2008, PR IEEE COMP DESIGN, P142, DOI 10.1109/ICCD.2008.4751853; Yang H.-F., 2013, NETWORKS, V35, P1872, DOI DOI 10.5244/C.29.55; Yang HF, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3152118; Yang H, 2014, C IND ELECT APPL, P1, DOI [10.1109/ICIEA.2014.6931121, 10.1016/j.ceramint.2014.05.109]; Yang X, 2015, PROCEEDINGS OF 2015 INTERNATIONAL SYMPOSIUM - COLLEGE FOREIGN LANGUAGES EDUCATION REFORM AND INNOVATION, P103; Yang Y, 2016, IEEE IMAGE PROC, P584, DOI 10.1109/ICIP.2016.7532424; Yi D., 2014, LEARNING FACE REPRES, V1411, P7923; Yi D, 2015, LECT NOTES COMPUT SC, V9005, P144, DOI 10.1007/978-3-319-16811-1_10; Yoo B, 2018, IEEE SIGNAL PROC LET, V25, P808, DOI 10.1109/LSP.2018.2822241; Zafeiriou S, 2015, COMPUT VIS IMAGE UND, V138, P1, DOI 10.1016/j.cviu.2015.03.015; Zhan J, 2014, DES AUT CON, DOI 10.1145/2593069.2593165; Zhang K, 2018, IEEE T CIRC SYST VID, V28, P1303, DOI 10.1109/TCSVT.2017.2654543; Zhang K, 2017, IEEE ACCESS, V5, P22492, DOI 10.1109/ACCESS.2017.2761849; Zhang Yu, 2017, ARXIV170708114, DOI DOI 10.1109/TKDE.2021.3070203; Zheng S., 2012, THESIS; Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X; Zhu Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P267, DOI 10.1109/ICCVW.2015.43; Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907	145	17	17	2	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2020	42	9					2113	2132		10.1109/TPAMI.2019.2910522	http://dx.doi.org/10.1109/TPAMI.2019.2910522			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MW9MI	30990174				2022-12-18	WOS:000557354900004
J	Haeffele, BD; Vidal, R				Haeffele, Benjamin D.; Vidal, Rene			Structured Low-Rank Matrix Factorization: Global Optimality, Algorithms, and Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Optimization; Machine learning; Principal component analysis; Videos; Standards; Calcium; Imaging; Low-rank matrix factorization; non-convex optimization; calcium imaging; hyperspectral compressed recovery	THRESHOLDING ALGORITHM; OPTIMIZATION	Convex formulations of low-rank matrix factorization problems have received considerable attention in machine learning. However, such formulations often require solving for a matrix of the size of the data matrix, making it challenging to apply them to large scale datasets. Moreover, in many applications the data can display structures beyond simply being low-rank, e.g., images and videos present complex spatio-temporal structures that are largely ignored by standard low-rank methods. In this paper we study a matrix factorization technique that is suitable for large datasets and captures additional structure in the factors by using a particular form of regularization that includes well-known regularizers such as total variation and the nuclear norm as particular cases. Although the resulting optimization problem is non-convex, we show that if the size of the factors is large enough, under certain conditions, any local minimizer for the factors yields a global minimizer. A few practical algorithms are also provided to solve the matrix factorization problem, and bounds on the distance from a given approximate solution of the optimization problem to the global optimum are derived. Examples in neural calcium imaging video segmentation and hyperspectral compressed recovery show the advantages of our approach on high-dimensional datasets.	[Haeffele, Benjamin D.; Vidal, Rene] Johns Hopkins Univ, Dept Biomed Engn, Math Inst Data Sci, Baltimore, MD 21218 USA	Johns Hopkins University	Haeffele, BD (corresponding author), Johns Hopkins Univ, Dept Biomed Engn, Math Inst Data Sci, Baltimore, MD 21218 USA.	bhaeffele@jhu.edu; rvidal@cis.jhu.edu			NSF [1447822, 1618485, 1618637, IARPA DIVA D17PC00345]	NSF(National Science Foundation (NSF))	Work supported by NSF grants 1447822, 1618485, 1618637 and IARPA DIVA D17PC00345.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Akerboom J, 2012, J NEUROSCI, V32, P13819, DOI 10.1523/JNEUROSCI.2601-12.2012; Bach F., 2013, ARXIV13093117V1; Bach F., 2008, ARXIV08121869V1; Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542; Birkholz H, 2011, J COMPUT APPL MATH, V235, P2502, DOI 10.1016/j.cam.2010.11.003; Boyd S, 2004, CONVEX OPTIMIZATION; Cabral R, 2013, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2013.309; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Combettes PL, 2011, SPRINGER SER OPTIM A, V49, P185, DOI 10.1007/978-1-4419-9569-8_10; d'Aspremont A, 2007, SIAM REV, V49, P434, DOI 10.1137/050645506; Golbabaee M, 2012, IEEE IMAGE PROC, P933, DOI 10.1109/ICIP.2012.6467014; Haeffele BD, 2014, PR MACH LEARN RES, V32, P2007; Hendrickx JM, 2010, SIAM J MATRIX ANAL A, V31, P2802, DOI 10.1137/09076773X; Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Lee DD, 2001, ADV NEUR IN, V13, P556; Mairal J., 2009, ADV NEURAL INFORM PR, P1033; Mairal J, 2010, J MACH LEARN RES, V11, P19; Pnevmatikakis E. A., 2013, COMPUT SYST NEUROSCI; Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835; Richard E., 2014, P ADV NEUR INF PROC, P3284; Romberg J, 2009, SIAM J IMAGING SCI, V2, P1098, DOI 10.1137/08072975X; Ryan R. A., 2002, SPRINGER MONOGRAPHS; Spruston N, 2008, NAT REV NEUROSCI, V9, P206, DOI 10.1038/nrn2286; Srebro Nathan, 2004, ADV NEURAL INFORM PR, V17, P1329; Stosiek C, 2003, P NATL ACAD SCI USA, V100, P7319, DOI 10.1073/pnas.1232232100; Tibshirani RJ, 2011, ANN STAT, V39, P1335, DOI 10.1214/11-AOS878; Vogelstein JT, 2010, J NEUROPHYSIOL, V104, P3691, DOI 10.1152/jn.01073.2009; Xu YY, 2013, SIAM J IMAGING SCI, V6, P1758, DOI 10.1137/120887795; Yu Y, 2017, BMC PUBLIC HEALTH, V18, DOI 10.1186/s12889-017-4632-x; Zhang HY, 2014, IEEE T GEOSCI REMOTE, V52, P4729, DOI 10.1109/TGRS.2013.2284280; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	36	17	19	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2020	42	6					1468	1482		10.1109/TPAMI.2019.2900306	http://dx.doi.org/10.1109/TPAMI.2019.2900306			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR3TM	30794507	Green Submitted			2022-12-18	WOS:000535615700013
J	Jiang, SH; Ding, ZM; Fu, Y				Jiang, Shuhui; Ding, Zhengming; Fu, Yun			Heterogeneous Recommendation via Deep Low-Rank Sparse Collective Factorization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Optimization; Numerical models; Sparse matrices; Motion pictures; Stochastic processes; Collaboration; Sports; Recommendation; cross-domain; collaborative factorization; low-rank decomposition	PERSONALIZATION; ALGORITHM	A real-world recommender usually adopts heterogeneous types of user feedbacks, for example, numerical ratings such as 5-star grades and binary ratings such as likes and dislikes. In this work, we focus on transferring knowledge from binary ratings to numerical ratings, facing a more serious data sparsity problem. Conventional Collective Factorization methods usually assume that there are shared user and item latent factors across multiple related domains, but may ignore the shared common knowledge of rating patterns. Furthermore, existing works may also fail to consider the hierarchical structures in the heterogeneous recommendation scenario (i.e., genre, sub-genre, detailed-category). To address these challenges, in this paper, we propose a novel Deep Low-rank Sparse Collective Factorization (DLSCF) framework for heterogeneous recommendation. Specifically, we adopt low-rank sparse decomposition to capture the common rating patterns in related domains while splitting the domain-specific patterns. We also factorize the model in multiple layers to capture the affiliation relation between latent categories and sub-categories. We propose both batch and Stochastic Gradient Descent (SGD) based optimization algorithms for solving DLSCF. Experimental results on MoviePilot, Netfilx, Flixter, MovieLens10M and MovieLens20M datasets demonstrate the effectiveness of the proposed algorithms, by comparing them with several state-of-the-art batch and SGD based approaches.	[Jiang, Shuhui] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA; [Ding, Zhengming] Indiana Univ Purdue Univ, Dept Comp Informat & Technol, Indianapolis, IN 46202 USA; [Fu, Yun] Northeastern Univ, Coll Engn, Khoury Coll Comp & Informat Sci, Dept Elect & Comp Engn, Boston, MA 02115 USA	Northeastern University; Indiana University System; Indiana University-Purdue University Indianapolis; Northeastern University	Jiang, SH (corresponding author), Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.	shjiang@ece.neu.edu; zd2@iu.edu; yunfu@ece.neu.edu	Ding, Zhengming/AAJ-2918-2021	Ding, Zhengming/0000-0002-6994-5278	NSF IIS award [1651902]; U.S. Army Research Office Young Investigator Award [W911NF-14-1-0218]	NSF IIS award(National Science Foundation (NSF)); U.S. Army Research Office Young Investigator Award	This work is supported in part by the NSF IIS award 1651902 and U.S. Army Research Office Young Investigator Award W911NF-14-1-0218.	Abel F, 2013, USER MODEL USER-ADAP, V23, P169, DOI 10.1007/s11257-012-9131-2; Bao ZM, 2015, 2015 FIRST INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE THEORY, SYSTEMS AND APPLICATIONS (CCITSA 2015), P119, DOI 10.1109/CCITSA.2015.22; Berkovsky S, 2008, USER MODEL USER-ADAP, V18, P245, DOI 10.1007/s11257-007-9042-9; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Cao B., 2010, ICML; Cremonesi P., 2011, 2011 IEEE International Conference on Data Mining Workshops, P496, DOI 10.1109/ICDMW.2011.57; Cremonesi P, 2014, PROCEEDINGS OF THE 8TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'14), P297, DOI 10.1145/2645710.2645769; Ding ZM, 2016, LECT NOTES COMPUT SC, V9910, P567, DOI 10.1007/978-3-319-46466-4_34; Ding ZM, 2014, IEEE DATA MINING, P110, DOI 10.1109/ICDM.2014.29; Ding Z, 2014, AAAI CONF ARTIF INTE, P1192; Du Y, 2009, ICIA: 2009 INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, VOLS 1-3, P1617; Enrich M, 2013, LECT NOTES BUS INF P, V152, P101; Fernandez-Tobias I., 2014, P CBRECSYS RECSYS OC, P34; Jiang SH, 2016, AAAI CONF ARTIF INTE, P1223; Jiang SH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P163, DOI 10.1145/3123266.3123361; Keshavan R., 2009, ADV NEURAL INFORM PR, P952; Koren Y., 2008, P 14 ACM SIGKDD INT, P426, DOI DOI 10.1145/1401890.1401944; Koren Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1644873.1644874; Lee CH, 2001, EXPERT SYST APPL, V21, P131, DOI 10.1016/S0957-4174(01)00034-3; Li B, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P2052; Liu H, 2010, IEEE IMAGE PROC, P1445, DOI 10.1109/ICIP.2010.5650235; Lu K., 2012, AIRS 2012 INFORM RET, P211; Maleszka M, 2013, KNOWL-BASED SYST, V47, P1, DOI 10.1016/j.knosys.2013.02.016; Moreno Orly, 2012, CIKM, P425, DOI DOI 10.1145/2396761.2396817; Pan W., 2011, AAAI 2011, P2318, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-386; Pan WK, 2014, IEEE INTELL SYST, V29, P48, DOI 10.1109/MIS.2014.2; Pan WK, 2013, ARTIF INTELL, V197, P39, DOI 10.1016/j.artint.2013.01.003; Pan WK, 2010, AAAI CONF ARTIF INTE, P230; Sahebi S., 2015, P 9 ACM C REC SYST, P131; Salakhutdinov R., 2007, ADV NEURAL INF PROCE, V20, P1257; Sarwar B., 2000, TR00043 MINN U MINN; Shapira B, 2013, USER MODEL USER-ADAP, V23, P211, DOI 10.1007/s11257-012-9128-x; Singh A, 2008, INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P650; Tiroshi Amit, 2013, P 7 ACM C REC SYST, P319, DOI DOI 10.1145/2507157.2507206; Trigeorgis G, 2014, PR MACH LEARN RES, V32, P1692; Wang J., 2013, P 7 ACM C REC SYST, P237; Wang SH, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1813; Wang X, 2013, SIXTH INTERNATIONAL CONFERENCE ON NONLINEAR MECHANICS (ICNM-VI), P161; Wang YG, 2016, 2016 INTERNATIONAL CONFERENCE ON ROBOTS & INTELLIGENT SYSTEM (ICRIS), P63, DOI 10.1109/ICRIS.2016.13; Wang ZY, 2016, PROC CVPR IEEE, P4792, DOI 10.1109/CVPR.2016.518; Xin X, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1827; Xu G., 2013, P 22 INT C WORLD WID, P595, DOI DOI 10.1145/2488388.2488441; Yang JF, 2009, SIAM J IMAGING SCI, V2, P569, DOI 10.1137/080730421; Zhang Y, 2010, ALTERNATING DIRECTIO; Zhang YuXia, 2010, Chinese Journal of Zoonoses, V26, P725; Zhao HD, 2017, AAAI CONF ARTIF INTE, P2921	47	17	20	2	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2020	42	5					1097	1111		10.1109/TPAMI.2019.2894137	http://dx.doi.org/10.1109/TPAMI.2019.2894137			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LA0ZT	30668466				2022-12-18	WOS:000523685800007
J	Whang, JJ; Hou, YY; Gleich, DF; Dhillon, IS				Whang, Joyce Jiyoung; Hou, Yangyang; Gleich, David F.; Dhillon, Inderjit S.			Non-Exhaustive, Overlapping Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustering algorithms; Linear programming; Kernel; Iterative methods; Computer science; Anomaly detection; Task analysis; Overlapping clustering; K-Means; outlier; semidefinite programming; graph clustering; community detection	ALGORITHM; CONVERGENCE; CUTS	Traditional clustering algorithms, such as K-Means, output a clustering that is disjoint and exhaustive, i.e., every single data point is assigned to exactly one cluster. However, in many real-world datasets, clusters can overlap and there are often outliers that do not belong to any cluster. While this is a well-recognized problem, most existing algorithms address either overlap or outlier detection and do not tackle the problem in a unified way. In this paper, we propose an intuitive objective function, which we call the NEO-K-Means (Non-Exhaustive, Overlapping K-Means) objective, that captures the issues of overlap and non-exhaustiveness in a unified manner. Our objective function can be viewed as a reformulation of the traditional K-Means objective, with easy-to-understand parameters that capture the degrees of overlap and non-exhaustiveness. By considering an extension to weighted kernel K-Means, we show that we can also apply our NEO-K-Means idea to overlapping community detection, which is an important task in network analysis. To optimize the NEO-K-Means objective, we develop not only fast iterative algorithms but also more sophisticated algorithms using low-rank semidefinite programming techniques. Our experimental results show that the new objective and algorithms are effective in finding ground-truth clusterings that have varied overlap and non-exhaustiveness; for the case of graphs, we show that our method outperforms state-of-the-art overlapping community detection algorithms.	[Whang, Joyce Jiyoung] Sungkyunkwan Univ SKKU, Dept Comp Sci & Engn, Suwon 440746, South Korea; [Hou, Yangyang; Gleich, David F.] Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA; [Dhillon, Inderjit S.] Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA	Sungkyunkwan University (SKKU); Purdue University System; Purdue University; Purdue University West Lafayette Campus; University of Texas System; University of Texas Austin	Whang, JJ (corresponding author), Sungkyunkwan Univ SKKU, Dept Comp Sci & Engn, Suwon 440746, South Korea.	jjwhang@skku.edu; hou13@purdue.edu; dgleich@purdue.edu; inderjit@cs.utexas.edu		Gleich, David/0000-0002-8107-6474	NRF of Korea - MOE [2016R1D1A1B03934766, NRF-2010-0020210]; Engineering Research Center Program through the NRF - Korean Government MSIT [NRF-2018R1A5 A1059921]; NSF CAREER [CCF-1149756, IIS-1422918, IIS-1546488]; NSF Center for Science of Information STC [CCF-0939370]; DARPA SIMPLEX; Sloan Research Fellowship; NSF [CCF-1320746, IIS-1546452]	NRF of Korea - MOE(National Research Foundation of Korea); Engineering Research Center Program through the NRF - Korean Government MSIT(Ministry of Science & ICT (MSIT), Republic of Korea); NSF CAREER(National Science Foundation (NSF)NSF - Office of the Director (OD)); NSF Center for Science of Information STC; DARPA SIMPLEX; Sloan Research Fellowship(Alfred P. Sloan Foundation); NSF(National Science Foundation (NSF))	This research was supported by Basic Science Research Program through the NRF of Korea funded by MOE (2016R1D1A1B03934766 and NRF-2010-0020210) and the Engineering Research Center Program through the NRF funded by the Korean Government MSIT (NRF-2018R1A5 A1059921) to JW, by NSF CAREER award CCF-1149756, IIS-1422918, IIS-1546488, NSF Center for Science of Information STC (CCF-0939370), DARPA SIMPLEX, and Sloan Research Fellowship to DG and by NSF grants CCF-1320746 and IIS-1546452 to ID. Joyce Jiyoung Whang and Yangyang Hou contributed equally to this work.	Banerjee A, 2005, P 11 ACM SIGKDD INT, P532, DOI DOI 10.1145/1081870.1081932; Benson AR, 2016, SCIENCE, V353, P163, DOI 10.1126/science.aad9029; Bezdek J. C., 1984, COMPUT GEOSCIENCES, V10; Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009; Burt G., 1992, STRUCTURAL HOLES SOC, P9; BYRD RH, 1995, SIAM J SCI COMPUT, V16, P1190, DOI 10.1137/0916069; Chawla S., 2013, P 2013 SIAM INT C DA; Chen YL, 2006, EUR J OPER RES, V173, P762, DOI 10.1016/j.ejor.2005.06.056; Cleuziou G, 2008, INT C PATT RECOG, P563; Coscia M., 2012, P 18 ACM SIGKDD INT, P615; Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI [10.1109/TPAMI.2007.1115, 10.1109/TP'AMI.2007.1115]; Elisseeff A, 2002, ADV NEUR IN, V14, P681; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Grant M., CVX MATLAB SOFTWARE; Hou Y., 2016, SIAM INT C DATA MINI, P297, DOI DOI 10.1137/1.9781611974348.34; Hou YY, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P427, DOI 10.1145/2783258.2783398; Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011; Knuth DE., 1993, STANFORD GRAPH BASE; Kulis B., 2007, INT C ART INT STAT, P235; Kumar A, 2010, ANN IEEE SYMP FOUND, P299, DOI 10.1109/FOCS.2010.35; Lancichinetti A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018961; Lang K., 2005, ADV NEURAL INFORM PR, P715; Leskovec J., STANFORD NETWORK ANA; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Lu HB, 2012, INT CONF DAT MIN WOR, P486, DOI 10.1109/ICDMW.2012.16; Lusseau D, 2003, BEHAV ECOL SOCIOBIOL, V54, P396, DOI 10.1007/s00265-003-0651-y; Parikh Neal, 2014, Foundations and Trends in Optimization, V1, P127, DOI 10.1561/2400000003; Peng JM, 2007, SIAM J OPTIMIZ, V18, P186, DOI 10.1137/050641983; Peng L, 2005, ZI SCH BUS FIN MA, P1, DOI 10.1007/0-387-25881-7_1; Pennanen T, 2002, MATH OPER RES, V27, P170, DOI 10.1287/moor.27.1.170.331; Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882; PUKELSHEIM F, 1994, AM STAT, V48, P88, DOI 10.2307/2684253; Rockafellar R. T., MATH OPER RES, V1, P97; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Strehl A., 2003, Journal of Machine Learning Research, V3, P583, DOI 10.1162/153244303321897735; Sun DF, 2015, SIAM J OPTIMIZ, V25, P882, DOI 10.1137/140964357; Trohidis K, 2011, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2011-426793; Vandaele A., 2015, CORR; Whang JJ, 2015, NONEXHAUSTIVE OVERLA, P936; Whang JJ, 2016, IEEE T KNOWL DATA EN, V28, P1272, DOI 10.1109/TKDE.2016.2518687; Xie JR, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2501654.2501657; Xing E. P., 2003, UCBUSD31265; Yang LQ, 2015, MATH PROGRAM COMPUT, V7, P331, DOI 10.1007/s12532-015-0082-6; Yang YY, 2013, PROCEEDINGS OF THE 2013 8TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE & EDUCATION (ICCSE 2013), P587	46	17	17	2	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2019	41	11					2644	2659		10.1109/TPAMI.2018.2863278	http://dx.doi.org/10.1109/TPAMI.2018.2863278			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JH6TG	30080141	hybrid			2022-12-18	WOS:000492900900001
J	Han, H; Li, J; Jain, AK; Shan, SG; Chen, XL				Han, Hu; Li, Jie; Jain, Anil K.; Shan, Shiguang; Chen, Xilin			Tattoo Image Search at Scale: Joint Detection and Compact Representation Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Large-scale tattoo search; joint detection and representation learning; sketch based search; multi-task learning	RETRIEVAL; HASH	The explosive growth of digital images in video surveillance and social media has led to the significant need for efficient search of persons of interest in law enforcement and forensic applications. Despite tremendous progress in primary biometric traits (e.g., face and fingerprint) based person identification, a single biometric trait alone can not meet the desired recognition accuracy in forensic scenarios. Tattoos, as one of the important soft biometric traits, have been found to be valuable for assisting in person identification. However, tattoo search in a large collection of unconstrained images remains a difficult problem, and existing tattoo search methods mainly focus on matching cropped tattoos, which is different from real application scenarios. To close the gap, we propose an efficient tattoo search approach that is able to learn tattoo detection and compact representation jointly in a single convolutional neural network (CNN) via multi-task learning. While the features in the backbone network are shared by both tattoo detection and compact representation learning, individual latent layers of each sub-network optimize the shared features toward the detection and feature learning tasks, respectively. We resolve the small batch size issue inside the joint tattoo detection and compact representation learning network via random image stitch and preceding feature buffering. We evaluate the proposed tattoo search system using multiple public-domain tattoo benchmarks, and a gallery set with about 300K distracter tattoo images compiled from these datasets and images from the Internet. In addition, we also introduce a tattoo sketch dataset containing 300 tattoos for sketch-based tattoo search. Experimental results show that the proposed approach has superior performance in tattoo detection and tattoo search at scale compared to several state-of-the-art tattoo retrieval algorithms.	[Han, Hu; Li, Jie; Shan, Shiguang; Chen, Xilin] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China; [Han, Hu] Peng Cheng Lab, Shenzhen, Peoples R China; [Han, Hu; Li, Jie; Shan, Shiguang; Chen, Xilin] Univ Chinese Acad Sci, Beijing 100049, Peoples R China; [Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA; [Shan, Shiguang] Chinese Acad Sci, Ctr Excellence Brain Sci & Intelligence Technol, Beijing, Peoples R China	Chinese Academy of Sciences; Institute of Computing Technology, CAS; Peng Cheng Laboratory; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Michigan State University; Chinese Academy of Sciences	Han, H (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.	hanhu@ict.ac.cn; jie.li@vipl.ict.ac.cn; jain@cse.msu.edu; sgshan@ict.ac.cn; xlchen@ict.ac.cn		Han, Hu/0000-0001-6010-1792; Shan, Shiguang/0000-0002-8348-392X	Natural Science Foundation of China [61732004, 61672496, 61650202]; Strategic Priority Research Program of CAS [XDB02070004]; External Cooperation Program of CAS [GJHZ1843]	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Strategic Priority Research Program of CAS; External Cooperation Program of CAS	This research was supported in part by the Natural Science Foundation of China (grants 61732004, 61672496, and 61650202), Strategic Priority Research Program of CAS (grant XDB02070004), and External Cooperation Program of CAS (grant GJHZ1843). The preliminary work appeared in the Proceedings of the 6th International Conference on Biometrics (ICB), 2013 [9].	Acton ST, 2008, 2008 IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS & INTERPRETATION, P21, DOI 10.1109/SSIAI.2008.4512275; [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.596; Babenko A, 2014, PROC CVPR IEEE, P931, DOI 10.1109/CVPR.2014.124; Bertillon A., 1896, SIGNALETIC INSTRUCTI; Cao Y., 2010, INT C MULT, P1605; Cao Y, 2011, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2011.5995460; Chi L., 2017, ARXIV170803798, P1; Chi LH, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3047307; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z; Di X., 2017, DEEP LEARNING TATTOO; Di X, 2016, IEEE COMPUT SOC CONF, P119, DOI 10.1109/CVPRW.2016.22; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gui J, 2018, IEEE T PATTERN ANAL, V40, P490, DOI 10.1109/TPAMI.2017.2678475; Han H, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCED CLOUD AND BIG DATA (CBD), P77, DOI 10.1109/CBD.2013.12; Han H, 2013, IEEE T INF FOREN SEC, V8, P191, DOI 10.1109/TIFS.2012.2228856; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Heflin B., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P31, DOI 10.1109/BTAS.2012.6374555; Hrkac T., 2016, P OAGM ARW JOINT WOR, P131; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Jain AK, 2007, LECT NOTES COMPUT SC, V4810, P256; Jain AK, 2012, IEEE MULTIMEDIA, V19, P20, DOI 10.1109/MMUL.2012.4; Jain AK, 2009, IEEE IMAGE PROC, P2745, DOI 10.1109/ICIP.2009.5414140; Jain H, 2017, IEEE I CONF COMP VIS, P833, DOI 10.1109/ICCV.2017.96; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jiang QY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2248; Kim JK, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0149333; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466; Kulis B, 2009, IEEE T PATTERN ANAL, V31, P2143, DOI 10.1109/TPAMI.2009.151; Kulis Brian, 2009, ADV NEURAL INFORM PR, P1042; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lee JE, 2012, IEEE MULTIMEDIA, V19, P40, DOI 10.1109/MMUL.2011.59; Li W., 2016, INT JOINT C ARTIFICI, P1711; Li W.-J., 2012, P ADV NEUR INF PROC, P1646; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin Y, 2013, PROC CVPR IEEE, P446, DOI 10.1109/CVPR.2013.64; Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862; Liu L, 2012, IEEE T PATTERN ANAL, V34, P574, DOI 10.1109/TPAMI.2011.145; Liu TI, 2008, C IND ELECT APPL, P1, DOI 10.1109/ICIEA.2008.4582469; Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912; Liu W, 2011, SER INF MANAGE SCI, V10, P1; [刘伟民 Liu Weimin], 2018, [海洋科学进展, Advances in Marine Science], V36, P1; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P2352, DOI 10.1109/TIP.2017.2678163; Manger D., 2012, 2012 Canadian Conference on Computer and Robot Vision, P454, DOI 10.1109/CRV.2012.67; McCabe R., 2000, NIST SPECIAL PUBLICA, V500-245, P1; Ngan M., 2015, 8078 NIST, P1; Norouzi M., 2011, INT C MACHINE LEARNI, P353; Philbin J, 2008, PROC CVPR IEEE, P2285; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Salakhutdinov Ruslan, 2007, J MACHINE LEARNING R, P412, DOI DOI 10.1109/ICCV.2017.74; Salvador A, 2016, IEEE COMPUT SOC CONF, P394, DOI 10.1109/CVPRW.2016.56; Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598; Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Sun ZH, 2016, INT C PATT RECOG, P3055, DOI 10.1109/ICPR.2016.7900103; Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976; Wang XJ, 2016, PROC CVPR IEEE, P2018, DOI 10.1109/CVPR.2016.222; Weiss Y, 2009, ADV NEURAL INFORM PR, P1753; Wilber MJ, 2014, IEEE WINT CONF APPL, P205, DOI 10.1109/WACV.2014.6836099; Xie LX, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P3, DOI 10.1145/2671188.2749289; Xie LX, 2014, IEEE IMAGE PROC, P5716, DOI 10.1109/ICIP.2014.7026156; Xu Q., 2016, IEEE T IND ELECTRON, P1; Xu XP, 2016, INT C PATT RECOG, P3019, DOI 10.1109/ICPR.2016.7900097; Yang HF, 2018, IEEE T PATTERN ANAL, V40, P437, DOI 10.1109/TPAMI.2017.2666812; Yi D., 2014, LEARNING FACE REPRES, V1411, P7923; Yu T, 2017, IEEE I CONF COMP VIS, P726, DOI 10.1109/ICCV.2017.85; Zhang QF, 2014, INT CONF MACH LEARN, P807, DOI 10.1109/ICMLC.2014.7009713; Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749; Zheng XK, 2009, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON POWER ENGINEERING 2009 (ICOPE-09), VOL 2, P89; Zhou W., 2012, ACM MULTIMEDIA; Zhou WG, 2018, IEEE T PATTERN ANAL, V40, P1154, DOI 10.1109/TPAMI.2017.2676779	80	17	19	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2019	41	10					2333	2348		10.1109/TPAMI.2019.2891584	http://dx.doi.org/10.1109/TPAMI.2019.2891584			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD1VC	30629491	Green Submitted			2022-12-18	WOS:000489763000005
J	Oyallon, E; Zagoruyko, S; Huang, G; Komodakis, N; Lacoste-Julien, S; Blaschko, M; Belilovsky, E				Oyallon, Edouard; Zagoruyko, Sergey; Huang, Gabriel; Komodakis, Nikos; Lacoste-Julien, Simon; Blaschko, Matthew; Belilovsky, Eugene			Scattering Networks for Hybrid Representation Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Scattering transform; wavelets; deep neural networks; invariance		Scattering networks are a class of designed Convolutional Neural Networks (CNNs) with fixed weights. We argue they can serve as generic representations for modelling images. In particular, by working in scattering space, we achieve competitive results both for supervised and unsupervised learning tasks, while making progress towards constructing more interpretable CNNs. For supervised learning, we demonstrate that the early layers of CNNs do not necessarily need to be learned, and can be replaced with a scattering network instead. Indeed, using hybrid architectures, we achieve the best results with predefined representations to-date, while being competitive with end-to-end learned CNNs. Specifically, even applying a shallow cascade of small-windowed scattering coefficients followed by 1 x 1-convolutions results in AlexNet accuracy on the ILSVRC2012 classification task. Moreover, by combining scattering networks with deep residual networks, we achieve a single-crop top-5 error of 11.4 percent on ILSVRC2012. Also, we show they can yield excellent performance in the small sample regime on CIFAR-10 and STL-10 datasets, exceeding their end-to-end counterparts, through their ability to incorporate geometrical priors. For unsupervised learning, scattering coefficients can be a competitive representation that permits image recovery. We use this fact to train hybrid GANs to generate images. Finally, we empirically analyze several properties related to stability and reconstruction of images from scattering coefficients.	[Oyallon, Edouard] Cent Supelec CVN, F-91190 Gif Sur Yvette, France; [Oyallon, Edouard] INRIA, Galen Team, F-91190 Gif Sur Yvette, France; [Zagoruyko, Sergey; Komodakis, Nikos] Ecole Fonts, F-77455 Champs Sur Marne, France; [Huang, Gabriel; Lacoste-Julien, Simon; Belilovsky, Eugene] Univ Montreal, Montreal, PQ H3T 1J4, Canada; [Blaschko, Matthew] Katholieke Univ Leuven, B-3000 Leuven, Belgium	Inria; Universite de Montreal; KU Leuven	Oyallon, E (corresponding author), Cent Supelec CVN, F-91190 Gif Sur Yvette, France.	edouard.oyallon@centralesupelec.fr; sergey.zagoruyko@enpc.fr; gabriel.huang@umontreal.ca; nilcos.kcmiodakis@enpc.fr; slacoste@iro.umontreal.ca; matthew.blaschko@esat.kuleuven.be; belilove@iro.umontreal.ca		Blaschko, Matthew/0000-0002-2640-181X	ERC [320959]; Internal Funds KU Leuven [FP7-MC-CIG 334380, DIGITEO 2013-0788D-SOPRANO]; NSERC [RGPIN-2017-06936]; Research Foundation - Flanders (FWO) [G0A2716N]; CVN (CentraleSupelec); Amazon Research Award	ERC(European Research Council (ERC)European Commission); Internal Funds KU Leuven; NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC)); Research Foundation - Flanders (FWO)(FWO); CVN (CentraleSupelec); Amazon Research Award	The authors would like to thank Mathieu Andreux, Tomas Angles, Joan Bruna, Carmine Cella, Bogdan Cirstea, Michael Eickenberg, Stephane Mallat, Louis Thiry for helpful discussions and support. The authors would also like to thank Rafael Marini and Nikos Paragios for use of computing resources. We would like to thank Florent Perronnin for providing important details of their work. This work is funded by the ERC grant InvariantClass 320959, via a grant for PhD Students of the Conseil regional d'Ile-de-France (RDM-IdF), Internal Funds KU Leuven, FP7-MC-CIG 334380, DIGITEO 2013-0788D-SOPRANO, NSERC Discovery Grant RGPIN-2017-06936, an Amazon Research Award to Matthew Blaschko, and by the Research Foundation - Flanders (FWO) through project number G0A2716N. We thank also the CVN (CentraleSupelec) for providing financial support.	Anden J., 2014, COMPUT SOFTW; Angles T., 2018, P INT C LEARN REPR; [Anonymous], 2015, SIGNAL IMAGE PROC; Arandjelovic R, 2017, IEEE I CONF COMP VIS, P609, DOI 10.1109/ICCV.2017.73; Arjovsky M, 2017, PR MACH LEARN RES, V70; Bernstein S, 2013, TRENDS MATH, P221; Bo L., 2013, EXPT ROBOTICS, P387, DOI DOI 10.1007/978-3-319-00065-7; Bo LF, 2013, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2013.91; Boureau YL, 2011, IEEE I CONF COMP VIS, P2651, DOI 10.1109/ICCV.2011.6126555; Bruna J., 2013, THESIS ECOLE POLYTEC; Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230; Bruna Joan, 2014, ICLR, DOI DOI 10.1145/3170427.3188467; Christian Szegedy, 2014, Arxiv, DOI arXiv:1312.6199; Coates A., 2011, ADV NEURAL INFORM PR, P2528, DOI DOI 10.1016/J.PSYCHRES.2009.03.008; Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167; Dokmanic I., 2017, SPARS; Donahue J., 2018, ICLR; Dosovitskiy A., 2014, ADV NEURAL INFORM PR, V27, P766, DOI [DOI 10.1109/TPAMI.2015.2496141, 10.48550/arXiv.1406.6909]; Goodfellow I.J., 2015, ARXIV PREPRINT ARXIV; Gulrajani I, 2017, P NIPS 2017; Han Song, 2015, ADV NEURAL INFORM PR, P1135, DOI DOI 10.5555/2969239.2969366; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Hoffer E., 2016, ARXIV161000243; Huh J., 2016, NIPS WORKSH LARG SCA; Jacobsen J. -H., 2017, HIERARCHICAL ATTRIBU; Koenderink JJ, 1999, INT J COMPUT VISION, V31, P159, DOI 10.1023/A:1008065931878; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496; LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Mairal J., 2014, ADV NEURAL INFORM PR, V27, P2627; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Mallat S, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0203; Mallat S, 2012, COMMUN PUR APPL MATH, V65, P1331, DOI 10.1002/cpa.21413; Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5; Oyallon E, 2017, IEEE I CONF COMP VIS, P5619, DOI 10.1109/ICCV.2017.599; Oyallon E, 2017, PROC CVPR IEEE, P1886, DOI 10.1109/CVPR.2017.204; Oyallon E, 2015, PROC CVPR IEEE, P2865, DOI 10.1109/CVPR.2015.7298904; Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278; Perronnin F, 2015, PROC CVPR IEEE, P3743, DOI 10.1109/CVPR.2015.7298998; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Sanchez J, 2011, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2011.5995504; Serre T., 2004, REALISTIC MODELING O; Sifre L, 2013, PROC CVPR IEEE, P1233, DOI 10.1109/CVPR.2013.163; Springenberg J. T, 2015, ARXIV PREPRINT ARXIV; Srivatsan R, 2015, SEVA, SAVIOUR AND STATE: CASTE POLITICS, TRIBAL WELFARE AND CAPITALIST DEVELOPMENT, P1; Sugiura M., 1977, UNITARY REPRESENTATI, V1, P100; Swersky K., 2013, ADV NEURAL INFORM PR, P2004, DOI DOI 10.1038/S41598-021-83582-6; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77; YOSINSKI J, 2014, ADV NEURAL INFORM PR, P3320, DOI DOI 10.1109/IJCNN.2016.7727519; Zagoruyko S, 2016, 5 INT C LEARN REPRES, DOI DOI 10.5244/C.30.87; Zagoruyko S., 2015, TORCH BLOG; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhao J., 2016, WORKSH TRACK ICLR	59	17	17	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2019	41	9					2208	2221		10.1109/TPAMI.2018.2855738	http://dx.doi.org/10.1109/TPAMI.2018.2855738			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IP9BY	30028690	Green Submitted			2022-12-18	WOS:000480343900012
J	Zhu, K; Xue, YJ; Fu, Q; Kang, SB; Chen, XL; Yu, JY				Zhu, Kang; Xue, Yujia; Fu, Qiang; Kang, Sing Bing; Chen, Xilin; Yu, Jingyi			Hyperspectral Light Field stereo Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hyperspectral light fields; stereo matching; spectral-invariant feature descriptor; spectral-aware defocus cues	IMAGING SPECTROMETRY; REGISTRATION	In this paper, we describe how scene depth can be extracted using a hyperspectral light field capture (H-LF) system. Our H-LF system consists of a 5 x 6 array of cameras, with each camera sampling a different narrow band in the visible spectrum. There are two parts to extracting scene depth. The first part is our novel cross-spectral pairwise matching technique, which involves a new spectral-invariant feature descriptor and its companion matching metric we call bidirectional weighted normalized cross correlation (BWNCC). The second part, namely, H-LF stereo matching, uses a combination of spectral-dependent correspondence and defocus cues. These two new cost terms are integrated into a Markov Random Field (MRF) for disparity estimation. Experiments on synthetic and real H-LF data show that our approach can produce high-quality disparity maps. We also show that these results can be used to produce the complete plenoptic cube in addition to synthesizing all-focus and defocused color images under different sensor spectral responses.	[Zhu, Kang; Fu, Qiang; Yu, Jingyi] Shanghai Tech Univ, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China; [Zhu, Kang; Chen, Xilin] Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, Beijing 100864, Peoples R China; [Xue, Yujia] Plex VR Inc, Shanghai 201203, Peoples R China; [Kang, Sing Bing] Microsoft Res, Redmond, WA 98052 USA; [Yu, Jingyi] Univ Delaware, Dept Comp & Informat Sci, Newark, DE 19716 USA	ShanghaiTech University; Chinese Academy of Sciences; Institute of Computing Technology, CAS; Microsoft; University of Delaware	Yu, JY (corresponding author), Shanghai Tech Univ, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China.	zhukang@shanghaitech.edu.cn; yujia.xue@plex-vr.com; fuqiangx@outlook.com; sbkang@microsoft.com; xlchen@ict.ac.cn; yujingyi@shanghaitech.edu.cn	Fu, Qiang/AAN-3134-2020	Fu, Qiang/0000-0001-6395-8521	STCSM [17XD1402900, 17JC1403800]	STCSM(Science & Technology Commission of Shanghai Municipality (STCSM))	This work is partially supported by the programs of STCSM (17XD1402900, 17JC1403800).	Ben-Dor E, 2008, ADV AGRON, V97, P321, DOI 10.1016/S0065-2113(07)00008-9; Bruton D., 1996, COLOR SCI; Chen C, 2014, PROC CVPR IEEE, P1518, DOI 10.1109/CVPR.2014.197; Clevers JGPW, 1999, ISPRS J PHOTOGRAMM, V54, P299, DOI 10.1016/S0924-2716(99)00033-7; Curran P. J., 2001, INT J APPL EARTH OBS, V3, P305, DOI DOI 10.1016/S0303-2434(01)85037-6; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Ding YY, 2011, IEEE I CONF COMP VIS, P2478, DOI 10.1109/ICCV.2011.6126533; Gat N, 2000, P SOC PHOTO-OPT INS, V4056, P50, DOI 10.1117/12.381686; Goesele M, 2007, IEEE I CONF COMP VIS, P825, DOI 10.1109/iccv.2007.4408933; GOETZ AFH, 1985, SCIENCE, V228, P1147, DOI 10.1126/science.228.4704.1147; Guo XQ, 2016, IEEE T VIS COMPUT GR, V22, P1852, DOI 10.1109/TVCG.2015.2476805; Hagen N., 2012, OPT ENG, V51; Heo YS, 2011, IEEE T PATTERN ANAL, V33, P807, DOI 10.1109/TPAMI.2010.136; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; Holloway J, 2015, IEEE T IMAGE PROCESS, V24, P823, DOI [10.1109/TIP.2014.2383315, 10.1109/TIP.2015.2413291]; Imai F., 2015, P IM APPL OPT; Kolmogorov V, 2014, IMAGE PROCESS ON LIN, V4, P220, DOI 10.5201/ipol.2014.97; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Landy M.S., 1991, COMPUTATIONAL MODELS; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Li NY, 2017, IEEE T PATTERN ANAL, V39, P1605, DOI 10.1109/TPAMI.2016.2610425; Lin HT, 2015, IEEE I CONF COMP VIS, P3451, DOI 10.1109/ICCV.2015.394; Lockwood RB, 2007, PROC SPIE, V6661, DOI 10.1117/12.735844; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; MacKay, 2003, INFORM THEORY INFERE; Mouroulis P, 2000, OPT ENG, V39, P808, DOI 10.1117/1.602431; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; Park J, 2014, IEEE T IMAGE PROCESS, V23, P5559, DOI 10.1109/TIP.2014.2361034; Perwass C, 2012, PROC SPIE, V8291, DOI 10.1117/12.909882; Ranchin T, 2000, PHOTOGRAMM ENG REM S, V66, P49; Ren N., 2005, 200502 CTSR STANF U; Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977; Shen XY, 2014, LECT NOTES COMPUT SC, V8692, P309, DOI 10.1007/978-3-319-10593-2_21; Shi F., 2001, BRIT MACH VIS C 2001; Smith T., 1931, T OPTICAL SOC, V33, P73, DOI [DOI 10.1088/1475-4878/33/3/301, 10.1088/1475-4878/33/3/301]; Su LJ, 2015, OPTIK, V126, P877, DOI 10.1016/j.ijleo.2015.01.034; Tao MW, 2016, IEEE T PATTERN ANAL, V38, P1155, DOI 10.1109/TPAMI.2015.2477811; Tao MW, 2015, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2015.7298804; Tao MW, 2013, IEEE I CONF COMP VIS, P673, DOI 10.1109/ICCV.2013.89; Wang TC, 2016, LECT NOTES COMPUT SC, V9907, P121, DOI 10.1007/978-3-319-46487-9_8; Wang TC, 2015, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2015.398; Wanner S, 2012, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2012.6247656; Xiong ZW, 2017, PROC CVPR IEEE, P6873, DOI 10.1109/CVPR.2017.727; Yu Z, 2013, IEEE I CONF COMP VIS, P2792, DOI 10.1109/ICCV.2013.347; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	45	17	17	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2019	41	5					1131	1143		10.1109/TPAMI.2018.2827049	http://dx.doi.org/10.1109/TPAMI.2018.2827049			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HS1FL	29993926	Green Submitted			2022-12-18	WOS:000463607400008
J	Zemene, E; Tesfaye, YT; Idrees, H; Prati, A; Pelillo, M; Shah, M				Zemene, Eyasu; Tesfaye, Yonatan Tariku; Idrees, Haroon; Prati, Andrea; Pelillo, Marcello; Shah, Mubarak			Large-Scale Image Geo-Localization Using Dominant Sets	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Geo-localization; dominant set clustering; multiple nearest neighbor feature matching; constrained dominant set	QUADRATIC OPTIMIZATION; RECOGNITION	This paper presents a new approach for the challenging problem of geo-localization using image matching in a structured database of city-wide reference images with known GPS coordinates. We cast the geo-localization as a clustering problem of local image features. Akin to existing approaches to the problem, our framework builds on low-level features which allow local matching between images. For each local feature in the query image, we find its approximate nearest neighbors in the reference set. Next, we cluster the features from reference images using Dominant Set clustering, which affords several advantages over existing approaches. First, it permits variable number of nodes in the cluster, which we use to dynamically select the number of nearest neighbors for each query feature based on its discrimination value. Second, this approach is several orders of magnitude faster than existing approaches. Thus, we obtain multiple clusters (different local maximizers) and obtain a robust final solution to the problem using multiple weak solutions through constrained Dominant Set clustering on global image features, where we enforce the constraint that the query image must be included in the cluster. This second level of clustering also bypasses heuristic approaches to voting and selecting the reference image that matches to the query. We evaluate the proposed framework on an existing dataset of 102k street view images as well as a new larger dataset of 300k images, and show that it outperforms the state-of-the-art by 20 and 7 percent, respectively, on the two datasets.	[Zemene, Eyasu; Pelillo, Marcello] Ca Foscari Univ Venice, DAIS, I-30123 Venice, VE, Italy; [Zemene, Eyasu; Tesfaye, Yonatan Tariku; Idrees, Haroon; Shah, Mubarak] Univ Cent Florida, CRCV, Orlando, FL 32816 USA; [Tesfaye, Yonatan Tariku] Univ IUAV Venice, Dept Design & Planning Complex Environm, I-30135 Venice, VE, Italy; [Prati, Andrea] Univ Parma, Dept Engn & Architecture, I-43121 Parma, PR, Italy	Universita Ca Foscari Venezia; State University System of Florida; University of Central Florida; IUAV University Venice; University of Parma	Zemene, E (corresponding author), Ca Foscari Univ Venice, DAIS, I-30123 Venice, VE, Italy.; Zemene, E (corresponding author), Univ Cent Florida, CRCV, Orlando, FL 32816 USA.	eyasu.zemene@unive.it; y.tesfaye@stud.iuav.it; haroom@eecs.ucf.edu; andrea.prati@unipr.it; pelillo@unive.it; shah@eecs.ucf.edu	; Prati, Andrea/B-7440-2014	Shah, Mubarak/0000-0001-6172-5572; Pelillo, Marcello/0000-0001-8992-9243; Prati, Andrea/0000-0002-1211-529X				Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2015, PROC CVPR IEEE; Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/CVPR.2016.572, 10.1109/TPAMI.2017.2711011]; Arandjelovic R, 2015, LECT NOTES COMPUT SC, V9006, P188, DOI 10.1007/978-3-319-16817-3_13; Avrithis Y., 2010, ACM MULTIMEDIA; Bergamo A, 2013, PROC CVPR IEEE, P763, DOI 10.1109/CVPR.2013.104; Bomze IM, 1997, J GLOBAL OPTIM, V10, P143, DOI 10.1023/A:1008230200610; Bomze IM, 1998, J GLOBAL OPTIM, V13, P369, DOI 10.1023/A:1008369322970; Bulo SR, 2011, COMPUT VIS IMAGE UND, V115, P984, DOI 10.1016/j.cviu.2010.12.004; Bulo SR, 2011, GAME ECON BEHAV, V71, P193, DOI 10.1016/j.geb.2010.06.004; Cao S, 2013, PROC CVPR IEEE, P700, DOI 10.1109/CVPR.2013.96; Chen CY, 2011, PROC CVPR IEEE, P1569, DOI 10.1109/CVPR.2011.5995412; Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610; Crandall David J, 2009, P INT C WORLD WID WE, DOI DOI 10.1145/1526709.1526812; Gronat P, 2013, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2013.122; Hakeem A, 2006, INT C PATT RECOG, P82; Hao Q, 2012, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2012.6248104; Hays James, 2008, CVPR, DOI DOI 10.1109/CVPR.2008.4587784; Hays James, 2015, MULTIMODAL LOCATION, P41, DOI DOI 10.1007/978-3-319-09861-6_3; Horst R., 2000, INTRO GLOBAL OPTIMIZ; Jacobs N, 2007, IEEE I CONF COMP VIS, P1305; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Kalogerakis E, 2009, IEEE I CONF COMP VIS, P253, DOI 10.1109/ICCV.2009.5459259; Kim HJ, 2015, IEEE I CONF COMP VIS, P1170, DOI 10.1109/ICCV.2015.139; Li YP, 2012, LECT NOTES COMPUT SC, V7572, P15, DOI 10.1007/978-3-642-33718-5_2; Lin TY, 2015, PROC CVPR IEEE, P5007, DOI 10.1109/CVPR.2015.7299135; Lin TY, 2013, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2013.120; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Pavan M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P362; Pavan M, 2007, IEEE T PATTERN ANAL, V29, P167, DOI 10.1109/TPAMI.2007.250608; Pelillo M., 2009, ENCY OPTIMIZATION, P3279; Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1; Ramalingam S, 2010, IEEE INT C INT ROBOT, P3816, DOI 10.1109/IROS.2010.5649105; Sattler T, 2016, PROC CVPR IEEE, P1582, DOI 10.1109/CVPR.2016.175; Sattler T, 2012, LECT NOTES COMPUT SC, V7572, P752, DOI 10.1007/978-3-642-33718-5_54; Schindler Grant, 2007, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2007.383150; Tesfaye YT, 2016, IET COMPUT VIS, V10, P289, DOI 10.1049/iet-cvi.2015.0297; Todorovic S, 2008, INT J COMPUT VISION, V78, P47, DOI 10.1007/s11263-007-0077-5; Tolias G, 2016, INT J COMPUT VISION, V116, P247, DOI 10.1007/s11263-015-0810-4; Tolias Giorgos, 2016, P ICLR; Torii A, 2015, IEEE T PATTERN ANAL, V37, P2346, DOI 10.1109/TPAMI.2015.2409868; Vaca-Castano G, 2012, PROC CVPR IEEE, P1186, DOI 10.1109/CVPR.2012.6247800; Van Gool, 2008, P INT C CONT BAS IM, P47, DOI DOI 10.1145/1386352.1386363; Vascon S, 2016, COMPUT VIS IMAGE UND, V143, P11, DOI 10.1016/j.cviu.2015.09.012; Weyand T, 2016, LECT NOTES COMPUT SC, V9912, P37, DOI 10.1007/978-3-319-46484-8_3; Workman S, 2015, IEEE I CONF COMP VIS, P3961, DOI 10.1109/ICCV.2015.451; Zamir AR, 2014, IEEE T PATTERN ANAL, V36, P1546, DOI 10.1109/TPAMI.2014.2299799; Zamir AR, 2010, LECT NOTES COMPUT SC, V6314, P255, DOI 10.1007/978-3-642-15561-1_19; Zeisl B, 2015, IEEE I CONF COMP VIS, P2704, DOI 10.1109/ICCV.2015.310; Zemene E, 2016, LECT NOTES COMPUT SC, V9912, P278, DOI 10.1007/978-3-319-46484-8_17; Zhang ST, 2015, IEEE T PATTERN ANAL, V37, P803, DOI 10.1109/TPAMI.2014.2346201; Zheng YT, 2009, PROC CVPR IEEE, P1085, DOI 10.1109/CVPRW.2009.5206749	54	17	18	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2019	41	1					148	161		10.1109/TPAMI.2017.2787132	http://dx.doi.org/10.1109/TPAMI.2017.2787132			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HD3QX	29990281	Green Submitted			2022-12-18	WOS:000452434800012
J	Yu, Y; Mora, KAF; Odobez, JM				Yu, Yu; Mora, Kenneth Alberto Funes; Odobez, Jean-Marc			HeadFusion: 360 degrees Head Pose Tracking Combining 3D Morphable Model and 3D Reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Head pose; 3D head reconstruction; 3D morphable model	REGISTRATION	Head pose estimation is a fundamental task for face and social related research. Although 3D morphable model (3DMM) based methods relying on depth information usually achieve accurate results, they usually require frontal or mid-profile poses which preclude a large set of applications where such conditions can not be garanteed, like monitoring natural interactions from fixed sensors placed in the environment. A major reason is that 3DMM models usually only cover the face region. In this paper, we present a framework which combines the strengths of a 3DMM model fitted online with a prior-free reconstruction of a 3D full head model providing support for pose estimation from any viewpoint. In addition, we also proposes a symmetry regularizer for accurate 3DMM fitting under partial observations, and exploit visual tracking to address natural head dynamics with fast accelerations. Extensive experiments show that our method achieves state-of-the-art performance on the public BIWI dataset, as well as accurate and robust results on UbiPose, an annotated dataset of natural interactions that we make public and where adverse poses, occlusions or fast motions regularly occur.	[Yu, Yu; Mora, Kenneth Alberto Funes; Odobez, Jean-Marc] Idiap Res Inst, Percept & Act Understanding Grp, CH-1920 Martigny, Switzerland; [Yu, Yu; Mora, Kenneth Alberto Funes; Odobez, Jean-Marc] Ecole Polytech Fed Lausanne, Lausanne, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Yu, Y (corresponding author), Idiap Res Inst, Percept & Act Understanding Grp, CH-1920 Martigny, Switzerland.; Yu, Y (corresponding author), Ecole Polytech Fed Lausanne, Lausanne, Switzerland.	rainyucool@gmail.com; kenneth.funes@idiap.ch; odobez@idiap.ch			UBIMPRESSED project of the Sinergia interdisciplinary program of the Swiss National Science Foundation (SNSF); European Union [688147]	UBIMPRESSED project of the Sinergia interdisciplinary program of the Swiss National Science Foundation (SNSF)(Swiss National Science Foundation (SNSF)); European Union(European Commission)	This work was partly funded by the UBIMPRESSED project of the Sinergia interdisciplinary program of the Swiss National Science Foundation (SNSF), and by the the European Union's Horizon 2020 research and innovation programme under grant agreement no. 688147 (MuMMER, mummer-project.eu).	Amberg B., 2008, IEEE INT C AUT FAC G, DOI [10.1109/AFGR.2008.4813376, DOI 10.1109/AFGR.2008.4813376]; Baltrusaitis T., 2016, 2016 IEEE WINT C APP, P1, DOI [10.1109/WACV.2016.7477553, DOI 10.1109/WACV.2016.7477553]; Baltrusaitis T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P354, DOI 10.1109/ICCVW.2013.54; Baltrusaitis T, 2012, PROC CVPR IEEE, P2610, DOI 10.1109/CVPR.2012.6247980; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598; Bouaziz S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461976; Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0; Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458; Funes-Mora KA, 2016, INT J COMPUT VISION, V118, P194, DOI 10.1007/s11263-015-0863-4; Gokturk SB, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P701, DOI 10.1109/ICCV.2001.937695; HADAR U, 1985, J NONVERBAL BEHAV, V9, P214, DOI 10.1007/BF00986881; Hsieh PL, 2015, PROC CVPR IEEE, P1675, DOI 10.1109/CVPR.2015.7298776; Izadi Shahram, 2011, UIST, DOI [10.1145/2047196.2047270, DOI 10.1145/2047196.2047270]; Jourabloo A, 2016, PROC CVPR IEEE, P4188, DOI 10.1109/CVPR.2016.454; Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241; Keller M, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P1, DOI 10.1109/3DV.2013.9; King DE, 2009, J MACH LEARN RES, V10, P1755; Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422; Meyer GP, 2015, IEEE I CONF COMP VIS, P3649, DOI 10.1109/ICCV.2015.416; Mora K. A. F., 2012, P IEEE COMP SOC C CO, P25, DOI DOI 10.1109/CVPRW.2012.6239182; Movellan J., 2008, 2008 8 IEEE INT C AU, P1, DOI DOI 10.1109/AFGR.2008.4813429; Muralidhar S, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P84, DOI 10.1145/2993148.2993191; Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631; Oertel C, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P21, DOI 10.1145/2993148.2993188; Papazov C, 2015, PROC CVPR IEEE, P4722, DOI 10.1109/CVPR.2015.7299104; Park SY, 2003, PATTERN RECOGN LETT, V24, P2967, DOI 10.1016/S0167-8655(03)00157-0; Paysan P., 2009, P 6 IEEE INT C ADV V; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Thomas Diego, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3299, DOI 10.1109/CVPR.2016.359; Vetter T., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P499, DOI 10.1007/BFb0054761; Weise T., 2011, P ACM SIGGRAPH; Yu Y, 2017, IEEE INT CONF AUTOMA, P711, DOI 10.1109/FG.2017.90; Zhang X, 2017, IEEE COMPUT SOC CONF, P2299, DOI 10.1109/CVPRW.2017.284; Zhou EJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P386, DOI 10.1109/ICCVW.2013.58; Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23	44	17	17	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2018	40	11					2653	2667		10.1109/TPAMI.2018.2841403	http://dx.doi.org/10.1109/TPAMI.2018.2841403			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GW2AF	29993569				2022-12-18	WOS:000446683700010
J	De, J; Zhang, XW; Lin, F; Cheng, L				De, Jaydeep; Zhang, Xiaowei; Lin, Feng; Cheng, Li			Transduction on Directed Graphs via Absorbing Random Walks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Random walks on directed graphs; transductive learning; absorbing Markov chain; transduction generalization error	ALGORITHM; IMAGES	In this paper we consider the problem of graph-based transductive classification, and we are particularly interested in the directed graph scenario which is a natural form for many real world applications. Different from existing research efforts that either only deal with undirected graphs or circumvent directionality by means of symmetrization, we propose a novel random walk approach on directed graphs using absorbing Markov chains, which can be regarded as maximizing the accumulated expected number of visits from the unlabeled transient states. Our algorithm is simple, easy to implement, and works with large-scale graphs on binary, multiclass, and multi-label prediction problems. Moreover, it is capable of preserving the graph structure even when the input graph is sparse and changes over time, as well as retaining weak signals presented in the directed edges. We present its intimate connections to a number of existing methods, including graph kernels, graph Laplacian based methods, and spanning forest of graphs. Its computational complexity and the generalization error are also studied. Empirically, our algorithm is evaluated on a wide range of applications, where it has shown to perform competitively comparing to a suite of state-of-the-art methods. In particular, our algorithm is shown to work exceptionally well with large sparse directed graphs with e.g., millions of nodes and tens of millions of edges, where it significantly outperforms other state-of-the-art methods. In the dynamic graph setting involving insertion or deletion of nodes and edge-weight changes over time, it also allows efficient online updates that produce the same results as of the batch update counterparts.	[De, Jaydeep; Zhang, Xiaowei; Cheng, Li] ASTAR, Bioinformat Inst, Singapore 138632, Singapore; [Lin, Feng] Nanyang Technol Univ, Sch Comp Sci & Comp Engn, Singapore 639798, Singapore; [Cheng, Li] Chongqing Univ, Sch Software Engn, Chongqing 400044, Peoples R China	Agency for Science Technology & Research (A*STAR); A*STAR - Bioinformatics Institute (BII); Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Chongqing University	Cheng, L (corresponding author), ASTAR, Bioinformat Inst, Singapore 138632, Singapore.; Cheng, L (corresponding author), Chongqing Univ, Sch Software Engn, Chongqing 400044, Peoples R China.	jaydeep1@e.ntu.edu.sg; zxwtroy87@gmail.com; asflin@ntu.edu.sg; chengli@ieee.org	Cheng, Li/AAU-6734-2020	Cheng, Li/0000-0003-3261-3533	A*STAR JCO grants	A*STAR JCO grants(Agency for Science Technology & Research (A*STAR))	We would like to acknowledge support for this project from A*STAR JCO grants. Jaydeep De and Xiaowei Zhang contributed equally in this work.	Agaev RP, 2001, AUTOMAT REM CONTR+, V62, P443, DOI 10.1023/A:1002862312617; Bartlett P. L., 2003, Journal of Machine Learning Research, V3, P463, DOI 10.1162/153244303321897690; Begin L, 2014, JMLR WORKSH CONF PRO, V33, P105; Bengio Y., 2006, SEMISUPERVISED LEARN, P193, DOI [10.7551/mitpress/9780262033589.003.0011, DOI 10.7551/MITPRESS/9780262033589.003.0011]; Cai X, 2012, LECT NOTES COMPUT SC, V7577, P823, DOI 10.1007/978-3-642-33783-3_59; Callut J, 2008, LECT NOTES ARTIF INT, V5211, P162, DOI 10.1007/978-3-540-87479-9_29; Chakrabarti S., 1998, SIGMOD Record, V27, P307, DOI 10.1145/276305.276332; Chapelle O., 2006, IEEE T NEURAL NETWOR, V20, P542; Chebotarev PY, 1998, AUTOMAT REM CONTR+, V59, P1443; Chebotarev PY, 1997, AUTOMAT REM CONTR+, V58, P1505; Chen M, 2010, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2010.5539889; Chung F, 2005, ANN COMB, V9, P1, DOI 10.1007/s00026-005-0237-z; Davis TA, 2004, ACM T MATH SOFTWARE, V30, P196, DOI 10.1145/992200.992206; De J, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-20; Demmel JW, 1999, SIAM J MATRIX ANAL A, V20, P720, DOI 10.1137/S0895479895291765; El-Yaniv R, 2009, J ARTIF INTELL RES, V35, P193, DOI 10.1613/jair.2587; Fouss F, 2012, NEURAL NETWORKS, V31, P53, DOI 10.1016/j.neunet.2012.03.001; Gartner T., 2005, P INT C NEUR INF PRO, P411; Giles C. L., 1998, Digital 98 Libraries. Third ACM Conference on Digital Libraries, P89, DOI 10.1145/276675.276685; Gillette TA, 2011, NEUROINFORMATICS, V9, P233, DOI 10.1007/s12021-011-9117-y; Godbole S, 2004, LECT NOTES ARTIF INT, V3056, P22; Golub G. H., 2012, MATRIX COMPUTATIONS; Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178; Kemeny J.G., 1976, MARKOV CHAINS, V6; Lang Ken, 1995, MACHINE LEARNING P; Leskovec J., 2005, P 11 ACM SIGKDD INT, P177, DOI DOI 10.1145/1081870.1081893; Lu Q., 2003, P 20 INT C MACHINE L, P496; Macskassy SA, 2007, J MACH LEARN RES, V8, P935; Mantrach A, 2011, PATTERN RECOGN, V44, P1212, DOI 10.1016/j.patcog.2010.11.019; Mantrach A, 2010, IEEE T PATTERN ANAL, V32, P1112, DOI 10.1109/TPAMI.2009.78; McAuley Julian, 2012, ADV NEURAL INFORM PR, P539; McCallum AK, 2000, INFORM RETRIEVAL, V3, P127, DOI 10.1023/A:1009953814988; Meijering E, 2004, CYTOM PART A, V58A, P167, DOI 10.1002/cyto.a.20022; Nene, 1996, CUCS00596 COL U DEP; Page L., 1999, PAGERANK CITATION RA; PAIGE CC, 1982, ACM T MATH SOFTWARE, V8, P43, DOI 10.1145/355984.355989; Saad Y., 2003, ITERATIVE METHODS SP, DOI [10.1137/1.9780898718003, DOI 10.1137/1.9780898718003]; Sarkar P., 2007, UAI, P335; Scholkopf B., 2002, LEARNING KERNELS; Sen P., 2007, CSTR4858 U MAR; Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627; Subramanya A, 2011, J MACH LEARN RES, V12, P3311; Turetken E, 2013, IEEE I CONF COMP VIS, P1553, DOI 10.1109/ICCV.2013.196; Turetken E, 2013, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2013.238; Wang H, 2010, LECT NOTES ARTIF INT, V6323, P451, DOI 10.1007/978-3-642-15939-8_29; Wang J, 2013, J MACH LEARN RES, V14, P771; Wu X.-M., 2012, NIPS, P3077; Zhou D., 2005, P 22 INT C MACH LEAR, P1036, DOI [10.1145/1102351.1102482, DOI 10.1145/1102351.1102482]; Zhou DY, 2004, ADV NEUR IN, V16, P321; Zhu X., 2003, INT C MACH LEARN; Zhu X., 2007, HLT NAACL, P97; Zhu X., 2009, SYNTHESIS LECT ARTIF, V3, P1, DOI [10.2200/S00196ED1V01Y200906AIM006, DOI 10.2200/S00196ED1V01Y200906AIM006]	52	17	17	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2018	40	7					1770	1784		10.1109/TPAMI.2017.2730871	http://dx.doi.org/10.1109/TPAMI.2017.2730871			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GI3TS	28809671				2022-12-18	WOS:000434294800017
J	Saleh, FS; Aliakbarian, MS; Salzmann, M; Petersson, L; Alvarez, JM; Gould, S				Saleh, Fatemeh Sadat; Aliakbarian, Mohammad Sadegh; Salzmann, Mathieu; Petersson, Lars; Alvarez, Jose M.; Gould, Stephen			Incorporating Network Built-in Priors in Weakly-Supervised Semantic Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantic segmentation; weak annotations; convolutional neural networks; weakly-supervised semantic segmentation		Pixel-level annotations are expensive and time consuming to obtain. Hence, weak supervision using only image tags could have a significant impact in semantic segmentation. Recently, CNN-based methods have proposed to fine-tune pre-trained networks using image tags. Without additional information, this leads to poor localization accuracy. This problem, however, was alleviated by making use of objectness priors to generate foreground/background masks. Unfortunately these priors either require pixel-level annotations/bounding boxes, or still yield inaccurate object boundaries. Here, we propose a novel method to extract accurate masks from networks pre-trained for the task of object recognition, thus forgoing external objectness modules. We first show how foreground/background masks can be obtained from the activations of higher-level convolutional layers of a network. We then show how to obtain multi-class masks by the fusion of foreground/background ones with information extracted from a weakly-supervised localization network. Our experiments evidence that exploiting these masks in conjunction with a weakly-supervised training loss yields state-of-the-art tag-based weakly-supervised semantic segmentation results.	[Saleh, Fatemeh Sadat; Aliakbarian, Mohammad Sadegh; Petersson, Lars; Alvarez, Jose M.; Gould, Stephen] Australian Natl Univ, Coll Engn & Comp Sci, GPO Box 4, Canberra, ACT 0200, Australia; [Saleh, Fatemeh Sadat; Aliakbarian, Mohammad Sadegh; Petersson, Lars; Alvarez, Jose M.; Gould, Stephen] CSIRO, Data61, Canberra, ACT 0200, Australia; [Salzmann, Mathieu] Ecole Polytech Fed Lausanne, CVLab, CH-1015 Lausanne, Switzerland	Australian National University; Commonwealth Scientific & Industrial Research Organisation (CSIRO); Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Saleh, FS (corresponding author), Australian Natl Univ, Coll Engn & Comp Sci, GPO Box 4, Canberra, ACT 0200, Australia.; Saleh, FS (corresponding author), CSIRO, Data61, Canberra, ACT 0200, Australia.	fatemehsadat.saleh@data61.csiro.au; mohammadsadegh.aliakbarian@data61.csiro.au; mathieu.salzmann@epfl.ch; Lars.Petersson@data61.csiro.au; Jose.Alvarez@nicta.com.au; stephen.gould@anu.edu.au	Petersson, Lars/C-2568-2019	Petersson, Lars/0000-0002-0103-1904; Salzmann, Mathieu/0000-0002-8347-8637				Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Bearman A, 2016, LECT NOTES COMPUT SC, V9911, P549, DOI 10.1007/978-3-319-46478-7_34; Bertasius G., 2014, CORR; Carreira J, 2010, PROC CVPR IEEE, P3241, DOI 10.1109/CVPR.2010.5540063; Chen L.-C., 2014, ARXIV PREPRINT ARXIV; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Dai JF, 2015, IEEE I CONF COMP VIS, P1635, DOI 10.1109/ICCV.2015.191; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; Huiskes M. J., 2010, P INT C MULT INF RET, P527, DOI DOI 10.1145/1743384.1743475; Isola P., 2014, P EUR C COMPUT VIS, P388; Jain SD, 2014, LECT NOTES COMPUT SC, V8692, P656, DOI 10.1007/978-3-319-10593-2_43; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Khoreva A., 2016, CORR; Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0; Kolesnikov A., 2016, CORR; Koltun V, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472; Lin M., 2013, INT C LEARN REPRESEN; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Mostajahi M, 2015, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2015.7298959; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242; OQUAB M, 2015, PROC CVPR IEEE, P685, DOI DOI 10.1109/CVPR.2015.7298668; Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203; Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223; Pathak D., 2015, INT C LEARNING REPRE, P1; Pathak D, 2015, IEEE I CONF COMP VIS, P1796, DOI 10.1109/ICCV.2015.209; Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780; Pourian N, 2015, IEEE I CONF COMP VIS, P1359, DOI 10.1109/ICCV.2015.160; Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065; Qi XJ, 2016, LECT NOTES COMPUT SC, V9912, P90, DOI 10.1007/978-3-319-46484-8_6; Qi XJ, 2015, IEEE I CONF COMP VIS, P2587, DOI 10.1109/ICCV.2015.297; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Saleh F, 2016, LECT NOTES COMPUT SC, V9912, P413, DOI 10.1007/978-3-319-46484-8_25; SHARMA A, 2015, PROC CVPR IEEE, P530, DOI DOI 10.1109/CVPR.2015.7298651; Shimoda W, 2016, LECT NOTES COMPUT SC, V9908, P218, DOI 10.1007/978-3-319-46493-0_14; Tang K, 2013, PROC CVPR IEEE, P2483, DOI 10.1109/CVPR.2013.321; Tokmakov P, 2016, LECT NOTES COMPUT SC, V9908, P388, DOI 10.1007/978-3-319-46493-0_24; Vezhnevets A, 2012, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2012.6247757; Vezhnevets A, 2011, IEEE I CONF COMP VIS, P643, DOI 10.1109/ICCV.2011.6126299; Vineet V, 2014, INT J COMPUT VISION, V110, P290, DOI 10.1007/s11263-014-0708-6; Wei YC, 2016, PATTERN RECOGN, V59, P234, DOI 10.1016/j.patcog.2016.01.015; Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929; Xu J, 2015, PROC CVPR IEEE, P3781, DOI 10.1109/CVPR.2015.7299002; Xu J, 2014, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2014.408; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179; ZHOU B, 2016, PROC CVPR IEEE, P2921, DOI DOI 10.1109/CVPR.2016.319; Zhou B., 2015, INT CONF LEARN REPRE	53	17	19	3	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2018	40	6					1382	1396		10.1109/TPAMI.2017.2713785	http://dx.doi.org/10.1109/TPAMI.2017.2713785			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GE9BK	28613162	Green Submitted			2022-12-18	WOS:000431524700008
J	Liu, XB; Zhao, YB; Zhu, SC				Liu, Xiaobai; Zhao, Yibiao; Zhu, Song-Chun			Single-View 3D Scene Reconstruction and Parsing by Attribute Grammar	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D scene reconstruction; region partition; scene parsing; attribute grammar	MANHATTAN-WORLD; DATABASE; CONTEXT	In this paper, we present an attribute grammar for solving two coupled tasks: i) parsing a 2D image into semantic regions; and ii) recovering the 3D scene structures of all regions. The proposed grammar consists of a set of production rules, each describing a kind of spatial relation between planar surfaces in 3D scenes. These production rules are used to decompose an input image into a hierarchical parse graph representation where each graph node indicates a planar surface or a composite surface. Different from other stochastic image grammars, the proposed grammar augments each graph node with a set of attribute variables to depict scene-level global geometry, e.g., camera focal length, or bee/geometry, e.g., surface normal, contact lines between surfaces. These geometric attributes impose constraints between a node and its off-springs in the parse graph. Under a probabilistic framework, we develop a Markov Chain Monte Carlo method to construct a parse graph that optimizes the 2D image recognition and 3D scene reconstruction purposes simultaneously. We evaluated our method on both public benchmarks and newly collected datasets. Experiments demonstrate that the proposed method is capable of achieving state-of-the-art scene reconstruction of a single image.	[Liu, Xiaobai] SDSU, San Diego, CA 92182 USA; [Zhao, Yibiao] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Zhu, Song-Chun] Univ Calif Los Angeles, Los Angeles, CA 90095 USA	California State University System; San Diego State University; Massachusetts Institute of Technology (MIT); University of California System; University of California Los Angeles	Liu, XB (corresponding author), SDSU, San Diego, CA 92182 USA.	xiaobai.liu@mail.sdsu.edu; ybzhao@ucla.edu; sczhu@stat.ucla.edu			NSF [IIS 1423305, IIS 1657600]; DARPA SIMPLEX project [N66001-15-C-4035]; ONR [MURI N00014-16-1-2007]	NSF(National Science Foundation (NSF)); DARPA SIMPLEX project; ONR(Office of Naval Research)	The project was supported by ONR MURI N00014-16-1-2007, DARPA SIMPLEX project N66001-15-C-4035, NSF IIS 1423305 and NSF IIS 1657600, and NSF IIS 1423305. The three image datasets were collected and annotated by the first author and his students at San Diego State University (SDSU). Xiaobai Liu is the corresponding author.	Bao SY, 2013, PROC CVPR IEEE, P1264, DOI 10.1109/CVPR.2013.167; Barbu A, 2005, IEEE T PATTERN ANAL, V27, P1239, DOI 10.1109/TPAMI.2005.161; Cabral R, 2014, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2014.546; CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813; Choi MJ, 2012, IEEE T PATTERN ANAL, V34, P240, DOI 10.1109/TPAMI.2011.119; Coughlan JM, 2003, NEURAL COMPUT, V15, P1063, DOI 10.1162/089976603765202668; Del Pero L., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2009, DOI 10.1109/CVPR.2011.5995737; Del Pero L, 2013, PROC CVPR IEEE, P153, DOI 10.1109/CVPR.2013.27; Del Pero L, 2012, PROC CVPR IEEE, P2719, DOI 10.1109/CVPR.2012.6247994; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4; Felzenszwalb PF, 2010, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2010.5540067; Furukawa Y, 2009, PROC CVPR IEEE, P1422, DOI 10.1109/CVPRW.2009.5206867; Gilbert A, 2006, LECT NOTES COMPUT SC, V3952, P125; Gupta A, 2010, LECT NOTES COMPUT SC, V6311, P171, DOI 10.1007/978-3-642-15549-9_13; Hane C, 2014, PROC CVPR IEEE, P652, DOI 10.1109/CVPR.2014.89; Hane C, 2013, PROC CVPR IEEE, P97, DOI 10.1109/CVPR.2013.20; Han F, 2003, FIRST IEEE INTERNATIONAL WORKSHOP ON HIGHER-LEVEL KNOWLEDGE IN 3D MODELING AND MOTION ANALYSIS, PROCEEDINGS, P12; Han F, 2009, IEEE T PATTERN ANAL, V31, P59, DOI 10.1109/TPAMI.2008.55; Heitz G., 2009, ADV NEURAL INFORM PR, V21, P641; Hejrati M, 2014, PROC CVPR IEEE, P2449, DOI 10.1109/CVPR.2014.314; Hoiem D, 2005, IEEE I CONF COMP VIS, P654; Hoiem D, 2006, CVPR, DOI DOI 10.1109/CVPR.2006.232; Hoiem D., 2008, 2008 IEEE C COMPUTER, P1, DOI DOI 10.1109/CVPR.2008.4587587; Koutsourakis P, 2009, IEEE I CONF COMP VIS, P1795, DOI 10.1109/ICCV.2009.5459400; Kundu A, 2014, LECT NOTES COMPUT SC, V8694, P703, DOI 10.1007/978-3-319-10599-4_45; Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19; Ladicky L, 2014, LECT NOTES COMPUT SC, V8693, P468, DOI 10.1007/978-3-319-10602-1_31; Li B, 2012, PATTERN RECOGN LETT, V33, P1, DOI 10.1016/j.patrec.2011.09.027; Lim JJ, 2013, IEEE I CONF COMP VIS, P2992, DOI 10.1109/ICCV.2013.372; Liu CX, 2015, PROC CVPR IEEE, P3413, DOI 10.1109/CVPR.2015.7298963; Liu XL, 2014, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2014.275; Marr D., 1982, VISION COMPUTATIONAL, V2, P4; Mobahi H., 2012, P 11 AS C COMP VIS, P593; Payet N., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2017, DOI 10.1109/CVPR.2011.5995326; Prokaj J, 2011, PROC CVPR IEEE, P1337, DOI 10.1109/CVPR.2011.5995593; Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Schwing AG, 2013, IEEE I CONF COMP VIS, P353, DOI 10.1109/ICCV.2013.51; Schwing AG, 2012, LECT NOTES COMPUT SC, V7577, P299, DOI 10.1007/978-3-642-33783-3_22; Straub J, 2014, PROC CVPR IEEE, P3770, DOI 10.1109/CVPR.2014.488; Tighe J, 2013, INT J COMPUT VISION, V101, P329, DOI 10.1007/s11263-012-0574-z; Tretyak E, 2012, INT J COMPUT VISION, V97, P305, DOI 10.1007/s11263-011-0488-1; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Wang S, 2013, PROC CVPR IEEE, P3111, DOI 10.1109/CVPR.2013.400; Wei P, 2013, IEEE I CONF COMP VIS, P3272, DOI 10.1109/ICCV.2013.406; Xiao J., 2012, ADV NEURAL INFORM PR, P755; Xiao JX, 2014, INT J COMPUT VISION, V110, P243, DOI 10.1007/978-3-642-33718-5_48; Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458; Zhang HY, 2013, IEEE I CONF COMP VIS, P3056, DOI 10.1109/ICCV.2013.379; Zhang YD, 2014, LECT NOTES COMPUT SC, V8694, P668, DOI 10.1007/978-3-319-10599-4_43; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718; Zhao Y., 2011, ADV NEURAL INFORM PR, V24, P73	55	17	18	2	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2018	40	3					710	725		10.1109/TPAMI.2017.2689007	http://dx.doi.org/10.1109/TPAMI.2017.2689007			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FV3KC	28368817	hybrid			2022-12-18	WOS:000424465900015
J	Kesaniemi, M; Virtanen, K				Kesaniemi, Martti; Virtanen, Kai			Direct Least Square Fitting of Hyperellipsoids	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Calibration; ellipsoid-specific fitting; ellipses; ellipsoids; least square fitting; regularization	CURVES; SURFACES	This paper presents two new computationally efficient direct methods for fitting n-dimensional ellipsoids to noisy data. They conduct the fitting by minimizing the algebraic distance in subject to suitable quadratic constraints. The hyperellipsoid-specific (HES) method is an elaboration of existing ellipse and 3D ellipsoid-specific fitting methods. It is shown that HES is ellipsoid-specific in n-dimensional space. A limitation of HES is that it may provide biased fitting results with data originating from an ellipsoid with a large ratio between the longest and shortest main axis. The sum-of-discriminants (SOD) method does not have such a limitation. The constraint used by SOD rejects a subset of non-ellipsoidal quadrics, which enables a high tendency to produce ellipsoidal solutions. Moreover, a regularization technique is presented to force the solutions towards ellipsoids with SOD. The regularization technique is compatible also with several existing 2D and 3D fitting methods. The new methods are compared through extensive numerical experiments with n-dimensional variants of three commonly used direct fitting approaches for quadratic surfaces. The results of the experiments imply that in addition to the superior capability to create ellipsoidal solutions, the estimation accuracy of the new methods is better or equal to that of the reference approaches.	[Kesaniemi, Martti; Virtanen, Kai] Aalto Univ, Syst Anal Lab, Dept Math & Syst Anal, Sch Sci, Aalto 00076, Finland	Aalto University	Kesaniemi, M (corresponding author), Aalto Univ, Syst Anal Lab, Dept Math & Syst Anal, Sch Sci, Aalto 00076, Finland.	martti.kesaniemi@gmail.com; kai.virtanen@aalto.fi						Ahn SJ, 2002, IEEE T PATTERN ANAL, V24, P620, DOI 10.1109/34.1000237; Allaire S, 2007, P ANN INT IEEE EMBS, P5087, DOI 10.1109/IEMBS.2007.4353484; Beyer W.H., 1987, CRC STANDARD MATH TA, P210; BIGGERSTAFF RH, 1972, J DENT RES, V51, P1509, DOI 10.1177/00220345720510055101; Blane MM, 2000, IEEE T PATTERN ANAL, V22, P298, DOI 10.1109/34.841760; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; Calafiore G, 2002, IEEE T SYST MAN CY A, V32, P269, DOI 10.1109/TSMCA.2002.1021114; De la Fraga LG, 2007, LECT NOTES COMPUT SC, V4448, P359; Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658; GANDER W, 1994, BIT, V34, P558, DOI 10.1007/BF01934268; Gietzelt M, 2013, COMPUT METH PROG BIO, V111, P62, DOI 10.1016/j.cmpb.2013.03.006; Hagbi N, 2011, IEEE T VIS COMPUT GR, V17, P1369, DOI 10.1109/TVCG.2010.241; Halir R, 1998, WSCG '98, VOL 1, P125; Kanatani K, 2011, COMPUT STAT DATA AN, V55, P2197, DOI 10.1016/j.csda.2010.12.012; Lee KK, 2005, PATTERN RECOGN LETT, V26, P1232, DOI 10.1016/j.patrec.2004.11.004; Li Q., 2004, P IEEE 2004, V2004, P335, DOI DOI 10.1109/GMAP.2004.1290055; Lin ZC, 2016, IEEE T PATTERN ANAL, V38, P1021, DOI 10.1109/TPAMI.2015.2469283; Masuzaki T., 2013, 6 PAC RIM S IM VID T, P314; Noschese S, 2012, NUMER ALGORITHMS, V60, P531, DOI 10.1007/s11075-012-9576-8; Pylvanainen T, 2008, APPL MATH MODEL, V32, P575, DOI 10.1016/j.apm.2007.02.004; ROSIN PL, 1993, PATTERN RECOGN LETT, V14, P799, DOI 10.1016/0167-8655(93)90062-I; SHAHRARAY B, 1989, IEEE T PATTERN ANAL, V11, P600, DOI 10.1109/34.24794; Szpak Z.L., 2012, LNCS, V7576, P87; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; TURNER DA, 1999, RR9803 U HUDD SCH CO; Watzenig D, 2004, IEEE T MAGN, V40, P1116, DOI 10.1109/TMAG.2004.824557; Ying XH, 2012, IEEE T PATTERN ANAL, V34, P1856, DOI 10.1109/TPAMI.2012.109; Zhang X., 2009, P EL MEAS INSTR ICEM, P145	28	17	17	3	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2018	40	1					63	76		10.1109/TPAMI.2017.2658574	http://dx.doi.org/10.1109/TPAMI.2017.2658574			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FP7IH	28129149				2022-12-18	WOS:000417806000006
J	Puggini, L; McLoone, S				Puggini, Luca; McLoone, Sean			Forward Selection Component Analysis: Algorithms and Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Unsupervised dimensionality reduction; subset selection; feature selection	NONLINEAR DIMENSIONALITY REDUCTION; PRINCIPAL COMPONENTS; IDENTIFICATION; CLASSIFICATION; VARIABLES	Principal Component Analysis (PCA) is a powerful and widely used tool for dimensionality reduction. However, the principal components generated are linear combinations of all the original variables and this often makes interpreting results and root-cause analysis difficult. Forward Selection Component Analysis (FSCA) is a recent technique that overcomes this difficulty by performing variable selection and dimensionality reduction at the same time. This paper provides, for the first time, a detailed presentation of the FSCA algorithm, and introduces a number of new variants of FSCA that incorporate a refinement step to improve performance. We then show different applications of FSCA and compare the performance of the different variants with PCA and Sparse PCA. The results demonstrate the efficacy of FSCA as a low information loss dimensionality reduction and variable selection technique and the improved performance achievable through the inclusion of a refinement step.	[Puggini, Luca] Natl Univ Ireland, Dept Elect Engn, Maynooth, Kildare, Ireland; [McLoone, Sean] Queens Univ Belfast, Sch Elect Elect Engn & Comp Sci, Belfast BT7 1NN, Antrim, North Ireland	Maynooth University; Queens University Belfast	Puggini, L (corresponding author), Natl Univ Ireland, Dept Elect Engn, Maynooth, Kildare, Ireland.	luca.puggini@gmail.com; s.mcloone@ieee.org		McLoone, Sean/0000-0002-3016-6197	Maynooth University	Maynooth University	The authors would like to thank Adrian Johnston, Seagate Technology and Niall MacGearailt, Intel Ireland for the provision of use cases and Maynooth University for the financial support provided. The authors would also like to acknowledge the anonymous reviewers for their valuable suggestions which have greatly enhanced the paper.	BARTLETT MS, 1951, ANN MATH STAT, V22, P107, DOI 10.1214/aoms/1177729698; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; CADIMA J, 1995, J APPL STAT, V22, P203, DOI 10.1080/757584614; Cevher V, 2011, IEEE J-STSP, V5, P979, DOI 10.1109/JSTSP.2011.2161862; Cui Y., 2008, SPARS OPT VAR SEL WO; d'Aspremont A, 2007, SIAM REV, V49, P434, DOI 10.1137/050645506; Diaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3; Dy JG, 2004, J MACH LEARN RES, V5, P845; Flynn B, 2011, IEEE T SEMICONDUCT M, V24, P480, DOI 10.1109/TSM.2011.2158122; Frank M., 1956, NAVAL RES LOGISTICS, V3, P95, DOI [DOI 10.1002/NAV.3800030109, 10.1002/nav.3800030109]; Geng X, 2005, IEEE T SYST MAN CY B, V35, P1098, DOI 10.1109/TSMCB.2005.850151; Golub G. H., 2012, MATRIX COMPUTATIONS, V3; Jaggi M., 2013, P 30 INT C MACHINE L, P427; Jain P., 2011, ADV NEURAL INF PROCE, P1215; Jenatton Rodolphe, 2010, P 13 INT C ART INT S, P366; Jolliffe I., 2011, INT ENCY STAT SCI; Jolliffe IT, 2003, J COMPUT GRAPH STAT, V12, P531, DOI 10.1198/1061860032148; JOLLIFFE IT, 1972, APPL STAT, V21, P160, DOI DOI 10.2307/2346488; KRZANOWSKI WJ, 1987, J R STAT SOC C-APPL, V36, P22; Li K, 2006, AUTOMATICA, V42, P1189, DOI 10.1016/j.automatica.2006.03.004; Li K, 2009, IEEE T CIRCUITS-I, V56, P630, DOI 10.1109/TCSI.2008.2002545; Liu R, 2011, INT J INF TECH DECIS, V10, P967, DOI 10.1142/S0219622011004671; Lu Y., 2007, P 15 ACM INT C MULTI, P301; Mao KZ, 2005, IEEE T SYST MAN CY B, V35, P339, DOI 10.1109/TSMCB.2004.843269; Mariey L, 2001, VIB SPECTROSC, V26, P151, DOI 10.1016/S0924-2031(01)00113-8; Masaeli M., 2010, P SIAM INT C DAT MIN, P619; MCCABE GP, 1984, TECHNOMETRICS, V26, P137, DOI 10.2307/1268108; Miller A., 2012, SUBSET SELECTION REG; Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133; Prakash PKS, 2012, ASMC PROC, P91, DOI 10.1109/ASMC.2012.6212875; Ragnoli E, 2009, 2009 IEEE/SEMI ADVANCED SEMICONDUCTOR MANUFACTURING CONFERENCE, P106, DOI 10.1109/ASMC.2009.5155966; Rao N, 2014, CONF REC ASILOMAR C, P437, DOI 10.1109/ACSSC.2014.7094480; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344; Shen HP, 2008, J MULTIVARIATE ANAL, V99, P1015, DOI 10.1016/j.jmva.2007.06.007; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Trygg J, 2007, J PROTEOME RES, V6, P469, DOI 10.1021/pr060594q; Wei HL, 2007, IEEE T PATTERN ANAL, V29, P162, DOI 10.1109/TPAMI.2007.250607; Whitley DC, 2000, J CHEM INF COMP SCI, V40, P1160, DOI 10.1021/ci000384c; Witten DM, 2009, BIOSTATISTICS, V10, P515, DOI 10.1093/biostatistics/kxp008; Wold H, 1966, RES PAPERS STAT, P411; Yue HH, 2000, IEEE T SEMICONDUCT M, V13, P374, DOI 10.1109/66.857948; Zeng DK, 2009, IEEE T SEMICONDUCT M, V22, P419, DOI 10.1109/TSM.2009.2031750; Zhang T, 2011, IEEE T INFORM THEORY, V57, P4689, DOI 10.1109/TIT.2011.2146690; Zhao Z, 2013, MACH LEARN, V92, P195, DOI 10.1007/s10994-013-5373-4; Zheng Z., 2007, P 24 INT C MACH LEAR, P1151, DOI DOI 10.1145/1273496.1273641; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	48	17	17	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2017	39	12					2395	2408		10.1109/TPAMI.2017.2648792	http://dx.doi.org/10.1109/TPAMI.2017.2648792			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL6ZQ	28103191	Green Accepted			2022-12-18	WOS:000414395400006
J	Yi, S; Wang, XG; Lu, CW; Jia, JY; Li, HS				Yi, Shuai; Wang, Xiaogang; Lu, Cewu; Jia, Jiaya; Li, Hongsheng			L-0 Regularized Stationary-Time Estimation for Crowd Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stationary-time estimation; stationary crowd analysis; crowd video surveillance	MIXTURE MODEL; BEHAVIORS; TRACKING; SCENES	In this paper, we tackle the problem of stationary crowd analysis which is as important as modeling mobile groups in crowd scenes and finds many important applications in crowd surveillance. Our key contribution is to propose a robust algorithm for estimating how long a foreground pixel becomes stationary. It is much more challenging than only subtracting background because failure at a single frame due to local movement of objects, lighting variation, and occlusion could lead to large errors on stationary-time estimation. To achieve robust and accurate estimation, sparse constraints along spatial and temporal dimensions are jointly added by mixed partials (which are second-order gradients) to shape a 3D stationary-time map. It is formulated as an L-0 optimization problem. Besides background subtraction, it distinguishes among different foreground objects, which are close or overlapped in the spatio-temporal space by using a locally shared foreground codebook. The proposed technologies are further demonstrated through three applications. 1) Based on the results of stationary-time estimation, 12 descriptors are proposed to detect four types of stationary crowd activities. 2) The averaged stationary-time map is estimated to analyze crowd scene structures. 3) The result of stationary-time estimation is also used to study the influence of stationary crowd groups to traffic patterns.	[Yi, Shuai; Wang, Xiaogang; Li, Hongsheng] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China; [Lu, Cewu; Jia, Jiaya] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China	Chinese University of Hong Kong; Chinese University of Hong Kong	Yi, S (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.	syi@ee.cuhk.edu.hk; xgwang@ee.cuhk.edu.hk; cwlu@cse.cuhk.edu.hk; leojia@cse.cuhk.edu.hk; hsli@ee.cuhk.edu.hk	Jia, Jiaya/I-3251-2012		General Research Fund - Research Grants Council of Hong Kong [CUHK14206114, CUHK14205615, CUHK419412, CUHK14203015, CUHK413113]; Hong Kong Innovation and Technology Support Programme [ITS/221/13FP]; National Natural Science Foundation of China [61371192, 61133009, 61301269]; PhD programs foundation of China [20130185120039]; Sichuan Hi-tech RD Program [2014GZX0009]	General Research Fund - Research Grants Council of Hong Kong(Hong Kong Research Grants Council); Hong Kong Innovation and Technology Support Programme; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); PhD programs foundation of China; Sichuan Hi-tech RD Program	This work is partially supported by the General Research Fund sponsored by the Research Grants Council of Hong Kong (Nos. CUHK14206114, CUHK14205615, CUHK419412, CUHK14203015, CUHK413113), the Hong Kong Innovation and Technology Support Programme (No. ITS/221/13FP), National Natural Science Foundation of China (Nos. 61371192, 61133009, 61301269), PhD programs foundation of China (No. 20130185120039), and Sichuan Hi-tech R&D Program (No. 2014GZX0009).	Ali S, 2007, PROC CVPR IEEE, P65; Amer MR, 2011, IEEE I CONF COMP VIS, P786, DOI 10.1109/ICCV.2011.6126317; [Anonymous], 1897, CROWD STUDY POPULAR; Bolei Zhou, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3441, DOI 10.1109/CVPR.2011.5995459; Bonabeau E, 2002, P NATL ACAD SCI USA, V99, P7280, DOI 10.1073/pnas.082080899; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569; Chang MC, 2011, IEEE I CONF COMP VIS, P747, DOI 10.1109/ICCV.2011.6126312; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cristani M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.23; Denman S, 2007, PATTERN RECOGN LETT, V28, P1232, DOI 10.1016/j.patrec.2007.02.008; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Emonet Remi, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3233, DOI 10.1109/CVPR.2011.5995572; Forsyth D.R., 2009, GROUP DYNAMICS; Fu YW, 2012, LECT NOTES COMPUT SC, V7575, P530, DOI 10.1007/978-3-642-33765-9_38; Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7; Ge WN, 2012, IEEE T PATTERN ANAL, V34, P1003, DOI 10.1109/TPAMI.2011.176; Haritaoglu I, 2001, PROC CVPR IEEE, P431; Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023; HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Hospedales T, 2009, IEEE I CONF COMP VIS, P1165, DOI 10.1109/ICCV.2009.5459342; Hospedales TM, 2011, IEEE T PATTERN ANAL, V33, P2451, DOI 10.1109/TPAMI.2011.81; Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004; Kindermann R., 1980, CONTEMP MATH, V1; Kuettel D., 2010, P IEEE C COMP VIS PA; Lan T., 2010, ADV NEURAL INFORM PR; Lan T, 2012, PROC CVPR IEEE, P1354, DOI 10.1109/CVPR.2012.6247821; Lan T, 2012, IEEE T PATTERN ANAL, V34, P1549, DOI 10.1109/TPAMI.2011.228; Lin DH, 2009, PROC CVPR IEEE, P747, DOI 10.1109/CVPRW.2009.5206660; Lucas B.D., 1981, IJCAI 81 P 7 INT JOI, P674, DOI DOI 10.1109/HPDC.2004.1323531; Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872; Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641; Moussaid M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010047; Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260; Rodriguez M, 2011, IEEE I CONF COMP VIS, P1235, DOI 10.1109/ICCV.2011.6126374; Scovanner P, 2009, IEEE I CONF COMP VIS, P381, DOI 10.1109/ICCV.2009.5459224; Sevilla-Lara L, 2014, LECT NOTES COMPUT SC, V8689, P423, DOI 10.1007/978-3-319-10590-1_28; Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Solmaz B, 2012, IEEE T PATTERN ANAL, V34, P2064, DOI 10.1109/TPAMI.2012.123; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Vazquez D, 2014, IEEE T PATTERN ANAL, V36, P797, DOI 10.1109/TPAMI.2013.163; Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87; Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208; Yamaguchi K, 2011, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2011.5995468; Yi S, 2015, PROC CVPR IEEE, P3488, DOI 10.1109/CVPR.2015.7298971; Zhang JM, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P379, DOI 10.1109/AVSS.2012.51; Zhou BL, 2014, IEEE T PATTERN ANAL, V36, P1586, DOI 10.1109/TPAMI.2014.2300484; Zhou BL, 2012, PROC CVPR IEEE, P2871, DOI 10.1109/CVPR.2012.6248013; Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992	51	17	17	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2017	39	5					981	994		10.1109/TPAMI.2016.2560807	http://dx.doi.org/10.1109/TPAMI.2016.2560807			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ES0WO	28113539				2022-12-18	WOS:000399250000011
J	Hauberg, S; Feragen, A; Enficiaud, R; Black, MJ				Hauberg, Soren; Feragen, Aasa; Enficiaud, Raffi; Black, Michael J.			Scalable Robust Principal Component Analysis Using Grassmann Averages	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Dimensionality reduction; subspace estimation; robust principal component analysis	SPARSE; PCA	In large datasets, manual data verification is impossible, and we must expect the number of outliers to increase with data size. While principal component analysis (PCA) can reduce data size, and scalable solutions exist, it is well-known that outliers can arbitrarily corrupt the results. Unfortunately, state-of-the-art approaches for robust PCA are not scalable. We note that in a zero-mean dataset, each observation spans a one-dimensional subspace, giving a point on the Grassmann manifold. We show that the average subspace corresponds to the leading principal component for Gaussian data. We provide a simple algorithm for computing this Grassmann Average (GA), and show that the subspace estimate is less sensitive to outliers than PCA for general distributions. Because averages can be efficiently computed, we immediately gain scalability. We exploit robust averaging to formulate the Robust Grassmann Average (RGA) as a form of robust PCA. The resulting Trimmed Grassmann Average (TGA) is appropriate for computer vision because it is robust to pixel outliers. The algorithm has linear computational complexity and minimal memory requirements. We demonstrate TGA for background modeling, video restoration, and shadow removal. We show scalability by performing robust PCA on the entire Star Wars IV movie; a task beyond any current method. Source code is available online.	[Hauberg, Soren] Tech Univ Denmark, Sect Cognit Syst, Lyngby, Denmark; [Feragen, Aasa] Univ Copenhagen, Dept Comp Sci, DK-1168 Copenhagen, Denmark; [Enficiaud, Raffi] Max Planck Inst Intelligent Syst, Software Workshop, Tubingen, Germany; [Black, Michael J.] Max Planck Inst Intelligent Syst, Perceiving Syst Dept, Tubingen, Germany	Technical University of Denmark; University of Copenhagen; Max Planck Society; Max Planck Society	Hauberg, S (corresponding author), Tech Univ Denmark, Sect Cognit Syst, Lyngby, Denmark.	sohau@dtu.dk; aasa@diku.dk; raffi.enficiaud@tue.mpg.de; black@tue.mpg.de	Hauberg, Søren/L-2104-2016; Feragen, Aasa/G-1465-2013	Hauberg, Søren/0000-0001-7223-877X; Feragen, Aasa/0000-0002-9945-981X	Villum Foundation; Danish Council for Independent Research (DFF), Natural Sciences; DFF, Technology and Production Sciences; Villum Fonden [00008721] Funding Source: researchfish	Villum Foundation(Villum Fonden); Danish Council for Independent Research (DFF), Natural Sciences; DFF, Technology and Production Sciences; Villum Fonden(Villum Fonden)	Soren Hauberg is funded in part by the Villum Foundation and the Danish Council for Independent Research (DFF), Natural Sciences; Aasa Feragen is funded in part by the DFF, Technology and Production Sciences. The authors are grateful to anonymous reviewers for helpful feedback.	Aanaes H, 2002, IEEE T PATTERN ANAL, V24, P1215, DOI 10.1109/TPAMI.2002.1033213; Arora R, 2012, ANN ALLERTON CONF, P861, DOI 10.1109/Allerton.2012.6483308; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Bhattacharya R, 2003, ANN STAT, V31, P1; Bishop C.M, 2006, PATTERN RECOGN; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; Bridson M., 1999, METRIC SPACE NONPOSI; Campbell N. A., 1980, Applied Statistics, V29, P231, DOI 10.2307/2346896; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; Cetingul HE, 2009, PROC CVPR IEEE, P1896, DOI 10.1109/CVPRW.2009.5206806; Cormen T.H., 2009, INTRO ALGORITHMS; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; Ding C., 2006, PROC INT C MACH LEAR, P281, DOI DOI 10.1145/1143844.1143880; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Embleton N. I., 1993, STAT ANAL SPHERICAL; Favaro P, 2011, PROC CVPR IEEE, P1801, DOI 10.1109/CVPR.2011.5995365; Feng J., 2012, P 29 INT C MACH LEAR, P1; Geman S, 1987, B INT STAT I, V4, P5; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Golub Gene H., 2013, MATRIX COMPUTATION, V3; HANCOCK PJB, 1992, NETWORK-COMP NEURAL, V3, P61, DOI 10.1088/0954-898X/3/1/008; Hauberg S, 2014, PROC CVPR IEEE, P3810, DOI 10.1109/CVPR.2014.481; Huber P., 1981, ROBUST STAT; HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519; Ji H, 2011, SIAM J IMAGING SCI, V4, P1122, DOI 10.1137/100817206; Jolliffe IT, 2002, ENCY STATIST BEHAV S, DOI [10.1007/0-387-22440-8_13, 10.1007/b98835]; Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114; Lee J.M., 2002, INTRO SMOOTH MANIFOL; LEONE FC, 1961, TECHNOMETRICS, V3, P543, DOI 10.2307/1266560; Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169; Lin L. W. Z., 2009, UILUENG092215; Liu G., 2010, P 27 INT C MACHINE L, P663, DOI DOI 10.1109/ICDMW.2010.64; Liu RS, 2014, NEUROCOMPUTING, V142, P529, DOI 10.1016/j.neucom.2014.03.046; Lui YM, 2012, IMAGE VISION COMPUT, V30, P380, DOI 10.1016/j.imavis.2011.08.002; Mardia K.V., 2000, DIRECTIONAL STAT, P15, DOI [10.1002/9780470316979, DOI 10.1002/9780470316979]; McCoy M, 2011, ELECTRON J STAT, V5, P1123, DOI 10.1214/11-EJS636; Naort A, 2013, STOC'13: PROCEEDINGS OF THE 2013 ACM SYMPOSIUM ON THEORY OF COMPUTING, P71; Netrapalli P., 2014, P ADV NEUR INF PROC, V27, P1107; Pennec X, 1999, PROCEEDINGS OF THE IEEE-EURASIP WORKSHOP ON NONLINEAR SIGNAL AND IMAGE PROCESSING (NSIP'99), P194; Roweis S, 1998, ADV NEUR IN, V10, P626; RUYMGAART FH, 1981, J MULTIVARIATE ANAL, V11, P485, DOI 10.1016/0047-259X(81)90091-9; Tron R, 2011, PROC CVPR IEEE, P57, DOI 10.1109/CVPR.2011.5995654; Vidal R., 2005, TPAMI, V27, P1945, DOI DOI 10.1109/TPAMI.2005.244; Wang F., 2013, THESIS; Wulff J, 2015, PROC CVPR IEEE, P120, DOI 10.1109/CVPR.2015.7298607; XU L, 1995, IEEE T NEURAL NETWOR, V6, P131, DOI 10.1109/72.363442; Yadong Mu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2609, DOI 10.1109/CVPR.2011.5995369	48	17	18	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2016	38	11					2298	2311		10.1109/TPAMI.2015.2511743	http://dx.doi.org/10.1109/TPAMI.2015.2511743			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DZ6AW	26731634				2022-12-18	WOS:000385945000012
J	Taghia, J; Leijon, A				Taghia, Jalil; Leijon, Arne			Variational Inference for Watson Mixture Model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian inference; variational inference; Watson distribution; mixture model; axially symmetric; clustering on the unit hypersphere; blind source separation; gene expression	BLIND SOURCE SEPARATION; TRANSCRIPTIONAL PROGRAM; DENSITY-ESTIMATION; FREQUENCY; DISTRIBUTIONS; EXPRESSION; NUMBER	This paper addresses modelling data using the Watson distribution. The Watson distribution is one of the simplest distributions for analyzing axially symmetric data. This distribution has gained some attention in recent years due to its modeling capability. However, its Bayesian inference is fairly understudied due to difficulty in handling the normalization factor. Recent development of Markov chain Monte Carlo (MCMC) sampling methods can be applied for this purpose. However, these methods can be prohibitively slow for practical applications. A deterministic alternative is provided by variational methods that convert inference problems into optimization problems. In this paper, we present a variational inference for Watson mixture models. First, the variational framework is used to side-step the intractability arising from the coupling of latent states and parameters. Second, the variational free energy is further lower bounded in order to avoid intractable moment computation. The proposed approach provides a lower bound on the log marginal likelihood and retains distributional information over all parameters. Moreover, we show that it can regulate its own complexity by pruning unnecessary mixture components while avoiding over-fitting. We discuss potential applications of the modeling with Watson distributions in the problem of blind source separation, and clustering gene expression data sets.	[Taghia, Jalil; Leijon, Arne] KTH Royal Inst Technol, Sch Elect Engn, Commun Theory Lab, S-10044 Stockholm, Sweden	Royal Institute of Technology	Taghia, J (corresponding author), KTH Royal Inst Technol, Sch Elect Engn, Commun Theory Lab, S-10044 Stockholm, Sweden.	taghia@kth.se; leijon@kth.se			European Commission within Marie Curie ITN AUDIS [PITNGA-2008-214699]	European Commission within Marie Curie ITN AUDIS	This work was funded by the European Commission within the Marie Curie ITN AUDIS, grant PITNGA-2008-214699.	Andrews G.E., 1999, SPECIAL FUNCTIONS, V71; Araki S, 2007, SIGNAL PROCESS, V87, P1833, DOI 10.1016/j.sigpro.2007.02.003; Banerjee A, 2005, J MACH LEARN RES, V6, P1345; Banerjee A, 2002, IEEE IJCNN, P1590, DOI 10.1109/IJCNN.2002.1007755; Beal M.J, 2003, THESIS; Besson O, 2013, SIGNAL PROCESS, V93, P3290, DOI 10.1016/j.sigpro.2012.12.018; Besson O, 2012, IEEE T SIGNAL PROCES, V60, P4210, DOI 10.1109/TSP.2012.2197619; Bhattacharya A, 2010, BIOMETRIKA, V97, P851, DOI 10.1093/biomet/asq044; Bishop CM, 2006, PATTERN RECOGNITION; Blei DM, 2007, ANN APPL STAT, V1, P17, DOI 10.1214/07-AOAS114; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Braun M., 2007, J AM STAT ASSOC, V105, P324; Chu S, 1998, SCIENCE, V282, P699, DOI 10.1126/science.282.5389.699; Daalhuis A.B.O., 2010, NIST HDB MATH FUNCTI; DeRisi JL, 1997, SCIENCE, V278, P680, DOI 10.1126/science.278.5338.680; Dhillon I. S., 2001, EFFICIENT CLUSTERING, P357; Dhillon IS, 2003, BIOINFORMATICS, V19, P1612, DOI 10.1093/bioinformatics/btg209; Dryden IL, 2005, ANN STAT, V33, P1643, DOI 10.1214/009053605000000264; Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863; Ghahramani Z, 2001, ADV NEUR IN, V13, P507; Hoff PD, 2009, J COMPUT GRAPH STAT, V18, P438, DOI 10.1198/jcgs.2009.07177; Hyvarinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71; Iyer VR, 1999, SCIENCE, V283, P83, DOI 10.1126/science.283.5398.83; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Jutten C, 2010, HANDBOOK OF BLIND SOURCE SEPARATION: INDEPENDENT COMPONENT ANALYSIS AND APPLICATIONS, P1, DOI 10.1016/B978-0-12-374726-6.00006-0; Lehmann EA, 2008, J ACOUST SOC AM, V124, P269, DOI 10.1121/1.2936367; Lennox KP, 2009, J AM STAT ASSOC, V104, P586, DOI 10.1198/jasa.2009.0024; Ma ZY, 2011, IEEE T PATTERN ANAL, V33, P2160, DOI 10.1109/TPAMI.2011.63; Makino S, 2007, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-4020-6479-1; Mardia K.V., 2000, DIRECTIONAL STAT; Mardia KV, 2007, BIOMETRICS, V63, P505, DOI 10.1111/j.1541-0420.2006.00682.x; Mardia KV, 1999, J ROY STAT SOC B, V61, P913, DOI 10.1111/1467-9868.00210; Neal Radford M, 2011, HDB MARKOV CHAIN MON, V2; Neal RM, 2001, STAT COMPUT, V11, P125, DOI 10.1023/A:1008923215028; O'Grady PD, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/784296; PRENTICE MJ, 1984, BIOMETRIKA, V71, P147, DOI 10.2307/2336406; Robert C, 2004, MONTE CARLO STAT MET, DOI DOI 10.1007/978-1-4757-4145-2; Salakhutdinov R., 2003, P INT C MACH LEARN, V20, P664; Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI DOI 10.1145/371920.372071; Sawada H, 2007, IEEE INT SYMP CIRC S, P3247, DOI 10.1109/ISCAS.2007.378164; Sawada H, 2011, IEEE T AUDIO SPEECH, V19, P516, DOI 10.1109/TASL.2010.2051355; Sharan R, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P307; Shatkay H, 2000, Proc Int Conf Intell Syst Mol Biol, V8, P317; Shen X, 2007, PROC 11 INT C ARTIF, P35; Smaragdis P, 1998, NEUROCOMPUTING, V22, P21, DOI 10.1016/S0925-2312(98)00047-2; Sohl-Dickstein J., 2012, ARXIV12051925, P10; Spellman PT, 1998, MOL BIOL CELL, V9, P3273, DOI 10.1091/mbc.9.12.3273; Sra S., 2011, J MULTIVARIATE ANAL, P256; Strehl A., 2000, WORKSHOP ARTIFICIAL, P58; Taghia J, 2014, IEEE T PATTERN ANAL, V36, P1701, DOI 10.1109/TPAMI.2014.2306426; Taghia J, 2014, IEEE SIGNAL PROC LET, V21, P625, DOI 10.1109/LSP.2014.2309607; Taghia J, 2012, INT CONF ACOUST SPEE, P253, DOI 10.1109/ICASSP.2012.6287865; Tran-Vu D. H., 2010, P INT WORKSH AC SIGN; Turner R., 2008, COUNTEREXAMPLES VARI; Turner R. E., 2011, BAYESIAN TIME SERIES, P109; Vincent E., 2009, P 8 INT C IND COMP A, P253; Vincent E, 2007, LECT NOTES COMPUT SC, V4666, P552; Vu D. H. T., 2010, P INT C AC SPEECH SI, P241; WATSON GS, 1965, BIOMETRIKA, V52, P193, DOI 10.2307/2333824; Yilmaz O, 2004, IEEE T SIGNAL PROCES, V52, P1830, DOI 10.1109/TSP.2004.828896	60	17	17	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2016	38	9					1886	1900		10.1109/TPAMI.2015.2498935	http://dx.doi.org/10.1109/TPAMI.2015.2498935			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DT4EK	26571512				2022-12-18	WOS:000381432700013
J	Saeidi, R; Astudillo, RF; Kolossa, D				Saeidi, Rahim; Astudillo, Ramon Fernandez; Kolossa, Dorothea			Uncertain LDA: Including Observation Uncertainties in Discriminative Transforms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	27th IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 23-28, 2014	Columbus, OH	Comp Vis Fdn, IEEE, IEEE Comp Soc		Uncertainty; linear discriminant analysis; LDA; speaker recognition; speech recognition	HIDDEN MARKOV-MODELS; SPEAKER VERIFICATION; HETEROSCEDASTIC EXTENSION; CHANNEL COMPENSATION; ROBUST RECOGNITION; SPEECH RECOGNITION; NOISY; SEPARATION; REDUCTION; DISTANCE	Linear discriminant analysis (LDA) is a powerful technique in pattern recognition to reduce the dimensionality of data vectors. It maximizes discriminability by retaining only those directions that minimize the ratio of within-class and between-class variance. In this paper, using the same principles as for conventional LDA, we propose to employ uncertainties of the noisy or distorted input data in order to estimate maximally discriminant directions. We demonstrate the efficiency of the proposed uncertain LDA on two applications using state-of-the-art techniques. First, we experiment with an automatic speech recognition task, in which the uncertainty of observations is imposed by real-world additive noise. Next, we examine a full-scale speaker recognition system, considering the utterance duration as the source of uncertainty in authenticating a speaker. The experimental results show that when employing an appropriate uncertainty estimation algorithm, uncertain LDA outperforms its conventional LDA counterpart.	[Saeidi, Rahim] Aalto Univ, Dept Signal Proc & Acoust, Espoo, Uusimaa, Finland; [Astudillo, Ramon Fernandez] INESC ID, Spoken Language Syst Lab, Lisbon, Portugal; [Kolossa, Dorothea] Ruhr Univ Bochum, Inst Commun Acoust, Univ Str 150, Bochum, Nrw, Germany	Aalto University; INESC-ID; Universidade de Lisboa; Ruhr University Bochum	Saeidi, R (corresponding author), Aalto Univ, Dept Signal Proc & Acoust, Espoo, Uusimaa, Finland.	rahim.saeidi@aalto.fi; ramon@astudillo.com; dorothea.kolossa@rub.de	Saeidi, Rahim/J-5963-2014	Saeidi, Rahim/0000-0002-9084-0091				Astudillo R., 2010, THESIS; Astudillo R. F., 2009, P INTERSPEECH, P2491; Astudillo RF, 2013, COMPUT SPEECH LANG, V27, P837, DOI 10.1016/j.csl.2012.07.009; Astudillo RF, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P713; Barker J, 2013, COMPUT SPEECH LANG, V27, P621, DOI 10.1016/j.csl.2012.10.004; Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980; Boril H, 2010, IEEE T AUDIO SPEECH, V18, P1379, DOI 10.1109/TASL.2009.2034770; Burget L, 2007, IEEE T AUDIO SPEECH, V15, P1979, DOI 10.1109/TASL.2007.902499; CHEN CH, 1976, INFORM SCIENCES, V10, P159, DOI 10.1016/S0020-0255(76)90746-5; Chengzhu Yu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4017, DOI 10.1109/ICASSP.2014.6854356; Cumani S, 2014, IEEE-ACM T AUDIO SPE, V22, P846, DOI 10.1109/TASLP.2014.2308473; Cumani S, 2013, INT CONF ACOUST SPEE, P7644, DOI 10.1109/ICASSP.2013.6639150; Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307; Deng L, 2005, IEEE T SPEECH AUDI P, V13, P412, DOI 10.1109/TSA.2005.845814; Droppo J, 2002, INT CONF ACOUST SPEE, P57; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Gales M, 2007, FOUND TRENDS SIGNAL, V1, P195, DOI 10.1561/2000000004; Gales MJF, 1999, IEEE T SPEECH AUDI P, V7, P272, DOI 10.1109/89.759034; Garcia-Romero D., 2011, 12 ANN C INT SPEECH; Haeb-Umbach R., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P13, DOI 10.1109/ICASSP.1992.225984; Hasan T, 2013, INT CONF ACOUST SPEE, P7663, DOI 10.1109/ICASSP.2013.6639154; Hastie T, 1996, J ROY STAT SOC B MET, V58, P155; Hastie T., 2013, ELEMENTS STAT LEARNI, V10; Hastie T., 2001, ELEMENTS STAT LEARNI, V1; Hatch AO, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1471; Hautamaki V., 2013, P INTERSPEECH, P3708; Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616; Hurmalainen A, 2013, COMPUT SPEECH LANG, V27, P763, DOI 10.1016/j.csl.2012.07.008; Ioffe S, 2006, LECT NOTES COMPUT SC, V3954, P531; Kanagasundaram A, 2013, INTERSPEECH, P2464; Kanagasundaram A, 2014, SPEECH COMMUN, V59, P69, DOI 10.1016/j.specom.2014.01.004; Kenny P., 2005, CRIM060813, V14, P2; Kenny P., 2010, ODYSSEY; Kenny P, 2007, IEEE T AUDIO SPEECH, V15, P1448, DOI 10.1109/TASL.2007.894527; Kenny P, 2013, INT CONF ACOUST SPEE, P7649, DOI 10.1109/ICASSP.2013.6639151; Kim H, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P527; Kinnunen T, 2013, INT CONF ACOUST SPEE, P7229, DOI 10.1109/ICASSP.2013.6639066; Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009; Kolossa D, 2005, IEEE WORK APPL SIG, P82, DOI 10.1109/ASPAA.2005.1540174; Kolossa D, 2011, ROBUST SPEECH RECOGNITION OF UNCERTAIN OR MISSING DATA: THEORY AND APPLICATIONS, P1, DOI 10.1007/978-3-642-21317-5; Kolossa D., 2009, P INT C AUD VIS SPEE, P117; Kolossa D, 2013, IEEE SIGNAL PROC LET, V20, P1018, DOI 10.1109/LSP.2013.2278556; Kumar N, 1998, SPEECH COMMUN, V26, P283, DOI 10.1016/S0167-6393(98)00061-2; Li YP, 2013, IEEE T KNOWL DATA EN, V25, P2463, DOI 10.1109/TKDE.2012.179; Liao H, 2007, INT CONF ACOUST SPEE, P389; Loog M, 2004, IEEE T PATTERN ANAL, V26, P732, DOI 10.1109/TPAMI.2004.13; Loog M, 2001, IEEE T PATTERN ANAL, V23, P762, DOI 10.1109/34.935849; Lu L, 2014, IEEE SIGNAL PROC LET, V21, P702, DOI 10.1109/LSP.2014.2313410; Mahanta MS, 2012, INT CONF ACOUST SPEE, P1921, DOI 10.1109/ICASSP.2012.6288280; Mandasari MI, 2013, IEEE T AUDIO SPEECH, V21, P2425, DOI 10.1109/TASL.2013.2279332; Peng J, 2012, INT GEOSCI REMOTE SE, P3493, DOI 10.1109/IGARSS.2012.6350667; Prince SJD, 2007, IEEE I CONF COMP VIS, P1751; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RAO CR, 1948, J ROY STAT SOC B, V10, P159; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361; Saeidi R, 2013, INTERSPEECH, P1985; Saeidi R., 2015, P INTERSPEECH; Shao Y, 2007, INT CONF ACOUST SPEE, P277; Solomonoff A, 2005, INT CONF ACOUST SPEE, P629; Srivastava S, 2007, J MACH LEARN RES, V8, P1277; Stafylakis T, 2013, INTERSPEECH, P3651; van Leeuwen DA, 2013, INT CONF ACOUST SPEE, P6778, DOI 10.1109/ICASSP.2013.6638974; VanDalen R. C., 2011, THESIS; Vincent E, 2013, INT CONF ACOUST SPEE, P126, DOI 10.1109/ICASSP.2013.6637622; Virtanen  T., 2012, TECHNIQUES NOISE ROB; Yoma NB, 2002, IEEE T SPEECH AUDI P, V10, P158, DOI 10.1109/TSA.2002.1001980; Young S.J., 2006, HTK BOOK VERSION 3 4; Zhao XJ, 2014, IEEE-ACM T AUDIO SPE, V22, P836, DOI 10.1109/TASLP.2014.2308398; Zhu ML, 2006, IEEE T PATTERN ANAL, V28, P1274, DOI 10.1109/TPAMI.2006.172	72	17	17	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2016	38	7							1479	10.1109/TPAMI.2015.2481420	http://dx.doi.org/10.1109/TPAMI.2015.2481420			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	DO6MH	26415158				2022-12-18	WOS:000377897100016
J	Cinbis, RG; Verbeek, J; Schmid, C				Cinbis, Ramazan Gokberk; Verbeek, Jakob; Schmid, Cordelia			Approximate Fisher Kernels of Non-iid Image Models for Image Categorization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Statistical image representations; object recognition; image classification; Fisher kernels	OBJECT CATEGORIZATION; CLASSIFICATION; DESCRIPTORS; VECTOR	The bag-of-words (BoW) model treats images as sets of local descriptors and represents them by visual word histograms. The Fisher vector (FV) representation extends BoW, by considering the first and second order statistics of local descriptors. In both representations local descriptors are assumed to be identically and independently distributed (iid), which is a poor assumption from a modeling perspective. It has been experimentally observed that the performance of BoW and FV representations can be improved by employing discounting transformations such as power normalization. In this paper, we introduce non-iid models by treating the model parameters as latent variables which are integrated out, rendering all local regions dependent. Using the Fisher kernel principle we encode an image by the gradient of the data log-likelihood w.r.t. the model hyper-parameters. Our models naturally generate discounting effects in the representations; suggesting that such transformations have proven successful because they closely correspond to the representations obtained for non-iid models. To enable tractable computation, we rely on variational free-energy bounds to learn the hyper-parameters and to compute approximate Fisher kernels. Our experimental evaluation results validate that our models lead to performance improvements comparable to using power normalization, as employed in state-of-the-art feature aggregation methods.	[Cinbis, Ramazan Gokberk] Milsoft, Ankara, Turkey; [Verbeek, Jakob; Schmid, Cordelia] Univ Grenoble Alpes, CNRS, Lab Jean Kuntzmann, LEAR Team,Inria Grenoble Rhone Alpes, Grenoble, France	Milsoft Software Technologies; UDICE-French Research Universities; Communaute Universite Grenoble Alpes; Institut National Polytechnique de Grenoble; Universite Grenoble Alpes (UGA); Centre National de la Recherche Scientifique (CNRS); Inria	Cinbis, RG (corresponding author), Milsoft, Ankara, Turkey.; Verbeek, J; Schmid, C (corresponding author), Univ Grenoble Alpes, CNRS, Lab Jean Kuntzmann, LEAR Team,Inria Grenoble Rhone Alpes, Grenoble, France.	ramazan.cinbis@inria.fr; Jakob.Verbeek@inria.fr; cordelia.schmid@inria.fr	Cinbis, Ramazan Gokberk/AAQ-6929-2020	Cinbis, Ramazan Gokberk/0000-0003-0962-7101	European integrated project AXES; ERC advanced grant ALLEGRO	European integrated project AXES; ERC advanced grant ALLEGRO	This work was supported by the European integrated project AXES and the ERC advanced grant ALLEGRO. Most of the work in this paper was done when R. G. Cinbis was with the LEAR team, Inria Grenoble, France.	Bilen H, 2014, P BRIT MACH VIS C, P112; Bishop C.M, 2006, PATTERN RECOGN; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Chandalia G., 2006, P NIPS WORKSH NOV AP; Chappelier JC, 2009, LECT NOTES ARTIF INT, V5781, P195, DOI 10.1007/978-3-642-04180-8_30; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Cinbis RG, 2013, IEEE I CONF COMP VIS, P2968, DOI 10.1109/ICCV.2013.369; Cinbis RG, 2012, PROC CVPR IEEE, P2184, DOI 10.1109/CVPR.2012.6247926; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Doersch Carl, 2013, NIPS; Elkan C, 2005, LECT NOTES COMPUT SC, V3772, P295; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26; Halevy A, 2009, IEEE INTELL SYST, V24, P8, DOI 10.1109/MIS.2009.36; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Hofmann T., 1999, P ADV NEUR INF PROC, V12, P914; Jaakkola TS, 1999, ADV NEUR IN, V11, P487; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Jegou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609; Jia Y., P ACM MULT, P675; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Juneja M, 2013, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2013.124; Kobayashi T, 2014, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2014.413; Krapac J, 2011, IEEE I CONF COMP VIS, P1487, DOI 10.1109/ICCV.2011.6126406; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Larlus D, 2009, IMAGE VISION COMPUT, V27, P523, DOI 10.1016/j.imavis.2008.04.022; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Liu L., 2014, P ADV NEUR INF PROC, V27, P1143; MacKay D. J. C., 2003, INFORM THEORY INFERE, P269; Madsen RE, 2005, P 22 INT C MACH LEAR, P545, DOI DOI 10.1145/1102351.1102420; Minka T., 2012, ESTIMATING DIRICHLET; Perina A., 2015, IEEE T PATTERN ANAL; Perina A., 2009, ADV NEURAL INFORM PR, P1428; Perina A, 2014, INT C PATT RECOG, P1770, DOI 10.1109/ICPR.2014.311; Perronnin F., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383266; Perronnin F, 2010, PROC CVPR IEEE, P2297, DOI 10.1109/CVPR.2010.5539914; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537; Quelhas P, 2005, IEEE I CONF COMP VIS, P883; Rana A., 2014, COMPUTER VISION FSLC, P152; Razavian A.S., 2014, ARXIV14036382; Sanchez J, 2015, PATTERN RECOGN LETT, V59, P26, DOI 10.1016/j.patrec.2015.03.010; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Sermanet P., 2014, P INT C LEARN REPR A; Simonyan K., 2014, 3 INT C LEARN REPR I; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132; Vedaldi A, 2010, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2010.5539949; Wang X., 2008, ADV NEURAL INFORM PR, P1577; Wei Y., 2014, COMPUT RES REPOSITOR; Winn J, 2005, IEEE I CONF COMP VIS, P1800; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4	55	17	17	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2016	38	6					1084	1098		10.1109/TPAMI.2015.2484342	http://dx.doi.org/10.1109/TPAMI.2015.2484342			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DL4LU	26441445	Green Submitted			2022-12-18	WOS:000375609000004
J	Barron, JT; Malik, J				Barron, Jonathan T.; Malik, Jitendra			Intrinsic Scene Properties from a Single RGB-D Image	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; machine learning; intrinsic images; shape from shading; shape estimation; illumination estimation; segmentation; normalized cuts; depth sensing	ILLUMINATION	In this paper, we present a technique for recovering a model of shape, illumination, reflectance, and shading from a single image taken from an RGB-D sensor. To do this, we extend the SIRFS ("shape, illumination and reflectance from shading") model, which recovers intrinsic scene properties from a single image [1]. Though SIRFS works well on neatly segmented images of objects, it performs poorly on images of natural scenes which often contain occlusion and spatially-varying illumination. We therefore present Scene-SIRFS, a generalization of SIRFS in which we model a scene using a mixture of shapes and a mixture of illuminations, where those mixture components are embedded in a "soft" segmentation-like representation of the input image. We use the noisy depth maps provided by RGB-D sensors (such as the Microsoft Kinect) to guide and improve shape estimation. Our model takes as input a single RGB-D image and produces as output an improved depth map, a set of surface normals, a reflectance image, a shading image, and a spatially varying model of illumination. The output of our model can be used for graphics applications such as relighting and retargeting, or for more broad applications (recognition, segmentation) involving RGB-D images.	[Barron, Jonathan T.; Malik, Jitendra] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA	University of California System; University of California Berkeley	Barron, JT; Malik, J (corresponding author), Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.	barron@eecs.berkeley.edu; malik@eecs.berkeley.edu			US National Science Foundation (NSF) GRFP; ONR MURI [N00014-10-10933]	US National Science Foundation (NSF) GRFP(National Science Foundation (NSF)); ONR MURI(MURIOffice of Naval Research)	J. Barron was supported by US National Science Foundation (NSF) GRFP and ONR MURI N00014-10-10933.	[Anonymous], 2015, P IEEE C COMP VIS PA; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Barron J. T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2521, DOI 10.1109/CVPR.2011.5995392; Barron JT, 2012, PROC CVPR IEEE, P334, DOI 10.1109/CVPR.2012.6247693; Barron JT, 2012, LECT NOTES COMPUT SC, V7575, P57, DOI 10.1007/978-3-642-33765-9_5; Barrow H. G., 1978, COMPUT VIS SYST; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; BLAKE A, 1985, IMAGE VISION COMPUT, V3, P183, DOI 10.1016/0262-8856(85)90006-X; Chen QF, 2013, IEEE I CONF COMP VIS, P241, DOI 10.1109/ICCV.2013.37; Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; Forsyth DA, 2011, INT J COMPUT VISION, V91, P280, DOI 10.1007/s11263-010-0396-9; Grosse R, 2009, IEEE I CONF COMP VIS, P2335, DOI 10.1109/ICCV.2009.5459428; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; HORN B, 1970, AITR232 MIT; Horn B. K., 1974, COMPUT VISION GRAPH, V3, P277, DOI DOI 10.1016/0146-664X(74)90022-7; Karst KL, 2011, SUPREME COURT REV, P1; KOENDERINK JJ, 1984, PERCEPTION, V13, P321, DOI 10.1068/p130321; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; Lee KJ, 2012, LECT NOTES COMPUT SC, V7577, P327, DOI 10.1007/978-3-642-33783-3_24; Leung T. K., 1998, P IEEE C COMP VIS PA, P1; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; Maire Michael, 2008, P IEEE C COMP VIS PA; Maji S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2057, DOI 10.1109/CVPR.2011.5995630; Ng AY, 2002, ADV NEUR IN, V14, P849; Ostrovsky Y, 2005, PERCEPTION, V34, P1301, DOI 10.1068/p5418; Pharr M., 2010, PHYS BASED RENDERING; Ramamoorthi R, 2001, COMP GRAPH, P497, DOI 10.1145/383259.383317; Rother C., 2011, ADV NEURAL INFORM PR, P765; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Tappen M. F., 2005, TP AMI; Yu YZ, 1999, COMP GRAPH, P215	34	17	18	0	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2016	38	4					690	703		10.1109/TPAMI.2015.2439286	http://dx.doi.org/10.1109/TPAMI.2015.2439286			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DH1MW	26959674	hybrid			2022-12-18	WOS:000372549700007
J	Zhang, XH; Qu, Y; Yang, D; Wang, HX; Kymer, J				Zhang, Xiaohong; Qu, Ying; Yang, Dan; Wang, Hongxing; Kymer, Jeff			Laplacian Scale-Space Behavior of Planar Curve Corners	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Corner detection; Laplacian of Gaussian; planar curve; scale space	MULTISCALE; DETECTOR; REGION	Scale-space behavior of corners is important for developing an efficient corner detection algorithm. In this paper, we analyze the scale-space behavior with the Laplacian of Gaussian (LoG) operator on a planar curve which constructs Laplacian Scale Space (LSS). The analytical expression of a Laplacian Scale-Space map (LSS map) is obtained, demonstrating the Laplacian Scale-Space behavior of the planar curve corners, based on a newly defined unified corner model. With this formula, some Laplacian Scale-Space behavior is summarized. Although LSS demonstrates some similarities to Curvature Scale Space (CSS), there are still some differences. First, no new extreme points are generated in the LSS. Second, the behavior of different cases of a corner model is consistent and simple. This makes it easy to trace the corner in a scale space. At last, the behavior of LSS is verified in an experiment on a digital curve.	[Zhang, Xiaohong] Minist Educ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400044, Peoples R China; [Zhang, Xiaohong; Yang, Dan; Kymer, Jeff] Chongqing Univ, Sch Software Engn, Chongqing 401331, Peoples R China; [Zhang, Xiaohong] State Key Lab Coal Mine Disaster Dynam & Control, Chongqing 400044, Peoples R China; [Qu, Ying] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China; [Wang, Hongxing] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore	Chongqing University; Chongqing University; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Zhang, XH (corresponding author), Minist Educ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400044, Peoples R China.	xhongz@cqu.edu.cn; ying.qu@cqu.edu.cn; dyang@cqu.edu.cn; ihxwang@ntu.edu.sg; kymer@industrialfun.com	YANG, Dan/HHD-2733-2022; Wang, Hongxing/F-4670-2011	Wang, Hongxing/0000-0001-7799-1023	National Natural Science Foundation of China [61173131, 91118005, 11202249]; Program for Changjiang Scholars and Innovative Research Team in University [IRT1196]; Fundamental Research Funds for the Central Universities [CDJZR12098801, CDJZR11095501]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Program for Changjiang Scholars and Innovative Research Team in University(Program for Changjiang Scholars & Innovative Research Team in University (PCSIRT)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	This work was partially supported by the National Natural Science Foundation of China (Grant no. 61173131, 91118005, 11202249), Program for Changjiang Scholars and Innovative Research Team in University (Grant No. IRT1196) and the Fundamental Research Funds for the Central Universities (Grant Nos. CDJZR12098801 and CDJZR11095501). Xiaohong Zhang is the corresponding author of the article.	ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; Awrangjeb M, 2008, IEEE T IMAGE PROCESS, V17, P2425, DOI 10.1109/TIP.2008.2006441; Awrangjeb M, 2012, IEEE T IMAGE PROCESS, V21, P4167, DOI 10.1109/TIP.2012.2200493; BALMASHNOVA E, 2007, P IEEE 11 INT C COMP, P1; Bebis G, 1999, PATTERN RECOGN, V32, P1175, DOI 10.1016/S0031-3203(98)00159-9; Chang CC, 2006, NEUROCOMPUTING, V69, P2017, DOI 10.1016/j.neucom.2005.11.002; Cui M, 2007, VISUAL COMPUT, V23, P607, DOI 10.1007/s00371-007-0164-1; Florack L, 2000, J MATH IMAGING VIS, V12, P65, DOI 10.1023/A:1008304909717; Garrido A, 1998, PATTERN RECOGN, V31, P791, DOI 10.1016/S0031-3203(97)00104-0; He XC, 2004, INT C PATT RECOG, P791, DOI 10.1109/ICPR.2004.1334377; Lindeberg T, 1996, PROC CVPR IEEE, P465, DOI 10.1109/CVPR.1996.517113; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Lindeberg T, 2013, J MATH IMAGING VIS, V46, P177, DOI 10.1007/s10851-012-0378-3; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mahmoudi S, 2007, PATTERN RECOGN LETT, V28, P1705, DOI 10.1016/j.patrec.2007.04.012; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; Mokhtarian F, 2005, PATTERN RECOGN, V38, P1021, DOI 10.1016/j.patcog.2004.11.021; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; Mokhtarian F, 1998, IEEE T PATTERN ANAL, V20, P1376, DOI 10.1109/34.735812; Paula IC, 2013, J MATH IMAGING VIS, V45, P251, DOI 10.1007/s10851-012-0365-8; Quddus A, 2002, PATTERN RECOGN LETT, V23, P215, DOI 10.1016/S0167-8655(01)00090-3; RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805; RAY BK, 1995, PATTERN RECOGN, V28, P1765, DOI 10.1016/0031-3203(95)00046-3; Tabbone S., 1993, Proceedings of the 8th Scandinavian Conference on Image Analysis, P1055; TABBONE S, 1994, INT C PATT RECOG, P52, DOI 10.1109/ICPR.1994.576225; Tabbone SA, 2005, J MATH IMAGING VIS, V23, P107, DOI 10.1007/s10851-005-4970-7; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; XIN K, 1995, PATTERN RECOGN, V28, P1145, DOI 10.1016/0031-3203(95)00007-M; Yeh CH, 2003, PATTERN RECOGN LETT, V24, P2797, DOI 10.1016/S0167-8655(03)00124-7; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]; Zabulis X, 2005, PATTERN RECOGN, V38, P75, DOI 10.1016/j.patcog.2004.06.003; Zhang XH, 2007, PATTERN RECOGN LETT, V28, P545, DOI 10.1016/j.patrec.2006.10.006; Zhang XH, 2009, PATTERN RECOGN LETT, V30, P449, DOI 10.1016/j.patrec.2008.11.002; Zhong BJ, 2007, IEEE T PATTERN ANAL, V29, P508, DOI 10.1109/TPAMI.2007.50; Zhong BJ, 2010, INFORMATION TECHNOLOGY FOR MANUFACTURING SYSTEMS, PTS 1 AND 2, P725, DOI 10.4028/www.scientific.net/AMM.20-23.725; Zhong BJ, 2009, IEEE T PATTERN ANAL, V31, P1517, DOI 10.1109/TPAMI.2008.295	39	17	17	2	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2015	37	11					2207	2217		10.1109/TPAMI.2015.2396074	http://dx.doi.org/10.1109/TPAMI.2015.2396074			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CS9KW	26440262				2022-12-18	WOS:000362411000005
J	Han, L; Wilson, RC; Hancock, ER				Han, Lin; Wilson, Richard C.; Hancock, Edwin R.			Generative Graph Prototypes from Information Theory	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Generative prototype; supergraph; minimum description length criterion; Von Neumann entropy; Jensen-Shannon divergence	ALGORITHM; 1ST-ORDER; MIXTURE	In this paper we present a method for constructing a generative prototype for a set of graphs by adopting a minimum description length approach. The method is posed in terms of learning a generative supergraph model from which the new samples can be obtained by an appropriate sampling mechanism. We commence by constructing a probability distribution for the occurrence of nodes and edges over the supergraph. We encode the complexity of the supergraph using an approximate Von Neumann entropy. A variant of the EM algorithm is developed to minimize the description length criterion in which the structure of the supergraph and the node correspondences between the sample graphs and the supergraph are treated as missing data. To generate new graphs, we assume that the nodes and edges of graphs arise under independent Bernoulli distributions and sample new graphs according to their node and edge occurrence probabilities. Empirical evaluations on real-world databases demonstrate the practical utility of the proposed algorithm and show the effectiveness of the generative model for the tasks of graph classification, graph clustering and generating new sample graphs.	[Han, Lin; Wilson, Richard C.; Hancock, Edwin R.] Univ York, Dept Comp Sci, York YO10 5GH, N Yorkshire, England	University of York - UK	Han, L (corresponding author), Univ York, Dept Comp Sci, York YO10 5GH, N Yorkshire, England.	hanlin0825@hotmail.com; richard.wilson@york.ac.uk; edwin.hancock@york.ac.uk	Hancock, Edwin/N-7548-2019; Hancock, Edwin R/C-6071-2008	Hancock, Edwin/0000-0003-4496-2028; Hancock, Edwin R/0000-0003-4496-2028				Ahuja N., 2007, INT C COMP VIS, P1; Anand K, 2011, PHYS REV E, V83, DOI 10.1103/PhysRevE.83.036109; [Anonymous], 2008, INT J AGENT TECHNOLO; Bagdanov AD, 2003, PATTERN RECOGN, V36, P1311, DOI 10.1016/S0031-3203(02)00227-3; Barabasi AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509; Braunstein SL, 2006, ANN COMB, V10, P291, DOI 10.1007/s00026-006-0289-3; Bridle J. S., 1990, PROC 2 INT C NEURAL, P211, DOI [10.5555/2969830, DOI 10.5555/2969830]; BURBEA J, 1982, IEEE T INFORM THEORY, V28, P489, DOI 10.1109/TIT.1982.1056497; CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565; Christmas WJ, 1996, IMAGE VISION COMPUT, V14, P617, DOI 10.1016/0262-8856(96)01093-1; Chung F, 2003, P NATL ACAD SCI USA, V100, P6313, DOI 10.1073/pnas.0937490100; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; Dunn J. C., 1974, Journal of Cybernetics, V4, P95, DOI 10.1080/01969727408546059; ERDOS P, 1960, B INT STATIST INST, V38, P343; Estrada FJ, 2009, INT J COMPUT VISION, V85, P167, DOI 10.1007/s11263-009-0251-z; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Friedman N, 2003, MACH LEARN, V50, P95, DOI 10.1023/A:1020249912095; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Grunwald P.D., 2005, ADV MINIMUM DESCRIPT; Han L, 2012, PATTERN RECOGN LETT, V33, P1958, DOI 10.1016/j.patrec.2012.03.016; Han L, 2011, LECT NOTES COMPUT SC, V7005, P133, DOI 10.1007/978-3-642-24471-1_10; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Krishnapuram B, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P20, DOI 10.1109/IWFHR.2004.46; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Luo B, 2006, PATTERN RECOGN, V39, P1188, DOI 10.1016/j.patcog.2006.01.001; Luo B, 2001, IEEE T PATTERN ANAL, V23, P1120, DOI 10.1109/34.954602; Martins AFT, 2009, J MACH LEARN RES, V10, P935; Mingkhwan A, 2006, MULTIMED TOOLS APPL, V29, P257, DOI 10.1007/s11042-006-0018-2; Nene A. S., 1996, CUCS00696; Ranzato M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2857, DOI 10.1109/CVPR.2011.5995710; Ren P, 2011, IEEE T NEURAL NETWOR, V22, P233, DOI 10.1109/TNN.2010.2091969; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150; Rissanen Jorma, 1989, STOCHASTIC COMPLEXIT; Shi JB, 1997, PROC CVPR IEEE, P731, DOI 10.1109/CVPR.1997.609407; Shokoufandeh A., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P491, DOI 10.1109/CVPR.1999.784726; Srinivasan A, 1996, ARTIF INTELL, V85, P277, DOI 10.1016/0004-3702(95)00122-0; Torsello A, 2006, IEEE T PATTERN ANAL, V28, P954, DOI 10.1109/TPAMI.2006.125; Torsello A., 2008, INT C PATT REC, P1; White D, 2008, INT C PATT RECOG, P3318; Xiao B, 2009, PATTERN RECOGN, V42, P2589, DOI 10.1016/j.patcog.2008.12.029; Zhu SC, 2006, FOUND TRENDS COMPUT, V2, P259, DOI 10.1561/0600000018	44	17	17	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2015	37	10					2013	2027		10.1109/TPAMI.2015.2400451	http://dx.doi.org/10.1109/TPAMI.2015.2400451			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CQ7VL	26340255				2022-12-18	WOS:000360813400006
J	Lu, F; Matsushita, Y; Sato, I; Okabe, T; Sato, Y				Lu, Feng; Matsushita, Yasuyuki; Sato, Imari; Okabe, Takahiro; Sato, Yoichi			From Intensity Profile to Surface Normal: Photometric Stereo for Unknown Light Sources and Isotropic Reflectances	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Uncalibrated photometric stereo; general reflectance; BRDF; intensity profile	SHAPE	We propose an uncalibrated photometric stereo method that works with general and unknown isotropic reflectances. Our method uses a pixel intensity profile, which is a sequence of radiance intensities recorded at a pixel under unknown varying directional illumination. We show that for general isotropic materials and uniformly distributed light directions, the geodesic distance between intensity profiles is linearly related to the angular difference of their corresponding surface normals, and that the intensity distribution of the intensity profile reveals reflectance properties. Based on these observations, we develop two methods for surface normal estimation; one for a general setting that uses only the recorded intensity profiles, the other for the case where a BRDF database is available while the exact BRDF of the target scene is still unknown. Quantitative and qualitative evaluations are conducted using both synthetic and real-world scenes, which show the state-of-the-art accuracy of smaller than 10 degree without using reference data and 5 degree with reference data for all 100 materials in MERL database.	[Lu, Feng; Sato, Yoichi] Univ Tokyo, Inst Ind Sci, Tokyo 1538505, Japan; [Matsushita, Yasuyuki] Microsoft Res Asia, Beijing 100080, Peoples R China; [Sato, Imari] Natl Inst Informat, Tokyo 1010003, Japan; [Okabe, Takahiro] Kyushu Inst Technol, Fukuoka 8208502, Japan	University of Tokyo; Microsoft; Microsoft Research Asia; Research Organization of Information & Systems (ROIS); National Institute of Informatics (NII) - Japan; Kyushu Institute of Technology	Lu, F (corresponding author), Univ Tokyo, Inst Ind Sci, Tokyo 1538505, Japan.	lufeng@iis.u-tokyo.ac.jp; yasumat@microsoft.com; imarik@nii.ac.jp; okabe@ai.kyutech.ac.jp; ysato@iis.u-tokyo.ac.jp		Matsushita, Yasuyui/0000-0002-1935-4752	Grants-in-Aid for Scientific Research [22135002] Funding Source: KAKEN	Grants-in-Aid for Scientific Research(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))		Alldrin N., 2008, IEEE C COMP VIS PATT, P1; Alldrin NG, 2007, IEEE I CONF COMP VIS, P417; [Anonymous], 2007, CVPR; Barsky S, 2003, IEEE T PATTERN ANAL, V25, P1239, DOI 10.1109/TPAMI.2003.1233898; Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7; Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611; Chandraker M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2505, DOI 10.1109/CVPR.2011.5995603; Chandraker MK, 2005, PROC CVPR IEEE, P788; Chung H., 2008, INT J PHOTOENERGY, V2008, P1; Drbohlav O, 2005, IEEE I CONF COMP VIS, P1850; Drbohlav O., 2002, P EUR C COMP VIS ECC, P644; Favaro P, 2012, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2012.6247754; Georghiades AS, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P816; Goldman DB, 2005, IEEE I CONF COMP VIS, P341; HAYAKAWA H, 1994, J OPT SOC AM A, V11, P3079, DOI 10.1364/JOSAA.11.003079; Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158; Higo T, 2010, PROC CVPR IEEE, P1157, DOI 10.1109/CVPR.2010.5540084; Holroyd M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409086; Ikehata S, 2012, PROC CVPR IEEE, P318, DOI 10.1109/CVPR.2012.6247691; Koppal S. J., 2006, PROC IEEE C COMPUT V, P1323; Kruskal JB, 1978, MULTIDIMENSIONAL SCA, V11; Lu F, 2013, PROC CVPR IEEE, P1490, DOI 10.1109/CVPR.2013.196; Matusik W., 2003, P ACM SIGGRAPH, P27; Miyazaki D, 2010, INT J COMPUT VISION, V86, P229, DOI 10.1007/s11263-009-0262-9; NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P418, DOI 10.1109/70.59367; Okabe T, 2009, IEEE I CONF COMP VIS, P1693, DOI 10.1109/ICCV.2009.5459381; Oxholm G, 2012, LECT NOTES COMPUT SC, V7572, P58, DOI 10.1007/978-3-642-33718-5_5; Papadhimitri T, 2013, PROC CVPR IEEE, P1474, DOI 10.1109/CVPR.2013.194; Ren P., 2011, P ACM SIGGRAPH; Sato I, 2007, IEEE I CONF COMP VIS, P1493; Shi BX, 2012, LECT NOTES COMPUT SC, V7574, P455, DOI 10.1007/978-3-642-33712-3_33; Shi BX, 2010, PROC CVPR IEEE, P1118, DOI 10.1109/CVPR.2010.5540091; Silver William M, 1980, THESIS MIT; Tan P, 2011, IEEE T PATTERN ANAL, V33, P2506, DOI 10.1109/TPAMI.2011.35; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Wu L, 2011, LECT NOTES COMPUT SC, V6494, P703, DOI 10.1007/978-3-642-19318-7_55; Wu TP, 2006, IEEE T PATTERN ANAL, V28, P1830, DOI 10.1109/TPAMI.2006.224; Wu Z, 2013, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2013.197; Yuille AL, 1999, INT J COMPUT VISION, V35, P203, DOI 10.1023/A:1008180726317; Zhou ZL, 2010, LECT NOTES COMPUT SC, V6312, P265, DOI 10.1007/978-3-642-15552-9_20	41	17	19	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2015	37	10					1999	2012		10.1109/TPAMI.2015.2389841	http://dx.doi.org/10.1109/TPAMI.2015.2389841			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CQ7VL	26353183				2022-12-18	WOS:000360813400005
J	Cohen, AR; Vitanyi, PMB				Cohen, Andrew R.; Vitanyi, Paul M. B.			Normalized Compression Distance of Multisets with Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Normalized compression distance; multisets or multiples; pattern recognition; data mining; similarity; classification; Kolmogorov complexity; retinal progenitor cells; synthetic data; organelle transport; handwritten character recognition	INFORMATION DISTANCE; TRANSPORT	Pairwise normalized compression distance (NCD) is a parameter-free, feature-free, alignment-free, similarity metric based on compression. We propose an NCD of multisets that is also metric. Previously, attempts to obtain such an NCD failed. For classification purposes it is superior to the pairwise NCD in accuracy and implementation complexity. We cover the entire trajectory from theoretical underpinning to feasible practice. It is applied to biological (stem cell, organelle transport) and OCR classification questions that were earlier treated with the pairwise NCD. With the new method we achieved significantly better results. The theoretic foundation is Kolmogorov complexity.	[Cohen, Andrew R.] Drexel Univ, Dept Elect & Comp Engn, Philadelphia, PA 19104 USA; [Vitanyi, Paul M. B.] Natl Res Ctr Math & Comp Sci, Amsterdam, Netherlands; [Vitanyi, Paul M. B.] Univ Amsterdam, NL-1098 XG Amsterdam, Netherlands	Drexel University; University of Amsterdam	Cohen, AR (corresponding author), Drexel Univ, Dept Elect & Comp Engn, 3120-40 Market St,Suite 313, Philadelphia, PA 19104 USA.	acohen@coe.drexel.edu; Paul.Vitanyi@cwi.nl	Vitanyi, Paul M.B./A-9037-2012	Vitanyi, Paul M.B./0000-0002-5712-7585; Cohen, Andrew/0000-0002-7707-5970	Drexel University; National Institute Of Neurological Disorders And Stroke [R01NS076709]; National Institute On Aging of the National Institutes of Health [R01AG041861]; Human Frontier Science Program grant [RGP0060/2012]; NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE [R01NS076709] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON AGING [R01AG041861] Funding Source: NIH RePORTER	Drexel University; National Institute Of Neurological Disorders And Stroke(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Neurological Disorders & Stroke (NINDS)); National Institute On Aging of the National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Aging (NIA)); Human Frontier Science Program grant(Human Frontier Science Program); NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Neurological Disorders & Stroke (NINDS)); NATIONAL INSTITUTE ON AGING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Aging (NIA))	Portions of this research were supported by Drexel University, by grant number R01NS076709 from the National Institute Of Neurological Disorders And Stroke, by the National Institute On Aging of the National Institutes of Health under award number R01AG041861, and by Human Frontier Science Program grant RGP0060/2012. The authors would like to thank Mark Winter and Steven Weber for their feedback on the approach and implementation. Thank you to Dan Ciresan for providing results and timing information on his convolutional neural network algorithms. Andrew R. Cohen is the corresponding author.	Ane C, 2005, SYST BIOL, V54, P146, DOI 10.1080/10635150590905984; Bennett CH, 1998, IEEE T INFORM THEORY, V44, P1407, DOI 10.1109/18.681318; Cayouette M, 2003, NEURON, V40, P897, DOI 10.1016/S0896-6273(03)00756-6; Cilibrasi R, 2005, IEEE T INFORM THEORY, V51, P1523, DOI 10.1109/TIT.2005.844059; Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110; Cohen AR, 2010, NAT METHODS, V7, P213, DOI [10.1038/nmeth.1424, 10.1038/NMETH.1424]; Cohen AR, 2009, IEEE T PATTERN ANAL, V31, P1386, DOI 10.1109/TPAMI.2008.162; Gacs P., 1974, SOV MATH DOKL, V15, P1477; Gauthier LR, 2004, CELL, V118, P127, DOI 10.1016/j.cell.2004.06.018; Guo YQ, 2007, BIOSTATISTICS, V8, P86, DOI 10.1093/biostatistics/kxj035; Kamvar S. D., 2003, P 18 INT JOINT C ART, P561; Keogh E., 2004, P 10 ACM SIGKDD INT, P206, DOI [DOI 10.1145/1014052.1014077, 10.1145/1014052.1014077]; Kirk SR, 2004, J SYST SOFTWARE, V72, P179, DOI 10.1016/S0164-1212(03)00217-6; Kocsor A, 2006, BIOINFORMATICS, V22, P407, DOI 10.1093/bioinformatics/bti806; Kolmogorov A. N., 1968, International Journal of Computer Mathematics, V2, P157, DOI 10.1080/00207166808803030; Kraft L. G., THESIS MIT CAMBRIDGE; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Levin L. A., 1974, Problems of Information Transmission, V10, P206; Li M, 2004, IEEE T INFORM THEORY, V50, P3250, DOI 10.1109/TIT.2004.838101; Li M, 2008, INTRO KOLMOGOROV COM; Li M, 2011, LECT NOTES ARTIF INT, V6926, P18, DOI 10.1007/978-3-642-24477-3_3; Long C, 2008, P 17 ACM C INF KNOWL, P1213, DOI [10.1145/1458082.1458242, DOI 10.1145/1458082.1458242]; MCMILLAN B, 1956, IRE T INFORM THEOR, V2, P115, DOI 10.1109/TIT.1956.1056818; Muchnik AA, 2002, THEOR COMPUT SCI, V271, P97, DOI 10.1016/S0304-3975(01)00033-0; Nykter M, 2008, P NATL ACAD SCI USA, V105, P1897, DOI 10.1073/pnas.0711525105; Nykter M, 2008, PHYS REV LETT, V100, DOI 10.1103/PhysRevLett.100.058702; Vitanyi PMB, 2011, IEEE T INFORM THEORY, V57, P2451, DOI 10.1109/TIT.2011.2110130; Winter M, 2011, NAT PROTOC, V6, P1942, DOI 10.1038/nprot.2011.422; Winter Mark R., 2012, International Journal of Computational Biology and Drug Design, V5, P35, DOI 10.1504/IJCBDD.2012.045950; Witten I.H., 2005, P DATA MINING LAS VE, P4; Wong W., 2008, HDB RES TEXT WEB MIN, P141; Zhang X, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P874; Zvonkin A.K., 1970, RUSSIAN MATH SURVEYS, V25, P83, DOI [10.1070/RM1970v025n06ABEH001269, 10.1070/ rm1970v025n06abeh001269, DOI 10.1070/RM1970V025N06ABEH001269]	33	17	17	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2015	37	8					1602	1614		10.1109/TPAMI.2014.2375175	http://dx.doi.org/10.1109/TPAMI.2014.2375175			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CM3ON	26352998	Green Submitted, Green Accepted			2022-12-18	WOS:000357591900006
J	Zhu, YY; Nayak, NM; Roy-Chowdhury, AK				Zhu, Yingying; Nayak, Nandita M.; Roy-Chowdhury, Amit K.			Context-Aware Activity Modeling Using Hierarchical Conditional Random Fields	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Activity localization and recognition; context-aware activity recognition model; hierarchical conditional random field	RECOGNITION	In this paper, rather than modeling activities in videos individually, we jointly model and recognize related activities in a scene using both motion and context features. This is motivated from the observations that activities related in space and time rarely occur independently and can serve as the context for each other. We propose a two-layer conditional random field model, that represents the action segments and activities in a hierarchical manner. The model allows the integration of both motion and various context features at different levels and automatically learns the statistics that capture the patterns of the features. With weakly labeled training data, the learning problem is formulated as a max-margin problem and is solved by an iterative algorithm. Rather than generating activity labels for individual activities, our model simultaneously predicts an optimum structural label for the related activities in the scene. We show promising results on the UCLA Office Dataset and VIRAT Ground Dataset that demonstrate the benefit of hierarchical modeling of related activities using both motion and context features.	[Zhu, Yingying; Roy-Chowdhury, Amit K.] Univ Calif Riverside, Dept Elect & Comp Engn, Riverside, CA 92521 USA; [Nayak, Nandita M.] Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA	University of California System; University of California Riverside; University of California System; University of California Riverside	Zhu, YY (corresponding author), Univ Calif Riverside, Dept Elect & Comp Engn, Riverside, CA 92521 USA.	yzhu010@ucr.edu; nandita.nayak@email.ucr.edu; amitrc@ee.ucr.edu			ONR [N00014-12-1-1026]; NSF [IIS-1316934]	ONR(Office of Naval Research); NSF(National Science Foundation (NSF))	This work was partially supported under ONR grant N00014-12-1-1026 and NSF grant IIS-1316934.	Amer MR, 2012, LECT NOTES COMPUT SC, V7575, P187, DOI 10.1007/978-3-642-33765-9_14; Amer MR, 2012, PROC CVPR IEEE, P1314, DOI 10.1109/CVPR.2012.6247816; Brendel W, 2011, IEEE I CONF COMP VIS, P778, DOI 10.1109/ICCV.2011.6126316; Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821; Choi W, 2012, LECT NOTES COMPUT SC, V7575, P215, DOI 10.1007/978-3-642-33765-9_16; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Desai C, 2011, INT J COMPUT VISION, V95, P1, DOI 10.1007/s11263-011-0439-x; Gaur U, 2011, IEEE I CONF COMP VIS, P2595, DOI 10.1109/ICCV.2011.6126548; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Gupta A, 2009, PROC CVPR IEEE, P2012, DOI 10.1109/CVPRW.2009.5206492; Han D, 2009, IEEE I CONF COMP VIS, P1933, DOI 10.1109/ICCV.2009.5459427; Jiang Y G, 2007, P 6 ACM INT C IM VID, P494, DOI DOI 10.1145/1282280.1282352; Khamis S, 2012, LECT NOTES COMPUT SC, V7572, P116, DOI 10.1007/978-3-642-33718-5_9; Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0; Komodakis N, 2011, IEEE I CONF COMP VIS, P73, DOI 10.1109/ICCV.2011.6126227; Ladicky L, 2010, LECT NOTES COMPUT SC, V6314, P424, DOI 10.1007/978-3-642-15561-1_31; Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248; Lan T., 2010, ADV NEURAL INFORM PR; Lan T, 2012, IEEE T PATTERN ANAL, V34, P1549, DOI 10.1109/TPAMI.2011.228; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Marszaek M., 2009, CVPR, P2929, DOI DOI 10.1109/CVPR.2009.5206557; Minh Hoai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3265, DOI 10.1109/CVPR.2011.5995470; Morariu Vlad I, 2011, P CVPR, P3289; Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1; Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29; Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009; Ryoo M.S., 2010, ICPR; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Si ZZ, 2011, IEEE I CONF COMP VIS, P41, DOI 10.1109/ICCV.2011.6126223; Song B, 2010, LECT NOTES COMPUT SC, V6311, P605, DOI 10.1007/978-3-642-15549-9_44; Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721; Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808; Taskar B., 2004, P ICML, DOI [10.1145/1015330.1015444, DOI 10.1145/1015330.1015444]; Teo CH, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P727; Teo CH, 2010, J MACH LEARN RES, V11, P311; Wang J, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995493; Wongun Choi, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3273, DOI 10.1109/CVPR.2011.5995707; YAO BP, 2010, PROC CVPR IEEE, P17, DOI DOI 10.1109/CVPR.2010.5540235; Yu C.-N. J., 2009, P 26 ANN INT C MACHI, P1169, DOI [10.1145/1553374.1553523, DOI 10.1145/1553374.1553523]; Yuille AL, 2003, NEURAL COMPUT, V15, P915, DOI 10.1162/08997660360581958; Zhu Y, 2013, COMPUT VIS IMAGE UND, V117, P1313, DOI 10.1016/j.cviu.2012.08.009; Zhu YY, 2013, IEEE J-STSP, V7, P91, DOI 10.1109/JSTSP.2012.2234722; ZHU YY, 2013, PROC CVPR IEEE, P2491; Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992	45	17	18	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2015	37	7					1360	1372		10.1109/TPAMI.2014.2369044	http://dx.doi.org/10.1109/TPAMI.2014.2369044			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CK0YG	26352445				2022-12-18	WOS:000355931100005
J	Kushnir, M; Shimshoni, I				Kushnir, Maria; Shimshoni, Ilan			Epipolar Geometry Estimation for Urban Scenes with Repetitive Structures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Fundamental matrix; repeated structures; SIFT	MODEL; FRAMEWORK; CONSENSUS; SETS	Algorithms for the estimation of epipolar geometry from a pair of images have been very successful in dealing with challenging wide baseline images. In this paper the problem of scenes with repeated structures is addressed, dealing with the common case where the overlap between the images consists mainly of facades of a building. These facades may contain many repeated structures that can not be matched locally, causing state-of-the-art algorithms to fail. Assuming that the repeated structures lie on a planar surface in an ordered fashion the goal is to match them. Our algorithm first rectifies the images such that the facade is fronto-parallel. It then clusters similar features in each of the two images and matches the clusters. From them a set of hypothesized homographies of the facade is generated, using local groups of features. For each homography the epipole is recovered, yielding a fundamental matrix. For the best solution, it then decides whether the fundamental matrix has been recovered reliably and, if not, returns only the homography. The algorithm has been tested on a large number of challenging image pairs of buildings from the benchmark ZuBuD database, outperforming several state-of-the-art algorithms.	[Kushnir, Maria; Shimshoni, Ilan] Univ Haifa, Dept Informat Syst, IL-31905 Haifa, Israel	University of Haifa	Kushnir, M (corresponding author), Univ Haifa, Dept Informat Syst, IL-31905 Haifa, Israel.	mkushn01@campus.haifa.ac.il; ishimshoni@mis.haifa.ac.il		Shimshoni, Ilan/0000-0002-5276-0242	VULCAN Consortium of The Israeli Ministry of Industry and Commerce	VULCAN Consortium of The Israeli Ministry of Industry and Commerce	This work was supported by the VULCAN Consortium of The Israeli Ministry of Industry and Commerce. The authors would like to thank the two anonymous reviewers whose comments and suggestions helped improve and clarify this manuscript.	Baatz G, 2010, LECT NOTES COMPUT SC, V6316, P266, DOI 10.1007/978-3-642-15567-3_20; Bansal M, 2012, LECT NOTES COMPUT SC, V7583, P175, DOI 10.1007/978-3-642-33863-2_18; Brahmachari AS, 2009, IEEE I CONF COMP VIS, P1685, DOI 10.1109/ICCV.2009.5459379; Chang W.-C., 2008, 3D MODEL MATCHING VI, P1, DOI DOI 10.1109/CVPR.2008.4587501; Chum O, 2005, PROC CVPR IEEE, P772; Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221; Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236; Chum O., 2004, P ACCV, V2, P812; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Frahm J.-M., 2006, P COMP VIS PATT REC, V1, P453, DOI DOI 10.1109/CVPR.2006.235; Goshen L, 2008, IEEE T PATTERN ANAL, V30, P1230, DOI 10.1109/TPAMI.2007.70768; Hartley R., 2004, ROBOTICA; Hays J, 2006, LECT NOTES COMPUT SC, V3952, P522; Jiang NJ, 2011, IEEE I CONF COMP VIS, P535, DOI 10.1109/ICCV.2011.6126285; Le Brese C, 2010, IEEE IMAGE PROC, P2949, DOI 10.1109/ICIP.2010.5653485; Lee JA, 2009, IEEE I CONF COMP VIS, P1258, DOI 10.1109/ICCV.2009.5459324; Liu YX, 2004, IEEE T PATTERN ANAL, V26, P354, DOI 10.1109/TPAMI.2004.1262332; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730; Noury N, 2010, LECT NOTES COMPUT SC, V6453, P231; Rabin J., 2010, P 3 INT S 3D DAT PRO; Raguram R, 2013, IEEE T PATTERN ANAL, V35, P2022, DOI 10.1109/TPAMI.2012.257; Roberts R., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3137, DOI 10.1109/CVPR.2011.5995549; Robertson D., 2004, P 15 BRIT MACH VIS C, P819; Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414; Schindler G, 2008, PROC CVPR IEEE, P77; Serradell E, 2010, LECT NOTES COMPUT SC, V6313, P58; Shao H., 2003, 260 CVL ETH ZUR; Sur F., 2011, RR7693 INRIA; Tordoff B, 2002, LECT NOTES COMPUT SC, V2350, P82; Torii A, 2013, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2013.119; Tylecek R, 2013, LECT NOTES COMPUT SC, V8142, P364, DOI 10.1007/978-3-642-40602-7_39; VEDALDI A, 2008, P 18 ACM INT C MULT, P1469; Wan GW, 2012, GRAPH MODELS, V74, P14, DOI 10.1016/j.gmod.2011.11.001; Wenzel S., 2008, Pattern Recognition and Image Analysis, V18, P406, DOI 10.1134/S1054661808030073; Wu CC, 2010, LECT NOTES COMPUT SC, V6312, P142; Zhang W, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P854	37	17	23	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2014	36	12					2381	2395		10.1109/TPAMI.2014.2339862	http://dx.doi.org/10.1109/TPAMI.2014.2339862			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AT5MW	26353146				2022-12-18	WOS:000344988000005
J	Platanios, EA; Chatzis, SP				Platanios, Emmanouil A.; Chatzis, Sotirios P.			Gaussian Process-Mixture Conditional Heteroscedasticity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gaussian process; Pitman-Yor process; mixture model; conditional heteroscedasticity; copula; volatility modeling	MULTIVARIATE; DISTRIBUTIONS; INFERENCE; MODELS	Generalized autoregressive conditional heteroscedasticity (GARCH) models have long been considered as one of the most successful families of approaches for volatility modeling in financial return series. In this paper, we propose an alternative approach based on methodologies widely used in the field of statistical machine learning. Specifically, we propose a novel nonparametric Bayesian mixture of Gaussian process regression models, each component of which models the noise variance process that contaminates the observed data as a separate latent Gaussian process driven by the observed data. This way, we essentially obtain a Gaussian process-mixture conditional heteroscedasticity (GPMCH) model for volatility modeling in financial return series. We impose a nonparametric prior with power-law nature over the distribution of the model mixture components, namely the Pitman-Yor process prior, to allow for better capturing modeled data distributions with heavy tails and skewness. Finally, we provide a copula-based approach for obtaining a predictive posterior for the covariances over the asset returns modeled by means of a postulated GPMCH model. We evaluate the efficacy of our approach in a number of benchmark scenarios, and compare its performance to state-of-the-art methodologies.	[Platanios, Emmanouil A.] Carnegie Mellon Univ, Dept Machine Learning, Pittsburgh, PA 15213 USA; [Chatzis, Sotirios P.] Cyprus Univ Technol, Dept Elect Engn Comp Engn & & Informat, CY-3036 Limassol, Cyprus	Carnegie Mellon University; Cyprus University of Technology	Platanios, EA (corresponding author), Carnegie Mellon Univ, Dept Machine Learning, Pittsburgh, PA 15213 USA.	e.a.platanios@gmail.com; soteri0s@me.com	Chatzis, Sotirios/H-1975-2014	Chatzis, Sotirios/0000-0002-4956-4013				Abegaz F, 2008, J STAT PLAN INFER, V138, P1131, DOI 10.1016/j.jspi.2007.04.028; Alexander C, 2006, J APPL ECONOMET, V21, P307, DOI 10.1002/jae.849; Alvarez M., 2008, NIPS, P57; Bauwens L, 2007, COMPUT STAT DATA AN, V51, P3551, DOI 10.1016/j.csda.2006.10.012; BLACKWELL D, 1973, ANN STAT, V1, P353, DOI 10.1214/aos/1176342372; Blei DM, 2006, BAYESIAN ANAL, V1, P121, DOI 10.1214/06-BA104; BLOCK HW, 1988, ANN PROBAB, V16, P1803, DOI 10.1214/aop/1176991598; Bo LF, 2010, INT J COMPUT VISION, V87, P28, DOI 10.1007/s11263-008-0204-y; BOLLERSLEV T, 1986, J ECONOMETRICS, V31, P307, DOI 10.1016/0304-4076(86)90063-1; Bonilla EV., 2008, ADV NEURAL INF PROCE, V20, P153, DOI DOI 10.5555/2981562.2981582; Boyle P., 2005, ADV NEURAL INFORM PR, P217; Brooks C, 2001, INT J FORECASTING, V17, P45, DOI 10.1016/S0169-2070(00)00070-4; Brownlees C. T., 2009, PRACTICAL GUIDE VOLA; Chandler D., 1987, INTRO MODERN STAT ME; Chatzis SP, 2008, IEEE T SIGNAL PROCES, V56, P949, DOI 10.1109/TSP.2007.907912; Chollete L, 2009, J FINANC ECONOMET, V7, P437, DOI 10.1093/jjfinec/nbp014; Cuadras CM, 2002, J STAT PLAN INFER, V103, P137, DOI 10.1016/S0378-3758(01)00216-6; Engle R, 2002, J BUS ECON STAT, V20, P339, DOI 10.1198/073500102288618487; ENGLE RF, 1995, ECONOMET THEOR, V11, P122, DOI 10.1017/S0266466600009063; ENGLE RF, 1982, ECONOMETRICA, V50, P987, DOI 10.2307/1912773; Fan WT, 2012, IEEE T NEUR NET LEAR, V23, P762, DOI 10.1109/TNNLS.2012.2190298; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; Girolami M, 2011, J R STAT SOC B, V73, P123, DOI 10.1111/j.1467-9868.2010.00765.x; Gu DB, 2012, IEEE T NEUR NET LEAR, V23, P1279, DOI 10.1109/TNNLS.2012.2200694; Haas M., 2004, J FINANC ECONOMET, V2, P211, DOI [10.1093/jjfinec/nbh009, DOI 10.1093/JJFINEC/NBH009]; Haas M, 2009, COMPUT STAT DATA AN, V53, P2129, DOI 10.1016/j.csda.2007.12.018; Hansen PR, 2005, J APPL ECONOM, V20, P873, DOI 10.1002/jae.800; Hoeffding W., 1940, SCHRIFTEN MATH INSTI, V5, P179; Joe H, 2005, J MULTIVARIATE ANAL, V94, P401, DOI 10.1016/j.jmva.2004.06.003; Joe H., 1997, MULTIVARIATE MODELS; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Kersting K., 2007, P 24 INT C MACH LEAR, P393, DOI DOI 10.1145/1273496.1273546; Lazaro-Gredilla M., 2011, P INT C MACH LEARN M, P841; Lei Xu, 1995, Advances in Neural Information Processing Systems 7, P633; LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116; McCullough B.D., 1998, J ECON SOC MEAS, V25, P59; Meeds E., 2006, ADV NEURAL INFORM PR, V18, P883; Muller P, 2004, STAT SCI, V19, P95, DOI 10.1214/088342304000000017; Neal RM, 2000, J COMPUT GRAPH STAT, V9, P249, DOI 10.2307/1390653; Nelsen RB., 2006, INTRO COPULAS, V2nd; Penalver A, 2012, IEEE T NEUR NET LEAR, V23, P534, DOI 10.1109/TNNLS.2011.2177670; Pitman J, 1997, ANN PROBAB, V25, P855; Qi YT, 2007, IEEE T SIGNAL PROCES, V55, P5209, DOI 10.1109/TSP.2007.898782; Rasmussen CE, 2002, ADV NEUR IN, V14, P881; Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899; SETHURAMAN J, 1994, STAT SINICA, V4, P639; Sklar A., 1959, PUBLICATIONS I STAT, V8, P229, DOI DOI 10.1007/BF01544178; Teh YW, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P985; Walker SG, 1999, J R STAT SOC B, V61, P485, DOI 10.1111/1467-9868.00190; Wilson AG., 2010, ADV NEURAL INFORM PR, P2460; Yu K., 2005, P 22 INT C MACH LEAR, P1012, DOI DOI 10.1145/1102351.1102479	51	17	18	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2014	36	5					888	900		10.1109/TPAMI.2013.183	http://dx.doi.org/10.1109/TPAMI.2013.183			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AH3VN	26353224				2022-12-18	WOS:000336054200005
J	Wang, G; Forsyth, D; Hoiem, D				Wang, Gang; Forsyth, David; Hoiem, Derek			Improved Object Categorization and Detection Using Comparative Object Similarity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Comparative object similarity; object categorization; object detection; kernel machines; SVM; deformable part model; PASCAL VOC; sharing	CLASSIFICATION; FEATURES	Due to the intrinsic long-tailed distribution of objects in the real world, we are unlikely to be able to train an object recognizer/detector with many visual examples for each category. We have to share visual knowledge between object categories to enable learning with few or no training examples. In this paper, we show that local object similarity information-statements that pairs of categories are similar or dissimilar-is a very useful cue to tie different categories to each other for effective knowledge transfer. The key insight: Given a set of object categories which are similar and a set of categories which are dissimilar, a good object model should respond more strongly to examples from similar categories than to examples from dissimilar categories. To exploit this category-dependent similarity regularization, we develop a regularized kernel machine algorithm to train kernel classifiers for categories with few or no training examples. We also adapt the state-of-the-art object detector [10] to encode object similarity constraints. Our experiments on hundreds of categories from the Labelme dataset show that our regularized kernel classifiers can make significant improvement on object categorization. We also evaluate the improved object detector on the PASCAL VOC 2007 benchmark dataset.	[Wang, Gang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639807, Singapore; [Wang, Gang] Adv Digital Sci Ctr, Singapore 639807, Singapore; [Forsyth, David; Hoiem, Derek] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; University of Illinois System; University of Illinois Urbana-Champaign	Wang, G (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, 37G Nanyang Ave 04-13, Singapore 639807, Singapore.	wanggang@ntu.edu.sg; daf@illinois.edu	Wang, Gang/B-7027-2013					[Anonymous], 2007, PASCAL VISUAL OBJECT; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Bart E, 2008, P IEEE C COMP VIS PA; Bart E, 2005, P IEEE C COMP VIS PA; Breiman L, 1998, ANN STAT, V26, P801; Dalai N, 2005, P IEEE C COMP VIS PA, V1; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J., 2009, 2009 IEEE C COMP VIS, P248, DOI [DOI 10.1109/CVPR.2009.5206848, 10.1109/CVPR.2009.5206848]; Farhadi A., 2009, P IEEE C COMP VIS PA; Fergus R, 2009, P NEUR INF PROC SYST; Frome A., 2007, P IEEE INT C COMP VI; Herbrich R, 2002, P ACM C KNOWL DISC D; Hullermeier E, 2008, ARTIF INTELL, V172, P1897, DOI 10.1016/j.artint.2008.08.002; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; Joachims T., 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]; Jun Xu, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P391; Kivinen J, 2004, IEEE T SIGNAL PROCES, V52, P2165, DOI 10.1109/TSP.2004.830991; Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48; Lampert C. H., 2009, P IEEE C COMP VIS PA; Langford J, 2009, J MACH LEARN RES, V10, P777; Lazebnik S., 2006, P IEEE C COMP VIS PA; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Liu T-Y., 2009, FOUND TRENDS INF RET, V3, P225, DOI DOI 10.1561/1500000016; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Miller EG, 2000, PROC CVPR IEEE, P464, DOI 10.1109/CVPR.2000.855856; Opelt A., 2006, P IEEE C COMP VIS PA, P3; Palatucci M., 2009, P NEUR INF PROC SYST; Papadimitriou C.H., 1998, COMBINATORIAL OPTIMI, VUnabridged edition; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Salakhutdinov R, 2011, P NEUR INF PROC SYST; SALAKHUTDINOV R., 2011, P IEEE C COMP VIS PA; SHALEV- SHWARTZ S., 2007, P 24 INT C MACH LEAR, P807, DOI [DOI 10.1145/1273496.1273598, 10.1145/1273496.1273598]; Sivic J., 2008, P IEEE C COMP VIS PA; Torralba A., 2004, P IEEE C COMP VIS PA; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/h0026750; VIOLA P, 2001, P IEEE C COMP VIS PA, V1; Wang G., 2009, P IEEE INT C COMP VI; WANG G., 2009, P IEEE C COMP VIS PA; Wang G., 2010, P IEEE C COMP VIS PA; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Xing E. P., 2003, ADV NEURAL INF PROCE, P521; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4	43	17	17	2	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2013	35	10					2442	2453		10.1109/TPAMI.2013.58	http://dx.doi.org/10.1109/TPAMI.2013.58			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	201XB	23969388				2022-12-18	WOS:000323175200010
J	Chen, B; Lam, W; Tsang, IW; Wong, TL				Chen, Bo; Lam, Wai; Tsang, Ivor W.; Wong, Tak-Lam			Discovering Low-Rank Shared Concept Space for Adapting Text Mining Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Domain adaptation; low-rank concept extraction; text mining		We propose a framework for adapting text mining models that discovers low-rank shared concept space. Our major characteristic of this concept space is that it explicitly minimizes the distribution gap between the source domain with sufficient labeled data and the target domain with only unlabeled data, while at the same time it minimizes the empirical loss on the labeled data in the source domain. Our method is capable of conducting the domain adaptation task both in the original feature space as well as in the transformed Reproducing Kernel Hilbert Space (RKHS) using kernel tricks. Theoretical analysis guarantees that the error of our adaptation model can be bounded with respect to the embedded distribution gap and the empirical loss in the source domain. We have conducted extensive experiments on two common text mining problems, namely, document classification and information extraction, to demonstrate the efficacy of our proposed framework.	[Chen, Bo; Lam, Wai] Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China; [Tsang, Ivor W.] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore; [Wong, Tak-Lam] Hong Kong Inst Educ, Dept Math & Informat Technol, Tai Po, Hong Kong, Peoples R China	Chinese University of Hong Kong; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Education University of Hong Kong (EdUHK)	Chen, B (corresponding author), Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China.	bchen@se.cuhk.edu.hk; wlam@se.cuhk.edu.hk; IvorTsang@ntu.edu.sg; tlwong@ied.edu.hk	Lam, Wai/GNW-3026-2022; Tsang, Ivor/E-8653-2011	Tsang, Ivor/0000-0003-2211-8176; Tsang, Ivor/0000-0001-8095-4637	Research Grant Council of the Hong Kong Special Administrative Region, China [CUHK413510]; Direct Grant of the Faculty of Engineering, CUHK [2050476, 2050522]	Research Grant Council of the Hong Kong Special Administrative Region, China(Hong Kong Research Grants Council); Direct Grant of the Faculty of Engineering, CUHK	The work described in this paper is substantially supported by grants from the Research Grant Council of the Hong Kong Special Administrative Region, China (Project Code: CUHK413510), and the Direct Grant of the Faculty of Engineering, CUHK (Project Codes: 2050476 and 2050522). This work is also affiliated with the CUHK MoE-Microsoft Key Laboratory of Human-centric Computing and Interface Technologies. The authors thank Bing Xu for his coding effort.	Ando RK, 2005, J MACH LEARN RES, V6, P1817; [Anonymous], 2008, P 14 ACM SIGKDD INT, DOI DOI 10.1145/1401890.1401951; [Anonymous], 2009, PROC AUAI 2009; Arnold A., 2007, PROC 7 IEEE INT C DA, P77, DOI DOI 10.1109/ICDMW.2007.109; Ben-David S., 2007, ADV NEURAL INFORM PR, V19, P137; Bickel S., 2008, ADV NEURAL INFORM PR, P145; Bickel S, 2009, J MACH LEARN RES, V10, P2137; Blitzer J., 2007, 45 ANN M ASS COMP LI; Blitzer J., 2006, P 2006 C EMP METH NA, P120, DOI DOI 10.3115/1610075.1610094; BLITZER J, 2007, ADV NEURAL INFORM PR, V20; Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242; Chen B, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P179; Dai WY, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P210; Dai Wenyuan, 2007, AAAI, P540; Daume H, 2007, P 45 ANN M ASS COMP, V45, P256; Demsar J, 2006, J MACH LEARN RES, V7, P1; Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109; Fan W, 2005, Fifth IEEE International Conference on Data Mining, Proceedings, P605; Finkel Jenny Rose, 2009, P HUM LANG TECHN 200, P602, DOI DOI 10.3115/1620754.1620842; Gretton A, 2009, NEURAL INF PROCESS S, P131; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Ji S., 2008, P 14 ACM SIGKDD INT, P381, DOI [DOI 10.1145/1401890.1401939, 10.1145/1401890.1401939]; Jiang Jing, 2007, P 16 ACM C INF KNOWL, P401; Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200; Joachims T., 2002, LEARNING CLASSIFY TE; Pan S.J., 2008, AAAI; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Raina R, 2007, 24 ANN INT C MACH LE, V227, P759, DOI [10.1145/1273496.1273592, DOI 10.1145/1273496.1273592]; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Smola, 2007, ADV NEURAL INFORM PR, P513, DOI DOI 10.5555/2188385.2188410; Sugiyama M., 2007, ADV NEURAL INFORM PR, P1337; Sugiyama Masashi, 2008, ADV NEURAL INFORM PR, V20; Weinberger K., 2009, ANN INT C MACH LEARN, P1113, DOI DOI 10.1145/1553374.1553516; Wong TL, 2010, IEEE T KNOWL DATA EN, V22, P523, DOI 10.1109/TKDE.2009.111; Xue G.-R., 2008, P 31 ANN INT ACM SIG, P627, DOI DOI 10.1145/1390334.1390441; Xue Y, 2007, J MACH LEARN RES, V8, P35; Yang J., 2007, P 15 ACM INT C MULT; Yu K., 2005, P 22 INT C MACH LEAR, P1012, DOI DOI 10.1145/1102351.1102479; Zadrozny B., 2004, P 21 INT C MACH LEAR, DOI 10.1145/1015330.1015425; Zhai, 2007, ANN M ASS COMP LING, P264, DOI [DOI 10.1145/1273496.1273558, DOI 10.1039/B610011B]; Zhang T., 2004, P 21 INT C MACH LEAR; Zhong EH, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1027	43	17	17	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2013	35	6					1284	1297		10.1109/TPAMI.2012.243	http://dx.doi.org/10.1109/TPAMI.2012.243			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	129QV	23599048				2022-12-18	WOS:000317857900002
J	Ablavsky, V; Sclaroff, S				Ablavsky, Vitaly; Sclaroff, Stan			Layered Graphical Models for Tracking Partially Occluded Objects	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; image representation; tracking; graphical models	PEOPLE; OCCLUSION; ONLINE; VIDEO	We propose a representation for scenes containing relocatable objects that can cause partial occlusions of people in a camera's field of view. In many practical applications, relocatable objects tend to appear often; therefore, models for them can be learned offline and stored in a database. We formulate an occluder-centric representation, called a graphical model layer, where a person's motion in the ground plane is defined as a first-order Markov process on activity zones, while image evidence is aggregated in 2D observation regions that are depth-ordered with respect to the occlusion mask of the relocatable object. We represent real-world scenes as a composition of depth-ordered, interacting graphical model layers, and account for image evidence in a way that handles mutual overlap of the observation regions and their occlusions by the relocatable objects. These layers interact: Proximate ground-plane zones of different model instances are linked to allow a person to move between the layers, and image evidence is shared between the observation regions of these models. We demonstrate our formulation in tracking pedestrians in the vicinity of parked vehicles. Our results compare favorably with a sprite-learning algorithm, with a pedestrian tracker based on deformable contours, and with pedestrian detectors.	[Ablavsky, Vitaly; Sclaroff, Stan] Boston Univ, Dept Comp Sci, Boston, MA 02215 USA	Boston University	Ablavsky, V (corresponding author), Boston Univ, Dept Comp Sci, 111 Cummington St, Boston, MA 02215 USA.	ablavsky@cs.bu.edu; sclaroff@cs.bu.edu		Ablavsky, Vitaly/0000-0003-2703-7666	US National Science Foundation [IIS-0713168, IIS-0910908, IIS-0855065]	US National Science Foundation(National Science Foundation (NSF))	This paper reports work that was supported in part by the US National Science Foundation under grants IIS-0713168, IIS-0910908, and IIS-0855065.	ABLAVSKY V, 2008, P IEEE INT C COMP VI; ANDRILUKA M, 2008, P IEEE INT C COMP VI; Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754; ATEV S, 2008, P IEEE INT C ROB AUT; BIRCHFIELD ST, 2009, KLT IMPLEMENTATION K; Bradski G., 2008, LEARNING OPENCV COMP; COMANICIU D, 2000, P IEEE INT C COMP VI; Dahlkamp H, 2007, INT J COMPUT VISION, V73, P139, DOI 10.1007/s11263-006-9786-4; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Duda R.O., 2001, PATTERN CLASSIFICATI; ELGAMMAL AM, 2001, P 8 IEEE INT C COMP; Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174; GE W, 2009, P IEEE INT C COMP VI; Greenhill D, 2008, IMAGE VISION COMPUT, V26, P430, DOI 10.1016/j.imavis.2006.12.007; GUTCHESS D, 2007, P SPIE C TRACK POINT; Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683; HOIEM D, 2007, P 11 IEEE INT C COMP; Irani M, 1998, IEEE T PATTERN ANAL, V20, P577, DOI 10.1109/34.683770; Isard M., 2001, P 8 IEEE INT C COMP; JEPSON AD, 2002, P EUR C COMP VIS; JOJIC N, 2001, P IEEE INT C COMP VI; KANG J, 2003, P IEEE INT C COMP VI; Khan SM, 2009, IEEE T PATTERN ANAL, V31, P505, DOI 10.1109/TPAMI.2008.102; Khan SM, 2006, LECT NOTES COMPUT SC, V3954, P133; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; Kumar MP, 2008, INT J COMPUT VISION, V76, P301, DOI 10.1007/s11263-007-0064-x; Leibe B, 2008, IEEE T PATTERN ANAL, V30, P1683, DOI 10.1109/TPAMI.2008.170; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Leotta MJ, 2009, PROC CVPR IEEE, P1311, DOI 10.1109/CVPRW.2009.5206738; LEYKIN A, 2006, P IEEE INT C COMP VI; Li Y, 2009, IEEE INTERNATIONAL CONFERENCE ON MICROWAVES, COMMUNICATIONS, ANTENNAS AND ELECTRONICS SYSTEMS (COMCAS 2009); Lv FJ, 2006, IEEE T PATTERN ANAL, V28, P1513, DOI 10.1109/TPAMI.2006.178; Ma  X., 2005, P 10 IEEE INT C COMP; Mittal A, 2003, INT J COMPUT VISION, V51, P189, DOI 10.1023/A:1021849801764; NEVATIA R., 2007, P IEEE INT C COMP VI; Ottlik A, 2008, INT J COMPUT VISION, V80, P211, DOI 10.1007/s11263-007-0112-6; Pece AEC, 2006, IMAGE VISION COMPUT, V24, P301, DOI 10.1016/j.imavis.2005.07.024; POLLARD T, 2007, IEEE INT C COMP VIS; PORIKLI F, 2006, P IEEE INT C COMP VI; Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458; RENNO J, 2002, P BRIT MACH VIS C; RYOO MS, 2008, P IEEE INT C COMP VI; SEITZ SM, 1997, P IEEE INT C COMP VI; Senior A, 2006, IMAGE VISION COMPUT, V24, P1233, DOI 10.1016/j.imavis.2005.06.007; SIEBEL N, 2001, P 2 IEEE INT WORKSH; SIGAL L, 2008, THESIS BROWN U; SIGAL L, 2006, P IEEE INT C COMP VI; SMITH K, 2005, P IEEE CS C COMP VIS; Smith K, 2008, IEEE T PATTERN ANAL, V30, P1212, DOI 10.1109/TPAMI.2007.70773; TAKALA V, 2007, P IEEE INT C COMP VI; Tao H, 2002, IEEE T PATTERN ANAL, V24, P75, DOI 10.1109/34.982885; TITSIAS M, 2005, THESIS U EDINBURGH; *U READ, 2001, PERF EV TRACK SURV P; Vacchetti L, 2004, IEEE T PATTERN ANAL, V26, P1385, DOI 10.1109/TPAMI.2004.92; VEDULA S, 1998, P 4 INT C VIRT SYST; VENKATARAMAN V, 2008, P IEEE INT C COMP VI; VEZZANI R, 2008, P BRIT MACH VIS C WO; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; WHITE B, 2007, P IEEE INT C MULT EX; Winn J., 2006, CVPR; Wu B, 2009, INT J COMPUT VISION, V82, P185, DOI 10.1007/s11263-008-0194-9; XING J, 2009, P IEEE INT C COMP VI; XU M, 2002, P BRIT MACH VIS C; YIN Z, 2007, P IEEE INT C COMP VI; YU T, 2008, P IEEE INT C COMP VI; ZHOU Y, 2003, P 3 IEEE INT C COMP; Zhu L, 2008, PATTERN RECOGN, V41, P2447, DOI 10.1016/j.patcog.2008.01.014	67	17	18	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2011	33	9					1758	1775		10.1109/TPAMI.2011.43	http://dx.doi.org/10.1109/TPAMI.2011.43			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	792JN	21383394	Green Submitted			2022-12-18	WOS:000292740000005
J	Sellent, A; Eisemann, M; Goldlucke, B; Cremers, D; Magnor, M				Sellent, Anita; Eisemann, Martin; Goldluecke, Bastian; Cremers, Daniel; Magnor, Marcus			Motion Field Estimation from Alternate Exposure Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Motion field estimation; motion blur; optical flow; occlusion; computational video	OPTICAL-FLOW ESTIMATION; COMPUTATION	Traditional optical flow algorithms rely on consecutive short-exposed images. In this work, we make use of an additional long-exposed image for motion field estimation. Long-exposed images integrate motion information directly in the form of motion-blur. With this additional information, more robust and accurate motion fields can be estimated. In addition, the moment of occlusion can be determined. Considering the basic signal-theoretical problem in motion field estimation, we exploit the fact that long-exposed images integrate motion information to prevent temporal aliasing. A suitable image formation model relates the long-exposed image to preceding and succeeding short-exposed images in terms of dense 2D motion and per-pixel occlusion/disocclusion timings. Based on our image formation model, we describe a practical variational algorithm to estimate the motion field not only for visible image regions but also for regions getting occluded. Results for synthetic as well as real-world scenes demonstrate the validity of the approach.	[Sellent, Anita; Eisemann, Martin; Magnor, Marcus] TU Braunschweig, Inst Comp Graph, D-38106 Braunschweig, Germany; [Goldluecke, Bastian; Cremers, Daniel] Tech Univ Munich, Dept Comp Sci, D-85748 Garching, Germany	Braunschweig University of Technology; Technical University of Munich	Sellent, A (corresponding author), TU Braunschweig, Inst Comp Graph, D-38106 Braunschweig, Germany.	sellent@cg.tu-bs.de; eisemann@cg.tu-bs.de; bastian.goldluecke@in.tum.de; daniel.cremers@in.tum.de; magnor@cg.tu-bs.de			German Science Foundation [DFG MA2555/4-1]	German Science Foundation(German Research Foundation (DFG))	The authors gratefully acknowledge funding by the German Science Foundation from project DFG MA2555/4-1.	AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965; Agrawal A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531401; Alvarez L, 2007, INT J COMPUT VISION, V75, P371, DOI 10.1007/s11263-007-0041-4; Baker S., 2007, P IEEE INT C COMP VI; Bar L, 2007, IEEE I CONF COMP VIS, P1410; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Ben-Ezra M, 2003, PROC CVPR IEEE, P657; BROX T, 2004, P 8 EUR C COMP VIS, V4, P25; Chambolle A, 2004, J MATH IMAGING VIS, V20, P89; Chen WG, 1996, IEEE T PATTERN ANAL, V18, P412, DOI 10.1109/34.491622; Chen WG, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pA199; Christmas WJ, 2000, IEEE T IMAGE PROCESS, V9, P1817, DOI 10.1109/83.869192; Dai S., 2008, P IEEE C COMP VIS PA, P1; FAVARO P, 2004, P IEEE C COMP VIS PA; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; Jia J., 2007, IEEE C COMP VIS PATT, P1; Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268; Levin A., 2007, ADV NEURAL INFORM PR, P841; Lim S, 2005, IEEE T IMAGE PROCESS, V14, P1074, DOI 10.1109/TIP.2005.851688; Mahajan D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531348; Mitiche A, 1996, INT J COMPUT VISION, V19, P29, DOI 10.1007/BF00131147; PAO T, 2003, P SPIE; Rekleitis IM, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P791, DOI 10.1109/ICIP.1996.560852; Sand Peter, 2008, International Journal of Computer Vision, V80, P72, DOI 10.1007/s11263-008-0136-6; SELLENT A, 2009, P IEEE INT C COMP PH; SELLENT A, 2009, P VIS MOD VIS WORKSH, P135; Tai Y.-W., 2008, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2008.4587507; Xiao JJ, 2006, LECT NOTES COMPUT SC, V3951, P211; Yuan L., 2007, P SIGGRAPH; Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22	30	17	18	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2011	33	8					1577	1589		10.1109/TPAMI.2010.218	http://dx.doi.org/10.1109/TPAMI.2010.218			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	779UH	21135447				2022-12-18	WOS:000291807200007
J	Li, HS; Shen, TA; Huang, XL				Li, Hongsheng; Shen, Tian; Huang, Xiaolei			Approximately Global Optimization for Robust Alignment of Generalized Shapes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape alignment; point registration; matching; distance transform; particle swarm optimization	NONRIGID REGISTRATION; PARTICLE SWARM; ALGORITHM; IMAGES	In this paper, we introduce a novel method to solve shape alignment problems. We use gray-scale "images" to represent source shapes, and propose a novel two-component Gaussian Mixture (GM) distance map representation for target shapes. This asymmetric representation is a flexible image-based representation which is able to represent different kinds of shape data, including continuous contours, unstructured sparse point sets, edge maps, and even gray-scale gradient maps. Using this representation, a new energy function based on a novel two-component Gaussian Mixture distance model is proposed. The new energy function was empirically evaluated to be a more robust shape dissimilarity metric that can be computed efficiently. Such high efficiency is essential for global optimization methods. We adopt and modify one of them, the Particle Swarm Optimization (PSO), to effectively estimate the global optimum of the new energy function. Differently from the original PSO, several new strategies were employed to make the optimization more robust and prevent it from converging prematurely. The overall performance of the proposed framework as well as the properties of each algorithmic component were evaluated and compared with those of some state-of-the-art methods. Extensive experiments and comparison performed on generalized 2D and 3D shape data demonstrate the robustness and effectiveness of the method.	[Li, Hongsheng; Shen, Tian; Huang, Xiaolei] Lehigh Univ, Dept Comp Sci & Engn, Bethlehem, PA 18015 USA	Lehigh University	Li, HS (corresponding author), Lehigh Univ, Dept Comp Sci & Engn, 19 Mem Dr W, Bethlehem, PA 18015 USA.	h.li@lehigh.edu; tis207@lehigh.edu; xih206@lehigh.edu			US National Science Foundation (NSF) [IIS-0812120]; US National Institutes of Health (NIH) [R21GM083928]; NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES [R21GM083928] Funding Source: NIH RePORTER	US National Science Foundation (NSF)(National Science Foundation (NSF)); US National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS))	This work was partially supported by the US National Science Foundation (NSF) Grant IIS-0812120, and US National Institutes of Health (NIH) Grant R21GM083928.	BARROW HG, 1977, P INT JOINT C ART IN, P1175; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bhowmick P, 2009, IEEE T PATTERN ANAL, V31, P769, DOI 10.1109/TPAMI.2007.70812; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Chui HL, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P190, DOI 10.1109/MMBIA.2000.852377; Clerc M, 2002, IEEE T EVOLUT COMPUT, V6, P58, DOI 10.1109/4235.985692; COCOSCO C, 1997, P INT C FUNCT MAPP H; Cross ADJ, 1998, IEEE T PATTERN ANAL, V20, P1236, DOI 10.1109/34.730557; DEREZENDE PJ, 1995, ALGORITHMICA, V13, P387, DOI 10.1007/BF01293487; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1131, DOI 10.1109/34.625115; Eberhart R., 1995, P 6 INT S MICR HUM S, P39, DOI 10.1109/MHS.1995.494215; ELMUNIM H, 2007, P IEEE C COMP VIS PA, P1; ERAFAT A, 1996, P 12 ANN ACM S COMP, P301; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fitzgibbon AW, 2003, IMAGE VISION COMPUT, V21, P1145, DOI 10.1016/j.imavis.2003.09.004; GODIN G, 1994, P SPIE VIDEOMETRICS, V3; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Granger S, 2002, LECT NOTES COMPUT SC, V2353, P418; Hill FS, 2007, COMPUTER GRAPHICS US; Huang XL, 2006, IEEE T PATTERN ANAL, V28, P1303, DOI 10.1109/TPAMI.2006.171; Huber P., 1981, ROBUST STAT; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Jagannathan A, 2005, PROC CVPR IEEE, P1008; Jian B, 2005, IEEE I CONF COMP VIS, P1246; Lempitsky V, 2007, IEEE I CONF COMP VIS, P620; Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835; Longji Tang, 2008, 2008 IEEE International Symposium on Service-Oriented System Engineering, P1, DOI 10.1109/SOSE.2008.37; Makadia A., 2006, P IEEE C COMP VIS PA, V1, P1297, DOI DOI 10.1109/CVPR.2006.122; Manay S, 2006, IEEE T PATTERN ANAL, V28, P1602, DOI 10.1109/TPAMI.2006.208; Masuda T., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P879, DOI 10.1109/ICPR.1996.546150; Maurer CR, 2003, IEEE T PATTERN ANAL, V25, P265, DOI 10.1109/TPAMI.2003.1177156; Paragios N, 2003, COMPUT VIS IMAGE UND, V89, P142, DOI 10.1016/S1077-3142(03)00010-9; Rangarajan A, 1997, Med Image Anal, V1, P379; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Sanders R.W., 2008, P 33 AES INT C AUD F, P1; Schmidt FR, 2007, IEEE I CONF COMP VIS, P1479; Sebastian T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P755, DOI 10.1109/ICCV.2001.937602; Sharvit D, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P56, DOI 10.1109/IVL.1998.694496; Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146; TEK H, 1999, P IEEE INT C COMP VI, P362; TSIN Y, 2004, P EUR C COMP VIS, V3, P558; Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241; Veltkamp RC, 2001, ADV PTRN RECOGNIT, P87; WANG C, 2010, NAVLAB SLAMMOT DATA; Wang F, 2008, IEEE T PATTERN ANAL, V30, P2011, DOI 10.1109/TPAMI.2007.70829; Wang Fei, 2006, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, V1, P1283; Wang Y, 2004, COMPUT GRAPH FORUM, V23, P677, DOI 10.1111/j.1467-8659.2004.00800.x; Xiao P., 2007, P 2007 IEEE C COMPUT, P1, DOI [10.1109/CVPR.2007.383359, DOI 10.1109/CVPR.2007.383359]; Xie XF, 2002, 2002 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I AND II, P1215, DOI 10.1109/ICOSP.2002.1180009; Zhang H, 2002, SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P261, DOI 10.1109/SMI.2002.1003554; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149; [No title captured]; [No title captured]	54	17	17	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2011	33	6					1116	1131		10.1109/TPAMI.2010.169	http://dx.doi.org/10.1109/TPAMI.2010.169			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	750DE	20820077				2022-12-18	WOS:000289524000004
J	Lehmann, F				Lehmann, Frederic			Turbo Segmentation of Textured Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Texture segmentation; Markov random field; hidden Markov autoregressive model; factor graph; forward-backward algorithm; turbo processing	HIDDEN MARKOV; STATISTICAL-ANALYSIS; CLASSIFICATION; MODELS; HMM	We consider the problem of semi-supervised segmentation of textured images. Existing model-based approaches model the intensity field of textured images as a Gauss-Markov random field to take into account the local spatial dependencies between the pixels. Classical Bayesian segmentation consists of also modeling the label field as a Markov random field to ensure that neighboring pixels correspond to the same texture class with high probability. Well-known relaxation techniques are available which find the optimal label field with respect to the maximum a posteriori or the maximum posterior mode criterion. But, these techniques are usually computationally intensive because they require a large number of iterations to converge. In this paper, we propose a new Bayesian framework by modeling two-dimensional textured images as the concatenation of two one-dimensional hidden Markov autoregressive models for the lines and the columns, respectively. A segmentation algorithm, which is similar to turbo decoding in the context of error-correcting codes, is obtained based on a factor graph approach. The proposed method estimates the unknown parameters using the Expectation-Maximization algorithm.	TELECOM SudParis, Inst TELECOM, Dept CITI, F-91011 Evry, France	IMT - Institut Mines-Telecom; IMT Atlantique; Institut Polytechnique de Paris	Lehmann, F (corresponding author), TELECOM SudParis, Inst TELECOM, Dept CITI, 9 Rue Charles Fourier, F-91011 Evry, France.	frederic.lehmann@it-sudparis.eu						BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196; BERROU C, 1993, IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS 93 : TECHNICAL PROGRAM, CONFERENCE RECORD, VOLS 1-3, P1064, DOI 10.1109/ICC.1993.397441; BESAG J, 1986, J R STAT SOC B, V48, P259; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; Chellappa R., 1984, PROGR PATTERN RECOGN; Chiang J, 2008, IEEE T SIGNAL PROCES, V56, P4069, DOI 10.1109/TSP.2008.925246; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; DEVIJVER PA, 1985, PATTERN RECOGN LETT, V3, P369, DOI 10.1016/0167-8655(85)90023-6; ELIAS P, 1954, IRE T INFORM THEOR, P29, DOI 10.1109/TIT.1954.1057464; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Giordana N, 1997, IEEE T PATTERN ANAL, V19, P465, DOI 10.1109/34.589206; HAMILTON JD, 1990, J ECONOMETRICS, V45, P39, DOI 10.1016/0304-4076(90)90093-9; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Krishnamachari S, 1997, IEEE T IMAGE PROCESS, V6, P251, DOI 10.1109/83.551696; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; LAKSHMANAN S, 1989, IEEE T PATTERN ANAL, V11, P799, DOI 10.1109/34.31443; Li J, 2000, IEEE T SIGNAL PROCES, V48, P517, DOI 10.1109/78.823977; MANJUNATH BS, 1990, IEEE T ACOUST SPEECH, V38, P1039, DOI 10.1109/29.56064; MANJUNATH BS, 1991, IEEE T PATTERN ANAL, V13, P478, DOI 10.1109/34.134046; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; ORUANAIDH J, 1996, NUMERICAL BAYESIAN M; Othman H, 2003, IEEE T PATTERN ANAL, V25, P1229, DOI 10.1109/TPAMI.2003.1233897; Pearl J., 1988, PROBABILISTIC RESONI; Perronnin F, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P329; Pyndiah RM, 1998, IEEE T COMMUN, V46, P1003, DOI 10.1109/26.705396; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; ROBERTSON P, 1995, ICC '95 - 1995 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CONFERENCE RECORD, VOLS 1-3, P1009, DOI 10.1109/ICC.1995.524253; Sargin ME, 2008, IEEE IMAGE PROC, P2552, DOI 10.1109/ICIP.2008.4712314; Sklar B, 1997, IEEE COMMUN MAG, V35, P94, DOI 10.1109/35.642838; Tuceryan M., 1998, HDB PATTERN RECOGNIT; WOODS JW, 1972, IEEE T INFORM THEORY, V18, P232, DOI 10.1109/TIT.1972.1054786; Zabih R, 2004, PROC CVPR IEEE, P437	35	17	20	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2011	33	1					16	29		10.1109/TPAMI.2010.58	http://dx.doi.org/10.1109/TPAMI.2010.58			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	681AC	21088316				2022-12-18	WOS:000284277600002
J	Glasmachers, T; Igel, C				Glasmachers, Tobias; Igel, Christian			Maximum Likelihood Model Selection for 1-Norm Soft Margin SVMs with Multiple Parameters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Support vector machines; model selection; regularization; maximum likelihood	SUPPORT; ADAPTATION	Adapting the hyperparameters of support vector machines (SVMs) is a challenging model selection problem, especially when flexible kernels are to be adapted and data are scarce. We present a coherent framework for regularized model selection of 1-norm soft margin SVMs for binary classification. It is proposed to use gradient-ascent on a likelihood function of the hyperparameters. The likelihood function is based on logistic regression for robustly estimating the class conditional probabilities and can be computed efficiently. Overfitting is an important issue in SVM model selection and can be addressed in our framework by incorporating suitable prior distributions over the hyperparameters. We show empirically that gradient-based optimization of the likelihood function is able to adapt multiple kernel parameters and leads to better models than four concurrent state-of-the-art methods.	[Glasmachers, Tobias] Dalle Molle Inst Artificial Intelligence IDSIA, CH-6928 Manno Lugano, Switzerland; [Igel, Christian] Ruhr Univ Bochum, Inst Neuroinformat, D-44780 Bochum, Germany	Universita della Svizzera Italiana; Ruhr University Bochum	Glasmachers, T (corresponding author), Dalle Molle Inst Artificial Intelligence IDSIA, CH-6928 Manno Lugano, Switzerland.	tobias@idsia.ch; christian.igel@neuroinformatik.rub.de	Igel, Christian/B-4091-2009	Igel, Christian/0000-0003-2868-0856	German Federal Ministry of Education and Research within the National Network Computational Neuroscience [01GQ0951]	German Federal Ministry of Education and Research within the National Network Computational Neuroscience	Christian Igel acknowledges support from the German Federal Ministry of Education and Research within the National Network Computational Neuroscience under grant number 01GQ0951 (Bernstein Fokus "Learning behavioral models: From human experiment to technical assistance").	Asuncion A, 2007, UCI MACHINE LEARNING; Bartlett PL, 2007, J MACH LEARN RES, V8, P775; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401; BRADLEY PS, 1998, P 15 INT C MACH LEAR, P82; Cawley GC, 2008, MACH LEARN, V71, P243, DOI 10.1007/s10994-008-5055-9; Cawley GC, 2007, J MACH LEARN RES, V8, P841; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; CHAPELLE O, 2002, THESIS LAB INFORM PA; Chapelle O, 2007, ADV NEURAL INFORM PR, V19; Chung KM, 2003, NEURAL COMPUT, V15, P2643, DOI 10.1162/089976603322385108; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Duan K, 2003, NEUROCOMPUTING, V51, P41, DOI 10.1016/S0925-2312(02)00601-X; Friedrichs F, 2005, NEUROCOMPUTING, V64, P107, DOI 10.1016/j.neucom.2004.11.022; Glasmachers T, 2005, NEURAL COMPUT, V17, P2099, DOI 10.1162/0899766054615635; Glasmachers T, 2008, LECT NOTES COMPUT SC, V5199, P185, DOI 10.1007/978-3-540-87700-4_19; Glasmachers T, 2006, J MACH LEARN RES, V7, P1437; Gold C, 2003, NEUROCOMPUTING, V55, P221, DOI 10.1016/S0925-2312(03)00375-8; Hansen N, 2001, EVOL COMPUT, V9, P159, DOI 10.1162/106365601750190398; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; Igel C, 2003, NEUROCOMPUTING, V50, P105, DOI 10.1016/S0925-2312(01)00700-7; Igel C, 2008, J MACH LEARN RES, V9, P993; Igel C, 2007, IEEE ACM T COMPUT BI, V4, P216, DOI [10.1109/TCBB.2007.070208, 10.1109/tcbb.2007.070208]; Jaakkola T, 1999, Proc Int Conf Intell Syst Mol Biol, P149; Keerthi SS, 2002, IEEE T NEURAL NETWOR, V13, P1225, DOI 10.1109/TNN.2002.1031955; Lin HT, 2007, MACH LEARN, V68, P267, DOI 10.1007/s10994-007-5018-6; Opper Manfred, 1999, ADV LARGE MARGIN CLA; Platt JC, 2000, ADV NEUR IN, P61; Ratsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488; Seeger M, 2000, ADV NEUR IN, V12, P603; Suttorp T, 2009, MACH LEARN, V75, P167, DOI 10.1007/s10994-009-5102-1; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Vapnik V, 2000, NEURAL COMPUT, V12, P2013, DOI 10.1162/089976600300015042; Vapnik V.N, 1998, STAT LEARNING THEORY; Wahba G, 2002, P NATL ACAD SCI USA, V99, P16524, DOI 10.1073/pnas.242574899; Zhang SS, 2004, NUCLEIC ACIDS RES, V32, P1, DOI 10.1093/nar/gkg933	36	17	18	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2010	32	8					1522	1528		10.1109/TPAMI.2010.95	http://dx.doi.org/10.1109/TPAMI.2010.95			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	611XQ	20421674				2022-12-18	WOS:000278858600013
J	Shima, T; Saito, S; Nakajima, M				Shima, Tetsuo; Saito, Suguru; Nakajima, Masayuki			Design and Evaluation of More Accurate Gradient Operators on Hexagonal Lattices	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image processing; hexagonal lattice; consistent gradient operator; gradient intensity; orientation		Digital two-dimensional images are usually sampled on square lattices, while the receptors of the human eye are following a hexagonal structure. It is the main motivation for adopting hexagonal lattices. The fundamental operation in many image processing algorithms is to extract the gradient information. As such, various gradient operators have been proposed for square lattices and have been thoroughly optimized. Accurate gradient operators for hexagonal lattices have, however, not been researched well enough, while the distance between neighbor pixels is constant. We therefore derive consistent gradient operators on hexagonal lattices and compare them with the existing optimized filters on square lattices. The results show that the derived filters on hexagonal lattices achieve a better signal-to-noise ratio than those on square lattices. Results on artificial images also show that the derived filters on hexagonal lattices outperform the square ones with respect to accuracy of gradient intensity and orientation detection.	[Shima, Tetsuo; Saito, Suguru; Nakajima, Masayuki] Tokyo Inst Technol, Grad Sch Informat Sci & Engn, Dept Comp Sci, Meguro Ku, Tokyo 1528552, Japan	Tokyo Institute of Technology	Shima, T (corresponding author), Tokyo Inst Technol, Grad Sch Informat Sci & Engn, Dept Comp Sci, Meguro Ku, W8-64,2-12-1 Ookayama, Tokyo 1528552, Japan.	shima@img.cs.titech.ac.jp; suguru@img.cs.titech.ac.jp; nakajima@img.cs.titech.ac.jp						ALLEN JD, 2005, P 5 INT C INF COMM S, P73; Ando S, 2000, IEEE T PATTERN ANAL, V22, P252, DOI 10.1109/34.841757; [Anonymous], COMPUTER VISION UNIF; BALAKRISHNAN M, 1993, OPT ENG, V32, P1430, DOI 10.1117/12.141686; CHETTIR S, 1989, P SPIE C OPT ILL IM, P152; CHOI K, 1996, P INT C IM PROC SEPT, V1, P497; DUBOIS E, 1985, P IEEE, V73, P502, DOI 10.1109/PROC.1985.13182; FREI W, 1977, IEEE T COMPUT, V26, P988, DOI 10.1109/TC.1977.1674733; Grigoryan AM, 2002, IEEE T SIGNAL PROCES, V50, P1438, DOI 10.1109/TSP.2002.1003067; HER I, 1995, IEEE T IMAGE PROCESS, V4, P1213, DOI 10.1109/83.413166; Jiang QT, 2008, IEEE T IMAGE PROCESS, V17, P1512, DOI 10.1109/TIP.2008.2001401; KIMURO Y, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P356, DOI 10.1109/IROS.1995.525909; KIRSCH RA, 1971, COMPUT BIOMED RES, V4, P315, DOI 10.1016/0010-4809(71)90034-6; MERSEREAU RM, 1979, P IEEE, V67, P930, DOI 10.1109/PROC.1979.11356; MIDDLETON L, 2002, P INT C CONTR AUT RO, V1, P90; Middleton L., 2005, ADV PTRN RECOGNIT; RUSS JC, 1998, IMAGE PROCESSING HDB, P253; SIMONCELLI EP, 1990, P IEEE, V78, P652, DOI 10.1109/5.54805; Staunton RC, 1999, IEE CONF PUBL, P841, DOI 10.1049/cp:19990443; STAUNTON RC, 1989, P SPIE C OPT ILL IM, P142; Thiel G, 2000, IEEE AERO EL SYS MAG, V15, P3, DOI 10.1109/62.854018; Tremblay M., 1995, Proceedings. CAMP '95 Computer Architectures for Machine Perception (Cat. No.95TB8093), P21, DOI 10.1109/CAMP.1995.521015; Ulichney Robert, 1987, DIGITAL HALFTONING, P5; Ville D.V.D., 2004, IEEE T IMAGE PROCESS, V13, P758	24	17	17	1	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2010	32	6					961	973		10.1109/TPAMI.2009.99	http://dx.doi.org/10.1109/TPAMI.2009.99			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	583JU	20431124				2022-12-18	WOS:000276671900001
J	Sagar, BSD				Sagar, B. S. Daya			Visualization of Spatiotemporal Behavior of Discrete Maps via Generation of Recursive Median Elements	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						GISci; spatial interpolation; mathematical morphology; thematic maps; dilation; erosion; interpolation formulas; spatial databases and GIS; cartography; morphological image representation; visualization techniques and methodologies; geometrical problems and computations; set theory	INTERPOLATION	Spatial interpolation is one of the demanding techniques in Geographic Information Science (GISci) to generate interpolated maps in a continuous manner by using two discrete spatial and/or temporal data sets. Noise-free data (thematic layers) depicting a specific theme at varied spatial or temporal resolutions consist of connected components either in aggregated or in disaggregated forms. This short paper provides a simple framework: 1) to categorize the connected components of layered sets of two different time instants through their spatial relationships and the Hausdorff distances between the companion-connected components and 2) to generate sequential maps (interpolations) between the discrete thematic maps. Development of the median set, using Hausdorff erosion and dilation distances to interpolate between temporal frames, is demonstrated on lake geometries mapped at two different times and also on the bubonic plague epidemic spread data available for 11 consecutive years. We documented the significantly fair quality of the median sets generated for epidemic data between alternative years by visually comparing the interpolated maps with actual maps. They can be used to visualize (animate) the spatiotemporal behavior of a specific theme in a continuous sequence.	Indian Stat Inst, Bangalore Ctr, Syst Sci & Informat Unit, Bangalore 560059, Karnataka, India	Indian Statistical Institute; Indian Statistical Institute Bangalore	Sagar, BSD (corresponding author), Indian Stat Inst, Bangalore Ctr, Syst Sci & Informat Unit, 8th Mile,Mysore Rd,RVCE PO, Bangalore 560059, Karnataka, India.	bsdsagar@isibang.ac.in	Sagar, BS Daya/A-2654-2012	Sagar, BS Daya/0000-0002-6140-8742				BEUCHER S, 1994, N1894MM EC MIN PARS; BURR DJ, 1981, IEEE T PATTERN ANAL, V3, P708, DOI 10.1109/TPAMI.1981.4767176; CHEN SY, 1990, IEEE T MED IMAGING, V9, P71, DOI 10.1109/42.52984; Cressie N., 2011, STAT SPATIO TEMPORAL; FRANK AU, 1998, P ANN C GIS PLAN 98; FRANK AU, 2005, P ER WORKSH CONC MOD; HAUSDORFF F, 1914, GRUNDZUGE MENGENLCHR; HERMAN GT, 1992, IEEE COMPUT GRAPH, V12, P69, DOI 10.1109/38.135915; Iwanowski M, 2000, COMP IMAG VIS, V18, P81; Iwanowski M, 2000, THESIS WARSAW U TECH; Lane S. Mac, 1967, ALGEBRA; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; MARAGOS P, 1990, IEEE T PATTERN ANAL, V12, P498, DOI 10.1109/34.55110; Maragos P, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P135, DOI 10.1016/B978-012119792-6/50072-3; Meyer F., 1994, N1694MM EC MIN PAR; RAYA SP, 1990, IEEE T MED IMAGING, V9, P32, DOI 10.1109/42.52980; SERRA J, 1998, MATH MORPHOLOGY ITS; Serra J, 1982, IMAGE ANAL MATH MORP; Serra J., 1994, N1594MM EC MIN PAR; SNODGRASS RT, 1992, LECT NOTES COMPUT SC, V639, P22; Tomlin C. D., 1990, GEOGRAPHIC INFORM SY; VIDAL J, 2005, P INT S MATH MORPH 4, P53; Werahera PN, 1995, IEEE T MED IMAGING, V14, P765, DOI 10.1109/42.476120; Worboys M.F., 2004, GIS COMPUTING PERSPE; YU HL, 2006, INT J HEALTH GEOGR, V5, P1, DOI DOI 10.1186/1476-072X-5-12	25	17	17	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2010	32	2					378	384		10.1109/TPAMI.2009.163	http://dx.doi.org/10.1109/TPAMI.2009.163			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	532IT	20075466				2022-12-18	WOS:000272741500015
J	Li, G; Zucker, SW				Li, Gang; Zucker, Steven W.			Differential Geometric Inference in Surface Stereo	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo matching; surface stereo; differential geometry; curved surface; slanted surface; computational inference; half-occluded surface region	CONTEXTUAL INFERENCE; IMAGE; OCCLUSIONS; ALGORITHM; TRACE	Many traditional two-view stereo algorithms explicitly or implicitly use the frontal parallel plane assumption when exploiting contextual information since, e.g., the smoothness prior biases toward constant disparity (depth) over a neighborhood. This introduces systematic errors to the matching process for slanted or curved surfaces. These errors are nonnegligible for detailed geometric modeling of natural objects such as a human face. We show how to use contextual information geometrically to avoid such errors. A differential geometric study of smooth surfaces allows contextual information to be encoded in Cartan's moving frame model over local quadratic approximations, providing a framework of geometric consistency for both depth and surface normals; the accuracy of our reconstructions argues for the sufficiency of the approximation. In effect, Cartan's model provides the additional constraint necessary to move beyond the frontal parallel plane assumption in stereo reconstruction. It also suggests how geometry can extend surfaces to account for unmatched points due to partial occlusion.	[Li, Gang] Siemens Corp Res, Real Time Vis & Modeling Dept, Princeton, NJ 08540 USA; [Zucker, Steven W.] Yale Univ, Dept Comp Sci, New Haven, CT 06520 USA	Siemens AG; Yale University	Li, G (corresponding author), Siemens Corp Res, Real Time Vis & Modeling Dept, 755 Coll Rd E, Princeton, NJ 08540 USA.	gang-li@siemens.com; steven.zucker@yale.edu			AFOSR; AFRL; ARO; NGA	AFOSR(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); AFRL(United States Department of DefenseUS Air Force Research Laboratory); ARO; NGA	The authors would like to thank the reviewers for their detailed comments. Research supported by AFOSR, AFRL, ARO, and NGA. This research was performed when G. Li was a student at Yale University.	BARNARD ST, 1982, COMPUT SURV, V14, P553, DOI 10.1145/356893.356896; Belhumeur PN, 1996, INT J COMPUT VISION, V19, P237, DOI 10.1007/BF00055146; Ben-Shahar O, 2003, IEEE T PATTERN ANAL, V25, P401, DOI 10.1109/TPAMI.2003.1190568; Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269; BIRCHFIELD S, 1999, P IEEE INT C COMP VI; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603; Cipolla R., 2000, VISUAL MOTION CURVES; DEVERNAY F, 1994, P IEEE C COMP VIS PA; DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; Egnal G, 2002, IEEE T PATTERN ANAL, V24, P1127, DOI 10.1109/TPAMI.2002.1023808; Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Felzenszwalb P. F., 2004, P IEEE C COMP VIS PA; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; FROHLINGHAUS T, 1996, P INT C PATT REC; Goldlucke B, 2007, IEEE T PATTERN ANAL, V29, P1194, DOI 10.1109/TPAMI.2007.1146.; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Hirschmuller H., 2007, P IEEE C COMP VIS PA; HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; Jin HL, 2005, INT J COMPUT VISION, V63, P175, DOI 10.1007/s11263-005-6876-7; KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kimmel R, 2002, J VIS COMMUN IMAGE R, V13, P324, DOI 10.1006/jvci.2001.0486; LENGAGNE R, 1997, P IEEE C COMP VIS PA; LI G, 2006, P IEEE C COMP VIS PA; LI G, 2006, P EUR C COMP VIS; Li G, 2006, INT J COMPUT VISION, V69, P59, DOI 10.1007/s11263-006-6853-9; Li S. Z., 2001, COMP SCI W; Lin MH, 2004, IEEE T PATTERN ANAL, V26, P1073, DOI 10.1109/TPAMI.2004.54; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; NAKAYAMA K, 1990, VISION RES, V30, P1811, DOI 10.1016/0042-6989(90)90161-D; OGALE AS, 2004, P IEEE C COMP VIS PA; ONeill B., 2006, ELEMENTARY DIFFERENT, DOI 10.1090/chel/341/01; Orban GA, 2006, TRENDS NEUROSCI, V29, P466, DOI 10.1016/j.tins.2006.06.012; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; SANDER PT, 1990, IEEE T PATTERN ANAL, V12, P833, DOI 10.1109/34.57680; Scharstein D, 1998, INT J COMPUT VISION, V28, P155, DOI 10.1023/A:1008015117424; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Scharstein D., 2003, P IEEE C COMP VIS PA; STRECHA C, 2003, P IEEE INT C COMP VI; Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509; TAO H, 2001, P IEEE INT C COMP VI; TAPPEN MF, 2003, P IEEE INT C COMP VI; TSIN Y, 2004, P IEEE C COMP VIS PA; WOODFORD OJ, 2008, P IEEE C COMP VIS PA; Zhang L, 2007, IEEE T PATTERN ANAL, V29, P331, DOI 10.1109/TPAMI.2007.36; Zitnick CL, 2000, IEEE T PATTERN ANAL, V22, P675, DOI 10.1109/34.865184; ZUCKER SW, 2005, HDB MATH MODELS COMP	54	17	17	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2010	32	1					72	86		10.1109/TPAMI.2008.270	http://dx.doi.org/10.1109/TPAMI.2008.270			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	520FQ	19926900				2022-12-18	WOS:000271826700007
J	Liu, YH				Liu, Yonghuai			Automatic Range Image Registration in the Markov Chain	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Automatic registration; range image; Markov chain; Lyapunov function; entropy maximization; mean field annealing	POINT; ALGORITHM	In this paper, a novel entropy that can describe both long and short-tailed probability distributions of constituents of a thermodynamic system out of its thermodynamic limit is first derived from the Lyapunov function for a Markov chain. We then maximize this entropy for the estimation of the probabilities of possible correspondences established using the traditional closest point criterion between two overlapping range images. When we change our viewpoint to look carefully at the minimum solution to the probability estimate of the correspondences, the iterative range image registration process can also be modeled as a Markov chain in which lessons from past experience in estimating those probabilities are learned. To impose the two-way constraint, outliers are explicitly modeled due to the almost ubiquitous occurrence of occlusion, appearance, and disappearance of points in either image. The estimated probabilities of the correspondences are finally embedded into the powerful mean field annealing scheme for global optimization, leading the camera motion parameters to be estimated in the weighted least-squares sense. A comparative study using real images shows that the proposed algorithm usually outperforms the state-of-the-art ICP variants and the latest genetic algorithm for automatic overlapping range image registration.	Aberystwyth Univ, Dept Comp Sci, Ceredigion SY23 3DB, Wales	Aberystwyth University	Liu, YH (corresponding author), Aberystwyth Univ, Dept Comp Sci, Ceredigion SY23 3DB, Wales.	yyl@aber.ac.uk	Liu, Yonghuai/ABF-3794-2020					Andreetto M, 2004, IEEE T IMAGE PROCESS, V13, P352, DOI 10.1109/TIP.2003.821351; ASHBROOK AP, 1998, P 5 ECCV, V2, P185; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Brusco N, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P262, DOI 10.1109/3DIM.2005.5; Chao C, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P254; Chui H, 2003, MED IMAGE ANAL, V7, P113, DOI 10.1016/S1361-8415(02)00102-0; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Chung A.J., 2004, P S EYE TRACK RES AP, P49; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dewaele G, 2004, LECT NOTES COMPUT SC, V3021, P495; Dorai C., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P770, DOI 10.1109/ICPR.1996.546128; Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745; Gelfand N, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P260, DOI 10.1109/IM.2003.1240258; Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1; Gorban AN, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.067104; Gorban P, 2003, PHYSICA A, V328, P380, DOI 10.1016/S0378-4371(03)00578-8; Granger S, 2002, LECT NOTES COMPUT SC, V2353, P418; Huber DF, 2003, IMAGE VISION COMPUT, V21, P637, DOI 10.1016/S0262-8856(03)00060-X; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; JONSSON H, 2001, 0116 LUND U DEP THEO; Lingemann K, 2005, ROBOT AUTON SYST, V51, P275, DOI 10.1016/j.robot.2005.02.004; Liu YG, 2005, PATTERN RECOGN, V38, P1615, DOI 10.1016/j.patcog.2005.01.008; Liu YH, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P172; Liu YH, 2004, PATTERN RECOGN LETT, V25, P955, DOI 10.1016/j.patrec.2004.02.006; Liu YH, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P187; Low KL, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P171; Nuchter A, 2004, IEEE INT CONF ROBOT, P1998, DOI 10.1109/ROBOT.2004.1308117; Park SY, 2003, PATTERN RECOGN LETT, V24, P2967, DOI 10.1016/S0167-8655(03)00157-0; Pulli K., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P160, DOI 10.1109/IM.1999.805346; PUZICHA J, 1997, P 15 IMACS WORLD C S, P445; Renyi A., 1970, PROBABILITY THEORY; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Sharp GC, 2002, IEEE T PATTERN ANAL, V24, P90, DOI 10.1109/34.982886; Silva L, 2005, IEEE T PATTERN ANAL, V27, P762, DOI 10.1109/TPAMI.2005.108; SINKHORN R, 1964, ANN MATH STAT, V35, P876, DOI 10.1214/aoms/1177703591; Stewart CV, 2003, IEEE T MED IMAGING, V22, P1379, DOI 10.1109/TMI.2003.819276; TAYLOR PD, 1978, MATH BIOSCI, V40, P145, DOI 10.1016/0025-5564(78)90077-9; TSALLIS C, 1988, J STAT PHYS, V52, P479, DOI 10.1007/BF01016429; Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241; WHITAKER RT, 1999, P 3DIM, P348; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149; Zheng YF, 2006, IEEE T PATTERN ANAL, V28, P643, DOI 10.1109/TPAMI.2006.81; EHRENFEST CHAINS	43	17	19	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2010	32	1					12	29		10.1109/TPAMI.2008.280	http://dx.doi.org/10.1109/TPAMI.2008.280			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	520FQ	19926896				2022-12-18	WOS:000271826700003
J	Bhusnurmath, A; Taylor, CJ				Bhusnurmath, Arvind; Taylor, Camillo J.			Graph cuts via l(1) norm minimization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	IEEE Conference on Computer Vision and Pattern Recognition	JUN 17-22, 2007	Minneapolis, MN	IEEE, hp invent, INI-GraphicsNet, VIOSO		convex optimization; computer vision; graph-theoretic methods; linear programming	ENERGY MINIMIZATION	Graph cuts have become an increasingly important tool for solving a number of energy minimization problems in computer vision and other fields. In this paper, the graph cut problem is reformulated as an unconstrained l(1) norm minimization that can be solved effectively using interior point methods. This reformulation exposes connections between graph cuts and other related continuous optimization problems. Eventually, the problem is reduced to solving a sequence of sparse linear systems involving the Laplacian of the underlying graph. The proposed procedure exploits the structure of these linear systems in a manner that is easily amenable to parallel implementations. Experimental results obtained by applying the procedure to graphs derived from image processing problems are provided.	[Bhusnurmath, Arvind; Taylor, Camillo J.] Univ Penn, Grasp Lab, Philadelphia, PA 19104 USA	University of Pennsylvania	Bhusnurmath, A (corresponding author), Univ Penn, Grasp Lab, 3330 Walnut St,Levine Hall, Philadelphia, PA 19104 USA.	bhusnur4@seas.upenn.edu; cjtaylor@cis.upenn.edu						[Anonymous], 1998, MATRIX COMPUTATIONS; Biggs N, 1993, ALGEBRAIC GRAPH THEO, V2nd; Bolz J, 2003, ACM T GRAPHIC, V22, P917, DOI 10.1145/882262.882364; Boyd S, 2004, CONVEX OPTIMIZATION; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; CONCUS P, 1985, SIAM J SCI STAT COMP, V6, P220, DOI 10.1137/0906018; Cormen TH, 2002, INTRO ALGORITHMS; DIXIT N, 2005, GPU CUTS COMBINATORI; Grady L, 2005, LECT NOTES COMPUT SC, V3750, P773, DOI 10.1007/11566489_95; Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233; Koh KM, 2007, J MACH LEARN RES, V8, P1519; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kruger J, 2003, ACM T GRAPHIC, V22, P908, DOI 10.1145/882262.882363; Papadimitriou C. H., 1982, COMBINATORIAL OPTIMI; RESENDE M, 1996, ADV LINEAR INTEGER P; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Sinha SN, 2005, IEEE I CONF COMP VIS, P349; Sinop AK, 2007, IEEE I CONF COMP VIS, P1016, DOI 10.1109/iccv.2007.4408927	20	17	18	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2008	30	10					1866	1871		10.1109/TPAMI.2008.82	http://dx.doi.org/10.1109/TPAMI.2008.82			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	336DQ	18703837				2022-12-18	WOS:000258344900015
J	Wimmer, M; Stulp, F; Pietzsch, S; Radig, B				Wimmer, Matthias; Stulp, Freek; Pietzsch, Sylvia; Radig, Bernd			Learning local objective functions for robust face model fitting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; vision and scene understanding; face and gesture recognition; real-time systems	RECOGNITION	Model-based fitting has proven to be a successful approach to interpreting the large amount of information contained in images. Fitting algorithms search for the global optimum of an objective function, which should correspond to the best model fit in a given image. Although fitting algorithms have been the subject of intensive research and evaluation, the objective function is usually designed ad hoc, based on implicit and domain-dependent knowledge. This often leads to functions with many local minima and a global minimum that does not correspond to the best model fit. We address the root of this problem by learning more robust objective functions. First, we formulate a set of desirable properties for objective functions and give a concrete example of an ideal function that has these properties. Then, we propose a novel approach that learns an objective function from training data generated by this function and manually annotated images. In this approach, critical decisions such as the feature selection are automated and the remaining manual steps hardly require domain-dependent knowledge. An extensive empirical evaluation demonstrates that learned objective functions enable fitting algorithms to determine the best model fit more accurately and efficiently than designed objective functions.	[Wimmer, Matthias; Pietzsch, Sylvia; Radig, Bernd] Tech Univ Munich, D-85748 Munich, Germany; [Stulp, Freek] Univ Bremen, Grp Cognit Neuroinformat, Fac Comp Sci 03, D-28359 Bremen, Germany	Technical University of Munich; University of Bremen	Wimmer, M (corresponding author), Tech Univ Munich, Boltzmannstr 3, D-85748 Munich, Germany.	matthias.wimmer@cs.tum.edu; freek.stulp@cs.tum.edu; sylvia.pietzsch@cs.tum.edu; bernd.radig@cs.tum.edu						Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21; BELKER T, 2004, THESIS U BONN; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; BOFFY A, 2006, P BRIT MACH VIS C, V2, P529; Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X; COOTES TF, 1998, P EUR C COMP VIS, V2, P484; Cootes TF., 2004, STAT MODELS APPEARAN; COOTES TF, 1993, P INT C COMP VIS; Cootes Timothy F, 1992, BMVC, DOI DOI 10.1007/978-1-4471-3201-1_28; CRISTINACCE D, 2006, P 17 BRIT MACH VIS C, P929; CRISTINACCE D, 2006, FGR, P429; DUFRENOIS F, 2007, P COMP VIS PATT REC, P1; EDWARDS GJ, 1998, P EUR C COMP VIS, V2, P581; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GRABNER H, 2006, P BMVC, V1, P47; GREST D, 2005, P VIS MOD VIS; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; Hall MA, 1997, P 4 INT C NEUR INF P, P855; HANEK R, 2004, THESIS TU MUNCHEN; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; ISARD M, 1996, P EUR C COMP VIS; JESORSKY O, 2001, P 3 INT C AUD VID BA, P90; Jones M.J., 2003, TR200396 MITS EL RES; Jurie F, 2002, IEEE T PATTERN ANAL, V24, P996, DOI 10.1109/TPAMI.2002.1017625; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; KUMAR VP, 2000, AUTOMATIC FACE GESTU, P96; Langs G, 2006, INT C PATT RECOG, P417; Lepetit V, 2005, PROC CVPR IEEE, P775; Lepetit V., 2006, FDN TRENDS COMPUTER, V1, P1; Lienhart R, 2002, IEEE IMAGE PROC, P900; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; LUCEY S, 2000, P INT C PATT REC, V3, P3182; MATAS J, 2002, P COMP VIS WINT WORK, P49; Messer K., 1999, AUDIO VIDEO BASED BI, P72; Nordstrom M. M., 2004, DK2800 TU DENM; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976; Quinlan J.R, 1993, C45 PROGRAMS MACHINE; ROMDHANI S, 2005, THESIS U BASEL; Stegmann M. B., 2000, PROPERTIES ACTIVE SH; STULP F, 2005, P INT JOINT C ART IN; THAYANANTHAN A, 2006, P 9 EUR C COMP VIS E, P124; TIPPING M, 2000, ADV NEURAL INFORM PR; van Ginneken B, 2002, IEEE T MED IMAGING, V21, P924, DOI 10.1109/TMI.2002.803121; VANGINNEKEN B, 2004, P 17 INT C PATT REC; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Williams O, 2005, IEEE T PATTERN ANAL, V27, P1292, DOI 10.1109/TPAMI.2005.167; Wimmer M, 2006, INT C PATT RECOG, P39; Witten I.H., 2005, P DATA MINING LAS VE, P4; Zetzsche C, 2001, J ELECTRON IMAGING, V10, P56, DOI 10.1117/1.1333056	50	17	18	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2008	30	8					1357	1370		10.1109/TPAMI.2007.70793	http://dx.doi.org/10.1109/TPAMI.2007.70793			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	312OC	18566491				2022-12-18	WOS:000256679700004
J	Ksantini, R; Ziou, D; Colin, B; Dubeau, F				Ksantini, Riadh; Ziou, Djemel; Colin, Bernard; Dubeau, Francois			Weighted pseudometric discriminatory power improvement using a Bayesian logistic regression model based on a variational method	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image retrieval; logistic regression; variational method; weighted pseudometric	IMAGE RETRIEVAL; RELEVANCE FEEDBACK	In this paper, we investigate the effectiveness of a Bayesian logistic regression model to compute the weights of a pseudometric in order to improve its discriminatory capacity and thereby increase image retrieval accuracy. In the proposed Bayesian model, the prior knowledge of the observations is incorporated and the posterior distribution is approximated by a tractable Gaussian form using variational transformation and Jensen's inequality, which allow a fast and straightforward computation of the weights. The pseudometric makes use of the compressed and quantized versions of wavelet decomposed feature vectors, and in our previous work, the weights were adjusted by the classical logistic regression model. A comparative evaluation of the Bayesian and classical logistic regression models is performed for content-based image retrieval, as well as for other classification tasks, in a decontextualized evaluation framework. In this same framework, we compare the Bayesian logistic regression model to some relevant state-of-the-art classification algorithms. Experimental results show that the Bayesian logistic regression model outperforms these linear classification algorithms and is a significantly better tool than the classical logistic regression model to compute the pseudometric weights and improve retrieval and classification performance. Finally, we perform a comparison with results obtained by other retrieval methods.	[Ksantini, Riadh; Ziou, Djemel] Univ Sherbrooke, Fac Sci, Dept Informat, Sherbrooke, PQ J1K 2R1, Canada; [Colin, Bernard; Dubeau, Francois] Univ Sherbrooke, Fac Sci, Dept Math, Sherbrooke, PQ J1K 2R1, Canada	University of Sherbrooke; University of Sherbrooke	Ksantini, R (corresponding author), Univ Sherbrooke, Fac Sci, Dept Informat, 2500 Bl, Sherbrooke, PQ J1K 2R1, Canada.	riadh.ksantini@usherbrooke.ca; djemel.ziou@usherbrooke.ca; bernard.colin@usherbrooke.ca; francois.dubeau@usherbrooke.ca						Aksoy S, 2001, PATTERN RECOGN LETT, V22, P563, DOI 10.1016/S0167-8655(00)00112-4; Aksoy S, 2000, INT C PATT RECOG, P812, DOI 10.1109/ICPR.2000.903041; ALBERT A, 1984, BIOMETRIKA, V71, P1; Bazaraa M.S., 1979, NONLINEAR PROGRAMMIN; Bhanu B, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P14, DOI 10.1109/IVL.1998.694471; Breiman L., 1996, BIAS VARIANCE ARCING; Caenen G, 2002, PROC SPIE, V4676, P49; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; CLOGG CC, 1991, J AM STAT ASSOC, V86, P68, DOI 10.2307/2289716; Congdon P., 2001, BAYESIAN STAT MODELL; CRAMER JS, 1986, EC APPL MAXIMUM LIKE; Cristianini M., 2000, INTRO SUPPORT VECTOR; Daubechies I., 1992, 10 LECT WAVELETS, DOI [10.1137/1.9781611970104.ch1, DOI 10.1137/1.9781611970104.CH1]; Deselaers T, 2004, INT C PATT RECOG, P505, DOI 10.1109/ICPR.2004.1334280; Domeniconi C, 2005, IEEE T NEURAL NETWOR, V16, P899, DOI 10.1109/TNN.2005.849821; Fergus R, 2003, PROC CVPR IEEE, P264; Freund RJ, 1979, REGRESSION METHODS T; GALINDOGARRE F, 2004, SOCIOLOGICAL METHODS, V33, P1; Gerlach R, 2002, AUST NZ J STAT, V44, P155, DOI 10.1111/1467-842X.00218; Ghebreab S, 2004, IEEE T MED IMAGING, V23, P676, DOI 10.1109/TMI.2004.826942; GILL PE, 1989, PRACTICAL OPTIMIZATI; GLOBERSON A, 2006, ADV NEURAL INFORM PR, V18, P451; GOLDBERGER J, 2005, P ADV NEUR INF PROC, P513; Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; Hosmer DW, 1989, APPL LOGISTIC REGRES; Jaakkola TS, 2000, STAT COMPUT, V10, P25, DOI 10.1023/A:1008932416310; Kherfi ML, 2006, IEEE T IMAGE PROCESS, V15, P1017, DOI 10.1109/TIP.2005.863969; Klautau A., 2003, P 20 INT C MACH LEAR, P353; KOMAREK P, 2004, THESIS SCH COMP SCI; KOOP G, 1995, J ROY STAT SOC A STA, V158, P123, DOI 10.2307/2983407; Ksantini R, 2006, INT J WAVELETS MULTI, V4, P147, DOI 10.1142/S0219691306001142; LAVRENKO V, 2003, P IEEE INT C AC SPEE, V3, P17; Lawrence N., 2003, P 16 ANN C NEURAL IN, P609; Long J.Scott., 1997, REGRESSION MODELS CA; MURTHY HA, 1987, IEEE J OCEANIC ENG, V12, P493, DOI 10.1109/JOE.1987.1145277; Perme MP., 2004, METODOLO KIZVEZKI, V1, P143; Roberts SJ, 1998, IEEE T PATTERN ANAL, V20, P1133, DOI 10.1109/34.730550; Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413; Shao H, 2003, LECT NOTES COMPUT SC, V2728, P71; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236; Vasconcelos N, 2004, IEEE T SIGNAL PROCES, V52, P2322, DOI 10.1109/TSP.2004.831125; Vasconcelos N, 2004, IEEE T INFORM THEORY, V50, P1482, DOI 10.1109/TIT.2004.830760; Wang S., 2004, INT J FUZZY SYST, V6, P147; Weinberger Kilian Q, 2006, ADV NEURAL INFORM PR, P1473, DOI DOI 10.1007/978-3-319-13168-9_; Weiss R, 1999, SOCIOL METHOD RES, V28, P91, DOI 10.1177/0049124199028001005; Westerveld T, 2005, IEE P-VIS IMAGE SIGN, V152, P852, DOI 10.1049/ip-vis:20045196; Xing E., 2002, ADV NEURAL INFORM PR, V15, P505, DOI DOI 10.5555/2968618.2968683; Yiu ML, 2005, IEEE T KNOWL DATA EN, V17, P176, DOI 10.1109/TKDE.2005.29	51	17	17	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2008	30	2					253	266		10.1109/TPAMI.2007.1165	http://dx.doi.org/10.1109/TPAMI.2007.1165			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	240IC	18084057				2022-12-18	WOS:000251580300005
J	Goldlucke, B; Ihrke, I; Linz, C; Magnor, M				Goldluecke, Bastian; Ihrke, Ivo; Linz, Christian; Magnor, Marcus			Weighted minimal hypersurface reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						weighted minimal hypersurfaces; tomography; reconstruction; Euler-Lagrange formulation	EVOLUTION; SURFACES	Many problems in computer vision can be formulated as a minimization problem for an energy functional. If this functional is given as an integral of a scalar-valued weight function over an unknown hypersurface, then the sought-after minimal surface can be determined as a solution of the functional's Euler-Lagrange equation. This paper deals with a general class of weight functions that may depend on surface point coordinates as well as surface orientation. We derive the Euler-Lagrange equation in arbitrary dimensional space without the need for any surface parameterization, generalizing existing proofs. Our work opens up the possibility of solving problems involving minimal hypersurfaces in a dimension higher than three, which were previously impossible to solve in practice. We also introduce two applications of our new framework: We show how to reconstruct temporally coherent geometry from multiple video streams, and we use the same framework for the volumetric reconstruction of refractive and transparent natural phenomena, here bodies of flowing water.	Max Planck Inst Informat, D-66123 Saarbrucken, Germany; Tech Univ Carolo Wilhelmina Braunschweig, Comp Graph Lab, D-38106 Braunschweig, Germany	Max Planck Society; Braunschweig University of Technology	Goldlucke, B (corresponding author), Max Planck Inst Informat, Stuhlsatzenhausweg 85, D-66123 Saarbrucken, Germany.	bg@mpii.de; ihrke@mpii.de; linz@cg.cs.tu-bs.de; magnor@cg.cs.tu-bs.de						AHRENBERG L, 2005, P INT WORKSH VOL GRA; Caselles V, 1997, IEEE T PATTERN ANAL, V19, P394, DOI 10.1109/34.588023; CASELLES V, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P694, DOI 10.1109/ICCV.1995.466871; CASELLES V, 1996, P EUR C COMP VIS APR, V1, P97; CHEN YG, 1991, J DIFFER GEOM, V33, P749; CHOPP DL, 1993, J COMPUT PHYS, V106, P77, DOI 10.1006/jcph.1993.1092; CLELLAND J, 1999, MSRI WORKSH LIE GROU; Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183; Goldluecke B, 2004, PROC CVPR IEEE, P350; GOLDLUECKE B, 2004, P ECCV 2 MAY, P366; Hasinoff SW, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1184; Ihrke I., 2004, P ACM SIGGRAPH EUR S, P367; Ihrke N, 2005, IEEE I CONF COMP VIS, P1055; Jin HL, 2003, PROC CVPR IEEE, P171; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kutulakos KN, 2005, IEEE I CONF COMP VIS, P1448; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; Matusik W, 2000, COMP GRAPH, P369, DOI 10.1145/344779.344951; Morris NJW, 2005, IEEE I CONF COMP VIS, P1573; MURASE H, 1992, IEEE T PATTERN ANAL, V14, P1045, DOI 10.1109/34.159906; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758; Pintaviroj C., 2004, J WSCG, V12, P333; SCHULTZ H, 1994, IEEE T PATTERN ANAL, V16, P195, DOI 10.1109/34.273732; Sethian J. A., 1999, LEVEL SET METHODS FA; Sharpe R. W., 1997, DIFFERENTIAL GEOMETR, V166; Zhao HK, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P194, DOI 10.1109/VLSM.2001.938900; Zvyagin AV, 2003, OPT EXPRESS, V11, P3503, DOI 10.1364/OE.11.003503	29	17	20	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2007	29	7					1194	1208		10.1109/TPAMI.2007.1146	http://dx.doi.org/10.1109/TPAMI.2007.1146			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	166QW	17496377				2022-12-18	WOS:000246395300007
J	Nopsuwanchai, R; Biem, A; Clocksin, WF				Nopsuwanchai, Roongroj; Biem, Alain; Clocksin, William F.			Maximization of mutual information for offline Thai handwriting recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						character recognition; hidden Markov model; discriminative training; PCA; feature extraction; Thai handwriting recognition	HIDDEN MARKOV-MODELS	This paper aims to improve the performance of an HMM- based offline Thai handwriting recognition system through discriminative training and the use of fine- tuned feature extraction methods. The discriminative training is implemented by maximizing the mutual information between the data and their classes. The feature extraction is based on our proposed block- based PCA and composite images, shown to be better at discriminating Thai confusable characters. We demonstrate significant improvements in recognition accuracies compared to the classifiers that are not discriminatively optimized.	Asahi Kasei Corp, Informat Technol Lab, Kanagawa 2430021, Japan; IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA; Oxford Brookes Univ, Dept Comp, Oxford OX33 1HX, England	Asahi Kasei Corporation; International Business Machines (IBM); Oxford Brookes University	Nopsuwanchai, R (corresponding author), Asahi Kasei Corp, Informat Technol Lab, AXT Maintower 22F,3050 Okada, Kanagawa 2430021, Japan.	roongroj@cantab.net; biem@us.ibm.com; wfc@brookes.ac.uk						Airphaiboon S, 1996, IEICE T INF SYST, VE79D, P1296; Biem AE, 2001, INT CONF ACOUST SPEE, P1529, DOI 10.1109/ICASSP.2001.941223; GEIST J, 1994, 2 CENS OPT CHAR REC; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Mitrpanont JL, 2002, LECT NOTES ARTIF INT, V2358, P536; NISHIMURA H, 1999, P 5 INT C DOC AN REC, V1, P49; Nopsuwanchai R, 2003, PROC INT CONF DOC, P114; NOPSUWANCHAI R, 2004, THESIS U CAMBRIDGE; PHOKHARATKUL P, 2000, P 4 S NAT LANG PROC, P108; POVEY D, 2004, THESIS U CAMBRIDGE; Quan VH, 2001, PROC INT CONF DOC, P627, DOI 10.1109/ICDAR.2001.953865; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; SCHLUTER R, 2000, THESIS RWTH AACHEN G; Woodland PC, 2002, COMPUT SPEECH LANG, V16, P25, DOI 10.1006/csla.2001.0182; Young J, 2002, AGRO FOOD IND HI TEC, V13, P2	15	17	17	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2006	28	8					1347	1351		10.1109/TPAMI.2006.167	http://dx.doi.org/10.1109/TPAMI.2006.167			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	051LK	16886869				2022-12-18	WOS:000238162400015
J	Pham, TV; Smeulders, AWM				Pham, TV; Smeulders, AWM			Sparse representation for coarse and fine object recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						B-spline; Gaussian derivatives; matching pursuit; multiscale; PCA; polynomial approximation; sparse representation	SUPPORT; FILTERS	This paper offers a sparse, multiscale representation of objects. It captures the object appearance by selection from a very large dictionary of Gaussian differential basis functions. The learning procedure results from the matching pursuit algorithm, while the recognition is based on polynomial approximation to the bases, turning image matching into a problem of polynomial evaluation. The method is suited for coarse recognition between objects and, by adding more bases, also for fine recognition of the object pose. The advantages over the common representation using PCA include storing sampled points for recognition is not required, adding new objects to an existing data set is trivial because retraining other object models is not needed, and significantly in the important case where one has to scan an image over multiple locations in search for an object, the new representation is readily available as opposed to PCA projection at each location. The experimental result on the COIL-100 data set demonstrates high recognition accuracy with real-time performance.	Univ Amsterdam, Fac Sci, NL-1098 SJ Amsterdam, Netherlands	University of Amsterdam	Pham, TV (corresponding author), Univ Amsterdam, Fac Sci, Kruislaan 403, NL-1098 SJ Amsterdam, Netherlands.	vitep@science.uva.nl; smeulders@science.uva.nl						Bengio Y, 2004, ADV NEURAL INFORM PR, V16; BUHLMANN P, 2001, J AM STAT ASSOC, V98, P324; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Geusebroek JM, 2003, IEEE T IMAGE PROCESS, V12, P938, DOI 10.1109/TIP.2003.812429; Girosi F, 1998, NEURAL COMPUT, V10, P1455, DOI 10.1162/089976698300017269; Knuth D E, 1997, ART COMPUTER PROGRAM, V2; KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371; Liu XW, 2004, IEEE T PATTERN ANAL, V26, P662, DOI 10.1109/TPAMI.2004.1273986; Mallat S., 1999, WAVELET TOUR SIGNAL, DOI 10.1016/B978-012466606-1/50008-8; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Mukherjee S, 1996, PATTERN RECOGN, V29, P1369, DOI 10.1016/0031-3203(95)00164-6; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Nene A. S., 1996, CUCS00696; Phillips PJ, 1998, IEEE T IMAGE PROCESS, V7, P1150, DOI 10.1109/83.704308; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0; Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777; Roth D, 2002, NEURAL COMPUT, V14, P1071, DOI 10.1162/089976602753633394; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Schaffalitzky F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P636, DOI 10.1109/ICCV.2001.937686; Schapire RE, 1998, ANN STAT, V26, P1651; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Smola AJ, 1998, ADV NEUR IN, V10, P343; Tax DMJ, 1999, PATTERN RECOGN LETT, V20, P1191, DOI 10.1016/S0167-8655(99)00087-2; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P834, DOI 10.1109/78.193221; UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P821, DOI 10.1109/78.193220; van Vliet LJ, 1998, INT C PATT RECOG, P509, DOI 10.1109/ICPR.1998.711192; Vapnik V.N, 1998, STAT LEARNING THEORY; VASCONCELOS N, 2004, P 8 EUR C COMP VIS, V3, P430; Vincent P, 2002, MACH LEARN, V48, P165, DOI 10.1023/A:1013955821559; WELLS WM, 1986, IEEE T PATTERN ANAL, V8, P234, DOI 10.1109/TPAMI.1986.4767776	37	17	18	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2006	28	4					555	567		10.1109/TPAMI.2006.84	http://dx.doi.org/10.1109/TPAMI.2006.84			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	011FK	16566505				2022-12-18	WOS:000235253300006
J	Yildiz, OT; Alpaydin, E				Yildiz, OT; Alpaydin, E			Ordering and finding the best of K > 2 supervised learning algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						machine learning; classifier design and evaluation; experimental design	CLASSIFICATION	Given a data set and a number of supervised learning algorithms, we would like to find the algorithm with the smallest expected error. Existing pairwise tests allow a comparison of two algorithms only; range tests and ANOVA check whether multiple algorithms have the same expected error and cannot be used for finding the smallest. We propose a methodology, the MultiTest algorithm, whereby we order supervised learning algorithms taking into account 1) the result of pairwise statistical tests on expected error (what the data tells us), and 2) our prior preferences, e. g., due to complexity. We define the problem in graph-theoretic terms and propose an algorithm to find the '' best '' learning algorithm in terms of these two criteria, or in the more general case, order learning algorithms in terms of their '' goodness.'' Simulation results using five classification algorithms on 30 data sets indicate the utility of the method. Our proposed method can be generalized to regression and other loss functions by using a suitable pairwise test.	Bogazici Univ, Dept Comp Engn, TR-34342 Istanbul, Turkey	Bogazici University	Yildiz, OT (corresponding author), Bogazici Univ, Dept Comp Engn, TR-34342 Istanbul, Turkey.	yildizol@cmpe.boun.edu.tr; alpaydin@boun.edu.tr	ALPAYDIN, ETHEM/E-6127-2013; Yildiz, Olcay Taner/ABE-5268-2021; YILDIZ, OLCAY/K-3869-2012	ALPAYDIN, ETHEM/0000-0001-7506-0321; Yildiz, Olcay Taner/0000-0001-5838-4615; 				Alpaydin E, 1999, NEURAL COMPUT, V11, P1885, DOI 10.1162/089976699300016007; Alpaydin E., 2004, INTRO MACHINE LEARNI; Alsing SG, 2002, PATTERN RECOGN, V35, P2397, DOI 10.1016/S0031-3203(01)00192-3; Blake C, 2000, UCI REPOSITORY MACHI; Bouckaert R.R., 2003, ICML, V3; Conover W. J, 1999, PRACTICAL NONPARAMET, V350; Dean A., 2017, DESIGN ANAL EXPT, DOI [10.1007/978-3-319-52250-0, DOI 10.1007/978-3-319-52250-0]; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; EFRON B, 1979, SIAM REV, V21, P460, DOI 10.1137/1021092; Everitt B.S., 1977, ANAL CONTINGENCY TAB; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; Hochberg Y, 1987, MULTIPLE COMPARISON; HOLM S, 1979, SCAND J STAT, V6, P65; Jensen DD, 2000, MACH LEARN, V38, P309, DOI 10.1023/A:1007631014630; LOONEY SW, 1988, PATTERN RECOGN LETT, V8, P5, DOI 10.1016/0167-8655(88)90016-5; Miller RG., 1981, SIMULTANEOUS STAT IN, P1, DOI [10.1007/978-1-4613-8122-8_1, DOI 10.1007/978-1-4613-8122-8]; Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854; PROVOST F, 1998, P 15 INT C MACH LEAR; Quinlan J., 2014, C4 5 PROGRAMS MACHIN, DOI DOI 10.1007/BF00993309; ROSEN KH, 1995, MATH ITS APPL; Ross S.M, 2004, INTRO PROBABILITY ST; Turney P., 2000, WORKSH COST SENS LEA, P15; YILDIZ OT, 2005, THESIS BOGAZICI U	23	17	17	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2006	28	3					392	402		10.1109/TPAMI.2006.61	http://dx.doi.org/10.1109/TPAMI.2006.61			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	001FB	16526425				2022-12-18	WOS:000234517900005
J	Furukawa, Y; Sethi, A; Ponce, J; Kriegman, DJ				Furukawa, Y; Sethi, A; Ponce, J; Kriegman, DJ			Robust structure and motion from outlines of smooth curved surfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						image processing and computer vision; motion; shape	FACTORIZATION METHOD; OCCLUDING CONTOURS; APPARENT CONTOURS; 3D OBJECTS; SHAPE; SILHOUETTES; DEFORMATION; RECOVERY; AFFINE	This paper addresses the problem of estimating the motion of a camera as it observes the outline ( or apparent contour) of a solid bounded by a smooth surface in successive image frames. In this context, the surface points that project onto the outline of an object depend on the viewpoint and the only true correspondences between two outlines of the same object are the projections of frontier points where the viewing rays intersect in the tangent plane of the surface. In turn, the epipolar geometry is easily estimated once these correspondences have been identified. Given the apparent contours detected in an image sequence, a robust procedure based on RANSAC and a voting strategy is proposed to simultaneously estimate the camera configurations and a consistent set of frontier point projections by enforcing the redundancy of multiview epipolar geometry. The proposed approach is, in principle, applicable to orthographic, weak-perspective, and affine projection models. Experiments with nine real image sequences are presented for the orthographic projection case, including a quantitative comparison with the ground-truth data for the six data sets for which the latter information is available. Sample visual hulls have been computed from all image sequences for qualitative evaluation.	Univ Illinois, Beckman Inst, Urbana, IL 61801 USA; Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA	University of Illinois System; University of Illinois Urbana-Champaign; University of California System; University of California San Diego	Furukawa, Y (corresponding author), Univ Illinois, Beckman Inst, 405 N Mathews Ave, Urbana, IL 61801 USA.	yfurukaw@uiuc.edu; asethi@uiuc.edu; ponce@cs.uiuc.edu; kriegman@cs.ucsd.edu		Sethi, Amit/0000-0002-8634-1804				AHUJA N, 1989, IEEE T PATTERN ANAL, V11, P137, DOI 10.1109/34.16710; Astrom K, 1999, IEEE T PATTERN ANAL, V21, P114, DOI 10.1109/34.748821; Baumgart B.G., 1974, THESIS STANFORD U; Birchfield S., 1998, KLT IMPLEMENTATION K; Boyer E, 1997, INT J COMPUT VISION, V22, P219, DOI 10.1023/A:1007978616082; CIPOLLA R, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P269, DOI 10.1109/ICCV.1995.466775; CIPOLLA R, 1992, INT J COMPUT VISION, V9, P83, DOI 10.1007/BF00129682; CONNOLLY CI, 1989, P IEEE WORKSHOP INTE, P124; FAUGERAS O, 1995, J OPT SOC AM A, V12, P465, DOI 10.1364/JOSAA.12.000465; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Forsyth DA, 2002, PRENT HALL PROF TECH; FURUKAWA Y, 2004, P EUR C COMP VIS, P287; Giblin P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P136; GIBLIN P, 1994, J OPT SOC AM, P1976; GIBLIN PJ, 1995, IMAGE VISION COMPUT, V13, P33, DOI 10.1016/0262-8856(95)91466-Q; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; JOSHI T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P290, DOI 10.1109/ICCV.1995.466927; KOENDERINK JJ, 1984, PERCEPTION, V13, P321, DOI 10.1068/p130321; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; LAURENTINI A, 1995, IEEE T PATTERN ANAL, V17, P188, DOI 10.1109/34.368170; Lazebnik S, 2001, PROC CVPR IEEE, P156; LAZEBNIK S, 2002, THESIS U ILLINOIS UR; Levi N, 2003, PROC CVPR IEEE, P518; MATUSIK W, 2001, P SIGGRAPH; MENDONCA P, 2000, P EUR C COMP VIS, P864; Poelman CJ, 1997, IEEE T PATTERN ANAL, V19, P206, DOI 10.1109/34.584098; Sethi A, 2004, INT J COMPUT VISION, V58, P73, DOI 10.1023/B:VISI.0000016148.08046.fc; Sullivan S, 1998, IEEE T PATTERN ANAL, V20, P1091, DOI 10.1109/34.722621; Szeliski R, 1998, INT J COMPUT VISION, V28, P27, DOI 10.1023/A:1008050630628; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; TORR PHS, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1037, DOI 10.1109/ICCV.1995.466820; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; VAILLANT R, 1992, IEEE T PATTERN ANAL, V14, P157, DOI 10.1109/34.121787; Vijayakumar B, 1996, PROC CVPR IEEE, P327, DOI 10.1109/CVPR.1996.517093; WANG Y, 2001, P IEEE INT C IM PROC; Wong KYK, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P217, DOI 10.1109/ICCV.2001.937627; Yezzi AJ, 2003, PROC CVPR IEEE, P525	39	17	17	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2006	28	2					302	315		10.1109/TPAMI.2006.41	http://dx.doi.org/10.1109/TPAMI.2006.41			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	991OY	16468625				2022-12-18	WOS:000233824500011
J	Mazzaro, MC; Sznaier, M; Camps, O				Mazzaro, MC; Sznaier, M; Camps, O			A model (in) validation approach to gait classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						gait classification; activity recognition; model (in) validation; risk-adjusted (in) validation	HUMAN MOVEMENT; RECOGNITION	This paper addresses the problem of human gait classification from a robust model (in)validation perspective. The main idea is to associate to each class of gaits a nominal model, subject to bounded uncertainty and measurement noise. In this context, the problem of recognizing an activity from a sequence of frames can be formulated as the problem of determining whether this sequence could have been generated by a given (model, uncertainty, and noise) triple. By exploiting interpolation theory, this problem can be recast into a nonconvex optimization. In order to efficiently solve it, we propose two convex relaxations, one deterministic and one stochastic. As we illustrate experimentally, these relaxations achieve over 83 percent and 86 percent success rates, respectively, even in the face of noisy data.	GE Global Res, Niskayuna, NY 12309 USA; Penn State Univ, Dept Elect Engn, University Pk, PA 16802 USA	General Electric; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park	Mazzaro, MC (corresponding author), GE Global Res, Niskayuna, NY 12309 USA.	mazzaro@research.ge.com; msznaier@frodo.ee.psu.edu; camps@psu.edu						Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744; Bissacco A, 2001, PROC CVPR IEEE, P52; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; BOYD S, 1994, SIAM STUDIES APPL MA, V15; Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450; Bregler C, 1997, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.1997.609382; Chen J., 2000, CONTROL ORIENTED SYS; Cunado D, 2003, COMPUT VIS IMAGE UND, V90, P1, DOI [10.1016/S1077-3142(03)00008-0, 10.1010/SI077-3142(03)00008-0]; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; Giese MA, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P27, DOI 10.1109/VS.2000.856855; Hoey J, 2000, PROC CVPR IEEE, P752, DOI 10.1109/CVPR.2000.855896; Huang PS, 2001, IEEE T SYST MAN CY B, V31, P818, DOI 10.1109/3477.956044; Khargonekar P, 1996, IEEE DECIS CONTR P, P3470, DOI 10.1109/CDC.1996.573700; Madabhushi A, 1999, SECOND IEEE WORKSHOP ON VISUAL SURVEILLANCE (VS'99), PROCEEDINGS, P25, DOI 10.1109/VS.1999.780265; Martin RJ, 2000, IEEE T SIGNAL PROCES, V48, P1164, DOI 10.1109/78.827549; Minnen D, 2003, PROC CVPR IEEE, P626; Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897; North B, 2000, IEEE T PATTERN ANAL, V22, P1016, DOI 10.1109/34.877523; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Plankers R, 2003, IEEE T PATTERN ANAL, V25, P1182, DOI 10.1109/TPAMI.2003.1227995; Sznaier M, 2005, IEEE T AUTOMAT CONTR, V50, P410, DOI 10.1109/TAC.2005.843852; Tuan H. D., 1999, Proceedings of the 38th IEEE Conference on Decision and Control (Cat. No.99CH36304), P1001, DOI 10.1109/CDC.1999.832925; VANOVERSCHEE P, 1993, AUTOMATICA, V29, P649, DOI 10.1016/0005-1098(93)90061-W; Yacoob Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P120, DOI 10.1109/ICCV.1998.710709	24	17	17	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2005	27	11					1820	1825		10.1109/TPAMI.2005.210	http://dx.doi.org/10.1109/TPAMI.2005.210			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	963SN	16285379				2022-12-18	WOS:000231826300011
J	Nishino, K; Nayar, SK; Jebara, T				Nishino, K; Nayar, SK; Jebara, T			Clustered blockwise PCA for representing visual data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						principal component analysis; singular value decomposition; eigenvalues and eigenvectors; natural image statistics; clustering; region growing/partitioning	ALGORITHM; IMAGES	Principal Component Analysis (PCA) is extensively used in computer vision and image processing. Since it provides the optimal linear subspace in a least-square sense, it has been used for dimensionality reduction and subspace analysis in various domains. However, its scalability is very limited because of its inherent computational complexity. We introduce a new framework for applying PCA to visual data which takes advantage of the spatio-temporal correlation and localized frequency variations that are typically found in such data. Instead of applying PCA to the whole volume of data (complete set of images), we partition the volume into a set of blocks and apply PCA to each block. Then, we group the subspaces corresponding to the blocks and merge them together. As a result, we not only achieve greater efficiency in the resulting representation of the visual data, but also successfully scale PCA to handle large data sets. We present a thorough analysis of the computational complexity and storage benefits of our approach. We apply our algorithm to several types of videos. We show that, in addition to its storage and speed benefits, the algorithm results in a useful representation of the visual data.	Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Columbia University	Nishino, K (corresponding author), Columbia Univ, Dept Comp Sci, MC 0401,1214 Amsterdam Ave, New York, NY 10027 USA.	kon@cs.columbia.edu; nayar@cs.columbia.edu; jebara@cs.columbia.edu						AVIDAN S, 2002, P EUR C COMP VIS, V3, P747; Bishop CM, 1999, ADV NEUR IN, V11, P382; BUNCH JR, 1978, NUMER MATH, V31, P111, DOI 10.1007/BF01397471; Chandrasekaran S, 1997, GRAPH MODEL IM PROC, V59, P321, DOI 10.1006/gmip.1997.0425; CHUNG FRK, 1997, SPECTRAL GRAPH TEHOR; Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Golub G. H., 1996, MATRIX COMPUTATION; GU M, 1994, SIAM J MATRIX ANAL A, V15, P1266, DOI 10.1137/S089547989223924X; Hall P, 2000, IEEE T PATTERN ANAL, V22, P1042, DOI 10.1109/34.877525; HALLINAN PW, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P995, DOI 10.1109/CVPR.1994.323941; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Jebara T, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P128, DOI 10.1109/ICCV.1998.710710; JOLLIFFE IT, 1986, PRINCIPA COMPONENT A; Leonardis A, 2002, PATTERN RECOGN, V35, P2613, DOI 10.1016/S0031-3203(01)00198-4; LEVIN A, 2002, P EUR C COMP VIS, V3, P635; Lin ZC, 2002, INT J COMPUT VISION, V49, P229, DOI 10.1023/A:1020153824351; Matusik W, 2002, ACM T GRAPHIC, V21, P427, DOI 10.1145/566570.566599; MOGHADDAM B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P786, DOI 10.1109/ICCV.1995.466858; MURAKAMI H, 1982, IEEE T PATTERN ANAL, V4, P511, DOI 10.1109/TPAMI.1982.4767295; MURASE H, 1995, IEEE T IMAGE PROCESS, V4, P620, DOI 10.1109/83.382496; Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720; Shashua A, 1997, INT J COMPUT VISION, V21, P99, DOI 10.1023/A:1007975506780; Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193; SIROVICH L, 1987, Q APPL MATH, V45, P561, DOI 10.1090/qam/910462; Stewart G., 1990, MATRIX PERTURBATION; ZHAO L, 1997, PATTERN RECOGN, V32, P1421	27	17	17	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2005	27	10					1675	1679		10.1109/TPAMI.2005.193	http://dx.doi.org/10.1109/TPAMI.2005.193			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	953OM	16238002	Green Submitted			2022-12-18	WOS:000231086700015
J	Tong, WS; Tang, CK; Medioni, G				Tong, WS; Tang, CK; Medioni, G			Simultaneous two-view epipolar geometry estimation and motion segmentation by 4D tensor voting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						epipolar geometry; motion segmentation; nonstatic scene; robust estimation; higher dimensional inference		We address the problem of simultaneous two-view epipolar geometry estimation and motion segmentation from nonstatic scenes. Given a set of noisy image pairs containing matches of n objects, we propose an unconventional, efficient, and robust method, 4D tensor voting, for estimating the unknown n epipolar geometries, and segmenting the static and motion matching pairs into n independent motions. By considering the 4D isotropic and orthogonal joint image space, only two tensor voting passes are needed, and a very high noise to signal ratio (up to five) can be tolerated. Epipolar geometries corresponding to multiple, rigid motions are extracted in succession. Only two uncalibrated frames are needed, and no simplifying assumption (such as affine camera model or homographic model between images) other than the pin-hole camera model is made. Our novel approach consists of propagating a local geometric smoothness constraint in the 4D joint image space, followed by global consistency enforcement for extracting the fundamental matrices corresponding to independent motions. We have performed extensive experiments to compare our method with some representative algorithms to show that better performance on nonstatic scenes are achieved. Results on challenging data sets are presented.	Hong Kong Univ Sci & Technol, Dept Comp Sci, Clear Water Bay, Hong Kong, Peoples R China; Univ So Calif, Inst Robot & Intelligent Syst, PHE 204, Los Angeles, CA 90083 USA	Hong Kong University of Science & Technology; University of Southern California	Tong, WS (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci, Clear Water Bay, Hong Kong, Peoples R China.	cstws@cs.ust.hk; cktang@cs.ust.hk; medioni@iris.usc.edu						Adam A, 2001, IEEE T PATTERN ANAL, V23, P78, DOI 10.1109/34.899948; ANANDAN P, 2000, P EUR C COMP VIS; ARMANGUE X, 2001, P 9 S NAC REC FORM A, P227; BALLARD DH, 1984, ARTIF INTELL, V22, P235, DOI 10.1016/0004-3702(84)90052-3; Davis J, 1998, PROC CVPR IEEE, P354, DOI 10.1109/CVPR.1998.698630; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Luong QT, 1996, INT J COMPUT VISION, V17, P43, DOI 10.1007/BF00127818; Medioni G., 2000, COMPUTATIONAL FRAMEW; Nicolescu M, 2002, INT C PATT RECOG, P303, DOI 10.1109/ICPR.2002.1047854; NICOLESCU M, 2002, P EUR C COMP VIS, V3, P423; Pritchett P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P754, DOI 10.1109/ICCV.1998.710802; Semple J.G, 1952, ALGEBRAIC PROJECTIVE; Sturm R., 1869, MATH ANN, V1, P533; Tang CK, 2001, IEEE T PATTERN ANAL, V23, P829, DOI 10.1109/34.946987; Tong WS, 2001, PROC CVPR IEEE, P926; TONG WS, 2001, THESIS HONG KONG U; Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552; TORR PHS, 1993, IMAGE VISION COMPUTI, V1; VIDAL R, 2001, P INT C COMP VIS, V1, P34; Wolf L, 2001, PROC CVPR IEEE, P263; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561	24	17	18	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2004	26	9					1167	1184		10.1109/TPAMI.2004.72	http://dx.doi.org/10.1109/TPAMI.2004.72			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	837CM	15742892				2022-12-18	WOS:000222605100006
J	Bao, YF; Krim, H				Bao, YF; Krim, H			Smart nonlinear diffusion: A probabilistic approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nonlinear diffusion; stochastic flow; particle system	ANISOTROPIC DIFFUSION; EDGE-DETECTION; IMAGE; RESTORATION; RELAXATION	In this paper, a stochastic interpretation of nonlinear diffusion equations used for image filtering is proposed. This is achieved by relating the problem of evolving/smoothing images to that of tracking the transition probability density functions of an underlying random process. We show that such an interpretation of, e.g., Perona-Malik equation, in turn allows additional insight and sufficient flexibility to further investigate some outstanding problems of nonlinear diffusion techniques. In particular, upon unraveling the limitations as well as the advantages of such an equation, we are able to propose a new approach which is demonstrated to improve performance over existing approaches and, more importantly, to lift the longstanding problem of a stopping criterion for a nonlinear evolution equation with no data term constraint. Substantiating examples in image enhancement and segmentation are provided.	Univ Miami, Sch Med, Dept Radiol, Miami, FL 33101 USA; N Carolina State Univ, Dept Elect & Comp Engn, Raleigh, NC 27695 USA	University of Miami; University of North Carolina; North Carolina State University	Bao, YF (corresponding author), Univ Miami, Sch Med, Dept Radiol, Miami, FL 33101 USA.	ybao2@med.miami.edu; ahk@eos.ncsu.edu						ALVAREZ J, 1992, J ASTHMA, V29, P3, DOI 10.3109/02770909209110635; ALVAREZ L, 1993, ARCH RATION MECH AN, V123, P199, DOI 10.1007/BF00375127; BAO Y, 2001, WAVELETS SIGNAL IMAG, V19, pCH6; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; Boccignone G, 2002, IEEE T PATTERN ANAL, V24, P1298, DOI 10.1109/TPAMI.2002.1039202; CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012; DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425; DURRETT R, 1997, STOCHASTIC CALCULUS; GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Hamza AB, 2002, IEEE SIGNAL PROC MAG, V19, P37, DOI 10.1109/MSP.2002.1028351; HUBER PJ, 1965, ANN MATH STAT, V36, P1753, DOI 10.1214/aoms/1177699803; KOENDRINK JJ, 1987, BIOL CYBERN, V50, P363; Krim H, 1999, INT CONF ACOUST SPEE, P1773, DOI 10.1109/ICASSP.1999.758263; KRIM H, 1995, STAT BEST BASES CRIT, P193; KRIM H, 1999, P IEEE INT C IM PROC, V2, P21; KUNITA H, 1978, LECT NOTES MATH, V1097, P143; KUNITA H, 1976, STOCHASTIC FLOWS STO; Kushner H.J., 1992, NUMERICAL METHODS ST; Mallat S., 1999, WAVELET TOUR SIGNAL; MALLAT S, 1989, IEEE T PATTERN ANAL, V11, P7; Miller MI, 1997, IEEE T IMAGE PROCESS, V6, P157, DOI 10.1109/83.552104; Monteil J, 1999, IEEE T PATTERN ANAL, V21, P940, DOI 10.1109/34.790435; Mumford D., 1994, ALGEBRAIC GEOMETRY I, V5681, P491, DOI DOI 10.1007/978-1-4612-2628-4_31; NORDSTROM KN, 1990, IMAGE VISION COMPUT, V8, P318, DOI 10.1016/0262-8856(90)80008-H; Oksendal B., 1992, STOCHASTIC DIFFERENT, V3rd; Papoulis A., 2002, PROBABILITY RANDOM V; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; PERONA P, 1988, P IEEE INT S CIRC SY, P2565; Pollak I, 2000, IEEE T IMAGE PROCESS, V9, P256, DOI 10.1109/83.821738; ROMENEY BMT, 1994, GEOMETRY DRIVEN DIFF; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; SAPIRO G, 1993, INT J COMPUT VISION, V11, P25, DOI 10.1007/BF01420591; SNYDER W, 1995, IEEE T PATTERN ANAL, V17, P620, DOI 10.1109/34.387509; SRIVASTAVA A, 1999, JUMP DIFFUSION PROCE; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; You YL, 1996, IEEE T IMAGE PROCESS, V5, P1539, DOI 10.1109/83.541424; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]; Zhu SC, 1997, IEEE T PATTERN ANAL, V19, P1236, DOI 10.1109/34.632983	40	17	17	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2004	26	1					63	72		10.1109/TPAMI.2004.1261079	http://dx.doi.org/10.1109/TPAMI.2004.1261079			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	752LF	15382686				2022-12-18	WOS:000187161400005
J	DeCarlo, D; Metaxas, D				DeCarlo, D; Metaxas, D			Adjusting shape parameters using model-based optical flow residuals	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nonrigid shape and motion estimation; model-based optical flow; deformable models	MOTION ESTIMATION; IMAGE SEQUENCES; SCENE ANALYSIS; INTEGRATION	We present a method for estimating the shape of a deformable model using the least-squares residuals from a model-based optical flow computation. This method is built on top of an estimation framework using optical flow and image features, where optical flow affects only the motion parameters of the model. Using the results of this computation, our new method adjusts all of the parameters so that the residuals from the flow computation are minimized. We present face tracking experiments that demonstrate that this method obtains a better estimate of shape compared to related frameworks.	Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA; Rutgers State Univ, Ctr Cognit Sci, Piscataway, NJ 08854 USA; Rutgers State Univ, Div Comp & Informat Sci, Piscataway, NJ 08854 USA; Rutgers State Univ, Dept Bioengn, Piscataway, NJ 08854 USA	Rutgers State University New Brunswick; Rutgers State University New Brunswick; Rutgers State University New Brunswick; Rutgers State University New Brunswick	DeCarlo, D (corresponding author), Rutgers State Univ, Dept Comp Sci, 110 Frelinghuysen Rd, Piscataway, NJ 08854 USA.	decarlo@cs.rutgers.edu; dnm@cs.rutgers.edu						BARRON J, 1988, TR8824 RBCV; BERGEN JR, 1992, P EUR C COMP VIS, P237; BLACK MJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P374, DOI 10.1109/ICCV.1995.466915; Bryson A.E., 2018, APPL OPTIMAL CONTROL, P90, DOI 10.1201/9781315137667-3; Cassell J, 2000, COMMUN ACM, V43, P70, DOI 10.1145/332051.332075; COOTES TF, 1998, P EUR C COMP VIS, V2, P484; DeCarlo D, 2000, INT J COMPUT VISION, V38, P99, DOI 10.1023/A:1008122917811; DURRANTWHYTE HF, 1987, INT J ROBOT RES, V6, P3, DOI 10.1177/027836498700600301; Fua P, 2000, INT J COMPUT VISION, V38, P153, DOI 10.1023/A:1008105802790; Gill P., 1982, PRACTICAL OPTIMIZATI; HEINZMANN J, 1999, P INT S ROB RES ISRR; Horn B., 1986, ROBOT VISION, P1; HUANG TS, 1994, P IEEE, V82, P252, DOI 10.1109/5.265351; Jebara Tony, 1999, IEEE SIGNAL PROCESSI, V16; KOCH R, 1993, IEEE T PATTERN ANAL, V15, P556, DOI 10.1109/34.216725; LI HB, 1993, IEEE T PATTERN ANAL, V15, P545, DOI 10.1109/34.216724; MCKENDALL R, 1992, DATA FUSION ROBOTICS; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; MOSES Y, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P296, DOI 10.1109/ICCV.1995.466926; NEGAHDARIPOUR S, 1987, IEEE T PATTERN ANAL, V9, P168, DOI 10.1109/TPAMI.1987.4767884; Negahdaripour S, 1998, IEEE T PATTERN ANAL, V20, P961, DOI 10.1109/34.713362; NETRAVALI AN, 1985, AT&T TECH J, V64, P335, DOI 10.1002/j.1538-7305.1985.tb00436.x; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; REHG J, 1997, P COMP VIS PATT REC; REYNARD D, 1996, P EUR C COMP VIS, V1, P357; Strang G., 1988, LINEAR ALGEBRA APPL, V3rd; Tao H, 1999, IEEE T CIRC SYST VID, V9, P264, DOI 10.1109/76.752094; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; TERZOPOULOS D, 1993, IEEE T PATTERN ANAL, V15, P569, DOI 10.1109/34.216726	29	17	19	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2002	24	6					814	823		10.1109/TPAMI.2002.1008387	http://dx.doi.org/10.1109/TPAMI.2002.1008387			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	556JU					2022-12-18	WOS:000175846300009
J	Dickinson, S; Pelillo, M; Zabih, R				Dickinson, S; Pelillo, M; Zabih, R			Introduction to the special section on graph algorithms in computer vision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada; Univ Ca Foscari Venezia, Dipartimento Informat, I-30172 Venice, Italy; Cornell Univ, Dept Comp Sci, Ithaca, NY 14853 USA	University of Toronto; Universita Ca Foscari Venezia; Cornell University	Dickinson, S (corresponding author), Univ Toronto, Dept Comp Sci, 6 Kings Coll Rd, Toronto, ON M5S 3G4, Canada.			Zabih, Ramin/0000-0001-8769-5666				Biggs N. L., 1976, GRAPH THEORY; Euler L., 1736, COMMENTARII ACAD SCI, V8, P128	2	17	17	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2001	23	10					1049	1052		10.1109/TPAMI.2001.954597	http://dx.doi.org/10.1109/TPAMI.2001.954597			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	482QK		Green Submitted			2022-12-18	WOS:000171586600001
J	Favata, JT				Favata, JT			Offline general handwritten word recognition using an approximate BEAM matching algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						handwriting recognition; OCR; BEAM search; word segmentation; machine reading; pattern recognition	CHARACTER; SEGMENTATION; STRATEGIES	A recognition system for general isolated offline handwritten words using an approximate segment-string matching algorithm is described. The fundamental paradigm employed is a character-based segment-then-recognize/match strategy. Additional user supplied contextual information in the form of a lexicon guides a graph search to estimate the most likely word image identity. This system is designed to operate robustly in the presence of document noise, poor handwriting, and lexicon errors, so this basic strategy is significantly extended and enhanced. A preprocessing step is initially applied to the image to remove noise artifacts and normalize the handwriting. An oversegmentation approach is taken to improve the likelihood of capturing the individual characters embedded in the word. The goal is to produce a segmentation point set that contains one subset which is the correct segmentation of the word image. This is accomplished by a segmentation module, employing several independent detection rules based on certain key features, which finds the most likely segmentation points of the word. Next, a sliding window algorithm, using a character recognition algorithm with a very good noncharacter rejection response, is used to find the most likely character boundaries and identities. A directed graph is then constructed that contains many possible interpretations of the word image, many implausible. Contextual information is used at this point and the lexicon is matched to the graph in a breath-first manner, under an appropriate metric. The matching algorithm employs a BEAM search algorithm with several heuristics to compensate for the most likely errors contained in the interpretation graph, including missing segments from segmentation failures, misrecognition of the segments, and lexicon errors. The most likely graph path and associated confidence is computed for each lexicon word to produce a final lexicon ranking. These confidences are very reliable and can be later thresholded to decrease total recognition error. Experiments highlighting the characteristics of this algorithm are given.	SUNY Coll Buffalo, CIS, Buffalo, NY 14222 USA	State University of New York (SUNY) System; Buffalo State College	Favata, JT (corresponding author), SUNY Coll Buffalo, CIS, Chase Hall,Room 202,1300 Elmwood Ave, Buffalo, NY 14222 USA.							Amin A, 1997, PROC INT CONF DOC, P596, DOI 10.1109/ICDAR.1997.620572; Casey RG, 1996, IEEE T PATTERN ANAL, V18, P690, DOI 10.1109/34.506792; CHEN MY, 1994, IEEE T PATTERN ANAL, V16, P481; COHEN E, 1992, 9206 STAT U NEW YORK; Dunn CE, 1992, P 11 INT C PATT REC, V2, P577; FAVATA J, 1992, P SPIE IS T S EL IM; Favata J.T., 1994, P 4 INT WORKSH FRONT, P57; Favata JT, 1996, INT J IMAG SYST TECH, V7, P304, DOI 10.1002/(SICI)1098-1098(199624)7:4<304::AID-IMA5>3.0.CO;2-C; FAVATA JT, 1996, P INT WORKSH FRONT H, P171; Gader PD, 1997, IEEE T SYST MAN CY B, V27, P158, DOI 10.1109/3477.552199; GILLOUX M, 1995, MACH VISION APPL, V8, P197, DOI 10.1007/BF01219587; HAMMAMOTO Y, 1997, IEEE T PATTERN ANAL, V19; HASTIE T, 1996, IEEE T PATTERN ANAL, V18; Kim G, 1997, IEEE T PATTERN ANAL, V19, P366, DOI 10.1109/34.588017; KIM G, 1996, P 5 INT WORKSH FRONT, P221; KIMURA F, 1993, P 3 INT WORKSH FRONT, P122; MADHVANTH S, 1999, IEEE T PATTERN ANAL, V21; MDHVANTH S, 2001, IEEE T PATTERN ANAL, V23; Mohamed M, 1996, IEEE T PATTERN ANAL, V18, P548, DOI 10.1109/34.494644; Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448; Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821; TAPPERT CC, 1986, GRAPHONOMICS CONT RE; WINSTON PH, 1994, ARTIFICIAL INTELLIGE; [No title captured]	24	17	17	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2001	23	9					1009	1021		10.1109/34.955113	http://dx.doi.org/10.1109/34.955113			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	470RP					2022-12-18	WOS:000170885200006
J	Raudys, S; Saudargiene, A				Raudys, S; Saudargiene, A			First-order tree-type dependence between variables and classification performance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						first-order tree-type dependence; a priori information; classification; generalization; sample size; dimensionality		Structuralization of the covariance matrix reduces the number of parameters to be estimated from the training data and does not affect an increase in the generalization error asymptotically as both the number of dimensions and training sample size grow. A method to benefit from approximately correct assumptions about the first order tree dependence between components of the feature vector is proposed. We use a structured estimate of the covariance matrix to decorrelate and scale the data and to train a single-layer perceptron in the transformed feature space. We show that training the perceptron can reduce negative effects of inexact a priori information. Experiments performed with 13 artificial and 10 real world data sets show that the first-order tree-type dependence model is the most preferable one out of two dozen of the covariance matrix structures investigated.	Inst Math & Informat, LT-2600 Vilnius, Lithuania	Vilnius University	Raudys, S (corresponding author), Inst Math & Informat, Akademijos 4, LT-2600 Vilnius, Lithuania.	raudys@das.mii.lt; ausraud@takas.lt						Atick JJ, 1990, NEURAL COMPUT, V2, P308, DOI 10.1162/neco.1990.2.3.308; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; DEEV AD, 1974, ENG CYBERN, P153; Deev AD., 1972, STAT METHODS CLASSIF, V31, P6; DEEV AD, 1970, REPORTS ACAD SCI USS, V195, P756; FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; HALKAAER S, 1996, ADV NEURAL INFORM PR, V9, P169; Kruskal J. B., 1956, P AM MATH SOC, V7, P48, DOI [DOI 10.1090/S0002-9939-1956-0078686-7, 10.2307/2033241]; LECUN Y, 1991, PHYS REV LETT, V66, P2396, DOI 10.1103/PhysRevLett.66.2396; Mclachlan GJ., 2005, DISCRIMINANT ANAL ST; MESHALKIN LD, 1978, THEOR PROBAB APPL+, V23, P741, DOI 10.1137/1123090; MESHALKIN LD, 1976, STAT PROBLEMS CONTRO, V14, P49; MORGERA SD, 1977, IEEE T INFORM THEORY, V23, P728, DOI 10.1109/TIT.1977.1055798; Prochorskas R., 1976, PROBLEMS ISCHEMIC HE, P216; Raudys S, 2000, PATTERN RECOGN, V33, P1989, DOI 10.1016/S0031-3203(99)00183-1; Raudys S, 1998, NEURAL NETWORKS, V11, P283, DOI 10.1016/S0893-6080(97)00135-4; Raudys S, 1998, IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, P1530, DOI 10.1109/IJCNN.1998.686004; RAUDYS S, 1980, IEEE T PATTERN ANAL, V2, P243; RAUDYS S, 1991, ZAVODSK LAB, P45; Raudys S, 1967, COMPUT SYST, V28, P79; Raudys S., 1972, TECH CYBERN, P168; RAUDYS S, 1998, P JOINT IAPR INT WOR, P583; RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512; Saudargiene A., 1999, Informatica, V10, P245; SERDOBOLSKIJ VI, 1979, MOMENTS DISCRIMINANT, V38, P27; ZARUDSKIJ VI, 1979, STAT PROBLEMS CONTRO, V38, P53; ZARUDSKIJ VI, 1980, ALGORITHMIC PROGRAMI, P189	28	17	17	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2001	23	2					233	239		10.1109/34.908975	http://dx.doi.org/10.1109/34.908975			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	401NJ					2022-12-18	WOS:000166933500014
J	Cohen, FS; Ibrahim, W; Pintavirooj, C				Cohen, FS; Ibrahim, W; Pintavirooj, C			Ordering and parameterizing scattered 3D data for B-spline surface approximation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						surface fitting; B-spline; Gaussian map; geodesics; NURBS	SHAPE ESTIMATION; IMAGE CONTOURS; CURVES; RECOGNITION	Surface representation is intrinsic to many applications in medical imaging, computer vision, and computer graphics. We present a method that is based on surface modeling by B-Spline. The B-Spline constructs a smooth surface that best fits a set of scattered unordered 3D range data points obtained from either a structured light system (a range finder). or from point coordinates on the external contours of a set of surface sections, as for example in histological coronal brain sections. B-Spline stands as of one the most efficient surface representations. it possesses many properties such as boundedness, continuity, local shape controllability, and invariance to affine transformations that makes it very suitable and attractive for surface representation. Despite its attractive properties, however, B-Spline has not been widely applied for representing a 3D scattered nonordered data set. This may be due to the problem in finding an ordering and a choice for the topological parameters of the B-Spline that lead to a physically meaningful surface parameterization based on the scattered data set. The parameters needed for the B-Spline surface construction, as well as finding the ordering of the data points, are calculated based on the geodesics of the surface extended Gaussian map. The set of control points is analytically calculated by solving a minimum mean square error problem for best surface fitting. For a noise immune modeling, we elect to use an approximating rather than an interpolating B-Spline. We also examine ways of making the B-Spline fitting technique robust to local deformation and noise.	Drexel Univ, Dept Elect & Comp Engn, Imaging & Comp Vis Ctr, Philadelphia, PA 19104 USA; Drexel Univ, Sch Biomed Engn & Hlth Sci Syst, Philadelphia, PA 19104 USA	Drexel University; Drexel University	Cohen, FS (corresponding author), Drexel Univ, Dept Elect & Comp Engn, Imaging & Comp Vis Ctr, Philadelphia, PA 19104 USA.							ANDERSSON E, 1988, COMPUT AIDED DESIGN, V20, P317, DOI 10.1016/0010-4485(88)90113-3; Bartels RH, 1987, INTRO SPLINES USE CO; COHEN FS, 1995, IEEE T IMAGE PROCESS, V4, P1, DOI 10.1109/83.350818; COHEN FS, 1994, IEEE T PATTERN ANAL, V16, P1, DOI 10.1109/34.273721; Cooke H., 1996, PRIOR ANAL, P325; De Boor C., 1978, PRACTICAL GUIDE SPLI, V27; Do Carmo M.P., 2016, DIFFERENTIAL GEOMETR, Vsecond; Huang ZH, 1996, IEEE T IMAGE PROCESS, V5, P1473, DOI 10.1109/83.536895; KRISHNAMURTHY V, 1996, P SIGGRAPH 96, P313, DOI DOI 10.1145/237170.237270; MA WY, 1995, COMPUT AIDED DESIGN, V27, P663, DOI 10.1016/0010-4485(94)00018-9; Millman R.S., 1977, ELEMENTS DIFFERENTIA; MILROY MJ, 1995, COMPUT AIDED DESIGN, V27, P471, DOI 10.1016/0010-4485(95)00020-R; PIEGEL L, 1991, IEEE T COMPUTER GRAP, V11; Tiller W., 1995, NURBS BOOK; WANG JY, 1994, IEEE T PATTERN ANAL, V16, P13; Yamaguchi F., 1988, CURVES SURFACES COMP	16	17	19	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2000	22	6					642	648		10.1109/34.862203	http://dx.doi.org/10.1109/34.862203			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	342WE					2022-12-18	WOS:000088667700010
J	Cui, YT; Weng, JY				Cui, YT; Weng, JY			A learning-based prediction-and-verification segmentation scheme for hand sign image sequence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						2D segmentation; hand sign recognition; visual learning nearest neighbor; feature derivation		We present a prediction-and-verification segmentation scheme using attention images from multiple fixations. A major advantage of this scheme is that it can handle a large number of different deformable objects presented in complex backgrounds. The scheme is also relatively efficient. The system was tested to segment hands in sequences of intensity images, where each sequence represents a hand sign in American Sign Language. The experimental result showed a 95 percent correct segmentation rate with a 3 percent false rejection rate.	VR Telecom, Wexford, PA 15090 USA; Michigan State Univ, Dept Comp Sci, E Lansing, MI 48824 USA	Michigan State University	Cui, YT (corresponding author), VR Telecom, 8500 Brooktree Rd, Wexford, PA 15090 USA.							Bobick A. F., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), P382, DOI 10.1109/ICCV.1995.466914; CHAZELLE B, 1985, INFORM CONTROL, V64, P77, DOI 10.1016/S0019-9958(85)80045-0; CUI Y, 1995, TR9543 MICH STAT U C; CUI Y, 1995, P IEEE INT S COMP VI, P305; CUI Y, 1995, P 5 INT C COMP VIS B, P631; Huang T. S., 1995, P INT WORKSH AUT FAC, P73; Loeve M., 1955, PROBABILITY THEORY F; MOGHADDAM B, 1995, P INT WORKSH AUT FAC, P122; Press WH., 1980, NUMERICAL RECIPES FO; Quek F. K. H., 1995, P INT WORKSH AUT FAC, P372	10	17	17	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1999	21	8					798	804		10.1109/34.784311	http://dx.doi.org/10.1109/34.784311			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	225YF					2022-12-18	WOS:000081993000013
J	Teo, PC; Hel-Or, Y				Teo, PC; Hel-Or, Y			Design of multiparameter steerable functions using cascade basis reduction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						steerable filters; filter design; low-level vision; pattern analysis	DECOMPOSITION; FILTERS; MOTION; PHASE	An efficient method of computing the least-squares optimal basis functions to steer any function locally is presented. The method combines the Lie group-theoretic and the singular value decomposition approaches. Its efficiency is demonstrated with the design of basis functions to steer a Gabor function under the four-parameter linear transformation group.	Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA; NASA, Ames Res Ctr, Moffett Field, CA 94035 USA	Stanford University; National Aeronautics & Space Administration (NASA); NASA Ames Research Center	Teo, PC (corresponding author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.	teo@cs.stanford.edu; toky@hp.technion.ac.il						ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; GOTSMAN C, 1994, COMPUT GRAPH FORUM, V13, P153, DOI 10.1111/1467-8659.1320153; Granlund G.H., 1995, SIGNAL PROCESSING CO; Heeger D. J., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P229, DOI 10.1145/218380.218446; HelOr Y, 1996, PROC CVPR IEEE, P809, DOI 10.1109/CVPR.1996.517165; Lenz R., 1990, GROUP THEORETICAL ME; LIU H, 1994, CSTR3291 U MAR; Manduchi R., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P378, DOI 10.1109/ICIP.1995.529725; MANMATHA R, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P141, DOI 10.1109/CVPR.1994.323821; MICHAELIS M, 1995, PATTERN RECOGN LETT, V16, P1165, DOI 10.1016/0167-8655(95)00066-P; NIMEROFF J, 1994, 5 EUR WORKSH REND; PERONA P, 1995, IEEE T PATTERN ANAL, V17, P488, DOI 10.1109/34.391394; SIMONCELLI E, IEEE T INFORMATION T, V38, P587; SIMONCELLI EP, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P189, DOI 10.1109/ICCV.1995.466787; WATSON AB, 1985, J OPT SOC AM A, V2, P322, DOI 10.1364/JOSAA.2.000322; WENG J, 1993, INT J COMPUT VISION, V11, P211, DOI 10.1007/BF01469343; XIONG Y, 1994, CMURITR9428	19	17	17	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1999	21	6					552	556		10.1109/34.771325	http://dx.doi.org/10.1109/34.771325			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	205KD		Green Submitted			2022-12-18	WOS:000080819100006
J	Bennett, J; Khotanzad, A				Bennett, J; Khotanzad, A			Modeling textured images using generalized long correlation models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						long correlation; random fields; autoregressive models; Markov models; texture analysis; texture synthesis; parameter estimation	SPATIAL-INTERACTION	The long correlation (LC) models are a general class of random field (RF) models which are able to model correlations which extend over large image regions with few model parameters. The LC models have seen limited use, due to lack of an effective method for estimating the model parameters. In this work, we develop an estimation scheme for a very general form of this model and demonstrate its applicability to texture modeling applications. The relationship of the generalized LC models to other classes of RF models, namely the simultaneous autoregressive (SAR) and Markov random field (MRF) models, is shown. While it is known that the SAR model is a special case of the LC model, we show that the MRF model is also encompassed by this model. Consequently, the LC model may be considered a generalization of the SAR and MRF models.	So Methodist Univ, Dept Elect Engn, Dallas, TX 75275 USA	Southern Methodist University	Bennett, J (corresponding author), So Methodist Univ, Dept Elect Engn, Dallas, TX 75275 USA.	jesse@seas.smu.edu; kha@seas.smu.edu						BENNETT JW, 1997, THESIS SO METHODIST; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; CHELLAPPA R, 1985, IEEE T SYST MAN CYB, V15, P298, DOI 10.1109/TSMC.1985.6313361; CHELLAPPA R, 1981, P IEEE CS C PATT REC, P577; JACOBS DAH, 1977, STATE ART NUMERICAL, pCH3; Kashyap R. L., 1980, Proceedings of the 5th International Conference on Pattern Recognition, P1103; KASHYAP RL, 1989, IEEE T PATTERN ANAL, V11, P58, DOI 10.1109/34.23113; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; KASHYAP RL, 1984, IEEE T PATTERN ANAL, V6, P800, DOI 10.1109/TPAMI.1984.4767604; KHOTANZAD A, 1987, IEEE T SYST MAN CYB, V17, P1087, DOI 10.1109/TSMC.1987.6499322; LAPSA PM, 1982, THESIS PURDUE U W LA; LARIMORE WE, 1977, P IEEE, V65, P961, DOI 10.1109/PROC.1977.10593; LIU DC, 1972, MATH PROGRAM, P503; WHITTLE P, 1954, BIOMETRIKA, V41, P434	15	17	21	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1998	20	12					1365	1370		10.1109/34.735810	http://dx.doi.org/10.1109/34.735810			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	147QV					2022-12-18	WOS:000077578300009
J	O'Gorman, L; Rabinovich, I				O'Gorman, L; Rabinovich, I			Secure identification documents via pattern recognition and public-key cryptography	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document authentication; document image recognition; photo signature; photo-ID documents; ID cards; counterfeiting; cryptography; pattern recognition		Personal identification documents, such as photo ID cards, are being used increasingly for such activities as financial transactions; entry into restricted areas; and personal verification for medical, government, and commercial (in particular, airlines) services. With this trend, there is also the increasing trend toward counterfeiting these documents for illegal gain. We present an approach to authenticating photo-ID documents that relies on pattern recognition and public-key cryptography and has security advantages over physical mechanisms that currently safeguard cards, such as optical laminates and holograms. The pattern-recognition component of this approach is based on a photo signature that is a concise representation of the photo image on the document. This photo signature is stored in a database for remote authentication or in encrypted form on the card for stand-alone authentication. Verification of the ID document entails scanning both the photo image and a machine-readable form of the text information, determining the photo signature, and comparing this information against the reference. In this paper, we describe the method and present results of testing a large database of images for photo-signature match in the presence of noise.	Veridicom Inc, Chatham, NJ 07928 USA; Bell Labs, Murray Hill, NJ 07974 USA	AT&T	O'Gorman, L (corresponding author), Veridicom Inc, 283 Main St, Chatham, NJ 07928 USA.							*ANSI, 1993, WORK DRAFT X930199X; BELL TE, 1995, IEEE SPECTRUM    APR, P17; BERGHEL H, 1996, IEEE COMPUT, V29, P101; BRASS LM, 1995, BAILLIERE CLIN NEUR, V4, P1; METZ BA, 1994, TECHNOLOGIES USED WA, P727; PAVLIDIS T, 1992, IEEE COMPUTER    JUN, P18; RAY LA, 1994, Patent No. 5321751; SCHNEIER B, 1996, APPL CRYPTOGRAPHY, P34; VANRENESSE RL, 1994, OPTICAL DOCUMENT SEC; Watson Craig I., 1994, NIST SPECIAL DATABAS	10	17	23	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1998	20	10					1097	1102		10.1109/34.722623	http://dx.doi.org/10.1109/34.722623			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	128QB					2022-12-18	WOS:000076416400007
J	Ratsaby, J				Ratsaby, J			Incremental learning with sample queries	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						incremental learning; sample querying; nearest-neighbor algorithm; active learning; model selection		The classical theory of pattern recognition assumes labeled examples appear according to unknown underlying class conditional probability distributions where the pattern classes are picked randomly in a passive manner according to their a priori probabilities. This paper presents experimental results for an incremental nearest-neighbor learning algorithm which actively selects samples from different pattern classes according to a querying rule as opposed to the a priori probabilities. The amount of improvement of this query-based approach over the passive batch approach depends on the complexity of the Bayes rule.	Manna Network Technol, IL-61574 Tel Aviv, Israel		Ratsaby, J (corresponding author), Manna Network Technol, Harachev St 4, IL-61574 Tel Aviv, Israel.	jer@mannanetwork.com	Ratsaby, Joel/AAV-8979-2021					Angluin D., 1988, Machine Learning, V2, P319, DOI 10.1023/A:1022821128753; COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1007/BF00993277; Cohn DA, 1996, NEURAL NETWORKS, V9, P1071, DOI 10.1016/0893-6080(95)00137-9; Fukuda K, 1995, CDD REFERENCE MANUAL; FUKUDA K, 1997, FREQUENTLY ASKED QUE; GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809; HART PE, 1968, IEEE T INFORMATION T, V14; ORourke J., 1994, COMPUTATIONAL GEOMET; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; RATSABY J, 1997, UNPUB INFORMATION CO; RIVEST RL, 1990, P 1990 WORKSH COMP L, P154; SILVERMAN BW, 1989, INT STAT REV, V57, P233, DOI 10.2307/1403796; Vapnik V., 1982, ESTIMATION DEPENDENC	14	17	22	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1998	20	8					883	888		10.1109/34.709619	http://dx.doi.org/10.1109/34.709619			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	110GT					2022-12-18	WOS:000075372700013
J	Jayakumar, M; Banavar, RN				Jayakumar, M; Banavar, RN			Risk-sensitive filters for recursive estimation of motion from images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						risk-sensitive estimation; motion parameters; vision	INTEGRAL PERFORMANCE INDEX; STOCHASTIC-SYSTEMS	In this paper, an Extended Risk-Sensitive Filter (ERSF) is used to estimate the motion parameters of an object recursively from a sequence of monocular images. The effect of varying the risk factor a on the estimation error is examined. The performance of the filter is compared with the Extended Kalman Filter (EKF) and the theoretical Cramer-Rao lower bound. When the risk factor theta and the uncertainty in the measurement noise are large, the initial estimation error of the ERSF is less than that of the corresponding EKF. The ERSF is also found to converge to the steady state value of the error faster that the EKF. In situations when the uncertainty in the initial estimate is large and the EKF diverges, the ERSF converges with small errors. In confirmation with the theory, as theta tends to zero, the behavior of the ERSF is the same as that of the EKF.	Indian Space Res Org, Bangalore 562140, Karnataka, India; Indian Inst Technol, Bombay 400076, Maharashtra, India	Department of Space (DoS), Government of India; Indian Space Research Organisation (ISRO); Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Bombay	Jayakumar, M (corresponding author), Indian Space Res Org, Bangalore 562140, Karnataka, India.		Banavar, Ravi/N-3017-2013					AGGARWAL JK, 1988, P IEEE, V76, P7917; AZARBAYEJANI A, 1995, IEEE T PATTERN ANAL, V17, P562, DOI 10.1109/34.387503; BENSOUSSAN A, 1985, SIAM J CONTROL OPTIM, V23, P599, DOI 10.1137/0323038; BROIDA TJ, 1990, IEEE T AERO ELEC SYS, V26, P639, DOI 10.1109/7.55557; BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; CHANG CB, 1992, P 27 C DEC CONTR AUS, V2, P2293; JACOBSON DH, 1973, IEEE T AUTOMAT CONTR, VAC18, P124, DOI 10.1109/TAC.1973.1100265; Jazwinski A.H., 1970, STOCHASTIC PROCESSES; KERR TH, 1989, IEEE T AERO ELEC SYS, V25, P590, DOI 10.1109/7.42076; KUMAR PR, 1981, J MATH ANAL APPL, V80, P312, DOI 10.1016/0022-247X(81)90109-8; Rao C. R, 1973, LINEAR STAT INFERENC; SPEYER J.L., 1992, P 31 C DEC CONTR, V2, P2293; SPEYER JL, 1974, IEEE T AUTOMAT CONTR, VAC19, P358, DOI 10.1109/TAC.1974.1100606; SPEYER JL, 1976, IEEE T AUTOMAT CONTR, V21, P371, DOI 10.1109/TAC.1976.1101206; TAYLOR JH, 1979, IEEE T AUTOMAT CONTR, V24, P343, DOI 10.1109/TAC.1979.1101979; WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074; WHITTLE P, 1981, ADV APPL PROBAB, V13, P764, DOI 10.2307/1426972; Whittle P, 1990, RISK SENSITIVE OPTIM; WILSON WJ, 1990, NATO ASI SERIES F, V57, P281	19	17	18	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1998	20	6					659	666		10.1109/34.683783	http://dx.doi.org/10.1109/34.683783			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZV807					2022-12-18	WOS:000074343300008
J	Zheng, JY; Fukagawa, Y; Abe, N				Zheng, JY; Fukagawa, Y; Abe, N			3D surface estimation and model construction from specular motion in image sequences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						specular motion; highlight; shape estimation; model recovery; epipolar-plane images; qualitative shape identification		This work reconstructs a 3D graphics model of an object with specular surfaces by its rotation. Continuous images are taken to measure highlights on the smooth surfaces and their motion. Coplanar extended lights determine a plane of rays to produce a highlight stripe on the object. 3D surfaces are then recovered from the moving stripe. We investigate global motion characteristics of the highlights in the Epipolar-plane images so as to qualitatively identify surface types and control the modeling process. Under single and multiple plane-of-rays illuminations, we give two quantitative approaches for surface and normal recovery which use highlight orientation in the image and highlight motion in the Epipolar-Plane images. The computations employ a first-order differential equation and linear equations, respectively.			Zheng, JY (corresponding author), KYUSHU INST TECHNOL,FAC COMP SCI & SYST ENGN,680-4 KAWAZU,IIZUKA,FUKUOKA 820,JAPAN.							BAKER H, 1988, CVPR88, P2; BELLVERCEBREROS C, 1992, OPT COMMUN, V92, P187, DOI 10.1016/0030-4018(92)90619-3; BLACK A, 1988, 2 ICCV, P364; CLARK J, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P981, DOI 10.1109/ICCV.1995.466827; IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167; KLINKER GJ, 1988, INT J COMPUT VISION, V2, P7, DOI 10.1007/BF00836279; OREN M, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P740, DOI 10.1109/ICCV.1995.466864; SCHULTZ H, 1994, IEEE T PATTERN ANAL, V16, P195, DOI 10.1109/34.273732; ZHENG JY, 1994, IEEE T PATTERN ANAL, V16, P163, DOI 10.1109/34.273734; ZHENG JY, 1994, 12 ICPR, V1, P331; ZHENG JY, 1995, 5 ICCV, P92; ZISSERMAN A, 1989, IMAGE VISUAL COMPUTI, V7, P287	12	17	19	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1997	19	5					513	520						8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XB163					2022-12-18	WOS:A1997XB16300011
J	Tistarelli, M				Tistarelli, M			Multiple constraints to compute optical flow	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						optical flow; velocity field; differential constraints; dynamic vision; motion analysis; image velocity; dynamic scene analysis; computer vision		The computation of the optical flow field from an image sequence requires the definition of constraints on the temporal change of image features. In this paper, we consider the implications of using multiple constraints in the computational schema. In the first step, it is shown that differential constraints correspond to an implicit feature tracking. Therefore, the best results (either in terms of measurement accuracy, and speed in the computation) are obtained by selecting and applying the constraints which are best ''tuned'' to the particular image feature under consideration. Considering also multiple image points not only allows us to obtain a (locally) better estimate of the velocity field, but also to detect erroneous measurements due to discontinuities in the velocity field. Moreover, by hypothesizing a constant acceleration motion model, also the derivatives of the optical flow are computed. Several experiments are presented from real image sequences.			Tistarelli, M (corresponding author), UNIV GENOA,DEPT COMMUN COMP & SYST SCI,INTEGRATED LAB ADV ROBOT,VIA OPERA PIA 13,I-16145 GENOA,ITALY.		Tistarelli, Massimo/AAH-9437-2021	Tistarelli, Massimo/0000-0002-3406-3048				BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BENTZVI D, 1993, PATTERN RECOGN, V26, P1549, DOI 10.1016/0031-3203(93)90160-X; CAMPANI M, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P22; Davis C. Q., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P7, DOI 10.1109/ISCV.1995.476969; DENNEY TS, 1992, P 1992 IEEE INT C AC, P257; FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772; LAI JS, 1993, P SOC PHOTO-OPT INS, V2056, P186, DOI 10.1117/12.150197; Markandey V., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P38, DOI 10.1109/ICCV.1990.139488; Nagel H.-H, 1994, P 3 EUR C COMP VIS S, P305; NAGEL HH, 1987, ARTIF INTELL, V33, P299, DOI 10.1016/0004-3702(87)90041-5; NESI P, 1993, IMAGE VISION COMPUT, V8, P419; OTTE M, 1995, ARTIF INTELL, V78, P5, DOI 10.1016/0004-3702(95)00033-X; SCHNORR C, 1992, INT J COMPUT VISION, V8, P153, DOI 10.1007/BF00127172; SCHUNCK BG, 1989, IEEE T PATTERN ANAL, V11, P1010, DOI 10.1109/34.42834; TISTARELLI M, 1992, CVGIP-IMAG UNDERSTAN, V56, P108, DOI 10.1016/1049-9660(92)90089-L; TISTARELLI M, 1994, P 3 EUR C COMP VIS S, P61; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; TRETIAK O, 1984, P 7 INT C PATT REC M, P16; Tryon R. C., 1970, CLUSTER ANAL; URAS S, 1988, BIOL CYBERN, V60, P79, DOI 10.1007/BF00202895; WEBER J, 1995, INT J COMPUT VISION, V14, P67, DOI 10.1007/BF01421489; WOODHAM RJ, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P42	22	17	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1996	18	12					1243	1250		10.1109/34.546260	http://dx.doi.org/10.1109/34.546260			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VZ150					2022-12-18	WOS:A1996VZ15000009
J	Liou, CY; Yang, HC				Liou, CY; Yang, HC			Handprinted character recognition based on spatial topology distance measurement	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						handprinted character recognition; spatial topology distance; self-organizing map; neural networks; elastic matching		In this work we present a self-organization matching approach to accomplish the recognition of handprinted characters drawn with thick strokes. This approach is used to flex the unknown handprinted character toward matching its object characters gradually. The extracted character features used in the self-organization matching are center loci, orientation, and major axes of ellipses which fit the inked area of the patterns. Simulations provide encouraging results using the proposed method.			Liou, CY (corresponding author), NATL TAIWAN UNIV,DEPT COMP SCI & INFORMAT ENGN,TAIPEI 10764,TAIWAN.		Liou, Cheng-Yuan/HDM-0177-2022	LIOU, CHENG-YUAN/0000-0001-7479-1413				BLASDEL GG, 1986, NATURE, V321, P579, DOI 10.1038/321579a0; BURR DJ, 1981, IEEE T PATTERN ANAL, V3, P708, DOI 10.1109/TPAMI.1981.4767176; BURR DJ, 1983, IEEE T PATTERN ANAL, V5, P554, DOI 10.1109/TPAMI.1983.4767435; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; HINTON G, 1992, ADV NEURAL INFORMATI, V4; HUBEL DH, 1990, PERCEPTUAL WORLD, P3; Kohonen T., 1989, SELF ORG ASSOCIATIVE, V3rd; LIOU CY, 1993, P INT C ART NEUR NET	9	17	19	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1996	18	9					941	945		10.1109/34.537349	http://dx.doi.org/10.1109/34.537349			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	VK799					2022-12-18	WOS:A1996VK79900009
J	Basri, R; Weinshall, D				Basri, R; Weinshall, D			Distance metric between 3D models and 2D images for recognition and classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						affine deformations; 3D-to-2D metric; object recognition; exterior orientation calibration		Similarity measurements between 3D objects and 2D images are useful for the tasks of object recognition and classification. We distinguish between two types of similarity metrics: metrics computed in image-space (image metrics) and metrics computed in transformation-space (transformation metrics). Existing methods typically use image metrics; namely, metrics that measure the difference in the image between the observed image and the nearest view of the object. Example for such a measure is the Euclidean distance between feature points in the image and their corresponding points in the nearest view. (This measure can be computed by solving the exterior orientation calibration problem.) In this paper we introduce a different type of metrics: transformation metrics. These metrics penalize for the deformations applied to the object to produce the observed image. In particular, we define a transformation metric that optimally penalizes for ''affine deformations'' under weak-perspective. A closed-form solution, together with the nearest view according to this metric, are derived. The metric is shown to be equivalent to the Euclidean image metric, in the sense that they bound each other from both above and below. It therefore provides an easy-to-use closed-form approximation sor the commonly-used least-squares distance between models and images. We demonstrate an image understanding application, where the true dimensions of a photographed battery charger are estimated by minimizing the transformation metric.	HEBREW UNIV JERUSALEM,INST COMP SCI,IL-91904 JERUSALEM,ISRAEL	Hebrew University of Jerusalem	Basri, R (corresponding author), WEIZMANN INST SCI,DEPT APPL MATH,IL-76100 REHOVOT,ISRAEL.							BASRI R, 1992, 1373 MIT AI; BASRI R, 1993, COMPUTER VISION PATT; DEMENTHON DF, 1992, P 2 EUR C COMP VIS S; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GRIMSON WEL, 1992, P IEEE C COMP VIS PA; HORAUD R, 1989, COMPUT VISION GRAPH, V47, P33, DOI 10.1016/0734-189X(89)90052-2; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; PHONG TQ, 1993, P 4 INT C COMP VIS B, P534; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; WEINSHALL D, 1993, INT J COMPUT VISION, V10, P27, DOI 10.1007/BF01440845; YUAN JSC, 1989, IEEE T ROBOTIC AUTOM, V5, P129, DOI 10.1109/70.88034	11	17	19	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1996	18	4					465	470		10.1109/34.491630	http://dx.doi.org/10.1109/34.491630			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UG345		Green Submitted			2022-12-18	WOS:A1996UG34500014
J	LIU, XD; EHRICH, RW				LIU, XD; EHRICH, RW			SUBPIXEL EDGE LOCATION IN BINARY IMAGES USING DITHERING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						DITHER; EDGE; INSPECTION; SUBPIXEL	STRAIGHT-LINES; ACCURACY	This paper concerns the problem of obtaining subpixel estimates of the locations of straight edges in binary digital images using dithering. By adding uniformly distributed independent random noise it is shown that estimation bias may be removed and that the estimation variance is inversely proportional to the length of the line segment. The sensitivity to incorrect dither amplitude is calculated, and implementation is discussed.			LIU, XD (corresponding author), VIRGINIA POLYTECH INST & STATE UNIV,DEPT COMP SCI,BLACKSBURG,VA 24060, USA.							BERENSTEIN CA, 1987, COMPUT VISION GRAPH, V40, P334, DOI 10.1016/S0734-189X(87)80146-9; COX IJ, 1990, IEEE T PATTERN ANAL, V12, P721, DOI 10.1109/34.57665; DEMICHELI E, 1989, IEEE T PATTERN ANAL, V11, P1106, DOI 10.1109/34.42841; DORST L, 1984, IEEE T PATTERN ANAL, V6, P450, DOI 10.1109/TPAMI.1984.4767550; DORST L, 1984, IEEE T PATTERN ANAL, V6, P632, DOI 10.1109/TPAMI.1984.4767577; GORDON SJ, 1986, IEEE T ROBOTIC AUTOM, V2, P931; HUERTAS A, 1985, 3RD P IEEE WORKSH CO, P63; HYDE PD, 1983, PATTERN RECOGN, V16, P413, DOI 10.1016/0031-3203(83)90063-8; LIU X, 1993, TR9311 VIRG TECH DEP; LYVERS EP, 1989, IEEE T PATTERN ANAL, V11, P1293, DOI 10.1109/34.41367; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; TABATABAI AJ, 1984, IEEE T PATTERN ANAL, V6, P188, DOI 10.1109/TPAMI.1984.4767502; WILLIAMS CS, 1989, INTRO OPTICAL TRANSF, P43; YOUNG RA, 1986, P SOC PHOTO-OPT INS, V728, P2	14	17	25	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1995	17	6					629	634		10.1109/34.387511	http://dx.doi.org/10.1109/34.387511			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QZ940		Green Submitted			2022-12-18	WOS:A1995QZ94000009
J	WERMAN, M; GEYZEL, Z				WERMAN, M; GEYZEL, Z			FITTING A 2ND DEGREE CURVE IN THE PRESENCE OF ERROR	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						PATTERN ANALYSIS; LOW-LEVEL PROCESSING; PERCEPTUAL GROUPING; CURVE FITTING		This correspondence presents a statistically sound, simple and, fast method to estimate the parameters of a second degree curve from a set of noisy paints that originated from the curve.			WERMAN, M (corresponding author), HEBREW UNIV JERUSALEM,DEPT COMP SCI,IL-91904 JERUSALEM,ISRAEL.							Duda R.O., 1973, J ROYAL STAT SOC SER; IMAI H, 1989, ALGORITHMICA, V4, P77, DOI 10.1007/BF01553880; Kummell CH, 1879, ANALYST, V6, P97, DOI DOI 10.2307/2635646; MADANSKY A, 1959, J AM STAT ASSOC, V54, P173, DOI 10.2307/2282145; Moran P.A.P., 1971, J MULTIVARIATE ANAL, V1, P232, DOI [10.1016/0047-259X(71)90013-3, DOI 10.1016/0047-259X(71)90013-3]; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; STEIN A, 1992, 3RD S DISC ALG; STEIN A, 1992, ROBUST STATISTICS SH, P540; Wald A, 1940, ANN MATH STAT, V11, P284, DOI 10.1214/aoms/1177731868; WERMAN M, 1987, PATTERN RECOGN LETT, V5, P207, DOI 10.1016/0167-8655(87)90065-1	10	17	17	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1995	17	2					207	211		10.1109/34.368167	http://dx.doi.org/10.1109/34.368167			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE825					2022-12-18	WOS:A1995QE82500011
J	OSULLIVAN, F; QIAN, MJ				OSULLIVAN, F; QIAN, MJ			A REGULARIZED CONTRAST STATISTIC FOR OBJECT BOUNDARY ESTIMATION - IMPLEMENTATION AND STATISTICAL EVALUATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						EDGE DETECTION; NONLINEAR OPTIMIZATION; TOMOGRAPHY	PRINCIPAL CURVES; EDGE-DETECTION; IMAGES; PET	We propose an optimization approach to the estimation of a simple closed curve describing the boundary of an object represented in an image. The problem arises in a variety of applications, such as template matching schemes for medical image registration. A regularized optimization formulation with an objective function that measures the normalized image contrast between the inside and outside of a boundary is proposed. Numerical methods are developed to implement the approach, and a set of simulation studies are carried out to quantify statistical performance characteristics. One set of simulations models emission computed tomography (ECT) images; a second set considers images with a locally coherent noise pattern. In both cases, the error characteristics are found to be quite encouraging. The approach is highly automated, which offers some practical advantages over currently used technologies in the medical imaging field.	UNIV WASHINGTON,DEPT BIOSTAT,SEATTLE,WA 98195; FULLERTON STATE UNIV,DEPT MATH,FULLERTON,CA 92634	University of Washington; University of Washington Seattle; California State University System; California State University Fullerton	OSULLIVAN, F (corresponding author), UNIV WASHINGTON,DEPT STAT,SEATTLE,WA 98195, USA.							ADAMS RM, 1993, COMMUNICATION; ALTMAN NS, 1990, J AM STAT ASSOC, V85, P749, DOI 10.2307/2290011; [Anonymous], 1986, LONDON ACAD PRESS; BANFIELD JD, 1992, J AM STAT ASSOC, V87, P7, DOI 10.2307/2290446; BOLLE RM, 1991, IEEE T PATTERN ANAL, V13, P1, DOI 10.1109/34.67626; BRINKLEY JF, 1985, IEEE T PATTERN ANAL, V7, P431, DOI 10.1109/TPAMI.1985.4767682; CHEN SY, 1991, CVGIP-GRAPH MODEL IM, V53, P457, DOI 10.1016/1049-9652(91)90030-N; CHIAO P, 1991, THESIS U MICHIGAN; COX DD, 1990, ANN STAT, V18, P1676, DOI 10.1214/aos/1176347872; De Boor C., 1978, PRACTICAL GUIDE SPLI, V27; DENNIS JR, 1983, NUMERICAL METHODS UN; EICHEL PH, 1988, IEEE T MED IMAGING, V7, P721; GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204; HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936; HOFFMAN EJ, 1990, IEEE T NUCL SCI, V37, P616, DOI 10.1109/23.106686; Isaacson E., 1966, ANAL NUMERICAL METHO; Kass M., 1988, INT J COMPUT VISION, V1, P321; KOROSTELEV AP, 1992, SPRINGER LECTURE NOT; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Menet S., 1990, P IEEE INT C SYST MA, P194; NATTERER F, 1986, MATH COMPUTERIZED TO; Olshen R., 1984, CLASSIFICATION REGRE; OSULLIVAN F, 1990, J AM STATIST ASS; PELIZZARI CA, 1989, J COMPUT ASSIST TOMO, V13, P20, DOI 10.1097/00004728-198901000-00004; RUDEMO M, 1990, 904 VET AGR U DEP MA; SYNDER DL, 1981, IEEE T NUCL SCI, V28, P3575; TAN HL, 1992, IEEE T PATTERN ANAL, V14, P3, DOI 10.1109/34.107010; Tikhonov A., 1977, SOLUTIONS ILL POSED; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769; WAHBA G, 1990, SPLINE MODELS STATIS; [No title captured]	32	17	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1994	16	6					561	570		10.1109/34.295901	http://dx.doi.org/10.1109/34.295901			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NR972					2022-12-18	WOS:A1994NR97200001
J	BUTUROVIC, LJ				BUTUROVIC, LJ			TOWARD BAYES-OPTIMAL LINEAR DIMENSION REDUCTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter								Dimension reduction is the process of transforming multidimensional vectors into a low-dimensional space. In pattern recognition, it is often desired that this task be performed without significant loss of classification information. The Bayes error is an ideal criterion for this purpose; however, it is known to be notoriously difficult for mathematical treatment. Consequently, suboptimal criteria have been used in practice. We propose an alternative criterion, based on the estimate of the Bayes error, that is hopefully closer to the optimal criterion than the criteria currently in use. An algorithm for linear dimension reduction, based on this criterion, is conceived and implemented. Experiments demonstrate its superior performance in comparison with conventional algorithms.	UNIV BELGRADE, FAC ELECT ENGN, BELGRADE, YUGOSLAVIA	University of Belgrade								BISWAS G, 1981, IEEE T PATTERN ANAL, V3, P701, DOI 10.1109/TPAMI.1981.4767175; BUTUROVIC L, 1991, PATTERN RECOGN, V24, P11; BUTUROVIC LJ, 1992, IEEE T INFORM THEORY, V38, P182, DOI 10.1109/18.108269; Devijver PA, 1982, PATTERN RECOGNITION; DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; FUKUNAGA K, 1987, IEEE T PATTERN ANAL, V9, P634, DOI 10.1109/TPAMI.1987.4767958; FUKUNAGA K, 1990, INTRO STATISTICAL PA; GORMAN RP, 1988, NEURAL NETWORKS, V1, P75, DOI 10.1016/0893-6080(88)90023-8; GUSEMAN LF, 1975, ANN STAT, V3, P661, DOI 10.1214/aos/1176343128; JAIN AK, 1978, PATTERN RECOGN, V10, P365, DOI 10.1016/0031-3203(78)90008-0; Kittler J., 1986, HDB PATTERN RECOGNIT; NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308; PEJNOVIC P, 1991, THSIS U BELGRADE BEL; RAUDYS SJ, 1979, PATTERN RECOGN, V11, P263, DOI 10.1016/0031-3203(79)90036-0	14	17	17	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1994	16	4					420	424		10.1109/34.277596	http://dx.doi.org/10.1109/34.277596			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NH607					2022-12-18	WOS:A1994NH60700009
J	OLESEN, KG				OLESEN, KG			CAUSAL PROBABILISTIC NETWORKS WITH BOTH DISCRETE AND CONTINUOUS-VARIABLES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note							INFLUENCE DIAGRAMS; BELIEF NETWORKS; EXPERT SYSTEMS	An extension of the expert system shell known as handling uncertainty by general influence networks (HUGIN) to include continuous variables, in the form of linear additive normally distributed variables, is presented. The theoretical foundation of the method was developed by Lauritzen [14], whereas this report primarily focus on implementation aspects. The approach has several advantages over purely discrete systems: It enables a more natural model of the domain in question, knowledge acquisition is eased, and the complexity of belief revision is most often reduced considerably.			OLESEN, KG (corresponding author), AALBORG UNIV,INST ELECTR SYST,AALBORG O,DENMARK.							ANDERSEN SK, 1989, 11TH P INT JOINT C A, P1080; ANDREASSEN S, 1992, ELECTROEN CLIN NEURO, V85, P143, DOI 10.1016/0168-5597(92)90080-U; ANDREASSEN S, 1987, 10TH P INT JOINT C A, P366; ANDREASSEN S, 1989, COMPUTER AIDED SURFA; ANDREASSEN S, IN PRESS EVALUATION; BELLAZZI R, 1991, COMPUT METH PROG BIO, V35, P177, DOI 10.1016/0169-2607(91)90120-I; COOPER GF, 1990, ARTIF INTELL, V42, P393, DOI 10.1016/0004-3702(90)90060-D; FORSYTHE GE, 1967, COMPUTER SOLUTION LI; GAMMERMAN AJ, IN PRESS COMPUTATION; Jensen F. V., 1990, Computational Statistics Quarterly, V5, P269; Jensen F. V., 1988, JUNCTION TREES DECOM; JENSEN FV, 1990, NETWORKS, V20, P637, DOI 10.1002/net.3230200509; KJAERULFF U, 1990, R9009 AALB U I EL SY; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; LAURITZEN SL, 1989, ANN STAT, V17, P31, DOI 10.1214/aos/1176347003; LAURITZEN SL, IN PRESS J AM STAT A; Leimer H.-G., 1988, ANN DISCRETE MATH, V41, P311; Olesen K. G., 1989, Applied Artificial Intelligence, V3, P385, DOI 10.1080/08839518908949933; PEARL J, 1986, ARTIF INTELL, V29, P241, DOI 10.1016/0004-3702(86)90072-X; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; SHACHTER RD, 1989, MANAGE SCI, V35, P527, DOI 10.1287/mnsc.35.5.527; SHACHTER RD, 1986, OPER RES, V34, P871, DOI 10.1287/opre.34.6.871; Shafer G.R, 1990, ANN MATH ARTIF INTEL, P327, DOI [10.1007/BF01531015, DOI 10.1007/BF01531015]	23	17	19	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1993	15	3					275	279		10.1109/34.204909	http://dx.doi.org/10.1109/34.204909			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	KT658					2022-12-18	WOS:A1993KT65800008
J	KAINDL, H; SHAMS, R; HORACEK, H				KAINDL, H; SHAMS, R; HORACEK, H			MINIMAX SEARCH ALGORITHMS WITH AND WITHOUT ASPIRATION WINDOWS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ALPHA-BETA SEARCH; ASPIRATION WINDOWS; MINIMAL WINDOW SEARCH; MINIMAX SEARCH ALGORITHMS; ORDERED GAME TREES; SIMULATION STUDIES; STATE-SPACE SEARCH	ALPHA-BETA; TREE-SEARCH	This paper is based on investigations of several algorithms for computing exact minimax values of game trees (utilizing backward pruning). The focus is especially on trees with an ordering similar to that we have actually found in game playing practice. We also compare the algorithms using two different distributions of the static values, the uniform distribution, and a distribution estimated from practical data. Moreover, this is the first systematic comparison of using aspiration windows for all of the usual minimax algorithms. We analyze the effects of aspiration windows of varying size and position. Increasing the ordering of moves to near the optimum results in unexpectedly high savings. Algorithms with linear space complexity especially benefit most. Although the ordering of the first move is of predominant importance, that of the remainder has only second-order effects. The use of an aspiration window not only makes alpha-beta (AB) search competitive, but there also exists previously unpublished dependencies of its effects on certain properties of the trees. In general, the more recently developed algorithms with exponential space complexity are not to be recommended for game-playing practice since their advantage in having to visit fewer nodes is more than outweighed under practical conditions by their enormous space requirements. Finally, we propose a method for an analytic determination of estimates of the optimal window size, presupposing evidence about some characteristic properties of the domain of application. In summary, we discovered and found empirical evidence for several effects unpredicted by theoretical studies.	ALCATEL ELIN,RES CTR,VIENNA,AUSTRIA; UNIV BIELEFELD,FAK LINGUIST & LITERATURWISSENSCH,W-4800 BIELEFELD,GERMANY	Alcatel-Lucent; University of Bielefeld	KAINDL, H (corresponding author), SIEMENS AG OSTERREICH,DEPT PROGRAM & SYST ENGN,VIENNA,AUSTRIA.			Kaindl, Hermann/0000-0002-1133-0529				BAUDET GM, 1978, THESIS CARNEGIE MELL; CAMPBELL MS, 1983, ARTIF INTELL, V20, P347, DOI 10.1016/0004-3702(83)90001-2; FISHBURN J, 1980, 394 U WISC DEP COMP; Gaschnig J. G., 1979, THESIS CARNEGIE MELL; GILLOGLY JJ, 1978, THESIS CARNEGIE MELL; KAINDL H, 1988, ICCA J, V11, P156; KAINDL H, 1989, MAY P WORKSH NEW DIR, P111; KAINDL H, 1989, PROBLEMLOSEN HEURIST; KAINDL H, 1983, AUG P IJCAI 83 KARLS, P760; KAINDL H, 1988, 50 U VIENN DEP STAT; KNUTH DE, 1975, ARTIF INTELL, V6, P293, DOI 10.1016/0004-3702(75)90019-3; KORF RE, 1985, ARTIF INTELL, V27, P97, DOI 10.1016/0004-3702(85)90084-0; MARSLAND TA, 1982, COMPUT SURV, V14, P533, DOI 10.1145/356893.356895; MARSLAND TA, 1987, ARTIF INTELL, V31, P185, DOI 10.1016/0004-3702(87)90019-1; MARSLAND TA, 1983, AUG P IJCAI 83 KARLS, P763; MUSCZYCKA A, 1985, IEEE T SYST MAN CYB, V15, P389; PEARL J, 1980, ARTIF INTELL, V14, P113, DOI 10.1016/0004-3702(80)90037-5; REINEFELD A, 1989, SPIELBAUM SUCHVERFAH; REINEFELD A, 1983, J INT COMPUT CHESS A, V6, P4; SCHAEFFER J, 1989, IEEE T PATTERN ANAL, V11, P1203, DOI 10.1109/34.42858; Schaeffer J., 1986, THESIS U WATERLOO CA; SHAMS R, 1991, AUG P IJCAI 91 SYDN, P192; SHAMS R, 1990, THESIS I PRAKTISCHE; STOCKMAN GC, 1979, ARTIF INTELL, V12, P179, DOI 10.1016/0004-3702(79)90016-X; 1984, HEURISTICS INTELLIGE	25	17	18	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1991	13	12					1225	1235		10.1109/34.106996	http://dx.doi.org/10.1109/34.106996			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GT950					2022-12-18	WOS:A1991GT95000003
J	BELL, B; PAU, LF				BELL, B; PAU, LF			CONTOUR TRACKING AND CORNER DETECTION IN A LOGIC PROGRAMMING ENVIRONMENT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											BELL, B (corresponding author), TECH UNIV DENMARK,AI & VIS GRP,BLDG 348-EMI,DK-2800 LYNGBY,DENMARK.		Pau, L.F./A-1262-2010	Pau, L.F./0000-0003-1503-1486				BARUCH O, 1988, PATTERN RECOGN LETT, V8, P271, DOI 10.1016/0167-8655(88)90034-7; BELL B, 1989, EMI R402 TECH U TECH; BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808; CHENG FH, 1988, PATTERN RECOGN LETT, V8, P47, DOI 10.1016/0167-8655(88)90023-2; Cruse D., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P493; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; GUIDUCCI A, 1988, PATTERN RECOGN LETT, V8, P311, DOI 10.1016/0167-8655(88)90080-3; HAN MH, 1989, PATTERN RECOGN, V22, P13, DOI 10.1016/0031-3203(89)90033-2; Huang Z. H., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P853; KURNER P, 1986, 8TH P INT C PATT REC, P240; LAWTON DT, 1988, P IEEE, V76, P1036, DOI 10.1109/5.5973; MARIMONT DH, 1984, 4TH P NAT C ART INT, P237; MCKEOWN DM, 1985, IEEE T PATTERN ANAL, V7, P570, DOI 10.1109/TPAMI.1985.4767704; NAZIF AM, 1984, IEEE T PATTERN ANAL, V6, P555, DOI 10.1109/TPAMI.1984.4767570; O'Gorman L., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P235, DOI 10.1109/CVPR.1988.196242; PAU LF, 1990, ASI SERIES; PAU LF, 1987, MACHINE INTELLIGENCE; Price K. E., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P990; RONSE C, 1986, CONNECTED COMPONENTS; TAN HS, 1986, PATTERN RECOGNITION, V2; XIE M, 1988, INRIA909 RES REP	21	17	19	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1990	12	9					913	917		10.1109/34.57685	http://dx.doi.org/10.1109/34.57685			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DV778		Green Submitted			2022-12-18	WOS:A1990DV77800006
J	LACROIX, V				LACROIX, V			A 3-MODULE STRATEGY FOR EDGE-DETECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											LACROIX, V (corresponding author), PHILIPS RES LAB,AVE E VAN BECELAERE 2,BOX 8,B-1170 BRUSSELS,BELGIUM.							ARGYLE E, 1971, PR INST ELECTR ELECT, V59, P285, DOI 10.1109/PROC.1971.8136; BERGHOLM F, 1986, 8TH P INT C PATT REC, P597; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; DAVIES ER, 1986, PATTERN RECOGN LETT, V4, P111, DOI 10.1016/0167-8655(86)90032-2; FREI W, 1977, IEEE T COMPUT, V26, P988, DOI 10.1109/TC.1977.1674733; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P121, DOI 10.1109/TPAMI.1985.4767628; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HUECKEL MH, 1973, J ACM, V20, P634, DOI 10.1145/321784.321791; JACOBUS CJ, 1981, IEEE T PATTERN ANAL, V3, P581, DOI 10.1109/TPAMI.1981.4767149; KIRSCH RA, 1971, COMPUT BIOMED RES, V4, P315, DOI 10.1016/0010-4809(71)90034-6; KUNT M, 1978, IEEE T BIO-MED ENG, V25, P121, DOI 10.1109/TBME.1978.326238; KUNT M, P ICASSP82, P1172; MACLEOD IDG, 1972, PR INST ELECTR ELECT, V60, P344, DOI 10.1109/PROC.1972.8642; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MERO L, 1975, 4TH P INT JOINT C AR, P650; NAGAO M, 1979, COMPUT VISION GRAPH, V9, P394, DOI 10.1016/0146-664X(79)90102-3; Prewitt, 1970, PICTURE PROCESSING P, V10, P15, DOI DOI 10.4236/AD.2014.22003; Roberts L, 1965, MACHINE PERCEPTION 3; Robinson G.S., 1977, COMPUT VISION GRAPH, V6, P492, DOI 10.1016/s0146-664x(77)80024-5; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P187; WITKIN AP, 1983, 4TH P INT JOINT C AR, P1019; Yakimovsky Y., 1976, JACM, V23, P598; YUILLE A, 1986, IEEE T PATTERN ANAL, V8, P187	24	17	22	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1988	10	6					803	810		10.1109/34.9103	http://dx.doi.org/10.1109/34.9103			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q9971					2022-12-18	WOS:A1988Q997100003
J	MULDER, JA; MACKWORTH, AK; HAVENS, WS				MULDER, JA; MACKWORTH, AK; HAVENS, WS			KNOWLEDGE STRUCTURING AND CONSTRAINT SATISFACTION - THE MAPSEE APPROACH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV BRITISH COLUMBIA,DEPT COMP SCI,VANCOUVER V6T 1W5,BC,CANADA; TEKTRONIX INC,BEAVERTON,OR 97077	University of British Columbia	MULDER, JA (corresponding author), DALHOUSIE UNIV,DEPT MATH STAT & COMP SCI,HALIFAX B3H 3J5,NS,CANADA.							BALLARD DH, 1978, COMPUTER VISION SYST, P271; Barrow H., 1978, COMPUT VIS SYST, V2, P2; Bartlett F. C, 1932, REMEMBERING STUDY EX; Binford T. O., 1982, INT J ROBOT RES, V1, P18; Bobrow DG., 1977, COGNITIVE SCI, V1, P3, DOI [DOI 10.1207/S15516709C0G0101_, 10.1207/s15516709cog0101_2, DOI 10.1207/S15516709COG0101_2]; BOLLES RC, 1979, 6TH P INT JOINT C AR, P73; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; FREUDER EC, 1978, COMMUN ACM, V21, P958, DOI 10.1145/359642.359654; GLICKSMAN J, 1983, 8TH P IJCAI, P1078; Hanson A., 1978, COMPUTER VISION SYST, P303; HAVENS W, 1983, COMPUTER, V16, P90, DOI 10.1109/MC.1983.1654203; HAVENS WS, 1985, COMPUTATIONAL INTELL, V1, P127; HAVENS WS, 1978, TR783 U BRIT COL DEP; HAVENS WS, 1981, 7TH P INT JOINT C AR, P625; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; KOHL C, 1987, 10TH P INT JOINT C A, P811; LEVINE MD, 1978, COMPUTER VISION SYST, P335; Mackworth A. K., 1978, COMPUTER VISION SYST, P53; MACKWORTH AK, 1977, ARTIF INTELL, V8, P99, DOI 10.1016/0004-3702(77)90007-8; MACKWORTH AK, 1985, ARTIF INTELL, V25, P65, DOI 10.1016/0004-3702(85)90041-4; MACKWORTH AK, 1977, 5TH P INT JOINT C AI, P598; MACKWORTH AK, 1987, TR874 U BRIT COL DEP; MACKWORTH AK, IN PRESS COMPUTATION; MACKWORTH AK, 1983, PHYSICAL BIOL PROCES, P33; MACKWORTH AK, 1987, ENCY ARTIFICIAL INTE, P205; MACKWORTH AK, 1985, COMPUTATIONAL INTELL, V1, P118; MATSUYAMA T, 1985, 9TH P INT JOINT C AR, P908; Minsky M., 1975, PSYCHOL COMPUTER VIS, P211; MULDER J, 1985, 9TH P INT JOINT C AR, P905; MULDER JA, 1985, TR8514 U BRIT COL DE; MULDER JA, 1987, 1987CS3 DALH U TECHN; MULDER JA, 1978, 2ND P NAT C CAN SOC, P244; MULDER JA, 1987, 10TH P INT JOINT C A, P855; MULDER JA, IN PRESS COMPUT VISI; ROBERTS RB, 1977, MIT408 ART INT LAB M; ROSENTHAL D, 1978, 4TH P INT JOINT C PA, P417; SABBAH D, 1985, COGNITIVE SCI, V9, P25, DOI 10.1207/s15516709cog0901_3; Shafer G., 1976, MATH THEORY EVIDENCE, VVolume 1; SHANK RC, 1972, COGNITIVE PSYCHOL, V3; STEFIK M, 1979, 6TH P INT JOINT C AR, P845; Stewart G., 1975, TOPICS NUMERICAL ANA, VII, P185, DOI [DOI 10.1016/B978-0-12-108550-6.50012-4, 10.1016/B978-0-12-496952-0.50023-4, DOI 10.1016/B978-0-12-496952-0.50023-4]; Tanimoto S., 1975, COMPUTER GRAPHICS IM, V4, P104; TENENBAUM JM, 1978, SRI TN173 AI CTR TEC; Tsotsos J. K., 1987, ENCY ARTIFICIAL INTE, P389; TSOTSOS JK, 1985, COMPUT INTELL, V1, P16; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19; WEYMOUTH T, 1986, COINS8624 U MASS DEP	47	17	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1988	10	6					866	879		10.1109/34.9108	http://dx.doi.org/10.1109/34.9108			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q9971		Green Submitted			2022-12-18	WOS:A1988Q997100008
J	SANZ, JLC; PETKOVIC, D				SANZ, JLC; PETKOVIC, D			MACHINE VISION ALGORITHMS FOR AUTOMATED INSPECTION OF THIN-FILM DISK HEADS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											SANZ, JLC (corresponding author), IBM CORP,ALMADEN RES CTR,DEPT COMP SCI,MACHINE VIS GRP,650 HARRY RD,SAN JOSE,CA 95120, USA.							Ballard D.H., 1982, COMPUTER VISION; BARLETT SL, 1987, 3RD P C AI APPL, P58; Barr A, 1981, HDB ARTIFICIAL INTEL, VI; CHIN RT, 1982, IEEE T PATTERN ANAL, V4, P557, DOI 10.1109/TPAMI.1982.4767309; DAVIS LS, 1975, IEEE T SYST MAN CYB, VSMC5, P383, DOI 10.1109/TSMC.1975.5408419; DINSTEIN I, 1984, INT C PATTERN RECOGN; DINSTEIN I, 1985, OPT ENG; FU KS, 1984, IEEE COMPUT      OCT; HANAHARA K, 1986, P INT C ROBOTICS AUT; HINKLE EB, 1987, J PARALLEL DISTRIB C; HINKLE EB, 1985, DEC INT C ADV IM PRO; IBRAHIM H, 1985, JUN IEEE C COMP VIS; JARVIS JF, 1980, IEEE T PATTERN ANAL, V2, P77, DOI 10.1109/TPAMI.1980.4766975; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; NEVATIA R, 1982, MACHINE PERCEPTION; PAVLIDIS T, 1978, 238 PRINC U DEP EL E; PETKOVIC D, 1987, IEEE T PATTERN ANAL, V9, P306, DOI 10.1109/TPAMI.1987.4767903; PETKOVIC D, 1986, INT C PATTERN RECOGN; PETKOVIC D, 1985, NOV P IEEE WORKSH CO; PETKOVIC D, 1985, IBM RJ4942 RES REP; PETKOVIC D, 1985, NOV P IEEE WORKSH CO, P169; RICE TA, 1985, INTEGRATED TECHNOLOG; ROSENFEL.A, 1966, J ACM, V13, P471; SANZ JL, 1986, J OPT SOC AM     SEP; SANZ JL, 1987, IEEE T PATTERN ANAL, V9; SANZ JLC, 1985, PATTERN RECOGNITION; SANZ JLC, 1985, JUN IEEE C COMP VIS; SANZ JLC, 1985, P IEEE           JUN; SANZ JLC, 1987, COMMUN ACM       APR; SANZ JLC, 1985, J OPT SOC AM     NOV; SKLANSKY J, 1981, PATTERN CLASSIFIERS; STOFFEL JC, 1974, IEEE T COMPUT, V23; TAYLOR R, 1984, 2ND P C IND ROB KYOT; WESZKA JS, 1978, COMPUT VISION GRAPH, V7, P259, DOI 10.1016/0146-664X(78)90116-8	34	17	19	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1988	10	6					830	848		10.1109/34.9106	http://dx.doi.org/10.1109/34.9106			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q9971					2022-12-18	WOS:A1988Q997100006
J	TOUZANI, A; POSTAIRE, JG				TOUZANI, A; POSTAIRE, JG			MODE DETECTION BY RELAXATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											TOUZANI, A (corresponding author), UNIV SCI & TECH LILLE FLANDRES ARTOIS,F-59655 VILLENEUVE DASCQ,FRANCE.							BOCK AH, 1974, AUTOMATISHE KLASSIFI; CACOULLOS T, 1965, ANN I STAT MATH, V18, P179; DANKER AJ, 1981, IEEE T PATTERN ANAL, V3, P79, DOI 10.1109/TPAMI.1981.4767053; Devijver PA, 1982, PATTERN RECOGNITION; EIGEN DJ, 1974, IEEE T SYST MAN CYB, VSMC4, P284, DOI 10.1109/TSMC.1974.5409135; EKLUNDH JO, 1978, TR701 U MAR COMP SCI; FEKETE G, 1981, IEEE T PATTERN ANAL, V3, P459, DOI 10.1109/TPAMI.1981.4767131; FROMM FR, 1973, 1ST P JOINT C PATT R, P18; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; GITMAN I, 1973, IEEE T SYST MAN CYB, VSMC3, P66, DOI 10.1109/TSMC.1973.5408579; GITMAN I, 1970, IEEE T COMPUT, VC 19, P583, DOI 10.1109/T-C.1970.222992; HARTIGAN JA, 1977, 1ST P INT S DAT AN I; HARTIGAN JA, 1977, CLASSIFICATION CLUST, P45; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; KATZ JO, 1973, SYST ZOOL, V22, P295, DOI 10.2307/2412309; KITTLER J, 1976, PATTERN RECOGN, V8, P23, DOI 10.1016/0031-3203(76)90026-1; KOONTZ WLG, 1976, IEEE T COMPUT, V25, P936, DOI 10.1109/TC.1976.1674719; KOONTZ WLG, 1972, IEEE T COMPUT, VC 21, P171, DOI 10.1109/TC.1972.5008922; KOONTZ WLG, 1972, IEEE T COMPUT, VC 21, P967, DOI 10.1109/TC.1972.5009073; KOPP B, 1976, BIOMETR Z, V18, P473; LEV A, 1977, IEEE T SYST MAN CYB, V7, P435, DOI 10.1109/TSMC.1977.4309740; MIZOGUCHI R, 1976, IEEE T COMPUT, V25, P1109, DOI 10.1109/TC.1976.1674561; NAGIN PA, 1978, COINS788 U MASS AMH; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; PELEG S, 1980, IEEE T PATTERN ANAL, V2, P362, DOI 10.1109/TPAMI.1980.4767035; POSTAIRE JG, 1982, IEEE T PATTERN ANAL, V4, P663, DOI 10.1109/TPAMI.1982.4767322; POSTAIRE JG, 1983, REV STATISTIQUE APPL, V31, P17; POSTAIRE JG, 1981, IEEE T PATTERN ANAL, V3; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2; ROSENFELD A, 1981, IEEE T PATTERN ANAL, V3; RYZIN JV, 1969, ANN MATH STATIST, V40, P1765; VASSEUR CP, 1980, IEEE T SYST MAN CYBE, V10; ZUCKER SW, 1978, IEEE T SYST MAN CYB, V8, P41; ZUCKER SW, 1981, IEEE T PATTERN ANAL, V3, P117, DOI 10.1109/TPAMI.1981.4767069	35	17	17	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1988	10	6					970	978		10.1109/34.9120	http://dx.doi.org/10.1109/34.9120			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q9971					2022-12-18	WOS:A1988Q997100020
J	ASADA, M; ICHIKAWA, H; TSUJI, S				ASADA, M; ICHIKAWA, H; TSUJI, S			DETERMINING SURFACE ORIENTATION BY PROJECTING A STRIPE PATTERN	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									OSAKA UNIV, DEPT CONTROL ENGN, TOYONAKA, OSAKA 560, JAPAN; TOYOTA AUTOMOBILE CO, TOYOTA, AICHI, JAPAN	Osaka University	ASADA, M (corresponding author), UNIV MARYLAND, CTR AUTOMAT RES, COLLEGE PK, MD 20742 USA.							Asada M., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P1162; Asada M., 1987, Proceedings of the 1987 IEEE International Conference on Robotics and Automation (Cat. No.87CH2413-3), P787; ASADA M, 1985, 9TH P IJCAI, P895; BOLES RC, 1983, 1ST P INT S ROB RES, P413; BRADY M, 1982, COMPUT SURV, V14, P3, DOI 10.1145/356869.356871; ECHIGO T, 1985, 9TH P IJCAI; HAKALA DG, 1981, SIGGRAPH 81; IKEUCHI K, 1986, INT J ROBOT RES, V5, P46, DOI 10.1177/027836498600500103; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P122, DOI 10.1109/TPAMI.1983.4767365; KELLEY RB, 1982, IEEE T SYST MAN CYB, V12, P204, DOI 10.1109/TSMC.1982.4308804; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; Merickel M. B., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P53; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; OSHIMA M, 1979, PATTERN RECOGN, V11, P9, DOI 10.1016/0031-3203(79)90024-4; OSHIMA M, 1983, IEEE T PATTERN ANAL, V5, P353, DOI 10.1109/TPAMI.1983.4767405; POSDAMER JL, 1982, COMPUT VISION GRAPH, V18, P1, DOI 10.1016/0146-664X(82)90096-X; Stockman G., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P602; SUGIHARA K, 1984, 2 INT S ROB RES, P17; Tsuji S., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P1358; WANG YF, 1987, IEEE T PATTERN ANAL, V9, P129, DOI 10.1109/TPAMI.1987.4767878; WILL PM, 1971, 2ND P INT JOINT C AR, P66; WOODHAM RJ, 1978, 22ND P INT S SPIE, V155, P136; XU G, 1987, IEEE T PATTERN ANAL, V9, P332, DOI 10.1109/TPAMI.1987.4767908; YACHIDA M, 1982, 6TH P IEEE INT C PAT, P220; [No title captured]	25	17	39	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1988	10	5					749	754		10.1109/34.6787	http://dx.doi.org/10.1109/34.6787			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Q4255					2022-12-18	WOS:A1988Q425500018
J	CHEN, BD; SIY, P				CHEN, BD; SIY, P			FORWARD BACKWARD CONTOUR TRACING WITH FEEDBACK	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									WAYNE STATE UNIV,DEPT ELECT & COMP ENGN,DETROIT,MI 48202	Wayne State University								ASHKAR GP, 1978, COMPUT VISION GRAPH, V7, P331, DOI 10.1016/S0146-664X(78)80002-1; CHEN BD, 1983, APR P C ART INT, P621; CHIEN YP, 1974, COMPUT GRAPHICS IMAG, V3, P125; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; FREI W, 1977, IEEE T COMPUT, V26, P988, DOI 10.1109/TC.1977.1674733; LIU HK, 1977, COMPUT VISION GRAPH, V6, P123, DOI 10.1016/S0146-664X(77)80008-7; MARTELLI A, 1976, COMMUN ACM, V19, P73, DOI 10.1145/359997.360004; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; Persoon E., 1976, COMPUTER GRAPHICS IM, V5, P425, DOI DOI 10.1016/S0146-664X(76)80030-5; Robinson G.S., 1977, COMPUT VISION GRAPH, V6, P492, DOI 10.1016/s0146-664x(77)80024-5	11	17	18	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1987	9	3					438	446		10.1109/TPAMI.1987.4767925	http://dx.doi.org/10.1109/TPAMI.1987.4767925			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	H0768	22516636				2022-12-18	WOS:A1987H076800008
J	THATHACHAR, MAL; SASTRY, PS				THATHACHAR, MAL; SASTRY, PS			RELAXATION LABELING WITH LEARNING AUTOMATA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											THATHACHAR, MAL (corresponding author), INDIAN INST SCI, DEPT ELECT ENGN, BANGALORE 560012, KARNATAKA, INDIA.		Sastry, P. S./AAO-4694-2020					DAVIS LS, 1981, ARTIF INTELL, V17, P245, DOI 10.1016/0004-3702(81)90026-6; FAUGERAS OD, 1981, IEEE T PATTERN ANAL, V3, P412, DOI 10.1109/TPAMI.1981.4767127; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390; Kushner H., 1971, INTRO STOCHASTIC CON; KUSHNER HJ, 1984, SIAM J CONTROL OPTIM, V22, P13, DOI 10.1137/0322002; Kushner HJ., 1984, APPROXIMATION WEAK C; LAKSHIMIVARAHAN S, 1981, LEARNING ALGORITHMS; Mars P., 1981, STOCHASTIC DETERMINI; NARENDRA KS, 1974, IEEE T SYST MAN CYB, VSMC4, P323, DOI 10.1109/TSMC.1974.5408453; OLEARY DP, 1983, IEEE T SYST MAN CYB, V13, P618, DOI 10.1109/TSMC.1983.6313149; PELEG S, 1980, IEEE T PATTERN ANAL, V2, P362, DOI 10.1109/TPAMI.1980.4767035; PELEG S, 1979, COMPUT VISION GRAPH, V10, P235, DOI 10.1016/0146-664X(79)90003-0; RABIN MO, 1976, ALGORITHMS COMPLEXIT; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SASTRY PS, 1985, THESIS INDIAN I SCI; THATHACHAR MAL, 1985, IEEE T SYST MAN CYB, V15, P168, DOI 10.1109/TSMC.1985.6313407; THATHACHAR MAL, 1984, EE163 IND I SCI DEP; Tsetlin M. L, 1961, AUTOMAT REM CONTR+, V22, P1345; ZUCKER SW, 1981, IEEE T PATTERN ANAL, V3, P117, DOI 10.1109/TPAMI.1981.4767069; [No title captured]	23	17	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1986	8	2					256	268		10.1109/TPAMI.1986.4767779	http://dx.doi.org/10.1109/TPAMI.1986.4767779			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	A1073	21869344				2022-12-18	WOS:A1986A107300013
J	SHAPIRA, R				SHAPIRA, R			MORE ABOUT POLYHEDRA - INTERPRETATION THROUGH CONSTRUCTIONS IN THE IMAGE PLANE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MIT,ELECTR RES LAB,COGNIT INFORMAT PROC GRP,CAMBRIDGE,MA 02139	Massachusetts Institute of Technology (MIT)								Ballard D.H., 1982, COMPUTER VISION; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; DRAPER SW, 1981, ARTIF INTELL, V17, P461, DOI 10.1016/0004-3702(81)90032-1; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; HUFFMAN DA, 1977, MACH INTELL, V8, P493; Huffman David, 1977, MACHINE INTELLIGENCE, V8, P475; MACKWORTH AK, 1973, ARTIF INTELL, V4, P121, DOI 10.1016/0004-3702(73)90003-9; SHAPIRA R, 1978, IEEE T COMPUT, V27, P841, DOI 10.1109/TC.1978.1675204; SHAPIRA R, 1979, COMMUN ASS COMPUT MA, V22, P841; SUGIHARA K, 1978, COMPUT VISION GRAPH, V8, P382, DOI 10.1016/0146-664X(78)90064-3; WHITELEY W, 1979, STRUCT TOPOL, V1	11	17	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	1					1	16		10.1109/TPAMI.1985.4767614	http://dx.doi.org/10.1109/TPAMI.1985.4767614			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ABF09	21869236				2022-12-18	WOS:A1985ABF0900001
J	GOIN, JE				GOIN, JE			CLASSIFICATION BIAS OF THE K-NEAREST NEIGHBOR ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											GOIN, JE (corresponding author), GEOMETR DATA,999 W VALLEY RD,WAYNE,PA 19087, USA.							COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DASARATHY BV, 1977, SEP P INT C CYB SOC, P630; Duda R.O., 1973, J ROYAL STAT SOC SER; Fix E, 1951, NONPARAMETRIC DISCRI; FUKUNAGA K, 1972, INTRO STATISTICAL PA; GOIN JE, 1982, PATTERN RECOGN, V15, P263, DOI 10.1016/0031-3203(82)90077-2; GOIN JE, 1983, PATTERN RECOGN, V16, P125, DOI 10.1016/0031-3203(83)90015-8; SAMMON JW, 1970, 9TH P IEEE C AD PROC	8	17	18	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	3					379	381		10.1109/TPAMI.1984.4767533	http://dx.doi.org/10.1109/TPAMI.1984.4767533			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SR542	21869207				2022-12-18	WOS:A1984SR54200016
J	JACOBSON, L; WECHSLER, H				JACOBSON, L; WECHSLER, H			A THEORY FOR INVARIANT OBJECT RECOGNITION IN THE FRONTOPARALLEL PLANE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											JACOBSON, L (corresponding author), UNIV MINNESOTA, DEPT ELECT ENGN, MINNEAPOLIS, MN 55455 USA.							Bajcsy R., 1976, COMPUT GRAPHICS IMAG, V5, P52, DOI DOI 10.1016/S0146-664X(76)80005-6; BARTELT HO, 1980, OPT COMMUN, V32, P32, DOI 10.1016/0030-4018(80)90308-9; BASTIAANS MJ, 1979, J OPT SOC AM, V69, P1710, DOI 10.1364/JOSA.69.001710; BASTIAANS MJ, 1978, OPT COMMUN, V25, P26, DOI 10.1016/0030-4018(78)90080-9; BROUSIL JK, 1967, IEEE TRANS ELECTRON, VEC16, P818, DOI 10.1109/PGEC.1967.264727; CASASENT D, 1976, APPL OPTICS, V15, P1795, DOI 10.1364/AO.15.001795; CAVANAGH P, 1978, PERCEPTION, V7, P167, DOI 10.1068/p070167; CAVANAGH P, 1981, PERCEPTION, V10, P469, DOI 10.1068/p100469; CLAASEN TACM, 1980, PHILIPS J RES, V35, P372; CLAASEN TACM, 1980, PHILIPS J RES, V35, P217; CLAASEN TACM, 1980, PHILIPS J RES, V35, P276; GAFNI H, 1977, BIOL CYBERN, V28, P73, DOI 10.1007/BF00335287; GAFNI H, 1979, BIOL CYBERN, V32, P165, DOI 10.1007/BF00337393; JACOBSON L, 1982, NEW PARADIGM COMPUTA; JACOBSON L, 1983, P IEEE INT C ACOUST; JACOBSON L, 1983, P IEEE COMPUT SOC C; JACOBSON L, 1984, P INT C ROBOTICS ATL; JACOBSON L, 1982, 6TH P INT JOINT C PA; Jacobson L, 1982, PATTERN RECOGN LETT, V1, P61, DOI 10.1016/0167-8655(82)90053-8; KULIKOWSKI JJ, 1982, BIOL CYBERN, V43, P187, DOI 10.1007/BF00319978; MARR D, 1979, MIT AI518 MEM; Marr D., 1982, VISION; OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022; SCHENKAR P, 1981, P IEE INT C AC SPEEC, P1144; SCHWARTZ EL, 1980, VISION RES, V20, P645, DOI 10.1016/0042-6989(80)90090-5; SCHWARTZ EL, 1977, BIOL CYBERN, V25, P181, DOI 10.1007/BF01885636; SCHWARTZ EL, 1981, PERCEPTION, V10, P455, DOI 10.1068/p100455; WEIMAN CFR, 1979, COMPUT VISION GRAPH, V11, P197, DOI 10.1016/0146-664X(79)90089-3; Wigner E, 1932, PHYS REV, V40, P0749, DOI 10.1103/PhysRev.40.749	29	17	20	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	3					325	331		10.1109/TPAMI.1984.4767525	http://dx.doi.org/10.1109/TPAMI.1984.4767525			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SR542	21869199				2022-12-18	WOS:A1984SR54200008
J	LIN, WC; FU, KS				LIN, WC; FU, KS			A SYNTACTIC APPROACH TO 3-D OBJECT REPRESENTATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											LIN, WC (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.		Lin, Wei-Chung/B-7248-2009					Aggarwal J. K., 1981, Progress in pattern recognition. Vol.1, P377; BADLER N, 1978, COMPUT GRAPHICS, V12, P153; BALLARD DH, 1982, COMPUTER VISION, pCH9; BARNHILL RE, 1977, DATA STRUCTURES COMP; BARNHILL RE, 1974, COMPTER AIDED GEOMET; BAUMGART BG, 1974, AIM249 STANF ART INT; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BINFORD TO, 1971, DEC P IEEE C DEC CON; CHASEN S, 1978, GEOMETRIC PRINCIPLES; Faux ID, 1979, COMPUTATIONAL GEOMET; FEDER J, 1971, INFORM SCIENCES, V3, P225, DOI 10.1016/S0020-0255(71)80008-7; FOLEY JD, 1982, FUNDAMENTALS INTERAC, pCH13; Forrest A., 1972, COMPUT GRAPHICS IMAG, V1, P341; FU KS, 1982, SYNTACTIC PATTERN RE; JACKINS CL, 1980, COMPUT VISION GRAPH, V14, P249, DOI 10.1016/0146-664X(80)90055-6; KANADE T, 1980, ARTIF INTELL, V13, P279, DOI 10.1016/0004-3702(80)90004-1; MANTYLA M, 1982, IEEE COMPUT GRAPH, V2, P17; MARCH L, 1974, GEOMETRY ENV; NEVATIA R, 1982, MACHINE PERCEPTION, P72; NEWELL ME, 1979, P WORKSHOP REPRESENT, pK1; Olmsted J.M.H., 1947, SOLID ANAL GEOMETRY; REQUICHA AAG, 1980, COMPUT SURVEYS, V12; REQUICHA AAG, 1982, IEEE COMPUT GRAPH, P9; SCHUDY R, 1979, 46 U ROCH DEP COMP S; SCHUDY R, 1979, COMPUTER MODEL EXTRA; Shapiro L. G., 1980, Proceedings of the Workshop on Picture Data Description and Management, P109; SRIHARI SN, 1981, COMPUT SURVEYS, V13	27	17	18	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	3					351	364		10.1109/TPAMI.1984.4767528	http://dx.doi.org/10.1109/TPAMI.1984.4767528			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	SR542	21869202				2022-12-18	WOS:A1984SR54200011
J	OROURKE, J; SLOAN, KR				OROURKE, J; SLOAN, KR			DYNAMIC QUANTIZATION - 2 ADAPTIVE DATA-STRUCTURES FOR MULTIDIMENSIONAL SPACES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MIT,ARCHITECTURE MACHINE GRP,CAMBRIDGE,MA 02139	Massachusetts Institute of Technology (MIT)	OROURKE, J (corresponding author), JOHNS HOPKINS UNIV,DEPT ELECT ENGN & COMP SCI,BALTIMORE,MD 21218, USA.							BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BENTLEY JL, 1979, IEEE T SOFTWARE ENG, V5, P333, DOI 10.1109/TSE.1979.234200; BROWN C, 1983, TR125 U ROCH DEP COM; COHEN M, 1977, PATTERN RECOGN, V9, P95, DOI 10.1016/0031-3203(77)90020-6; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; FRIEDMANN JH, 1975, IEEE T COMPUT    OCT; FRIEDMANN JH, 1977, ACM T MATH SOFTWARE, V3; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; O'Rourke J., 1981, 7TH P INT JOINT C AR, V2, P737; OROURKE J, 1981, AUG P IEEE C PATT RE, P82; OROURKE J, 1981, 1981 P C INF SCI SYS, P301; OROURKE J, 1981, JHUEE811 J HOPK U TE; SHAPIRO SD, 1978, COMPUT VISION GRAPH, V8, P219, DOI 10.1016/0146-664X(78)90050-3; Sloan K. R., 1981, 7 IJCAI, P734; SLOAN KR, 1980, 5TH P INT C PATT REC, P174; SLOAN KR, UNPUB DYNAMICALLY QU; Tanimoto S., 1975, COMPUTER GRAPHICS IM, V4, P104	18	17	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	3					266	280		10.1109/TPAMI.1984.4767519	http://dx.doi.org/10.1109/TPAMI.1984.4767519			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SR542	21869193				2022-12-18	WOS:A1984SR54200002
J	RAY, R; BIRK, J; KELLEY, RB				RAY, R; BIRK, J; KELLEY, RB			ERROR ANALYSIS OF SURFACE NORMALS DETERMINED BY RADIOMETRY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									HEWLETT PACKARD CO,PALO ALTO,CA 93303; UNIV RHODE ISL,ROBOT RES CTR,KINGSTON,RI 02881	Hewlett-Packard; University of Rhode Island	RAY, R (corresponding author), OBJECT RECOGNIT SYST INC,PRINCETON,NJ 08540, USA.							Andrews H.C., 1977, DIGITAL IMAGE RESTOR; BIRK J, 1979, APR7413935 U RHOD IS; CHAPPELL A, 1978, TEXAS INSTRUMENTS EL; CHEN N, 1979, THESIS U RHODE ISLAN; Dahlquist G., 1974, NUMERICAL METHODS; FORBUS K, 1978, SPIE IMAGE UNDERSTAN, V55, P50; FORSYTHE G, 1970, CS147 STANF U TECH R; GOURAUD H, 1971, IEEE T COMPUT, VC 20, P623, DOI 10.1109/T-C.1971.223313; HARALICK RM, 1976, DIGITAL PICTURE ANAL; HILDEBRAND FB, 1976, ADV CALCULUS APPLICA; HORN B, 1975, MIT AIM335 ART INT L; HORN B, 1978, MIT AIM490 ART INT L; HORN B, 1970, MIT MAC TR79 DEP EL; HORN B, 1978, MIT AIM498 ART INT L; Horn B. K., 1974, COMPUT VISION GRAPH, V3, P277, DOI DOI 10.1016/0146-664X(74)90022-7; HORN BKP, 1978, COMMUN ACM, V21, P914, DOI 10.1145/359642.359647; HORN BKP, 1979, APR DARPA IM UND WOR, P79; IKEUCHI K, 1979, MIT AIM539 ART INT L; IKEUCHI K, 1980, 5TH P INT C PATT REC, V2; Keitz H.A.E, 1971, LIGHT CALCULATIONS M; KENDER JR, 1980, P IJCAI, P475; KINGSLAKE R, 1965, APPLIED OPTICS OPTIC, V2; KINGSLAKE R, 1965, APPLIED OPTICS OPTIC, V1; KRAKAUER L, 1971, MIT MAC TR82 DEP EL; LAVIN EP, 1971, MONOGRAPHS APPLIED O, V2; MARR D, 1979, COMPUTER VISION SYST; MARR D, 1976, MIT AIM364 ART INT L; NICODEMUS FE, 1977, NBS MONOGRAPH US DEP, V160; PHONG BT, 1975, COMMUN ASS COMPUT MA, V18; THOMAS GB, 1972, CALCULUS ANAL GEOMET; ULLMAN S, 1979, ARTIFICIAL INTELLIGE, V2; WOODHAM R, 1978, SPIE IMAGE UNDERSTAN, V155; WOODHAM RJ, 1978, MIT AITR457 ART INT; [No title captured]	34	17	17	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	6					631	645		10.1109/TPAMI.1983.4767454	http://dx.doi.org/10.1109/TPAMI.1983.4767454			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RV488	21869151				2022-12-18	WOS:A1983RV48800011
J	KIM, CE; ROSENFELD, A				KIM, CE; ROSENFELD, A			CONVEX DIGITAL SOLIDS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MARYLAND,CTR COMP SCI,DEPT COMP SCI,COMP VIS LAB,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park								HERMAN GT, 1978, COMPUT VISION GRAPH, V7, P130, DOI 10.1016/S0146-664X(78)80018-5; KIM CE, 1982, IEEE T PATTERN ANAL, V4, P149, DOI 10.1109/TPAMI.1982.4767221; KIM CE, 1982, COMPUT VISION GRAPH, V18, P369, DOI 10.1016/0146-664X(82)90005-3; KIM CE, 1981, IEEE T PATTERN ANAL, V3, P617, DOI 10.1109/TPAMI.1981.4767162; KIM CE, UNPUB PATTERN RECOGN; KIM CE, 1980, TR957 U MAR COMP VIS; LIU HK, 1977, COMPUT VISION GRAPH, V6, P123, DOI 10.1016/S0146-664X(77)80008-7; Minsky M., 1969, PERCEPTRONS; PREPARATA FP, 1977, COMMUN ACM, V20, P87, DOI 10.1145/359423.359430; REDDY DR, 1978, CMUCS78113; ROSENFELD A, 1974, IEEE T COMPUT, VC 23, P1264, DOI 10.1109/T-C.1974.223845; ROSENFELD A, 1970, J ACM, V17, P146, DOI 10.1145/321556.321570; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SKLANSKY J, 1970, PATTERN RECOGN, V2, P3, DOI 10.1016/0031-3203(70)90037-3; SKLANSKY J, 1972, IEEE T COMPUT, VC 21, P1355, DOI 10.1109/T-C.1972.223507; SKLANSKY J, 1972, IEEE T COMPUT, V21, P250; Zucker S. W., 1979, Proceedings of the 1979 IEEE Computer Society Conference on Pattern Recognition and Image Processing, P162	17	17	17	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	6					612	618		10.1109/TPAMI.1982.4767314	http://dx.doi.org/10.1109/TPAMI.1982.4767314			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PS237	22499635				2022-12-18	WOS:A1982PS23700006
J	NEVATIA, R; PRICE, KE				NEVATIA, R; PRICE, KE			LOCATING STRUCTURES IN AERIAL IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV SO CALIF,DEPT COMP SCI,LOS ANGELES,CA 90089; UNIV SO CALIF,DEPT ELECT ENGN SYST,LOS ANGELES,CA 90089; UNIV SO CALIF,INST IMAGE PROC,LOS ANGELES,CA 90089	University of Southern California; University of Southern California; University of Southern California	NEVATIA, R (corresponding author), UNIV SO CALIF,DEPT ELECT ENGN,LOS ANGELES,CA 90089, USA.							BAJCSY R, 1976, IEEE T SYST MAN CYB, V6, P623, DOI 10.1109/TSMC.1976.4309568; BAJCSY R, 1974, 2ND P INT JOINT C PA, P174; BARROW H, 1976, INTERATIVE AIDS CART; FAUGERAS OD, 1981, IEEE T PATTERN ANAL, V3, P633, DOI 10.1109/TPAMI.1981.4767164; GARVEY TD, 1974, 2ND P INT JOINT C PA, P162; MILGRAM DL, 1979, COMPUT VISION GRAPH, V9, P82, DOI 10.1016/0146-664X(79)90085-6; NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0; OHLANDER R, 1978, COMPUT VISION GRAPH, V8, P313, DOI 10.1016/0146-664X(78)90060-6; PRICE K, 1979, IEEE T PATTERN ANAL, V1, P110, DOI 10.1109/TPAMI.1979.4766884; REISER JF, 1976, STANCS76574 STANF U; TENENBAUM JM, 1973, COMPUTER GRAPHICS IM, V2, P308	11	17	21	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	5					476	484		10.1109/TPAMI.1982.4767291	http://dx.doi.org/10.1109/TPAMI.1982.4767291			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PG894	21869066				2022-12-18	WOS:A1982PG89400003
J	JACOBUS, CJ; CHIEN, RT				JACOBUS, CJ; CHIEN, RT			2 NEW EDGE DETECTORS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV ILLINOIS,COORDINATED SCI LAB,URBANA,IL 61801	University of Illinois System; University of Illinois Urbana-Champaign								BRICE CR, 1970, ARTIF INTELL, V1, P205, DOI 10.1016/0004-3702(70)90008-1; BURR D, 1977, THESIS U ILLINOIS; DEUTSCH ES, 1978, IEEE T COMPUT, V27, P205, DOI 10.1109/TC.1978.1675073; FELDMAN JA, 1974, ARTIF INTELL, V5, P349, DOI 10.1016/0004-3702(74)90002-2; GRIFFITH AK, 1973, J ACM, V20, P62, DOI 10.1145/321738.321744; HANSON A, 1975, 3RD P MILW S AUT COM, P407; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; HUECKEL MH, 1974, J ACM, V21, P350, DOI 10.1145/321812.321830; HUECKEL MH, 1973, J ACM, V20, P634, DOI 10.1145/321784.321791; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; JACOBUS C, 1978, CSL T60 U ILL URB; LINDGREN BW, 1976, STATISTICAL THEORY; MARR D, 1974, MIT AI340 MEM; MERO L, 1975, 4TH P INT JOINT C AR, P650; OGORMAN F, 1973, 3RD P IJC AI KYOT, P543; OHLANDER R, 1975, THESIS CARNEGIE MELL; PERKINS W, 1977, GMR2410; Roberts L, 1965, MACHINE PERCEPTION 3; ROSENFELD A, 1972, IEEE T COMPUT, VC 21, P677, DOI 10.1109/T-C.1972.223573; SCHACTER BJ, 1976, SIGART NEWSL, V58, P16; SHIRAI Y, 1975, 4TH P INT JOINT C AR, P674; TENENBAUM JM, 1977, ARTIF INTELL, V8, P241, DOI 10.1016/0004-3702(77)90031-5; YAKIMOVSKY Y, 1976, J ACM, V23, P599, DOI 10.1145/321978.321981	24	17	18	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	5					581	593		10.1109/TPAMI.1981.4767149	http://dx.doi.org/10.1109/TPAMI.1981.4767149			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MQ358	21868976				2022-12-18	WOS:A1981MQ35800007
J	MEIRI, AZ				MEIRI, AZ			ON MONOCULAR PERCEPTION OF 3-D MOVING-OBJECTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											MEIRI, AZ (corresponding author), RAFAEL,HAIFA,ISRAEL.							BONDE T, 1979, APR WORKSH COMP AN T, P44; HADANI I, UNPUBLISHED; HADANI I, 1980, THESIS HAIFA; ROACH JW, 1979, AMBIGUITY 3 DIMENSIO, P46; WEAST RC, 1964, HDB CHEM PHYSICS	5	17	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	6					582	583		10.1109/TPAMI.1980.6447706	http://dx.doi.org/10.1109/TPAMI.1980.6447706			2	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KS962					2022-12-18	WOS:A1980KS96200012
J	MOORE, RK				MOORE, RK			DYNAMIC-PROGRAMMING ALGORITHM FOR THE DISTANCE BETWEEN 2 FINITE AREAS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											MOORE, RK (corresponding author), UNIV LONDON UNIV COLL, DEPT PHONET & LINGUIST, LONDON WC1E 6BT, ENGLAND.		Moore, Roger K/B-1985-2016	Moore, Roger K/0000-0003-0065-3311				BAHL LR, 1975, IEEE T INFORM THEORY, V21, P404, DOI 10.1109/TIT.1975.1055419; ITAKURA F, 1975, IEEE T ACOUST SPEECH, VAS23, P67, DOI 10.1109/TASSP.1975.1162641; OKUDA T, 1976, IEEE T COMPUT, V25, P172, DOI 10.1109/TC.1976.5009232; Sellers P. H., 1974, Journal of Combinatorial Theory, Series A, V16, P253, DOI 10.1016/0097-3165(74)90050-8; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; WHITE GM, 1976, IEEE T ACOUST SPEECH, V24, P183, DOI 10.1109/TASSP.1976.1162779	6	17	17	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	1					86	88		10.1109/TPAMI.1979.4766879	http://dx.doi.org/10.1109/TPAMI.1979.4766879			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HA303	21868834				2022-12-18	WOS:A1979HA30300010
J	Li, CY; Guo, CL; Han, LH; Jiang, J; Cheng, MM; Gu, JW; Loy, CC				Li, Chongyi; Guo, Chunle; Han, Linghao; Jiang, Jun; Cheng, Ming-Ming; Gu, Jinwei; Loy, Chen Change			Low-Light Image and Video Enhancement Using Deep Learning: A Survey	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Lighting; Deep learning; Feature extraction; Supervised learning; Cameras; Training data; Photography; Image and video restoration; low-light image dataset; low-light image enhancement platform; computational photography	DYNAMIC HISTOGRAM EQUALIZATION; NETWORK; REPRESENTATION; ILLUMINATION	Low-light image enhancement (LLIE) aims at improving the perception or interpretability of an image captured in an environment with poor illumination. Recent advances in this area are dominated by deep learning-based solutions, where many learning strategies, network structures, loss functions, training data, etc. have been employed. In this paper, we provide a comprehensive survey to cover various aspects ranging from algorithm taxonomy to unsolved open issues. To examine the generalization of existing methods, we propose a low-light image and video dataset, in which the images and videos are taken by different mobile phones' cameras under diverse illumination conditions. Besides, for the first time, we provide a unified online platform that covers many popular LLIE methods, of which the results can be produced through a user-friendly web interface. In addition to qualitative and quantitative evaluation of existing methods on publicly available and our proposed datasets, we also validate their performance in face detection in the dark. This survey together with the proposed dataset and online platform could serve as a reference source for future study and promote the development of this research field. The proposed platform and dataset as well as the collected methods, datasets, and evaluation metrics are publicly available and will be regularly updated. Project page: https://www.mmlab-ntu.com/project/lliv_survey/index.html.	[Li, Chongyi; Loy, Chen Change] Nanyang Technol Univ NTU, S Lab, Singapore 639798, Singapore; [Guo, Chunle; Han, Linghao; Cheng, Ming-Ming] Nankai Univ, Coll Comp Sci, Tianjin 300071, Peoples R China; [Jiang, Jun; Gu, Jinwei] SenseTime, San Jose, CA 95110 USA	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Nankai University	Loy, CC (corresponding author), Nanyang Technol Univ NTU, S Lab, Singapore 639798, Singapore.	chongyi.li@ntu.edu.sg; guochunle@nankai.edu.cn; lhhan@mail.nankai.edu.cn; jiangjun@sensebrain.site; cmm@nankai.edu.cn; gujinwei@sensebrain.site; ccloy@ntu.edu.sg	Cheng, Ming-Ming/A-2527-2009	Cheng, Ming-Ming/0000-0001-5550-8758; Loy, Chen Change/0000-0001-5345-1591	RIE2020 Industry Alignment Fund Industry Collaboration Projects (IAF-ICP) Funding Initiative; NTU SUG; NAP grant; CAAI-Huawei MindSpore Open Fund	RIE2020 Industry Alignment Fund Industry Collaboration Projects (IAF-ICP) Funding Initiative; NTU SUG(Nanyang Technological University); NAP grant; CAAI-Huawei MindSpore Open Fund	This work was supported under the RIE2020 Industry Alignment Fund Industry Collaboration Projects (IAF-ICP) Funding Initiative, as well as cash and in-kind contribution from the industry partner(s). It was also partially supported by the NTU SUG and NAP grant. Chunle Guo is sponsored by CAAIHuawei MindSpore Open Fund. Chongyi Li and Chunle Guo contribute equally.	Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734; Blau Y, 2018, PROC CVPR IEEE, P6228, DOI 10.1109/CVPR.2018.00652; Bychkovsky V, 2011, PROC CVPR IEEE, P97; Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218; Chen Change Loy, 2020, Arxiv, DOI arXiv:2010.13412; Chen C, 2019, IEEE I CONF COMP VIS, P3184, DOI 10.1109/ICCV.2019.00328; Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347; Chen QF, 2017, IEEE I CONF COMP VIS, P2516, DOI 10.1109/ICCV.2017.273; Chen YS, 2018, PROC CVPR IEEE, P6306, DOI 10.1109/CVPR.2018.00660; Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733; Deng J., 2009, P 2009 IEEE C COMP V, P248, DOI DOI 10.1109/CVPR.2009.5206848; Deng YB, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P870, DOI 10.1145/3240508.3240531; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Fan MH, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2317, DOI 10.1145/3394171.3413757; Fang YM, 2020, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR42600.2020.00373; Fangchen Liu, 2020, Arxiv, DOI arXiv:1805.04687; Fu XY, 2021, INT J COMPUT VISION, V129, P1691, DOI 10.1007/s11263-020-01428-6; Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186; Fu XY, 2015, IEEE T IMAGE PROCESS, V24, P4965, DOI 10.1109/TIP.2015.2474701; Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592; Gu ZH, 2020, IEEE T IMAGE PROCESS, V29, P3239, DOI 10.1109/TIP.2019.2958144; Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185; Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450; Hao SJ, 2020, IEEE T MULTIMEDIA, V22, P3025, DOI 10.1109/TMM.2020.2969790; He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213; Hu YM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3181974; Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280; Jain V., 2008, P ADV NEUR INF PROC, V21, P1, DOI DOI 10.5555/2981780.2981876; Jiang HY, 2019, IEEE I CONF COMP VIS, P7323, DOI 10.1109/ICCV.2019.00742; Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462; Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356; LAND EH, 1986, P NATL ACAD SCI USA, V83, P3078, DOI 10.1073/pnas.83.10.3078; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059; Lee C, 2012, IEEE T IMAGE PROCESS, V21, P80, DOI 10.1109/TIP.2011.2159387; Li CY, 2021, IEEE T PATTERN ANAL, V44, P4225, DOI 10.1109/TPAMI.2021.3063604; Li CY, 2018, PATTERN RECOGN LETT, V104, P15, DOI 10.1016/j.patrec.2018.01.010; Li J, 2019, PROC CVPR IEEE, P5055, DOI 10.1109/CVPR.2019.00520; Li JQ, 2021, IEEE T MULTIMEDIA, V23, P3153, DOI 10.1109/TMM.2020.3021243; Li JJ, 2021, IEEE T CIRC SYST VID, V31, P4227, DOI 10.1109/TCSVT.2021.3049940; Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539; Lim S, 2021, IEEE T MULTIMEDIA, V23, P4272, DOI 10.1109/TMM.2020.3039361; Liu JY, 2021, INT J COMPUT VISION, V129, P1153, DOI 10.1007/s11263-020-01418-8; Liu RS, 2021, PROC CVPR IEEE, P10556, DOI 10.1109/CVPR46437.2021.01042; Loh YP, 2019, COMPUT VIS IMAGE UND, V178, P30, DOI 10.1016/j.cviu.2018.10.010; Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008; Lu K, 2021, IEEE T MULTIMEDIA, V23, P4093, DOI 10.1109/TMM.2020.3037526; Lv FF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1450, DOI 10.1145/3394171.3413925; Lv J. W. Feifan, 2018, BR MACH VIS C; Ma C, 2017, COMPUT VIS IMAGE UND, V158, P1, DOI 10.1016/j.cviu.2016.12.009; Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726; Ni ZK, 2020, IEEE T IMAGE PROCESS, V29, P9140, DOI 10.1109/TIP.2020.3023615; Park S, 2017, IEEE T CONSUM ELECTR, V63, P178, DOI 10.1109/TCE.2017.014847; Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412; Ren XT, 2020, IEEE T IMAGE PROCESS, V29, P5862, DOI 10.1109/TIP.2020.2984098; Ronneberger O., 2015, P MED IM COMP ASS IN, P234, DOI DOI 10.1007/978-3-319-24574-4_28; Simonyan K., 2015, VERY DEEP CONVOLUTIO; Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677; Triantafyllidou Danai, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P103, DOI 10.1007/978-3-030-58601-0_7; Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984; Wang LW, 2020, IEEE T IMAGE PROCESS, V29, P7984, DOI 10.1109/TIP.2020.3008396; Wang RX, 2019, PROC CVPR IEEE, P6842, DOI 10.1109/CVPR.2019.00701; Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309; Wang WC, 2020, IEEE ACCESS, V8, P87884, DOI 10.1109/ACCESS.2020.2992749; Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002; Wang Y, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2015, DOI 10.1145/3343031.3350983; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wei C., 2018, P BRIT MACH VIS C; Whittle P., 1994, BRIGHTNESS LIGHTNESS, P35; Xu K, 2020, PROC CVPR IEEE, P2278, DOI 10.1109/CVPR42600.2020.00235; Xu QY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P1184, DOI 10.1109/ICInfA.2015.7279466; Xue TF, 2019, INT J COMPUT VISION, V127, P1106, DOI 10.1007/s11263-018-01144-2; Yan ZC, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2790296; Yang WH, 2021, IEEE T IMAGE PROCESS, V30, P3461, DOI 10.1109/TIP.2021.3062184; Yang WH, 2021, IEEE T IMAGE PROCESS, V30, P2072, DOI 10.1109/TIP.2021.3050850; Yang WH, 2020, PROC CVPR IEEE, P3060, DOI 10.1109/CVPR42600.2020.00313; Yang WH, 2017, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2017.183; Yu RS, 2018, ADV NEUR IN, V31; Yuan Y., 2019, ARXIV; Zeng H, 2022, IEEE T PATTERN ANAL, V44, P2058, DOI 10.1109/TPAMI.2020.3026740; Zhang F, 2021, PROC CVPR IEEE, P4965, DOI 10.1109/CVPR46437.2021.00493; Zhang L, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1623, DOI 10.1145/3343031.3351069; Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068; Zhang YH, 2021, INT J COMPUT VISION, V129, P1013, DOI 10.1007/s11263-020-01407-x; Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926; Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865; Zhao ZJ, 2022, IEEE T CIRC SYST VID, V32, P1076, DOI 10.1109/TCSVT.2021.3073371; Zhu AQ, 2020, IEEE INT CON MULTI; Zhu MF, 2020, AAAI CONF ARTIF INTE, V34, P13106	89	16	16	18	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2022	44	12					9396	9416		10.1109/TPAMI.2021.3126387	http://dx.doi.org/10.1109/TPAMI.2021.3126387			21	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	6A4XX	34752382	Green Submitted			2022-12-18	WOS:000880661400060
J	Zhang, DW; Zeng, WY; Yao, JR; Han, JW				Zhang, Dingwen; Zeng, Wenyuan; Yao, Jieru; Han, Junwei			Weakly Supervised Object Detection Using Proposal- and Semantic-Level Relationships	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cognition; Proposals; Object detection; Supervised learning; Semantics; Task analysis; Network architecture; Weakly supervised object detection; multiple-instance learning; graphical convolutional network		In recent years, weakly supervised object detection has attracted great attention in the computer vision community. Although numerous deep learning-based approaches have been proposed in the past few years, such an ill-posed problem is still challenging and the learning performance is still behind the expectation. In fact, most of the existing approaches only consider the visual appearance of each proposal region but ignore to make use of the helpful context information. To this end, this paper introduces two levels of context into the weakly supervised learning framework. The first one is the proposal-level context, i.e., the relationship of the spatially adjacent proposals. The second one is the semantic-level context, i.e., the relationship of the co-occurring object categories. Therefore, the proposed weakly supervised learning framework contains not only the cognition process on the visual appearance but also the reasoning process on the proposal- and semantic-level relationships, which leads to the novel deep multiple instance reasoning framework. Specifically, built upon a conventional CNN-based network architecture, the proposed framework is equipped with two additional graph convolutional network-based reasoning models to implement object location reasoning and multi-label reasoning within an end-to-end network training procedure. Comprehensive experiments on the widely used PASCAL VOC and MS COCO benchmarks have been implemented, which demonstrate the superior capacity of the proposed approach when compared with other state-of-the-art methods and baseline models.	[Zhang, Dingwen; Zeng, Wenyuan; Yao, Jieru; Han, Junwei] Northwestern Polytech Univ, Sch Automat, Brain & Artificial Intelligence Lab, Xian 710072, Peoples R China	Northwestern Polytechnical University	Han, JW (corresponding author), Northwestern Polytech Univ, Sch Automat, Brain & Artificial Intelligence Lab, Xian 710072, Peoples R China.	zdw@xidian.edu.cn; zwy1996@mail.nwpu.edu.cn; jieruyao@126.com; junweihan2010@gmail.com			Key R&D Program of Guangdong Province [2019B010110001]; National Science Foundation of China [61876140, U1801265]; Research Funds for Interdisciplinary subject, NWPU	Key R&D Program of Guangdong Province; National Science Foundation of China(National Natural Science Foundation of China (NSFC)); Research Funds for Interdisciplinary subject, NWPU	This work was supported in part by the Key R&D Program of Guangdong Province (2019B010110001), the National Science Foundation of China under Grants 61876140 and U1801265, and Research Funds for Interdisciplinary subject, NWPU.	Arun A, 2019, PROC CVPR IEEE, P9424, DOI 10.1109/CVPR.2019.00966; Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311; Chen TS, 2019, IEEE I CONF COMP VIS, P522, DOI 10.1109/ICCV.2019.00061; Chen ZQ, 2019, PROC CVPR IEEE, P5932, DOI 10.1109/CVPR.2019.00609; Cinbis RG, 2014, PROC CVPR IEEE, P2409, DOI 10.1109/CVPR.2014.309; Deselaers T, 2012, INT J COMPUT VISION, V100, P275, DOI 10.1007/s11263-012-0538-3; Diba A, 2017, PROC CVPR IEEE, P5131, DOI 10.1109/CVPR.2017.545; Durand T, 2019, PROC CVPR IEEE, P647, DOI 10.1109/CVPR.2019.00074; Gao JY, 2019, PROC CVPR IEEE, P4644, DOI 10.1109/CVPR.2019.00478; Gao MF, 2018, LECT NOTES COMPUT SC, V11205, P155, DOI 10.1007/978-3-030-01246-5_10; Gao Y, 2019, IEEE I CONF COMP VIS, P9833, DOI 10.1109/ICCV.2019.00993; Ge WF, 2018, PROC CVPR IEEE, P1277, DOI 10.1109/CVPR.2018.00139; Han JW, 2021, IEEE T PATTERN ANAL, V43, P1423, DOI 10.1109/TPAMI.2019.2949562; Jiang B, 2019, PROC CVPR IEEE, P11305, DOI 10.1109/CVPR.2019.01157; Kanazawa A, 2016, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2016.354; Kantorov V, 2016, LECT NOTES COMPUT SC, V9909, P350, DOI 10.1007/978-3-319-46454-1_22; Kipf T. N., 2017, INT C LEARN REPR, DOI [DOI 10.1109/ICDM.2008.17, DOI 10.1109/ICDM.2019.00070]; Kosugi S, 2019, IEEE I CONF COMP VIS, P6063, DOI 10.1109/ICCV.2019.00616; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Li GH, 2019, IEEE I CONF COMP VIS, P9266, DOI 10.1109/ICCV.2019.00936; Liu ZY, 2019, IEEE I CONF COMP VIS, P3898, DOI 10.1109/ICCV.2019.00400; Ma XH, 2019, PROC CVPR IEEE, P8258, DOI 10.1109/CVPR.2019.00846; Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383; Park J, 2019, IEEE I CONF COMP VIS, P6518, DOI 10.1109/ICCV.2019.00662; Pont-Tuset J, 2017, IEEE T PATTERN ANAL, V39, P128, DOI 10.1109/TPAMI.2016.2537320; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74; Shen YH, 2019, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.2019.00079; Shi Z, 2013, IEEE I CONF COMP VIS, P2984, DOI 10.1109/ICCV.2013.371; Singh KK, 2019, PROC CVPR IEEE, P9406, DOI 10.1109/CVPR.2019.00964; Su SC, 2016, PROC CVPR IEEE, pCP40, DOI 10.1109/CVPR.2016.382; Tang P, 2018, LECT NOTES COMPUT SC, V11215, P370, DOI 10.1007/978-3-030-01252-6_22; Tang P, 2020, IEEE T PATTERN ANAL, V42, P176, DOI 10.1109/TPAMI.2018.2876304; Tang P, 2017, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2017.326; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Wan F, 2019, PROC CVPR IEEE, P2194, DOI 10.1109/CVPR.2019.00230; Wan F, 2018, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2018.00141; Wang JJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P971; Wang XL, 2018, LECT NOTES COMPUT SC, V11209, P413, DOI 10.1007/978-3-030-01228-1_25; Wang ZD, 2019, PROC CVPR IEEE, P1117, DOI 10.1109/CVPR.2019.00121; Wei YC, 2018, LECT NOTES COMPUT SC, V11215, P454, DOI 10.1007/978-3-030-01252-6_27; Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444; Yang K, 2019, IEEE I CONF COMP VIS, P8371, DOI 10.1109/ICCV.2019.00846; Yang ZH, 2019, PROC CVPR IEEE, P2912, DOI 10.1109/CVPR.2019.00303; Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42; Ye KR, 2019, IEEE I CONF COMP VIS, P9685, DOI 10.1109/ICCV.2019.00978; Zeng RH, 2019, IEEE I CONF COMP VIS, P7093, DOI 10.1109/ICCV.2019.00719; Zeng ZY, 2019, IEEE I CONF COMP VIS, P8291, DOI 10.1109/ICCV.2019.00838; Zhang DW, 2019, IEEE T CIRC SYST VID, V29, P3622, DOI 10.1109/TCSVT.2018.2884173; Zhang DW, 2019, INT J COMPUT VISION, V127, P363, DOI 10.1007/s11263-018-1112-4; Zhang DW, 2020, IEEE T PATTERN ANAL, V42, P475, DOI 10.1109/TPAMI.2018.2881114; Zhang XP, 2018, LECT NOTES COMPUT SC, V11207, P248, DOI 10.1007/978-3-030-01219-9_15; Zhang XP, 2018, PROC CVPR IEEE, P4262, DOI 10.1109/CVPR.2018.00448; Zhang YQ, 2018, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.2018.00103; Zhongzheng Ren, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10595, DOI 10.1109/CVPR42600.2020.01061	58	16	16	49	76	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2022	44	6					3349	3363		10.1109/TPAMI.2020.3046647	http://dx.doi.org/10.1109/TPAMI.2020.3046647			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1R1DD	33351751				2022-12-18	WOS:000803117500040
J	Ma, HC; Liu, D; Yan, N; Li, HQ; Wu, F				Ma, Haichuan; Liu, Dong; Yan, Ning; Li, Houqiang; Wu, Feng			End-to-End Optimized Versatile Image Compression With Wavelet-Like Transform	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image coding; Quantization (signal); Wavelet transforms; Bit rate; Entropy coding; Rate-distortion; Deep network; end-to-end optimization; image compression; lossless compression; lossy compression; wavelet transform		Built on deep networks, end-to-end optimized image compression has made impressive progress in the past few years. Previous studies usually adopt a compressive auto-encoder, where the encoder part first converts image into latent features, and then quantizes the features before encoding them into bits. Both the conversion and the quantization incur information loss, resulting in a difficulty to optimally achieve arbitrary compression ratio. We propose iWave++ as a new end-to-end optimized image compression scheme, in which iWave, a trained wavelet-like transform, converts images into coefficients without any information loss. Then the coefficients are optionally quantized and encoded into bits. Different from the previous schemes, iWave++ is versatile: a single model supports both lossless and lossy compression, and also achieves arbitrary compression ratio by simply adjusting the quantization scale. iWave++ also features a carefully designed entropy coding engine to encode the coefficients progressively, and a de-quantization module for lossy compression. Experimental results show that lossy iWave++ achieves state-of-the-art compression efficiency compared with deep network-based methods; on the Kodak dataset, lossy iWave++ leads to 17.34 percent bits saving over BPG; lossless iWave++ achieves comparable or better performance than FLIF. Our code and models are available at https://github.com/mahaichuan/Versatile-Image-Compression.	[Ma, Haichuan; Liu, Dong; Yan, Ning; Li, Houqiang; Wu, Feng] Univ Sci & Technol China, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei 230027, Peoples R China	Chinese Academy of Sciences; University of Science & Technology of China, CAS	Liu, D (corresponding author), Univ Sci & Technol China, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei 230027, Peoples R China.	hcma@mail.ustc.edu.cn; dongeliu@ustc.edu.cn; nyan@mail.ustc.edu.cn; lihq@ustc.edu.cn; fengwu@ustc.edu.cn	liu, dong/GRJ-9115-2022	Liu, Dong/0000-0001-9100-2906	National Key Research and Development Program of China [2018YFA070 1603]; Natural Science Foundation of China [61772483, 61931014]	National Key Research and Development Program of China; Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the National Key Research and Development Program of China under Grant 2018YFA070 1603, and the Natural Science Foundation of China under Grants 61772483 and 61931014.	Agustsson E, 2019, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2019.00031; Agustsson E, 2017, ADV NEUR IN, V30; Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150; Asuni N., 2013, J GRAPH TOOLS, V17, P113, DOI DOI 10.1080/2165347X.2015.1024298; Ball J., 2018, VARIATIONAL IMAGE CO; Balle J., 2016, END TO END OPTIMIZED; Balle J, 2016, PICT COD SYMP, DOI 10.1109/pcs.2016.7906310; Cai CL, 2019, IEEE T CIRC SYST VID, V29, P3687, DOI 10.1109/TCSVT.2018.2880492; Choi Y, 2019, IEEE I CONF COMP VIS, P3146, DOI 10.1109/ICCV.2019.00324; Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468; Claypoole RL, 2003, IEEE T IMAGE PROCESS, V12, P1449, DOI 10.1109/TIP.2003.817237; Covell M., 2015, VARIABLE RATE IMAGE; Dai YY, 2017, LECT NOTES COMPUT SC, V10132, P28, DOI 10.1007/978-3-319-51811-4_3; Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026; Dumas T, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1188; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Ho J., 2019, COMPRESSIONWITH FLOW; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Hoogeboom E., 2019, INTEGER DISCRETE FLO; Jacobsen Jorn-Henrik, 2018, I REVNET DEEP INVERT; Johnston N, 2018, PROC CVPR IEEE, P4385, DOI 10.1109/CVPR.2018.00461; Kang J, 2017, IEEE IMAGE PROC, P26; King DB, 2015, ACS SYM SER, V1214, P1; Lee J., 2019, END TO END JOINT LEA; Lee J., 2018, CONTEXT ADAPTIVE ENT; Lee JH, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (ICAIIC 2019), P560, DOI 10.1109/ICAIIC.2019.8669002; Li M., 2018, ENLARGING CONTEXT LO; Li MH, 2018, PROC CVPR IEEE, P6644, DOI 10.1109/CVPR.2018.00695; Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151; Lipton Z, 2015, CRITICAL REV RECURRE, DOI DOI 10.1093/eurheartj/ehw128; Liu H., 2019, P IEEE CVF C COMP VI, P1; Liu H., 2019, NONLOCAL ATTENTION O; Luxburg U. V., 2016, ADV NEURAL INFORM PR, V29, P4790; Ma HC, 2020, IEEE T MULTIMEDIA, V22, P1667, DOI 10.1109/TMM.2019.2957990; Mentzer F, 2018, PROC CVPR IEEE, P4394, DOI 10.1109/CVPR.2018.00462; Mentzer Fabian, 2019, P IEEE CVF C COMP VI; Minnen David, 2018, ARXIV180902736; Rippel O, 2017, PR MACH LEARN RES, V70; Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834; Salimans Tim, 2017, ARXIV170105517; SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085; Sneyers J, 2016, IEEE IMAGE PROC, P66, DOI 10.1109/ICIP.2016.7532320; Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191; Sutskever I., 2014, ARXIV; Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015; Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830; Theis Lucas, 2017, INT C LEARN REPR; Toderici G, 2017, PROC CVPR IEEE, P5435, DOI 10.1109/CVPR.2017.577; van den Oord A, 2016, PR MACH LEARN RES, V48; Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165; Zhou J., 2019, PROC IEEECVF C COMPU, P1	51	16	16	19	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1247	1263		10.1109/TPAMI.2020.3026003	http://dx.doi.org/10.1109/TPAMI.2020.3026003			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32966210				2022-12-18	WOS:000752018000014
J	Dai, WC; Zhang, Y; Li, P; Fang, Z; Scherer, S				Dai, Weichen; Zhang, Yu; Li, Ping; Fang, Zheng; Scherer, Sebastian			RGB-D SLAM in Dynamic Environments Using Point Correlations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						SLAM; motion estimation; dynamic environments	VISUAL ODOMETRY; TRACKING; MOTION; ALGORITHM	In this paper, a simultaneous localization and mapping (SLAM) method that eliminates the influence of moving objects in dynamic environments is proposed. This method utilizes the correlation between map points to separate points that are part of the static scene and points that are part of different moving objects into different groups. A sparse graph is first created using Delaunay triangulation from all map points. In this graph, the vertices represent map points, and each edge represents the correlation between adjacent points. If the relative position between two points remains consistent over time, there is correlation between them, and they are considered to be moving together rigidly. If not, they are considered to have no correlation and to be in separate groups. After the edges between the uncorrelated points are removed during point-correlation optimization, the remaining graph separates the map points of the moving objects from the map points of the static scene. The largest group is assumed to be the group of reliable static map points. Finally, motion estimation is performed using only these points. The proposed method was implemented for RGB-D sensors, evaluated with a public RGB-D benchmark, and tested in several additional challenging environments. The experimental results demonstrate that robust and accurate performance can be achieved by the proposed SLAM method in both slightly and highly dynamic environments. Compared with other state-of-the-art methods, the proposed method can provide competitive accuracy with good real-time performance.	[Dai, Weichen] Zhejiang Univ, Coll Control Sci & Engn, Hangzhou 310027, Zhejiang, Peoples R China; [Zhang, Yu; Li, Ping] Zhejiang Univ, State Key Lab Ind Control Technol, Coll Control Sci & Engn, Hangzhou 310027, Zhejiang, Peoples R China; [Fang, Zheng] Northeastern Univ, Fac Robot Sci & Engn, Shenyang 110032, Peoples R China; [Scherer, Sebastian] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Zhejiang University; Zhejiang University; Northeastern University - China; Carnegie Mellon University	Zhang, Y (corresponding author), Zhejiang Univ, State Key Lab Ind Control Technol, Coll Control Sci & Engn, Hangzhou 310027, Zhejiang, Peoples R China.	weichendai@zju.edu.cn; zhangyu80@zju.edu.cn; pli@iipc.zju.edu.cn; fangzheng@mail.neu.edu.cn; basti@andrew.cmu.edu		Zhang, Yu/0000-0002-0043-4904; dai, weichen/0000-0002-5019-2755; Scherer, Sebastian/0000-0002-8373-4688	National Natural Science Foundation of China [61673341, 61573091]; National Key R&D Program of China [2016YFD0200701-3]; China's Double First-class Initiative; Project of State Key Laboratory of Industrial Control Technology, Zhejiang University, China [ICT1913]; Open Research Project of the State Key Laboratory of Industrial Control Technology, Zhejiang University, China [ICT1900312, ICT20037]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key R&D Program of China; China's Double First-class Initiative; Project of State Key Laboratory of Industrial Control Technology, Zhejiang University, China; Open Research Project of the State Key Laboratory of Industrial Control Technology, Zhejiang University, China	This work was supported by the National Natural Science Foundation of China (Grant Nos. 61673341, and 61573091), National Key R&D Program of China (2016YFD0200701-3), China's Double First-class Initiative, the Project of State Key Laboratory of Industrial Control Technology, Zhejiang University, China (No. ICT1913) and the Open Research Project of the State Key Laboratory of Industrial Control Technology, Zhejiang University, China (No. ICT1900312, No. ICT20037). Weichen Dai and Yu Zhang contributed equally to thiswork.	Alcantarilla PF, 2012, IEEE INT CONF ROBOT, P1290, DOI 10.1109/ICRA.2012.6224690; Azartash Haleh, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1280, DOI 10.1109/ICASSP.2014.6853803; Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821; Barfoot T. D., 2017, STATE ESTIMATION ROB, DOI [10.1017/9781316671528, DOI 10.1017/9781316671528]; Barsan IA, 2018, IEEE INT CONF ROBOT, P7510; Bescos B, 2018, IEEE ROBOT AUTOM LET, V3, P4076, DOI 10.1109/LRA.2018.2860039; Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754; Chiuso A, 2002, IEEE T PATTERN ANAL, V24, P523, DOI 10.1109/34.993559; Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343; Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049; Dryanovski I, 2013, IEEE INT CONF ROBOT, P2305, DOI 10.1109/ICRA.2013.6630889; Endres F, 2014, IEEE T ROBOT, V30, P177, DOI 10.1109/TRO.2013.2279412; Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Forster C, 2017, IEEE T ROBOT, V33, P249, DOI 10.1109/TRO.2016.2623335; Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8; Gordon D, 2018, IEEE ROBOT AUTOM LET, V3, P788, DOI 10.1109/LRA.2018.2792152; Gutmann J.-S., 1999, Proceedings 1999 IEEE International Symposium on Computational Intelligence in Robotics and Automation. CIRA'99 (Cat. No.99EX375), P318, DOI 10.1109/CIRA.1999.810068; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; Huang JH, 2020, PROC CVPR IEEE, P2165, DOI 10.1109/CVPR42600.2020.00224; Jaimez Mariano, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3992, DOI 10.1109/ICRA.2017.7989459; Kerl C, 2013, IEEE INT C INT ROBOT, P2100, DOI 10.1109/IROS.2013.6696650; Kerl C, 2013, IEEE INT CONF ROBOT, P3748, DOI 10.1109/ICRA.2013.6631104; Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437; Kim DH, 2016, IEEE T ROBOT, V32, P1565, DOI 10.1109/TRO.2016.2609395; Kim DH, 2015, ADV INTELL SYST, V345, P11, DOI 10.1007/978-3-319-16841-8_2; Kitt B, 2010, IEEE INT C INT ROBOT, P5551, DOI 10.1109/IROS.2010.5650517; Klein George, 2007, P1; Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607; Kundu A, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P4306, DOI 10.1109/IROS.2009.5354227; Lee S, 2019, IEEE INT C INT ROBOT, P6891, DOI 10.1109/IROS40897.2019.8968208; Li SL, 2017, IEEE ROBOT AUTOM LET, V2, P2263, DOI 10.1109/LRA.2017.2724759; MacTavish K, 2015, 2015 12TH CONFERENCE ON COMPUTER AND ROBOT VISION CRV 2015, P62, DOI 10.1109/CRV.2015.52; Migliore D., 2009, ICRA WORKSH SAF NAV, P12; Mouragnon E., 2006, IEEE COMP SOC C COMP, V1, P363, DOI DOI 10.1109/CVPR.2006.236; Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103; Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513; Palazzolo E, 2019, IEEE INT C INT ROBOT, P7855, DOI 10.1109/IROS40897.2019.8967590; Polok L., 2013, ROBOTICS SCI SYSTEMS, P328; Qiu KJ, 2019, IEEE T ROBOT, V35, P799, DOI 10.1109/TRO.2019.2909085; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Riazuelo L, 2017, 2017 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR); Runz Martin, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4471, DOI 10.1109/ICRA.2017.7989518; Runz M, 2018, INT SYM MIX AUGMENT, P10, DOI 10.1109/ISMAR.2018.00024; Saputra MRU, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3177853; Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233; Scona R, 2018, IEEE INT CONF ROBOT, P3849; Stachniss C, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1153; Steinbrucker F, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS); Strasdat H, 2012, IMAGE VISION COMPUT, V30, P65, DOI 10.1016/j.imavis.2012.02.009; Strecke M, 2019, IEEE I CONF COMP VIS, P5864, DOI 10.1109/ICCV.2019.00596; STUCKLER J, 2013, P BMVC, P1; Stuhmer J, 2010, LECT NOTES COMPUT SC, V6376, P11; Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773; Sun YX, 2017, ROBOT AUTON SYST, V89, P110, DOI 10.1016/j.robot.2016.11.012; Tan W, 2013, INT SYM MIX AUGMENT, P209, DOI 10.1109/ISMAR.2013.6671781; Xu BB, 2019, IEEE INT CONF ROBOT, P5231, DOI 10.1109/ICRA.2019.8794371; Yang SC, 2019, IEEE T ROBOT, V35, P925, DOI 10.1109/TRO.2019.2909168; ZHANG T, 2020, P IEEE INT C ROB AUT; Zou DP, 2013, IEEE T PATTERN ANAL, V35, P354, DOI 10.1109/TPAMI.2012.104	60	16	17	87	164	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					373	389		10.1109/TPAMI.2020.3010942	http://dx.doi.org/10.1109/TPAMI.2020.3010942			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	32750826	Green Submitted			2022-12-18	WOS:000728561300027
J	Choe, J; Lee, S; Shim, H				Choe, Junsuk; Lee, Seungho; Shim, Hyunjung			Attention-Based Dropout Layer for Weakly Supervised Single Object Localization and Semantic Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Semantics; Training; Image segmentation; Feature extraction; Computational modeling; Convolutional codes; Attention; weakly supervised; object localization; semantic segmentation		Both weakly supervised single object localization and semantic segmentation techniques learn an object's location using only image-level labels. However, these techniques are limited to cover only the most discriminative part of the object and not the entire object. To address this problem, we propose an attention-based dropout layer, which utilizes the attention mechanism to locate the entire object efficiently. To achieve this, we devise two key components, 1) hiding the most discriminative part from the model to capture the entire object, and 2) highlighting the informative region to improve the classification power of the model. These allow the classifier to be maintained with a reasonable accuracy while the entire object is covered. Through extensive experiments, we demonstrate that the proposed method effectively improves the weakly supervised single object localization accuracy, thereby achieving a new state-of-the-art localization accuracy on the CUB-200-2011 and a comparable accuracy existing state-of-the-arts on the ImageNet-1k. The proposed method is also effective in improving the weakly supervised semantic segmentation performance on the Pascal VOC and MS COCO. Furthermore, the proposed method is more efficient than existing techniques in terms of parameter and computation overheads. Additionally, the proposed method can be easily applied in various backbone networks.	[Choe, Junsuk] NAVER Corp, Clova AI Res, Seongnam Si 13561, Gyeonggi Do, South Korea; [Lee, Seungho; Shim, Hyunjung] Yonsei Univ, Sch Integrated Technol, Seoul 03722, South Korea	Yonsei University	Shim, H (corresponding author), Yonsei Univ, Sch Integrated Technol, Seoul 03722, South Korea.	junsukchoe@yonsei.ac.kr; seungholee@yonsei.ac.kr; kateshim@yonsei.ac.kr	Lee, Seungho/AAC-5844-2022		National Research Foundation of Korea (NRF) - MSIP [NRF-2019R1A2C2006123]; Institute of Information & Communications Technology Planning & Evaluation (IITP) - Korea government(MSIT) (Artificial Intelligence Graduate School Program (YONSEI UNIVERSITY)) [2020-0-01361]; ICT R&D program of MSIP/IITP [R7124-160004]	National Research Foundation of Korea (NRF) - MSIP(National Research Foundation of Korea); Institute of Information & Communications Technology Planning & Evaluation (IITP) - Korea government(MSIT) (Artificial Intelligence Graduate School Program (YONSEI UNIVERSITY))(Institute for Information & Communication Technology Planning & Evaluation (IITP), Republic of KoreaMinistry of Science & ICT (MSIT), Republic of Korea); ICT R&D program of MSIP/IITP(Institute for Information & Communication Technology Planning & Evaluation (IITP), Republic of Korea)	This work was supported by the Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the MSIP (NRF-2019R1A2C2006123), and by Institute of Information & Communications Technology Planning & Evaluation (IITP) grant funded by the Korea government(MSIT) (2020-0-01361, Artificial Intelligence Graduate School Program (YONSEI UNIVERSITY)). This work was also supported by ICT R&D program of MSIP/IITP [R7124-160004, Development of Intelligent Interaction Technology Based on Context Awareness and Human Intention Understanding]. Junsuk Choe and Seungho Lee contributed equally to this work.	Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Adam, 2017, MOBILENETS EFFICIENT; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311; Chen LC, 2015, CORR; Choe J, 2019, PROC CVPR IEEE, P2214, DOI 10.1109/CVPR.2019.00232; Cinbis RG, 2014, PROC CVPR IEEE, P2409, DOI 10.1109/CVPR.2014.309; Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755; Diba A, 2017, PROC CVPR IEEE, P5131, DOI 10.1109/CVPR.2017.545; Dong XY, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P279, DOI 10.1145/3123266.3123455; Dong XY, 2019, IEEE T PATTERN ANAL, V41, P1641, DOI 10.1109/TPAMI.2018.2844853; Durand T, 2017, PROC CVPR IEEE, P5957, DOI 10.1109/CVPR.2017.631; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Gao MF, 2018, LECT NOTES COMPUT SC, V11205, P155, DOI 10.1007/978-3-030-01246-5_10; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang ZL, 2018, PROC CVPR IEEE, P7014, DOI 10.1109/CVPR.2018.00733; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jie ZQ, 2017, PROC CVPR IEEE, P4294, DOI 10.1109/CVPR.2017.457; Kantorov V, 2016, LECT NOTES COMPUT SC, V9909, P350, DOI 10.1007/978-3-319-46454-1_22; Karen Simonyan, 2014, ARXIV13126034CS, DOI DOI 10.1038/S41591-018-0335-9; Khoreva A, 2016, PROC CVPR IEEE, P183, DOI 10.1109/CVPR.2016.27; Kim D, 2017, IEEE I CONF COMP VIS, P3554, DOI 10.1109/ICCV.2017.382; Kolesnikov A, 2016, LECT NOTES COMPUT SC, V9908, P695, DOI 10.1007/978-3-319-46493-0_42; Krahenbuhl P., 2011, ADV NEURAL INF PROCE, V24, P109; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Li KP, 2018, PROC CVPR IEEE, P9215, DOI 10.1109/CVPR.2018.00960; Liang XD, 2015, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2015.120; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6; min L., 2014, P INT C LEARN REPR; Oh SJ, 2017, PROC CVPR IEEE, P5038, DOI 10.1109/CVPR.2017.535; Oquab M, 2015, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2015.7298668; Park Jongchan, 2018, ARXIV180706514; Park S, 2017, LECT NOTES COMPUT SC, V10112, P189, DOI 10.1007/978-3-319-54184-6_12; Parmar Niki, 2018, PR MACH LEARN RES, P4055; Pathak D, 2015, IEEE I CONF COMP VIS, P1796, DOI 10.1109/ICCV.2015.209; Roy A, 2017, PROC CVPR IEEE, P7282, DOI 10.1109/CVPR.2017.770; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74; Shi MJ, 2017, IEEE I CONF COMP VIS, P3401, DOI 10.1109/ICCV.2017.366; Singh K.K., 2018, ARXIV181102545; Singh KK, 2017, IEEE I CONF COMP VIS, P3544, DOI 10.1109/ICCV.2017.381; Song HO., 2014, ADV NEURAL INFORM PR, V2, P1637; Song HO, 2014, PR MACH LEARN RES, V32, P1611; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Su SC, 2016, PROC CVPR IEEE, pCP40, DOI 10.1109/CVPR.2016.382; Sun C, 2016, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2016.379; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Teh Eu Wern, 2016, BRIT MACH VIS C BMVC; Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664; Vaswani A, 2017, ADV NEUR IN, V30; Wah C., 2011, TECH REP; Wang C, 2014, LECT NOTES COMPUT SC, V8694, P431, DOI 10.1007/978-3-319-10599-4_28; Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683; Wang JD, 2017, INT J COMPUT VISION, V123, P251, DOI 10.1007/s11263-016-0977-3; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Wei XS, 2017, IEEE T IMAGE PROCESS, V26, P2868, DOI 10.1109/TIP.2017.2688133; Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687; Wei YC, 2018, PROC CVPR IEEE, P7268, DOI 10.1109/CVPR.2018.00759; Wei YC, 2018, LECT NOTES COMPUT SC, V11215, P454, DOI 10.1007/978-3-030-01252-6_27; Wei YC, 2017, IEEE T PATTERN ANAL, V39, P2314, DOI 10.1109/TPAMI.2016.2636150; Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1; Wu Y, 2016, TENSORPACK; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Zagoruyko S., 2017, P INT C LEARN REPR, DOI DOI 10.1109/CVPR.2019.00271; Zhang JM, 2018, INT J COMPUT VISION, V126, P1084, DOI 10.1007/s11263-017-1059-x; Zhang XL, 2018, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2018.00144; Zhang XL, 2018, LECT NOTES COMPUT SC, V11216, P610, DOI 10.1007/978-3-030-01258-8_37; Zhang XP, 2018, LECT NOTES COMPUT SC, V11207, P248, DOI 10.1007/978-3-030-01219-9_15; Zhang XP, 2016, PROC CVPR IEEE, P1134, DOI 10.1109/CVPR.2016.128; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; Zhu Y, 2017, IEEE I CONF COMP VIS, P1859, DOI 10.1109/ICCV.2017.204; Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540	76	16	16	7	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2021	43	12					4256	4271		10.1109/TPAMI.2020.2999099	http://dx.doi.org/10.1109/TPAMI.2020.2999099			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR0MQ	32750779				2022-12-18	WOS:000714203900010
J	Zaeemzadeh, A; Rahnavard, N; Shah, M				Zaeemzadeh, Alireza; Rahnavard, Nazanin; Shah, Mubarak			Norm-Preservation: Why Residual Networks Can Become Extremely Deep?	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Optimization; Training; Residual neural networks; Convolution; Numerical stability; Computer architecture; Residual networks; convolutional neural networks; optimization stability; norm preservation; spectral regularization		Augmenting neural networks with skip connections, as introduced in the so-called ResNet architecture, surprised the community by enabling the training of networks of more than 1,000 layers with significant performance gains. This paper deciphers ResNet by analyzing the effect of skip connections, and puts forward new theoretical results on the advantages of identity skip connections in neural networks. We prove that the skip connections in the residual blocks facilitate preserving the norm of the gradient, and lead to stable back-propagation, which is desirable from optimization perspective. We also show that, perhaps surprisingly, as more residual blocks are stacked, the norm-preservation of the network is enhanced. Our theoretical arguments are supported by extensive empirical evidence. Can we push for extra norm-preservation? We answer this question by proposing an efficient method to regularize the singular values of the convolution operator and making the ResNet's transition layers extra norm-preserving. Our numerical investigations demonstrate that the learning dynamics and the classification performance of ResNet can be improved by making it even more norm preserving. Our results and the introduced modification for ResNet, referred to as Procrustes ResNets, can be used as a guide for training deeper networks and can also inspire new deeper architectures.	[Zaeemzadeh, Alireza; Rahnavard, Nazanin; Shah, Mubarak] Univ Cent Florida, Sch Elect Engn & Comp Sci, Orlando, FL 32816 USA	State University System of Florida; University of Central Florida	Zaeemzadeh, A (corresponding author), Univ Cent Florida, Sch Elect Engn & Comp Sci, Orlando, FL 32816 USA.	zaeemzadeh@eecs.ucf.edu; nazanin@eecs.ucf.edu; shah@crcv.ucf.edu	Zaeemzadeh, Alireza/J-2092-2019	Zaeemzadeh, Alireza/0000-0003-2980-1787; Shah, Mubarak/0000-0001-6172-5572	National Science Foundation [1741431, CCF-1718195]; Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA RD [D17PC00345]	National Science Foundation(National Science Foundation (NSF)); Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA RD	This work was supported in part by the National Science Foundation under Grants 1741431 and CCF-1718195 and the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA R&D Contract No. D17PC00345. The views, findings, opinions, and conclusions or recommendations contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the NSF, ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon.	BARTLETT P. L, 2018, ARXIV180405012; Behrmann J, 2019, PR MACH LEARN RES, V97; Dinh L, 2017, 5 INT C LEARN REPR I; Dong X., 2017, ERASERELU SIMPLE WAY, V1709; Glorot X., 2010, PROC MACH LEARN RES, P249; Gomez Aidan N, 2017, ADV NEURAL INFORM PR, P2214; GOWER JC, 2004, OX STAT SCI, V30, pR13; Gunasekar S, 2018, ADV NEUR IN, V31; HARDT M., 2017, P 5 INT C LEARN REPR; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Higham NJ, 1997, NUMER ALGORITHMS, V15, P227, DOI 10.1023/A:1019150005407; Hoffer E., 2017, ADV NEURAL INF PROCE; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Kawaguchi K, 2019, NEURAL NETWORKS, V118, P167, DOI 10.1016/j.neunet.2019.06.009; Kawaguchi Kenji, 2016, ADV NEURAL INFORM PR, P586; Krizhevsky A., 2009, TR2009 U TOR DEP COM, P32; Montufar G.F., 2014, ADV NEURAL INF PROCE, V27, P2924, DOI DOI 10.5555/2969033.2969153; Pitkow X., 2018, INT C LEARN REPR; Sedghi H., 2019, P ICLR; Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270; Srivastava Rupesh K, 2015, TRAINING VERY DEEP N, V28, P2377; Veit A, 2016, ADV NEUR IN, V29	26	16	16	3	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2021	43	11					3980	3990		10.1109/TPAMI.2020.2990339	http://dx.doi.org/10.1109/TPAMI.2020.2990339			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WA1JH	32340937	Green Submitted			2022-12-18	WOS:000702649700021
J	Liu, S; Ren, Z; Yuan, JS				Liu, Sheng; Ren, Zhou; Yuan, Junsong			SibNet: Sibling Convolutional Encoder for Video Captioning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visualization; Decoding; Semantics; Task analysis; Feature extraction; Pipelines; Natural languages; SibNet; video captioning; autoencoder; visual-semantic joint embedding; convolutional encoder		Visual captioning, the task of describing an image or a video using one or few sentences, is a challenging task owing to the complexity of understanding the copious visual information and describing it using natural language. Motivated by the success of applying neural networks for machine translation, previous work applies sequence to sequence learning to translate videos into sentences. In this work, different from previous work that encodes visual information using a single flow, we introduce a novel Sibling Convolutional Encoder (SibNet) for visual captioning, which employs a dual-branch architecture to collaboratively encode videos. The first content branch encodes visual content information of the video with an autoencoder, capturing the visual appearance information of the video as other networks often do. While the second semantic branch encodes semantic information of the video via visual-semantic joint embedding, which brings complementary representation by considering the semantics when extracting features from videos. Then both branches are effectively combined with soft-attention mechanism and finally fed into a RNN decoder to generate captions. With our SibNet explicitly capturing both content and semantic information, the proposed model can better represent the rich information in videos. To validate the advantages of the proposed model, we conduct experiments on two benchmarks for video captioning, YouTube2Text and MSR-VTT. Our results demonstrate that the proposed SibNet consistently outperforms existing methods across different evaluation metrics.	[Liu, Sheng; Yuan, Junsong] Univ Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA; [Ren, Zhou] Wormpex AI Res, Seattle, WA 98004 USA	State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Liu, S (corresponding author), Univ Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA.	sliu66@buffalo.edu; renzhou200622@gmail.com; jsyuan@buffalo.edu			University at Buffalo; Snap Research	University at Buffalo; Snap Research	This work is supported in part by the start-up funds of the University at Buffalo and gift grants from Snap Research.	[Anonymous], 2016, LANGUAGE MODELING GA; [Anonymous], 2016, ARXIV160903499; [Anonymous], 2016, P ECCV; Ballas N., 2015, P INT C LEARNING REP; Baraldi L, 2017, PROC CVPR IEEE, P3185, DOI 10.1109/CVPR.2017.339; Bin Y, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P436, DOI 10.1145/2964284.2967258; BOURLARD H, 1988, BIOL CYBERN, V59, P291, DOI 10.1007/BF00332918; Bowman SR., 2015, EMNLP, P632, DOI DOI 10.18653/V1/D15-1075; Chen David, 2011, P 49 ANN M ASS COMP, P190; Chen SZ, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P5, DOI 10.1145/3078971.3079000; Chen SZ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1838, DOI 10.1145/3123266.3123420; Chen SZ, 2019, IEEE T MULTIMEDIA, V21, P2407, DOI 10.1109/TMM.2019.2896515; Chen X, 2015, CORR, V1504, P325; Chen YY, 2018, LECT NOTES COMPUT SC, V11217, P367, DOI 10.1007/978-3-030-01261-8_22; Chenyou Fan, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P459, DOI 10.1007/978-3-319-46604-0_33; Cho K., 2014, P 2014 C EMP METH NA, P1724; Chung Junyoung, 2014, ARXIV PREPRINT ARXIV; Crandall D., 2017, ARXIV170606275; Crouse JR, 2007, JAMA-J AM MED ASSOC, V297, P1344, DOI 10.1001/jama.297.12.1344; Das P, 2013, PROC CVPR IEEE, P2634, DOI 10.1109/CVPR.2013.340; Dong JF, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1082, DOI 10.1145/2964284.2984064; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Dyer C, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P334; Dzmitry Bahdanau, 2016, Arxiv, DOI arXiv:1409.0473; Fan C, 2018, J VIS COMMUN IMAGE R, V55, P40, DOI 10.1016/j.jvcir.2018.05.008; Gan Z, 2017, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2017.127; Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019; Gehring J, 2017, PR MACH LEARN RES, V70; Gehring J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P123, DOI 10.18653/v1/P17-1012; Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139; Glorot X., 2010, P 13 INT C ART INT S, P249, DOI DOI 10.1.1/207.2059; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Guo Z, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P357, DOI 10.1145/2964284.2967242; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hinton G, 1994, ADV NEURAL INFORM PR, V6, DOI DOI 10.1021/jp906511z; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Huang DA, 2018, PROC CVPR IEEE, P7366, DOI 10.1109/CVPR.2018.00769; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Jin Q., 2016, P 24 ACM INT C MULTI, P1087, DOI 10.1145/2964284.2984065; Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494; Kalchbrenner Nal, 2013, P 2013 C EMP METH NA, P1700, DOI DOI 10.1146/ANNUREV.NEURO.26.041002.131047; Kingma D.P, P 3 INT C LEARNING R; KROGH A, 1992, ADV NEUR IN, V4, P950; Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562; Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.3115/V1/D14-1020; Lin Z., 2017, ARXIV PREPRINT ARXIV; Logan B., 2000, P 1 INT S MUS INF RE; Luong M., 2015, ARXIV150804025; Luong Minh-Thang, 2016, CORR; Mei T., 2017, MSR VTT CHALLENGE; Nair V., 2010, ICML, P807; Nina O., 2018, ARXIV180907257; Pan PB, 2016, PROC CVPR IEEE, P1029, DOI 10.1109/CVPR.2016.117; Pan YW, 2017, PROC CVPR IEEE, P984, DOI 10.1109/CVPR.2017.111; Pan YW, 2016, PROC CVPR IEEE, P4594, DOI 10.1109/CVPR.2016.497; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pasunuru R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1273, DOI 10.18653/v1/P17-1117; Ramanishka V., 2016, P 24 ACM INT C MULT, P1092, DOI DOI 10.1145/2964284.2984066; Ren Z, 2017, P BRIT MACH VIS C; Ren Z, 2016, THESIS U CALIFORNIA; Ren Z, 2017, PROC CVPR IEEE, P1151, DOI 10.1109/CVPR.2017.128; Ren Zhou, 2016, PROC 24 ACM INT C MU, P207; Rush Alexander M, 2015, P 2015 C EMP METH NA, P379, DOI DOI 10.18653/V1/D15-1044; Shen ZQ, 2017, PROC CVPR IEEE, P5159, DOI 10.1109/CVPR.2017.548; Shetty R., 2016, P 2016 ACM MULT C, P1073, DOI DOI 10.1145/2964284.2984062; Soomro K., 2012, ARXIVPREPRINT, P2556; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Sutskever I., 2014, P ADV INT C NEUR INF, P3104; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tu YB, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1014, DOI 10.1145/3123266.3123354; Turian J, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P384; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vaswani A., 2017, ADV NEURAL INFORM PR, V30; Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087; Venugopalan, 2016, ARXIV160401729; Venugopalan S., 2015, P C N AM CHAPT ASS C, P1494, DOI 10.3115/v1/N15-1173; Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515; Vijayakumar A. K, 2018, P ASS ADV ART INT; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Vinyals Oriol, 2015, NIPS; Wang BR, 2018, PROC CVPR IEEE, P7622, DOI 10.1109/CVPR.2018.00795; Wang JB, 2018, PROC CVPR IEEE, P7512, DOI 10.1109/CVPR.2018.00784; Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541; Wu X, 2018, PROC CVPR IEEE, P6829, DOI 10.1109/CVPR.2018.00714; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Xu J, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P537, DOI 10.1145/3123266.3123448; Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Xu R, 2015, AAAI CONF ARTIF INTE, P2346; Yang ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P146, DOI 10.1145/3123266.3123327; Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512; You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503; Yu HN, 2016, PROC CVPR IEEE, P4584, DOI 10.1109/CVPR.2016.496; Zhou LW, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P305, DOI 10.1145/3126686.3126717; Zhou LW, 2018, PROC CVPR IEEE, P8739, DOI 10.1109/CVPR.2018.00911; Zhu LC, 2017, PROC CVPR IEEE, P1339, DOI 10.1109/CVPR.2017.147	98	16	17	7	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2021	43	9					3259	3272		10.1109/TPAMI.2019.2940007	http://dx.doi.org/10.1109/TPAMI.2019.2940007			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TU6DH	32149622				2022-12-18	WOS:000681124300030
J	Zhang, M; Li, HQ; Pan, SR; Chang, XJ; Zhou, CA; Ge, ZY; Su, S				Zhang, Miao; Li, Huiqi; Pan, Shirui; Chang, Xiaojun; Zhou, Chuan; Ge, Zongyuan; Su, Steven			One-Shot Neural Architecture Search: Maximising Diversity to Overcome Catastrophic Forgetting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer architecture; Training; Optimization; Neural networks; Search methods; Australia; Germanium; AutoML; neural architecture search; continual learning; catastrophic forgetting; novelty search		One-shot neural architecture search (NAS) has recently become mainstream in the NAS community because it significantly improves computational efficiency through weight sharing. However, the supernet training paradigm in one-shot NAS introduces catastrophic forgetting, where each step of the training can deteriorate the performance of other architectures that contain partially-shared weights with current architecture. To overcome this problem of catastrophic forgetting, we formulate supernet training for one-shot NAS as a constrained continual learning optimization problem such that learning the current architecture does not degrade the validation accuracy of previous architectures. The key to solving this constrained optimization problem is a novelty search based architecture selection (NSAS) loss function that regularizes the supernet training by using a greedy novelty search method to find the most representative subset. We applied the NSAS loss function to two one-shot NAS baselines and extensively tested them on both a common search space and a NAS benchmark dataset. We further derive three variants based on the NSAS loss function, the NSAS with depth constrain (NSAS-C) to improve the transferability, and NSAS-G and NSAS-LG to handle the situation with a limited number of constraints. The experiments on the common NAS search space demonstrate that NSAS and it variants improve the predictive ability of supernet training in one-shot NAS with remarkable and efficient performance on the CIFAR-10, CIFAR-100, and ImageNet datasets. The results with the NAS benchmark dataset also confirm the significant improvements these one-shot NAS baselines can make.	[Zhang, Miao; Li, Huiqi] Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China; [Zhang, Miao; Pan, Shirui; Chang, Xiaojun] Monash Univ, Fac Informat Technol, Clayton, Vic 3800, Australia; [Zhang, Miao; Su, Steven] Univ Technol Sydney, Fac Engn & Informat Technol, Ultimo, NSW 2007, Australia; [Chang, Xiaojun] King Abdulaziz Univ, Fac Comp & Informat Technol, Jeddah 21589, Saudi Arabia; [Zhou, Chuan] Chinese Acad Sci, Acad Math & Syst Sci, Beijing 100081, Peoples R China; [Ge, Zongyuan] Monash Univ, Monash E Res Ctr, Clayton, Vic 3800, Australia	Beijing Institute of Technology; Monash University; University of Technology Sydney; King Abdulaziz University; Chinese Academy of Sciences; Academy of Mathematics & System Sciences, CAS; Monash University	Li, HQ (corresponding author), Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China.; Pan, SR (corresponding author), Monash Univ, Fac Informat Technol, Clayton, Vic 3800, Australia.	Miao.Zhang-2@student.uts.edu.au; huiqili@bit.edu.cn; shirui.pan@monash.edu; xiaojun.chang@monash.edu; zhouchuan@amss.ac.cn; Zongyuan.Ge@monash.edu; steven.su@uts.edu.au	Pan, Shirui/K-6763-2018; Chang, Xiaojun/A-2055-2015	Pan, Shirui/0000-0003-0794-527X; Chang, Xiaojun/0000-0002-7778-8807; Zhang, Miao/0000-0002-1262-4174; Zhou, Chuan/0000-0001-9958-8673; Su, Steven/0000-0002-5720-8852; Ge, Zongyuan/0000-0002-5880-8673	NSFC [61702415, 61972315]; Australian Research Council (ARC) under a Discovery Early Career Researcher Award (DECRA) [DE190100626]; Air Force Research Laboratory, DARPA [FA8750-19-20501]; Youth Innovation Promotion Association CAS [2017210]	NSFC(National Natural Science Foundation of China (NSFC)); Australian Research Council (ARC) under a Discovery Early Career Researcher Award (DECRA)(Australian Research Council); Air Force Research Laboratory, DARPA; Youth Innovation Promotion Association CAS	This work was supported in part by the NSFC under Grant No. 61702415 and No. 61972315, the Australian Research Council (ARC) under a Discovery Early Career Researcher Award (DECRA) No. DE190100626, the Air Force Research Laboratory, DARPA under Agreement No. FA8750-19-20501, and the Youth Innovation Promotion Association CAS (No. 2017210).	Aljundi R, 2019, ADV NEUR IN, V32; Bender G, 2018, PR MACH LEARN RES, V80; Benyahia Y, 2019, PR MACH LEARN RES, V97; Brock A., 2018, ICLR, P1; Cai Han, 2019, INT C LEARN REPR; Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901; Chen S, 2018, LECT NOTES COMPUT SC, V10996, P428, DOI 10.1007/978-3-319-97909-0_46; Chen X, 2019, IEEE I CONF COMP VIS, P1294, DOI 10.1109/ICCV.2019.00138; Chen YK, 2019, PROC CVPR IEEE, P4782, DOI 10.1109/CVPR.2019.00492; Cheng X., 2020, ADV NEURAL INFORM PR, V33, P22158; Dong XT, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3023706; Dong XY, 2019, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2019.00186; Elsken T, 2019, J MACH LEARN RES, V20; Fusi, 2019, 190205116 ARXIV; Goldstein T., 2020, P INT C MACH LEARN; Guo MH, 2019, PROC CVPR IEEE, P9013, DOI 10.1109/CVPR.2019.00923; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hinton G., 2015, ARXIV150302531; Howard A.G., 2017, MOBILENETS EFFICIENT; Hutter, 2019, 190504970 ARXIV; Jang E., 2017, ICLR; KENDALL MG, 1945, BIOMETRIKA, V33, P239, DOI 10.2307/2332303; Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114; Lee SW, 2017, ADV NEUR IN, V30; Li, 2019, 190701845 ARXIV; Li L, 2020, PR MACH LEARN RES, V115, P367; Li Xiang, 2020, P IEEE CVF C COMP VI, P13836; Li XL, 2019, PR MACH LEARN RES, V97; Li ZH, 2019, PATTERN RECOGN, V88, P595, DOI 10.1016/j.patcog.2018.12.010; Li ZZ, 2018, IEEE T PATTERN ANAL, V40, P2935, DOI 10.1109/TPAMI.2017.2773081; Lian Dongze, 2020, INT C LEARN REPR; Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2; Liu H., 2018, PROC INT C LEARN REP; Liu H, 2019, PROCEEDINGS OF THE THIRD INTERNATIONAL SYMPOSIUM - EDUCATIONAL RESEARCH AND EDUCATIONAL TECHNOLOGY, 2019, P3; Lorraine, 2019, 190400438 ARXIV; Luo RQ, 2018, ADV NEUR IN, V31; Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8; Maddison Chris J, 2017, ICLR; Mei Jieru, 2020, ICLR; Miao Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7806, DOI 10.1109/CVPR42600.2020.00783; Naik, 2018, ACCELERATING NEURAL; Nayman N, 2019, ADV NEUR IN, V32; Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012; Pham H, 2018, PR MACH LEARN RES, V80; Real E, 2019, AAAI CONF ARTIF INTE, P4780; Ren, 2020, 200602903 ARXIV; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Savani, 2019, 191011858 ARXIV; Schmidt, 2019, 190607590 ARXIV; Shu Yao, 2020, INT C LEARN REPR; Su S., 2020, P 34 C NEUR INF PROC; Su S., 2020, P INT JOINT C ART IN; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Wang Wenguan, 2020, CVPR; Xie Sirui, 2019, ICLR, V1, P13; Xu Y, 2020, PLANT SOIL, V449, P133, DOI 10.1007/s11104-020-04435-1; Yang A., 2020, PROC INT C LEARN REP; Yang ZH, 2020, PROC CVPR IEEE, P1826, DOI 10.1109/CVPR42600.2020.00190; Yao QM, 2020, AAAI CONF ARTIF INTE, V34, P6664; Ying C, 2019, PR MACH LEARN RES, V97; Yu Kaicheng, 2020, ICLR; Zela A., 2020, INT C LEARN REPRESEN; Zhang Chris, 2019, ICLR; Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716; Zhang XB, 2021, IEEE T PATTERN ANAL, V43, P2891, DOI 10.1109/TPAMI.2020.3020300; Zhou HP, 2019, PR MACH LEARN RES, V97; Zoph B., 2017, P1; Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907	72	16	16	7	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2021	43	9					2921	2935		10.1109/TPAMI.2020.3035351	http://dx.doi.org/10.1109/TPAMI.2020.3035351			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TU6DH	33147140				2022-12-18	WOS:000681124300008
J	Tank, A; Covert, I; Foti, N; Shojaie, A; Fox, EB				Tank, Alex; Covert, Ian; Foti, Nicholas; Shojaie, Ali; Fox, Emily B.			Neural Granger Causality	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Time series analysis; Neural networks; Reactive power; Recurrent neural networks; Predictive models; Estimation; Data models; Time series; Granger causality; neural networks; structured sparsity; interpretability	TIME-SERIES; MODELS; REGRESSION; SELECTION	While most classical approaches to Granger causality detection assume linear dynamics, many interactions in real-world applications, like neuroscience and genomics, are inherently nonlinear. In these cases, using linear models may lead to inconsistent estimation of Granger causal interactions. We propose a class of nonlinear methods by applying structured multilayer perceptrons (MLPs) or recurrent neural networks (RNNs) combined with sparsity-inducing penalties on the weights. By encouraging specific sets of weights to be zero-in particular, through the use of convex group-lasso penalties-we can extract the Granger causal structure. To further contrast with traditional approaches, our framework naturally enables us to efficiently capture long-range dependencies between series either via our RNNs or through an automatic lag selection in the MLP. We show that our neural Granger causality methods outperform state-of-the-art nonlinear Granger causality methods on the DREAM3 challenge data. This data consists of nonlinear gene expression and regulation time courses with only a limited number of time points. The successes we show in this challenging dataset provide a powerful example of how deep learning can be useful in cases that go beyond prediction on large datasets. We likewise illustrate our methods in detecting nonlinear interactions in a human motion capture dataset.	[Tank, Alex] Univ Washington, Dept Stat, Seattle, WA 98103 USA; [Covert, Ian; Foti, Nicholas; Fox, Emily B.] Univ Washington, Dept Comp Sci, Seattle, WA 98103 USA; [Shojaie, Ali] Univ Washington, Dept Biostat, Seattle, WA 98103 USA	University of Washington; University of Washington Seattle; University of Washington; University of Washington Seattle; University of Washington; University of Washington Seattle	Tank, A (corresponding author), Univ Washington, Dept Stat, Seattle, WA 98103 USA.	alextank@uw.edu; icovert@cs.washington.edu; nfoti@uw.edu; ashojaie@uw.edu; ebfox@uw.edu		Fox, Emily/0000-0003-3188-9685	ONR [N00014-15-1-2380]; NSF CAREER Award [IIS-1350133]; AFOSR [FA9550-16-1-0038]; NSF [DMS-1161565, DMS1561814]; NIH [R01GM114029, R01GM133848]	ONR(Office of Naval Research); NSF CAREER Award(National Science Foundation (NSF)NSF - Office of the Director (OD)); AFOSR(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); NSF(National Science Foundation (NSF)); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	The work of Alex Tank, Ian Covert, Nicholas Foti and Emily B. Fox was supported by the ONR Grant N00014-15-1-2380, NSF CAREER Award IIS-1350133, and AFOSR Grant FA9550-16-1-0038. The work of Alex Tank and Ali Shojaie was supported by the NSF grants DMS-1161565 and DMS1561814 and NIH grants R01GM114029 and R01GM133848. Alex Tank and Ian Covert contributed equally to this work.	Alvarez Jose M, 2016, ADV NEURAL INFORM PR, P2270; Amblard PO, 2011, J COMPUT NEUROSCI, V30, P7, DOI 10.1007/s10827-010-0231-x; [Anonymous], 2012, ARXIV12104792; Basu S, 2015, J MACH LEARN RES, V16, P417; Basu S, 2015, ANN STAT, V43, P1535, DOI 10.1214/15-AOS1315; Billings SA, 2013, NONLINEAR SYSTEM IDENTIFICATION: NARMAX METHODS IN THE TIME, FREQUENCY, AND SPATIO-TEMPORAL DOMAINS, P1, DOI 10.1002/9781118535561; Billings SA, 1996, DETERMINATION MULTIV, P231; Buhlmann P, 2011, SPRINGER SER STAT, P1, DOI 10.1007/978-3-642-20192-9; Chu S. R., 1990, IEEE Control Systems Magazine, V10, P31, DOI 10.1109/37.55121; CMU, 2009, CARN MELL U MOT CAPT; Feng J., 2017, ARXIV 171107592; Fox EB, 2014, ANN APPL STAT, V8, P1281, DOI 10.1214/14-AOAS742; Fujita A, 2010, LECT N BIOINFORMAT, V6268, P13, DOI 10.1007/978-3-642-15060-9_2; Gong Pinghua, 2013, JMLR Workshop Conf Proc, V28, P37; GRANGER CWJ, 1969, ECONOMETRICA, V37, P424, DOI 10.2307/1912791; Graves A, 2012, STUD COMPUT INTELL, V385, P5; Guo T., 2018, ARXIV 180405251; Guo T, 2019, PR MACH LEARN RES, V97; HALL E. C., 2016, ARXIV160502693; Hsu E, 2005, ACM T GRAPHIC, V24, P1082, DOI 10.1145/1073204.1073315; Huang JZ, 2011, J MACH LEARN RES, V12, P3371; Jenatton R, 2011, J MACH LEARN RES, V12, P2297; Karimi A, 2010, CHAOS, V20, DOI 10.1063/1.3496397; Kingma D.P, P 3 INT C LEARNING R; Kisi O, 2004, J HYDROL ENG, V9, P60, DOI 10.1061/(ASCE)1084-0699(2004)9:1(60); Koutnik J., 2014, PR MACH LEARN RES; Lebre S, 2009, STAT APPL GENET MOL, V8, DOI 10.2202/1544-6115.1294; Lee J, 2010, PROCEEDINGS OF THE 17TH INTERNATIONAL CONGRESS ON SOUND AND VIBRATION; Li Y., 2018, P 6 INT C LEARNING R; Lim N, 2015, MACH LEARN, V99, P489, DOI 10.1007/s10994-014-5479-3; Lozano AC, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P577; Lozano AC, 2009, BIOINFORMATICS, V25, pI110, DOI 10.1093/bioinformatics/btp199; Lusch B, 2016, PHYS REV E, V94, DOI 10.1103/PhysRevE.94.032220; Lutkepohl H., 2005, NEW INTRO MULTIPLE T, DOI DOI 10.1007/978-3-540-27752-1; Marinazzo D, 2008, PHYS REV E, V77, DOI 10.1103/PhysRevE.77.056215; McCullagh P, 1989, GEN LINEAR MODELS, V2nd; Nicholson W. B., 2014, ARXIV14125250; Oord A.V.D., 2016, SSW; Parikh N., 2014, FDN TRENDS OPTIM, V1, P127, DOI DOI 10.1561/2400000003; Pavlovic V, 2001, ADV NEUR IN, V13, P981; Prill RJ, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0009202; Raissi M., 2018, ARXIV 180101236; Runge J, 2012, PHYS REV LETT, V108, DOI 10.1103/PhysRevLett.108.258701; Sameshima K., 2016, METHODS BRAIN CONNEC; Sharpe W. F., 1968, INVESTMENTS; Sheikhattar A, 2018, P NATL ACAD SCI USA, V115, pE3869, DOI 10.1073/pnas.1718154115; Shojaie A, 2010, BIOINFORMATICS, V26, pi517, DOI 10.1093/bioinformatics/btq377; Simon N, 2013, J COMPUT GRAPH STAT, V22, P231, DOI 10.1080/10618600.2012.681250; Sporns O., 2016, NETWORKS BRAIN; Stokes PA, 2017, P NATL ACAD SCI USA, V114, pE7063, DOI 10.1073/pnas.1704663114; Tank A., 2017, ARXIV 170602781; Tao Y., 2018, ARXIV 180600685; Terasvirta T., 2010, MODELLING NONLINEAR; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tong H., 2011, INT ENCY DIA STAT SC, P955; Vicente R, 2011, J COMPUT NEUROSCI, V30, P45, DOI 10.1007/s10827-010-0262-3; Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167; Welling M, 2017, P 31 C NEUR INF PROC, P3288; WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337; Wiegreffe S., 2019, ARXIV 190804626; Williams R.J., 1995, GRADIENT BASED LEARN; Xiao L, 2014, SIAM J OPTIMIZ, V24, P2057, DOI 10.1137/140961791; Yu R., 2017, ARXIV 171100073; Yuan M, 2006, J R STAT SOC B, V68, P49, DOI 10.1111/j.1467-9868.2005.00532.x; Zhang GP, 2003, NEUROCOMPUTING, V50, P159, DOI 10.1016/S0925-2312(01)00702-0	66	16	16	8	31	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 11	2021	44	8					4267	4279		10.1109/TPAMI.2021.3065601	http://dx.doi.org/10.1109/TPAMI.2021.3065601			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HX	33705309	Green Accepted			2022-12-18	WOS:000820522700002
J	Garcia, NC; Morerio, P; Murino, V				Garcia, Nuno C.; Morerio, Pietro; Murino, Vittorio			Learning with Privileged Information via Adversarial Discriminative Modality Distillation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Training; Videos; Data models; Analytical models; Deep learning; Two dimensional displays; Multimodal deep learning; adversarial learning; privileged information; network distillation; modality hallucination		Heterogeneous data modalities can provide complementary cues for several tasks, usually leading to more robust algorithms and better performance. However, while training data can be accurately collected to include a variety of sensory modalities, it is often the case that not all of them are available in real life (testing) scenarios, where a model has to be deployed. This raises the challenge of how to extract information from multimodal data in the training stage, in a form that can be exploited at test time, considering limitations such as noisy or missing modalities. This paper presents a new approach in this direction for RGB-D vision tasks, developed within the adversarial learning and privileged information frameworks. We consider the practical case of learning representations from depth and RGB videos, while relying only on RGB data at test time. We propose a new approach to train a hallucination network that learns to distill depth information via adversarial learning, resulting in a clean approach without several losses to balance or hyperparameters. We report state-of-the-art results for object classification on the NYUD dataset, and video action recognition on the largest multimodal dataset available for this task, the NTU RGB+D, as well as on the Northwestern-UCLA.	[Garcia, Nuno C.; Morerio, Pietro; Murino, Vittorio] Ist Italiano Tecnol, Pattern Anal & Comp Vis, I-16163 Genoa, Italy; [Garcia, Nuno C.] Univ Genoa, I-16126 Genoa, Italy; [Murino, Vittorio] Univ Verona, Dept Comp Sci, I-37129 Verona, Italy	Istituto Italiano di Tecnologia - IIT; University of Genoa; University of Verona	Garcia, NC (corresponding author), Ist Italiano Tecnol, Pattern Anal & Comp Vis, I-16163 Genoa, Italy.	nuno.garcia@iit.it; pietro.morerio@iit.it; vittorio.murino@iit.it	Garcia, Nuno Cruz/U-8422-2018	Garcia, Nuno Cruz/0000-0002-6371-3310; Murino, Vittorio/0000-0002-8645-2328				[Anonymous], 2016, TRAIN GAN TIPS TRICK; Arjovsky M, 2017, PR MACH LEARN RES, V70; Arora S., 2018, P INT C LEARN REPR; Belagiannis V., 2018, P EUR C COMP VIS; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Eitel A, 2015, IEEE INT C INT ROBOT, P681, DOI 10.1109/IROS.2015.7353446; Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787; Firman M, 2016, IEEE COMPUT SOC CONF, P661, DOI 10.1109/CVPRW.2016.88; Garcia NC, 2018, LECT NOTES COMPUT SC, V11212, P106, DOI 10.1007/978-3-030-01237-3_7; GIBSON EJ, 1960, SCI AM, V202, P64, DOI 10.1038/scientificamerican0460-64; Gkioxari G, 2015, PROC CVPR IEEE, P759, DOI 10.1109/CVPR.2015.7298676; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Guo J., 2015, CORR; Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23; Hazirbas C, 2017, LECT NOTES COMPUT SC, V10111, P213, DOI 10.1007/978-3-319-54181-5_14; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Hinton G., 2015, NIPS WORKSH, P1; Hoffman J, 2016, PROC CVPR IEEE, P826, DOI 10.1109/CVPR.2016.96; Isola P., 2017, IMAGE TO IMAGE TRANS, P1125; Janoch A., 2013, CONSUMER DEPTH CAMER, P141, DOI DOI 10.1007/978-1-4471-4640-7_8; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207; Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Li CC, 2018, IEEE IMAGE PROC, P2132, DOI 10.1109/ICIP.2018.8451161; Liu J, 2006, 2006 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, VOLS 1-6, PROCEEDINGS, P1006, DOI 10.1109/ISIT.2006.261879; Lopez-Paz D., 2016, P INT C LEARN REPR, P1; Luo ZL, 2018, LECT NOTES COMPUT SC, V11218, P174, DOI 10.1007/978-3-030-01264-9_11; Luo ZL, 2017, PROC CVPR IEEE, P7101, DOI 10.1109/CVPR.2017.751; Mallick T, 2014, IEEE SENS J, V14, P1731, DOI 10.1109/JSEN.2014.2309987; Mirza M., 2014, ARXIV; Morerio P., 2018, PROC INT C LEARN REP; Neverova N, 2016, IEEE T PATTERN ANAL, V38, P1692, DOI 10.1109/TPAMI.2015.2461544; Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Rahmani H, 2018, IEEE T PATTERN ANAL, V40, P667, DOI 10.1109/TPAMI.2017.2691768; Rahmani H, 2017, IEEE I CONF COMP VIS, P5833, DOI 10.1109/ICCV.2017.621; Roheda S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2926; Rupprecht T, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1772, DOI 10.1145/2976749.2989041; Salimans T, 2016, ADV NEUR IN, V29; Servos P, 2000, EXP BRAIN RES, V130, P35, DOI 10.1007/s002210050004; Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312; Shahroudy A, 2018, IEEE T PATTERN ANAL, V40, P1045, DOI 10.1109/TPAMI.2017.2691321; Shi ZY, 2017, PROC CVPR IEEE, P4684, DOI 10.1109/CVPR.2017.498; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522; Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; Vapnik V, 2009, NEURAL NETWORKS, V22, P544, DOI 10.1016/j.neunet.2009.06.042; Volpi R, 2018, PROC CVPR IEEE, P5495, DOI 10.1109/CVPR.2018.00576; Wang AR, 2015, IEEE T MULTIMEDIA, V17, P1887, DOI 10.1109/TMM.2015.2476655; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180; Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Wang YX, 2018, AAAI CONF ARTIF INTE, P5561; Watson M.R., 2012, ENCY HUMAN BEHAV, V2nd, P690; Xue XB, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P525, DOI 10.1145/2348283.2348355; Ye E. S., 2013, UCBEECS20133; Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454; Zheng C, 2018, PROCEEDINGS OF THE FIRST WORKSHOP ON RADICAL AND EXPERIENTIAL SECURITY (RESEC'18), P61, DOI 10.1145/3203422.3203425	65	16	16	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2020	42	10					2581	2593		10.1109/TPAMI.2019.2929038	http://dx.doi.org/10.1109/TPAMI.2019.2929038			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NL5QY	31331879	Green Submitted			2022-12-18	WOS:000567471300019
J	Cai, ZW; Saberian, M; Vasconcelos, N				Cai, Zhaowei; Saberian, Mohammad; Vasconcelos, Nuno			Learning Complexity-Aware Cascades for Pedestrian Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Complexity theory; Detectors; Boosting; Feature extraction; Proposals; Deep learning; Energy consumption; Real-time pedestrian detection; detector cascades; boosting; complexity constrained learning	BOOSTING ALGORITHMS; OBJECT	The problem of pedestrian detection is considered. The design of complexity-aware cascaded pedestrian detectors, combining features of very different complexities, is investigated. A new cascade design procedure is introduced, by formulating cascade learning as the Lagrangian optimization of a risk that accounts for both accuracy and complexity. A boosting algorithm, denoted as complexity aware cascade training (CompACT), is then derived to solve this optimization. CompACT cascades are shown to seek an optimal trade-off between accuracy and complexity by pushing features of higher complexity to the later cascade stages, where only a few difficult candidate patches remain to be classified. This enables the use of features of vastly different complexities in a single detector. In result, the feature pool can be expanded to features previously impractical for cascade design, such as the responses of a deep convolutional neural network (CNN). This is demonstrated through the design of pedestrian detectors with a pool of features whose complexities span orders of magnitude. The resulting cascade generalizes the combination of a CNN with an object proposal mechanism: rather than a pre-processing stage, CompACT cascades seamlessly integrate CNNs in their stages. This enables accurate detection at fairly fast speeds.	[Cai, Zhaowei; Vasconcelos, Nuno] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA; [Saberian, Mohammad] Netflix Inc, Los Gatos, CA 95032 USA	University of California System; University of California San Diego; Netflix, Inc.	Cai, ZW (corresponding author), Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.	zwcai@ucsd.edu; esaberian@netflix.com; nuno@ucsd.edu		Vasconcelos, Nuno/0000-0002-9024-4302	NSF [IIS-1208522, IIS1637941]; ONR [UCSD-SUBK-N141-076]; NVIDIA	NSF(National Science Foundation (NSF)); ONR(Office of Naval Research); NVIDIA	This work was funded by NSF Awards IIS-1208522 and IIS1637941, ONR award UCSD-SUBK-N141-076, and a GPU donation from NVIDIA.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2009, IEEE DECIS CONTR P; [Anonymous], 2007, IEEE I CONF COMP VIS; [Anonymous], 2015, PROC CVPR IEEE; [Anonymous], 2009, DIR DEV; Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5_47; Benenson R, 2013, PROC CVPR IEEE, P3666, DOI 10.1109/CVPR.2013.470; Bourdev L, 2005, PROC CVPR IEEE, P236, DOI 10.1109/cvpr.2005.310; Brazil G, 2017, IEEE I CONF COMP VIS, P4960, DOI 10.1109/ICCV.2017.530; Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22; Chen X., 2015, ADV NEURAL INFORM PR, V28, P424; Chen XZ, 2016, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2016.236; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Cortes C, 2014, PR MACH LEARN RES, V32, P1179; Costea AD, 2017, PROC CVPR IEEE, P993, DOI 10.1109/CVPR.2017.112; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Dollar P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Gall J, 2009, PROC CVPR IEEE, P1022, DOI 10.1109/CVPRW.2009.5206740; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Hariharan B, 2012, LECT NOTES COMPUT SC, V7575, P459, DOI 10.1007/978-3-642-33765-9_33; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508; Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406; Masnadi-Shirazi H., 2007, P IEEE 11 INT C COMP, P1; Mason L, 2000, ADV NEUR IN, V12, P512; Nam Woonhyun, 2014, ADV NEURAL INFORM PR, V1, P424; Ouyang WL, 2018, IEEE T PATTERN ANAL, V40, P1874, DOI 10.1109/TPAMI.2017.2738645; Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257; Paisitkriangkrai S, 2014, LECT NOTES COMPUT SC, V8692, P546, DOI 10.1007/978-3-319-10593-2_36; Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Saberian M, 2014, J MACH LEARN RES, V15, P2569; Saberian MJ, 2012, IEEE T PATTERN ANAL, V34, P2005, DOI 10.1109/TPAMI.2011.281; Schapire RE, 1998, ANN STAT, V26, P1651; Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465; Shechtman E, 2007, PROC CVPR IEEE, P1744; Tang DH, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.58; Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221; van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang XY, 2013, IEEE I CONF COMP VIS, P17, DOI 10.1109/ICCV.2013.10; Xiao R, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P709; Yang B, 2015, IEEE I CONF COMP VIS, P82, DOI 10.1109/ICCV.2015.18; Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28; Zhang SS, 2017, PROC CVPR IEEE, P4457, DOI 10.1109/CVPR.2017.474; Zhang SS, 2015, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2015.7298784; Zhang SS, 2014, PROC CVPR IEEE, P947, DOI 10.1109/CVPR.2014.126; Zhou K, 2016, DESTECH TRANS COMP	59	16	16	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2020	42	9					2195	2211		10.1109/TPAMI.2019.2910514	http://dx.doi.org/10.1109/TPAMI.2019.2910514			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MW9MI	30990173	Green Submitted, hybrid			2022-12-18	WOS:000557354900009
J	Matsukawa, T; Okabe, T; Suzuki, E; Sato, Y				Matsukawa, Tetsu; Okabe, Takahiro; Suzuki, Einoshin; Sato, Yoichi			Hierarchical Gaussian Descriptors with Application to Person Re-Identification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image color analysis; Gaussian distribution; Manifolds; Covariance matrices; Histograms; Colored noise; Measurement; Person re-identification; image feature descriptor; Gaussian distribution; Riemannian geometry; symmetric positive definite matrices; log-Euclidean Riemannian metric	FISHER VECTOR; COVARIANCE; CLASSIFICATION; MANIFOLDS	Describing the color and textural information of a person image is one of the most crucial aspects of person re-identification (re-id). Although a covariance descriptor has been successfully applied to person re-id, it loses the local structure of a region and mean information of pixel features, both of which tend to be the major discriminative information for person re-id. In this paper, we present novel meta-descriptors based on a hierarchical Gaussian distribution of pixel features, in which both mean and covariance information are included in patch and region level descriptions. More specifically, the region is modeled as a set of multiple Gaussian distributions, each of which represents the appearance of a local patch. The characteristics of the set of Gaussian distributions are again described by another Gaussian distribution. Because the space of Gaussian distribution is not a linear space, we embed the parameters of the distribution into a point of Symmetric Positive Definite (SPD) matrix manifold in both steps. We show, for the first time, that normalizing the scale of the SPD matrix enhances the hierarchical feature representation on this manifold. Additionally, we develop feature norm normalization methods with the ability to alleviate the biased trends that exist on the SPD matrix descriptors. The experimental results conducted on five public datasets indicate the effectiveness of the proposed descriptors and the two types of normalizations.	[Matsukawa, Tetsu; Suzuki, Einoshin] Kyushu Univ, Fac Informat Sci & Elect Engn, Fukuoka 8190395, Japan; [Okabe, Takahiro] Kyushu Inst Technol, Grad Sch Comp Sci & Syst Engn, Fukuoka 8208502, Japan; [Sato, Yoichi] Univ Tokyo, Inst Ind Sci, Tokyo 1538505, Japan	Kyushu University; Kyushu Institute of Technology; University of Tokyo	Matsukawa, T (corresponding author), Kyushu Univ, Fac Informat Sci & Elect Engn, Fukuoka 8190395, Japan.	matsukawa@inf.kyushu-u.ac.jp; okabe@ai.kyutech.ac.jp; suzuki@inf.kyushu-u.ac.jp; ysato@iis.u-tokyo.ac.jp		Okabe, Takahiro/0000-0002-2183-7112; Sato, Yoichi/0000-0003-0097-4537	"R&D Program for Implementation of Anti-Crime and Anti-Terrorism Technologies for a Safe and Secure Society," under the fund for the integrated promotion of social system reform and research and development of MEXT Japan; JSPS KAKENHI [JP15K16028, JP17K20008]	"R&D Program for Implementation of Anti-Crime and Anti-Terrorism Technologies for a Safe and Secure Society," under the fund for the integrated promotion of social system reform and research and development of MEXT Japan; JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	We thank the anonymous reviewers and the associate editor for their valuable comments to improve this paper. This work was supported by the "R&D Program for Implementation of Anti-Crime and Anti-Terrorism Technologies for a Safe and Secure Society," under the fund for the integrated promotion of social system reform and research and development of MEXT Japan, JSPS KAKENHI JP15K16028, and JP17K20008.	Ali T., 2018, P EUR C COMPUT VIS, P123; Amari S., 2001, METHODS INFORM GEOME; [Anonymous], 2012, LECT NOTES COMPUT SC; [Anonymous], 2016, NEUROCOMPUTING, DOI DOI 10.1016/J.NEUCOM.2015.07.134; [Anonymous], 2009, 2009 INT C COMM; [Anonymous], 2012, LECT NOTES COMPUT SC; [Anonymous], 2012, LECT NOTES COMPUT SC; Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996; Bak S, 2017, IEEE T SYST MAN CY-S, V47, P2538, DOI 10.1109/TSMC.2016.2531658; Bak S, 2012, IMAGE VISION COMPUT, V30, P443, DOI 10.1016/j.imavis.2011.08.008; Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008; Biagio MS, 2013, IEEE I CONF COMP VIS, P809, DOI 10.1109/ICCV.2013.105; Carreira J, 2015, IEEE T PATTERN ANAL, V37, P1177, DOI 10.1109/TPAMI.2014.2361137; Chen DP, 2017, INT J COMPUT VISION, V123, P392, DOI 10.1007/s11263-017-0991-0; Chen YC, 2018, IEEE T PATTERN ANAL, V40, P392, DOI 10.1109/TPAMI.2017.2666805; Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68; Csurka G., 2004, P WORKSH STAT LEARN, P59; Dikmen M., 2010, P AS C COMP VIS, P501; Dryden IL, 2009, ANN APPL STAT, V3, P1102, DOI 10.1214/09-AOAS249; Faraki M, 2015, PROC CVPR IEEE, P4951, DOI 10.1109/CVPR.2015.7299129; Faraki M, 2014, PATTERN RECOGN, V47, P2348, DOI 10.1016/j.patcog.2013.10.011; Fukunaga K., 1972, INTRO STAT PATTERN R; Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21; Guo YL, 2018, PROC CVPR IEEE, P2335, DOI 10.1109/CVPR.2018.00248; Harandi M, 2018, IEEE T PATTERN ANAL, V40, P48, DOI 10.1109/TPAMI.2017.2655048; Harandi M, 2014, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2014.132; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hermans A., 2017, ARXIV170307737; Huang ZW, 2015, PR MACH LEARN RES, V37, P720; Ilea I, 2016, IEEE IMAGE PROC, P3543, DOI 10.1109/ICIP.2016.7533019; Jayasumana S, 2015, IEEE T PATTERN ANAL, V37, P2464, DOI 10.1109/TPAMI.2015.2414422; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Jegou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55; Karanam S, 2019, IEEE T PATTERN ANAL, V41, P523, DOI 10.1109/TPAMI.2018.2807450; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kviatkovsky I, 2013, IEEE T PATTERN ANAL, V35, P1622, DOI 10.1109/TPAMI.2012.246; Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24; Li PH, 2018, PROC CVPR IEEE, P947, DOI 10.1109/CVPR.2018.00105; Li PH, 2017, IEEE I CONF COMP VIS, P2089, DOI 10.1109/ICCV.2017.228; Li PH, 2017, IEEE T PATTERN ANAL, V39, P803, DOI 10.1109/TPAMI.2016.2560816; Li PH, 2013, IEEE I CONF COMP VIS, P1689, DOI 10.1109/ICCV.2013.212; Li W., 2012, P AS C COMP VIS, P31; Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27; Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832; Lovric M, 2000, J MULTIVARIATE ANAL, V74, P36, DOI 10.1006/jmva.1999.1853; Loy CC, 2010, INT J COMPUT VISION, V90, P106, DOI 10.1007/s11263-010-0347-5; Ma B., 2014, P AS C COMP VIS WORK, P505; Ma BP, 2014, IMAGE VISION COMPUT, V32, P379, DOI 10.1016/j.imavis.2014.04.002; Matsukawa T, 2016, INT C PATT RECOG, P2428, DOI 10.1109/ICPR.2016.7900000; Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152; Minh H. Q., 2014, ADV NEURAL INF PROCE, V27, P388; Nakayama H, 2010, PROC CVPR IEEE, P2336, DOI 10.1109/CVPR.2010.5539921; Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40; Roth P. M., 2014, MAHALANOBIS DISTANCE; Sanchez J, 2015, PATTERN RECOGN LETT, V59, P26, DOI 10.1016/j.patrec.2015.03.010; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Serra G., 2014, P INT C MULT RETR; Serra G, 2015, COMPUT VIS IMAGE UND, V134, P22, DOI 10.1016/j.cviu.2015.01.005; Sra S., 2012, ADV NEURAL INFORM PR, P144; Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427; Subramaniam A., 2016, P 30 INT C NEUR INF, P2675; Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25; Tosato D, 2013, IEEE T PATTERN ANAL, V35, P1972, DOI 10.1109/TPAMI.2012.263; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589; Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48; Wang HX, 2018, INT J COMPUT VISION, V126, P1288, DOI 10.1007/s11263-018-1105-3; Wang QL, 2017, PROC CVPR IEEE, P6507, DOI 10.1109/CVPR.2017.689; Wang QL, 2016, PROC CVPR IEEE, P4433, DOI 10.1109/CVPR.2016.480; Wang QL, 2016, PATTERN RECOGN, V59, P63, DOI 10.1016/j.patcog.2016.03.004; Xie LX, 2016, IEEE T CIRC SYST VID, V26, P1251, DOI 10.1109/TCSVT.2015.2461978; Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1; Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35; Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139; Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103; Zhao R, 2017, IEEE T PATTERN ANAL, V39, P356, DOI 10.1109/TPAMI.2016.2544310; Zheng L., 2016, ARXIV161002984; Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133; Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138	82	16	16	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2020	42	9					2179	2194		10.1109/TPAMI.2019.2914686	http://dx.doi.org/10.1109/TPAMI.2019.2914686			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MW9MI	31059427	Green Submitted			2022-12-18	WOS:000557354900008
J	Sarkar, S; Ghosh, AK				Sarkar, Soham; Ghosh, Anil K.			On Perfect Clustering of High Dimension, Low Sample Size Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustering algorithms; Indexes; Euclidean distance; Sociology; Statistics; Single photon emission computed tomography; Estimation; Dunn index; hierarchical clustering; high dimensional consistency; k-means clustering; pairwise distances; Rand index	LARGE NUMBERS; DATA SET; LAWS; PCA	Popular clustering algorithms based on usual distance functions (e.g., the Euclidean distance) often suffer in high dimension, low sample size (HDLSS) situations, where concentration of pairwise distances and violation of neighborhood structure have adverse effects on their performance. In this article, we use a new data-driven dissimilarity measure, called MADD, which takes care of these problems. MADD uses the distance concentration phenomenon to its advantage, and as a result, clustering algorithms based on MADD usually perform well for high dimensional data. We establish it using theoretical as well as numerical studies. We also address the problem of estimating the number of clusters. This is a challenging problem in cluster analysis, and several algorithms are available for it. We show that many of these existing algorithms have superior performance in high dimensions when they are constructed using MADD. We also construct a new estimator based on a penalized version of the Dunn index and prove its consistency in the HDLSS asymptotic regime. Several simulated and real data sets are analyzed to demonstrate the usefulness of MADD for cluster analysis of high dimensional data.	[Sarkar, Soham] Ecole Polytech Fed Lausanne, Inst Math, Stn 8, CH-1015 Lausanne, Switzerland; [Ghosh, Anil K.] Indian Stat Inst, Theoret Stat & Math Unit, 203 BT Rd, Kolkata 700108, India	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Indian Statistical Institute; Indian Statistical Institute Kolkata	Sarkar, S (corresponding author), Ecole Polytech Fed Lausanne, Inst Math, Stn 8, CH-1015 Lausanne, Switzerland.	soham.sarkar@epfl.ch; akghosh@isical.ac.in	Boothapati, Anil Kumar/HHS-1813-2022	Sarkar, Soham/0000-0003-0412-6826	Keysight Technologies, Inc., USA	Keysight Technologies, Inc., USA	The authors would like to thank the Associate Editor and all the anonymous reviewers for their insightful comments. They also thank Dr. J. Ahn for providing us with the codes for MDP clustering. This research was partially supported by Keysight Technologies, Inc., USA.	Aggarwal CC, 2001, LECT NOTES COMPUT SC, V1973, P420; Ahn J, 2012, STAT SINICA, V22, P443, DOI 10.5705/ss.2010.148; Alcock R. J., 1999, P 7 PANH C INF, P27; Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501; ANDREWS DWK, 1988, ECONOMET THEOR, V4, P458, DOI 10.1017/S0266466600013396; Aryal S, 2017, KNOWL INF SYST, V53, P479, DOI 10.1007/s10115-017-1046-0; Baringhaus L, 2010, STAT SINICA, V20, P1333; Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217; Biswas M, 2015, STAT SINICA, V25, P1421, DOI 10.5705/ss.2014.155; Biswas M, 2014, BIOMETRIKA, V101, P913, DOI 10.1093/biomet/asu045; Borysov P, 2014, J MULTIVARIATE ANAL, V124, P465, DOI 10.1016/j.jmva.2013.11.010; DEJONG RM, 1995, ECONOMET THEOR, V11, P347, DOI 10.1017/S0266466600009208; Doborjeh MG, 2018, EVOL SYST-GER, V9, P195, DOI 10.1007/s12530-017-9178-8; Donoho D. L., 2000, AMS MATH CHALLENGES, V1; Duda R.O., 2012, PATTERN CLASSIFICATI; Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046; Dutta S, 2016, MACH LEARN, V102, P57, DOI 10.1007/s10994-015-5495-y; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Francois D, 2007, IEEE T KNOWL DATA EN, V19, P873, DOI 10.1109/TKDE.2007.1037; Hall P, 2005, J R STAT SOC B, V67, P427, DOI 10.1111/j.1467-9868.2005.00510.x; Hartigan J. A., 1975, CLUSTERING ALGORITHM; Hastie T., 2009, ELEMENTS STAT LEARNI; Huang HW, 2015, J COMPUT GRAPH STAT, V24, P975, DOI 10.1080/10618600.2014.948179; Johnson R. A., 2014, ED RES QUANTITATIVE; KRZANOWSKI WJ, 1988, BIOMETRICS, V44, P23, DOI 10.2307/2531893; Kulis B, 2013, FOUND TRENDS MACH LE, V5, P287, DOI 10.1561/2200000019; Lin Z., 1996, LIMIT THEORY MIXING, V378; Ng AY, 2002, ADV NEUR IN, V14, P849; Radovanovic M, 2010, J MACH LEARN RES, V11, P2487; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7; Roverso D., 2000, P 3 ANS INT TOP M NU; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Sugar CA, 2003, J AM STAT ASSOC, V98, P750, DOI 10.1198/016214503000000666; Szekely GJ, 2013, J STAT PLAN INFER, V143, P1249, DOI 10.1016/j.jspi.2013.03.018; Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293; Ting KM, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1205, DOI 10.1145/2939672.2939779; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wang JH, 2010, BIOMETRIKA, V97, P893, DOI 10.1093/biomet/asq061; Yata K, 2012, J MULTIVARIATE ANAL, V105, P193, DOI 10.1016/j.jmva.2011.09.002; Zhou ZH, 2012, ARTIF INTELL, V176, P2291, DOI 10.1016/j.artint.2011.10.002	42	16	16	5	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2020	42	9					2257	2272		10.1109/TPAMI.2019.2912599	http://dx.doi.org/10.1109/TPAMI.2019.2912599			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MW9MI	31027041	Green Submitted			2022-12-18	WOS:000557354900013
J	Que, QQ; Belkin, M				Que, Qichao; Belkin, Mikhail			Back to the Future: Radial Basis Function Network Revisited	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Supervised learning; radial basis function networks; k-means	APPROXIMATION; ALGORITHM	Radial Basis Function (RBF) networks are a classical family of algorithms for supervised learning. The most popular approach for training RBF networks has relied on kernel methods using regularization based on a norm in a Reproducing Kernel Hilbert Space (RKHS), which is a principled and empirically successful framework. In this paper we aim to revisit some of the older approaches to training the RBF networks from a more modern perspective. Specifically, we analyze two common regularization procedures, one based on the square norm of the coefficients in the network and another one using centers obtained by k-means clustering. We show that both of these RBF methods can be recast as certain data-dependent kernels. We provide a theoretical analysis of these methods as well as a number of experimental results, pointing out very competitive experimental performance as well as certain advantages over the standard kernel methods in terms of both flexibility (incorporating of unlabeled data) and computational complexity. Finally, our results shed light on some impressive recent successes of using soft k-means features for image recognition and other tasks.	[Que, Qichao; Belkin, Mikhail] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA	University System of Ohio; Ohio State University	Que, QQ (corresponding author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.	que@cse.ohio-state.edu; mbelkin@cse.ohio-state.edu			US National Science Foundation [1117707, 1422830, 1550757]	US National Science Foundation(National Science Foundation (NSF))	We thank Vikas Sindhwani for encouraging us to understand the difference between l<SUP>2</SUP> and RKHS regularization. The work was supported by US National Science Foundation Grants 1117707, 1422830, 1550757.	[Anonymous], 2008, P ADV NEUR INF PROC; Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027; Bishop C, 1991, NEURAL COMPUT, V3, P579, DOI 10.1162/neco.1991.3.4.579; Broomhead D. S., 1988, TECH REP; Chen S, 1996, INT J CONTROL, V64, P829, DOI 10.1080/00207179608921659; CHEN S, 1991, IEEE T NEURAL NETWOR, V2, P302, DOI 10.1109/72.80341; Coates Adam, 2011, AISTATS, V6, DOI DOI 10.1177/1753193410390845; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Graf S., 2000, FDN QUANTIZATION PRO; Kulis B., 2012, P 29 INT C MACH LEAR, P1131; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Mahajan M, 2012, THEOR COMPUT SCI, V442, P13, DOI 10.1016/j.tcs.2010.05.034; Netzer Y., 2011, READING DIGITS NATUR; Niyogi P, 1996, NEURAL COMPUT, V8, P819, DOI 10.1162/neco.1996.8.4.819; Orr M. J., 1993, REGULARISED CTR RECR, V59; Orr M.J.L, 1996, INTRO RADIAL BASIS F; ORR MJL, 1995, NEURAL COMPUT, V7, P606, DOI 10.1162/neco.1995.7.3.606; PARK J, 1993, NEURAL COMPUT, V5, P305, DOI 10.1162/neco.1993.5.2.305; Park J, 1991, NEURAL COMPUT, V3, P246, DOI 10.1162/neco.1991.3.2.246; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Que Q., 2014, ADV NEURAL INFORM PR, P2951; Que Qichao, 2010, THESIS; Scholkopf B, 1997, IEEE T SIGNAL PROCES, V45, P2758, DOI 10.1109/78.650102; Smale S, 2005, APPL COMPUT HARMON A, V19, P285, DOI 10.1016/j.acha.2005.03.001	25	16	16	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG. 1	2020	42	8					1856	1867		10.1109/TPAMI.2019.2906594	http://dx.doi.org/10.1109/TPAMI.2019.2906594			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MF5XR	30908191	hybrid			2022-12-18	WOS:000545415400004
J	Kalayeh, MM; Shah, MB				Kalayeh, Mahdi M.; Shah, Mubarak			Training Faster by Separating Modes of Variation in Batch-Normalized Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Batch normalization; convolutional neural networks; generative probability models; Gaussian mixture model; fisher vector		Batch Normalization (BN) is essential to effectively train state-of-the-art deep Convolutional Neural Networks (CNN). It normalizes the layer outputs during training using the statistics of each mini-batch. BN accelerates training procedure by allowing to safely utilize large learning rates and alleviates the need for careful initialization of the parameters. In this work, we study BN from the viewpoint of Fisher kernels that arise from generative probability models. We show that assuming samples within a mini-batch are from the same probability density function, then BN is identical to the Fisher vector of a Gaussian distribution. That means batch normalizing transform can be explained in terms of kernels that naturally emerge from the probability density function that models the generative process of the underlying data distribution. Consequently, it promises higher discrimination power for the batch-normalized mini-batch. However, given the rectifying non-linearities employed in CNN architectures, distribution of the layer outputs show an asymmetric characteristic. Therefore, in order for BN to fully benefit from the aforementioned properties, we propose approximating underlying data distribution not with one, but a mixture of Gaussian densities. Deriving Fisher vector for a Gaussian Mixture Model (GMM), reveals that batch normalization can be improved by independently normalizing with respect to the statistics of disentangled sub-populations. We refer to our proposed soft piecewise version of batch normalization as Mixture Normalization (MN). Through extensive set of experiments on CIFAR-10 and CIFAR-100, using both a 5-layers deep CNN and modern Inception-V3 architecture, we show that mixture normalization reduces required number of gradient updates to reach the maximum test accuracy of the batch-normalized model by $\sim 31\%-47\%$similar to 31%-47% across a variety of training scenarios. Replacing even a few BN modules with MN in the 48-layers deep Inception-V3 architecture is sufficient to not only obtain considerable training acceleration but also better final test accuracy. We show that similar observations are valid for 40 and 100-layers deep DenseNet architectures as well. We complement our study by evaluating the application of mixture normalization to the Generative Adversarial Networks (GANs), where "mode collapse" hinders the training process. We solely replace a few batch normalization layers in the generator with our proposed mixture normalization. Our experiments using Deep Convolutional GAN (DCGAN) on CIFAR-10 show that mixture-normalized DCGAN not only provides an acceleration of $\sim 58\%$similar to 58% but also reaches lower (better) "Frechet Inception Distance" (FID) of 33.35 compared to 37.56 of its batch-normalized counterpart.	[Kalayeh, Mahdi M.; Shah, Mubarak] Univ Cent Florida, Dept Comp Sci, Ctr Res Comp Vis CRCV, Orlando, FL 32816 USA	State University System of Florida; University of Central Florida	Kalayeh, MM (corresponding author), Univ Cent Florida, Dept Comp Sci, Ctr Res Comp Vis CRCV, Orlando, FL 32816 USA.	mahdi@eecs.ucf.edu; shah@crcv.ucf.edu		Shah, Mubarak/0000-0001-6172-5572	US National Science Foundation [1741431]	US National Science Foundation(National Science Foundation (NSF))	This material is based upon work supported by the US National Science Foundation under Grant No. 1741431. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the US National Science Foundation.	Amari S, 1998, NEURAL COMPUT, V10, P251, DOI 10.1162/089976698300017746; Amari S.-I., 2007, METHODS INFORM GEOME; [Anonymous], 2017, ICLR; [Anonymous], 2017, ADV NEURAL INFORM PR; Arjovsky M., 2017, P 2017 INT C LEARN R, P1; Arora S., 2018, ICML; Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027; Ba L.J, 2016, P C WORKSH NEUR INF; Bachem O., 2016, ADV NEURAL INFORM PR, V29, P55; Bachem O, 2016, AAAI CONF ARTIF INTE, P1459; Bachem O, 2017, PR MACH LEARN RES, V70; Bahmani B, 2012, PROC VLDB ENDOW, V5, P622, DOI 10.14778/2180912.2180915; Bengio Y, 2013, INT CONF ACOUST SPEE, P8624, DOI 10.1109/ICASSP.2013.6639349; Che T., 2017, 5 INT C LEARN REPR T; Chen X, 2016, ADV NEUR IN, V29; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; GATYS LA, 2016, PROC CVPR IEEE, P2414, DOI DOI 10.1109/CVPR.2016.265; Ghosh A, 2018, PROC CVPR IEEE, P8513, DOI 10.1109/CVPR.2018.00888; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Hardt M, 2016, PR MACH LEARN RES, V48; Heusel M., 2017, P 31 INT C NEUR INF, P6629; Hosseini R., 2017, ARXIV170603267; Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Ioffe Sergey, 2017, NIPS, P3; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Jaakkola TS, 1999, ADV NEUR IN, V11, P487; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90; Kingma D.P., 2015, INT C LEARN REPR, P1; Krizhevsky A., 2009, TR2009 U TOR DEP COM, P32; Ledig C., 2017, PROC CVPR IEEE, P4681, DOI [10.1109/CVPR.2017.19, DOI 10.1109/CVPR.2017.19]; Lin M., 2013, ICLR; Liu DJ, 2017, LECT N EDUC TECHNOL, P3, DOI 10.1007/978-981-10-4343-7_1; Lucic M., 2017, J MACH LEARN RES, V18, P5885; Metz L., 2017, ICLR; Nair V., 2010, ICML, P807; Okuta R, 2017, PROC 31 C NEURAL INF; Perronnin F., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383266; Radford A., 2015, ARXIV PREPR ARXIV151; Ren M., 2017, INT C LEARN REPR ICL; Salimans T., 2016, ADV NEUR IN, P2234; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Szegedy C., 2017, P 31 AAAI C ART INT, V4, P12; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26; Titterington D. M., 1985, STAT ANAL FINITEMIXT; Tokui S., 2015, P WORKSH MACH LEARN; Ulyanov D., 2017, CVPR, P6924; Verbeek JJ, 2003, NEURAL COMPUT, V15, P469, DOI 10.1162/089976603762553004; Wasserstein G.A.N., 2017, ARXIV170107875; Wu Y., 2018, EUR C COMP VIS ECCV; Zagoruyko S., 2016, BMVC	54	16	19	4	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2020	42	6					1483	1500		10.1109/TPAMI.2019.2895781	http://dx.doi.org/10.1109/TPAMI.2019.2895781			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR3TM	30703010	hybrid, Green Submitted			2022-12-18	WOS:000535615700014
J	Zhang, R; Tang, S; Zhang, YD; Li, JT; Yan, SC				Zhang, Rui; Tang, Sheng; Zhang, Yongdong; Li, Jintao; Yan, Shuicheng			Perspective-Adaptive Convolutions for Scene Parsing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape; Standards; Strain; Proposals; Convolutional neural networks; Training; Task analysis; Scene parsing; convolutional neural networks; perspective-adaptive convolutions; context adaptive biases		Many existing scene parsing methods adopt Convolutional Neural Networks with receptive fields of fixed sizes and shapes, which frequently results in inconsistent predictions of large objects and invisibility of small objects. To tackle this issue, we propose perspective-adaptive convolutions to acquire receptive fields of flexible sizes and shapes during scene parsing. Through adding a new perspective regression layer, we can dynamically infer the position-adaptive perspective coefficient vectors utilized to reshape the convolutional patches. Consequently, the receptive fields can be adjusted automatically according to the various sizes and perspective deformations of the objects in scene images. Our proposed convolutions are differentiable to learn the convolutional parameters and perspective coefficients in an end-to-end way without any extra training supervision of object sizes. Furthermore, considering that the standard convolutions lack contextual information and spatial dependencies, we propose a context adaptive bias to capture both local and global contextual information through average pooling on the local feature patches and global feature maps, followed by flexible attentive summing to the convolutional results. The attentive weights are position-adaptive and context-aware, and can be learned through adding an additional context regression layer. Experiments on Cityscapes and ADE20K datasets well demonstrate the effectiveness of the proposed methods.	[Zhang, Rui; Tang, Sheng; Zhang, Yongdong; Li, Jintao] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China; [Zhang, Rui; Tang, Sheng; Zhang, Yongdong; Li, Jintao] Univ Chinese Acad Sci, Beijing 100049, Peoples R China; [Yan, Shuicheng] AI Inst Qihoo 360, Beijing 100025, Peoples R China	Chinese Academy of Sciences; Institute of Computing Technology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Tang, S; Zhang, YD (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.	zhangrui@ict.ac.cn; ts@ict.ac.cn; zhyd@ict.ac.cn; jtli@ict.ac.cn; yanshuicheng@360.cn	Yan, Shuicheng/HCI-1431-2022; Tang, Sheng/L-5792-2013	Tang, Sheng/0000-0003-3573-2407	National Natural Science Foundation of China [61525206, 61572472]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the National Natural Science Foundation of China under Grant 61525206 and Grant 61572472.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56; Byeon W, 2015, PROC CVPR IEEE, P3547, DOI 10.1109/CVPR.2015.7298977; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396; Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Ghiasi G, 2016, LECT NOTES COMPUT SC, V9907, P519, DOI 10.1007/978-3-319-46487-9_32; Graves A, 2007, LECT NOTES COMPUT SC, V4668, P549; Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947; Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642; Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hoiem D, 2005, IEEE I CONF COMP VIS, P654; Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5; Jaderberg M, 2015, ADV NEUR IN, V28; Jin XJ, 2017, IEEE I CONF COMP VIS, P5581, DOI 10.1109/ICCV.2017.595; Jin X, 2016, INT C MANAGE SCI ENG, P1409; Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19; Li X, 2017, IEEE I CONF COMP VIS, P784, DOI 10.1109/ICCV.2017.91; Li Yi, 2017, P IEEE C COMP VIS PA; Liang XD, 2016, PROC CVPR IEEE, P3185, DOI 10.1109/CVPR.2016.347; Liang XD, 2016, LECT NOTES COMPUT SC, V9905, P125, DOI 10.1007/978-3-319-46448-0_8; Liang XD, 2015, IEEE I CONF COMP VIS, P1386, DOI 10.1109/ICCV.2015.163; Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549; Lin GS, 2016, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2016.348; Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162; Mostajahi M, 2015, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2015.7298959; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shuai B, 2016, PROC CVPR IEEE, P3620, DOI 10.1109/CVPR.2016.394; Sturgess P., 2009, P BRIT MACH VIS C, P1; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Vemulapalli R, 2016, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2016.351; Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163; Wu Z, 2016, CORR, P1; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Yu F., 2016, ABS151107122 CORR; Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474; Zhang R, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1156; Zhang R, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3427; Zhang R, 2017, IEEE I CONF COMP VIS, P2050, DOI 10.1109/ICCV.2017.224; Zhang ZY, 2015, IEEE I CONF COMP VIS, P2614, DOI 10.1109/ICCV.2015.300; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179; Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	55	16	16	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2020	42	4					909	924		10.1109/TPAMI.2018.2890637	http://dx.doi.org/10.1109/TPAMI.2018.2890637			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LE2GI	30605095				2022-12-18	WOS:000526541100009
J	Ding, ZM; Shao, M; Fu, Y				Ding, Zhengming; Shao, Ming; Fu, Yun			Generative Zero-Shot Learning via Low-Rank Embedded Semantic Dictionary	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Visualization; Dictionaries; Generative adversarial networks; Gallium nitride; Training; Data models; Generative adversarial network; low-rank embedding; semantic dictionary; zero-shot learning	CLASSIFICATION	Zero-shot learning for visual recognition, which approaches identifying unseen categories through a shared visual-semantic function learned on the seen categories and is expected to well adapt to unseen categories, has received considerable research attention most recently. However, the semantic gap between discriminant visual features and their underlying semantics is still the biggest obstacle, because there usually exists domain disparity across the seen and unseen classes. To deal with this challenge, we design two-stage generative adversarial networks to enhance the generalizability of semantic dictionary through low-rank embedding for zero-shot learning. In detail, we formulate a novel framework to simultaneously seek a two-stage generative model and a semantic dictionary to connect visual features with their semantics under a low-rank embedding. Our first-stage generative model is able to augment more semantic features for the unseen classes, which are then used to generate more discriminant visual features in the second stage, to expand the seen visual feature space. Therefore, we will be able to seek a better semantic dictionary to constitute the latent basis for the unseen classes based on the augmented semantic and visual data. Finally, our approach could capture a variety of visual characteristics from seen classes that are "ready-to-use" for new classes. Extensive experiments on four zero-shot benchmarks demonstrate that our proposed algorithm outperforms the state-of-the-art zero-shot algorithms.	[Ding, Zhengming] Indiana Univ Purdue Univ, Dept Comp Informat & Technol, 420 Univ Blvd, Indianapolis, IN 46202 USA; [Shao, Ming] Univ Massachusetts Dartmouth, Dept Comp & Informat Sci, N Dartmouth, MA 02747 USA; [Fu, Yun] Northeastern Univ, Coll Comp & Informat Sci, Dept Elect & Comp Engn, Boston, MA 02115 USA	Indiana University System; Indiana University-Purdue University Indianapolis; University of Massachusetts System; University Massachusetts Dartmouth; Northeastern University	Ding, ZM (corresponding author), Indiana Univ Purdue Univ, Dept Comp Informat & Technol, 420 Univ Blvd, Indianapolis, IN 46202 USA.	zd2@iu.edu; mshao@umassd.edu; yunfu@ece.neu.edu	Ding, Zhengming/AAJ-2918-2021	Ding, Zhengming/0000-0002-6994-5278; Fu, Yun/0000-0002-5098-2853	US National Science Foundation IIS award [1651902]; NIJ Graduate Research Fellowship [2016-R2-CX-0013]; ONR Young Investigator Award [N00014-14-1-0484]; U.S. Army Research Office Award [W911NF-17-1-0367]	US National Science Foundation IIS award(National Science Foundation (NSF)); NIJ Graduate Research Fellowship; ONR Young Investigator Award; U.S. Army Research Office Award	This work is supported in part by the US National Science Foundation IIS award 1651902, NIJ Graduate Research Fellowship 2016-R2-CX-0013, ONR Young Investigator Award N00014-14-1-0484, and U.S. Army Research Office Award W911NF-17-1-0367.	Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Nguyen A, 2016, ADV NEUR IN, V29; BARTELS RH, 1972, COMMUN ACM, V15, P820, DOI 10.1145/361573.361582; Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18; Bucher M, 2016, LECT NOTES COMPUT SC, V9909, P730, DOI 10.1007/978-3-319-46454-1_44; Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575; Chao WL, 2016, LECT NOTES COMPUT SC, V9906, P52, DOI 10.1007/978-3-319-46475-6_4; Chen X., 2016, ARXIV160603657, P2172; Chen Y, 2017, IEEE I CONF COMP VIS, P1221, DOI 10.1109/ICCV.2017.137; Ding ZY, 2020, INT J PARALLEL PROG, V48, P534, DOI 10.1007/s10766-018-0595-5; Ding ZM, 2018, IEEE T IMAGE PROCESS, V27, P5214, DOI 10.1109/TIP.2018.2851067; Ding ZM, 2018, IEEE T NEUR NET LEAR, V29, P310, DOI 10.1109/TNNLS.2016.2618765; Ding ZM, 2016, LECT NOTES COMPUT SC, V9910, P567, DOI 10.1007/978-3-319-46466-4_34; FAN K, 1949, P NATL ACAD SCI USA, V35, P652, DOI 10.1073/pnas.35.11.652; Fu YW, 2015, IEEE T PATTERN ANAL, V37, P2332, DOI 10.1109/TPAMI.2015.2408354; FU ZY, 2015, PROC CVPR IEEE, P2635, DOI DOI 10.1109/CVPR.2015.7298879; Gan C, 2016, PROC CVPR IEEE, P87, DOI 10.1109/CVPR.2016.17; Ganin Y, 2015, PR MACH LEARN RES, V37, P1180; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gulrajani I, 2017, P NIPS 2017; Jiang B, 2017, PROC CVPR IEEE, P550, DOI 10.1109/CVPR.2017.66; Jiang HJ, 2017, IEEE I CONF COMP VIS, P4233, DOI 10.1109/ICCV.2017.453; Kodirov E, 2015, IEEE I CONF COMP VIS, P2452, DOI 10.1109/ICCV.2015.282; Kolouri S, 2018, AAAI CONF ARTIF INTE, P3431; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Li X, 2015, IEEE I CONF COMP VIS, P4211, DOI 10.1109/ICCV.2015.479; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu ZW, 2017, I C INTELL COMPUT TE, P327, DOI 10.1109/ICICTA.2017.79; Mensink T, 2014, PROC CVPR IEEE, P2441, DOI 10.1109/CVPR.2014.313; Mirza M., 2014, ARXIV; Mu X, 2017, AAAI CONF ARTIF INTE, P2373; Mu X, 2017, IEEE T KNOWL DATA EN, V29, P1605, DOI 10.1109/TKDE.2017.2691702; Odena A., 2016, SEMISUPERVISED LEARN; Palatucci Mark, 2009, ADV NEURAL INFORM PR, P1410; Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281; Peng PX, 2016, LECT NOTES COMPUT SC, V9908, P336, DOI 10.1007/978-3-319-46493-0_21; Qiao RZ, 2016, PROC CVPR IEEE, P2249, DOI 10.1109/CVPR.2016.247; Radovanovic M, 2010, J MACH LEARN RES, V11, P2487; Reed S, 2016, PR MACH LEARN RES, V48; Salimans T, 2016, ADV NEUR IN, V29; Shao M, 2016, AAAI CONF ARTIF INTE, P2023; Shao M, 2014, INT J COMPUT VISION, V109, P74, DOI 10.1007/s11263-014-0696-6; Sutskever I., 2014, ARXIV14093215, DOI DOI 10.1007/S10107-014-0839-0; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463; van den Oord Aaron, 2016, ARXIV160605328; Wang HR, 2018, IEEE SYS MAN CYBERN, P2798, DOI 10.1109/SMC.2018.00477; Xu X, 2016, LECT NOTES COMPUT SC, V9906, P343, DOI 10.1007/978-3-319-46475-6_22; Yang K, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6343; Ye M, 2017, PROC CVPR IEEE, P5103, DOI 10.1109/CVPR.2017.542; Yu XD, 2010, LECT NOTES COMPUT SC, V6315, P127; Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474; ZHANG ZM, 2016, PROC CVPR IEEE, P6034, DOI DOI 10.1109/CVPR.2016.649; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179; Zhu Y, 2018, IEEE T KNOWL DATA EN, V30, P1901, DOI 10.1109/TKDE.2018.2810872	61	16	16	4	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2019	41	12					2861	2874		10.1109/TPAMI.2018.2867870	http://dx.doi.org/10.1109/TPAMI.2018.2867870			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JQ0XI	30176581				2022-12-18	WOS:000498677600006
J	Xu, YY; Gao, SH; Wu, JR; Li, NY; Yu, JY				Xu, Yanyu; Gao, Shenghua; Wu, Junru; Li, Nianyi; Yu, Jingyi			Personalized Saliency and Its Prediction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Observers; Saliency detection; Feature extraction; Visualization; Semantics; Predictive models; Image color analysis; Universal saliency; personalized saliency; multi-task learning; convolutional neural network	MODEL	Nearly all existing visual saliency models by far have focused on predicting a universal saliency map across all observers. Yet psychology studies suggest that visual attention of different observers can vary significantly under specific circumstances, especially a scene is composed of multiple salient objects. To study such heterogenous visual attention pattern across observers, we first construct a personalized saliency dataset and explore correlations between visual attention, personal preferences, and image contents. Specifically, we propose to decompose a personalized saliency map (referred to as PSM) into a universal saliency map (referred to as USM) predictable by existing saliency detection models and a new discrepancy map across users that characterizes personalized saliency. We then present two solutions towards predicting such discrepancy maps, i.e., a multi-task convolutional neural network (CNN) framework and an extended CNN with Person-specific Information Encoded Filters (CNN-PIEF). Extensive experimental results demonstrate the effectiveness of our models for PSM prediction as well their generalization capability for unseen observers.	[Xu, Yanyu; Gao, Shenghua; Yu, Jingyi] ShanghaiTech Univ, Shanghai 201210, Peoples R China; [Xu, Yanyu] Univ Chinese Acad Sci, Beijing 100049, Peoples R China; [Wu, Junru] Texas A&M Univ, College Stn, TX 77843 USA; [Li, Nianyi] Univ Delaware, Newark, DE 19716 USA	ShanghaiTech University; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Texas A&M University System; Texas A&M University College Station; University of Delaware	Gao, SH (corresponding author), ShanghaiTech Univ, Shanghai 201210, Peoples R China.	xuyy2@shanghaitech.edu.cn; gaoshh@shanghaitech.edu.cn; wujr1@shanghaitech.edu.cn; nianyi@udel.edu; yu@eecis.udel.edu		Xu, Yanyu/0000-0001-8926-7833; Li, Nianyi/0000-0002-4172-4940	NSFC [61502304]; US National Science Foundation [HCC-1319598, IIS-1422477]	NSFC(National Natural Science Foundation of China (NSFC)); US National Science Foundation(National Science Foundation (NSF))	This project is supported by the NSFC (No. 61502304). Nianyi Li was partially supported by US National Science Foundation grants HCC-1319598 and IIS-1422477. Yanyu Xu, Shenghua Gao, and Junru Wu are equal contributors.	Absher J.R., 2016, NEUROIMAGING PERSONA; Alwall N, 2010, PERS INDIV DIFFER, V49, P729, DOI 10.1016/j.paid.2010.06.016; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2011, 1027 MRC INT; [Anonymous], 2012, TECH REP; Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833; Borji A, 2012, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2012.6247706; Brabandere B.D., 2016, ADV NEURAL INFORM PR, P667; Bylinskii Z, 2015, MIT SALIENCY BENCHMA; Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512; Chang MML, 2016, LECT NOTES COMPUT SC, V9768, P453, DOI 10.1007/978-3-319-40621-3_33; Cornia M, 2016, INT C PATT RECOG, P3488, DOI 10.1109/ICPR.2016.7900174; Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11; Fang S, 2017, IEEE T NEUR NET LEAR, V28, P1095, DOI 10.1109/TNNLS.2016.2522440; Gygli M, 2013, IEEE I CONF COMP VIS, P1633, DOI 10.1109/ICCV.2013.205; Hewig J, 2008, J NONVERBAL BEHAV, V32, P67, DOI 10.1007/s10919-007-0043-5; Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38; Imafuku M, 2017, INFANCY, V22, P223, DOI 10.1111/infa.12144; Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jiang M, 2017, IEEE I CONF COMP VIS, P3287, DOI 10.1109/ICCV.2017.354; Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Kmmerer M., 2014, ARXIV14111045; Krishna O, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193149; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620; Kruthiventi SSS, 2016, PROC CVPR IEEE, P5781, DOI 10.1109/CVPR.2016.623; Kummerer M, 2017, IEEE I CONF COMP VIS, P4799, DOI 10.1109/ICCV.2017.513; Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562; Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306; Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43; Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Noh H., 2015, P CVPR, P30; Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71; Riche N, 2013, SIGNAL PROCESS-IMAGE, V28, P642, DOI 10.1016/j.image.2013.03.009; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Setlur Vidya, 2005, P 4 INT C MOB UB MUL, P59, DOI DOI 10.1145/1149488.1149499; Symmonds M, 2012, NEUROSCIENCE OF PREFERENCE AND CHOICE: COGNITIVE AND NEURAL MECHANISMS, P3, DOI 10.1016/B978-0-12-381431-9.00001-2; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358; Wilson R., 1979, ADV CONSUM RES, V06, P55; Xu J, 2014, J VISION, V14, DOI 10.1167/14.1.28; Xu P., 2015, COMPUT SCI; Xu Pingmei, 2015, ARXIV150406755; Xu YY, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3887; Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26; Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7	53	16	16	2	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2019	41	12					2975	2989		10.1109/TPAMI.2018.2866563	http://dx.doi.org/10.1109/TPAMI.2018.2866563			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JQ0XI	30136932	Green Submitted			2022-12-18	WOS:000498677600014
J	Rao, YM; Lu, JW; Lin, J; Zhou, J				Rao, Yongming; Lu, Jiwen; Lin, Ji; Zhou, Jie			Runtime Network Routing for Efficient Image Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deep network compression; image classification; efficient inference model; reinforcement learning; deep learning		In this paper, we propose a generic Runtime Network Routing (RNR) framework for efficient image classification, which selects an optimal path inside the network. Unlike existing static neural network acceleration methods, our method preserves the full ability of the original large network and conducts dynamic routing at runtime according to the input image and current feature maps. The routing is performed in a bottom-up, layer-by-layer manner, where we model it as a Markov decision process and use reinforcement learning for training. The agent determines the estimated reward of each sub-path and conducts routing conditioned on different samples, where a faster path is taken when the image is easier for the task. Since the ability of network is fully preserved, the balance point is easily adjustable according to the available resources. We test our method on both multi-path residual networks and incremental convolutional channel pruning, and show that RNR consistently outperforms static methods at the same computation complexity on both the CIFAR and ImageNet datasets. Our method can also be applied to off-the-shelf neural network structures and easily extended to other application scenarios.	[Rao, Yongming; Lu, Jiwen; Lin, Ji; Zhou, Jie] Tsinghua Univ, Dept Automat, Beijing Natl Res Ctr Informat Sci & Tech Nol BNRi, State Key Bib Intelligent Technol & Syst, Beijing 100084, Peoples R China	Tsinghua University	Lu, JW (corresponding author), Tsinghua Univ, Dept Automat, Beijing Natl Res Ctr Informat Sci & Tech Nol BNRi, State Key Bib Intelligent Technol & Syst, Beijing 100084, Peoples R China.	rym18@mails.tsinghua.edu.cn; lujiwen@tsinghua.edu.cn; lin-j14@mails.tsinghua.edu.cn; jzhou@tsinghua.edu.cn	; Lu, Jiwen/C-5291-2009	Lin, Ji/0000-0001-6053-4344; Rao, Yongming/0000-0003-3952-8753; Lu, Jiwen/0000-0002-6121-5529	National Key Research and Development Program of China [2017YFA0700802]; National Natural Science Foundation of China [61822603, U1713214, 61672306, 61572271, 61527808]; Shenzhen fundamental research fund (subject arrangement) [JCYJ20170412170602564]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Shenzhen fundamental research fund (subject arrangement)	This work is supported in part by the National Key Research and Development Program of China under Grant 2017YFA0700802, and the National Natural Science Foundation of China under Grant 61822603, Grant U1713214, Grant 61672306, Grant 61572271, and 61527808, and Shenzhen fundamental research fund (subject arrangement) under Grant JCYJ20170412170602564. Partial of this work was presented in [39].	Almahairi A, 2016, PR MACH LEARN RES, V48; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 1989, ADV NEURAL INFORM PR; Anwar S, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005348; BELLMAN R, 1956, P NATL ACAD SCI USA, V42, P767, DOI 10.1073/pnas.42.10.767; Benbouzid D., 2012, P 29 INT C MACH LEAR, P747; Bengio E.l, 2016, P INT C LEARN REPR W; Bengio Yoshua, 2013, ARXIV13083432; Bolukbasi T., 2017, P 34 INT C MACH LEAR, P527; Caicedo JC, 2015, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2015.286; Changpinyo S, 2017, ARXIV170206257; Chetlur S., 2014, ARXIV; Cun YL., 1990, ADV NEURAL INF PROCE, P598, DOI DOI 10.5555/109230.109298; Denoyer L., 2014, P C NEUR INF PROC SY; Figurnov M, 2017, PROC CVPR IEEE, P1790, DOI 10.1109/CVPR.2017.194; Gastaldi Xavier, 2017, ARXIV170507485; Han S., 2016, P 4 INT C LEARN REPR, P1; Han Song, 2015, ADV NEURAL INFORM PR, P1135, DOI DOI 10.5555/2969239.2969366; He, 2012, ADV NEURAL INFORM PR, P3149; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Howard A.G., 2017, MOBILENETS EFFICIENT; Hu H., 2016, ARXIV PREPRINT ARXIV; Huang GS, 2007, 2007 7TH IEEE CONFERENCE ON NANOTECHNOLOGY, VOL 1-3, P7, DOI 10.1109/NANO.2007.4601129; Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39; Huang J, 2017, IEEE INT C INT ROBOT, P3296; Iandola F.N., 2016, ARXIV; Jaderberg Max, 2014, P BRIT MACH VIS C, P2, DOI DOI 10.5244/C.28.88; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Karayev S., 2012, ADV NEURAL INFORM PR, V25, P890; Kingma D.P, P 3 INT C LEARNING R; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar Neeraj, 2011, IEEE Trans Pattern Anal Mach Intell, V33, P1962, DOI 10.1109/TPAMI.2011.48; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Leroux S, 2017, KNOWL INF SYST, V52, P791, DOI 10.1007/s10115-017-1029-1; Li H., 2017, P INT C LEARN REPR I, P1; Li Yi, 2017, P IEEE C COMP VIS PA; Littman ML, 2015, NATURE, V521, P445, DOI 10.1038/nature14540; Liu LY, 2018, AAAI CONF ARTIF INTE, P5253; Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298; Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236; Molchanov P., 2017, P INT C LEARN REPR I, P1; Murray Kenton, 2015, P 2015 C EMP METH NA, P908; Odena A., 2017, P INT C LEARN REPR W; Paszke Adam, 2017, PYTORCH TENSORS DYNA, P6; Puterman Martin L., 1994, MARKOV DECISION PROC, V1st, DOI DOI 10.1002/9780470316887; Rao JF, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1217, DOI 10.1145/3077136.3080648; Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Stollenga M.F., 2014, ADV NEURAL INFORM PR, P3545; Stork D.G., 1993, ADV NEURAL INF PROCE, P164; Strom N., 1997, FREE SPEECH J, V5, P2; Sun C, 2016, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2016.379; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Sutton RS, 2000, ADV NEUR IN, V12, P1057; Szegedy C., 2017, AAAI, V4, P12, DOI DOI 10.1016/J.PATREC.2014.01.008; Szegedy C., 2016, P IEEE C COMP VIS PA, P2818, DOI DOI 10.1109/CVPR.2016.308; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26; Wang M, 2017, IEEE INT CONF COMP V, P545, DOI 10.1109/ICCVW.2017.71; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698; Wen W, 2016, ADV NEUR IN, V29; Zhang F., 2015, P AS C REFR AIR COND; Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579	69	16	19	2	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2019	41	10					2291	2304		10.1109/TPAMI.2018.2878258	http://dx.doi.org/10.1109/TPAMI.2018.2878258			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD1VC	30371355				2022-12-18	WOS:000489763000002
J	Blouvshtein, L; Cohen-Or, D				Blouvshtein, Leonid; Cohen-Or, Daniel			Outlier Detection for Robust Multi-Dimensional Scaling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multidimensional scaling; outliers; robust; embedding; data exploration; data visualization	VISUALIZATION	Multi-dimensional scaling (MDS) plays a central role in data-exploration, dimensionality reduction and visualization. State-of-the-art MDS algorithms are not robust to outliers, yielding significant errors in the embedding even when only a handful of outliers are present. In this paper, we introduce a technique to detect and filter outliers based on geometric reasoning. We test the validity of triangles formed by three points, and mark a triangle as broken if its triangle inequality does not hold. The premise of our work is that unlike inliers, outlier distances tend to break many triangles. Our method is tested and its performance is evaluated on various datasets and distributions of outliers. We demonstrate that for a reasonable amount of outliers, e.g., under 20 percent, our method is effective, and leads to a high embedding quality.	[Blouvshtein, Leonid; Cohen-Or, Daniel] Tel Aviv Univ, Blavatnik Sch Comp Sci, IL-69978 Tel Aviv, Israel	Tel Aviv University	Blouvshtein, L (corresponding author), Tel Aviv Univ, Blavatnik Sch Comp Sci, IL-69978 Tel Aviv, Israel.	leonidbl91@gmail.com; dcor@tau.ac.il		Blouvshtein, Leonid/0000-0001-6370-0758				BORG I., 2005, MODERN MULTIDIMENSIO, P207; Bronstein AM, 2006, P NATL ACAD SCI USA, V103, P1168, DOI 10.1073/pnas.0508601103; Buja A, 2002, J CLASSIF, V19, P7, DOI 10.1007/s00357-001-0031-0; Buja A, 2008, J COMPUT GRAPH STAT, V17, P444, DOI 10.1198/106186008X318440; Burkardt J., 2011, CITIES CITY DISTANCE; Cayton L., 2006, P 23 INT C MACH LEAR, P169; Chan FKW, 2009, IEEE T SIGNAL PROCES, V57, P4548, DOI 10.1109/TSP.2009.2024869; Chen ZQ, 2010, J COMPUT INF SCI ENG, V10, DOI 10.1115/1.3290769; de Silva V., 2004, TECH REP; DELEEUW J, 1988, J CLASSIF, V5, P163, DOI 10.1007/BF01897162; DELEEUW J, 2009, J STAT SOFTW, V31, P1; Denoeux T, 2004, IEEE T SYST MAN CY B, V34, P95, DOI 10.1109/TSMCB.2002.806496; Forero PA, 2012, IEEE T SIGNAL PROCES, V60, P4118, DOI 10.1109/TSP.2012.2197617; Graepel T, 1999, ADV NEUR IN, V11, P438; Jaworska N, 2009, TUTOR QUANT METHODS, V5, P1, DOI 10.20982/tqmp.05.1.p001; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565; Li YY, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818071; Mandanas F, 2018, PATTERN RECOGN, V73, P235, DOI 10.1016/j.patcog.2017.08.023; Mandanas FD, 2017, IEEE T SIGNAL PROCES, V65, P919, DOI 10.1109/TSP.2016.2625265; NEIDELL LA, 1969, J MARKETING, V33, P37, DOI 10.2307/1248671; Pickup D., 2014, EUROGRAPHICS WORKSHO, P101; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; SHEPARD RN, 1980, SCIENCE, V210, P390, DOI 10.1126/science.210.4468.390; SHEPARD RN, 1962, PSYCHOMETRIKA, V27, P125, DOI 10.1007/BF02289630; SPENCE I, 1989, PSYCHOMETRIKA, V54, P501, DOI 10.1007/BF02294632; Zhang LW, 2016, J R STAT SOC B, V78, P849, DOI 10.1111/rssb.12138; Zhang YY, 2007, J ENG DESIGN, V18, P227, DOI 10.1080/09544820600752781; Zigelman G, 2002, IEEE T VIS COMPUT GR, V8, P198, DOI 10.1109/2945.998671	28	16	17	1	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2019	41	9					2273	2279		10.1109/TPAMI.2018.2851513	http://dx.doi.org/10.1109/TPAMI.2018.2851513			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	IP9BY	29994700	Green Submitted			2022-12-18	WOS:000480343900017
J	Hou, CP; Zeng, LL; Hu, DW				Hou, Chenping; Zeng, Ling-Li; Hu, Dewen			Safe Classification with Augmented Features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Augmented features; safe; classification; multi-view learning	FUNCTIONAL CONNECTIVITY; PREDICTION; PATTERN	With the evolution of data collection methods, it is possible to produce abundant data described by multiple feature sets. Previous studies show that including more features does not necessarily bring positive effects. How to prevent the augmented features from worsening classification performance is crucial but rarely studied. In this paper, we study this challenging problem by proposing a safe classification approach, whose accuracy is never degenerated when exploiting augmented features. We propose two ways to achieve the safeness of our method named as SAfe Classification (SAC). First, to leverage augmented features, we learn various types of classifiers and adapt them by employing a specially designed robust loss. It provides various candidate classifiers to meet the assumption of safeness operation. Second, we search for a safe prediction by integrating all candidate classifiers. Under a mild assumption, the integrated classifier has theoretical safeness guarantee. Several new optimization methods have been developed to accommodate the problems with proved convergence. Besides evaluating SAC on 16 data sets, we also apply SAC in the application of diagnostic classification of schizophrenia since it has vast application potentiality. Experimental results demonstrate the effectiveness of SAC in both tackling safeness problem and discriminating schizophrenic patients from healthy controls.	[Hou, Chenping] Natl Univ Def Technol, Coll Sci, Changsha 410073, Hunan, Peoples R China; [Zeng, Ling-Li; Hu, Dewen] Natl Univ Def Technol, Coll Mechatron & Automat, Changsha 410073, Hunan, Peoples R China	National University of Defense Technology - China; National University of Defense Technology - China	Hu, DW (corresponding author), Natl Univ Def Technol, Coll Mechatron & Automat, Changsha 410073, Hunan, Peoples R China.	houchenping@nudt.edu.cn; fzengphd@nudt.edu.cn; dwhu@nudt.edu.cn	Hu, Dewen/AAN-8511-2020; Hu, Dewen/D-1978-2015	Zeng, Ling-Li/0000-0002-0515-256X	National Science Foundation China [91420302, 61473302, 61722313, 61420106001]; Fok Ying Tung Education Foundation [161057]	National Science Foundation China(National Natural Science Foundation of China (NSFC)); Fok Ying Tung Education Foundation(Fok Ying Tung Education Foundation)	The authors thank Hong Tao and Wenzhang Zhuge for discussions. Thanks Lin Yuan for his help in processing the fMRI data. This work was supported by National Science Foundation China (No. 91420302, 61473302, 61722313 and 61420106001) and Fok Ying Tung Education Foundation (161057).	APA APA, 2013, DIAGN STAT MAN MENT; Arbabshirani MR, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00133; Bach F. R., 2004, ADV NEURAL INFORM PR, V17, P73; Bishop C.M, 2006, PATTERN RECOGN; Boyd S, 2004, CONVEX OPTIMIZATION; Chen N, 2012, IEEE T PATTERN ANAL, V34, P2365, DOI 10.1109/TPAMI.2012.64; CVX Research, 2012, CVX MATLAB SOFTWARE; Diethe T, 2008, MULTIVIEW FISHER DIS; Dietterich T. G., 2016, AI MAG, V38; Dosenbach NUF, 2010, SCIENCE, V329, P1358, DOI 10.1126/science.1194144; Du W, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00145; Dueck D, 2007, IEEE I CONF COMP VIS, P198; Farquhar JDR, 2005, ADV NEURAL INFORM PR, P355, DOI 10.5555/2976248.2976293; Gonen M, 2011, J MACH LEARN RES, V12, P2211; Grant MC, 2008, LECT NOTES CONTR INF, V371, P95, DOI 10.1007/978-1-84800-155-8_7; Guo Y., 2012, P 29 INT C MACH LEAR, P915; Hou Bo-Jian, 2017, NIPS, P1416; Hou CP, 2017, IEEE T KNOWL DATA EN, V29, P1998, DOI 10.1109/TKDE.2017.2681670; Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740; Lanckriet G. R. G., 2002, 19 INT C MACH LEARN, P323, DOI [10.1023/B:JODS.0000012018.62090.a7, DOI 10.1023/B:JODS.0000012018.62090.A7]; Lee YJ, 2009, INT J COMPUT VISION, V85, P143, DOI 10.1007/s11263-009-0252-y; Li YF, 2016, AAAI CONF ARTIF INTE, P1816; Li YF, 2017, AAAI CONF ARTIF INTE, P2217; Li ZY, 2011, CHINESE PHYS LETT, V28, DOI 10.1088/0256-307X/28/9/098101; Nie FP, 2017, AAAI CONF ARTIF INTE, P2415; Poldrack RA, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.110; Shen H, 2010, NEUROIMAGE, V49, P3110, DOI 10.1016/j.neuroimage.2009.11.011; Silva R, 2014, J COASTAL RES, P1, DOI 10.2112/SI71-001.1; Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978; Wang HN, 2015, SCI REP-UK, V5, DOI 10.1038/srep14655; Wang W, 2007, LECT NOTES ARTIF INT, V4701, P454; Watanabe T, 2014, NEUROIMAGE, V96, P183, DOI 10.1016/j.neuroimage.2014.03.067; Wilcoxon F., 1992, INDIVIDUAL COMP RANK; Xiang SM, 2012, IEEE T NEUR NET LEAR, V23, P1738, DOI 10.1109/TNNLS.2012.2212721; Xie XJ, 2014, APPL INTELL, V41, P1059, DOI 10.1007/s10489-014-0563-8; Xu C., 2016, CORR; Xu C., 2013, CORR; Ye H.-J., 2015, P 24 ACM INT C INF K, P991; Yuan L, 2018, IEEE ACM T COMPUT BI, V15, P551, DOI 10.1109/TCBB.2015.2448081; Zeng LL, 2012, BRAIN, V135, P1498, DOI 10.1093/brain/aws059; Zhao J., 2003, INFORM FUSION, V38, P43; Zheng S, 2015, AAAI CONF ARTIF INTE, P1973; Zien A., 2007, P 24 INT C MACH LEAR, P1191, DOI DOI 10.1145/1273496.1273646	45	16	17	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2019	41	9					2176	2192		10.1109/TPAMI.2018.2849378	http://dx.doi.org/10.1109/TPAMI.2018.2849378			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IP9BY	29994111				2022-12-18	WOS:000480343900010
J	Li, C; Zia, MZ; Tran, QH; Yu, X; Hager, GD; Chandraker, M				Li, Chi; Zia, M. Zeeshan; Quoc-Huy Tran; Yu, Xiang; Hager, Gregory D.; Chandraker, Manmohan			Deep Supervision with Intermediate Concepts	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Deep learning; multi-task learning; single image 3D structure prediction; object pose estimation	PERCEPTUAL ORGANIZATION	Recent data-driven approaches to scene interpretation predominantly pose inference as an end-to-end black-box mapping, commonly performed by a Convolutional Neural Network (CNN). However, decades of work on perceptual organization in both human and machine vision suggest that there are often intermediate representations that are intrinsic to an inference task, and which provide essential structure to improve generalization. In this work, we explore an approach for injecting prior domain structure into neural network training by supervising hidden layers of a CNN with intermediate concepts that normally are not observed in practice. We formulate a probabilistic framework which formalizes these notions and predicts improved generalization via this deep supervision method. One advantage of this approach is that we are able to train only from synthetic CAD renderings of cluttered scenes, where concept values can be extracted, but apply the results to real images. Our implementation achieves the state-of-the-art performance of 2D/3D keypoint localization and image classification on real image benchmarks including KITTI, PASCALVOC, PASCAL3D+, IKEA, and CIFAR100. We provide additional evidence that our approach outperforms alternative forms of supervision, such as multi-task networks.	[Li, Chi] Johns Hopkins Univ, Comp Sci, Baltimore, MD 21218 USA; [Zia, M. Zeeshan] Microsoft, Hololens, Redmond, WA USA; [Quoc-Huy Tran; Yu, Xiang; Chandraker, Manmohan] NEC Labs America Inc, Media Analyt, Cupertino, CA 95014 USA; [Hager, Gregory D.] Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA	Johns Hopkins University; Microsoft; Johns Hopkins University	Li, C (corresponding author), Johns Hopkins Univ, Comp Sci, Baltimore, MD 21218 USA.	chi_li@jhu.edu; zeeshan.zia@microsoft.com; qhtran@nec-labs.com; xiangyu@nec-labs.com; hager@cs.jhu.edu; manu@nec-labs.com	Chandraker, Manmohan/AAU-4762-2021	Zia, Zeeshan/0000-0001-8221-2637; Tran, Quoc-Huy/0000-0003-1396-6544	NSF [IIS-127228, IIS-1637949]	NSF(National Science Foundation (NSF))	This work was part of C. Li's intern project at NEC Labs America, in Cupertino. We acknowledge the support by NSF under grants IIS-127228 and IIS-1637949. We also thank Rene Vidal, Alan Yuille, Austin Reiter and Chong You for helpful discussions.	ABUMOSTAFA YS, 1995, NEURAL COMPUT, V7, P639, DOI 10.1162/neco.1995.7.4.639; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 1985, PERCEPTUAL ORG VISUA; [Anonymous], 2014, 2014 IEEE C COMP VIS, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]; Aubry M, 2014, PROC CVPR IEEE, P3762, DOI 10.1109/CVPR.2014.487; Bansal A, 2016, PROC CVPR IEEE, P5965, DOI 10.1109/CVPR.2016.642; Baxter J, 2000, J ARTIF INTELL RES, V12, P149, DOI 10.1613/jair.731; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chang A. X., 2015, ARXIV PREPRINT ARXIV; Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng J, 2014, LECT NOTES COMPUT SC, V8689, P48, DOI 10.1007/978-3-319-10590-1_4; Dosovitskiy A, 2015, PROC CVPR IEEE, P1538, DOI 10.1109/CVPR.2015.7298761; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Glorot X., 2010, P 13 INT C ART INT S, P249, DOI DOI 10.1.1/207.2059; Gulcehre C, 2016, J MACH LEARN RES, V17; Gupta Saurabh, 2015, ARXIV150204652; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; IOFFE S, 2015, J MACH LEARN RES, V37, P448; Jimenez Rezende D., 2016, ADV NEURAL INFORM PR, P4996; Kanazawa A, 2016, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2016.354; Kar A, 2015, PROC CVPR IEEE, P1966, DOI 10.1109/CVPR.2015.7298807; Krizhevsky A., 2009, TR2009 U TOR DEP COM, P32; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kulkarni TD, 2015, ADV NEUR IN, V28; Lebesgue Henri, 1902, ANNALI MATEMATICA PU, V7, P231; LEE CY, 2015, J MACHINE LEARNING R, V38, P562; LEE HJ, 1985, COMPUT VISION GRAPH, V30, P148, DOI 10.1016/0734-189X(85)90094-5; Li C, 2017, PROC CVPR IEEE, P388, DOI 10.1109/CVPR.2017.49; Li Y, 2011, IEEE T PATTERN ANAL, V33, P1860, DOI 10.1109/TPAMI.2011.40; Lim JJ, 2014, LECT NOTES COMPUT SC, V8694, P478, DOI 10.1007/978-3-319-10599-4_31; Lim JJ, 2013, IEEE I CONF COMP VIS, P2992, DOI 10.1109/ICCV.2013.372; Long J.L., 2014, P C NEUR INF PROC SY, V27, P1601; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; Maurer A, 2016, J MACH LEARN RES, V17; Mishkin D, 2016, 2016 INT C LEARN REP; MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P1121, DOI 10.1109/34.42852; Moreno P, 2016, LECT NOTES COMPUT SC, V9915, P170, DOI 10.1007/978-3-319-49409-8_16; Mottaghi R, 2015, PROC CVPR IEEE, P418, DOI 10.1109/CVPR.2015.7298639; Pepik B, 2013, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2013.422; Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7; Sarkar S, 2000, IEEE T PATTERN ANAL, V22, P504, DOI 10.1109/34.857006; SMITH BJ, 1985, COMPUT VISION GRAPH, V31, P242, DOI 10.1016/S0734-189X(85)80007-4; Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308; Tatarchenko M, 2016, LECT NOTES COMPUT SC, V9911, P322, DOI 10.1007/978-3-319-46478-7_20; Tulsiani S., 2016, P IEEE C COMP VIS PA, P1510; Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207; Wu JJ, 2016, LECT NOTES COMPUT SC, V9910, P365, DOI 10.1007/978-3-319-46466-4_22; Wu TF, 2016, IEEE T PATTERN ANAL, V38, P1829, DOI 10.1109/TPAMI.2015.2497699; Xiang Y, 2015, PROC CVPR IEEE, P1903, DOI 10.1109/CVPR.2015.7298800; Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101; Xiang Y, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P530, DOI 10.1109/ICCVW.2013.75; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Yu X, 2016, LECT NOTES COMPUT SC, V9909, P52, DOI 10.1007/978-3-319-46454-1_4; Zhang C., 2017, P INT C LEARN REPR I; Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7; Zhou TH, 2016, PROC CVPR IEEE, P117, DOI 10.1109/CVPR.2016.20; Zia MZ, 2015, INT J COMPUT VISION, V112, P188, DOI 10.1007/s11263-014-0780-y	60	16	16	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2019	41	8					1828	1843		10.1109/TPAMI.2018.2863285	http://dx.doi.org/10.1109/TPAMI.2018.2863285			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IG2BD	30106706	Green Submitted, Bronze			2022-12-18	WOS:000473598800004
J	Mheich, A; Hassan, M; Khalil, M; Gripon, V; Dufor, O; Wendling, F				Mheich, Ahmad; Hassan, Mahmoud; Khalil, Mohamad; Gripon, Vincent; Dufor, Olivier; Wendling, Fabrice			SimiNet: A Novel Method for Quantifying Brain Network Similarity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Graph similarity; brain networks; spatial information	GRAPH-THEORETICAL ANALYSIS; FUNCTIONAL CONNECTIVITY; COMPLEX NETWORKS; VARIABILITY; ALGORITHM; DISTANCE; DISEASE; KERNELS; AGE	Quantifying the similarity between two networks is critical in many applications. A number of algorithms have been proposed to compute graph similarity, mainly based on the properties of nodes and edges. Interestingly, most of these algorithms ignore the physical location of the nodes, which is a key factor in the context of brain networks involving spatially defined functional areas. In this paper, we present a novel algorithm called "SimiNet" for measuring similarity between two graphs whose nodes are defined a priori within a 3D coordinate system. SimiNet provides a quantified index (ranging from 0 to 1) that accounts for node, edge and spatiality features. Complex graphs were simulated to evaluate the performance of SimiNet that is compared with eight state-of-art methods. Results show that SimiNet is able to detect weak spatial variations in compared graphs in addition to computing similarity using both nodes and edges. SimiNet was also applied to real brain networks obtained during a visual recognition task. The algorithm shows high performance to detect spatial variation of brain networks obtained during a naming task of two categories of visual stimuli: animals and tools. A perspective to this work is a better understanding of object categorization in the human brain.	[Mheich, Ahmad; Hassan, Mahmoud; Wendling, Fabrice] Univ Rennes 1, LTSI, INSERM, U1099, F-35000 Rennes, France; [Mheich, Ahmad; Khalil, Mohamad] Lebanese Univ, AZM Ctr EDST, Tripoli, Lebanon; [Gripon, Vincent; Dufor, Olivier] IMT Atlantique Bretagne Pays Loire, UMR, CNRS, Lab STICC, F-29238 Brest, France	Institut National de la Sante et de la Recherche Medicale (Inserm); Universite de Rennes; Lebanese University; Centre National de la Recherche Scientifique (CNRS); IMT - Institut Mines-Telecom; IMT Atlantique; Universite de Bretagne Occidentale	Hassan, M (corresponding author), Univ Rennes 1, LTSI, INSERM, U1099, F-35000 Rennes, France.	mheich.ahmad@gmail.com; mahmoud.hassan@univ-rennes1.fr; mohamad.khalil@ul.edu.lb; vincent@gripon.fr; dufor@telecom-bretagne.eu; fabrice.wendling@univ-rennes1.fr	Gripon, Vincent/X-6371-2019; DUFOR, Olivier/ABB-7740-2021; WENDLING, Fabrice/P-9574-2019; Wendling, Fabrice/F-8924-2013; Hassan, Mahmoud/AAF-4519-2019	Gripon, Vincent/0000-0002-4353-4542; WENDLING, Fabrice/0000-0003-2428-9665; Hassan, Mahmoud/0000-0003-0307-5086; Kahlil, Mohamad/0000-0002-9814-1949	French government; National Research Agency in the "Investing for the Future" program [ANR-10-LABX-07-01]; Rennes University Hospital (COREC Project named conneXion); European Research Council under the European Union [290901]	French government; National Research Agency in the "Investing for the Future" program; Rennes University Hospital (COREC Project named conneXion); European Research Council under the European Union(European Research Council (ERC))	This work has received a French government support granted to the CominLabs excellence laboratory and managed by the National Research Agency in the "Investing for the Future" program under reference ANR-10-LABX-07-01. It was also financed by the Rennes University Hospital (COREC Project named conneXion, 2012-14). This work was also supported by the European Research Council under the European Union's Seventh Framework Programme (FP7/2007-2013) / ERC grant agreement no 290901.	Achard S, 2006, J NEUROSCI, V26, P63, DOI 10.1523/JNEUROSCI.3874-05.2006; Alario FX, 1999, BEHAV RES METH INS C, V31, P531, DOI 10.3758/BF03200732; Armiti A., 2014, P 16 LWA WORKSH KDML, P111; Bassett DS, 2011, P NATL ACAD SCI USA, V108, P7641, DOI 10.1073/pnas.1018985108; Bassett DS, 2006, NEUROSCIENTIST, V12, P512, DOI 10.1177/1073858406293182; Borgwardt KM, 2005, Fifth IEEE International Conference on Data Mining, Proceedings, P74, DOI 10.1109/ICDM.2005.132; Bressler SL, 2010, TRENDS COGN SCI, V14, P277, DOI 10.1016/j.tics.2010.04.004; Bullmore ET, 2009, NAT REV NEUROSCI, V10, P186, DOI 10.1038/nrn2575; Bunke H., 2007, GRAPH THEORETIC APPR, V24.; Cao B, 2013, APPL MATH INFORM SCI, V7, P169, DOI 10.12785/amis/071L24; Cordella LP, 2004, IEEE T PATTERN ANAL, V26, P1367, DOI 10.1109/TPAMI.2004.75; Costa LD, 2007, ADV PHYS, V56, P167, DOI 10.1080/00018730601170527; Destrieux CE., 1998, SOC NEUR ABSTR, V24, P1164; FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168; Fornito A, 2015, NAT REV NEUROSCI, V16, P159, DOI 10.1038/nrn3901; Gao XB, 2010, PATTERN ANAL APPL, V13, P113, DOI 10.1007/s10044-008-0141-y; Gong GL, 2009, J NEUROSCI, V29, P15684, DOI 10.1523/JNEUROSCI.2308-09.2009; Guye M, 2010, MAGN RESON MATER PHY, V23, P409, DOI 10.1007/s10334-010-0205-z; Hagmann P, 2008, PLOS BIOL, V6, P1479, DOI 10.1371/journal.pbio.0060159; Hassan M, 2017, NEUROIMAGE-CLIN, V14, P591, DOI 10.1016/j.nicl.2017.03.002; Hassan M., 2016, BRAIN TOPOGR, P1, DOI [DOI 10.1007/S10548-016-0517-Z, 10.1007/s10548-016-0517-z]; Hassan M, 2015, CORTEX, V73, P276, DOI 10.1016/j.cortex.2015.08.019; Hassan M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138297; Hassan M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0105041; Huth AG, 2012, NEURON, V76, P1210, DOI 10.1016/j.neuron.2012.10.014; Kabbara A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-03420-6; Kay KN, 2008, NATURE, V452, P352, DOI 10.1038/nature06713; Koutra D., 2013, P 2013 SIAM INT C DA, P162, DOI DOI 10.1137/1.9781611972832.18; Liu Y, 2008, BRAIN, V131, P945, DOI 10.1093/brain/awn018; Martin A, 2001, CURR OPIN NEUROBIOL, V11, P194, DOI 10.1016/S0959-4388(00)00196-3; Meunier D, 2010, FRONT NEUROSCI-SWITZ, V4, DOI 10.3389/fnins.2010.00200; Mheich A, 2015, J NEUROSCI METH, V242, P77, DOI 10.1016/j.jneumeth.2015.01.002; Mueller S, 2013, NEURON, V77, P586, DOI 10.1016/j.neuron.2012.12.028; Papadimitriou P, 2010, J INTERNET SERV APPL, V1, P19, DOI 10.1007/s13174-010-0003-x; Pineda-Pardo A., 2014, BRAIN TOPOGRAPHY, V28, P1; Schieber TA, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms13928; Sethian J.A., 1999, LEVEL SET METHODS FA, V3; Shervashidze N, 2011, J MACH LEARN RES, V12, P2539; Shimada Y, 2016, SCI REP-UK, V6, DOI 10.1038/srep34944; Stam CJ, 2007, CEREB CORTEX, V17, P92, DOI 10.1093/cercor/bhj127; Stam CJ, 2009, BRAIN, V132, P213, DOI 10.1093/brain/awn262; Stam Cornelis J, 2007, Nonlinear Biomed Phys, V1, P3, DOI 10.1186/1753-4631-1-3; Supekar K, 2009, PLOS BIOL, V7, DOI 10.1371/journal.pbio.1000157; Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0; van den Heuvel MP, 2011, J NEUROSCI, V31, P15775, DOI 10.1523/JNEUROSCI.3539-11.2011; van Wijk BCM, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0013701; VanRullen R, 2001, J COGNITIVE NEUROSCI, V13, P454, DOI 10.1162/08989290152001880; Vihla M, 2006, NEUROIMAGE, V33, P732, DOI 10.1016/j.neuroimage.2006.06.040; Vishwanathan SVN, 2010, J MACH LEARN RES, V11, P1201; Wilson RC, 2008, PATTERN RECOGN, V41, P2833, DOI 10.1016/j.patcog.2008.03.011; Zalesky A, 2010, NEUROIMAGE, V53, P1197, DOI 10.1016/j.neuroimage.2010.06.041	51	16	16	8	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2018	40	9					2238	2249		10.1109/TPAMI.2017.2750160	http://dx.doi.org/10.1109/TPAMI.2017.2750160			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GP4UX	28910755	Green Submitted			2022-12-18	WOS:000440868400015
J	Storath, M; Weinmann, A				Storath, Martin; Weinmann, Andreas			Fast Median Filtering for Phase or Orientation Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Median filter; circle-median; phase data; orientation data; circle-valued data; manifold-valued data	TOTAL VARIATION REGULARIZATION; DIRECTIONAL-DATA; CONSTANT-TIME; SIGNALS; CIRCLE	Median filtering is among the most utilized tools for smoothing real-valued data, as it is robust, edge-preserving, value-preserving, and yet can be computed efficiently. For data living on the unit circle, such as phase data or orientation data, a filter with similar properties is desirable. For these data, there is no unique means to define a median; so we discuss various possibilities. The arc distance median turns out to be the only variant which leads to robust, edge-preserving and value-preserving smoothing. However, there are no efficient algorithms for filtering based on the arc distance median. Here, we propose fast algorithms for filtering of signals and images with values on the unit circle based on the arc distance median. For non-quantized data, we develop an algorithm that scales linearly with the filter size. The runtime of our reference implementation is only moderately higher than the Matlab implementation of the classical median filter for real-valued data. For quantized data, we obtain an algorithm of constant complexity w.r.t. the filter size. We demonstrate the performance of our algorithms for real life data sets: phase images from interferometric synthetic aperture radar, planar flow fields from optical flow, and time series of wind directions.	[Storath, Martin] Heidelberg Univ, Heidelberg Collab Image Proc, Image Anal & Learning Grp, D-69117 Heidelberg, Germany; [Weinmann, Andreas] Helmholtz Zentrum Munchen, Inst Computat Biol, D-64295 Darmstadt, Germany; [Weinmann, Andreas] Hsch Darmstadt, Dept Math & Nat Sci, D-64295 Darmstadt, Germany	Ruprecht Karls University Heidelberg; Helmholtz Association; Helmholtz-Center Munich - German Research Center for Environmental Health; Hochschule Darmstadt	Storath, M (corresponding author), Heidelberg Univ, Heidelberg Collab Image Proc, Image Anal & Learning Grp, D-69117 Heidelberg, Germany.	martin.storath@iwr.uni-heidelberg.de; andreas.weinmann@helmholtz-muenchen.de	Storath, Martin/F-5725-2015	Storath, Martin/0000-0003-1427-0776	German Research Foundation [DFG STO1126/2-1, WE5886/4-1, WE5886/3-1]	German Research Foundation(German Research Foundation (DFG))	This work was supported by the German Research Foundation (DFG STO1126/2-1, WE5886/4-1, and WE5886/3-1).	Adato Y, 2011, PROC CVPR IEEE, P1145, DOI 10.1109/CVPR.2011.5995419; [Anonymous], 2009, DIRECTIONAL STAT; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Arias-Castro E, 2009, ANN STAT, V37, P1172, DOI 10.1214/08-AOS604; Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2; Berens P, 2009, J STAT SOFTW, V31, P1, DOI 10.18637/jss.v031.i10; Bergmann R, 2014, SIAM J IMAGING SCI, V7, P2916, DOI 10.1137/140969993; Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P422, DOI 10.1006/jvci.2001.0491; Cremers D, 2013, J MATH IMAGING VIS, V47, P258, DOI 10.1007/s10851-012-0396-1; Davis JC, 2002, STAT DATA ANAL GEOLO; DUCHARME GR, 1987, BIOMETRIKA, V74, P212, DOI 10.1093/biomet/74.1.212; Fisher N.I., 1995, STAT ANAL CIRCULAR D, DOI DOI 10.1017/CBO9780511564345; FISHER NI, 1985, J ROY STAT SOC B MET, V47, P342; FISHER NI, 1989, AUST J EARTH SCI, V36, P91, DOI 10.1080/14400958985270081; Fletcher PT, 2009, NEUROIMAGE, V45, pS143, DOI 10.1016/j.neuroimage.2008.10.052; Fritz H, 2012, COMPUTATION STAT, V27, P393, DOI 10.1007/s00180-011-0262-4; GIAQUINTA M, 1993, CALC VAR PARTIAL DIF, V1, P87, DOI 10.1007/BF02163266; GIL J, 1993, IEEE T PATTERN ANAL, V15, P504, DOI 10.1109/34.211471; Grohs P, 2016, INF INFERENCE, V5, P353, DOI 10.1093/imaiai/iaw011; Hanbury AG, 2001, IEEE T IMAGE PROCESS, V10, P1842, DOI 10.1109/83.974569; HE XM, 1992, ANN STAT, V20, P351, DOI 10.1214/aos/1176348526; HORN BKP, 1981, P SOC PHOTO-OPT INST, V281, P319; HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188; Lellmann J, 2013, IEEE I CONF COMP VIS, P2944, DOI 10.1109/ICCV.2013.366; LIU RY, 1992, ANN STAT, V20, P1468, DOI 10.1214/aos/1176348779; LUTKENHONER B, 1991, ACTA OTO-LARYNGOL, P52; Ma ZY, 2013, IEEE I CONF COMP VIS, P49, DOI 10.1109/ICCV.2013.13; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Massonnet D, 1998, REV GEOPHYS, V36, P441, DOI 10.1029/97RG03139; Nikolaidis N, 1998, IEEE T SIGNAL PROCES, V46, P3181, DOI 10.1109/78.735295; Otieno BS, 2006, ENVIRON ECOL STAT, V13, P311, DOI 10.1007/s10651-004-0014-5; Perreault S, 2007, IEEE T IMAGE PROCESS, V16, P2389, DOI 10.1109/TIP.2007.902329; PURKAYASTHA S, 1995, J STAT PLAN INFER, V46, P77, DOI 10.1016/0378-3758(94)00092-A; Purkayastha S., 1995, STAT DECISIONS, V13, P243; Rocca F., 1997, P 3 ERS S SPAC SERV; SCHULTZ H, 1990, J GEOPHYS RES-OCEANS, V95, P5291, DOI 10.1029/JC095iC04p05291; SMALL CG, 1990, INT STAT REV, V58, P263, DOI 10.2307/1403809; Sowa Y, 2005, NATURE, V437, P916, DOI 10.1038/nature04003; Storath M, 2016, SIAM J SCI COMPUT, V38, pA614, DOI 10.1137/15M101796X; Strekalovskiy E., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1905, DOI 10.1109/CVPR.2011.5995573; Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939; Thiel KH, 1997, ESA SP PUBL, V414, P475; WEHRLY TE, 1981, BIOMETRIKA, V68, P334, DOI 10.1093/biomet/68.1.334; Weinmann A, 2016, J MATH IMAGING VIS, V55, P428, DOI 10.1007/s10851-015-0628-2; Weinmann A, 2014, SIAM J IMAGING SCI, V7, P2226, DOI 10.1137/130951075; Weiss B, 2006, ACM T GRAPHIC, V25, P519, DOI 10.1145/1141911.1141918; Yang QX, 2015, INT J COMPUT VISION, V112, P307, DOI 10.1007/s11263-014-0764-y; Zhang Q, 2014, PROC CVPR IEEE, P2830, DOI 10.1109/CVPR.2014.362	49	16	16	1	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2018	40	3					639	652		10.1109/TPAMI.2017.2692779	http://dx.doi.org/10.1109/TPAMI.2017.2692779			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FV3KC	28422681	Green Submitted			2022-12-18	WOS:000424465900010
J	You, S; Matsushita, Y; Sinha, S; Bou, Y; Ikeuchi, K				You, Shaodi; Matsushita, Yasuyuki; Sinha, Sudipta; Bou, Yusuke; Ikeuchi, Katsushi			Multiview Rectification of Folded Documents	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Robust digitally unwarpping; ridge-aware surface reconstruction; mobile phone friendly algorithms	IMAGE-RESTORATION; 3D SHAPE; RECONSTRUCTION; SURFACES	Digitally unwrapping images of paper sheets is crucial for accurate document scanning and text recognition. This paper presents a method for automatically rectifying curved or folded paper sheets from a few images captured from multiple viewpoints. Prior methods either need expensive 3D scanners or model deformable surfaces using over-simplified parametric representations. In contrast, our method uses regular images and is based on general developable surface models that can represent a wide variety of paper deformations. Our main contribution is a new robust rectification method based on ridge-aware 3D reconstruction of a paper sheet and unwrapping the reconstructed surface using properties of developable surfaces via l(1) conformal mapping. We present results on several examples including book pages, folded letters and shopping receipts.	[You, Shaodi] CSIRO, Data61, Canberra, ACT 2601, Australia; [You, Shaodi] Australian Natl Univ, Canberra, ACT 0200, Australia; [Matsushita, Yasuyuki] Osaka Univ, Suita, Osaka 5650871, Japan; [Sinha, Sudipta] Microsoft Res, Redmond, WA 98052 USA; [Bou, Yusuke] Microsoft, Tokyo 1080075, Japan; [Ikeuchi, Katsushi] Microsoft Res Asia, Beijing 100080, Peoples R China	Commonwealth Scientific & Industrial Research Organisation (CSIRO); Australian National University; Osaka University; Microsoft; Microsoft; Microsoft Research Asia	You, S (corresponding author), CSIRO, Data61, Canberra, ACT 2601, Australia.; You, S (corresponding author), Australian Natl Univ, Canberra, ACT 0200, Australia.	youshaodi@gmail.com; yasumat@ist.osaka-u.ac.jp; sudipta.sinha@microsoft.com; yusuketa@microsoft.com; katsushi.ikeuchi@outlook.jp	Sinha, Sudipta/AAA-2447-2019; Shaodi, YOU/AAA-4524-2022	Shaodi, YOU/0000-0001-8973-645X; Matsushita, Yasuyui/0000-0002-1935-4752				Avron H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1857907.1857911; Brown MS, 2007, IEEE T PATTERN ANAL, V29, P1904, DOI 10.1109/TPAMI.2007.1118; Brown MS, 2004, IEEE T PATTERN ANAL, V26, P1295, DOI 10.1109/TPAMI.2004.87; Candes EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x; Cao HG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P228, DOI 10.1109/ICCV.2003.1238346; Courteille F, 2007, MACH VISION APPL, V18, P301, DOI 10.1007/s00138-006-0062-y; Ezaki H, 2005, PROC INT CONF DOC, P302, DOI 10.1109/ICDAR.2005.87; Fu B., 2007, P 2 INTERNATIONALWOR, P63; Hartley R., 2004, ROBOTICA; Kazhdan Michael, 2006, P EUR S GEOM PROC, V7, P2; Kim BS, 2015, PATTERN RECOGN, V48, P3600, DOI 10.1016/j.patcog.2015.04.026; Koo HI, 2009, IEEE T IMAGE PROCESS, V18, P1551, DOI 10.1109/TIP.2009.2019301; Levy B, 2002, ACM T GRAPHIC, V21, P362, DOI 10.1145/566570.566590; Liang J, 2008, IEEE T PATTERN ANAL, V30, P591, DOI 10.1109/TPAMI.2007.70724; Liu CS, 2015, INT J DOC ANAL RECOG, V18, P111, DOI 10.1007/s10032-014-0233-8; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu SJ, 2006, IMAGE VISION COMPUT, V24, P837, DOI 10.1016/j.imavis.2006.02.008; Meng GF, 2014, PROC CVPR IEEE, P3890, DOI 10.1109/CVPR.2014.497; Meng GF, 2012, IEEE T PATTERN ANAL, V34, P707, DOI 10.1109/TPAMI.2011.151; Oztireli AC, 2009, COMPUT GRAPH FORUM, V28, P493, DOI 10.1111/j.1467-8659.2009.01388.x; Perriollat M, 2013, COMPUT ANIMAT VIRT W, V24, P457, DOI 10.1002/cav.1478; Pilu M, 2001, PROC CVPR IEEE, P67; PORTNOY E, 1975, PAC J MATH, V57, P281, DOI 10.2140/pjm.1975.57.281; Salvi D, 2015, IEEE WINT CONF APPL, P757, DOI 10.1109/WACV.2015.106; Stamatopoulos N, 2011, IEEE T IMAGE PROCESS, V20, P910, DOI 10.1109/TIP.2010.2080280; Tan CL, 2006, IEEE T PATTERN ANAL, V28, P195, DOI 10.1109/TPAMI.2006.40; Tian YD, 2011, PROC CVPR IEEE, P377, DOI 10.1109/CVPR.2011.5995540; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tsoi Yau-Chat, 2007, P IEEE C COMP VIS PA, P1; Tsoi YC, 2004, PROC CVPR IEEE, P240; Ulges A, 2005, PROC INT CONF DOC, P1001, DOI 10.1109/ICDAR.2005.90; Wada T, 1997, INT J COMPUT VISION, V24, P125, DOI 10.1023/A:1007906904009; Yamashita A, 2004, INT C PATT RECOG, P482, DOI 10.1109/ICPR.2004.1334171; Zhang L, 2008, IEEE T PATTERN ANAL, V30, P728, DOI 10.1109/TPAMI.2007.70831; Zhang L, 2009, PATTERN RECOGN, V42, P2961, DOI 10.1016/j.patcog.2009.03.025; Zhang Z, 2004, INT C PATT RECOG, P486, DOI 10.1109/ICPR.2004.1334172; Zhang ZD, 2011, IEEE I CONF COMP VIS, P1347, DOI 10.1109/ICCV.2011.6126388	37	16	16	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2018	40	2					505	511		10.1109/TPAMI.2017.2675980	http://dx.doi.org/10.1109/TPAMI.2017.2675980			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FS9AN	28362582	Green Submitted			2022-12-18	WOS:000422706000019
J	Pham, AT; Raich, R; Fern, XZ				Pham, Anh T.; Raich, Raviv; Fern, Xiaoli Z.			Dynamic Programming for Instance Annotation in Multi-Instance Multi-Label Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multi-instance multi-label learning; instance annotation; expectation maximization; graphical model; dynamic programming		Labeling data for classification requires significant human effort. To reduce labeling cost, instead of labeling every instance, a group of instances (bag) is labeled by a single bag label. Computer algorithms are then used to infer the label for each instance in a bag, a process referred to as instance annotation. This task is challenging due to the ambiguity regarding the instance labels. We propose a discriminative probabilistic model for the instance annotation problem and introduce an expectation maximization framework for inference, based on the maximum likelihood approach. For many probabilistic approaches, brute-force computation of the instance label posterior probability given its bag label is exponential in the number of instances in the bag. Our contribution is a dynamic programming method for computing the posterior that is linear in the number of instances. We evaluate our method using both benchmark and real world data sets, in the domain of bird song, image annotation, and activity recognition. In many cases, the proposed framework outperforms, sometimes significantly, the current state-of-the-art MIML learning methods, both in instance label prediction and bag label prediction.	[Pham, Anh T.; Raich, Raviv; Fern, Xiaoli Z.] Oregon State Univ, Sch EECS, Corvallis, OR 97331 USA	Oregon State University	Pham, AT (corresponding author), Oregon State Univ, Sch EECS, Corvallis, OR 97331 USA.	phaman@eecs.oregonstate.edu; raich@eecs.oregonstate.edu; xfern@eecs.oregonstate.edu	Pham, Anh T./J-5909-2015		US National Science Foundation [CCF-1254218, DBI-1356792, IIS-1055113]	US National Science Foundation(National Science Foundation (NSF))	This work is partially supported by the US National Science Foundation grants CCF-1254218, DBI-1356792, and IIS-1055113. Some of the material in this manuscript was first published in [1] and [2].	Akbas E., 2007, P C COMP VIS CVPR 20, P1; Andrews S., 2002, NIPS, V2, P561; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Boyd S, 2004, CONVEX OPTIMIZATION; Briggs F., 2012, P 18 ACM SIGKDD INT, P534, DOI DOI 10.1145/2339530.2339616; Briggs F, 2013, ACM T KNOWL DISCOV D, V7, DOI 10.1145/2500491; Chen YC, 2014, IEEE T INF FOREN SEC, V9, P2076, DOI 10.1109/TIFS.2014.2359642; Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPRW.2009.5206800, 10.1109/CVPR.2009.5206800]; Cour T, 2011, J MACH LEARN RES, V12, P1501; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Foulds J., 2011, SIAM INT C DATA MINI, P606; FREY PW, 1991, MACH LEARN, V6, P161, DOI 10.1023/A:1022606404104; Golub G. H., 2012, MATRIX COMPUTATIONS, V3; Guan XZ, 2016, PR MACH LEARN RES, V48; Hastie T, 2009, ELEMENTS STAT LEARNI, V2, DOI [10.1007/b94608, DOI 10.1007/B94608]; Heckerman D., 1994, Uncertainty in Artificial Intelligence. Proceedings of the Tenth Conference (1994), P286; Herbrich R., 2006, ADV NEURAL INFORM PR, P569; Huang SJ, 2014, AAAI CONF ARTIF INTE, P1868; Jaakkola TS, 1999, ADV NEUR IN, V11, P487; Li L., 2011, P 28 INT C MACH LEAR, P625; Li YX, 2012, IEEE ACM T COMPUT BI, V9, P98, DOI 10.1109/TCBB.2011.73; Liu L., 2012, ADV NEURAL INFORM PR, P548; Mao Q, 2013, IEEE T IMAGE PROCESS, V22, P1583, DOI 10.1109/TIP.2012.2233490; Mcauliffe Jon D., 2008, P ADV NEURAL INFORM, P121; McLachlan G., 2007, EM ALGORITHM EXTENSI, V382; Ng A. Y., 2001, NIPS, P841; Nguyen N., 2008, P INT C KNOWL DISC D, P551; Pham A. T., 2014, P IEEE INT WORKSH MA, P1; Pham AT, 2015, PR MACH LEARN RES, V37, P2427; Pham AT, 2014, 2014 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING (SSP), P137, DOI 10.1109/SSP.2014.6884594; Ramage D., 2009, P 2009 C EMP METH NA, V1, P248, DOI DOI 10.3115/1699510.1699543; Srivastava N., 2012, ADV NEURAL INFORM PR, P2222, DOI [DOI 10.1162/NEC0_A_00311, DOI 10.1109/CVPR.2013.49]; Stein S., 2013, P 5 INT WORKSHOP MUL, P39, DOI [10.1145/2506023.2506031, DOI 10.1145/2506023.2506031]; Surdeanu M, 2012, P 2012 JOINT C EMP M, V2012, P455; TASKAR B., 2002, P 18 C UNC ART INT, P485; Vapnik V. N., 1998, STAT LEARNING THEORY, V2; Wang J., 2000, PROC 17 INT C MACHIN, P1119; Wang YJ, 2010, PRODUCTION GRIDS IN ASIA: APPLICATIONS, DEVELOPMENTS AND GLOBAL TIES, P155, DOI 10.1007/978-1-4419-0046-3_13; Wu JS, 2014, IEEE ACM T COMPUT BI, V11, P891, DOI 10.1109/TCBB.2014.2323058; Xu X.-S., 2012, P 20 ACM INT C MULT, P737; Yang S. H., 2009, ADV NEURAL INFORM PR, P2143; Zeng ZN, 2013, PROC CVPR IEEE, P708, DOI 10.1109/CVPR.2013.97; Zha Zheng-Jun, 2008, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2008.4587384; Zhang M.L, 2007, AAAI, V7, P669; Zhang ML, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1335, DOI 10.1145/2939672.2939788; Zhang ML, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4048; Zhang ML, 2008, IEEE DATA MINING, P688, DOI 10.1109/ICDM.2008.27; Zhang ML, 2014, P 14 SIAM INT C DAT, P37; Zhang X., 2010, P 13 INT C ARTIFICIA, P956; Zheng Y., 2013, P IAAI, P1575; Zhou Z.-H., 2009, ANN INT C MACH LEARN, P1249, DOI DOI 10.1145/1553374.1553534; Zhou Z.H., 2007, NIPS 19, P1609, DOI DOI 10.1016/J.PATCOG.2006.12.019; Zhou ZH, 2012, ARTIF INTELL, V176, P2291, DOI 10.1016/j.artint.2011.10.002	54	16	17	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2017	39	12					2381	2394		10.1109/TPAMI.2017.2647944	http://dx.doi.org/10.1109/TPAMI.2017.2647944			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL6ZQ	28103189	hybrid, Green Submitted			2022-12-18	WOS:000414395400005
J	Adam, A; Dann, C; Yair, O; Mazor, S; Nowozin, S				Adam, Amit; Dann, Christoph; Yair, Omer; Mazor, Shai; Nowozin, Sebastian			Bayesian Time-of-Flight for Realtime Shape, Illumination and Albedo	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Time-of-flight; Bayes; depth cameras; intrinsic images; multipath	MULTIPATH INTERFERENCE; SINGLE-IMAGE; P-VALUES	We propose a computational model for shape, illumination and albedo inference in a pulsed time-of-flight (TOF) camera. In contrast to TOF cameras based on phase modulation, our camera enables general exposure profiles. This results in added flexibility and requires novel computational approaches. To address this challenge we propose a generative probabilistic model that accurately relates latent imaging conditions to observed camera responses. While principled, realtime inference in the model turns out to be infeasible, and we propose to employ efficient non-parametric regression trees to approximate the model outputs. As a result we are able to provide, for each pixel, at video frame rate, estimates and uncertainty for depth, effective albedo, and ambient light intensity. These results we present are state-of-the-art in depth imaging. The flexibility of our approach allows us to easily enrich our generative model. We demonstrate this by extending the original single-path model to a two-path model, capable of describing some multipath effects. The new model is seamlessly integrated in the system at no additional computational cost. Our work also addresses the important question of optimal exposure design in pulsed TOF systems. Finally, for benchmark purposes and to obtain realistic empirical priors of multipath and insights into this phenomena, we propose a physically accurate simulation of multipath phenomena.	[Adam, Amit; Yair, Omer; Mazor, Shai] Microsoft AIT, Haifa, Israel; [Dann, Christoph] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA; [Nowozin, Sebastian] Microsoft Res, Machine Learning & Percept Grp, Cambridge, England	Carnegie Mellon University; Microsoft	Adam, A (corresponding author), Microsoft AIT, Haifa, Israel.	email.amitadam@gmail.com; cdann@cmu.edu; omeryair@gmail.com; smazor.shai@gmail.com; Sebastian.Nowozin@microsoft.com						Barron J. T., 2013, UCBEECS2013117; Barron JT, 2013, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2013.10; Barron JT, 2012, PROC CVPR IEEE, P334, DOI 10.1109/CVPR.2012.6247693; Bayarri MJ, 2000, J AM STAT ASSOC, V95, P1127, DOI 10.2307/2669749; Berger J. O., 1985, STAT DECISION THEORY; Bhandari A, 2014, OPT LETT, V39, P1705, DOI 10.1364/OL.39.001705; Breiman L., 2017, CLASSIFICATION REGRE; Bucila C, 2006, P 12 ACM SIGKDD INT, P535, DOI DOI 10.1145/1150402.1150464; Criminisil A, 2011, FOUND TRENDS COMPUT, V7, P81, DOI [10.1561/0600000035, 10.1501/0000000035]; DAWID AP, 1982, J AM STAT ASSOC, V77, P605, DOI 10.2307/2287720; Dorrington AA, 2011, PROC SPIE, V7864, DOI 10.1117/12.876586; Felzenshtein S., 2014, U.S. Patent, Patent No. 8717469; Finlayson GD, 2002, LECT NOTES COMPUT SC, V2353, P823; Foi A, 2008, IEEE T IMAGE PROCESS, V17, P1737, DOI 10.1109/TIP.2008.2001399; Freedman D, 2014, LECT NOTES COMPUT SC, V8689, P234, DOI 10.1007/978-3-319-10590-1_16; Fuchs Stefan, 2013, Computer Vision Systems. 9th International Conference, ICVS 2013. Proceedings: LNCS 7963, P31, DOI 10.1007/978-3-642-39402-7_4; Fuchs Stefan, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3583, DOI 10.1109/ICPR.2010.874; Gelman Andrew, 2013, Br J Math Stat Psychol, V66, P8, DOI 10.1111/j.2044-8317.2011.02037.x; Godbaz J. P., 2012, IS T SPIE ELECT IMAG; Gupta M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2735702; Han J., 2013, IEEE T CYBERNETICS; Hansard M. E., 2013, SPRINGER BRIEFS COMP; Haralick RM, 1996, INT J PATTERN RECOGN, V10, P561, DOI 10.1142/S0218001496000347; HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126; Heide F, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516974; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jakob Wenzel, 2010, MITSUBA RENDERER; Jarabo A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661251; Jimenez D, 2014, IMAGE VISION COMPUT, V32, P1, DOI 10.1016/j.imavis.2013.10.008; Kadambi A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508428; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kirmani A, 2013, IEEE INT CON MULTI; Kirmani A, 2009, IEEE I CONF COMP VIS, P159, DOI 10.1109/ICCV.2009.5459160; Kolb A, 2010, COMPUT GRAPH FORUM, V29, P141, DOI 10.1111/j.1467-8659.2009.01583.x; Lange R, 2001, IEEE J QUANTUM ELECT, V37, P390, DOI 10.1109/3.910448; Lefloch Damien, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P3, DOI 10.1007/978-3-642-44964-2_1; Lin JY, 2014, PROC CVPR IEEE, P3230, DOI 10.1109/CVPR.2014.419; Lunn D., 2012, BUGS BOOK PRACTICAL, DOI DOI 10.1201/B13613; MENG XL, 1994, ANN STAT, V22, P1142, DOI 10.1214/aos/1176325622; Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378; O'Toole M, 2014, PROC CVPR IEEE, P3246, DOI 10.1109/CVPR.2014.421; O'Toole M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601103; Payne AD, 2011, PROC SPIE, V8085, DOI 10.1117/12.889399; Pharr M., 2010, PHYS BASED RENDERING; Pitts P., 2014, MSRTR2014142; Reynolds M, 2011, PROC CVPR IEEE, P945, DOI 10.1109/CVPR.2011.5995550; Robins JM, 2000, J AM STAT ASSOC, V95, P1143, DOI 10.2307/2669750; Rother C., 2011, ADV NEURAL INFORM PR, P765; Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3; Schwarte R, 1997, P SOC PHOTO-OPT INS, V3100, P245, DOI 10.1117/12.287751; Shao L, 2013, IEEE T CYBERNETICS, V43, P1314, DOI 10.1109/TCYB.2013.2276144; Shotton J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI 10.1109/TPAMI.2012.241; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Smith AIP, 2008, TLS-TIMES LIT SUPPL, P8; Tadmor Erez, 2014, IEEE Sensors 2014. Proceedings, P618, DOI 10.1109/ICSENS.2014.6985074; Thrun S., 2005, PROBABILISTIC ROBOT; Veach E., 1997, P 24 ANN C COMP GRAP, P65; Veach E., 1994, PHOTOREALISTIC RENDE, P145; Wu D, 2012, PROC CVPR IEEE, P366, DOI 10.1109/CVPR.2012.6247697; Xiao Y, 2014, PROC CVPR IEEE, P3011, DOI 10.1109/CVPR.2014.385; Yahav G., 2010, U.S. Patent Application, Patent No. 20120154535	61	16	20	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2017	39	5					851	864		10.1109/TPAMI.2016.2567379	http://dx.doi.org/10.1109/TPAMI.2016.2567379			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ES0WO	27187943	Green Submitted			2022-12-18	WOS:000399250000002
J	Leifman, G; Shtrom, E; Tal, A				Leifman, George; Shtrom, Elizabeth; Tal, Ayellet			Surface Regions of Interest for Viewpoint Selection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Saliency detection; surfaces; point clouds	MESH SALIENCY; 3D; ATTENTION; PATHS; POINT; SHAPE	While the detection of the interesting regions in images has been extensively studied, relatively few papers have addressed surfaces. This paper proposes an algorithm for detecting the regions of interest of surfaces. It looks for regions that are distinct both locally and globally and accounts for the distance to the foci of attention. It is also shown how this algorithm can be adopted to saliency detection in point clouds. Many applications can utilize these regions. In this paper we explore one such application-viewpoint selection. The most informative views are those that collectively provide the most descriptive presentation of the surface. We show that our results compete favorably with the state-of-the-art results.	[Leifman, George; Shtrom, Elizabeth; Tal, Ayellet] Technion Israel Inst Technol, Dept Elect Engn, Haifa, Israel; [Leifman, George] MIT, Media Lab, Cambridge, MA 02139 USA	Technion Israel Institute of Technology; Massachusetts Institute of Technology (MIT)	Leifman, G (corresponding author), Technion Israel Inst Technol, Dept Elect Engn, Haifa, Israel.; Leifman, G (corresponding author), MIT, Media Lab, Cambridge, MA 02139 USA.	gleifman@mit.edu; slizas@gmail.com; ayellet@ee.technion.ac.il			Intel Collaborative Research Institute for Computational Intelligence (ICRI-CI); Omek Consortium under the MAGNET program of the ministry of economy; Technion Funds for Security Research; Ollendorff foundation	Intel Collaborative Research Institute for Computational Intelligence (ICRI-CI); Omek Consortium under the MAGNET program of the ministry of economy; Technion Funds for Security Research; Ollendorff foundation	The models were generously provided by the AIM@SHAPE Shape Repository, The Technion's CG&M Lab, Stanford 3D Scanning Repository and the Princeton Benchmark. This research was funded in part by the Intel Collaborative Research Institute for Computational Intelligence (ICRI-CI), Omek Consortium under the MAGNET program of the ministry of economy, the Technion Funds for Security Research, and the Ollendorff foundation.	[Anonymous], 2010, EUR WORKSH 3D OBJ RE, DOI DOI 10.2312/3DOR/3DOR10/007-014; [Anonymous], 2006, NIPS; Bobenko Alexander I, 2005, EUR S GEOM PROC, P101; Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89; Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893; Castellani U, 2008, COMPUT GRAPH FORUM, V27, P643, DOI 10.1111/j.1467-8659.2008.01162.x; Chen XB, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185525; Cui X, 2009, C P ACM INT C MULTIM, P617, DOI DOI 10.1145/1631272.1631370; Dutagaci H, 2012, VISUAL COMPUT, V28, P901, DOI 10.1007/s00371-012-0746-4; Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902; Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507; Garland M., 1997, P 24 ANN C COMPUTER, P209, DOI [DOI 10.1145/258734.258849, 10.1145/258734.258849]; Gelfand N., 2005, P 3 EUR S GEOM PROC, V2, P5; Godil A., 2011, P SOC PHOTO-OPT INS, V7864; Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272; Haibin L., 2006, P IEEE C COMP VIS PA, P246, DOI DOI 10.1109/CVPR.2006.99; Hall P., 2005, BRIT MACHINE VISION, V1, P7; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; Hou X, 2007, 2007 IEEE C COMP VIS, V800, P1, DOI DOI 10.1109/CVPR.2007.383267; Huang X., 2015, P INT C COMP VIS, P262; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; JOHNSON DB, 1977, J ACM, V24, P1, DOI 10.1145/321992.321993; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Katz S, 2005, VISUAL COMPUT, V21, P649, DOI 10.1007/s00371-005-0344-9; Kazhdan M, 2002, LECT NOTES COMPUT SC, V2351, P642; Kim W, 2011, IEEE T CIRC SYST VID, V21, P446, DOI 10.1109/TCSVT.2011.2125450; Kim Y, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1670671.1670676; Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431; KOCH C, 1985, HUM NEUROBIOL, V4, P219; KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F; Laga H., 2010, P 3 EUR C 3D OBJ RET, P15; Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244; Lee JH, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P31; Leifman G, 2012, PROC CVPR IEEE, P414, DOI 10.1109/CVPR.2012.6247703; Li J., 2015, P IEEE INT C COMP VI, P190; Li XC, 2005, PROCEEDINGS OF THE 2005 CONFERENCE OF SYSTEM DYNAMICS AND MANAGEMENT SCIENCE, VOL 1, P217; Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112; Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39; Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151; Mathe S, 2012, LECT NOTES COMPUT SC, V7573, P842, DOI 10.1007/978-3-642-33709-3_60; Mitchell JC, 2008, SIAM J SCI COMPUT, V30, P525, DOI 10.1137/030601879; Mokhtarian F., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P272; Mortara M, 2009, COMPUT GRAPH-UK, V33, P280, DOI 10.1016/j.cag.2009.03.003; Novatnack J, 2007, IEEE I CONF COMP VIS, P2001; Rudoy D, 2013, PROC CVPR IEEE, P1147, DOI 10.1109/CVPR.2013.152; Secord A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019628; Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15; Shilane P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1243980.1243981; Shtrom E, 2013, IEEE I CONF COMP VIS, P3591, DOI 10.1109/ICCV.2013.446; Song R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2530691; Sun J., 2009, COMP GRAPH FOR S GEO, V28, p[2, 9], DOI DOI 10.1111/J.1467-8659.2009.01515.X; Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0; Tao PP, 2015, COMPUT GRAPH-UK, V46, P264, DOI 10.1016/j.cag.2014.09.023; TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5; van Kaick O, 2011, COMPUT GRAPH FORUM, V30, P1681, DOI 10.1111/j.1467-8659.2011.01884.x; Vieira T, 2009, COMPUT GRAPH FORUM, V28, P717, DOI 10.1111/j.1467-8659.2009.01412.x; Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001; Wu JL, 2013, GRAPH MODELS, V75, P255, DOI 10.1016/j.gmod.2013.05.002; Yamauchi H, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P265; Yang YB, 2009, LECT NOTES COMPUT SC, V5879, P292, DOI 10.1007/978-3-642-10467-1_25; Zhou F, 2014, PROC CVPR IEEE, P3358, DOI 10.1109/CVPR.2014.429	62	16	16	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2016	38	12					2544	2556		10.1109/TPAMI.2016.2522437	http://dx.doi.org/10.1109/TPAMI.2016.2522437			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EC2WJ	26829779	Green Submitted			2022-12-18	WOS:000387984700015
J	Zhou, F; De la Torre, F				Zhou, Feng; De la Torre, Fernando			Spatio-Temporal Matching for Human Pose Estimation in Video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human pose estimation; dense trajectories; spatio-temporal bilinear model; trajectory matching	BODY MOTION CAPTURE; 3D HUMAN POSE; MULTIPLE; TRACKING	Detection and tracking humans in videos have been long-standing problems in computer vision. Most successful approaches (e.g., deformable parts models) heavily rely on discriminative models to build appearance detectors for body joints and generative models to constrain possible body configurations (e.g., trees). While these 2D models have been successfully applied to images (and with less success to videos), a major challenge is to generalize these models to cope with camera views. In order to achieve view-invariance, these 2D models typically require a large amount of training data across views that is difficult to gather and time-consuming to label. Unlike existing 2D models, this paper formulates the problem of human detection in videos as spatio-temporal matching (STM) between a 3D motion capture model and trajectories in videos. Our algorithm estimates the camera view and selects a subset of tracked trajectories that matches the motion of the 3D model. The STM is efficiently solved with linear programming, and it is robust to tracking mismatches, occlusions and outliers. To the best of our knowledge this is the first paper that solves the correspondence between video and 3D motion capture data for human pose detection. Experiments on the CMU motion capture, Human3.6M, Berkeley MHAD and CMU MAD databases illustrate the benefits of our method over state-of-the-art approaches.	[Zhou, Feng; De la Torre, Fernando] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Zhou, F (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.	zhfe99@gmail.com; ftorre@cs.cmu.edu						Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21; Akhter I, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2159516.2159523; Akhter I, 2011, IEEE T PATTERN ANAL, V33, P1442, DOI 10.1109/TPAMI.2010.201; Andriluka M, 2008, PROC CVPR IEEE, P1873, DOI 10.1109/CVPR.2008.4587583; Andriluka M, 2012, INT J COMPUT VISION, V99, P259, DOI 10.1007/s11263-011-0498-z; Andriluka M, 2010, PROC CVPR IEEE, P623, DOI 10.1109/CVPR.2010.5540156; [Anonymous], 2015, CARNEGIE MELLON U MO; Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9; Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1; Burgos-Artizzu XP, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.58; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deutscher J, 2005, INT J COMPUT VISION, V61, P185, DOI 10.1023/B:VISI.0000043757.18370.9c; DEUTSCHER J, 2000, P IEEE C COMP VIS PA, V2, P126, DOI DOI 10.1109/CVPR.2000.854758; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Eichner M, 2012, INT J COMPUT VISION, V99, P190, DOI 10.1007/s11263-012-0524-9; Elgammal A, 2004, PROC CVPR IEEE, P681; Farneback G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50; Gower J. C., 2004, PROCRUSTES PROBLEMS; Huang D, 2014, LECT NOTES COMPUT SC, V8691, P410, DOI 10.1007/978-3-319-10578-9_27; Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248; Ionescu C, 2011, IEEE I CONF COMP VIS, P2220, DOI 10.1109/ICCV.2011.6126500; Jain A, 2015, LECT NOTES COMPUT SC, V9004, P302, DOI 10.1007/978-3-319-16808-1_21; Jiang H, 2007, IEEE T PATTERN ANAL, V29, P959, DOI 10.1109/TPAMI.2007.1048; Ju SX, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P38, DOI 10.1109/AFGR.1996.557241; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Lin Z., 2010, ARXIV10095055, DOI DOI 10.1016/J.JSB.2012.10.010; Matikainen Pyry, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P514, DOI 10.1109/ICCVW.2009.5457659; Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154; Ofli F, 2013, IEEE WORK APP COMP, P53, DOI 10.1109/WACV.2013.6474999; Park D, 2011, IEEE I CONF COMP VIS, P2627, DOI 10.1109/ICCV.2011.6126552; Rohr K., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P8, DOI 10.1109/CVPR.1993.341008; Sapp B, 2011, PROC CVPR IEEE, P1281, DOI 10.1109/CVPR.2011.5995607; Sapp B, 2010, LECT NOTES COMPUT SC, V6312, P406, DOI 10.1007/978-3-642-15552-9_30; Shotton J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI 10.1109/TPAMI.2012.241; Sidenbladh H., 2000, LNCS, V2, P702; Sigal L, 2006, LECT NOTES COMPUT SC, V4069, P185; Simo-Serra E, 2012, PROC CVPR IEEE, P2673, DOI 10.1109/CVPR.2012.6247988; Song Y, 2003, IEEE T PATTERN ANAL, V25, P814, DOI 10.1109/TPAMI.2003.1206511; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; Trendafilov N., 2004, FUTURE GENER COMP SY, V19, P1177; Urtasun R., 2006, 2006 IEEE COMP SOC C, V1, P238, DOI DOI 10.1109/CVPR.2006.15; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang H, 2009, J OPTOELECTRON BIOME, V1, P1; Wei X. K., 2010, ACM T GRAPHIC, V29, P1; Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7; Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261; Yao A, 2012, INT J COMPUT VISION, V100, P16, DOI 10.1007/s11263-012-0532-9; Yu TH, 2013, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2013.467	51	16	16	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2016	38	8			SI		1492	1504		10.1109/TPAMI.2016.2526002	http://dx.doi.org/10.1109/TPAMI.2016.2526002			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DR5EO	26863647	Green Submitted			2022-12-18	WOS:000379926200002
J	Seth, S; Eugster, MJA				Seth, Sohan; Eugster, Manuel J. A.			Archetypal Analysis for Nominal Observations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Archetypal analysis; nominal observations; variational Bayes; clustering; prototype; simplex visualization		Archetypal analysis is a popular exploratory tool that explains a set of observations as compositions of few 'pure' patterns. The standard formulation of archetypal analysis addresses this problem for real valued observations by finding the approximate convex hull. Recently, a probabilistic formulation has been suggested which extends this framework to other observation types such as binary and count. In this article we further extend this framework to address the general case of nominal observations which includes, for example, multiple-option questionnaires. We view archetypal analysis in a generative framework: this allows explicit control over choosing a suitable number of archetypes by assigning appropriate prior information, and finding efficient update rules using variational Bayes'. We demonstrate the efficacy of this approach extensively on simulated data, and three real world examples: Austrian guest survey dataset, German credit dataset, and SUN attribute image dataset.	[Seth, Sohan; Eugster, Manuel J. A.] Aalto Univ, Helsinki Inst Informat Technol, Dept Comp Sci, Helsinki, Finland	Aalto University; University of Helsinki	Seth, S; Eugster, MJA (corresponding author), Aalto Univ, Helsinki Inst Informat Technol, Dept Comp Sci, Helsinki, Finland.	sohan.seth@hiit.fi; manuel.eugster@hiit.fi						[Anonymous], P 19 ACM INT C INF K, DOI DOI 10.1145/1871437.1871729; Bauckhage C, 2009, LECT NOTES COMPUT SC, V5748, P272, DOI 10.1007/978-3-642-03798-6_28; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Chan BHP, 2003, MON NOT R ASTRON SOC, V338, P790, DOI 10.1046/j.1365-8711.2003.06099.x; CHEN Y., 2014, CORR; CUTLER A, 1994, TECHNOMETRICS, V36, P338, DOI 10.2307/1269949; Dolnicar S., 2004, AUSTRALASIAN MARKETI, V12, P51, DOI DOI 10.1016/S1441-3582(04)70088-9; Dolnicar S, 2011, INT J MARKET RES, V53, P231, DOI 10.2501/IJMR-53-2-231-252; Eugster MJA, 2012, INT J PERF ANAL SPOR, V12, P166, DOI 10.1080/24748668.2012.11868592; Eugster MJA, 2011, COMPUT STAT DATA AN, V55, P1215, DOI 10.1016/j.csda.2010.10.017; Hofmann T., 2013, ARXIV13016705; Holladay J. E., 2007, P 7 INT S INT DAT AN, P1; Lichman M, 2013, UCI MACHINE LEARNING; MIMNO D, 2009, P 2009 C EMP METH NA, V2, P880; Morup M, 2012, NEUROCOMPUTING, V80, P54, DOI 10.1016/j.neucom.2011.06.033; Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Seth S., 2015, MACH LEARN, P1; Xiong YJ, 2013, IEEE I CONF COMP VIS, P585, DOI 10.1109/ICCV.2013.78	19	16	16	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2016	38	5					849	861		10.1109/TPAMI.2015.2470655	http://dx.doi.org/10.1109/TPAMI.2015.2470655			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DJ4GZ	27046837	Green Submitted			2022-12-18	WOS:000374164700002
J	Deng, J; Krause, J; Stark, M; Fei-Fei, L				Deng, Jia; Krause, Jonathan; Stark, Michael; Fei-Fei, Li			Leveraging the Wisdom of the Crowd for Fine-Grained Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object recognition; Crowdsourcing; human computation; Gamification	INFORMATION	Fine-grained recognition concerns categorization at sub-ordinate levels, where the distinction between object classes is highly local. Compared to basic level recognition, fine-grained categorization can be more challenging as there are in general less data and fewer discriminative features. This necessitates the use of a stronger prior for feature selection. In this work, we include humans in the loop to help computers select discriminative features. We introduce a novel online game called "Bubbles" that reveals discriminative features humans use. The player's goal is to identify the category of a heavily blurred image. During the game, the player can choose to reveal full details of circular regions ("bubbles"), with a certain penalty. With proper setup the game generates discriminative bubbles with assured quality. We next propose the "BubbleBank" representation that uses the human selected bubbles to improve machine recognition performance. Finally, we demonstrate how to extend BubbleBank to a view-invariant 3D representation. Experiments demonstrate that our approach yields large improvements over the previous state of the art on challenging benchmarks.	[Deng, Jia] Univ Michigan, Comp Sci & Engn, Ann Arbor, MI 48109 USA; [Krause, Jonathan; Fei-Fei, Li] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA; [Stark, Michael] Max Planck Inst Informat, Comp Vis & Multimodal Comp, Saarbrucken, Germany	University of Michigan System; University of Michigan; Stanford University; Max Planck Society	Deng, J (corresponding author), Univ Michigan, Comp Sci & Engn, Ann Arbor, MI 48109 USA.; Krause, J; Fei-Fei, L (corresponding author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.; Stark, M (corresponding author), Max Planck Inst Informat, Comp Vis & Multimodal Comp, Saarbrucken, Germany.	jiadeng@umich.edu; jkrause@cs.stanford.edu; stark@mpi-inf.mpg.de; feifeili@cs.stanford.edu			Intel ISTC; ONR-MURI; Max Planck Center for Visual Computing and Communication;  [NSF-IIS-1115313]	Intel ISTC; ONR-MURI(MURIOffice of Naval Research); Max Planck Center for Visual Computing and Communication; 	The authors thank Alexandre Alahi, Michelle Greene, Olga Russakovsky, Bangpeng Yao for their helpful comments. The research is partially supported by grants from Intel ISTC, an ONR-MURI, NSF-IIS-1115313, Max Planck Center for Visual Computing and Communication. Earlier versions of this work appeared in [1] and [2].	Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Branson S, 2011, IEEE I CONF COMP VIS, P1832, DOI 10.1109/ICCV.2011.6126450; Branson S, 2010, LECT NOTES COMPUT SC, V6314, P438, DOI 10.1007/978-3-642-15561-1_32; Chai Y, 2013, IEEE I CONF COMP VIS, P321, DOI 10.1109/ICCV.2013.47; Chai YN, 2012, LECT NOTES COMPUT SC, V7572, P794, DOI 10.1007/978-3-642-33718-5_57; Chen Q, 2012, PROC CVPR IEEE, P3426, DOI 10.1109/CVPR.2012.6248083; Cline D, 2009, COMPUT GRAPH FORUM, V28, P1217, DOI 10.1111/j.1467-8659.2009.01499.x; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J, 2010, LECT NOTES COMPUT SC, V6315, P71, DOI 10.1007/978-3-642-15555-0_6; Donahue J, 2011, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2011.6126394; Druck G., 2009, P C EMP METH NAT LAN, P81, DOI DOI 10.3115/1699510.1699522; Duan K, 2012, PROC CVPR IEEE, P3474, DOI 10.1109/CVPR.2012.6248089; Farrell R, 2011, IEEE I CONF COMP VIS, P161, DOI 10.1109/ICCV.2011.6126238; Fox D, 2010, ADV NEURAL INFORM PR, P244; Gosselin F, 2001, VISION RES, V41, P2261, DOI 10.1016/S0042-6989(01)00097-9; Gupta P, 2009, IEEE I CONF COMP VIS, P1655, DOI 10.1109/ICCV.2009.5459373; Jia D, 2013, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2013.81; Khan F., 2011, INT C NEUR INF PROCE; Krause J., 2013, 4 INT IEEE WORKSH 3D; Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36; Law E., 2011, P 1 WORKSH FIN GRAIN; Liebelt J, 2010, PROC CVPR IEEE, P1688, DOI 10.1109/CVPR.2010.5539836; Liu JX, 2012, LECT NOTES COMPUT SC, V7572, P172, DOI 10.1007/978-3-642-33718-5_13; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maji S., 2012, P WORKSH 26 AAAI C A; Maji S, 2012, LECT NOTES COMPUT SC, V7585, P21, DOI 10.1007/978-3-642-33885-4_3; Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229; Parikh D., 2011, P 2 WORKSH COMP SOC, V11; Parikh D, 2011, PROC CVPR IEEE, P1681, DOI 10.1109/CVPR.2011.5995451; Parkash A, 2012, LECT NOTES COMPUT SC, V7574, P354, DOI 10.1007/978-3-642-33712-3_26; Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092; Pepik B, 2012, LECT NOTES COMPUT SC, V7577, P356, DOI 10.1007/978-3-642-33783-3_26; Redondo-Cabrera C, 2012, PROC CVPR IEEE, P3458, DOI 10.1109/CVPR.2012.6248087; Scheirer WJ, 2014, IEEE T PATTERN ANAL, V36, P1679, DOI 10.1109/TPAMI.2013.2297711; Sorokin A, 2008, PROC CVPR IEEE, P23; Su H., 2010, ADV NEURAL PROCESSIN, V1, P1378; van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154; van de Weijer J, 2007, PROC CVPR IEEE, P1898; Vijayanarasimhan S, 2011, PROC CVPR IEEE, P1449, DOI 10.1109/CVPR.2011.5995430; von Ahn L., 2006, P SIGCHI C HUMAN FAC, P55, DOI DOI 10.1145/1124772.1124782; Von Ahn Luis, 2004, P SIGCHI C HUM FACT, P319, DOI DOI 10.1145/985692.985733; Wah C, 2011, IEEE I CONF COMP VIS, P2524, DOI 10.1109/ICCV.2011.6126539; Wah Catherine, 2011, CALTECH UCSD BIRDS 2; WANG JJ, 2010, PROC CVPR IEEE, P3360, DOI DOI 10.1109/CVPR.2010.5540018; Welinder Peter, 2010, CALTECH UCSD BIRDS 2, V200; Yang S., 2012, ADV NEURAL INFORM PR, P3122; Yao BP, 2012, PROC CVPR IEEE, P3466, DOI 10.1109/CVPR.2012.6248088; Yao BP, 2011, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR.2011.5995368; Zhang N, 2012, PROC CVPR IEEE, P3665, DOI 10.1109/CVPR.2012.6248364; Zia M. Z., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P569, DOI 10.1109/ICCVW.2011.6130294	52	16	18	1	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2016	38	4					666	676		10.1109/TPAMI.2015.2439285	http://dx.doi.org/10.1109/TPAMI.2015.2439285			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DH1MW	26959672				2022-12-18	WOS:000372549700005
J	Hu, H; Feng, JJ; Zhou, J				Hu, Han; Feng, Jianjiang; Zhou, Jie			Exploiting Unsupervised and Supervised Constraints for Subspace Clustering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Subspace clustering; motion segmentation; face clustering; linear programming; branch and bound; constrained clustering	MOTION SEGMENTATION; FACE RECOGNITION; ALGORITHM; MULTIBODY; REPRESENTATION; AFFINITY; ROBUST; CUTS	Data in many image and video analysis tasks can be viewed as points drawn from multiple low-dimensional subspaces with each subspace corresponding to one category or class. One basic task for processing such kind of data is to separate the points according to the underlying subspace, referred to as subspace clustering. Extensive studies have been made on this subject, and nearly all of them use unconstrained subspace models, meaning the points can be drawn from everywhere of a subspace, to represent the data. In this paper, we attempt to do subspace clustering based on a constrained subspace assumption that the data is further restricted in the corresponding subspaces, e.g., belonging to a submanifold or satisfying the spatial regularity constraint. This assumption usually describes the real data better, such as differently moving objects in a video scene and face images of different subjects under varying illumination. A unified integer linear programming optimization framework is used to approach subspace clustering, which can be efficiently solved by a branch-and-bound (BB) method. We also show that various kinds of supervised information, such as subspace number, outlier ratio, pairwise constraints, size prior and etc., can be conveniently incorporated into the proposed framework. Experiments on real data show that the proposed method outperforms the state-of-the-art algorithms significantly in clustering accuracy. The effectiveness of the proposed method in exploiting supervised information is also demonstrated.	[Hu, Han; Feng, Jianjiang; Zhou, Jie] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China; [Hu, Han] Baidu Res, Inst Deep Learning, Beijing, Peoples R China	Tsinghua University; Baidu	Hu, H (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.	huhan02@baidu.com; jfeng@tsinghua.edu.cn; jzhou@tsinghua.edu.cn			National Natural Science Foundation of China [61225008, 61020106004, 61373074, 61373090]; National Basic Research Program of China [2014CB349304]; Ministry of Education of China [20120002110033]; Tsinghua University Initiative Scientific Research Program	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China(National Basic Research Program of China); Ministry of Education of China(Ministry of Education, China); Tsinghua University Initiative Scientific Research Program	The authors would like to thank the reviewers and associate editor for the constructive comments. This work is supported by the National Natural Science Foundation of China under Grants 61225008, 61020106004, 61373074 and 61373090, the National Basic Research Program of China under Grant 2014CB349304, the Ministry of Education of China under Grant 20120002110033, and the Tsinghua University Initiative Scientific Research Program. J. Feng is the corresponding author.	Aldroubi A, 2012, IEEE SIGNAL PROC LET, V19, P704, DOI 10.1109/LSP.2012.2214211; BALINSKI ML, 1965, MANAGE SCI, V12, P253, DOI 10.1287/mnsc.12.3.253; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Basri R, 2001, PROC CVPR IEEE, P374; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Chen GL, 2009, INT J COMPUT VISION, V81, P317, DOI 10.1007/s11263-008-0178-9; Cheng B, 2011, IEEE I CONF COMP VIS, P2439, DOI 10.1109/ICCV.2011.6126528; Chin T.-J., 2009, NIPS, V22, P333; Chin TJ, 2010, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2010.5539931; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; Del Bue A, 2012, IEEE T PATTERN ANAL, V34, P1496, DOI 10.1109/TPAMI.2011.238; EFROYMSON MA, 1966, OPER RES, V14, P361, DOI 10.1287/opre.14.3.361; Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Elhamifar Ehsan, 2011, ADV NEURAL INF PROCE, V24, P3; Eriksson A, 2007, 11 IEEE INT C COMP V, P1; Fan ZM, 2006, IEEE T PATTERN ANAL, V28, P91, DOI 10.1109/TPAMI.2006.16; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gear CW, 1998, INT J COMPUT VISION, V29, P133, DOI 10.1023/A:1008026310903; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Goh A, 2007, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2007.383235; Gonzalez-Mora J, 2007, IEEE I CONF COMP VIS, P2776; Hartley R., 2004, ROBOTICA; Hinton G. E., 1994, P ADV NEUR INF PROC, V7, P1015; Holmberg K, 1999, EUR J OPER RES, V113, P544, DOI 10.1016/S0377-2217(98)00008-3; Horn R.A., 2007, MATRIX ANAL; Hu H., 2009, P BRIT MACH VIS C; Hu H, 2014, PROC CVPR IEEE, P3834, DOI 10.1109/CVPR.2014.484; Hu H, 2013, IEEE T IMAGE PROCESS, V22, P4328, DOI 10.1109/TIP.2013.2271865; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; Kanatani K, 1998, INT J COMPUT VISION, V26, P171, DOI 10.1023/A:1007948927139; Kanatani K., 2002, P 5 AS C COMP VIS, P23; KANATANI K, 2003, P AUSTR JAP ADV WORK, P335; Klose A., 1998, International Transactions in Operational Research, V5, P155, DOI 10.1111/j.1475-3995.1998.tb00111.x; Komodakis N, 2007, IEEE T PATTERN ANAL, V29, P1436, DOI 10.1109/TPAMI.2007.1061; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Lauer F, 2009, IEEE I CONF COMP VIS, P678, DOI 10.1109/ICCV.2009.5459173; LAWLER EL, 1966, OPER RES, V14, P699, DOI 10.1287/opre.14.4.699; Lazic N., 2010, EXPERT SYST APPL, V9, P429; Lazic N, 2009, IEEE I CONF COMP VIS, P825, DOI 10.1109/ICCV.2009.5459302; Lee CM, 2013, IEEE I CONF COMP VIS, P1585, DOI 10.1109/ICCV.2013.200; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Li R., 2012, P 29 INT C MACH LEAR, P377; Liu G., 2010, P 27 INT C MACHINE L, P663, DOI DOI 10.1109/ICDMW.2010.64; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu GC, 2011, IEEE I CONF COMP VIS, P1615, DOI 10.1109/ICCV.2011.6126422; Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26; Ma Y, 2007, IEEE T PATTERN ANAL, V29, P1546, DOI 10.1109/TP'AMI.2007.1085; Marques M, 2009, COMPUT VIS IMAGE UND, V113, P261, DOI 10.1016/j.cviu.2008.09.004; Mittal S, 2012, IEEE T PATTERN ANAL, V34, P2351, DOI 10.1109/TPAMI.2012.52; MOSEK ApS, 2013, MOS MOD MAN ONL; Park JH, 2004, LECT NOTES COMPUT SC, V2034, P390; Rao S, 2010, IEEE T PATTERN ANAL, V32, P1832, DOI 10.1109/TPAMI.2009.191; Rother C., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383203; Schrijver A., 1998, THEORY LINEAR INTEGE; Shashua A, 1997, INT J COMPUT VISION, V21, P99, DOI 10.1023/A:1007975506780; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Tron R, 2007, PROC CVPR IEEE, P41, DOI 10.1109/cvpr.2007.382974; Vidal R, 2005, IEEE T PATTERN ANAL, V27, P1945, DOI 10.1109/TPAMI.2005.244; Vidal R, 2008, INT J COMPUT VISION, V79, P85, DOI 10.1007/s11263-007-0099-z; Vidal R, 2011, IEEE SIGNAL PROC MAG, V28, P52, DOI 10.1109/MSP.2010.939739; Wang HZ, 2004, INT J COMPUT VISION, V59, P139, DOI 10.1023/B:VISI.0000022287.61260.b0; Wang S., 2011, P 25 AAAI C ARTIFICI, P519; Yan JY, 2006, LECT NOTES COMPUT SC, V3954, P94; Yu SX, 2004, IEEE T PATTERN ANAL, V26, P173, DOI 10.1109/TPAMI.2004.1262179; Zappella L, 2011, PATTERN RECOGN, V44, P454, DOI 10.1016/j.patcog.2010.08.015; Zelnik-Manor L, 2003, PROC CVPR IEEE, P287; Zhang L, 2009, PROCEEDINGS OF 2009 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS TECHNOLOGY AND APPLICATIONS, P212, DOI 10.1109/ICCOMTA.2009.5349209; Zhang T, 2010, PROC CVPR IEEE, P1927, DOI 10.1109/CVPR.2010.5539866; Zografos V, 2013, PROC CVPR IEEE, P2107, DOI 10.1109/CVPR.2013.274	71	16	16	0	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2015	37	8					1542	1557		10.1109/TPAMI.2014.2377740	http://dx.doi.org/10.1109/TPAMI.2014.2377740			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CM3ON	26352994				2022-12-18	WOS:000357591900002
J	Li, K; Wang, J; Wang, HQ; Dai, QH				Li, Kai; Wang, Jue; Wang, Haoqian; Dai, Qionghai			Structuring Lecture Videos by Automatic Projection Screen Localization and Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Lecture video; presentation video; video structuring; video summarization; projection screen localization	SHOT-BOUNDARY DETECTION; TRACKING; MODEL	We present a fully automatic system for extracting the semantic structure of a typical academic presentation video, which captures the whole presentation stage with abundant camera motions such as panning, tilting, and zooming. Our system automatically detects and tracks both the projection screen and the presenter whenever they are visible in the video. By analyzing the image content of the tracked screen region, our system is able to detect slide progressions and extract a high-quality, non-occluded, geometrically-compensated image for each slide, resulting in a list of representative images that reconstruct the main presentation structure. Afterwards, our system recognizes text content and extracts keywords from the slides, which can be used for keyword-based video retrieval and browsing. Experimental results show that our system is able to generate more stable and accurate screen localization results than commonly-used object tracking methods. Our system also extracts more accurate presentation structures than general video summarization methods, for this specific type of video.	[Li, Kai; Dai, Qionghai] Tsinghua Univ, Dept Automat, Tsinghua Natl Lab Informat Sci & Technol TNList, Beijing 100084, Peoples R China; [Li, Kai; Wang, Haoqian] Tsinghua Univ, Grad Sch Shenzhen, Shenzhen 518055, Peoples R China; [Wang, Jue] Adobe Res, Seattle, WA 98103 USA; [Dai, Qionghai] Tsinghua Univ, Beijing Key Lab Multidimens & Multiscale Computat, Beijing 100084, Peoples R China	Tsinghua University; Tsinghua University; University Town of Shenzhen; Tsinghua Shenzhen International Graduate School; Adobe Systems Inc.; Tsinghua University	Wang, HQ (corresponding author), Tsinghua Univ, Grad Sch Shenzhen, Shenzhen 518055, Peoples R China.	l-k10@mails.tsinghua.edu.cn; juewang@ieee.org; wanghaoqian@tsinghua.edu.cn; qionghaidai@tsinghua.edu.cn	Dai, Qionghai/ABD-5298-2021; Wang, Jue/GVU-0480-2022	Dai, Qionghai/0000-0001-7043-3061; Li, Kai/0000-0002-8336-9684; Wang, Jue/0000-0002-3641-3136	NSFC [61035002, 61120106003]	NSFC(National Natural Science Foundation of China (NSFC))	The authors would like to thank the reviewers and associate editor for their constructive comments. This work was supported by the Project of NSFC (No. 61035002 & 61120106003).	[Anonymous], [No title captured]; Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737; Benhimane S., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P943; Bischof H., 2006, BMVC, P47; Bouthemy P, 1999, IEEE T CIRC SYST VID, V9, P1030, DOI 10.1109/76.795057; Bradski Gary R, 1998, COMPUTER VISION FACE, P1; Cernekova Z, 2006, IEEE T CIRC SYST VID, V16, P82, DOI 10.1109/TCSVT.2005.856896; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951; DeMenthon D., 1998, Proceedings ACM Multimedia 98, P211, DOI 10.1145/290747.290773; Fan QF, 2007, INT CONF ACOUST SPEE, P989; Fan QF, 2011, IEEE T IMAGE PROCESS, V20, P2315, DOI 10.1109/TIP.2011.2109727; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gong YH, 2000, PROC CVPR IEEE, P174, DOI 10.1109/CVPR.2000.854772; Grundmann M, 2011, PROC CVPR IEEE, P225, DOI 10.1109/CVPR.2011.5995525; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656; He LW, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P489, DOI 10.1145/319463.319691; Huang CL, 2001, IEEE T CIRC SYST VID, V11, P1281, DOI 10.1109/76.974682; Jinhui Yuan, 2005, 13th Annual ACM International Conference on Multimedia, P539, DOI 10.1145/1101149.1101271; KRUPPA H, 2003, JOINT IEEE INT WORKS, P157; Liu HC, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P77, DOI 10.1109/ICME.2002.1035722; Liu T., 2004, Proceedings. IEEE Sixth International Symposium on Multimedia Software, P574; Lougee-Heimer R, 2003, IBM J RES DEV, V47, P57, DOI 10.1147/rd.471.0057; Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410; Mohanta PP, 2012, IEEE T MULTIMEDIA, V14, P223, DOI 10.1109/TMM.2011.2170963; Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694; Ngo CW, 2003, IEEE FIFTH INTERNATIOANL SYMPOSIUM ON MULTIMEDIA SOFTWARE ENGINEERING, PROCEEDINGS, P215; Ngo CW, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA533; Nguyen C, 2012, P SIGCHI C HUM FACT, P647, DOI DOI 10.1145/2207676.2207767.978-1-4503-1015-4; Patel NV, 1997, PATTERN RECOGN, V30, P583, DOI 10.1016/S0031-3203(96)00114-8; Repp S, 2006, FOURTH ANNUAL IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS, PROCEEDINGS, P240, DOI 10.1109/PERCOMW.2006.122; Rodriguez M, 2010, PROC CVPR IEEE, P3328, DOI 10.1109/CVPR.2010.5540030; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Simon G, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P120, DOI 10.1109/ISAR.2000.880935; Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011; Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991; Sujatha C., 2011, 2011 Proceedings of International Conference on Computational Intelligence and Communication Networks (CICN 2011), P73, DOI 10.1109/CICN.2011.15; Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305; von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300; Wang F., 2003, P 11 ACM INT C MULT, P315; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Zabih R., 1995, P 3 ACM INT C MULTIM, P189, DOI DOI 10.1145/217279.215266; ZHANG HJ, 1995, P ACM MULT 95 SAN FR, P15, DOI DOI 10.1145/217279.215068; Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655	45	16	16	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2015	37	6					1233	1246		10.1109/TPAMI.2014.2361133	http://dx.doi.org/10.1109/TPAMI.2014.2361133			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CH9SR	26357345				2022-12-18	WOS:000354377100009
J	Perrier, R; Arnaud, E; Sturm, P; Ortner, M				Perrier, Regis; Arnaud, Elise; Sturm, Peter; Ortner, Mathias			Estimation of an Observation Satellite's Attitude Using Multimodal Pushbroom Cameras	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Multimodal image registration; satellite attitude; pushbroom cameras; hyperparameter learning; maximum a posteriori estimator		Pushbroom cameras are widely used for earth observation applications. This sensor acquires 1D images over time and uses the straight motion of the satellite to sweep out a region of space and build a 2D image. The stability of the satellite is critical during the pushbroom acquisition process. Therefore its attitude is assumed to be constant over time. However, the recent manufacture of smaller and lighter satellites to reduce launching cost has weakened this assumption. Small oscillations of the satellite's attitude can result in noticeable warps in images, and geolocation information is lost as the satellite does not capture what it ought to. Current solutions use inertial sensors to control the attitude and correct the images, but they are costly and of limited precision. As the warped images do contain information about attitude variations, we suggest using image registration to estimate them. We exploit the geometry of the focal plane and the stationary nature of the disturbances to recover undistorted images. We embed the estimation in a Bayesian framework where image registration, a prior on attitude variations and a radiometric correction model are fused to retrieve the motion of the satellite. We illustrate the performance of our algorithm on four satellite datasets.	[Perrier, Regis] CEA Leti, Grenoble, France; [Arnaud, Elise] Univ Grenoble 1, Grenoble, France; [Sturm, Peter] INRIA, Grenoble, France; [Ortner, Mathias] EADS Astrium, Toulouse, France	CEA; UDICE-French Research Universities; Communaute Universite Grenoble Alpes; Universite Grenoble Alpes (UGA); Inria; Airbus; EADS Astrium	Perrier, R (corresponding author), CEA Leti, Grenoble, France.	perrier.regis@gmail.com; elise.arnaud@inria.fr; peter.sturm@inrialpes.fr; mathias.ortner@astrium.eads.net			EADS Astrium; INRIA Grenoble	EADS Astrium; INRIA Grenoble	This work was fully sponsored by EADS Astrium, the European satellite manufacturer, in collaboration with INRIA Grenoble.	AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; BRUNET F., 2010, VMV 2010 VISION MODE, P33; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Cramer M., 2001, INT ARCH PHOTOGRAMM, V33, P198; DeLussy F., 2008, P INT SOC PHOT REM S, V37, P27; Dowson N, 2008, IEEE T PATTERN ANAL, V30, P180, DOI 10.1109/TPAMI.2007.70757; Drareni J., 2008, P 8 WORKSH OMN VIS C, P146; Forstner W, 1984, INT ARCH PHOTOGRAMME, V25, P197; Gruen A., 2003, PHOTOGRAMM FERNERKUN, V1, P85; Guimond A, 2001, IEEE T MED IMAGING, V20, P58, DOI 10.1109/42.906425; Gupta R, 1997, IEEE T PATTERN ANAL, V19, P963, DOI 10.1109/34.615446; Gupta R., 1995, P 2 AS C COMP VIS; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Hirschmuller H, 2005, LECT NOTES COMPUT SC, V3663, P58; Inglada J, 2004, IEEE T GEOSCI REMOTE, V42, P2104, DOI 10.1109/TGRS.2004.835294; Irani M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P959, DOI 10.1109/ICCV.1998.710832; Irani M., 2000, VISION ALGORITHMS TH, V1883, P267, DOI DOI 10.1007/3-540-44480-7; Iwasaki A., 2011, ADV SPACECRAFT TECHN, P259; Jalobeanu A, 2002, PATTERN RECOGN, V35, P341, DOI 10.1016/S0031-3203(00)00178-3; Jalobeanu A., 2011, P 7 INT S SPAT DAT Q; Lamard JL, 2004, ESA SP PUBL, V554, P149; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas B. D., 1981, INT JOINT C ART INT, P674, DOI DOI 10.5555/1623264.1623280; MacKay D. J. C., 2002, INFORM THEORY INFERE; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.448; Magerand L., 2010, P INT S 3D DAT PROC; MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792; Perrier R., 2010, P 10 AS C COMP VIS, P361; Perrier R, 2010, PROC CVPR IEEE, P591, DOI 10.1109/CVPR.2010.5540160; Petrie G., 2005, GEOINFORMATICS, V8, P50; Poli D., 2002, INT ARCH PHOTOGRAMME, V34 (1), P177; PUNSKA O., 1999, THESIS CAMBRIDGE U C; Rademacher P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P199, DOI 10.1145/280814.280871; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Robinson D, 2004, IEEE T IMAGE PROCESS, V13, P1185, DOI 10.1109/TIP.2004.832923; Roche A, 1999, LECT NOTES COMPUT SC, V1679, P555; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Szeliski R., 2010, COMPUTER VISION ALGO, DOI DOI 10.1007/978-3-030-34372-9; Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9; Zomet A, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P27, DOI 10.1109/ACV.2002.1182150	42	16	16	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2015	37	5					987	1000		10.1109/TPAMI.2014.2360394	http://dx.doi.org/10.1109/TPAMI.2014.2360394			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CF4PS	26353323				2022-12-18	WOS:000352533000007
J	Yang, YC; Sundaramoorthi, G				Yang, Yanchao; Sundaramoorthi, Ganesh			Shape Tracking with Occlusions via Coarse-to-Fine Region-Based Sobolev Descent	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object segmentation from video; object tracking; deformable templates; occlusions; shape metrics; optical flow	OPTICAL-FLOW ESTIMATION; IMAGE SEGMENTATION; DEFORMING OBJECTS; ACTIVE CONTOURS; DIFFEOMORPHISMS; ALGORITHMS; FRAMEWORK; METRICS; CURVES; MODELS	We present a method to track the shape of an object from video. The method uses a joint shape and appearance model of the object, which is propagated to match shape and radiance in subsequent frames, determining object shape. Self-occlusions and dis-occlusions of the object from camera and object motion pose difficulties to joint shape and appearance models in tracking. They are unable to adapt to new shape and appearance information, leading to inaccurate shape detection. In this work, we model self-occlusions and dis-occlusions in a joint shape and appearance tracking framework. Self-occlusions and the warp to propagate the model are coupled, thus we formulate a joint optimization problem. We derive a coarse-to-fine optimization method, advantageous in tracking, that initially perturbs the model by coarse perturbations before transitioning to finer-scale perturbations seamlessly. This coarse-to-fine behavior is automatically induced by gradient descent on a novel infinite-dimensional Riemannian manifold that we introduce. The manifold consists of planar parameterized regions, and the metric that we introduce is a novel Sobolev metric. Experiments on video exhibiting occlusions/dis-occlusions, complex radiance and background show that occlusion/dis-occlusion modeling leads to superior shape accuracy.	[Yang, Yanchao; Sundaramoorthi, Ganesh] KAUST, Dept Elect Engn, Thuwal, Saudi Arabia; [Sundaramoorthi, Ganesh] KAUST, Dept Appl Math & Computat Sci, Thuwal, Saudi Arabia	King Abdullah University of Science & Technology; King Abdullah University of Science & Technology	Yang, YC (corresponding author), KAUST, Dept Elect Engn, Thuwal, Saudi Arabia.	yanchao.yang@kaust.edu.sa; ganesh.sundaramoorthi@kaust.edu.sa			KAUST Baseline and Visual Computing Center	KAUST Baseline and Visual Computing Center	This work was funded by KAUST Baseline and Visual Computing Center funding.	Alvarez L, 2002, LECT NOTES COMPUT SC, V2350, P721; Ayvaci A., 2011, INT J COMPUT VISION, V6, P1; Bai X, 2010, LECT NOTES COMPUT SC, V6315, P617; Bai X, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531376; Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2; Beg MF, 2005, INT J COMPUT VISION, V61, P139, DOI 10.1023/B:VISI.0000043755.93987.aa; BENARI R, 2007, IEEE 11 INT C COMP V, P1, DOI DOI 10.1109/ICCV.2007.4408996; Bibby C, 2010, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2010.5539818; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286; Charpiat G, 2007, INT J COMPUT VISION, V73, P325, DOI 10.1007/s11263-006-9966-2; Christensen GE, 1996, IEEE T IMAGE PROCESS, V5, P1435, DOI 10.1109/83.536892; Cremers D, 2006, IEEE T PATTERN ANAL, V28, P1262, DOI 10.1109/TPAMI.2006.161; EBIN DG, 1970, ANN MATH, V92, P102, DOI 10.2307/1970699; Evans L. C., 1998, AM MATH SOC, V2; Fan JL, 2012, IEEE T PATTERN ANAL, V34, P1633, DOI 10.1109/TPAMI.2011.257; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Huang XL, 2006, IEEE T PATTERN ANAL, V28, P1303, DOI 10.1109/TPAMI.2006.171; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jackson JD, 2008, INT J COMPUT VISION, V79, P71, DOI 10.1007/s11263-007-0097-1; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855; Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333; Klodt M, 2011, IEEE I CONF COMP VIS, P2236, DOI 10.1109/ICCV.2011.6126502; Lucas B.D., 1981, IJCAI 81 P 7 INT JOI, P674, DOI DOI 10.1109/HPDC.2004.1323531; Mennucci ACG, 2008, INTERFACE FREE BOUND, V10, P423; Michor PW, 2007, APPL COMPUT HARMON A, V23, P74, DOI 10.1016/j.acha.2006.07.004; Michor PW, 2006, J EUR MATH SOC, V8, P1, DOI 10.4171/JEMS/37; Miller MI, 2006, J MATH IMAGING VIS, V24, P209, DOI 10.1007/s10851-005-3624-0; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; Niethammer M, 2008, IEEE T PATTERN ANAL, V30, P1093, DOI 10.1109/TPAMI.2008.28; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758; Paragios N, 2002, J VIS COMMUN IMAGE R, V13, P249, DOI 10.1006/jvci.2001.0475; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Pock T, 2009, PROC CVPR IEEE, P810, DOI 10.1109/CVPRW.2009.5206604; Rathi Y, 2007, IEEE T PATTERN ANAL, V29, P1470, DOI 10.1109/TPAMI.2007.1081; Ricco S, 2012, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2012.6247877; Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591; Strecha C, 2004, LECT NOTES COMPUT SC, V3247, P71; Sundaramoorthi G, 2008, IEEE T PATTERN ANAL, V30, P851, DOI 10.1109/TPAMI.2007.70751; Sundaramoorthi G, 2007, INT J COMPUT VISION, V73, P345, DOI 10.1007/s11263-006-0635-2; Sundaramoorthi G, 2011, SIAM J IMAGING SCI, V4, P109, DOI 10.1137/090781139; Sundberg P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2233, DOI 10.1109/CVPR.2011.5995364; Trouve A, 1998, INT J COMPUT VISION, V28, P213, DOI 10.1023/A:1008001603737; Wirth B, 2011, INT J COMPUT VISION, V93, P293, DOI 10.1007/s11263-010-0416-9; Xiao JJ, 2006, LECT NOTES COMPUT SC, V3951, P211; Yang YC, 2013, IEEE I CONF COMP VIS, P201, DOI 10.1109/ICCV.2013.32; Yezzi A, 2005, IEEE I CONF COMP VIS, P913; Younes L, 2008, REND LINCEI-MAT APPL, V19, P25	55	16	17	0	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2015	37	5					1053	1066		10.1109/TPAMI.2014.2360380	http://dx.doi.org/10.1109/TPAMI.2014.2360380			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CF4PS	26353328	Green Submitted			2022-12-18	WOS:000352533000012
J	Lee, H; Shechtman, E; Wang, J; Lee, S				Lee, Hyunjoon; Shechtman, Eli; Wang, Jue; Lee, Seungyong			Automatic Upright Adjustment of Photographs with Robust Camera Calibration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Upright adjustment; perspective correction; photo aesthetics enhancement; single image camera calibration	PHOTO	Man-made structures often appear to be distorted in photos captured by casual photographers, as the scene layout often conflicts with how it is expected by human perception. In this paper, we propose an automatic approach for straightening up slanted man-made structures in an input image to improve its perceptual quality. We call this type of correction upright adjustment. We propose a set of criteria for upright adjustment based on human perception studies, and develop an optimization framework which yields an optimal homography for adjustment. We also develop a new optimization-based camera calibration method that performs favorably to previous methods and allows the proposed system to work reliably for a wide range of images. The effectiveness of our system is demonstrated by both quantitative comparisons and qualitative user study.	[Lee, Hyunjoon; Lee, Seungyong] Pohang Univ Sci & Technol POSTECH, Dept Comp Sci & Engn, Pohang 790784, South Korea; [Shechtman, Eli; Wang, Jue] Adobe Res, Creat Technol Lab, Seattle, WA 98103 USA	Pohang University of Science & Technology (POSTECH); Adobe Systems Inc.	Lee, H (corresponding author), Pohang Univ Sci & Technol POSTECH, Dept Comp Sci & Engn, Pohang 790784, South Korea.	crowlove@postech.ac.kr; elishe@adobe.com; juewang@adobe.com; leesy@postech.ac.kr	Shechtman, Eli/B-2736-2012; Wang, Jue/GVU-0480-2022	Wang, Jue/0000-0002-3641-3136	Industrial Strategic Technology Development Program of KEIT [KI001820]; IT/SW Creative Research Program of NIPA [NIPA-2012-H0503-12-1008]; Basic Science Research Program of NRF [2012-0008835]	Industrial Strategic Technology Development Program of KEIT; IT/SW Creative Research Program of NIPA; Basic Science Research Program of NRF(National Research Foundation of Korea)	We would like to thank P. Theiner and T. Ratcliff for the use of their photographs in this paper. This work was supported in part by Industrial Strategic Technology Development Program of KEIT (KI001820), IT/SW Creative Research Program of NIPA (NIPA-2012-H0503-12-1008), and Basic Science Research Program of NRF (2012-0008835).	Aiger D, 2012, COMPUT GRAPH FORUM, V31, P439, DOI 10.1111/j.1467-8659.2012.03023.x; [Anonymous], 2010, MATLAB OPT TOOLB; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Carroll R, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778864; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Coughlan J.M., 1999, P ICCV, V2, P941, DOI DOI 10.1109/ICCV.1999.790349; D'Amelio J., 2004, PERSPECTIVE DRAWING; Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23; Denis P, 2008, LECT NOTES COMPUT SC, V5303, P197, DOI 10.1007/978-3-540-88688-4_15; Dhar S, 2011, PROC CVPR IEEE, P1657, DOI 10.1109/CVPR.2011.5995467; Freeman M., 2007, DIGITAL SLR HDB; Gallagher AC, 2005, 2ND CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P460, DOI 10.1109/CRV.2005.84; Hartley R., 2004, MULTIPLE VIEW GEOMET, P213; Ke Yan, 2006, 2006 IEEE COMPUTER S, V1, P419, DOI DOI 10.1109/CVPR.2006.303; Kosecka J, 2002, LECT NOTES COMPUT SC, V2353, P476; Kubovy M., 2003, PSYCHOL PERSPECTIVE; Lagarias JC, 1998, SIAM J OPTIMIZ, V9, P112, DOI 10.1137/S1052623496303470; Lee H, 2012, PROC CVPR IEEE, P877, DOI 10.1109/CVPR.2012.6247761; Liu LG, 2010, COMPUT GRAPH FORUM, V29, P469, DOI 10.1111/j.1467-8659.2009.01616.x; Luo YW, 2008, LECT NOTES COMPUT SC, V5304, P386; Mirzaei F. M., 2011, P ICCV; Park J., 2012, P ICIP; Schindler G, 2004, PROC CVPR IEEE, P203; Tardif JP, 2009, IEEE I CONF COMP VIS, P1250, DOI 10.1109/ICCV.2009.5459328; Tretyak E, 2012, INT J COMPUT VISION, V97, P305, DOI 10.1007/s11263-011-0488-1; Vedaldi A., 2012, P ECCV; von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300; Waltz RA, 2006, MATH PROGRAM, V107, P391, DOI 10.1007/s10107-004-0560-5; Wildenauer H, 2012, PROC CVPR IEEE, P2831, DOI 10.1109/CVPR.2012.6248008; Wong L.-K., 2011, IEEE WORKSH APPL COM, P73; Yao L, 2012, INT J COMPUT VISION, V96, P353, DOI 10.1007/s11263-011-0478-3; Zhang ZD, 2012, INT J COMPUT VISION, V99, P1, DOI 10.1007/s11263-012-0515-x; Zhengdong Zhang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2321, DOI 10.1109/CVPR.2011.5995548	33	16	18	0	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2014	36	5					833	844		10.1109/TPAMI.2013.166	http://dx.doi.org/10.1109/TPAMI.2013.166			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AH3VN	26353220				2022-12-18	WOS:000336054200001
J	Thorpe, C; Li, F; Li, ZJ; Yu, Z; Saunders, D; Yu, JY				Thorpe, Christopher; Li, Feng; Li, Zijia; Yu, Zhan; Saunders, David; Yu, Jingyi			A Coprime Blur Scheme for Data Security in Video Surveillance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video surveillance; greatest common divisor; image deblurring; visual cryptography; CUDA	PRIVACY	This paper presents a novel coprime blurred pair (CBP) model to improve data security in camera surveillance. While most previous approaches have focused on completely encrypting the video stream, we introduce a spatial encryption scheme by strategically blurring the image/video contents. Specifically, we form a public stream and a private stream by blurring the original video data using two different kernels. Each blurred stream will provide the user who has lower clearance less access to personally identifiable details while still allowing behavior to be monitored. If the behavior is recognized as suspicious, a supervisor can use both streams to deblur the contents. Our approach is based on a new CBP theory where the two kernels are coprime when mapped to bivariate polynomials in the z domain. We show that coprimality can be derived in terms of the rank of Bezout matrix [3] formed by sampled polynomials, and we present an efficient algorithm to factor the Bezout matrix for recovering the latent image. To make our solution practical, we implement our decryption scheme on a graphics processing unit (GPU) to achieve real-time performance. Extensive experiments demonstrate that our new scheme can effectively protect sensitive identity information in surveillance videos and faithfully reconstruct the unblurred video stream when both CBP sequences are available.	[Thorpe, Christopher; Yu, Zhan; Saunders, David; Yu, Jingyi] Univ Delaware, Dept Comp & Informat Sci, Newark, DE 19716 USA; [Li, Feng] Qualcomm Technol Inc, San Diego, CA 92121 USA; [Li, Zijia] Johannes Kepler Univ Linz, Doctoral Program Computat Math, A-4040 Linz, Austria; [Li, Zijia] Key Lab Math Mech AMSS, Beijing 100190, Peoples R China	University of Delaware; Qualcomm; Johannes Kepler University Linz	Thorpe, C (corresponding author), Univ Delaware, Dept Comp & Informat Sci, 101E Smith Hall,18 Amstel Ave, Newark, DE 19716 USA.	fengl@qualcomm.com		Li, Zijia/0000-0002-8734-4396	US National Science Foundation (NSF) [IIS-CAREER-0845268, IIS-RI-1016395]; US Air Force Office of Scientific Research under the YIP Award; NKBRPC [2011CB302400]; Chinese NSF [60821002/F02, 60911130369, 10871194]	US National Science Foundation (NSF)(National Science Foundation (NSF)); US Air Force Office of Scientific Research under the YIP Award(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); NKBRPC(National Basic Research Program of China); Chinese NSF(National Natural Science Foundation of China (NSFC))	This project was supported in part by the US National Science Foundation (NSF) under grants IIS-CAREER-0845268 and IIS-RI-1016395, and by the US Air Force Office of Scientific Research under the YIP Award. Z. Li was supported by a NKBRPC 2011CB302400, the Chinese NSF grants 60821002/F02, 60911130369 and 10871194.	Agrawal P, 2011, IEEE T CIRC SYST VID, V21, P299, DOI 10.1109/TCSVT.2011.2105551; Avidan S., 2006, P EUR C COMP VIS; BARNETT S, 1972, SIAM J APPL MATH, V22, P84, DOI 10.1137/0122009; Bayazit M., 2009, P IAPR C MACH VIS AP, P9; Bini DA, 2007, ISSAC 2007: PROCEEDINGS OF THE 2007 INTERNATIONAL SYMPOSIUM ON SYMBOLIC AND ALGEBRAIC COMPUTATION, P9; Brogan W.L., 1991, MODERN CONTROL THEOR, V3rd; Chang Y, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1005, DOI 10.1109/ICME.2006.262703; Chen D., 2007, EURASIP J APPL SIG P, V1, P107; Chen J., 2008, P IEEE C COMP VIS PA; Erkin Z, 2009, LECT NOTES COMPUT SC, V5672, P235, DOI 10.1007/978-3-642-03168-7_14; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; Gathen J.V.Z., 2010, J SYMB COMPUT, V45, P879; Greiner S., 2008, P 34 ANN IEEE NE BIO; Hu N., 2007, ICIP, P1553; Joshi N, 2009, PROC CVPR IEEE, P1550, DOI 10.1109/CVPRW.2009.5206802; Levin A., 2007, P NEUR INF PROC SYST; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; Li F, 2011, IEEE I CONF COMP VIS, P217, DOI 10.1109/ICCV.2011.6126245; Myodo E, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2114; Naor M., 1995, P ADV CRYPT; Newton EM, 2005, IEEE T KNOWL DATA EN, V17, P232, DOI 10.1109/TKDE.2005.32; Rav-Acha A, 2005, PATTERN RECOGN LETT, V26, P311, DOI 10.1016/j.patrec.2004.10.017; RICHARDSON WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055; Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672; SHASHANK J, 2008, P IEEE C COMP VIS PA; Sun DX, 2007, MATH COMPUT SCI, V1, P427, DOI 10.1007/s11786-007-0014-6; Tai YW, 2011, IEEE T PATTERN ANAL, V33, P1603, DOI 10.1109/TPAMI.2010.222; Upmanyu M, 2009, IEEE I CONF COMP VIS, P1639, DOI 10.1109/ICCV.2009.5459370; Wang ZM, 2006, IEEE IMAGE PROC, P109, DOI 10.1109/ICIP.2006.312384; Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5; Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157; Yuan L, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239452; Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249	33	16	16	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2013	35	12					3066	3072		10.1109/TPAMI.2013.161	http://dx.doi.org/10.1109/TPAMI.2013.161			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	245YV	24136441	Green Submitted			2022-12-18	WOS:000326502200020
J	Vemulapalli, PK; Monga, V; Brennan, SN				Vemulapalli, Pramod K.; Monga, Vishal; Brennan, Sean N.			Robust Extrema Features for Time-Series Data Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Time series; pattern recognition; feature extraction; extrema features	REGION	The extraction of robust features for comparing and analyzing time series is a fundamentally important problem. Research efforts in this area encompass dimensionality reduction using popular signal analysis tools such as the discrete Fourier and wavelet transforms, various distance metrics, and the extraction of interest points from time series. Recently, extrema features for analysis of time-series data have assumed increasing significance because of their natural robustness under a variety of practical distortions, their economy of representation, and their computational benefits. Invariably, the process of encoding extrema features is preceded by filtering of the time series with an intuitively motivated filter (e. g., for smoothing), and subsequent thresholding to identify robust extrema. We define the properties of robustness, uniqueness, and cardinality as a means to identify the design choices available in each step of the feature generation process. Unlike existing methods, which utilize filters "inspired" from either domain knowledge or intuition, we explicitly optimize the filter based on training time series to optimize robustness of the extracted extrema features. We demonstrate further that the underlying filter optimization problem reduces to an eigenvalue problem and has a tractable solution. An encoding technique that enhances control over cardinality and uniqueness is also presented. Experimental results obtained for the problem of time series subsequence matching establish the merits of the proposed algorithm.	[Vemulapalli, Pramod K.; Monga, Vishal] Penn State Univ, Dept Elect Engn, University Pk, PA 16802 USA; [Vemulapalli, Pramod K.; Brennan, Sean N.] Penn State Univ, Dept Mech & Nucl Engn, University Pk, PA 16802 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park	Vemulapalli, PK (corresponding author), Penn State Univ, Dept Elect Engn, University Pk, PA 16802 USA.	pkv106@psu.edu; vmonga@engr.psu.edu; sbrennan@psu.edu		Brennan, Sean/0000-0001-9844-6948				Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907; Anstreicher K, 1999, LINEAR ALGEBRA APPL, V301, P121, DOI 10.1016/S0024-3795(99)00205-0; Bourennane E, 2002, SIGNAL PROCESS, V82, P1317, DOI 10.1016/S0165-1684(02)00283-9; Boyd S, 2004, CONVEX OPTIMIZATION; Cai Y., 2004, P ACM SIGMOD INT C M, P599, DOI DOI 10.1145/1007568.1007636; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chakrabarti K., 2002, P ACM SIGMOD, P151; Chan KP, 1999, PROC INT CONF DATA, P126, DOI 10.1109/ICDE.1999.754915; Chen L., 2004, P 30 INT C VERY LARG, V30, P792, DOI [10.1016/B978-012088469-8/50070-X, DOI 10.1016/B978-012088469-8/50070-X]; Chen Q., 2007, P 33 INT C VER LARG, P435; Ding H, 2008, PROC VLDB ENDOW, V1, P1542; Ellis D., 2009, ROBUST LANDMARK BASE; Faloutsos C., 1994, SIGMOD Record, V23, P419, DOI 10.1145/191843.191925; Gandhi H.S., 2010, J EXPT THEORETICAL A, P89; Hauser Kris, 2012, B553 LECT 7 CONSTRAI; Indyk P., 2001, ALGORITHMS NEAREST N; Kadetotad S., 2011, P ASME DYN SYST CONT; Keogh E., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P406; Keogh E., 2001, Knowledge and Information Systems, V3, P263, DOI 10.1007/PL00011669; Keogh E., 2003, WELCOME UCR TIME SER; Keogh Eamonn, 2002, P 8 ACM SIGKDD INT C, P550, DOI DOI 10.1145/775047.775128; Kicey CJ, 1997, J FOURIER ANAL APPL, V3, P63, DOI 10.1007/BF02647947; Korn F., 1997, SIGMOD Record, V26, P289, DOI 10.1145/253262.253332; Lin J, 2007, DATA MIN KNOWL DISC, V15, P107, DOI 10.1007/s10618-007-0064-z; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Marteau PF, 2009, IEEE T PATTERN ANAL, V31, P306, DOI 10.1109/TPAMI.2008.76; McAteer RTJ, 2010, SOL PHYS, V262, P387, DOI 10.1007/s11207-010-9530-7; Monga V, 2006, IEEE T IMAGE PROCESS, V15, P3452, DOI 10.1109/TIP.2006.881948; Perng C.-S., 2000, Proceedings of 16th International Conference on Data Engineering (Cat. No.00CB37073), P33, DOI 10.1109/ICDE.2000.839385; PETROU M, 1991, IEEE T PATTERN ANAL, V13, P483, DOI 10.1109/34.134047; Rath T.M., 2003, P IEEE C COMP VIS PA, V2; STERN RJ, 1995, SIAM J OPTIMIZ, V5, P286, DOI 10.1137/0805016; Van Laerhoven K., 2009, P 8 INT C MACH LEARN; Vemulapalli P., 2011, P AM CONTR C JUN; Vemulapalli PK, 2012, P AMER CONTR CONF, P2189; Vlachos M, 2006, VLDB J, V15, P1, DOI 10.1007/s00778-004-0144-2; Vlachos M, 2002, PROC INT CONF DATA, P673, DOI 10.1109/ICDE.2002.994784; Wang A., 2003, ISMIR, P7; Wang A, 2006, COMMUN ACM, V49, P44, DOI 10.1145/1145287.1145312; Wu D., 1996, P 5 INT C INF KNOWL	40	16	16	1	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2013	35	6					1464	1479		10.1109/TPAMI.2012.216	http://dx.doi.org/10.1109/TPAMI.2012.216			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	129QV	23599059				2022-12-18	WOS:000317857900015
J	Ayvaci, A; Soatto, S				Ayvaci, Alper; Soatto, Stefano			Detachable Object Detection: Segmentation and Depth Ordering from Short-Baseline Video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object detection; video segmentation; occlusion; layers; graph cuts; ordering constraints; model selection	MOTION SEGMENTATION; OCCLUSION; BOUNDARIES	We describe an approach for segmenting a moving image into regions that correspond to surfaces in the scene that are partially surrounded by the medium. It integrates both appearance and motion statistics into a cost functional that is seeded with occluded regions and minimized efficiently by solving a linear programming problem. Where a short observation time is insufficient to determine whether the object is detachable, the results of the minimization can be used to seed a more costly optimization based on a longer sequence of video data. The result is an entirely unsupervised scheme to detect and segment an arbitrary and unknown number of objects. We test our scheme to highlight the potential, as well as limitations, of our approach.	[Ayvaci, Alper; Soatto, Stefano] Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA	University of California System; University of California Los Angeles	Ayvaci, A (corresponding author), Univ Calif Los Angeles, Dept Comp Sci, Boelter Hall,405 Hilgard Ave, Los Angeles, CA 90095 USA.	ayvaci@cs.ucla.edu; soatto@cs.ucla.edu			US Office of Naval Research [N000141110863]; US Army Research Office [56765-CI]; Qualcomm Innovation Fellowship QinF	US Office of Naval Research(Office of Naval Research); US Army Research Office; Qualcomm Innovation Fellowship QinF	This research was supported by US Office of Naval Research N000141110863 and US Army Research Office 56765-CI; A. Ayvaci was also supported by the Qualcomm Innovation Fellowship QinF. This work was originally registered as Technical Report UCLA-CSD-100036.	Amer M., 2010, P INT C IM PROC SEPT; [Anonymous], [No title captured]; Apostoloff N., 2005, P IEEE C COMP VIS PA; Apostoloff N., 2006, P BRIT MACH VIS C; ARBELAEZ P, 2009, P IEEE C COMP VIS PA; Ayvaci A., 2011, P INT C EN MIN METH; Ayvaci A., 2011, INT J COMPUT VISION, V6, P1; Boltz S, 2008, INT J COMPUT VISION, V80, P242, DOI 10.1007/s11263-007-0124-2; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Brendel W, 2009, P IEEE INT C COMP VI; Brostow G., 1999, P IEEE INT C COMP VI; Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21; Chan TF, 2005, SIAM J APPL MATH, V65, P1817, DOI 10.1137/040604297; Cremers D, 2005, INT J COMPUT VISION, V62, P249, DOI 10.1007/s11263-005-4882-4; Fanti C, 2004, ADV NEUR IN, V16, P1603; Feldman D, 2008, IEEE T PATTERN ANAL, V30, P1171, DOI 10.1109/TPAMI.2007.70766; Fulkerson B., 2010, P WORKSH COMP VIS US; Gibson J. J., 1984, ECOLOGICAL APPROACH; Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233; Grant M., 2014, CVX MATLAB SOFTWARE; Grunwald P. D., 2007, MINIMUM DESCRIPTION; He X., 2010, P EUR C COMP VIS; Huang YC, 2009, PROC CVPR IEEE, P1738, DOI 10.1109/CVPRW.2009.5206795; Jackson J.D., 2005, P INT C EN MIN METH; Jackson JD, 2008, INT J COMPUT VISION, V79, P71, DOI 10.1007/s11263-007-0097-1; Jepson AD, 2002, LECT NOTES COMPUT SC, V2350, P692; Kumar MP, 2008, INT J COMPUT VISION, V76, P301, DOI 10.1007/s11263-007-0064-x; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Morel J., 2008, P IND C COMP VIS GRA; Ogale AS, 2005, IEEE T PATTERN ANAL, V27, P988, DOI 10.1109/TPAMI.2005.123; Rother C., 2006, P IEEE C COMP VIS PA; Sargin M. E., 2009, P INT C COMP VIS, p[2233, 2235, 2236, 2239]; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; SINOP AK, 2007, P IEEE INT C COMP VI; Smith P, 2004, IEEE T PATTERN ANAL, V26, P479, DOI 10.1109/TPAMI.2004.1265863; Stein A., 2008, P IEEE C COMP VIS PA; Stein AN, 2009, INT J COMPUT VISION, V82, P325, DOI 10.1007/s11263-008-0203-z; Unger M., 2009, P 7 INT C EN MIN MET; Vazquez-Reina A, 2010, P EUR C COMP VIS; Wang CH, 2009, IEEE I CONF COMP VIS, P747; WANG J, 2004, P ACM SIGGRAPH; Yezzi A, 2003, INT J COMPUT VISION, V53, P31, DOI 10.1023/A:1023079624234	43	16	16	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2012	34	10					1942	1951		10.1109/TPAMI.2011.271	http://dx.doi.org/10.1109/TPAMI.2011.271			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	988WY	22201065	Green Submitted			2022-12-18	WOS:000307522700006
J	Saberian, MJ; Vasconcelos, N				Saberian, Mohammad Javad; Vasconcelos, Nuno			Learning Optimal Embedded Cascades	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; real-time object detection; embedded detector cascades; boosting	ROBUST OBJECT DETECTION; STATISTICAL VIEW; DESIGN; SPARSE	The problem of automatic and optimal design of embedded object detector cascades is considered. Two main challenges are identified: optimization of the cascade configuration and optimization of individual cascade stages, so as to achieve the best tradeoff between classification accuracy and speed, under a detection rate constraint. Two novel boosting algorithms are proposed to address these problems. The first, RCBoost, formulates boosting as a constrained optimization problem which is solved with a barrier penalty method. The constraint is the target detection rate, which is met at all iterations of the boosting process. This enables the design of embedded cascades of known configuration without extensive cross validation or heuristics. The second, ECBoost, searches over cascade configurations to achieve the optimal tradeoff between classification risk and speed. The two algorithms are combined into an overall boosting procedure, RCECBoost, which optimizes both the cascade configuration and its stages under a detection rate constraint, in a fully automated manner. Extensive experiments in face, car, pedestrian, and panda detection show that the resulting detectors achieve an accuracy versus speed tradeoff superior to those of previous methods.	[Saberian, Mohammad Javad; Vasconcelos, Nuno] Univ Calif San Diego, Stat Visual Comp Lab, La Jolla, CA 92093 USA	University of California System; University of California San Diego	Saberian, MJ (corresponding author), Univ Calif San Diego, Stat Visual Comp Lab, Room 5512,9500 Gilman Dr,Mail Code 0407,EBU 1, La Jolla, CA 92093 USA.	saberian@ucsd.edu; nvasconcelos@ucsd.edu		Vasconcelos, Nuno/0000-0002-9024-4302				Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108; [Anonymous], 1999, NUMERICAL OPTIMIZATI; Bourdev L, 2005, PROC CVPR IEEE, P236, DOI 10.1109/cvpr.2005.310; Brubaker SC, 2008, INT J COMPUT VISION, V77, P65, DOI 10.1007/s11263-007-0060-1; Dollar P., 2010, P BRIT MACH VIS C, P681; Dollar P., 2009, P IEEE C COMP VIS PA; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Fan W., 1999, P INT C MACH LEARN; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Fergus R, 2003, PROC CVPR IEEE, P264; Freund Y., 1995, P EUR C COMP LEARN T; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Fritz M, 2005, IEEE I CONF COMP VIS, P1363; Han S., 2011, P IEEE CS C COMP VIS; Hou X., 2006, P IEEE CS C COMP VIS; Jones, 2001, ADV NEUR INF PROC SY; Lampert CH, 2009, IEEE T PATTERN ANAL, V31, P2129, DOI 10.1109/TPAMI.2009.144; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68; Liu C, 2003, PROC CVPR IEEE, P587; Luo HT, 2005, PROC CVPR IEEE, P480; Maji Subhransu, 2008, CVPR, DOI DOI 10.1109/CVPR.2008.4587630; Masnadi-Shirazi H., 2010, P IEEE C COMP VIS PA; Masnadi-Shirazi H., 2007, P IEEE INT C COMP VI; Masnadi-Shirazi H, 2011, IEEE T PATTERN ANAL, V33, P294, DOI 10.1109/TPAMI.2010.71; Mason L., 2000, P ADV NEUR INF PROC; Mease D, 2008, J MACH LEARN RES, V9, P131; Mutch J, 2006, IEEE CVPR, V1, P11, DOI DOI 10.1109/CVPR.2006.200; Pham M., 2008, P IEEE C COMP VIS PA, P1; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Schneiderman H, 2004, PROC CVPR IEEE, P29; Sochman J, 2005, PROC CVPR IEEE, P150; Sochman J., 2009, THESIS CZECH TU; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Ting Kai Ming, 2000, P 17 INT C MACH LEAR, P983; Viola P., 2001, IEEE COMP SOC C COMP; Wald A., 1947, SEQUENTIAL ANAL; Wong A., 2005, P INT C MACH LEARN D; Wu B., 2007, PROC IEEE C COMPUT V, P1, DOI 10.1109/cvpr.2007.383042; Wu JX, 2008, IEEE T PATTERN ANAL, V30, P369, DOI 10.1109/TPAMI.2007.1181; Xiao R, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P709; Xiao R, 2007, IEEE I CONF COMP VIS, P1679; Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757	44	16	17	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2012	34	10					2005	2018		10.1109/TPAMI.2011.281	http://dx.doi.org/10.1109/TPAMI.2011.281			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	988WY	22213762	Green Submitted			2022-12-18	WOS:000307522700011
J	McCarthy, C; Barnes, N				McCarthy, Chris; Barnes, Nick			A Unified Strategy for Landing and Docking Using Spherical Flow Divergence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Robot vision; visuo-motor control; visual navigation; optical flow	TIME-TO-COLLISION; VISUAL CONTROL; FIELD; AVOIDANCE; PARALLAX; HONEYBEES; COMPONENT; MOVEMENT	We present a new visual control input from optical flow divergence enabling the design of novel, unified control laws for docking and landing. While divergence-based time-to-contact estimation is well understood, the use of divergence in visual control currently assumes knowledge of surface orientation, and/or egomotion. There exists no directly observable visual cue capable of supporting approaches to surfaces of arbitrary orientation under general motion. Central to our measure is the use of the maximum flow field divergence on the view sphere (max-div). We prove kinematic properties governing the location of max-div, and show that max-div provides a temporal measure of proximity. From this, we contribute novel control laws for regulating both approach velocity and angle of approach toward planar surfaces of arbitrary orientation, without structure-from-motion recovery. The strategy is tested in simulation, over real image sequences and in closed-loop control of docking/landing maneuvers on a mobile platform.	[McCarthy, Chris; Barnes, Nick] Australian Natl Univ, NICTA Canberra Res Lab, Canberra, ACT 2601, Australia; [McCarthy, Chris; Barnes, Nick] Australian Natl Univ, Coll Engn & Comp Sci, Canberra, ACT 2601, Australia	Australian National University; Australian National University	McCarthy, C (corresponding author), Australian Natl Univ, NICTA Canberra Res Lab, Tower A,7 London Circuit, Canberra, ACT 2601, Australia.	chris.mccarthy@nicta.com.au; nick.barnes@nicta.com.au	Barnes, Nick/Y-2744-2018	Barnes, Nick/0000-0002-9343-9535; McCarthy, Chris/0000-0003-3848-1631	Australian Government; Australian Research Council through the ICT Centre of Excellence	Australian Government(Australian GovernmentCGIAR); Australian Research Council through the ICT Centre of Excellence(Australian Research Council)	NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the Australian Research Council through the ICT Centre of Excellence Program.	Ancona N., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P209, DOI 10.1109/ICCV.1993.378218; Badia SBI, 2007, INT J ROBOT RES, V26, P759, DOI 10.1177/0278364907080253; Bouguet Jean yves, 2000, PYRAMIDAL IMPLEMENTA, P1; Brodsky T, 1998, INT J COMPUT VISION, V26, P5, DOI 10.1023/A:1007928406666; Chahl JS, 2004, INT J ROBOT RES, V23, P101, DOI 10.1177/0278364904041320; Cipolla R, 1997, INT J ROBOT RES, V16, P77, DOI 10.1177/027836499701600106; Colombo C., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P220, DOI 10.1109/ICCV.1999.791223; Coombs D, 1998, IEEE T ROBOTIC AUTOM, V14, P49, DOI 10.1109/70.660840; Duric Z, 1999, INT J COMPUT VISION, V31, P83, DOI 10.1023/A:1008098810511; Green WE, 2004, IEEE INT CONF ROBOT, P2347, DOI 10.1109/ROBOT.2004.1307412; KOENDERINK JJ, 1975, OPT ACTA, V22, P773, DOI 10.1080/713819112; KOENDERINK JJ, 1976, J OPT SOC AM, V66, P717, DOI 10.1364/JOSA.66.000717; KOENDERINK JJ, 1981, J OPT SOC AM, V71, P953, DOI 10.1364/JOSA.71.000953; LEE DN, 1976, PERCEPTION, V5, P437, DOI 10.1068/p050437; LEE DN, 1993, J EXP BIOL, V180, P85; Lourakis M. I. A., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P640, DOI 10.1109/CVPR.1999.784993; Lucas B. D., 1981, IJCAI, P121, DOI DOI 10.5555/1623264.1623280; McCarthy C, 2008, IEEE T ROBOT, V24, P832, DOI 10.1109/TRO.2008.926871; MEYER FG, 1994, IEEE T ROBOTIC AUTOM, V10, P792, DOI 10.1109/70.338534; NELSON RC, 1989, IEEE T PATTERN ANAL, V11, P1102, DOI 10.1109/34.42840; QUESTA P, 1995, P SOC PHOTO-OPT INS, V2488, P274, DOI 10.1117/12.211980; Questa P, 1996, IROS 96 - PROCEEDINGS OF THE 1996 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - ROBOTIC INTELLIGENCE INTERACTING WITH DYNAMIC WORLDS, VOLS 1-3, P1622, DOI 10.1109/IROS.1996.569029; Rind FC, 1997, FROM LIVING EYES TO SEEING MACHINES, P105; ROBERTSON RM, 1993, J EXP BIOL, V183, P35; Ruffier F, 2005, ROBOT AUTON SYST, V50, P177, DOI 10.1016/j.robot.2004.09.016; SantosVictor J, 1996, MACH VISION APPL, V9, P130, DOI 10.1007/BF01216818; SantosVictor J, 1997, COMPUT VIS IMAGE UND, V67, P223, DOI 10.1006/cviu.1997.0528; Srinivasan MV, 2000, BIOL CYBERN, V83, P171, DOI 10.1007/s004220000162; SUBBARAO M, 1990, COMPUT VISION GRAPH, V50, P329, DOI 10.1016/0734-189X(90)90151-K; TISTARELLI M, 1993, IEEE T PATTERN ANAL, V15, P401, DOI 10.1109/34.206959; WAGNER H, 1982, NATURE, V297, P147, DOI 10.1038/297147a0; Zufferey JC, 2006, IEEE T ROBOT, V22, P137, DOI 10.1109/TRO.2005.858857	32	16	18	0	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2012	34	5					1024	U		10.1109/TPAMI.2012.27	http://dx.doi.org/10.1109/TPAMI.2012.27			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	911VJ	22248631				2022-12-18	WOS:000301747400015
J	Singaraju, D; Vidal, R				Singaraju, Dheeraj; Vidal, Rene			Estimation of Alpha Mattes for Multiple Image Layers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image matting; alpha matte; multiple layers; matting Laplacian; superposition principle		Image matting deals with the estimation of the alpha matte at each pixel, i.e., the contribution of the foreground and background objects to the composition of the image at that pixel. Existing methods for image matting are typically limited to estimating the alpha mattes for two image layers only. However, in several applications one is interested in editing images with multiple objects. In this work, we consider the problem of estimating the alpha mattes of multiple (n >= 2) image layers. We show that this problem can be decomposed into n simpler subproblems of alpha matte estimation for two image layers. Moreover, we show that, by construction, the estimated alpha mattes at each pixel are constrained to sum up to 1 across the multiple image layers. A key feature of our framework is that the alpha mattes can be estimated in closed form. We further show that, due to the nature of spatial regularization used in the estimation, the final estimated alpha mattes are not constrained to take values in [0, 1]. Hence, we study the optimization problem of estimating the alpha mattes for multiple image layers subject to the fact that the alpha mattes are nonnegative and sum up to 1 at each pixel. We present experiments to show that our proposed method can be used to extract mattes of multiple image layers.	[Singaraju, Dheeraj; Vidal, Rene] Johns Hopkins Univ, Dept Biomed Engn, Ctr Imaging Sci, Baltimore, MD 21218 USA	Johns Hopkins University	Singaraju, D (corresponding author), Johns Hopkins Univ, Dept Biomed Engn, Ctr Imaging Sci, Clark Hall,3400 N Charles St, Baltimore, MD 21218 USA.	dheeraj@cis.jhu.edu; rvidal@cis.jhu.edu	Vidal, Rene/A-3367-2010		Johns Hopkins University; US Office of Naval Research [YIP N00014-09-1-0839]	Johns Hopkins University(Johns Hopkins University); US Office of Naval Research(Office of Naval Research)	This work was supported by Johns Hopkins University startup funds and US Office of Naval Research Grant YIP N00014-09-1-0839. The authors would like to thank Dr. Carsten Rother and Dr. Christoph Rhemann for providing the data set used in [17] and also Dr. Anat Levin for making the images and code of [11] and [14] publicly available. They would also like to thank Stuart Chandler for providing the image of the feathers used in Figs. 11, 12, and 13.	Bai X., 2007, P IEEE INT C COMP VI; Berman A., 2000, U. S. Patent, Patent No. 6134346; Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14; Bleyer M, 2009, PROC CVPR IEEE, P501, DOI 10.1109/CVPRW.2009.5206656; Chuang YY, 2001, PROC CVPR IEEE, P264; Cohen M. F., 2007, P IEEE C COMP VIS PA; Doyle P. G., 1984, RANDOM WALKS ELECT N; Grady L, 2005, PROCEEDINGS OF THE FIFTH IASTED INTERNATIONAL CONFERENCE ON VISUALIZATION, IMAGING, AND IMAGE PROCESSING, P423; Grady L., 2008, 2008 IEEE C COMP VIS, P1; Guan Y, 2006, COMPUT GRAPH FORUM, V25, P567, DOI 10.1111/j.1467-8659.2006.00976.x; Hsu E, 2008, ACM T GRAPHIC, V27, DOI [10.1145/1399504.1360669, 10.1145/1360612.1360669]; Kuhn H., 1951, P 2 BERK S MATH STAT, P481, DOI DOI 10.1007/BF01582292; Levin A, 2008, IEEE T PATTERN ANAL, V30, P1699, DOI 10.1109/TPAMI.2008.168; Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177; Omer I, 2004, PROC CVPR IEEE, P946; Rhemann C., 2008, P IEEE C COMP VIS PA; Rhemann C, 2009, PROC CVPR IEEE, P1826, DOI 10.1109/CVPRW.2009.5206503; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Ruzon MA, 2000, PROC CVPR IEEE, P18, DOI 10.1109/CVPR.2000.855793; Shan Q, 2007, IEEE I CONF COMP VIS, P738; SINGARAJU D, 2008, P IEEE C COMP VIS PA; Singaraju D, 2009, PROC CVPR IEEE, P659, DOI 10.1109/CVPRW.2009.5206491; Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721; Wang J, 2005, IEEE I CONF COMP VIS, P936; Wang J, 2007, FOUND TRENDS COMPUT, V3, P97, DOI 10.1561/0600000019; Zheng Y., 2008, P IEEE C COMP VIS PA	26	16	17	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2011	33	7					1295	1309		10.1109/TPAMI.2010.206	http://dx.doi.org/10.1109/TPAMI.2010.206			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	763QE	21135445	Green Submitted			2022-12-18	WOS:000290574000002
J	Peng, B; Qian, G				Peng, Bo; Qian, Gang			Online Gesture Spotting from Visual Hull Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Online gesture spotting; view invariance; multilinear analysis; visual hull; hidden Markov models; nongesture models	SIGN-LANGUAGE RECOGNITION; MODEL; ALGORITHM	This paper presents a robust framework for online full-body gesture spotting from visual hull data. Using view-invariant pose features as observations, hidden Markov models (HMMs) are trained for gesture spotting from continuous movement data streams. Two major contributions of this paper are 1) view-invariant pose feature extraction from visual hulls, and 2) a systematic approach to automatically detecting and modeling specific nongesture movement patterns and using their HMMs for outlier rejection in gesture spotting. The experimental results have shown the view-invariance property of the proposed pose features for both training poses and new poses unseen in training, as well as the efficacy of using specific nongesture models for outlier rejection. Using the IXMAS gesture data set, the proposed framework has been extensively tested and the gesture spotting results are superior to those reported on the same data set obtained using existing state-of-the-art gesture spotting methods.	[Peng, Bo; Qian, Gang] Sch Arts Media & Engn, Tempe, AZ 85281 USA		Peng, B (corresponding author), Sch Arts Media & Engn, 699 S Mill Ave,Suite 395,POB 878709, Tempe, AZ 85281 USA.	bpeng3@asu.edu; gqian@ieee.org			US National Science Foundation [RI-04-03428, DGE-05-04647]	US National Science Foundation(National Science Foundation (NSF))	This work was supported in part by US National Science Foundation grants RI-04-03428 and DGE-05-04647. The authors are thankful to the referees for their insightful comments and to Stjepan Rajko for developing and releasing the reduced HMM code to the public and proofreading an early version of the paper.	Alon J, 2009, IEEE T PATTERN ANAL, V31, P1685, DOI 10.1109/TPAMI.2008.203; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Bobick AF, 1998, PROC CVPR IEEE, P196, DOI 10.1109/CVPR.1998.698609; Camurri A, 2000, COMPUT MUSIC J, V24, P57, DOI 10.1162/014892600559182; Camurri A, 2003, J VISUAL COMP ANIMAT, V14, P269, DOI 10.1002/vis.324; CHU C, 2005, P CVPR, P69; CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892; Davis JW, 2003, IMAGE VISION COMPUT, V21, P1001, DOI 10.1016/S0262-8856(03)00138-0; Dietterich T.G., 2002, P JOINT IAPR INT WOR, V2396, P15; Eickeler S, 1998, INT C PATT RECOG, P1206, DOI 10.1109/ICPR.1998.711914; Elden L, 2007, FUND ALGORITHMS, V4, pIX, DOI 10.1137/1.9780898718867; Francke H, 2007, LECT NOTES COMPUT SC, V4872, P533; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Holte MB, 2008, INT CONF ACOUST SPEE, P797, DOI 10.1109/ICASSP.2008.4517730; Keskin Cem, 2007, 2007 3DTV C, P1, DOI [10.1109/3DTV.2007.4379488, DOI 10.1109/3DTV.2007.4379488]; KIERS HAL, 1993, COMPUT STAT DATA AN, V16, P103, DOI 10.1016/0167-9473(93)90247-Q; Kirishima T, 2005, IEEE T PATTERN ANAL, V27, P351, DOI 10.1109/TPAMI.2005.61; LATHAUWER LD, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI DOI 10.1137/S0895479896305696; Lee CK, 2007, 13TH INTERNATIONAL WORKSHOP ON THERMAL INVESTIGATION OF ICS AND SYSTEMS, PROCEEDINGS, P48; Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904; Lee SW, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P645; Lichtenauer JF, 2008, IEEE T PATTERN ANAL, V30, P2040, DOI 10.1109/TPAMI.2008.123; LV F, 2007, P IEEE C COMP VIS PA; McCallum Andrew, 2000, P 17 INT C MACH LEAR, P591; Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280; MYERS C, 1980, IEEE T ACOUST SPEECH, V28, P623, DOI 10.1109/TASSP.1980.1163491; Nickel K, 2007, IMAGE VISION COMPUT, V25, P1875, DOI 10.1016/j.imavis.2005.12.020; Parameswaran V, 2006, INT J COMPUT VISION, V66, P83, DOI 10.1007/s11263-005-3671-4; Park HS, 2006, LECT NOTES COMPUT SC, V4319, P662; PENG B, 2009, P INT C DISTR SMART; Peng B, 2008, PROC CVPR IEEE, P144; Peng B, 2009, ADV PATTERN RECOGNIT, P215, DOI 10.1007/978-1-84882-299-3_10; Pereira F. C. N., 2001, P 18 INT C MACH LEAR, P282; Pikrakis A, 2003, IEEE T SPEECH AUDI P, V11, P175, DOI 10.1109/TSA.2003.811533; Qian G, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1579; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rajko S., 2007, P IEEE C COMP VIS PA, P1; Rajko S., 2008, 8 IEEE INT C AUT FAC, P1; SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055; Shen YP, 2009, IEEE T PATTERN ANAL, V31, P1898, DOI 10.1109/TPAMI.2009.41; Shi JB, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P943, DOI 10.1109/ICIP.1998.723676; Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811; Starner T, 2003, MACH VISION APPL, V14, P59, DOI 10.1007/s00138-002-0096-8; Vasilescu M.A.O., 2002, P EUR C COMP VIS, P447; Vasilescu MAO, 2004, ACM T GRAPHIC, V23, P336, DOI 10.1145/1015706.1015725; Vasilescu MAO, 2002, INT C PATT RECOG, P456, DOI 10.1109/ICPR.2002.1047975; Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209; Weinland D, 2007, IEEE I CONF COMP VIS, P170; Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013; Yang HD, 2007, IEEE T ROBOT, V23, P256, DOI 10.1109/TRO.2006.889491; Yang HD, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P231; Yang HD, 2009, IEEE T PATTERN ANAL, V31, P1264, DOI 10.1109/TPAMI.2008.172; Ye G., 2004, P IEEE C COMP VIS PA, P160; Ye GQ, 2004, MACH VISION APPL, V16, P13, DOI 10.1007/s00138-004-0159-0; Yilmaz A, 2005, IEEE I CONF COMP VIS, P150; Zhu YX, 2002, COMPUT VIS IMAGE UND, V85, P189, DOI 10.1006/cviu.2002.0967	56	16	16	1	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2011	33	6					1175	1188		10.1109/TPAMI.2010.199	http://dx.doi.org/10.1109/TPAMI.2010.199			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	750DE	21079277				2022-12-18	WOS:000289524000008
J	Sandhu, R; Dambreville, S; Yezzi, A; Tannenbaum, A				Sandhu, Romeil; Dambreville, Samuel; Yezzi, Anthony; Tannenbaum, Allen			A Nonrigid Kernel-Based Framework for 2D-3D Pose Estimation and 2D Image Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D pose estimation; image segmentation; statistical learning; kernel PCA	ACTIVE CONTOURS; REGISTRATION; GRADIENT; SPACE; MODEL	In this work, we present a nonrigid approach to jointly solving the tasks of 2D-3D pose estimation and 2D image segmentation. In general, most frameworks that couple both pose estimation and segmentation assume that one has exact knowledge of the 3D object. However, under nonideal conditions, this assumption may be violated if only a general class to which a given shape belongs is given (e. g., cars, boats, or planes). Thus, we propose to solve the 2D-3D pose estimation and 2D image segmentation via nonlinear manifold learning of 3D embedded shapes for a general class of objects or deformations for which one may not be able to associate a skeleton model. Thus, the novelty of our method is threefold: First, we present and derive a gradient flow for the task of nonrigid pose estimation and segmentation. Second, due to the possible nonlinear structures of one's training set, we evolve the preimage obtained through kernel PCA for the task of shape analysis. Third, we show that the derivation for shape weights is general. This allows us to use various kernels, as well as other statistical learning methodologies, with only minimal changes needing to be made to the overall shape evolution scheme. In contrast with other techniques, we approach the nonrigid problem, which is an infinite-dimensional task, with a finite-dimensional optimization scheme. More importantly, we do not explicitly need to know the interaction between various shapes such as that needed for skeleton models as this is done implicitly through shape learning. We provide experimental results on several challenging pose estimation and segmentation scenarios.	[Sandhu, Romeil; Yezzi, Anthony] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA; [Tannenbaum, Allen] Georgia Inst Technol, Dept Biomed Engn, Atlanta, GA 30318 USA; [Dambreville, Samuel] Boston Consulting Grp Inc, Boston, MA USA; [Tannenbaum, Allen] Technion Israel Inst Technol, Dept Elect Engn, Sch Elect Engn, IL-32000 Haifa, Israel	University System of Georgia; Georgia Institute of Technology; University System of Georgia; Georgia Institute of Technology; Boston Consulting Group (BCG); Technion Israel Institute of Technology	Sandhu, R (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.	rsandhu@gatech.edu; dambreville_samuel@yahoo.fr; anthony.yezzi@ece.gatech.edu; tannenba@ece.gatech.edu	Yezzi, Anthony/AAB-4235-2020		US National Science Foundation (NSF); US Air Force Office of Scientific Research; US Army Research Office; US National Institutes of Health (NIH) through Brigham and Women's Hospital [NAC P41 RR-13218]; National Institutes of Health through the NIH Roadmap for Medical Research [U54 EB005149]; NATIONAL CENTER FOR RESEARCH RESOURCES [P41RR013218, U41RR019703] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [P41EB015902, U54EB005149] Funding Source: NIH RePORTER	US National Science Foundation (NSF)(National Science Foundation (NSF)); US Air Force Office of Scientific Research(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); US Army Research Office; US National Institutes of Health (NIH) through Brigham and Women's Hospital(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); National Institutes of Health through the NIH Roadmap for Medical Research(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NATIONAL CENTER FOR RESEARCH RESOURCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR)); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB))	This work was supported in part by grants from the US National Science Foundation (NSF), the US Air Force Office of Scientific Research, the US Army Research Office, as well as by a grant from the US National Institutes of Health (NIH) (NAC P41 RR-13218) through Brigham and Women's Hospital. This work is part of the National Alliance for Medical Image Computing (NAMIC) funded by the National Institutes of Health through the NIH Roadmap for Medical Research, Grant U54 EB005149. Information on the National Centers for Biomedical Computing can be obtained from http://nihroadmap.nih.gov/bioinformatics.	BALAN AO, 2007, P IEEE C COMP VIS PA; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; BOWDEN R, 1998, P BRIT MACH VIS C U, V2, P904; Bray M, 2006, LECT NOTES COMPUT SC, V3952, P642; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Charles GW, 2007, P CVPR, P1; Charpiat G, 2007, INT J COMPUT VISION, V73, P325, DOI 10.1007/s11263-006-9966-2; Charpiat G, 2005, FOUND COMPUT MATH, V5, P1, DOI 10.1007/s10208-003-0094-x; Cremers D, 2003, PATTERN RECOGN, V36, P1929, DOI 10.1016/S0031-3203(03)00056-6; DAMBREVILLE S, 2008, THESIS GEORGIA I TEC; DAMBREVILLE S, 2008, P EUR C COMP VIS; Dambreville S, 2008, IEEE T PATTERN ANAL, V30, P1385, DOI 10.1109/TPAMI.2007.70774; Debreuve E, 2007, J MATH IMAGING VIS, V28, P47, DOI 10.1007/s10851-007-0012-y; Deutscher J, 2005, INT J COMPUT VISION, V61, P185, DOI 10.1023/B:VISI.0000043757.18370.9c; DHOME M, 1989, IEEE T PATTERN ANAL, V11, P1265, DOI 10.1109/34.41365; DRUMMOND T, 2000, P EUR C COMP VIS; Gonzalez R., 2001, DIGITAL IMAGE PROCES, V2; HAN F, 2003, P INT WORKSH HIGH LE, V2; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Jin HL, 2003, PROC CVPR IEEE, P171; Kichenassamy S, 1996, ARCH RATION MECH AN, V134, P275, DOI 10.1007/BF00379537; Kohli P, 2008, INT J COMPUT VISION, V79, P285, DOI 10.1007/s11263-007-0120-6; Kwok JTY, 2004, IEEE T NEURAL NETWOR, V15, P1517, DOI 10.1109/TNN.2004.837781; Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835; Ma Yi, 2001, INVITATION 3D VISION; Marchand E, 2001, IMAGE VISION COMPUT, V19, P941, DOI 10.1016/S0262-8856(01)00054-3; Michailovich O, 2007, IEEE T IMAGE PROCESS, V16, P2787, DOI 10.1109/TIP.2007.908073; Mika S., 1999, ADV NEURAL INFORM PR, V11; Paragios N, 2002, J VIS COMMUN IMAGE R, V13, P249, DOI 10.1006/jvci.2001.0475; Quan L, 1999, IEEE T PATTERN ANAL, V21, P774, DOI 10.1109/34.784291; RATHI Y, 2005, P IEEE C COMP VIS PA; Rathi Y, 2006, PROC SPIE, V6064, DOI 10.1117/12.641417; Riklin-Raviv T, 2005, IEEE I CONF COMP VIS, P204; Rosenhahn B, 2005, INT J COMPUT VISION, V62, P267, DOI 10.1007/s11263-005-4883-3; Rosenhahn B, 2007, INT J COMPUT VISION, V73, P243, DOI [10.1007/s11263-006-9965-3, 10.1007/S11263-006-9965-3]; Rosenhahn B, 2006, LECT NOTES COMPUT SC, V4174, P495; ROTHER D, 2009, P INT C COMP VIS; Sandhu R., 2009, P IEEE C COMP VIS PA; Schmaltz C, 2007, LECT NOTES COMPUT SC, V4478, P56; Snow D, 2000, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2000.855839; Sofka M., P 2007 IEEE C COMP V, P1; Taron M, 2009, IEEE T PATTERN ANAL, V31, P99, DOI 10.1109/TPAMI.2008.36; Tsai A, 2003, IEEE T MED IMAGING, V22, P137, DOI 10.1109/TMI.2002.808355; Unal G, 2007, IEEE T PATTERN ANAL, V29, P1322, DOI 10.1109/TPAMI.2007.1035; Yezzi A, 2003, INT J COMPUT VISION, V53, P31, DOI 10.1023/A:1023079624234	49	16	16	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2011	33	6					1098	1115		10.1109/TPAMI.2010.162	http://dx.doi.org/10.1109/TPAMI.2010.162			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	750DE	20733218	Green Accepted			2022-12-18	WOS:000289524000003
J	Shafait, F; Breuel, TM				Shafait, Faisal; Breuel, Thomas M.			The Effect of Border Noise on the Performance of Projection-Based Page Segmentation Methods	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Document page segmentation; OCR; performance evaluation; border noise removal; document cleanup	DOCUMENT IMAGE-ANALYSIS	Projection methods have been used in the analysis of bitonal document images for different tasks such as page segmentation and skew correction for more than two decades. However, these algorithms are sensitive to the presence of border noise in document images. Border noise can appear along the page border due to scanning or photocopying. Over the years, several page segmentation algorithms have been proposed in the literature. Some of these algorithms have come into widespread use due to their high accuracy and robustness with respect to border noise. This paper addresses two important questions in this context: 1) Can existing border noise removal algorithms clean up document images to a degree required by projection methods to achieve competitive performance? 2) Can projection methods reach the performance of other state-of-the-art page segmentation algorithms (e.g., Docstrum or Voronoi) for documents where border noise has successfully been removed? We perform extensive experiments on the University of Washington (UW-III) data set with six border noise removal methods. Our results show that although projection methods can achieve the accuracy of other state-of-the-art algorithms on the cleaned document images, existing border noise removal techniques cannot clean up documents captured under a variety of scanning conditions to the degree required to achieve that accuracy.	[Shafait, Faisal] German Res Ctr Artificial Intelligence DFKI GmbH, Multimedia Anal & Data Min MADM Competence Ctr, D-67663 Kaiserslautern, Germany; [Breuel, Thomas M.] Tech Univ Kaiserslautern, Dept Comp Sci, D-67663 Kaiserslautern, Germany	German Research Center for Artificial Intelligence (DFKI); University of Kaiserslautern	Shafait, F (corresponding author), German Res Ctr Artificial Intelligence DFKI GmbH, Multimedia Anal & Data Min MADM Competence Ctr, D-67663 Kaiserslautern, Germany.	faisal.shafait@dfki.de; tmb@informatik.uni-kl.de	Shafait, Faisal/A-1342-2012	Shafait, Faisal/0000-0002-0922-0566	BMBF (German Federal Ministry of Education and Research) [01 IW 07001]	BMBF (German Federal Ministry of Education and Research)(Federal Ministry of Education & Research (BMBF))	This work was partially funded by the BMBF (German Federal Ministry of Education and Research), project PaREn (01 IW 07001).	AVILA BT, 2004, P INT C IM AN REC SE, P249; Bagdanov A, 1997, PROC INT CONF DOC, P401, DOI 10.1109/ICDAR.1997.619878; BAIRD HS, 1987, P SOC PHOTOGRAPHIC S, V40, P21; Breuel TM, 2002, LECT NOTES COMPUT SC, V2423, P188; BREUEL TM, 2008, P SPIE DOC REC RETR, pF1; Cattoni R., 1998, GEOMETRIC LAYOUT ANA; Cinque L, 2002, PATTERN RECOGN, V35, P1167, DOI 10.1016/S0031-3203(01)00082-6; Fan KC, 2002, PATTERN RECOGN, V35, P2593, DOI 10.1016/S0031-3203(01)00205-9; Guyon Isabelle, 1997, HDB CHARACTER RECOGN, P779; HA J, 1995, P 3 INT C DOC AN REC, P1119; Kanai J., 1998, International Journal on Document Analysis and Recognition, V1, P43; Kise K, 1998, COMPUT VIS IMAGE UND, V70, P370, DOI 10.1006/cviu.1998.0684; KRISHNAMOORTHY M, 1993, IEEE T PATTERN ANAL, V15, P737, DOI 10.1109/34.221173; Mao S, 2001, IEEE T PATTERN ANAL, V23, P242, DOI 10.1109/34.910877; Mao S., 2002, INT J DOC ANAL RECOG, V4, P205; Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820; NAGY G, 1992, COMPUTER, V25, P10, DOI 10.1109/2.144436; NAGY G, 1984, P 7 INT C PATT REC M, P347; Nagy G, 2009, IEEE T PATTERN ANAL, V31, P762, DOI 10.1109/TPAMI.2008.192; OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677; Peerawit W., 2004, P 4 INF COMP ENG POS; Shafait F, 2009, P 13 IEEE INT MULT C; Shafait F, 2008, INT J DOC ANAL RECOG, V11, P81, DOI 10.1007/s10032-008-0071-7; Shafait F, 2008, IEEE T PATTERN ANAL, V30, P941, DOI 10.1109/TPAMI.2007.70837; Shafait F, 2007, LECT NOTES COMPUT SC, V4522, P651; Shafait F, 2006, INT C PATT RECOG, P872; Shafait F, 2009, IEEE T PATTERN ANAL, V31, P763, DOI 10.1109/TPAMI.2008.220; Stamatopoulos N., 2007, P 2 INT WORKSH CAM B, P71; Sylwester D., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P615, DOI 10.1109/ICDAR.1995.601971; WONG KY, 1982, IBM J RES DEV, V26, P647, DOI 10.1147/rd.266.0647	30	16	16	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2011	33	4					846	851		10.1109/TPAMI.2010.194	http://dx.doi.org/10.1109/TPAMI.2010.194			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	721QT	21330690				2022-12-18	WOS:000287370400015
J	Wang, HZ; Oliensis, J				Wang, Hongzhi; Oliensis, John			Rigid Shape Matching by Segmentation Averaging	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Shape matching; image segmentation; mutual information	OBJECT RECOGNITION; IMAGE SEGMENTATION; SPACE	We use segmentations to match images by shape. The new matching technique does not require point-to-point edge correspondence and is robust to small shape variations and spatial shifts. To address the unreliability of segmentations computed bottom-up, we give a closed form approximation to an average over all segmentations. Our method has many extensions, yielding new algorithms for tracking, object detection, segmentation, and edge-preserving smoothing. For segmentation, instead of a maximum a posteriori approach, we compute the "central" segmentation minimizing the average distance to all segmentations of an image. For smoothing, instead of smoothing images based on local structures, we smooth based on the global optimal image structures. Our methods for segmentation, smoothing, and object detection perform competitively, and we also show promising results in shape-based tracking.	[Wang, Hongzhi] Univ Penn, Sch Med, Dept Radiol, PICSL, Philadelphia, PA 19104 USA; [Oliensis, John] Stevens Inst Technol, Dept Comp Sci, Hoboken, NJ 07030 USA	University of Pennsylvania; Stevens Institute of Technology	Wang, HZ (corresponding author), Univ Penn, Sch Med, Dept Radiol, PICSL, 3600 Market St,Suite 320, Philadelphia, PA 19104 USA.	hongzhiw@mail.med.upenn.edu; oliensis@cs.stevens.edu						Agarwal S., 2002, P EUR C COMP VIS; AHUJA N, 2007, P INT C COMP VIS; BARROW HG, 1977, P 5 INT JOINT C ART; Basri R, 1997, INT J COMPUT VISION, V25, P145, DOI 10.1023/A:1007919917506; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Berg A., 2005, P IEEE C COMP VIS PA; BERG A, 2001, P IEEE C COMP VIS PA; Borenstein E, 2008, IEEE T PATTERN ANAL, V30, P2109, DOI 10.1109/TPAMI.2007.70840; Bosch A., 2007, P ACM INT C IM VID R; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; CHARPIAT G, 2007, P IEEE C COMP VIS PA; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Dalal N., 2005, HISTOGRAMS ORIENTED; DINH HQ, 2006, P IEEE C COMP VIS PA; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144; Ferrari V, 2006, INT J COMPUT VISION, V67, P159, DOI 10.1007/s11263-005-3964-7; Gdalyahu Y, 2001, IEEE T PATTERN ANAL, V23, P1053, DOI 10.1109/34.954598; HUANG CY, 1997, P IEEE C COMP VIS PA; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; JOJIC N, 2004, P IEEE C COMP VIS PA; Joshi S, 2004, NEUROIMAGE, V23, pS151, DOI 10.1016/j.neuroimage.2004.07.068; Jurie F., 2005, P INT C COMP VIS; Lazebnik S., 2006, P IEEE C COMP VIS PA; LEIBE B, 2004, P EUR C COMP VIS WOR; Levin A, 2009, INT J COMPUT VISION, V81, P105, DOI 10.1007/s11263-008-0166-0; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MARTIN D, 2001, P INT C COMP VIS; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; MEILA M, 2003, P C LEARN THEOR; Opelt A., 2006, P EUR C COMP VIS; OPELT A, 2006, P BRIT MACH VIS C; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; REN X, 2003, P INT C COMP VIS; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Russakoff D. B., 2004, P EUR C COMP VIS; Russell B. C., 2006, P IEEE C COMP VIS PA; Sharon E, 2006, NATURE, V442, P810, DOI 10.1038/nature04977; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shotton J, 2008, IEEE T PATTERN ANAL, V30, P1270, DOI 10.1109/TPAMI.2007.70772; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; STAUFFER C, 2001, P IEEE C COMP VIS PA; Sundar H., 2003, P SHAP MOD INT; Tomasi C., 1998, P INT C COMP VIS; Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; WANG H, 2008, P EUR C COMP VIS; Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109; Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005; YOUNG WE, 1969, J FINANC QUANT ANAL, V4, P179, DOI 10.2307/2329839; YU SX, 2002, P NEUR INF PROC SYST; ZHU L. L., 2008, P EUR C COMP VIS; Zhu SC, 1996, INT J COMPUT VISION, V20, P187	54	16	16	2	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2010	32	4					619	635		10.1109/TPAMI.2009.199	http://dx.doi.org/10.1109/TPAMI.2009.199			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	555XA	20224119				2022-12-18	WOS:000274548800005
J	Chen, YH; Zhu, L; Yuille, A; Zhang, HJ				Chen, Yuanhao; Zhu, Long (Leo); Yuille, Alan; Zhang, Hongjiang			Unsupervised Learning of Probabilistic Object Models (POMs) for Object Classification, Segmentation, and Recognition Using Knowledge Propagation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Unsupervised learning; object classification; segmentation; recognition		We present a method to learn probabilistic object models (POMs) with minimal supervision, which exploit different visual cues and perform tasks such as classification, segmentation, and recognition. We formulate this as a structure induction and learning task and our strategy is to learn and combine elementary POMs that make use of complementary image cues. We describe a novel structure induction procedure, which uses knowledge propagation to enable POMs to provide information to other POMs and "teach them" (which greatly reduces the amount of supervision required for training and speeds up the inference). In particular, we learn a POM-IP defined on Interest Points using weak supervision [1], [ 2] and use this to train a POM-mask, defined on regional features, which yields a combined POM that performs segmentation/localization. This combined model can be used to train POM-edgelets, defined on edgelets, which gives a full POM with improved performance on classification. We give detailed experimental analysis on large data sets for classification and segmentation with comparison to other methods. Inference takes five seconds while learning takes approximately four hours. In addition, we show that the full POM is invariant to scale and rotation of the object (for learning and inference) and can learn hybrid objects classes (i.e., when there are several objects and the identity of the object in each image is unknown). Finally, we show that POMs can be used to match between different objects of the same category, and hence, enable objects recognition.	[Chen, Yuanhao] Univ Sci & Technol China, Dept Automat, Hefei 230026, Anhui, Peoples R China; [Zhu, Long (Leo)] MIT, Cambridge, MA 02139 USA; [Yuille, Alan] Univ Calif Los Angeles, Dept Stat Psychol & Comp Sci, Los Angeles, CA 90095 USA; [Zhang, Hongjiang] Microsoft Adv Technol Ctr, Beijing 100080, Peoples R China	Chinese Academy of Sciences; University of Science & Technology of China, CAS; Massachusetts Institute of Technology (MIT); University of California System; University of California Los Angeles; Microsoft	Chen, YH (corresponding author), Univ Sci & Technol China, Dept Automat, Hefei 230026, Anhui, Peoples R China.	yhchen4@ustc.edu; leozhu@csail.mit.edu; yuille@stat.ucla.edu; hjzhang@microsoft.com		Yuille, Alan L./0000-0001-5207-9249	National Science Foundation (NSF) [0413214, 0736015, 0613563]	National Science Foundation (NSF)(National Science Foundation (NSF))	Long (Leo) Zhu and Alan Yuille were supported by the National Science Foundation (NSF) grants 0413214, 0736015, 0613563, and the W. M. Keck Foundation in performing this research. The authors thank Microsoft Research Asia for providing the internship to Yuanhao Chen to perform the research, and Iasonas Kokkinos, Zhuowen Tu, and YingNian Wu for helpful feedback. Three anonymous reviewers gave detailed comments, which greatly improved the clarity of the paper.	Amit Y, 1999, NEURAL COMPUT, V11, P1691, DOI 10.1162/089976699300016197; BLAKE A, 2004, P ECCV, V1, P428; Borenstein E, 2004, LECT NOTES COMPUT SC, V3023, P315; Bouchard G, 2005, PROC CVPR IEEE, P710; Boykov Y, 2001, LECT NOTES COMPUT SC, V2134, P359; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Cao L., 2007, P INT C COMP VIS; CHEN Y, 2008, P IEEE C COMP VIS PA; Crandall D, 2005, PROC CVPR IEEE, P10; Crandall DJ, 2006, LECT NOTES COMPUT SC, V3951, P16; Fergus R, 2005, PROC CVPR IEEE, P380; Ferguson J, 2003, GLOBAL NETW, V3, P271, DOI 10.1111/1471-0374.00062; Frey BJ, 2003, IEEE T PATTERN ANAL, V25, P1, DOI 10.1109/TPAMI.2003.1159942; Friedman N, 2003, MACH LEARN, V50, P95, DOI 10.1023/A:1020249912095; GRENANDER U, 1978, PATTERN ANAL LECTURE, V2; Grenander U., 1976, PATTERN SYNTHESIS LE, VI; JOJIC N, 2006, P IEEE C COMP VIS PA, V1, P117; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; Kumar MP, 2005, PROC CVPR IEEE, P18; KUSHAL A, P IEEE C COMP VIS PA; Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151; Leibe B., 2004, EUROPEAN C COMPUTER, P17; LEVIN A, 2006, P EUR C COMP VIS, V4, P581; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Neal R. M., 1999, LEARNING GRAPHICAL M, P355, DOI DOI 10.1007/978-94-011-5014-9; REN X, 2005, P C NEUR INF PROC SY; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Sivic J, 2005, IEEE I CONF COMP VIS, P370; Winn J, 2005, IEEE I CONF COMP VIS, P756; Wu Y, 2007, ADV INTEL SYS RES, DOI 10.2991/iske.2007.35; ZHU L, 2006, P C NEUR INF PROC SY, P1617; Zhu L, 2009, IEEE T PATTERN ANAL, V31, P114, DOI 10.1109/TPAMI.2008.67	33	16	19	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2009	31	10					1747	1761		10.1109/TPAMI.2009.95	http://dx.doi.org/10.1109/TPAMI.2009.95			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	483VK	19696447	Green Submitted			2022-12-18	WOS:000268996500003
J	Riklin-Raviv, T; Sochen, N; Kiryati, N				Riklin-Raviv, Tammy; Sochen, Nir; Kiryati, Nahum			On Symmetry, Perspectivity, and Level-Set-Based Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Symmetry; segmentation; level-sets; homography	ACTIVE CONTOURS; SHAPE PRIORS; RECONSTRUCTION; VIEW	We introduce a novel variational method for the extraction of objects with either bilateral or rotational symmetry in the presence of perspective distortion. Information on the symmetry axis of the object and the distorting transformation is obtained as a by-product of the segmentation process. The key idea is the use of a flip or a rotation of the image to segment as if it were another view of the object. We call this generated image the symmetrical counterpart image. We show that the symmetrical counterpart image and the source image are related by planar projective homography. This homography is determined by the unknown planar projective transformation that distorts the object symmetry. The proposed segmentation method uses a level-set-based curve evolution technique. The extraction of the object boundaries is based on the symmetry constraint and the image data. The symmetrical counterpart of the evolving level-set function provides a dynamic shape prior. It supports the segmentation by resolving possible ambiguities due to noise, clutter, occlusions, and assimilation with the background. The homography that aligns the symmetrical counterpart to the source level-set is recovered via a registration process carried out concurrently with the segmentation. Promising segmentation results of various images of approximately symmetrical objects are shown.	[Riklin-Raviv, Tammy] MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA; [Sochen, Nir] Tel Aviv Univ, Sch Math Sci, Dept Appl Math, IL-69978 Tel Aviv, Israel; [Kiryati, Nahum] Tel Aviv Univ, Sch Elect Engn, IL-69978 Tel Aviv, Israel	Massachusetts Institute of Technology (MIT); Tel Aviv University; Tel Aviv University	Riklin-Raviv, T (corresponding author), MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA.	tammy@csail.mit.edu; sochen@post.tau.ac.il; sochen@math.tau.ac.il	Raviv, Tammy Riklin/A-3462-2013	Kiryati, Nahum/0000-0003-1436-2275	A. M. N. Foundation; EC	A. M. N. Foundation; EC(European CommissionEuropean Commission Joint Research Centre)	This research was supported by the A. M. N. Foundation and by MUSCLE: Multimedia Understanding through Semantics, Computation and Learning, a European Network of Excellence funded by the EC Sixth Framework IST Programme. Tammy Riklin-Raviv was also supported by the Yizhak and Chaya Weinstein Research Institute for Signal Processing.	Bruckstein AM, 1998, PATTERN RECOGN, V31, P181, DOI 10.1016/S0031-3203(97)00018-6; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Chen YM, 2002, INT J COMPUT VISION, V50, P315, DOI 10.1023/A:1020878408985; Cornelius H, 2006, INT C PATT RECOG, P292; Cremers D, 2006, INT J COMPUT VISION, V66, P67, DOI 10.1007/s11263-005-3676-z; Cremers D, 2003, PATTERN RECOGN, V36, P1929, DOI 10.1016/S0031-3203(03)00056-6; CREMERS D, 2003, P 2 IEEE WORKSH VAR, P169; Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5; Cremers D, 2006, IEEE T PATTERN ANAL, V28, P1262, DOI 10.1109/TPAMI.2006.161; DERVIEUX A, 1979, LECT NOTES MATH, V771, P145; FAWCETT R, 1994, IMAGE VISION COMPUT, V12, P615, DOI 10.1016/0262-8856(94)90015-9; GAUCH JM, 1993, IEEE T PATTERN ANAL, V15, P753, DOI 10.1109/34.236253; GUPTA A, 2005, P IEEE INT C IM PROC, V3, P133; Hartley R., 2003, MULTIPLE VIEW GEOMET; Hong W, 2004, INT J COMPUT VISION, V60, P241, DOI 10.1023/B:VISI.0000036837.76476.10; Ishikawa H, 2005, IEEE I CONF COMP VIS, P1132; Kanatani K, 1997, IEEE T PATTERN ANAL, V19, P246, DOI 10.1109/34.584101; Keller Y, 2004, INT C PATT RECOG, P186, DOI 10.1109/ICPR.2004.1334499; KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855; Kimmel R, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P59, DOI 10.1007/0-387-21810-6_4; Kimmel R, 2003, INT J COMPUT VISION, V53, P225, DOI 10.1023/A:1023030907417; Kiryati N, 1998, INT J COMPUT VISION, V29, P29, DOI 10.1023/A:1008034529558; Kohlberger T, 2006, LECT NOTES COMPUT SC, V4190, P92; LAIRD A, 1991, P SOC PHOTO-OPT INS, V1381, P536, DOI 10.1117/12.25183; Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835; Liu TL, 1998, INT C PATT RECOG, P994, DOI 10.1109/ICPR.1998.711856; Lorigo LM, 2000, PROC CVPR IEEE, P444, DOI 10.1109/CVPR.2000.855853; MAROLA G, 1989, IEEE T PATTERN ANAL, V11, P104, DOI 10.1109/34.23119; Milner D, 2007, PATTERN RECOGN, V40, P2237, DOI 10.1016/j.patcog.2006.12.008; MUKHERJEE DP, 1995, PHILOS T R SOC A, V351, P77, DOI 10.1098/rsta.1995.0026; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Prasad VSN, 2005, IEEE I CONF COMP VIS, P954; Riklin-Raviv T, 2005, IEEE I CONF COMP VIS, P204; Riklin-Raviv T, 2008, INT J COMPUT VISION, V79, P231, DOI 10.1007/s11263-007-0115-3; Riklin-Raviv T, 2007, INT J COMPUT VISION, V72, P309, DOI 10.1007/s11263-006-9042-y; RIKLINRAVIV T, 2006, P IEEE C COMP VIS PA, V1, P1015; RIKLINRAVIV T, 2004, P EUR C COMP VIS, V4, P50; RIKLINRAVIV T, 2006, P 5 IEEE CS WORKSH P; ROUSSON M, 2002, P EUR C COMP VIS, P78; Shimshoni I, 2000, INT J COMPUT VISION, V39, P97, DOI 10.1023/A:1008118909580; STAHL JS, 2006, P IEEE C COMP VIS PA, V1, P1030; Tari S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1123, DOI 10.1109/ICCV.1998.710857; TERZOPOULOS D, 1987, INT J COMPUT VISION, V1, P211, DOI 10.1007/BF00127821; Thrun S, 2005, IEEE I CONF COMP VIS, P1824; Tsai A, 2003, IEEE T MED IMAGING, V22, P137, DOI 10.1109/TMI.2002.808355; Tyler C.W., 2002, HUMAN SYMMETRY PERCE; VANGOOL L, 1995, COMPUT VIS IMAGE UND, V61, P138, DOI 10.1006/cviu.1995.1010; VANGOOL L, 1995, INT J ROBOT RES, V14, P407, DOI 10.1177/027836499501400502; Vasilevskiy A, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P149, DOI 10.1109/ICCV.2001.937511; Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076; Yang AY, 2005, COMPUT VIS IMAGE UND, V99, P210, DOI 10.1016/j.cviu.2005.01.004; YANG Y, 2003, P INT C COMP VIS, V2, P1251; Zabrodsky H., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P678, DOI 10.1109/CVPR.1993.341031; Zabrodsky H, 1997, COMPUT VIS IMAGE UND, V67, P48, DOI 10.1006/cviu.1996.0506; ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508	57	16	17	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2009	31	8					1458	1471		10.1109/TPAMI.2008.160	http://dx.doi.org/10.1109/TPAMI.2008.160			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	458UN	19542579	Green Submitted, Green Published			2022-12-18	WOS:000267050600009
J	Hospedales, TM; Vijayakumar, S				Hospedales, Timothy M.; Vijayakumar, Sethu			Structure Inference for Bayesian Multisensory Scene Understanding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Sensor fusion; audiovisual; multimodal; detection; tracking; graphical models; model selection; Bayesian inference; speaker association	TRACKING; ASSOCIATION; INTEGRATION; SONAR	We investigate a solution to the problem of multisensor scene understanding by formulating it in the framework of Bayesian model selection and structure inference. Humans robustly associate multimodal data as appropriate, but previous modeling work has focused largely on optimal fusion, leaving segregation unaccounted for and unexploited by machine perception systems. We illustrate a unifying Bayesian solution to multisensory perception and tracking, which accounts for both integration and segregation by explicit probabilistic reasoning about data association in a temporal context. Such an explicit inference of multimodal data association is also of intrinsic interest for higher level understanding of multisensory data. We illustrate this by using a probabilistic implementation of data association in a multiparty audiovisual scenario, where unsupervised learning and structure inference is used to automatically segment, associate, and track individual subjects in audiovisual sequences. Indeed, the structure-inference-based framework introduced in this work provides the theoretical foundation needed to satisfactorily explain many confounding results in human psychophysics experiments involving multimodal cue integration and association.	[Hospedales, Timothy M.; Vijayakumar, Sethu] Univ Edinburgh, Inst Percept Act & Behav, Edinburgh EH8 9AB, Midlothian, Scotland	University of Edinburgh	Hospedales, TM (corresponding author), Univ Edinburgh, Inst Percept Act & Behav, 10 Crichton St, Edinburgh EH8 9AB, Midlothian, Scotland.	t.hospedales@ac.uk; sethu.vijayakumar@ac.uk		Hospedales, Timothy/0000-0003-4867-7486				Alais D, 2004, CURR BIOL, V14, P257, DOI 10.1016/j.cub.2004.01.029; Bar-Shalom Y, 2005, IEEE AERO EL SYS MAG, V20, P37, DOI 10.1109/MAES.2005.1499275; BARSHALOM Y, 1975, AUTOMATICA, V11, P451, DOI 10.1016/0005-1098(75)90021-7; Battaglia PW, 2003, J OPT SOC AM A, V20, P1391, DOI 10.1364/JOSAA.20.001391; Beal MJ, 2003, IEEE T PATTERN ANAL, V25, P828, DOI 10.1109/TPAMI.2003.1206512; BILMES J, 2000, P 16 ANN C UNC ART I; BOUTILIER C, 1996, P 12 ANN C UNC ART I; Chen YQ, 2004, P IEEE, V92, P485, DOI 10.1109/JPROC.2003.823146; *CLEAR, 2006, CLEAR 2006 EV WORKSH; Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a; Fisher JW, 2004, IEEE T MULTIMEDIA, V6, P406, DOI 10.1109/TMM.2004.827503; FORTMANN TE, 1983, IEEE J OCEANIC ENG, V8, P173, DOI 10.1109/JOE.1983.1145560; Frey BJ, 2003, IEEE T PATTERN ANAL, V25, P1, DOI 10.1109/TPAMI.2003.1159942; Gatica-Perez D, 2007, IEEE T AUDIO SPEECH, V15, P601, DOI 10.1109/TASL.2006.881678; Geiger D, 1996, ARTIF INTELL, V82, P45, DOI 10.1016/0004-3702(95)00014-3; HAIN T, 2005, P 9 EUR C SPEECH COM; Hershey J. R., 1999, ADV NEURAL INFORM PR; Jacobs RA, 1999, VISION RES, V39, P3621, DOI 10.1016/S0042-6989(99)00088-7; Jojic N, 2000, PROC CVPR IEEE, P26, DOI 10.1109/CVPR.2000.854728; JOJIC N, 2001, P IEEE C COMP VIS PA, V1; Kording KP, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000943; MacKay D. J. C., 2003, INFORM THEORY INFERE, P269; MANSINGHKA VK, 2006, P 22 C UNC ART INT U; NEFIAN A, 2002, EURASIP J APPL SIG P, V11, P1; Perez P, 2004, P IEEE, V92, P495, DOI 10.1109/JPROC.2003.823147; Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458; Recanzone GH, 2003, J NEUROPHYSIOL, V89, P1078, DOI 10.1152/jn.00706.2002; Serby D, 2004, INT C PATT RECOG, P184, DOI 10.1109/ICPR.2004.1334091; Shams L, 2005, NEUROREPORT, V16, P1923, DOI 10.1097/01.wnr.0000187634.68504.bb; Shams L, 2000, NATURE, V408, P788, DOI 10.1038/35048669; SILVA R, 2006, P 23 INT C MACH LEAR; SIRACUSA MR, 2007, P 11 INT C ART INT S; Slaney M., 2000, ADV NEURAL INFORM PR; Stiefelhagen R, 2007, LNCS, V4122; Stone L., 1999, ARTECH HOUSE RADAR; Vermaak J, 2005, IEEE T AERO ELEC SYS, V41, P309, DOI 10.1109/TAES.2005.1413764; Vijayakumar S., 2001, P IEEE RSJ INT C INT; Williams CKI, 2004, NEURAL COMPUT, V16, P1039, DOI 10.1162/089976604773135096	39	16	17	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2008	30	12					2140	2157		10.1109/TPAMI.2008.25	http://dx.doi.org/10.1109/TPAMI.2008.25			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	360CF	18988948	Green Submitted			2022-12-18	WOS:000260033900006
J	Blanchet, J; Forbes, F				Blanchet, Juliette; Forbes, Florence			Triplet Markov fields for the classification of complex structure data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						triplet Markov model; supervised classification; conditional independence; complex noise models; high-dimensional data; EM-like algorithms		We address the issue of classifying complex data. We focus on three main sources of complexity, namely, the high dimensionality of the observed data, the dependencies between these observations, and the general nature of the noise model underlying their distribution. We investigate the recent Triplet Markov Fields and propose new models in this class designed for such data and in particular allowing very general noise models. In addition, our models can handle the inclusion of a learning step in a consistent way so that they can be used in a supervised framework. One advantage of our models is that whatever the initial complexity of the noise model, parameter estimation can be carried out using state-of-the-art Bayesian clustering techniques under the usual simplifying assumptions. As generative models, they can be seen as an alternative, in the supervised case, to discriminative Conditional Random Fields. Identifiability issues underlying the models in the nonsupervised case are discussed while the models performance is illustrated on simulated and real data, exhibiting the mentioned various sources of complexity.	[Blanchet, Juliette; Forbes, Florence] ZIRST, INRIA Rhone Alpes, MISTIS Team, F-38334 Saint Ismier, France		Blanchet, J (corresponding author), ZIRST, INRIA Rhone Alpes, MISTIS Team, 655 Av Europe, F-38334 Saint Ismier, France.	Juliette.Blanchet@inrialpes.fr; Florence.Forbes@inrialpes.fr			Direct For Mathematical & Physical Scien [0915110] Funding Source: National Science Foundation	Direct For Mathematical & Physical Scien(National Science Foundation (NSF)NSF - Directorate for Mathematical & Physical Sciences (MPS))		Benboudjema D, 2005, COMPUT VIS IMAGE UND, V99, P476, DOI 10.1016/j.cviu.2005.04.003; Benboudjema D, 2007, IEEE T PATTERN ANAL, V29, P1367, DOI 10.1109/TPAMI.2007.1059; BESAG J, 1986, J R STAT SOC B, V48, P259; BLANCHET J, 2005, P BRIT MACH VIS C SE; BOUVEYRON C, 2007, COMPUTATIONAL STAT D; CELEUX G, 1995, PATTERN RECOGN, V28, P781, DOI 10.1016/0031-3203(94)00125-6; Celeux G, 2003, PATTERN RECOGN, V36, P131, DOI 10.1016/S0031-3203(02)00027-4; CHALMOND B, 1989, PATTERN RECOGN, V22, P747, DOI 10.1016/0031-3203(89)90011-3; CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; DEBONET JS, 1998, P IEEE C COMP VIS PA; Delignon Y, 1997, IEEE T IMAGE PROCESS, V6, P1364, DOI 10.1109/83.624951; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Forbes F, 2003, IEEE T PATTERN ANAL, V25, P1089, DOI 10.1109/TPAMI.2003.1227985; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Jasra A, 2005, STAT SCI, V20, P50, DOI 10.1214/088342305000000016; Kumar S, 2006, INT J COMPUT VISION, V68, P179, DOI 10.1007/s11263-006-7007-9; LAZEBNIK S, 2003, P IEEE INT C COMP VI; Le Hegarat-Mascle S, 2007, IEEE T IMAGE PROCESS, V16, P865, DOI 10.1109/TIP.2007.891150; LI J, 2005, J COMPUTATIONAL GRAP, V14; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Pieczynski W., 2000, Machine Graphics & Vision, V9, P705; QIAN W, 1991, PHILOS T ROY SOC A, V337, P407, DOI 10.1098/rsta.1991.0132; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Toyoda T., 2005, 4 INT WORKSH TEXT AN, V12, P131; VIGNES M, 2007, IEEE ACM T COMPUTATI; [No title captured]	30	16	17	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2008	30	6					1055	1067		10.1109/TPAMI.2008.27	http://dx.doi.org/10.1109/TPAMI.2008.27			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	286UW	18421110	Green Submitted			2022-12-18	WOS:000254872500010
J	Zhang, XY; Liu, YC; Huang, TS				Zhang, XY; Liu, YC; Huang, TS			Motion analysis of articulated objects from monocular images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						articulated object; kinematic chain; motion estimation; exponential map; point pattern matching	TRACKING; SEGMENTATION; AFFINE; POSE	This paper presents a new method of motion analysis of articulated objects from feature point correspondences over monocular perspective images without imposing any constraints on motion. An articulated object is modeled as a kinematic chain consisting of joints and links, and its 3D joint positions are estimated within a scale factor using the connection relationship of two links over two or three images. Then, twists and exponential maps are employed to represent the motion of each link, including the general motion of the base link and the rotation of other links around their joints. Finally, constraints from image point correspondences, which are similar to that of the essential matrix in rigid motion, are developed to estimate the motion. In the algorithm, the characteristic of articulated motion, i.e., motion correlation among links, is applied to decrease the complexity of the problem and improve the robustness. A point pattern matching algorithm for articulated objects is also discussed in this paper. Simulations and experiments on real images show the correctness and efficiency of the algorithms.	Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Dept Automat, Shanghai 200240, Peoples R China; Univ Illinois, Beckman Inst, Urbana, IL 61801 USA	Shanghai Jiao Tong University; University of Illinois System; University of Illinois Urbana-Champaign	Zhang, XY (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Dept Automat, Min Hang Campus,1954 Huashan Rd, Shanghai 200240, Peoples R China.	xiao_yun@sjtu.org; whomliu@sjtu.edu.cn; huang@ifp.uiuc.edu						Aggarwal J. K., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P2, DOI 10.1109/MNRAO.1994.346261; Aggarwal JK, 1997, IEEE NONRIGID AND ARTICULATED MOTION WORKSHOP, PROCEEDINGS, P90, DOI 10.1109/NAMW.1997.609859; Barron C, 2001, COMPUT VIS IMAGE UND, V81, P269, DOI 10.1006/cviu.2000.0888; Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; Borshukov GD, 1997, IEEE T IMAGE PROCESS, V6, P1591, DOI 10.1109/83.641420; Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; CAMPBELL LW, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P624, DOI 10.1109/ICCV.1995.466880; Chan D, 2004, INT J SELECT ASSESS, V12, P9, DOI 10.1111/j.0965-075X.2004.00260.x; CHUNHONG P, 2000, CHINESE J ELECTRON, V9, P76; Covell MM, 2000, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2000.854875; DEUTSCHER J, 2000, P IEEE C COMP VIS PA, V2, P126, DOI DOI 10.1109/CVPR.2000.854758; Drummond T, 2002, IEEE T PATTERN ANAL, V24, P932, DOI 10.1109/TPAMI.2002.1017620; Feldmar J, 1996, INT J COMPUT VISION, V18, P99, DOI 10.1007/BF00054998; Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056; Herda L, 2000, COMP ANIM CONF PROC, P77, DOI 10.1109/CA.2000.889046; Holt RJ, 1997, PATTERN RECOGN, V30, P1435, DOI 10.1016/S0031-3203(96)00179-3; HUANG TS, 1994, P IEEE, V82, P252, DOI 10.1109/5.265351; Iiyama M, 2000, INT C PATT RECOG, P695, DOI 10.1109/ICPR.2000.903640; Jojic N., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P123, DOI 10.1109/ICCV.1999.791207; Ju SX, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P38, DOI 10.1109/AFGR.1996.557241; KAKADIARIS IA, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P980, DOI 10.1109/CVPR.1994.323938; KRAHNSTOEVER N, 2001, P C C COMP VIS PATT; Lin M. H., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P648, DOI 10.1109/ICCV.1999.791286; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897; Murray R. M., 1994, MATH INTRO ROBOTIC M; O'Brien JF, 2000, PROC GRAPH INTERF, P53; Sidenbladh H., 2000, P EUR C COMP VIS; SILAGHI MC, 1998, P WORKSH MOD MOT CAP; Sinclair D, 1996, PROC CVPR IEEE, P94, DOI 10.1109/CVPR.1996.517059; Sminchisescu C, 2003, INT J ROBOT RES, V22, P371, DOI 10.1177/0278364903022006003; SMITH SM, 1995, IEEE T PATTERN ANAL, V17, P814, DOI 10.1109/34.400573; SUNDARESAN A, 2004, P C IM PROC; WEBB JA, 1982, ARTIF INTELL, V19, P107, DOI 10.1016/0004-3702(82)90023-6; Wu Y., 1999, P IEEE INT C COMP VI, P606; Zhang XB, 2004, ANN CLIN LAB SCI, V34, P3	36	16	18	0	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2006	28	4					625	636		10.1109/TPAMI.2006.78	http://dx.doi.org/10.1109/TPAMI.2006.78			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	011FK	16566510				2022-12-18	WOS:000235253300011
J	Todorovic, S; Nechyba, MC				Todorovic, S; Nechyba, MC			Dynamic trees for unsupervised segmentation and matching of image regions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						generative models; Bayesian networks; dynamic trees; variational inference; image segmentation; image matching; object recognition	VARIATIONAL-METHODS	We present a probabilistic framework - namely, multiscale generative models known as Dynamic Trees (DT) - for unsupervised image segmentation and subsequent matching of segmented regions in a given set of images. Beyond these novel applications of DTs, we propose important additions for this modeling paradigm. First, we introduce a novel DT architecture, where multilayered observable data are incorporated at all scales of the model. Second, we derive a novel probabilistic inference algorithm for DTs - Structured Variational Approximation (SVA) - which explicitly accounts for the statistical dependence of node positions and model structure in the approximate posterior distribution, thereby relaxing poorly justified independence assumptions in previous work. Finally, we propose a similarity measure for matching dynamic-tree models, representing segmented image regions, across images. Our results for several data sets show that DTs are capable of capturing important component-subcomponent relationships among objects and their parts, and that DTs perform well in segmenting images into plausible pixel clusters. We demonstrate the significantly improved properties of the SVA algorithm - both in terms of substantially faster convergence rates and larger approximate posteriors for the inferred models - when compared with competing inference algorithms. Furthermore, results on unsupervised object recognition demonstrate the viability of the proposed similarity measure for matching dynamic-structure statistical models.	Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA; Pittsburgh Pattern Recognit, Pittsburgh, PA 15222 USA	State University System of Florida; University of Florida	Todorovic, S (corresponding author), Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.	sinisha@ufl.edu; michael@pittpatt.com						ADAMS NJ, 2001, THESIS U EDINBURGH E; ADAMS NJ, 2002, P 15 INT C PATT REC, V3, P147; AITKIN M, 1985, J ROY STAT SOC B MET, V47, P67; Cheng H, 2001, IEEE T IMAGE PROCESS, V10, P511, DOI 10.1109/83.913586; Choi H, 2001, IEEE T IMAGE PROCESS, V10, P1309, DOI 10.1109/83.941855; D'Elia C, 2003, IEEE T IMAGE PROCESS, V12, P1259, DOI 10.1109/TIP.2003.817257; DeMenthon D, 2000, INT C PATT RECOG, P143, DOI 10.1109/ICPR.2000.903505; Feng XJ, 2002, IEEE T PATTERN ANAL, V24, P467, DOI 10.1109/34.993555; FREY BJ, 2004, IEEE T PATTERN ANAL; Greenspan H, 2001, COMPUT VIS IMAGE UND, V84, P384, DOI 10.1006/cviu.2001.0946; Hermosillo G, 2002, INT J COMPUT VISION, V50, P329, DOI 10.1023/A:1020830525823; Irving WW, 1997, IEEE T IMAGE PROCESS, V6, P1517, DOI 10.1109/83.641412; Jaakkola TS, 2001, NEU INF PRO, P129; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; JUANG BH, 1985, AT&T TECH J, V64, P391, DOI 10.1002/j.1538-7305.1985.tb00439.x; Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343; KONEN WK, 1994, NEURAL NETWORKS, V7, P1019, DOI 10.1016/S0893-6080(05)80157-1; Laferte JM, 2000, IEEE T IMAGE PROCESS, V9, P390, DOI 10.1109/83.826777; Li J, 2000, IEEE T INFORM THEORY, V46, P1826, DOI 10.1109/18.857794; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MACKAY DJC, 1999, LEARNING GRAPHICAL M, P175; MACKAY DJC, 2003, INFORM THEORY INFERE, P357; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Mignotte M, 2000, IEEE T IMAGE PROCESS, V9, P1216, DOI 10.1109/83.847834; Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P780, DOI 10.1109/TPAMI.2002.1008384; MONTANVERT A, 1991, IEEE T PATTERN ANAL, V13, P307, DOI 10.1109/34.88566; Neal R. M., 1993, PROBABILISTIC INFERE; Nechyba MC, 1998, IEEE T ROBOTIC AUTOM, V14, P437, DOI 10.1109/70.678453; Pearl J., 1988, PROC PROBABILISTIC R, P143, DOI DOI 10.1016/B978-0-08-051489-5.50010-2; Schneider MK, 2000, IEEE T IMAGE PROCESS, V9, P456, DOI 10.1109/83.826782; Schneiderman H, 2004, INT J COMPUT VISION, V56, P151, DOI 10.1023/B:VISI.0000011202.85607.00; Storkey AJ, 2003, IEEE T PATTERN ANAL, V25, P859, DOI 10.1109/TPAMI.2003.1206515; STORKEY AJ, 2000, P 16 C UNC ART INT, P566; Thomas J. A, 1991, ELEMENTS INF THEORY; Ying ZR, 2002, INT J COMPUT VISION, V49, P57, DOI 10.1023/A:1019881831890	36	16	18	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2005	27	11					1762	1777		10.1109/TPAMI.2005.219	http://dx.doi.org/10.1109/TPAMI.2005.219			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	963SN	16285375				2022-12-18	WOS:000231826300007
J	Bouma, H; Vilanova, A; van Vliet, LJ; Gerritsen, FA				Bouma, H; Vilanova, A; van Vliet, LJ; Gerritsen, FA			Correction for the dislocation of curved surfaces caused by the PSF in 2D and 3D CT images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						edge and feature detection	REGULARIZATION	Conventional edge-detection methods suffer from the dislocation of curved surfaces due to the PSF. We propose a new method that uses the isophote curvature to circumvent this. It is accurate for objects with locally constant curvature, even for small objects (like blood vessels) and in the presence of noise.	Tech Univ Eindhoven, Dept Biomed Engn, NL-5600 MB Eindhoven, Netherlands; Delft Univ Technol, Fac Sci Appl, Quantitat Imaging Grp, NL-2600 AA Delft, Netherlands; Tech Univ Eindhoven, Dept Biomed Engn, NL-5600 MB Eindhoven, Netherlands; Philips Med Syst, NL-5680 DA Best, Netherlands	Eindhoven University of Technology; Delft University of Technology; Eindhoven University of Technology; Philips; Philips Healthcare	Bouma, H (corresponding author), Tech Univ Eindhoven, Dept Biomed Engn, Postbus 513, NL-5600 MB Eindhoven, Netherlands.	h.bouma2@tue.nl; a.vilanova@tue.nl; l.j.vanvliet@ph.tn.tudelft.nl; Frans.Gerritsen@philips.com	van Vliet, Lucas/E-1678-2012	van Vliet, Lucas/0000-0001-7018-726X; Bouma, Henri/0000-0002-9363-6870				BOUMA H, 2004, Patent No. 041010273; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Carasso AS, 1999, SIAM J NUMER ANAL, V36, P1659, DOI 10.1137/S0036142997320413; Dore S, 1997, P ANN INT IEEE EMBS, V19, P788, DOI 10.1109/IEMBS.1997.757757; Fahrig R, 1999, MED PHYS, V26, P1589, DOI 10.1118/1.598672; Frangi AF, 1999, IEEE T MED IMAGING, V18, P946, DOI 10.1109/42.811279; Hoogeveen RM, 1998, JMRI-J MAGN RESON IM, V8, P1228, DOI 10.1002/jmri.1880080608; KRISSIAN K, 1999, 3736 INRIA; KRISSIAN K, 1998, 3442 INRIA; LLACER J, 1994, SPIE P, V2302, P207; Luengo Hendriks CL, 2003, LECT NOTES COMPUT SC, V2756, P681; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MENDONCA PRS, 2004, P EUR C COMP VIS M 2, P554; NICKOLOFF EL, 1985, MED PHYS, V12, P437, DOI 10.1118/1.595706; Nielsen M, 1997, J MATH IMAGING VIS, V7, P291, DOI 10.1023/A:1008282127190; OTTENBERG K, 1993, THESIS UTRECHT U NET; Reinhardt JM, 1997, IEEE T MED IMAGING, V16, P820, DOI 10.1109/42.650878; Ter Haar Romeny B., 2002, FRONT END VISION MUL; van den Boomgaard R, 2001, LECT NOTES COMPUT SC, V2106, P205; Van der Heijden F., 1994, IMAGE BASED MEASUREM; van Kempen GMP, 2000, J MICROSC-OXFORD, V198, P63, DOI 10.1046/j.1365-2818.2000.00671.x; Van Vliet L. J., 1993, Proceedings of the 8th Scandinavian Conference on Image Analysis, P1403; VANVLIET LJ, 1994, PATTERN RECOGN LETT, V15, P485, DOI 10.1016/0167-8655(94)90140-6; VERBEEK PW, 1994, IEEE T PATTERN ANAL, V16, P726, DOI 10.1109/34.297954	24	16	18	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2005	27	9					1501	1507		10.1109/TPAMI.2005.174	http://dx.doi.org/10.1109/TPAMI.2005.174			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	944XB	16173193				2022-12-18	WOS:000230463300013
J	Calway, A				Calway, A			Recursive estimation of 3D motion and surface structure from local affine flow parameters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						structure from motion; surface normals; affine motion models; Kalman filtering	STRUCTURE-FROM-MOTION; OPTICAL-FLOW; IMAGE SEQUENCES; COMPUTATION; INFORMATION; MODELS	A recursive structure from motion algorithm based on optical flow measurements taken from an image sequence is described. It provides estimates of surface normals in addition to 3D motion and depth. The measurements are affine motion parameters which approximate the local flow fields associated with near-planar surface patches in the scene. These are integrated over time to give estimates of the 3D parameters using an extended Kalman filter. This also estimates the camera focal length and, so, the 3D estimates are metric. The use of parametric measurements means that the algorithm is computationally less demanding than previous optical flow approaches and the recursive filter builds in a degree of noise robustness. Results of experiments on synthetic and real image sequences demonstrate that the algorithm performs well.	Univ Bristol, Dept Comp Sci, Bristol BS8 1UB, Avon, England	University of Bristol	Calway, A (corresponding author), Univ Bristol, Dept Comp Sci, Woodland Rd, Bristol BS8 1UB, Avon, England.	Andrew.Calway@bristol.ac.uk						ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965; AZARBAYEJANI A, 1995, IEEE T PATTERN ANAL, V17, P562, DOI 10.1109/34.387503; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BERGEN JR, 1992, IEEE T PATTERN ANAL, V14, P886, DOI 10.1109/34.161348; Black MJ, 1996, IEEE T PATTERN ANAL, V18, P972, DOI 10.1109/34.541407; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; CALWAY A, 2000, P BRIT MACH VIS C, P92; Calway AD, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P189, DOI 10.1109/ICIP.1996.560416; Candy J.V, 1986, SIGNAL PROCESSING MO; Chiuso A, 2002, IEEE T PATTERN ANAL, V24, P523, DOI 10.1109/34.993559; DELLAERT F, 1998, P IEEE RSJ INT C INT; FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HUANG TS, 1994, P IEEE, V82, P252, DOI 10.1109/5.265351; Jebara T, 1999, IEEE SIGNAL PROC MAG, V16, P66, DOI 10.1109/79.768574; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; LONGUETHIGGINS HC, 1984, PROC R SOC SER B-BIO, V223, P165, DOI 10.1098/rspb.1984.0088; MEYER FG, 1994, CVGIP-IMAG UNDERSTAN, V60, P119, DOI 10.1006/ciun.1994.1042; Murray DW, 1996, COMPUT VIS IMAGE UND, V63, P169, DOI 10.1006/cviu.1996.0012; NEGAHDARIPOUR S, 1992, INT J COMPUT VISION, V9, P163, DOI 10.1007/BF00133700; Soatto S, 1997, INT J COMPUT VISION, V22, P235, DOI 10.1023/A:1007930700152; Soatto S, 1998, IEEE T PATTERN ANAL, V20, P933, DOI 10.1109/34.713360; SUBBARAO M, 1986, COMPUT VISION GRAPH, V36, P208, DOI 10.1016/0734-189X(86)90076-9; Szeliski R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P752, DOI 10.1109/CVPR.1993.341157; Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; WILSON R, 1998, P IEEE INT C IM PROC; Xiong YL, 1998, COMPUT VIS IMAGE UND, V69, P222, DOI 10.1006/cviu.1997.0601	29	16	17	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2005	27	4					562	574		10.1109/TPAMI.2005.83	http://dx.doi.org/10.1109/TPAMI.2005.83			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	895FG	15794161				2022-12-18	WOS:000226845700007
J	Kim, SW; Oommen, BJ				Kim, SW; Oommen, BJ			On utilizing search methods to select subspace dimensions for kernel-based nonlinear subspace classifiers	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	17th Australian Joint Conference on Artificial Intelligence	DEC, 2004	Perth, AUSTRALIA	KOSEF, Korea Sci & Engn Fdn, NSERC		kernel principal component analysis (kPCA); kernel-based nonlinear subspace (KNS) classifier; subspace dimension selections; state-space search algorithms		In Kernel-based Nonlinear Subspace (KNS) methods, the subspace dimensions have a strong influence on the performance of the subspace classifier. In order to get a high classification accuracy, a large dimension is generally required. However, if the chosen subspace dimension is too large, it leads to a low performance due to the overlapping of the resultant subspaces and, if it is too small, it increases the classification error due to the poor resulting approximation. The most common approach is of an ad hoc nature, which selects the dimensions based on the so-called cumulative proportion [ 13] computed from the kernel matrix for each class. In this paper, we propose a new method of systematically and efficiently selecting optimal or near-optimal subspace dimensions for KNS classifiers using a search strategy and a heuristic function termed the Overlapping criterion. The rationale for this function has been motivated in the body of the paper. The task of selecting optimal subspace dimensions is reduced to finding the best ones from a given problem-domain solution space using this criterion as a heuristic function. Thus, the search space can be pruned to very efficiently find the best solution. Our experimental results demonstrate that the proposed mechanism selects the dimensions efficiently without sacrificing the classification accuracy.	Myongji Univ, Dept Comp Sci & Engn, Yongin 449728, South Korea; Carleton Univ, Sch Comp Sci, Ottawa, ON K1S 5B6, Canada	Myongji University; Carleton University	Kim, SW (corresponding author), Myongji Univ, Dept Comp Sci & Engn, Yongin 449728, South Korea.	kimsw@mju.ac.kr; oommen@scs.carleton.ca	Oommen, B. John/P-6323-2017	Oommen, B. John/0000-0002-5105-1575				Achlioptas D., 2001, P 33 ANN ACM S THEOR, P611; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; KANAL LN, 1979, IEEE T PATTERN ANAL, V1, P193, DOI 10.1109/TPAMI.1979.4766905; Kim SW, 2004, PATTERN RECOGN, V37, P227, DOI 10.1016/j.patcog.2003.07.006; KIM SW, UNPUB USING PROTOTYP; LAAKSONEN J, 1996, P INT C ART NEUR NET, P227; MAEDA E, 1999, P IEEE INT AC SPEECH; MAEDA K, 1985, IEICE T INF SYST, V68, P345; Muller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517; Newman C. B. D., 1998, UCI REPOSITORY MACHI; Nilsson N.J., 1971, PROBLEM SOLVING METH; OJA E, 1983, SUBSPACE METHODS PAT; OOMMEN BJ, IN PRESS ARTIFICIAL; Rich E., 1991, ARTIF INTELL; Scholkopf B, 1999, IEEE T NEURAL NETWOR, V10, P1000, DOI 10.1109/72.788641; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Smola A. J., 2000, P 17 INT C MACH LEAR, P911; TIPPING ME, 2001, ADV NEURAL INFORMATI, V13; TSUDA K, 1999, IEICE T INF SYST, V82, P592; WILLIAMS CKI, 2001, ADV NEURAL INFORMATI, V13	21	16	17	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2005	27	1					136	141		10.1109/TPAMI.2005.15	http://dx.doi.org/10.1109/TPAMI.2005.15			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	870BE	15628275				2022-12-18	WOS:000225028200013
J	Weruaga, L; Verdu, R; Morales, J				Weruaga, L; Verdu, R; Morales, J			Frequency domain formulation of active parametric deformable models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						active deformable models; snakes; frequency domain; Fast Fourier transform	ALGORITHM; SNAKES	Active deformable models are simple tools, very popular in computer vision and computer graphics, for solving ill-posed problems or mimic real physical systems. The classical formulation is given in the spatial domain, the motor of the procedure is a second-order linear system, and rigidity and elasticity are the basic parameters for its characterization. This paper proposes a novel formulation based on a frequency-domain analysis: The internal energy functional and the Lagrange minimization are performed entirely in the frequency domain, which leads to a simple formulation and design. The frequency-based implementation offers important computational savings in comparison to the original one, a feature that is improved by the efficient hardware and software computation of the FFT algorithm. This new formulation focuses on the stiffness spectrum, allowing the possibility of constructing deformable models apart from the elasticity and rigidity-based original formulation. Simulation examples validate the theoretical results.	Austrian Acad Sci, Commiss Sci Visualisat, A-1010 Vienna, Austria; Cartagena Univ Technol, Informat & Commun Technol Dept, Cartagena, Spain	Austrian Academy of Sciences; Universidad Politecnica de Cartagena	Weruaga, L (corresponding author), Austrian Acad Sci, Commiss Sci Visualisat, A-1010 Vienna, Austria.	luis.weruaga@oeaw.ac.at; rafael.verdu@upct.es; juan.morales@upct.es	Verdú-Monedero, Rafael/A-2473-2012	Verdú-Monedero, Rafael/0000-0001-9227-7397; Morales-Sanchez, Juan/0000-0002-2894-3292				BAAS BM, 1999, THESIS STANFORD U ST; Brigger P, 2000, IEEE T IMAGE PROCESS, V9, P1484, DOI 10.1109/83.862624; COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675; DUHAMEL P, 1990, SIGNAL PROCESS, V19, P259, DOI 10.1016/0165-1684(90)90158-U; Eberhardt B, 1996, IEEE COMPUT GRAPH, V16, P52, DOI 10.1109/38.536275; Faloutsos P, 1997, IEEE T VIS COMPUT GR, V3, P201, DOI 10.1109/2945.620488; Haykin S., 2014, ADAPTIVE FILTER THEO, V5th ed.; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LAM KM, 1994, ELECTRON LETT, V30, P21, DOI 10.1049/el:19940040; Liang J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P933, DOI 10.1109/ICCV.1999.790348; MATUSIAK R, 1998, SPRA297 TEX INSTR; McInerney T, 2000, MED IMAGE ANAL, V4, P73, DOI 10.1016/S1361-8415(00)00008-6; Metaxas D, 1996, PHYS BASED DEFORMABL; NEUENSCHWANDER W, 1997, COMPUTER VISION GRAP, P237; Olstad B, 1996, IEEE T PATTERN ANAL, V18, P863, DOI 10.1109/34.537341; Oppenheim A.V., 1999, DISCRETE TIME SIGNAL; SINGH, 1995, DEFORMABLE MODELS ME; Terzopoulos D, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P21, DOI 10.1007/0-387-21810-6_2; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; Tikhonov A.N., 1977, SOLUTION ILL POSED P; Wang M, 1996, IEEE T IMAGE PROCESS, V5, P1586, DOI 10.1109/83.541430; Weruaga L, 2003, IEEE T MED IMAGING, V22, P766, DOI 10.1109/TMI.2003.814782; WILLIAMS DJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P14, DOI 10.1016/1049-9660(92)90003-L; Yu QX, 1998, COMP ANIM CONF PROC, P2, DOI 10.1109/CA.1998.681900	25	16	16	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2004	26	12					1568	1578		10.1109/TPAMI.2004.124	http://dx.doi.org/10.1109/TPAMI.2004.124			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	861AO	15573818				2022-12-18	WOS:000224388700003
J	Chesi, G; Hashimoto, K				Chesi, G; Hashimoto, K			A simple technique for improving camera displacement estimation in eye-in-hand visual servoing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; visual servoing; camera displacement estimation	POSE ESTIMATION	A simple technique for estimating the camera displacement from point correspondences in eye-in-hand visual servoing is presented. The idea for providing more accurate results than existing methods consists of taking into account that the point correspondences used during the camera motion correspond to stationary spatial points, hence exploiting additional information. This is done by first estimating the object Euclidean structure and then estimating the camera displacement from this estimate.	Univ Siena, Dept Informat Engn, I-53100 Siena, Italy; Tohoku Univ, Grad Sch Informat Sci, Dept Syst Informat Sci, Aoba Ku, Sendai, Miyagi 9808579, Japan	University of Siena; Tohoku University	Chesi, G (corresponding author), Univ Siena, Dept Informat Engn, Via Roma 56, I-53100 Siena, Italy.	chesi@dii.unisi.it; koichi@ic.is.tohoku.ac.jp	Hashimoto, Koichi/AAF-7646-2019; Chesi, Graziano/C-1575-2009	Chesi, Graziano/0000-0003-4214-4224; Hashimoto, Koichi/0000-0002-4473-2698				Ansar A, 2003, IEEE T PATTERN ANAL, V25, P578, DOI 10.1109/TPAMI.2003.1195992; Corke PI, 2001, IEEE T ROBOTIC AUTOM, V17, P507, DOI 10.1109/70.954764; Deguchi K, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P705, DOI 10.1109/IROS.1998.727274; DERICHE R, 1994, P EUR C COMP VIS; ESPIAU B, 1992, IEEE T ROBOTIC AUTOM, V8, P313, DOI 10.1109/70.143350; Faugeras O. D., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P485, DOI 10.1142/S0218001488000285; Fiore PD, 2001, IEEE T PATTERN ANAL, V23, P140, DOI 10.1109/34.908965; HASHIMOTO K, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2267, DOI 10.1109/ROBOT.1991.131968; Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199; Malis E, 2000, INT J COMPUT VISION, V37, P79, DOI 10.1023/A:1008181530296; Malis E, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P217, DOI 10.1109/ROBOT.2002.1013364; Quan L, 1999, IEEE T PATTERN ANAL, V21, P774, DOI 10.1109/34.784291; Taylor C. J., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P2734, DOI 10.1109/ROBOT.2000.846441; Thuilot B, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1624, DOI 10.1109/ROBOT.2002.1014775; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; Wilson WJ, 1996, IEEE T ROBOTIC AUTOM, V12, P684, DOI 10.1109/70.538974; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561	18	16	16	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2004	26	9					1239	1242		10.1109/TPAMI.2004.56	http://dx.doi.org/10.1109/TPAMI.2004.56			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	837CM	15742899				2022-12-18	WOS:000222605100013
J	Bouganis, CS; Brookes, M				Bouganis, CS; Brookes, M			Multiple light source detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computer vision; illuminant detection; Lambertian sphere limitations; image synthesis	ILLUMINANT DIRECTION	This paper presents the V2R algorithm, a novel method for multiple light source detection using a Lambertian sphere as a calibration object. The algorithm segments the image of the sphere into regions that are each illuminated by a single virtual light and subtracts the virtual lights of adjacent regions to estimate the light source vectors. The algorithm uses all pixels within a region to form a robust estimate of the corresponding virtual light. The circumstances under which the light source detection problem lacks a unique solution are discussed in detail and the way in which the V2R algorithm resolves the ambiguity is explained. The V2R algorithm includes novel procedures for identifying the critical lines that bound the regions, for estimating the light source vectors, and for identifying opposite light pairs. Experiments are performed on synthetic and real images and the performance of the V2R algorithm is compared to that of a recent algorithm from the literature. The experimental results demonstrate that the proposed algorithm is robust and that it gives substantially improved accuracy.	Univ London Imperial Coll Sci Technol & Med, Dept Elect Engn, London SW7 2BT, England	Imperial College London	Bouganis, CS (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Elect Engn, Exhibit Rd, London SW7 2BT, England.	ccb98@imperial.ac.uk; mike.brooks@imperial.ac.uk	Bouganis, Christos/AAL-8145-2020	Bouganis, Christos-Savvas/0000-0002-4906-4510				Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; CHOJNACKI W, 1994, J OPT SOC AM A, V11, P118, DOI 10.1364/JOSAA.11.000118; Gantmacher F.R., 1959, THEORY MATRICES, V2; Horn B., 1986, ROBOT VISION, P1; Hougen D. R., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P148, DOI 10.1109/ICCV.1993.378225; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; MARSCHNER SR, 1997, P 5 COL IM C; Paul D., 1998, P SIGGRAPH 98, P189, DOI [10.1145/280814.280864, DOI 10.1145/280814.280864]; PENTLAND AP, 1982, J OPT SOC AM, V72, P448, DOI 10.1364/JOSA.72.000448; Powell MW, 2001, IEEE T PATTERN ANAL, V23, P1022, DOI 10.1109/34.955114; Ramamoorthi R, 2001, J OPT SOC AM A, V18, P2448, DOI 10.1364/JOSAA.18.002448; SATO I, 1999, P IEEE CS C COMP VIS, V1, P306; Wang Y, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P38, DOI 10.1109/PCCGA.2002.1167837; WANG Y, 2002, P EUR C COMP VIS, V3, P272; Yang Y., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P534, DOI 10.1109/CVPR.1991.139749; YANG YH, 1998, VISION INTERFACE 98, P271; Zhang YF, 2001, IEEE T PATTERN ANAL, V23, P915, DOI 10.1109/34.946995; Zhang YF, 2000, PROC CVPR IEEE, P269, DOI 10.1109/CVPR.2000.855829; ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658	19	16	18	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2004	26	4					509	514		10.1109/TPAMI.2004.1265865	http://dx.doi.org/10.1109/TPAMI.2004.1265865			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	801NO	15382654	Green Submitted			2022-12-18	WOS:000220102800006
J	Laskov, P; Kambhamettu, C				Laskov, P; Kambhamettu, C			Curvature-based algorithms for nonrigid motion and correspondence estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nonrigid motion; correspondence estimation; differential geometry; Gaussian curvature	RANGE IMAGES; RECOVERY; SHAPE; DEFORMATIONS; REGISTRATION; SURFACES; MODELS	We present a novel technique for utilizing the Gaussian curvature information in 3D nonrigid motion estimation in the absence of known correspondence. Differential-geometric constraints derived in the paper allow one to estimate parameters of the local affine motion model given the values of Gaussian curvature before and after motion. These constraints can be further combined with the previously known constraints based on the unit normals before and after motion. Our experiments demonstrate that the resulting hybrid algorithm is more accurate than each of its constituents and more accurate than the classical ICP algorithm. We also present a technique for curvilinear orthogonal ization of quadratic Monge patches that is essential in our derivation and useful in other applications.	Fraunhofer Inst FIRST, D-12489 Berlin, Germany; Univ Delaware, Dept Comp & Informat Sci, Newark, DE 19716 USA	Fraunhofer Gesellschaft; University of Delaware	Laskov, P (corresponding author), Fraunhofer Inst FIRST, Kekulestr 7, D-12489 Berlin, Germany.	laskov@first.fhg.de; chandra@cis.udel.edu						AGGARWAL JK, 1994, P IEEE COMP SOC WORK, P16; AMINI AA, 1992, IMAGE VISION COMPUT, V10, P418, DOI 10.1016/0262-8856(92)90027-Z; AMINI AA, 1992, P SPIE MATH METH MED, V1786, P170; AMINI AA, 1991, P INT C INF PROC MED, P343; Angelopoulou E, 1998, IEEE T PATTERN ANAL, V20, P1056, DOI 10.1109/34.722615; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BESL PJ, 1986, COMPUT VISION GRAPH, V33, P33, DOI 10.1016/0734-189X(86)90220-3; CHEN S, 1988, ADV COMPUTER VISION, V3, P179; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; COHEN I, 1992, P EUR C COMP VIS, P458; Courant R, 1974, INTRO CALCULUS ANAL; DeCarlo D, 2002, IEEE T PATTERN ANAL, V24, P814, DOI 10.1109/TPAMI.2002.1008387; DEVERNAY F, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P208, DOI 10.1109/CVPR.1994.323831; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; DOUROS I, 2002, IN PRESS SCANNING 20; FELDMAR J, 1994, 2200 INRIA; FELDMAR J, 1996, INT J COMPUTER VISIO, V18; Flynn P. J., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P110, DOI 10.1109/CVPR.1989.37837; Goldgof D. B., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P375, DOI 10.1109/CVPR.1988.196262; Huang T. S., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P361, DOI 10.1109/ICPR.1990.118129; KAMBHAMETTU C, 1994, CVGIP-IMAG UNDERSTAN, V60, P26, DOI 10.1006/ciun.1994.1029; Kambhamettu C, 2003, IMAGE VISION COMPUT, V21, P229, DOI 10.1016/S0262-8856(02)00041-0; KAMBHAMETTU C, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P943, DOI 10.1109/CVPR.1994.323930; Kambhamettu C., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P222, DOI 10.1109/CVPR.1992.223271; KAMBHAMETTU C, 1991, P SCAND C IM AN, P1126; KAMBHAMETTU C, 1994, HDB PATTERN RECOGNIT, P405; KOENDERINK JJ, 1986, J OPT SOC AM A, V3, P242, DOI 10.1364/JOSAA.3.000242; LASKOV P, 2002, P 5 AS C COMP VIS JA, V1, P19; LASKOV P, 2001, P BRIT MACH VIS, P273; Laskov P, 2001, THESIS U DELAWARE; Lutkepohl H., 1996, HDB MATRICES; Magnus J. R., 1988, WILEY SERIES PROBABI; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; Mishra S. K., 1992, International Journal of Imaging Systems and Technology, V4, P214, DOI 10.1002/ima.1850040308; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P730, DOI 10.1109/34.85661; Shi CJR, 2000, IEEE T COMPUT AID D, V19, P1, DOI 10.1109/43.822616; TANG CK, 1999, P 7 INT C COMP VIS K, P426; Tao H, 2002, INT J COMPUT VISION, V50, P111, DOI 10.1023/A:1020389714861; TAO H, 1999, P COMP VIS PATT REC, V1, P611; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; TRUCCO E, 1995, IEEE T PATTERN ANAL, V17, P177, DOI 10.1109/34.368172; Wang YM, 2000, PROC CVPR IEEE, P644, DOI 10.1109/CVPR.2000.854933; Weatherburn C.E, 2016, DIFFERENTIAL GEOMETR; Yahia HM, 2000, PROC CVPR IEEE, P663, DOI 10.1109/CVPR.2000.855883; Zhou L, 2001, IEEE T PATTERN ANAL, V23, P1330, DOI 10.1109/34.969121; Zhou L, 2000, PROC CVPR IEEE, P752, DOI 10.1109/CVPR.2000.854950	46	16	17	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2003	25	10					1349	1354		10.1109/TPAMI.2003.1233911	http://dx.doi.org/10.1109/TPAMI.2003.1233911			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	723ZE					2022-12-18	WOS:000185460800017
J	Sheynin, S; Tuzikov, A				Sheynin, S; Tuzikov, A			Moment computation for objects with spline curve boundary	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						area; moment; parametric curve; spline; explicit formulae	POLYGONS; FORMULAS	A new approach is proposed for computation of area and geometric moments for a plane object with a spline curve boundary. The explicit formulae are obtained for area and low order moment calculation. The complexity of calculation depends on the moment order, spline degree, and the number of control points used in spline representation. The formulae proposed use the advantage that the sequence of spline control points is cyclic. It allowed us to reduce substantially the number of summands in them. The formulae might be useful in different applications where it is necessary to perform measurements for shapes with a smooth boundary.	Natl Acad Sci Belarus, Natl Ctr Informat Resources & Technol, Minsk 220072, BELARUS	National Academy of Sciences of Belarus (NASB)	Sheynin, S (corresponding author), Natl Acad Sci Belarus, Natl Ctr Informat Resources & Technol, Akad Skaja 25, Minsk 220072, BELARUS.	sheynin@mpen.bas-net.by; tuzikov@mpen.bas-net.by	Tuzikov, Alexander V./AGX-5875-2022	Tuzikov, Alexander V./0000-0001-5970-4852				Catmull Edwin, 1974, COMPUT AIDED GEOM D, P317, DOI 10.1016/B978-0-12-079050-0.50020-5; ELDER G, 2000, 200004 CIS COMP SCI; FLUSSER J, 1999, N1946 ACAD SCI CZECH; Gonzalez-Ochoa C, 1998, ACM T GRAPHIC, V17, P143, DOI 10.1145/285857.285858; Jacob M, 2001, IEEE T PATTERN ANAL, V23, P633, DOI 10.1109/34.927463; LI BC, 1993, PATTERN RECOGN, V26, P1229, DOI 10.1016/0031-3203(93)90207-D; LIGGETT JA, 1988, COMMUN APPL NUMER M, V4, P815, DOI 10.1002/cnm.1630040616; Mukundan R., 1998, MOMENT FUNCTIONS IMA; Qin KH, 2000, VISUAL COMPUT, V16, P177, DOI 10.1007/s003710050206; REISS T, 1993, LECT NOTES COMPUTER, V676; Sheynin SA, 2001, PATTERN RECOGN LETT, V22, P1103, DOI 10.1016/S0167-8655(01)00067-8; SINGER MH, 1993, PATTERN RECOGN, V26, P1019, DOI 10.1016/0031-3203(93)90003-F; Soldea O, 2002, COMPUT AIDED DESIGN, V34, P529, DOI 10.1016/S0010-4485(01)00124-5; UEDA K, 1999, P 1999 IEEE INT C IN, P309; Watt A., 1993, 3D COMPUTER GRAPHICS; Wu CH, 2001, PATTERN RECOGN, V34, P1319, DOI 10.1016/S0031-3203(00)00100-X; YANG J, 1996, SCI AGR SINICA, V29, P7; [No title captured]	18	16	22	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2003	25	10					1317	1322		10.1109/TPAMI.2003.1233905	http://dx.doi.org/10.1109/TPAMI.2003.1233905			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	723ZE					2022-12-18	WOS:000185460800011
J	Hoogs, A; Collins, R; Kaucic, R; Mundy, J				Hoogs, A; Collins, R; Kaucic, R; Mundy, J			A common set of perceptual observables for grouping, figure-ground discrimination, and texture classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						perceptual grouping; texture classification; image segmentation; figure-ground separation	NORMALIZED CUTS; IMAGE; REFLECTANCE; ROBUST	We present a complete set of perceptual observables that provides a unified image description for grouping, figure-ground separation, and texture analysis. Although much progess has been made recently in treating contours and texture simultaneously for image segmentation and grouping, current approaches rely on different models for contours, regions, and texture such as one-dimensional intensity discontinuities for contours and filter bank responses for texture. This results in expensive computation that arbitrates between these disparate representations at each pixel. In our approach, salient image content such as contours, regions, and texture are represented in a common, low-level framework of image observables. We model the image as a partition of surfaces bounded by intensity discontinuities and derive perceptual measures as relations between neighboring surfaces. This enables us to extend the traditional Gestalt measures based on local edge geometry and contrast to region-based measures that jointly exploit large-scale image topology, photometry, and geometry. These measures provide a natural basis for grouping on multidimensional similarity criteria and texture is directly derived as relational properties on local region neighborhoods. The viability of our model is demonstrated by applying the common observables to texture recognition, figure-ground separation, and generic image segmentation. The texture classification algorithm approaches or exceeds the accuracy of filter bank approaches on both periodic and nonperiodic textures that have significant 3D structure. The measures are invariant to image rotation and slowly varying against large changes in illumination, viewpoint, and scale. The same perceptual measures are successfully applied in a difficult figure-ground separation problem in aerial images. Regions are first filtered, then grouped, using an efficient search algorithm based on perceptual salience to delineate objects of interest. Results for both are shown on large sets of complex, real-world images exhibiting difficult conditions.	GE Corp Res & Dev, Moscow 123098, Russia; Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA; Brown Univ, Div Engn, Providence, RI 02912 USA	General Electric; Rensselaer Polytechnic Institute; Brown University	Hoogs, A (corresponding author), GE Corp Res & Dev, KWC 408B,1 Res Circle, Moscow 123098, Russia.	hoogs@crd.ge.com; collinsr@cs.rpi.edu; kaucic@crd.ge.com; mundy@lems.brown.edu						Amir A, 1998, IEEE T PATTERN ANAL, V20, P168, DOI 10.1109/34.659934; Basri R, 2001, IEEE T PATTERN ANAL, V23, P519, DOI 10.1109/34.922709; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; CULA O, 2001, P C COMP VIS PATT RE; DANA K, 1998, P C COMP VIS PATT RE; Dana KJ, 1997, PROC CVPR IEEE, P151, DOI 10.1109/CVPR.1997.609313; Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778; Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Guy G, 1996, INT J COMPUT VISION, V20, P113, DOI 10.1007/BF00144119; HERAULT L, 1993, IEEE T PATTERN ANAL, V15, P899, DOI 10.1109/34.232076; Hoogs A, 2000, INT C PATT RECOG, P284, DOI 10.1109/ICPR.2000.905320; HORMANN T, 1998, IEEE T PATTERN ANAL, V20, P803; Jacobs DW, 1996, IEEE T PATTERN ANAL, V18, P23, DOI 10.1109/34.476008; KONISHI S, 2000, P C COMP VIS PATT RE; Leonardis A., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P121, DOI 10.1109/ICCV.1990.139508; LEUNG T, 1999, P INT C COMP VIS; MALIK J, 1999, P INT C COMP VIS; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; Nock R, 2001, PROC CVPR IEEE, P271; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; ROCK I, 1990, SCI AM, V263, P84, DOI 10.1038/scientificamerican1290-84; Sarkar S, 2000, IEEE T PATTERN ANAL, V22, P504, DOI 10.1109/34.857006; SARKAR S, 1996, P C COMP VIS PATT RE, P1996; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shi JB, 1997, PROC CVPR IEEE, P731, DOI 10.1109/CVPR.1997.609407; Suen PH, 2000, IEEE T PATTERN ANAL, V22, P491, DOI 10.1109/34.857005; TU Z, 2001, P INT C COMPUTER VIS; WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673; ZALESNY A, 2001, P C COMPUTER VISION; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	32	16	19	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2003	25	4					458	474		10.1109/TPAMI.2003.1190572	http://dx.doi.org/10.1109/TPAMI.2003.1190572			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	659BV					2022-12-18	WOS:000181758100007
J	Sipe, MA; Casasent, D				Sipe, MA; Casasent, D			Feature space trajectory methods for active computer vision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						active vision; classification; object recognition; pose estimation	OBJECT RECOGNITION; POSE ESTIMATION; CLASSIFICATION	We advance new active object recognition algorithms that classify rigid objects and estimate their pose from intensity images. Our algorithms automatically detect if the class or pose of an object is ambiguous in a given image, reposition the sensor as needed, and incorporate data from multiple object views in determining the final object class and pose estimate. A probabilistic feature space trajectory (FST) in a global eigenspace is used to represent 3D distorted views of an object and to estimate the class and pose of an input object. Confidence measures for the class and pose estimates, derived using the probabilistic FST object representation, determine when additional observations are required as well as where the sensor should be positioned to provide the most useful information. We demonstrate the ability to use FSTs constructed from images rendered from computer-aided design models to recognize real objects in real images and present test results for a set of metal machined parts.	Cellom Inc, Pittsburgh, PA 15219 USA; Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Sipe, MA (corresponding author), Cellom Inc, Pittsburgh, PA 15219 USA.	sipe@ieee.org; casasent@ece.cmu.edu						Arbel T., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P248, DOI 10.1109/ICCV.1999.791227; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; CALLARI FG, 1996, P 13 INT C PATT REC, V1, P925; Casasent D, 1998, OPT ENG, V37, P914, DOI 10.1117/1.602017; Casasent D, 1997, OPT ENG, V36, P2719, DOI 10.1117/1.601520; Casasent DP, 1995, NEURAL NETWORKS, V8, P1117, DOI 10.1016/0893-6080(95)00047-X; DARRELL B, 1996, P 1996 IEEE C COMP V; Dickinson SJ, 1997, COMPUT VIS IMAGE UND, V67, P239, DOI 10.1006/cviu.1997.0532; Grimson W. E. L., 1990, OBJECT RECOGNITION C; HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063; HUTCHINSON SA, 1992, DATA FUSION ROBOTICS, P165; Jain A, 2004, FUNDAMENTALS DIGITAL, P342; JOHNSON AE, 1998, P COMP VIS PATT REC, P23; Lamdan Y., 1988, P IEEE INT C COMP VI, P238; LENDARIS GG, 1970, PR INST ELECTR ELECT, V58, P198, DOI 10.1109/PROC.1970.7593; Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227; Murase H, 1997, PATTERN RECOGN LETT, V18, P375, DOI 10.1016/S0167-8655(97)00017-2; MURASE H, 1994, IEEE T PATTERN ANAL, V16, P1219, DOI 10.1109/34.387485; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; NEILBERG L, 1996, THESIS CARNEGIE MELL; Papoulis A., 2002, PROBABILITY RANDOM V; PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814; Sipe MA, 1998, P SOC PHOTO-OPT INS, V3522, P139, DOI 10.1117/12.325758; Sipe MA, 1999, P SOC PHOTO-OPT INS, V3837, P2, DOI 10.1117/12.360284; Sipe MA, 1998, NEURAL COMPUT APPL, V7, P195, DOI 10.1007/BF01414882; STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785; Therrien C. W., 1989, DECISION ESTIMATION; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wells G, 1996, IMAGE VISION COMPUT, V14, P715, DOI 10.1016/0262-8856(96)89022-6	29	16	17	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2002	24	12					1634	1643		10.1109/TPAMI.2002.1114854	http://dx.doi.org/10.1109/TPAMI.2002.1114854			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	618YA					2022-12-18	WOS:000179444600007
J	Cheung, KW; Yeung, DY; Chin, RT				Cheung, KW; Yeung, DY; Chin, RT			Bidirectional deformable matching with application to handwritten character extraction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						model-based segmentation; deformable models; Bayesian inference; bidirectional matching; Hausdorff matching	RECOGNITION; TEMPLATES	To achieve integrated segmentation and recognition in complex scenes, the model-based approach has widely been accepted as a promising paradigm. However, the performance is still far from satisfactory when the target object is highly deformed and the level of outlier contamination is high. In this paper, we first describe two Bayesian frameworks, one for classifying input patterns and another for detecting target patterns in complex scenes using deformable models. Then, we show that the two frameworks are similar to the forward-reverse setting of Hausdorff matching and that their matching and discriminating properties are complementary to each other. By properly combining the two frameworks, we propose a new matching scheme called bidirectional matching. This combined approach inherits the advantages of the two Bayesian frameworks. In particular, we have obtained encouraging empirical results on shape-based pattern extraction, using a subset of the CEDAR handwriting database containing handwritten words of highly varying shape.	Hong Kong Baptist Coll, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China; Hong Kong Univ Sci & Technol, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	Hong Kong Baptist University; Hong Kong University of Science & Technology	Cheung, KW (corresponding author), Hong Kong Baptist Coll, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.	william@comp.hkbu.edu.hk; dyyeung@cs.ust.hk; roland@cs.ust.hk	Chin, Roland Tai Hong/E-9856-2010	Cheung, William Kwok Wai/0000-0002-7428-2050				Cheung KW, 1998, IEEE T PATTERN ANAL, V20, P1382, DOI 10.1109/34.735813; CHEUNG KW, 2000, THESIS HONG KONG U S; CHEUNG KW, 1999, P 7 INT C COMP VIS S, P1105; DAYAN P, 1995, NEURAL COMPUT, V7, P889, DOI 10.1162/neco.1995.7.5.889; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555; Jolly MPD, 1996, IEEE T PATTERN ANAL, V18, P293, DOI 10.1109/34.485557; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.448; Revow M, 1996, IEEE T PATTERN ANAL, V18, P592, DOI 10.1109/34.506410; Rucklidge W., 1996, EFFICIENT VISUAL REC; YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169	13	16	16	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2002	24	8					1133	1139		10.1109/TPAMI.2002.1024135	http://dx.doi.org/10.1109/TPAMI.2002.1024135			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	578JY					2022-12-18	WOS:000177115100011
J	Luong, QT; Fua, P; Leclerc, YG				Luong, QT; Fua, P; Leclerc, YG			The radiometry of multiple images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						reconstruction; multiple views; linear models; radiometric recovery; Lambertian reflection; point light sources; ambiant illumination; surface albedo	STEREO; RANGE	We introduce a methodology for radiometric reconstruction, the simultaneous recovery of multiple illuminants and surface albedoes from multiple views, assuming that the geometry of the scene and of the cameras is known. We formulate the linear theory of multiple illuminants and show its similarities with the theory of geometric recovery of multiple views. Linear and nonlinear implementations are proposed, simulation results are discussed, and, finally, results on real images are presented.	SRI Int, Ctr Artificial Intelligence, Menlo Pk, CA 94025 USA; Ecole Polytech Fed Lausanne, LIG, DI, CH-1015 Lausanne, Switzerland	SRI International; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Luong, QT (corresponding author), SRI Int, Ctr Artificial Intelligence, Menlo Pk, CA 94025 USA.	luong@ai.sri.com; pascal.fua@epfl.ch; leclerc@ai.sri.com		Fua, Pascal/0000-0002-6702-9970				Angelopoulou E., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P442, DOI 10.1109/ICCV.1999.791254; BARIBEAU R, 1992, IEEE T PATTERN ANAL, V14, P263, DOI 10.1109/34.121793; Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611; Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P564; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P671, DOI 10.1109/34.85657; Fua P., 1993, Machine Vision and Applications, V6, P35, DOI 10.1007/BF01212430; FUA P, 1995, INT J COMPUT VISION, V16, P35, DOI 10.1007/BF01428192; FUA P, 2000, INT J COMPUTER VISIO, V38; Georghiades AS, 1999, IEEE WORKSHOP ON MULTI-VIEW MODELING & ANALYSIS OF VISUAL SCENES (MVIEW'99). PROCEEDINGS, P47, DOI 10.1109/MVIEW.1999.781082; GRUEN A, 1992, P WORKSH CAL OR CAM; Hartley R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P761, DOI 10.1109/CVPR.1992.223179; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HAYAKAWA H, 1994, J OPT SOC AM A, V11, P3079, DOI 10.1364/JOSAA.11.003079; HONR B, 1986, ROBOT VISION; Horn B.K.P., 1989, SHAPE SHADING; IKEUCHI K, 1991, IEEE T PATTERN ANAL, V13, P1139, DOI 10.1109/34.103274; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Luong QT, 1997, INT J COMPUT VISION, V22, P261, DOI 10.1023/A:1007982716991; Luong QT, 1996, INT J COMPUT VISION, V17, P43, DOI 10.1007/BF00127818; Marschner S. R, 1998, THESIS CORNELL U; Marschner SR, 1997, FIFTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS, AND APPLICATIONS, P262; Mitsunaga T., P 1999 IEEE COMP SOC, P374; MOSES Y, 1993, THESIS WEIZMANN I SC; Mukawa N., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P507, DOI 10.1109/ICCV.1990.139583; Press WH, 1986, NUMERICAL RECIPES C, V818; Sato I., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P875, DOI 10.1109/ICCV.1999.790314; SATO M, 1997, P SIGGRAPH COMPUTER, P379; Shashua A, 1997, INT J COMPUT VISION, V21, P99, DOI 10.1023/A:1007975506780; SILVER W, 1990, THESIS MIT; SZELISKI R, 1999, P BRIT MACH VIS C, V2, P314; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Yu YZ, 1999, COMP GRAPH, P215; ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658	37	16	18	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2002	24	1					19	33		10.1109/34.982882	http://dx.doi.org/10.1109/34.982882			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	506FZ		Green Submitted			2022-12-18	WOS:000172960300002
J	Kamgar-Parsi, B; Kamgar-Parsi, B; Jain, AK; Dayhoff, JE				Kamgar-Parsi, B; Kamgar-Parsi, B; Jain, AK; Dayhoff, JE			Aircraft detection: A case study in using human similarity measure	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						aircraft detection; automatic target recognition (ATR); data generation; learning; similarity measure; training set augmentation	DEFORMABLE TEMPLATES; VISION	The problem of screening images of the skies to determine whether or not aircraft are present is of both theoretical and practical interest. After the most prominent signal in an infrared image of the sky is extracted, the question is whether the signal corresponds to an aircraft. Common approaches calculate the degree of similarity of the shape of the 2D signal with a model aircraft using a similarity measure such as Euclidean distance, and make a decision based on whether the degree of similarity exceeds a (prespecified) threshold. We present a new approach that avoids metric similarity measures and the use of thresholds, and instead attempts to learn similarity measures like those used by humans. In the absence of sufficient real data, the approach allows us to specifically generate an arbitrarily large number of training exemplars projecting near the classification boundary. Once trained on such a training set, the performance of our neural network-based system was comparable to that of a human expert and far better than a network trained only on the available real data. Furthermore, the results were considerably better than those obtained using an Euclidean discriminator.	USN, Res Lab, Washington, DC 20375 USA; Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA; Complex Res Solut Inc, Silver Spring, MD 20906 USA	United States Department of Defense; United States Navy; Naval Research Laboratory; Michigan State University	Kamgar-Parsi, B (corresponding author), USN, Res Lab, Washington, DC 20375 USA.	kamgar@aic.nrl.navy.mil; behzad@ait.nrl.navy.mil; jain@cse.msu.edu; dayhoff@pressroom.com						AMIT Y, 1991, J AM STAT ASSOC, V86, P376, DOI 10.2307/2290581; BALUJA S, 1994, CONNECTION SCI, V6; Cun YL., 1990, ADV NEURAL INF PROCE, P598, DOI DOI 10.5555/109230.109298; David E., 1986, PARALLEL DISTRIBUTED, P318, DOI DOI 10.5555/104279.104293; Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555; Jain AK, 1997, PATTERN RECOGN, V30, P183, DOI 10.1016/S0031-3203(96)00073-8; KAMGARPARSI B, 1989, IEEE T PATTERN ANAL, V11, P929, DOI 10.1109/34.35496; KAMGARPARSI B, 1999, Patent No. 5923776; KAMGARPARSI B, UNPUB RECOGNIZING EY; KAMGARPARSI B, 1999, P IEEE C COMP VIS PA, V1, P268; KAMGARPARSI B, 1995, 1995 NRL REV, P143; KARGARPARSI B, 1995, P WORLD C NEUR NETW, V2, P174; MOODY J, 1992, ADV NEUR IN, V4, P683; Osuna E., 1997, 1602 AI MIT; POGGIO T, 2000, INT J COMPUTER VISIO, V38; Ross TD, 1999, P SOC PHOTO-OPT INS, V3721, P662, DOI 10.1117/12.357681; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Santini S, 1999, IEEE T PATTERN ANAL, V21, P871, DOI 10.1109/34.790428; Tesauro G, 1994, ADV NEURAL INFORM PR, V6, P263; UTTAL WR, 1995, PERCEPT PSYCHOPHYS, V57, P668, DOI 10.3758/BF03213272; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd	21	16	16	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2001	23	12					1404	1414		10.1109/34.977564	http://dx.doi.org/10.1109/34.977564			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	500NY					2022-12-18	WOS:000172634700006
J	Cloppet, F; Oliva, JM; Stamon, G				Cloppet, F; Oliva, JM; Stamon, G			Angular bisector network, a simplified generalized voronoi diagram: Application to processing complex intersections in biomedical images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape descriptors; skeleton; generalized Voronoi diagram; graph theory	SHAPE	One of the major goals of computer vision is the research and the development of flexible methods for shape description. A large group of shape description techniques is given by heuristic approaches, which yield acceptable results in the description of simple shapes and regions. In this case; objects are represented by a planar graph with nodes symbolizing subregions from region decomposition, and region shape is then described by the graph properties. In this paper, the Angular Bisector Network (ABN), a descriptor of polygonal shape, is used to automatically detect intersections between neurites of cell structures. Some properties of the ABN, such as linear algebraic complexity, easy extraction of characteristic points, etc., are very useful and experimental results are promising.	Univ Paris 05, UFR Math & Informat, Lab SIP CRIP5, F-75006 Paris, France; BEICIP, FRANLAB, Geosci Software Div, F-92502 Rueil Malmaison, France	UDICE-French Research Universities; Universite Paris Cite	Cloppet, F (corresponding author), Univ Paris 05, UFR Math & Informat, Lab SIP CRIP5, 45 Rue St Peres, F-75006 Paris, France.							Aichholzer O, 1995, J UNIVERS COMPUT SCI, V1, P752, DOI DOI 10.3217/JUCS-001-12-0752; Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154; BOISSONNAT JD, 1995, EDISCIENCE INT, P425; Brandt J. W., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P666, DOI 10.1109/CVPR.1991.139773; CLOPPET F, 1996, P IMAGECOM 96 MAY, P239; Deseilligny MP, 1998, IEEE T PATTERN ANAL, V20, P505, DOI 10.1109/34.682180; LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346; LEE DT, 1982, IEEE T PATTERN ANAL, V4, P363, DOI 10.1109/TPAMI.1982.4767267; MONTANARI U, 1969, J ACM, V16, P534, DOI 10.1145/321541.321543; OLIVA JM, 1995, THESIS ENSME FRANCE; OLIVA JM, 1996, COMPUT GRAPH FORUM, V15, P397; PERRIN M, 1994, RR942 ENSME; SCHMITT M, 1988, GEOMETRY ROBOTICS; SRINAVASAN V, 1992, P IEEE, V80, P534; SUGIHARA K, 1993, CVGIP-GRAPH MODEL IM, V55, P522, DOI 10.1006/cgip.1993.1039	15	16	18	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2000	22	1					120	128		10.1109/34.824824	http://dx.doi.org/10.1109/34.824824			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	286WR					2022-12-18	WOS:000085472300007
J	Blostein, D; Haken, L				Blostein, D; Haken, L			Using diagram generation software to improve diagram recognition: A case study of music notation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						document image analysis; graphics recognition; diagram recognition; music notation	PRINTED MUSIC	Diagrams are widely used in society, to transmit information such as circuit designs, music, mathematical formulae, architectural plans, and molecular structure. Computers must process diagrams both as images (marks on paper) and as information. A diagram recognizer translates from image to information and a diagram generator translates from information to image. Current technology for diagram generation is ahead of the technology for diagram recognition. Diagram generators have extensive knowledge of notational conventions which relate to readability and aesthetics, whereas current diagram recognizers focus on the hard constraints of the notation. To create a recognizer capable of exploiting layout information, it is expedient to reuse the expertise in existing diagram generators. In particular, we discuss the use of Lime (our editor and generator for music notation) to proofread and correct the raw output of MIDIScan (a third-party commercial recognizer for music notation). Over the past several years, this combination of software has been distributed to thousands of users.	Queens Univ, Kingston, ON K7L 3N6, Canada; Univ Illinois, CERL Sound Grp, Urbana, IL 61801 USA	Queens University - Canada; University of Illinois System; University of Illinois Urbana-Champaign	Blostein, D (corresponding author), Queens Univ, Kingston, ON K7L 3N6, Canada.	blostein@cs.queensu.ca						Abak AT, 1997, PROC INT CONF DOC, P697, DOI 10.1109/ICDAR.1997.620597; BAINBRIDGE D, 1996, P 19 AUSTR COMP SCI, P308; BAINBRIDGE D, 1997, HDB CHARACTER RECOGN, P583; BELKIN A, 1994, COMPUT MUSIC J, V18, P53, DOI 10.2307/3680522; BERTIN J., 2011, SEMIOLOGY GRAPHICS D; BLOSTEIN D, 1994, SOFTWARE PRACT EXPER, V24, P289, DOI 10.1002/spe.4380240304; BLOSTEIN D, 1991, COMMUN ACM, V34, P88, DOI 10.1145/102868.102874; Blostein D., 1996, Graphics Recognition, Methods and Applications. First International Workshop. Selected Papers, P106; Blostein D., 1996, HDB OPTICAL CHARACTE, P557; CHAUNDY T, 1957, PRINTING MATH; Chhabra AK, 1998, LECT NOTES COMPUT SC, V1389, P68; CHOU PA, 1995, P SOC PHOTO-OPT INS, V2422, P66; Cordella L. P., 1996, Graphics Recognition, Methods and Applications. First International Workshop. Selected Papers, P13; DORI D, 1997, HDB CHARACTER RECOGN, P421; GOURLAY J, 1987, OSUCISRC1087TR35 DEP; HAKEN L, 1993, COMPUT MUSIC J, V17, P43, DOI 10.2307/3680942; HAKEN L, 1995, P INT COMP MUS C BAN, P118; HARALICK RM, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P385, DOI 10.1109/CVPR.1994.323855; JOSEPH S, 1995, P INT WORKSH GRAPH R, P189; Kanungo T, 1995, P INT WORKSH GRAPH R, P119; KNUTH DE, 1979, B AM MATH SOC, V1, P337, DOI 10.1090/S0273-0979-1979-14598-1; KOPEC GE, 1994, IEEE T PATTERN ANAL, V16, P602, DOI 10.1109/34.295905; Kopec GE, 1996, J ELECTRON IMAGING, V5, P7, DOI 10.1117/12.227527; LOHSE GL, 1994, COMMUN ACM, V37, P36, DOI 10.1145/198366.198376; Nieminen S, 1998, P SOC PHOTO-OPT INS, V3305, P100, DOI 10.1117/12.304623; O'Gorman L., 1995, DOCUMENT IMAGE ANAL; PAULISCH FN, 1990, SOFTWARE PRACT EXPER, V20, pS63, DOI 10.1002/spe.4380201307; PETRE M, 1995, COMMUN ACM, V38, P33, DOI 10.1145/203241.203251; PHILLIPS I, 1998, GRAPHICS RECOGNITION, P375; Prerau D, 1992, STRUCTURED DOCUMENT, P405; PROTSKO LB, 1991, IEEE T SOFTWARE ENG, V17, P10, DOI 10.1109/32.67575; Read G., 1979, MUSIC NOTATION MANUA; ROSS T, 1970, ART MUSIC ENGRAVING; ROUSH D, 1988, OSUCISRC388TR10 DEP; Serrano J. A., 1995, Proceedings. 11th IEEE International Symposium on Visual Languages (Cat. No.95TB8105), P211, DOI 10.1109/VL.1995.520811; SLOBODA J, 1981, VISIBLE LANG, V15, P86; Smeulders AWM, 1998, LECT NOTES COMPUT SC, V1389, P335; Strzalkowski T., 1990, Computational Intelligence, V6, P145, DOI 10.1111/j.1467-8640.1990.tb00131.x; TAMASSIA R, 1988, IEEE T SYST MAN CYB, V18, P61, DOI 10.1109/21.87055; WENYIN L, 1998, GRAPHICS RECOGNITION, P359; 1998, INT J DOCUMENT A FEB; 1999, P INT C DOC AN REC J; 1991, P INT C DOC AN REC F; 1997, P INT C DOC AN REC G; 1998, P IAPR WORKSH DOC AN; 1995, P IAPR WORKSH GRAPH; 1999, P IAPR WORKSH GRAPH; 1997, P ANN S DOC AN INF R; 1996, P IAPR WORKSH DOC AN; 1995, P INT C DOC AN REC C; 1993, P INT C DOC AN REC J; 1997, P IAPR WORKSH GRAPH; 1994, P IAPR WORKSH DOC AN	54	16	16	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1999	21	11					1121	1136		10.1109/34.809106	http://dx.doi.org/10.1109/34.809106			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	259YG					2022-12-18	WOS:000083921100002
J	Bouchaffra, D; Govindaraju, V; Srihari, S				Bouchaffra, D; Govindaraju, V; Srihari, S			A methodology for mapping scores to probabilities	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						recognizer; reestimation methods; feature space; classifier; probability	RECOGNITION	This paper describes the derivation of probability of correctness from scores assigned by most recognizers. Derivation of probability values puts the output of different recognizers on the same scale; this makes comparison across recognizers trivial.	SUNY Buffalo, Dept Comp Sci, CEDAR, Amherst, NY 14228 USA	State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Bouchaffra, D (corresponding author), SUNY Buffalo, Dept Comp Sci, CEDAR, Amherst, NY 14228 USA.		Srihari, Sargur N/E-8100-2011					Bouchaffra D, 1996, INT J IMAG SYST TECH, V7, P320, DOI 10.1002/(SICI)1098-1098(199624)7:4<320::AID-IMA7>3.0.CO;2-A; Bouchaffra D, 1998, PROC CVPR IEEE, P930, DOI 10.1109/CVPR.1998.698716; Duda R.O., 1973, J ROYAL STAT SOC SER; FAVATA J, 1996, P INT WORKSH FRONT H; HARTIGAN JA, 1975, CLUSERING ALGORITHMS; HO TK, 1994, IEEE T PATTERN ANAL, V16; Hull JJ, 1996, IEEE T PATTERN ANAL, V18, P1251, DOI 10.1109/34.546261; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Kim G, 1997, IEEE T PATTERN ANAL, V19, P366, DOI 10.1109/34.588017; SUEN CY, 1992, P IEEE, V80, P1162, DOI 10.1109/5.156477	10	16	18	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1999	21	9					923	927		10.1109/34.790432	http://dx.doi.org/10.1109/34.790432			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	234TZ		Green Submitted			2022-12-18	WOS:000082501600008
J	Cucchiara, R; Filicori, F				Cucchiara, R; Filicori, F			The Vector-Gradient Hough Transform	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hough transform; shape detection; visual inspection; feature extraction; image analysis; object recognition		The paper presents a new transform, called Vector-Gradient Hough Transform, for identifying elongated shapes in gray-scale images. This goal is achieved not only by collecting information on the edges of the objects, but also by reconstructing their transversal profile of luminosity. The main features of the new approach are related to its vector space formulation and the associated capability of exploiting all the vector information of the luminosity gradient.	Univ Ferrara, Dipartimento Ingn, I-44100 Ferrara, Italy; Univ Bologna, DEIS, I-410136 Bologna, Italy	University of Ferrara; University of Bologna	Cucchiara, R (corresponding author), Univ Ferrara, Dipartimento Ingn, Via Sagat 1, I-44100 Ferrara, Italy.		Cucchiara, Rita/L-3006-2015	Cucchiara, Rita/0000-0002-2239-283X; FILICORI, FABIO/0000-0001-7461-5145				COSTA LD, 1993, CVGIP-GRAPH MODEL IM, V55, P180, DOI 10.1006/cgip.1993.1013; CUCCHIARA R, 1996, 33 U FERR DIP ING; DEANS SR, 1981, IEEE T PATTERN ANAL, V3; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; HUDDLESTON JN, 1993, CVGIP-IMAG UNDERSTAN, V57, P227, DOI 10.1006/ciun.1993.1015; ILLINGWORTH J, 1988, COMPUTER VISION GRAP, V43, P221; NEWMAN TS, 1995, COMPUT VIS IMAGE UND, V61, P231, DOI 10.1006/cviu.1995.1017; OGORMAN F, 1976, IEEE T COMPUT, V25, P449, DOI 10.1109/TC.1976.1674627; PAO DCW, 1992, IEEE T PATTERN ANAL, V14, P1076, DOI 10.1109/34.166622; ROSENFELD A, 1988, COMPUT VISION GRAPH, V41, P293, DOI 10.1016/0734-189X(88)90104-1; VANVEEN TM, 1981, PATTERN RECOGN, V14, P137, DOI 10.1016/0031-3203(81)90055-8; [No title captured]	12	16	19	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1998	20	7					746	750		10.1109/34.689304	http://dx.doi.org/10.1109/34.689304			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZY930		Green Accepted			2022-12-18	WOS:000074677200006
J	Horiuchi, T				Horiuchi, T			Decision rule for pattern classification by integrating interval feature values	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian classification; Dempster-Shafer theory; integration; pattern classification; probability		Pattern classification based on Bayesian statistical decision theory needs a complete knowledge of the probability laws to perform the classification. In the actual pattern classification, however, it is generally impossible to get the complete knowledge as constant feature values by the influence of noise. Therefore, it is necessary to construct more flexible and robust theory for pattern classification. In this paper, a pattern classification theory using feature values defined on closed interval is formalized in the framework of Dempster-Shafer measure. Then, in order to make up lacked information, an integration algorithm is proposed, which integrates information observed by several information sources with considering source values.	Iwate Prefectural Univ, Fac Software & Informat Sci, Morioka, Iwate 0200173, Japan		Horiuchi, T (corresponding author), Iwate Prefectural Univ, Fac Software & Informat Sci, Morioka, Iwate 0200173, Japan.	tah@iwate-pu.ac.jp	Horiuchi, Takahiko/M-7864-2017	Horiuchi, Takahiko/0000-0002-8197-6499				ANDRESS KM, 1988, AI MAG, V9, P75; BERGER RL, 1979, COMMUN STAT A-THEOR, V8, P543, DOI 10.1080/03610927908827780; Chen C. H., 1978, Pattern Recognition and Signal Processing, P117; CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406; CHOW CK, 1994, P 3 ANN S DOC AN INF, P1; Chow CK., 1957, IRE T ELECT COMPUTER, VEC-6, P247, DOI DOI 10.1109/TEC.1957.5222035; DEMPSTER AP, 1967, ANN MATH STAT, V38, P325, DOI 10.1214/aoms/1177698950; DUBUISSON B, 1993, PATTERN RECOGN, V26, P155, DOI 10.1016/0031-3203(93)90097-G; Duda R.O., 1973, J ROYAL STAT SOC SER; Fukunaga K., 1990, INTRO STAT PATTERN C; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; GARVEY TD, 1987, IEEE T GEOSCI REMOTE, V25, P294, DOI 10.1109/TGRS.1987.289801; GUPTA SD, 1977, MULTIVARIATE ANAL, V4; GUPTA SD, 1973, DISCRIMINANT ANAL PR; Ha TM, 1997, IEEE T PATTERN ANAL, V19, P608, DOI 10.1109/34.601248; HA TM, 1996, P 13 INT C PATT REC, V2, P75; HAMPEL FR, 1986, ROBUST STATICS APPRO; Horiuchi T, 1996, INT J SYST SCI, V27, P447, DOI 10.1080/00207729608929236; HORIUCHI T, 1996, IN PRESS PATTERN REC, V2, P176; Huber P., 1981, ROBUST STAT; KADANE JB, 1978, ANN STAT, V6, P1095, DOI 10.1214/aos/1176344313; KHARIN Y., 1996, ROBUSTNESS STAT PATT; Lachenbruch PA, 1975, DISCRIMINANT ANAL; LAUNER L, 1979, ROBUSTNESS STATICS; Matsuyama T., 1993, IEICE T JAPAN, VJ76-D-2, P843; MATSUYAMA T, 1994, P MULT FUS INT INT S, P379; Mclachlan GJ., 2005, DISCRIMINANT ANAL ST; PATRICK FA, 1972, FUNDAMENTALS PATTERN; REY WJJ, 1978, LECT NOTES MATH, V690, P1; Rieder H., 1994, ROBUST ASYMPTOTIC ST; Ripley BD., 1996; Shafer G., 1976, MATH THEORY EVIDENCE, VVolume 1; Smets P., 1990, UNCERTAINTY ARTIF IN, V5, P29; TIKU ML, 1986, ROBUST INFERENCE; Tukey J.W., 1960, CONTRIBUTIONS PROBAB, P448; VERHAGEN CJDM, 1980, REP PROG PHYS, V43, P785, DOI 10.1088/0034-4885/43/6/002; YAGER RR, 1987, INFORM SCIENCES, V41, P93, DOI 10.1016/0020-0255(87)90007-7; Zadeh LA, 1984, AI MAG, V5, P81, DOI DOI 10.1609/aimag.v5i3.452	38	16	18	1	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1998	20	4					440	448		10.1109/34.677286	http://dx.doi.org/10.1109/34.677286			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZP214					2022-12-18	WOS:000073729200011
J	Debrunner, C; Ahuja, N				Debrunner, C; Ahuja, N			Segmentation and factorization-based motion and structure estimation for long image sequences	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multiple motion segmentation; motion sequence segmentation; image segmentation; image motion factorization; motion understanding; motion estimation; trajectory detection; point tracking		This paper presents a computer algorithm which, given a dense temporal sequence of intensity images of multiple moving objects, will separate the images into regions showing distinct objects, and, for those objects which are rotating, will calculate the three-dimensional structure and motion.	Lockheed Martin Corp, Denver, CO 80201 USA; Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA; Univ Illinois, Beckman Inst, Urbana, IL 61801 USA	Lockheed Martin; University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign	Debrunner, C (corresponding author), Lockheed Martin Corp, Denver, CO 80201 USA.	chris.h.debrunner@lmco.com						ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; BERGEN JR, 1990, P INT C COMP VIS OS; BLOSTEIN SD, 1991, IEEE T SIGNAL PROCES, V39, P1611, DOI 10.1109/78.134399; BOULT TE, 1991, P IEEE MOT WORKSH PR, P21; DEBRUNNER C, UNPUB ESTIMATION STR; DEBRUNNER C, 1990, THESIS U ILLINOIS UR; Debrunner C. H., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P384, DOI 10.1109/ICPR.1990.118133; FANG JQ, 1984, IEEE T PATTERN ANAL, V6, P545, DOI 10.1109/TPAMI.1984.4767569; Hildreth E., 1984, MEASUREMENT VISUAL M; KANADE T, 1991, COMMUNICATION    OCT; KUNG SY, 1983, J OPT SOC AM, V73, P1799, DOI 10.1364/JOSA.73.001799; RANADE S, 1980, PATTERN RECOGN, V12, P269, DOI 10.1016/0031-3203(80)90067-9; Salari V., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P327; Sethi I. K., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P667; SETHI IK, 1987, IEEE T PATTERN ANAL, V9, P56, DOI 10.1109/TPAMI.1987.4767872; SETHI IK, 1987, NATO ASI SERIES F, V30, P119; THOMPSON WB, 1985, IEEE T PATTERN ANAL, V7, P374, DOI 10.1109/TPAMI.1985.4767677; Tomasi C., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P21, DOI 10.1109/WVM.1991.212792; ULLMAN S, 1979, PROC R SOC SER B-BIO, V203, P405, DOI 10.1098/rspb.1979.0006; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779	20	16	16	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1998	20	2					206	211		10.1109/34.659941	http://dx.doi.org/10.1109/34.659941			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YZ697					2022-12-18	WOS:000072281800010
J	Gevorkian, DZ; Astola, JT; Atourian, SM				Gevorkian, DZ; Astola, JT; Atourian, SM			Improving Gil-Werman algorithm for running Min and Max filters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						running min and max; morphological filters; algorithms; computational complexity		The current best bound on the number of comparison operations needed to compute the running maximum or minimum over a p-element sliding data window is approximately three comparisons per output sample [1], [2], [3], [4]. This bound is probabilistic for the algorithms in [2], [3], [4] and is derived for their complexities on the average for independent, identically distributed (i.i.d.) input signals (uniformly i.i.d., in the case of the algorithm in [2]). The worst-case complexities of these algorithms are O(p). The worst-case complexity C-1 = 3 - 4/p comparisons per output sample for 1D signals is achieved in the Gil-Werman algorithm [1]. In this correspondence we propose a modification of the Gil-Werman algorithm with the same worst-case complexity but with a lower average complexity. A theoretical analysis shows that using the proposed modification the complexities of sliding Max or Min 1D and 2D filters over i.i.d. signals are reduced to C-1 = 2.5 - 3.5/p + 1/p(2) and C-2 = 5 - 7/p + 2/p(2) comparisons per output sample on the average, respectively. Simulations confirm the theoretical results. Moreover, experiments show that even for highly correlated data, namely, for real images the behavior of the algorithm remains the same as for i.i.d. signals.			Gevorkian, DZ (corresponding author), TAMPERE UNIV,SIGNAL PROC LAB,POB 553,FIN-33101 TAMPERE,FINLAND.		Astola, Jaakko T/G-4297-2014	Astola, Jaakko/0000-0002-2750-5311				BOVIK AC, 1983, IEEE T ACOUST SPEECH, V31, P1342, DOI 10.1109/TASSP.1983.1164247; BUTZ AR, 1993, ELECTRON LETT, V29, P1547, DOI 10.1049/el:19931031; DOUGLAS S, 1996, P IEEE INT S CIRC SY, V5, P5; Douglas SC, 1996, IEEE T SIGNAL PROCES, V44, P2872, DOI 10.1109/78.542446; Douglas SC, 1994, IEEE SIGNAL PROC LET, V1, P49, DOI 10.1109/97.295321; GIL J, 1993, IEEE T PATTERN ANAL, V15, P504, DOI 10.1109/34.211471; PITAS I, 1989, IEEE T CIRCUITS SYST, V36, P795, DOI 10.1109/31.90400; SERRA J, 1985, IMAGE ANAL MATH MORP; VEMIS M, 1995, SIGNAL PROCESS, V45, P161, DOI 10.1016/0165-1684(95)00048-I; WERMAN M, 1985, IEEE T PATTERN ANAL, V7, P730, DOI 10.1109/TPAMI.1985.4767732	10	16	22	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1997	19	5					526	529		10.1109/34.589214	http://dx.doi.org/10.1109/34.589214			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XB163					2022-12-18	WOS:A1997XB16300013
J	Oommen, BJ; Zhang, K				Oommen, BJ; Zhang, K			The normalized string editing problem revisited	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						sequence processing; string editing; normalized string distances; Levenshtein Distance	SUBSEQUENCES; COMPUTATION; ALGORITHM; DISTANCES	Marzal and Vidal [8] recently considered the problem of computing the normalized edit distance between two strings, and reported experimental results which demonstrated the use of the measure to recognize hand-written characters. Their paper formulated the theoretical properties of the measure and developed two algorithms to compute it. In this short communication we shall demonstrate how this measure is related to an auxiliary measure already defined in the literature-the inter-string constrained edit distance [10], [11], [15]. Since the normalized edit distance can be computed efficiently using the latter, the analytic and experimental results reported in [8] can be obtained just as accurately, but more efficiently, using the strategies presented here.	UNIV WESTERN ONTARIO, DEPT COMP SCI, LONDON, ON N6A 5B7, CANADA	Western University (University of Western Ontario)	Oommen, BJ (corresponding author), CARLETON UNIV, SCH COMP SCI, OTTAWA, ON K1S 5B6, CANADA.		Oommen, B. John/P-6323-2017	Oommen, B. John/0000-0002-5105-1575				HALL PAV, 1980, COMPUT SURV, V12, P381, DOI 10.1145/356827.356830; KASHYAP RL, 1983, IEEE T SOFTWARE ENG, V9, P365, DOI 10.1109/TSE.1983.237018; KASHYAP RL, 1981, INFORM SCIENCES, V23, P123, DOI 10.1016/0020-0255(81)90052-9; KASHYAP RL, 1983, INT J COMPUT MATH, V13, P17, DOI 10.1080/00207168308803349; Kruskal J.B., 1983, TIME WARPS STRING ED; KUKICH K, 1992, COMPUT SURV, V24, P377; Levenshtein V. I, 1966, SOV PHYS DOKL, V10, P707; MARZAL A, 1993, IEEE T PATTERN ANAL, V15, P926, DOI 10.1109/34.232078; MASEK WJ, 1980, J COMPUT SYST SCI, V20, P18, DOI 10.1016/0022-0000(80)90002-1; MEGIDDO N, 1983, J ACM, V30, P852, DOI 10.1145/2157.322410; OOMMEN BJ, 1988, IEEE T PATTERN ANAL, V10, P983; OOMMEN BJ, 1986, INFORM SCIENCES, V40, P267, DOI 10.1016/0020-0255(86)90061-7; OOMMEN BJ, 1987, IEEE T PATTERN ANAL, V9, P676, DOI 10.1109/TPAMI.1987.4767962; PETERSON JL, 1980, COMMUN ACM, V23, P676, DOI 10.1145/359038.359041; VIDAL E, IN PRESS FAST COMPUT; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; ZHANG K, 1990, P IASTED INT S, P92	18	16	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1996	18	6					669	672		10.1109/34.506420	http://dx.doi.org/10.1109/34.506420			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UR254		Green Submitted			2022-12-18	WOS:A1996UR25400013
J	LINDENBAUM, M				LINDENBAUM, M			BOUNDS ON SHAPE-RECOGNITION PERFORMANCE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						RECOGNITION; LOCALIZATION; PROBABILISTIC MODELS; OBJECT SIMILARITY; PERFORMANCE EVALUATION; COMPUTER VISION	MODEL-BASED RECOGNITION; OBJECT RECOGNITION; LOCALIZATION	The Localization and the recognition tasks are analyzed here relying on a probabilistic model, and independently of the recognition method used. Rigorous upper and lower bounds on the probability that a set of measurements is sufficient to localize an object within a certain precision, are derived. The bounds quantify the difficulty of the localization task regarding many of its aspects, including the number of measurements, the uncertainty in their position, the information they reveal, and the ''ability of the objects to confuse the recognizer.'' Similar results are obtained for the recognition task. The asymptotic difficulty of recognition/localization tasks is characterized by a single parameter, thus making it possible to compare between different tasks. The bounds provide a theoretical benchmark to which experimentally measured performance of localization/recognition methods can be compared.			LINDENBAUM, M (corresponding author), TECHNION ISRAEL INST TECHNOL,DEPT COMP SCI,IL-32000 HAIFA,ISRAEL.							ALT H, 1988, DISCRETE COMPUT GEOM, V3, P237, DOI 10.1007/BF02187910; ARKIN EM, 1991, IEEE T PATTERN ANAL, V13, P209, DOI 10.1109/34.75509; BAIRD HS, 1985, MODEL BASED IMAGE MA; BENEDEK GM, IN PRESS THEORETICAL, P80; CASS AC, 1991, 3RD P INT C COMP VIS, P360; COSTA M, 1989, 6TH P ISR C AI, P35; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; ELLIS RE, 1991, IEEE T ROBOTIC AUTOM, V7, P361, DOI 10.1109/70.88145; FAUGERAS OD, 1983, 8TH P INT JOINT C AR, P996; GOTTSCHALK PG, 1989, INT J ROBOT RES, V8, P110, DOI 10.1177/027836498900800608; Grimson W. E. L., 1990, OBJECT RECOGNITION C; GRIMSON WEL, 1990, IEEE T PATTERN ANAL, V12, P255, DOI 10.1109/34.49052; GRIMSON WEL, 1991, IEEE T PATTERN ANAL, V13, P1201, DOI 10.1109/34.106994; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; GRIMSON WEL, 1986, J ACM, V33, P658, DOI 10.1145/6490.6492; GRIMSON WEL, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P334; GRIMSON WEL, 1991, 3RD P INT C COMP VIS, P644; GRIMSON WEL, 1991, IEEE T PATTERN ANAL, V13; GRIMSON WEL, 1992, IEEE T PATTERN ANAL, V14; GRIMSON WEL, 1992, 2 EUR C COMP VIS, P291; LAMDAN Y, 1988, IEEE C COMP VIS PATT, P22; LINDENBAUM M, 1993, CIS9329 COMP SCI DEP; LINDENBAUM M, 1994, INT C PATTERN RECOGN; LINDENBAUM M, 1992, CIS9215 COMP SCI DEP; MOSES Y, 1991, MIT AI1301 AI LAB; MUNDY JL, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P268; [No title captured]	27	16	16	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1995	17	7					666	680		10.1109/34.391409	http://dx.doi.org/10.1109/34.391409			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RF224					2022-12-18	WOS:A1995RF22400003
J	STONE, JV; ISARD, SD				STONE, JV; ISARD, SD			ADAPTIVE SCALE FILTERING - A GENERAL-METHOD FOR OBTAINING SHAPE FROM TEXTURE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						SHAPE FROM TEXTURE; FILTER; ADAPTIVE; SCALE PERSPECTIVE		We introduce adaptive stale filtering, a general method for deriving shape from texture under perspective projection without recourse to prior segmentation of the image into geometric texture elements (texels), and without thresholding of filtered images. If texels on a given surface can be identified in an image then the orientation of that surface can be obtained [11]. However, there is no general characterization of texels for arbitrary textures. Furthermore, even if the size and shape of texels on the surface is invariant with regard to position, perspective projection ensures that the size and shape of the corresponding image texels vary by orders of magnitude. Commencing with an initial set F-o of identical image filters, adaptive scale filtering iteratively derives a set F-N which contains a unique filter for each image position. Each element of F-N is tuned to the three-dimensional structure of the surface; that is, all image filters in F-N back-project to an identical shape and size on the surface. Thus image texels of various sizes, but associated with a single spatial scale on the surface, can be identified in different parts of the image. When combined with conventional shape from texture methods, edges derived using F-N provide accurate estimates of surface orientation. Results for planar surfaces are presented.	UNIV SUSSEX,SCH COGNIT & COMP SCI,BRIGHTON BN1 9QY,E SUSSEX,ENGLAND; UNIV EDINBURGH,CTR SPEECH TECHNOL RES,EDINBURGH,MIDLOTHIAN,SCOTLAND	University of Sussex; University of Edinburgh	STONE, JV (corresponding author), UNIV SUSSEX,SCH BIOL SCI,BRIGHTON BN1 9QY,E SUSSEX,ENGLAND.							ALOIMONOS J, 1988, BIOL CYBERN, V58, P345, DOI 10.1007/BF00363944; BAJCSY R, 1976, COMPUTER GRAPHICS IM, P552; BLAKE A, 1990, ARTIF INTELL, V45, P323, DOI 10.1016/0004-3702(90)90011-N; BLOSTEIN D, 1989, PAMI, V1, P1233; GARDING J, 1991, THESIS U STOCKHOLM S; JAU JY, 1990, COMPUT VISION GRAPH, V52, P248, DOI 10.1016/0734-189X(90)90057-3; JOHNSTON A, 1989, MODELS BRAIN FUNCTIO; KANATANI K, 1989, ARTIF INTELL, V38, P1, DOI 10.1016/0004-3702(89)90066-0; KUBE P, 1986, 2TH ANN C COGN SOC A, P235; Marr D., 1981, VISION; OHTA Y, 1981, P INT JOINT C ART IN, P746; STONE JV, 1991, 209 U SUSS COGN COMP; STONE JV, 1992, P BRIT MACH VIS C LE, P177; STONE JV, 1990, P BRIT MACH VIS C, P181; STONE JV, 1992, PHILOS T ROY SOC B, P53; STONE JV, 1991, THESIS U SUSSEX ENGL; TURNER MR, 1991, BIOL CYBERN, V65, P215, DOI 10.1007/BF00206219; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9	18	16	17	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1995	17	7					713	718		10.1109/34.391414	http://dx.doi.org/10.1109/34.391414			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RF224					2022-12-18	WOS:A1995RF22400007
J	HELOR, Y; WERMAN, M				HELOR, Y; WERMAN, M			POSE ESTIMATION BY FUSING NOISY DATA OF DIFFERENT DIMENSIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						SENSOR FUSION; KALMAN FILTER; POSE ESTIMATION; MODEL BASED; OBJECT RECOGNITION	ORIENTATION; RANGE	A method for fusing and integrating different 2D and 3D measurements for pose estimation is proposed. The 2D measured data is viewed as 3D data with infinite uncertainty in particular directions. The method is implemented using Kalman filtering. It is robust and easily parallelizable.			HELOR, Y (corresponding author), HEBREW UNIV JERUSALEM, INST COMP SCI, IL-91904 JERUSALEM, ISRAEL.							ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; Blostein S. D., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P246; FAUGERAS OD, 1984, P AI APPLICATIONS C, P218; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GAUGERAS OD, 1986, TECHNIQUES 3D MACHIN, P13; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063; HELOR Y, 1993, THESIS HEBREW U JERU; HELOR Y, 1991, ACTIVE PERCEPTION RO; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; Jazwinski A.H., 1970, STOCHASTIC PROCESSES; KUMAR R, 1992, THESIS U MASSACHUSET; Lin Z., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P194; Liu Y., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P82, DOI 10.1109/CVPR.1988.196218; MATTHIES L, 1987, INT J ROBOTICS RES, V4; Maybeck P. S., 1982, STOCHASTIC MODELS ES; SABATA B, 1991, CVGIP-IMAG UNDERSTAN, V54, P309, DOI 10.1016/1049-9660(91)90032-K; SHMUEL A, 1990, 10TH P INT C PATT RE, P48; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; YUAN JSC, 1989, IEEE T ROBOTIC AUTOM, V5, P129, DOI 10.1109/70.88034	21	16	21	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1995	17	2					195	201		10.1109/34.368169	http://dx.doi.org/10.1109/34.368169			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE825					2022-12-18	WOS:A1995QE82500009
J	BHANU, B; POGGIO, T				BHANU, B; POGGIO, T			INTRODUCTION TO THE SPECIAL SECTION ON LEARNING IN COMPUTER VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									MIT, CAMBRIDGE, MA 02139 USA	Massachusetts Institute of Technology (MIT)	BHANU, B (corresponding author), UNIV CALIF RIVERSIDE, RIVERSIDE, CA 92521 USA.							De Jong K., 1988, Machine Learning, V3, P121, DOI 10.1023/A:1022606120092; MICHALSKI RS, 1986, MACHINE LEARNING, V2; MING J, 1990, SEP P DARPA IM UND W, P742; NEGAHDARIPOUR S, 1992, IEEE P COMPUT SOC C, P189; NEGAHDARIPOUR S, 1991, FINAL REPORT NSF WOR; ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519; SAMUEL A, 1963, COMPUTERS THOUGHT; SEGRE AM, 1992, IEEE EXPERT, V7, P31	8	16	16	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1994	16	9					865	867						3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PE802					2022-12-18	WOS:A1994PE80200001
J	CHIORBOLI, G; VECCHI, GP				CHIORBOLI, G; VECCHI, GP			DESIGN OF FIDUCIALS FOR ACCURATE REGISTRATION USING MACHINE VISION - COMMENT	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						MACHINE VISION; IMAGE PROCESSING; POSITIONAL ACCURACY; SUBPIXEL REGISTRATION; CAMERA CALIBRATION		Subpixel registration accuracy improves by one order of magnitude if images are not binarized as indicated in the referenced paper, but gray scale information is fully exploited in calculating centroid position.			CHIORBOLI, G (corresponding author), UNIV PARMA,DIPARTIMENTO INGN INFORMAZ,VIALE SCI,I-43100 PARMA,ITALY.		Chiorboli, Giovanni/H-4622-2015	Chiorboli, Giovanni/0000-0001-7399-1827				BOSE CB, 1990, IEEE T PATTERN ANAL, V12, P1196, DOI 10.1109/34.62609	1	16	16	2	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1993	15	12					1330	1332		10.1109/34.250850	http://dx.doi.org/10.1109/34.250850			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MP176					2022-12-18	WOS:A1993MP17600011
J	SCHNORR, C				SCHNORR, C			ON FUNCTIONALS WITH GREYVALUE-CONTROLLED SMOOTHNESS TERMS FOR DETERMINING OPTICAL-FLOW	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						COMPUTATIONAL VISION; ENERGY FUNCTIONALS; IMAGE MOTION ANALYSIS; OPTICAL FLOW; REGULARIZATION; SMOOTHNESS TERMS	IMAGE SEQUENCES; MOTION; VISION; SHAPE	Recently, we have provided a thorough mathematical formulation of the approach of Horn and Schunck for determining optical flow and its modification due to Nagel. In this correspondence, we generalize this approach to the case that motion information is given locally by more than one constraint equation. Applying this scheme to three constraint equations reported in the literature, we obtain, as a special case, a generalization of Nagel's approach. We show that this new approach improves on similar approaches by Nagel and Enkelmann [16]. We show existence and uniqueness of solutions under very general conditions that, in turn, ensures the applicability of standard techniques to compute an approximate solution. Our results can be used to avoid numerical problems of Nagel and Enkelmann's approach, which have been reported by Aisbett [1].			SCHNORR, C (corresponding author), UNIV HAMBURG,FACHBEREICH INFORMAT,ARBEITSBEREICH KOGNIT SYST,W-2000 HAMBURG 13,GERMANY.							AISBETT J, 1989, IEEE T PATTERN ANAL, V11, P512, DOI 10.1109/34.24783; ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; ANANDAN P, 1987, MAY INT C COMP VIS L, P219; BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962; Ciarlet P.G., 1978, FINITE ELEMENT METHO; GIROSI F, 1989, MAR P IEEE WORKSH VI, P116; Golub G.H., 2013, MATRIX COMPUTATIONS, P357; HACKBUSCH W, 1985, MULTIGRID METHODS, V5; HASHIMOTO M, 1987, COMPUT VISION GRAPH, V39, P28, DOI 10.1016/S0734-189X(87)80201-3; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; Lawson C. L., 1974, SOLVING LEAST SQUARE; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NAGEL HH, 1987, ARTIF INTELL, V33, P299, DOI 10.1016/0004-3702(87)90041-5; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; NAGEL HH, 1983, AUG P INT JOINT C AR, P945; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; SCHNORR C, 1992, INT J COMPUT VISION, V8, P153, DOI 10.1007/BF00127172; SCHNORR C, 1991, INT J COMPUT VISION, V6, P25, DOI 10.1007/BF00127124; SHNORR C, 1987, THESIS U KARLSRUHE; TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8; TRETIAK O, 1984, P 7 INT C PATT REC M, P16; URAS S, 1988, BIOL CYBERN, V60, P79, DOI 10.1007/BF00202895	23	16	16	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1993	15	10					1074	1079		10.1109/34.254064	http://dx.doi.org/10.1109/34.254064			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MD775					2022-12-18	WOS:A1993MD77500009
J	HUANG, XF; GU, J; WU, YS				HUANG, XF; GU, J; WU, YS			A CONSTRAINED APPROACH TO MULTIFONT CHINESE CHARACTER-RECOGNITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						CONSTRAINT GRAPH; CORRESPONDENCE MAPPING; FORCE-DRIVEN ELASTIC MATCHING; OPTICAL CHARACTER RECOGNITION (OCR); RELAXATIONAL OPTIMIZATION	RELAXATION; TRANSFORM; MODEL	Recognizing multifont, multiple-size Chinese characters was a difficult task in the area of optical character recognition (OCR). In this correspondence, we introduce the constraint graph as a general character representation framework. Each character class is described by a constraint graph model. Sampling points on a character skeleton are taken as nodes in the graph. Connection constraints and position constraints are taken as arcs in the graph. For patterns of the same character class, this model captures both the topological invariance and the geometrical invariance in a general and uniform way. Character recognition is then formulated as a constraint-based optimization problem. A cooperative relaxation matching algorithm that solves this optimization problem is developed. A practical OCR system able to recognize multifont, multiple-size Chinese characters with a satisfactory performance was implemented.	TSING HUA UNIV,DEPT ELECT ENGN,BEIJING,PEOPLES R CHINA	Tsinghua University	HUANG, XF (corresponding author), UNIV CALGARY,DEPT ELECT & COMP ENGN,CALGARY T2N 1N4,ALBERTA,CANADA.							CASH GL, 1987, COMPUT VISION GRAPH, V39, P291, DOI 10.1016/S0734-189X(87)80183-4; CHEN LH, 1990, PATTERN RECOGN, V23, P1189, DOI 10.1016/0031-3203(90)90115-2; CHENG FH, 1989, IEEE T PATTERN ANAL, V11, P429, DOI 10.1109/34.19042; FU KS, 1986, IEEE T PATT ANAL MAC, V8; FUKUNAGA K, 1982, INTRO STATISTICAL PA; GAN KW, 1991, PATTERN RECOGN, V25, P877; GOVINDAN VK, 1990, PATTERN RECOGN, V23, P671, DOI 10.1016/0031-3203(90)90091-X; GU J, IN PRESS CONSTRAINT; HUANG JS, 1987, PATTERN RECOGN, V20, P425, DOI 10.1016/0031-3203(87)90068-9; KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274, DOI 10.1109/TPAMI.1987.4767901; KRZYZAK A, 1990, P 1 INT WORKSH FRONT, P155; KUNDU A, 1989, PATTERN RECOGN, V22, P283, DOI 10.1016/0031-3203(89)90076-9; LECUN Y, 1990, P FRONTIERS HANDWRIT, V145; LEUNG CH, 1988, 1 INNS M, P31; MORI S, 1992, P IEEE, V80, P1029, DOI 10.1109/5.156468; NASRABADI NM, 1991, IEEE T SYST MAN CYB, V21, P1523, DOI 10.1109/21.135694; SIMON JC, 1972, PATTERN RECOGN, V4, P73, DOI 10.1016/0031-3203(72)90020-9; XIE SL, 1988, PATTERN RECOGN, V21, P1, DOI 10.1016/0031-3203(88)90066-0	18	16	18	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1993	15	8					838	843		10.1109/34.236243	http://dx.doi.org/10.1109/34.236243			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LR948					2022-12-18	WOS:A1993LR94800011
J	COPPINI, G; DEMI, M; POLI, R; VALLI, G				COPPINI, G; DEMI, M; POLI, R; VALLI, G			AN ARTIFICIAL VISION SYSTEM FOR X-RAY IMAGES OF HUMAN CORONARY TREES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						BOTTOM-UP PROCESSING; COMPUTER VISION; HIERARCHICAL SYMBOLIC REPRESENTATION; MEDICAL IMAGING; PRIMAL SKETCH; SEGMENTATION; X-RAY CORONARY ANGIOGRAPHY		The coronary tree expert (CORTEX) analyzer, which is a vision system for the description of the bidimensional shape and position of coronary vessels using standard nonsubtracted radiographic images, is described. A bottom-up approach was used to deal with the typical characteristics of medical images, such as structural and nonstructural noise and complexity and variability of biological shapes. On these grounds, grouping criteria were utilized to produce intermediate image representations with an increasing complexity in a hierarchical manner (from edge points to curves, segments, bars, and finally to vessels and their mutual relations). In this way, uncertain, inconsistent, and deficient information was efficiently processed. The evaluation of CORTEX segmentation is also performed according to a signal-detection-theory-like approach.	UNIV FIRENZE, DIPARTIMENTO INGN ELETTRON, FLORENCE, ITALY	University of Florence	COPPINI, G (corresponding author), CNR, INST CLIN PHYSIOL, I-56100 PISA, ITALY.		Coppini, Giuseppe/C-4000-2009	Coppini, Giuseppe/0000-0002-1931-0282				CALAMAI R, 1990, J NUCL MED ALLIED S, V34, P42; CATROS JY, 1988, PATTERN RECOGN LETT, V8, P123, DOI 10.1016/0167-8655(88)90053-0; Coppini G., 1989, Proceedings. Computers in Cardiology 1988 (Cat. No.88CH2733-4), P293, DOI 10.1109/CIC.1988.72620; Egan J.P., 1975, SIGNAL DETECTION THE; EICHEL PH, 1988, IEEE T MED IMAGING, V7, P313, DOI 10.1109/42.14514; ELION JL, 1988, P COMPUT CARDIOLOGY, P201; FLEANGLE SR, 1987, P COMPUT CARDIOLOGY, P197; GECKLE WJ, 1987, P COMPUT CARDIOLOGY, P269; Grossman W., 1986, CARDIAC CATHETERIZAT; KITAMURA K, 1988, IEEE T MED IMAGING, V7, P173, DOI 10.1109/42.7779; Macovski A., 1983, MED IMAGING SYSTEMS; Marr D., 1982, VISION; POPE DL, 1987, P COMPUT CARDIOLOGY, P277; Reiber J H, 1984, IEEE Trans Med Imaging, V3, P131, DOI 10.1109/TMI.1984.4307669; STANFIELD S, 1986, INFORMATION PROCESSI, P364; SUN Y, 1986, P COMPUT CARDIOLOGY, P583; YING S, 1989, IEEE T MED IMAGING, V8, P78, DOI 10.1109/42.20365	17	16	16	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1993	15	2					156	162		10.1109/34.192487	http://dx.doi.org/10.1109/34.192487			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KL910					2022-12-18	WOS:A1993KL91000006
J	TIRUMALAI, AP; SCHUNCK, BG; JAIN, RC				TIRUMALAI, AP; SCHUNCK, BG; JAIN, RC			DYNAMIC STEREO WITH SELF-CALIBRATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						ACTIVE VISION; DEPTH RECOVERY; DYNAMIC STEREO; ENVIRONMENT MODELING; KALMAN FILTERING; RECURSIVE ESTIMATION; ROBUST ALGORITHMS; SELF-CALIBRATION; SENSOR FUSION; 3-D SENSING		We present an approach for incremental refinement of disparity maps obtained from a dynamic stereo sequence of a static scene. The approach has been implemented using a binocular stereo vision system mounted on a mobile robot. We present a robust least median of squares (LMS)-based algorithm to recover the camera motion between successive viewpoints, which provides a self-calibration mechanism. The recovered motion is utilized for recursive disparity prediction and refinement using a robust Kalman filter model.	UNIV MICHIGAN,ARTIFICIAL INTELLIGENCE LAB,ANN ARBOR,MI 48109	University of Michigan System; University of Michigan	TIRUMALAI, AP (corresponding author), UNIV S CAROLINA,DEPT COMP SCI,COLUMBIA,SC 29208, USA.							ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; Ayache N., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P73; Ballard D.H., 1982, COMPUTER VISION; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; FORSTNER W, 1987, COMPUT VISION GRAPH, V40, P273, DOI 10.1016/S0734-189X(87)80144-5; Gelb A., 1974, APPL OPTIMAL ESTIMAT; HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063; HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127; Huber P., 1981, ROBUST STATISTICS, DOI [10.1002/0471725250, 10.1002/0471725250.ch1]; MASRELIEZ CJ, 1975, IEEE T AUTOMAT CONTR, VAC20, P107, DOI 10.1109/TAC.1975.1100882; MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032; MOEZZI S, 1990, IEEE T ROBOTIC AUTOM, P1148; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; SCHUNCK BG, 1990, P INT WORKSHOP ROBUS, P1; SINHA SS, 1992, IEEE T PATTERN ANAL, V14, P36, DOI 10.1109/34.107012	16	16	17	2	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1992	14	12					1184	1189		10.1109/34.177383	http://dx.doi.org/10.1109/34.177383			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KC573					2022-12-18	WOS:A1992KC57300004
J	STRAFORINI, M; COELHO, C; CAMPANI, M; TORRE, V				STRAFORINI, M; COELHO, C; CAMPANI, M; TORRE, V			THE RECOVERY AND UNDERSTANDING OF A LINE DRAWING FROM INDOOR SCENES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						LINE DRAWING; 3-D STRUCTURE; VANISHING POINTS	PERSPECTIVE IMAGES; EDGE-DETECTION; CONSTRAINTS; POLYHEDRA; OBJECTS; SHAPE	The recovery of the 3-D structure and the recognition of viewed objects from TV images are among the main goals of computer vision. The understanding of images of indoor scenes, such as corridors and offices, is greatly simplified by the recovery of a faithful line drawing of the image and by the exploration of geometrical properties of the viewed scene. In this paper, a general procedure for the understanding of a class of indoor scenes is proposed. The suggested algorithm makes use of an extensive 2-D processing of the image that provides a faithful line drawing of the viewed scene. It also uses procedures adequate for both the understanding of the 3-D structure and for the recognition of several items in the scene.	ELSAG BAILEY,GENOA,ITALY		STRAFORINI, M (corresponding author), UNIV GENOA,DIPARTMENTO FIS,I-16126 GENOA,ITALY.			Campani, Marco/0000-0002-3519-7750				Ballard D.H., 1982, COMPUTER VISION; BARNARD ST, 1983, ARTIF INTELL, V21, P435, DOI 10.1016/S0004-3702(83)80021-6; BARROW HG, 1981, ARTIF INTELL, V17, P75, DOI 10.1016/0004-3702(81)90021-7; BARRY M, 1988, ARTIF INTELL, V37, P291, DOI 10.1016/0004-3702(88)90058-6; BELLUTTA P, 1989, P IEEE WORKSHOP INTE; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CAPRILE B, 1990, IN PRESS INT J COMPU; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; COELHO C, 1990, P SPIES INT S APPLIC; DELLAFRANCESCA P, 1942, PROSPECTIVA PINGENDI; DEMICHELI E, 1989, IEEE T PATTERN ANAL, V11, P1106, DOI 10.1109/34.42841; DHOME M, 1987, IEEE T PATTERN ANAL, V9, P429, DOI 10.1109/TPAMI.1987.4767924; FIUMICELLI A, 1986, SPIE, V726; Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627; FREUDER EC, 1980, ARTIF INTELL, V15, P1, DOI 10.1016/0004-3702(80)90020-X; HARALICK RM, 1980, COMPUT VISION GRAPH, V13, P191, DOI 10.1016/0146-664X(80)90046-5; HARALICK RM, 1984, PATTERN RECOGN, V17, P607, DOI 10.1016/0031-3203(84)90014-1; HORAUD R, 1987, IEEE T PATTERN ANAL, V9, P401, DOI 10.1109/TPAMI.1987.4767922; HUFFMAN DA, 1971, MACH INTELL, V6, P259; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; KANATANI K, 1988, COMPUT VISION GRAPH, V41, P28, DOI 10.1016/0734-189X(88)90115-6; KANATANI KI, 1986, IEEE T PATTERN ANAL, V8, P456, DOI 10.1109/TPAMI.1986.4767809; KANTANI K, 1988, ARTIF INTELL, V37, P15; KAPUR D, 1988, ARTIF INTELL, V37, P1, DOI 10.1016/0004-3702(88)90047-1; KENDER J, 1979, AUG P INT JOINT C AR, P475; MACKWORTH AK, 1973, ARTIF INTELL, V4, P121, DOI 10.1016/0004-3702(73)90003-9; MAGEE MJ, 1984, COMPUT VISION GRAPH, V26, P256, DOI 10.1016/0734-189X(84)90188-9; MEHLHORN K, 1984, MULTIDIMENSIONAL SEA; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; MUNDY JL, 1985, P IMAGE UNDERSTANDIN, P83; NAKATANI H, 1986, THESIS OSAKA U; NALWA VS, 1988, INT J COMPUT VISION, V2, P103, DOI 10.1007/BF00133696; NALWA VS, 1988, IEEE T PATTERN ANAL, V10, P514, DOI 10.1109/34.3914; PACIOLI L, 1956, DE DIVINA PROPORTION; QUAN L, 1989, PATTERN RECOGN LETT, V9, P279, DOI 10.1016/0167-8655(89)90006-8; Serra J, 1982, IMAGE ANAL MATH MORP; SHAFER SA, 1983, COMPUT VISION GRAPH, V24, P182, DOI 10.1016/0734-189X(83)90042-7; Shakunaga T., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P594; SHAKUNAGA T, 1988, Y2ND P INT C COMP VI; SUGIHARA K, 1984, ARTIF INTELL, V23, P59, DOI 10.1016/0004-3702(84)90005-5; SUGIHARA K, 1982, IEEE T PATTERN ANAL, V4, P458, DOI 10.1109/TPAMI.1982.4767289; WALKER EL, 1988, ARTIF INTELL, V37, P275, DOI 10.1016/0004-3702(88)90057-4; WALTZ D, 1972, MACAITR271 MIT	44	16	18	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1992	14	2					298	303		10.1109/34.121797	http://dx.doi.org/10.1109/34.121797			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HC029					2022-12-18	WOS:A1992HC02900016
J	KIRYATI, N; BRUCKSTEIN, AM				KIRYATI, N; BRUCKSTEIN, AM			ON NAVIGATING BETWEEN FRIENDS AND FOES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						HOUGH TRANSFORM; LINE FITTING; M-ESTIMATORS; PATH PLANNING; ROBUST LEAST SQUARES TECHNIQUE	HOUGH TRANSFORM	A problem of determining the optimal straight path between a planar set of points is considered. Each point contributes to the cost of a path a value that depends on the distance between the path and the point. The cost function, quantifying this dependence, can be arbitrary and may be different for different points. An algorithm to solve this problem, via an extension of the Hough transform, is described. The range of applications includes straight-line fitting to a set of points in the presence of outliers, navigation, and path planning. The suggested extended Hough transform can be tuned to be equivalent to well-known robust least squares techniques, and allows, in particular, to efficiently carry out approximate M-estimation.	TECHNION ISRAEL INST TECHNOL,DEPT COMP SCI,IL-32000 HAIFA,ISRAEL	Technion Israel Institute of Technology	KIRYATI, N (corresponding author), TECHNION ISRAEL INST TECHNOL,DEPT ELECT ENGN,TECHNION CITY,IL-32000 HAIFA,ISRAEL.			Kiryati, Nahum/0000-0003-1436-2275				DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; DUDA RO, 1973, PATTERN CLASSIFICATI, P328; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; KAMGARPARSI B, 1987, CARTR315 U MAR TECH; KIRYATI N, 1990, 605 ISR I TECHN DEP; KIRYATI N, 1989, 16TH P IEEE C EL EL; KIRYATI N, 1990, OCT P INT WORKSH ROB; KIRYATI N, 1988, EE PUB, V672; KIRYATI N, 1989, 6TH P SCAND C IM AN, P621; NIBLACK W, 1988, JUN P IEEE COMP SOC, P574; PNUELI Y, 1989, 6TH P ISR C ART INT; THRIFT PR, 1983, COMPUT VISION GRAPH, V21, P383, DOI 10.1016/S0734-189X(83)80050-4; WEISS I, 1988, JUN IEEE COMP SOC C, P647	13	16	16	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1991	13	6					602	606		10.1109/34.87346	http://dx.doi.org/10.1109/34.87346			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FU372					2022-12-18	WOS:A1991FU37200009
J	HAVELOCK, DI				HAVELOCK, DI			THE TOPOLOGY OF LOCALES AND ITS EFFECTS ON POSITION UNCERTAINTY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						IMAGE METROLOGY; LOCALES; NOISE; PRECISION; REGISTRATION; TARGETS	DIGITIZED STRAIGHT-LINES; SUBPIXEL REGISTRATION; REPRESENTATION; SEGMENTS	The precision to which the position of a target in a digital image can be estimated, may be analyzed by considering the possible digital representations of the target. Such an analysis leads to regions of indistinguishable target position, referred to as locales. By considering the density, distribution, and shape of these locales the available precision can be estimated. Previously, such analyses have presumed an absence of noise in the digital image. It is shown here how the noise tolerance for position estimation is affected by the topological properties of locales, such as locale connectivity, adjacency, and clustering.			HAVELOCK, DI (corresponding author), NATL RES COUNCIL CANADA,INST MICROSTRUCT SCI,OTTAWA K1A 0R6,ONTARIO,CANADA.							ANDERSON TA, 1985, COMPUT VISION GRAPH, V30, P279, DOI 10.1016/0734-189X(85)90161-6; BERENSTEIN CA, 1988, IEEE T PATTERN ANAL, V10, P880, DOI 10.1109/34.9109; BRUCKSTEIN AM, 1987, IEEE T ACOUST SPEECH, V35, P553, DOI 10.1109/TASSP.1987.1165148; BRUCKSTEIN AM, 1989, DESIGN SHAPES PRECIS; COX IJ, 1990, IEEE T PATTERN ANAL, V12, P721, DOI 10.1109/34.57665; DOROS M, 1984, COMPUT VISION GRAPH, V28, P377, DOI 10.1016/S0734-189X(84)80015-8; DORST L, 1984, IEEE T PATTERN ANAL, V6, P632, DOI 10.1109/TPAMI.1984.4767577; DORST L, 1986, IEEE T PATTERN ANAL, V8, P276, DOI 10.1109/TPAMI.1986.4767781; FORSTNER W, 1982, JUN P ISPRS COMMUN S, V3, P176; HAVELOCK DI, 1989, IEEE T PATTERN ANAL, V11, P1065, DOI 10.1109/34.42837; HAVELOCK DI, 1984, INT ARCH PHOTOGRAMME, V25, P381; HAVELOCK DI, 1989, SEP P C OPT 3 D MEAS, P470; HAVELOCK DI, 1989, THESIS CARLETON U OT; Hill J.W., 1980, MACH INTELL, P75; KATZENELSON J, 1962, IRE T AUTOMAT CONTR, P58; KLAASMAN H, 1975, COMPUT GRAPHICS IMAG, V4, P225; KOPLOWITZ J, 1981, PAMI, V3; NAKAMURA A, 1984, COMPUT VISION GRAPH, V26, P242, DOI 10.1016/0734-189X(84)90187-7; NEUHOFF DL, 1985, IEEE T INFORM THEORY, V31, P53, DOI 10.1109/TIT.1985.1056998; OGORMAN L, 1990, UNPUB 10TH ICPR; TABATABAI AJ, 1984, IEEE T PATTERN ANAL, V6, P181; TIAN Q, 1986, COMPUT VISION GRAPH, V35, P220, DOI 10.1016/0734-189X(86)90028-9; UNRUH JE, 1982, PHOTOGRAMM ENG REM S, V48, P1343; VOSSEPOEL AM, 1982, COMPUT VISION GRAPH, V20, P347, DOI 10.1016/0146-664X(82)90057-0; Widrow B., 1956, IRE T CIRCUIT THEORY, VCT-3, P266, DOI DOI 10.1109/TCT.1956.1086334	25	16	16	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1991	13	4					380	386		10.1109/34.88574	http://dx.doi.org/10.1109/34.88574			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FL566					2022-12-18	WOS:A1991FL56600009
J	JERIAN, C; JAIN, R				JERIAN, C; JAIN, R			POLYNOMIAL METHODS FOR STRUCTURE FROM MOTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MICHIGAN,DEPT ELECT ENGN & COMP SCI,ARTIFICIAL INTELLIGENCE LAB,ANN ARBOR,MI 48109	University of Michigan System; University of Michigan								AGGARWAL JK, 1985, 3RD P IEEE WORKSH VI, P127; DRESCHLER L, 1982, COMPUT VISION GRAPH, V20, P199, DOI 10.1016/0146-664X(82)90081-8; FANG JQ, 1984, IEEE T PATTERN ANAL, V6, P545, DOI 10.1109/TPAMI.1984.4767569; FAUGERAS OD, 1989, MAR P IEEE WORKSH VI, P248; FAUGERAS OD, P ICPR 84, P796; HILDRETH EC, 1987, J OPT SOC AM A, V4, P503; HUANG TS, 1987, APR P BRIT PATT REC; Jacobson N, 1974, BASIC ALGEBRA; JERIAN CP, 1988, THESIS U MICHIGAN; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Mitiche A., 1986, Proceedings of the Workshop on Motion: Representation and Analysis (Cat. No.86CH2322-6), P175; MITICHE A, 1984, P WORKSHOP COMPUTER, P63; SPETSAKIS ME, 1987, P AAAI 6 NAT C ART I, P738; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; WATSON LT, 1980, ACM T MATH SOFTWARE, V6, P252, DOI 10.1145/355887.355899; WILF HS, 1962, MATH PHYSICAL SCI; 1986, MAXIMA USERS GUIDE	17	16	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1990	12	12					1150	1165		10.1109/34.62604	http://dx.doi.org/10.1109/34.62604			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EN500					2022-12-18	WOS:A1990EN50000003
J	KIROUSIS, LM				KIROUSIS, LM			EFFECTIVELY LABELING PLANAR PROJECTIONS OF POLYHEDRA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									COMP TECHNOL INST,GR-26110 PATRAS,GREECE				Kirousis, Lefteris/AAD-3728-2019					CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; FREUDER EC, 1980, ARTIF INTELL, V15, P1, DOI 10.1016/0004-3702(80)90020-X; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; KIROUSIS LM, 1988, J COMPUT SYST SCI, V37, P14, DOI 10.1016/0022-0000(88)90043-8; PAPADIMITRIOU CH, 1985, COMMUNICATION; QUINN MJ, 1984, COMPUT SURV, V16, P319, DOI 10.1145/2514.2515; SUGIHARA K, 1982, IEEE T PATTERN ANAL, V4, P458, DOI 10.1109/TPAMI.1982.4767289; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19; Winston P. H., 1984, ARTIFICIAL INTELLIGE	9	16	16	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1990	12	2					123	130		10.1109/34.44400	http://dx.doi.org/10.1109/34.44400			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CL282		Green Submitted			2022-12-18	WOS:A1990CL28200002
J	KODRATOFF, Y; TECUCI, G				KODRATOFF, Y; TECUCI, G			LEARNING BASED ON CONCEPTUAL DISTANCE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									RES INST COMP & INFORMAT,BUCHAREST,ROMANIA	National Institute R&D Informatics Bucharest	KODRATOFF, Y (corresponding author), UNIV PARIS 11,RECH INFORMAT LAB,F-91405 ORSAY,FRANCE.							BENAMOU N, 1986, LRI305 U PAR SUD RES; Bobrow DG., 1977, COGNITIVE SCI, V1, P3, DOI [DOI 10.1207/S15516709C0G0101_, 10.1207/s15516709cog0101_2, DOI 10.1207/S15516709COG0101_2]; COHEN PR, 1982, HDB ARTIFICIAL INTEL, V3, P323; DIETTERICH TG, 1981, ARTIF INTELL, V16, P257, DOI 10.1016/0004-3702(81)90002-3; FISHER D, 1985, 9TH P INT JOINT C AR, P688; Kodratoff Y., 1987, International Journal of Expert Systems Research and Applications, V1, P39; KODRATOFF Y, 1984, P ECAI84, P483; KODRATOFF Y, 1985, ADV ARTIFICIAL INTEL, P229; LANGLEY P, 1987, 4TH P INT WORKSH MAC; Michalski R. S., 1986, MACHINE LEARNING ART, V2; Michalski R.S., 1983, MACHINE LEARNING ART, V1; MICHALSKI RS, 1983, MACHINE LEARNING ART, P163; Minsky M., 1975, PSYCHOL COMPUTER VIS, P211; MITCHELL TM, 1985, MACHINE LEARNING GUI; SRIDHARAN N, 1983, CBMTR134 RUTG U TECH; TECUCI G, 1983, COMPUT ARTIFICIAL IN, V2; TECUCI G, 1984, COMPUT ARTIFICIAL IN, V3; VANRYZIN J, 1977, CLASSIFICATION CLUST; [No title captured]; [No title captured]	20	16	17	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1988	10	6					897	909		10.1109/34.9111	http://dx.doi.org/10.1109/34.9111			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	Q9971					2022-12-18	WOS:A1988Q997100011
J	GORDON, SJ; SEERING, WP				GORDON, SJ; SEERING, WP			REAL-TIME PART POSITION SENSING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									MIT,ARTIFICIAL INTELLIGENCE LAB,CAMBRIDGE,MA 02139; MIT,DEPT MECH ENGN,CAMBRIDGE,MA 02139	Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT)	GORDON, SJ (corresponding author), INTELLIGENT AUTOMAT SYST INC,MALDEN,MA 02148, USA.							Acton F., 1959, ANAL STRAIGHT LINE D; AGAPAKIS JE, 1985, THESIS MIT; Beers Y., 1957, INTRO THEORY ERROR, V2; BENTON R, 1985, AFWALMLTC1 REP; BOLLE RM, 1985, DEC P SPIE C VIS ROB; BOLLE RM, 1986, IEEE T PATTERN ANAL, V8; BOLLES RB, 1984, ROBOTICS RES; BOLLES RC, 1981, 7TH P INT JOINT C AR, P637; DRAKE A, 1967, FUNDAMENTALS APPLIED; DURRANTWHYTE HF, 1986, IEEE INT C ROBOTICS, P1464; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; FAUGERAS OD, 1984, 2ND P INT S ROB RES; FAUGERAS OD, 1984, ROBOTICS RES; Faux ID, 1979, COMPUTATIONAL GEOMET; Gelb A., 1974, APPL OPTIMAL ESTIMAT; GORDON S, 1987, IEEE, P801; GORDON SJ, 1986, THESIS MIT; GORDON SJ, 1986, IEEE COMPUT SOC P RO, P931; GORDON SJ, 1986, MIT932 ART INT LAB T; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; GRIMSON WEL, 1986, IEEE J ROBOTIC AUTOM, P286; HILL J, 1980, 10TH SRI INT REP, P75; Horn B., 1986, ROBOT VISION, P1; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5; LOZANOPEREZ T, 1987, IEEE T ROBOTIC AUTOM, P202; MASON MT, 1986, ROBOT HANDS MECHANIC; NITZAN D, 1983, 12 SRI INT TECH REP; Oppenheim A.V., 1975, DIGIT SIGNAL PROCESS; PERVIN E, 1982, CMUCS82150 CARN U DE; POPPLESTONE RJ, 1975, 5TH P INT JOINT C AR, P664; RUTKOWSKI WS, 1987, IEEE T ROBOTIC AUTOM, P1419; SALAMIN E, 1979, UNPUB APPLICATION QU; SALISBURY JK, 1982, THESIS STANFORD U; SALISBURY JK, STANCS82921 STANF DE; SHEKHAR S, 1986, IEEE T ROBOTIC AUTOM, P1623; SHIRAI Y, 1971, 2ND P INT JOINT C AR, P80; SMITH FG, 1971, OPTICS; [No title captured]	38	16	17	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1988	10	3					374	386		10.1109/34.3901	http://dx.doi.org/10.1109/34.3901			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	N5337		Green Submitted			2022-12-18	WOS:A1988N533700008
J	GARBER, FD; DJOUADI, A				GARBER, FD; DJOUADI, A			BOUNDS ON THE BAYES CLASSIFICATION ERROR BASED ON PAIRWISE RISK FUNCTIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											GARBER, FD (corresponding author), OHIO STATE UNIV,DEPT ELECT ENGN,ELECTROSCI LAB,COLUMBUS,OH 43210, USA.							CHEN CH, 1978, MAY P IEEE COMP SOC, P188; CHEN CH, 1973, STATISTICAL PATTERN; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; DEVIJVER PA, 1974, IEEE T COMPUT, VC 23, P70, DOI 10.1109/T-C.1974.223779; Devijver PA, 1982, PATTERN RECOGNITION; DJOUADI A, 1987, THESIS OHIO STATE U; DJOUADI A, 7180483 EL LAB REP; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6, P779, DOI 10.1109/TPAMI.1984.4767601; JAIN AK, 1976, IEEE T SYST MAN CYB, V6, P763; KAMIS A, 1985, 7165591 OH STAT U DE; KITTLER J, 1982, IEEE T PATTERN ANAL, V4, P215, DOI 10.1109/TPAMI.1982.4767229; KSIENSKI AA, 1975, P IEEE, V63, P1651, DOI 10.1109/PROC.1975.10033; LAINIOTIS DG, 1969, IEEE T INFORM THEORY, V15, P730, DOI 10.1109/TIT.1969.1054374; LAINIOTIS DG, 1971, IEEE T SYST MAN CYBE, V11, P175; LISSACK TSVI, 1976, IEEE T INFORM THEORY, V22, P34, DOI 10.1109/TIT.1976.1055512; SHORT RD, 1981, IEEE T INFORM THEORY, V27, P622, DOI 10.1109/TIT.1981.1056403; TOUSSAINT GT, 1977, P IEEE, V65, P275, DOI 10.1109/PROC.1977.10469; TOUSSAINT GT, 1974, IEEE T INFORM THEORY, V20, P472, DOI 10.1109/TIT.1974.1055260	18	16	16	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1988	10	2					281	288		10.1109/34.3891	http://dx.doi.org/10.1109/34.3891			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	M2974					2022-12-18	WOS:A1988M297400013
J	GU, J; WANG, W; HENDERSON, TC				GU, J; WANG, W; HENDERSON, TC			A PARALLEL ARCHITECTURE FOR DISCRETE RELAXATION ALGORITHM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV UTAH,DEPT ELECT ENGN,SALT LAKE CITY,UT 84112	Utah System of Higher Education; University of Utah	GU, J (corresponding author), UNIV UTAH,DEPT COMP SCI,SALT LAKE CITY,UT 84112, USA.							[Anonymous], 1940, RELAXATION METHODS E; Ballard D.H., 1982, COMPUTER VISION; BUNDY A, 1984, SYMBOLIC COMPUTATION; BURGER W, 1986, VIRTUAL SHUFFLE DYNA; FISHER AL, 1985, IEEE T COMPUT, V34, P734, DOI 10.1109/TC.1985.1676619; GASPAR M, 1986, COMMUNICATION    DEC; GU J, 1987, IN PRESS DESIGN IMPL; GU J, 1986, UUCSTR86116 U UT DEP; Hayes A. B., 1983, Third Caltech Conference on Very Large Scale Integration, P257; HENDERSON TC, IN PRESS DISCRETE RE; HWANG K, 1984, COMPUTER ARCHITECTUR; KU DCL, 1986, DRA1 DEP COMP SCI CH; KUNG HT, 1985, LECTURE NOTES COMPUT, V163, P70; KUNG SY, 1982, IEEE T COMPUT, V31, P1054, DOI 10.1109/TC.1982.1675922; MCCALL JT, 1985, IEEE T COMPUT, V34, P973, DOI 10.1109/TC.1985.1676530; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SMITH KF, 1986, UUCS86003 U UT DEP C; SMITH KF, 1982, IEEE T ELECTRON DEVI, V29; SNYDER L, 1982, COMPUTER, V15, P47, DOI 10.1109/MC.1982.1653826; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19; WANG W, 1987, IEEE T CIRCUITS SYST, V34; WEISER U, 1981, P CMU C VLSI SYST CO, P226; 1986, DRA2 U SO CAL INF SC	23	16	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1987	9	6					816	831		10.1109/TPAMI.1987.4767988	http://dx.doi.org/10.1109/TPAMI.1987.4767988			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	K6735	21869443				2022-12-18	WOS:A1987K673500009
J	HAIMICOHEN, R; COHEN, A				HAIMICOHEN, R; COHEN, A			GRADIENT-TYPE ALGORITHMS FOR PARTIAL SINGULAR VALUE DECOMPOSITION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									BEN GURION UNIV NEGEV,DEPT ELECT & COMP ENGN,IL-84105 BEERSHEBA,ISRAEL	Ben Gurion University			Haimi-Cohen, Raziel/U-7141-2019	Haimi-Cohen, Raziel/0000-0001-8417-8807				CADZOW JA, 1983, IEE PROC-F, V130, P202, DOI 10.1049/ip-f-1.1983.0034; CHEN H, 1985, 1985 P IEEE INT C AC, P81; Devijver PA, 1982, PATTERN RECOGNITION; FUHRMANN DR, 1984, 1984 P IEEE INT C AC; FUKUNAGA K, 1972, INTRO STATISTICAL PA; GERBRANDS JJ, 1981, PATTERN RECOGN, V14, P375, DOI 10.1016/0031-3203(81)90082-0; Golub G., 1965, SIAM J NUMER ANAL, V2, P205, DOI DOI 10.1137/0702016; GOLUB GH, 1970, NUMER MATH, V14, P403, DOI 10.1007/BF02163027; Gourlay AR, 1973, COMPUTATIONAL METHOD; HAIMICOHEN R, THESIS BENGURION U B; KARHUNEN J, 1984, 1984 P IEEE INT C AC; KLEMA VC, 1980, IEEE T AUTOMAT CONTR, V25, P164, DOI 10.1109/TAC.1980.1102314; KONSTANTINIDES K, 1984, P INT C ACOUST SPEEC, V1; LEUNBERGER AG, 1973, INTRO LINEAR NONLINE; MURAKAMI H, 1982, IEEE T PATTERN ANAL, V4, P511, DOI 10.1109/TPAMI.1982.4767295; OJA E, 1983, SUBSPACE METHODS PAT; PISARENKO VF, 1973, GEOPHYS J ROY ASTR S, V33, P347, DOI 10.1111/j.1365-246X.1973.tb03424.x; PISARENKO VF, 1972, GEOPHYS J ROY ASTRON, V18, P511; RATISHAUSER H, 1969, NUMER MATH, V13, P4; SHLEIN A, 1982, IEEE T PATTERN ANAL, V4, P671; TUFTS DW, 1982, IEEE T ACOUST SPEECH, V30, P671, DOI 10.1109/TASSP.1982.1163927	21	16	16	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1987	9	1					137	142		10.1109/TPAMI.1987.4767879	http://dx.doi.org/10.1109/TPAMI.1987.4767879			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	F3785	21869384				2022-12-18	WOS:A1987F378500012
J	GROSKY, WI; JAIN, R				GROSKY, WI; JAIN, R			A PYRAMID-BASED APPROACH TO SEGMENTATION APPLIED TO REGION MATCHING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MICHIGAN,DEPT ELECT ENGN & COMP SCI,ANN ARBOR,MI 48109	University of Michigan System; University of Michigan	GROSKY, WI (corresponding author), WAYNE STATE UNIV,DEPT COMP SCI,DETROIT,MI 48202, USA.							ADELSON EH, 1981, P C PATT REC IM PROC, P218; AHUJA N, 1984, COMPUT VISION GRAPH, V26, P207, DOI 10.1016/0734-189X(84)90183-X; AHUJA N, 1984, IEEE T PATTERN ANAL, V6, P463, DOI 10.1109/TPAMI.1984.4767551; AHUJA N, 1980, 1ST P NAT C ART INT, P44; ANTONISSE HJ, 1982, COMPUT VISION GRAPH, V19, P367, DOI 10.1016/0146-664X(82)90022-3; Apostol TM., 1960, MATH ANAL; BESL PJ, 1985, COMPUT SURV, V17, P75, DOI 10.1145/4078.4081; BURT PJ, 1981, IEEE T SYST MAN CYB, V11, P802, DOI 10.1109/TSMC.1981.4308619; CASEY RG, 1970, IBM J RES DEV, V14, P548, DOI 10.1147/rd.145.0548; CIBULSKIS JM, 1984, IEEE T SYST MAN CYB, V14, P424, DOI 10.1109/TSMC.1984.6313235; CONNOLLY CI, 1984, MAR P INT C ROB ATL, P25; Doctor L. J., 1981, IEEE Computer Graphics and Applications, V1, P29, DOI 10.1109/MCG.1981.1673936; Duda R.O., 1973, J ROYAL STAT SOC SER; DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; DYER CR, 1977, TR544 U MAR DEP COMP; DYER CR, 1977, TR596 U MAR DEP COMP; Gonzalez R.C., 1977, DIGITAL IMAGE PROCES; GROSKY WI, 1983, OCT P IEEE COMP SOC, P153; GROSKY WI, 1985, CSC8505 WAYN STAT U; HALL EL, 1975, IEEE T BIO-MED ENG, V22, P518, DOI 10.1109/TBME.1975.324475; HARALICK RM, 1980, COMPUT VISION GRAPH, V12, P60, DOI 10.1016/0146-664X(80)90004-0; HARALICK RM, 1983, INT J ROBOT RES, V2, P50, DOI 10.1177/027836498300200105; HARALICK RM, 1983, COMPUT VISION GRAPH, V22, P28, DOI 10.1016/0734-189X(83)90094-4; HONG TH, 1982, IEEE T SYST MAN CYB, V12, P660; HONG TH, 1984, IEEE T PATTERN ANAL, V6, P229, DOI 10.1109/TPAMI.1984.4767506; HONG TH, 1982, IEEE T SYST MAN CYB, V12, P611, DOI 10.1109/TSMC.1982.4308880; HSIA TC, 1980, IEEE T SYST MAN CYB, V11, P831; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; ICHIKAWA T, 1981, IEEE T PATTERN ANAL, V3, P257, DOI 10.1109/TPAMI.1981.4767098; JACKINS CL, 1980, COMPUT VISION GRAPH, V14, P249, DOI 10.1016/0146-664X(80)90055-6; KASIF S, 1983, IEEE T SYST MAN CYB, V13, P84, DOI 10.1109/TSMC.1983.6313035; KELLY MD, 1971, MACH INTELL, V6, P397; MEAGHER D, 1982, COMPUT VISION GRAPH, V19, P129, DOI 10.1016/0146-664X(82)90104-6; NARAYANAN KA, 1981, IEEE T SYST MAN CYB, V11, P826; NARAYANAN KA, 1982, PATTERN RECOGN, V15, P389, DOI 10.1016/0031-3203(82)90042-5; PATON K, 1975, COMPUT GRAPHICS IMAG, V4, P40, DOI DOI 10.1016/0146-664X(75)90020-9; PIETIKAINEN M, 1981, IEEE T SYST MAN CYB, V11, P822; PRICE K, 1979, IEEE T PATTERN ANAL, V1, P110, DOI 10.1109/TPAMI.1979.4766884; REEVES AP, 1981, P PRIP, P171; SAMET H, 1984, COMPUT SURV, V16, P187, DOI 10.1145/356924.356930; TANIMOTO S, 1980, STRUCTURED COMPUTER; Tanimoto S. L., 1983, 10th Annual International Conference on Computer Architecture Conference Proceedings, P372, DOI 10.1145/800046.801676; TANIMOTO SL, 1980, 800503 U WASH DEP CO; WIEJAK JS, 1983, IMAGE VISION COMPUT, V1, P79; WONG RY, 1978, COMPUT VISION GRAPH, V8, P16, DOI 10.1016/S0146-664X(78)80028-8	45	16	16	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1986	8	5					639	651		10.1109/TPAMI.1986.4767837	http://dx.doi.org/10.1109/TPAMI.1986.4767837			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	D7584	21869361				2022-12-18	WOS:A1986D758400005
J	KANATANI, KI				KANATANI, KI			THE CONSTRAINTS ON IMAGES OF RECTANGULAR POLYHEDRA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											KANATANI, KI (corresponding author), UNIV MARYLAND,CTR AUTOMAT RES,COLLEGE PK,MD 20742, USA.							CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; GUZMAN A, 1968, MIT MACTR59 PROJ MAC; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; KANADE T, 1980, ARTIF INTELL, V13, P279, DOI 10.1016/0004-3702(80)90004-1; KANATANI K, 1984, ARTIF INTELL, V23, P213, DOI 10.1016/0004-3702(84)90010-9; KANATANI K, 1985, COMPUT VISION GRAPH, V29, P13, DOI 10.1016/S0734-189X(85)90147-1; KANATANI K, 1984, COMPUT VIS GRAPHICS, V29, P1; MACKWORTH AK, 1976, PERCEPTION, V5, P349, DOI 10.1068/p050349; MACKWORTH AK, 1973, ARTIF INTELL, V4, P121, DOI 10.1016/0004-3702(73)90003-9; STEVENS KA, 1981, BIOL CYBERN, V42, P95, DOI 10.1007/BF00336727; SUGIHARA K, 1978, COMPUT VISION GRAPH, V8, P382, DOI 10.1016/0146-664X(78)90064-3; SUGIHARA K, 1982, PERCEPTION, V11, P65, DOI 10.1068/p110065; SUGIHARA K, 1984, IEEE T PATTERN ANAL, V6, P578, DOI 10.1109/TPAMI.1984.4767571; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9	18	16	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1986	8	4					456	463		10.1109/TPAMI.1986.4767809	http://dx.doi.org/10.1109/TPAMI.1986.4767809			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	C7400					2022-12-18	WOS:A1986C740000004
J	LUNSCHER, WHHJ; BEDDOES, MP				LUNSCHER, WHHJ; BEDDOES, MP			OPTIMAL EDGE DETECTOR DESIGN .2. COEFFICIENT QUANTIZATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV BRITISH COLUMBIA,DEPT ELECT ENGN,VANCOUVER V6T 1W5,BC,CANADA	University of British Columbia	LUNSCHER, WHHJ (corresponding author), DEVELCON ELECTR LTD,DIV RES & DEV,SASKATOON,SASKATCHEWAN,CANADA.							CHAN DSK, 1973, IEEE T ACOUST SPEECH, VAU21, P354, DOI 10.1109/TAU.1973.1162497; Feller W, 2008, INTRO PROBABILITY TH, V2; GREEN WB, 1983, DIGITAL IMAGE PROCES; KITCHEN L, 1981, IEEE T SYST MAN CYB, V11, P597, DOI 10.1109/TSMC.1981.4308758; LUNSCHER WHHJ, 1986, IEEE T PATTERN ANAL, V8, P164, DOI 10.1109/TPAMI.1986.4767770; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020	6	16	16	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1986	8	2					178	187		10.1109/TPAMI.1986.4767771	http://dx.doi.org/10.1109/TPAMI.1986.4767771			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	A1073	21869336				2022-12-18	WOS:A1986A107300005
J	MITICHE, A				MITICHE, A			ON KINEOPSIS AND COMPUTATION OF STRUCTURE AND MOTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									INRS TELECOMMUN,ILE DES SOEURS,QUEBEC,CANADA	University of Quebec; Institut national de la recherche scientifique (INRS)								BALLARD DH, 1983, COMPUT VISION GRAPH, V22, P95, DOI 10.1016/0734-189X(83)90097-X; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; GIBSON EJ, 1959, J EXP PSYCHOL, V58, P40, DOI 10.1037/h0043883; HILDRETH ED, 1982, MIT AI699 MEM; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; LAWTON DT, 1983, P IMAGE UNDERSTANDIN, P77; LELONGFERRAND J, 1974, COURS MATH, V3; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; Marr D, 1978, COMPUTER VISION SYST; Mitiche A., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P156; Nagel HH, 1982, PATTERN RECOGN LETT, V1, P55, DOI 10.1016/0167-8655(82)90052-6; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; NAKAYAMA K, 1974, PERCEPTION, V3, P63, DOI 10.1068/p030063; PAQUIN R, 1983, COMPUT GRAPHICS IMAG, P205; POTTER JL, 1972, COMPUT GRAPHICS IMAG, V6, P558; PRAZDNY K, 1983, COMPUT VISION GRAPH, V22, P239, DOI 10.1016/0734-189X(83)90067-1; ROACH JW, 1980, IEEE T PATTERN ANAL, V2, P554, DOI 10.1109/TPAMI.1980.6447703; THOMPSON WB, 1980, IEEE T PATTERN ANAL, V2, P543, DOI 10.1109/TPAMI.1980.6447701; THOMPSON WB, 1981, COMPUTER, V14, P20, DOI 10.1109/C-M.1981.220559; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; ULLMAN S, 1976, MIT AI476 LINC LAB M; WAXMAN AM, 1983, P IMAGE UNDERSTANDIN, P175; WOHN KY, 1983, PATTERN RECOGN, V16, P563, DOI 10.1016/0031-3203(83)90072-9	26	16	16	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1986	8	1					109	112		10.1109/TPAMI.1986.4767758	http://dx.doi.org/10.1109/TPAMI.1986.4767758			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AWT86	21869329				2022-12-18	WOS:A1986AWT8600013
J	BOUTHEMY, P; BENVENISTE, A				BOUTHEMY, P; BENVENISTE, A			MODELING OF ATMOSPHERIC DISTURBANCES IN METEOROLOGICAL PICTURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									INRS TELECOMMUN,DEPT VISUAL COMMUN,MONTREAL,QUEBEC,CANADA	University of Quebec; Institut national de la recherche scientifique (INRS)	BOUTHEMY, P (corresponding author), INST NATL RECH INFORMAT & AUTOMAT,RENNES,FRANCE.							BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BOUTHEMY P, 1983, NATO ASI SERIES F, V2, P580; BOUTHEMY P, 1982, THESIS IRISA U RENNE; DEMASTERS D, 1978, SPIE IMAGE UNDERSTAN, V155, P8; DESBOIS M, 1982, J APPL METEOROL, V21, P401, DOI 10.1175/1520-0450(1982)021<0401:ACOCOM>2.0.CO;2; DESBOIS M, 1976, TR70 LAB MET DYN; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Endlich R.M., 1971, J APPL METEOROL CLIM, V10, P105; HAASS UL, 1980, APR P ICASSP DENV, V2, P422; HESTENES MR, 1977, SEP P IFIP C OPT TEC, P8; LATTUATI V, 1982, PATTERN RECOGN, V15, P145, DOI 10.1016/0031-3203(82)90065-6; Leese J.A., 1971, J APPL METEOR, V10, P118, DOI [10.1175/1520-0450(1971)0102.0.CO;2, DOI 10.1175/1520-0450(1971)0102.0.CO;2]; ROCHARD G, 1978, TREERM408 CTR MET SP; SHIPMAN AL, 1982, MAY P ICASSP PAR, V3, P1948; WARNECKE G, 1981, REMOTE SENSING METEO, P452; ZICK C, 1983, METEOROLOGISHE RUUDS, V36; ZWATZMEISS V, 1981, REMOTE SENSING METEO, P412	17	16	16	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	5					587	600		10.1109/TPAMI.1984.4767572	http://dx.doi.org/10.1109/TPAMI.1984.4767572			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TM813	21869227				2022-12-18	WOS:A1984TM81300004
J	MCDERMOTT, D				MCDERMOTT, D			CONTEXTS AND DATA DEPENDENCIES - A SYNTHESIS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											MCDERMOTT, D (corresponding author), YALE UNIV,DEPT COMP SCI,NEW HAVEN,CT 06520, USA.							BOBROW G, 1974, COMPUT SURVEYS, V6, P155; CHARNIAK E, 1981, ARTIF INTELL, V16, P225, DOI 10.1016/0004-3702(81)90001-1; DEKLEER J, P C ARTIFICIAL INTEL, P116; DEKLEER J, 1977, MIT AI427 LAB MEM; DOYLE J, 1979, ARTIF INTELL, V12, P231, DOI 10.1016/0004-3702(79)90008-0; DOYLE J, 1980, MIT AI581 LAB TECH R; FAHLMAN SE, 1974, ARTIF INTELL, V5, P1, DOI 10.1016/0004-3702(74)90008-3; HEWITT C, 1971, P IJCAI, V2; HEWITT C, 1969, P IJCAI, V1; LONDON PE, 1978, AFIPS NAT COMPUT C P, V47; MCALLESTER DA, 1980, MIT AI551 LAB TECH R; MCDERMOTT DV, 1982, P AAAI, V2; MCDERMOTT DV, UNPUB ARTIFICIAL INT; MCDERMOTT DV, 1980, P AAAI, V1; MCDERMOTT DV, 1974, MIT AI291 LAB TECH R; MEEHAN JR, 1979, NEW UCI LISP MANUAL; RIEGER C, 1976, 459 U MAR DEP COMP S; RULIFSON JF, 1972, SRI AI73 CTR TECH NO; STALLMAN R, 1977, ARTIFICIAL INTELL, V9; SUSSMAN GJ, 1972, P JOINT COMPUTER C 2, V41, P1171; THOMPSON A, 1979, P IJCAI, V6, P877; [No title captured]	22	16	16	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	3					237	246		10.1109/TPAMI.1983.4767388	http://dx.doi.org/10.1109/TPAMI.1983.4767388			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	QS785	21869109				2022-12-18	WOS:A1983QS78500001
J	PEARL, J; LEAL, A; SALEH, J				PEARL, J; LEAL, A; SALEH, J			GODDESS - A GOAL-DIRECTED DECISION STRUCTURING SYSTEM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									TEXTRAX CORP,CANOGA PK,CA 91306		PEARL, J (corresponding author), UNIV CALIF LOS ANGELES,SCH ENGN & APPL SCI,COGNIT SYST LAB,LOS ANGELES,CA 90024, USA.		Leal-Millán, Antonio/M-2317-2014	Leal-Millán, Antonio/0000-0003-3037-5818				ARMSTRONG LS, 1975, ORG BEHAVIOR HUMAN P, V14, P257; Ernst G, 1969, GPS CASE STUDY GEN P; FIKES RE, 1971, ARTIFICIAL INTELL, V2, P184; GETTYS CF, 1973, ORG BEHAVIOR HUMAN P, V10, P379; LEAL A, 1977, IEEE T SYST MAN CYB, V7, P368, DOI 10.1109/TSMC.1977.4309725; LEAL A, 1976, UCLAENGREP7666 U CAL; LEAL A, 1978, PQTR1046782 PERC TEC; MERKHOFER MW, 1977, DECISION STRUCTURING; Nilsson N.J., 1971, PROBLEM SOLVING METH; PEARL J, 1981, UCLAENG8136; PEARL J, 1978, UCLAENG7811 U CAL SC; PITZ GF, 1980, ORGAN BEHAV HUM PERF, V26, P396, DOI 10.1016/0030-5073(80)90075-6; SALEH J, 1980, THESIS U CALIFORNIA; SLOVIC P, 1977, ANN REV PSYCHOL, V28, P23; STEEB R, 1981, IEEE T SYST MAN CYBE, V11	15	16	16	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	3					250	262		10.1109/TPAMI.1982.4767242	http://dx.doi.org/10.1109/TPAMI.1982.4767242			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	NN069	21869032				2022-12-18	WOS:A1982NN06900003
J	BROWN, CM				BROWN, CM			SOME MATHEMATICAL AND REPRESENTATIONAL ASPECTS OF SOLID MODELING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											BROWN, CM (corresponding author), UNIV ROCHESTER,COLL ENGN & APPL SCI,ROCHESTER,NY 14627, USA.							AGIN GJ, 1976, IEEE T COMPUT, V25, P439, DOI 10.1109/TC.1976.1674626; BAUMGART BG, 1972, STANCS320 STANF U ST; BRAID IC, 1978, CAD100 U CAMBR CAD G; BRAID IC, 1978, MAR P GEOM MOD PROJ; BROWN CM, 1978, 1978 P ACM WASH; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; EASTMAN CM, 1972, EFFICIENT ALGORITHM; EASTMAN CM, 1977, COMPUT GRAPH, V11, P24; EASTMAN CM, 1979, 78 CARN MELL U I PHY; Hocking J.G., 1961, TOPOLOGY; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; REQUICHA A, 1977, 25 U ROCH PROD AUT P; REQUICHA AAG, 1977, 28 U ROCH PROD AUT P; Requicha AAG, 1978, 27 U ROCH PROD AUT P; REQUICHA AAG, 1977, 19 U ROCH PROD AUT P; REQUICHA AAG, 1979, 29 U ROCH PROD AUT P; SHAMOS MI, 1978, 17TH P ANN IEEE S F, P208; Shamos MI, 1975, P 7 ANN ACM S THEOR, P224; SILVA CE, 1980, 36 U ROCH PROD AUT P; SUTHERLAND IE, 1974, COMMUN ACM, V17, P32, DOI 10.1145/360767.360802; TILOVE RB, 1980, IEEE T COMPUT, V29, P874, DOI 10.1109/TC.1980.1675470; TURNER KJ, 1974, U EDINBURGH DEP MACH; VOELCKER HB, 1977, COMPUTER, V10, P48, DOI 10.1109/C-M.1977.217601; VOELCKER HB, 1979, 1ST P ANN C COMP GRA; VOELCKER HB, 1978, 1978 P SIGGRAPH; VOELCKER HB, 1978, COMPUT GRAPH, V12, P257; WALTZ DL, 1972, MIT TR271 AI LAB REP; Weiler K., 1980, Computer Graphics, V14, P10, DOI 10.1145/965105.807462; WEILER K, 1977, COMPUT GRAPH, V11, P214; WEILER K, 1980, 1980 P SIGGRAPH; 1977, PADL10 U ROCH PROD A; 1979, MAY P WORKSH REP 3 D	32	16	17	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	4					444	453		10.1109/TPAMI.1981.4767129	http://dx.doi.org/10.1109/TPAMI.1981.4767129			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MQ357	21868964				2022-12-18	WOS:A1981MQ35700008
J	BENBASSAT, M; KLOVE, KL; WEIL, MH				BENBASSAT, M; KLOVE, KL; WEIL, MH			SENSITIVITY ANALYSIS IN BAYESIAN CLASSIFICATION MODELS - MULTIPLICATIVE DEVIATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									TEL AVIV UNIV,FAC MANAGEMENT,TEL AVIV,ISRAEL	Tel Aviv University	BENBASSAT, M (corresponding author), UNIV SO CALIF,SCH MED,INST CRIT CARE MED,DIV CRIT CARE MED,LOS ANGELES,CA 90027, USA.							BENBASSAT M, 1980, IEEE T PATTERN ANAL, V2, P148, DOI 10.1109/TPAMI.1980.4766992; HOGARTH RM, 1975, J AM STAT ASSOC, V70, P271, DOI 10.2307/2285808; LICHTENSTEIN S, 1978, DECISION MAKING CHAN; LINDLEY RS, 1959, SCIENCE, V130, P9; SLOVIC P, 1977, ANNU REV PSYCHOL, V28, P1, DOI 10.1146/annurev.ps.28.020177.000245	5	16	16	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	3					261	266		10.1109/TPAMI.1980.4767015	http://dx.doi.org/10.1109/TPAMI.1980.4767015			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JR843	21868901				2022-12-18	WOS:A1980JR84300008
J	KAZAKOS, D; COTSIDAS, T				KAZAKOS, D; COTSIDAS, T			DECISION-THEORY APPROACH TO THE APPROXIMATION OF DISCRETE PROBABILITY DENSITIES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											KAZAKOS, D (corresponding author), SUNY BUFFALO,DEPT ELECT ENGN,AMHERST,NY 14260, USA.							BERAN R, 1977, ANN STAT, V5, P445, DOI 10.1214/aos/1176343842; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; CHOW CK, 1973, IEEE T INFORM THEORY, V19, P369, DOI 10.1109/TIT.1973.1055013; GOOD JJ, 1963, ANN MATH STATIST, V34, P911; KADOTA TT, 1967, IEEE T INFORM THEORY, V13, P278, DOI 10.1109/TIT.1967.1054013; KU HH, 1969, IEEE T INFORM THEORY, V15, P444, DOI 10.1109/TIT.1969.1054336; LAINIOTIS DG, 1971, IEEE T SYST MAN CYBE, V1; Lewis PM., 1959, INF CONTROL, V2, P214, DOI 10.1016/S0019-9958(59)90207-4; MATUSITA K, 1955, ANN MATH STAT, V26, P631, DOI 10.1214/aoms/1177728422; Rockafellar R.T., CONVEX ANAL; TOUSSAINT GT, 1975, IEEE T INFORM THEORY, V21, P99, DOI 10.1109/TIT.1975.1055311; VANNESS JW, 1977, IEEE T SYST MAN CYB, V7, P560; YOUNG TY, 1971, IEEE T COMPUT, VC 20, P967, DOI 10.1109/T-C.1971.223390; YOUNG TY, 1978, IEEE T INFORM THEORY, V24, P152, DOI 10.1109/TIT.1978.1055866	15	16	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	1					61	67		10.1109/TPAMI.1980.4766971	http://dx.doi.org/10.1109/TPAMI.1980.4766971			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	JD568	22499624				2022-12-18	WOS:A1980JD56800009
J	Wei, XS; Song, YZ; Mac Aodha, O; Wu, JX; Peng, YX; Tang, JH; Yang, J; Belongie, S				Wei, Xiu-Shen; Song, Yi-Zhe; Mac Aodha, Oisin; Wu, Jianxin; Peng, Yuxin; Tang, Jinhui; Yang, Jian; Belongie, Serge			Fine-Grained Image Analysis With Deep Learning: A Survey	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image recognition; Image analysis; Deep learning; Task analysis; Image retrieval; Birds; Visualization; Fine-grained images analysis; deep learning; fine-grained image recognition; fine-grained image retrieval	ATTENTION; MODEL; CLASSIFICATION; RECOGNITION; KNOWLEDGE; CNNS	Fine-grained image analysis (FGIA) is a longstanding and fundamental problem in computer vision and pattern recognition, and underpins a diverse set of real-world applications. The task of FGIA targets analyzing visual objects from subordinate categories, e.g., species of birds or models of cars. The small inter-class and large intra-class variation inherent to fine-grained image analysis makes it a challenging problem. Capitalizing on advances in deep learning, in recent years we have witnessed remarkable progress in deep learning powered FGIA. In this paper we present a systematic survey of these advances, where we attempt to re-define and broaden the field of FGIA by consolidating two fundamental fine-grained research areas - fine-grained image recognition and fine-grained image retrieval. In addition, we also review other key issues of FGIA, such as publicly available benchmark datasets and related domain-specific applications. We conclude by highlighting several research directions and open problems which need further exploration from the community.	[Wei, Xiu-Shen; Yang, Jian] Minist Educ, Key Lab Intelligent Percept & Syst High Dimens In, PCA Lab, Nanjing 210094, Jiangsu, Peoples R China; [Wei, Xiu-Shen; Yang, Jian] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Jiangsu Key Lab Image & Video Understanding Socia, Nanjing 210094, Jiangsu, Peoples R China; [Song, Yi-Zhe] Univ Surrey, Guildford GU2 7XH, Surrey, England; [Mac Aodha, Oisin] Univ Edinburgh, Edinburgh EH8 9YL, Midlothian, Scotland; [Wu, Jianxin] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210094, Jiangsu, Peoples R China; [Peng, Yuxin] Peking Univ, Beijing 100871, Peoples R China; [Tang, Jinhui] Nanjing Univ Sci & Technol, Nanjing 210094, Jiangsu, Peoples R China; [Belongie, Serge] Univ Copenhagen, DK-1165 Copenhagen, Denmark; [Belongie, Serge] Pioneer Ctr AI, DK-1165 Copenhagen, Denmark	Nanjing University of Science & Technology; University of Surrey; University of Edinburgh; Nanjing University; Peking University; Nanjing University of Science & Technology; University of Copenhagen	Wei, XS; Yang, J (corresponding author), Minist Educ, Key Lab Intelligent Percept & Syst High Dimens In, PCA Lab, Nanjing 210094, Jiangsu, Peoples R China.	weixs.gm@gmail.com; y.song@surrey.ac.uk; oisin.macaodha@ed.ac.uk; wujx2001@gmail.com; pengyuxin@pku.edu.cn; jinhuitang@njust.edu.cn; csjyang@njust.edu.cn; sjb344@cornell.edu		Wei, Xiu-Shen/0000-0002-8200-1845; Belongie, Serge/0000-0002-0388-5217	National Key R&D Program of China [2021YFA1001100]; Natural Science Foundation of Jiangsu Province of China [BK20210340]; National Natural Science Foundation of China [61925201, 62132001, 61772256]; Fundamental Research Funds for the Central Universities [30920041111]; CAAI-Huawei MindSpore Open Fund; "111" Program [B13022]	National Key R&D Program of China; Natural Science Foundation of Jiangsu Province of China(Natural Science Foundation of Jiangsu Province); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); CAAI-Huawei MindSpore Open Fund; "111" Program(Ministry of Education, China - 111 Project)	This work was supported in part by the National Key R&D Program of China under Grant 2021YFA1001100, in part by the Natural Science Foundation of Jiangsu Province of China under Grant BK20210340, in part by the National Natural Science Foundation of China under Grants 61925201, 62132001, and 61772256, in part by the Fundamental Research Funds for the Central Universities under Grant 30920041111, in part by CAAI-Huawei MindSpore Open Fund, and in part by "111" Program B13022.	acm, ACM TOMM SPEC ISS FI; Amos Storkey, 2020, Arxiv, DOI arXiv:2004.05439; Andrea Vedaldi, 2013, Arxiv, DOI arXiv:1306.5151; [Anonymous], 2019, ICCV 2019 WORKSH COM; Berg T, 2014, PROC CVPR IEEE, P2019, DOI 10.1109/CVPR.2014.259; Bhunia Ayan Kumar, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9776, DOI 10.1109/CVPR42600.2020.00980; Bin-Bin Gao, 2015, Arxiv, DOI arXiv:1504.05277; Bishop C. M., 2006, PATTERN RECOGN, DOI DOI 10.1117/1.2819119.ARNING; Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29; Boyan Zhou, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9716, DOI 10.1109/CVPR42600.2020.00974; Branson S., 2014, PROC BRIT MACH VIS C; Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339; Cai SJ, 2017, IEEE I CONF COMP VIS, P511, DOI 10.1109/ICCV.2017.63; Chang DL, 2020, IEEE T IMAGE PROCESS, V29, P4683, DOI 10.1109/TIP.2020.2973812; Chen TS, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P627; Chen T, 2020, PR MACH LEARN RES, V119; Chen Y, 2019, PROC CVPR IEEE, P5152, DOI 10.1109/CVPR.2019.00530; Chu G, 2019, IEEE INT CONF COMP V, P247, DOI 10.1109/ICCVW.2019.00033; Cimpoi M, 2015, PROC CVPR IEEE, P3828, DOI 10.1109/CVPR.2015.7299007; Cole E., 2021, ARXIV; computer.org, IEEE TPAMI SPEC ISS; Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755; Cui Y., 2019, ARXIV; Cui Y, 2019, PROC CVPR IEEE, P9260, DOI 10.1109/CVPR.2019.00949; Cui Y, 2018, PROC CVPR IEEE, P4109, DOI 10.1109/CVPR.2018.00432; Cui Y, 2017, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR.2017.325; Cui Y, 2016, PROC CVPR IEEE, P1153, DOI 10.1109/CVPR.2016.130; Deng J, 2016, IEEE T PATTERN ANAL, V38, P666, DOI 10.1109/TPAMI.2015.2439285; Ding Y, 2019, IEEE I CONF COMP VIS, P6598, DOI 10.1109/ICCV.2019.00670; Dubey A, 2018, LECT NOTES COMPUT SC, V11216, P71, DOI 10.1007/978-3-030-01258-8_5; Dubey A, 2018, ADV NEUR IN, V31; elsevier, NEUR SPEC ISS FIN GR; elsevier, PATTERN RECOGN; Engin M, 2018, LECT NOTES COMPUT SC, V11206, P629, DOI 10.1007/978-3-030-01216-8_38; Fang Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P718, DOI 10.1007/978-3-030-58529-7_42; Feurer M, 2015, ADV NEUR IN, V28; fgva, CVPR 2021 TUT FIN GR; Frank Hutter, 2019, Arxiv, DOI arXiv:1808.05377; Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476; Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41; Gao Y, 2020, AAAI CONF ARTIF INTE, V34, P10818; Ge WF, 2019, PROC CVPR IEEE, P3029, DOI 10.1109/CVPR.2019.00315; Ge Yuying, 2019, CVPR; Gebru T, 2017, IEEE I CONF COMP VIS, P1358, DOI 10.1109/ICCV.2017.151; Gidaris Spyros, 2018, ARXIV180307728; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, PROC CVPR IEEE, P437, DOI 10.1109/CVPR.2015.7298641; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; google, 8 WORKSH FIN GRAIN V; Gosselin PH, 2014, PATTERN RECOGN LETT, V49, P92, DOI 10.1016/j.patrec.2014.06.011; Guillaumin M, 2014, INT J COMPUT VISION, V110, P328, DOI 10.1007/s11263-014-0713-9; Haroon Idrees, 2018, Arxiv, DOI arXiv:1808.03998; He XT, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1740, DOI 10.1145/3343031.3350974; He XT, 2019, INT J COMPUT VISION, V127, P1235, DOI 10.1007/s11263-019-01176-2; He XT, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P741; He XT, 2019, IEEE T CIRC SYST VID, V29, P1394, DOI 10.1109/TCSVT.2018.2834480; He XT, 2017, AAAI CONF ARTIF INTE, P4075; He XT, 2017, PROC CVPR IEEE, P7332, DOI 10.1109/CVPR.2017.775; Hou SH, 2017, IEEE I CONF COMP VIS, P541, DOI 10.1109/ICCV.2017.66; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jaderberg M, 2015, ADV NEUR IN, V28; Ji R, 2020, PROC IEEE C COMPUT V, p10 468; Jin S, 2020, IEEE T IMAGE PROCESS, V29, P5336, DOI 10.1109/TIP.2020.2971105; Jing LL, 2021, IEEE T PATTERN ANAL, V43, P4037, DOI 10.1109/TPAMI.2020.2992393; Johnson KE, 1998, COGNITIVE DEV, V13, P515, DOI 10.1016/S0885-2014(98)90005-3; Jong-Chyi Su, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P645, DOI 10.1007/978-3-030-58571-6_38; Guo J, 2020, Arxiv, DOI arXiv:2011.09040; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301; kaggle, COMP HOM INATURALIST; Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975; Kaiyue Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10344, DOI 10.1109/CVPR42600.2020.01036; Karlinsky L, 2017, PROC CVPR IEEE, P965, DOI 10.1109/CVPR.2017.109; Khan SD, 2019, COMPUT VIS IMAGE UND, V182, P50, DOI 10.1016/j.cviu.2019.03.001; Khosla A., 2011, PROC IEEE C COMPUT V, P806; Kong S, 2017, PROC CVPR IEEE, P7025, DOI 10.1109/CVPR.2017.743; Krause J, 2016, LECT NOTES COMPUT SC, V9907, P301, DOI 10.1007/978-3-319-46487-9_19; Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194; Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77; Lam M, 2017, PROC CVPR IEEE, P6497, DOI 10.1109/CVPR.2017.688; Larochelle H., 2010, ADV NEURAL INFORM PR, P1243; Lazebnik S., 2006, P IEEE C COMP VIS PA, P1; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lehmann J, 2015, SEMANT WEB, V6, P167, DOI 10.3233/SW-140134; Li CC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2152, DOI 10.1145/3343031.3350989; Li K, 2017, IEEE T IMAGE PROCESS, V26, P5908, DOI 10.1109/TIP.2017.2745106; Li PH, 2018, PROC CVPR IEEE, P947, DOI 10.1109/CVPR.2018.00105; Li PH, 2017, IEEE I CONF COMP VIS, P2089, DOI 10.1109/ICCV.2017.228; Li W., 2016, INT JOINT C ARTIFICI, P1711; Li YH, 2017, IEEE I CONF COMP VIS, P2098, DOI 10.1109/ICCV.2017.229; Li Yi, 2014, BMVC; Lin D, 2015, PROC CVPR IEEE, P1666, DOI 10.1109/CVPR.2015.7298775; Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826; Lin TY, 2018, IEEE T PATTERN ANAL, V40, P1309, DOI 10.1109/TPAMI.2017.2723400; Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170; Linfang Wang, 2020, Arxiv, DOI arXiv:2008.10545; Liu CB, 2020, AAAI CONF ARTIF INTE, V34, P11555; Liu LQ, 2015, PROC CVPR IEEE, P4749, DOI 10.1109/CVPR.2015.7299107; Liu X, 2017, AAAI CONF ARTIF INTE, P4190; Liu XH, 2021, IEEE T IMAGE PROCESS, V30, P1744, DOI 10.1109/TIP.2020.3048623; Liu ZW, 2019, PROC CVPR IEEE, P2532, DOI 10.1109/CVPR.2019.00264; Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Luming Tang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14340, DOI 10.1109/CVPR42600.2020.01436; Luo W, 2019, IEEE I CONF COMP VIS, P8241, DOI 10.1109/ICCV.2019.00833; Mac Aodha O, 2019, IEEE I CONF COMP VIS, P9595, DOI 10.1109/ICCV.2019.00969; Mafla A., 2020, PROC IEEE WORKSHOP A, P4023; Mafla A, 2020, IEEE WINT CONF APPL, P2939, DOI 10.1109/WACV45572.2020.9093373; Ye M, 2020, Arxiv, DOI arXiv:2001.04193; Menglin Jia, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P316, DOI 10.1007/978-3-030-58452-8_19; Min SB, 2020, IEEE T IMAGE PROCESS, V29, P4996, DOI 10.1109/TIP.2020.2977457; Mu JQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P629, DOI 10.18653/v1/P17-2099; Munro J, 2020, PROC CVPR IEEE, P119, DOI 10.1109/CVPR42600.2020.00020; Musgrave Kevin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P681, DOI 10.1007/978-3-030-58595-2_41; Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47; Pham N, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P239, DOI 10.1145/2487575.2487591; Niu L, 2018, PROC CVPR IEEE, P7171, DOI 10.1109/CVPR.2018.00749; Pang KY, 2019, PROC CVPR IEEE, P677, DOI 10.1109/CVPR.2019.00077; Pang Kaiyue, 2017, BMVC; Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P1487, DOI 10.1109/TIP.2017.2774041; Quan Cui, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P189, DOI 10.1007/978-3-030-58580-8_12; Quanshi Zhang, 2018, Arxiv, DOI arXiv:1802.00614; Radenovic F, 2018, LECT NOTES COMPUT SC, V11209, P774, DOI 10.1007/978-3-030-01228-1_46; Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; retailvisionworkshop, P IEEE C COMP VIS PA; Ruoyi Du, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P153, DOI 10.1007/978-3-030-58565-5_10; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sain A., 2020, PROC BRIT MACH VIS C, P1; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; sciencedirect, PATTERN RECOGN; Sergey I. Nikolenko, 2019, Arxiv, DOI arXiv:1909.11512; Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136; Sinan Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9210, DOI 10.1109/CVPR42600.2020.00923; Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434; Song J., 2017, P BRIT MACH VIS C, P1; Song JF, 2017, IEEE I CONF COMP VIS, P5552, DOI 10.1109/ICCV.2017.592; Song KT, 2020, IEEE T IMAGE PROCESS, V29, P7006, DOI 10.1109/TIP.2020.2996736; Songtao Ji, 2016, 2016 IEEE International Workshop on Electromagnetics (iWEM): Applications and Student Innovation Competition, P1, DOI 10.1109/iWEM.2016.7505029; Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25; Sun GL, 2020, AAAI CONF ARTIF INTE, V34, P12047; Sun M, 2018, LECT NOTES COMPUT SC, V11220, P834, DOI 10.1007/978-3-030-01270-0_49; Sun XX, 2019, AAAI CONF ARTIF INTE, P273; Tsutsui S, 2019, ADV NEUR IN, V32; Van Horn G, 2021, PROC CVPR IEEE, P12879, DOI 10.1109/CVPR46437.2021.01269; Van Horn G, 2018, PROC CVPR IEEE, P8769, DOI 10.1109/CVPR.2018.00914; Van Horn G, 2015, PROC CVPR IEEE, P595, DOI 10.1109/CVPR.2015.7298658; Wah C., 2011, CNSTR2011001 U CAL; Wang JD, 2018, IEEE T PATTERN ANAL, V40, P769, DOI 10.1109/TPAMI.2017.2699960; Wang L, 2015, IEEE I CONF COMP VIS, P4570, DOI 10.1109/ICCV.2015.519; Wang M, 2021, NEUROCOMPUTING, V429, P215, DOI 10.1016/j.neucom.2020.10.081; Wang Q., 2020, PROC IEEE C COMPUT V, P10771; Wang QL, 2021, IEEE T PATTERN ANAL, V43, P2582, DOI 10.1109/TPAMI.2020.2974833; Wang QL, 2017, PROC CVPR IEEE, P6507, DOI 10.1109/CVPR.2017.689; Wang XS, 2022, PHILOSOPHIA, V50, P337, DOI 10.1007/s11406-021-00355-1; Wang YM, 2018, PROC CVPR IEEE, P4148, DOI 10.1109/CVPR.2018.00436; Wang YM, 2016, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2016.131; Wang YM, 2020, IEEE WINT CONF APPL, P1217, DOI 10.1109/WACV45572.2020.9093306; Wang ZH, 2020, AAAI CONF ARTIF INTE, V34, P12289; Wei X.-S., 2019, ARXIV; Wei X, 2018, LECT NOTES COMPUT SC, V11207, P365, DOI 10.1007/978-3-030-01219-9_22; Wei XS, 2019, LECT NOTES COMPUT SC, V11362, P575, DOI 10.1007/978-3-030-20890-5_37; Wei XS, 2019, IEEE T IMAGE PROCESS, V28, P6116, DOI 10.1109/TIP.2019.2924811; Wei XS, 2019, PATTERN RECOGN, V88, P113, DOI 10.1016/j.patcog.2018.10.022; Wei XS, 2018, PATTERN RECOGN, V76, P704, DOI 10.1016/j.patcog.2017.10.002; Wei XS, 2017, IEEE T IMAGE PROCESS, V26, P2868, DOI 10.1109/TIP.2017.2688133; Wei YC, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8875910; Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685; Xie SN, 2015, PROC CVPR IEEE, P2645, DOI 10.1109/CVPR.2015.7298880; Xiong W, 2020, PROC CVPR IEEE, P5839, DOI 10.1109/CVPR42600.2020.00588; Xu HP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1043; Xu Z., 2018, IEEE T PATTERN ANAL, V40, P769; Xu Z, 2015, IEEE I CONF COMP VIS, P2524, DOI 10.1109/ICCV.2015.290; Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789; Yang JF, 2018, IEEE T IMAGE PROCESS, V27, P5303, DOI 10.1109/TIP.2018.2855449; Yang Z, 2018, LECT NOTES COMPUT SC, V11218, P438, DOI 10.1007/978-3-030-01264-9_26; Yao BP, 2011, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR.2011.5995368; Yin J, 2020, INT J COMPUT VISION, V128, P1654, DOI 10.1007/s11263-019-01259-0; Yu CJ, 2018, LECT NOTES COMPUT SC, V11220, P595, DOI 10.1007/978-3-030-01270-0_35; Yu Q, 2016, PROC CVPR IEEE, P799, DOI 10.1109/CVPR.2016.93; Zanzotto FM, 2019, J ARTIF INTELL RES, V64, P243, DOI 10.1613/jair.1.11345; Zeiler M. D., 2014, EUR C COMP VIS, P818; Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474; Zeng X., 2020, IMAGE VIS COMPUT, V93, P2868; Zhang CY, 2020, AAAI CONF ARTIF INTE, V34, P12781; Zhang H, 2016, PROC CVPR IEEE, P1143, DOI 10.1109/CVPR.2016.129; Zhang H, 2018, AAAI CONF ARTIF INTE, P7542; Zhang JY, 2018, LECT NOTES COMPUT SC, V11206, P304, DOI 10.1007/978-3-030-01216-8_19; Zhang LB, 2019, IEEE I CONF COMP VIS, P8330, DOI 10.1109/ICCV.2019.00842; Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54; Zhang XP, 2016, PROC CVPR IEEE, P1134, DOI 10.1109/CVPR.2016.128; Zhang YB, 2018, LECT NOTES COMPUT SC, V11212, P241, DOI 10.1007/978-3-030-01237-3_15; Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, P1713, DOI 10.1109/TIP.2016.2531289; Zhao B, 2017, INT J AUTOM COMPUT, V14, P119, DOI 10.1007/s11633-017-1053-3; Zheng HL, 2019, ADV NEUR IN, V32; Zheng HL, 2019, PROC CVPR IEEE, P5007, DOI 10.1109/CVPR.2019.00515; Zheng HL, 2020, IEEE T IMAGE PROCESS, V29, P476, DOI 10.1109/TIP.2019.2921876; Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557; Zheng M, 2018, INT CONF SIGN PROCES, P533, DOI 10.1109/ICSP.2018.8652307; Zheng XW, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1226; Zheng XW, 2019, AAAI CONF ARTIF INTE, P9291; Zhihui Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9746, DOI 10.1109/CVPR42600.2020.00977; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; Zhou F, 2016, PROC CVPR IEEE, P1124, DOI 10.1109/CVPR.2016.127; Zhu C, 2018, LECT NOTES COMPUT SC, V11209, P139, DOI 10.1007/978-3-030-01228-1_9; Zhuang BH, 2017, PROC CVPR IEEE, P2915, DOI 10.1109/CVPR.2017.311; Zhuang PQ, 2020, AAAI CONF ARTIF INTE, V34, P13130; Zixuan Huang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8659, DOI 10.1109/CVPR42600.2020.00869	211	15	15	14	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2022	44	12					8927	8948		10.1109/TPAMI.2021.3126648	http://dx.doi.org/10.1109/TPAMI.2021.3126648			22	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	6A4XX	34752384	Green Accepted, Green Submitted			2022-12-18	WOS:000880661400029
J	Nirkin, Y; Wolf, L; Keller, Y; Hassner, T				Nirkin, Yuval; Wolf, Lior; Keller, Yosi; Hassner, Tal			DeepFake Detection Based on Discrepancies Between Faces and Their Context	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Faces; Videos; Information integrity; Benchmark testing; Training; Neck; Hair; Image forensics; deep learning; deep fake; face swapping; fake image detection		We propose a method for detecting face swapping and other identity manipulations in single images. Face swapping methods, such as DeepFake, manipulate the face region, aiming to adjust the face to the appearance of its context, while leaving the context unchanged. We show that this modus operandi produces discrepancies between the two regions (e.g., Fig. 1). These discrepancies offer exploitable telltale signs of manipulation. Our approach involves two networks: (i) a face identification network that considers the face region bounded by a tight semantic segmentation, and (ii) a context recognition network that considers the face context (e.g., hair, ears, neck). We describe a method which uses the recognition signals from our two networks to detect such discrepancies, providing a complementary detection signal that improves conventional real versus fake classifiers commonly used for detecting fake images. Our method achieves state of the art results on the FaceForensics++ and Celeb-DF-v2 benchmarks for face manipulation detection, and even generalizes to detect fakes produced by unseen methods.	[Nirkin, Yuval; Keller, Yosi] Bar Ilan Univ, Fac Engn, IL-5290002 Ramat Gan, Israel; [Wolf, Lior] Tel Aviv Univ, IL-6997801 Tel Aviv, Israel; [Hassner, Tal] Facebook AI, Menlo Pk, CA 94025 USA	Bar Ilan University; Tel Aviv University; Facebook Inc	Nirkin, Y (corresponding author), Bar Ilan Univ, Fac Engn, IL-5290002 Ramat Gan, Israel.	yuval.nirkin@gmail.com; liorwolf@gmail.com; yosi.keller@gmail.com; talhassner@gmail.com			European Research Council (ERC) through the European Unions Horizon 2020 research and innovation programme [ERC CoG 725974]	European Research Council (ERC) through the European Unions Horizon 2020 research and innovation programme(European Research Council (ERC))	This work was supported by the European Research Council (ERC) through the European Unions Horizon 2020 research and innovation programme under Grant ERC CoG 725974. Lior Wolf, Yosi Keller, and Tal Hassner have equally contributed.	Afchar D, 2018, IEEE INT WORKS INFOR; Al-Sanjary OI, 2016, FORENSIC SCI INT, V266, P565, DOI 10.1016/j.forsciint.2016.07.013; Alexander O, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P176, DOI 10.1109/CVMP.2009.29; Anil Jain, 2020, Arxiv, DOI arXiv:1910.01717; [Anonymous], DEEPFAKES; [Anonymous], FACESWAP; Averbuch-Elor H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130818; Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019; Bayar Belhassen, 2016, P 4 ACM WORKSHOP INF, P5, DOI DOI 10.1145/2909827.2930786; Ben Pflaum, 2019, Arxiv, DOI arXiv:1910.08854; Bitouk D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360638; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Blanz V, 2004, COMPUT GRAPH FORUM, V23, P669, DOI 10.1111/j.1467-8659.2004.00799.x; Blanz V, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P202, DOI 10.1109/AFGR.2002.1004155; Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Ciftci U. A., 2020, 2020 IEEE INT JOINT, P1; Cozzolino D., ARXIV; Cozzolino D, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P159, DOI 10.1145/3082031.3083247; Enrique Sanchez, 2018, Arxiv, DOI arXiv:1811.03492; Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402; Fuming Fang, 2019, Arxiv, DOI arXiv:1906.06876; googleai, CONTR DAT DEEPF DET; Harkonen E., 2020, ARXIV; Honggang Qi, 2020, Arxiv, DOI arXiv:1909.12962; Hu S., 2020, ARXIV; Huang G.B., 2008, WORKSHOP FACESREAL L; Huy H. Nguyen, 2019, Arxiv, DOI arXiv:1910.12467; Jia S, 2018, IEEE ACCESS, V6, P25323, DOI 10.1109/ACCESS.2018.2819624; Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813; Kemelmacher-Shlizerman I, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925871; Kim H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201283; Kingma D.P, P 3 INT C LEARNING R; Korshunov P, 2019, INT CONF BIOMETR; Korshunov P, 2018, EUR SIGNAL PR CONF, P2375, DOI 10.23919/EUSIPCO.2018.8553270; Kritaphat Songsri-in, 2019, Arxiv, DOI arXiv:1910.05455; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Li J, 2019, PROC CVPR IEEE, P5055, DOI 10.1109/CVPR.2019.00520; Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505; Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020; Ming-Ching Chang, 2018, Arxiv, DOI arXiv:1806.02877; Mosaddegh S, 2015, LECT NOTES COMPUT SC, V9005, P159, DOI 10.1007/978-3-319-16811-1_11; Nagano K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275075; Natsume R, 2019, LECT NOTES COMPUT SC, V11366, P117, DOI 10.1007/978-3-030-20876-9_8; Nguyen HH, 2019, 13TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY (ARES 2018), DOI 10.1145/3230833.3230863; Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728; Nirkin Y, 2018, IEEE INT CONF AUTOMA, P98, DOI 10.1109/FG.2018.00024; Pumarola A, 2018, LECT NOTES COMPUT SC, V11214, P835, DOI 10.1007/978-3-030-01249-6_50; Qi H, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4318, DOI 10.1145/3394171.3413707; Quan WZ, 2018, IEEE T INF FOREN SEC, V13, P2772, DOI 10.1109/TIFS.2018.2834147; Rahmouni N, 2017, IEEE INT WORKS INFOR; Ronneberger O., 2015, P MEDICAL IMAGE COMP, P234; Natsume R, 2018, Arxiv, DOI arXiv:1804.03447; Sabir E, 2019, INTERFACES GUI, V3, P1; Siwei Lyu, 2019, Arxiv, DOI arXiv:1811.00656; Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Thies J., 2019, ARXIV; Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262; Wang SY, 2019, IEEE I CONF COMP VIS, P10071, DOI 10.1109/ICCV.2019.01017; Wolf L, 2010, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2010.5540133; Wu Y, 2018, LECT NOTES COMPUT SC, V11210, P170, DOI 10.1007/978-3-030-01231-1_11; Wu Y, 2019, PROC CVPR IEEE, P9535, DOI 10.1109/CVPR.2019.00977; Wu Y, 2018, IEEE WINT CONF APPL, P1907, DOI 10.1109/WACV.2018.00211; Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164; Yuan Lin, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P333, DOI 10.1109/ICME.2012.26; Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229	70	15	15	6	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2022	44	10					6111	6121		10.1109/TPAMI.2021.3093446	http://dx.doi.org/10.1109/TPAMI.2021.3093446			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	4N2UL	34185639				2022-12-18	WOS:000853875300021
J	Poggi, M; Tosi, F; Batsos, K; Mordohai, P; Mattoccia, S				Poggi, Matteo; Tosi, Fabio; Batsos, Konstantinos; Mordohai, Philippos; Mattoccia, Stefano			On the Synergies Between Machine Learning and Binocular Stereo for Depth Estimation From Images: A Survey	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Stereo matching; machine learning; deep learning; monocular depth estimation		Stereo matching is one of the longest-standing problems in computer vision with dose to 40 years of studies and research. Throughout the years the paradigm has shifted from local, pixel-level decision to various forms of discrete and continuous optimization to data-driven, learning-based methods. Recently, the rise of machine learning and the rapid proliferation of deep learning enhanced stereo matching with new exciting trends and applications unthinkable until a few years ago. Interestingly, the relationship between these two worlds is two-way. While machine, and especially deep, learning advanced the state-of-the-art in stereo matching, stereo itself enabled new ground-breaking methodologies such as self-supervised monocular depth estimation based on deep networks. In this paper, we review recent research in the field of learning-based depth estimation from single and binocular images highlighting the synergies, the successes achieved so far and the open challenges the community is going to face in the immediate future.	[Poggi, Matteo; Tosi, Fabio; Mattoccia, Stefano] Univ Bologna, Dept Comp Sci & Engn, I-40126 Bologna, Italy; [Batsos, Konstantinos] Argo AI, Pittsburgh, PA 15222 USA; [Mordohai, Philippos] Stevens Inst Technol, Dept Comp Sci, Hoboken, NJ 07030 USA	University of Bologna; Stevens Institute of Technology	Poggi, M (corresponding author), Univ Bologna, Dept Comp Sci & Engn, I-40126 Bologna, Italy.	m.poggi@unibo.it; fabio.tosi5@unibo.it; kbatsos@stevens.edu; mordohai@stevens.edu; stefano.mattoccia@unibo.it	Mattoccia, Stefano/AAV-6931-2021	Mattoccia, Stefano/0000-0002-3681-7704	National Science Foundation [IIS-1527294, IIS-1637761]	National Science Foundation(National Science Foundation (NSF))	This work was supported in part by National Science Foundation under Grants IIS-1527294 and IIS-1637761.	Aditya Joshi, 2020, Arxiv, DOI arXiv:1912.04838; Aleotti F, 2019, LECT NOTES COMPUT SC, V11129, P337, DOI 10.1007/978-3-030-11009-3_20; Andraghetti L, 2019, INT CONF 3D VISION, P424, DOI 10.1109/3DV.2019.00054; Angel X. Chang, 2015, Arxiv, DOI arXiv:1512.03012; Batsos K, 2018, PROC CVPR IEEE, P2060, DOI 10.1109/CVPR.2018.00220; Batsos K, 2018, INT CONF 3D VISION, P238, DOI 10.1109/3DV.2018.00036; Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603; Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44; Chabra R, 2019, PROC CVPR IEEE, P11778, DOI 10.1109/CVPR.2019.01206; Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567; Chang MF, 2019, PROC CVPR IEEE, P8740, DOI 10.1109/CVPR.2019.00895; Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49; Chen ZY, 2015, IEEE I CONF COMP VIS, P972, DOI 10.1109/ICCV.2015.117; Chen-Wei Xie, 2018, Arxiv, DOI arXiv:1804.06242; Cheng XJ, 2020, IEEE T PATTERN ANAL, V42, P2361, DOI [10.1109/TPAMI.2019.2947374, 10.5194/isprs-archives-XLII-3-W7-1-2019]; De-Maeztu L, 2011, IEEE I CONF COMP VIS, P1708, DOI 10.1109/ICCV.2011.6126434; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dosovitskiy A., 2017, C ROBOT LEARNING, P1; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Duggal S, 2019, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2019.00448; Eigen D, 2014, ADV NEUR IN, V27; Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214; Fu ZH, 2018, IEEE WINT CONF APPL, P1321, DOI 10.1109/WACV.2018.00149; Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45; Gast J, 2018, PROC CVPR IEEE, P3369, DOI 10.1109/CVPR.2018.00355; Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Gidaris S, 2017, PROC CVPR IEEE, P7187, DOI 10.1109/CVPR.2017.760; Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393; Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699; Gouveia R, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P180, DOI 10.1109/3DV.2015.28; Guo XY, 2019, PROC CVPR IEEE, P3268, DOI 10.1109/CVPR.2019.00339; Guo XY, 2018, LECT NOTES COMPUT SC, V11215, P506, DOI 10.1007/978-3-030-01252-6_30; Haeusler R, 2013, PROC CVPR IEEE, P305, DOI 10.1109/CVPR.2013.46; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; Hirschmuller Heiko, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383248; Hoffman J, 2018, PR MACH LEARN RES, V80; Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156; Hu XY, 2012, IEEE T PATTERN ANAL, V34, P2121, DOI 10.1109/TPAMI.2012.46; Huang XY, 2020, IEEE T PATTERN ANAL, V42, P2702, DOI 10.1109/TPAMI.2019.2926463; Ilg E, 2018, LECT NOTES COMPUT SC, V11216, P626, DOI 10.1007/978-3-030-01258-8_38; Jaderberg M, 2015, ADV NEUR IN, V28; Jiang HZ, 2019, IEEE I CONF COMP VIS, P3194, DOI 10.1109/ICCV.2019.00329; Jie ZQ, 2018, PROC CVPR IEEE, P3838, DOI 10.1109/CVPR.2018.00404; Karsch K, 2014, IEEE T PATTERN ANAL, V36, P2144, DOI 10.1109/TPAMI.2014.2316835; Kendall A., 2017, WHAT UNCERTAINTIES W, V3, P4; Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781; Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17; Kesten R., 2019, LYFT LEVEL 5 AV DATA; Khamis S, 2018, LECT NOTES COMPUT SC, V11219, P596, DOI 10.1007/978-3-030-01267-0_35; Kim S, 2019, PROC CVPR IEEE, P205, DOI 10.1109/CVPR.2019.00029; Kim S, 2019, IEEE T IMAGE PROCESS, V28, P1299, DOI 10.1109/TIP.2018.2878325; Kim S, 2017, IEEE T IMAGE PROCESS, V26, P6019, DOI 10.1109/TIP.2017.2750404; Knobelreiter P., 2017, P IEEE C COMP VIS PA, P2339; Knobelreiter P, 2019, LECT NOTES COMPUT SC, V11824, P3, DOI 10.1007/978-3-030-33676-9_1; Knobelreiter P, 2018, INT GEOSCI REMOTE SE, P4379; Komodakis N., 2007, IEEE 11 INT C COMP V, P1; Kuznietsov Y, 2017, PROC CVPR IEEE, P2215, DOI 10.1109/CVPR.2017.238; Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19; Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Li A., 2018, PROC ASIAN C COMPUT, P197; Liang ZF, 2018, PROC CVPR IEEE, P2811, DOI 10.1109/CVPR.2018.00297; Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283; Liu H., 2019, PROC INT C LEARN REP; Liu SF, 2017, ADV NEUR IN, V30; Luo CX, 2020, IEEE T PATTERN ANAL, V42, P2624, DOI 10.1109/TPAMI.2019.2930258; Luo WJ, 2016, PROC CVPR IEEE, P5695, DOI 10.1109/CVPR.2016.614; Luo Y, 2018, PROC CVPR IEEE, P155, DOI 10.1109/CVPR.2018.00024; Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498; Mayer N, 2018, INT J COMPUT VISION, V126, P942, DOI 10.1007/s11263-018-1082-6; Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438; Mehta I, 2018, INT CONF 3D VISION, P314, DOI 10.1109/3DV.2018.00044; Mei Xing, 2011, IEEE INT C COMP VIS, P467, DOI DOI 10.1109/ICCVW.2011.6130280; Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925; Mostegel C, 2016, PROC CVPR IEEE, P4067, DOI 10.1109/CVPR.2016.441; Nie GY, 2019, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2019.00340; Pang JH, 2018, PROC CVPR IEEE, P2070, DOI 10.1109/CVPR.2018.00221; Pang JH, 2017, IEEE INT CONF COMP V, P878, DOI 10.1109/ICCVW.2017.108; Park H, 2017, IEEE SIGNAL PROC LET, V24, P1788, DOI 10.1109/LSP.2016.2637355; Park MG, 2019, IEEE T PATTERN ANAL, V41, P1397, DOI 10.1109/TPAMI.2018.2837760; Park MG, 2015, PROC CVPR IEEE, P101, DOI 10.1109/CVPR.2015.7298605; Peluso V, 2019, DES AUT TEST EUROPE, P1703, DOI 10.23919/DATE.2019.8714893; Pillai S, 2019, IEEE INT CONF ROBOT, P9250, DOI 10.1109/ICRA.2019.8793621; Pilzer A, 2019, PROC CVPR IEEE, P9760, DOI 10.1109/CVPR.2019.01000; Poggi M, 2019, PROC CVPR IEEE, P979, DOI 10.1109/CVPR.2019.00107; Poggi M, 2020, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR42600.2020.00329; Poggi M, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102905; Poggi M, 2018, IEEE INT C INT ROBOT, P5848, DOI 10.1109/IROS.2018.8593814; Poggi M, 2018, INT CONF 3D VISION, P324, DOI 10.1109/3DV.2018.00045; Poggi M, 2017, IEEE I CONF COMP VIS, P5238, DOI 10.1109/ICCV.2017.559; Poggi M, 2017, PROC CVPR IEEE, P4541, DOI 10.1109/CVPR.2017.483; Poggi M, 2016, INT CONF 3D VISION, P509, DOI 10.1109/3DV.2016.61; Poggi Matteo, 2016, BMVC; Pollefeys M, 2016, BRIT MACH VIS C BMVC; Puscas MM, 2019, INT CONF 3D VISION, P18, DOI 10.1109/3DV.2019.00012; Ramirez PZ, 2019, LECT NOTES COMPUT SC, V11363, P298, DOI 10.1007/978-3-030-20893-6_19; Ronneberger O., 2015, P INT C MED IM COMP; Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Scharstein D, 2003, PROC CVPR IEEE, P195; Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3; Schonberger JL, 2018, LECT NOTES COMPUT SC, V11217, P758, DOI 10.1007/978-3-030-01261-8_45; Schops T, 2017, PROC CVPR IEEE, P2538, DOI 10.1109/CVPR.2017.272; Schuster R, 2019, PROC CVPR IEEE, P2551, DOI 10.1109/CVPR.2019.00266; Sebastian Ruder, 2017, Arxiv, DOI arXiv:1706.05098; Seki A, 2017, PROC CVPR IEEE, P6640, DOI 10.1109/CVPR.2017.703; Shaked A, 2017, PROC CVPR IEEE, P6901, DOI 10.1109/CVPR.2017.730; Song X, 2019, LECT NOTES COMPUT SC, V11365, P20, DOI 10.1007/978-3-030-20873-8_2; Song XN, 2022, IEEE T CYBERNETICS, V52, P178, DOI 10.1109/TCYB.2020.2972634; Spyropoulos A, 2016, INT J COMPUT VISION, V118, P300, DOI 10.1007/s11263-015-0877-y; Spyropoulos A, 2014, PROC CVPR IEEE, P1621, DOI 10.1109/CVPR.2014.210; Tonioni A, 2019, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2019.00028; Tonioni A, 2019, PROC CVPR IEEE, P9653, DOI 10.1109/CVPR.2019.00989; Tonioni A, 2020, IEEE T PATTERN ANAL, V42, P2396, DOI 10.1109/TPAMI.2019.2940948; Tonioni A, 2017, IEEE I CONF COMP VIS, P1614, DOI 10.1109/ICCV.2017.178; Tosi F., 2017, P 28 BRIT MACH VIS C; Tosi F, 2019, PROC CVPR IEEE, P9791, DOI 10.1109/CVPR.2019.01003; Tosi F, 2018, LECT NOTES COMPUT SC, V11210, P323, DOI 10.1007/978-3-030-01231-1_20; Tulyakov S, 2018, ADV NEUR IN, V31; Tulyakov S, 2017, IEEE I CONF COMP VIS, P1348, DOI 10.1109/ICCV.2017.150; Wang Y, 2019, IEEE INT CONF ROBOT, P5893, DOI 10.1109/ICRA.2019.8794003; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Watson J, 2019, IEEE I CONF COMP VIS, P2162, DOI 10.1109/ICCV.2019.00225; Wu ZY, 2019, IEEE I CONF COMP VIS, P7483, DOI 10.1109/ICCV.2019.00758; Xie JY, 2016, LECT NOTES COMPUT SC, V9908, P842, DOI 10.1007/978-3-319-46493-0_51; Yang GS, 2019, PROC CVPR IEEE, P5510, DOI 10.1109/CVPR.2019.00566; Yang GR, 2019, PROC CVPR IEEE, P899, DOI 10.1109/CVPR.2019.00099; Yang GR, 2018, LECT NOTES COMPUT SC, V11211, P660, DOI 10.1007/978-3-030-01234-2_39; Yang N, 2018, LECT NOTES COMPUT SC, V11212, P835, DOI 10.1007/978-3-030-01237-3_50; Yang ZH, 2019, LECT NOTES COMPUT SC, V11133, P691, DOI 10.1007/978-3-030-11021-5_43; Ye XQ, 2017, IEEE ACCESS, V5, P18745, DOI 10.1109/ACCESS.2017.2754318; Yin ZC, 2019, PROC CVPR IEEE, P6037, DOI 10.1109/CVPR.2019.00620; Yu LD, 2018, AAAI CONF ARTIF INTE, P7517; Yusiong JPT, 2019, IEEE WINT CONF APPL, P443, DOI 10.1109/WACV.2019.00053; Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345; Zbontar J, 2016, J MACH LEARN RES, V17; Zhan HY, 2018, PROC CVPR IEEE, P340, DOI 10.1109/CVPR.2018.00043; Zhan WJ, 2019, IEEE INT CONF ROBOT, P2946, DOI 10.1109/ICRA.2019.8793573; Zhang FH, 2019, PROC CVPR IEEE, P185, DOI 10.1109/CVPR.2019.00027; Zhang FH, 2018, IEEE T IMAGE PROCESS, V27, P822, DOI 10.1109/TIP.2017.2752370; Zhang K, 2009, IEEE T CIRC SYST VID, V19, P1073, DOI 10.1109/TCSVT.2009.2020478; Zhong YR, 2018, LECT NOTES COMPUT SC, V11206, P104, DOI 10.1007/978-3-030-01216-8_7; Zhou C, 2017, IEEE I CONF COMP VIS, P1576, DOI 10.1109/ICCV.2017.174; Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	150	15	15	51	79	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2022	44	9					5314	5334		10.1109/TPAMI.2021.3070917	http://dx.doi.org/10.1109/TPAMI.2021.3070917			21	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	3O2KN	33819150	Green Submitted			2022-12-18	WOS:000836666600059
J	Wang, WG; Zhou, TF; Qi, SY; Shen, JB; Zhu, SC				Wang, Wenguan; Zhou, Tianfei; Qi, Siyuan; Shen, Jianbing; Zhu, Song-Chun			Hierarchical Human Semantic Parsing With Comprehensive Part-Relation Modeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Biological system modeling; Cognition; Task analysis; Legged locomotion; Computational modeling; Message passing; Human parsing; hierarchical model; relation reasoning; graph neural network	PRODUCTS	Modeling the human structure is central for human parsing that extracts pixel-wise semantic information from images. We start with analyzing three types of inference processes over the hierarchical structure of human bodies: direct inference (directly predicting human semantic parts using image information), bottom-up inference (assembling knowledge from constituent parts), and top-down inference (leveraging context from parent nodes). We then formulate the problem as a compositional neural information fusion (CNIF) framework, which assembles the information from the three inference processes in a conditional manner, i.e., considering the confidence of the sources. Based on CNIF, we further present a part-relation-aware human parser (PRHP), which precisely describes three kinds of human part relations, i.e., decomposition, composition, and dependency, by three distinct relation networks. Expressive relation information can be captured by imposing the parameters in the relation networks to satisfy specific geometric characteristics of different relations. By assimilating generic message-passing networks with their edge-typed, convolutional counterparts, PRHP performs iterative reasoning over the human body hierarchy. With these efforts, PRHP provides a more general and powerful form of CNIF, and lays the foundation for more sophisticated and flexible human relation patterns of reasoning. Experiments on five datasets demonstrate that our two human parsers outperform the state-of-the-arts in all cases.	[Wang, Wenguan; Zhou, Tianfei] Swiss Fed Inst Technol, Zurich, Switzerland; [Qi, Siyuan] Google, Mountain View, CA 94043 USA; [Shen, Jianbing] Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates; [Shen, Jianbing] Beijing Inst Technol, Sch Comp Sci, Beijing, Peoples R China; [Zhu, Song-Chun] Tsinghua Univ, Beijing 100084, Peoples R China; [Zhu, Song-Chun] Peking Univ, Beijing 100871, Peoples R China	Swiss Federal Institutes of Technology Domain; ETH Zurich; Google Incorporated; Beijing Institute of Technology; Tsinghua University; Peking University	Shen, JB (corresponding author), Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates.	wenguanwang.ai@gmail.com; ztfei.debug@gmail.com; syqi@cs.ucla.edu; shenjianbingcg@gmail.com; sczhu@stat.ucla.edu	Zhou, Tianfei/AAC-6115-2022	Zhou, Tianfei/0000-0001-5475-1473	CCF-Baidu Open Fund; Zhejiang Lab's Open Fund [2019KD0AB04]	CCF-Baidu Open Fund; Zhejiang Lab's Open Fund	This work was supported in part by the CCF-Baidu Open Fund and Zhejiang Lab's Open Fund (No. 2019KD0AB04). This work builds upon two earlier conference papers, appeared in ICCV2019 [1] and CVPR2020 [2], respectively.	Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Battaglia Peter W, 2018, ARXIV180601261; Behnke S, 2003, LECT NOTES COMPUT SC, V2766, P1; Chen H., 2006, PROC IEEE COMPUT SCI, V1, P943; Chen L, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278067; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396; Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709; Chen XJ, 2014, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2014.254; Dang K., 2014, PROC BRIT MACH VIS C; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1; Dong J, 2014, PROC CVPR IEEE, P843, DOI 10.1109/CVPR.2014.113; Dong J, 2013, IEEE I CONF COMP VIS, P3408, DOI 10.1109/ICCV.2013.423; Duvenaud David K, 2015, P NIPS; Epshtein B, 2008, P NATL ACAD SCI USA, V105, P14298, DOI 10.1073/pnas.0800968105; Eslami S.M.A, 2012, ADV NEURAL INFORM PR, V25, P100; Fan LF, 2019, IEEE I CONF COMP VIS, P5723, DOI 10.1109/ICCV.2019.00582; Fan LF, 2018, PROC CVPR IEEE, P6460, DOI 10.1109/CVPR.2018.00676; Fang HS, 2018, AAAI CONF ARTIF INTE, P6821; Fang HS, 2018, PROC CVPR IEEE, P70, DOI 10.1109/CVPR.2018.00015; Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Gilmer J, 2017, PR MACH LEARN RES, V70; Gong K, 2018, LECT NOTES COMPUT SC, V11208, P805, DOI 10.1007/978-3-030-01225-0_47; Gong K, 2019, PROC CVPR IEEE, P7442, DOI 10.1109/CVPR.2019.00763; Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715; Grill-Spector K, 2014, NAT REV NEUROSCI, V15, P536, DOI 10.1038/nrn3747; Hamilton W. L., 2017, ARXIV 170905584; Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520; He K., 2016, PROC IEEE C COMPUTER, P770, DOI DOI 10.1109/CVPR.2016.90; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 1999, IEE CONF PUBL, P1, DOI 10.1049/cp:19991075; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Hu RH, 2016, LECT NOTES COMPUT SC, V9905, P108, DOI 10.1007/978-3-319-46448-0_7; Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573; Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]; Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117; Khaleghi B, 2013, INFORM FUSION, V14, P28, DOI 10.1016/j.inffus.2011.08.001; KIMCHI R, 1992, PSYCHOL BULL, V112, P24, DOI 10.1037/0033-2909.112.1.24; Kipf T. N., 2017, 5 INT C LEARN REPR; Ladicky L, 2013, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2013.459; Li JS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P45, DOI 10.1145/3240508.3240515; Li JF, 2019, PROC CVPR IEEE, P10855, DOI 10.1109/CVPR.2019.01112; Li Q., 2017, ARXIV 170903612; Li YL, 2020, PROC CVPR IEEE, P379, DOI 10.1109/CVPR42600.2020.00046; Liang Shiyu, 2017, ARXIV PREPRINT ARXIV; Liang XD, 2017, PROC CVPR IEEE, P2175, DOI 10.1109/CVPR.2017.234; Liang XD, 2016, PROC CVPR IEEE, P3185, DOI 10.1109/CVPR.2016.347; Liang XD, 2016, LECT NOTES COMPUT SC, V9905, P125, DOI 10.1007/978-3-319-46448-0_8; Liang XD, 2015, IEEE I CONF COMP VIS, P1386, DOI 10.1109/ICCV.2015.163; Liang XD, 2015, IEEE T PATTERN ANAL, V37, P2402, DOI 10.1109/TPAMI.2015.2408360; Liu S, 2018, AAAI CONF ARTIF INTE, P7146; Liu S, 2017, PROC CVPR IEEE, P1013, DOI 10.1109/CVPR.2017.114; Liu S, 2015, PROC CVPR IEEE, P1419, DOI 10.1109/CVPR.2015.7298748; Liu S, 2014, IEEE T MULTIMEDIA, V16, P253, DOI 10.1109/TMM.2013.2285526; Liu T, 2018, ARXIV 180905996; Liu XC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P338, DOI 10.1145/3343031.3350857; Long J., 2015, P IEEE C COMPUTER VI, P3431, DOI DOI 10.1109/CVPR.2015.7298965; Luc P., 2016, NIPS WORKSHOP ADVERS; Luo P, 2013, IEEE I CONF COMP VIS, P2648, DOI 10.1109/ICCV.2013.329; Luo XH, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P654, DOI 10.1145/3240508.3240634; Luo YW, 2018, LECT NOTES COMPUT SC, V11213, P424, DOI 10.1007/978-3-030-01240-3_26; MARCEL AJ, 1983, COGNITIVE PSYCHOL, V15, P238, DOI 10.1016/0010-0285(83)90010-5; NAVON D, 1977, COGNITIVE PSYCHOL, V9, P353, DOI 10.1016/0010-0285(77)90012-3; Nie XC, 2018, LECT NOTES COMPUT SC, V11209, P519, DOI 10.1007/978-3-030-01228-1_31; Niepert M, 2016, PR MACH LEARN RES, V48; Qi SY, 2018, LECT NOTES COMPUT SC, V11213, P407, DOI 10.1007/978-3-030-01240-3_25; Rauschert I, 2012, LECT NOTES COMPUT SC, V7576, P704, DOI 10.1007/978-3-642-33715-4_51; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605; Shi XJ, 2015, ADV NEUR IN, V28; Song X, 2013, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2013.421; Sutton C, 2012, FOUND TRENDS MACH LE, V4, P267, DOI 10.1561/2200000013; Tang W, 2018, LECT NOTES COMPUT SC, V11207, P197, DOI 10.1007/978-3-030-01219-9_12; Vaswani A, 2017, ADV NEUR IN, V30; Veit A, 2018, LECT NOTES COMPUT SC, V11205, P3, DOI 10.1007/978-3-030-01246-5_1; Velickovic P., 2018, P INT C LEARN REPR; Wainwright MJ, 2008, FOUND TRENDS MACH LE, V1, P1, DOI 10.1561/2200000001; Wang N, 2011, IEEE I CONF COMP VIS, P1535, DOI 10.1109/ICCV.2011.6126412; Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933; Wang WG, 2019, IEEE I CONF COMP VIS, P5702, DOI 10.1109/ICCV.2019.00580; Wang WG, 2019, PROC CVPR IEEE, P5961, DOI 10.1109/CVPR.2019.00612; Wang WG, 2018, PROC CVPR IEEE, P4271, DOI 10.1109/CVPR.2018.00449; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Wenguan Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8926, DOI 10.1109/CVPR42600.2020.00895; Wu TF, 2011, INT J COMPUT VISION, V93, P226, DOI 10.1007/s11263-010-0346-6; Xia FT, 2016, AAAI CONF ARTIF INTE, P3632; Xia FT, 2017, PROC CVPR IEEE, P6080, DOI 10.1109/CVPR.2017.644; Xia FT, 2016, LECT NOTES COMPUT SC, V9909, P648, DOI 10.1007/978-3-319-46454-1_39; Xiu Y., 2018, BMVC; Yamaguchi K, 2013, IEEE I CONF COMP VIS, P3519, DOI 10.1109/ICCV.2013.437; Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101; Yang W, 2014, PROC CVPR IEEE, P3182, DOI 10.1109/CVPR.2014.407; Yihang Bo, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2265, DOI 10.1109/CVPR.2011.5995609; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhao J, 2020, INT J COMPUT VISION, V128, P2185, DOI 10.1007/s11263-019-01181-5; Zhao J, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P792, DOI 10.1145/3240508.3240509; Zhao J, 2017, IEEE COMPUT SOC CONF, P1595, DOI 10.1109/CVPRW.2017.204; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179; Zheng ZL, 2019, PROC CVPR IEEE, P3662, DOI 10.1109/CVPR.2019.00683; Zhou TF, 2022, IEEE T PATTERN ANAL, V44, P2827, DOI 10.1109/TPAMI.2021.3049156; Zhu BK, 2018, AAAI CONF ARTIF INTE, P7607; Zhu L., 2008, IEEE C COMP VIS PATT, P1	107	15	15	4	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2022	44	7					3508	3522		10.1109/TPAMI.2021.3055780	http://dx.doi.org/10.1109/TPAMI.2021.3055780			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1V0WH	33513100				2022-12-18	WOS:000805820500014
J	Sakaridis, C; Dai, DX; Van Gool, L				Sakaridis, Christos; Dai, Dengxin; Van Gool, Luc			Map-Guided Curriculum Domain Adaptation and Uncertainty-Aware Evaluation for Semantic Nighttime Image Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Image segmentation; Adaptation models; Annotations; Task analysis; Measurement; Lighting; Domain adaptation; semantic segmentation; nighttime; evaluation; curriculum learning	PEDESTRIAN DETECTION; TRACKING	We address the problem of semantic nighttime image segmentation and improve the state-of-the-art, by adapting daytime models to nighttime without using nighttime annotations. Moreover, we design a new evaluation framework to address the substantial uncertainty of semantics in nighttime images. Our central contributions are: 1) a curriculum framework to gradually adapt semantic segmentation models from day to night through progressively darker times of day, exploiting cross-time-of-day correspondences between daytime images from a reference map and dark images to guide the label inference in the dark domains; 2) a novel uncertainty-aware annotation and evaluation framework and metric for semantic segmentation, including image regions beyond human recognition capability in the evaluation in a principled fashion; 3) the Dark Zurich dataset, comprising 2416 unlabeled nighttime and 2920 unlabeled twilight images with correspondences to their daytime counterparts plus a set of 201 nighttime images with fine pixel-level annotations created with our protocol, which serves as a first benchmark for our novel evaluation. Experiments show that our map-guided curriculum adaptation significantly outperforms state-of-the-art methods on nighttime sets both for standard metrics and our uncertainty-aware metric. Furthermore, our uncertainty-aware evaluation reveals that selective invalidation of predictions can improve results on data with ambiguous content such as our benchmark and profit safety-oriented applications involving invalid inputs.	[Sakaridis, Christos; Dai, Dengxin; Van Gool, Luc] Swiss Fed Inst Technol, Dept Informat Technol & Elect Engn, CH-8092 Zurich, Switzerland; [Van Gool, Luc] Katholieke Univ Leuven, Dept Elect Engn, B-3000 Leuven, Belgium	Swiss Federal Institutes of Technology Domain; ETH Zurich; KU Leuven	Sakaridis, C (corresponding author), Swiss Fed Inst Technol, Dept Informat Technol & Elect Engn, CH-8092 Zurich, Switzerland.	csakarid@vision.ee.ethz.ch; dai@vision.ee.ethz.ch; vangool@vision.ee.ethz.ch		Van Gool, Luc/0000-0002-3445-5711	Toyota Motor Europe via the research project TRACE-Zurich	Toyota Motor Europe via the research project TRACE-Zurich	This work was supported by Toyota Motor Europe via the research project TRACE-Zurich. The authors thank Simon Hecker for his advice on decoding GoPro GPS data.	Alvarez JM, 2011, IEEE T INTELL TRANSP, V12, P184, DOI 10.1109/TITS.2010.2076349; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Bengio Yoshua., 2009, P 26 ANN INT C MACHI, P41, DOI 10.1145/ 1553374.1553380; Bevandic P, 2019, LECT NOTES COMPUT SC, V11824, P33, DOI 10.1007/978-3-030-33676-9_3; Bijelic M, 2018, IEEE INT VEH SYM, P1773; Chang MF, 2019, PROC CVPR IEEE, P8740, DOI 10.1109/CVPR.2019.00895; Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen X, 2019, IEEE I CONF COMP VIS, P4089, DOI 10.1109/ICCV.2019.00419; Chen YH, 2018, PROC CVPR IEEE, P7892, DOI 10.1109/CVPR.2018.00823; Chen Y, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P5079, DOI 10.1109/WCICA.2008.4593753; Choi Y, 2018, IEEE T INTELL TRANSP, V19, P934, DOI 10.1109/TITS.2018.2791533; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Dai DX, 2020, INT J COMPUT VISION, V128, P1182, DOI 10.1007/s11263-019-01182-4; Dai DX, 2018, IEEE INT C INTELL TR, P3819, DOI 10.1109/ITSC.2018.8569387; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Ge JF, 2009, IEEE T INTELL TRANSP, V10, P283, DOI 10.1109/TITS.2009.2018961; Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393; Guangrui Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P440, DOI 10.1007/978-3-030-58568-6_26; Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185; Hahner M, 2019, IEEE INT C INTELL TR, P3675, DOI 10.1109/ITSC.2019.8917518; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hecker S, 2018, LECT NOTES COMPUT SC, V11211, P449, DOI 10.1007/978-3-030-01234-2_27; Hentschel M., 2010, 2010 13th International IEEE Conference on Intelligent Transportation Systems (ITSC 2010), P1645, DOI 10.1109/ITSC.2010.5625092; Hoffman J, 2018, PR MACH LEARN RES, V80; Hoffman J, 2014, PROC CVPR IEEE, P867, DOI 10.1109/CVPR.2014.116; Hong WX, 2018, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2018.00145; Irie K, 2013, IEEE INT C INT ROBOT, P1938, DOI 10.1109/IROS.2013.6696613; Kahng SJ, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010017; Kang G., 2020, ARXIV201100147V1 CSC; Kendall A., 2017, P ADV NEUR INF PROC, V30; Kirillov A, 2019, PROC CVPR IEEE, P9396, DOI 10.1109/CVPR.2019.00963; Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239547, 10.1145/1276377.1276497]; Kuang HL, 2018, IEEE T INTELL TRANSP, V19, P814, DOI 10.1109/TITS.2017.2702665; Kurdej M, 2015, IEEE INTEL TRANSP SY, V7, P30, DOI 10.1109/MITS.2014.2352371; Larsson M, 2019, PROC CVPR IEEE, P9524, DOI 10.1109/CVPR.2019.00976; Levinson J, 2010, IEEE INT CONF ROBOT, P4372, DOI 10.1109/ROBOT.2010.5509700; Li YA, 2019, IEEE I CONF COMP VIS, P3275, DOI 10.1109/ICCV.2019.00337; Li YS, 2019, PROC CVPR IEEE, P6929, DOI 10.1109/CVPR.2019.00710; Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549; Lv J. W. Feifan, 2018, BR MACH VIS C; Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498; Moras J, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P778, DOI 10.1109/IVS.2012.6232252; Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723; Neuhold G, 2017, IEEE I CONF COMP VIS, P5000, DOI 10.1109/ICCV.2017.534; Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8; PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X; Pham QH, 2020, IEEE INT CONF ROBOT, P2267, DOI 10.1109/ICRA40945.2020.9197385; Ros G, 2015, IEEE INT VEH SYM, P537, DOI 10.1109/IVS.2015.7225740; Sakaridis C, 2019, IEEE I CONF COMP VIS, P7373, DOI 10.1109/ICCV.2019.00747; Sakaridis C, 2018, LECT NOTES COMPUT SC, V11217, P707, DOI 10.1007/978-3-030-01261-8_42; Sakaridis C, 2018, INT J COMPUT VISION, V126, P973, DOI 10.1007/s11263-018-1072-8; Sankaranarayanan S, 2018, PROC CVPR IEEE, P8503, DOI 10.1109/CVPR.2018.00887; Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897; Satzoda RK, 2019, IEEE T INTELL TRANSP, V20, P4297, DOI 10.1109/TITS.2016.2614545; Tsai YH, 2018, PROC CVPR IEEE, P7472, DOI 10.1109/CVPR.2018.00780; Vu TH, 2019, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2019.00262; Tung F, 2017, IEEE ROBOT AUTOM LET, V2, P2188, DOI 10.1109/LRA.2017.2723926; Valada Abhinav, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4644, DOI 10.1109/ICRA.2017.7989540; Wang RX, 2019, PROC CVPR IEEE, P6842, DOI 10.1109/CVPR.2019.00701; Wu ZX, 2018, LECT NOTES COMPUT SC, V11209, P535, DOI 10.1007/978-3-030-01228-1_32; Wulfmeier M, 2018, IEEE INT CONF ROBOT, P4489; Wulfmeier M, 2017, IEEE INT C INT ROBOT, P1551; Xu FL, 2005, IEEE T INTELL TRANSP, V6, P63, DOI 10.1109/TITS.2004.838222; Yang B., 2018, P C ROB LEARN, P146; Yu F., 2016, P ICLR 2016; Yu F., 2020, ARXIV180504687V1 CSC; Zaech J.-N., 2020, ARXIV200414251V1 CSC; Zendel O, 2018, LECT NOTES COMPUT SC, V11210, P407, DOI 10.1007/978-3-030-01231-1_25; Zendel O, 2017, INT J COMPUT VISION, V125, P95, DOI 10.1007/s11263-017-1020-z; Zhang Y, 2017, IEEE I CONF COMP VIS, P2039, DOI 10.1109/ICCV.2017.223; Zhang YH, 2018, PROC CVPR IEEE, P6810, DOI 10.1109/CVPR.2018.00712; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhao SC, 2019, ADV NEUR IN, V32; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zhu XG, 2018, LECT NOTES COMPUT SC, V11211, P587, DOI 10.1007/978-3-030-01234-2_35; Ziegler J, 2014, IEEE INT VEH SYM, P1231, DOI 10.1109/IVS.2014.6856560; Ziwei Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12403, DOI 10.1109/CVPR42600.2020.01242; Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI 10.1007/978-3-030-01219-9_	79	15	15	21	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2022	44	6					3139	3153		10.1109/TPAMI.2020.3045882	http://dx.doi.org/10.1109/TPAMI.2020.3045882			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1R1DD	33338013	Green Accepted, Green Submitted			2022-12-18	WOS:000803117500026
J	Khan, SS; Sundar, V; Boominathan, V; Veeraraghavan, A; Mitra, K				Khan, Salman Siddique; Sundar, Varun; Boominathan, Vivek; Veeraraghavan, Ashok; Mitra, Kaushik			FlatNet: Towards Photorealistic Scene Reconstruction From Lensless Measurements	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Image reconstruction; Lenses; Multiplexing; Computational modeling; Mathematical model; lensless imaging; image reconstruction	CAMERAS	Lensless imaging has emerged as a potential solution towards realizing ultra-miniature cameras by eschewing the bulky lens in a traditional camera. Without a focusing lens, the lensless cameras rely on computational algorithms to recover the scenes from multiplexed measurements. However, the current iterative-optimization-based reconstruction algorithms produce noisier and perceptually poorer images. In this work, we propose a non-iterative deep learning-based reconstruction approach that results in orders of magnitude improvement in image quality for lensless reconstructions. Our approach, called FlatNet, lays down a framework for reconstructing high-quality photorealistic images from mask-based lensless cameras, where the camera's forward model formulation is known. FlatNet consists of two stages: (1) an inversion stage that maps the measurement into a space of intermediate reconstruction by learning parameters within the forward model formulation, and (2) a perceptual enhancement stage that improves the perceptual quality of this intermediate reconstruction. These stages are trained together in an end-to-end manner. We show high-quality reconstructions by performing extensive experiments on real and challenging scenes using two different types of lensless prototypes: one which uses a separable forward model and another, which uses a more general non-separable cropped-convolution model. Our end-to-end approach is fast, produces photorealistic reconstructions, and is easy to adopt for other mask-based lensless cameras.	[Khan, Salman Siddique; Sundar, Varun; Mitra, Kaushik] Indian Inst Technol Madras, Dept Elect Engn, Chennai 600036, Tamil Nadu, India; [Boominathan, Vivek; Veeraraghavan, Ashok] Rice Univ, Houston, TX 77005 USA	Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Madras; Rice University	Khan, SS (corresponding author), Indian Inst Technol Madras, Dept Elect Engn, Chennai 600036, Tamil Nadu, India.	sk39@smail.iitm.ac.in; varunsundar@smail.iitm.ac.in; vivekb@rice.edu; vashok@rice.edu; kmitra@smail.iitm.ac.in			NSF CAREER [IIS-1652633]; NSF EXPEDITIONS [CCF-1730574]; DARPA NESD [HR0011-17-C0026]; NIH [R21EY029459]; Qualcomm Innovation Fellowship 2020 India	NSF CAREER(National Science Foundation (NSF)NSF - Office of the Director (OD)); NSF EXPEDITIONS; DARPA NESD; NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Qualcomm Innovation Fellowship 2020 India	This work was supported in part by the NSF CAREER: IIS-1652633, NSF EXPEDITIONS: CCF-1730574, DARPA NESD: HR0011-17-C0026, NIH Grant: R21EY029459 and the Qualcomm Innovation Fellowship 2020 India. Salman Siddique Khan and Varun Sundar contributed equally to this work.	Adams JK, 2017, SCI ADV, V3, DOI 10.1126/sciadv.1701548; Antipa N, 2019, IEEE INT CONF COMPUT; Antipa N, 2018, OPTICA, V5, P1, DOI 10.1364/OPTICA.5.000001; Asif MS, 2017, IEEE T COMPUT IMAG, V3, P384, DOI 10.1109/TCI.2016.2593662; Boominathan L., 2018, P BRIT MACH VIS C; Boominathan V, 2020, IEEE T PATTERN ANAL, V42, P1618, DOI 10.1109/TPAMI.2020.2987489; Boominathan V, 2016, IEEE SIGNAL PROC MAG, V33, P23, DOI 10.1109/MSP.2016.2581921; CAROLI E, 1987, SPACE SCI REV, V45, P349, DOI 10.1007/BF00171998; Chang JHR, 2017, IEEE I CONF COMP VIS, P5889, DOI 10.1109/ICCV.2017.627; Chi WL, 2011, OPT EXPRESS, V19, P4294, DOI 10.1364/OE.19.004294; Dave A, 2019, IEEE T COMPUT IMAG, V5, P37, DOI 10.1109/TCI.2018.2882698; Dave A, 2017, IEEE IMAGE PROC, P1702; DeWeert MJ, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.2.023102; DICKE RH, 1968, ASTROPHYS J, V153, pL101, DOI 10.1086/180230; Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gu SH, 2019, IEEE I CONF COMP VIS, P2511, DOI 10.1109/ICCV.2019.00260; Huang G, 2013, IEEE IMAGE PROC, P2101, DOI 10.1109/ICIP.2013.6738433; Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43; Khan SS, 2019, IEEE I CONF COMP VIS, P7859, DOI 10.1109/ICCV.2019.00795; Kim G, 2017, APPL OPTICS, V56, P6450, DOI 10.1364/AO.56.006450; Kingma D.P., 2015, P ICLR; Kulkarni K, 2016, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2016.55; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Li CB, 2013, COMPUT OPTIM APPL, V56, P507, DOI 10.1007/s10589-013-9576-1; LOHMANN AW, 1989, APPL OPTICS, V28, P4996, DOI 10.1364/AO.28.004996; Mechrez R, 2018, LECT NOTES COMPUT SC, V11218, P800, DOI 10.1007/978-3-030-01264-9_47; Mousavi A, 2015, ANN ALLERTON CONF, P1336, DOI 10.1109/ALLERTON.2015.7447163; Ramachandran Prajit, 2018, INT C LEARN REPR ICL, P2; Reddy D, 2011, PROC CVPR IEEE, P329, DOI 10.1109/CVPR.2011.5995542; Reeves SJ, 2005, IEEE T IMAGE PROCESS, V14, P1448, DOI 10.1109/TIP.2005.854474; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Satat G, 2017, IEEE T COMPUT IMAG, V3, P398, DOI 10.1109/TCI.2017.2684624; Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207; Shimano T, 2018, APPL OPTICS, V57, P2841, DOI 10.1364/AO.57.002841; Simonyan Karen, 2015, VERY DEEP CONVOLUTIO; Stork D. G., 2013, LENSLESS ULTRA MINIA, P186; Tremblay EJ, 2007, APPL OPTICS, V46, P463, DOI 10.1364/AO.46.000463; Zhang J, 2018, PROC CVPR IEEE, P1828, DOI 10.1109/CVPR.2018.00196; Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068	42	15	16	15	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					1934	1948		10.1109/TPAMI.2020.3033882	http://dx.doi.org/10.1109/TPAMI.2020.3033882			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33104508	hybrid, Green Submitted			2022-12-18	WOS:000764815300021
J	Luo, YW; Ren, CX; Dai, DQ; Yan, H				Luo, You-Wei; Ren, Chuan-Xian; Dai, Dao-Qing; Yan, Hong			Unsupervised Domain Adaptation via Discriminative Manifold Propagation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Manifolds; Machine learning; Measurement; Training; Prototypes; Task analysis; Dictionaries; Unsupervised domain adaptation; riemannian manifold; discriminant embedding; manifold alignment	ALGORITHMS; FRAMEWORK	Unsupervised domain adaptation is effective in leveraging rich information from a labeled source domain to an unlabeled target domain. Though deep learning and adversarial strategy made a significant breakthrough in the adaptability of features, there are two issues to be further studied. First, hard-assigned pseudo labels on the target domain are arbitrary and error-prone, and direct application of them may destroy the intrinsic data structure. Second, batch-wise training of deep learning limits the characterization of the global structure. In this paper, a Riemannian manifold learning framework is proposed to achieve transferability and discriminability simultaneously. For the first issue, this framework establishes a probabilistic discriminant criterion on the target domain via soft labels. Based on pre-built prototypes, this criterion is extended to a global approximation scheme for the second issue. Manifold metric alignment is adopted to be compatible with the embedding space. The theoretical error bounds of different alignment metrics are derived for constructive guidance. The proposed method can be used to tackle a series of variants of domain adaptation problems, including both vanilla and partial settings. Extensive experiments have been conducted to investigate the method and a comparative study shows the superiority of the discriminative manifold learning framework.	[Luo, You-Wei; Ren, Chuan-Xian; Dai, Dao-Qing] Sun Yat Sen Univ, Intelligent Data Ctr, Sch Math, Guangzhou 510275, Peoples R China; [Yan, Hong] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China	Sun Yat Sen University; City University of Hong Kong	Ren, CX (corresponding author), Sun Yat Sen Univ, Intelligent Data Ctr, Sch Math, Guangzhou 510275, Peoples R China.	luoyw28@mail2.sysu.edu.cn; rchuanx@mail.sysu.edu.cn; stsddq@mail.sysu.edu.cn; h.yan@cityu.edu.hk		, Luo/0000-0002-3027-6679; YAN, Hong/0000-0001-9661-3095	National Natural Science Foundation of China [61976229, 61906046, 61572536, 11631015, U1611265]; Science and Technology Program of Guangzhou [201804010248]; City University of Hong Kong [9610460]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Science and Technology Program of Guangzhou; City University of Hong Kong(City University of Hong Kong)	This work was supported in part by the National Natural Science Foundation of China under Grants 61976229, 61906046, 61572536, 11631015, and U1611265, in part by the Science and Technology Program of Guangzhou under Grant 201804010248 and City University of Hong Kong (Project 9610460). You-Wei Luo and Chuan-Xian Ren contributed equally to this work.	Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996; Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4; Bergamo A., 2010, ADV NEURAL INFORM PR, P181; Cao ZJ, 2018, LECT NOTES COMPUT SC, V11212, P139, DOI 10.1007/978-3-030-01237-3_9; Cao ZJ, 2019, PROC CVPR IEEE, P2980, DOI 10.1109/CVPR.2019.00310; Cao ZJ, 2018, PROC CVPR IEEE, P2724, DOI 10.1109/CVPR.2018.00288; Chang WG, 2019, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2019.00753; Chen C, 2019, AAAI CONF ARTIF INTE, P3296; Chen XY, 2019, PR MACH LEARN RES, V97; Das D, 2018, LECT NOTES COMPUT SC, V11141, P342, DOI 10.1007/978-3-030-01424-7_34; Ding ZM, 2019, IEEE T NEUR NET LEAR, V30, P1768, DOI 10.1109/TNNLS.2018.2874567; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Ganin Y, 2016, J MACH LEARN RES, V17; Ge PF, 2020, IEEE T NEUR NET LEAR, V31, P1417, DOI 10.1109/TNNLS.2019.2919948; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Griffin G., 2007, 120 CAL I TECHN; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu JL, 2015, PROC CVPR IEEE, P325, DOI 10.1109/CVPR.2015.7298629; Huang ZW, 2018, IEEE T PATTERN ANAL, V40, P2827, DOI 10.1109/TPAMI.2017.2776154; Lee CY, 2019, PROC CVPR IEEE, P10277, DOI 10.1109/CVPR.2019.01053; Lim LH, 2019, SIAM J MATRIX ANAL A, V40, P371, DOI 10.1137/18M1169321; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Long MS, 2018, ADV NEUR IN, V31; Long MS, 2019, IEEE T PATTERN ANAL, V41, P3071, DOI 10.1109/TPAMI.2018.2868685; Long MS, 2017, PR MACH LEARN RES, V70; Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274; Luo YW, 2020, AAAI CONF ARTIF INTE, V34, P5029; Moon JH, 2020, INT CONF ACOUST SPEE, P4172, DOI 10.1109/ICASSP40776.2020.9052976; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Pan YW, 2019, PROC CVPR IEEE, P2234, DOI 10.1109/CVPR.2019.00234; Papadopoulo T, 2000, LECT NOTES COMPUT SC, V1842, P554; Peng Xingchao, 2017, VISDA VISUAL DOMAIN; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Pinheiro PO, 2018, PROC CVPR IEEE, P8004, DOI 10.1109/CVPR.2018.00835; Ren CX, 2020, IEEE T INF FOREN SEC, V15, P1290, DOI 10.1109/TIFS.2019.2939750; Ren CX, 2021, IEEE T CYBERNETICS, V51, P2166, DOI 10.1109/TCYB.2019.2957033; Ren CX, 2020, IEEE T IMAGE PROCESS, V29, P2875, DOI 10.1109/TIP.2019.2954176; Ren CX, 2021, IEEE T CYBERNETICS, V51, P2006, DOI 10.1109/TCYB.2019.2916198; Ren CX, 2020, IEEE T CYBERNETICS, V50, P821, DOI 10.1109/TCYB.2018.2874219; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392; Sankaranarayanan S, 2018, PROC CVPR IEEE, P8503, DOI 10.1109/CVPR.2018.00887; Shao L, 2015, IEEE T NEUR NET LEAR, V26, P1019, DOI 10.1109/TNNLS.2014.2330900; Shekhar S, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2431440; Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572; Xu RJ, 2019, IEEE I CONF COMP VIS, P1426, DOI 10.1109/ICCV.2019.00151; Yosinski J, 2014, ADV NEUR IN, V27; Zhang J, 2018, PROC CVPR IEEE, P8156, DOI 10.1109/CVPR.2018.00851; ZWALD L, 2006, ADV NEURAL INFORM PR, V18, P1649	54	15	15	19	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2022	44	3					1653	1669		10.1109/TPAMI.2020.3014218	http://dx.doi.org/10.1109/TPAMI.2020.3014218			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YU4MA	32749963	Green Submitted			2022-12-18	WOS:000752018000041
J	Wang, Z; Li, ZQ; Wang, R; Nie, FP; Li, XL				Wang, Zhen; Li, Zhaoqing; Wang, Rong; Nie, Feiping; Li, Xuelong			Large Graph Clustering With Simultaneous Spectral Embedding and Discretization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Clustering methods; Clustering algorithms; Optimization; Complexity theory; Acceleration; Optical imaging; Laplace equations; Large graph clustering; spectral embedding; spectral rotation; label propagation	K-MEANS ALGORITHM	Spectral clustering methods are gaining more and more interests and successfully applied in many fields because of their superior performance. However, there still exist two main problems to be solved: 1) spectral clustering methods consist of two successive optimization stages-spectral embedding and spectral rotation, which may not lead to globally optimal solutions, 2) and it is known that spectral methods are time-consuming with very high computational complexity. There are methods proposed to reduce the complexity for data vectors but not for graphs that only have information about similarity matrices. In this paper, we propose a new method to solve these two challenging problems for graph clustering. In the new method, a new framework is established to perform spectral embedding and spectral rotation simultaneously. The newly designed objective function consists of both terms of embedding and rotation, and we use an improved spectral rotation method to make it mathematically rigorous for the optimization. To further accelerate the algorithm, we derive a low-dimensional representation matrix from a graph by using label propagation, with which, in return, we can reconstruct a double-stochastic and positive semidefinite similarity matrix. Experimental results demonstrate that our method has excellent performance in time cost and accuracy.	[Wang, Zhen] Northwestern Polytech Univ, Sch Mech Engn, Xian 710072, Shaanxi, Peoples R China; [Wang, Zhen; Li, Zhaoqing; Wang, Rong; Nie, Feiping; Li, Xuelong] Northwestern Polytech Univ, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China; [Li, Zhaoqing] Northwestern Polytech Univ, Sch Automat, Xian 710072, Shaanxi, Peoples R China; [Wang, Rong; Nie, Feiping; Li, Xuelong] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China	Northwestern Polytechnical University; Northwestern Polytechnical University; Northwestern Polytechnical University; Northwestern Polytechnical University	Nie, FP; Li, XL (corresponding author), Northwestern Polytech Univ, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China.; Nie, FP; Li, XL (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.	zhenwang0@gmail.com; zhaoqingli@mail.nwpu.edu.cn; wangrong07@tsinghua.org.cn; feipingnie@gmail.com; xuelong_li@nwpu.edu.cn	Li, Zhaoqing/HGA-2068-2022	Nie, Feiping/0000-0002-0871-6519; Li, Zhaoqing/0000-0001-8649-4934; Wang, Rong/0000-0001-9240-6726	Key Area R&D Program of Guangdong Province [2019B010137004]; National Natural Science Foundation of China [U1803263, 11931015, 81961138010]; Fundamental Research Funds for the Central Universities [3102019PJ006]; Key Area R&D Program of Shaanxi Province [2019ZDLGY17-07]	Key Area R&D Program of Guangdong Province; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Key Area R&D Program of Shaanxi Province	This work was supported in part by Key Area R&D Program of Guangdong Province (No. 2019B010137004), National Natural Science Foundation of China (Grant No. U1803263, 11931015, 81961138010), the Fundamental Research Funds for the Central Universities (No. 3102019PJ006), and Key Area R&D Program of Shaanxi Province (No. 2019ZDLGY17-07). ZhenWang and Zhaoqing Li contributed equally to thiswork.	Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49; Ben-Hur A, 2002, J MACH LEARN RES, V2, P125, DOI 10.1162/15324430260185565; Cai D, 2005, IEEE T KNOWL DATA EN, V17, P1624, DOI 10.1109/TKDE.2005.198; Cai D, 2015, IEEE T CYBERNETICS, V45, P1669, DOI 10.1109/TCYB.2014.2358564; CHAN PK, 1994, IEEE T COMPUT AID D, V13, P1088, DOI 10.1109/43.310898; Chen X., 2017, IJCAI, P1518; Chen XJ, 2013, IEEE T KNOWL DATA EN, V25, P932, DOI 10.1109/TKDE.2011.262; Chen XJ, 2012, PATTERN RECOGN, V45, P434, DOI 10.1016/j.patcog.2011.06.004; Ding CHQ, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P107, DOI 10.1109/ICDM.2001.989507; Ester M., 1996, P 2 INT C KNOWL DISC, P226; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; Frank A., 2010, UCI MACHINE LEARNING; Ghahramani Z, 2002, LEARNING LABELED UNL, P8, DOI DOI 10.21236/ADA565197; Girolami M, 2002, IEEE T NEURAL NETWOR, V13, P780, DOI 10.1109/TNN.2002.1000150; HAGEN L, 1992, IEEE T COMPUT AID D, V11, P1074, DOI 10.1109/43.159993; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Hong W, 2006, IEEE T IMAGE PROCESS, V15, P3655, DOI 10.1109/TIP.2006.882016; HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Jing L, 2007, IEEE T KNOWL DATA EN, V19, P1026, DOI 10.1109/TKDE.2007.1048; JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588; Kanatani K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P586, DOI 10.1109/ICCV.2001.937679; Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616; Kriegel HP, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1497577.1497578; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li ZT, 2018, IEEE T IMAGE PROCESS, V27, P4478, DOI 10.1109/TIP.2018.2839916; Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491, DOI 10.1109/TKDE.2005.66; Liu W., 2010, P 27 INT C MACH LEAR, P679; Mehrkanoon S, 2015, IEEE T NEUR NET LEAR, V26, P720, DOI 10.1109/TNNLS.2014.2322377; Ng AY, 2002, ADV NEUR IN, V14, P849; Nie FP, 2017, ADV NEUR IN, V30; Nie FP, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-016-9021-9; Nie FP, 2010, LECT NOTES ARTIF INT, V6322, P451; Panda R, 2018, IEEE T CYBERNETICS, V48, P836, DOI 10.1109/TCYB.2017.2657692; Pang YW, 2014, IEEE T NEUR NET LEAR, V25, P2191, DOI 10.1109/TNNLS.2014.2306844; Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shinnou H, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P201; Su MS, 2001, IEEE T PATTERN ANAL, V23, P674, DOI 10.1109/34.927466; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wang X., 2010, P 16 ACM SIGKDD INT, P563, DOI DOI 10.1145/1835804.1835877; WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673; Xiao Cai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1977, DOI 10.1109/CVPR.2011.5995740; Xu W., 2003, P 26 ANN INT ACM SIG, P267, DOI DOI 10.1145/860435.860485; Yang Y., 2011, P 22 INT JOINT C ART, P1589, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-267; Yang Y, 2015, IEEE T CYBERNETICS, V45, P1069, DOI 10.1109/TCYB.2014.2344015; Yu SX, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P313, DOI 10.1109/iccv.2003.1238361; Zhang HX, 2009, KNOWL-BASED SYST, V22, P477, DOI 10.1016/j.knosys.2009.06.009; Zhang XR, 2008, IEEE T GEOSCI REMOTE, V46, P2126, DOI 10.1109/TGRS.2008.918647; Zhong S, 2005, IEEE IJCNN, P3180	50	15	15	5	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2021	43	12					4426	4440		10.1109/TPAMI.2020.3002587	http://dx.doi.org/10.1109/TPAMI.2020.3002587			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR0MQ	32750787				2022-12-18	WOS:000714203900020
J	Chen, R; Han, SF; Xu, J; Su, H				Chen, Rui; Han, Songfang; Xu, Jing; Su, Hao			Visibility-Aware Point-Based Multi-View Stereo Network	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Image reconstruction; Geometry; Two dimensional displays; Task analysis; Aggregates; Surface reconstruction; Multi-view stereo; 3D deep learning	GRAPH-CUTS	We introduce VA-Point-MVSNet, a novel visibility-aware point-based deep framework for multi-view stereo (MVS). Distinct from existing cost volume approaches, our method directly processes the target scene as point clouds. More specifically, our method predicts the depth in a coarse-to-fine manner. We first generate a coarse depth map, convert it into a point cloud and refine the point cloud iteratively by estimating the residual between the depth of the current iteration and that of the ground truth. Our network leverages 3D geometry priors and 2D texture information jointly and effectively by fusing them into a feature-augmented point cloud, and processes the point cloud to estimate the 3D flow for each point. This point-based architecture allows higher accuracy, more computational efficiency and more flexibility than cost-volume-based counterparts. Furthermore, our visibility-aware multi-view feature aggregation allows the network to aggregate multi-view appearance cues while taking into account visibility. Experimental results show that our approach achieves a significant improvement in reconstruction quality compared with state-of-the-art methods on the DTU and the Tanks and Temples dataset. The code of VA-Point-MVSNet proposed in this work will be released at https://github.com/callmeray/PointMVSNet.	[Chen, Rui; Xu, Jing] Tsinghua Univ, State Key Lab Tribol, Beijing Key Lab Precis Ultraprecis Mfg Equipment, Dept Mech Engn, Beijing 100084, Peoples R China; [Han, Songfang] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China; [Su, Hao] Univ Calif San Diego, Dept Comp Sci & Engn, San Diego, CA 92093 USA	Tsinghua University; Hong Kong University of Science & Technology; University of California System; University of California San Diego	Xu, J (corresponding author), Tsinghua Univ, State Key Lab Tribol, Beijing Key Lab Precis Ultraprecis Mfg Equipment, Dept Mech Engn, Beijing 100084, Peoples R China.	callmeray@163.com; hansongfang@gmail.com; jingxu@tsinghua.edu.cn; haosu@eng.ucsd.edu		Chen, Rui/0000-0002-4041-4131; Han, Songfang/0000-0002-6432-8764	National Key Research and Development Program of China [2016YFE0206200]; National Natural Science Foundation of China (NSFC) [U1613205, 51675291]; NSF [IIS-1764078]; DMAI	National Key Research and Development Program of China; National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); NSF(National Science Foundation (NSF)); DMAI	This work was supported in part by the National Key Research and Development Program of China under Grant 2016YFE0206200, and in part by the National Natural Science Foundation of China (NSFC) under Grant U1613205 and Grant 51675291, NSF Grant IIS-1764078, gifts from Qualcomm, Adobe and support from DMAI.	Aanaes H, 2016, INT J COMPUT VISION, V120, P153, DOI 10.1007/s11263-016-0902-9; Agarwal S, 2011, COMMUN ACM, V54, P105, DOI 10.1145/2001269.2001293; Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14; Calli B, 2015, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P510, DOI 10.1109/ICAR.2015.7251504; Campbell NDF, 2008, LECT NOTES COMPUT SC, V5302, P766, DOI 10.1007/978-3-540-88682-2_58; Chen R, 2019, IEEE I CONF COMP VIS, P1538, DOI 10.1109/ICCV.2019.00162; Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693; Donne S, 2019, PROC CVPR IEEE, P7626, DOI 10.1109/CVPR.2019.00782; Dyer CR, 2001, SPRING INT SER ENG C, V628, P469; Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016; Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Galliani S, 2015, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2015.106; Gu X., 2019, ARXIV191206378; Hane C, 2011, IEEE INT C INT ROBOT, P1618, DOI 10.1109/IROS.2011.6048261; Han XF, 2015, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2015.7298948; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Heise P, 2013, IEEE I CONF COMP VIS, P2360, DOI 10.1109/ICCV.2013.293; Hinton G., 2012, LECT NOTES; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; Hornung A., 2006, COMP VIS PATT REC 20, V1, P503, DOI 10.1109/CVPR.2006.135; Hornung A, 2006, LECT NOTES COMPUT SC, V3952, P179; Huang PH, 2018, PROC CVPR IEEE, P2821, DOI 10.1109/CVPR.2018.00298; Im S., 2019, P INT C LEARN REPR M, P1; Ji MQ, 2017, IEEE I CONF COMP VIS, P2326, DOI 10.1109/ICCV.2017.253; Kar A., 2017, ADV NEURAL INFORM PR; Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17; Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599; Knobelreiter P, 2017, PROC CVPR IEEE, P1456, DOI 10.1109/CVPR.2017.159; Lhuillier M, 2005, IEEE T PATTERN ANAL, V27, P418, DOI 10.1109/TPAMI.2005.44; Liu YB, 2010, IEEE T VIS COMPUT GR, V16, P407, DOI 10.1109/TVCG.2009.88; Luo KY, 2019, IEEE I CONF COMP VIS, P10451, DOI 10.1109/ICCV.2019.01055; Owens A, 2013, IEEE I CONF COMP VIS, P33, DOI 10.1109/ICCV.2013.461; Pang JH, 2017, IEEE INT CONF COMP V, P878, DOI 10.1109/ICCVW.2017.108; Qi CR, 2017, ADV NEUR IN, V30; Romanoni A, 2019, IEEE I CONF COMP VIS, P10412, DOI 10.1109/ICCV.2019.01051; Rothermel M., 2012, P LC3D WORKSH BERL G; Schonberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31; Seki A, 2017, PROC CVPR IEEE, P6640, DOI 10.1109/CVPR.2017.703; Sinha SN, 2007, IEEE I CONF COMP VIS, P1318; Tang Chengzhou, 2019, P ICLR; Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230; Todorov E, 2012, IEEE INT C INT ROBOT, P5026, DOI 10.1109/IROS.2012.6386109; Tola E, 2012, MACH VISION APPL, V23, P903, DOI 10.1007/s00138-011-0346-8; Vogiatzis G, 2007, IEEE T PATTERN ANAL, V29, P2241, DOI 10.1109/TPAMI.2007.70712; Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362; Xu QS, 2019, PROC CVPR IEEE, P5478, DOI 10.1109/CVPR.2019.00563; Xue YZ, 2019, IEEE I CONF COMP VIS, P4311, DOI 10.1109/ICCV.2019.00441; Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3_47; Yao Y, 2019, PROC CVPR IEEE, P5520, DOI 10.1109/CVPR.2019.00567; Yu LQ, 2018, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2018.00295; Zaharescu A, 2007, LECT NOTES COMPUT SC, V4844, P166; Zhou HZ, 2018, LECT NOTES COMPUT SC, V11220, P851, DOI 10.1007/978-3-030-01270-0_50	53	15	16	11	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2021	43	10					3695	3708		10.1109/TPAMI.2020.2988729	http://dx.doi.org/10.1109/TPAMI.2020.2988729			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UK8RG	32324542	hybrid			2022-12-18	WOS:000692232400031
J	Chen, YC; Lin, YY; Yang, MH; Huang, JB				Chen, Yun-Chun; Lin, Yen-Yu; Yang, Ming-Hsuan; Huang, Jia-Bin			Show, Match and Segment: Joint Weakly Supervised Learning of Semantic Matching and Object Co-Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Task analysis; Image segmentation; Training; Clutter; Proposals; Pattern matching; Semantic matching; object co-segmentation; weakly-supervised learning	GRAPH; FLOW	We present an approach for jointly matching and segmenting object instances of the same category within a collection of images. In contrast to existing algorithms that tackle the tasks of semantic matching and object co-segmentation in isolation, our method exploits the complementary nature of the two tasks. The key insights of our method are two-fold. First, the estimated dense correspondence fields from semantic matching provide supervision for object co-segmentation by enforcing consistency between the predicted masks from a pair of images. Second, the predicted object masks from object co-segmentation in turn allow us to reduce the adverse effects due to background clutters for improving semantic matching. Our model is end-to-end trainable and does not require supervision from manually annotated correspondences and object masks. We validate the efficacy of our approach on five benchmark datasets: TSS, Internet, PF-PASCAL, PF-WILLOW, and SPair-71k, and show that our algorithm performs favorably against the state-of-the-art methods on both semantic matching and object co-segmentation tasks.	[Chen, Yun-Chun] Acad Sinica, Res Ctr Informat Technol Innovat, Taipei 115, Taiwan; [Lin, Yen-Yu] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan; [Yang, Ming-Hsuan] Univ Calif Merced, Sch Engn, Merced, CA 95343 USA; [Huang, Jia-Bin] Virginia Tech, Dept Elect & Comp Engn, Blacksburg, VA 24061 USA	Academia Sinica - Taiwan; National Yang Ming Chiao Tung University; University of California System; University of California Merced; Virginia Polytechnic Institute & State University	Huang, JB (corresponding author), Virginia Tech, Dept Elect & Comp Engn, Blacksburg, VA 24061 USA.	ycchen918@gmail.com; lin@cs.nctu.edu.tw; mhyang@ucmerced.edu; jbhuang@vt.edu	Yang, Ming-Hsuan/T-9533-2019	Yang, Ming-Hsuan/0000-0003-4848-2304; Lin, Yen-Yu/0000-0002-7183-6070				Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2017, P BMVC; Batra D, 2011, INT J COMPUT VISION, V93, P273, DOI 10.1007/s11263-010-0415-x; Chang HS, 2015, COMPUT VIS IMAGE UND, V141, P18, DOI 10.1016/j.cviu.2015.06.004; Chen H., 2018, ACCV, P435; Chen L, 2014, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2014.135; Chen Y, 2018, LECT NOTES COMPUT SC, V11256, P347, DOI 10.1007/978-3-030-03398-9_30; Chen YC, 2019, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2019.00189; Choy CB, 2016, ADV NEUR IN, V29; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dale K, 2009, IEEE I CONF COMP VIS, P2217, DOI 10.1109/ICCV.2009.5459473; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Duchenne O, 2011, IEEE I CONF COMP VIS, P1792, DOI 10.1109/ICCV.2011.6126445; Dwibedi D, 2019, PROC CVPR IEEE, P1801, DOI 10.1109/CVPR.2019.00190; Faktor A, 2013, IEEE I CONF COMP VIS, P1297, DOI 10.1109/ICCV.2013.164; Gaur U, 2017, IEEE I CONF COMP VIS, P1744, DOI 10.1109/ICCV.2017.192; Ham B, 2018, IEEE T PATTERN ANAL, V40, P1711, DOI 10.1109/TPAMI.2017.2724510; Ham B, 2016, PROC CVPR IEEE, P3475, DOI 10.1109/CVPR.2016.378; Han K, 2017, IEEE I CONF COMP VIS, P1849, DOI 10.1109/ICCV.2017.203; Han XF, 2015, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2015.7298948; Hati A, 2016, LECT NOTES COMPUT SC, V9910, P736, DOI 10.1007/978-3-319-46466-4_44; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hsu KJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P748; Hsu KJ, 2019, PROC CVPR IEEE, P8838, DOI 10.1109/CVPR.2019.00905; Hsu KJ, 2018, LECT NOTES COMPUT SC, V11209, P502, DOI 10.1007/978-3-030-01228-1_30; Hsu KJ, 2015, PROC CVPR IEEE, P1921, DOI 10.1109/CVPR.2015.7298802; Hu YT, 2018, LECT NOTES COMPUT SC, V11212, P56, DOI 10.1007/978-3-030-01237-3_4; Hu YT, 2016, PROC CVPR IEEE, P346, DOI 10.1109/CVPR.2016.44; Hu YT, 2015, IEEE T IMAGE PROCESS, V24, P5995, DOI 10.1109/TIP.2015.2496305; Huang PH, 2018, PROC CVPR IEEE, P2821, DOI 10.1109/CVPR.2018.00298; Huang XG, 2018, 2018 INTERNATIONAL SYMPOSIUM IN SENSING AND INSTRUMENTATION IN IOT ERA (ISSI); Jeon S., 2018, P EUR C COMP VIS, P351; Jerripothula KR, 2017, PROC CVPR IEEE, P3881, DOI 10.1109/CVPR.2017.413; Jerripothula KR, 2016, IEEE T MULTIMEDIA, V18, P1896, DOI 10.1109/TMM.2016.2576283; Joulin A, 2012, PROC CVPR IEEE, P542, DOI 10.1109/CVPR.2012.6247719; Joulin A, 2010, PROC CVPR IEEE, P1943, DOI 10.1109/CVPR.2010.5539868; Kanazawa A, 2016, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2016.354; Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17; Kim G, 2011, IEEE I CONF COMP VIS, P169, DOI 10.1109/ICCV.2011.6126239; Kim J, 2013, PROC CVPR IEEE, P2307, DOI 10.1109/CVPR.2013.299; Kim S, 2020, IEEE T PATTERN ANAL, V42, P59, DOI 10.1109/TPAMI.2018.2878240; Kim S, 2019, IEEE T PATTERN ANAL, V41, P581, DOI 10.1109/TPAMI.2018.2803169; Kim S, 2017, IEEE I CONF COMP VIS, P4539, DOI 10.1109/ICCV.2017.485; Kim S, 2017, PROC CVPR IEEE, P616, DOI 10.1109/CVPR.2017.73; Kim S, 2015, PROC CVPR IEEE, P2103, DOI 10.1109/CVPR.2015.7298822; Kingma D.P, P 3 INT C LEARNING R; Krahenbuhl P., 2011, ADV NEURAL INF PROCE, V24, P109; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Laskar Z., 2018, P EUROPEAN C COMPUTE, P444; Lee C, 2015, PROC CVPR IEEE, P3837, DOI 10.1109/CVPR.2015.7299008; Lee HY, 2020, INT J COMPUT VISION, V128, P2402, DOI 10.1007/s11263-019-01284-z; Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3; Li Weihao, 2018, P AS C COMP VIS, P3; Lin S., 2018, P 32 C NEUR INF PROC, P1; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Liu Yu-Lun, 2019, P 33 C ART INT AAAI, P2; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Meisel SF, 2018, PSYCHOL MED, V48, P2299, DOI 10.1017/S0033291718000491; Min J., 2019, ARXIV190810543; Min J, 2019, IEEE I CONF COMP VIS, P3394, DOI 10.1109/ICCV.2019.00349; Mustafa A, 2017, PROC CVPR IEEE, P5583, DOI 10.1109/CVPR.2017.592; Novotny D, 2018, PROC CVPR IEEE, P3637, DOI 10.1109/CVPR.2018.00383; Novotny D, 2017, PROC CVPR IEEE, P2867, DOI 10.1109/CVPR.2017.306; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Quan R, 2016, PROC CVPR IEEE, P687, DOI 10.1109/CVPR.2016.81; Rafi U., 2018, P BMVC, P1; Rocco I, 2018, ADV NEUR IN, V31; Rocco I, 2018, PROC CVPR IEEE, P6917, DOI 10.1109/CVPR.2018.00723; Rocco I, 2017, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2017.12; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Rother C., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91; Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253; Seo PH, 2018, LECT NOTES COMPUT SC, V11208, P367, DOI 10.1007/978-3-030-01225-0_22; Shah M, 2019, PROC CVPR IEEE, P6642, DOI 10.1109/CVPR.2019.00681; Shechtman E, 2007, PROC CVPR IEEE, P1744; Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1; Sun J, 2016, INT J COMPUT VISION, V120, P111, DOI 10.1007/s11263-016-0899-0; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Taniai T, 2016, PROC CVPR IEEE, P4246, DOI 10.1109/CVPR.2016.460; Tao ZQ, 2017, AAAI CONF ARTIF INTE, P4285; Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77; Tulsiani S, 2018, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR.2018.00306; Ufer N, 2017, PROC CVPR IEEE, P5929, DOI 10.1109/CVPR.2017.628; Voigtlaender P, 2019, PROC CVPR IEEE, P9473, DOI 10.1109/CVPR.2019.00971; Wang C, 2017, IEEE T IMAGE PROCESS, V26, P5825, DOI 10.1109/TIP.2017.2750410; Wang XG, 2019, PROC CVPR IEEE, P8868, DOI [10.1109/CVPR.2019.00908, 10.1109/CVPR.2019.00267]; Wong A, 2019, PROC CVPR IEEE, P5627, DOI 10.1109/CVPR.2019.00579; Yang F, 2017, PROC CVPR IEEE, P4151, DOI 10.1109/CVPR.2017.442; Yang HS, 2014, PROC CVPR IEEE, P3406, DOI 10.1109/CVPR.2014.435; Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261; Yuan ZH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3371; Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700; Zhou TH, 2016, PROC CVPR IEEE, P117, DOI 10.1109/CVPR.2016.20; Zhou TH, 2015, PROC CVPR IEEE, P1191, DOI 10.1109/CVPR.2015.7298723; Zhou W., 2017, RECENT ADV CONTENT B; Zhou XW, 2015, IEEE I CONF COMP VIS, P4032, DOI 10.1109/ICCV.2015.459; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zou YL, 2018, LECT NOTES COMPUT SC, V11209, P38, DOI 10.1007/978-3-030-01228-1_3	98	15	15	7	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2021	43	10					3632	3647		10.1109/TPAMI.2020.2985395	http://dx.doi.org/10.1109/TPAMI.2020.2985395			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UK8RG		Green Submitted			2022-12-18	WOS:000692232400027
J	Gao, HY; Wang, ZY; Cai, L; Ji, SW				Gao, Hongyang; Wang, Zhengyang; Cai, Lei; Ji, Shuiwang			ChannelNets: Compact and Efficient Convolutional Neural Networks via Channel-Wise Convolutions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convolutional codes; Image coding; Computational modeling; Kernel; Computational efficiency; Mobile handsets; Computer architecture; Deep learning; group convolution; channel-wise convolution; convolutional classification; model compression		Convolutional neural networks (CNNs) have shown great capability of solving various artificial intelligence tasks. However, the increasing model size has raised challenges in employing them in resource-limited applications. In this work, we propose to compress deep models by using channel-wise convolutions, which replace dense connections among feature maps with sparse ones in CNNs. Based on this novel operation, we build light-weight CNNs known as ChannelNets. ChannelNets use three instances of channel-wise convolutions; namely group channel-wise convolutions, depth-wise separable channel-wise convolutions, and the convolutional classification layer. Compared to prior CNNs designed for mobile devices, ChannelNets achieve a significant reduction in terms of the number of parameters and computational cost without loss in accuracy. Notably, our work represents an attempt to compress the fully-connected classification layer, which usually accounts for about 25 percent of total parameters in compact CNNs. Along this new direction, we investigate the behavior of our proposed convolutional classification layer and conduct detailed analysis. Based on our in-depth analysis, we further propose convolutional classification layers without weight-sharing. This new classification layer achieves a good trade-off between fully-connected classification layers and the convolutional classification layer. Experimental results on the ImageNet dataset demonstrate that ChannelNets achieve consistently better performance compared to prior methods.	[Gao, Hongyang; Wang, Zhengyang; Ji, Shuiwang] Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA; [Cai, Lei] Washington State Univ, Sch Elect Engn & Comp Sci, Pullman, WA 99164 USA	Texas A&M University System; Texas A&M University College Station; Washington State University	Ji, SW (corresponding author), Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA.	hongyang.gao@tamu.edu; zhengyang.wang@tamu.edu; lei.cai@wsu.edu; sji@tamu.edu			National Science Foundation [IIS-1633359, DBI-1641223]	National Science Foundation(National Science Foundation (NSF))	This work was supported in part by National Science Foundation grants IIS-1633359 and DBI-1641223.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Bar-Joseph Z, 2001, Bioinformatics, V17 Suppl 1, pS22; Chang J, 2017, IEICE ELECTRON EXPR, V14, DOI 10.1587/elex.13.20161134; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen Shi, 2019, IEEE Trans Pattern Anal Mach Intell, V41, P3048, DOI 10.1109/TPAMI.2018.2874634; Chen WL, 2015, PR MACH LEARN RES, V37, P2285; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Gao H., 2018, ADV NEURAL INFORM PR, P5203; Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Howard A.G, 2017, ARXIV170404861; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Iandola F.N., 2016, ARXIV PREPRINT ARXIV; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jaderberg M., 2014, SYNTHETIC DATA ARTIF, P1; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Kim H, 2017, DES AUT CON, DOI 10.1145/3061639.3062189; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32; Laurent S, 2014, THESIS ECOLE POLYTEC; Lebedev V., 2015, 3 INT C LEARNING REP; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8; Liong VE, 2020, IEEE T PATTERN ANAL, V42, P580, DOI 10.1109/TPAMI.2018.2882816; Luong A, 2016, P 20 SIGNLL C COMP N, P291, DOI DOI 10.18653/V1/K16-1029; Peng B., 2018, P EUR C COMP VIS, P300; Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tan MX, 2019, PROC CVPR IEEE, P2815, DOI 10.1109/CVPR.2019.00293; Wei Y, 2018, LECT NOTES COMPUT SC, V11212, P274, DOI 10.1007/978-3-030-01237-3_17; Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Zhang T, 2017, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2017.469; Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716; Zhao R., 2019, P IEEE C COMP VIS PA, p11 303	47	15	15	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG 1	2021	43	8					2570	2581		10.1109/TPAMI.2020.2975796	http://dx.doi.org/10.1109/TPAMI.2020.2975796			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TF2YV	32091991	hybrid, Green Submitted			2022-12-18	WOS:000670578800004
J	Valle, R; Buenaposada, JM; Baumela, L				Valle, Roberto; Buenaposada, Jose M.; Baumela, Luis			Multi-Task Head Pose Estimation in-the-Wild	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Face recognition; Pose estimation; Magnetic heads; Training; Faces; Decoding; Head pose estimation; multi-task learning; face alignment; occlusions detection	FACE ALIGNMENT	We present a deep learning-based multi-task approach for head pose estimation in images. We contribute with a network architecture and training strategy that harness the strong dependencies among face pose, alignment and visibility, to produce a top performing model for all three tasks. Our architecture is an encoder-decoder CNN with residual blocks and lateral skip connections. We show that the combination of head pose estimation and landmark-based face alignment significantly improve the performance of the former task. Further, the location of the pose task at the bottleneck layer, at the end of the encoder, and that of tasks depending on spatial information, such as visibility and alignment, in the final decoder layer, also contribute to increase the final performance. In the experiments conducted the proposed model outperforms the state-of-the-art in the face pose and visibility tasks. By including a final landmark regression step it also produces face alignment results on par with the state-of-the-art.	[Valle, Roberto; Baumela, Luis] Univ Politecn Madrid, Dept Inteligencia Artificial, Campus Montegancedo S-N, Boadilla Del Monte 28660, Spain; [Buenaposada, Jose M.] Univ Rey Juan Carlos, ETSII, C Tulipan S-N, Mostoles 28933, Spain	Universidad Politecnica de Madrid; Universidad Rey Juan Carlos	Buenaposada, JM (corresponding author), Univ Rey Juan Carlos, ETSII, C Tulipan S-N, Mostoles 28933, Spain.	rvalle@fi.upm.es; josemiguel.buenaposada@urjc.es; lbaumela@fi.upm.es	Buenaposada, Jose Miguel/L-6458-2014; Valle Fernández, Roberto/GZL-6706-2022	Buenaposada, Jose Miguel/0000-0002-4308-9653; Valle Fernández, Roberto/0000-0003-1423-1478; BAUMELA MOLINA, LUIS/0000-0001-6910-4359	Spanish Ministry of Economy and Competitiveness [TIN2016-75982-C2-2-R]; Comunidad de Madrid project RoboCity2030-DIH-CM [S2018/NMT-4331]	Spanish Ministry of Economy and Competitiveness(Spanish Government); Comunidad de Madrid project RoboCity2030-DIH-CM(Comunidad de Madrid)	This work was supported by the Spanish Ministry of Economy and Competitiveness, project TIN2016-75982-C2-2-R. Jose M. Buenaposada was also partially funded by the Comunidad de Madrid project RoboCity2030-DIH-CM (S2018/NMT-4331). The authors would like to thank the anonymous reviewers for their comments and Felix Kuhnke for his help in interpreting Biwi annotations.	Amador E., 2017, P IB C PATT REC, P45; Ba SO, 2011, IEEE T PATTERN ANAL, V33, P101, DOI 10.1109/TPAMI.2010.69; Bergasa LM, 2008, PROCEEDINGS OF THE 11TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, P1149, DOI 10.1109/ITSC.2008.4732544; Bhagavatula C, 2017, IEEE I CONF COMP VIS, P4000, DOI 10.1109/ICCV.2017.429; Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116; Bulat A, 2017, IEEE I CONF COMP VIS, P3726, DOI 10.1109/ICCV.2017.400; Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191; Cao JJ, 2018, PROC CVPR IEEE, P4290, DOI 10.1109/CVPR.2018.00451; Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chang FJ, 2017, IEEE INT CONF COMP V, P1599, DOI 10.1109/ICCVW.2017.188; Chang FJ, 2019, INT J COMPUT VISION, V127, P930, DOI 10.1007/s11263-019-01151-x; Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976; DEMENTHON DF, 1995, INT J COMPUT VISION, V15, P123, DOI 10.1007/BF01450852; Deng JK, 2018, IEEE INT CONF AUTOMA, P399, DOI 10.1109/FG.2018.00064; Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0; Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P557, DOI 10.1007/978-3-030-01264-9_33; Feng ZH, 2018, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2018.00238; Han H, 2018, IEEE T PATTERN ANAL, V40, P2597, DOI 10.1109/TPAMI.2017.2738004; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Honari S, 2016, PROC CVPR IEEE, P5743, DOI 10.1109/CVPR.2016.619; Hsu HW, 2019, IEEE T MULTIMEDIA, V21, P1035, DOI 10.1109/TMM.2018.2866770; Jeon S, 2019, IEEE I CONF COMP VIS, P7293, DOI 10.1109/ICCV.2019.00739; Jin S., 2015, AUTOMATIC DETECTION; Koepke A. Sophia, 2018, P BRIT MACH VIS C, P302; Kostinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS); Kokkinos I, 2017, PROC CVPR IEEE, P5454, DOI 10.1109/CVPR.2017.579; Kuhnke F, 2019, IEEE I CONF COMP VIS, P10163, DOI 10.1109/ICCV.2019.01026; Kumar A, 2018, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2018.00052; Kumar A, 2018, IMAGE VISION COMPUT, V79, P49, DOI 10.1016/j.imavis.2018.09.009; Liu ZX, 2019, IEEE INT CONF COMP V, P1232, DOI 10.1109/ICCVW.2019.00156; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233; Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Ruiz N, 2018, IEEE COMPUT SOC CONF, P2155, DOI 10.1109/CVPRW.2018.00281; Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002; Shen J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1003, DOI 10.1109/ICCVW.2015.132; Standley T., 2019, P 37 INT C MACH LEAR; Thewlis J, 2019, IEEE I CONF COMP VIS, P6370, DOI 10.1109/ICCV.2019.00646; Tran AT, 2019, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2019.00148; Valle R, 2018, LECT NOTES COMPUT SC, V11218, P609, DOI 10.1007/978-3-030-01264-9_36; Valle R, 2020, PATTERN RECOGN LETT, V136, P326, DOI 10.1016/j.patrec.2019.10.012; Valle R, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102846; Wang ZR, 2019, PROC CVPR IEEE, P11285, DOI 10.1109/CVPR.2019.01155; Wu WY, 2018, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2018.00227; Wu Y, 2019, INT J COMPUT VISION, V127, P115, DOI 10.1007/s11263-018-1097-z; Wu Y, 2017, PROC CVPR IEEE, P5719, DOI 10.1109/CVPR.2017.606; Wu Y, 2015, IEEE I CONF COMP VIS, P3658, DOI 10.1109/ICCV.2015.417; Yang H., 2015, P BRIT MACH VIS C; Yang J, 2017, IEEE COMPUT SOC CONF, P2025, DOI 10.1109/CVPRW.2017.253; Yang TY, 2019, PROC CVPR IEEE, P1087, DOI 10.1109/CVPR.2019.00118; Zamir AR, 2018, PROC CVPR IEEE, P3712, DOI 10.1109/CVPR.2018.00391; Zhang H., 2020, P 34 AAAI C ART INT, p12 789; Zhang HW, 2018, IEEE T INF FOREN SEC, V13, P2409, DOI 10.1109/TIFS.2018.2800901; Zhang W, 2018, LECT NOTES COMPUT SC, V10996, P148, DOI 10.1007/978-3-319-97909-0_16; Zhang YT, 2018, PROC CVPR IEEE, P2694, DOI 10.1109/CVPR.2018.00285; Zhang ZP, 2016, IEEE T PATTERN ANAL, V38, P918, DOI 10.1109/TPAMI.2015.2469286; Zhong Y, 2016, INT C PATT RECOG, P2264, DOI 10.1109/ICPR.2016.7899973; Zhou YQ, 2017, IEEE INT CONF AUTOMA, P872, DOI 10.1109/FG.2017.112; Zhu ML, 2019, PROC CVPR IEEE, P3481, DOI 10.1109/CVPR.2019.00360; Zhu XY, 2019, IEEE T PATTERN ANAL, V41, P78, DOI 10.1109/TPAMI.2017.2778152	64	15	15	7	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG 1	2021	43	8					2874	2881		10.1109/TPAMI.2020.3046323	http://dx.doi.org/10.1109/TPAMI.2020.3046323			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TF2YV	33351746	Green Submitted			2022-12-18	WOS:000670578800027
J	Kurt, MN; Yilmaz, Y; Wang, XD				Kurt, Mehmet Necip; Yilmaz, Yasin; Wang, Xiaodong			Real-Time Nonparametric Anomaly Detection in High-Dimensional Settings	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Anomaly detection; Real-time systems; Data models; Approximation algorithms; Reliability; Probability density function; Entropy; High-dimensional data; summary statistic; geometric entropy minimization (GEM); principal component analysis (PCA); real-time anomaly detection; nonparametric; cumulative sum (CUSUM)	CHANGE-POINT DETECTION; AVERAGE RUN-LENGTH; CYBER-ATTACKS; APPROXIMATIONS	Timely detection of abrupt anomalies is crucial for real-time monitoring and security of modern systems producing high-dimensional data. With this goal, we propose effective and scalable algorithms. Proposed algorithms are nonparametric as both the nominal and anomalous multivariate data distributions are assumed unknown. We extract useful univariate summary statistics and perform anomaly detection in a single-dimensional space. We model anomalies as persistent outliers and propose to detect them via a cumulative sum-like algorithm. In case the observed data have a low intrinsic dimensionality, we find a submanifold in which the nominal data are embedded and evaluate whether the sequentially acquired data persistently deviate from the nominal submanifold. Further, in the general case, we determine an acceptance region for nominal data via Geometric Entropy Minimization and evaluate whether the sequentially observed data persistently fall outside the acceptance region. We provide an asymptotic lower bound and an asymptotic approximation for the average false alarm period of the proposed algorithm. Moreover, we provide a sufficient condition to asymptotically guarantee that the decision statistic of the proposed algorithm does not diverge in the absence of anomalies. Experiments illustrate the effectiveness of the proposed schemes in quick and accurate anomaly detection in high-dimensional settings.	[Kurt, Mehmet Necip; Wang, Xiaodong] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA; [Yilmaz, Yasin] Univ S Florida, Dept Elect Engn, Tampa, FL 33620 USA	Columbia University; State University System of Florida; University of South Florida	Wang, XD (corresponding author), Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.	m.n.kurt@columbia.edu; yasiny@usf.edu; wangx@ee.columbia.edu		Kurt, Mehmet Necip/0000-0001-5827-2533	U.S. National Science Foundation [ECCS-1405327, CNS1737598]; U.S. Office of Naval Research [N000141712827]	U.S. National Science Foundation(National Science Foundation (NSF)); U.S. Office of Naval Research(Office of Naval Research)	This work was supported in part by the U.S. National Science Foundation under Grants ECCS-1405327 and CNS1737598, and in part by the U.S. Office of Naval Research under Grant N000141712827.	Abur A, 2004, POWER SYSTEM STATE E; Bartlett P. L., 2011, ADV NEURAL INFORM PR, P478; Basseville M., DETECTION ABRUPT CHA; Bertino E, 2017, COMPUTER, V50, P76, DOI 10.1109/MC.2017.62; Bishop C.M, 2006, PATTERN RECOGN; Boracchi G, 2018, PR MACH LEARN RES, V80; Cao Y, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20020108; CHAMP CW, 1991, COMMUN STAT SIMULAT, V20, P191, DOI 10.1080/03610919108812948; Chen H, 2019, ANN STAT, V47, P1381, DOI 10.1214/18-AOS1718; Dasu T., 2006, 38 S INTERFACE STAT, P1; Dheeru D., 2019, UCI MACHINE LEARNING; Dunia R., 1997, P AM CONTR C; Faivishevsky L, 2016, INT CONF ACOUST SPEE, P6250, DOI 10.1109/ICASSP.2016.7472879; Georgakopoulos SV, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2219, DOI 10.1109/BigData.2015.7364010; Ghoting A, 2008, DATA MIN KNOWL DISC, V16, P349, DOI 10.1007/s10618-008-0093-2; Hero A.O., 2006, NIPS, V19, P585; Hunt XJ, 2019, IEEE T PATTERN ANAL, V41, P1173, DOI 10.1109/TPAMI.2018.2829189; Jumutc V, 2014, IEEE T PATTERN ANAL, V36, P2510, DOI 10.1109/TPAMI.2014.2327984; KHAN RA, 1978, J STAT PLAN INFER, V2, P63, DOI 10.1016/0378-3758(78)90023-X; Kittler J, 2014, IEEE T PATTERN ANAL, V36, P845, DOI 10.1109/TPAMI.2013.209; Kolias C, 2017, COMPUTER, V50, P80, DOI 10.1109/MC.2017.201; Kurt MN, 2019, IEEE T AERO ELEC SYS, V55, P1498, DOI 10.1109/TAES.2018.2873067; Kurt MN, 2019, IEEE T INF FOREN SEC, V14, P498, DOI 10.1109/TIFS.2018.2854745; Kurt MN, 2018, IEEE T INF FOREN SEC, V13, P2015, DOI 10.1109/TIFS.2018.2800908; Lai TL, 1998, IEEE T INFORM THEORY, V44, P2917, DOI 10.1109/18.737522; Lakhina A, 2004, ACM SIGCOMM COMP COM, V34, P219, DOI 10.1145/1030194.1015492; Laxhammar R, 2014, IEEE T PATTERN ANAL, V36, P1158, DOI 10.1109/TPAMI.2013.172; LORDEN G, 1971, ANN MATH STAT, V42, P1897, DOI 10.1214/aoms/1177693055; Meidan Y, 2018, IEEE PERVAS COMPUT, V17, P12, DOI 10.1109/MPRV.2018.03367731; MOUSTAKIDES GV, 1986, ANN STAT, V14, P1379, DOI 10.1214/aos/1176350164; Murguia Carlos, 2016, 2016 IEEE Conference on Control Applications (CCA), P474, DOI 10.1109/CCA.2016.7587875; Pierre D. J., 2010, SUBSPACE TRACKING SI, P211; Pimentel MAF, 2014, SIGNAL PROCESS, V99, P215, DOI 10.1016/j.sigpro.2013.12.026; Poor HV, 2008, QUICKEST DETECTION, P1; Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882; Ratsch G, 2002, IEEE T PATTERN ANAL, V24, P1184, DOI 10.1109/TPAMI.2002.1033211; Reyes-Ortiz JL, 2016, NEUROCOMPUTING, V171, P754, DOI 10.1016/j.neucom.2015.07.085; REYNOLDS MR, 1975, TECHNOMETRICS, V17, P65, DOI 10.2307/1268002; Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965; Smola, 2007, ADV NEURAL INFORM PR, P513, DOI DOI 10.5555/2188385.2188410; Toledo AL, 2007, IEEE J SEL AREA COMM, V25, P1124, DOI 10.1109/JSAC.2007.070807; Van der Vaart AW, 1998, ASYMPTOTIC STAT, V3; Wang Q, 2006, 2006 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, VOLS 1-6, PROCEEDINGS, P242, DOI 10.1109/ISIT.2006.261842; Wu MR, 2009, IEEE T PATTERN ANAL, V31, P2088, DOI 10.1109/TPAMI.2009.24; Xie Y, 2013, IEEE J-STSP, V7, P12, DOI 10.1109/JSTSP.2012.2234082; Yang QY, 2016, SECUR COMMUN NETW, V9, P833, DOI 10.1002/sec.835; Yilmaz Y, 2017, IEEE INT SYMP INFO; Zhao M., 2009, ADV NEURAL INFORM PR, P2250; Zimmerman RD, 2011, IEEE T POWER SYST, V26, P12, DOI 10.1109/TPWRS.2010.2051168; Zimmermann R, 2018, SIAM J MATRIX ANAL A, V39, P234, DOI 10.1137/17M1123286	50	15	15	4	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2021	43	7					2463	2479		10.1109/TPAMI.2020.2970410	http://dx.doi.org/10.1109/TPAMI.2020.2970410			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL3FK	32011245	Green Submitted			2022-12-18	WOS:000692540900021
J	Mei, J; Cheng, MM; Xu, G; Wan, LR; Zhang, H				Mei, Jie; Cheng, Ming-Ming; Xu, Gang; Wan, Lan-Ruo; Zhang, Huan			SANet: A Slice-Aware Network for Pulmonary Nodule Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Lung; Three-dimensional displays; Computed tomography; Two dimensional displays; Feature extraction; Proposals; Object detection; Pulmonary nodule detection; nodule dataset; slice grouped non-local; false positive reduction	LUNG-CANCER; DIAGNOSIS; VALIDATION; ALGORITHMS; SYSTEM; SCANS	Lung cancer is the most common cause of cancer death worldwide. A timely diagnosis of the pulmonary nodules makes it possible to detect lung cancer in the early stage, and thoracic computed tomography (CT) provides a convenient way to diagnose nodules. However, it is hard even for experienced doctors to distinguish them from the massive CT slices. The currently existing nodule datasets are limited in both scale and category, which is insufficient and greatly restricts its applications. In this paper, we collect the largest and most diverse dataset named PN9 for pulmonary nodule detection by far. Specifically, it contains 8,798 CT scans and 40,439 annotated nodules from 9 common classes. We further propose a slice-aware network (SANet) for pulmonary nodule detection. A slice grouped non-local (SGNL) module is developed to capture long-range dependencies among any positions and any channels of one slice group in the feature map. And we introduce a 3D region proposal network to generate pulmonary nodule candidates with high sensitivity, while this detection stage usually comes with many false positives. Subsequently, a false positive reduction module (FPR) is proposed by using the multi-scale feature maps. To verify the performance of SANet and the significance of PN9, we perform extensive experiments compared with several state-of-the-art 2D CNN-based and 3D CNN-based detection methods. Promising evaluation results on PN9 prove the effectiveness of our proposed SANet. The dataset and source code is available at https://mmcheng.net/SANet/.	[Mei, Jie; Cheng, Ming-Ming; Xu, Gang] Nankai Univ, Coll Comp Sci, TKLNDST, Tianjin 300350, Peoples R China; [Wan, Lan-Ruo; Zhang, Huan] InferVision, Beijing 100025, Peoples R China	Nankai University	Cheng, MM (corresponding author), Nankai Univ, Coll Comp Sci, TKLNDST, Tianjin 300350, Peoples R China.	meijie@mail.nankai.edu.cn; cmm@nankai.edu.cn; gangxu@mail.nankai.edu.cn; wlanruo@infervision.com; zhuah@infervision.com			Major Project for New Generation of AI [2018AAA0100400]; NSFC [61922046]; S&T innovation project from Chinese Ministry of Education; Tianjin Natural Science Foundation [18ZXZNGX00110]	Major Project for New Generation of AI; NSFC(National Natural Science Foundation of China (NSFC)); S&T innovation project from Chinese Ministry of Education; Tianjin Natural Science Foundation(Natural Science Foundation of Tianjin)	This work was supported by the Major Project for New Generation of AI under Grant No. 2018AAA0100400, NSFC (61922046), S&T innovation project from Chinese Ministry of Education, and Tianjin Natural Science Foundation (18ZXZNGX00110).	Aberle DR, 2011, NEW ENGL J MED, V365, P395, DOI 10.1056/NEJMoa1102873; Aerts HJWL, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5006; Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204; Brosch T, 2014, LECT NOTES COMPUT SC, V8674, P462, DOI 10.1007/978-3-319-10470-6_58; Chen Y., 2017, ADV NEURAL INFORM PR, P4468; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7; Detterbeck FC, 2013, CHEST, V143, pE78, DOI 10.1378/chest.12-2350; Ding J., 2017, INT C MED IM COMP CO, P559; Dou Q, 2017, IEEE T BIO-MED ENG, V64, P1558, DOI 10.1109/TBME.2016.2613502; Duggan N, 2015, LECT NOTES COMPUT SC, V8932, P478, DOI 10.1007/978-3-319-14612-6_35; Duncan JS, 2000, IEEE T PATTERN ANAL, V22, P85, DOI 10.1109/34.824822; El-Baz A, 2011, LECT NOTES COMPUT SC, V6801, P772, DOI 10.1007/978-3-642-22092-0_63; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; Ettinger DS, 2016, J NATL COMPR CANC NE, V14, P255, DOI 10.6004/jnccn.2016.0031; Ferlay J, 2015, INT J CANCER, V136, pE359, DOI 10.1002/ijc.29210; Fu C. -Y., 2017, ARXIV17010665; Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216; Han FF, 2013, PROCEEDINGS OF 2013 IEEE INTERNATIONAL CONFERENCE ON MEDICAL IMAGING PHYSICS AND ENGINEERING (ICMIPE), P14, DOI 10.1109/ICMIPE.2013.6864494; Harsono IW, 2020, J KING SAUD UNIV-COM, V34, P567, DOI 10.1016/j.jksuci.2020.03.013; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Howard A.G., 2017, MOBILENETS EFFICIENT; Hussein S, 2017, LECT NOTES COMPUT SC, V10265, P249, DOI 10.1007/978-3-319-59050-9_20; Infante M, 2009, AM J RESP CRIT CARE, V180, P445, DOI 10.1164/rccm.200901-0076OC; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jacobs C, 2014, MED IMAGE ANAL, V18, P374, DOI 10.1016/j.media.2013.12.001; Kazerooni EA, 2014, J THORAC IMAG, V29, P310, DOI 10.1097/RTI.0000000000000097; Kim BC, 2019, NEURAL NETWORKS, V115, P1, DOI 10.1016/j.neunet.2019.03.003; Li YM, 2020, I S BIOMED IMAGING, P1866, DOI 10.1109/ISBI45749.2020.9098317; Liao FZ, 2019, IEEE T NEUR NET LEAR, V30, P3484, DOI 10.1109/TNNLS.2019.2892409; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Torres EL, 2015, MED PHYS, V42, P1477, DOI 10.1118/1.4907970; MacMahon H, 2017, RADIOLOGY, V284, P228, DOI 10.1148/radiol.2017161659; Manos D, 2014, CAN ASSOC RADIOL J, V65, P121, DOI 10.1016/j.carj.2014.03.004; McNitt-Gray MF, 2007, PROC SPIE, V6514, DOI 10.1117/12.713754; Messay T, 2010, MED IMAGE ANAL, V14, P390, DOI 10.1016/j.media.2010.02.004; Ozdemir O, 2020, IEEE T MED IMAGING, V39, P1419, DOI 10.1109/TMI.2019.2947595; Peng XJ, 2016, LECT NOTES COMPUT SC, V9908, P744, DOI 10.1007/978-3-319-46493-0_45; Pereira FR, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P537, DOI 10.5220/0007398705370544; Prasoon A, 2013, LECT NOTES COMPUT SC, V8150, P246, DOI 10.1007/978-3-642-40763-5_31; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ronneberger O., 2015, P INT C MED IMAG COM, P234, DOI [DOI 10.1007/978-3-319-24574-4_28, DOI 10.48550/ARXIV.1505.04597]; Setio AAA, 2017, MED IMAGE ANAL, V42, P1, DOI 10.1016/j.media.2017.06.015; Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809; Shen Wei, 2015, Inf Process Med Imaging, V24, P588, DOI 10.1007/978-3-319-19992-4_46; Shin HC, 2013, IEEE T PATTERN ANAL, V35, P1930, DOI 10.1109/TPAMI.2012.277; Siegel RL, 2017, CA-CANCER J CLIN, V67, P7, DOI 10.3322/caac.21387; Singh SP, 2012, J THORAC IMAG, V27, P249, DOI 10.1097/RTI.0b013e318256951e; Tang H, 2019, LECT NOTES COMPUT SC, V11769, P266, DOI 10.1007/978-3-030-32226-7_30; Tao Song, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P550, DOI 10.1007/978-3-030-59725-2_53; van Ginneken B, 2010, MED IMAGE ANAL, V14, P707, DOI 10.1016/j.media.2010.05.005; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Way TW, 2006, MED PHYS, V33, P2323, DOI 10.1118/1.2207129; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wei Shen, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P124, DOI 10.1007/978-3-319-46723-8_15; Wu BC, 2017, IEEE COMPUT SOC CONF, P446, DOI 10.1109/CVPRW.2017.60; Wu YH, 2021, IEEE T IMAGE PROCESS, V30, P3113, DOI 10.1109/TIP.2021.3058783; Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI 10.1007/s11263-019-01198-w; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Yan X, 2017, LECT NOTES COMPUT SC, V10118, P91, DOI 10.1007/978-3-319-54526-4_7; Yue KY, 2018, ADV NEUR IN, V31; Zhu W., 2017, INT C MED IM COMP CO, P603, DOI [10.1007/978-3-319-66179-7_69, DOI 10.1007/978-3-319-66179-7_69]; Zhu WT, 2018, IEEE WINT CONF APPL, P673, DOI 10.1109/WACV.2018.00079	71	15	15	12	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 9	2021	44	8					4374	4387		10.1109/TPAMI.2021.3065086	http://dx.doi.org/10.1109/TPAMI.2021.3065086			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HO	33687839				2022-12-18	WOS:000820521800005
J	Meng, QH; Wang, WG; Zhou, TF; Shen, JB; Jia, YD; Van Gool, L				Meng, Qinghao; Wang, Wenguan; Zhou, Tianfei; Shen, Jianbing; Jia, Yunde; Van Gool, Luc			Towards a Weakly Supervised Framework for 3D Point Cloud Object Detection and Annotation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D object detection; 3D annotation; weakly supervised learning; cascade inference; autonomous driving		It is quite laborious and costly to manually label LiDAR point cloud data for training high-quality 3D object detectors. This work proposes a weakly supervised framework which allows learning 3D detection from a few weakly annotated examples. This is achieved by a two-stage architecture design. Stage-1 learns to generate cylindrical object proposals under inaccurate and inexact supervision, obtained by our proposed BEV center-click annotation strategy, where only the horizontal object centers are click-annotated in bird's view scenes. Stage-2 learns to predict cuboids and confidence scores in a coarse-to-fine, cascade manner, under incomplete supervision, i.e., only a small portion of object cuboids are precisely annotated. With KITTI dataset, using only 500 weakly annotated scenes and 534 precisely labeled vehicle instances, our method achieves 86 - 97 percent the performance of current topleading, fully supervised detectors (which require 3,712 exhaustively annotated scenes with 15,654 instances). More importantly, with our elaborately designed network architecture, our trained model can be applied as a 3D object annotator, supporting both automatic and active (human-in-the-loop) working modes. The annotations generated by our model can be used to train 3D object detectors, achieving over 95 percent of their original performance (with manually labeled training data). Our experiments also show our model's potential in boosting performance when given more training data. The above designs make our approach highly practical and open-up opportunities for learning 3D detection at reduced annotation cost.	[Meng, Qinghao; Shen, Jianbing; Jia, Yunde] Beijing Inst Technol, Sch Comp Sci, Beijing, Peoples R China; [Wang, Wenguan; Zhou, Tianfei; Van Gool, Luc] Swiss Fed Inst Technol, Zurich, Switzerland; [Shen, Jianbing] Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates	Beijing Institute of Technology; Swiss Federal Institutes of Technology Domain; ETH Zurich	Wang, WG (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.	mengqinghao@bit.edu.cn; wenguan.wang@gmail.com; ztfei.debug@gmail.com; shenjianbingcg@gmail.com; jiayunde@bit.edu.cn; vangool@vision.ee.ethz.ch	Zhou, Tianfei/AAC-6115-2022; Meng, Qinghao/GPX-4444-2022	Zhou, Tianfei/0000-0001-5475-1473; Meng, Qinghao/0000-0001-7659-435X	Natural Science Foundation of China [61773062]; Zhejiang Lab's Open Fund [2020AA3AB14]; CCF-Baidu Open Fund	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Zhejiang Lab's Open Fund; CCF-Baidu Open Fund	This work was supported by the Natural Science Foundation of China (under Grant 61773062), CCF-Baidu Open Fund and Zhejiang Lab's Open Fund (No. 2020AA3AB14). A preliminary version of this work has appeared in ECCV 2020 [1]. Our codes and annotated data are available in https://github.com/hlesmqh/WS3D.	[Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; Bearman A, 2016, LECT NOTES COMPUT SC, V9911, P549, DOI 10.1007/978-3-319-46478-7_34; Benenson R, 2019, PROC CVPR IEEE, P11692, DOI 10.1109/CVPR.2019.01197; Chabot F, 2017, PROC CVPR IEEE, P1827, DOI 10.1109/CVPR.2017.198; Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511; Chen X., 2015, ADV NEUR IN, V28; Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691; Chen XZ, 2016, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2016.236; Chen YL, 2019, IEEE I CONF COMP VIS, P9774, DOI 10.1109/ICCV.2019.00987; Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Gwak J, 2017, INT CONF 3D VISION, P263, DOI 10.1109/3DV.2017.00038; Huang XY, 2020, IEEE T PATTERN ANAL, V42, P2702, DOI 10.1109/TPAMI.2019.2926463; Kar A, 2019, IEEE I CONF COMP VIS, P4550, DOI 10.1109/ICCV.2019.00465; Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298; Lee J, 2018, IEEE INT C INTELL TR, P2504, DOI 10.1109/ITSC.2018.8569793; Li B, 2016, ROBOTICS: SCIENCE AND SYSTEMS XII; Li BY, 2019, PROC CVPR IEEE, P1019, DOI 10.1109/CVPR.2019.00111; Liang M, 2019, PROC CVPR IEEE, P7337, DOI 10.1109/CVPR.2019.00752; Liang M, 2018, LECT NOTES COMPUT SC, V11220, P663, DOI 10.1007/978-3-030-01270-0_39; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Liu Z, 2020, AAAI CONF ARTIF INTE, V34, P11677; Ma QL, 2020, PROC CVPR IEEE, P6468, DOI 10.1109/CVPR42600.2020.00650; Maninis KK, 2018, PROC CVPR IEEE, P616, DOI 10.1109/CVPR.2018.00071; Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481; Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438; Mottaghi R, 2015, PROC CVPR IEEE, P418, DOI 10.1109/CVPR.2015.7298639; Mousavian A, 2017, PROC CVPR IEEE, P5632, DOI 10.1109/CVPR.2017.597; Na Zhao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11076, DOI 10.1109/CVPR42600.2020.01109; Papadopoulos DP, 2017, IEEE I CONF COMP VIS, pCP38, DOI 10.1109/ICCV.2017.528; Papadopoulos DP, 2017, PROC CVPR IEEE, P180, DOI 10.1109/CVPR.2017.27; Qi CR, 2017, ADV NEUR IN, V30; Qi CR, 2020, PROC CVPR IEEE, P4403, DOI 10.1109/CVPR42600.2020.00446; Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937; Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102; Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609; Qinghao Meng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P515, DOI 10.1007/978-3-030-58601-0_31; Rethage D, 2018, LECT NOTES COMPUT SC, V11208, P625, DOI 10.1007/978-3-030-01225-0_37; Saining Xie, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P574, DOI 10.1007/978-3-030-58580-8_34; Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086; Shi SS, 2021, IEEE T PATTERN ANAL, V43, P2647, DOI 10.1109/TPAMI.2020.2977026; Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655; Stutz D, 2018, PROC CVPR IEEE, P1955, DOI 10.1109/CVPR.2018.00209; Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114; Tang YS, 2019, IEEE I CONF COMP VIS, P1931, DOI 10.1109/ICCV.2019.00202; Wang H., 2020, ARXIV 201204355; Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801; Xiang Y, 2015, PROC CVPR IEEE, P1903, DOI 10.1109/CVPR.2015.7298800; Xie JW, 2018, PROC CVPR IEEE, P8629, DOI 10.1109/CVPR.2018.00900; Xie J, 2016, PROC CVPR IEEE, P3688, DOI 10.1109/CVPR.2016.401; Xu X., 2020, P IEEECVF C COMP VIS, P13703, DOI DOI 10.1109/CVPR42600.2020.01372; Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337; Yang B, 2018, PROC CVPR IEEE, P7652, DOI 10.1109/CVPR.2018.00798; Yang ZT, 2019, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2019.00204; Zakharov Sergey, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12221, DOI 10.1109/CVPR42600.2020.01224; Zetong Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11037, DOI 10.1109/CVPR42600.2020.01105; Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644; Zhou TF, 2022, IEEE T PATTERN ANAL, V44, P2827, DOI 10.1109/TPAMI.2021.3049156; Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472	59	15	15	4	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 3	2021	44	8					4454	4468		10.1109/TPAMI.2021.3063611	http://dx.doi.org/10.1109/TPAMI.2021.3063611			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6IC	33656990	Green Accepted			2022-12-18	WOS:000820523200003
J	Dong, JF; Li, XR; Xu, CX; Yang, X; Yang, G; Wang, X; Wang, M				Dong, Jianfeng; Li, Xirong; Xu, Chaoxi; Yang, Xun; Yang, Gang; Wang, Xun; Wang, Meng			Dual Encoding for Video Retrieval by Text	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Encoding; Visualization; Feature extraction; Computational modeling; Linguistics; Electronic mail; Recurrent neural networks; Video retrieval; cross-modal representation learning; dual encoding; hybrid space learning	IMAGE	This paper attacks the challenging problem of video retrieval by text. In such a retrieval paradigm, an end user searches for unlabeled videos by ad-hoc queries described exclusively in the form of a natural-language sentence, with no visual example provided. Given videos as sequences of frames and queries as sequences of words, an effective sequence-to-sequence cross-modal matching is crucial. To that end, the two modalities need to be first encoded into real-valued vectors and then projected into a common space. In this paper we achieve this by proposing a dual deep encoding network that encodes videos and queries into powerful dense representations of their own. Our novelty is two-fold. First, different from prior art that resorts to a specific single-level encoder, the proposed network performs multi-level encoding that represents the rich content of both modalities in a coarse-to-fine fashion. Second, different from a conventional common space learning algorithm which is either concept based or latent space based, we introduce hybrid space learning which combines the high performance of the latent space and the good interpretability of the concept space. Dual encoding is conceptually simple, practically effective and end-to-end trained with hybrid space learning. Extensive experiments on four challenging video datasets show the viability of the new method. Code and data are available at https://github.com/danieljf24/hybrid_space.	[Dong, Jianfeng; Wang, Xun] Zhejiang Gongshang Univ, Coll Comp & Informat Engn, Hangzhou 310035, Peoples R China; [Li, Xirong; Xu, Chaoxi; Yang, Gang] Renmin Univ China, Sch Informat, Key Lab Data Engn & Knowledge Engn, Beijing 100872, Peoples R China; [Li, Xirong; Xu, Chaoxi; Yang, Gang] Renmin Univ China, Sch Informat, AI & Media Comp Lab, Beijing 100872, Peoples R China; [Yang, Xun] Natl Univ Singapore, Sch Comp, Singapore 37580, Singapore; [Wang, Meng] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Peoples R China	Zhejiang Gongshang University; Renmin University of China; Renmin University of China; National University of Singapore; Hefei University of Technology	Wang, X (corresponding author), Zhejiang Gongshang Univ, Coll Comp & Informat Engn, Hangzhou 310035, Peoples R China.; Li, XR (corresponding author), Renmin Univ China, Sch Informat, Key Lab Data Engn & Knowledge Engn, Beijing 100872, Peoples R China.; Li, XR (corresponding author), Renmin Univ China, Sch Informat, AI & Media Comp Lab, Beijing 100872, Peoples R China.	dongjf24@gmail.com; xirong@ruc.edu.cn; xcx@ruc.edu.cn; yanggang@ruc.edu.cn; xunyang@nus.edu.sg; wx@mail.zjgsu.edu.cn; wangmeng@hfut.edu.cn	Li, Xirong/AAD-3347-2019	Li, Xirong/0000-0002-0220-8310	NSFC [61902347, 61672523]; BJNSF [4202033]; ZJNSF [LQ19F020002]; Public Welfare Technology Research Project of Zhejiang Province [LGF21F020010]; Fundamental Research Funds for the Central Universities; Research Funds of Renmin University of China [18XNLG19]; Research Program of Zhejiang Lab [2019KD0AC02]; Public Computing Cloud of Renmin University of China; Alibaba-ZJU Joint Research Institute of Frontier Technologies	NSFC(National Natural Science Foundation of China (NSFC)); BJNSF; ZJNSF(Natural Science Foundation of Zhejiang Province); Public Welfare Technology Research Project of Zhejiang Province; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Research Funds of Renmin University of China; Research Program of Zhejiang Lab; Public Computing Cloud of Renmin University of China; Alibaba-ZJU Joint Research Institute of Frontier Technologies	This work was supported by the NSFC (No. 61902347, No. 61672523), BJNSF (No. 4202033), and ZJNSF (No. LQ19F020002), the Public Welfare Technology Research Project of Zhejiang Province (No. LGF21F020010), the Fundamental Research Funds for the Central Universities and the Research Funds of Renmin University of China (No. 18XNLG19), the Research Program of Zhejiang Lab (No. 2019KD0AC02), the Public Computing Cloud of Renmin University of China, and the Alibaba-ZJU Joint Research Institute of Frontier Technologies.	[Anonymous], 2017, TRECVID; Awad, 2016, TRECVID 2016 EVALUAT; Awad G., 2018, P TRECVID; Awad G., 2017, P TRECVID 2017; Awad G, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P3, DOI 10.1145/3078971.3079044; Bastan M., 2018, PROC TRECVID WORKSHO; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Chang XJ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2234; Chen S., 2020, PROC IEEECVF C COMPU, p10 638; Cho K., 2014, P 2014 C EMP METH NA, P1724; Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142; Dalton J, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P1857, DOI 10.1145/2505515.2507880; Devlin J., 2019, P 2019 C N AM CHAPT, V1, P4171; Dong J., 2017, PROC TRECVID WORKSHO; Dong JF, 2019, PROC CVPR IEEE, P9338, DOI 10.1109/CVPR.2019.00957; Dong JF, 2018, IEEE T MULTIMEDIA, V20, P3377, DOI 10.1109/TMM.2018.2832602; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Faghri Fartash, 2018, BMVC, P12; Francis D., 2019, P IEEE CVF INT C COM; Gabeur V., 2020, ECCV, P214; Google Research, 2018, TENS PRETR BERT; Habibian A., 2014, ICMR, P17; Habibian A, 2017, IEEE T PATTERN ANAL, V39, P2089, DOI 10.1109/TPAMI.2016.2627563; Habibian A, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P17, DOI 10.1145/2647868.2654913; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang P.-Y., 2018, TRECVID P, V70; Jiang L, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P547, DOI 10.1145/2647868.2654918; Kim Y, 2014, IEEE ASME INT C ADV, P1747, DOI 10.1109/AIM.2014.6878336; Kingma DP, 2015, INT C LEARN REPR ICL; Kittler J, 1998, PATTERN ANAL APPL, V1, P18, DOI 10.1007/BF01238023; Koelma D. C., 2017, PROC TRECVID WORKSHO; Kratochvil M, 2020, LECT NOTES COMPUT SC, V11962, P790, DOI 10.1007/978-3-030-37734-2_71; Le D., 2016, PROC TRECVID WORKSHO; Li SW, 2017, IEEE T PATTERN ANAL, V39, P2423, DOI 10.1109/TPAMI.2017.2651818; Li X., 2018, TRECVID; Li XR, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1786, DOI 10.1145/3343031.3350906; Li YC, 2016, PROC CVPR IEEE, P4641, DOI 10.1109/CVPR.2016.502; Liang J., 2016, PROC TRECVID WORKSHO; Liu, 2019, ARXIV 190713487; Lokoc J, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2553, DOI 10.1145/3394171.3414002; Lu YJ, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P127, DOI 10.1145/2911996.2912015; Markatopoulou F., 2016, P TRECVID WORKSH; Markatopoulou F, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P412, DOI 10.1145/3078971.3079041; Mettes P, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3377875; Miech, 2018, ARXIV 180402516; Miech A, 2019, IEEE I CONF COMP VIS, P2630, DOI 10.1109/ICCV.2019.00272; Mikolov T., 2013, 1 INT LEARN REPR ICL; Mithun NC, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P19, DOI 10.1145/3206025.3206064; Nguyen P.A., 2017, PROC TRECVID WORKSHO; Otani Mayu, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P651, DOI 10.1007/978-3-319-46604-0_46; PAIVIO A, 1991, CAN J PSYCHOL, V45, P255, DOI 10.1037/h0084295; Rohrbach A, 2015, PROC CVPR IEEE, P3202, DOI 10.1109/CVPR.2015.7298940; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Shao D, 2018, LECT NOTES COMPUT SC, V11213, P202, DOI 10.1007/978-3-030-01240-3_13; Song Y, 2019, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2019.00208; Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556; Torabi Atousa, 2016, ARXIV160908124; Ueki K., 2018, PROC TRECVID WORKSHO; Ueki K., 2017, TRECVID; Vaswani A., 2017, P 31 INT C NEUR INF, P5998, DOI DOI 10.5555/3295222.3295349; Wang X, 2019, IEEE I CONF COMP VIS, P4580, DOI 10.1109/ICCV.2019.00468; Wray M, 2019, IEEE I CONF COMP VIS, P450, DOI 10.1109/ICCV.2019.00054; Wu F., 2013, P 21 ACM INT C MULT, P877, DOI DOI 10.1145/2502081.2502097; Wu S, 2014, PROC CVPR IEEE, P2665, DOI 10.1109/CVPR.2014.341; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Xiong Y, 2019, IEEE I CONF COMP VIS, P4591, DOI 10.1109/ICCV.2019.00469; Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571; Xu R, 2015, AAAI CONF ARTIF INTE, P2346; Yang X, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1339, DOI 10.1145/3397271.3401151; Yu Y, 2018, LECT NOTES COMPUT SC, V11211, P487, DOI 10.1007/978-3-030-01234-2_29; Yu Y, 2017, PROC CVPR IEEE, P3261, DOI 10.1109/CVPR.2017.347; Zhang BW, 2018, LECT NOTES COMPUT SC, V11217, P385, DOI 10.1007/978-3-030-01261-8_23; Zhao R, 2020, IEEE INT CON MULTI; Zhou Bolei, 2015, ARXIV151202167; Zhu Linchao, 2020, P IEEE CVF C COMP VI, P8746, DOI DOI 10.1109/CVPR42600.2020.00877; Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11	77	15	15	3	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 15	2021	44	8					4065	4080		10.1109/TPAMI.2021.3059295	http://dx.doi.org/10.1109/TPAMI.2021.3059295			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HR	33587696	Green Submitted			2022-12-18	WOS:000820522100001
J	Xie, JW; Zhu, SC; Wu, YN				Xie, Jianwen; Zhu, Song-Chun; Wu, Ying Nian			Learning Energy-Based Spatial-Temporal Generative ConvNets for Dynamic Patterns	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Data models; Heuristic algorithms; Solid modeling; Generators; Three-dimensional displays; Video sequences; Dynamics; Deep generative models; energy-based models; dynamic textures; generative ConvNets; spatial-temporal ConvNets	NETWORKS	Video sequences contain rich dynamic patterns, such as dynamic texture patterns that exhibit stationarity in the temporal domain, and action patterns that are non-stationary in either spatial or temporal domain. We show that an energy-based spatial-temporal generative ConvNet can be used to model and synthesize dynamic patterns. The model defines a probability distribution on the video sequence, and the log probability is defined by a spatial-temporal ConvNet that consists of multiple layers of spatial-temporal filters to capture spatial-temporal patterns of different scales. The model can be learned from the training video sequences by an "analysis by synthesis" learning algorithm that iterates the following two steps. Step 1 synthesizes video sequences from the currently learned model. Step 2 then updates the model parameters based on the difference between the synthesized video sequences and the observed training sequences. We show that the learning algorithm can synthesize realistic dynamic patterns. We also show that it is possible to learn the model from incomplete training sequences with either occluded pixels or missing frames, so that model learning and pattern completion can be accomplished simultaneously.	[Xie, Jianwen] Hikvis Res Inst, Santa Clara, CA 95054 USA; [Zhu, Song-Chun; Wu, Ying Nian] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA	University of California System; University of California Los Angeles	Xie, JW (corresponding author), Hikvis Res Inst, Santa Clara, CA 95054 USA.	jianwen@ucla.edu; sczhu@stat.ucla.edu; ywu@stat.ucla.edu			NVIDIA Corporation; ONR MURI [N00014-16-1-2007]; DARPA ARO [W911NF-16-1-0579]	NVIDIA Corporation; ONR MURI(MURIOffice of Naval Research); DARPA ARO(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Xp GPU used for this research. The work is supported by ONR MURI N00014-16-1-2007, and DARPA ARO W911NF-16-1-0579.	Abraham B., 2005, PROC INT WORKSHOP TE, V1, P53; [Anonymous], 2006, IEEE T AUTOM SCI ENG; [Anonymous], 2016, P ECCV; Carl V., 2016, ADV NEURAL INFORM PR, V29, P613, DOI DOI 10.13016/M26GIH-TNYZ; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Chen QF, 2017, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2017.168; Costantini R, 2008, IEEE T IMAGE PROCESS, V17, P42, DOI 10.1109/TIP.2007.910956; Dai J., 2014, ARXIV14126296; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Dosovitskiy A, 2015, PROC CVPR IEEE, P1538, DOI 10.1109/CVPR.2015.7298761; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Feichtenhofer Christoph, 2016, P ADV NEUR INF PROC; Funke C. M., 2017, ARXIV170207006; Gao RQ, 2018, PROC CVPR IEEE, P9155, DOI 10.1109/CVPR.2018.00954; Ghanem B, 2010, LECT NOTES COMPUT SC, V6312, P223; Girolami M, 2011, J R STAT SOC B, V73, P123, DOI 10.1111/j.1467-9868.2010.00765.x; Goncalves GR, 2018, SIBGRAPI, P110, DOI 10.1109/SIBGRAPI.2018.00021; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gregor K, 2015, PR MACH LEARN RES, V37, P1462; Grenander U., 2007, PATTERN THEORY REPRE; Grenander U., 1970, ADV COMPUT, V10; Han T, 2019, IEEE WINT CONF APPL, P809, DOI 10.1109/WACV.2019.00091; Han T, 2017, AAAI CONF ARTIF INTE, P1976; Han Z, 2015, J MATH IMAGING VIS, V53, P151, DOI 10.1007/s10851-015-0563-2; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Jin L., 2017, ADV NEURAL INFORM PR, P823; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Kingma DP, 2 INT C LEARN REPR I, P1; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kulkarni TD, 2015, ADV NEUR IN, V28; Kumar M., 2019, ARXIV190301434; Landau D. P., 2014, GUIDE MONTE CARLO SI; Lazarow J, 2017, IEEE I CONF COMP VIS, P2793, DOI 10.1109/ICCV.2017.302; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee K, 2018, PROC CVPR IEEE, P3702, DOI 10.1109/CVPR.2018.00390; Lu Y, 2016, AAAI CONF ARTIF INTE, P1902; Montufar G. F., 2014, ADV NEURAL INFORM PR, P2924; Neal RM, 2011, CH CRC HANDB MOD STA, P113; Ngiam J., 2011, P 28 INT C MACHINE L, P1105; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; Saito M, 2017, IEEE I CONF COMP VIS, P2849, DOI 10.1109/ICCV.2017.308; Seung HS, 1998, ADV NEUR IN, V10, P654; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tesfaldet M, 2018, PROC CVPR IEEE, P6703, DOI 10.1109/CVPR.2018.00701; Tu Z, 2007, PROC CVPR IEEE, P500; Tulyakov S, 2018, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2018.00165; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917; Wang YZ, 2004, IEEE T PATTERN ANAL, V26, P1348, DOI 10.1109/TPAMI.2004.76; Wang YZ, 2002, LECT NOTES COMPUT SC, V2350, P583; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Welling Max, 2009, P 26 ANN INT C MACH, P1121, DOI DOI 10.1145/1553374.1553517; Wildes R. P., 2017, P CVPR, P4728; Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270; Wu Y. N., 2017, P IEEE C COMP VIS PA, P7093; Wu YN, 2000, INT J COMPUT VISION, V38, P247, DOI 10.1023/A:1008199424771; Xie J., 2014, P IEEE INT C MULT EX, P1; Xie JW, 2019, AAAI CONF ARTIF INTE, P5498; Xie JW, 2020, IEEE T PATTERN ANAL, V42, P27, DOI 10.1109/TPAMI.2018.2879081; Xie JW, 2018, PROC CVPR IEEE, P8629, DOI 10.1109/CVPR.2018.00900; Xie JW, 2016, PR MACH LEARN RES, V48; Xie JW, 2016, APPL COMPUT HARMON A, V41, P4, DOI 10.1016/j.acha.2015.08.004; You XG, 2016, IEEE T IMAGE PROCESS, V25, P4782, DOI 10.1109/TIP.2016.2598653; Younes L., STOCHASTICS INT J PR, V65, P177; Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474; Zhu SC, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P847, DOI 10.1109/ICCV.1998.710816; Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627; Ziebart B. D., 2008, AAAI, V8, P1433	73	15	15	3	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2021	43	2					516	531		10.1109/TPAMI.2019.2934852	http://dx.doi.org/10.1109/TPAMI.2019.2934852			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PR6ZZ	31425020	Green Submitted			2022-12-18	WOS:000607383300010
J	Zhou, Y; Cheung, YM				Zhou, Yang; Cheung, Yiu-ming			Bayesian Low-Tubal-Rank Robust Tensor Factorization with Multi-Rank Determination	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Robust PCA; tensor factorization; tubal rank; multi-rank determination; Bayesian inference	DECOMPOSITIONS; MODELS	Robust tensor factorization is a fundamental problem in machine learning and computer vision, which aims at decomposing tensors into low-rank and sparse components. However, existing methods either suffer from limited modeling power in preserving low-rank structures, or have difficulties in determining the target tensor rank and the trade-off between the low-rank and sparse components. To address these problems, we propose a fully Bayesian treatment of robust tensor factorization along with a generalized sparsity-inducing prior. By adapting the recently proposed low-tubal-rank model in a generative manner, our method is effective in preserving low-rank structures. Moreover, benefiting from the proposed prior and the Bayesian framework, the proposed method can automatically determine the tensor rank while inferring the trade-off between the low-rank and sparse components. For model estimation, we develop a variational inference algorithm, and further improve its efficiency by reformulating the variational updates in the frequency domain. Experimental results on both synthetic and real-world datasets demonstrate the effectiveness of the proposed method in multi-rank determination as well as its superiority in image denoising and background modeling over state-of-the-art approaches.	[Zhou, Yang; Cheung, Yiu-ming] Hong Kong Baptist Univ, Dept Comp Sci, Kowloon Tong, Hong Kong, Peoples R China; [Zhou, Yang] East China Normal Univ, Sch Comp Sci & Software Engn, Shanghai 200062, Peoples R China; [Cheung, Yiu-ming] Hong Kong Baptist Univ, Inst Res & Continuing Educ, Kowloon Tong, Hong Kong, Peoples R China	Hong Kong Baptist University; East China Normal University; Hong Kong Baptist University	Zhou, Y (corresponding author), Hong Kong Baptist Univ, Dept Comp Sci, Kowloon Tong, Hong Kong, Peoples R China.; Zhou, Y (corresponding author), East China Normal Univ, Sch Comp Sci & Software Engn, Shanghai 200062, Peoples R China.	youngzhou12@gmail.com; ymc@comp.hkbu.edu.hk	; Cheung, Yiu-ming/E-2050-2015	Zhou, Yang/0000-0002-0873-619X; Cheung, Yiu-ming/0000-0001-7629-4648	National Natural Science Foundation of China [61672444, 61272366]; Faculty Research Grant of Hong Kong Baptist University (HKBU) [FRG2/17-18/082]; KTO Grant of HKBU [MPCF-004-2017/18]; SZSTI [JCYJ20160531194006833]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Faculty Research Grant of Hong Kong Baptist University (HKBU); KTO Grant of HKBU; SZSTI	We thank Dr. Jian Lou for helpful discussions. This work was supported by the National Natural Science Foundation of China under Grants: 61672444 and 61272366 and in part by the Faculty Research Grant of Hong Kong Baptist University (HKBU) under Project FRG2/17-18/082, the KTO Grant of HKBU under Project MPCF-004-2017/18, and the SZSTI under Grant JCYJ20160531194006833.	Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Babacan SD, 2012, IEEE T SIGNAL PROCES, V60, P3964, DOI 10.1109/TSP.2012.2197748; Bahri M, 2017, IEEE I CONF COMP VIS, P3372, DOI 10.1109/ICCV.2017.363; Beal M.J., 2003, VARIATIONAL ALGORITH; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791; Chen XA, 2018, IEEE T NEUR NET LEAR, V29, P5380, DOI 10.1109/TNNLS.2018.2796606; Chu W., 2009, PROC 12 INT C ARTIF, V5, P89; Ding XH, 2011, IEEE T IMAGE PROCESS, V20, P3419, DOI 10.1109/TIP.2011.2156801; Goldfarb D, 2014, SIAM J MATRIX ANAL A, V35, P225, DOI 10.1137/130905010; Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919; Harshman R.A., 1970, MULTIMODAL FACTOR AN; Hillar CJ, 2013, J ACM, V60, DOI 10.1145/2512329; Hu WR, 2017, IEEE T IMAGE PROCESS, V26, P724, DOI 10.1109/TIP.2016.2627803; Huang B., 2014, OPTIM ONLINE, V4252, P2; Ji H, 2010, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2010.5539849; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Khan SA, 2016, MACH LEARN, V105, P233, DOI 10.1007/s10994-016-5563-y; Kilmer ME, 2013, SIAM J MATRIX ANAL A, V34, P148, DOI 10.1137/110837711; Kilmer ME, 2011, LINEAR ALGEBRA APPL, V435, P641, DOI 10.1016/j.laa.2010.09.020; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Koren Y., 2008, P 14 ACM SIGKDD INT, P426, DOI DOI 10.1145/1401890.1401944; Landsberg J., 2011, TENSORS GEOMETRY APP, V128; Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39; LIU XY, 2016, ARXIV161001690; Lu CY, 2020, IEEE T PATTERN ANAL, V42, P925, DOI 10.1109/TPAMI.2019.2891760; Lu CY, 2016, PROC CVPR IEEE, P5249, DOI 10.1109/CVPR.2016.567; Lu H., 2013, MULTILINEAR SUBSPACE; Martin CD, 2013, SIAM J SCI COMPUT, V35, pA474, DOI 10.1137/110841229; Morup M, 2011, WIRES DATA MIN KNOWL, V1, P24, DOI 10.1002/widm.1; Mu C, 2014, PR MACH LEARN RES, V32, P73; Neal Radford M, 2012, BAYESIAN LEARNING NE, V118; Pang M, 2020, IEEE T INF FOREN SEC, V15, P195, DOI 10.1109/TIFS.2019.2919950; Rai P, 2014, PR MACH LEARN RES, V32, P1800; Semerci O, 2014, IEEE T IMAGE PROCESS, V23, P1678, DOI 10.1109/TIP.2014.2305840; Shi QQ, 2019, IEEE T NEUR NET LEAR, V30, P1803, DOI 10.1109/TNNLS.2018.2873655; Shi QQ, 2017, LECT NOTES ARTIF INT, V10534, P564, DOI 10.1007/978-3-319-71249-9_34; Shi R., 2015, ARXIV150406074; TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464; Wang NY, 2013, IEEE I CONF COMP VIS, P1785, DOI 10.1109/ICCV.2013.224; Winn J, 2005, J MACH LEARN RES, V6, P661; Wright Y., 2009, ADV NEURAL INFORM PR, V22, DOI DOI 10.5555/2984093.2984326; Xiong L., 2010, P SDM COL OH, P211; Xu Z., 2012, 29 INT C MACH LEARN, P1675; Xu ZL, 2015, IEEE T PATTERN ANAL, V37, P475, DOI 10.1109/TPAMI.2013.201; Zhang ZM, 2017, IEEE T SIGNAL PROCES, V65, P1511, DOI 10.1109/TSP.2016.2639466; Zhao Q., 2015, IEEE T NEURAL NETWOR, V13, P736, DOI DOI 10.1109/TNNLS.2015.2423694; Zhou P, 2018, IEEE T IMAGE PROCESS, V27, P1152, DOI 10.1109/TIP.2017.2762595; Zhou P, 2017, PROC CVPR IEEE, P3938, DOI 10.1109/CVPR.2017.419; Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132	52	15	15	4	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2021	43	1					62	76		10.1109/TPAMI.2019.2923240	http://dx.doi.org/10.1109/TPAMI.2019.2923240			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PC7WN	31226066				2022-12-18	WOS:000597206900005
J	Jiang, L; Zhang, JY; Deng, BL				Jiang, Luo; Zhang, Juyong; Deng, Bailin			Robust RGB-D Face Recognition Using Attribute-Aware Loss	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; Face; Training; Training data; Feature extraction; Task analysis; Deep learning; Face recognition; RGB-D images; uneven sampling density; attribute-aware loss	MARGIN SOFTMAX	Existing convolutional neural network (CNN) based face recognition algorithms typically learn a discriminative feature mapping, using a loss function that enforces separation of features from different classes and/or aggregation of features within the same class. However, they may suffer from bias in the training data such as uneven sampling density, because they optimize the adjacency relationship of the learned features without considering the proximity of the underlying faces. Moreover, since they only use facial images for training, the learned feature mapping may not correctly indicate the relationship of other attributes such as gender and ethnicity, which can be important for some face recognition applications. In this paper, we propose a new CNN-based face recognition approach that incorporates such attributes into the training process. Using an attribute-aware loss function that regularizes the feature mapping using attribute proximity, our approach learns more discriminative features that are correlated with the attributes. We train our face recognition model on a large-scale RGB-D data set with over 100K identities captured under real application conditions. By comparing our approach with other methods on a variety of experiments, we demonstrate that depth channel and attribute-aware loss greatly improve the accuracy and robustness of face recognition.	[Jiang, Luo; Zhang, Juyong] Univ Sci & Technol China, Sch Math Sci, Hefei 230052, Peoples R China; [Deng, Bailin] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF10 3AT, Wales	Chinese Academy of Sciences; University of Science & Technology of China, CAS; Cardiff University	Zhang, JY (corresponding author), Univ Sci & Technol China, Sch Math Sci, Hefei 230052, Peoples R China.	jluo@mail.ustc.edu.cn; juyong@ustc.edu.cn; DengB3@cardiff.ac.uk	Jiang, Luo/T-9803-2019	Jiang, Luo/0000-0002-7578-8723; Deng, Bailin/0000-0002-0158-7670	National Natural Science Foundation of China [61672481]; Youth Innovation Promotion Association CAS [2018495]; Beijing Dilusense Technology Corporation	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Youth Innovation Promotion Association CAS; Beijing Dilusense Technology Corporation	This work was supported by National Natural Science Foundation of China (No. 61672481), and Youth Innovation Promotion Association CAS (No. 2018495). This work was also partially funded by Beijing Dilusense Technology Corporation. The research work was done when Luo Jiang did his internship at Beijing Dilusense Technology Corporation.	Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018; [Anonymous], 2011, NEURAL INF PROCESS S; Cui JY, 2018, LECT NOTES COMPUT SC, V10996, P358, DOI 10.1007/978-3-319-97909-0_39; Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287; Gilani SZ, 2018, PROC CVPR IEEE, P1896, DOI 10.1109/CVPR.2018.00203; Goswami G, 2014, IEEE T INF FOREN SEC, V9, P1629, DOI 10.1109/TIFS.2014.2343913; Guo YD, 2019, IEEE T PATTERN ANAL, V41, P1294, DOI 10.1109/TPAMI.2018.2837742; Hadsell R., 2006, 2006 IEEE COMPUTER S, P1735, DOI DOI 10.1109/CVPR.2006.100; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hernandez M, 2015, IMAGE VISION COMPUT, V36, P61, DOI 10.1016/j.imavis.2014.12.004; Hsu GS, 2014, IEEE T INF FOREN SEC, V9, P2110, DOI 10.1109/TIFS.2014.2361028; Hu GS, 2017, IEEE I CONF COMP VIS, P3764, DOI 10.1109/ICCV.2017.404; Huang H, 2014, WOODH PUB SER ELECT, P3, DOI 10.1533/9780857099334.1.3; Jain P, 2012, J MACH LEARN RES, V13, P519; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Deng JK, 2018, Arxiv, DOI arXiv:1801.07698; Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527; Kim D, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P133, DOI 10.1109/BTAS.2017.8272691; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Kumar BGV, 2016, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2016.581; Lee Y., 2016, P BRIT MACH VIS C; Li BYL, 2016, NEUROCOMPUTING, V214, P93, DOI 10.1016/j.neucom.2016.06.012; Li HB, 2014, NEUROCOMPUTING, V133, P179, DOI 10.1016/j.neucom.2013.11.018; Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212; Liu WY, 2016, PR MACH LEARN RES, V48; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Phillips PJ, 2005, PROC CVPR IEEE, P947; Ranjan R., 2017, US Patent App., Patent No. [15/938,898, 15938898]; Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Richardson E, 2017, PROC CVPR IEEE, P5553, DOI 10.1109/CVPR.2017.589; Rudd EM, 2016, LECT NOTES COMPUT SC, V9909, P19, DOI 10.1007/978-3-319-46454-1_2; Samangouei P., 2016, INT CONF BIOMETR THE, P1; Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Sohn K, 2016, ADV NEUR IN, V29; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vijayakumar VN, 2012, PHASE TRANSIT, V85, P113, DOI 10.1080/01411594.2011.594371; Wang F, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1041, DOI 10.1145/3123266.3123359; Weinberger KQ, 2009, J MACH LEARN RES, V10, P207; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566; Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032; Xing E. P., 2002, ADV NEURAL INF P SYS, P521, DOI DOI 10.1063/1.4908605; Yi D, 2014, ARXIV PREPRINT ARXIV; Zhang H, 2018, IEEE INT CONF AUTOMA, P8, DOI 10.1109/FG.2018.00012; Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360	53	15	16	10	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2020	42	10					2552	2566		10.1109/TPAMI.2019.2919284	http://dx.doi.org/10.1109/TPAMI.2019.2919284			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NL5QY	31144624	Green Accepted, Green Submitted			2022-12-18	WOS:000567471300017
J	Liu, Y; Liao, SZ; Jiang, SL; Ding, LZ; Lin, HL; Wang, WP				Liu, Yong; Liao, Shizhong; Jiang, Shali; Ding, Lizhong; Lin, Hailun; Wang, Weiping			Fast Cross-Validation for Kernel-Based Algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Approximation algorithms; Kernel; Training; Taylor series; Support vector machines; Upper bound; Computational modeling; Cross-validation; approximation; bouligand influence function; model selection; kernel methods	SUPPORT VECTOR MACHINES; MODEL SELECTION; ROBUSTNESS PROPERTIES; CONSISTENCY; HYPERPARAMETERS; REGULARIZATION; OPTIMIZATION; REGRESSION	Cross-validation (CV) is a widely adopted approach for selecting the optimal model. However, the computation of empirical cross-validation error (CVE) has high complexity due to multiple times of learner training. In this paper, we develop a novel approximation theory of CVE and present an approximate approach to CV based on the Bouligand influence function (BIF) for kernel-based algorithms. We first represent the BIF and higher order BIFs in Taylor expansions, and approximate CV via the Taylor expansions. We then derive an upper bound of the discrepancy between the original and approximate CV. Furthermore, we provide a novel computing method to calculate the BIF for general distribution, and evaluate BIF criterion for sample distribution to approximate CV. The proposed approximate CV requires training on the full data set only once and is suitable for a wide variety of kernel-based algorithms. Experimental results demonstrate that the proposed approximate CV is sound and effective.	[Liu, Yong; Lin, Hailun] Chinese Acad Sci, Inst Informat Engn, Beijing 100864, Peoples R China; [Liao, Shizhong] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300457, Peoples R China; [Jiang, Shali] Washington Univ, St Louis, MO 63130 USA; [Ding, Lizhong] IIAI, Abu Dhabi, U Arab Emirates; [Wang, Weiping] Chinese Acad Sci, Natl Engn Res Ctr Informat Secur, Inst Informat Engn, Beijing 100864, Peoples R China; [Wang, Weiping] Natl Engn Lab Informat Secur Technol, Beijing 100864, Peoples R China	Chinese Academy of Sciences; Institute of Information Engineering, CAS; Tianjin University; Washington University (WUSTL); Chinese Academy of Sciences	Liu, Y (corresponding author), Chinese Acad Sci, Inst Informat Engn, Beijing 100864, Peoples R China.	liuyong@iie.ac.cn; szliao@tju.edu.cn; shalijiang@gmail.com; lizhong.ding@inceptioniai.org; linhailun@iie.ac.cn; wangweiping@iie.ac.cn			National Natural Science Foundation of China [61703396, 61673293, 61602467]; Youth Innovation Promotion Association CAS; Science and Technology Project of Beijing [Z181100002718004]; National Key Research and Development Program of China [2016YFB1000604]; Excellent Talent Introduction of Institute of Information Engineering of CAS [Y7Z0111107]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Youth Innovation Promotion Association CAS; Science and Technology Project of Beijing; National Key Research and Development Program of China; Excellent Talent Introduction of Institute of Information Engineering of CAS	This work is supported in part by the National Natural Science Foundation of China (No.61703396, No.61673293, No.61602467), the Youth Innovation Promotion Association CAS, the Science and Technology Project of Beijing (Z181100002718004), the National Key Research and Development Program of China (2016YFB1000604), and the Excellent Talent Introduction of Institute of Information Engineering of CAS (Y7Z0111107).	Abbasnejad ME, 2012, KNOWL INF SYST, V31, P193, DOI 10.1007/s10115-011-0404-6; ALLEN DM, 1974, TECHNOMETRICS, V16, P125, DOI 10.2307/1267500; An SJ, 2007, PATTERN RECOGN, V40, P2154, DOI 10.1016/j.patcog.2006.12.015; [Anonymous], THESIS; [Anonymous], P 30 INT C MACH LEAR; [Anonymous], 2006, P NINTH SCANDINAVIAN; [Anonymous], 2002, LEARNING KERNELS; [Anonymous], P ADV LARG MARG CLAS; Bengio Y, 2004, J MACH LEARN RES, V5, P1089; Cawley GC, 2008, MACH LEARN, V71, P243, DOI 10.1007/s10994-008-5055-9; Cawley GC, 2007, J MACH LEARN RES, V8, P841; Cawley GC, 2006, IEEE IJCNN, P1661; Cawley GC, 2004, NEURAL NETWORKS, V17, P1467, DOI 10.1016/j.neunet.2004.07.002; Cawley GC, 2003, PATTERN RECOGN, V36, P2585, DOI 10.1016/S0031-3203(03)00136-5; Chang C.-C., 2011, ACM T INTEL SYST TEC, V2, P1, DOI [10.1145/1961189.1961199, DOI 10.1145/1961189.1961199]; Chapelle O, 2000, ADV NEUR IN, V12, P230; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Chapelle O, 2007, NEURAL COMPUT, V19, P1155, DOI 10.1162/neco.2007.19.5.1155; Christmann A, 2004, J MACH LEARN RES, V5, P1007; Christmann A., 2008, SUPPORT VECTOR MACHI; Christmann A, 2008, J MACH LEARN RES, V9, P915; Christmann A, 2007, BERNOULLI, V13, P799, DOI 10.3150/07-BEJ5102; Christmann A, 2012, COMPUT STAT DATA AN, V56, P854, DOI 10.1016/j.csda.2011.04.006; Christmann A, 2009, STAT INTERFACE, V2, P311; De Vito E, 2004, J MACH LEARN RES, V5, P1363; Debruyne M, 2008, J MACH LEARN RES, V9, P2377; Ding LZ, 2017, IEEE T CYBERNETICS, V47, P554, DOI 10.1109/TCYB.2016.2520582; Hable R, 2011, J MULTIVARIATE ANAL, V102, P993, DOI 10.1016/j.jmva.2011.01.009; Hampel FR., 2011, WILEY SERIES PROBABI; Josse J, 2012, COMPUT STAT DATA AN, V56, P1869, DOI 10.1016/j.csda.2011.11.012; Keerthi SS, 2002, IEEE T NEURAL NETWOR, V13, P1225, DOI 10.1109/TNN.2002.1031955; Koh PW, 2017, PR MACH LEARN RES, V70; Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1137; Liu Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2497; Liu Y, 2017, AAAI CONF ARTIF INTE, P2280; Liu Y, 2014, PR MACH LEARN RES, V32; Mao WT, 2014, NEURAL COMPUT APPL, V24, P441, DOI 10.1007/s00521-012-1234-5; Pedregosa F, 2016, PR MACH LEARN RES, V48; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; ROBINSON SM, 1991, MATH OPER RES, V16, P292, DOI 10.1287/moor.16.2.292; Saunders C., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P515; Seeger M., 2006, P ADV NEUR INF PROC, P1233; Seeger MW, 2008, J MACH LEARN RES, V9, P1147; STONE M, 1974, J R STAT SOC B, V36, P111, DOI 10.1111/j.2517-6161.1974.tb00994.x; Sundararajan S, 2001, NEURAL COMPUT, V13, P1103, DOI 10.1162/08997660151134343; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Van Messem A, 2010, ADV DATA ANAL CLASSI, V4, P199, DOI 10.1007/s11634-010-0067-2; Vapnik V, 2000, NEURAL COMPUT, V12, P2013, DOI 10.1162/089976600300015042; Vapnik V., 2000, NATURE STAT LEARNING; Wahba G, 2000, ADV NEUR IN, P297; Xu H, 2009, J MACH LEARN RES, V10, P1485; Yong Liu, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8725, P290, DOI 10.1007/978-3-662-44851-9_19	52	15	15	1	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2020	42	5					1083	1096		10.1109/TPAMI.2019.2892371	http://dx.doi.org/10.1109/TPAMI.2019.2892371			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LA0ZT	30640598				2022-12-18	WOS:000523685800006
J	Engelsma, JJ; Cao, K; Jain, AK				Engelsma, Joshua J.; Cao, Kai; Jain, Anil K.			RaspiReader: Open Source Fingerprint Reader	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Raspberry Pi; frustrated total internal reflection (FTIR); open source fingerprint readers; presentation attack detection; spoof detection; interoperability	LIVENESS; PERSPIRATION	We open source an easy to assemble, spoof resistant, high resolution, optical fingerprint reader, called RaspiReader, using ubiquitous components. By using our open source STL files and software, RaspiReader can be built in under one hour for only US $175. As such, RaspiReader provides the fingerprint research community a seamless and simple method for quickly prototyping new ideas involving fingerprint reader hardware. In particular, we posit that this open source fingerprint reader will facilitate the exploration of novel fingerprint spoof detection techniques involving both hardware and software. We demonstrate one such spoof detection technique by specially customizing RaspiReader with two cameras for fingerprint image acquisition. One camera provides high contrast, frustrated total internal reflection (FTIR) fingerprint images, and the other outputs direct images of the finger in contact with the platen. Using both of these image streams, we extract complementary information which, when fused together and used for spoof detection, results in marked performance improvement over previous methods relying only on grayscale FTIR images provided by COTS optical readers. Finally, fingerprint matching experiments between images acquired from the FTIR output of RaspiReader and images acquired from a COTS reader verify the interoperability of the RaspiReader with existing COTS optical readers.	[Engelsma, Joshua J.; Cao, Kai; Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Michigan State University	Engelsma, JJ (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.	engelsm7@cse.msu.edu; kaicao@cse.msu.edu; jain@cse.msu.edu			NIST Measurement Science program [70NANB17H027]; Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA RD Contract [2017 - 17020200004]	NIST Measurement Science program; Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA RD Contract	This research was supported by grant no. 70NANB17H027 from the NIST Measurement Science program and by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA R&D Contract No. 2017 - 17020200004. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, ofODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein.	Abhyankar A, 2009, PATTERN RECOGN, V42, P452, DOI 10.1016/j.patcog.2008.06.012; [Anonymous], 2012, UIDAI BIOMETRIC DEVI; [Anonymous], 2016, IARPA ODIN PROGRAM; [Anonymous], 2013, SECUREID NEWS MATCH; [Anonymous], 2016, UPI UNITED PAYMENTS; [Anonymous], 2012, REPORT HONG KONG CHI; [Anonymous], 2012, GOODIX LIVE FINGER D; Baldisserra D, 2006, LECT NOTES COMPUT SC, V3832, P265; Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286; Cao K., 2016, MSUCSE162; Choi JY, 2010, IEEE IMAGE PROC, P4541, DOI 10.1109/ICIP.2010.5653653; Chugh T, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P581, DOI 10.1109/BTAS.2017.8272745; Cignoni P., 2008, ERCIM NEWS, V73, P45, DOI DOI 10.2312/L0CALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPC0NF2008/129-136; Ding Y, 2016, ADV SOC SCI EDUC HUM, V49, P1; Engelsma JJ, 2018, IEEE T INF FOREN SEC, V13, P1564, DOI 10.1109/TIFS.2018.2797000; Ghiani L, 2013, INT CONF BIOMETR, DOI 10.1109/ICB.2013.6613027; Ghiani L, 2012, INT C PATT RECOG, P537; Ghiani L, 2012, LECT NOTES COMPUT SC, V7378, P210, DOI 10.1007/978-3-642-31567-1_21; Gragnaniello Diego, 2013, Proceedings of the 2013 IEEE Workshop on Biometric Measurements and Systems for Security and Medical Applications (BIOMS), P46, DOI 10.1109/BIOMS.2013.6656148; Gragnaniello D, 2015, PATTERN RECOGN, V48, P1050, DOI 10.1016/j.patcog.2014.05.021; Howard A.G., 2017, MOBILENETS EFFICIENT; ISO/IEC, 2016, 3010712016 ISOIEC; Jia XF, 2012, INT C PATT RECOG, P3001; Lapsley P. D., 1998, U.S. Patent, Patent No. [5737439, 5737439A]; Maltoni D., 2009, HDB FINGERPRINT RECO; Marasco E, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2617756; Marasco E, 2011, BIOSIGNALS 2011, P553; Marasco E, 2012, PATTERN RECOGN LETT, V33, P1148, DOI 10.1016/j.patrec.2012.01.009; Matsumoto T, 2002, P SOC PHOTO-OPT INS, V4677, P275, DOI 10.1117/12.462719; Menotti David, 2015, IEEE Transactions on Information Forensics and Security, V10, P864, DOI 10.1109/TIFS.2015.2398817; Mura V., 2015, P 7 IEEE INT C BIOM, P1; Nikam SB, 2008, INT J BIOMETRICS, V1, P141, DOI 10.1504/IJBM.2008.020141; Nixon KA., 2008, HDB BIOMETRICS, P403, DOI DOI 10.1007/978-0-387-71041-9_20; Nogueira RF, 2016, IEEE T INF FOREN SEC, V11, P1206, DOI 10.1109/TIFS.2016.2520880; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Rattani A., 2014, IEEE INT JOINT C BIO, P1; Rattani A, 2015, IEEE T INF FOREN SEC, V10, P2447, DOI 10.1109/TIFS.2015.2464772; Ross A, 2004, LECT NOTES COMPUT SC, V3087, P134; Rowe R. K., 2008, U.S. Patent, Patent No. [7 460 696, 7460696]; Schuckers S. A. C., 2002, INF SECUR TECH REP, V7, P56, DOI DOI 10.1016/S1363-4127(02)00407-7; Sepasian M, 2009, ELE COM ENG, P150; Shirastsuki A, 2005, P SOC PHOTO-OPT INS, V5686, P80, DOI 10.1117/12.590110; Tang JP, 2010, PROCEEDINGS OF INTERNATIONAL FORUM OF KNOWLEDGE AS A SERVICE, P1, DOI 10.1145/1852658.1852661; van der Putte T, 2000, INT FED INFO PROC, V52, P289; Watson C. I., 2015, 80342015 NIST, DOI [10.6028/NIST.IR.8034, DOI 10.6028/NIST.IR.8034, 10.6028/nist.ir.8034]; Yambay D., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P208, DOI 10.1109/ICB.2012.6199810; Yoon S, 2012, IEEE T PATTERN ANAL, V34, P451, DOI 10.1109/TPAMI.2011.161	47	15	15	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2019	41	10					2511	2524		10.1109/TPAMI.2018.2858764	http://dx.doi.org/10.1109/TPAMI.2018.2858764			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD1VC	30040627	Green Submitted, hybrid			2022-12-18	WOS:000489763000017
J	Wang, YQ; Li, LS; Dang, CY				Wang, Yongqiao; Li, Lishuai; Dang, Chuangyin			Calibrating Classification Probabilities with Shape-Restricted Polynomial Regression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Classification calibration; probability prediction; isotonic regression; semidefinite programming; polynomial regression		In many real-world classification problems, accurate prediction of membership probabilities is critical for further decision making. The probability calibration problem studies how to map scores obtained from one classification algorithm to membership probabilities. The requirement of non-decreasingness for this mapping involves an infinite number of inequality constraints, which makes its estimation computationally intractable. For the sake of this difficulty, existing methods failed to achieve four desiderata of probability calibration: universal flexibility, non-decreasingness, continuousness and computational tractability. This paper proposes a method with shape-restricted polynomial regression, which satisfies all four desiderata. In the method, the calibrating function is approximated with monotone polynomials, and the continuously-constrained requirement of monotonicity is equivalent to some semidefinite constraints. Thus, the calibration problem can be solved with tractable semidefinite programs. This estimator is both strongly and weakly universally consistent under a trivial condition. Experimental results on both artificial and real data sets clearly show that the method can greatly improve calibrating performance in terms of reliability-curve related measures.	[Wang, Yongqiao] Zhejiang Gongshang Univ, Sch Finance, Hangzhou 310018, Zhejiang, Peoples R China; [Li, Lishuai; Dang, Chuangyin] City Univ Hong Kong, Dept Syst Engn & Engn Management, Kowloon, 83 Tat Chee Ave, Hong Kong, Peoples R China	Zhejiang Gongshang University; City University of Hong Kong	Wang, YQ (corresponding author), Zhejiang Gongshang Univ, Sch Finance, Hangzhou 310018, Zhejiang, Peoples R China.	wangyq@zjsu.edu.cn; lishuai.li@cityu.edu.hk; mecdang@cityu.edu.hk	Li, Lishuai/K-8472-2014; Dang, Chuangyin/F-5964-2012	Li, Lishuai/0000-0002-0990-5119; Wang, Yongqiao/0000-0002-8345-9284; Dang, Chuangyin/0000-0003-4731-4616	National Natural Science Foundation of China [71571163]; Zhejiang Natural Science Foundation [LY19G010001]; Hong Kong Research Grant Council, Early Career Scheme [21202716]; Hong Kong Innovation and Technology Commission, Innovation & Technology Fund [ITS/151/16]; Hong Kong Research Grant Council of Hong Kong SAR Government [CityU 11302715]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Zhejiang Natural Science Foundation(Natural Science Foundation of Zhejiang Province); Hong Kong Research Grant Council, Early Career Scheme; Hong Kong Innovation and Technology Commission, Innovation & Technology Fund; Hong Kong Research Grant Council of Hong Kong SAR Government	The work was supported by National Natural Science Foundation of China (71571163), Zhejiang Natural Science Foundation (LY19G010001), Hong Kong Research Grant Council, Early Career Scheme (21202716), Hong Kong Innovation and Technology Commission, Innovation & Technology Fund (ITS/151/16). The work was partially supported by Hong Kong Research Grant Council: CityU 11302715 of Hong Kong SAR Government.	AYER M, 1955, ANN MATH STAT, V26, P641, DOI 10.1214/aoms/1177728423; BRUNK HD, 1955, ANN MATH STAT, V26, P607, DOI 10.1214/aoms/1177728420; CORDEIRO GM, 1991, J ROY STAT SOC B MET, V53, P629; COSSLETT SR, 1983, ECONOMETRICA, V51, P765, DOI 10.2307/1912157; DeVore R. A., 1993, CONSTRUCTIVE APPROXI; FRIEDMAN J, 1984, TECHNOMETRICS, V26, P243, DOI 10.2307/1267550; FRITSCH FN, 1980, SIAM J NUMER ANAL, V17, P238, DOI 10.1137/0717021; Gonzaga C. C., 2006, SIAM J OPTIMIZ, V2, P349; Grant M., 2014, CVX MATLAB SOFTWARE; Hall P, 2001, ANN STAT, V29, P624; Hastie T, 1998, ADV NEUR IN, V10, P507; He XM, 1999, COMPUTATION STAT, V14, P315, DOI 10.1007/s001800050019; HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503; HETTICH R, 1993, SIAM REV, V35, P380, DOI 10.1137/1035089; HILDRETH C, 1954, J AM STAT ASSOC, V49, P598, DOI 10.2307/2281132; Jiang XQ, 2012, J AM MED INFORM ASSN, V19, P263, DOI 10.1136/amiajnl-2011-000291; Jiang Xiaoqian, 2011, AMIA Jt Summits Transl Sci Proc, V2011, P16; Kim SJ, 2009, SIAM REV, V51, P339, DOI 10.1137/070690274; KING G, 2001, POLITICAL ANAL, V0009; Lanza A, 2011, IEEE T PATTERN ANAL, V33, P1894, DOI 10.1109/TPAMI.2011.42; Leathart T, 2017, P MACH LEARN RES, V77, P145; Liang Percy S, 2015, NIPS; Lorentz G., 1996, CONSTR APPROX, V304, DOI New York; MAZUMDER R, 2018, J AM STAT ASS; Menon Aditya Krishna, 2012, Proc Int Conf Mach Learn, V2012, P703; Naeini MP, 2018, KNOWL INF SYST, V54, P151, DOI 10.1007/s10115-017-1133-2; Naeini Mahdi Pakdaman, 2015, Proc SIAM Int Conf Data Min, V2015, P208; Naeini Mahdi Pakdaman, 2016, Proc SIAM Int Conf Data Min, V2016, P261, DOI 10.1137/1.9781611974348.30; Naeini MP, 2015, AAAI CONF ARTIF INTE, P2901; Naeini MP, 2016, IEEE DATA MINING, P360, DOI [10.1109/ICDM.2016.0047, 10.1109/ICDM.2016.96]; Nesterov Y., 1994, STUD APPL MATH, V13; Nesterov Y., 2000, HIGH PERFORMANCE OPT, V33, P405, DOI [DOI 10.1007/978-1-4757-3216-0_17, 10.1007/978-1-4757-3216-017, DOI 10.1007/978-1-4757-3216-017]; Niculescu-Mizil Alexandru, 2005, P 22 INT C MACHINE L, P625, DOI 10.1145/1102351.1102430; Ozdemir O, 2018, IEEE T PATTERN ANAL, V40, P2740, DOI 10.1109/TPAMI.2017.2774300; Painsky A, 2016, IEEE T PATTERN ANAL, V38, P308, DOI 10.1109/TPAMI.2015.2441063; Platt JC, 2000, ADV NEUR IN, P61; Reemtsen R., 1998, SEMIINFINITE PROGRAM, V25; Vovk V., 2015, ADV NEURAL INFORM PR, P892; Wang J, 2012, COMPUT STAT DATA AN, V56, P2729, DOI 10.1016/j.csda.2012.02.018; Wang X, 2008, J COMPUT GRAPH STAT, V17, P21, DOI 10.1198/106186008X285627; Wang YQ, 2014, EUR J OPER RES, V232, P671, DOI 10.1016/j.ejor.2013.06.049; Wang YQ, 2012, KNOWL-BASED SYST, V30, P87, DOI 10.1016/j.knosys.2011.12.010; Zadrozny Bianca, 2001, ICML; Zhong Leon Wenliang, 2013, P 23 INT JOINT C ART, P1939; Zhu LH, 2017, 2017 IEEE SECOND INTERNATIONAL CONFERENCE ON DATA SCIENCE IN CYBERSPACE (DSC), P213, DOI 10.1109/DSC.2017.89	47	15	16	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2019	41	8					1813	1827		10.1109/TPAMI.2019.2895794	http://dx.doi.org/10.1109/TPAMI.2019.2895794			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IG2BD	30703012				2022-12-18	WOS:000473598800003
J	Yu, L; Yang, TY; Chan, AB				Yu, Lei; Yang, Tianyu; Chan, Antoni B.			Density-Preserving Hierarchical EM Algorithm: Simplifying Gaussian Mixture Models for Approximate Inference	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Density simplification; likelihood approximation; Gaussian mixture model; recursive Bayesian filtering	VISUAL TRACKING; OBJECT TRACKING; TUTORIAL	We propose an algorithm for simplifying a finite mixture model into a reduced mixture model with fewer mixture components. The reduced model is obtained by maximizing a variational lower bound of the expected log-likelihood of a set of virtual samples. We develop three applications for our mixture simplification algorithm: recursive Bayesian filtering using Gaussian mixture model posteriors, KDE mixture reduction, and belief propagation without sampling. For recursive Bayesian filtering, we propose an efficient algorithm for approximating an arbitrary likelihood function as a sum of scaled Gaussian. Experiments on synthetic data, human location modeling, visual tracking, and vehicle self-localization show that our algorithm can be widely used for probabilistic data analysis, and is more accurate than other mixture simplification methods.	[Yu, Lei; Yang, Tianyu; Chan, Antoni B.] City Univ Hong Kong, Dept Comp Sci, Kowloon Tong, Hong Kong, Peoples R China	City University of Hong Kong	Yu, L (corresponding author), City Univ Hong Kong, Dept Comp Sci, Kowloon Tong, Hong Kong, Peoples R China.	leiyu6-c@my.cityu.edu.hk; tianyyang8-c@my.cityu.edu.hk; abchan@cityu.edu.hk	; CHAN, Antoni B./D-7858-2013	Yang, Tianyu/0000-0002-9674-5220; CHAN, Antoni B./0000-0002-2886-2513	Research Grants Council of the Hong Kong SAR, China [CityU 110513]	Research Grants Council of the Hong Kong SAR, China(Hong Kong Research Grants Council)	The authors would like to thank: A Ihler and M Mandel for KDE toolbox; E Cho, SA Myers and J Leskovec for the Gowalla dataset in [63]; Y Wu, J Lim and MH Yang for the tracking dataset and codes in [66]; K Zhang, L Zhang and MH Yang for the codes in [64]; MA Brubaker, A Geiger and R Urtasun for the dataset and codes for self-localization in [21]. This work was supported by the Research Grants Council of the Hong Kong SAR, China (CityU 110513).	Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881; Bardet F, 2009, IEEE I CONF COMP VIS, P1623, DOI 10.1109/ICCV.2009.5459367; Baron D, 2010, IEEE T SIGNAL PROCES, V58, P269, DOI 10.1109/TSP.2009.2027773; Brubaker MA, 2016, IEEE T PATTERN ANAL, V38, P652, DOI 10.1109/TPAMI.2015.2453975; Bruneau P, 2010, PATTERN RECOGN, V43, P850, DOI 10.1016/j.patcog.2009.08.006; Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61; Cham T.-J., 1999, P IEEE C COMP VIS PA; Chen Z, 2003, STATISTICS-ABINGDON, V182, P1, DOI [10.1080/02331880309257, DOI 10.1080/02331880309257]; Cho E., 2011, SIGKDD, P1082, DOI [10.1145/2020408.2020579, DOI 10.1145/2020408.2020579]; Coughlan JM, 2002, LECT NOTES COMPUT SC, V2352, P453; Coviello E, 2014, J MACH LEARN RES, V15, P697; Coviello E, 2012, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2012.6247900; Csiszar I., 1984, STAT DECISIONS, V1, P205; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dhillon J., 2007, P INT C NEUR INF PRO; Ellis K., 2011, P 12 INT SOC MUS INF, P723; Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138; Gershman SJ, 2012, J MATH PSYCHOL, V56, P1, DOI 10.1016/j.jmp.2011.08.004; Goldberger J., 2004, P INT C NEURAL INFOR, P505; Hershey JR, 2007, INT CONF ACOUST SPEE, P317, DOI 10.1109/icassp.2007.366913; Hong S, 2014, LECT NOTES COMPUT SC, V8689, P1, DOI 10.1007/978-3-319-10590-1_1; Ihler A., 2009, P AISTATS, V5, P256; Ihler AT, 2005, IEEE J SEL AREA COMM, V23, P809, DOI 10.1109/JSAC.2005.843548; Isard M., 2009, P NEUR INF PROC SYST, P737; Jaakkola TS, 2001, NEU INF PRO, P129; Jebara T, 2007, LECT NOTES ARTIF INT, V4701, P164; Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Kwak S, 2011, IEEE I CONF COMP VIS, P2174, DOI 10.1109/ICCV.2011.6126494; Li Y, 2015, IEEE I CONF COMP VIS, P4006, DOI 10.1109/ICCV.2015.456; Lichman M, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P35, DOI 10.1145/2623330.2623681; Ma YT, 2016, IEEE T SIGNAL PROCES, V64, P5611, DOI 10.1109/TSP.2016.2599484; McLachlan GJ, 2004, FINITE MIXTURE MODEL, DOI [10.1002/0471721182, DOI 10.1002/0471721182]; Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623; Muller O, 2013, IEEE I CONF COMP VIS, P1129, DOI 10.1109/ICCV.2013.144; Mumtaz A, 2013, IEEE T PATTERN ANAL, V35, P1606, DOI 10.1109/TPAMI.2012.236; Oron S, 2015, INT J COMPUT VISION, V111, P213, DOI 10.1007/s11263-014-0740-6; Perez P, 2002, LECT NOTES COMPUT SC, V2350, P661; Psiaki ML, 2016, IEEE T SIGNAL PROCES, V64, P5499, DOI 10.1109/TSP.2016.2595503; Psiaki ML, 2015, J GUID CONTROL DYNAM, V38, P292, DOI 10.2514/1.G000541; Ravichandran A, 2009, PROC CVPR IEEE, P1651, DOI 10.1109/CVPRW.2009.5206847; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Sadilek A, 2012, ICWSM, P322, DOI DOI 10.1109/RTEICT.2016.7808045; Scott DW, 2015, MULTIVARIATE DENSITY; Sigal L, 2012, INT J COMPUT VISION, V98, P15, DOI 10.1007/s11263-011-0493-4; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; Sudderth EB, 2010, COMMUN ACM, V53, P95, DOI 10.1145/1831407.1831431; Titterington DM, 1985, STAT ANAL FINITE MIX; Vaca-Castano G, 2012, PROC CVPR IEEE, P1186, DOI 10.1109/CVPR.2012.6247800; Varas D, 2014, PROC CVPR IEEE, P3470, DOI 10.1109/CVPR.2014.444; Vasconcelos N., 2001, Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001, pI, DOI 10.1109/CVPR.2001.990449; Vasconcelos N., 1998, NIPS, P606; Vaughan-Nichols SJ, 2009, COMPUTER, V42, P14, DOI 10.1109/MC.2009.65; Wainwright MJ, 2008, FOUND TRENDS MACH LE, V1, P1, DOI 10.1561/2200000001; Wang D, 2014, PROC CVPR IEEE, P3478, DOI 10.1109/CVPR.2014.445; Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307; Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Zamir AR, 2010, LECT NOTES COMPUT SC, V6314, P255, DOI 10.1007/978-3-642-15561-1_19; Zhang K, 2010, IEEE T NEURAL NETWOR, V21, P644, DOI 10.1109/TNN.2010.2040835; Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62; Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908; Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227	66	15	16	6	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2019	41	6					1323	1337		10.1109/TPAMI.2018.2845371	http://dx.doi.org/10.1109/TPAMI.2018.2845371			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HW9UU	29994194				2022-12-18	WOS:000467037000004
J	Ozdemir, O; Allen, TG; Choi, S; Wimalajeewa, T; Varshney, PK				Ozdemir, Onur; Allen, Thomas G.; Choi, Sora; Wimalajeewa, Thakshila; Varshney, Pramod K.			Copula Based Classifier Fusion Under Statistical Dependence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Copulas; classification; probability score fusion; statistical dependence	DECISIONS	We consider the problem of fusing probability scores from a set of classifiers to estimate a final fused probability score. Our interest is in scenarios where the classifiers are statistically dependent. To that end, we propose a new classifier fusion approach that is data driven and founded on the statistical theory of copulas. Numerical results with both simulated and real data show that our copula based classifier fusion approach produces better probability scores than individual classifiers and outperforms existing probability score fusion approaches.	[Ozdemir, Onur; Allen, Thomas G.] Boston Fus Corp, Lexington, MA 02421 USA; [Ozdemir, Onur] Draper Lab, Cambridge, MA 02139 USA; [Allen, Thomas G.] Syst & Technol Res, Woburn, MA 01801 USA; [Choi, Sora] Syracuse Univ, Syracuse, NY 13244 USA; [Choi, Sora] Delphi Elect & Safety, Kokomo, IN 46902 USA; [Wimalajeewa, Thakshila; Varshney, Pramod K.] Syracuse Univ, Dept Elect Engn & Comp Sci, Syracuse, NY 13244 USA	Syracuse University; Delphi; Syracuse University	Ozdemir, O (corresponding author), Boston Fus Corp, Lexington, MA 02421 USA.; Ozdemir, O (corresponding author), Draper Lab, Cambridge, MA 02139 USA.	oozdemir@syr.edu; allen@alum.mit.edu; schoi101@syr.edu; twwewelw@syr.edu; varshney@syr.edu	Wimalajeewa, Thakshila/ABI-3531-2020	Varshney, Pramod/0000-0003-4504-5088	DARPA SMISC program	DARPA SMISC program	The authors would like to thank Elizabeth Benagh and Francis O'Donovan for their assistance with the collection of Twitter data and extraction of user features. This work was in part sponsored by the DARPA SMISC program. Approved for Public Release, 16-MDA-8938 (8 December 16).	Allard D, 2012, MATH GEOSCI, V44, P545, DOI 10.1007/s11004-012-9396-3; Berkes P., 2009, P INT C ADV NEUR INF, P129; Brunel N, 2005, INT CONF ACOUST SPEE, P717; Casella G, 2002, DUXBURY; Davy M, 2003, IEEE SIGNAL PROC LET, V10, P215, DOI 10.1109/LSP.2003.811636; DEGROOT MH, 1983, J ROY STAT SOC D-STA, V32, P12; Elidan Gal, 2013, COPULAE MATH QUANTIT, P39; Iyengar SG, 2007, CONFERENCE RECORD OF THE FORTY-FIRST ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1-5, P2248; Iyengar SG, 2012, IEEE T SIGNAL PROCES, V60, P4888, DOI 10.1109/TSP.2012.2202113; Iyengar SG, 2011, IEEE T SIGNAL PROCES, V59, P2308, DOI 10.1109/TSP.2011.2105483; Iyengar SG, 2010, INT CONF ACOUST SPEE, P505, DOI 10.1109/ICASSP.2010.5495664; Joe H., 1996, 166 U BRIT COL DEP S; Joe H, 2014, DEPENDENCE MODELING; Jouini MN, 1996, OPER RES, V44, P444, DOI 10.1287/opre.44.3.444; Krylov VA, 2011, IEEE J-STSP, V5, P554, DOI 10.1109/JSTSP.2010.2103925; Lee K., 2011, P INT AAAI C WEB SOC, V5, P185; Mercier G, 2007, INT GEOSCI REMOTE SE, P2394, DOI 10.1109/IGARSS.2007.4423324; Nelsen R. B., 2007, INTRO COPULAS; Ozdemir O., 2015, P SPIE MULT MULT INF, V9498; Paz D. L, 2013, P INT C MACH LEARN; Ranjan R, 2010, J R STAT SOC B, V72, P71, DOI 10.1111/j.1467-9868.2009.00726.x; Satopaa VA, 2014, INT J FORECASTING, V30, P344, DOI 10.1016/j.ijforecast.2013.09.009; Sklar A., 1959, PUBLICATIONS I STAT, V8, P229, DOI DOI 10.1007/978-3-642-33590-7; STONE M, 1961, ANN MATH STAT, V32, P1339, DOI 10.1214/aoms/1177704873; Subramanian A., 2011, 14 INT C INF FUS, P1; Sundaresan A, 2011, IEEE T AERO ELEC SYS, V47, P454, DOI 10.1109/TAES.2011.5705686; Tran Dustin, 2015, P NIPS 15, P3564; Wilson KJ, 2017, INT J FORECASTING, V33, P325, DOI 10.1016/j.ijforecast.2015.11.014	29	15	15	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2018	40	11					2740	2748		10.1109/TPAMI.2017.2774300	http://dx.doi.org/10.1109/TPAMI.2017.2774300			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GW2AF	29990102				2022-12-18	WOS:000446683700016
J	Agudo, A; Moreno-Noguer, F				Agudo, Antonio; Moreno-Noguer, Francesc			Force-Based Representation for Non-Rigid Shape and Elastic Model Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Non-rigid structure from motion; 3D reconstruction; expectation maximization; elastic model; force space	STRUCTURE-FROM-MOTION; 3D RECONSTRUCTION	This paper addresses the problem of simultaneously recovering 3D shape, pose and the elastic model of a deformable object from only 2D point tracks in a monocular video. This is a severely under-constrained problem that has been typically addressed by enforcing the shape or the point trajectories to lie on low-rank dimensional spaces. We show that formulating the problem in terms of a low-rank force space that induces the deformation and introducing the elastic model as an additional unknown, allows for a better physical interpretation of the resulting priors and a more accurate representation of the actual object's behavior. In order to simultaneously estimate force, pose, and the elastic model of the object we use an expectation maximization strategy, where each of these parameters are successively learned by partial M-steps. Once the elastic model is learned, it can be transfered to similar objects to code its 3D deformation. Moreover, our approach can robustly deal with missing data, and encode both rigid and non-rigid points under the same formalism. We thoroughly validate the approach on Mocap and real sequences, showing more accurate 3D reconstructions than state-of-the-art, and additionally providing an estimate of the full elastic model with no a priori information.	[Agudo, Antonio; Moreno-Noguer, Francesc] UPC, CSIC, Inst Robot & Informat Ind, Barcelona 08028, Spain	Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Institut de Robotica i Informatica Industrial (IRII); Universitat Politecnica de Catalunya	Agudo, A (corresponding author), UPC, CSIC, Inst Robot & Informat Ind, Barcelona 08028, Spain.	aagudo@iri.upc.edu; fmoreno@iri.upc.edu	Agudo, Antonio/C-5147-2017	Agudo, Antonio/0000-0001-6845-4998	Spanish Ministry of Science and Innovation under project RobInstruct [TIN2014-58178-R]; Google Faculty Award; Spanish State Research Agency through the Maria de Maeztu Seal of Excellence [MDM-2016-0656]	Spanish Ministry of Science and Innovation under project RobInstruct(Ministry of Science and Innovation, Spain (MICINN)); Google Faculty Award(Google Incorporated); Spanish State Research Agency through the Maria de Maeztu Seal of Excellence(Spanish Government)	This work has been partially supported by the Spanish Ministry of Science and Innovation under project RobInstruct TIN2014-58178-R; and by a Google Faculty Award. This work is also supported by the Spanish State Research Agency through the Maria de Maeztu Seal of Excellence to IRI MDM-2016-0656. We thank Paulo Gotardo for making the ASL dataset publicly available.	Agudo A., 2014, P BR MACH VIS C; Agudo A., 2016, P IEEE WINT C APPL C, P1; Agudo A, 2017, J MATH IMAGING VIS, V57, P75, DOI 10.1007/s10851-016-0668-2; Agudo A, 2016, IEEE T PATTERN ANAL, V38, P979, DOI 10.1109/TPAMI.2015.2469293; Agudo A, 2015, IEEE I CONF COMP VIS, P756, DOI 10.1109/ICCV.2015.93; Agudo A, 2015, PROC CVPR IEEE, P2179, DOI 10.1109/CVPR.2015.7298830; Agudo A, 2014, PROC CVPR IEEE, P1558, DOI 10.1109/CVPR.2014.202; Agudo A, 2012, PROC CVPR IEEE, P1418; Akhter Ijaz, 2008, ADV NEURAL INFORM PR, P41; Barbic J, 2005, ACM T GRAPHIC, V24, P982, DOI 10.1145/1073204.1073300; Bathe Klaus Jurgen., 1982, J PRESS VESSEL TECHN; Becker M., 2007, VISUAL COMPUT, V24, P963; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Bouman KL, 2013, IEEE I CONF COMP VIS, P1984, DOI 10.1109/ICCV.2013.455; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Brubaker MA, 2009, IEEE I CONF COMP VIS, P2389, DOI 10.1109/ICCV.2009.5459407; Dai YC, 2012, PROC CVPR IEEE, P2018, DOI 10.1109/CVPR.2012.6247905; Davis A, 2015, PROC CVPR IEEE, P5335, DOI 10.1109/CVPR.2015.7299171; Del Bue A, 2006, P IEEE C COMP VIS PA, V1, P1191; Eskandari H, 2011, INVERSE PROBL, V27, DOI 10.1088/0266-5611/27/8/085002; Fayad J., 2009, P BR MACH VIS C; Fayad J, 2010, LECT NOTES COMPUT SC, V6314, P297, DOI 10.1007/978-3-642-15561-1_22; Fragkiadaki Katerina, 2014, ADV NEURAL INFORM PR, P55; Garg R, 2013, PROC CVPR IEEE, P1272, DOI 10.1109/CVPR.2013.168; Garg R, 2013, INT J COMPUT VISION, V104, P286, DOI 10.1007/s11263-012-0607-7; Gotardo P. F. U., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3065, DOI 10.1109/CVPR.2011.5995560; Gotardo PFU, 2011, IEEE I CONF COMP VIS, P802, DOI 10.1109/ICCV.2011.6126319; HIGHAM NJ, 1988, LINEAR ALGEBRA APPL, V103, P103, DOI 10.1016/0024-3795(88)90223-6; Hwangbo M, 2008, IEEE INT CONF ROBOT, P1306, DOI 10.1109/ROBOT.2008.4543384; Lee M, 2017, IEEE T PATTERN ANAL, V39, P1388, DOI 10.1109/TPAMI.2016.2596720; Lee M, 2014, PROC CVPR IEEE, P1550, DOI 10.1109/CVPR.2014.201; Magnus J. R., 1988, WILEY SERIES PROBABI; Malti A, 2015, PROC CVPR IEEE, P1629, DOI 10.1109/CVPR.2015.7298771; Malti A, 2013, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2013.200; Marques M., 2008, P IEEE WORKSH MOT VI, P1; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; Moreno-Noguer F, 2011, PROC CVPR IEEE, P1289, DOI 10.1109/CVPR.2011.5995532; Paladini Marco, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2898, DOI 10.1109/CVPRW.2009.5206602; PALADINI M, 2010, P 11 EUR C COMP, V6312, P15; Park HS, 2010, LECT NOTES COMPUT SC, V6313, P158; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P730, DOI 10.1109/34.85661; Roweis S, 1998, ADV NEUR IN, V10, P626; Russell C., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3009, DOI 10.1109/CVPR.2011.5995383; Salzmann M, 2011, IEEE I CONF COMP VIS, P2064, DOI 10.1109/ICCV.2011.6126480; Sayd P., 2008, P IEEE C COMP VIS PA, P1; Sclaroff S., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P158, DOI 10.1109/MNRAO.1994.346241; Simon T, 2014, LECT NOTES COMPUT SC, V8691, P204, DOI 10.1007/978-3-319-10578-9_14; Syllebranque C, 2008, VISUAL COMPUT, V24, P963, DOI 10.1007/s00371-008-0273-5; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torresani L, 2004, ADV NEUR IN, V16, P1555; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Tsap LV, 2000, IEEE T PATTERN ANAL, V22, P526, DOI 10.1109/34.857007; Valmadre J, 2012, PROC CVPR IEEE, P1394, DOI 10.1109/CVPR.2012.6247826; Vicente S, 2012, LECT NOTES COMPUT SC, V7574, P426, DOI 10.1007/978-3-642-33712-3_31; White R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239485; Woodbury M.A., 1950, 42 PRINC U; Wuhrer S, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P1, DOI 10.1109/3DIMPVT.2012.16; Xiao J, 2004, PROC CVPR IEEE, P535; Zhu YY, 2014, PROC CVPR IEEE, P1542, DOI 10.1109/CVPR.2014.200; Zhu YN, 2003, IEEE T MED IMAGING, V22, P890, DOI 10.1109/TMI.2003.815065	61	15	15	1	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2018	40	9					2137	2150		10.1109/TPAMI.2017.2752710	http://dx.doi.org/10.1109/TPAMI.2017.2752710			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GP4UX	28922113	Green Submitted			2022-12-18	WOS:000440868400008
J	Soleimani, H; Hensman, J; Saria, S				Soleimani, Hossein; Hensman, James; Saria, Suchi			Scalable Joint Models for Reliable Uncertainty-Aware Event Prediction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Uncertainty-aware prediction; missing data; scalable Gaussian processes; survival analysis; joint modeling; time series	THERAPY; RISK	Missing data and noisy observations pose significant challenges for reliably predicting events from irregularly sampled multivariate time series (longitudinal) data. Imputation methods, which are typically used for completing the data prior to event prediction, lack a principled mechanism to account for the uncertainty due to missingness. Alternatively, state-of-the-art joint modeling techniques can be used for jointly modeling the longitudinal and event data and compute event probabilities conditioned on the longitudinal observations. These approaches, however, make strong parametric assumptions and do not easily scale to multivariate signals with many observations. Our proposed approach consists of several key innovations. First, we develop a flexible and scalable joint model based upon sparse multiple-output Gaussian processes. Unlike state-of-the-art joint models, the proposed model can explain highly challenging structure including non-Gaussian noise while scaling to large data. Second, we derive an optimal policy for predicting events using the distribution of the event occurrence estimated by the joint model. The derived policy trades-off the cost of a delayed detection versus incorrect assessments and abstains from making decisions when the estimated event probability does not satisfy the derived confidence criteria. Experiments on a large dataset show that the proposed framework significantly outperforms state-of-the-art techniques in event prediction.	[Soleimani, Hossein; Saria, Suchi] Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA; [Hensman, James] Univ Lancaster, Div Med, Lancaster LA1 4YB, England	Johns Hopkins University; Lancaster University	Soleimani, H (corresponding author), Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA.	hsoleimani@jhu.edu; james.hensman@lancaster.ac.uk; ssaria@cs.jhu.edu			Div Of Information & Intelligent Systems [1418590] Funding Source: National Science Foundation	Div Of Information & Intelligent Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))		Abadi M, 2015, P 12 USENIX S OPERAT; Alaa A. M., 2016, P INT C MACH LEARN W; Alvarez MA, 2011, J MACH LEARN RES, V12, P1459; [Anonymous], 2001, MISSING DATA; Bartlett PL, 2008, J MACH LEARN RES, V9, P1823; Billingsley P., 2008, PROBABILITY MEASURE; BYRD RH, 1995, SIAM J SCI COMPUT, V16, P1190, DOI 10.1137/0916069; Chow CK., 1957, IRE T ELECT COMPUTER, VEC-6, P247, DOI DOI 10.1109/TEC.1957.5222035; Enders C. K., 2010, APPL MISSING DATA AN; Fernandez T., 2016, ADV NEURAL INFORM PR; Futoma J., 2016, C UNC ART INT, P222; Ghassemi M, 2015, AAAI CONF ARTIF INTE, P446; Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215; Golfarelli M, 1997, IEEE T PATTERN ANAL, V19, P786, DOI 10.1109/34.598237; Gunawardana A., 2011, ADV NEURAL INFORM PR, P1962; Henry KE, 2015, SCI TRANSL MED, V7, DOI 10.1126/scitranslmed.aab3719; Hensman J, 2015, P INT C ART INT STAT, V38, P1; Hensman J., 2016, ARXIV161106740; Hensman J., 2013, P 20 9 C UNCERTAINTY, P282, DOI DOI 10.1093/IMAIAI/IAX023; Hensman James, 2016, GPFLOW; Joensuu H, 2012, LANCET ONCOL, V13, P265, DOI 10.1016/S1470-2045(11)70299-6; Journel A.G., 1978, MINING GEOSTATISTICS; Kalbfleisch J.D., 2011, STAT ANAL FAILURE TI, DOI DOI 10.1016/0197-2456(81)90009-X; Kingma D.P, P 3 INT C LEARNING R; Kumar A, 2006, CRIT CARE MED, V34, P1589, DOI 10.1097/01.CCM.0000217961.75225.E9; Lasko TA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0066341; Lazaro-Gredilla M., 2009, ADV NEURAL INFORM PR, V22, P1087; Li, 2016, ADV NEURAL INFORM PR, P1804; Lipton Z.C., 2016, MACH LEARN HEALTHCAR, V56; Little R., 2014, STAT ANAL MISSING DA, V2; Liu ZT, 2016, AAAI CONF ARTIF INTE, P1273; Matthews AGD, 2016, JMLR WORKSH CONF PRO, V51, P231; Hoai M, 2014, INT J COMPUT VISION, V107, P191, DOI 10.1007/s11263-013-0683-3; Osborne M., 2012, ADV NEURAL INF PROCE, V25, P1; Parrish N, 2013, J MACH LEARN RES, V14, P3561; Pelkonen T, 2015, PROC VLDB ENDOW, V8, P1816; Poor, 2013, INTRO SIGNAL DETECTI; Proust-Lima C, 2016, STAT MED, V35, P382, DOI 10.1002/sim.6731; Proust-Lima C, 2014, STAT METHODS MED RES, V23, P74, DOI 10.1177/0962280212445839; Quinn JA, 2009, IEEE T PATTERN ANAL, V31, P1537, DOI 10.1109/TPAMI.2008.191; Ranganath R., 2016, P MACH LEARN HEALTHC, P1; Ranganath R, 2015, JMLR WORKSH CONF PRO, V38, P762; Rivers E, 2001, NEW ENGL J MED, V345, P1368, DOI 10.1056/NEJMoa010307; Rizopoulos D, 2012, CH CRC BIOSTAT SER, P1, DOI 10.1201/b12208; Rizopoulos D, 2014, J AM STAT ASSOC, V109, P1385, DOI 10.1080/01621459.2014.931236; Rizopoulos D, 2011, BIOMETRICS, V67, P819, DOI 10.1111/j.1541-0420.2010.01546.x; Rizopoulos D, 2010, J STAT SOFTW, V35, P1; RUBIN DB, 1976, BIOMETRIKA, V63, P581, DOI 10.2307/2335739; Sangnier M, 2016, P INT C MACH LEARN, P2310; Saul A. D., 2016, P INT C ART INT STAT, P1; SCHEIN RMH, 1990, CHEST, V98, P1388, DOI 10.1378/chest.98.6.1388; Schulam P., 2015, NIPS; Seeger M., 2005, EPFLREPORT161465; Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899; Sehulam P, 2016, J MACH LEARN RES, V17, P1; Smith AF, 1998, RESUSCITATION, V37, P133, DOI 10.1016/S0300-9572(98)00056-2; Stanculescu I, 2014, IEEE J BIOMED HEALTH, V18, P1560, DOI 10.1109/JBHI.2013.2294692; Sweeting MJ, 2011, BIOMETRICAL J, V53, P750, DOI 10.1002/bimj.201100052; Titsias M. K., 2009, P INT C ART INT STAT, P1; Tsiatis AA, 2004, STAT SINICA, V14, P809; van Houwelingen HC, 2007, SCAND J STAT, V34, P70, DOI 10.1111/j.1467-9469.2006.00529.x; van Houwelingen JC., 2012, DYNAMIC PREDICTION C; Verbeke G, 2009, SPRINGER SER STAT, P1; Wu M, 2017, J AM MED INFORM ASSN, V24, P488, DOI 10.1093/jamia/ocw138; Young R, 2015, J MARRIAGE FAM, V77, P277, DOI 10.1111/jomf.12144	66	15	15	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2018	40	8					1948	1963		10.1109/TPAMI.2017.2742504	http://dx.doi.org/10.1109/TPAMI.2017.2742504			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GL6DT	28841550	Bronze, Green Submitted			2022-12-18	WOS:000437271100012
J	Do, TT; Cheung, NM				Do, Thanh-Toan; Cheung, Ngai-Man			Embedding Based on Function Approximation for Large Scale Image Search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image search; function approximation; feature embedding	QUANTIZATION; DESCRIPTORS	The objective of this paper is to design an embedding method that maps local features describing an image (e.g., SIFT) to a higher dimensional representation useful for the image retrieval problem. First, motivated by the relationship between the linear approximation of a nonlinear function in high dimensional space and the state-of-the-art feature representation used in image retrieval, i.e., VLAD, we propose a new approach for the approximation. The embedded vectors resulted by the function approximation process are then aggregated to form a single representation for image retrieval. Second, in order to make the proposed embedding method applicable to large scale problem, we further derive its fast version in which the embedded vectors can be efficiently computed, i.e., in the closed-form. We compare the proposed embedding methods with the state of the art in the context of image search under various settings: when the images are represented by medium length vectors, short vectors, or binary vectors. The experimental results show that the proposed embedding methods outperform existing the state of the art on the standard public image retrieval benchmarks.	[Do, Thanh-Toan; Cheung, Ngai-Man] Singapore Univ Technol & Design, Singapore 487372, Singapore; [Do, Thanh-Toan] Univ Adelaide, Adelaide, SA 5005, Australia	Singapore University of Technology & Design; University of Adelaide	Do, TT (corresponding author), Singapore Univ Technol & Design, Singapore 487372, Singapore.; Do, TT (corresponding author), Univ Adelaide, Adelaide, SA 5005, Australia.	thanh-toan.do@adelaide.edu.au; ngaiman_cheung@sutd.edu.sg						Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38; Boureau Y.L., 2010, P 27 INT C MACH LEAR, P111; Boyd S., 2004, CONVEX OPTIMIZATION, P528; Carreira-Perpinan MA, 2015, PROC CVPR IEEE, P557, DOI 10.1109/CVPR.2015.7298654; Chen DM, 2014, IEEE MULTIMEDIA, V21, P14, DOI 10.1109/MMUL.2013.46; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Cimpoi M, 2015, PROC CVPR IEEE, P3828, DOI 10.1109/CVPR.2015.7299007; Coleman TF, 1996, SIAM J OPTIMIZ, V6, P418, DOI 10.1137/0806023; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Delhumeau Jonathan, 2013, ACM MM, P653, DOI DOI 10.1145/2502081.2502171; Duan LY, 2015, IEEE T MULTIMEDIA, V17, P828, DOI 10.1109/TMM.2015.2419973; Folland GB., 2002, ADV CALCULUS; Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Jegou H, 2014, PROC CVPR IEEE, P3310, DOI 10.1109/CVPR.2014.417; Jegou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jegou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609; Jia Y., 2014, CORR; Kalantidis Y, 2014, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR.2014.298; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Murray N, 2014, PROC CVPR IEEE, P2473, DOI 10.1109/CVPR.2014.317; Negrel R, 2014, IEEE IMAGE PROC, P2192, DOI 10.1109/ICIP.2014.7025444; Negrel R, 2013, IEEE MULTIMEDIA, V20, P24, DOI 10.1109/MMUL.2013.14; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Paulin M., 2016, CORR; Perronnin F., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383266; PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009; Perronnin F, 2015, PROC CVPR IEEE, P3743, DOI 10.1109/CVPR.2015.7298998; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Phillips J. C., 2008, P 2008 ACM IEEE C SU, P8; Picard D, 2011, IEEE IMAGE PROC, P669, DOI 10.1109/ICIP.2011.6116641; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Do TT, 2016, LECT NOTES COMPUT SC, V9909, P219, DOI 10.1007/978-3-319-46454-1_14; Do TT, 2015, PROC CVPR IEEE, P3556, DOI 10.1109/CVPR.2015.7298978; Tolias G, 2016, P INT C LEARN REPR; Vedaldi Andrea, 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249; WANG JJ, 2010, PROC CVPR IEEE, P3360, DOI DOI 10.1109/CVPR.2010.5540018; Yandex Artem Babenko, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1269, DOI 10.1109/ICCV.2015.150; Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757; Yu Kai, 2009, ADV NEURAL INFORM PR, P2223; Yu Kai, 2010, ICML, P1215; Zepeda J, 2015, PROC CVPR IEEE, P3052, DOI 10.1109/CVPR.2015.7298924; Zhao WL, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.99; Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11	56	15	16	2	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2018	40	3					626	638		10.1109/TPAMI.2017.2686861	http://dx.doi.org/10.1109/TPAMI.2017.2686861			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FV3KC	28358674	Green Submitted			2022-12-18	WOS:000424465900009
J	Murray, N; Jegou, H; Perronnin, F; Zisserman, A				Murray, Naila; Jegou, Herve; Perronnin, Florent; Zisserman, Andrew			Interferences in Match Kernels	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image-level representations; match kernels; large-scale image retrieval	OBJECT RECOGNITION; FEATURES; ALGORITHM; SCALE	We consider the design of an image representation that embeds and aggregates a set of local descriptors into a single vector. Popular representations of this kind include the bag-of-visual-words, the Fisher vector and the VLAD. When two such image representations are compared with the dot-product, the image-to-image similarity can be interpreted as a match kernel. In match kernels, one has to deal with interference, i.e., with the fact that even if two descriptors are unrelated, their matching score may contribute to the overall similarity. We formalise this problem and propose two related solutions, both aimed at equalising the individual contributions of the local descriptors in the final representation. These methods modify the aggregation stage by including a set of per-descriptor weights. They differ by the objective function that is optimised to compute those weights. The first is a "democratisation" strategy that aims at equalising the relative importance of each descriptor in the set comparison metric. The second one involves equalising the match of a single descriptor to the aggregated vector. These concurrent methods give a substantial performance boost over the state of the art in image search with short or mid-size vectors, as demonstrated by our experiments on standard public image retrieval benchmarks.	[Murray, Naila; Perronnin, Florent] Xerox Res Ctr Europe, F-38240 Meylan, France; [Jegou, Herve] Facebook AI Res, F-75002 Paris, France; [Zisserman, Andrew] Univ Oxford, Oxford OX1 2JD, England	Xerox; Facebook Inc; University of Oxford	Murray, N (corresponding author), Xerox Res Ctr Europe, F-38240 Meylan, France.	naila.murray@xrce.xerox.com; rvj@fb.com; florent.perronnin@xrce.xerox.com; az@robots.ox.ac.uk			ANR French research agency; ERC [228180]	ANR French research agency(French National Research Agency (ANR)); ERC(European Research Council (ERC)European Commission)	This work was done within the Project Fire-ID, supported by the ANR French research agency, and also supported by ERC grant VisRec no. 228180.	Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Azizpour H, 2016, IEEE T PATTERN ANAL, V38, P1790, DOI 10.1109/TPAMI.2015.2500224; Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38; Boughorbel S, 2005, IEEE IMAGE PROC, P2629; Boureau Y.-L., 2010, ICML, P111, DOI DOI 10.5555/3104322.3104338; BOUREAU YL, 2010, PROC CVPR IEEE, P2559, DOI DOI 10.1109/CVPR.2010.5539963; Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Chum O, 2010, PROC CVPR IEEE, P3416, DOI 10.1109/CVPR.2010.5539997; Cinbis RG, 2012, PROC CVPR IEEE, P2184, DOI 10.1109/CVPR.2012.6247926; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; de Campos T, 2012, COMPUT VIS IMAGE UND, V116, P68, DOI 10.1016/j.cviu.2011.07.011; Delhumeau Jonathan, 2013, ACM MM, P653, DOI DOI 10.1145/2502081.2502171; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Fryzlewicz P, 2004, J COMPUT GRAPH STAT, V13, P621, DOI 10.1198/106186004X2697; FUKUSHIMA K, 1982, PATTERN RECOGN, V15, P455, DOI 10.1016/0031-3203(82)90024-3; Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943; Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26; Gordo A, 2012, PROC CVPR IEEE, P3045, DOI 10.1109/CVPR.2012.6248035; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Jegou H, 2014, PROC CVPR IEEE, P3310, DOI 10.1109/CVPR.2014.417; Jegou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jegou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609; Jegou H, 2010, IEEE T PATTERN ANAL, V32, P2, DOI 10.1109/TPAMI.2008.285; Jegou H, 2007, PROC CVPR IEEE, P9; Jia YQ, 2012, PROC CVPR IEEE, P3370, DOI 10.1109/CVPR.2012.6248076; Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272; Knight PA, 2008, SIAM J MATRIX ANAL A, V30, P261, DOI 10.1137/060659624; Koniusz P., 2012, COMPUTER VISION IMAG, V117, P479; Koniusz P., 2016, IEEE T PATTERN ANAL, P1; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 1989, ADV NEURAL INFORM PR, V2; Lee H, 2009, P 26 ANN INT C MACH, V26, P609, DOI [10.1145/1553374.1553453, DOI 10.1145/1553374.1553453]; Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lyu SW, 2005, PROC CVPR IEEE, P223; Mairal J, 2008, NIPS, P1033; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Murray N, 2014, PROC CVPR IEEE, P2473, DOI 10.1109/CVPR.2014.317; PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009; Perronnin F, 2006, LECT NOTES COMPUT SC, V3954, P464; Perronnin F, 2010, PROC CVPR IEEE, P2297, DOI 10.1109/CVPR.2010.5539914; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Perronnin F, 2007, PROC CVPR IEEE, P2272; Phillips J. C., 2008, P 2008 ACM IEEE C SU, P8; Pinto N, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.0040027; Ranzato M.A., 2007, NIPS P 20 INT C NEUR, V20, P1185; Razavian A.S., 2014, ABS14126574 CORR; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819; Safadi B, 2013, INT WORK CONTENT MUL, P65, DOI 10.1109/CBMI.2013.6576554; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Serre T, 2005, PROC CVPR IEEE, P994; SINKHORN R, 1964, ANN MATH STAT, V35, P876, DOI 10.1214/aoms/1177703591; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Sminchisescu C, 2009, NEURIPS, P135; Tolias G, 2014, PATTERN RECOGN, V47, P3466, DOI 10.1016/j.patcog.2014.04.007; Tolias G, 2013, IEEE I CONF COMP VIS, P1401, DOI 10.1109/ICCV.2013.177; Torii A, 2013, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2013.119; van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132; Vedaldi A, 2010, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2010.5539949; Wallraven C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P257; WANG JJ, 2010, PROC CVPR IEEE, P3360, DOI DOI 10.1109/CVPR.2010.5540018; Winn J, 2005, IEEE I CONF COMP VIS, P1800; Yandex Artem Babenko, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1269, DOI 10.1109/ICCV.2015.150; Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123; Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11	71	15	15	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2017	39	9					1797	1810		10.1109/TPAMI.2016.2615621	http://dx.doi.org/10.1109/TPAMI.2016.2615621			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	FC4WC	27723578	Green Submitted			2022-12-18	WOS:000406840800008
J	Zhu, FY; Chen, GY; Hao, JY; Heng, PA				Zhu, Fengyuan; Chen, Guangyong; Hao, Jianye; Heng, Pheng-Ann			Blind Image Denoising via Dependent Dirichlet Process Tree	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image denoising; Bayesian nonparametrics; noise modeling; dependent Dirichlet process; variational inference; patch modeling	SCALE MIXTURES; MODELS; SPARSE; NOISE	Most existing image denoising approaches assumed the noise to be homogeneous white Gaussian distributed with known intensity. However, in real noisy images, the noise models are usually unknown beforehand and can be much more complex. This paper addresses this problem and proposes a novel blind image denoising algorithm to recover the clean image from noisy one with the unknown noise model. To model the empirical noise of an image, our method introduces the mixture of Gaussian distribution, which is flexible enough to approximate different continuous distributions. The problem of blind image denoising is reformulated as a learning problem. The procedure is to first build a two-layer structural model for noisy patches and consider the clean ones as latent variable. To control the complexity of the noisy patch model, this work proposes a novel Bayesian nonparametric prior called "Dependent Dirichlet Process Tree" to build the model. Then, this study derives a variational inference algorithm to estimate model parameters and recover clean patches. We apply our method on synthesis and real noisy images with different noise models. Comparing with previous approaches, ours achieves better performance. The experimental results indicate the efficiency of the proposed algorithm to cope with practical image denoising tasks.	[Zhu, Fengyuan; Chen, Guangyong; Heng, Pheng-Ann] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China; [Hao, Jianye] Tianjin Univ, Tianjin 300072, Peoples R China	Chinese University of Hong Kong; Tianjin University	Zhu, FY (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.	fyzhu@cse.cuhk.edu.hk; gychen@cse.cuhk.edu.hk; jianye.hao@tju.edu.cn; pheng@cse.cuhk.edu.hk		Heng, Pheng Ann/0000-0003-3055-5034	National Basic Program of China, 973 Program [2015CB351706]; Research Grants Council of Hong Kong [CUHK14202514]	National Basic Program of China, 973 Program(National Basic Research Program of China); Research Grants Council of Hong Kong(Hong Kong Research Grants Council)	This work was supported by the National Basic Program of China, 973 Program (Project No. 2015CB351706), and the Research Grants Council of Hong Kong (Project No. CUHK14202514). Guangyong Chen is the corresponding author.	Aldous D. J., 1985, COLE DT PROBABILITS; [Anonymous], 2001, ARTIFICIAL INTELLIGE; Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027; Barthe E, 2009, POLICE PRACT RES, V10, P255, DOI 10.1080/15614260802381067; Bishop C.M, 2006, PATTERN RECOGN; BLACKWELL D, 1973, ANN STAT, V1, P353, DOI 10.1214/aos/1176342372; Blei DM, 2006, BAYESIAN ANAL, V1, P121, DOI 10.1214/06-BA104; Blei DM, 2010, J ACM, V57, DOI 10.1145/1667053.1667056; Blei DM, 2004, ADV NEUR IN, V16, P17; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38; Candes EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5; Chen GY, 2015, IEEE I CONF COMP VIS, P477, DOI 10.1109/ICCV.2015.62; Colom M, 2014, IEEE IMAGE PROC, P4261, DOI 10.1109/ICIP.2014.7025865; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Dong WS, 2011, PROC CVPR IEEE, P457, DOI 10.1109/CVPR.2011.5995478; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360; Ghahramani Z., 1996, CRGTR961 U TORN DEP; Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366; Lebrun M, 2013, SIAM J IMAGING SCI, V6, P1665, DOI 10.1137/120874989; Lebrun M, 2015, IEEE T IMAGE PROCESS, V24, P3149, DOI 10.1109/TIP.2015.2439041; Liu C, 2008, IEEE T PATTERN ANAL, V30, P299, DOI [10.1109/TPAMI.2007.1176, 10.1109/TPAMI.20071176]; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Meng DY, 2013, IEEE I CONF COMP VIS, P1337, DOI 10.1109/ICCV.2013.169; Paisley J, 2015, IEEE T PATTERN ANAL, V37, P256, DOI 10.1109/TPAMI.2014.2318728; Ponomarenko N., 2009, ADV MOD RADIOELECTRO, V10, P30; Portilla J, 2004, IEEE IMAGE PROC, P1217; Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640; Portilla J., 2004, P 4 IEEE BEN SIGN PR, P17; Rajwade A, 2013, IEEE T PATTERN ANAL, V35, P849, DOI 10.1109/TPAMI.2012.140; Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835; Sethuraman J., 1991, M843 DEF TECH INF CT; Soltanolkotabi M, 2014, ANN STAT, V42, P669, DOI 10.1214/13-AOS1199; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Theis L, 2011, J MACH LEARN RES, V12, P3071; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; Tsin Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P480, DOI 10.1109/ICCV.2001.937555; Vidal R, 2011, IEEE SIGNAL PROC MAG, V28, P52, DOI 10.1109/MSP.2010.939739; Wang Chong, 2009, ADV NEURAL INFORM PR, V22, P1990; Wang YQ, 2013, SIAM J IMAGING SCI, V6, P999, DOI 10.1137/120901131; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wiener N., 1975, EXTRAPOLATION INTERP, DOI [10.7551/mitpress/2946.001.0001, DOI 10.7551/MITPRESS/2946.001.0001]; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Yerebakan H.Z., 2014, ADV NEURAL INFORM PR, P28; Yu GS, 2012, IEEE T IMAGE PROCESS, V21, P2481, DOI 10.1109/TIP.2011.2176743; Zhao Q, 2014, PR MACH LEARN RES, V32, P55; Zoran D., 2012, ADV NEURAL INF PROCE, P1736; Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278	49	15	15	1	32	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2017	39	8					1518	1531		10.1109/TPAMI.2016.2604816	http://dx.doi.org/10.1109/TPAMI.2016.2604816			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EZ3JD	28113573	Green Submitted			2022-12-18	WOS:000404606300003
J	Nguyen, Q; Tudisco, F; Gautier, A; Hein, M				Quynh Nguyen; Tudisco, Francesco; Gautier, Antoine; Hein, Matthias			An Efficient Multilinear Optimization Framework for Hypergraph Matching	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hypergraph Matching; tensor; multilinear form; block coordinate ascent	GRAPH; KERNEL	Hypergraphmatching has recently become a popular approach for solving correspondence problems in computer vision as it allows the use of higher-order geometric information. Hypergraphmatching can be formulated as a third-order optimization problem subject to assignment constraints which turns out to be NP-hard. In recent work, we have proposed an algorithm for hypergraph matching which first lifts the third-order problem to a fourth-order problem and then solves the fourth-order problem via optimization of the corresponding multilinear form. This leads to a tensor block coordinate ascent scheme which has the guarantee of providing monotonic ascent in the original matching score function and leads to state-of-the-art performance both in terms of achieved matching score and accuracy. In this paper we show that the lifting step to a fourth-order problem can be avoided yielding a third-order scheme with the same guarantees and performance but being two times faster. Moreover, we introduce a homotopy type method which further improves the performance.	[Quynh Nguyen; Tudisco, Francesco; Gautier, Antoine; Hein, Matthias] Saarland Univ, Dept Math & Comp Sci, D-66123 Saarbrucken, Saarland, Germany	Saarland University	Nguyen, Q (corresponding author), Saarland Univ, Dept Math & Comp Sci, D-66123 Saarbrucken, Saarland, Germany.	quynh@cs.uni-saarland.de; tudisco@cs.uni-saarland.de; antoine.gautier@uni-saarland.de; hein@cs.uni-saarland.de	Tudisco, Francesco/O-7449-2018	Tudisco, Francesco/0000-0002-8150-4475	ERC	ERC(European Research Council (ERC)European Commission)	This work has been supported by the ERC grant NOLEPRO. We sincerely thank the reviewers for their helpful comments and Cristian Caloian for helping us to correct grammatical mistakes.	Arora C, 2013, IEEE I CONF COMP VIS, P177, DOI 10.1109/ICCV.2013.29; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Boros E, 2002, DISCRETE APPL MATH, V123, P155, DOI 10.1016/S0166-218X(01)00336-5; Burkhard R. E., 2012, ASSIGNMENT PROBLEMS; Carcassoni M, 2003, PATTERN RECOGN, V36, P193, DOI 10.1016/S0031-3203(02)00054-7; Cheng ZQ, 2013, IEEE T VIS COMPUT GR, V19, P1885, DOI 10.1109/TVCG.2013.15; Chertok M, 2010, IEEE T PATTERN ANAL, V32, P2205, DOI 10.1109/TPAMI.2010.51; Cho MS, 2014, PROC CVPR IEEE, P2091, DOI 10.1109/CVPR.2014.268; Cho MS, 2013, IEEE I CONF COMP VIS, P25, DOI 10.1109/ICCV.2013.11; Cho M, 2012, PROC CVPR IEEE, P398, DOI 10.1109/CVPR.2012.6247701; Cho M, 2010, LECT NOTES COMPUT SC, V6315, P492; Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228; Cour T., 2007, P ADV NEURAL INFORM, P313; Duchenne O, 2011, IEEE I CONF COMP VIS, P1792, DOI 10.1109/ICCV.2011.6126445; Duchenne O, 2011, IEEE T PATTERN ANAL, V33, P2383, DOI 10.1109/TPAMI.2011.110; Filatov A., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P845, DOI 10.1109/ICDAR.1995.602033; Foggia P, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414500013; Hartley R., 1994, P ESPRIT WORKSH; Hays J, 2006, LECT NOTES COMPUT SC, V3952, P522; Hopcroft J.E, 1974, STOC, P172, DOI [10.1145/800119.803896, DOI 10.1145/800119.803896]; Jungmin Lee, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2816, DOI 10.1109/ICPR.2010.690; Kolmogorov V, 2007, IEEE T PATTERN ANAL, V29, P1274, DOI 10.1109/TPAMI.2007.1031; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Lee J, 2011, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2011.5995387; Lee R. S. T., 1999, 1999 Third International Conference on Knowledge-Based Intelligent Information Engineering Systems. Proceedings (Cat. No.99TH8410), P284, DOI 10.1109/KES.1999.820179; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Leordeanu M, 2009, PROC CVPR IEEE, P864, DOI 10.1109/CVPRW.2009.5206533; Leordeanu Marius, 2009, ADV NEURAL INFORM PR; Lian W, 2014, PROC CVPR IEEE, P352, DOI 10.1109/CVPR.2014.52; Liu ZY, 2012, IEEE T PATTERN ANAL, V34, P1451, DOI 10.1109/TPAMI.2012.45; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Luo B, 2000, LECT NOTES COMPUT SC, V1876, P226; Maciel J, 2003, IEEE T PATTERN ANAL, V25, P187, DOI 10.1109/TPAMI.2003.1177151; MUNDY JL, 1993, APPL INVARIANCE COMP; Ngoc QN, 2015, PROC CVPR IEEE, P5270, DOI 10.1109/CVPR.2015.7299164; SCHELLEWALD C, 2005, ENERGY MINIMIZATION; Sharma A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2481, DOI 10.1109/CVPR.2011.5995455; Singh R, 2007, LECT NOTES COMPUT SC, V4453, P16; Suh YM, 2015, PROC CVPR IEEE, P5070, DOI 10.1109/CVPR.2015.7299142; Taylor WR, 2002, MOL CELL PROTEOMICS, V1, P334, DOI 10.1074/mcp.T200001-MCP200; Torresani L, 2008, LECT NOTES COMPUT SC, V5303, P596, DOI 10.1007/978-3-540-88688-4_44; Wang HF, 2006, PATTERN RECOGN, V39, P1012, DOI 10.1016/j.patcog.2005.05.013; Wang YH, 2004, P ANN INT IEEE EMBS, V26, P2972; Yan JC, 2015, PROC CVPR IEEE, P1520, DOI 10.1109/CVPR.2015.7298759; Zaslavskiy M, 2009, IEEE T PATTERN ANAL, V31, P2227, DOI 10.1109/TPAMI.2008.245; Zass R., 2008, P 2008 IEEE C COMP V, P1, DOI DOI 10.1109/CVPR.2008.4587500; Zeng Y, 2010, PROC CVPR IEEE, P382, DOI 10.1109/CVPR.2010.5540189; Zhou F., 2013, P IEEE C COMP VIS PA; Zhou F, 2012, PROC CVPR IEEE, P127, DOI 10.1109/CVPR.2012.6247667	49	15	16	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2017	39	6					1054	1075		10.1109/TPAMI.2016.2574706	http://dx.doi.org/10.1109/TPAMI.2016.2574706			22	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EU5RR	27254858	Green Submitted			2022-12-18	WOS:000401091200002
J	Chen, D; Cao, XD; Wipf, D; Wen, F; Sun, J				Chen, Dong; Cao, Xudong; Wipf, David; Wen, Fang; Sun, Jian			An Efficient Joint Formulation for Bayesian Face Verification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian face recognition; face verification; EM algorithm	RECOGNITION	This paper revisits the classical Bayesian face recognition algorithm from Baback Moghaddam et al. and proposes enhancements tailored to face verification, the problem of predicting whether or not a pair of facial images share the same identity. Like a variety of face verification algorithms, the original Bayesian face model only considers the appearance difference between two faces rather than the raw images themselves. However, we argue that such a fixed and blind projection may prematurely reduce the separability between classes. Consequently, we model two facial images jointly with an appropriate prior that considers intra-and extra-personal variations over the image pairs. This joint formulation is trained using a principled EM algorithm, while testing involves only efficient closed-formed computations that are suitable for real-time practical deployment. Supporting theoretical analyses investigate computational complexity, scale-invariance properties, and convergence issues. We also detail important relationships with existing algorithms, such as probabilistic linear discriminant analysis and metric learning. Finally, on extensive experimental evaluations, the proposed model is superior to the classical Bayesian face algorithm and many alternative state-of-the-art supervised approaches, achieving the best test accuracy on three challenging datasets, Labeled Face in Wild, Multi-PIE, and YouTube Faces, all with unparalleled computational efficiency.	[Chen, Dong; Cao, Xudong; Wipf, David; Wen, Fang; Sun, Jian] Microsoft Res, Visual Comp Grp, Beijing 100080, Peoples R China	Microsoft	Chen, D (corresponding author), Microsoft Res, Visual Comp Grp, Beijing 100080, Peoples R China.	doch@microsoft.com; xudongca@microsoft.com; davidwip@microsoft.com; fangwen@microsoft.com; jiansun@microsoft.com		Wipf, David/0000-0002-2768-4540				Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Berg T, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.129; Cao Q, 2013, IEEE I CONF COMP VIS, P2408, DOI 10.1109/ICCV.2013.299; Cao XD, 2013, IEEE I CONF COMP VIS, P3208, DOI 10.1109/ICCV.2013.398; CAO ZM, 2010, PROC CVPR IEEE, P2707, DOI DOI 10.1109/CVPR.2010.5539992; Chen D, 2012, LECT NOTES COMPUT SC, V7574, P566, DOI 10.1007/978-3-642-33712-3_41; Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389; Cui Z, 2013, PROC CVPR IEEE, P3554, DOI 10.1109/CVPR.2013.456; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Gross R., 2008, P IEEE INT C AUT FAC, V28, P1; Guillaumin M, 2009, IEEE I CONF COMP VIS, P498, DOI 10.1109/ICCV.2009.5459197; Huang C, 2011, TR115 NEC; Huang G. B., 2007, P EUR C COMPUT VIS; Ioffe S, 2006, LECT NOTES COMPUT SC, V3954, P531; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Leger F, 2011, INT CONF ACOUST SPEE, P1113; Li HX, 2013, PROC CVPR IEEE, P3499, DOI 10.1109/CVPR.2013.449; Li P, 2012, IEEE T PATTERN ANAL, V34, P144, DOI 10.1109/TPAMI.2011.104; Li ZF, 2004, PROC CVPR IEEE, P374; Luenberger D.G, 2016, LINEAR NONLINEAR PRO, DOI 10.1007/978-3-319-18842-3; Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X; Nguyen Hieu V, 2010, P AS C COMP VIS, P709, DOI DOI 10.1007/978-3-642-19309-5_55; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Prince SJD, 2007, IEEE I CONF COMP VIS, P1751; Ramanan D, 2009, IEEE I CONF COMP VIS, P301, DOI 10.1109/ICCV.2009.5459265; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Sun Y., 2014, ADV NEURAL INFORM PR, P1988; Susskind J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2793, DOI 10.1109/CVPR.2011.5995541; Taigman Y., 2011, ARXIV11081122; Taigman Y., 2009, BMVC, P1; Wang X., 2003, P ACM SIGMM WORKSH B, P70; Wang XG, 2005, PROC CVPR IEEE, P574; Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57; Weinberger K. Q., 2005, J MACHINE LEARNING R, V10, P207; Wolf L., 2011, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2011.5995566; WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060; Yin Q, 2011, PROC CVPR IEEE, P497, DOI 10.1109/CVPR.2011.5995494; Ying YM, 2012, J MACH LEARN RES, V13, P1; Zhi CH, 2011, PROC CVPR IEEE, P481, DOI 10.1109/CVPR.2011.5995680; Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679	42	15	17	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2017	39	1					32	46		10.1109/TPAMI.2016.2533383	http://dx.doi.org/10.1109/TPAMI.2016.2533383			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EF6DP	26915111				2022-12-18	WOS:000390421300005
J	Garro, V; Giachetti, A				Garro, Valeria; Giachetti, Andrea			Scale Space Graph Representation and Kernel Matching for Non Rigid and Textured 3D Shape Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Textured 3D model retrieval; shape descriptors; auto diffusion function; graph kernel; graph-based representation; non-rigid shape retrieval; matching	SIGNATURE	In this paper we introduce a novel framework for 3D object retrieval that relies on tree-based shape representations (TreeSha) derived from the analysis of the scale-space of the Auto Diffusion Function (ADF) and on specialized graph kernels designed for their comparison. By coupling maxima of the Auto Diffusion Function with the related basins of attraction, we can link the information at different scales encoding spatial relationships in a graph description that is isometry invariant and can easily incorporate texture and additional geometrical information as node and edge features. Using custom graph kernels it is then possible to estimate shape dissimilarities adapted to different specific tasks and on different categories of models, making the procedure a powerful and flexible tool for shape recognition and retrieval. Experimental results demonstrate that the method can provide retrieval scores similar or better than state-of-the-art on textured and non textured shape retrieval benchmarks and give interesting insights on effectiveness of different shape descriptors and graph kernels.	[Garro, Valeria] ISTI CNR, Italian Natl Res Council, Pisa, Italy; [Giachetti, Andrea] Univ Verona, Dept Comp Sci, I-37100 Verona, Italy	Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienza e Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR); University of Verona	Garro, V (corresponding author), ISTI CNR, Italian Natl Res Council, Pisa, Italy.; Giachetti, A (corresponding author), Univ Verona, Dept Comp Sci, I-37100 Verona, Italy.	valeria.garro@isti.cnr.it; andrea.giachetti@univr.it	Giachetti, Andrea/AAD-8247-2020	giachetti, andrea/0000-0002-7523-6806				Agathos A., 2009, P EUR WORKSH 3D OBJ, P29; Bai X, 2008, IEEE T PATTERN ANAL, V30, P1282, DOI 10.1109/TPAMI.2007.70769; Barra V, 2013, PATTERN RECOGN, V46, P2985, DOI 10.1016/j.patcog.2013.03.019; Biasotti S, 2013, COMPUT GRAPH FORUM, V32, P13, DOI 10.1111/cgf.12168; Biasotti S, 2014, P EUROGRAPHICS WORKS, P111, DOI 10.2312/3DOR.20141057; Borgwardt KM, 2005, Fifth IEEE International Conference on Data Mining, Proceedings, P74, DOI 10.1109/ICDM.2005.132; Bunke H, 1983, PATTERN RECOGN LETT, V1, P245, DOI 10.1016/0167-8655(83)90033-8; Caelli T, 2004, IEEE T PATTERN ANAL, V26, P515, DOI 10.1109/TPAMI.2004.1265866; Cerri A, 2013, P 6 EUR WORKSH 3D OB, P73; CHAZAL F, 2009, RR6968 INRIA; Cohen-Steiner D, 2003, P 19 ANN S COMP GEOM, P312, DOI DOI 10.1145/777792.777839; Dey TK, 2010, COMPUT GRAPH FORUM, V29, P1545, DOI 10.1111/j.1467-8659.2010.01763.x; Dickinson PJ, 2003, LECT NOTES COMPUT SC, V2726, P13; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI 10.1007/BF01386390; Dupe F.-X., 2008, CORR, Vabs/0810, P3579; Edelsbrunner H, 2002, DISCRETE COMPUT GEOM, V28, P511, DOI 10.1007/s00454-002-2885-2; FINLAYSON GD, 1995, COEFFICIENT COLOR CO; FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168; Garro V., 2014, P EUR WORKSH 3D OBJ, P17; GARTNER T, 2002, P NIPS WORKSH UNR DA; Gebal K, 2009, COMPUT GRAPH FORUM, V28, P1405, DOI 10.1111/j.1467-8659.2009.01517.x; Giachetti A, 2012, COMPUT GRAPH FORUM, V31, P1669, DOI 10.1111/j.1467-8659.2012.03172.x; HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136; Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282; Horvath Tamas, 2004, P 10 ACM SIGKDD INT, P158, DOI DOI 10.1145/1014052.1014072; Koenderink J. J., 1984, BIOL CYBERN, V50, P363; Kovnatsky A, 2013, NUMER MATH-THEORY ME, V6, P199, DOI 10.4208/nmtma.2013.mssvm11; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Laga H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516975; Lavoue G, 2012, VISUAL COMPUT, V28, P931, DOI 10.1007/s00371-012-0724-x; Lee W. - J., 2012, IJPRAI, V26; Lee WJ, 2008, LECT NOTES COMPUT SC, V5342, P35; Li CY, 2014, MULTIMED TOOLS APPL, V72, P1027, DOI 10.1007/s11042-013-1417-9; Lian Z., 2011, 3DOR, P79, DOI DOI 10.2312/3DOR/3DOR11/079-088; Lian ZH, 2013, PATTERN RECOGN, V46, P449, DOI 10.1016/j.patcog.2012.07.014; Lindeberg T., 1994, SCALE SPACE THEORY C; Milnor J., 1963, ANN MATH STUD, V51; Mohamed W, 2012, VISUAL COMPUT, V28, P305, DOI 10.1007/s00371-011-0640-5; Peyre G., 2009, TOOLBOX FAST MARCHIN; Peyre G., 2009, TOOLBOX GRAPH; Philipp-Foliguet S., 2010, P ACM WORKSH 3D OBJ, P69; Pinkall U., 1993, EXPT MATH, V2, P15, DOI DOI 10.1080/10586458.1993.10504266; Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011; Riesen K, 2009, IMAGE VISION COMPUT, V27, P950, DOI 10.1016/j.imavis.2008.04.004; Rustamov Raif M, 2007, P 5 EUR S GEOM PROC, P225, DOI DOI 10.2312/SGP/SGP07/225-233; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175; Shapira L, 2008, VISUAL COMPUT, V24, P249, DOI 10.1007/s00371-007-0197-5; Skraba P., 2010, 2010 IEEE COMP SOC C, P45, DOI DOI 10.1109/CVPRW.2010.5543285; Smeets D, 2012, PATTERN RECOGN, V45, P2817, DOI 10.1016/j.patcog.2012.01.020; Suard F, 2007, P EUR S ART NEUR NET, P355; Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x; Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609; Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0; Tung T., 2005, International Journal of Shape Modeling, V11, P91, DOI 10.1142/S0218654305000748; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; Wyszecki G., 2000, COLOR SCI CONCEPTS M, Vsecond	57	15	15	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2016	38	6					1258	1271		10.1109/TPAMI.2015.2477823	http://dx.doi.org/10.1109/TPAMI.2015.2477823			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DL4LU	26372206				2022-12-18	WOS:000375609000016
J	Zhang, ZM; Torr, PHS				Zhang, Ziming; Torr, Philip H. S.			Object Proposal Generation Using Two-Stage Cascade SVMs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object proposal generation; scale/aspect-ratio quantization; cascade SVMs; linear filters; 2D convolution		Object proposal algorithms have shown great promise as a first step for object recognition and detection. Good object proposal generation algorithms require high object detection recall rate as well as low computational cost, because generating object proposals is usually utilized as a preprocessing step. The problem of how to accelerate the object proposal generation and evaluation process without decreasing recall is thus of great interest. In this paper, we propose a new object proposal generation method using two-stage cascade support vector machines (SVMs), where in the first stage linear filters are learned for predefined quantized scales/aspect-ratios independently, and in the second stage a global linear classifier is learned across all the quantized scales/aspect-ratios for calibration, so that all the windows from the first stage can be compared properly. The windows with highest scores from the second stage are kept as inputs to our new efficient proposal calibration algorithm to improve their localization quality significantly, resulting in our final object proposals. We explain our scale/aspect-ratio quantization scheme, and investigate the effects of combinations of l(1) and l(2) regularizers in cascade SVMs with/without ranking constraints in learning. Comprehensive experiments on VOC2007 dataset are conducted, and our method is comparable with the current state-of-the-art methods with much better computational efficiency.	[Zhang, Ziming] Xidian Univ, Sch Comp Sci, Xian 710071, Peoples R China; [Zhang, Ziming] Boston Univ, Dept Elect & Comp Engn, Boston, MA 02215 USA; [Torr, Philip H. S.] Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England	Xidian University; Boston University; University of Oxford	Zhang, ZM (corresponding author), Xidian Univ, Sch Comp Sci, Xian 710071, Peoples R China.	zzhang14@bu.edu; philip.torr@eng.ox.ac.uk	Zhang, ziming/HGA-8604-2022		EPSRC; ERC [ERC-2012-AdG 321162-HELIOS]; Engineering and Physical Sciences Research Council [EP/I001107/1] Funding Source: researchfish; EPSRC [EP/I001107/1] Funding Source: UKRI	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); ERC(European Research Council (ERC)European Commission); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was supported by the EPSRC and by ERC grant ERC-2012-AdG 321162-HELIOS.	Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; [Anonymous], 2007, PASCAL VISUAL OBJECT; Blaschko MB, 2013, LECT NOTES COMPUT SC, V7944, P408; Bleyer M, 2012, LECT NOTES COMPUT SC, V7576, P467, DOI 10.1007/978-3-642-33715-4_34; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Chum O., 2007, P IEEE C COMP VIS PA, P1; Endres I, 2014, IEEE T PATTERN ANAL, V36, P222, DOI 10.1109/TPAMI.2013.122; Everingham M., 2006, PASCAL VISUAL OBJECT; Felzenszwalb P.F., 2012, THEORY COMPUT, V8, P415, DOI DOI 10.4086/TOC.2012.V008A019; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Felzenszwalb PF, 2010, PROC CVPR IEEE, P2241, DOI 10.1109/CVPR.2010.5539906; Heitz G., 2009, ADV NEURAL INFORM PR, V21, P641; Herbrich R, 2000, ADV NEUR IN, P115; Hosang J., 2014, BMVC; Krahenbuhl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47; Lampert CH, 2010, PROC CVPR IEEE, P1022, DOI 10.1109/CVPR.2010.5540107; Lampert CH, 2009, IEEE T PATTERN ANAL, V31, P2129, DOI 10.1109/TPAMI.2009.144; Manen S, 2013, IEEE I CONF COMP VIS, P2536, DOI 10.1109/ICCV.2013.315; Oneata D, 2014, LECT NOTES COMPUT SC, V8691, P737, DOI 10.1007/978-3-319-10578-9_48; Park D, 2010, LECT NOTES COMPUT SC, V6314, P241, DOI 10.1007/978-3-642-15561-1_18; Rahtu E, 2011, IEEE I CONF COMP VIS, P1052, DOI 10.1109/ICCV.2011.6126351; Rantalankila P, 2014, PROC CVPR IEEE, P2417, DOI 10.1109/CVPR.2014.310; Saberian MJ, 2012, IEEE T PATTERN ANAL, V34, P2005, DOI 10.1109/TPAMI.2011.281; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183; Vedaldi Andrea, 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang XY, 2013, IEEE I CONF COMP VIS, P17, DOI 10.1109/ICCV.2013.10; Wei Y., 2014, ARXIV PREPRINT ARXIV; Yanulevskaya V, 2014, PROC CVPR IEEE, P3134, DOI 10.1109/CVPR.2014.401; Zhang Z., 2011, P IEEE INT C COMP VI; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	34	15	16	0	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2016	38	1					102	115		10.1109/TPAMI.2015.2430348	http://dx.doi.org/10.1109/TPAMI.2015.2430348			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CY8OW	26656580	Green Submitted			2022-12-18	WOS:000366669200008
J	Cao, YS; Brubaker, MA; Fleet, DJ; Hertzmann, A				Cao, Yanshuai; Brubaker, Marcus A.; Fleet, David J.; Hertzmann, Aaron			Efficient Optimization for Sparse Gaussian Process Regression	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gaussian process regression; low rank; matrix factorization; sparsity		We propose an efficient optimization algorithm to select a subset of training data as the inducing set for sparse Gaussian process regression. Previous methods either use different objective functions for inducing set and hyperparameter selection, or else optimize the inducing set by gradient-based continuous optimization. The former approaches are harder to interpret and suboptimal, whereas the latter cannot be applied to discrete input domains or to kernel functions that are not differentiable with respect to the input. The algorithm proposed in this work estimates an inducing set and the hyperparameters using a single objective. It can be used to optimize either the marginal likelihood or a variational free energy. Space and time complexity are linear in training set size, and the algorithm can be applied to large regression problems on discrete or continuous domains. Empirical evaluation shows state-of-art performance in discrete cases, competitive prediction results as well as a favorable trade-off between training and test time in continuous cases.	[Cao, Yanshuai; Fleet, David J.; Hertzmann, Aaron] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 1A1, Canada; [Brubaker, Marcus A.] TTI Chicago Inst, Chicago, IL USA; [Hertzmann, Aaron] Adobe Res, San Francisco, CA USA	University of Toronto; Adobe Systems Inc.	Cao, YS (corresponding author), Univ Toronto, Dept Comp Sci, Toronto, ON M5S 1A1, Canada.			Brubaker, Marcus/0000-0002-7892-9026; /0000-0003-0734-7114; Hertzmann, Aaron/0000-0001-9667-0292	NSERC Canada; Canadian Institute for Advanced Research through the Program on Neural Computation and Adaptive Perception	NSERC Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)); Canadian Institute for Advanced Research through the Program on Neural Computation and Adaptive Perception	This work has been supported by NSERC Canada, through grants to DJF, AH and a fellowship to MAB, and by the Canadian Institute for Advanced Research through the Program on Neural Computation and Adaptive Perception. We thank TaeHyung Kim for the advice on data collection for the BindingDB dataset. Y. Cao is the corresponding author.	Bach F.R., 2005, P 22 INT C MACH LEAR, P33, DOI DOI 10.1145/1102351.1102356; Bach FR, 2008, J MACH LEARN RES, V9, P1019; Bo L., 2008, UNCERTAINTY ARTIFICI; Bo LF, 2010, INT J COMPUT VISION, V87, P28, DOI 10.1007/s11263-008-0204-y; Borgwardt KM, 2005, Fifth IEEE International Conference on Data Mining, Proceedings, P74, DOI 10.1109/ICDM.2005.132; Chalupka K, 2013, J MACH LEARN RES, V14, P333; Csato L, 2002, NEURAL COMPUT, V14, P641, DOI 10.1162/089976602317250933; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Gartner T, 2003, LECT NOTES ARTIF INT, V2777, P129, DOI 10.1007/978-3-540-45167-9_11; Inokuchi A., 2003, INT C MACHINE LEARNI, P321; Keerthi S., 2006, ADV NEURAL INFORM PR, P643; Lawrence N., 2003, P 16 ANN C NEURAL IN, P609; LEE JJ, 2008, MITCSAILTR200817; Quinonero-Candela JQ, 2005, J MACH LEARN RES, V6, P1939; Ramon J., 2003, PROC 1 INT WORKSHOP, P65; Rasmussen C., 2006, ADAPT COMPUT MACH LE; Seeger M.W., 2003, INT WORKSHOP ARTIFIC, VR4, P254; Shervashidze N., 2009, P 12 INT C ART INT S, P488; Shervashidze N, 2011, J MACH LEARN RES, V12, P2539; Smola A. J., 2000, P 17 INT C MACH LEAR, P911; Smola AJ, 2001, ADV NEUR IN, V13, P619; Snelson E., 2006, ADV NEURAL INFORM PR, V18, P1259; Titsias M. K., 2009, ARTIF INTELL STAT, V3; Vishwanathan SVN, 2010, J MACH LEARN RES, V11, P1201; Walder C., 2008, ICML, P1112	25	15	15	3	19	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2015	37	12					2415	2427		10.1109/TPAMI.2015.2424873	http://dx.doi.org/10.1109/TPAMI.2015.2424873			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CW2OK	26539847	Green Submitted			2022-12-18	WOS:000364831700005
J	Dikmen, O; Yang, ZR; Oja, E				Dikmen, Onur; Yang, Zhirong; Oja, Erkki			Learning the Information Divergence	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Information divergence; tweedie distribution; maximum likelihood; nonnegative matrix factorization; stochastic neighbor embedding	NONNEGATIVE MATRIX FACTORIZATION; ALPHA-BETA; ROBUST	Information divergence that measures the difference between two nonnegative matrices or tensors has found its use in a variety of machine learning problems. Examples are Nonnegative Matrix/Tensor Factorization, Stochastic Neighbor Embedding, topic models, and Bayesian network optimization. The success of such a learning task depends heavily on a suitable divergence. A large variety of divergences have been suggested and analyzed, but very few results are available for an objective choice of the optimal divergence for a given task. Here we present a framework that facilitates automatic selection of the best divergence among a given family, based on standard maximum likelihood estimation. We first propose an approximated Tweedie distribution for the beta-divergence family. Selecting the best beta then becomes a machine learning problem solved by maximum likelihood. Next, we reformulate alpha-divergence in terms of beta-divergence, which enables automatic selection of a by maximum likelihood with reuse of the learning principle for beta-divergence. Furthermore, we show the connections between gamma- and beta-divergences as well as Renyi- and alpha-divergences, such that our automatic selection framework is extended to non-separable divergences. Experiments on both synthetic and real-world data demonstrate that our method can quite accurately select information divergence across different learning problems and various divergence families.	[Dikmen, Onur; Yang, Zhirong; Oja, Erkki] Aalto Univ, Dept Informat & Comp Sci, Espoo 00076, Finland	Aalto University	Dikmen, O (corresponding author), Aalto Univ, Dept Informat & Comp Sci, Espoo 00076, Finland.	onur.dikmen@aalto.fi; zhirong.yang@aalto.fi; erkki.oja@aalto.fi	Yang, Zhirong/E-8312-2012	Yang, Zhirong/0000-0001-8412-5684	Academy of Finland (Finnish Center of Excellence in Computational Inference Research COIN) [251170, 140398]	Academy of Finland (Finnish Center of Excellence in Computational Inference Research COIN)	This work was financially supported by the Academy of Finland (Finnish Center of Excellence in Computational Inference Research COIN, grant no 251170; Zhirong Yang additionally by decision number 140398).	Abramowitz M., 1972, HDB MATH FUNCTIONS, P890; Amari S.-i., 1985, DIFFERENTIAL GEOMETR, V28; Basu A, 1998, BIOMETRIKA, V85, P549, DOI 10.1093/biomet/85.3.549; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bregman L. M., 1967, COMP MATH MATH PHYS+, V7, P200, DOI DOI 10.1016/0041-5553(67)90040-7; Choi H., 2010, P IEEE INT C AC SPEE, P14; Cichocki A, 2008, PATTERN RECOGN LETT, V29, P1433, DOI 10.1016/j.patrec.2008.02.016; Cichocki A, 2011, ENTROPY-SWITZ, V13, P134, DOI 10.3390/e13010134; Cichocki Andrzej, 2009, NONNEGATIVE MATRIX T, P2; Csiszar I., 1963, AKAD MAT KUTAT INT K, V8, P85; Dunn P. K., 2001, P 16 INT WORKSH STAT; Dunn PK, 2005, STAT COMPUT, V15, P267, DOI 10.1007/s11222-005-4070-y; Eguchi S., 2001, 802 I STAT MATH, V802; Fevotte C, 2011, NEURAL COMPUT, V23, P2421, DOI 10.1162/NECO_a_00168; Fevotte C, 2009, NEURAL COMPUT, V21, P793, DOI 10.1162/neco.2008.04-08-771; Fujisawa H, 2008, J MULTIVARIATE ANAL, V99, P2053, DOI 10.1016/j.jmva.2008.02.004; Hinton GE., 2002, NIPS, V15, P833; Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649; Hyvarinen A, 2005, J MACH LEARN RES, V6, P695; Hyvarinen A, 2007, COMPUT STAT DATA AN, V51, P2499, DOI 10.1016/j.csda.2006.09.003; JORGENSEN B, 1987, J ROY STAT SOC B MET, V49, P127; Kompass R, 2007, NEURAL COMPUT, V19, P780, DOI 10.1162/neco.2007.19.3.780; Kulis B, 2009, J MACH LEARN RES, V10, P341; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Lu Z., 2012, LECT NOTES COMPUTER, P419; Mihoko M, 2002, NEURAL COMPUT, V14, P1859, DOI 10.1162/089976602760128045; Minka T, 2005, MSRTR2005; MORIMOTO T, 1963, J PHYS SOC JPN, V18, P328, DOI 10.1143/JPSJ.18.328; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Renyi A, 1961, PROC 4 BERKELEY SYMP, V1, P547; Sato I., 2012, P INT C MACH LEARN, P999; Sra S., 2006, ADV NEURAL INFORM PR, V18, P283; Tan V. Y. F., 2009, P WORKSH SIGN PROC A; Tan VYF, 2013, IEEE T PATTERN ANAL, V35, P1592, DOI 10.1109/TPAMI.2012.240; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Yang Z., 2011, P 21 INT C ART NEUR, P14; Yang ZR, 2012, PATTERN RECOGN, V45, P1500, DOI 10.1016/j.patcog.2011.10.014; Yang ZR, 2010, LECT NOTES COMPUT SC, V6365, P514, DOI 10.1007/978-3-642-15995-4_64; Yang ZR, 2010, IEEE T NEURAL NETWOR, V21, P734, DOI 10.1109/TNN.2010.2041361; Yang ZR, 2009, LECT NOTES COMPUT SC, V5768, P20, DOI 10.1007/978-3-642-04274-4_3; Yilmaz Y. K., 2012, ABS12094280 CORR; Yuan ZJ, 2005, LECT NOTES COMPUT SC, V3540, P333	47	15	15	2	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2015	37	7					1442	1454		10.1109/TPAMI.2014.2366144	http://dx.doi.org/10.1109/TPAMI.2014.2366144			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CK0YG	26352451	Green Submitted			2022-12-18	WOS:000355931100011
J	Tschiatschek, S; Pernkopf, F				Tschiatschek, Sebastian; Pernkopf, Franz			On Bayesian Network Classifiers with Reduced Precision Parameters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian network classifiers; custom precision; quantization; discriminative learning		Bayesian network classifier (BNCs) are typically implemented on nowadays desktop computers. However, many real world applications require classifier implementation on embedded or low power systems. Aspects for this purpose have not been studied rigorously. We partly close this gap by analyzing reduced precision implementations of BNCs. In detail, we investigate the quantization of the parameters of BNCs with discrete valued nodes including the implications on the classification rate (CR). We derive worst-case and probabilistic bounds on the CR for different bit-widths. These bounds are evaluated on several benchmark datasets. Furthermore, we compare the classification performance and the robustness of BNCs with generatively and discriminatively optimized parameters, i.e. parameters optimized for high data likelihood and parameters optimized for classification, with respect to parameter quantization. Generatively optimized parameters are more robust for very low bit-widths, i.e. less classifications change because of quantization. However, classification performance is better for discriminatively optimized parameters for all but very low bit-widths. Additionally, we perform analysis for margin-optimized tree augmented network (TAN) structures which outperform generatively optimized TAN structures in terms of CR and robustness.	[Tschiatschek, Sebastian; Pernkopf, Franz] Graz Univ Technol, Dept Elect Engn, Lab Signal Proc & Speech Commun, A-8010 Styria, Austria	Graz University of Technology	Tschiatschek, S (corresponding author), Graz Univ Technol, Dept Elect Engn, Lab Signal Proc & Speech Commun, A-8010 Styria, Austria.	tschiatschek@tugraz.at; pernkopf@tugraz.at	Mücke, Manfred/B-7040-2015	Mücke, Manfred/0000-0002-3960-4296	Austrian Science Fund [P25244-N15]; Austrian Science Fund (FWF) [P 25244] Funding Source: researchfish	Austrian Science Fund(Austrian Science Fund (FWF)); Austrian Science Fund (FWF)(Austrian Science Fund (FWF))	This work was supported by the Austrian Science Fund (project number P25244-N15).	Acid S, 2005, MACH LEARN, V59, P213, DOI 10.1007/s10994-005-0473-4; Bernardo J. M., 1994, BAYESIAN THEORY; Bielza C, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2576868; Bishop Christopher M., 2007, PATTERN RECOGNITION, V4, DOI 10.1117/1.2819119; Chan H, 2002, J ARTIF INTELL RES, V17, P265, DOI 10.1613/jair.967; Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199; Greiner K, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P167; Guo Y., 2005, UNCERTAINTY ARTIFICI, P233; HASTIE T, 2003, ELEMENTS STAT LEARNI; Heckerman D., 1995, MSRTR9105; Helman P, 2004, J COMPUT BIOL, V11, P581, DOI 10.1089/cmb.2004.11.581; Husmeier D., 2004, PROBABILISTIC MODELL; Koller D., 2009, PROBABILISTIC GRAPHI; KONONENKO I, 1991, LECT NOTES ARTIF INT, V482, P206, DOI 10.1007/BFb0017015; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee DU, 2006, IEEE T COMPUT AID D, V25, P1990, DOI 10.1109/TCAD.2006.873887; Papoulis A., 2002, PROBABILITY RANDOM V; Peharz R., 2012, P 29 INT C MACH LEAR; Peharz R., 2014, ACAD PRESS LIB SIGNA, VVolume 1, P989, DOI [10.1016/B978-0-12-396502-8.00018-8, DOI 10.1016/B978-0-12-396502-8.00018-8]; Pernkopf F, 2013, PATTERN RECOGN, V46, P464, DOI 10.1016/j.patcog.2012.08.007; Pernkopf F, 2012, IEEE T PATTERN ANAL, V34, P521, DOI 10.1109/TPAMI.2011.149; Pernkopf F, 2011, INT CONF ACOUST SPEE, P2076; Pernkopf F, 2010, J MACH LEARN RES, V11, P2323; Piatkowski Nico, 2014, 3rd International Conference on Pattern Recognition Applications and Methods (ICPRAM 2014). Proceedings, P296; Roos T, 2005, MACH LEARN, V59, P267; Tschiatschek Sebastian, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8726, P209, DOI 10.1007/978-3-662-44845-8_14; Tschiatschek S, 2013, INT CONF ACOUST SPEE, P3357, DOI 10.1109/ICASSP.2013.6638280; Tschiatschek Sebastian, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P74, DOI 10.1007/978-3-642-33460-3_10; Widrow B, 1996, IEEE T INSTRUM MEAS, V45, P353, DOI 10.1109/19.492748	30	15	15	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2015	37	4					774	785		10.1109/TPAMI.2014.2353620	http://dx.doi.org/10.1109/TPAMI.2014.2353620			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CD6QF	26353293				2022-12-18	WOS:000351213400006
J	Yeung, SK; Wu, TP; Tang, CK; Chan, TF; Osher, SJ				Yeung, Sai-Kit; Wu, Tai-Pang; Tang, Chi-Keung; Chan, Tony F.; Osher, Stanley J.			Normal Estimation of a Transparent Object Using a Video	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Transparent object; normal estimation; graph-cuts; segmentation	PHOTOMETRIC STEREO; SHAPE	Reconstructing transparent objects is a challenging problem. While producing reasonable results for quite complex objects, existing approaches require custom calibration or somewhat expensive labor to achieve high precision. When an overall shape preserving salient and fine details is sufficient, we show in this paper a significant step toward solving the problem when the object's silhouette is available and simple user interaction is allowed, by using a video of a transparent object shot under varying illumination. Specifically, we estimate the normal map of the exterior surface of a given solid transparent object, from which the surface depth can be integrated. Our technical contribution lies in relating this normal estimation problem to one of graph-cut segmentation. Unlike conventional formulations, however, our graph is dual-layered, since we can see a transparent object's foreground as well as the background behind it. Quantitative and qualitative evaluation are performed to verify the efficacy of this practical solution.	[Yeung, Sai-Kit] Singapore Univ Technol & Design, Pillar Informat Syst Technol & Design, Singapore, Singapore; [Wu, Tai-Pang] HK Jiuling Technol Co Ltd, Hong Kong, Hong Kong, Peoples R China; [Tang, Chi-Keung; Chan, Tony F.] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China; [Osher, Stanley J.] Univ Calif Los Angeles, Dept Math, Los Angeles, CA 90024 USA	Singapore University of Technology & Design; Hong Kong University of Science & Technology; University of California System; University of California Los Angeles	Yeung, SK (corresponding author), Singapore Univ Technol & Design, Pillar Informat Syst Technol & Design, Singapore, Singapore.	saikit@sutd.edu.sg; tpwu@9ling.hk; cktang@ust.hk; tonyfchan@ust.hk; sjo@math.ucla.edu	Chan, Tony F/A-4166-2013	Chan, Tony F/0000-0001-6196-2068	Singapore University of Technology and Design (SUTD) StartUp Grant [ISTD 2011 016]; SUTD-ZJU Collaboration Research Grant [2012 SUTD-ZJU/RES/03/2012]; SUTD-MIT International Design Centre [IDG31300106]; Singapore MOE Academic Research Fund [MOE2013-T2-1-159]; Research Grant Council of the Hong Kong Special Administrative Region [619112]	Singapore University of Technology and Design (SUTD) StartUp Grant(Singapore University of Technology & Design); SUTD-ZJU Collaboration Research Grant(Singapore University of Technology & Design); SUTD-MIT International Design Centre(Singapore University of Technology & Design); Singapore MOE Academic Research Fund(Ministry of Education, Singapore); Research Grant Council of the Hong Kong Special Administrative Region(Hong Kong Research Grants Council)	The authors would like to thank the Associate Editor and all of the anonymous reviewers. Special thanks to Reviewer 1 for his/her helpful and detailed comments throughout the review cycle. Sai-Kit Yeung is supported by Singapore University of Technology and Design (SUTD) StartUp Grant ISTD 2011 016, SUTD-ZJU Collaboration Research Grant 2012 SUTD-ZJU/RES/03/2012, SUTD-MIT International Design Centre Grant IDG31300106 and Singapore MOE Academic Research Fund MOE2013-T2-1-159. Chi-Keung Tang is supported by the Research Grant Council of the Hong Kong Special Administrative Region under grant no. 619112.	Ackermann J, 2012, PROC CVPR IEEE, P262, DOI 10.1109/CVPR.2012.6247684; Adato Y, 2010, IEEE T PATTERN ANAL, V32, P2054, DOI 10.1109/TPAMI.2010.126; Agrawal A, 2006, LECT NOTES COMPUT SC, V3951, P578; Barron JT, 2013, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2013.10; Blake A., 1985, IJCAI, P973; Chandraker M., 2007, P IEEE C COMPUTER VI, P1; Chen T, 2006, P IEEE C COMP VIS PA, P1825, DOI [10.1109/CVPR.2006.182, DOI 10.1109/CVPR.2006.182]; David Li Yifan, 2013, IEEE Int Conf Rehabil Robot, V2013, P6650373, DOI 10.1109/ICORR.2013.6650373; DEBEVEC PE, 1996, THESIS U CALIFORNIA; Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158; Hullin MB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360686; Ihrke I., 2008, EUROGRAPHICS STAR P, P87; Ihrke I, 2010, COMPUT GRAPH FORUM, V29, P2400, DOI 10.1111/j.1467-8659.2010.01753.x; IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kutulakos KN, 2005, IEEE I CONF COMP VIS, P1448; Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719; Liu MM, 2011, IEEE I CONF COMP VIS, P579, DOI 10.1109/ICCV.2011.6126291; Matusik W, 2000, COMP GRAPH, P369, DOI 10.1145/344779.344951; Miyazaki D, 2004, IEEE T PATTERN ANAL, V26, P73, DOI 10.1109/TPAMI.2004.1261080; Miyazaki D., 2010, IEEE COMP SOC C COMP, P70; Miyazaki D, 2007, IEEE T PATTERN ANAL, V29, P2018, DOI 10.1109/TPAMI.2007.1117; Morris NJW, 2007, IEEE I CONF COMP VIS, P425; Morris NJW, 2005, IEEE I CONF COMP VIS, P1573; Ng HS, 2010, IEEE T PATTERN ANAL, V32, P2085, DOI 10.1109/TPAMI.2009.183; Oren M, 1997, INT J COMPUT VISION, V24, P105, DOI 10.1023/A:1007954719939; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Sai-Kit Yeung, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2513, DOI 10.1109/CVPR.2011.5995472; SANDERSON AC, 1988, IEEE T PATTERN ANAL, V10, P44, DOI 10.1109/34.3866; Shan Q, 2012, PROC CVPR IEEE, P286, DOI 10.1109/CVPR.2012.6247687; Shi BX, 2014, IEEE T PATTERN ANAL, V36, P1078, DOI 10.1109/TPAMI.2013.196; SIMCHONY T, 1990, IEEE T PATTERN ANAL, V12, P435, DOI 10.1109/34.55103; Wu TP, 2006, IEEE T PATTERN ANAL, V28, P1830, DOI 10.1109/TPAMI.2006.224; Yu LF, 2013, PROC CVPR IEEE, P1415, DOI 10.1109/CVPR.2013.186	34	15	15	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2015	37	4					890	897		10.1109/TPAMI.2014.2346195	http://dx.doi.org/10.1109/TPAMI.2014.2346195			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CD6QF	26353301				2022-12-18	WOS:000351213400014
J	Gershman, SJ; Frazier, PI; Blei, DM				Gershman, Samuel J.; Frazier, Peter I.; Blei, David M.			Distance Dependent Infinite Latent Feature Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian nonparametrics; dimensionality reduction; matrix factorization; Indian buffet process; distance functions		Latent feature models are widely used to decompose data into a small number of components. Bayesian nonparametric variants of these models, which use the Indian buffet process (IBP) as a prior over latent features, allow the number of features to be determined from the data. We present a generalization of the IBP, the distance dependent Indian buffet process (dd-IBP), for modeling non-exchangeable data. It relies on distances defined between data points, biasing nearby data to share more features. The choice of distance measure allows for many kinds of dependencies, including temporal and spatial. Further, the original IBP is a special case of the dd-IBP. We develop the dd-IBP and theoretically characterize its feature-sharing properties. We derive a Markov chain Monte Carlo sampler for a linear Gaussian model with a dd-IBP prior and study its performance on real-world non-exchangeable data.	[Gershman, Samuel J.] MIT, Dept Brain & Cognit Sci, Cambridge, MA 02139 USA; [Frazier, Peter I.] Cornell Univ, Sch Operat Res & Informat Engn, Ithaca, NY USA; [Blei, David M.] Princeton Univ, Dept Comp Sci, Princeton, NJ 08544 USA	Massachusetts Institute of Technology (MIT); Cornell University; Princeton University	Gershman, SJ (corresponding author), MIT, Dept Brain & Cognit Sci, E25-618, Cambridge, MA 02139 USA.	sjgershm@mit.edu; pf98@cornell.edu; blei@cs.princeton.edu			US National Science Foundation (NSF) from the MIT Intelligence Initiative; NSF [142251, 1247696, 1254298]; AFOSR [FA9550-11-1-0083, FA9550-12-1-0200]; NSF CAREER [NSF IIS-0745520]; NSF BIGDATA [NSF IIS-1247664]; NSF NEURO [NSF IIS-1009542]; ONR [N00014-11-1-0651]; Alfred P. Sloan foundation; DARPA [FA8750-14-2-0009]; Directorate For Engineering [1254298] Funding Source: National Science Foundation	US National Science Foundation (NSF) from the MIT Intelligence Initiative; NSF(National Science Foundation (NSF)); AFOSR(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); NSF CAREER(National Science Foundation (NSF)NSF - Office of the Director (OD)); NSF BIGDATA; NSF NEURO; ONR(Office of Naval Research); Alfred P. Sloan foundation(Alfred P. Sloan Foundation); DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); Directorate For Engineering(National Science Foundation (NSF)NSF - Directorate for Engineering (ENG))	SJG was supported by a US National Science Foundation (NSF) graduate research fellowship and a postdoctoral fellowship from the MIT Intelligence Initiative. PIF acknowledges support from NSF Awards #142251, #1247696 and #1254298, and from AFOSR Awards FA9550-11-1-0083 and FA9550-12-1-0200. DMB acknowledges support from NSF CAREER NSF IIS-0745520, NSF BIGDATA NSF IIS-1247664, NSF NEURO NSF IIS-1009542, ONR N00014-11-1-0651, the Alfred P. Sloan foundation, and DARPA FA8750-14-2-0009. The authors thank Matt Hoffman, Chong Wang, Gungor Polatkan, Sean Gerrish and John Paisley for helpful discussions. They are also grateful to Sinead Williamson and Mingyuan Zhou for sharing their code.	Ahmed A., 2010, P 26 C UNC ART INT; Beckmann CF, 2003, NEUROIMAGE, V20, P1052, DOI 10.1016/S1053-8119(03)00435-X; Bishop C.M, 2006, PATTERN RECOGN; BLACKWELL D, 1973, ANN STAT, V1, P353, DOI 10.1214/aos/1176342372; Blei DM, 2011, J MACH LEARN RES, V12, P2461; Christou N, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019178; Chung YS, 2011, ANN I STAT MATH, V63, P59, DOI 10.1007/s10463-008-0218-9; Doshi-Velez F., 2009, P 26 ANN INT C MACH, P273; Doshi-Velez F., 2009, P 25 C UNC ART INT, P143; Doucet, 2007, P 23 C UNC ART INT; Duan JA, 2007, BIOMETRIKA, V94, P809, DOI 10.1093/biomet/asm071; ERKINJUNTTI T, 1986, ACTA NEUROL SCAND, V74, P393; ESCOBAR MD, 1995, J AM STAT ASSOC, V90, P577, DOI 10.2307/2291069; Foti N. J., 2012, SURVEY NONEXCHANGEAB; Griffin JE, 2006, J AM STAT ASSOC, V101, P179, DOI 10.1198/016214505000000727; Griffiths T. L., 2005, P ADV NEUR INF PROC, V18; Griffiths TL, 2011, J MACH LEARN RES, V12, P1185; Knowles D, 2007, LECT NOTES COMPUT SC, V4666, P381; Meeds E., 2007, ADV NEURAL INFORM PR, P977; Miller K. T., 2008, P 24 C UNC ART INT; Miller K. T., 2009, P ADV NEUR INF PROC; Navarro DJ, 2008, NEURAL COMPUT, V20, P2597, DOI 10.1162/neco.2008.04-07-504; Rao V., 2009, ADV NEURAL INFORM PR, P1554; Rasmussen CE, 2000, ADV NEUR IN, V12, P554; Ren L., 2011, ADV NEURAL INF PROCE, V24, P963; Robert C, 2004, MONTE CARLO STAT MET, DOI DOI 10.1007/978-1-4757-4145-2; Thibaux Romain, 2007, INT C ART INT STAT, P564; Williamson S., 2010, P INT C ART INT STAT; Woolrich MW, 2004, NEUROIMAGE, V21, P1732, DOI 10.1016/j.neuroimage.2003.12.023; Zhou M., 2011, P INT C ART INT STAT	30	15	15	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2015	37	2					334	345		10.1109/TPAMI.2014.2321387	http://dx.doi.org/10.1109/TPAMI.2014.2321387			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CB4VD	26353245	Green Submitted			2022-12-18	WOS:000349625500010
J	Widynski, N; Mignotte, M				Widynski, Nicolas; Mignotte, Max			A MultiScale Particle Filter Framework for Contour Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Particle filtering; sequential Monte Carlo methods; statistical model; multiscale contour detection; BSDS	SEQUENTIAL MONTE-CARLO; EDGE-DETECTION; IMAGE; MULTIPLE; TRACKING; MODELS	We investigate the contour detection task in complex natural images. We propose a novel contour detection algorithm which jointly tracks at two scales small pieces of edges called edgelets. This multiscale edgelet structure naturally embeds semi-local information and is the basic element of the proposed recursive Bayesian modeling. Prior and transition distributions are learned offline using a shape database. Likelihood functions are learned online, thus are adaptive to an image, and integrate color and gradient information via local, textural, oriented, and profile gradient-based features. The underlying model is estimated using a sequential Monte Carlo approach, and the final soft contour detection map is retrieved from the approximated trajectory distribution. We also propose to extend the model to the interactive cut-out task. Experiments conducted on the Berkeley Segmentation data sets show that the proposed MultiScale Particle Filter Contour Detector method performs well compared to competing state-of-the-art methods.	[Widynski, Nicolas; Mignotte, Max] Univ Montreal, Dept Comp Sci & Operat Res DIRO, Montreal, PQ, Canada	Universite de Montreal	Widynski, N (corresponding author), Univ Montreal, Dept Comp Sci & Operat Res DIRO, Montreal, PQ, Canada.	widynski@iro.umontreal.ca; mignotte@iro.umontreal.ca	Mignotte, Max/F-7014-2015					Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CHEN Z, 2003, TECHNICAL REPORT; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Desolneux A, 2001, J MATH IMAGING VIS, V14, P271, DOI 10.1023/A:1011290230196; Destrempes F, 2004, IEEE T PATTERN ANAL, V26, P626, DOI 10.1109/TPAMI.2004.1273940; Destrempes F, 2007, IEEE T PATTERN ANAL, V29, P1603, DOI 10.1109/TPAMI.2007.1157; Dollar P., 2006, P IEEE COMP SOC C CO, V2, P1964, DOI DOI 10.1109/CVPR.2006.298; Doucet A., 2001, SEQUENTIAL MONTE CAR; Doucet A, 2006, J COMPUT GRAPH STAT, V15, P693, DOI 10.1198/106186006X142744; Felzenszwalb P., 2006, IEEE C COMP VIS PATT, V2006, P185, DOI DOI 10.1109/CVPRW.2006.18; Florin C, 2006, LECT NOTES COMPUT SC, V3953, P476, DOI 10.1007/11744078_37; John M., 2000, LECT NOTES COMPUTER, P3, DOI DOI 10.1007/3-540-45053-X1; Kokkinos I, 2010, LECT NOTES COMPUT SC, V6312, P650, DOI 10.1007/978-3-642-15552-9_47; Lesage D, 2008, I S BIOMED IMAGING, P268, DOI 10.1109/ISBI.2008.4540984; MacCormick J, 2000, INT J COMPUT VISION, V39, P57, DOI 10.1023/A:1008122218374; Mairal J, 2008, LECT NOTES COMPUT SC, V5304, P43, DOI 10.1007/978-3-540-88690-7_4; Maire M., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587420; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Mortensen E. N., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P191, DOI 10.1145/218380.218442; Payet N, 2013, INT J COMPUT VISION, V104, P15, DOI 10.1007/s11263-013-0612-5; Perez P, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P524, DOI 10.1109/ICCV.2001.937670; Ren XF, 2008, LECT NOTES COMPUT SC, V5304, P533; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Sun J, 2011, IEEE T IMAGE PROCESS, V20, P1529, DOI 10.1109/TIP.2010.2095871; Widynski N., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P421, DOI 10.1109/ICSIPA.2011.6144087; Widynski N, 2012, LECT NOTES COMPUT SC, V7572, P780, DOI 10.1007/978-3-642-33718-5_56; Wu B, 2005, IEEE I CONF COMP VIS, P90; Xiaofeng R., 2012, P ADV NEUR INF PROC, P584, DOI DOI 10.1634/THEONCOLOGIST.8-3-252	31	15	17	1	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2014	36	10					1922	1935		10.1109/TPAMI.2014.2307856	http://dx.doi.org/10.1109/TPAMI.2014.2307856			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AP3MX	26352625				2022-12-18	WOS:000341981300002
J	Chen, HZ; Gallagher, AC; Girod, B				Chen, Huizhong; Gallagher, Andrew C.; Girod, Bernd			The Hidden Sides of Names-Face Modeling with First Name Attributes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Facial processing; attributes learning; social contexts; multi-feature fusion	IMPLICIT EGOTISM; RECOGNITION; EIGENFACES	This paper introduces the new idea of describing people using first names. We show that describing people in terms of similarity to a vector of possible first names is a powerful representation of facial appearance that can be used for a number of important applications, such as naming never-seen faces and building facial attribute classifiers. We build models for 100 common first names used in the US and for each pair, construct a pairwise first-name classifier. These classifiers are built using training images downloaded from the internet, with no additional user interaction. This gives our approach important advantages in building practical systems that do not require additional human intervention for data labeling. The classification scores from each pairwise name classifier can be used as a set of facial attributes to describe facial appearance. We show several surprising results. Our name attributes predict the correct first names of test faces at rates far greater than chance. The name attributes are applied to gender recognition and to age classification, outperforming state-of-the-art methods with all training images automatically gathered from the internet. We also demonstrate the powerful use of our name attributes for associating faces in images with names from caption, and the important application of unconstrained face verification.	[Chen, Huizhong; Girod, Bernd] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA; [Gallagher, Andrew C.] Cornell Univ, Sch Elect & Comp Engn, Ithaca, NY 14853 USA; [Gallagher, Andrew C.] Eastman Kodak Co, Rochester, NY 14650 USA; [Gallagher, Andrew C.] TaggPic, Ithaca, NY USA; [Girod, Bernd] Stanford Univ, Informat Syst Lab, Stanford, CA 94305 USA; [Girod, Bernd] Univ Erlangen Nurnberg, Dept Elect Engn, Erlangen, Germany; [Girod, Bernd] Polycom, San Jose, CA USA; [Girod, Bernd] Vivo Software, New York, NY USA; [Girod, Bernd] 8x8, San Jose, CA USA; [Girod, Bernd] RealNetworks, Seattle, WA USA; [Girod, Bernd] IEEE, New York, NY USA; [Girod, Bernd] EURASIP, Midrand, South Africa	Stanford University; Cornell University; Eastman Kodak; Stanford University; University of Erlangen Nuremberg	Chen, HZ (corresponding author), Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA.	hchen2@stanford.edu; acg226@cornell.edu; bgirod@stanford.edu						Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; [Anonymous], 2014, US SOCIAL SECURITY A; Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Berg T, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.129; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chen, 2009, P IEEE C COMP VIS PA; Chen H., 2013, P IEEE C COMP VIS PA; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Farhadi Ali, 2009, CVPR; Figlio D., 2005, NBER WORKING PAPERS; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36; Gallagher A., 2008, P IEEE C COMP VIS PA; GARWOOD SG, 1980, J APPL SOC PSYCHOL, V10, P431, DOI 10.1111/j.1559-1816.1980.tb00721.x; Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427; Huang GB, 2007, 07 UMASS TR; Jones JT, 2004, J PERS SOC PSYCHOL, V87, P665, DOI 10.1037/0022-3514.87.5.665; Kalist DE, 2009, SOC SCI QUART, V90, P39, DOI 10.1111/j.1540-6237.2009.00601.x; Kanade T., 1973, THESIS KYOTO U; Kumar N., 2008, P EUR C COMP VIS ECC; Kumar Neeraj, 2011, IEEE Trans Pattern Anal Mach Intell, V33, P1962, DOI 10.1109/TPAMI.2011.48; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Lea MA, 2007, PSYCHON B REV, V14, P901, DOI 10.3758/BF03194119; Li L., 2010, P ADV NEUR INF PROCE; Li L., 2010, P EUR C COMP VIS ECC; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003; NUTTIN JM, 1985, EUR J SOC PSYCHOL, V15, P353, DOI 10.1002/ejsp.2420150309; Parikh D., 2011, P IEEE C COMP VIS PA; Pelham B., 2003, J PERS SOC PSYCHOL, V85, P789; Pelham BW, 2002, J PERS SOC PSYCHOL, V82, P469, DOI 10.1037//0022-3514.82.4.469; Pinto N., 2011, P INT C AUT FAC GEST; Torresani L., 2010, P EUR C COMP VIS ECC; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79	40	15	16	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2014	36	9					1860	1873		10.1109/TPAMI.2014.2302443	http://dx.doi.org/10.1109/TPAMI.2014.2302443			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	AM9OE	26352237				2022-12-18	WOS:000340210100012
J	Ben-Ari, R				Ben-Ari, Rami			A Unified Approach for Registration and Depth in Depth from Defocus	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D reconstruction; registration; focus sensing; depth from defocus; extended depth of field; GPU computing	COMPUTATION	Depth from Defocus (DFD) suggests a simple optical set-up to recover the shape of a scene through imaging with shallow depth of field. Although numerous methods have been proposed for DFD, less attention has been paid to the particular problem of alignment between the captured images. The inherent shift-variant defocus often prevents standard registration techniques from achieving the accuracy needed for successful shape reconstruction. In this paper, we address the DFD and registration problem in a unified framework, exploiting their mutual relation to reach a better solution for both cues. We draw a formal connection between registration and defocus blur, find its limitations and reveal the weakness of the standard isolated approaches of registration and depth estimation. The solution is approached by energy minimization. The efficiency of the associated numerical scheme is justified by showing its equivalence to the celebrated Newton-Raphson method and proof of convergence of the emerged linear system. The computationally intensive approach of DFD, newly combined with simultaneous registration, is handled by GPU computing. Experimental results demonstrate the high sensitivity of the recovered shapes to slight errors in registration and validate the superior performance of the suggested approach over two, separately applying registration and DFD alternatives.	Orbotech Ltd, IL-81101 Yavne, Israel		Ben-Ari, R (corresponding author), Orbotech Ltd, IL-81101 Yavne, Israel.	benari.rami@gmail.com						BAGNARA R, 1995, SIAM REV, V37, P93, DOI 10.1137/1037008; Ben-Ari Rami, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P522, DOI 10.1109/ICCVW.2011.6130287; Ben-Ari R, 2010, IEEE T PATTERN ANAL, V32, P2071, DOI 10.1109/TPAMI.2010.32; Ben-Ari R, 2009, J MATH IMAGING VIS, V33, P178, DOI 10.1007/s10851-008-0124-z; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; ENS J, 1993, IEEE T PATTERN ANAL, V15, P97, DOI 10.1109/34.192482; Favaro P, 2005, IEEE T PATTERN ANAL, V27, P406, DOI 10.1109/TPAMI.2005.43; Favaro P., 2010, P IEEE C CVPR SAN FR; Favaro P., 2007, 3 D SHAPE ESTIMATION; Favaro P, 2008, IEEE T PATTERN ANAL, V30, P518, DOI 10.1109/TPAMI.2007.1175; GREEN P, 2007, P ACM SIGGRAPH; Gupta M, 2011, PROC CVPR IEEE, P713, DOI 10.1109/CVPR.2011.5995321; Gwosdek P., 2010, P 3 ECCV WORKSH CVGP; Hasinoff S, 2009, INT J COMPUT VISION, V81, P82, DOI 10.1007/s11263-008-0164-2; Heo YS, 2011, IEEE T PATTERN ANAL, V33, P807, DOI 10.1109/TPAMI.2010.136; Kumar A., 2013, P INT C COMP PHOT CA, P112; Levin A., 2007, P SIGGRAPH; Lin X., 2013, P ICCP CAMBR MA US; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mairal J., 2006, P 3DPVT CHAP HILL NC; Myles Z, 1998, IEEE T PATTERN ANAL, V20, P652, DOI 10.1109/34.683782; Papenberg N, 2006, INT J COMPUT VISION, V67, P141, DOI 10.1007/s11263-005-3960-y; Park SY, 2006, PATTERN RECOGN LETT, V27, P1318, DOI 10.1016/j.patrec.2006.01.003; Robinson D, 2004, IEEE T IMAGE PROCESS, V13, P1185, DOI 10.1109/TIP.2004.832923; Rosman G, 2011, J MATH IMAGING VIS, V40, P199, DOI 10.1007/s10851-010-0254-y; Rosman G, 2009, SIAM J IMAGING SCI, V2, P858, DOI 10.1137/080728391; Sabater N, 2012, IEEE T PATTERN ANAL, V34, P930, DOI 10.1109/TPAMI.2011.207; SUBBARAO M, 1994, INT J COMPUT VISION, V13, P271, DOI 10.1007/BF02028349; Sundaram N, 2010, LECT NOTES COMPUT SC, V6311, P438, DOI 10.1007/978-3-642-15549-9_32; Szeliski R., 1993, P CVPR; Watanabe M, 1996, P SOC PHOTO-OPT INS, V2599, P14, DOI 10.1117/12.230388; Watanabe M, 1998, INT J COMPUT VISION, V27, P203, DOI 10.1023/A:1007905828438; Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1; Zhou C., 2009, P ICCV	35	15	15	2	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2014	36	6					1041	1055		10.1109/TPAMI.2014.14	http://dx.doi.org/10.1109/TPAMI.2014.14			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AI8AJ	26353270				2022-12-18	WOS:000337124200001
J	d'Angelo, E; Jacques, L; Alahi, A; Vandergheynst, P				d'Angelo, Emmanuel; Jacques, Laurent; Alahi, Alexandre; Vandergheynst, Pierre			From Bits to Images: Inversion of Local Binary Descriptors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computer vision; inverse problems; image reconstruction; BRIEF; FREAK; privacy		Local Binary Descriptors are becoming more and more popular for image matching tasks, especially when going mobile. While they are extensively studied in this context, their ability to carry enough information in order to infer the original image is seldom addressed. In this work, we leverage an inverse problem approach to show that it is possible to directly reconstruct the image content from Local Binary Descriptors. This process relies on very broad assumptions besides the knowledge of the pattern of the descriptor at hand. This generalizes previous results that required either a prior learning database or non-binarized features. Furthermore, our reconstruction scheme reveals differences in the way different Local Binary Descriptors capture and encode image information. Hence, the potential applications of our work are multiple, ranging from privacy issues caused by eavesdropping image keypoints streamed by mobile devices to the design of better descriptors through the visualization and the analysis of their geometric content.	[d'Angelo, Emmanuel] Adv Silicon SA, CH-1004 Lausanne, Switzerland; [Vandergheynst, Pierre] Ecole Polytech Fed Lausanne, Signal Proc Labs LTS2, CH-1015 Lausanne, Switzerland; [Alahi, Alexandre] Stanford Univ, Stanford Vis Lab, Stanford, CA 94305 USA; [Jacques, Laurent] Univ Catholique Louvain UCL, ELEN Dept, ICTEAM Inst, B-1348 Louvain, Belgium	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Stanford University; Universite Catholique Louvain	d'Angelo, E (corresponding author), Adv Silicon SA, CH-1004 Lausanne, Switzerland.	emmanuel.dangelo@advancedsilicon.com; laurent.jacques@uclouvain.be; alahi@stanford.edu; pierre.vandergheynst@epfl.ch	Alahi, Alexandre/AAP-5936-2021; Jacques, Laurent/N-7820-2019	Alahi, Alexandre/0000-0002-5004-1498; Jacques, Laurent/0000-0002-6261-0328	Belgian Fund for Scientific Research-F.R.S-FNRS; Swiss National Science Foundation [PBELP2_141078]	Belgian Fund for Scientific Research-F.R.S-FNRS(Fonds de la Recherche Scientifique - FNRS); Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission)	The authors would like to thank the reviewers for their thorough reading of this manuscript, and also Jerome Gilles (UCLA) who contributed to the implementation of the wavelet transforms. The Kata image comes from the iCoseg dataset<SUP>3</SUP> [32]. The results obtained with the algorithm [4] were kindly provided by its authors. Corresponding original images are courtesy of INRIA through the INRIA Copydays dataset. L. Jacques is funded by the Belgian Fund for Scientific Research-F.R.S-FNRS. A. Alahi is funded by the Swiss National Science Foundation under the fellowship PBELP2_141078.	Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715; Batra D, 2011, INT J COMPUT VISION, V93, P273, DOI 10.1007/s11263-010-0415-x; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Blumensath T, 2009, APPL COMPUT HARMON A, V27, P265, DOI 10.1016/j.acha.2009.04.002; Boufounos PT, 2008, 2008 42ND ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, VOLS 1-3, P16, DOI 10.1109/CISS.2008.4558487; Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1; Chang HS, 2009, IEEE IMAGE PROC, P3025, DOI 10.1109/ICIP.2009.5414426; Combettes PL, 2011, SPRINGER SER OPTIM A, V49, P185, DOI 10.1007/978-1-4419-9569-8_10; d'Angelo E., 2012, P 21 ICPR TSUK JAP S, P1; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Gonzalez A., 2012, COMPRESSIVE OPTICAL; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Jacques L, 2013, IEEE T INFORM THEORY, V59, P2082, DOI 10.1109/TIT.2012.2234823; Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MICHELOT C, 1986, J OPTIMIZ THEORY APP, V50, P195, DOI 10.1007/BF00938486; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Perez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269; Plan Y, 2013, COMMUN PUR APPL MATH, V66, P1275, DOI 10.1002/cpa.21442; Raguet H, 2013, SIAM J IMAGING SCI, V6, P1199, DOI 10.1137/120872802; Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34; Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Sidky EY, 2012, PHYS MED BIOL, V57, P3065, DOI 10.1088/0031-9155/57/10/3065; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tumblin J, 2005, PROC CVPR IEEE, P103; Vondrick C., 2013, P ICCV; Weinzaepfel P, 2011, PROC CVPR IEEE, P337, DOI 10.1109/CVPR.2011.5995616	31	15	15	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2014	36	5					874	887		10.1109/TPAMI.2013.228	http://dx.doi.org/10.1109/TPAMI.2013.228			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AH3VN	26353223	Green Submitted			2022-12-18	WOS:000336054200004
J	Cannons, KJ; Wildes, RP				Cannons, Kevin J.; Wildes, Richard P.			The Applicability of Spatiotemporal Oriented Energy Features to Region Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Visual tracking; feature representations; motion analysis; spatiotemporal orientation; visual spacetime	ROBUST; MODELS; FLOW	This paper proposes the novel application of an uncommonly rich feature representation to the domain of visual tracking. The proposed representation for tracking models both the spatial structure and dynamics of a target in a unified fashion, while simultaneously offering robustness to illumination variations. Specifically, the proposed feature is derived from spatiotemporal energy measurements that are computed by filtering in 3D, (x, y, t), image spacetime. These spatiotemporal energy measurements capture the underlying local spacetime orientation structure of the target across multiple scales. The breadth of applicability of these features within the field of visual tracking is demonstrated by their instantiation within three disparate tracking paradigms that are representative of the various basic types of region trackers in the field. Instantiation within these three tracking paradigms requires that the raw oriented energy measurements be post-processed using different methodologies that range from histogram accumulation to the identity transform. Qualitative and quantitative empirical evaluation on a challenging suite of videos demonstrates the strength and applicability of the proposed representation to tracking, as it outperforms other commonly-used features across all tracking paradigms. Moreover, it is shown that overall high tracking accuracy can be obtained with this proposed representation, as spatiotemporal oriented energy instantiations are shown to outperform several recent, state-of-the-art trackers.	[Cannons, Kevin J.; Wildes, Richard P.] York Univ, Dept Comp Sci & Engn, N York, ON M3J 1P3, Canada; [Cannons, Kevin J.; Wildes, Richard P.] York Univ, Ctr Vis Res, N York, ON M3J 1P3, Canada	York University - Canada; York University - Canada	Cannons, KJ (corresponding author), York Univ, Dept Comp Sci & Engn, N York, ON M3J 1P3, Canada.	kcannons@cse.yorku.ca; wildes@cse.yorku.ca			NSERC	NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC))	This research was supported by an NSERC Discovery grant to R. Wildes. The authors also thank Jacob Gryn for assisting with the evaluation and data annotation.	Adam A., 2006, IEEE C COMP VIS PATT; ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; Andriyenko A, 2010, LECT NOTES COMPUT SC, V6311, P466, DOI 10.1007/978-3-642-15549-9_34; Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35; Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737; BERGEN JR, 1992, LECT NOTES COMPUT SC, V588, P237; Beymer D., 1999, P 7 IEEE INT C COMP; Bhattacharyya A., 1943, BULL CALCUTTA MATH S, V35, P99; BIRCHFIELD S, 2005, P IEEE C COMP VIS PA; Birchfield S., 1998, P IEEE C COMP VIS PA; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Bogomolov Y., 2003, BMVC, P142; Brand M, 2000, IEEE T PATTERN ANAL, V22, P844, DOI 10.1109/34.868685; Brox T, 2010, IEEE T PATTERN ANAL, V32, P402, DOI 10.1109/TPAMI.2009.32; Burt P. J., 1989, Proceedings. Workshop on Visual Motion (IEEE Cat. No.89CH2716-9), P2, DOI 10.1109/WVM.1989.47088; Cannons K., 2008, CSE200807 YORK U DEP; Cannons K, 2007, LECT NOTES COMPUT SC, V4843, P532; Cannons KJ, 2010, LECT NOTES COMPUT SC, V6314, P511, DOI 10.1007/978-3-642-15561-1_37; Collins R, 2003, P IEEE C COMP VIS PA; Comaniciu D., 2000, P IEEE C COMP VIS PA; Cremers D, 2003, IMAGE VISION COMPUT, V21, P77, DOI 10.1016/S0262-8856(02)00128-2; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Derpanis KG, 2013, IEEE T PATTERN ANAL, V35, P527, DOI 10.1109/TPAMI.2012.141; Derpanis KG, 2012, IEEE T PATTERN ANAL, V34, P1193, DOI 10.1109/TPAMI.2011.221; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Elgammal A., 2003, P IEEE C COMP VIS PA; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fieguth P., 1997, P IEEE C COMP VIS PA; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19; Hager G., 2004, P IEEE C COMP VIS PA; Haritaoglu I., 2001, P IEEE C COMP VIS PA; Heeger D., 1988, INT J COMPUT VISION, V1, P297; Huang C, 2008, LECT NOTES COMPUT SC, V5303, P788, DOI 10.1007/978-3-540-88688-4_58; Huber P J, 1977, ROBUST STAT PROCEDUR; Intille S.S., 1997, P IEEE C COMP VIS PA; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Jia X., 2012, P IEEE C COMP VIS PA; Kalal Z., 2010, P IEEE C COMP VIS PA; Kwon J., 2010, P IEEE C COMP VIS PA; Kwon J, 2009, PROC CVPR IEEE, P1208, DOI 10.1109/CVPRW.2009.5206502; Lindeberg T., 1994, SCALE SPACE THEORY C; Lucas B. D., 1981, IJCAI, P121, DOI DOI 10.5555/1623264.1623280; MEYER FG, 1994, CVGIP-IMAG UNDERSTAN, V60, P119, DOI 10.1006/ciun.1994.1042; Nejhum S.M.S, 2008, P IEEE C COMP VIS PA; Nguyen HT, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P678, DOI 10.1109/ICCV.2001.937587; Oron S., 2012, P IEEE C COMP VIS PA; Reilly V, 2010, LECT NOTES COMPUT SC, V6313, P186; Ross D., 2004, P 8 EUR C COMP VIS; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; SAFFARI A., 2010, P IEEE C COMP VIS PA; Santner J, 2010, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2010.5540145; Sato K, 2004, COMPUT VIS IMAGE UND, V96, P100, DOI 10.1016/j.cviu.2004.02.003; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Simoncelli E, 1993, THESIS MIT; Sizintsev M, 2012, IEEE T PATTERN ANAL, V34, P1206, DOI 10.1109/TPAMI.2011.202; Song B, 2010, LECT NOTES COMPUT SC, V6311, P605, DOI 10.1007/978-3-642-15549-9_44; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Wang F., 2008, P INT C CONTR AUT RO; Wildes R., 2000, P IEEE EUR C COMP VI, P784; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; YANG C, 2005, P IEEE C COMP VIS PA; Yao R., 2012, P 12 EUR C COMP VIS; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Yin Z., 2007, P IEEE C COMP VIS PA; Yin Z., 2008, P IEEE WORKSH APPL C; Zaharescu A., 2010, P 11 EUR C COMP VIS; Zeisl B., 2010, P IEEE C COMP VIS PA; ZIVKOVIC Z, 2004, P IEEE C COMP VIS PA	71	15	16	0	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2014	36	4					784	796		10.1109/TPAMI.2013.233	http://dx.doi.org/10.1109/TPAMI.2013.233			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AE6MX	26353200				2022-12-18	WOS:000334109000012
J	Liao, S; Shen, DG; Chung, ACS				Liao, Shu; Shen, Dinggang; Chung, Albert C. S.			A Markov Random Field Groupwise Registration Framework for Face Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; deformable image registration; groupwise registration; Markov random field; correspondences; anatomical signature	IMAGE; SCALE; EIGENFACES	In this paper, we propose a new framework for tackling face recognition problem. The face recognition problem is formulated as groupwise deformable image registration and feature matching problem. The main contributions of the proposed method lie in the following aspects: (1) Each pixel in a facial image is represented by an anatomical signature obtained from its corresponding most salient scale local region determined by the survival exponential entropy (SEE) information theoretic measure. (2) Based on the anatomical signature calculated from each pixel, a novel Markov random field based groupwise registration framework is proposed to formulate the face recognition problem as a feature guided deformable image registration problem. The similarity between different facial images are measured on the nonlinear Riemannian manifold based on the deformable transformations. (3) The proposed method does not suffer from the generalizability problem which exists commonly in learning based algorithms. The proposed method has been extensively evaluated on four publicly available databases: FERET, CAS-PEAL-R1, FRGC ver 2.0, and the LFW. It is also compared with several state-of-the-art face recognition approaches, and experimental results demonstrate that the proposed method consistently achieves the highest recognition rates among all the methods under comparison.	[Liao, Shu; Chung, Albert C. S.] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China; [Shen, Dinggang] Univ N Carolina, Dept Radiol, BRIC, Chapel Hill, NC USA	Hong Kong University of Science & Technology; University of North Carolina; University of North Carolina Chapel Hill	Liao, S (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.	liaoshu.cse@gmail.com; dinggang_shen@med.unc.edu; achung@cse.ust.hk	Shen, Dinggang/ABF-6812-2020; Chung, Albert C. S./GZB-0224-2022	Shen, Dinggang/0000-0002-7934-5698; 	NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [R01EB009634, R01EB008374] Funding Source: NIH RePORTER; NIBIB NIH HHS [R01 EB009634, R01 EB008374] Funding Source: Medline	NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NIBIB NIH HHS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB))		Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Asthana A, 2011, IEEE I CONF COMP VIS, P937, DOI 10.1109/ICCV.2011.6126336; Balci S.K., 2007, MED IMAGE COMPUT COM, V10, P23, DOI DOI 10.1901/JABA.2007.10-23; Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Cootes TF, 2010, IEEE T PATTERN ANAL, V32, P1994, DOI 10.1109/TPAMI.2009.193; Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557; Guo YM, 2012, LECT NOTES COMPUT SC, V7573, P631, DOI 10.1007/978-3-642-33709-3_45; Guo YM, 2012, PATTERN RECOGN, V45, P3834, DOI 10.1016/j.patcog.2012.04.003; He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55; Huang G.B., 2008, WORKSHOP FACESREAL L; Hwang W., 2006, IEEE C COMPUT VIS PA, V2, P1574; Jia HJ, 2010, NEUROIMAGE, V51, P1057, DOI 10.1016/j.neuroimage.2010.03.010; Joshi S, 2004, NEUROIMAGE, V23, pS151, DOI 10.1016/j.neuroimage.2004.07.068; Koelstra S, 2010, IEEE T PATTERN ANAL, V32, P1940, DOI 10.1109/TPAMI.2010.50; Lee MW, 2003, PATTERN RECOGN, V36, P1835, DOI 10.1016/S0031-3203(03)00008-6; Lei Z, 2011, IEEE T IMAGE PROCESS, V20, P247, DOI 10.1109/TIP.2010.2060207; Liao S, 2006, LECT NOTES COMPUT SC, V4191, P964; Liao S, 2010, PROC CVPR IEEE, P2675, DOI 10.1109/CVPR.2010.5539986; Liu CJ, 2006, IEEE T PATTERN ANAL, V28, P725, DOI 10.1109/TPAMI.2006.90; Liu ZM, 2010, PATTERN RECOGN, V43, P2882, DOI 10.1016/j.patcog.2010.03.003; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128; Nowak E, 2007, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2007.382969; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Pan ZH, 2003, IEEE T PATTERN ANAL, V25, P1552, DOI 10.1109/TPAMI.2003.1251148; Phillips PJ, 2005, PROC CVPR IEEE, P947; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Pinto Nicolas, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2591, DOI 10.1109/CVPRW.2009.5206605; Ravela S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P608, DOI 10.1109/ICCV.1998.710780; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Seo HJ, 2011, IEEE T INF FOREN SEC, V6, P1275, DOI 10.1109/TIFS.2011.2159205; Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964; Shen DG, 1999, IMAGE VISION COMPUT, V17, P489, DOI 10.1016/S0262-8856(98)00141-3; Su Y, 2009, IEEE T IMAGE PROCESS, V18, P1885, DOI 10.1109/TIP.2009.2021737; Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Thomas M., 1991, ELEMENTS INFORM THEO; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; ul Hussain S, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.99; Vercauteren T, 2009, NEUROIMAGE, V45, pS61, DOI 10.1016/j.neuroimage.2008.10.040; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235; Wolf L., 2008, P FACES REAL LIFE IM; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397; Xie XD, 2005, PATTERN RECOGN, V38, P221, DOI 10.1016/j.patcog.2004.07.002; Yousefi S, 2010, IEEE IMAGE PROC, P4549, DOI 10.1109/ICIP.2010.5650670; Zhan YQ, 2006, LECT NOTES COMPUT SC, V4191, P620; Zhang WC, 2005, IEEE I CONF COMP VIS, P786; Zhu M., 2006, RROC INT C COMP VIS, V1, P132, DOI DOI 10.1109/CVPR.2006.271; Zhu ML, 2006, IEEE T PATTERN ANAL, V28, P1274, DOI 10.1109/TPAMI.2006.172; Zografos K, 2005, IEEE T INFORM THEORY, V51, P1239, DOI 10.1109/TIT.2004.842772; Zou J, 2007, IEEE T IMAGE PROCESS, V16, P2617, DOI 10.1109/TIP.2007.904421	62	15	16	0	37	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2014	36	4					657	669		10.1109/TPAMI.2013.141	http://dx.doi.org/10.1109/TPAMI.2013.141			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AE6MX	25506109	Green Accepted, Green Published			2022-12-18	WOS:000334109000003
J	Bengio, S; Deng, L; Larochelle, H; Lee, H; Salakhutdinov, R				Bengio, Samy; Deng, Li; Larochelle, Hugo; Lee, Honglak; Salakhutdinov, Ruslan			Guest Editors' Introduction: Special Section on Learning Deep Architectures	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Editorial Material									[Bengio, Samy] Google Res, Mountain View, CA 94043 USA; [Deng, Li] Microsoft Res, Redmond, WA 98052 USA; [Larochelle, Hugo] Univ Sherbrooke, Dept Informat, Sherbrooke, PQ J1K 2R1, Canada; [Lee, Honglak] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA; [Salakhutdinov, Ruslan] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada; [Salakhutdinov, Ruslan] Univ Toronto, Dept Stat, Toronto, ON M5S 3G4, Canada	Google Incorporated; Microsoft; University of Sherbrooke; University of Michigan System; University of Michigan; University of Toronto; University of Toronto	Bengio, S (corresponding author), Google Res, 1600 Amphitheatre Pkwy, Mountain View, CA 94043 USA.	bengio@google.com; deng@microsoft.com; hugo.larochelle@usherbrooke.ca; honglak@eecs.umich.edu; rsalakhu@cs.toronto.edu	Jeong, Yongwook/N-7413-2016						0	15	17	1	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2013	35	8					1795	1797		10.1109/TPAMI.2013.118	http://dx.doi.org/10.1109/TPAMI.2013.118			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	164AP	23946944				2022-12-18	WOS:000320381400001
J	Darkner, S; Sporring, J				Darkner, Sune; Sporring, Jon			Locally Orderless Registration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Similarity measure; registration; Normalized Mutual Information; Sum of Squared Differences; density estimation; local histogram; scale space; Locally Orderless Images	MULTIMODALITY IMAGE REGISTRATION; MUTUAL-INFORMATION; INTERPOLATION	This paper presents a unifying approach for calculating a wide range of popular, but seemingly very different, similarity measures. Our domain is the registration of n-dimensional images sampled on a regular grid, and our approach is well suited for gradient-based optimization algorithms. Our approach is based on local intensity histograms and built upon the technique of Locally Orderless Images. Histograms by Locally Orderless Images are well posed and offer explicit control over the three inherent and unavoidable scales: the spatial resolution, intensity levels, and spatial extent of local histograms. Through Locally Orderless Images, we offer new insight into the relations between these scales. We demonstrate our unification by developing a Locally Orderless Registration algorithm for two quite different similarity measures, namely, Normalized Mutual Information and Sum of Squared Differences, and we compare these variations both theoretically and empirically. Finally, using our algorithm, we explain the empirically observed differences between two popular joint density estimation techniques used in registration: Parzen Windows and Generalized Partial Volume.	[Darkner, Sune; Sporring, Jon] Univ Copenhagen, Dept Comp Sci, DK-2100 Copenhagen, Denmark	University of Copenhagen	Darkner, S (corresponding author), Univ Copenhagen, Dept Comp Sci, Univ Pk 1, DK-2100 Copenhagen, Denmark.	darkner@diku.dk; sporring@diku.dk	Sporring, Jon/L-4499-2016; Darkner, Sune/N-1834-2016	Sporring, Jon/0000-0003-1261-6702; Darkner, Sune/0000-0001-6114-7100	Oticon foundation; Villum Fonden [00008721] Funding Source: researchfish	Oticon foundation; Villum Fonden(Villum Fonden)	Sune Darkner would like to thank the Oticon foundation for supporting his work through the project grant "A Fast and Personalized Biomechanical Model."	Bruce J.W., 1992, CURVES SINGULARITIES; Chen HM, 2003, IEEE T MED IMAGING, V22, P1111, DOI 10.1109/TMI.2003.816949; Christensen GE, 1996, IEEE T IMAGE PROCESS, V5, P1435, DOI 10.1109/83.536892; COLLIGNON A, 1995, COMP IMAG VIS, V3, P263; Darkner S., 2012, LOCALLY ORDERLESS RE; Darkner S, 2011, LECT NOTES COMPUT SC, V6801, P436, DOI 10.1007/978-3-642-22092-0_36; Darkner S, 2011, LECT NOTES COMPUT SC, V6688, P295, DOI 10.1007/978-3-642-21227-7_28; Florack L, 1999, INT J COMPUT VISION, V31, P247, DOI 10.1023/A:1008026217765; Griffin L., 2006, P 3 INT C SCAL SPAC; Griffin LD, 1997, IMAGE VISION COMPUT, V15, P369, DOI 10.1016/S0262-8856(97)87979-6; Haber E, 2007, METHOD INFORM MED, V46, P292, DOI 10.1160/ME9046; Hermosillo G, 2002, INT J COMPUT VISION, V50, P329, DOI 10.1023/A:1020830525823; Koenderink JJ, 1999, INT J COMPUT VISION, V31, P159, DOI 10.1023/A:1008065931878; Loeckx D, 2007, LECT NOTES COMPUT SC, V4584, P725; Loeckx D, 2006, LECT NOTES COMPUT SC, V4057, P206; Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664; Maes F, 1999, Med Image Anal, V3, P373, DOI 10.1016/S1361-8415(99)80030-9; Marcus DS, 2007, J COGNITIVE NEUROSCI, V19, P1498, DOI 10.1162/jocn.2007.19.9.1498; Modat M, 2010, COMPUT METH PROG BIO, V98, P278, DOI 10.1016/j.cmpb.2009.09.002; Pluim JPW, 2000, COMPUT VIS IMAGE UND, V77, P211, DOI 10.1006/cviu.1999.0816; Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867; Rajwade A, 2009, IEEE T PATTERN ANAL, V31, P475, DOI 10.1109/TPAMI.2008.97; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; Sommer S., 2011, P 22 INT C INF PROC; Sporring J, 1999, IEEE T INFORM THEORY, V45, P1051, DOI 10.1109/18.761342; Sporring J., 2011, 4 U COP DEP COMP SCI; Studholme C, 1999, PATTERN RECOGN, V32, P71, DOI 10.1016/S0031-3203(98)00091-0; Thevenaz P, 2000, IEEE T IMAGE PROCESS, V9, P2083, DOI 10.1109/83.887976; Wells W M 3rd, 1996, Med Image Anal, V1, P35; Zhuang XH, 2011, IEEE T MED IMAGING, V30, P1819, DOI 10.1109/TMI.2011.2150240	31	15	15	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2013	35	6					1437	1450		10.1109/TPAMI.2012.238	http://dx.doi.org/10.1109/TPAMI.2012.238			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	129QV	23599057	Green Submitted, Green Published			2022-12-18	WOS:000317857900013
J	Vondrak, M; Sigal, L; Jenkins, OC				Vondrak, Marek; Sigal, Leonid; Jenkins, Odest Chadwicke			Dynamical Simulation Priors for Human Motion Tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Articulated tracking; human pose tracking; human motion; physical simulation; physics-based priors; Bayesian filtering; particle filtering	INVERSE DYNAMICS	We propose a simulation-based dynamical motion prior for tracking human motion from video in presence of physical ground-person interactions. Most tracking approaches to date have focused on efficient inference algorithms and/or learning of prior kinematic motion models; however, few can explicitly account for the physical plausibility of recovered motion. Here, we aim to recover physically plausible motion of a single articulated human subject. Toward this end, we propose a full-body 3D physical simulation-based prior that explicitly incorporates a model of human dynamics into the Bayesian filtering framework. We consider the motion of the subject to be generated by a feedback "control loop" in which Newtonian physics approximates the rigid-body motion dynamics of the human and the environment through the application and integration of interaction forces, motor forces, and gravity. Interaction forces prevent physically impossible hypotheses, enable more appropriate reactions to the environment (e.g., ground contacts), and are produced from detected human-environment collisions. Motor forces actuate the body, ensure that proposed pose transitions are physically feasible, and are generated using a motion controller. For efficient inference in the resulting high-dimensional state space, we utilize an exemplar-based control strategy that reduces the effective search space of motor forces. As a result, we are able to recover physically plausible motion of human subjects from monocular and multiview video. We show, both quantitatively and qualitatively, that our approach performs favorably with respect to Bayesian filtering methods with standard motion priors.	[Vondrak, Marek; Jenkins, Odest Chadwicke] Brown Univ, Dept Comp Sci, Providence, RI 02912 USA; [Sigal, Leonid] Disney Res, Pittsburgh, PA 15213 USA	Brown University	Vondrak, M (corresponding author), Brown Univ, Dept Comp Sci, POB 1910,4th Floor,115 Waterman St, Providence, RI 02912 USA.	marek@cs.brown.edu; lsigal@disneyresearch.com; cjenkins@cs.brown.edu		Jenkins, Odest/0000-0003-3750-7334	US Office of Naval Research (ONR) Young Investigator Award [N000140710141]; ONR Presidential Early Career Awards for Scientists and Engineers (PECASE) Award [N000140810910]	US Office of Naval Research (ONR) Young Investigator Award(Office of Naval Research); ONR Presidential Early Career Awards for Scientists and Engineers (PECASE) Award	This work was supported in part by the US Office of Naval Research (ONR) Young Investigator Award N000140710141 and ONR Presidential Early Career Awards for Scientists and Engineers (PECASE) Award N000140810910. The authors wish to thank Michael J. Black for valuable contributions in the early stages of this project; Alexandru Balan for the PF code; David Fleet for insightful discussions; Matt Loper, Deqing Sun, and the reviewers for feedback on the paper itself; Morgan McGuire, and German Gonzalez for discussions; Sarah Jenkins for proofreading.	Balan A. O., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P349; Balan Alexandru O., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383340; Bandouch J, 2008, LECT NOTES COMPUT SC, V5098, P248, DOI 10.1007/978-3-540-70517-8_24; Baraff D., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P137, DOI 10.1145/237170.237226; Bo LF, 2008, PROC CVPR IEEE, P1833; Brubaker MA, 2008, PROC CVPR IEEE, P1586; Brubaker MA, 2009, IEEE I CONF COMP VIS, P2389, DOI 10.1109/ICCV.2009.5459407; Brubaker MA, 2007, PROC CVPR IEEE, P2644; Chai JX, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239459; Chakraborty N., 2007, P ROB SCI SYST; Deutscher J, 2005, INT J COMPUT VISION, V61, P185, DOI 10.1023/B:VISI.0000043757.18370.9c; DeVita P, 2000, J APPL PHYSIOL, V88, P1804, DOI 10.1152/jappl.2000.88.5.1804; Faloutsos P, 2001, COMP GRAPH, P251, DOI 10.1145/383259.383287; Fang AC, 2003, ACM T GRAPHIC, V22, P417, DOI 10.1145/882262.882286; Forsyth D. A., 2006, FDN TRENDS COMPUTER, V1, P77; Gordon N, 2001, SEQENTIAL MONTE CARL; Grauman K, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P641; Hodgins J. K., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P71, DOI 10.1145/218380.218414; JENKINS OC, 2004, INT J HUM ROBOT, V1, P237, DOI [10.1142/S0219843604000186, DOI 10.1142/S0219843604000186]; Kokkevis E., 2004, P GAM DEV C; Kuo AD, 1998, J BIOMECH ENG-T ASME, V120, P148, DOI 10.1115/1.2834295; Lee CS, 2007, IEEE I CONF COMP VIS, P1570; Li R, 2007, IEEE I CONF COMP VIS, P1687; Li R, 2010, INT J COMPUT VISION, V87, P170, DOI 10.1007/s11263-009-0283-4; Lu Z., 2007, P NEUR INF PROC SYST, P1705; McCann J., 2006, P 2006 ACM SIGGRAPH, P205; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; Michel P, 2006, IEEE INT CONF ROBOT, P3089, DOI 10.1109/ROBOT.2006.1642171; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; Nakamura Y, 2000, IEEE T ROBOTIC AUTOM, V16, P124, DOI 10.1109/70.843167; Pavlovic V., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P94, DOI 10.1109/ICCV.1999.791203; Popovic Z, 1999, COMP GRAPH, P11, DOI 10.1145/311535.311536; Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016; Riemer R, 2008, J BIOMECH, V41, P1503, DOI 10.1016/j.jbiomech.2008.02.011; Rosenhahn B, 2008, PROC CVPR IEEE, P1381; Rosenhahn B, 2008, LECT NOTES COMPUT SC, V5096, P385, DOI 10.1007/978-3-540-69321-5_39; Safonova A, 2004, ACM T GRAPHIC, V23, P514, DOI 10.1145/1015706.1015754; Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; Siciliano B., 2008, SPRINGER HDB ROBOTIC, DOI [10.1007/978-3-540-30301-5, DOI 10.1007/978-3-540-30301-5]; Sidenbladh H, 2002, LECT NOTES COMPUT SC, V2350, P784; Sidenbladh H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P709, DOI 10.1109/ICCV.2001.937696; Sigal L., 2006, TECHNICAL REPORT; Sminchisescu C, 2005, PROC CVPR IEEE, P390; Sminchisescu C., 2004, ICML; Spong MW, 2006, ROBOT MODELING CONTR; Stephens B, 2007, IEEE-RAS INT C HUMAN, P589, DOI 10.1109/ICHR.2007.4813931; Urtasun R, 2005, IEEE I CONF COMP VIS, P403; Urtasun R., 2008, P 25 INT C MACHINE L, P1080; Urtasun R., 2006, P IEEE C COMP VIS PA; Urtasun R., 2008, P IEEE C COMP VIS PA; Vondrak M., 2009, MOTION CONTROL; Vondrak M, 2008, PROC CVPR IEEE, P1849; Winter DA, 2009, BIOMECHANICS MOTOR C, DOI 10.1002/9780470549148.ch5; Wren CR, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P22, DOI 10.1109/AFGR.1998.670920; Wrotek P., 2006, P ACM SIGGR S VID; Xu XY, 2007, IEEE I CONF COMP VIS, P968; YAMANE K, 2007, P ROB SCI SYST; Yamane K., 2007, P INT S ROB RES; Yin KK, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360680; Yin KK, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239556; Youngjin Choi, 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P1966; Zordan VB, 2005, ACM T GRAPHIC, V24, P697, DOI 10.1145/1073204.1073249	63	15	16	2	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2013	35	1					52	65		10.1109/TPAMI.2012.61	http://dx.doi.org/10.1109/TPAMI.2012.61			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	037SV	22392709				2022-12-18	WOS:000311127700007
J	Kerautret, B; Lachaud, JO				Kerautret, Bertrand; Lachaud, Jacques-Olivier			Meaningful Scales Detection along Digital Contours for Unsupervised Local Noise Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Local noise detection; discrete geometry; maximal segments; shape analysis	CURVATURE ESTIMATION; STRAIGHTNESS	The automatic detection of noisy or damaged parts along digital contours is a difficult problem since it is hard to distinguish between information and perturbation without further a priori hypotheses. However, solving this issue has a great impact on numerous applications, including image segmentation, geometric estimators, contour reconstruction, shape matching, or image edition. We propose an original strategy to detect what the relevant scales are at which each point of the digital contours should be considered. It relies on theoretical results of asymptotic discrete geometry. A direct consequence is the automatic detection of the noisy or damaged parts of the contour, together with its quantitative evaluation (or noise level). Apart from a given maximal observation scale, the proposed approach does not require any parameter tuning and is easy to implement. We demonstrate its effectiveness on several datasets. We present different direct applications of this local measure to contour smoothing and geometric estimators whose algorithms initially required a noise/scale parameter to tune: They show the pertinence of the proposed measure for digital shape analysis and reconstruction.	[Kerautret, Bertrand] Univ Lorraine, CNRS, UMR 7503, LORIA, F-54506 Vandoeuvre Les Nancy, France; [Lachaud, Jacques-Olivier] Univ Savoie, UFR SFA, Lab Math LAMA, CNRS,UMR 5127, F-73776 Le Bourget Du Lac, France	Centre National de la Recherche Scientifique (CNRS); Universite de Lorraine; Centre National de la Recherche Scientifique (CNRS); CNRS - Institute of Physics (INP); CNRS - National Institute for Mathematical Sciences (INSMI); Universite de Savoie	Kerautret, B (corresponding author), Univ Lorraine, CNRS, UMR 7503, LORIA, Campus Sci,BP 239, F-54506 Vandoeuvre Les Nancy, France.	kerautre@loria.fr; jacques-olivier.lachaud@univ-savoie.fr	Lachaud, Jacques-Olivier/AAL-1080-2020					Barash D, 2002, IEEE T PATTERN ANAL, V24, P844, DOI 10.1109/TPAMI.2002.1008390; Bhowmick P, 2007, IEEE T PATTERN ANAL, V29, P1590, DOI 10.1109/TPAMI.2007.1082; Bovik A, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, pV, DOI 10.1016/B978-012119792-6/50062-0; BRUCKSTEIN AM, 1991, CONT MATH, V119, P1; Chen K, 2005, IEEE T PATTERN ANAL, V27, P1552, DOI 10.1109/TPAMI.2005.190; Couprie C, 2011, IEEE T PATTERN ANAL, V33, P1384, DOI 10.1109/TPAMI.2010.200; De Vieilleville F, 2007, J MATH IMAGING VIS, V27, P139, DOI 10.1007/s10851-007-0779-x; Debled-Rennesson I, 2006, COMPUT GRAPH-UK, V30, P30, DOI 10.1016/j.cag.2005.10.007; DEBLEDRENNESSON I, 1995, INT J PATTERN RECOGN, V9, P635, DOI 10.1142/S0218001495000249; DORST L, 1984, IEEE T PATTERN ANAL, V6, P450, DOI 10.1109/TPAMI.1984.4767550; Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301; Goshtasby A, 2008, COMPUT VIS IMAGE UND, V111, P155, DOI 10.1016/j.cviu.2007.09.008; Hoang T.V., 2011, P IEEE 18 INT C IM P; JEONG H, 1992, IEEE T PATTERN ANAL, V14, P579, DOI 10.1109/34.134062; KANUNGO T, 1996, THESIS U WASHINGTON; Kerautret B, 2009, PATTERN RECOGN, V42, P2265, DOI 10.1016/j.patcog.2008.11.013; Kerautret B., 2010, MS ONLINE DEMONSTRAT; Kerautret B., 2011, ONLINE ANNEX ARTICLE; Kerautret B, 2009, LECT NOTES COMPUT SC, V5852, P187, DOI 10.1007/978-3-642-10210-3_15; Kervrann C, 2004, LECT NOTES COMPUT SC, V3023, P132; Klette R, 2004, DISCRETE APPL MATH, V139, P197, DOI 10.1016/j.dam.2002.12.001; Klette R., 2004, DIGITAL GEOMETRY GEO; Lachaud J.O., 2006, ESPACES NONEUCLIDIEN; Lachaud JO, 2007, IMAGE VISION COMPUT, V25, P1572, DOI 10.1016/j.imavis.2006.06.019; Liu HR, 2008, INT J COMPUT VISION, V80, P104, DOI 10.1007/s11263-008-0131-y; Malgouyres R, 2008, LECT NOTES COMPUT SC, V4992, P370, DOI 10.1007/978-3-540-79126-3_33; MARJI M, 2003, THESIS WAYNE STATE U; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; Nguyen TP, 2007, LECT NOTES COMPUT SC, V4673, P474; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; ROSENFELD A, 1974, IEEE T COMPUT, VC 23, P1264, DOI 10.1109/T-C.1974.223845; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729	34	15	15	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2012	34	12					2379	2392		10.1109/TPAMI.2012.38	http://dx.doi.org/10.1109/TPAMI.2012.38			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	021VO	22271824				2022-12-18	WOS:000309913700008
J	Xiu, PP; Baird, HS				Xiu, Pingping; Baird, Henry S.			Whole-Book Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Whole-book recognition; document image recognition; book recognition; style consistency; isogeny; adaptive classification; adaptive OCR; adaptive machine learning; model adaptation; anytime algorithm; cross entropy	CLASSIFICATION	Whole-book recognition is a document image analysis strategy that operates on the complete set of a book's page images using automatic adaptation to improve accuracy. We describe an algorithm which expects to be initialized with approximate iconic and linguistic models-derived from (generally errorful) OCR results and (generally imperfect) dictionaries-and then, guided entirely by evidence internal to the test set, corrects the models which, in turn, yields higher recognition accuracy. The iconic model describes image formation and determines the behavior of a character-image classifier, and the linguistic model describes word-occurrence probabilities. Our algorithm detects "disagreements" between these two models by measuring cross entropy between 1) the posterior probability distribution of character classes (the recognition results resulting from image classification alone) and 2) the posterior probability distribution of word classes (the recognition results from image classification combined with linguistic constraints). We show how disagreements can identify candidates for model corrections at both the character and word levels. Some model corrections will reduce the error rate over the whole book, and these can be identified by comparing model disagreements, summed across the whole book, before and after the correction is applied. Experiments on passages up to 180 pages long show that when a candidate model adaptation reduces whole-book disagreement, it is also likely to correct recognition errors. Also, the longer the passage operated on by the algorithm, the more reliable this adaptation policy becomes, and the lower the error rate achieved. The best results occur when both the iconic and linguistic models mutually correct one another. We have observed recognition error rates driven down by nearly an order of magnitude fully automatically without supervision (or indeed without any user intervention or interaction). Improvement is nearly monotonic, and asymptotic accuracy is stable, even over long runs. If implemented naively, the algorithm runs in time quadratic in the length of the book, but random subsampling and caching techniques speed it up by two orders of magnitude with negligible loss of accuracy. Whole-book recognition has potential applications in digital libraries as a safe unsupervised anytime algorithm.	[Xiu, Pingping] Microsoft Advertising R&D, Redmond, WA 98052 USA; [Baird, Henry S.] Lehigh Univ, Dept Comp Sci & Engn, Bethlehem, PA 18015 USA	Lehigh University	Xiu, PP (corresponding author), Microsoft Advertising R&D, 1 Microsoft Way, Redmond, WA 98052 USA.	pingxiu@imdb.com; baird@cse.lehigh.edu			BBN Technologies on US Federal Government [HR0011-08-C-004]	BBN Technologies on US Federal Government	The authors are grateful for insightful criticism offered by Siyuan Chen, Brian D. Davison, Jianying Hu, Henry F. Korth, Dar-Shyang Lee, Daniel P. Lopresti, George Nagy, Prateek Sarkar, Faisal Shafait, and Ray Smith. They are especially happy also to acknowledge Prof. Cheng and his students in the Beijing Institute of Information Science and Technology for crucial assistance in manual ground-truthing a book's 180 page images, which were provided to the international research community by Google, Inc. This research was also supported, in part, by a subcontract from BBN Technologies on US Federal Government contract HR0011-08-C-004.	Breuel TM, 2001, INT CONF ACOUST SPEE, P1333, DOI 10.1109/ICASSP.2001.941172; Decerbo M, 2005, PROC INT CONF DOC, P411, DOI 10.1109/ICDAR.2005.189; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; FANG C, 1995, P SOC PHOTO-OPT INS, V2422, P76, DOI 10.1117/12.205843; Fang C., 1997, THESIS STATE U NEW Y; Hamamura T., 2007, P IAPR 9 INT C DOC A; Ho T. K., 2000, P IAPR 15 INT C PATT, V4, P4027; HONG T, 1995, THESIS STATE U NEW Y; Huang G., 2007, P IAPR 9 INT C DOC A; KAM A, 1993, THESIS MIT; KANUNGO T, 1996, THESIS U WASHINGTON; Kopec G., 2002, P IS T SPIE EL IM 20; KOPEC GE, 1994, IEEE T PATTERN ANAL, V16, P602, DOI 10.1109/34.295905; Leishman S., 2007, THESIS U TORONTO; Li YH, 1996, IEEE T PATTERN ANAL, V18, P99, DOI 10.1109/34.481536; Minka T. P., 2001, P IS T SPIE EL IM 01; NAGY G, 1966, IEEE T INFORM THEORY, V12, P215, DOI 10.1109/TIT.1966.1053864; NAGY G, 1987, IEEE T PATTERN ANAL, V9, P710, DOI 10.1109/TPAMI.1987.4767969; Nagy G., 1994, P IS T SPIE S EL IM; Popat K., 2001, P IS T SPIE EL IM 01; Sarkar P, 2005, IEEE T PATTERN ANAL, V27, P88, DOI 10.1109/TPAMI.2005.18; Sarkar P., 2003, P IAPR 7 INT C DOC A; Sarkar P., 2002, P IAPR 16 INT C PATT, V4, P40; SHORE JE, 1981, IEEE T INFORM THEORY, V27, P472, DOI 10.1109/TIT.1981.1056373; Suzuki A., 1993, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ76D-II, P464; Veeramachaneni S, 2005, IEEE T PATTERN ANAL, V27, P14, DOI 10.1109/TPAMI.2005.19; Veeramachaneni S, 2007, IEEE T PATTERN ANAL, V29, P1280, DOI 10.1109/TPAMI.2007.1030; Vincent L., 2007, P IAPR 9 INT C DOC A; Weinman J., 2007, P IAPR 9 INT C DOC A; Xiu P., 2010, P 9 IAPR DOC AN WORK; Xiu P., 2008, P 8 IAPR DOC AN WORK; Xiu P., 2009, P IAPR 10 INT C DOC; Xiu P., 2010, P IS T SPIE DOC REC; Xiu P., 2010, P IAPR 20 INT C PATT; Xiu P., 2008, P IS T SPIE DOC REC; Zilberstein S, 1996, AI MAG, V17, P73	36	15	15	0	15	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2012	34	12					2467	2480		10.1109/TPAMI.2012.50	http://dx.doi.org/10.1109/TPAMI.2012.50			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	021VO	22350165				2022-12-18	WOS:000309913700014
J	Weng, MF; Chuang, YY				Weng, Ming-Fang; Chuang, Yung-Yu			Cross-Domain Multicue Fusion for Concept-Based Video Indexing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Video annotation; concept detection; cross-domain learning; contextual correlation; temporal dependency; TRECVID	RETRIEVAL; FRAMEWORK	The success of query-by-concept, proposed recently to cater to video retrieval needs, depends greatly on the accuracy of concept-based video indexing. Unfortunately, it remains a challenge to recognize the presence of concepts in a video segment or to extract an objective linguistic description from it because of the semantic gap, that is, the lack of correspondence between machine-extracted low-level features and human high-level conceptual interpretation. This paper studies three issues with the aim to reduce such a gap: 1) how to explore cues beyond low-level features, 2) how to combine diverse cues to improve performance, and 3) how to utilize the learned knowledge when applying it to a new domain. To solve these problems, we propose a framework that jointly exploits multiple cues across multiple video domains. First, recursive algorithms are proposed to learn both interconcept and intershot relationships from annotations. Second, all concept labels for all shots are simultaneously refined in a single fusion model. Additionally, unseen shots are assigned pseudolabels according to their initial prediction scores so that contextual and temporal relationships can be learned, thus requiring no additional human effort. Integration of cues embedded within training and testing video sets accommodates domain change. Experiments on popular benchmarks show that our framework is effective, achieving significant improvements over popular baselines.	[Weng, Ming-Fang; Chuang, Yung-Yu] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10617, Taiwan	National Taiwan University	Weng, MF (corresponding author), Natl Taiwan Univ, Dept Comp Sci & Informat Engn, 1,Sec 4,Roosevelt Rd, Taipei 10617, Taiwan.	mfueng@cmlab.csie.ntu.edu.tw; cyy@csie.ntu.edu.tw		Chuang, Yung-Yu/0000-0002-1383-0017	National Science Council of Taiwan, R.O.C. [NSC100-2628-E-002-009, NSC100-2622-E-002-016-CC2]	National Science Council of Taiwan, R.O.C.(Ministry of Science and Technology, Taiwan)	Project website and codes along with experimental data available at http://www.cmlab.csie.ntu.edu.tw/similar to mfueng/CBVI.html. This work was supported by the National Science Council of Taiwan, R.O.C., under grants NSC100-2628-E-002-009 and NSC100-2622-E-002-016-CC2.	Adams WH, 2003, EURASIP J APPL SIG P, V2003, P170, DOI 10.1155/S1110865703211173; AMIR A., 2005, P TRECVID WORKSH; [Anonymous], 2007, P 15 ACM INT C MULTI; Bishop Christopher M., 2007, PATTERN RECOGNITION, V4, DOI 10.1117/1.2819119; Cao J., 2006, P TRECVID WORKSH; Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248; Gupta A, 2009, PROC CVPR IEEE, P2012, DOI 10.1109/CVPRW.2009.5206492; Gupta A, 2007, PROC CVPR IEEE, P2564; Hsu W. H., 2006, P 14 ANN ACM INT C M, P35, DOI [10.1145/1180639.1180654, DOI 10.1145/1180639.1180654]; Hyafil L., 1976, Information Processing Letters, V5, P15, DOI 10.1016/0020-0190(76)90095-8; Jiang W, 2007, INT CONF ACOUST SPEE, P949; Jiang Y G, 2007, P 6 ACM INT C IM VID, P494, DOI DOI 10.1145/1282280.1282352; Jiang Y.-G., 2009, P IEEE INT C COMP VI; Jiang Y.-G., 2008, VELEST USERS GUIDE S; Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235; Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121; Kennedy L. S., 2007, P 6 ACM INT C IM VID, P333, DOI DOI 10.1145/1282280.1282331; Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005; Liu KH, 2008, IEEE T MULTIMEDIA, V10, P240, DOI 10.1109/TMM.2007.911826; Marszaek M., 2009, CVPR, P2929, DOI DOI 10.1109/CVPR.2009.5206557; Moore D. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P80, DOI 10.1109/ICCV.1999.791201; Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63; Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601; Naphade MR, 2002, IEEE T CIRC SYST VID, V12, P40; Press W.H., 1992, NUMERICAL RECIPES C, V2; Qi G.-J., 2007, P 15 INT C MULT, P17, DOI DOI 10.1145/1291233.1291245; Smeaton A.F., 2006, MIR 2006 P 8 ACM INT, P321, DOI DOI 10.1145/1178677.1178722; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Smith JF, 2003, J PHASE EQUILIB, V24, P2, DOI 10.1361/105497103770330947; Snoek C.G., 2006, P 14 ANN ACM INT C M, P421, DOI DOI 10.1145/1180639.1180727; Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014; Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5; WANG D, 2007, P INT WORKSH MULT IN, P61, DOI DOI 10.1145/1290082.1290094; Weng M.-F., 2012, ACM T MULTIM COMPUT, V8, P1; Weng MF, 2008, P 16 ACM INT C MULT, P71, DOI DOI 10.1145/1459359.1459370; Wu JX, 2007, IEEE I CONF COMP VIS, P290, DOI 10.1109/ICCV.2007.4408865; Yan R, 2003, LECT NOTES COMPUT SC, V2728, P238; Yan R, 2007, P 15 ACM INT C MULT, P991, DOI DOI 10.1145/1291233.1291448; Yanagawa A., 2007, VELEST USERS GUIDE S; Yang J, 2006, P 8 ACM SIGMM INT WO, P33, DOI DOI 10.1145/1178677.1178685; Yang YH, 2009, IEEE T CIRC SYST VID, V19, P1880, DOI 10.1109/TCSVT.2009.2026978; Yilmaz E., 2006, P 15 ACM INT C INFOR, P102, DOI [10.1145/1183614.1183633, DOI 10.1145/1183614.1183633]	43	15	15	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2012	34	10					1927	1941		10.1109/TPAMI.2011.273	http://dx.doi.org/10.1109/TPAMI.2011.273			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	988WY	22201049	Green Submitted			2022-12-18	WOS:000307522700005
J	Li, R; Tian, TP; Sclaroff, S				Li, Rui; Tian, Tai-Peng; Sclaroff, Stan			Divide, Conquer and Coordinate: Globally Coordinated Switching Linear Dynamical System	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bayesian learning; nonlinear manifold; nonlinear dynamical model; dynamic texture; human motion	MODELS	The goal of this work is to learn a parsimonious and informative representation for high-dimensional time series. Conceptually, this comprises two distinct yet tightly coupled tasks: learning a low-dimensional manifold and modeling the dynamical process. These two tasks have a complementary relationship as the temporal constraints provide valuable neighborhood information for dimensionality reduction and, conversely, the low-dimensional space allows dynamics to be learned efficiently. Solving these two tasks simultaneously allows important information to be exchanged mutually. If nonlinear models are required to capture the rich complexity of time series, then the learning problem becomes harder as the nonlinearities in both tasks are coupled. A divide, conquer, and coordinate method is proposed. The solution approximates the nonlinear manifold and dynamics using simple piecewise linear models. The interactions and coordinations among the linear models are captured in a graphical model. The model structure setup and parameter learning are done using a variational Bayesian approach, which enables automatic Bayesian model structure selection, hence solving the problem of overfitting. By exploiting the model structure, efficient inference and learning algorithms are obtained without oversimplifying the model of the underlying dynamical process. Evaluation of the proposed framework with competing approaches is conducted in three sets of experiments: dimensionality reduction and reconstruction using synthetic time series, video synthesis using a dynamic texture database, and human motion synthesis, classification, and tracking on a benchmark data set. In all experiments, the proposed approach provides superior performance.	[Li, Rui; Tian, Tai-Peng] Gen Elect Global Res Ctr, Niskayuna, NY 12309 USA; [Sclaroff, Stan] Boston Univ, Coll Arts & Sci, Dept Comp Sci, Boston, MA 02215 USA	General Electric; Boston University	Li, R (corresponding author), Gen Elect Global Res Ctr, 305 Connor Court, Niskayuna, NY 12309 USA.	lir@cs.bu.edu; tian@cs.bu.edu; sclaroff@cs.bu.edu			US National Science Foundation (NSF) [IIS-0308213, IIS-0329009, IIS-0713168,s, CNS-0202067]; Div Of Information & Intelligent Systems [0855065] Funding Source: National Science Foundation	US National Science Foundation (NSF)(National Science Foundation (NSF)); Div Of Information & Intelligent Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This paper reports the work that was supported in part by the US National Science Foundation (NSF) under grants IIS-0308213, IIS-0329009, IIS-0713168,s and CNS-0202067.	Beal M.J., 2003, VARIATIONAL ALGORITH; Beal MJ, 2002, ADV NEUR IN, V14, P577; Black M. J., 2006, CS0608 BROWN U; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dellaportas P, 1999, BIOMETRIKA, V86, P615, DOI 10.1093/biomet/86.3.615; Elgammal A, 2004, PROC CVPR IEEE, P681; Feyman R., 1972, STAT MECH; Fox E., 2008, P ADV NEUR INF PROC; Fox E. B., 2009, THESIS MIT; Gelman A, 2013, BAYESIAN DATA ANAL, P16; Ghahramani Z, 1998, LECT NOTES ARTIF INT, V1387, P168, DOI 10.1007/BFb0053999; Ghahramani Z, 1999, ADV NEUR IN, V11, P431; Ghahramani Z., 1996, EM ALGORITHM MIXTURE; Ghahramani Z., 1998, P ADV NEUR INF PROC, V11, P599; GHAHRAMANI Z, 2000, ADV NEURAL INFORM PR, P507; Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755; Jenkins O. C., 2004, P 21 INT C MACH LEAR, P56, DOI DOI 10.1145/1015330; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Jitsuhiro T, 2003, ASRU'03: 2003 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING ASRU '03, P77, DOI 10.1109/ASRU.2003.1318407; Lawrence N. D., 2007, P 24 INT C MACH LEAR, P481; Lawrence ND, 2004, ADV NEUR IN, V16, P329; Li R., 2009, THESIS BOSTON U; Li R, 2006, LECT NOTES COMPUT SC, V3952, P137; Lin RS, 2006, LECT NOTES COMPUT SC, V3952, P245; MacKay D., 1995, P NEUR INF PROC SYST; MacKay D.J.C., 1997, BOOK ENSEMBLE LEARNI; MACKAY DJC, 1995, ELECTRON LETT, V31, P446, DOI 10.1049/el:19950331; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.448; McDonald D., 2004, PRACTICAL HAZOPS TRI; Moon K., 2006, P CVPR, V1, P198; Oh S. M., 2005, GITGVU0516; PAVLOVIC V., 2000, ADV NEURAL INFORM PR, V13, P981; Poppe R., 2007, P IEEE C COMP VIS PA; Rahimi A, 2007, IEEE T PATTERN ANAL, V29, P1759, DOI 10.1109/TPAMI.2007.1001; Ralaivola L, 2004, ADV NEUR IN, V16, P129; RAUCH HE, 1965, AIAA J, V3, P1445, DOI 10.2514/3.3166; Roweis S, 2002, ADV NEUR IN, V14, P889; RUBIN DB, 1982, PSYCHOMETRIKA, V47, P69, DOI 10.1007/BF02293851; Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI [10.1109/MASSP.1986.1165342, 10.1002/0471250953.bia03as18]; Siddiqi S.M., 2007, ARTIF INTELL, P492; Sigal L, 2004, PROC CVPR IEEE, P421; Singer H., 1996, P INT C AC SPEECH SI, P1890; Sminchisescu C, 2004, P ICML, P96; Takami J., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P573, DOI 10.1109/ICASSP.1992.225855; Taylor GW, 2011, J MACH LEARN RES, V12, P1025; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tian T.-P., 2005, P IEEE C COMP VIS PA, P50; Urtasun R, 2005, IEEE I CONF COMP VIS, P403; URTASUN R, 2008, P IEEE INT C MACH LE; Varsta M, 2001, NEURAL PROCESS LETT, V13, P237, DOI 10.1023/A:1011353011837; Verbeek J, 2006, IEEE T PATTERN ANAL, V28, P1236, DOI 10.1109/TPAMI.2006.166; Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167; Wang JM., 2007, P 24 INT C MACHINE L, P975, DOI DOI 10.1145/1273496.1273619	53	15	16	1	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2012	34	4					654	669		10.1109/TPAMI.2011.152	http://dx.doi.org/10.1109/TPAMI.2011.152			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	896PO	21808088				2022-12-18	WOS:000300581700003
J	Moreno, R; Garcia, MA; Puig, D; Pizarro, L; Burgeth, B; Weickert, J				Moreno, Rodrigo; Angel Garcia, Miguel; Puig, Domenec; Pizarro, Luis; Burgeth, Bernhard; Weickert, Joachim			On Improving the Efficiency of Tensor Voting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Perceptual methods; tensor voting; perceptual grouping; nonlinear approximation; curveness and junctionness propagation	INFERENCE; CURVATURE	This paper proposes two alternative formulations to reduce the high computational complexity of tensor voting, a robust perceptual grouping technique used to extract salient information from noisy data. The first scheme consists of numerical approximations of the votes, which have been derived from an in-depth analysis of the plate and ball voting processes. The second scheme simplifies the formulation while keeping the same perceptual meaning of the original tensor voting: The stick tensor voting and the stick component of the plate tensor voting must reinforce surfaceness, the plate components of both the plate and ball tensor voting must boost curveness, whereas junctionness must be strengthened by the ball component of the ball tensor voting. Two new parameters have been proposed for the second formulation in order to control the potentially conflictive influence of the stick component of the plate vote and the ball component of the ball vote. Results show that the proposed formulations can be used in applications where efficiency is an issue since they have a complexity of order O(1). Moreover, the second proposed formulation has been shown to be more appropriate than the original tensor voting for estimating saliencies by appropriately setting the two new parameters.	[Moreno, Rodrigo] Linkoping Univ, Ctr Med Image Sci & Visualizat CMIV, IMT, S-58185 Linkoping, Sweden; [Moreno, Rodrigo] Linkoping Univ, Dept Med & Hlth Sci IMH, IMT, S-58185 Linkoping, Sweden; [Angel Garcia, Miguel] Autonomous Univ Madrid, Dept Elect & Commun Technol, E-28049 Madrid, Spain; [Puig, Domenec] Univ Rovira & Virgili, Intelligent Robot & Comp Vis Grp, Tarragona 43007, Spain; [Pizarro, Luis] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England; [Pizarro, Luis] Univ Diego Portales, Sch Informat Engn, Santiago, Chile; [Weickert, Joachim] Univ Saarland, Fac Math & Comp Sci, Math Image Anal Grp, D-66041 Saarbrucken, Germany	Linkoping University; Linkoping University; Autonomous University of Madrid; Universitat Rovira i Virgili; Imperial College London; University Diego Portales; Saarland University	Moreno, R (corresponding author), Linkoping Univ, Ctr Med Image Sci & Visualizat CMIV, IMT, Campus US,13th Floor, S-58185 Linkoping, Sweden.	rodrigo.moreno@liu.se; miguelangel.garcia@uam.es; domenec.puig@urv.cat; l.pizarro@imperial.ac.uk; burgeth@math.uni-sb.de; weickert@mia.uni-saarland.de	Garcia, Miguel Angel/C-4304-2014	Garcia, Miguel Angel/0000-0003-2611-6821; Moreno, Rodrigo/0000-0001-5765-2964	Spanish Ministry of Science and Technology [DPI2007-66556-C03-03]	Spanish Ministry of Science and Technology(Ministry of Science and Innovation, Spain (MICINN)Spanish Government)	This research has been partially supported by the Spanish Ministry of Science and Technology (project DPI2007-66556-C03-03).	Andrews EW, 2001, MAT SCI ENG A-STRUCT, V303, P120, DOI 10.1016/S0921-5093(00)01854-2; Belbahri K, 2010, ADV APPL MATH, V45, P548, DOI 10.1016/j.aam.2010.01.010; Bridgman P.W., 1922, DIMENSIONAL ANAL; Bruce V., 2003, VISUAL PERCEPTION PH, V4th; Fischer S, 2007, SIGNAL PROCESS, V87, P2503, DOI 10.1016/j.sigpro.2007.03.019; Franken E, 2006, LECT NOTES COMPUT SC, V3954, P228; Fwa T.F., 2005, HDB HIGHWAY ENG; Guy G, 1997, IEEE T PATTERN ANAL, V19, P1265, DOI 10.1109/34.632985; Guy G, 1996, INT J COMPUT VISION, V20, P113, DOI 10.1007/BF00144119; Jonasson L, 2005, MED IMAGE ANAL, V9, P223, DOI 10.1016/j.media.2004.07.004; Loss L, 2009, COMPUT VIS IMAGE UND, V113, P126, DOI 10.1016/j.cviu.2008.07.011; Lu DF, 2005, LECT NOTES COMPUT SC, V3752, P283; Magee DJ, 2008, ORTHOPEDIC PHYS ASSE, V5th; Marchant T, 2008, SOC CHOICE WELFARE, V31, P693, DOI 10.1007/s00355-008-0298-8; Medioni G., 2000, COMPUTATIONAL FRAMEW; Miller Z, 2005, J BIOMECH, V38, P1855, DOI 10.1016/j.jbiomech.2004.08.018; Min C, 2006, INT C PATT RECOG, P1103; MORDOHAI P, 2006, TENSOR VOTING PERCEP; Mordohai P, 2010, J MACH LEARN RES, V11, P411; Peeters THJM, 2009, MATH VIS, P113, DOI 10.1007/978-3-540-88378-4_6; Reisert M, 2008, PROC CVPR IEEE, P92; RICKETTS JT, 2003, STANDARD HDB CIVIL E; Sornette D, 2006, CRITICAL PHENOMENA N; Tong WS, 2004, IEEE T PATTERN ANAL, V26, P594, DOI 10.1109/TPAMI.2004.1273934; Wu TP, 2010, PROC CVPR IEEE, P1482, DOI 10.1109/CVPR.2010.5539796; WU TP, 2009, CLOSED FORM SOLUTION	26	15	17	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2011	33	11					2215	2228		10.1109/TPAMI.2011.23	http://dx.doi.org/10.1109/TPAMI.2011.23			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	820MM	21282853	Green Published			2022-12-18	WOS:000294910000008
J	Fidalgo-Merino, R; Nunez, M				Fidalgo-Merino, Raul; Nunez, Marlon			Self-Adaptive Induction of Regression Trees	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Machine learning; mining methods and algorithms; knowledge acquisition; heuristics design		A new algorithm for incremental construction of binary regression trees is presented. This algorithm, called SAIRT, adapts the induced model when facing data streams involving unknown dynamics, like gradual and abrupt function drift, changes in certain regions of the function, noise, and virtual drift. It also handles both symbolic and numeric attributes. The proposed algorithm can automatically adapt its internal parameters and model structure to obtain new patterns, depending on the current dynamics of the data stream. SAIRT can monitor the usefulness of nodes and can forget examples from selected regions, storing the remaining ones in local windows associated to the leaves of the tree. On these conditions, current regression methods need a careful configuration depending on the dynamics of the problem. Experimentation suggests that the proposed algorithm obtains better results than current algorithms when dealing with data streams that involve changes with different speeds, noise levels, sampling distribution of examples, and partial or complete changes of the underlying function.	[Fidalgo-Merino, Raul; Nunez, Marlon] Univ Malaga, Dept Lenguajes & Ciencias Computac, E-29071 Malaga, Spain	Universidad de Malaga	Fidalgo-Merino, R (corresponding author), Univ Malaga, Dept Lenguajes & Ciencias Computac, Complejo Tecnol,Campus Teatinos, E-29071 Malaga, Spain.	rfm@uma.es; mnunez@lcc.uma.es	Núñez, Marlon/P-1334-2014	Núñez, Marlon/0000-0001-5374-5231	Junta de Andalucia-Consejeria de Innovacion, Ciencia y Empresa, Spain [P07-TIC-02861]	Junta de Andalucia-Consejeria de Innovacion, Ciencia y Empresa, Spain	The authors wish to thank Elena Ikonomovska and Joao Gama for providing them with the implementation of the FIRT-DD algorithm. The authors appreciate the reviewer's suggestions, which helped them to improve the quality of this paper. This work has been partially supported by the project P07-TIC-02861 of the Junta de Andalucia-Consejeria de Innovacion, Ciencia y Empresa, Spain.	AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470; [Anonymous], P MACH LEARN; Asuncion A, 2007, UCI MACHINE LEARNING; Demsar J, 2006, J MACH LEARN RES, V7, P1; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Domingos P., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P71, DOI 10.1145/347090.347107; Esposito F, 1997, IEEE T PATTERN ANAL, V19, P476, DOI 10.1109/34.589207; Fan W., 2004, P 10 ACM SIGKDD INT, P128, DOI [10.1145/1014052.1014069, DOI 10.1145/1014052.1014069]; GAMA J, 2004, PATTERN RECOGN, P149; Harries MB, 1998, MACH LEARN, V32, P101, DOI 10.1023/A:1007420529897; HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952; Hulten G., 2001, P 7 ACM SIGKDD INT C, P97, DOI DOI 10.1145/502512.502529; IKONOMOVSKA E, 2008, P INT C DISC SCI, P52; Ikonomovska E, 2009, LECT NOTES ARTIF INT, V5808, P121, DOI 10.1007/978-3-642-04747-3_12; Klinkenberg R., 2004, Intelligent Data Analysis, V8, P281; Klinkenberg R., 2000, ICML, P487; Kolter J., 2005, P 22 INT C MACH LEAR, P449, DOI DOI 10.1145/1102351.1102408; Kubat M., 1995, P 8 EUR C MACH LEARN, P307; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; Maloof MA, 2000, MACH LEARN, V41, P27, DOI 10.1023/A:1007661119649; NAGLE JB, 1987, IEEE T COMMUN, V35, P435, DOI 10.1109/TCOM.1987.1096782; NUNEZ M, 2005, P 4 MEX INT C ART IN, P443; Nunez M, 2007, J MACH LEARN RES, V8, P2595; Olshen R., 1984, CLASSIFICATION REGRE; PAXSON V, 2000, RFC 2988 COMPUTING T; POSTEL J, 1981, RFC 793 TCP SPECIFIC; Potts D, 2005, MACH LEARN, V61, P5, DOI 10.1007/s10994-005-1121-8; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; QUINLAN JR, 1992, P 5 AUSTR JOINT C AR, P307; RASMUSSEN CE, 2003, DELVE DATASET REPOSI; ROSENTHAL F, 2009, P INT C MACH LEARN D, P221; Tukey J. W., 1977, EXPLORATORY DATA ANA; VLACHOS P, 2007, STATLIB REPOSITORY; Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1023/A:1018046501280; Widyantoro DH, 1999, PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION KNOWLEDGE MANAGEMENT, CIKM'99, P405, DOI 10.1145/319950.323230; Witten I.H., 2005, P DATA MINING LAS VE, P4	36	15	16	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2011	33	8					1659	1672		10.1109/TPAMI.2011.19	http://dx.doi.org/10.1109/TPAMI.2011.19			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	779UH	21263164				2022-12-18	WOS:000291807200013
J	Pena, JM; Nilsson, R				Pena, Jose M.; Nilsson, Roland			On the Complexity of Discrete Feature Selection for Optimal Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature evaluation and selection; classifier design and evaluation; machine learning		Consider a classification problem involving only discrete features that are represented as random variables with some prescribed discrete sample space. In this paper, we study the complexity of two feature selection problems. The first problem consists in finding a feature subset of a given size k that has minimal Bayes risk. We show that for any increasing ordering of the Bayes risks of the feature subsets (consistent with an obvious monotonicity constraint), there exists a probability distribution that exhibits that ordering. This implies that solving the first problem requires an exhaustive search over the feature subsets of size k. The second problem consists of finding the minimal feature subset that has minimal Bayes risk. In the light of the complexity of the first problem, one may think that solving the second problem requires an exhaustive search over all of the feature subsets. We show that, under mild assumptions, this is not true. We also study the practical implications of our solutions to the second problem.	[Pena, Jose M.] Linkoping Univ, Dept Comp & Informat Sci, S-58183 Linkoping, Sweden; [Nilsson, Roland] Harvard Univ, Sch Med, Dept Syst Biol, Boston, MA 02115 USA	Linkoping University; Harvard University; Harvard Medical School	Pena, JM (corresponding author), Linkoping Univ, Dept Comp & Informat Sci, S-58183 Linkoping, Sweden.	jospe@ida.liu.se; nilsson@chgr.mgh.harvard.edu	Nilsson, Roland/AAJ-3519-2021	Nilsson, Roland/0000-0002-6020-7498	Swedish Research Council [VR-621-2005-4202]; CENIIT at Linkoping University [09.01]	Swedish Research Council(Swedish Research CouncilEuropean Commission); CENIIT at Linkoping University	This work is funded by the Swedish Research Council (ref. VR-621-2005-4202) and CENIIT at Linkoping University (ref. 09.01). The authors thank the associate editor and the anonymous referees for their insightful comments.	COVER TM, 1977, IEEE T SYST MAN CYB, V7, P657, DOI 10.1109/TSMC.1977.4309803; Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Nilsson R, 2007, J MACH LEARN RES, V8, P589; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Pena JM, 2007, INT J APPROX REASON, V45, P211, DOI 10.1016/j.ijar.2006.06.008; Steinwart I, 2002, J MACH LEARN RES, V2, P67, DOI 10.1162/153244302760185252; Tsamardinos I., 2003, P 9 INT WORKSH ART I; TSAMARDINOS I, 2003, P 16 INT FLOR ART IN, P376; VANCAMPENHOUT JM, 1980, J AM STAT ASSOC, V75, P104, DOI 10.1080/01621459.1980.10477438	11	15	15	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2010	32	8					1517	U1522		10.1109/TPAMI.2010.84	http://dx.doi.org/10.1109/TPAMI.2010.84			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	611XQ	20558881	Green Published			2022-12-18	WOS:000278858600012
J	Kim, M; Pavlovic, V				Kim, Minyoung; Pavlovic, Vladimir			Discriminative Learning for Dynamic State Prediction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Discriminative models and learning; dynamic state prediction; state-space models; conditional random fields	POSITIVE-DEFINITE SOLUTION; MODELS; EXISTENCE	We consider the problem of predicting a sequence of real-valued multivariate states that are correlated by some unknown dynamics, from a given measurement sequence. Although dynamic systems such as the State-Space Models are popular probabilistic models for the problem, their joint modeling of states and observations, as well as the traditional generative learning by maximizing a joint likelihood may not be optimal for the ultimate prediction goal. In this paper, we suggest two novel discriminative approaches to the dynamic state prediction: 1) learning generative state-space models with discriminative objectives and 2) developing an undirected conditional model. These approaches are motivated by the success of recent discriminative approaches to the structured output classification in discrete-state domains, namely, discriminative training of Hidden Markov Models and Conditional Random Fields (CRFs). Extending CRFs to real multivariate state domains generally entails imposing density integrability constraints on the CRF parameter space, which can make the parameter learning difficult. We introduce an efficient convex learning algorithm to handle this task. Experiments on several problem domains, including human motion and robot-arm state estimation, indicate that the proposed approaches yield high prediction accuracy comparable to or better than state-of-the-art methods.	[Kim, Minyoung; Pavlovic, Vladimir] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA	Rutgers State University New Brunswick	Kim, M (corresponding author), Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA.	mikim@cs.rutgers.edu; vladimir@cs.rutgers.edu			US National Science Foundation (NSF) [IIS-0413105]	US National Science Foundation (NSF)(National Science Foundation (NSF))	This work was supported in part by the US National Science Foundation (NSF) grant IIS-0413105.	Abbeel P., 2005, P ROB SCI SYST; Bar-Shalom Y, 1993, ESTIMATION TRACKING; EK CH, 2007, P JOINT WORKSH MACH; ENGWERDA JC, 1993, LINEAR ALGEBRA APPL, V186, P255, DOI 10.1016/0024-3795(93)90295-Y; ENGWERDA JC, 1993, LINEAR ALGEBRA APPL, V194, P91, DOI 10.1016/0024-3795(93)90115-5; Ghahramani Z., 1999, ADV NEURAL INFORM PR; GREINER R, 2002, P 18 ANN NAT C ART I; Hollander M, 1973, NONPARAMETRIC STAT M; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Jordan MI, 2004, STAT SCI, V19, P140, DOI 10.1214/088342304000000026; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; Kakade S, 2002, P INT C MACH LEARN; KIM M, 2006, P IEEE CS C COMP VIS; Lafferty J., 2001, CONDITIONAL RANDOM F; Lafferty J., 2004, P INT C MACH LEARN; MACKAY DJC, 1992, NEURAL COMPUT, V4, P448, DOI 10.1162/neco.1992.4.3.448; MCCALLUM A, 2000, P INT C MACH LEARN; Ng A, 2002, NEURAL INFORM PROCES; Pernkopf F., 2005, P INT C MACH LEARN; ROSS D, 2006, P INT C MACH LEARN; SHA F, 2003, P HUM LANG TECHN C N; SMINCHISESCU C, 2005, P IEEE CS C COMP VIS; TAPPEN MF, 2007, P IEEE CS C COMP VIS; TAYCHER L, 2006, P IEEE CS C COMP VIS; TIAN TP, 2005, P IEEE WORKSH COMP V; URTASUN R, 2005, P IEEE INT C COMP VI; URTASUN R, 2006, P IEEE CS C COMP VIS; vanderMerwe R., 2001, P IEEE INT C AC SPEE; Woodland PC, 2002, COMPUT SPEECH LANG, V16, P25, DOI 10.1006/csla.2001.0182; Xing E., 2002, P ADV NEUR INF PROC, V15, P1; [No title captured]	31	15	15	1	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2009	31	10					1847	1861		10.1109/TPAMI.2009.37	http://dx.doi.org/10.1109/TPAMI.2009.37			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	483VK	19696454				2022-12-18	WOS:000268996500010
J	Nayak, S; Sarkar, S; Loeding, B				Nayak, Sunita; Sarkar, Sudeep; Loeding, Barbara			Distribution-Based Dimensionality Reduction Applied to Articulated Motion Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human motion classification; embedding probability density functions; gesture recognition; sign language recognition	HUMAN MOVEMENT; SIGN-LANGUAGE; MODEL; REPRESENTATION; DISTANCE; HMM	Some articulated motion representations rely on frame-wise abstractions of the statistical distribution of low-level features such as orientation, color, or relational distributions. As configuration among parts changes with articulated motion, the distribution changes, tracing a trajectory in the latent space of distributions, which we call the configuration space. These trajectories can then be used for recognition using standard techniques such as dynamic time warping. The core theory in this paper concerns embedding the frame-wise distributions, which can be looked upon as probability functions, into a low-dimensional space so that we can estimate various meaningful probabilistic distances such as the Chernoff, Bhattacharya, Matusita, Kullback-Leibler (KL) or symmetric-KL distances based on dot products between points in this space. Apart from computational advantages, this representation also affords speed-normalized matching of motion signatures. Speed normalized representations can be formed by interpolating the configuration trajectories along their arc lengths, without using any knowledge of the temporal scale variations between the sequences. We experiment with five different probabilistic distance measures and show the usefulness of the representation in three different contexts-sign recognition (with large number of possible classes), gesture recognition (with person variations), and classification of human-human interaction sequences (with segmentation problems). We find the importance of using the right distance measure for each situation. The low-dimensional embedding makes matching two to three times faster, while achieving recognition accuracies that are close to those obtained without using a low-dimensional embedding. We also empirically establish the robustness of the representation with respect to low-level parameters, embedding parameters, and temporal-scale parameters.	[Nayak, Sunita] Photometria Inc, San Diego, CA 92122 USA; Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA; [Loeding, Barbara] Univ S Florida, Dept Special Educ, Lakeland, FL 33803 USA	State University System of Florida; University of South Florida; State University System of Florida; University of South Florida	Nayak, S (corresponding author), Photometria Inc, 4320 La Jolla Village,Dr 205, San Diego, CA 92122 USA.	snayak@photometria.com; sarkar@cse.usf.edu; bloeding@lakeland.usf.edu	Sarkar, Sudeep/A-8213-2009; Sarkar, Sudeep/ABD-7629-2021	Sarkar, Sudeep/0000-0001-7332-4207; Sarkar, Sudeep/0000-0001-7332-4207	US National Science Foundation (NSF) ITR [IIS 0312993, EIA-0196217]	US National Science Foundation (NSF) ITR(National Science Foundation (NSF))	The authors thank the anonymous reviewers for their highly useful comments and reviews. They thank Sameer Agarwal for his insightful discussion on this paper. This work was supported by funding from US National Science Foundation (NSF) ITR Grant IIS 0312993. The human interaction data set used in this project was obtained from mocap.cs.cmu.edu that was created with the funding from NSF EIA-0196217.	Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744; Balan A. O., 2006, 2006 IEEE COMPUTER S, V1, P758; Belkin M, 2002, ADV NEUR IN, V14, P585; BEZDEK RJ, 2003, NEURAL PARALLEL SCI, P351; Bhattacharyya A., 1943, BULL CALCUTTA MATH S, V35, P99; Blank M, 2005, IEEE I CONF COMP VIS, P1395; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Bobick AF, 1997, IEEE T PATTERN ANAL, V19, P1325, DOI 10.1109/34.643892; *CMU GRAPH LAB MOT, HUM INT; Cooper H, 2007, LECT NOTES COMPUT SC, V4796, P88; Cover T. M., 2006, ELEMENTS INFORM THEO, V2; Cox T.F., 2001, MULTIDIMENSIONAL SCA, V2nd; Crandall D, 2004, PROC CVPR IEEE, P379; EFROS AA, 2003, P IEEE INT C COMP VI, P726; FREEMAN WT, 1995, INT WORKSH AUT FAC G, P296; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; Hernandez-Rebollar JL, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P547, DOI 10.1109/AFGR.2004.1301590; HORN RA, 1985, MATRIX ANAL, pCH7; JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378; JUST A, 2005, 24 IDIAP RES I; KE Y, 2007, P INT C COMP VIS; Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904; Li H, 2005, IEEE I CONF COMP VIS, P236; Masoud O, 2003, IMAGE VISION COMPUT, V21, P729, DOI 10.1016/S0262-8856(03)00068-4; MATUSITA K, 1955, ANN MATH STAT, V26, P631, DOI 10.1214/aoms/1177728422; McCallum Andrew, 2000, P 17 INT C MACH LEAR, P591; MIKOLAJCZYK K, 2004, P EUR C COMP VIS PRA, V1, P69; Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; NAYAK S, 2004, P IND C COMP VIS GRA; NAYAK S, 2005, P CVPR WORKSH VIS HU; Phung SL, 2005, IEEE T PATTERN ANAL, V27, P148, DOI 10.1109/TPAMI.2005.17; POIZNER H, 1981, J EXP PSYCHOL HUMAN, V7, P430, DOI 10.1037/0096-1523.7.2.430; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shan C, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P669; Sheikh Y, 2005, IEEE I CONF COMP VIS, P144; Sminchisescu C, 2005, IEEE I CONF COMP VIS, P1808; TARTTER VC, 1982, PERCEPT PSYCHOPHYS, V32, P327, DOI 10.3758/BF03206238; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; UKRAINITZ Y, 2006, P EUR C COMP VIS, V3, P538; Urtasun R, 2006, COMPUT VIS IMAGE UND, V104, P157, DOI 10.1016/j.cviu.2006.08.006; Vaswani N, 2005, IEEE T IMAGE PROCESS, V14, P1603, DOI 10.1109/TIP.2005.852197; Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246; Vega IR, 2003, IEEE T PATTERN ANAL, V25, P1323, DOI 10.1109/TPAMI.2003.1233906; Wang CL, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P411, DOI 10.1109/AFGR.2002.1004188; WANG SB, 2006, CVPR, V2, P1521, DOI DOI 10.1109/CVPR.2006.132; Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429; Wong SF, 2006, INT C PATT RECOG, P1084; Yacoob Y, 1999, COMPUT VIS IMAGE UND, V73, P232, DOI 10.1006/cviu.1998.0726; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803; Zahedi M, 2005, LECT NOTES COMPUT SC, V3663, P401; Zelnik-Manor L, 2006, IEEE T PATTERN ANAL, V28, P1530, DOI 10.1109/TPAMI.2006.194; Zhang ZH, 2007, NEURAL COMPUT, V19, P1400, DOI 10.1162/neco.2007.19.5.1400	58	15	16	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2009	31	5					795	810		10.1109/TPAMI.2008.80	http://dx.doi.org/10.1109/TPAMI.2008.80			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	418JM	19299856				2022-12-18	WOS:000264144500003
J	Guo, Y; Gao, JB; Kwan, PW				Guo, Yi; Gao, Junbin; Kwan, Paul W.			Twin Kernel Embedding	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						dimensionality reduction; Twin Kernel Embedding; kernel learning	COMPONENT ANALYSIS	In most existing dimensionality reduction algorithms, the main objective is to preserve relational structure among objects of the input space in a low-dimensional embedding space. This is achieved by minimizing the inconsistency between two similarity/dissimilarity measures-one for the input data and another for the embedded data-via a separate matching objective function. Based on this idea, a new dimensionality reduction method called Twin Kernel Embedding (TKE) is proposed. TKE addresses the problem of visualizing nonvectorial data that is difficult for conventional methods in practice due to the lack of efficient vectorial representation. TKE solves this problem by minimizing the inconsistency between the similarity measures captured respectively by their kernel Gram matrices in the two spaces. In the implementation, by optimizing a nonlinear objective function using the gradient descent algorithm, a local minimum can be reached. The results obtained include both the optimal similarity-preserving embedding and the appropriate values for the hyperparameters of the kernel. Experimental evaluation on real nonvectorial data sets confirmed the effectiveness of TKE. TKE can be applied to other types of data beyond those mentioned in this paper whenever suitable measures of similarity/dissimilarity can be defined on the input data.	[Guo, Yi; Kwan, Paul W.] Univ New England, Sch Sci & Technol, Armidale, NSW 2351, Australia; [Gao, Junbin] Charles Sturt Univ, Sch Acc & Comp Sci, Bathurst, NSW 2795, Australia	University of New England; Charles Sturt University	Guo, Y (corresponding author), Univ New England, Sch Sci & Technol, Armidale, NSW 2351, Australia.	yguo4@turing.une.edu.au; jbgao@cse.edu.au; kwan@turing.une.edu.au	Gao, Junbin/C-6566-2008; Guo, Yi/B-3594-2010; Gao, Junbin/A-1766-2009	Gao, Junbin/0000-0001-9803-0256				Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Cox T., 2001, MONOGRAPHS STAT APPL, V1; Cuturi M, 2005, J MACH LEARN RES, V6, P1169; Gartner T., 2003, ACM SIGKDD EXPLORATI, V5, P49; Globerson A., 2005, ADV NEURAL INFORM PR, V17, P497; GUO Y, 2007, P IEEE INT C DAT MIN, P319, DOI DOI 10.1109/ICDMW.2007.112; GUO Y, 2006, P WORKSH INT AI DAT, P11; Guo Y, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P181; Guo Y, 2006, LECT NOTES COMPUT SC, V4304, P1179; JOLLIFFE M, 1986, PRINCIPAL COMPONENT; Lawrence N, 2005, J MACH LEARN RES, V6, P1783; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5; Popescu M, 2006, IEEE ACM T COMPUT BI, V3, P263, DOI 10.1109/TCBB.2006.37; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Scholkopf B., 2004, COMPUTATIONAL MOL BI; Scholkopf B., 2001, LEARNING KERNELS SUP; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Weinberger K. Q., 2004, P 21 INT C MACH LEAR, P106, DOI 10.1145/1015330.1015345; WOLF L, 2003, J MACHINE LEARNING R, V4, P913; [No title captured]	22	15	15	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2008	30	8					1490	1495		10.1109/TPAMI.2008.74	http://dx.doi.org/10.1109/TPAMI.2008.74			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	312OC	18566501				2022-12-18	WOS:000256679700014
J	Lefevre, J; Baillet, S				Lefevre, Julien; Baillet, Sylvain			Optical flow and advection on 2-Riemannian manifolds: A common framework	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						partial differential equations; optical flow; advection; differential geometry; Riemannian manifold; finite element method; MEG; EEG; brain imaging; propagation	PARTIAL-DIFFERENTIAL-EQUATIONS; INTEGRATED LEAST-SQUARES; VARIATIONAL-PROBLEMS; COMPUTATION; DIFFUSION; ALGORITHM; DOMAINS; PDES	Dynamic pattern analysis and motion extraction can be efficiently addressed using optical flow techniques. This paper presents a generalization of these questions to nonflat surfaces, where optical flow is tackled through the problem of evolution processes on non-euclidean domains. The classical equations of optical flow in the euclidean case are transposed to the theoretical framework of differential geometry. We adopt this formulation for the regularized optical flow problem, prove its mathematical well posedness, and combine it with the advection equation. The optical flow and advection problems are dual: A motion field may be retrieved from some scalar evolution using optical flow; conversely, a scalar field may be deduced from a velocity field using advection. These principles are illustrated with qualitative and quantitative evaluations from numerical simulations bridging both approaches. The proof-of-concept is further demonstrated with preliminary results from time-resolved functional brain imaging data, where organized propagations of cortical activation patterns are evidenced using our approach.	[Lefevre, Julien; Baillet, Sylvain] CNRS, UPR 640, LENA, Cognit Neurosci & Brain Imaging Lab, F-75651 Paris 13, France	Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; Universite Paris Cite	Lefevre, J (corresponding author), CNRS, UPR 640, LENA, Cognit Neurosci & Brain Imaging Lab, 47,Boul Hop, F-75651 Paris 13, France.	julien.lefevre@chups.jussieu.fr; sylvain.baillet@chups.jussieu.fr	Baillet, Sylvain/AAF-6512-2019; Lefèvre, Julien/G-1789-2013	Baillet, Sylvain/0000-0002-6762-5713; Lefèvre, Julien/0000-0003-3670-6112				Allaire G, 2005, ANAL NUMERIQUE OPTIM; Aubert G, 1999, SIAM J APPL MATH, V60, P156, DOI 10.1137/S0036139998340170; AZERAD P, 1996, CR HEBD ACAD SCI, P721; Baillet Sylvain, 2001, IEEE SIGNAL PROCESSI; Barron J. L., 1997, Bioimaging, V5, P82, DOI 10.1002/1361-6374(199706)5:2<82::AID-BIO5>3.3.CO;2-6; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141; BEREZIAT D, 2000, P INT C COMP VIS PAT, V2, P2487; Bertalmio M, 2001, J COMPUT PHYS, V174, P759, DOI 10.1006/jcph.2001.6937; Besson O, 2004, INT J NUMER METH FL, V44, P525, DOI 10.1002/fld.655; BOOK DL, 1975, J COMPUT PHYS, V18, P248, DOI 10.1016/0021-9991(75)90002-9; BOSSAVIT A, 1988, IEE PROC-A, V135, P493, DOI 10.1049/ip-a-1.1988.0077; Bowler NEH, 2004, J HYDROL, V288, P74, DOI 10.1016/j.jhydrol.2003.11.011; Cachia A, 2003, IEEE T MED IMAGING, V22, P754, DOI 10.1109/TMI.2003.814781; Clarenz Ulrich, 2004, P 1 EUR C POINT BAS, P201; Corpetti T, 2006, EXP FLUIDS, V40, P80, DOI 10.1007/s00348-005-0048-y; Corpetti T, 2002, IEEE T PATTERN ANAL, V24, P365, DOI 10.1109/34.990137; Cosmelli D, 2004, NEUROIMAGE, V23, P128, DOI 10.1016/j.neuroimage.2004.05.008; Diewald U, 2000, IEEE T VIS COMPUT GR, V6, P139, DOI 10.1109/2945.856995; DoCarmo M., 1993, RIEMANNIAN GEOMETRY; Druet O, 2004, MATH N PRINC, V45, P1; Giachetti A, 1998, IEEE T ROBOTIC AUTOM, V14, P34, DOI 10.1109/70.660838; Guermond JL, 2004, SIAM J NUMER ANAL, V42, P714, DOI 10.1137/S0036142902417054; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; IMIYA A, 2005, P COMP AN IM PATT; INOUYE T, 1995, NEUROSCI LETT, V187, P29, DOI 10.1016/0304-3940(95)11329-U; Jirsa VK, 2002, IEEE T MED IMAGING, V21, P493, DOI 10.1109/TMI.2002.1009385; Johnson C., 1987, NUMERICAL SOLUTION P; LEFEVRE J, 2007, P 20 INT C INF PROC; LENGLET C, 2004, INFERRING WHITE MATT; Liu HC, 1998, COMPUT VIS IMAGE UND, V72, P271, DOI 10.1006/cviu.1998.0675; LOPEZPEREZ L, 2004, COMPUTER VISION MATH; Lui LM, 2005, LECT NOTES COMPUT SC, V3752, P307; Memoli F, 2004, J COMPUT PHYS, V195, P263, DOI 10.1016/j.jcp.2003.10.007; NAGEL HH, 1987, ARTIF INTELL, V33, P299, DOI 10.1016/0004-3702(87)90041-5; Nunez PL, 2000, BEHAV BRAIN SCI, V23, P371, DOI 10.1017/S0140525X00003253; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; PERROCHET P, 1995, J COMPUT PHYS, V117, P183, DOI 10.1006/jcph.1995.1057; Rossmanith JA, 2004, J COMPUT PHYS, V199, P631, DOI 10.1016/j.jcp.2004.03.002; SCHNORR C, 1991, INT J COMPUT VISION, V6, P25, DOI 10.1007/BF00127124; Sochen N, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P832; Spira A, 2007, J COMPUT PHYS, V223, P235, DOI 10.1016/j.jcp.2006.09.008; Sun ZH, 2006, IEEE T PATTERN ANAL, V28, P694, DOI 10.1109/TPAMI.2006.104; TORII A, 2005, P 1 INT S BRAIN VIS; Tschumperle D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87; Wang K, 2006, ACM T GRAPHIC, V25, P1041, DOI 10.1145/1141911.1141991; Weickert J, 2001, INT J COMPUT VISION, V45, P245, DOI 10.1023/A:1013614317973	47	15	15	1	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2008	30	6					1081	1092		10.1109/TPAMI.2008.51	http://dx.doi.org/10.1109/TPAMI.2008.51			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	286UW	18421112				2022-12-18	WOS:000254872500012
J	Zoller, T; Buhmann, JM				Zoeller, Thomas; Buhmann, Joachim M.			Robust image segmentation using resampling and shape constraints	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						segmentation; mixture models; shape analysis; learning; resampling; generalization		Automated segmentation of images has been considered an important intermediate processing task to extract semantic meaning from pixels. We propose an integrated approach for image segmentation based on a generative clustering model combined with coarse shape information and robust parameter estimation. The sensitivity of segmentation solutions to image variations is measured by image resampling. Shape information is included in the inference process to guide ambiguous groupings of color and texture features. Shape and similarity-based grouping information is combined into a semantic likelihood map in the framework of Bayesian statistics. Experimental evidence shows that semantically meaningful segments are inferred even when image data alone gives rise to ambiguous segmentations.	Fraunhofer Inst Intelligent Anal & Informat Syst, Dept ART, D-53754 St Augustin, Germany; ETH, Swiss Fed Inst Technol, Inst Computat Sci, CH-8092 Zurich, Switzerland	Fraunhofer Gesellschaft; Swiss Federal Institutes of Technology Domain; ETH Zurich; Universita della Svizzera Italiana	Zoller, T (corresponding author), Fraunhofer Inst Intelligent Anal & Informat Syst, Dept ART, Schloss Birlinghoven, D-53754 St Augustin, Germany.	thomas.zoeller@iais.fraunhofer.de; jbuhmann@inf.ethz.ch	Buhmann, Joachim/AAU-4760-2020					BORENSTEIN E, 2002, P EUR C COMP VIS, P109; CREMERS D, 2003, P IEEE C COMP VIS PA; CREMERS D, 2002, P EUR C COMP VIS ECC, P78; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; EFRON B, 1984, INTRO BOOTSTRAP; Efron Bradley, 1982, JACKKNIFE BOOTSTRAP; Fergus R., 2003, P IEEE C COMP VIS PA; Fischer B, 2003, IEEE T PATTERN ANAL, V25, P1411, DOI 10.1109/TPAMI.2003.1240115; GALUN M, 2003, P INT C COMP VIS ICC; GYSI T, 2005, ETH ZURICH; Hermes L, 2004, IEEE T GEOSCI REMOTE, V42, P1984, DOI 10.1109/TGRS.2004.832849; HERMES L, 2002, P EUR C COMP VIS, P577; JEHANBESSON S, 2003, P INT C COMP VIS ICC; Lange T, 2004, NEURAL COMPUT, V16, P1299, DOI 10.1162/089976604773717621; LEIBE B, 2004, P EUR C COMP VIS ECC; Malik J, 1999, LECT NOTES COMPUT SC, V1681, P155; Malina H Z, 2001, BMC Physiol, V1, P7, DOI 10.1186/1472-6793-1-7; Martens M, 2001, J INT MONEY FINANC, V20, P1, DOI 10.1016/S0261-5606(00)00047-4; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; ROUSSON M, 2002, P EUR C COMP VIS, P78; Sharon E, 2001, PROC CVPR IEEE, P469; SONKA M, 1998, IMAGE PROCESSING UND; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Van Rijsbergen CJ, 1979, INFORM RETRIEVAL; Vapnik V.N, 1998, STAT LEARNING THEORY; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343; Zoller T, 2004, PROC CVPR IEEE, P386	27	15	16	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2007	29	7					1147	1164		10.1109/TPAMI.2007.1150	http://dx.doi.org/10.1109/TPAMI.2007.1150			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	166QW	17496374				2022-12-18	WOS:000246395300004
J	Zeng, G; Paris, S; Quan, L; Sillion, F				Zeng, Gang; Paris, Sylvain; Quan, Long; Sillion, Francois			Accurate and scalable surface representation and reconstruction from images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						computing methodologies; image processing and computer vision; reconstruction and applications; patchwork representation and reconstruction; space carving; graph-cuts; level-sets; patch-wise carving; patch-wise propagation	STEREO; SHAPE; SILHOUETTE	We introduce a new surface representation method, called patchwork, to extend three-dimensional surface reconstruction capabilities from multiple images. A patchwork is the combination of several patches that are built one by one. This design potentially allows for the reconstruction of an object with arbitrarily large dimensions while preserving a fine level of detail. We formally demonstrate that this strategy leads to a spatial complexity independent of the dimensions of the reconstructed object and to a time complexity that is linear with respect to the object area. The former property ensures that we never run out of storage and the latter means that reconstructing an object can be done in a reasonable amount of time. In addition, we show that the patchwork representation handles equivalently open and closed surfaces, whereas most of the existing approaches are limited to a specific scenario, an open or closed surface, but not both. The patchwork concept is orthogonal to the method chosen for surface optimization. Most of the existing optimization techniques can be cast into this framework. To illustrate the possibilities offered by this approach, we propose two applications that demonstrate how our method dramatically extends a recent accurate graph technique based on minimal cuts. We first revisit the popular carving techniques. This results in a well-posed reconstruction problem that still enjoys the tractability of voxel space. We also show how we can advantageously combine several image-driven criteria to achieve a finely detailed geometry by surface propagation. These two examples demonstrate the versatility and flexibility of patchwork reconstruction. They underscore other properties inherited from patchwork representation: Although some min-cut methods have difficulty in handling complex shapes ( e. g., with complex topologies), they can naturally manipulate any geometry through the patchwork representation while preserving their intrinsic qualities. The above properties of patchwork representation and reconstruction are demonstrated with real image sequences.	Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China; MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA; INRIA Rhone Alpes, ARTIS, GRAVIR, IMAG, F-38330 Montbonnot St Martin, France	Hong Kong University of Science & Technology; Massachusetts Institute of Technology (MIT)	Zeng, G (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci, Clear Water Bay, Kowloon, Hong Kong, Peoples R China.	zenggang@cse.ust.hk; sparis@csail.mit.edu; quan@cse.ust.hk; Francois.Sillion@imag.fr						ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098; AHUJA RK, 1993, NETWORKS FLOWS THEOR; Amenta N, 2001, COMP GEOM-THEOR APPL, V19, P127, DOI 10.1016/S0925-7721(01)00017-7; Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; BLEYER M, 2005, P SPIE C; Boyer E, 2003, PROC CVPR IEEE, P695; Boykov Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P26; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Broadhurst A, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P388, DOI 10.1109/ICCV.2001.937544; BUEHLER C, 2002, P EUR C COMP VIS; CARCERONI RL, 2001, P IEEE INT C COMP VI, V2; Cherkassky BV, 1997, ALGORITHMICA, V19, P390, DOI 10.1007/PL00009180; CULBERTSON W, 1999, P INT WORKSH VIS ALG, P100; CURLESS B, 1996, P SIGGRAPH C; DEBONET JS, 1999, P INT C COMP VIS; Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016; Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183; Fua P, 1997, INT J COMPUT VISION, V24, P19, DOI 10.1023/A:1007918123901; HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709; Hoppe H., 1994, P SIGGRAPH 94, P295, DOI DOI 10.1145/192161.192233; Ishikawa H, 2003, IEEE T PATTERN ANAL, V25, P1333, DOI 10.1109/TPAMI.2003.1233908; Isidoro J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1335; JIN H, 2004, P EUR C COMP VIS; Jin HL, 2003, PROC CVPR IEEE, P171; Jin HL, 2003, J SCI COMPUT, V19, P267, DOI 10.1023/A:1025308109816; KIRSANOV D, 2004, TR1404 HARV COMP SCI; KOLMOGOROV V, 2002, P EUR C COMP VIS MAY; KOLMOGOROV V, 2003, P INT WORKSH EN MIN; Kolmogorov V., 2004, IEEE T PATTERN ANAL, V26; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; KUTULAKOS KN, 2000, P EUR C COMP VIS, P67; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; LETALLEC P, 1994, COMPUTATIONAL MECH A, V1, P123; Lhuillier M, 2005, IEEE T PATTERN ANAL, V27, P418, DOI 10.1109/TPAMI.2005.44; Lhuillier M, 2002, IEEE T PATTERN ANAL, V24, P1140, DOI 10.1109/TPAMI.2002.1023810; LHUILLIER M, 2003, P INT C COMP VIS OCT; Lin MH, 2004, IEEE T PATTERN ANAL, V26, P1073, DOI 10.1109/TPAMI.2004.54; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; MATUSIK W, 2001, P EUR WORKSH REND; NARAYANAN PJ, 1998, P INT C COMP VIS; Ohtake Y, 2003, ACM T GRAPHIC, V22, P463, DOI 10.1145/882262.882293; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Paris S, 2006, INT J COMPUT VISION, V66, P141, DOI 10.1007/s11263-005-3953-x; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Roy S, 1999, INT J COMPUT VISION, V34, P147, DOI 10.1023/A:1008192004934; Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763; Seitz SM, 1997, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.1997.609462; Sharf A, 2004, ACM T GRAPHIC, V23, P878, DOI 10.1145/1015706.1015814; SLABAUGH GG, 2001, P INT WORKSH VOL GRA; Sullivan S, 1998, IEEE T PATTERN ANAL, V20, P1091, DOI 10.1109/34.722621; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; VOGIATZIS G, 2005, P COMP VIS PATT REC; Wong KYK, 2004, IEEE T IMAGE PROCESS, V13, P379, DOI 10.1109/TIP.2003.821113; ZENG G, 2004, P EUR C COMP VIS; ZENG G, 2005, P INT C COMP VIS; Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766	59	15	16	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2007	29	1					141	158		10.1109/TPAMI.2007.250605	http://dx.doi.org/10.1109/TPAMI.2007.250605			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	104VI	17108389				2022-12-18	WOS:000241988300011
J	Butakoff, C; Frangi, AF				Butakoff, Constantine; Frangi, Alejandro F.			A framework for weighted fusion of multiple statistical models of shape and appearance	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						AAM; ASM; model fusion; statistical model; segmentation	CARDIAC MR; SEGMENTATION; EFFICIENT	This paper presents a framework for weighted fusion of several Active Shape and Active Appearance Models. The approach is based on the eigenspace fusion method proposed by Hall et al. [1], which has been extended to fuse more than two weighted eigenspaces using unbiased mean and covariance matrix estimates. To evaluate the performance of fusion, a comparative assessment on segmentation precision as well as facial verification tests are performed using the AR, EQUINOX, and XM2VTS databases. Based on the results, it is concluded that the fusion is useful when the model needs to be updated online or when the original observations are absent.	Univ Pompeu Fabra, Dept Technol, Computat Imaging Lab, E-08003 Barcelona, Spain	Pompeu Fabra University	Butakoff, C (corresponding author), Univ Pompeu Fabra, Dept Technol, Computat Imaging Lab, Pg Circumavallacio 8, E-08003 Barcelona, Spain.	constantine.butakoff@upf.edu; alejandro.frangi@upf.edu	Frangi, Alejandro F/C-6500-2008; Butakoff, Constantine/E-8644-2016; Butakoff, Constantine/A-1904-2009	Frangi, Alejandro F/0000-0002-2675-528X; Butakoff, Constantine/0000-0002-8526-5045; Butakoff, Constantine/0000-0002-8526-5045				Batur AU, 2005, IEEE T IMAGE PROCESS, V14, P1707, DOI 10.1109/TIP.2005.854473; Beichel R, 2005, IEEE T MED IMAGING, V24, P1151, DOI 10.1109/TMI.2005.853237; BUNCH JR, 1978, NUMER MATH, V31, P31, DOI 10.1007/BF01396012; Chandrasekaran S, 1997, GRAPH MODEL IM PROC, V59, P321, DOI 10.1006/gmip.1997.0425; Cootes T, 1992, P BRIT MACH VIS C, P266; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; COOTES TF, 1998, P EUR C COMP VIS, V2, P484; Davies R., 2002, THESIS U MANCHESTER; DEGROAT RD, 1990, IEEE T ACOUST SPEECH, V38, P301, DOI 10.1109/29.103066; Franco A, 2002, INT C PATT RECOG, P156, DOI 10.1109/ICPR.2002.1048261; Hall P, 2000, IEEE T PATTERN ANAL, V22, P1042, DOI 10.1109/34.877525; Hoffman K., 1971, LINEAR ALGEBRA, V2nd; Levy A, 2000, IEEE T IMAGE PROCESS, V9, P1371, DOI 10.1109/83.855432; LIM J, 2005, ADV NEURAL INFORM PR, V17; Martinez A.M., 1998, AR FACE DATABASE TEC; Messer K., 1999, 2 INT C AUDIO VIDEO, P965; MEYER CD, 2001, SIAM SOC IND APPL MA; Mitchell SC, 2002, IEEE T MED IMAGING, V21, P1167, DOI 10.1109/TMI.2002.804425; Mitchell SC, 2001, IEEE T MED IMAGING, V20, P415, DOI 10.1109/42.925294; MURAKAMI H, 1982, IEEE T PATTERN ANAL, V4, P511, DOI 10.1109/TPAMI.1982.4767295; Perlibakas V, 2004, PATTERN RECOGN LETT, V25, P711, DOI 10.1016/j.patrec.2004.01.011; RICHARD A. J., 2002, APPL MULTIVARIATE ST; Stegmann MB, 2003, IEEE T MED IMAGING, V22, P1319, DOI 10.1109/TMI.2003.817780; Sukno FM, 2005, PROC SPIE, V5779, P152, DOI 10.1117/12.603552; van Assen HC, 2006, MED IMAGE ANAL, V10, P286, DOI 10.1016/j.media.2005.12.001; van Ginneken B, 2002, IEEE T MED IMAGING, V21, P924, DOI 10.1109/TMI.2002.803121; Zhou XS, 2005, IEEE T PATTERN ANAL, V27, P115, DOI 10.1109/TPAMI.2005.3	28	15	15	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2006	28	11					1847	1857		10.1109/TPAMI.2006.215	http://dx.doi.org/10.1109/TPAMI.2006.215			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	083GC	17063688				2022-12-18	WOS:000240443400011
J	Tamminen, T; Lampinen, J				Tamminen, T; Lampinen, J			Sequential Monte Carlo for Bayesian matching of objects with occlusions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object recognition; statistical models in pattern recognition; Monte Carlo simulation	IMAGE-ANALYSIS; MARKOV-CHAIN	We consider the problem of locating instances of a known object in a novel scene by matching the fiducial features of the object. The appearance of the features and the shape of the object are modeled separately and combined in a Bayesian framework. In this paper, we present a novel matching scheme based on Sequential Monte Carlo, in which the features are matched sequentially, utilizing the information about the locations of previously matched features to constrain the task. The particle representation of hypotheses about the object position allow matching in multimodal and cluttered environments, where batch algorithms may have convergence difficulties. The proposed method requires no initialization or predetermined matching order, as the sequence can be started from any feature. We also utilize a Bayesian model to deal with features that are not detected due to occlusions or abnormal appearance. In our experiments, the proposed matching system shows promising results, with performance equal to batch approaches when the target distribution is unimodal, while surpassing traditional methods under multimodal conditions. Using the occlusion model, the object can be localized from only a few visible features, with the nonvisible parts predicted from the conditional prior model.	Aalto Univ, Lab Computat Engn, FIN-02015 Espoo, Finland	Aalto University	Tamminen, T (corresponding author), Aalto Univ, Lab Computat Engn, POB 9203, FIN-02015 Espoo, Finland.	toni.tamminen@tkk.fi; jouko.lampinen@tkk.fi	Lampinen, Jouko/D-3927-2014					Chopin N, 2002, BIOMETRIKA, V89, P539, DOI 10.1093/biomet/89.3.539; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; COUGHLAN J, 2004, P WORKSH GEN MOD BAS; CRISTINACCE D, 2004, P BRIT MACH VIS C; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; Doucet A., 2001, SEQUENTIAL MONTE CAR; FELZENSZWALB PF, 2003, P IEEE C COMP VIS PA; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fox D, 2001, STAT ENG IN, P401; Gelman A., 2004, BAYESIAN DATA ANAL, V2nd, DOI DOI 10.1201/9780429258411; *GILKS WR, 1996, MARKOV CHAIN MONTE C; ISARD M, 2003, P IEEE C COMP VIS PA; JESORSKY O, 2001, P INT C AUD VID BAS; KARLSSON R, 2001, P IEE INT SEM TARG T; Kitagawa Genshiro, 2021, J COMPUT GRAPH STAT, V5, P1, DOI [DOI 10.2307/1390750, 10.2307/1390750]; KONG A, 1994, J AM STAT ASSOC, V89, P278, DOI 10.2307/2291224; LI FF, 2003, P INT C COMP VIS; Liang F, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.056101; MATTHEWS P, 1993, STAT PROBABIL LETT, V17, P231, DOI 10.1016/0167-7152(93)90172-F; Mumford D., 1996, PERCEPTION BAYESIAN; Perez P., 2001, P IEEE INT C COMP VI; Robert C, 2004, MONTE CARLO STAT MET, DOI DOI 10.1007/978-1-4757-4145-2; Rucklidge WJ, 1997, INT J COMPUT VISION, V24, P251, DOI 10.1023/A:1007975324482; SIGAL L, 2003, P NEUR INF PROC SYST; STEGER C, 2002, INT ARCH PHOTOGR 3A, V34; STEGMANN MB, 2002, ANAL SEGMENTATION FA; SUDDERTH EB, 2003, P IEEE C COMP VIS PA; Sullivan J, 2001, INT J COMPUT VISION, V44, P111, DOI 10.1023/A:1011818912717; TAMMINEN T, 2004, P BRIT MACH VIS C; TAMMINEN T, 2003, BAYESIAN STAT, V7; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Wiskott L, 1999, INT SER COMPUTAT INT, P355; ZHANG J, 2004, P IEEE C COMP VIS PA; Zhong Y, 2000, IEEE T PATTERN ANAL, V22, P544, DOI 10.1109/34.857008; ZHOU Y, 2003, P IEEE C COMP VIS PA	36	15	15	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2006	28	6					930	941		10.1109/TPAMI.2006.128	http://dx.doi.org/10.1109/TPAMI.2006.128			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	031WB	16724587				2022-12-18	WOS:000236734400007
J	van der Heijden, F				van der Heijden, F			Consistency checks for particle filters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						particle filtering; consistency checks; modeling errors; fault detection; model validation	TRACKING	An "inconsistent" particle filter produces-in a statistical sense-larger estimation errors than predicted by the model on which the filter is based. Two test variables are introduced that allow the detection of inconsistent behavior. The statistical properties of the variables are analyzed. Experiments confirm their suitability for inconsistency detection.	Univ Twente, Fac EEMCS, NL-7500 AE Enschede, Netherlands	University of Twente	van der Heijden, F (corresponding author), Univ Twente, Fac EEMCS, POB 217, NL-7500 AE Enschede, Netherlands.	F.vanderHeijden@utwente.nl		van der Heijden, Ferdinand/0000-0001-8065-8053				Andrieu C, 2004, P IEEE, V92, P423, DOI 10.1109/JPROC.2003.823142; Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374; Bar-Shalom Y, 1993, ESTIMATION TRACKING; BARSHALOM Y, 1983, AUTOMATICA, V19, P431, DOI 10.1016/0005-1098(83)90059-6; Blackman R., 1958, MEASUREMENT POWER SP; GERLACH R, 1999, J TIME SER ANAL, V20, P309; ROSENBLATT M, 1952, ANN MATH STAT, V23, P470, DOI 10.1214/aoms/1177729394; SORENSON HW, 1985, FALMAN FILTERING THE; Van der Heijden F., 2004, CLASSIFICATION PARAM; Vaswani N, 2004, P AMER CONTR CONF, P5387; Vermaak J, 2002, IEEE T SPEECH AUDI P, V10, P173, DOI 10.1109/TSA.2002.1001982	12	15	15	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2006	28	1					140	U1		10.1109/TPAMI.2006.5	http://dx.doi.org/10.1109/TPAMI.2006.5			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	982OR	16402626				2022-12-18	WOS:000233172000012
J	Dehak, SMR; Bloch, I; Maitre, H				Dehak, SMR; Bloch, I; Maitre, H			Spatial reasoning with incomplete information on relative positioning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						probabilistic geometry; spatial reasoning; geometrical inference	MOBILE ROBOT LOCALIZATION; OBJECTS	This paper describes a probabilistic method of inferring the position of a point with respect to a reference point knowing their relative spatial position to a third point. We address this problem in the case of incomplete information where only the angular spatial relationships are known. The use of probabilistic representations allows us to model prior knowledge. We derive exact formulae expressing the conditional probability of the position given the two known angles, in typical cases: uniform or Gaussian random prior distributions within rectangular or circular regions. This result is illustrated with respect to two different simulations: The first is devoted to the localization of a mobile phone using only angular relationships, the second, to geopositioning within a city. This last example uses angular relationships and some additional knowledge about the position.	LRDE, EPITA, F-94276 Le Kremlin Bicetre, France; CNRS, UMR 5141, GET Telecom, LTCI, F-75013 Paris, France	Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; Universite Paris Cite	Dehak, SMR (corresponding author), LRDE, EPITA, 14-16 Rue Voltaire, F-94276 Le Kremlin Bicetre, France.	reda@lrde.epita.fr; Isabelle.Bloch@enst.fr; Henri.Maitre@enst.fr						ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434; Betke M, 1997, IEEE T ROBOTIC AUTOM, V13, P251, DOI 10.1109/70.563647; Bloch I, 1999, IEEE T PATTERN ANAL, V21, P657, DOI 10.1109/34.777378; Bloch I, 2003, PATTERN RECOGN, V36, P1563, DOI 10.1016/S0031-3203(02)00263-7; BORENSTEIN J, 1996, WHERE AM I SENSOR ME; Burgard W, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P896; CHANG SK, 1987, IEEE T PATTERN ANAL, V9, P413, DOI 10.1109/TPAMI.1987.4767923; Chatila R., 1985, P 1985 IEEE INT C RO, V2, P138, DOI [DOI 10.1109/ROBOT.1985.1087373, 10.1109/ROBOT.1985.1087373]; COHN AG, 1999, P IJCAI 99 WORKSH AD, P33; DEHAK R, 2002, THESIS ECOLE NATL SU; Doherty L, 2001, IEEE INFOCOM SER, P1655, DOI 10.1109/INFCOM.2001.916662; DRIANKOV D, 2001, STUDIES FUZZINESS SO; DURRANTWHYTE HF, 1988, IEEE J ROBOT AUTOM, V4, P23, DOI 10.1109/56.768; Dutta S., 1991, International Journal of Approximate Reasoning, V5, P307, DOI 10.1016/0888-613X(91)90015-E; Fox D, 1998, ROBOT AUTON SYST, V25, P195, DOI 10.1016/S0921-8890(98)00049-9; Freeman J., 1975, COMPUT VISION GRAPH, V4, P156, DOI [DOI 10.1016/S0146-664X(75)80007-4, 10.1016/S0146-664X(75)80007-4]; FREKSA C, 1992, 1992 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, VOLS 1 AND 2, P261, DOI 10.1109/ICSMC.1992.271766; Grosicki E, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P2794, DOI 10.1109/ICC.2004.1313039; JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620; Keller J. M., 1995, Proceedings of ISUMA - NAFIPS '95 The Third International Symposium on Uncertainty Modeling and Analysis and Annual Conference of the North American Fuzzy Information Processing Society (Cat. No.95TB8082), P679, DOI 10.1109/ISUMA.1995.527776; Keller JM, 1996, FUZZ-IEEE '96 - PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P118, DOI 10.1109/FUZZY.1996.551729; KOCZY LT, 1988, PATTERN RECOGN LETT, V8, P21, DOI 10.1016/0167-8655(88)90019-0; LANDAU B, 1993, BEHAV BRAIN SCI, V16, P217, DOI 10.1017/S0140525X00029733; LEONARD JJ, 1991, IEEE T ROBOTIC AUTOM, V7, P376, DOI 10.1109/70.88147; Ligozat G, 1998, J VISUAL LANG COMPUT, V9, P23, DOI 10.1006/jvlc.1997.9999; Matsakis P, 1999, IEEE T PATTERN ANAL, V21, P634, DOI 10.1109/34.777374; MIYAJIMA K, 1994, FUZZY SET SYST, V65, P225, DOI 10.1016/0165-0114(94)90021-3; Moravec H., 1985, P 1985 IEEE INT C RO, P116; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; SIMMONS R, 1995, P INT JOINT C ART IN, P1080; SMITH RC, 1986, INT J ROBOT RES, V5, P56, DOI 10.1177/027836498600500404; SMITH WE, 1993, PHTHALOCYANINES PROP, V3, P167; Spletzer JR, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1258; Talmy L., 1983, SPATIAL ORIENTATION, P177, DOI [10.1007/978-1-4615-9325-6_11, DOI 10.1007/978-1-4615-9325-6_11]; Vieu L., 1997, SPATIAL TEMPORAL REA, P5, DOI [10.1007/978-0-585-28322-7_1, DOI 10.1007/978-0-585-28322-7_1]	35	15	18	1	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2005	27	9					1473	1484		10.1109/TPAMI.2005.186	http://dx.doi.org/10.1109/TPAMI.2005.186			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	944XB	16173189				2022-12-18	WOS:000230463300009
J	Yagi, Y; Imai, K; Tsuji, K; Yachida, M				Yagi, Y; Imai, K; Tsuji, K; Yachida, M			Iconic memory-based omnidirectional route panorama navigation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						omnidirectional vision; route panorama; localization; navigation; active contour model	VISION	A route navigation method for a mobile robot with an omnidirectional image sensor is described. The route is memorized from a series of consecutive omnidirectional images of the horizon when the robot moves to its goal. While the robot is navigating to the goal point, input is matched against the memorized spatio-temporal route pattern by using dual active contour models and the exact robot position and orientation is estimated from the converged shape of the active contour models.	Osaka Univ, Inst Sci & Ind Res, Osaka 5670047, Japan; Osaka Univ, Grad Sch Engn Sci, Osaka 5608531, Japan	Osaka University; Osaka University	Yagi, Y (corresponding author), Osaka Univ, Inst Sci & Ind Res, 8-1 Mihogaoka, Osaka 5670047, Japan.	yagi@am.sanken.osaka-u.ac.jp; k0usuke@rose.freemail.ne.jp; k-tsuji@yachi-lab.sys.es.osaka-u.ac.jp; yachida@sys.es.osaka-u.ac.jp						Aihara N, 1998, INT C PATT RECOG, P1799, DOI 10.1109/ICPR.1998.712078; Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364; CAO ZL, 1986, J ROBOTIC SYST, V3, P5, DOI 10.1002/rob.4620030103; Chahl JS, 1997, APPL OPTICS, V36, P8275, DOI 10.1364/AO.36.008275; GREGUSS P, 1985, OPT LASER TECHNOL, V17, P41, DOI 10.1016/0030-3992(85)90123-9; HONG JW, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P620, DOI 10.1109/ROBOT.1991.131651; Ishiguro H, 1996, IROS 96 - PROCEEDINGS OF THE 1996 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - ROBOTIC INTELLIGENCE INTERACTING WITH DYNAMIC WORLDS, VOLS 1-3, P634, DOI 10.1109/IROS.1996.571018; Jogan M, 2000, INT C PATT RECOG, P136, DOI 10.1109/ICPR.2000.902882; Kawasaki H, 2000, INT C PATT RECOG, P379, DOI 10.1109/ICPR.2000.905357; Matsunaga Y, 1997, ELEC SOC S, V97, P184; Pegard C, 1996, IEEE INT CONF ROBOT, P89, DOI 10.1109/ROBOT.1996.503578; PERI V, 1996, P US JAP GRAD STUD F, P28; Takahashi T, 2000, INT C PATT RECOG, P468, DOI 10.1109/ICPR.2000.902959; Ulrich I., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1023, DOI 10.1109/ROBOT.2000.844734; YAGI Y, 1994, IEEE T ROBOTIC AUTOM, V10, P11, DOI 10.1109/70.285581; Yagi Y, 1998, IEEE INT CONF ROBOT, P1250, DOI 10.1109/ROBOT.1998.677273; Yagi Y, 1999, IEICE T INF SYST, VE82D, P568; Yagi Y., 1990, Proceedings. IROS '90. IEEE International Workshop on Intelligent Robots and Systems '90. Towards a New Frontier of Applications (Cat. No.90TH0332-7), P181, DOI 10.1109/IROS.1990.262385; YAGI Y, 1994, IEEE INT CONF ROBOT, P1679, DOI 10.1109/ROBOT.1994.351350; Yamaguchi K, 2000, INT C PATT RECOG, P589, DOI 10.1109/ICPR.2000.902988; YAMAZAWA K, 1993, IROS 93 : PROCEEDINGS OF THE 1993 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOL 1-3, P1029, DOI 10.1109/IROS.1993.583287; ZHENG JY, 1992, INT J COMPUT VISION, V9, P55	22	15	15	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2005	27	1					78	87		10.1109/TPAMI.2005.11	http://dx.doi.org/10.1109/TPAMI.2005.11			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	870BE	15628270	Green Submitted, Green Published			2022-12-18	WOS:000225028200008
J	Maybank, SJ				Maybank, SJ			Detection of image structures using the Fisher information and the Rao metric	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						analysis of algorithms; clustering; edge and feature detection; multivariate statistics; robust regression; sampling; search process		In many detection problems, the structures to be detected are parameterized by the points of a parameter space. If the conditional probability density function for the measurements is known, then detection can be achieved by sampling the parameter space at a finite number of points and checking each point to see if the corresponding structure is supported by the data. The number of samples and the distances between neighboring samples are calculated using the Rao metric on the parameter space. The Rao metric is obtained from the Fisher information which is, in turn, obtained from the conditional probability density function. An upper bound is obtained for the probability of a false detection. The calculations are simplified in the low noise case by making an asymptotic approximation to the Fisher information. An application to line detection is described. Expressions are obtained for the asymptotic approximation to the Fisher information, the volume of the parameter space, and the number of samples. The time complexity for line detection is estimated. An experimental comparison is made with a Hough transform-based method for detecting lines.	Univ London Birkbeck Coll, Sch Comp Sci & Informat Syst, London WC1E 7HX, England	University of London; Birkbeck University London	Maybank, SJ (corresponding author), Univ London Birkbeck Coll, Sch Comp Sci & Informat Syst, Malet St, London WC1E 7HX, England.	sjmaybank@dcs.bbk.ac.uk						Amari S., 1985, DIFFERENTIAL GEOMETR, V28; BALASUBRAMANIAN V, 1996, PUPT1588 PRINC U DEP; Chavel I., 1984, EIGENVALUES RIEMANNI; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; Do Carmo M.P., 1992, RIEMANNIAN GEOMETRY; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fisher R.A., 1922, PHILOS T R SOC LON A, V222, P309, DOI [DOI 10.1098/RSTA.1922.0009, 10.1098/rsta.1922.0009]; Forsyth David A, 2012, COMPUTER VISION MODE; Gallot S., 1990, RIEMANNIAN GEOMETRY; GONZALEZ R., 2002, DIGITAL IMAGE PROCES; GRIMSON WEL, 1990, IEEE T PATTERN ANAL, V12, P255, DOI 10.1109/34.49052; Hamarneh G., 1999, AUTOMATIC LINE DETEC; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; ILLINGWORTH J, 1988, COMPUTER VISION GRAP, V43, P221; KOTZ S, 1992, BREAKTHROUGHS STAT, V1; LAM WCY, 1994, PATTERN RECOGN LETT, V15, P1127, DOI 10.1016/0167-8655(94)90128-7; LEAVERS VF, 1992, SHAPE DETECTION COMP; Lee AB, 2001, INT J COMPUT VISION, V41, P35, DOI 10.1023/A:1011109015675; MAYBANK SJ, 2003, P ROY SOC LOND A MAT, V459, P1; Misner C. W., 1973, GRAVITATION; MYUNG J, P NATL ACAD SCI, V97, P11170; Rao C.R., 1945, BULL CALCUTTA MATH S, V37, P81, DOI DOI 10.1007/978-1-4612-0919-5_15; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; WERMAN M, 1999, P COMP VIS PATT REC, V2, P552; Wolfram S, 1999, MATH BOOK; Yuen S.Y.K., 1991, P 7 SCAND C IM AN, P733	26	15	15	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2004	26	12					1579	1589		10.1109/TPAMI.2004.122	http://dx.doi.org/10.1109/TPAMI.2004.122			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	861AO	15573819	Green Accepted, Green Submitted			2022-12-18	WOS:000224388700004
J	Destrempes, F; Mignotte, M				Destrempes, F; Mignotte, M			A statistical model for contours in images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						contours in images; edge-detection; parameter estimation; unsupervised statistical segmentation; Markov Random Field model	SEGMENTATION; MIXTURE	In this paper, we describe a statistical model for the gradient vector field of the gray level in images validated by different experiments. Moreover, we present a global constrained Markov model for contours in images that uses this statistical model for the likelihood. Our model is amenable to an Iterative Conditional Estimation (ICE) procedure for the estimation of the parameters; our model also allows segmentation by means of the Simulated Annealing (SA) algorithm, the Iterated Conditional Modes (ICM) algorithm, or the Modes of Posterior Marginals (MPM) Monte Carlo (MC) algorithm. This yields an original unsupervised statistical method for edge-detection, with three variants. The estimation and the segmentation procedures have been tested on a total of 160 images. Those tests indicate that the model and its estimation are valid for applications that require an energy term based on the log-likelihood ratio. Besides edge-detection, our model can be used for semiautomatic extraction of contours, localization of shapes, non-photo-realistic rendering; more generally, it might be useful in various problems that require a statistical likelihood for contours.	DIRO, Montreal, PQ H3C 3J7, Canada	Universite de Montreal	Destrempes, F (corresponding author), DIRO, CP 6128,Succ Ctr Ville, Montreal, PQ H3C 3J7, Canada.	destremp@iro.unmontreal.ca; mignotte@iro.unmontreal.ca	Mignotte, Max/F-7014-2015					BANKS S, 1990, SIGNAL PROCESSING IM; BESAG J, 1986, J R STAT SOC B, V48, P259; Bowyer K, 2001, COMPUT VIS IMAGE UND, V84, P77, DOI 10.1006/cviu.2001.0931; Braathen B., 1993, MACHINE GRAPHICS VIS, V2, P39; Caillol H, 1997, IEEE T IMAGE PROCESS, V6, P425, DOI 10.1109/83.557353; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; COHEN AC, 1965, TECHNOMETRICS, V7, P579, DOI 10.2307/1266397; Delignon Y, 1997, IEEE T IMAGE PROCESS, V6, P1364, DOI 10.1109/83.624951; Demigny D, 2002, IEEE T IMAGE PROCESS, V11, P728, DOI 10.1109/TIP.2002.800887; DEMPSTER AP, 1976, MAXIMUM LIKELIHOOD I, P1; DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164; DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871; Destrempes F., 2002, Proceedings of the Fourth IASTED International Conference Signal and Image Processing, P60; Destrempes F., 2002, Proceedings of the Fourth IASTED International Conference Signal and Image Processing, P66; DESTREMPES F, 2003, P 10 IEEE INT C IM P, V2, P1053; DESTREMPES F, 2002, THESIS U MONTREAL; Diebolt J., 1993, COMMUNICATIONS STAT, V9, P599, DOI DOI 10.1080/15326349308807283; Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006; GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204; GEMAN D, 1987, 35 BROWN U DIV APPL; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Giordana N, 1997, IEEE T PATTERN ANAL, V19, P465, DOI 10.1109/34.589206; Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Klugman SA, 1998, WILEY SER PROB STAT; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Mignotte M, 2000, IEEE T IMAGE PROCESS, V9, P1216, DOI 10.1109/83.847834; MIGNOTTE M, 2003, P 10 IEEE INT C IM P, V3, P573; Mortensen EN, 1998, GRAPH MODEL IM PROC, V60, P349, DOI 10.1006/gmip.1998.0480; Peng A, 1995, GRAPH MODEL IM PROC, V57, P389, DOI 10.1006/gmip.1995.1033; PEREZ P, 2001, P INT C COMP VIS JUL; Pieczynski W, 2000, IEEE T IMAGE PROCESS, V9, P308, DOI 10.1109/83.821750; Salzenstein F, 1997, GRAPH MODEL IM PROC, V59, P205, DOI 10.1006/gmip.1997.0431; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SHEN J, 1992, CVGIP-GRAPH MODEL IM, V54, P112, DOI 10.1016/1049-9652(92)90060-B; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010; YOUNES L, 1989, PROBAB THEORY REL, V82, P625, DOI 10.1007/BF00341287	40	15	19	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2004	26	5					626	638		10.1109/TPAMI.2004.1273940	http://dx.doi.org/10.1109/TPAMI.2004.1273940			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	811EY	15460283	Green Submitted			2022-12-18	WOS:000220756400007
J	Wang, L; Kang, SB; Shum, HY; Xu, GY				Wang, L; Kang, SB; Shum, HY; Xu, GY			Error analysis of pure rotation-based self-calibration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						calibration; rotating cameras; error analysis		Self-calibration using pure rotation is a well-known technique and has been shown to be a reliable means for recovering intrinsic camera parameters. However, in practice, it is virtually impossible to ensure that the camera motion for this type of self-calibration is a pure rotation. In this paper, we present an error analysis of recovered intrinsic camera parameters due to the presence of translation. We derived closed-form error expressions for a single pair of images with nondegenerate motion; for multiple rotations for which there are no closed-form solutions, analysis was done through repeated experiments. Among others, we show that translation -independent solutions do exist under certain practical conditions. Our analysis can be used to help choose the least error-prone approach (if multiple approaches exist) for a given set of conditions.	Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China; Microsoft Res, Redmond, WA 98052 USA; Microsoft Res Asia, Beijing 100080, Peoples R China	Tsinghua University; Microsoft; Microsoft; Microsoft Research Asia	Wang, L (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.	wanglei99@mails.tsinghua.edu.cn; sbkang@microsoft.com; hshum@microsoft.com; dcs-xgy@tsinghua.edu.cn						Agapito L, 2001, INT J COMPUT VISION, V45, P107, DOI 10.1023/A:1012471930694; Basu A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P495, DOI 10.1109/CVPR.1993.341084; Du F., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P477, DOI 10.1109/CVPR.1993.341087; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Hartley RI, 1997, INT J COMPUT VISION, V22, P5, DOI 10.1023/A:1007957826135; HARTLEY RI, 1994, P 3 EUR C COMP VIS S, V1, P471; HAYMAN E, 2002, 225002 OUEL; Higham N.J., 1994, P S APPL MATH, V48, P49; MA Y, 1999, P INT C COMP VIS SEP, V1, P773; MAYBANK SJ, 1992, INT J COMPUT VISION, V8, P123, DOI 10.1007/BF00127171; SEO YD, 1999, P 1999 7 IEEE INT C, V1, P183; Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169; STEIN GP, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P230, DOI 10.1109/ICCV.1995.466781; Sturm P, 1997, PROC CVPR IEEE, P1100, DOI 10.1109/CVPR.1997.609467; Sturm P., 1999, P IEEE C COMP VIS PA, P432, DOI DOI 10.1109/CVPR.1999.786974; Triggs B., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P89, DOI 10.1007/BFb0055661; WANG L, 2002, ERROR ANAL PURE ROTA; WANG L, 2001, P INT C COMP VIS JUL, V1, P464; Zhang Z., 1999, P 7 IEEE INT C COMP, V1, P666, DOI DOI 10.1109/ICCV.1999.791289	19	15	16	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2004	26	2					275	280		10.1109/TPAMI.2004.1262199	http://dx.doi.org/10.1109/TPAMI.2004.1262199			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	762DA	15376903				2022-12-18	WOS:000187954300014
J	Kim, ZW; Nevatia, R				Kim, ZW; Nevatia, R			Expandable Bayesian networks for 3D object description from multiple views and multiple mode inputs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						multiview object description; learning; uncertain reasoning; building description; Bayesian network		Computing 3D object descriptions from images is an important goal of computer vision. A key problem here is the evaluation of a hypothesis based on evidence that is uncertain. There have been few efforts on applying formal reasoning methods to this problem. In multiview and multimode object description problems, reasoning is required on evidence features extracted from multiple images and nonintensity data. One challenge here is that the number of the evidence features varies at runtime because the number of images being used is not fixed and some modalities may not always be available. We introduce an augmented Bayesian network, the expandable Bayesian network (EBN), which instantiates its structure at runtime according to the structure of input. We introduce the use of hidden variables to handle correlation of evidence features across images. We show an application of an EBN to a multiview building description system. Experimental results show that the proposed method gives significant and consistent performance improvement to others.	Univ Calif Berkeley, Richmond, CA 94804 USA; Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA	University of California System; University of California Berkeley; University of Southern California	Kim, ZW (corresponding author), Univ Calif Berkeley, 1357 S 46th St, Richmond, CA 94804 USA.	zuzvhan@cs.berkeley.edu; nevatia@usc.edu						Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Binder J, 1997, MACH LEARN, V29, P213, DOI 10.1023/A:1007421730016; BRAND M, 1997, P IEEE C COMP VIS PA, P995; Buchanan B.G., 1984, RULE BASED EXPERT SY; COOPER GF, 1990, ARTIF INTELL, V42, P393, DOI 10.1016/0004-3702(90)90060-D; Dean T., 1989, ARTIF INTELL, V93, P1; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361; Dougherty J., 1995, P MACH LEARN TAH CIT; Duda R.O., 1973, J ROYAL STAT SOC SER; Friedman Nir, 1996, P 13 INT C MACH LEAR, P157; GRUEN A, 1998, COMPUTER VISION IMAG, V72; Huertas A., 1999, Proceedings of the Second International Conference on Information Fusion. FUSION '99, P680; HUERTAS A, 1998, P DARPA IM UND WORKS, P577; JENSEN FV, 1989, 8915 R U AALB I EL S; KIM Z, 2001, THESIS U SO CALIFORN; Kim ZW, 1999, COMPUT VIS IMAGE UND, V76, P278, DOI 10.1006/cviu.1999.0803; KOHAVI R, 1909, P 14 INT JOINT C ART, P1137; Maloof MA, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P194, DOI 10.1109/ACV.1998.732879; Noronha S, 2001, IEEE T PATTERN ANAL, V23, P501, DOI 10.1109/34.922708; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; RIMEY RD, 1994, INT J COMPUT VISION, V12, P173, DOI 10.1007/BF01421202; Russell S., 2021, ARTIF INTELL, V19, P23; SARKAR S, 1995, COMPUT VIS IMAGE UND, V62, P27, DOI 10.1006/cviu.1995.1039; TRESP V, 1999, P 15 C UNC ART INT; VANALLEN T, 2000, P 17 INT C MACH LEAR, P1047; [No title captured]	27	15	15	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2003	25	6					769	774		10.1109/TPAMI.2003.1201825	http://dx.doi.org/10.1109/TPAMI.2003.1201825			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	680DP					2022-12-18	WOS:000182961300010
J	Neumann, A				Neumann, A			Graphical Gaussian shape models and their application to image segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape; bookstein coordinates; conditional independence; graphical Gaussian models; Markov random fields; Bayesian image segmentation; Markov chain Monte Carlo sampling methods; Gibbs sampler; slice sampler	CHAIN MONTE-CARLO; STOCHASTIC RELAXATION; COVARIANCE-SELECTION; BOUNDARY DETECTION; MARKOV; DISTRIBUTIONS; COMPUTATION; CONTOURS; SEARCH	This paper presents a novel approach to shape modeling and a model-based image segmentation procedure tailor-made for the proposed shape model. A common way to represent shape is based on so-called key points and leads to shape variables, which are invariant with respect to similarity transformations. We propose a graphical shape model, which relies on a certain conditional independence structure among the shape variables. Most often, it is sufficient to use a sparse underlying graph reflecting both nearby and long-distance key point interactions. Graphical shape models allow for specific shape modeling, since, e.g., for the subclass of decomposable graphical Gaussian models both model selection procedures and explicit parameter estimates are available. A further prerequisite to a successful application of graphical shape models in image analysis is provided by the "toolbox" of Markov chain Monte Carlo methods offering highly flexible and effective methods for the exploration of a specified distribution. For Bayesian image segmentation based on a graphical Gaussian shape model, we suggest applying a hybrid approach composed of the well-known Gibbs sampler and the more recent slice sampler. Shape modeling as well as image analysis are demonstrated for the segmentation of vertebrae from two-dimensional slices of computer tomography images.	Hop Paris, Assistance Publ, AP HP, DIME, F-75004 Paris, France	Assistance Publique Hopitaux Paris (APHP)	Neumann, A (corresponding author), Hop Paris, Assistance Publ, AP HP, DIME, 3 Ave Victoria, F-75004 Paris, France.			Neumann, Anke/0000-0002-6697-8023				AMIT Y, 1991, J MULTIVARIATE ANAL, V37, P197, DOI 10.1016/0047-259X(91)90080-L; BESAG J, 1993, J ROY STAT SOC B MET, V55, P25; BESAG J, 1986, J R STAT SOC B, V48, P259; Bookstein FL., 1986, STAT SCI, V1, P181, DOI [DOI 10.1214/SS/1177013696, 10.1214/ss/1177013696]; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; CHALMOND B, 1988, SIGNAL PROCESS, V15, P115, DOI 10.1016/0165-1684(88)90065-5; COOTES TF, 1994, ADV APPL STAT SER, V2, P111; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; DEFIGUEIREDO MT, 1992, IEEE T MED IMAGING, V11, P416, DOI 10.1109/42.158946; DEMPSTER AP, 1972, BIOMETRICS, V28, P157, DOI 10.2307/2528966; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; EDWARDS RG, 1988, PHYSL REV D, V38; FRIEDLAND N, 1989, IEEE T MED IMAGING, V8, P344, DOI 10.1109/42.41487; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711; GRENANDER U, 1991, RES NOTES NEURAL COM, V2; Higdon DM, 1998, J AM STAT ASSOC, V93, P585; Jain AK, 1998, SIGNAL PROCESS, V71, P109, DOI 10.1016/S0165-1684(98)00139-X; Kendall David G, 1989, STAT SCI, P6, DOI DOI 10.1214/SS/1177012582; KENDALL DG, 1977, ADV APPL PROBAB, V9, P428, DOI 10.2307/1426091; KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81; Kervrann C, 1998, GRAPH MODEL IM PROC, V60, P173, DOI 10.1006/gmip.1998.0469; KNUIMAN M, 1978, ADV APPL PROBABILI S, V10, P123; Krahnstover N, 1999, PROC SPIE, V3661, P620, DOI 10.1117/12.348618; LAURITZEN SL, 1996, GRPAHICAL MODELS; MARROQUIN JL, 1985, MASSACHUSETTS I TECH, V839; McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7; MIRA A, 1997, 63 U DEGL STUD PAV; Montaud A, 1998, J I ENERGY, V71, P2; Neumann A, 1998, COMPUT MED IMAG GRAP, V22, P133, DOI 10.1016/S0895-6111(98)00015-9; Neumann A, 1999, P SOC PHOTO-OPT INS, V3661, P192, DOI 10.1117/12.348574; NEUMANN A, 2001, GRAPHICAL MODELS SHA; Pievatolo A, 1998, J ROY STAT SOC B, V60, P609, DOI 10.1111/1467-9868.00143; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; ROBERTS GO, 1994, STOCH PROC APPL, V49, P207, DOI 10.1016/0304-4149(94)90134-1; SCLOVE SL, 1987, PSYCHOMETRIKA, V52, P333, DOI 10.1007/BF02294360; STORVIK G, 1994, IEEE T PATTERN ANAL, V16, P976, DOI 10.1109/34.329011; SWENDSEN RH, 1987, PHYS REV LETT, V58, P86, DOI 10.1103/PhysRevLett.58.86; TIERNEY L, 1994, ANN STAT, V22, P1701, DOI 10.1214/aos/1176325750; WERMUTH N, 1976, BIOMETRICS, V32, P253, DOI 10.2307/2529496; WERMUTH N, 1980, J AM STAT ASSOC, V75, P963, DOI 10.2307/2287189	41	15	16	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2003	25	3					316	329		10.1109/TPAMI.2003.1182095	http://dx.doi.org/10.1109/TPAMI.2003.1182095			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	647BL					2022-12-18	WOS:000181071300004
J	Yeasin, M				Yeasin, M			Optical flow in log-mapped image plane - A new approach	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						foveated vision; logarithmic mapping; nonuniform sampling; optical flow	VISION	Foveating vision sensors are important in both machine and biological vision. The term space-variant or foveating vision refers to sensor architectures based on smooth variation of resolution across the visual field, like that of the human visual system. Traditional image processing techniques do not hold when applied directly to such a image representation since the translation symmetry and the neighborhood structure in the spatial domain is broken by the space-variant properties of the sensor. Unfortunately, there has been little systematic development of image processing tools that are explicitly designed for foveated vision. In this article, we propose a novel approach to compute the optical flow directly on log-mapped images. We propose the use of a generalized dynamic image model (GDIM) based method for computing the optical flow as opposed to the brightness constancy model (BCM) based method. We introduce a new notion of "variable window" and use the space-variant form of gradient operator while computing the spatio-temporal gradient in log-mapped images for a better accuracy and to ensure that the local neighborhood is preserved. We emphasize that the proposed method must be numerically accurate, provide a consistent interpretation, and be capable of computing the peripheral motion. Experimental results on both the synthetic and real images have been presented to show the efficacy of the proposed method.	Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park	Yeasin, M (corresponding author), Penn State Univ, Dept Comp Sci & Engn, University Pk, PA 16802 USA.							ANANDAN P, 1987, THESIS U MASSACHUSSE; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; DANIILIDIS K, 1995, COMPUTATION 3D MOTIO; DANIILIDIS K, 1995, OPTICAL FLOW COMPUTA; DANIILIDIS K, 1997, J REAL TIME IMAGING; Fischl B, 1998, INT J COMPUT VISION, V28, P199, DOI 10.1023/A:1008043919667; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Negahdaripour S, 1998, IEEE T PATTERN ANAL, V20, P961, DOI 10.1109/34.713362; Schwartz Eric L., 1994, Cerebral Cortex, V10, P359; TISTARELLI M, 1992, CVGIP-IMAG UNDERSTAN, V56, P108, DOI 10.1016/1049-9660(92)90089-L; TISTARELLI M, 1993, IEEE T PATTERN ANAL, V15, P401, DOI 10.1109/34.206959; Watson A.B, 1983, MOTION PERCEPTION RE, P1; WOODHAM RJ, 1990, P INT C COMP VIS DEC; YEASIN M, 2001, P ROBOT VISION 2001, P252	15	15	16	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2002	24	1					125	131		10.1109/34.982889	http://dx.doi.org/10.1109/34.982889			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	506FZ					2022-12-18	WOS:000172960300009
J	Tang, M; Ma, SD				Tang, M; Ma, SD			General scheme of region competition based on scale space	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nonparametric probability model; region competition; region growing; scale space-based classification; segmentation	SEGMENTATION	In this paper, we propose a general scheme of region competition (GSRC) for image segmentation based on scale space. First, we present a novel classification algorithm to cluster the image feature data according to the generally defined peaks under a certain scale and a scale space-based classification scheme to classify the pixels by grouping the resultant feature data clusters into several classes with a standard classification algorithm. Second, to reduce the resultant segmentation error, we develop a nonparametric probability model from which the functional for GSRC is derived. Third, we design a general and formal approach to automatically determine the initial regions. Finally, we propose the kernel procedure of GSRC which segments an image by minimizing the functional. The strategy adopted by GSRC is first to label pixels whose corresponding regions can be determined in large likelihood, and then to fine-tune the final regions with the help of the nonparametric probability model, boundary smoothing, and region competition. GSRC quantitatively controls the segmentation extent with the scale space-based classification scheme. Although the description of the scheme is nonparametric in this paper, GSRC can also work parametrically if all nonparametric procedures in this paper are substituted with the parametric counterparts.	Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100080, Peoples R China	Chinese Academy of Sciences; Institute of Automation, CAS	Tang, M (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, POB 2728, Beijing 100080, Peoples R China.	tangm@nlpr.ia.ac.cn; masd@nlpr.ia.ac.cn						ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913; Ballard D.H., 1982, COMPUTER VISION; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; CHEEVASUVIT F, 1986, COMPUT VISION GRAPH, V34, P268, DOI 10.1016/S0734-189X(86)80042-1; CHEN SY, 1991, CVGIP-GRAPH MODEL IM, V53, P457, DOI 10.1016/1049-9652(91)90030-N; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Davis L. S., 1975, COMPUT VISION GRAPH, V4, P248, DOI [DOI 10.1016/0146-664X(75)90012-X, 10.1016/0146-664X(75)90012-X]; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Haralick R.M., 1993, COMPUTER ROBOT VISIO, VI; HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; Li S., 1995, MARKOV RANDOM FIELD, P1; MA SD, 1998, IMAGE VISION COMPUT, V16, P43; Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M; PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J; PAPAMARKOS N, 1994, CVGIP-GRAPH MODEL IM, V56, P357, DOI 10.1006/cgip.1994.1033; PAVLIDIS T, 1990, IEEE T PATTERN ANAL, V12, P225, DOI 10.1109/34.49050; Roberts SJ, 1997, PATTERN RECOGN, V30, P261, DOI 10.1016/S0031-3203(96)00079-9; RONFARD R, 1994, INT J COMPUTER VISIO, V13; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; TANG M, 2000, NEW SCHEME CLASSIFIC; WILSON R, 1990, PATTERN RECOGN, V23, P1413, DOI 10.1016/0031-3203(90)90087-2; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343; Zucker S. W., 1976, Computer Graphics and Image Processing, V5, P382, DOI 10.1016/S0146-664X(76)80014-7	32	15	20	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2001	23	12					1366	1378		10.1109/34.977561	http://dx.doi.org/10.1109/34.977561			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	500NY					2022-12-18	WOS:000172634700003
J	Li, M; Tam, HY				Li, M; Tam, HY			Hybrid evolutionary search method based on clusters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						evolutionary computation; ART neural network; prematurity; cluster; optimization	GENETIC ALGORITHMS; FUZZY ART; CONVERGENCE; OPTIMIZATION; DIVERSITY; MINIMIZATION; SELECTION	This paper presents a hybrid evolutionary search method based on clusters (HESC). The method is specifically designed to enhance the search efficiency while alleviating the problem of premature convergence inherent in standard evolutionary search methods (SES). It involves the simultaneous evolution of a main species and an additional fast mutating species, A hybrid search method which includes a local parallel single agent search and a global multiagent evolutionary search is carried out for the main species. Effective utilization of the search history is achieved with the clustering and training of a fuzzy ART neural network (ART NN) during the search. The advantages of HESC include 1) guaranteed population diversity at each generation, 2) effective integration of local search for the exploitation of important regions and the global search for the exploration of the entire space, and 3) fast exploration ability of the fast mutating species and migration from the additional species to the main species. Those advantages have been confirmed with experiments in which hard optimization problems were successfully solved with HESC.	Nanchang Inst Aeronaut Technol, Dept Test & Control Engn, Jiangxi 330034, Peoples R China; City Univ Hong Kong, Dept Mfg Engn & Engn Management, Kowloon, Hong Kong, Peoples R China	Nanchang Hangkong University; City University of Hong Kong	Li, M (corresponding author), Nanchang Inst Aeronaut Technol, Dept Test & Control Engn, 173 Shangai Rd, Jiangxi 330034, Peoples R China.	limingl@public.nc.jx.cn; hon.y.tam@cityu.edu.hk		TAM, Hon Yuen/0000-0002-2334-8953; Li, Ming/0000-0002-5899-9043				Back T, 1993, EVOL COMPUT, V1, P1, DOI 10.1162/evco.1993.1.1.1; Beyer HG, 1995, EVOL COMPUT, V3, P81, DOI 10.1162/evco.1995.3.1.81; CARPENTER GA, 1991, NEURAL NETWORKS, V4, P759, DOI 10.1016/0893-6080(91)90056-B; CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2; CHAKRABORTY UK, 1993, INFORM PROCESS LETT, V46, P199, DOI 10.1016/0020-0190(93)90027-7; Chellapilla K., 1998, IEEE Transactions on Evolutionary Computation, V2, P91, DOI 10.1109/4235.735431; Davis L, 1991, HDB GENETIC ALGORITH, DOI DOI 10.1.1.87.3586; De Jong K.A., 1996, P 1 INT C EV COMP IT, P7; DUAN QY, 1993, J OPTIMIZ THEORY APP, V76, P501, DOI 10.1007/BF00939380; FOGEL DB, 1994, IEEE T NEURAL NETWOR, V5, P1; FORREST S, 1993, MACH LEARN, V13, P285, DOI 10.1007/BF00993046; Goldberg D. E., 1987, Genetic Algorithms and their Applications: Proceedings of the Second International Conference on Genetic Algorithms, P41; Goldberg DavidE., 1989, GENETIC ALGORITHMS S, V1st; GREFENSTETTE JJ, 1986, IEEE T SYST MAN CYB, V16, P122, DOI 10.1109/TSMC.1986.289288; Herrera F, 1996, INT J INTELL SYST, V11, P1013, DOI 10.1002/(SICI)1098-111X(199612)11:12<1013::AID-INT1>3.3.CO;2-K; HUANG JX, 1995, NEURAL NETWORKS, V8, P203, DOI 10.1016/0893-6080(94)00073-U; HUNG CA, 1995, NEURAL NETWORKS, V8, P605, DOI 10.1016/0893-6080(94)00106-V; KEANE AJ, 1995, ARTIF INTELL ENG, V9, P75, DOI 10.1016/0954-1810(95)95751-Q; Kim BM, 1997, COMPUT IND ENG, V33, P581, DOI 10.1016/S0360-8352(97)00198-8; Kuo T, 1997, APPL INTELL, V7, P257, DOI 10.1023/A:1008276600101; Leung Y, 1997, IEEE T NEURAL NETWOR, V8, P1165, DOI 10.1109/72.623217; Mao CY, 1996, IEEE T COMPUT AID D, V15, P826, DOI 10.1109/43.503949; MCDONNELL JR, 1994, IEEE T NEURAL NETWOR, V5, P24, DOI 10.1109/72.265958; MUHLENBEIN H, 1991, PARALLEL COMPUT, V17, P619, DOI 10.1016/S0167-8191(05)80052-3; POTTS JC, 1994, IEEE T SYST MAN CYB, V24, P73, DOI 10.1109/21.259687; QI XF, 1994, IEEE T NEURAL NETWOR, V5, P102, DOI 10.1109/72.265965; QUAGLIARELLA D, 1998, GENETIC ALGORITHMS E; Renders JM, 1996, IEEE T SYST MAN CY B, V26, P243, DOI 10.1109/3477.485836; RUDOLPH G, 1994, IEEE T NEURAL NETWOR, V5, P96, DOI 10.1109/72.265964; SCHAFFER JD, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P51; SCHRAUDOLPH NN, 1992, MACH LEARN, V9, P9, DOI 10.1007/BF00993252; SOLIS FJ, 1981, MATH OPER RES, V6, P19, DOI 10.1287/moor.6.1.19; TANESE R, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P434; TANESE R, 1987, P 2 INT C GEN ALG, P177; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]	40	15	16	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2001	23	8					786	799		10.1109/34.946984	http://dx.doi.org/10.1109/34.946984			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	460AH					2022-12-18	WOS:000170283300001
J	Boccignone, G; Ferraro, M; Caelli, T				Boccignone, G; Ferraro, M; Caelli, T			Encoding visual information using anisotropic transformations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						scale space; anisotropic diffusion; entropy production; feature encoding	SCALE-SPACE; EDGE; DIFFUSION	The evolution of information in images undergoing fine-to-coarse anisotropic transformations is analyzed by using an approach based on the theory of irreversible transformations. In particular, we show that, when an anisotropic diffusion model is used, local variation of entropy production over space and scale provides the basis for a general method to extract relevant image features.	Univ Salerno, Dipartimento Informaz & Ingn Elettr, I-84084 Salerno, Italy; Univ Turin, Dipartimento Fis Sperimentale, I-10125 Turin, Italy; Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2H1, Canada	University of Salerno; University of Turin; University of Alberta	Boccignone, G (corresponding author), Univ Salerno, Dipartimento Informaz & Ingn Elettr, Via Ponte Don Melillo 1, I-84084 Salerno, Italy.	boccig@diiie.unisa.it; ferraro@ph.unito.it; tcaelli@ualberta.ca	Boccignone, Giuseppe/AAH-4459-2020; Boccignone, Giuseppe/G-7542-2012	Boccignone, Giuseppe/0000-0002-5572-0924; Boccignone, Giuseppe/0000-0002-5572-0924; Caelli, Terry/0000-0001-9281-2556				Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192; Boccignone G, 2000, INT C PATT RECOG, P202, DOI 10.1109/ICPR.2000.905303; Ferraro M, 1999, IEEE T PATTERN ANAL, V21, P1199, DOI 10.1109/34.809112; Lindeberg T., 1994, SCALE SPACE THEORY C; NITZBERG M, 1992, IEEE T PATTERN ANAL, V14, P826, DOI 10.1109/34.149593; NORDSTROM KN, 1990, IMAGE VISION COMPUT, V8, P318, DOI 10.1016/0262-8856(90)80008-H; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Sporring J, 1999, IEEE T INFORM THEORY, V45, P1051, DOI 10.1109/18.761342; WHITAKER RT, 1993, CVGIP-IMAG UNDERSTAN, V57, P99, DOI 10.1006/ciun.1993.1006; You YL, 1996, IEEE T IMAGE PROCESS, V5, P1539, DOI 10.1109/83.541424	11	15	16	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2001	23	2					207	211		10.1109/34.908970	http://dx.doi.org/10.1109/34.908970			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	401NJ					2022-12-18	WOS:000166933500009
J	Srivastava, AN; Su, RJ; Weigend, AS				Srivastava, AN; Su, RJ; Weigend, AS			Data mining for features using scale-sensitive gated experts	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mixture of experts; mixture model; classification and regression; time series segmentation; neural networks		This article introduces a new tool for exploratory data analysis and data mining called Scale-Sensitive Gated Experts (SSGE) which can partition a complex nonlinear regression surface into a set of simpler surfaces (which we call features). The set of simpler surfaces has the property that each element of the set can be efficiently modeled by a single feedforward neural network. The degree to which the regression surface is partitioned is controlled by an external scale parameter. The SSGE consists of a nonlinear gating network and several competing nonlinear experts. Although SSGE is similar to the mixture of experts model of Jacobs et al. [10] the mixture of experts model gives only one partitioning of the input-output space, and thus a single set of features, whereas the SSGE gives the user the capability to discover families of features. One obtains a new member of the family of features for each setting of the scale parameter. In this paper, we derive the Scale-Sensitive Gated Experts and demonstrate its performance on a time series segmentation problem. The main results are: 1) the scale parameter controls the granularity of the features of the regression surface, 2) similar features are modeled by the same expert and different kinds of features are modeled by different experts, and 3) for the time series problem, the SSGE finds different regimes of behavior, each with a specific and interesting interpretation.	IBM Corp, Almaden Res Ctr, Deep Comp Consulting Grp, San Jose, CA 95120 USA; Univ Colorado, Dept Elect & Comp Engn, Boulder, CO 80309 USA; Emotioneering Inc, Hillsborough, CA 94010 USA	International Business Machines (IBM); University of Colorado System; University of Colorado Boulder	Srivastava, AN (corresponding author), IBM Corp, Almaden Res Ctr, Deep Comp Consulting Grp, 650 Harry Rd, San Jose, CA 95120 USA.							BASSEVILLE M, 1993, DETECTION ABRUPT CHA; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; Duda R.O., 1973, J ROYAL STAT SOC SER; DURBIN R, 1987, NATURE, V326, P689, DOI 10.1038/326689a0; FANCOURT C, 1996, P INT C NEUR NETW; GERSHENFELD N, 1995, P 1995 FLOR WORKSH N, V1, P1; GUIASU S, 1977, INFORMATION THEORY A; Hertz J., 1991, INTRO THEORY NEURAL, DOI DOI 10.1201/9780429499661; JACOBS RA, 1993, IEEE T SYSTEMS MAN C; Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; McCullagh P., 1989, GEN LINEAR MODELS, V2nd; Pawelzik K, 1996, NEURAL COMPUT, V8, P340, DOI 10.1162/neco.1996.8.2.340; QUANDT RE, 1958, J AM STAT ASSOC, V53, P873, DOI 10.2307/2281957; Rao C.R., 1965, LINEAR STAT INFERENC, V2nd; ROSE K, 1990, PHYS REV LETT, V65, P945, DOI 10.1103/PhysRevLett.65.945; Rumelhart David E, 1995, BACKPROPAGATION THEO, P3, DOI DOI 10.5555/201784.201785; SHI S, 1998, THESIS U COLORADO; SWOKOWSKI LW, 1984, CALCULUS ANAL GEOMET; Takens F., 1981, DYNAMICAL SYSTEMS TU, P366, DOI [DOI 10.1007/BFB0091924, 10.1007/bfb0091924, 10.1007/BFb0091924]; Weigend A. S, 1994, TIME SERIES PREDICTI; Weigend AS, 1995, INT J NEURAL SYST, V6, P373, DOI 10.1142/S0129065795000251; WONG YF, 1993, NEURAL COMPUT, V5, P89, DOI 10.1162/neco.1993.5.1.89	23	15	15	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1999	21	12					1268	1279		10.1109/34.817407	http://dx.doi.org/10.1109/34.817407			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	275PG					2022-12-18	WOS:000084828100002
J	Kanungo, T; Haralick, RM				Kanungo, T; Haralick, RM			An automatic closed-loop methodology for generating character groundtruth for scanned documents	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						automatic real groundtruth; document image analysis; OCR; performance evaluation; image registration; geometric transformations; image warping		Character groundtruth for real, scanned document images is crucial for evaluating the performance of OCR systems, training OCR algorithms, and validating document degradation models. Unfortunately, manual collection of accurate groundtruth for characters in a real (scanned) document image is not practical because (i) accuracy in delineating groundtruth character bounding boxes is not high enough, (ii) it is extremely laborious and time consuming, and (iii) the manual labor required for this task is prohibitively expensive. In this paper we describe a closed-loop methodology for collecting very accurate groundtruth for scanned documents. We first create ideal documents using a typesetting language. Next we create the groundtruth for the ideal document. The ideal document is then printed, photocopied and then scanned. A registration algorithm estimates the global geometric transformation and then performs a robust local bitmap match to register the ideal document image to the scanned document image. Finally, groundtruth associated with the ideal document image is transformed using the estimated geometric transformation to create the groundtruth for the scanned document image. This methodology is very general and can be used far creating groundtruth for documents in typeset in any language, layout, font, and style. We have demonstrated the method by generating groundtruth for English, Hindi, and FAX document images. The cost of creating groundtruth using our methodology is minimal. If character, word or zone groundtruth is available for any real document, the registration algorithm can be used to generate the corresponding groundtruth for a rescanned version of the document.	Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA; Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA	University System of Maryland; University of Maryland College Park; University of Washington; University of Washington Seattle	Kanungo, T (corresponding author), Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA.		Haralick, Robert/AAW-5151-2020	manickam, vijayabhama.M/0000-0001-9437-9477				CASEY RG, 1990, IBM SYST J, V29, P435, DOI 10.1147/sj.293.0435; Doermann D. S., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P497, DOI 10.1109/ICDAR.1993.395687; HARALICK RM, 1994, UW ENGLISH DATABASE, V1; HOBBY JD, 1997, P INT C DOC AN REC U, P313; Kanungo T., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P669, DOI 10.1109/ICPR.1996.547030; KANUNGO T, 1998, LAMPTR026 U MAR CTR; KANUNGO T, 1994, P INT WORKSH MACH VI; KANUNGO T, 1995, P 4 ANN S DOC AN INF; KANUNGO T, 1996, DOCUMENT DEGRADATION; KANUNGO T, 1994, INT J IMAGING SYSTEM, V5; KNUTH DE, 1988, TEX PROGRAM; Lamport Leslie, 1986, LATEX DOCUMENT PREPA; LEMOIGNE J, 1997, IM REG WORKSH NASA G; VELTHUIS FJ, DEVANAGARI MACRO LAT; Wolberg G, 1990, DIGITAL IMAGE WARPIN	15	15	19	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1999	21	2					179	183		10.1109/34.748827	http://dx.doi.org/10.1109/34.748827			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	167NL					2022-12-18	WOS:000078639900007
J	Lee, TCM				Lee, TCM			Segmenting images corrupted by correlated noise	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						correlated noise; image segmentation; merging algorithm; minimum description length	SEGMENTATION; MODELS	Image segmentation is fundamental to many image analysis problems. It aims to partition a digital image into a set of nonoverlapping homogeneous regions. The main contribution of this paper is the development of a new segmentation procedure which is designed to segment images corrupted by correlated noise. This new segmentation procedure is based on Rissanen's minimum description length (MDL) principle and consists of two components: i) an MDL-based criterion in which the "best" segmentation is defined as its minimizer and ii) a merging algorithm which attempts to locate this minimizer. The performance of this procedure is illustrated via a simulation study, with promising results.	Univ Chicago, Dept Stat, Chicago, IL 60637 USA	University of Chicago	Lee, TCM (corresponding author), Univ Chicago, Dept Stat, 5734 S Univ Ave, Chicago, IL 60637 USA.	tlee@galton.uchicago.edu		Lee, Thomas/0000-0001-7067-405X				ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913; Baddeley A.J., 1992, NIEUW ARCH WISK, V10, P157; BEAULIEU JM, 1989, IEEE T PATTERN ANAL, V11, P150, DOI 10.1109/34.16711; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; Bose S, 1997, J AM STAT ASSOC, V92, P92, DOI 10.2307/2291453; CAMERON MA, 1987, J TIME SER ANAL, V8, P379; CHANG YL, 1994, IEEE T IMAGE PROCESS, V3, P868, DOI 10.1109/83.336259; CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P194, DOI 10.1109/TASSP.1985.1164507; CHEN SY, 1991, CVGIP-GRAPH MODEL IM, V53, P457, DOI 10.1016/1049-9652(91)90030-N; Glasbey CA, 1995, IMAGE ANAL BIOL SCI; Haralick RM., 1992, COMPUTER ROBOT VISIO; HART JD, 1991, J ROY STAT SOC B MET, V53, P173; Jain A. K., 1989, FUNDAMENTALS DIGITAL; JOHNSON VE, 1994, J AM STAT ASSOC, V89, P230, DOI 10.2307/2291219; Kanungo T., 1995, 996087919 RJ IBM RES; KASHYAP RL, 1984, IEEE T INFORM THEORY, V30, P736, DOI 10.1109/TIT.1984.1056955; LAVALLE SM, 1995, IEEE T PATTERN ANAL, V17, P211, DOI 10.1109/34.368166; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; LEE TCM, 1997, UNPUB MINIMUM DESCRI; LEE TCM, 1997, THESIS MACQUARIE U S; MODESTINO JW, 1981, IEEE T PATTERN ANAL, V3, P557, DOI 10.1109/TPAMI.1981.4767148; Rissanen Jorma, 1989, STOCHASTIC COMPLEXIT; SOLO V, 1986, IEEE T INFORM THEORY, V32, P743, DOI 10.1109/TIT.1986.1057241; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; VICKERS AL, 1982, IEEE T PATTERN ANAL, V4, P61, DOI 10.1109/TPAMI.1982.4767197; ZHANG J, 1990, IEEE T PATTERN ANAL, V12, P1009, DOI 10.1109/34.58873; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	27	15	15	1	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1998	20	5					481	492		10.1109/34.682178	http://dx.doi.org/10.1109/34.682178			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZR253					2022-12-18	WOS:000073955600004
J	Sim, DG; Park, RH				Sim, DG; Park, RH			Robust reweighted MAP motion estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion estimation; regularization; MAP estimation; robust statistics; LMedS	OPTICAL-FLOW; COMPUTER VISION; POSED PROBLEMS; COMPUTATION; FRAMEWORK; REGULARIZATION; DECOMPOSITION; SEGMENTATION; DOMAIN	This paper proposes a motion estimation algorithm that is robust to motion discontinuity and noise. The proposed algorithm is constructed by embedding the least median squares (LMedS) of robust statistics into the maximum a posteriori (MAP) estimator. Difficulties in accurate estimation of the motion field arise from the smoothness constraint and the sensitivity to noise. To cope robustly with these problems, a median operator and the concept of reweighted least squares (RLS) are applied to the MAP motion estimator, resulting in the reweighted robust MAP (RRMAP). The proposed RRMAP motion estimation algorithm is also generalized for multiple image frame cases. Computer simulation with various synthetic image sequences shows that the proposed algorithm reduces errors, compared to three existing robust motion estimation algorithms that are based on Nf-estimation, total least squares (TLS), and Hough transform. It is also observed that the proposed algorithm is statistically efficient and robust to additive Gaussian noise and impulse noise. Furthermore, the proposed algorithm yields reasonable performance for real image sequences.	Sogang Univ, Dept Elect Engn, Seoul 100611, South Korea	Sogang University	Sim, DG (corresponding author), Sogang Univ, Dept Elect Engn, CPO Box 1142, Seoul 100611, South Korea.	rhpark@ccs.songag.ac.kr	Park, Rae-Hong/Q-7908-2019; Park, Rae-Hong/Q-7955-2019	Park, Rae-Hong/0000-0002-4792-2980				AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965; ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; [Anonymous], 1990, NONLINEAR DIGITAL FI; AYER S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P777, DOI 10.1109/ICCV.1995.466859; BabHadiashar A, 1997, PROC CVPR IEEE, P988, DOI 10.1109/CVPR.1997.609448; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962; Black M. J., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P296, DOI 10.1109/CVPR.1991.139705; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; BLACK MJ, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P15, DOI 10.1109/CVPR.1994.323805; Black MJ, 1993, P 4 INT C COMP VIS, P231, DOI DOI 10.1109/ICCV.1993.378214; BLACK MJ, 1994, P EUR C COMP VIS STO, V800, P138; BOBER M, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P947, DOI 10.1109/CVPR.1994.323931; BOBER M, 1995, P 2 AS C COMP VIS SI, P301; Bournan C, 1993, IEEE T IMAGE PROCESS, V2, P296, DOI 10.1109/83.236536; Clark J.J., 1990, DATA FUSION SENSORY; DARRELL T, 1995, IEEE T PATTERN ANAL, V17, P474, DOI 10.1109/34.391395; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Jepson A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P760, DOI 10.1109/CVPR.1993.341161; Ju SX, 1996, PROC CVPR IEEE, P307, DOI 10.1109/CVPR.1996.517090; KASHYAP RL, 1988, IEEE T ACOUST SPEECH, V36, P1313, DOI 10.1109/29.1659; KASSAM SA, 1985, P IEEE, V73, P433, DOI 10.1109/PROC.1985.13167; KOIVO AJ, 1989, IEEE T SYST MAN CYB, V19, P1659, DOI 10.1109/21.44082; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; SCHNORR C, 1992, INT J COMPUT VISION, V8, P153, DOI 10.1007/BF00127172; Sim DG, 1996, J VIS COMMUN IMAGE R, V7, P259, DOI 10.1006/jvci.1996.0023; Sim DG, 1997, COMPUT VIS IMAGE UND, V65, P19, DOI 10.1006/cviu.1996.0483; SINHA SS, 1992, IEEE T PATTERN ANAL, V14, P36, DOI 10.1109/34.107012; STEVENSON RL, 1994, IEEE T SYST MAN CYB, V24, P455, DOI 10.1109/21.278994; SZELISKI E, 1995, P 5 INT C COMP VIS B; VEGARIVEROS JF, 1989, IEE PROC-I, V136, P397, DOI 10.1049/ip-i-2.1989.0060; WEBER J, 1995, INT J COMPUT VISION, V14, P67, DOI 10.1007/BF01421489; Weiss Y, 1996, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.1996.517092; YU XM, 1994, IEEE T PATTERN ANAL, V16, P530, DOI 10.1109/34.291443; ZHUANG XH, 1992, IEEE T PATTERN ANAL, V14, P19, DOI 10.1109/34.107011	37	15	15	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1998	20	4					353	365		10.1109/34.677261	http://dx.doi.org/10.1109/34.677261			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZP214					2022-12-18	WOS:000073729200001
J	Shum, HY; Hebert, M; Ikeuchi, K; Reddy, R				Shum, HY; Hebert, M; Ikeuchi, K; Reddy, R			An integral approach to free-form object modeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						3D object modeling; free-form object modeling; multiple view merging; principal component analysis; resampling; local curvature	RANGE IMAGES	This paper presents a new approach to free-form object modeling from multiple range images. In most conventional approaches, successive views are registered sequentially. In contrast to the sequential approaches, we propose an integral approach which reconstructs statistically optimal object models by simultaneously aggregating all data from multiple views into a weighted least-squares (WLS) formulation. The integral approach has two components. First, a global resampling algorithm constructs partial representations of the object from individual views, so that correspondence can be established among different views. Second, a weighted least-squares algorithm integrates resampled partial representations of multiple views, using the techniques of principal component analysis with missing data (PCAMD). Experiments show that our approach is robust against noise and mismatch.	CARNEGIE MELLON UNIV, INST ROBOT, PITTSBURGH, PA 15213 USA; UNIV TOKYO, INST IND SCI, MINATO KU, TOKYO 106, JAPAN; CARNEGIE MELLON UNIV, SCH COMP SCI, PITTSBURGH, PA 15213 USA	Carnegie Mellon University; University of Tokyo; Carnegie Mellon University	Shum, HY (corresponding author), MICROSOFT CORP, RES, 1 MICROSOFT WAY, REDMOND, WA 98052 USA.							AHUJA N, 1989, IEEE T PATTERN ANAL, V11, P137, DOI 10.1109/34.16710; ARMAN F, 1993, COMPUT SURV, V25, P5, DOI 10.1145/151254.151255; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BHANU B, 1984, IEEE T PATTERN ANAL, V6, P340, DOI 10.1109/TPAMI.1984.4767527; Champleboux G., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P83, DOI 10.1109/CVPR.1992.223223; CHEN Y, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2724, DOI 10.1109/ROBOT.1991.132043; CHEN YY, 1994, INT CONF WAFER SCALE, P153, DOI 10.1109/ICWSI.1994.291256; DELINGETTE H, 1993, P INT C COMP VIS 93; Ferrie F. P., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P117; HIGUCHI K, 1995, GRAPH MODEL IM PROC, V57, P315, DOI 10.1006/gmip.1995.1028; Hoppe H., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P295, DOI 10.1145/192161.192233; PARVIN B, 1992, 1992 IEEE INTERNATIONAL CONF ON ROBOTICS AND AUTOMATION : PROCEEDINGS, VOLS 1-3, P1602, DOI 10.1109/ROBOT.1992.220023; RUHE A, 1974, UMINF4874 DEP INF PR; SHUM H, 1995, CMUCS95135; SHUM HY, 1995, IEEE T PATTERN ANAL, V17, P854, DOI 10.1109/34.406651; Soucy M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P348, DOI 10.1109/CVPR.1992.223166; TAUBIN G, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P902, DOI 10.1109/ICCV.1995.466840; Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241; Vasilescu M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P829, DOI 10.1109/CVPR.1992.223247; VEMURI BC, 1986, JUN P C COMP VIS PAT, P435; Wiberg T, 1976, P 2 S COMP STAT, P229; [No title captured]	22	15	15	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1997	19	12					1366	1370		10.1109/34.643895	http://dx.doi.org/10.1109/34.643895			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YK781					2022-12-18	WOS:A1997YK78100005
J	Lindenbaum, M				Lindenbaum, M			An integrated model for evaluating the amount of data required for reliable recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object recognition; localization; pose estimation; similarity measures; noise models; performance analysis		Many recognition procedures rely on the consistency of a subset of data features with a hypothesis as the sufficient evidence to the presence of the corresponding object. We analyze here the performance of such procedures, using a probabilistic model, and provide expressions for the sufficient size of such data subsets, that, if consistent, guarantee the validity of the hypotheses with arbitrary confidence. We focus on 2D objects and the affine transformation class, and provide, for the first time, an integrated model which takes into account the shape of the objects involved, the accuracy of the data collected, the clutter present in the scene, the class of the transformations involved, the accuracy of the localization, and the confidence we would like to have in our hypotheses. Interestingly, it turns out that most of these factors can be quantified cumulatively by one parameter, denoted ''effective similarity,'' which largely determines the sufficient subset size. The analysis is based on representing the class of instances corresponding to a model object and a group of transformations, as members of a metric space, and quantifying the variation of the instances by a metric cover.			Lindenbaum, M (corresponding author), TECHNION ISRAEL INST TECHNOL, DEPT COMP SCI, IL-32000 HAIFA, ISRAEL.							AMIR A, 1996, IN PRESS IEEE T PATT; Ben-David S., 1993, Proceeding of the Sixth Annual ACM Conference on Computational Learning Theory, P327, DOI 10.1145/168304.168364; BREUEL TM, 1993, COMPUTER VISION PATT, P707; CASS TA, 1992, P EUR C COMP VIS, P834; GOTTSCHALK PG, 1989, INT J ROBOT RES, V8, P110, DOI 10.1177/027836498900800608; GRIMSON W, 1992, P EUROPEAN C COMPUTE, P291; GRIMSON WEL, 1991, IEEE T PATTERN ANAL, V13, P1201, DOI 10.1109/34.106994; GRIMSON WEL, 1992, IEEE T PATTERN ANAL, V14, P97; GRIMSON WEL, 1991, IEEE T PATTERN ANAL, V13; HAGERUP T, 1990, INFORM PROCESS LETT, V33, P305, DOI 10.1016/0020-0190(90)90214-I; LINDENBAUM M, 1995, IEEE T PATTERN ANAL, V17, P666, DOI 10.1109/34.391409; LINDENBAUM M, 1994, INT C PATT RECOG, P726; LINDENBAUM M, 1993, 9329 CIS TECHN; LINDENBAUM M, 1994, IN PRESS J MACHINE I, P239; MAYBANK SJ, 1995, INT J COMPUT VISION, V16, P5, DOI 10.1007/BF01428191; Mundy J., 1992, GEOMETRIC INVARIANCE; RUCKLIDGE WJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P457, DOI 10.1109/ICCV.1995.466904; Rudshtein A., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P35, DOI 10.1109/ICPR.1996.545987; Sarachik K. B., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P400, DOI 10.1109/CVPR.1993.341099; SARACHIK KB, 1994, P IM UND WORKSH, P1269	20	15	16	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1997	19	11					1251	1264		10.1109/34.632984	http://dx.doi.org/10.1109/34.632984			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YG585					2022-12-18	WOS:A1997YG58500006
J	Jackowski, M; Goshtasby, A; Bines, S; Roseman, D; Yu, C				Jackowski, M; Goshtasby, A; Bines, S; Roseman, D; Yu, C			Correcting the geometry and color of digital images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						geometry correction; color correction; approximation; parametric surface; rational Gaussian surface	RATIONAL GAUSSIAN CURVES; CALIBRATION; DISTORTION; CONSTANCY; SURFACES	A unified method for correcting the geometry and color of digital images is presented. The method uses a color chart with a prearranged array of known color patches. Using the true geometry and color of the chart and geometry and color of the image of the chart, transformation functions that describe the geometry and color characteristics of the camera are determined. The transformation functions are then used to correct the geometry and color of obtained images. Experimental results of the proposed method on images acquired under different scene illuminations and camera settings are presented and evaluated.	RUSH PRESBYTERIAN ST LUKES MED CTR,DEPT GEN SURG,CHICAGO,IL 60612; UNIV ILLINOIS,DEPT ELECT ENGN & COMP SCI,CHICAGO,IL 60607	Rush University; University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital	Jackowski, M (corresponding author), WRIGHT STATE UNIV,DEPT COMP SCI & ENGN,DAYTON,OH 45435, USA.		Jackowski, Marcel/G-7602-2012					BARNARD K, 1996, P 4 EUR C COMP VIS A, V2, P3; Cowan W. B., 1983, Computer Graphics, V17, P315, DOI 10.1145/964967.801163; Duchon J., 1977, CONSTRUCTIVE THEORY, P85; ECHIGO T, 1990, MACH VISION APPL, V1, P159; FRYER JG, 1986, PHOTOGRAMM ENG REM S, V52, P51; GOSHTASBY A, 1995, COMPUT AIDED DESIGN, V27, P363, DOI 10.1016/0010-4485(95)96800-2; GOSHTASBY A, 1993, COMPUT AIDED GEOM D, V10, P143, DOI 10.1016/0167-8396(93)90017-W; GOSHTASBY A, 1984, IEEE T PATTERN ANAL, V6, P374, DOI 10.1109/TPAMI.1984.4767532; GOSHTASBY A, 1993, INT J COMPUT VISION, V10, P233, DOI 10.1007/BF01539537; GOSHTASBY A, 1989, COMPUTER VISION GRAP, V427, P385; GREEN WB, 1975, APPL OPTICS, V14, P105, DOI 10.1364/AO.14.000105; HARDY RL, 1990, COMPUTER MATH APPL, V19, P1905; HEALEY G, 1994, J OPT SOC AM A, V11, P3003, DOI 10.1364/JOSAA.11.003003; HOLUB R, 1988, J IMAGING TECHNOL, V14, P53; HOLUB R, 1988, J IMAGING TECHNOL, V14, P47; HUNG PC, 1991, P SOC PHOTO-OPT INS, V1448, P164, DOI 10.1117/12.45355; HUNG PC, 1988, P SPIE IMAGING APPL, P111; KANAMORI K, 1990, P SOC PHOTO-OPT INS, V1244, P272, DOI 10.1117/12.19518; KANAMORI K, 1992, J IMAGING SCI TECHN, V36, P73; KANG HR, 1992, J IMAGING SCI TECHN, V36, P162; KANG RH, 1998, J ELECTRON IMAGING, V1, P125; KASSON JM, 1992, ACM T GRAPHIC, V11, P373, DOI 10.1145/146443.146479; LEE HC, 1986, J OPT SOC AM A, V3, P1694, DOI 10.1364/JOSAA.3.001694; Lenz RK, 1987, IEEE T ROBOTIC AUTOM, P68; MALONEY LT, 1986, J OPT SOC AM A, V3, P29, DOI 10.1364/JOSAA.3.000029; MARIMONT DH, 1992, J OPT SOC AM, V9, P1906; McCamy C. S., 1976, Journal of Applied Photographic Engineering, V2, P95; NAGAO M, 1979, COMPUT VISION GRAPH, V10, P195, DOI 10.1016/0146-664X(79)90001-7; OHLANDER R, 1978, COMPUT VISION GRAPH, V8, P313, DOI 10.1016/0146-664X(78)90060-6; PARKKINEN JPS, 1989, J OPT SOC AM A, V6, P318, DOI 10.1364/JOSAA.6.000318; Powell M.J.D., 1987, ALGORITHMS APPROXIMA, P143; SAI A, 1987, MATH SURFACES, V2, P321; STAES K, 1997, SOC MOTION PICTURE T, V86, P537; STOKES M, 1992, ACM T GRAPHIC, V11, P406, DOI 10.1145/146443.146482; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; THOMPSON M, 1976, MANUAL PHOTOGRAMMETR, P84; TSAI RY, 1986, COMPUTER VISION GRAP, V3, P346; VRHEL MJ, 1992, COLOR RES APPL, V17, P328, DOI 10.1002/col.5080170507; VRHEL MJ, 1994, IEEE T IMAGE PROCESS, V3, P147, DOI 10.1109/83.277897; WANG LL, 1992, IEEE T PATTERN ANAL, V14, P965; WENG JY, 1992, IEEE T PATTERN ANAL, V14, P965, DOI 10.1109/34.159901; WILLSON RG, 1994, TCMURITR9403 CARN ME	42	15	18	1	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1997	19	10					1152	1158		10.1109/34.625125	http://dx.doi.org/10.1109/34.625125			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YB678					2022-12-18	WOS:A1997YB67800011
J	Lauren, PD; Nandhakumar, N				Lauren, PD; Nandhakumar, N			Estimating the viewing parameters of random, noisy projections of asymmetric objects for tomographic reconstruction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						tomography; pose estimation; motion analysis; 3D reconstruction	ANGULAR RECONSTITUTION; ELECTRON-MICROGRAPHS; 3-DIMENSIONAL RECONSTRUCTION; MACROMOLECULES; DIRECTIONS; PARTICLES	The ability to determine the viewing parameters of objects from their projections has enabled well established tomographic techniques to be employed in the three-dimensional reconstruction of objects from images obtained via modalities where the orientation of the objects cannot be controlled. A method is described for the determination of the viewing parameters of randomly acquired projections of asymmetric objects. It extends upon the common lines algorithm by determining the relative orientation of projections from the location of lines of intersection among the Fourier transforms of the projections in three-dimensional Fourier space. A new technique for finding the lines of intersection in the presence of translational displacement, and for subsequently finding the translational displacement, is presented. The complete algorithm is described and its efficacy is demonstrated using real data. A new technique for dealing with noise is also discussed.	ELECTROGLAS INC,SANTA CLARA,CA 95054		Lauren, PD (corresponding author), MEDIA CYBERNET LP,8484 GEORGIA AVE,SILVER SPRING,MD 20910, USA.							Bracewell R. N., 1956, AUSTR J PHYS, V9, P198, DOI 10.1071/PH560198; COLSHER JG, 1976, THESIS U CALIFORNIA; CROWTHER RA, 1970, PROC R SOC LON SER-A, V317, P319, DOI 10.1098/rspa.1970.0119; CROWTHER RA, 1971, PHILOS T R SOC B, V261, P221, DOI 10.1098/rstb.1971.0054; DEROSIER DJ, 1968, NATURE, V217, P130, DOI 10.1038/217130a0; DEROSIER DJ, 1970, J MOL BIOL, V52, P355, DOI 10.1016/0022-2836(70)90036-7; FARROW NA, 1992, J OPT SOC AM A, V9, P1749, DOI 10.1364/JOSAA.9.001749; FRANK J, 1981, SCIENCE, V214, P1353, DOI 10.1126/science.7313694; FULLER SD, 1987, CELL, V48, P923, DOI 10.1016/0092-8674(87)90701-X; Goncharov A. B., 1987, Soviet Physics - Crystallography, V32, P504; HOPPE W, 1976, Z NATURFORSCH A, V31, P645; HOPPE W, 1968, NATURWISSENSCHAFTEN, V55, P333, DOI 10.1007/BF00600449; LANCASTER P, 1987, CURVE SURFACE FITTIN, P36; Lauren P. D., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P71, DOI 10.1109/CVPR.1992.223225; LAUREN PD, 1996, THESIS U VIRGINIA; Orlova EV, 1996, NAT STRUCT BIOL, V3, P547, DOI 10.1038/nsb0696-547; PROVENCHER SW, 1983, PROGR SCI COMPUTING, V2, P304; RADERMACHER M, 1988, J ELECTRON MICR TECH, V9, P359, DOI 10.1002/jemt.1060090405; RADERMACHER M, 1994, ULTRAMICROSCOPY, V53, P121, DOI 10.1016/0304-3991(94)90003-5; RADERMACHER M, 1985, ULTRAMICROSCOPY, V17, P117, DOI 10.1016/0304-3991(85)90004-X; RADERMACHER M, 1986, ULTRAMICROSCOPY, V19, P75; RADERMACHER M, 1984, P 8 EUR C EL MICR, V2, P1345; SCHATZ M, 1995, J STRUCT BIOL, V114, P28, DOI 10.1006/jsbi.1995.1003; SERYSHEVA II, 1995, NAT STRUCT BIOL, V2, P18, DOI 10.1038/nsb0195-18; STEINKILBERG M, 1980, H-S Z PHYSIOL CHEM, V361, P1363, DOI 10.1515/bchm2.1980.361.2.1363; VAINSTEIN BK, 1986, DOKL AKAD NAUK SSSR+, V287, P1131; VANHEEL M, 1987, ULTRAMICROSCOPY, V21, P111, DOI 10.1016/0304-3991(87)90078-7; [No title captured]	28	15	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1997	19	5					417	430		10.1109/34.589202	http://dx.doi.org/10.1109/34.589202			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XB163					2022-12-18	WOS:A1997XB16300001
J	Nogawa, H; Nakajima, Y; Sato, Y; Tamura, S				Nogawa, H; Nakajima, Y; Sato, Y; Tamura, S			Acquisition of symbolic description from flow fields: A new approach based on a fluid model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						symbolic description; flow field; fluid model; Rankine's vortex; physics-based vision	ORIENTED PATTERNS; TURBULENCE	We propose a new model and new algorithm for acquiring symbolic description from a flow field. Our model is derived from physical data, and our algorithm is based on holomorphic complex function theory. Application of this method enables both qualitative and quantitative information to be obtained from a flow field. We also demonstrate the robustness or our method using a simulated flow field and a real image sequence.			Nogawa, H (corresponding author), OSAKA UNIV, SCH MED, DIV FUNCT DIAG IMAGING, 2-2 YAMADAOKA, SUITA, OSAKA 565, JAPAN.		Sato, Yoshinobu/C-9361-2009					ADRIAN RJ, 1991, ANNU REV FLUID MECH, V23, P261, DOI 10.1146/annurev.fl.23.010191.001401; BURR DJ, 1981, IEEE T PATTERN ANAL, V3, P708, DOI 10.1109/TPAMI.1981.4767176; CHONG MS, 1990, PHYS FLUIDS A-FLUID, V2, P765, DOI 10.1063/1.857730; ECKHARDT B, 1989, P IUTAM S CAMBR AUG, P23; FORD RM, 1994, CVGIP-GRAPH MODEL IM, V56, P75, DOI 10.1006/cgip.1994.1007; HELMAN J, 1989, IEEE COMPUT, V22, P27, DOI DOI 10.1109/2.35197.10; Kanatani K., 1993, GEOMETRIC COMPUTATIO; KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0; KASS M, 1987, P 1 INT C COMP VIS L; KISHIBA S, 1993, J PHYS SOC JPN, V62, P3783, DOI 10.1143/JPSJ.62.3783; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; MELANDER MV, 1993, PHYS REV E, V48, P2669, DOI 10.1103/PhysRevE.48.2669; Milne-Thomson L.M., 1972, THEORETICAL HYDRODYN; NOMURA A, 1993, P 4 INT WORKSH, P343; OTTINO JH, 1989, P IUTAM S CAMBR AUG, P13; POLAVINI LM, 1989, P IUTAM S CAMBR AUG, P34; Press WH, 1988, NUMERICAL RECIPES C; QIAN RJ, 1993, P AS C COMP VIS 93 O, P794; RAO AR, 1992, IEEE T PATTERN ANAL, V14, P693, DOI 10.1109/34.142908; SENG J, 1991, SPRINGER SERIES INFO; Shu C.-F., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P352, DOI 10.1109/CVPR.1991.139715; SHU CF, 1994, IEEE T PATTERN ANAL, V16, P946, DOI 10.1109/34.310692; Spivak M., 1979, DIFFERENTIAL GEOMETR; TOBAK M, 1982, ANNU REV FLUID MECH, V14, P61, DOI 10.1146/annurev.fl.14.010182.000425; ZHONG J, 1994, P C COMP VIS PATT RE, P310	25	15	15	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1997	19	1					58	63		10.1109/34.566811	http://dx.doi.org/10.1109/34.566811			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WE528					2022-12-18	WOS:A1997WE52800006
J	Jung, DM; Krishnamoorthy, MS; Nagy, G; Shapira, A				Jung, DM; Krishnamoorthy, MS; Nagy, G; Shapira, A			N-tuple features for OCR revisited	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						backtracking; character features; classification; decision trees; distinguishing string; missing configuration; n-tuples; OCR; simulated parallelism		N-tuple features for optical character recognition have received only scattered attention since the 1960s. Our main purpose here is to show that advances in computer technology and computer science compel renewed interest. N-tuple features are useful for printed character classification because they indicate the presence or absence of a given rigid configuration of n black and white pixels in a pattern. Desirable n-tuples fit each pattern of a specified (positive) training set of characters in at least p different shift positions, and fail to fit each pattern of a specified (negative) training set by at least n - q pixels in each shift position. In this work we prove that the problem of finding a distinguishing n-tuple is NP-complete, by examining a natural subproblem with binary strings called the missing configuration problem. The NP-completeness result notwithstanding, distinguishing n-tuples are found automatically in a few seconds on contemporary workstations. We exhibit a practical search algorithm for generating, from a small training set, a collection of n-tuples with low class-conditional correlation and with specified design parameters n, p, and q. The generator, which is available on the Internet, is empirically shown to be effective through a comparison with a benchmark generator. We show experimentally that the design parameters provide a useful tradeoff between distinguishing power and generation time, and also between the conditional probabilities for the positive and negative classes. We explore the feature probabilities obtainable for various dichotomies, and show that the design parameters control the feature probabilities.	RENSSELAER POLYTECH INST, TROY, NY 12180 USA	Rensselaer Polytechnic Institute	Jung, DM (corresponding author), CAERE CORP, 100 COOPER COURT, LOS GATOS, CA 95030 USA.			Nagy, George/0000-0002-0521-1443				[Anonymous], 1959, P E JOINT COMP C, DOI DOI 10.1145/1460299.1460326; BAKIS R, 1968, IEEE T SYST SCI CYB, VSSC4, P119, DOI 10.1109/TSSC.1968.300138; DUDA RO, 1973, PATTERN CLASSIFICATI, P32; Garey M.R., 1979, COMPUTERS INTRACTABI; JUNG DM, 1995, THESIS RENSSELAER PO; Kamentsky L., 1964, COMPUTER INFORMATION, P194; KAMENTSKY LA, 1963, IBM J RES DEV, V7, P2, DOI 10.1147/rd.71.0002; LEVINE MD, 1969, P IEEE, V57, P1391, DOI 10.1109/PROC.1969.7277; LIU CN, 1966, IEEE TRANS ELECTRON, VEC15, P916, DOI 10.1109/PGEC.1966.264474; NADLER M, 1972, MACHINE PERCEPTION P, P3; NAGY G, 1996, P S DOC AN INF RETR; NILSSON NJ, 1980, PRINCIPLES ARTIFICIA, P72; RAO VN, 1993, IEEE T PARALL DISTR, V4, P427, DOI 10.1109/71.219757; RICE SV, 1994, 3 ANN TEST OCR ACCUR, P15; SHAPIRA A, 1995, 959 RENSS POL I COMP; SHAPIRA A, 1996, E COMMUNICATION; SHAPIRA A, 1995, ECSEOCR20DEC95 RENSS; SHAPIRO A, 1996, THESIS RENSSELAER PO; STENTIFORD FWM, 1985, IEEE T PATTERN ANAL, V7, P349, DOI 10.1109/TPAMI.1985.4767665; ULLMANN JR, 1969, IEEE T COMPUT, VC 18, P1135, DOI 10.1109/T-C.1969.222599; WANG X, 1995, THESIS RENSSELAER PO	21	15	18	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1996	18	7					734	745		10.1109/34.506795	http://dx.doi.org/10.1109/34.506795			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UZ457					2022-12-18	WOS:A1996UZ45700005
J	AVIITZHAK, HI; VANMIEGHEM, JA; RUB, L				AVIITZHAK, HI; VANMIEGHEM, JA; RUB, L			MULTIPLE SUBCLASS PATTERN-RECOGNITION - A MAXIMIN CORRELATION APPROACH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						PATTERN RECOGNITION; NEAREST NEIGHBOR; TEMPLATE MATCHING; CORRELATION; MAXIMIN; MINIMAX; CLUSTERING; MULTIFONT OPTICAL CHARACTER RECOGNITION	TEMPLATE	This paper addresses a correlation based nearest neighbor pattern recognition problem where each class is given as a collection of subclass templates. The recognition is performed in two stages, In the first stage the class is determined. Templates for this stage are created using the subclass templates. Assignment into subclasses occurs in the second stage. This two stage approach may be used to accelerate template matching. In particular, the second stage may be omitted when only the class needs to be determined. We present a method for optimal aggregation of subclass templates into class templates. For each class, the new template is optimal in that it maximizes the worst case (i.e., minimum) correlation with its subclass templates. An algorithm which solves this maximin optimization problem is presented and its correctness is proved. In addition, test results are provided, indicating that the algorithm's execution time is polynomial in the number of subclass templates. We show tight bounds on the maximin correlation. The bounds are functions only of the number of original subclass templates and the minimum element in their correlation matrix. The algorithm is demonstrated on a multifont optical character recognition problem.	STANFORD UNIV,GRAD SCH BUSINESS,STANFORD,CA 94305; OCTEL COMMUN CORP,MILPITAS,CA 95035	Stanford University	AVIITZHAK, HI (corresponding author), CANON RES CTR AMER,4009 MIRANDA AVE,PALO ALTO,CA 94304, USA.							[Anonymous], 1968, LINEAR ALGEBRA APPL, DOI DOI 10.1016/0024-3795(68)90052-9; CAPODIFERRO L, 1987, APR P IEEE INT C AC; COVER TM, 1967, IEEE T INFORMATION T, V13; Dantzig GB, 1993, LINEAR PROGRAMMING E; Duda R.O., 1973, J ROYAL STAT SOC SER; FUKUNAGA K, 1984, IEEE T PATTERN ANAL, V6; Gill P. E., 1981, PRACTICAL OPTIMIZATI; GOSHTASBY A, 1984, IEEE T PATTERN ANAL, V6, P374, DOI 10.1109/TPAMI.1984.4767532; GREWAL MS, 1993, KALMAN FILTERING THE; HOESSJER O, 1993, IEEE T INFORMATION T, V39; HUANG S, 1987, NOV P IEEE CS WORKSH, P315; JENKINS F, 1993, S DOCUMENT ANAL INFO; KAHAN S, 1987, IEEE T PATTERN ANAL, V9, P274, DOI 10.1109/TPAMI.1987.4767901; Kumar S, 1991, RECENT DEV MATH PROG; LEE JC, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P722; LI K, 1986, JUN P CS WORKSH COMP, P610; LUENBERGER D.G., 1989, INTRO LINEAR NONLINE; MORI S, 1992, P IEEE, V80, P1029, DOI 10.1109/5.156468; Nakashima M., 1986, Proceedings of the SPIE - The International Society for Optical Engineering, V635, P480, DOI 10.1117/12.964164; RAMAPRIYAN HK, 1976, IEEE T COMPUT, V25, P66, DOI 10.1109/TC.1976.5009206; RICE SV, 1992, S DOCUMENT ANAL INFO; ROSENFELD A, 1977, IEEE T SYST MAN CYB, V7, P104; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SVEDLOW M, 1976, S MACHINE PROCESSING; Tou JT, 1974, PATTERN RECOGN; VANDERBRUG GJ, 1977, IEEE T COMPUT, V26, P384, DOI 10.1109/TC.1977.1674847; 1992, HGIH PEFORMANCE NUME	27	15	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	1995	17	4					418	431		10.1109/34.385977	http://dx.doi.org/10.1109/34.385977			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QR628					2022-12-18	WOS:A1995QR62800008
J	ADJOUADI, M; CANDOCIA, F				ADJOUADI, M; CANDOCIA, F			A STEREO MATCHING PARADIGM-BASED ON THE WALSH TRANSFORMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						WALSH-BASED ATTRIBUTES; FEATURE EXTRACTION; STEREO MATCHING; DISPARITY EXTRACTION	VISION	This correspondence describes a new feature-based stereo matching technique which exploits the Walsh transformation. The established matching strategy adopts and integrates the fundamental steps of the stereo vision problem: a) detecting and locating feature points, b) searching for potential matches, c) validating a match through a global consistency check, and d) determining the disparity of the matched feature points. The unique representation of stereo images into Walsh-based attributes unites the aforementioned steps into an integrated process which yields accurate disparity extraction. It will be shown that the first and second Walsh attributes are used as operators approximating the first and second derivatives for the extraction and localization of feature points. The complete set of these attributes are then used as matching primitives contributing equally to the decision making process and providing relevant information on both the characterization of a potential match and its validation through a consistency check. Computer results using images of varying complexities prove the soundness and the relatively fast processing time of this stereo matching technique.			ADJOUADI, M (corresponding author), FLORIDA INT UNIV, DEPT ELECT & COMP ENGN, UNIV PK, MIAMI, FL 33199 USA.		Adjouadi, Malek/AAV-2037-2021					BEAUCHAMP KG, 1987, APPLICATION WALSH RE; BOYER KL, 1988, IEEE T PATTERN ANAL, V10, P144, DOI 10.1109/34.3880; COCHRAN SD, 1992, IEEE T PATTERN ANAL, V14; DHOND UR, 1989, IEEE T SYST MAN CYBE, V19; DRUMHELLER M, 1986, P IEEE ROBOT AUTOMAT; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; Marr D., 1982, VISION; MEDIONI G, 1985, COMPUT VISION GRAPH, V31, P2, DOI 10.1016/S0734-189X(85)80073-6; MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P113, DOI 10.1109/34.16708; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; SHAH YC, 1989, IEEE T PATTERN ANAL, V11, P768, DOI 10.1109/34.192472	11	15	17	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1994	16	12					1212	1218		10.1109/34.387486	http://dx.doi.org/10.1109/34.387486			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QA715					2022-12-18	WOS:A1994QA71500006
J	YIP, RKK; TAM, PKS; LEUNG, DNK				YIP, RKK; TAM, PKS; LEUNG, DNK			APPLICATION OF ELLIPTIC FOURIER DESCRIPTORS TO SYMMETRY DETECTION UNDER PARALLEL PROJECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						PARALLEL PROJECTION; SYMMETRY; ELLIPTIC FOURIER DESCRIPTORS; ARC LENGTH PARAMETERIZATION; INVARIANTS; GRADIENT VECTOR (P, Q)	SHAPE; RECOGNITION; CONTOUR; AXES	In this paper, the method of elliptic Fourier descriptors using arc length parameterization is applied to tackle the problem of detection and recovery of symmetry under parallel projection. A simple and fast iteration algorithm together with the invariants of symmetry provides sufficient information for the detection and recovery of symmetry under parallel projection. The proposed method has been extensively tested using symmetric figures under different parallel projections. Simulation results of the algorithm are presented. The extension of this method for planar object recognition under parallel projection is also addressed.			YIP, RKK (corresponding author), HONG KONG POLYTECH,DEPT ELECTR ENGN,KOWLOON,HONG KONG.		Rohlf, F J/A-8710-2008					ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206; ATALLAH MJ, 1985, IEEE T COMPUT, V34, P663, DOI 10.1109/TC.1985.1676605; BARROW HG, 1981, ARTIF INTELL, V17, P75, DOI 10.1016/0004-3702(81)90021-7; BRADY M, 1984, IEEE T PATTERN ANAL, V6, P288, DOI 10.1109/TPAMI.1984.4767521; CRIMMINS TR, 1982, IEEE T SYST MAN CYB, V12, P8248; DAVIS LS, 1977, IEEE T SYST MAN CYB, P204; FRIEDBERG SA, 1986, COMPUT VISION GRAPH, V34, P138, DOI 10.1016/S0734-189X(86)80055-X; GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926; GUZMAN A, 1968, FAL P JOINT COMP C, P291; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; KUHL FP, 1982, COMPUT VISION GRAPH, V18, P236, DOI 10.1016/0146-664X(82)90034-X; LEOU JJ, 1987, PATTERN RECOGN, V20, P571, DOI 10.1016/0031-3203(87)90028-8; LIN CS, 1987, PATTERN RECOGN, V20, P535, DOI 10.1016/0031-3203(87)90080-X; MAROLA G, 1989, IEEE T PATTERN ANAL, V11, P104, DOI 10.1109/34.23119; NALWA VS, 1989, IEEE T PATTERN ANAL, V11, P1117, DOI 10.1109/34.42842; PARUI SK, 1983, PATTERN RECOGN, V16, P63, DOI 10.1016/0031-3203(83)90009-2; PERSOON E, 1986, IEEE T PATTERN ANAL, V8, P388, DOI 10.1109/TPAMI.1986.4767799; SCOTT GL, 1987, 3 ALV VIS C CAMBR EN, P341; WALLACE TP, 1980, COMPUT VISION GRAPH, V13, P99, DOI 10.1016/S0146-664X(80)80035-9; YIP RKK, 1991, 1991 P IEEE REG 10 I, P359; YIP RKK, 1990, INT C AUT ROBOTICS C, P1007; ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949	22	15	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1994	16	3					277	286		10.1109/34.276127	http://dx.doi.org/10.1109/34.276127			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	NF114					2022-12-18	WOS:A1994NF11400008
J	ALLINEY, S				ALLINEY, S			DIGITAL ANALYSIS OF ROTATED IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						IMAGE ANALYSIS; MOTION ESTIMATION	MOTION ESTIMATION; REGISTRATION	We consider the problem of estimating the relative rotations of two images taken from the same scene, and we present a numerical method to compute such rotations. The main features of the proposed method consist of the possibility of fast in-place computations with no preliminary interpolation of the data and a considerable precision for moderate rotation angles. The final estimate is performed with a least square criterion, but in the present case, even such computations can be substantially simplified. A detailed analysis shows that for practical applications, the influence of discretization errors does not affect, in a relevant way, the precision of the results; that is also confirmed hy numerical experiments.			ALLINEY, S (corresponding author), UNIV BOLOGNA,IST MATEMAT GEN & FINANZIARIA,I-40126 BOLOGNA,ITALY.							ALLINEY S, 1986, IEEE T PATTERN ANAL, V8, P222, DOI 10.1109/TPAMI.1986.4767775; ALLINEY S, 1983, SIGNAL PROCESS, V2, P9; Anuta PE., 1970, IEEE T GEOSCI ELECTR, V8, P353, DOI [10.1109/tge.1970.271435, DOI 10.1109/TGE.1970.271435]; BIEMOND J, 1987, SIGNAL PROCESS, V13, P399, DOI 10.1016/0165-1684(87)90021-1; BRESLER Y, 1987, IEEE T ACOUST SPEECH, V35, P70, DOI 10.1109/TASSP.1987.1165025; DECASTRO E, 1987, IEEE T PATTERN ANAL, V9, P700, DOI 10.1109/TPAMI.1987.4767966; Golub G. H., 1996, MATRIX COMPUTATIONS; GOSHTASBY A, 1985, IEEE T PATTERN ANAL, V7, P338, DOI 10.1109/TPAMI.1985.4767663; Gradshteyn I. S, 1980, TABLES INTEGRALS SUM; HUANG TS, 1981, IMAGE SEQUENCE ANAL; KUGLIN CD, 1975, 1975 P IEEE INT C CY, P163; PAPOULIS A, 1968, SYSTEMS TRANSFORMS A; PELI E, 1987, IEEE T MED IMAGING, V6, P272, DOI 10.1109/TMI.1987.4307837; WENG JY, 1987, IEEE T PATTERN ANAL, V9, P370, DOI 10.1109/TPAMI.1987.4767920; Wilkinson JH., 1963, ROUNDING ERRORS ALGE	15	15	22	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1993	15	5					499	504		10.1109/34.211470	http://dx.doi.org/10.1109/34.211470			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LB470					2022-12-18	WOS:A1993LB47000008
J	HUMMEL, R; SUNDARESWARAN, V				HUMMEL, R; SUNDARESWARAN, V			MOTION PARAMETER-ESTIMATION FROM GLOBAL FLOW FIELD DATA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						EGOMOTION; FLOW FIELD ANALYSIS; FOCUS OF EXPANSION; MOTION ESTIMATION; ROTATIONAL VELOCITY	OPTICAL-FLOW; 3-DIMENSIONAL MOTION; IMAGE FLOW; PLANAR SURFACES; PARALLAX FIELD; VISUAL-MOTION; DEFORMATION; DIRECTION; SEQUENCES; OBSERVER	We present two methods for the determination of the parameters of motion of a sensor, given the vector flow field induced by an imaging system governed by a perspective transformation of a rigid scene. We assume that the flow field V = (u(x, y), v(x, y)) is given. Both algorithms are new, and both integrate global data to determine motion parameters. The first algorithm (the flow circulation algorithm) determines the rotational parameters. It uses the curl of the flow field (curl (V)), which under many conditions is approximately a linear function of the form g(x, y) = ax + by + c. The coefficients of the linear function, a, b, and c, which may be determined by simple regression, are proportional to the desired rotational parameters of motion. Circulation values may be used in place of curl values, resulting in less noise. The second algorithm (the FOE search algorithm) determines the translational parameters of the motion independently of the first algorithm. This algorithm extends a recent method of Heeger and Jepson, giving a method for searching for the image focus of expansion. For every location (x0, y0) in the image plane, we compute a function u . (-y + y0) + v . (x - x0). When (x0, y0) is located at the focus of expansion, this function will be a quadratic polynomial (of a special form). We suggest several methods for determining when the function has the appropriate form; one method involves filtering the function by a collection of circular-surround zero-mean receptive fields. The other methods project the function onto a linear space of quadratic polynomials and measures the distance between the two functions. The error function for the first two methods is a quadratic polynomial of the candidate position, yielding a very ra id search strategy.	NYU,CTR MODELLING & SIMULAT,NEW YORK,NY 10012	New York University	HUMMEL, R (corresponding author), NYU,COURANT INST MATH SCI,DEPT COMP SCI,NEW YORK,NY 10012, USA.							ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BERGEN J, 1985, J OPT SOC AM, V2, P284; BURGER W, 1990, IEEE T PATTERN ANAL, V12, P1040, DOI 10.1109/34.61704; FAUGERAS O, 1990, 1ST P ECCV, P105; FAUGERAS OD, 1987, 1ST P INT C COMP VIS, P25; GIBSON J J, 1955, Am J Psychol, V68, P372, DOI 10.2307/1418521; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; HEEGER D, 1990, NEURAL COMPUT, V2, P127; Heeger D. J., 1988, INT J COMPUT VISION, V1, P279; HEEGER DJ, 1992, INT J COMPUT VISION, V7, P95, DOI 10.1007/BF00128130; HEEGER DJ, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P96; HILDRETH EC, 1984, ARTIF INTELL, V23, P309, DOI 10.1016/0004-3702(84)90018-3; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; JEPSON A, UNPUB INT J COMPUT V; JERIAN C, 1990, IEEE T PATTERN ANAL, V12, P1150, DOI 10.1109/34.62604; KOENDERINK, 1976, J OPT SOC AM, V66; KOENDERINK JJ, 1975, OPT ACTA, V22, P773, DOI 10.1080/713819112; KOENDERINK JJ, 1981, J OPT SOC AM, V71, P953, DOI 10.1364/JOSA.71.000953; LAWTON DT, 1983, COMPUT VISION GRAPH, V22, P116, DOI 10.1016/0734-189X(83)90098-1; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; MITICHE A, 1988, IEEE T PATTERN ANAL, V10, P943, DOI 10.1109/34.9116; NAKAYAMA K, 1974, PERCEPTION, V3, P63, DOI 10.1068/p030063; PRAZDNY K, 1981, COMPUT VISION GRAPH, V17, P238, DOI 10.1016/0146-664X(81)90004-6; PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077; PRAZDNY K, 1983, COMPUT VISION GRAPH, V22, P239, DOI 10.1016/0734-189X(83)90067-1; REGAN D, 1985, J OPT SOC AM A, V2, P280, DOI 10.1364/JOSAA.2.000280; RIEGER JH, 1983, P ACM INTERDISCIPLIN, P33; SUBBARAO M, 1986, COMPUT VISION GRAPH, V36, P208, DOI 10.1016/0734-189X(86)90076-9; SUNDARESWARAN V, 1992, THESIS NEW YORK U; SUNDARESWARAN V, P IEEE WORKSH VISUAL; TANAKA K, 1989, J NEUROPHYSIOL, V62, P626, DOI 10.1152/jn.1989.62.3.626; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; VONHELMHOLTZ H, 1925, HDB PHYSL OPTIK; WAXMAN AM, 1985, INT J ROBOT RES, V4, P72, DOI 10.1177/027836498500400306; WAXMAN AM, 1985, INT J ROBOT RES, V4, P95, DOI 10.1177/027836498500400307; WAXMAN AM, 1987, 1ST P INT C COMP VIS, P12; WAXMAN AM, 1988, ADV COMPUTER VISION, V1, P165; WERKHOVEN P, 1990, BIOL CYBERN, V63, P185, DOI 10.1007/BF00195857; WOHN K, 1990, COMPUT VISION GRAPH, V49, P127, DOI 10.1016/0734-189X(90)90134-H	43	15	15	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1993	15	5					459	476		10.1109/34.211466	http://dx.doi.org/10.1109/34.211466			18	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LB470					2022-12-18	WOS:A1993LB47000004
J	ECKERT, MP; BUCHSBAUM, G; WATSON, AB				ECKERT, MP; BUCHSBAUM, G; WATSON, AB			SEPARABILITY OF SPATIOTEMPORAL SPECTRA OF IMAGE SEQUENCES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter								We calculated the spatiotemporal power spectrum of 14 image sequences in order to determine the degree to which the spectra are separable in space and time and to assess the validity of the commonly used exponential correlation model found in the literature. We expand the spectrum by a singular value decomposition into a sum of separable terms and define an index of spatiotemporal separability as the fraction of the signal energy that can be represented by the first (largest) separable term. All spectra were found to be highly separable with an index of separability above 0.98. The power spectra of the sequences were well fit by a separable model of the form P(k, f) = ab/(4pi3)/((a/2pi)2 + k2)3/2((b/2pi)2 + f2) where k is radial spatial frequency, f is temporal frequency, and a,b are spatial and temporal model parameters that determine the effective spatiotemporal bandwidth of the signal. This power spectrum model corresponds to a product of exponential autocorrelation functions separable in space and time.	NASA,AMES RES CTR,MOFFETT FIELD,CA 94035	National Aeronautics & Space Administration (NASA); NASA Ames Research Center	ECKERT, MP (corresponding author), UNIV PENN,SCH ENGN & APPL SCI,DEPT BIOENGN,PHILADELPHIA,PA 19104, USA.							CHEN WH, 1987, IEEE J SEL AREA COMM, V5, P1155, DOI 10.1109/JSAC.1987.1146625; COLL DC, 1976, IEEE T COMMUN, V12, P1201; CONNOR DJ, 1974, IEEE T COMMUN, V10, P1564; Dennis J., 1987, NEW COMPUTING ENV MI, V11, P6; Dudgeon D. E., 1984, MULTIDIMENSIONAL DIG; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; FRANKS LE, 1966, BELL SYST TECH J APR, P609; Gonzalez R. C., 1987, DIGITAL IMAGE PROCES; JAIN AK, 1977, J OPTIMIZ THEORY APP, V23, P65, DOI 10.1007/BF00932298; JAYANT NS, 1985, DIGITAL CODING WAVEF; Rosenfeld A., 1982, DIGITAL PICTURE PROC; SRINIVASAN MV, 1982, PROC R SOC SER B-BIO, V216, P427, DOI 10.1098/rspb.1982.0085; TREITEL S, 1971, IEEE T GEOSCI ELECT, VGE 9, P10, DOI 10.1109/TGE.1971.271457; WATSON AB, 1990, J OPT SOC AM A, V7, P1943, DOI 10.1364/JOSAA.7.001943	14	15	15	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1992	14	12					1210	1213		10.1109/34.177387	http://dx.doi.org/10.1109/34.177387			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KC573		Green Submitted			2022-12-18	WOS:A1992KC57300008
J	NEY, H				NEY, H			A COMPARATIVE-STUDY OF 2 SEARCH STRATEGIES FOR CONNECTED WORD RECOGNITION - DYNAMIC-PROGRAMMING AND HEURISTIC-SEARCH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						BEST-1ST SEARCH; BRANCH-AND-BOUND SEARCH; BREADTH-1ST-SEARCH; CONNECTED WORD RECOGNITION; DYNAMIC PROGRAMMING; HEURISTIC SEARCH; MINIMUM COST PATH FOR FINITE STATE NETWORKS; SEARCH FOR CONTINUOUS SPEECH RECOGNITION		A most successful approach to recognizing continuous speech is to model the recognition problem as one of finding an optimal path through a finite state network. This paper presents a comparison of two search strategies for finding the optimal path: dynamic programming and heuristic search. The comparison is based on theoretical considerations and experimental tests on a digit string task.			NEY, H (corresponding author), PHILIPS RES LAB AACHEN,AACHEN,GERMANY.							[Anonymous], 1980, PRINCIPLES ARTIFICIA; Bridle J. S., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P899; JELINEK F, 1975, IEEE T INFORM THEORY, V21, P250, DOI 10.1109/TIT.1975.1055384; KAMP Y, 1985, SPEECH SPEAKER RECOG, P115; LEVINSON SE, 1985, P IEEE, V73, P1625, DOI 10.1109/PROC.1985.13344; Lowerre B., 1980, TRENDS SPEECH RECOGN, P340; NEY H, 1984, IEEE T ACOUST SPEECH, V32, P263, DOI 10.1109/TASSP.1984.1164320; NEY H, 1987, APR P IEEE INT C AC, P833; NEY H, 1982, 6TH P INT C PATT REC, P1119; Sedgewick R., 1983, ALGORITHMS; SPOHRER JC, 1980, OCT P INT C CYB SOC, P36; STEINBISS V, 1990, 1990 P INT C AC SPEE, P57; Winston P. H., 1977, ARTIFICIAL INTELLIGE	13	15	15	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1992	14	5					586	595		10.1109/34.134063	http://dx.doi.org/10.1109/34.134063			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HR650					2022-12-18	WOS:A1992HR65000008
J	WANG, YF; WANG, JF				WANG, YF; WANG, JF			SURFACE RECONSTRUCTION USING DEFORMABLE MODELS WITH INTERIOR AND BOUNDARY CONSTRAINTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						LEAST ACTION PRINCIPLE; PHYSICAL MODEL; RECONSTRUCTION; STRUCTURED LIGHTING; SURFACE; VISION		In this correspondence, we introduce a technique for 3-D surface reconstruction using elastic, deformable models. The model used is an imaginary elastic grid, which is made of membranous, thin-plate type material. The elastic grid is bent, twisted, compressed, and stretched into any desirable 3-D shape, which is specified by the shape constraints derived automatically from images of a real 3-D object. Shape reconstruction is guided by a set of imaginary springs that enforce the consistency in the position, orientation, and/or curvature measurements of the elastic grid and the desired shape. The dynamics of a surface reconstruction process is regulated by Hamilton's principle or the principle of the least action. Furthermore, a 1-D deformable template that borders the elastic grid may be used. This companion boundary template is attracted/repelled by image forces to confirm with the silhouette of the imaged object. Implementation results using simple analytic shapes and images of real objects are presented.	IBM CORP,RES TRIANGLE PK,NC 27709	International Business Machines (IBM)	WANG, YF (corresponding author), UNIV CALIF SANTA BARBARA,DEPT COMP SCI,SANTA BARBARA,CA 93106, USA.							AGGARWAL JK, 1989, ADV MACHINE VISION, P64; BRADY M, 1982, COMPUT SURV, V14, P3, DOI 10.1145/356869.356871; COURANT R, 1953, METHODS MATH PHYSICS, V1; KASS M, 1987, 1ST P INT C COMP VIS, P259; Smith GD., 1978, NUMERICAL SOLUTION P; STRUIK DJ, 1961, DIFFERENTIAL GEOMETR; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; Wang Y. F., 1991, International Journal of Imaging Systems and Technology, V3, P279, DOI 10.1002/ima.1850030402; WANG YF, 1987, IEEE T PATTERN ANAL, V9, P129, DOI 10.1109/TPAMI.1987.4767878; WANG YF, 1991, JUL SPIE C GEOM METH	10	15	17	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1992	14	5					572	579		10.1109/34.134061	http://dx.doi.org/10.1109/34.134061			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HR650					2022-12-18	WOS:A1992HR65000006
J	NAMANE, A; SIDAHMED, MA				NAMANE, A; SIDAHMED, MA			CHARACTER SCALING BY CONTOUR METHOD	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											NAMANE, A (corresponding author), UNIV WINDSOR,DEPT ELECT ENGN,WINDSOR N9B 3P4,ONTARIO,CANADA.							CASEY RG, 1980, 5TH P INT C PATT REC, V2, P872; Chottera A., 1982, Canadian Electrical Engineering Journal, V7, P29; Davis F.E., 1986, Desktop publishing; HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508; JOHNSON LW, NUMERICAL ANAL, P237; KULKARNI AD, 1984, SIGNAL PROCESS, V7, P65, DOI 10.1016/0165-1684(84)90025-2; Pratt W. K., 1978, DIGITAL IMAGE PROCES; ULICHNEY RA, 1982, IEEE T PATTERN ANAL, V4, P331, DOI 10.1109/TPAMI.1982.4767254; ULICHNEY RA, 1979, THESIS MIT CAMBRIDGE	10	15	16	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1990	12	6					600	606		10.1109/34.56197	http://dx.doi.org/10.1109/34.56197			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DE003					2022-12-18	WOS:A1990DE00300010
J	OLSEN, SI				OLSEN, SI			STEREO CORRESPONDENCE BY SURFACE RECONSTRUCTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											OLSEN, SI (corresponding author), UNIV COPENHAGEN,DEPT COMP SCI,UNIVERSTIETSPARKEN 1,DK-2100 COPENHAGEN,DENMARK.			Olsen, Soren Ingvor/0000-0002-4466-1914				BAKER HH, 1981, 7TH P INT JOINT C AR; BERZINS V, 1984, COMPUT VISION GRAPHI, V27; BURT P, 1980, PERCEPTION, V9; BURT P, 1983, IEEE T COMMUN, V31; CANNY JF, 1983, MIT720 TECH REP; DERICHE R, 1987, INT J COMPUT VISION, V1; EASTMAN RD, 1987, COMPUT VISION GRAPHI, V39; Grimson W. E. L., 1985, IEEE T PATTERN ANAL, V7; GRIMSON WEL, 1981, IMAGES SURFACES; HILDRETH EC, 1983, COMPUT VISION GRAPHI, V22; HOFF W, 1987, 1ST P C COMP VIS LON; HUERTAS A, 1986, IEEE T PATTERN ANAL, V8; KASS K, 1983, 8TH P JOINT C ART IN; MARR D, 1979, P ROY SOC LONDON B, V204; MARR D, 1980, P ROY SOC LONDON B, V207; MAYHEW JEW, 1981, ARTIFICIAL INTELL, V17; POLLARD SB, 1985, PERCEPTION, V14; PRAZDNY K, 1985, BIOL CYBERN, V52; QUAM LH, 1984, OCT P IM UND WORKSH; Smith G. D., 1978, NUMERICAL SOLUTION P, V2nd; TERZOPOULOS D, 1985, MIT800 TECH REP	21	15	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1990	12	3					309	315		10.1109/34.49055	http://dx.doi.org/10.1109/34.49055			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CP943					2022-12-18	WOS:A1990CP94300006
J	PRASANNAKUMAR, VK; REISIS, DI				PRASANNAKUMAR, VK; REISIS, DI			IMAGE COMPUTATIONS ON MESHES WITH MULTIPLE BROADCAST	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											PRASANNAKUMAR, VK (corresponding author), UNIV SO CALIF,DEPT ELECT ENGN SYST,LOS ANGELES,CA 90089, USA.							BATCHER K, 1980, IEEE T COMPUT, V29; BOKHARI SH, 1984, IEEE T COMPUT, V33, P133, DOI 10.1109/TC.1984.1676405; CARLSON D, 1985, MESH GLOBAL MESH FLE; CHALASANI SB, 1987, P PAMI WORKSHOP; DAVIS R, 1984, ELEECTRON DESIGN OCT; DYER CR, 1981, IEEE T PATTERN ANAL, V2; DYER CR, 1981, P IEEE C PATTERN REC; GOPALAKRISHNAN PS, 1985, EFFICIENT CONNECTED; HWANG K, 1984, COMPUTER ARCHITECTUR; KUNG HT, 1977, COMMUN ACM; MILLER R, 1987, SIAM J COMPUT, V16; MILLER R, 1984 P INT C PAR PRO; MILLER R, 1984 P INT C PAR PRO, P66; NAIR R, 1985, SEARCH MINIMUM DISTR; NASSIMI D, 1980, SIAM J COMPUT, V9, P744, DOI 10.1137/0209058; NASSIMI D, 1981, IEEE T COMPUT, V30; OVERMARS MH, 1980, 12TH P S THEOR COMP; PRASANNAKUMAR VK, 1987, USC CRI8748 TECH REP; PRASANNAKUMAR VK, 1985, INT C PARALLEL PROCE; PRASANNAKUMAR VK, 1987, INT C PARALLEL PROCE; [No title captured]	21	15	15	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1989	11	11					1194	1201		10.1109/34.42857	http://dx.doi.org/10.1109/34.42857			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AW796					2022-12-18	WOS:A1989AW79600006
J	NALWA, VS				NALWA, VS			LINE-DRAWING INTERPRETATION - STRAIGHT-LINES AND CONIC SECTIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									STANFORD UNIV,ROBOT LAB,STANFORD,CA 94305	Stanford University								[Anonymous], 1961, INTRO ORDINARY DIFFE; Blaschke W., 1923, VORLESUNGEN DIFFEREN; GANS D, 1969, TRANSFORMATIONS GEOM; Guillemin V., 2010, DIFFERENTIAL TOPOLOG, V370; Hilbert D., 1952, GEOMETRY IMAGINATION; Hirsch M. W., 1976, GRADUATE TEXTS MATH; KOENDERINK JJ, 1984, PERCEPTION, V13, P321, DOI 10.1068/p130321; Lipschutz M., 1969, DIFFERENTIAL GEOMETR; Maschke H, 1902, T AM MATH SOC, V3, P482, DOI 10.2307/1986470; Olmsted J.M.H., 1947, SOLID ANAL GEOMETRY; Spivak M., 1965, CALCULUS MANIFOLDS, DOI DOI 10.1201/9780429501906; STRANG G, 1976, LINEAR ALGEBRA ITS A; WHITNEY H, 1955, ANN MATH, V62, P374, DOI 10.2307/1970070	13	15	15	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1988	10	4					514	529		10.1109/34.3914	http://dx.doi.org/10.1109/34.3914			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	P1493					2022-12-18	WOS:A1988P149300007
J	NISHIHARA, HK; CROSSLEY, PA				NISHIHARA, HK; CROSSLEY, PA			MEASURING PHOTOLITHOGRAPHIC OVERLAY ACCURACY AND CRITICAL DIMENSIONS BY CORRELATING BINARIZED LAPLACIAN OF GAUSSIAN CONVOLUTIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											NISHIHARA, HK (corresponding author), SCHLUMBERGER PALO ALTO RES,TECH STAFF,3340 HILLVIEW AVE,PALO ALTO,CA 94304, USA.							ARNOLD RD, 1980, SPIE, V238, P281; BAKER HH, 1981, 7TH P INT JOINT C AR, P631; CHIVERS KA, 1984, P KODAK MICROELECTRO, P44; GENNERY DB, 1980, 339 STANF U STANF AR; HORN BKP, 1983, PHOTOGRAMM ENG REM S, V49, P535; JULESZ B, 1971, F CYCLOPEAN PERCEPTI; KELLY RE, 1977, PHOTOGRAMM ENG REM S, V43, P1407; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Moravec H.P., 1980, 340 STANF U STANF AR; NISHIHARA HK, 1982, NATURE, V300, P347, DOI 10.1038/300347a0; NISHIHARA HK, 1984, OPT ENG, V23, P536, DOI 10.1117/12.7973334; OHTA Y, 1983, CMUCS83162 CARN U DE; POGGIO GF, 1984, ANNU REV NEUROSCI, V7, P379, DOI 10.1146/annurev.ne.07.030184.002115; TSAI RY, 1983, IEEE T PATTERN ANAL, V5, P159, DOI 10.1109/TPAMI.1983.4767368	15	15	22	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1988	10	1					17	30		10.1109/34.3864	http://dx.doi.org/10.1109/34.3864			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	L4366					2022-12-18	WOS:A1988L436600003
J	HAMBRICK, LN; LOEW, MH; CARROLL, RL				HAMBRICK, LN; LOEW, MH; CARROLL, RL			THE ENTRY EXIT METHOD OF SHADOW BOUNDARY SEGMENTATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									GEORGE WASHINGTON UNIV,DEPT ELECT ENGN & COMP SCI,WASHINGTON,DC 20052	George Washington University	HAMBRICK, LN (corresponding author), ENVIRONM SATELLITE DATA INC,5200 AUTH RD,SUITLAND,MD 20746, USA.							BINFORD TO, 1981, ART INTELL, V17, P75; HAMBRICK LN, 1984, THESIS G WASHINGTON; HASLER AF, 1981, B AM METEOROL SOC, V62, P194, DOI 10.1175/1520-0477(1981)062<0194:SOFGSA>2.0.CO;2; HUERTAS A, 1982, DARPA3119 U SO CAL D; HUERTAS A, 1982, CLASSIFICATION EDGES, P22; HUERTAS A, 1982, EDGE BASED SYSTEM DE, P41; HUERTAS A, 1983, DARPA3119 FIN TECH R; LOWE DG, 1981, ARPA IUS WORKSH, P39; MEDIONI G, 1983, JUN P COMP VIS PATT; PHILLIPS D, 1983, COMMUNICATION    OCT; SHAFER SA, 1983, COMPUT VISION GRAPH, V22, P145, DOI 10.1016/0734-189X(83)90099-3; [No title captured]	12	15	15	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1987	9	5					597	607		10.1109/TPAMI.1987.4767954	http://dx.doi.org/10.1109/TPAMI.1987.4767954			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	J7393	21869418				2022-12-18	WOS:A1987J739300001
J	GU, WK; YANG, JY; HUANG, TS				GU, WK; YANG, JY; HUANG, TS			MATCHING PERSPECTIVE VIEWS OF A POLYHEDRON USING CIRCUITS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									E CHINA ENGN INST,DEPT COMP SCI,NANJING,PEOPLES R CHINA; UNIV ILLINOIS,COORDINATED SCI LAB,URBANA,IL 61801	University of Illinois System; University of Illinois Urbana-Champaign	GU, WK (corresponding author), ZHEJIANG UNIV,DEPT RADIO ENGN,HANGZHOU,PEOPLES R CHINA.							BARROW HG, 1978, MAY P DARPA IU WORKS, P21; BITTNER JR, 1975, COMMUN ACM, V18, P651; CHENG JK, 1981, AUG P IEEE C PRIP DA; CORNEIL DG, 1970, J ACM, V17, P51, DOI 10.1145/321556.321562; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876; Grimson W.E.L., 1980, THESIS MIT; GU WK, 1985, IEEE T PATTERN ANAL, V7, P422, DOI 10.1109/TPAMI.1985.4767681; GU WK, 1984, T137 U ILL URB CHAMP; HUNDERSON RL, 1979, RADCTR7980 ROM AIR D; Johnson D. B., 1975, SIAM Journal on Computing, V4, P77, DOI 10.1137/0204007; LAVINE D, 1983, PATTERN RECOGN, V16, P289, DOI 10.1016/0031-3203(83)90034-1; MARR D, 1976, SCIENCE, V194; MARR D, 1977, MIT451 ART INT MEM; Mateti P., 1976, SIAM Journal on Computing, V5, P90, DOI 10.1137/0205007; MATSUYAMA T, 1984, COMPUT VISION GRAPH, V27, P177, DOI 10.1016/S0734-189X(84)80042-0; PATON K, 1969, COMMUN ACM, V12, P514, DOI 10.1145/363219.363232; Pavlidis T., 1977, STRUCTURAL PATTERN R; PEN F, 1986, UNPUB 8TH ICPR PAR; RANADE S, 1980, PR12 MAR U DEP COMP; ROBERTS LG, 1968, OPTICAL ELECTROOPTIC; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Rosenfeld A., 1982, DIGITAL PICTURE PROC; SHAPIRO LG, 1984, PATTERN RECOGNITION, V17; SHAPIRO LG, 1985, IEEE T PATTERN ANAL, V7; STOCKMAN G, 1982, IEEE T PATTERN ANAL, V4, P229, DOI 10.1109/TPAMI.1982.4767240; YANG JY, 1985, 4TH P SCIA TRONDH NO, P183; [No title captured]	27	15	20	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	1987	9	3					390	400		10.1109/TPAMI.1987.4767921	http://dx.doi.org/10.1109/TPAMI.1987.4767921			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	H0768	22516632				2022-12-18	WOS:A1987H076800004
J	MINAMI, T; SHINOHARA, K				MINAMI, T; SHINOHARA, K			ENCODING OF LINE DRAWINGS WITH A MULTIPLE GRID CHAIN CODE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											MINAMI, T (corresponding author), KOGAKUIN UNIV,DEPT ELECTR ENGN,TOKYO 160,JAPAN.							FREEMAN H, 1980, COMPUT GRAPH IMAGE P, V12; FREEMAN H, 1974, COMPUT SURV, V6; FREEMAN H, 1978, MAY P IEEE COMP SOC; FREEMAN H, 1961, IRE T ELECTRON COMPU, V10; KANEKO T, 1983, IECE JAPAN IE, V83, P82; KEGEL A, 1977, P COMMUN IEEE EUROCO; KISHIMOTO T, 1981, IEEE T COMMUN, V29; KONDO K, 1983, IECE JAPAN IE, V83, P107; KOPLOWITZ J, 1981, IEEE T PATTERN ANAL, V3; MINAMI T, 1984, 1984 PICT COD S CESS; ROSENFELD A, 1981, IMAGE MODELLING; SAGHRI JA, 1981, IEEE T PATTERN ANAL, V3; SANTALO LA, 1976, ENCY MATH ITS APPLIC, V1, P27; SATO Y, 1983, ELECTRIC COMM LAB TE, V32; SCHOLTEN DK, 1983, IEEE T PATTERN ANAL, V5; SHINOHARA K, 1984, 1984 P IIEE JAP NAT	16	15	17	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1986	8	2					269	276		10.1109/TPAMI.1986.4767780	http://dx.doi.org/10.1109/TPAMI.1986.4767780			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	A1073	21869345				2022-12-18	WOS:A1986A107300014
J	DESSIMOZ, JD; BIRK, JR; KELLEY, RB; MARTINS, HAS; LIN, C				DESSIMOZ, JD; BIRK, JR; KELLEY, RB; MARTINS, HAS; LIN, C			MATCHED-FILTERS FOR BIN PICKING	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV RHODE ISL,DEPT ELECT ENGN,KINGSTON,RI 02881	University of Rhode Island								BIRK J, 1981, 9TH NSF GRANT C PROD; DESSIMOZ JD, 1982, 3RD P INT C AUT ASS, P603; DESSIMOZ JD, 1979, 9TH P INT S IND ROB, P357; Duda R.O., 1973, J ROYAL STAT SOC SER; FERLONI A, 1980, 10TH P INT S IND ROB, P655; KELLEY R, 1983, JUL P IEEE, P803; KELLEY R, 1981, APR P INT C ROB VIS, P169; MARTINS HA, 1981, COMPUT VISION GRAPH, V17, P173, DOI 10.1016/0146-664X(81)90024-1; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; Pratt W. K., 1978, DIGITAL IMAGE PROCES; ROMITI A, 1981, 11TH P INT S IND ROB, P273; ROTH SD, 1982, COMPUT VISION GRAPH, V18, P109, DOI 10.1016/0146-664X(82)90169-1; SAKATA T, 1982, 3RD P INT C ASS AUT, P615; TELLA R, 1982, IEEE T SYST MAN CYBE, V12	14	15	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	6					686	697		10.1109/TPAMI.1984.4767593	http://dx.doi.org/10.1109/TPAMI.1984.4767593			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TX361	22499650				2022-12-18	WOS:A1984TX36100003
J	FUKUNAGA, K; FLICK, TE				FUKUNAGA, K; FLICK, TE			CLASSIFICATION ERROR FOR A VERY LARGE NUMBER OF CLASSES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											FUKUNAGA, K (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.							ALBRECHT G, 1979, WEYERS FLOTTEN TASCH; BLACKMAN RVB, 1973, JANES FIGHTING SHIPS; COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964; FRASER DAS, 1957, NONPARAMETRIC METHOD, pCH4; FUKUNAGA K, 1971, IEEE T COMPUT, VC 20, P176, DOI 10.1109/T-C.1971.223208; FUKUNAGA K, 1982, TREE8236 PURD TECH R; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P258; FUKUNAGA K, 1972, INTRO STATISTICAL PA	8	15	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	6					779	788		10.1109/TPAMI.1984.4767601	http://dx.doi.org/10.1109/TPAMI.1984.4767601			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TX361	22499658				2022-12-18	WOS:A1984TX36100011
J	MORGERA, SD; DATTA, L				MORGERA, SD; DATTA, L			TOWARD A FUNDAMENTAL THEORY OF OPTIMAL FEATURE-SELECTION .1.	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											MORGERA, SD (corresponding author), CONCORDIA UNIV,DEPT ELECT ENGN,MONTREAL H3G 1M8,QUEBEC,CANADA.							ANDERSON BDO, 1978, AUTOMATICA, V14, P615, DOI 10.1016/0005-1098(78)90051-1; ANTOSIK P, 1973, THEORY DISTRIBUTIONS; BELL DA, 1953, INFORMATION THEORY I; CHESLER DA, 1968, IEEE T INFORM THEORY, V14, P820, DOI 10.1109/TIT.1968.1054235; GANTMACHER FR, 1959, THEORY MATRICES, V1, P324; GRAY AH, 1976, IEEE T ACOUST SPEECH, V24, P380, DOI 10.1109/TASSP.1976.1162849; GRENANDER U, 1974, ANN STAT, V2, P347, DOI 10.1214/aos/1176342668; GRENANDER U, 1981, ABSTRACT INFERENCE, P290; Hardy G. H., 1952, INEQUALITIES; KADOTA TT, 1967, IEEE T INFORM THEORY, V13, P278, DOI 10.1109/TIT.1967.1054013; KANAL L, 1974, IEEE T INFORM THEORY, V20, P697, DOI 10.1109/TIT.1974.1055306; KAZAKOS D, 1980, IEEE T AUTOMAT CONTR, V25, P950, DOI 10.1109/TAC.1980.1102475; KAZAKOS D, 1980, IEEE T AUTOMAT CONTR, V25, P294, DOI 10.1109/TAC.1980.1102275; KAZAKOS D, 1978, IEEE T INFORM THEORY, V24, P651, DOI 10.1109/TIT.1978.1055919; Okamoto M., 1961, OSAKA MATH J, V13, P1; POLYA G, 1976, PROBLEMS THEOREMS AN, V1; Rao CR., 1963, SANKHY INDIAN J STAT, V25, P303; RAO CS, 1973, LINEAR STATISTICAL I, P40; SHUMWAY RH, 1974, J AM STAT ASSOC, V69, P948, DOI 10.2307/2286169; TOU JT, 1966, COMPUTER INFORMATION, V2; TOUSSAINT GT, 1972, IEEE T COMMUN, VCO20, P485, DOI 10.1109/TCOM.1972.1091157; Turin G., 1962, IRE T COMMUN SYST, V10, P22; Zemanian A, 1965, DISTRIBUTION THEORY	24	15	15	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	5					601	616		10.1109/TPAMI.1984.4767573	http://dx.doi.org/10.1109/TPAMI.1984.4767573			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TM813	21869228				2022-12-18	WOS:A1984TM81300005
J	PEARL, J				PEARL, J			SOME RECENT RESULTS IN HEURISTIC-SEARCH THEORY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV CALIF LOS ANGELES,DEPT COMP SCI,COGNIT SCI LAB,LOS ANGELES,CA 90024	University of California System; University of California Los Angeles								[Anonymous], 1980, PRINCIPLES ARTIFICIA; BAGCHI A, 1983, J ACM, V30, P1, DOI 10.1145/322358.322359; BAUDET GM, 1978, ARTIF INTELL, V10, P173, DOI 10.1016/S0004-3702(78)80011-3; BEAL D, 1980, ADV COMPUTER CHESS, V2; BERLINER H, 1979, ARTIF INTELL, V12, P23, DOI 10.1016/0004-3702(79)90003-1; Dechter R., 1983, AUG P NAT C ART INT, P95; Fuller S. H., 1973, ANAL ALPHA BETA PRUN; GASCHNIG J, 1979, CMUCS79124 CARN MELL; GELPERIN D, 1977, ARTIF INTELL, V8, P69, DOI 10.1016/0004-3702(77)90005-4; HART PE, 1968, IEEE T SYST SCI CYBE, V4, P1000; HUYN N, 1980, ARTIF INTELL, V15, P241, DOI 10.1016/0004-3702(80)90045-4; IBARAKI T, 1978, INFORM CONTROL, V36, P1, DOI 10.1016/S0019-9958(78)90197-3; KNUTH DE, 1975, ARTIF INTELL, V6, P293, DOI 10.1016/0004-3702(75)90019-3; MARTELLI A, 1977, ARTIF INTELL, V8, P1, DOI 10.1016/0004-3702(77)90002-9; MERO L, 1981, 7TH P INT JOINT C AI, P572; NAU DS, 1983, ARTIF INTELL, V21, P221, DOI 10.1016/S0004-3702(83)80011-3; NAU DS, 1980, 1ST P NAT C ART INT, P102; NOE TD, 1980, UCLAENGCSL8017 U CAL; PEARL J, 1983, ARTIF INTELL, V20, P1, DOI 10.1016/0004-3702(83)90013-9; PEARL J, 1982, COMMUN ACM, V25, P559, DOI 10.1145/358589.358616; PEARL J, 1980, ARTIF INTELL, V14, P113, DOI 10.1016/0004-3702(80)90037-5; PEARL J, 1983, ARTIFICIAL INTELL, V21; PEARL J, 1982, UCLA COMPUT SCI DEP, V10, P121; Pearl Judea, 1984, HEURISTICS; POHL I, 1970, MACH INTELL, V5, P219; ROIZEN I, 1983, ARTIF INTELL, V21, P199, DOI 10.1016/S0004-3702(83)80010-1; ROIZEN I, 1983, UCLAENGCSL83 U CAL T; SLAGLE JR, 1969, J ACM, V16, P189, DOI 10.1145/321510.321511; STOCKMAN GC, 1979, ARTIF INTELL, V12, P179, DOI 10.1016/0004-3702(79)90016-X	29	15	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1984	6	1					1	13		10.1109/TPAMI.1984.4767470	http://dx.doi.org/10.1109/TPAMI.1984.4767470			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	SB213	21869160				2022-12-18	WOS:A1984SB21300001
J	GESCHKE, CC				GESCHKE, CC			A SYSTEM FOR PROGRAMMING AND CONTROLLING SENSOR-BASED ROBOT MANIPULATORS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV ILLINOIS,COORDINATED SCI LAB,URBANA,IL 61801	University of Illinois System; University of Illinois Urbana-Champaign								FINKEL R, 1974, STANCS74456 STANF U; GESCHKE C, 1979, R837 U ILL COORD SCI; PAUL R, 1976, JUL P JOINT AUT CONT, P649; PAUL R, 1976, SME MR76615 TECH PAP; SCHEINMAN VD, 1969, AIM92 STANF U STANF	5	15	15	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	1					1	7		10.1109/TPAMI.1983.4767338	http://dx.doi.org/10.1109/TPAMI.1983.4767338			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PZ844	21869077				2022-12-18	WOS:A1983PZ84400001
J	DEFIGUEIREDO, RJP; HU, CL				DEFIGUEIREDO, RJP; HU, CL			WAVEFORM FEATURE-EXTRACTION BASED ON TAUBERIAN APPROXIMATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									RICE UNIV,DEPT MATH SCI,HOUSTON,TX 77001	Rice University	DEFIGUEIREDO, RJP (corresponding author), RICE UNIV,DEPT ELECT ENGN,HOUSTON,TX 77001, USA.							BENNETT CK, 1973, RADCTR7370 ROM AIR D; BENNETT JO, 1974, 6TH P SE S SYST THEO; CHEN CH, 1976, INFORM SCIENCES, V10, P159, DOI 10.1016/S0020-0255(76)90746-5; CISCO DO, 1970, RADCTR70257 ROM AIR, V1; CISCO DO, 1970, RADCTR70257 ROM AIR, V2; DEFIGUEIREDO R, 1979, EE7907 RIC U TECH RE; DEFIGUEIREDO RJP, 1977, PATTERN RECOGNITION; Hildebrand F. B., 1974, INTRO NUMERICAL ANAL; KENNAUGH EM, 1977, COMMUNICATION    OCT; Schoenberg I., 1969, J APPROXIMATION THEO, V2, P167; STOCKMAN PH, 1973, THESIS SYRACUSE U SY; VANBLARICUM ML, 1978, IEEE T ANTENNAS PROP, P174; WEBB H, COMMUNICATION; Wiener N., 1933, FOURIER INTEGRAL CER	14	15	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	2					105	116		10.1109/TPAMI.1982.4767214	http://dx.doi.org/10.1109/TPAMI.1982.4767214			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	NE957	21869013				2022-12-18	WOS:A1982NE95700003
J	DONDES, PA; ROSENFELD, A				DONDES, PA; ROSENFELD, A			PIXEL CLASSIFICATION BASED ON GRAY LEVEL AND LOCAL BUSYNESS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											DONDES, PA (corresponding author), UNIV MARYLAND,CTR COMP SCI,COMP VIS LAB,COLLEGE PK,MD 20742, USA.							AHUJA N, 1980, PATTERN RECOGN, V12, P251, DOI 10.1016/0031-3203(80)90065-5; COLEMAN GB, 1979, P IEEE, V67, P773, DOI 10.1109/PROC.1979.11327; EKLUNDH JO, 1980, IEEE T PATTERN ANAL, V2, P72, DOI 10.1109/TPAMI.1980.4766973; PELEG S, 1978, IEEE T SYST MAN CYB, V8, P548; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SCHACHTER BJ, 1979, PATTERN RECOGN, V11, P19, DOI 10.1016/0031-3203(79)90025-6	6	15	17	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	1					79	84		10.1109/TPAMI.1982.4767200	http://dx.doi.org/10.1109/TPAMI.1982.4767200			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MY534	21869008				2022-12-18	WOS:A1982MY53400014
J	ALAGAR, VS; THIEL, LH				ALAGAR, VS; THIEL, LH			ALGORITHMS FOR DETECTING M-DIMENSIONAL OBJECTS IN N-DIMENSIONAL SPACES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											ALAGAR, VS (corresponding author), CONCORDIA UNIV,DEPT COMP SCI,MONTREAL H3G 1M8,QUEBEC,CANADA.							ALAGAR VS, 1976, J APPL PROBAB, V13, P558, DOI 10.2307/3212475; COHEN M, 1977, PATTERN RECOGN, V9, P95, DOI 10.1016/0031-3203(77)90020-6; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; DUDANI SA, 1978, PATTERN RECOGN, V10, P145, DOI 10.1016/0031-3203(78)90023-7; GARWOOD F, 1966, MATH GAZ, V50, P283; GRIFFITH AK, 1970, THESIS MASS I TECHNO; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; Iannino A., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing, P32; Kendall M.G., 1962, GEOMETRIC PROBABILIT; MARSAGLIA G, 1968, P NATL ACAD SCI USA, V61, P25, DOI 10.1073/pnas.61.1.25; MARSAGLIA G, UNPUBLISHED; MOORE DJH, 1974, PATTERN RECOGN, V6, P149, DOI 10.1016/0031-3203(74)90018-1; OGORMAN F, 1976, IEEE T COMPUT, V25, P449, DOI 10.1109/TC.1976.1674627; ROSENFELD A, 1969, PICTURE PROCESSING C; Shapiro S. D., 1975, Computer Graphics and Image Processing, V4, P328, DOI 10.1016/0146-664X(75)90002-7; SHIRAI Y, 1972, MIT263 ART INT LAB M; SKLANSKY J, 1978, IEEE T COMPUT, V27, P923, DOI 10.1109/TC.1978.1674971	17	15	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	3					245	256		10.1109/TPAMI.1981.4767097	http://dx.doi.org/10.1109/TPAMI.1981.4767097			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	MN969	21868945				2022-12-18	WOS:A1981MN96900001
J	SAVOL, AM; LI, CC; HOY, RJ				SAVOL, AM; LI, CC; HOY, RJ			COMPUTER-AIDED RECOGNITION OF SMALL ROUNDED PNEUMOCONIOSIS OPACITIES IN CHEST X-RAYS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV PITTSBURGH,DEPT ELECT ENGN,PITTSBURGH,PA 15261	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh								BALLARD D, 1973, COMPUT BIOMED RES, V6, P299, DOI 10.1016/0010-4809(73)90066-9; BALLARD DH, 1976, IEEE T COMPUT, V25, P503, DOI 10.1109/TC.1976.1674638; DWYER SJ, 1976, DIGITAL PROCESSING B, P271; Hall E. L., 1976, 3rd International Joint Conference on Pattern Recognition, P60; Hall E. L., 1973, 1st International Joint Conference on Pattern Recognition, P77; HALL EL, 1975, IEEE T BIO-MED ENG, V22, P518, DOI 10.1109/TBME.1975.324475; Hankinson J. L., 1979, Proceedings of the 1979 IEEE Computer Society Conference on Pattern Recognition and Image Processing, P353; HEITZMAN ER, 1973, LUNG RADIOLOGIC PATH; JACOBSON G, 1972, MEDICAL RAD PHOTOGRA, V48, P66; JAGOE J, 1976, IEEE T COMPUT, V25, P95; JAGOE JR, 1975, BRIT J IND MED, V32, P267; JAGOE JR, 1979, COMPUT BIOMED RES, V12, P1, DOI 10.1016/0010-4809(79)90002-8; KRUGER RP, 1977, APPL OPTICS, V16, P2637, DOI 10.1364/AO.16.002637; KRUGER RP, 1974, IEEE T SYST MAN CYB, VSMC4, P40, DOI 10.1109/TSMC.1974.5408519; LEDLEY R S, 1975, Computers in Biology and Medicine, V5, P53, DOI 10.1016/0010-4825(75)90018-9; Li C. C., 1977, Proceedings of the International Conference on Cybernetics and Society, P422; Li C. C., 1978, Proceedings of the 1978 Conference on Pattern Recognition and Image Processing, P390; SAVOL AM, 1977, P IEEE COMP SOC C PA, P70; SAVOL AM, 1978, P BIOSIGMA 78 PARIS, V2, P245; STARK H, 1976, IEEE T SYST MAN CYB, V6, P788; STARK H, 1974, 2ND P INT JOINT C PA, P264; TURNER AF, 1976, INVEST RADIOL, V11, P258, DOI 10.1097/00004424-197607000-00002	22	15	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	5					479	482		10.1109/TPAMI.1980.6592371	http://dx.doi.org/10.1109/TPAMI.1980.6592371			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KW185					2022-12-18	WOS:A1980KW18500013
J	Han, YZ; Huang, G; Song, SJ; Yang, L; Wang, HH; Wang, YL				Han, Yizeng; Huang, Gao; Song, Shiji; Yang, Le; Wang, Honghui; Wang, Yulin			Dynamic Neural Networks: A Survey	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Computational modeling; Adaptation models; Computer architecture; Adaptive systems; Routing; Deep learning; Training; Dynamic networks; adaptive inference; efficient inference; convolutional neural networks	NEURONS; MODEL	Dynamic neural network is an emerging research topic in deep learning. Compared to static models which have fixed computational graphs and parameters at the inference stage, dynamic networks can adapt their structures or parameters to different inputs, leading to notable advantages in terms of accuracy, computational efficiency, adaptiveness, etc. In this survey, we comprehensively review this rapidly developing area by dividing dynamic networks into three main categories: 1) sample-wise dynamic models that process each sample with data-dependent architectures or parameters; 2) spatial-wise dynamic networks that conduct adaptive computation with respect to different spatial locations of image data; and 3) temporal-wise dynamic models that perform adaptive inference along the temporal dimension for sequential data such as videos and texts. The important research problems of dynamic networks, e.g., architecture design, decision making scheme, optimization technique and applications, are reviewed systematically. Finally, we discuss the open problems in this field together with interesting future research directions.	[Han, Yizeng; Huang, Gao; Song, Shiji; Yang, Le; Wang, Honghui; Wang, Yulin] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China; [Huang, Gao] Beijing Acad Artificial Intelligence, Beijing 100084, Peoples R China	Tsinghua University	Huang, G (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.; Huang, G (corresponding author), Beijing Acad Artificial Intelligence, Beijing 100084, Peoples R China.	hanyz18@mails.tsinghua.edu.cn; gaohuang@tsinghua.edu.cn; shijis@tsinghua.edu.cn; yangle15@mails.tsinghua.edu.cn; wanghh20@mails.tsinghua.edu.cn; wang-yl19@mails.tsinghua.edu.cn		Huang, Gao/0000-0002-7251-0988	National Science and Technology Major Project of the Ministry of Science and Technology of China [2018AAA0100701]; National Natural Science Foundation of China [61906106, 62022048]	National Science and Technology Major Project of the Ministry of Science and Technology of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by the National Science and Technology Major Project of the Ministry of Science and Technology of China under Grant 2018AAA0100701, in part by the National Natural Science Foundation of China under Grants 61906106 and 62022048, and in part by the Institute for Guo Qiang of Tsinghua University.	Akhlaghi V, 2018, CONF PROC INT SYMP C, P662, DOI 10.1109/ISCA.2018.00061; Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11; Alex Graves, 2017, Arxiv, DOI arXiv:1603.08983; Almahairi A, 2016, PR MACH LEARN RES, V48; Alwassel H, 2018, LECT NOTES COMPUT SC, V11213, P253, DOI 10.1007/978-3-030-01240-3_16; Andrew Davis, 2014, Arxiv, DOI arXiv:1312.4461; Andrew G. Howard, 2017, Arxiv, DOI arXiv:1704.04861; Angelova A., 2015, P BRIT MACH VIS C, P1; Antonio Criminisi, 2016, Arxiv, DOI arXiv:1603.01250; Ba J., 2015, ICLR 2015 C TRACK P; Bejnordi B. E., 2020, PROC INT C LEARN REP; Bello Irwan, 2021, INT C LEARN REPR; Bengio, 2016, ARXIV160901704; Bengio E.l, 2016, P INT C LEARN REPR W; Bengio Y., 2013, ARXIV; Bertinetto Luca, 2016, NIPS; Bhowmik A, 2018, IEEE SIGNAL PROC LET, V25, P85, DOI 10.1109/LSP.2017.2752806; Bolukbasi T, 2017, PR MACH LEARN RES, V70; Brown T., 2020, P INT C NEUR INF PRO, V33; Bulo SR, 2014, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2014.18; Cai S., 2021, P IEEECVF WINTER C A, P3588; Campos V., 2018, ICLR, P1; Cao SJ, 2019, PROC CVPR IEEE, P11208, DOI 10.1109/CVPR.2019.01147; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Chang M, 2020, P EUR C COMP VIS, P171; Chaudhari S, 2021, ACM T INTEL SYST TEC, V12, DOI 10.1145/3465055; Chen CL, 2019, IEEE T MULTIMEDIA, V21, P3205, DOI 10.1109/TMM.2019.2916104; Chen J, 2021, PROC CVPR IEEE, P8060, DOI 10.1109/CVPR46437.2021.00797; Chen JT, 2019, LECT NOTES COMPUT SC, V11953, P175, DOI 10.1007/978-3-030-36708-4_15; Chen L, 2018, LECT NOTES COMPUT SC, V11207, P435, DOI 10.1007/978-3-030-01219-9_26; Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667; Chen Yinpeng, 2020, ARXIV200310027; Chen ZR, 2019, PROC CVPR IEEE, P9164, DOI 10.1109/CVPR.2019.00939; Cheng ACE, 2020, AAAI CONF ARTIF INTE, V34, P3577; Cho K., 2014, ARXIV; Choi G, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22121336; Cinar YG, 2017, LECT NOTES COMPUT SC, V10638, P533, DOI 10.1007/978-3-319-70139-4_54; Cordonnier JB, 2021, PROC CVPR IEEE, P2351, DOI 10.1109/CVPR46437.2021.00238; Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Dai X, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P235, DOI 10.1145/3340531.3411973; De Brabandere B, 2016, ADV NEUR IN, V29; de Vries H, 2017, ADV NEUR IN, V30; Denil M., 2013, ADV NEURAL INFORM PR, P2148, DOI DOI 10.5555/2999792.2999852; Devlin J., 2019, P 2019 C N AM CHAPTE, P4171, DOI [10.18653/v1/n19-1423, DOI 10.18653/V1/N19-1423]; Diba A, 2019, IEEE I CONF COMP VIS, P6191, DOI 10.1109/ICCV.2019.00629; Dong XY, 2017, PROC CVPR IEEE, P1895, DOI 10.1109/CVPR.2017.205; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Duen Horng Chau, 2020, Arxiv, DOI arXiv:2006.11979; Ehteshami Bejnordi Ali, 2020, KI 2020: Advances in Artificial Intelligence. 43rd German Conference on AI. Proceedings. Lecture Notes in Artificial Intelligence Subseries of Lecture Notes in Computer Science (LNAI 12325), P33, DOI 10.1007/978-3-030-58285-2_3; Eigen D., 2013, P INT C LEARN REPR W; Elbayad Maha, 2020, INT C LEARNING REPRE; Eslami SM, 2016, NEURIPS, V1; Fan CY, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2527, DOI 10.1145/3292500.3330662; Fan HH, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P705; Fayyaz M., 2021, PROC IEEECVF C COMPU, P4731; Figurnov M, 2017, PROC CVPR IEEE, P1790, DOI 10.1109/CVPR.2017.194; Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476; Fu T.-J., 2018, PROC C EMPIRICAL MET, P4439; Gao H., 2019, P INT C LEARN REPR; Gao RH, 2020, PROC CVPR IEEE, P10454, DOI 10.1109/CVPR42600.2020.01047; Gao X., 2019, PROC INT C LEARN REP; Geoffrey Hinton, 2017, Arxiv, DOI arXiv:1711.09784; Ghodrati A, 2021, PROC CVPR IEEE, P15603, DOI 10.1109/CVPR46437.2021.01535; Guan JQ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2184; Gumbel E. J., 1954, APPL MATH SERIES, V33; Guo CA, 2017, PR MACH LEARN RES, V70; Guo JD, 2020, IEEE INT CON MULTI; Guo QS, 2019, PROC CVPR IEEE, P5142, DOI 10.1109/CVPR.2019.00529; Guo YH, 2019, PROC CVPR IEEE, P4800, DOI 10.1109/CVPR.2019.00494; Ha David, 2016, ARXIV160909106; Han K., 2020, PROC C NEURAL INF PR; Hansen C., 2019, P INT C LEARN REPR; Hao ZK, 2017, PROC CVPR IEEE, P1913, DOI 10.1109/CVPR.2017.207; Haque Mirazul, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14252, DOI 10.1109/CVPR42600.2020.01427; Harley AW, 2017, IEEE I CONF COMP VIS, P5048, DOI 10.1109/ICCV.2017.539; Hazimeh H, 2020, PR MACH LEARN RES, V119; He JJ, 2019, IEEE I CONF COMP VIS, P3561, DOI 10.1109/ICCV.2019.00366; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hehn TM, 2020, INT J COMPUT VISION, V128, P997, DOI 10.1007/s11263-019-01237-6; Hein M, 2019, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2019.00013; Herrmann Charles, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P241, DOI 10.1007/978-3-030-58583-9_15; Hinton G., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1109/TPAMI.2012.59; Hinton Geoffrey E, 2018, MATRIX CAPSULES ROUT; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hong S., 2021, PROC INT C LEARN REP; Hori C, 2017, IEEE I CONF COMP VIS, P4203, DOI 10.1109/ICCV.2017.450; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Hu JS, 2018, IEEE ICC; Hu T.-K., 2020, PROC INT C LEARN REP, P1; Hu XC, 2019, PROC CVPR IEEE, P1575, DOI 10.1109/CVPR.2019.00167; Hua WZ, 2019, ADV NEUR IN, V32; Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang Gao, 2018, ICLR; Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11; Huang ZJ, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1019, DOI 10.1145/3132847.3132947; Huang ZH, 2020, IEEE T NEUR NET LEAR, V31, P4461, DOI 10.1109/TNNLS.2019.2955567; Hubara I, 2016, ADV NEUR IN, V29; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837; Ioffe S., 2015, P 32 INT C MACH LEAR; Izhikevich EM, 2003, IEEE T NEURAL NETWOR, V14, P1569, DOI 10.1109/TNN.2003.820440; Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79; Jaderberg M., 2014, P BRIT MACH VIS C; Jaderberg M, 2015, ADV NEUR IN, V28; Jang E., 2017, ICLR; Jernite Y., 2017, PROC INT C LEARN REP; Jiang X., 2019, P 2019 C N AM CHAPTE, V1, P978, DOI [10.18653/v1/N19-1103, DOI 10.18653/V1/N19-1103]; Jiang YG, 2020, IEEE T IMAGE PROCESS, V29, P8747, DOI 10.1109/TIP.2020.3018269; Jie ZQ, 2021, IEEE T PATTERN ANAL, V43, P1875, DOI 10.1109/TPAMI.2019.2959322; Jin Q, 2020, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR42600.2020.00222; Jin X., 2021, PROC INT C SUSTAIN M, P495; Jo Y, 2018, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2018.00340; Kaiser L., 2018, ARXIV; Kang D, 2017, ADV NEUR IN, V30; Kaya Y, 2019, PR MACH LEARN RES, V97; Ke Nan Rosemary, 2018, PROC INT C MACH LEAR, V80, P2554; Khan S., 2021, ARXIV, DOI 10.48550/arXiv.2101.01169; Kim S, 2019, PROC CVPR IEEE, P205, DOI 10.1109/CVPR.2019.00029; Kim TH, 2017, IEEE I CONF COMP VIS, P4058, DOI 10.1109/ICCV.2017.435; Kingma D.P, 2015, P INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1412.6980; Kirillov Alexander, 2020, CVPR; Kong S, 2019, IEEE WINT CONF APPL, P1024, DOI 10.1109/WACV.2019.00114; Kontschieder P, 2015, IEEE I CONF COMP VIS, P1467, DOI 10.1109/ICCV.2015.172; Korbar B, 2019, IEEE I CONF COMP VIS, P6241, DOI 10.1109/ICCV.2019.00633; Krizhevsky A., 2012, P C NEUR INF PROC SY; Lee H, 2019, IEEE I CONF COMP VIS, P1854, DOI 10.1109/ICCV.2019.00194; Leroux S, 2017, KNOWL INF SYST, V52, P791, DOI 10.1007/s10115-017-1029-1; Leroux Sam, 2018, ICLR WORKSH; Li CL, 2021, PROC CVPR IEEE, P8603, DOI 10.1109/CVPR46437.2021.00850; Li H., 2021, P IEEECVF C COMPUTER, P6155; Li H, 2019, IEEE I CONF COMP VIS, P1891, DOI 10.1109/ICCV.2019.00198; Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170; Li J, 2020, PROC CVPR IEEE, P3348, DOI 10.1109/CVPR42600.2020.00341; Li J, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2894; Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060; Li XX, 2017, PROC CVPR IEEE, P6459, DOI 10.1109/CVPR.2017.684; Li ZC, 2017, IEEE INT CONF COMP V, P1199, DOI 10.1109/ICCVW.2017.145; Lin J, 2017, ADV NEUR IN, V30; Lin Y, 2017, IEEE INT CONF COMMUN, P782; Linxi Fan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P505, DOI 10.1007/978-3-030-58529-7_30; Liu CJ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3001; Liu Hanxiao, 2018, ARXIV180609055; Liu LL, 2018, AAAI CONF ARTIF INTE, P3675; Liu Weijie, 2020, P 58 ANN M ASS COMP, P6035, DOI DOI 10.18653/V1/2020.ACL-MAIN.537; Liu XG, 2020, NEUROCOMPUTING, V371, P177, DOI 10.1016/j.neucom.2019.08.082; Liu XH, 2019, ADV NEUR IN, V32; Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298; Ma JQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1930, DOI 10.1145/3219819.3220007; Maass W, 1997, NEURAL NETWORKS, V10, P1659, DOI 10.1016/S0893-6080(97)00011-7; Marin D, 2019, IEEE I CONF COMP VIS, P2131, DOI 10.1109/ICCV.2019.00222; McGill M, 2017, PR MACH LEARN RES, V70; Meng Y, 2022, PSYCHOL MARKET, V39, P360, DOI 10.1002/mar.21601; Mnih V, 2014, ADV NEUR IN, V27; Mullapudi RT, 2018, PROC CVPR IEEE, P8080, DOI 10.1109/CVPR.2018.00843; Murata A, 2000, J NEUROPHYSIOL, V83, P2580, DOI 10.1152/jn.2000.83.5.2580; Niklaus S, 2017, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2017.37; Niklaus S, 2017, PROC CVPR IEEE, P2270, DOI 10.1109/CVPR.2017.244; Nikolentzos G., 2020, PROC AAAI ARTIF INTE, P8854; Ningning Ma, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P351, DOI 10.1007/978-3-030-58621-8_21; Ningning Ma, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P776, DOI 10.1007/978-3-030-58555-6_46; Odena Augustus, 2017, ARXIV170207780; Pan B., 2021, ARXIV; Pan B., 2021, PROC INT C LEARN REP; Panda R., 2021, ARXIV; Park E, 2015, 2015 INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE CODESIGN AND SYSTEM SYNTHESIS (CODES+ISSS), P124, DOI 10.1109/CODESISSS.2015.7331375; Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244; Paulicke D, 2019, PFLEGE, V32, P315, DOI 10.1024/1012-5302/a000701; Perez E, 2018, AAAI CONF ARTIF INTE, P3942; Qijing Huang, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P206, DOI 10.1145/3431920.3439295; Qilong Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11531, DOI 10.1109/CVPR42600.2020.01155; Rahman W, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2359, DOI 10.18653/v1/2020.acl-main.214; Rao YM, 2017, IEEE I CONF COMP VIS, P3951, DOI 10.1109/ICCV.2017.424; Recasens A, 2018, LECT NOTES COMPUT SC, V11213, P52, DOI 10.1007/978-3-030-01240-3_4; Ren MY, 2018, PROC CVPR IEEE, P8711, DOI 10.1109/CVPR.2018.00908; Riegler G, 2015, IEEE I CONF COMP VIS, P522, DOI 10.1109/ICCV.2015.67; Rosenbaum C., 2018, 6 INT C LEARN REPR I; Rosenfeld A, 2017, LECT NOTES COMPUT SC, V10115, P264, DOI 10.1007/978-3-319-54193-8_17; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P421, DOI 10.1007/978-3-030-00928-1_48; Sabour S, 2017, ADV NEUR IN, V30; SCHMIDHUBER J, 1992, NEURAL COMPUT, V4, P131, DOI 10.1162/neco.1992.4.1.131; Schwartz Roy, 2020, P 58 ANN M ASS COMP, P6640; Seo M., 2018, P INT C LEARN REPR, P1; Shan S., 2020, P C NEUR INF PROC SY, P5047; Shen FL, 2018, PROC CVPR IEEE, P8061, DOI 10.1109/CVPR.2018.00841; Shen JH, 2020, AAAI CONF ARTIF INTE, V34, P5700; Shen YL, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1047, DOI 10.1145/3097983.3098177; Simonovsky M, 2017, PROC CVPR IEEE, P29, DOI 10.1109/CVPR.2017.11; Simonyan K., 2015, INT C LEARN REPR ICL; Song WP, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1161, DOI 10.1145/3357384.3357925; Song WP, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P555, DOI 10.1145/3289600.3290989; Su H, 2019, PROC CVPR IEEE, P11158, DOI 10.1109/CVPR.2019.01142; Su YC, 2016, LECT NOTES COMPUT SC, V9911, P783, DOI 10.1007/978-3-319-46478-7_48; Sun C, 2019, IEEE I CONF COMP VIS, P7463, DOI 10.1109/ICCV.2019.00756; Sun WJ, 2020, IEEE T IMAGE PROCESS, V29, P4027, DOI 10.1109/TIP.2020.2970248; Sun XM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7355, DOI 10.1109/ICCV48922.2021.00728; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558; Tanno R, 2019, PR MACH LEARN RES, V97; Tao J, 2019, SENSYS-ML'19: PROCEEDINGS OF THE FIRST WORKSHOP ON MACHINE LEARNING ON EDGE IN SENSOR SYSTEMS, P31, DOI 10.1145/3362743.3362965; Tavarone R, 2018, INTERSPEECH, P1274; Teerapittayanon S, 2016, INT C PATT RECOG, P2464, DOI 10.1109/ICPR.2016.7900006; Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651; Tokunaga H, 2019, PROC CVPR IEEE, P12589, DOI 10.1109/CVPR.2019.01288; Vaswani A, 2017, ADV NEUR IN, V30; Vaudaux-Ruth Guillaume, 2020, 2020 25th International Conference on Pattern Recognition (ICPR), P631, DOI 10.1109/ICPR48806.2021.9413153; Veit A, 2018, LECT NOTES COMPUT SC, V11205, P3, DOI 10.1007/978-3-030-01246-5_1; Verelst T., 2021, PROC INT C COMPUT VI, P5158; Verelst T, 2020, PROC CVPR IEEE, P2317, DOI 10.1109/CVPR42600.2020.00239; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683; Wang GR, 2019, PROC CVPR IEEE, P1781, DOI 10.1109/CVPR.2019.00188; Wang HY, 2019, PROC CVPR IEEE, P2253, DOI 10.1109/CVPR.2019.00236; Wang JQ, 2019, IEEE I CONF COMP VIS, P3007, DOI 10.1109/ICCV.2019.00310; Wang S., 2017, PROC BRIT MACH VIS C; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Wang X, 2020, PR MACH LEARN RES, V115, P552; Wang X, 2018, LECT NOTES COMPUT SC, V11217, P420, DOI 10.1007/978-3-030-01261-8_25; Wang X, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P580; Wang X, 2019, PROC CVPR IEEE, P1831, DOI 10.1109/CVPR.2019.00193; Wang Y., 2020, PROC C NEURAL INF PR; Wang Y, 2020, IEEE J-STSP, V14, P623, DOI 10.1109/JSTSP.2020.2979669; Wang YL, 2019, ADV NEUR IN, V32; Fedus W, 2021, Arxiv, DOI arXiv:2101.03961; Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1; Wu F, 2020, NEUROCOMPUTING, V384, P182, DOI 10.1016/j.neucom.2019.12.042; Wu JL, 2018, LECT NOTES COMPUT SC, V11214, P188, DOI 10.1007/978-3-030-01249-6_12; Wu WH, 2020, IEEE COMPUT SOC CONF, P2890, DOI 10.1109/CVPRW50498.2020.00346; Wu WH, 2019, IEEE I CONF COMP VIS, P6231, DOI 10.1109/ICCV.2019.00632; Wu ZX, 2019, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR.2019.00137; Wu ZX, 2019, ADV NEUR IN, V32; Wu ZX, 2018, PROC CVPR IEEE, P8817, DOI 10.1109/CVPR.2018.00919; Xia WH, 2022, IEEE T EMERG TOP COM, V10, P962, DOI 10.1109/TETC.2021.3056031; Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685; Xin J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2246; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Xu YS, 2018, PROC CVPR IEEE, P6556, DOI 10.1109/CVPR.2018.00686; Yan ZC, 2015, IEEE I CONF COMP VIS, P2740, DOI 10.1109/ICCV.2015.314; Yang B, 2019, ADV NEUR IN, V32; Yang JL, 2017, PROC CVPR IEEE, P5216, DOI 10.1109/CVPR.2017.554; Yang L, 2020, PROC CVPR IEEE, P2366, DOI 10.1109/CVPR42600.2020.00244; Yang T, 2018, ADV NEUR IN, V31; Yang YF, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P23, DOI 10.1145/3289602.3293902; Yang Z., 2019, PROC SPIE OPTOELECTR; Yanwei Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8550, DOI 10.1109/CVPR42600.2020.00858; Yeung S, 2016, PROC CVPR IEEE, P2678, DOI 10.1109/CVPR.2016.293; Yinpeng Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11027, DOI 10.1109/CVPR42600.2020.01104; Yu AW, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1880, DOI 10.18653/v1/P17-1172; Yu H., 2021, PROC AAAI ARTIF INTE, P93; Yu K., 2018, PROC INT C LEARN REP; Yue KY, 2018, ADV NEUR IN, V31; Yue Meng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P86, DOI 10.1007/978-3-030-58571-6_6; Wang YL, 2021, Arxiv, DOI arXiv:2105.15075; YulinWang Zhaoxi Chen, 2021, PROC INT C COMPUT VI, P16249; Zadeh A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2236; Weng ZJ, 2021, Arxiv, DOI arXiv:2104.09760; Zhang HP, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8322; Zhenda Xie, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P531, DOI 10.1007/978-3-030-58452-8_31; Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557; Zheng YD, 2020, IEEE T IMAGE PROCESS, V29, P7970, DOI 10.1109/TIP.2020.3007826; Zhihang Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P175, DOI 10.1007/978-3-030-58536-5_11; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; Zhou HY, 2017, IEEE I CONF COMP VIS, P3525, DOI 10.1109/ICCV.2017.379; Zhou SC, 2019, IEEE I CONF COMP VIS, P2482, DOI 10.1109/ICCV.2019.00257; Zhou W., 2020, PROC C NEURAL INF PR; Zhu PH, 2020, PROC CVPR IEEE, P5103, DOI 10.1109/CVPR42600.2020.00515; Zhu XZ, 2019, IEEE I CONF COMP VIS, P6687, DOI 10.1109/ICCV.2019.00679; Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953; Zilong Zhong, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13062, DOI 10.1109/CVPR42600.2020.01308; Zoph B., 2017, P1	280	14	14	10	20	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2022	44	11					7436	7456		10.1109/TPAMI.2021.3117837	http://dx.doi.org/10.1109/TPAMI.2021.3117837			21	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	5C5UY	34613907	Green Submitted			2022-12-18	WOS:000864325900016
J	Chao, HQ; Wang, K; He, YW; Zhang, JP; Feng, JF				Chao, Hanqing; Wang, Kun; He, Yiwei; Zhang, Junping; Feng, Jianfeng			GaitSet: Cross-View Gait Recognition Through Utilizing Gait As a Deep Set	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Gait recognition; Feature extraction; Three-dimensional displays; Legged locomotion; Deep learning; Pipelines; Data mining; Gait recognition; biometric authentication; GaitSet; deep learning		Gait is a unique biometric feature that can be recognized at a distance; thus, it has broad applications in crime prevention, forensic identification, and social security. To portray a gait, existing gait recognition methods utilize either a gait template which makes it difficult to preserve temporal information, or a gait sequence that maintains unnecessary sequential constraints and thus loses the flexibility of gait recognition. In this paper, we present a novel perspective that utilizes gait as a deep set, which means that a set of gait frames are integrated by a global-local fused deep network inspired by the way our left- and right-hemisphere processes information to learn information that can be used in identification. Based on this deep set perspective, our method is immune to frame permutations, and can naturally integrate frames from different videos that have been acquired under different scenarios, such as diverse viewing angles, different clothes, or different item-carrying conditions. Experiments show that under normal walking conditions, our single-model method achieves an average rank-1 accuracy of 96.1 percent on the CASIA-B gait dataset and an accuracy of 87.9 percent on the OU-MVLP gait dataset. Under various complex scenarios, our model also exhibits a high level of robustness. It achieves accuracies of 90.8 and 70.3 percent on CASIA-B under bag-carrying and coat-wearing walking conditions respectively, significantly outperforming the best existing methods. Moreover, the proposed method maintains a satisfactory accuracy even when only small numbers of frames are available in the test samples; for example, it achieves 85.0 percent on CASIA-B even when using only 7 frames. The source code has been released at https://github.com/AbnerHqC/GaitSet.	[Chao, Hanqing; Wang, Kun; He, Yiwei; Zhang, Junping] Fudan Univ, Sch Comp Sci, Shanghai Key Lab Intelligent Informat Proc, Shanghai 200438, Peoples R China; [Feng, Jianfeng] Fudan Univ, Inst Sci & Technol Brain Inspired Intelligence, Shanghai 200438, Peoples R China	Fudan University; Fudan University	Zhang, JP (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai Key Lab Intelligent Informat Proc, Shanghai 200438, Peoples R China.	hqchao16@fudan.edu.cn; KunWang17@fudan.edu.cn; heyw15@fudan.edu.cn; jpzhang@fudan.edu.cn; jianfeng64@gmail.com			Shanghai Municipal Science and Technology Major Project [2018SHZDZX01]; National Key R&D Program of China [2018YFB1305104]; National Natural Science Foundation of China [61673118]; ZJLab	Shanghai Municipal Science and Technology Major Project; National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); ZJLab	The authors would like to thank the associate editor and anonymous reviewers for their valuable comments, which greatly improved the quality of this paper. This work was supported in part by the Shanghai Municipal Science and Technology Major Project (Grant No. 2018SHZDZX01) and ZJLab, the National Key R&D Program of China (No. 2018YFB1305104), and National Natural Science Foundation of China (Grant No. 61673118).	Ba J., 2017, P 3 INT C LEARN REPR; Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027; Chao HQ, 2019, AAAI CONF ARTIF INTE, P8126; Chen X, 2018, IEEE T PATTERN ANAL, V40, P1697, DOI 10.1109/TPAMI.2017.2726061; Chung JS, 2018, INTERSPEECH, P1086; Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693; Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28; Fan C., 2020, PROC IEEE C COMPUT V, p14 225; Fu Y, 2019, AAAI CONF ARTIF INTE, P8295; Garcia, 2019, P AS C PATT REC AUCK, P274; Guan Y, 2015, IEEE T PATTERN ANAL, V37, P1521, DOI 10.1109/TPAMI.2014.2366766; Hamilton WL, 2017, ADV NEUR IN, V30; Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38; He YW, 2019, IEEE T INF FOREN SEC, V14, P102, DOI 10.1109/TIFS.2018.2844819; Hermans Alexander, 2017, ARXIV170307737; Hu MD, 2013, IEEE T INF FOREN SEC, V8, P2034, DOI 10.1109/TIFS.2013.2287605; Krause J, 2017, PROC CVPR IEEE, P3337, DOI 10.1109/CVPR.2017.356; Kusakunniran W, 2014, IEEE T IMAGE PROCESS, V23, P696, DOI 10.1109/TIP.2013.2294552; Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243; Liu ZY, 2006, IEEE T PATTERN ANAL, V28, P863, DOI 10.1109/TPAMI.2006.122; Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12; Peyrin C, 2004, NEUROIMAGE, V23, P698, DOI 10.1016/j.neuroimage.2004.06.020; Qi CR, 2017, ADV NEUR IN, V30; Rijun Liao, 2017, Biometric Recognition. 12th Chinese Conference, CCBR 2017. Proceedings: LNCS 10568, P474, DOI 10.1007/978-3-319-69923-3_51; Saihui Hou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P382, DOI 10.1007/978-3-030-58545-7_22; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Shiraga K, 2016, INT CONF BIOMETR; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Takemura N., 2018, IPSJ T COMPUTER VISI, V10, P1, DOI 10.1186/s41074-018-0039-6; Takemura N, 2019, IEEE T CIRC SYST VID, V29, P2708, DOI 10.1109/TCSVT.2017.2760835; Wang C, 2012, IEEE T PATTERN ANAL, V34, P2164, DOI 10.1109/TPAMI.2011.260; Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362; Weizhi An, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P421, DOI 10.1109/TBIOM.2020.3008862; Wolf T, 2016, IEEE IMAGE PROC, P4165, DOI 10.1109/ICIP.2016.7533144; Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669; Xing XL, 2016, PATTERN RECOGN, V50, P107, DOI 10.1016/j.patcog.2015.08.011; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yu SQ, 2006, INT C PATT RECOG, P441; Yu SQ, 2017, IEEE COMPUT SOC CONF, P532, DOI 10.1109/CVPRW.2017.80; Yu SQ, 2017, NEUROCOMPUTING, V239, P81, DOI 10.1016/j.neucom.2017.02.006; Zaheer M., 2017, ADV NEURAL INFORM PR, P3391; Zhang YQ, 2020, IEEE T IMAGE PROCESS, V29, P1001, DOI 10.1109/TIP.2019.2926208; Zheng L., 2016, ARXIV PREPRINT ARXIV; Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472	46	14	14	19	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2022	44	7					3467	3478		10.1109/TPAMI.2021.3057879	http://dx.doi.org/10.1109/TPAMI.2021.3057879			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1V0WH	33560976	Green Submitted			2022-12-18	WOS:000805820500011
J	Zhang, JY; Yao, YX; Deng, BL				Zhang, Juyong; Yao, Yuxin; Deng, Bailin			Fast and Robust Iterative Closest Point	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Convergence; Acceleration; Three-dimensional displays; Measurement; Optimization; Robustness; Iterative closest point algorithm; Rigid registration; robust estimator; fixed-point iterations; majorlazer minimization method; anderson acceleration	ANDERSON ACCELERATION; REWEIGHTED ALGORITHMS; CONVERGENCE ANALYSIS; KRYLOV METHODS; REGISTRATION; SETS; OPTIMIZATION; ICP	The iterative closest point (ICP) algorithm and its variants are a fundamental technique for rigid registration between two point sets, with wide applications in different areas from robotics to 3D reconstruction. The main drawbacks for ICP are its slow convergence, as well as its sensitivity to outliers, missing data, and partial overlaps. Recent work such as Sparse ICP achieves robustness via sparsity optimization at the cost of computational speed. In this paper, we propose a new method for robust registration with fast convergence. First, we show that the classical point-to-point ICP can be treated as a majorization-minimization (MM) algorithm, and propose an Anderson acceleration approach to speed up its convergence. In addition, we introduce a robust error metric based on the Welsch's function, which is minimized efficiently using the MM algorithm with Anderson acceleration. On challenging datasets with noises and partial overlaps, we achieve similar or better accuracy than Sparse ICP while being at least an order of magnitude faster. Finally, we extend the robust formulation to point-to-plane ICP, and solve the resulting problem using a similar Anderson-accelerated MM strategy. Our robust ICP methods improve the registration accuracy on benchmark datasets while being competitive in computational time.	[Zhang, Juyong; Yao, Yuxin] Univ Sci & Technol China, Sch Math Sci, Hefei 230052, Anhui, Peoples R China; [Deng, Bailin] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF10 3AT, Wales	Chinese Academy of Sciences; University of Science & Technology of China, CAS; Cardiff University	Deng, BL (corresponding author), Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF10 3AT, Wales.	juyong@ustc.edu.cn; yaoyuxin@mail.ustc.edu.cn; DengB3@cardiff.ac.uk			National Natural Science Foundation of China [61672481]; Youth Innovation Promotion Association CAS [2018495]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Youth Innovation Promotion Association CAS	This work was supported by the National Natural Science Foundation of China (No. 61672481), and Youth Innovation Promotion Association CAS (No. 2018495).	Aiger D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360684; ANDERSON DG, 1965, J ACM, V12, P547, DOI 10.1145/321296.321305; Apostolopoulos PA, 2018, GLOB INFORM INFRAS; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bohg J, 2014, IEEE INT CONF ROBOT, P3143, DOI 10.1109/ICRA.2014.6907311; Bouaziz S., 2016, PROC SIGGRAPH ASIA C, P1; Bouaziz S, 2013, COMPUT GRAPH FORUM, V32, P113, DOI 10.1111/cgf.12178; Chartrand R, 2008, INT CONF ACOUST SPEE, P3869, DOI 10.1109/ICASSP.2008.4518498; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007; Choy C, 2020, PROC CVPR IEEE, P2511, DOI 10.1109/CVPR42600.2020.00259; De Sterck H, 2012, SIAM J SCI COMPUT, V34, pA1351, DOI 10.1137/110835530; Diebel J, 2006, REPRESENTING ATTITUD; EPFL Computer Graphics and Geometry Laboratory, 2012, EPFL STAT MOD REP; Evans C, 2020, SIAM J NUMER ANAL, V58, P788, DOI 10.1137/19M1245384; Eyert V, 1996, J COMPUT PHYS, V124, P271, DOI 10.1006/jcph.1996.0059; Fang HR, 2009, NUMER LINEAR ALGEBR, V16, P197, DOI 10.1002/nla.617; Fitzgibbon AW, 2003, IMAGE VISION COMPUT, V21, P1145, DOI 10.1016/j.imavis.2003.09.004; Fu AQ, 2020, SIAM J SCI COMPUT, V42, pA3560, DOI 10.1137/19M1290097; Gallier J., 2003, International Journal of Robotics & Automation, V18, P10; Gelfand N., 2005, P 3 EUR S GEOM PROC, V2, P5; Ham B, 2018, IEEE T PATTERN ANAL, V40, P192, DOI 10.1109/TPAMI.2017.2669034; Ho N, 2017, SIAM J SCI COMPUT, V39, pS461, DOI 10.1137/16M1076770; HOFFMAN DK, 1972, J MATH PHYS, V13, P528, DOI 10.1063/1.1666011; HOLLAND PW, 1977, COMMUN STAT A-THEOR, V6, P813, DOI 10.1080/03610927708827533; Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223; Lange K, 2016, MM OPTIMIZATION ALGORITHMS, P1, DOI 10.1137/1.9781611974409; Lange K., 2004, OPTIMIZATION, P119; Lipnikov K, 2013, SIAM J SCI COMPUT, V35, pA1120, DOI 10.1137/120867846; MASUDA T, 1995, COMPUT VIS IMAGE UND, V61, P295, DOI 10.1006/cviu.1995.1024; Mellado N, 2014, COMPUT GRAPH FORUM, V33, P205, DOI 10.1111/cgf.12446; Mitra Niloy J, 2004, P 2004 EUR ACM SIGGR, P22, DOI DOI 10.1145/1057432.1057435; Mitra NJ, 2004, INT J COMPUT GEOM AP, V14, P261, DOI 10.1142/S0218195904001470; Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46; Ochs P, 2015, SIAM J IMAGING SCI, V8, P331, DOI 10.1137/140971518; Olsson C, 2009, IEEE T PATTERN ANAL, V31, P783, DOI 10.1109/TPAMI.2008.131; Ouyang WQ, 2020, COMPUT GRAPH FORUM, V39, P221, DOI 10.1111/cgf.14081; Peng Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201290; Pomerleau F, 2013, AUTON ROBOT, V34, P133, DOI 10.1007/s10514-013-9327-2; Pomerleau F, 2012, INT J ROBOT RES, V31, P1705, DOI 10.1177/0278364912458814; Potra FA, 2013, LINEAR ALGEBRA APPL, V438, P1002, DOI 10.1016/j.laa.2012.09.008; Pottmann H, 2004, COMPUT VIS IMAGE UND, V95, P54, DOI 10.1016/j.cviu.2004.04.002; Pottmann H, 2006, INT J COMPUT VISION, V67, P277, DOI 10.1007/s11263-006-5167-2; Pratapa PP, 2016, J COMPUT PHYS, V306, P43, DOI 10.1016/j.jcp.2015.11.018; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Rusinkiewicz S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323037; Rusu RB, 2009, IEEE INT CONF ROBOT, P1848; Sorkine-Hornung O., 2017, TECHNICAL REPORT; Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773; Suryanarayana P, 2019, COMPUT PHYS COMMUN, V234, P278, DOI 10.1016/j.cpc.2018.07.007; Tam GKL, 2013, IEEE T VIS COMPUT GR, V19, P1199, DOI 10.1109/TVCG.2012.310; Toth A, 2015, SIAM J NUMER ANAL, V53, P805, DOI 10.1137/130919398; Trucco E, 1999, PATTERN RECOGN LETT, V20, P889, DOI 10.1016/S0167-8655(99)00055-0; Varadarajan V., 1984, LIE GROUPS LIE ALGEB, V102; Vongkulbhisal J, 2018, PROC CVPR IEEE, P2993, DOI 10.1109/CVPR.2018.00316; Wang Y, 2019, J SCI COMPUT, V78, P29, DOI 10.1007/s10915-018-0757-z; Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362; Yang H, 2021, IEEE T ROBOT, V37, P314, DOI 10.1109/TRO.2020.3033695; Yang JL, 2016, IEEE T PATTERN ANAL, V38, P2241, DOI 10.1109/TPAMI.2015.2513405; Yu L, 2007, IEEE INT C BIOINFORM, P9, DOI 10.1109/BIBM.2007.19; Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29; Zhang JY, 2019, IEEE T VIS COMPUT GR, V25, P1774, DOI 10.1109/TVCG.2018.2816926; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149; Zhou QY, 2016, LECT NOTES COMPUT SC, V9906, P766, DOI 10.1007/978-3-319-46475-6_47	67	14	14	30	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2022	44	7					3450	3466		10.1109/TPAMI.2021.3054619	http://dx.doi.org/10.1109/TPAMI.2021.3054619			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1V0WH	33497327	Green Accepted, Green Submitted			2022-12-18	WOS:000805820500010
J	Lu, XK; Ma, C; Shen, JB; Yang, XK; Reid, I; Yang, MH				Lu, Xiankai; Ma, Chao; Shen, Jianbing; Yang, Xiaokang; Reid, Ian; Yang, Ming-Hsuan			Deep Object Tracking With Shrinkage Loss	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Target tracking; Visualization; Training; Benchmark testing; Object tracking; Data models; Correlation; Data imbalance; shrinkage loss; regression tracking; classification tracking; Siamese tracking	CORRELATION FILTERS; VISUAL TRACKING; ONLINE TRACKING; REGRESSION	In this paper, we address the issue of data imbalance in learning deep models for visual object tracking. Although it is well known that data distribution plays a crucial role in learning and inference models, considerably less attention has been paid to data imbalance in visual tracking. For the deep regression trackers that directly learn a dense mapping from input images of target objects to soft response maps, we identify their performance is limited by the extremely imbalanced pixel-to-pixel differences when computing regression loss. This prevents existing end-to-end learnable deep regression trackers from performing as well as discriminative correlation filters (DCFs) trackers. For the deep classification trackers that draw positive and negative samples to learn discriminative classifiers, there exists heavy class imbalance due to a limited number of positive samples when compared to the number of negative samples. To balance training data, we propose a novel shrinkage loss to penalize the importance of easy training data mostly coming from the background, which facilitates both deep regression and classification trackers to better distinguish target objects from the background. We extensively validate the proposed shrinkage loss function on six benchmark datasets, including the OTB-2013, OTB-2015, UAV-123, VOT-2016, VOT-2018 and LaSOT. Equipped with our shrinkage loss, the proposed one-stage deep regression tracker achieves favorable results against state-of-the-art methods, especially in comparison with DCFs trackers. Meanwhile, our shrinkage loss generalizes well to deep classification trackers. When replacing the original binary cross entropy loss with our shrinkage loss, three representative baseline trackers achieve large performance gains, even setting new state-of-the-art results.	[Lu, Xiankai; Ma, Chao; Yang, Xiaokang] Shanghai Jiao Tong Univ, AI Inst, MoE Key Lab Artificial Intelligence, Shanghai 200240, Peoples R China; [Lu, Xiankai] Shandong Univ, Sch Software, Jinan 250100, Peoples R China; [Shen, Jianbing] Incept Inst Artificial Intelligence, Abu Dhabi 5151, U Arab Emirates; [Reid, Ian] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Yang, Ming-Hsuan] Univ Calif Merced, Sch Elect Engn & Comp Sci, Merced, CA 95343 USA	Shanghai Jiao Tong University; Shandong University; University of Adelaide; University of California System; University of California Merced	Ma, C (corresponding author), Shanghai Jiao Tong Univ, AI Inst, MoE Key Lab Artificial Intelligence, Shanghai 200240, Peoples R China.	carrierlxk@gmail.com; chaoma@sjtu.edu.cn; shenjianbingcg@gmail.com; xkyang@sjtu.edu.cn; ian.reid@adelaide.edu.au; mhyang@ucmerced.edu		Shen, Jianbing/0000-0002-4109-8353; Reid, Ian/0000-0001-7790-6423	National Key Research and Development Program of China [2016YFB1001003]; NSFC [61906119, 61527804]; STCSM [18DZ1112300]; Shanghai Pujiang Program	National Key Research and Development Program of China; NSFC(National Natural Science Foundation of China (NSFC)); STCSM(Science & Technology Commission of Shanghai Municipality (STCSM)); Shanghai Pujiang Program(Shanghai Pujiang Program)	This work was supported in part by the National Key Research and Development Program of China (2016YFB1001003), NSFC (61906119, 61527804), STCSM(18DZ1112300), and Shanghai Pujiang Program. Xiankai Lu and ChaoMa contribute equally.	Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; Berman M, 2018, PROC CVPR IEEE, P4413, DOI 10.1109/CVPR.2018.00464; Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156; Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56; Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30; Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960; Chen K, 2018, IEEE T IMAGE PROCESS, V27, P3611, DOI 10.1109/TIP.2018.2819362; COPAS JB, 1983, J R STAT SOC B, V45, P311; Dai K., 2019, COMPUT VIS PATTERN R; Danelljan M, 2014, BRIT MACHINE VISIO, P1; Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733; Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29; Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490; Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84; Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143; Danelljan Martin, 2019, CVPR, V2, P6; Dong Q, 2017, IEEE I CONF COMP VIS, P1869, DOI 10.1109/ICCV.2017.205; Dong XP, 2021, IEEE T PATTERN ANAL, V43, P1515, DOI 10.1109/TPAMI.2019.2956703; Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28; Dong XP, 2017, IEEE T MULTIMEDIA, V19, P763, DOI 10.1109/TMM.2016.2631884; Fan H, 2019, P IEEECVF C COMPUTER, P5374; Fan H, 2017, IEEE I CONF COMP VIS, P5487, DOI 10.1109/ICCV.2017.585; Fan H, 2017, IEEE COMPUT SOC CONF, P2217, DOI 10.1109/CVPRW.2017.275; Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI 10.1109/ICCV.2017.129; Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13; Gao JY, 2019, PROC CVPR IEEE, P4644, DOI 10.1109/CVPR.2019.00478; Gao JY, 2018, IEEE T IMAGE PROCESS, V27, P3074, DOI 10.1109/TIP.2018.2813166; Guo Q., 2017, IEEE I CONF COMP VIS; Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251; He A., 2018, PROC EUR C COMP VIS, P132; He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508; He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45; Henriques J. F., 2012, EUR C COMP VIS, P702, DOI DOI 10.1007/978-3-642-33765-9_50; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675; Hongyi Su, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9225, P1, DOI 10.1007/978-3-319-22180-9_1; Hua Y, 2015, IEEE I CONF COMP VIS, P3092, DOI 10.1109/ICCV.2015.354; Huang C, 2016, PROC CVPR IEEE, P5375, DOI 10.1109/CVPR.2016.580; Jia Y., 2014, P 22 ACM INT C MULT, P675; Jung Ilchae, 2018, P EUR C COMP VIS ECC, P83; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Khan Salman H, 2018, IEEE Trans Neural Netw Learn Syst, V29, P3573, DOI 10.1109/TNNLS.2017.2732482; Kingma D. P., 2015, P INT C LEARN REPR, P749; Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1; Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kukar M, 1998, ECAI 1998: 13TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P445; Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441; Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935; Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515; Li H., 2014, P BRIT MACH VIS C, P1420; Li HX, 2015, LECT NOTES COMPUT SC, V9007, P194, DOI 10.1007/978-3-319-16814-2_13; Li PX, 2019, IEEE I CONF COMP VIS, P6161, DOI 10.1109/ICCV.2019.00626; Li X, 2019, PROC CVPR IEEE, P1369, DOI 10.1109/CVPR.2019.00146; Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu S, 2016, PROC CVPR IEEE, P4312, DOI 10.1109/CVPR.2016.467; Liu WY, 2016, PR MACH LEARN RES, V48; Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22; Lukezic A, 2018, INT J COMPUT VISION, V126, P671, DOI 10.1007/s11263-017-1061-3; Ma C, 2018, INT J COMPUT VISION, V126, P771, DOI 10.1007/s11263-018-1076-4; Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352; Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177; Maciejewski T., 2011, Proceedings 2011 IEEE Symposium on Computational Intelligence and Data Mining (CIDM 2011), P104, DOI 10.1109/CIDM.2011.5949434; Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66; Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27; Nam H., 2016, ARXIV160807242; Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465; Ning JF, 2016, PROC CVPR IEEE, P4266, DOI 10.1109/CVPR.2016.462; Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466; Real E, 2017, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR.2017.789; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Salti S, 2012, IEEE T IMAGE PROCESS, V21, P4334, DOI 10.1109/TIP.2012.2206035; Shen JB, 2018, IEEE T INTELL TRANSP, V19, P162, DOI 10.1109/TITS.2017.2750082; Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89; Simonyan Karen, 2015, VERY DEEP CONVOLUTIO; Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230; Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937; Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279; Sun C, 2018, PROC CVPR IEEE, P8962, DOI 10.1109/CVPR.2018.00934; Sun Y., 2019, IEEE C COMP VIS PATT; Tang YC, 2009, IEEE T SYST MAN CY B, V39, P281, DOI 10.1109/TSMCB.2008.2002909; Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158; Ting K. M., 2000, P 17 ACM INT C MACH, P435; Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531; Wang LJ, 2016, PROC CVPR IEEE, P1373, DOI 10.1109/CVPR.2016.153; Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357; Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2; Wang MM, 2017, PROC CVPR IEEE, P4800, DOI 10.1109/CVPR.2017.510; Wang N., 2013, P 26 INT C NEUR INF, P809; Wang NY, 2015, IEEE I CONF COMP VIS, P3101, DOI 10.1109/ICCV.2015.355; Wang N, 2019, PROC CVPR IEEE, P1308, DOI 10.1109/CVPR.2019.00140; Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Xu TY, 2019, IEEE I CONF COMP VIS, P7949, DOI 10.1109/ICCV.2019.00804; Zadrozny B, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P435, DOI 10.1109/icdm.2003.1250950; Zhang J., 2014, EUR C COMP VIS; Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9; Zhang L., 2019, LEARNING MODEL UPDAT, P4010, DOI [10.1109/ICCV.2019.00411, DOI 10.1109/ICCV.2019.00411]; Zhang S, 2020, INT J COMPUT VISION, V128, P96, DOI 10.1007/s11263-019-01212-1; Zhang TZ, 2019, IEEE T PATTERN ANAL, V41, P365, DOI 10.1109/TPAMI.2018.2797062; Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI 10.1109/CVPR.2017.512; Zhang TZ, 2016, PROC CVPR IEEE, P3880, DOI 10.1109/CVPR.2016.421; Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0; Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI [10.1007/978-3-030-01234-2_18, 10.1007/978-3-030-01240-3_22]; Zhu G, 2016, PROC CVPR IEEE, P943, DOI 10.1109/CVPR.2016.108	113	14	14	22	41	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2386	2401		10.1109/TPAMI.2020.3041332	http://dx.doi.org/10.1109/TPAMI.2020.3041332			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33253114	Green Published			2022-12-18	WOS:000792921400014
J	Ramachandra, B; Jones, MJ; Vatsavai, RR				Ramachandra, Bharathkumar; Jones, Michael J.; Vatsavai, Ranga Raju			A Survey of Single-Scene Video Anomaly Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Anomaly detection; Computational modeling; Cameras; Training; Buildings; Legged locomotion; Feeds; Video anomaly detection; abnormal event detection; surveillance	ABNORMAL EVENT DETECTION; NEURAL-NETWORKS; LOCALIZATION; MIXTURES	This article summarizes research trends on the topic of anomaly detection in video feeds of a single scene. We discuss the various problem formulations, publicly available datasets and evaluation criteria. We categorize and situate past research into an intuitive taxonomy and provide a comprehensive comparison of the accuracy of many algorithms on standard test sets. Finally, we also provide best practices and suggest some possible directions for future research.	[Ramachandra, Bharathkumar; Vatsavai, Ranga Raju] North Carolina State Univ, Dept Comp Sci, Raleigh, NC 27695 USA; [Jones, Michael J.] Mitsubishi Elect Res Labs MERL, Cambridge, MA 02139 USA; [Vatsavai, Ranga Raju] North Carolina State Univ, Behav Reinforcement Learning Lab, Lirio, Raleigh, NC 27695 USA	University of North Carolina; North Carolina State University; University of North Carolina; North Carolina State University	Jones, MJ (corresponding author), Mitsubishi Elect Res Labs MERL, Cambridge, MA 02139 USA.	bramach2@ncsu.edu; mjones@merl.com; rvatsavai@ncsu.edu		Vatsavai, Ranga Raju/0000-0002-7083-0267				Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825; Antic B., 2015, ARXIV150206235; Antic B, 2011, IEEE I CONF COMP VIS, P2415, DOI 10.1109/ICCV.2011.6126525; Benezeth Y., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2458, DOI 10.1109/CVPRW.2009.5206686; Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524; Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Casale P, 2014, PATTERN RECOGN, V47, P854, DOI 10.1016/j.patcog.2013.08.007; Chan AB, 2008, IEEE T PATTERN ANAL, V30, P909, DOI 10.1109/TPAMI.2007.70738; Chan F.-H., 2016, AS C COMP VIS ACCV; Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625; Chatfield K, 2014, COMPUT SCI; Che Z., ARXIV 190401975V2; Cheng KW, 2015, PROC CVPR IEEE, P2909, DOI 10.1109/CVPR.2015.7298909; Cho K., 2014, P 2014 C EMP METH NA, P1724; Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23; Chong YS, 2015, ARXIV150500523; Cong Y, 2013, PATTERN RECOGN, V46, P1851, DOI 10.1016/j.patcog.2012.11.021; Dalal N., 2005, P IEEE COMP SOC C CO; Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33; Del Giorno A, 2016, LECT NOTES COMPUT SC, V9909, P334, DOI 10.1007/978-3-319-46454-1_21; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256; Feng YC, 2017, NEUROCOMPUTING, V219, P548, DOI 10.1016/j.neucom.2016.09.063; Freund Y, 1992, ADV NEURAL INFORM PR, V4, P912; Fritzke B., 1995, Advances in Neural Information Processing Systems 7, P625; Gao DS, 2009, NEURAL COMPUT, V21, P239, DOI 10.1162/neco.2009.11-06-391; Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Guansong Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12170, DOI 10.1109/CVPR42600.2020.01219; Haresh S., 2020, P IEEE INT VEH S, P18; Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86; HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282; Herzig R, 2019, IEEE INT CONF COMP V, P2347, DOI 10.1109/ICCVW.2019.00288; Hinami R, 2017, IEEE I CONF COMP VIS, P3639, DOI 10.1109/ICCV.2017.391; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Vu H, 2019, AAAI CONF ARTIF INTE, P5216; Ionescu RT, 2019, IEEE WINT CONF APPL, P1951, DOI 10.1109/WACV.2019.00212; Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315; Ionescu Radu Tudor, 2019, CVPR, P7842; Isola P., 2017, IMAGE TO IMAGE TRANS, P1125; Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569; Keogh E, 2005, Fifth IEEE International Conference on Data Mining, Proceedings, P226, DOI 10.1109/ICDM.2005.79; Kipf T.N., 2017, 5 INT C LEARN REPRES, P1; Kiran BR, 2018, J IMAGING, V4, DOI 10.3390/jimaging4020036; Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lafferty J., 2001, P 18 INT C MACHINE L, P282, DOI DOI 10.5555/645530.655813; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Leyva R, 2017, IEEE T IMAGE PROCESS, V26, P3463, DOI 10.1109/TIP.2017.2695105; Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029; Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111; Lin T.-Y., 2017, PROC CVPR IEEE, P936, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684; Liu Yusha, 2018, P BMVC, V1, P8; Lobo JM, 2008, GLOBAL ECOL BIOGEOGR, V17, P145, DOI 10.1111/j.1466-8238.2007.00358.x; Lu CW, 2019, INT J COMPUT VISION, V127, P993, DOI 10.1007/s11263-018-1129-8; Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338; Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45; Ma K., 2015, ANOMALY DETECTION CR; Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872; Makhzani A., 2015, ADV NEURAL INFORM PR, P2791; Markovitz Amir, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10536, DOI 10.1109/CVPR42600.2020.01055; Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641; mha.cs.umn.edu, 2006, UNUSUAL CROWD ACTIVI; Morais R., 2019, PROC IEEE C COMPUT V, p11 996; Park H, 2020, PERSPECT CONTEMP KOR, P1, DOI 10.1109/CVPR42600.2020.01438; Ramachandra B., 2019, THESIS N CAROLINA ST; Ramachandra B, 2020, IEEE WINT CONF APPL, P2558, DOI 10.1109/WACV45572.2020.9093457; Ramachandra B, 2020, IEEE WINT CONF APPL, P2587, DOI 10.1109/WACV45572.2020.9093417; Rasmussen CE, 2004, LECT NOTES ARTIF INT, V3176, P63, DOI 10.1007/978-3-540-28650-9_4; Ravanbakhsh M, 2018, IEEE WINT CONF APPL, P1689, DOI 10.1109/WACV.2018.00188; Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577; Ren S., 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.169; Rodrigues R, 2020, IEEE WINT CONF APPL, P2615, DOI 10.1109/WACV45572.2020.9093633; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sabokrou Mohammad, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P56, DOI 10.1109/CVPRW.2015.7301284; Sabokrou M, 2018, PROC CVPR IEEE, P3379, DOI 10.1109/CVPR.2018.00356; Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006; Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780; Saligrama V, 2012, PROC CVPR IEEE, P2112, DOI 10.1109/CVPR.2012.6247917; Saligrama V, 2010, IEEE SIGNAL PROC MAG, V27, P18, DOI 10.1109/MSP.2010.937393; Scholkopf B, 2000, ADV NEUR IN, V12, P582; Scovanner P., 2007, ACM MM, P357; Smeureanu S, 2017, LECT NOTES COMPUT SC, V10485, P779, DOI 10.1007/978-3-319-68548-9_70; Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319; Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678; Sun QR, 2017, PATTERN RECOGN, V64, P187, DOI 10.1016/j.patcog.2016.09.016; Tang Y, 2020, PATTERN RECOGN LETT, V129, P123, DOI 10.1016/j.patrec.2019.11.024; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Tran H., 2017, P BRIT MACH VIS C; Nguyen TN, 2019, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2019.00136; Turchini F, 2017, LECT NOTES COMPUT SC, V10484, P174, DOI 10.1007/978-3-319-68560-1_16; van den Oord A., 2014, NIPS, P3518; Vu H., 2017, ARXIV 170805211; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882; Xingjian S., 2015, ADV NEURAL INFORM PR, P802, DOI DOI 10.1007/978-3-319-21233-3_6; Xu Dan, 2015, ARXIV151001553; Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4; Zhang Y, 2016, PATTERN RECOGN, V51, P443, DOI 10.1016/j.patcog.2015.09.005; Zhong JX, 2019, PROC CVPR IEEE, P1237, DOI 10.1109/CVPR.2019.00133; Zhou SF, 2016, SIGNAL PROCESS-IMAGE, V47, P358, DOI 10.1016/j.image.2016.06.007; Zhu Y., 2019, P BRIT MACH VIS C, P12	109	14	15	16	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2022	44	5					2293	2312		10.1109/TPAMI.2020.3040591	http://dx.doi.org/10.1109/TPAMI.2020.3040591			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	1C1XU	33237854	Green Submitted			2022-12-18	WOS:000792921400008
J	Akbari, A; Awais, M; Feng, ZH; Farooq, A; Kittler, J				Akbari, Ali; Awais, Muhammad; Feng, Zhenhua; Farooq, Ammarah; Kittler, Josef			Distribution Cognisant Loss for Cross-Database Facial Age Estimation With Sensitivity Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Estimation; Databases; Training; Protocols; Loss measurement; Faces; Testing; Age estimation; Generalisation; divergence measures; cross-domain recognition; deep learning; sensitivity analysis		Existing facial age estimation studies have mostly focused on intra-database protocols that assume training and test images are captured under similar conditions. This is rarely valid in practical applications, where we typically encounter training and test sets with different characteristics. In this article, we deal with such situations, namely subjective-exclusive cross-database age estimation. We formulate the age estimation problem as the distribution learning framework, where the age labels are encoded as a probability distribution. To improve the cross-database age estimation performance, we propose a new loss function which provides a more robust measure of the difference between ground-truth and predicted distributions. The desirable properties of the proposed loss function are theoretically analysed and compared with the state-of-the-art approaches. In addition, we compile a new balanced large-scale age estimation database. Last, we introduce a novel evaluation protocol, called subject-exclusive cross-database age estimation protocol, which provides meaningful information of a method in terms of the generalisation capability. The experimental results demonstrate that the proposed approach outperforms the state-of-the-art age estimation methods under both intra-database and subject-exclusive cross-database evaluation protocols. In addition, in this article, we provide a comparative sensitivity analysis of various algorithms to identify trends and issues inherent to their performance. This analysis introduces some open problems to the community which might be considered when designing a robust age estimation system.	[Akbari, Ali; Awais, Muhammad; Farooq, Ammarah; Kittler, Josef] Univ Surrey, Ctr Vis Speech & Signal Proc CVSSP, Guildford GU2 7XH, Surrey, England; [Feng, Zhenhua] Univ Surrey, Ctr Vis Speech & Signal Proc CVSSP, Dept Comp Sci, Guildford GU2 7XH, Surrey, England	University of Surrey; University of Surrey	Akbari, A (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc CVSSP, Guildford GU2 7XH, Surrey, England.	ali.akbari@surrey.ac.uk; m.a.rana@surrey.ac.uk; z.feng@surrey.ac.uk; ammarah.farooq@surrey.ac.uk; j.kittler@surrey.ac.uk	Awais, Muhammad/HCI-3725-2022	Kittler, Josef/0000-0002-8110-9205	EPSRC Programme Grant (FACER2VM) [EP/N007743/1]; EPSRC/dstl/MURI project [EP/R018456/1]	EPSRC Programme Grant (FACER2VM)(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC/dstl/MURI project(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was supported in part by the EPSRC Programme Grant (FACER2VM) EP/N007743/1 and the EPSRC/dstl/MURI project EP/R018456/1.	Aherne FJ, 1998, KYBERNETIKA, V34, P363; Akbari A., 2020, PROC IEEE INT JOINT, P1; Akbari A, 2016, 2016 IEEE 18 INT WOR, P1; Akbari A, 2020, IEEE T CIRC SYST VID, V30, P2559, DOI 10.1109/TCSVT.2019.2927912; Akbari A, 2017, INT CONF DIGIT SIG; Akbari A, 2017, IEEE GLOB CONF SIG, P6; Angulu R, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0278-6; Bashar M, 2020, IEEE ICC; Bashar M, 2020, IEEE J SEL AREA COMM, V38, P1678, DOI 10.1109/JSAC.2020.3000812; Carletti V, 2020, IEEE T PATTERN ANAL, V42, P2113, DOI 10.1109/TPAMI.2019.2910522; Cha S.H, 2007, CITY, V1, P300, DOI DOI 10.1007/S00167-009-0884-Z; Chen JK, 2018, IEEE T AFFECT COMPUT, V9, P38, DOI 10.1109/TAFFC.2016.2593719; Chen SX, 2018, IEEE T MULTIMEDIA, V20, P2209, DOI 10.1109/TMM.2017.2786869; Chen SX, 2017, PROC CVPR IEEE, P742, DOI 10.1109/CVPR.2017.86; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Ebner NC, 2010, BEHAV RES METHODS, V42, P351, DOI 10.3758/BRM.42.1.351; Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646; Gao BB, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P712; Gao BB, 2017, IEEE T IMAGE PROCESS, V26, P2825, DOI 10.1109/TIP.2017.2689998; Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733; Geng X, 2016, IEEE T KNOWL DATA EN, V28, P1734, DOI 10.1109/TKDE.2016.2545658; Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51; Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2; Gross R, 2008, IEEE INT CONF AUTOMA, P849; Guo G., 2010, P 2010 IEEE COMPUTER, P71, DOI DOI 10.1109/CVPRW.2010.5543609; Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681; Han H, 2018, IEEE T PATTERN ANAL, V40, P2597, DOI 10.1109/TPAMI.2017.2738004; Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759; Hardt M, 2016, PR MACH LEARN RES, V48; He ZZ, 2017, IEEE T IMAGE PROCESS, V26, P3846, DOI 10.1109/TIP.2017.2655445; Hu ZZ, 2017, IEEE T IMAGE PROCESS, V26, P3087, DOI 10.1109/TIP.2016.2633868; Huang D, 2017, PROC CVPR IEEE, P4058, DOI 10.1109/CVPR.2017.432; Kouw WM, 2021, IEEE T PATTERN ANAL, V43, P766, DOI 10.1109/TPAMI.2019.2945942; Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091; Li K, 2017, PATTERN RECOGN, V66, P95, DOI 10.1016/j.patcog.2017.01.007; Li WH, 2019, PROC CVPR IEEE, P1145, DOI 10.1109/CVPR.2019.00124; Liu H, 2018, IEEE T INF FOREN SEC, V13, P292, DOI 10.1109/TIFS.2017.2746062; Liu KH, 2019, IEEE T IMAGE PROCESS, V28, P5187, DOI 10.1109/TIP.2019.2916768; Lou ZY, 2018, IEEE T PATTERN ANAL, V40, P365, DOI 10.1109/TPAMI.2017.2679739; Mitchell S. A, 2010, SAND20106286C SAND N; Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250; Ngan M., 2014, 7995 NAT I STAND TEC; Niu ZX, 2016, PROC CVPR IEEE, P4920, DOI 10.1109/CVPR.2016.532; Osterreicher F., 2002, CSISZARS F DIVERGENC; Pan HY, 2018, PROC CVPR IEEE, P5285, DOI 10.1109/CVPR.2018.00554; Panis G, 2016, IET BIOMETRICS, V5, P37, DOI 10.1049/iet-bmt.2014.0053; Parkhi Omkar M., 2015, BRIT MACH VIS C; Ramanathan N., 2006, P IEEE COMP SOC C CO, P387, DOI DOI 10.1109/CVPR.2006.187; Ramanathan N, 2006, IEEE T IMAGE PROCESS, V15, P3349, DOI 10.1109/TIP.2006.881993; Ranjan R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P351, DOI 10.1109/ICCVW.2015.54; Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341; Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3; Rothe R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P252, DOI 10.1109/ICCVW.2015.41; Sason I, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20050383; Seong S., 2018, P C UNC ART INT, P1; Sharma R., 2015, INT J COMPUTER APPL, V126, P21; Shen W, 2021, IEEE T PATTERN ANAL, V43, P404, DOI 10.1109/TPAMI.2019.2937294; Shen W, 2018, PROC CVPR IEEE, P2304, DOI 10.1109/CVPR.2018.00245; Shen W, 2017, ADV NEUR IN, V30; Su B, 2019, IEEE T PATTERN ANAL, V41, P2961, DOI 10.1109/TPAMI.2018.2870154; Sun YL, 2018, IEEE T PATTERN ANAL, V40, P332, DOI 10.1109/TPAMI.2017.2669035; Tan ZC, 2018, IEEE T PATTERN ANAL, V40, P2610, DOI 10.1109/TPAMI.2017.2779808; Turaga P, 2010, INT CONF ACOUST SPEE, P946, DOI 10.1109/ICASSP.2010.5495292; Wan J, 2018, IEEE T CYBERNETICS, V48, P2531, DOI 10.1109/TCYB.2017.2741998; Wang XL, 2015, IEEE WINT CONF APPL, P534, DOI 10.1109/WACV.2015.77; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Wu T, 2012, LECT NOTES COMPUT SC, V7577, P58, DOI 10.1007/978-3-642-33783-3_5; Xie JC, 2019, IEEE T INF FOREN SEC, V14, P2500, DOI 10.1109/TIFS.2019.2902823; Xing JH, 2017, PATTERN RECOGN, V66, P106, DOI 10.1016/j.patcog.2017.01.005; Yi D, 2015, LECT NOTES COMPUT SC, V9005, P144, DOI 10.1007/978-3-319-16811-1_10; Zeng X., 2019, SOFT RANKING LABEL E; Zhang C, 2019, PROC CVPR IEEE, P12579, DOI 10.1109/CVPR.2019.01287; Zhang J, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3291124; Zhang K, 2017, IEEE ACCESS, V5, P22492, DOI 10.1109/ACCESS.2017.2761849; Zhang LN, 2019, INFRARED PHYS TECHN, V99, P1, DOI 10.1016/j.infrared.2019.03.035; Zhang Y., 2017, P BRIT MACH VIS C; Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360; Zhang Y, 2010, PROC CVPR IEEE, P2622, DOI 10.1109/CVPR.2010.5539975; Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463	79	14	14	8	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2022	44	4					1869	1887		10.1109/TPAMI.2020.3029486	http://dx.doi.org/10.1109/TPAMI.2020.3029486			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ZN1PQ	33026982				2022-12-18	WOS:000764815300017
J	Otberdout, N; Daoudi, M; Kacem, A; Ballihi, L; Berretti, S				Otberdout, Naima; Daoudi, Mohammed; Kacem, Anis; Ballihi, Lahoucine; Berretti, Stefano			Dynamic Facial Expression Generation on Hilbert Hypersphere With Conditional Wasserstein Generative Adversarial Nets	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face; Gallium nitride; Generative adversarial networks; Videos; Dynamics; Geometry; Training; Facial expression generation; conditional manifold-valued wasserstein generative adversarial networks; facial landmarks; Riemannian geometry	RECOGNITION; POSE	In this work, we propose a novel approach for generating videos of the six basic facial expressions given a neutral face image. We propose to exploit the face geometry by modeling the facial landmarks motion as curves encoded as points on a hypersphere. By proposing a conditional version of manifold-valued Wasserstein generative adversarial network (GAN) for motion generation on the hypersphere, we learn the distribution of facial expression dynamics of different classes, from which we synthesize new facial expression motions. The resulting motions can be transformed to sequences of landmarks and then to images sequences by editing the texture information using another conditional Generative Adversarial Network. To the best of our knowledge, this is the first work that explores manifold-valued representations with GAN to address the problem of dynamic facial expression generation. We evaluate our proposed approach both quantitatively and qualitatively on two public datasets; Oulu-CASIA and MUG Facial Expression. Our experimental results demonstrate the effectiveness of our approach in generating realistic videos with continuous motion, realistic appearance and identity preservation. We also show the efficiency of our framework for dynamic facial expressions generation, dynamic facial expression transfer and data augmentation for training improved emotion recognition models.	[Otberdout, Naima; Ballihi, Lahoucine] Mohammed V Univ Rabat, LRIT CNRST URAC 29, Fac Sci, Rabat 10000, Morocco; [Daoudi, Mohammed] Univ Lille, UMR 9189, CRIStAL, IMT Lille Douai,CNRS, F-59000 Lille, France; [Kacem, Anis] Univ Luxembourg, SnT Interdisciplinary Ctr Secur Reliabil & Trust, F-59000 Lille, France; [Berretti, Stefano] Univ Florence, Dept Informat Engn, I-50121 Florence, Italy	Centre National de la Recherche Scientifique & Technologique (CNRST); Mohammed V University in Rabat; Centre National de la Recherche Scientifique (CNRS); IMT - Institut Mines-Telecom; IMT Nord Europe; Universite de Lille - ISITE; Centrale Lille; Universite de Lille; University of Florence	Otberdout, N (corresponding author), Mohammed V Univ Rabat, LRIT CNRST URAC 29, Fac Sci, Rabat 10000, Morocco.	naima.otberdout@um5s.net.ma; mohamed.daoudi@imt-lille-douai.fr; anis.kacem@uni.lu; lahoucine.ballihi@um5.ac.ma; stefano.berretti@unifi.it	; Daoudi, Mohammed/H-5935-2013	Berretti, Stefano/0000-0003-1219-4386; Otberdout, naima/0000-0002-5694-0128; Daoudi, Mohammed/0000-0003-4219-7860; kacem, anis/0000-0003-0640-9862; lahoucine, Ballihi/0000-0002-4307-7468	CNRST's Scholarship of Excellence (Morocco); CAMPUS FRANCE [41539RH]; National Agency for Research (ANR) under the Investments for the future program [ANR-16-IDEX-0004 ULNE]	CNRST's Scholarship of Excellence (Morocco); CAMPUS FRANCE; National Agency for Research (ANR) under the Investments for the future program(French National Research Agency (ANR))	This work was supported by the CNRST's Scholarship of Excellence (Morocco), and by CAMPUS FRANCE [PHC TOUBKAL 2019 (French-Morocco Bilateral Program)] under Grant 41539RH. This work was also supported in part by the French State, managed by the National Agency for Research (ANR) under the Investments for the future program with reference ANR-16-IDEX-0004 ULNE. This work was partially done when A. Kacemwas a Ph.Dstudent at IMT Lille-Douai.	Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Aifanti N, 2010, 11 INT WORKSH IM AN, P1; Amos Brandon, 2016, CMUCS16118; Arjovsky M, 2017, PR MACH LEARN RES, V70; Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019; Carl V., 2016, ADV NEURAL INFORM PR, V29, P613, DOI DOI 10.13016/M26GIH-TNYZ; Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264; Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916; Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X; Cox T., 2000, MULTIDIMENSIONAL SCA; Devanne M, 2015, IEEE T CYBERNETICS, V45, P1340, DOI 10.1109/TCYB.2014.2350774; Ding H., 2017, ARXIV170903842; Ding H, 2018, AAAI CONF ARTIF INTE, P6781; Drira H, 2013, IEEE T PATTERN ANAL, V35, P2270, DOI 10.1109/TPAMI.2013.48; Fan LJ, 2019, AAAI CONF ARTIF INTE, P3510; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gulrajani I, 2017, P NIPS 2017; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Huang ZW, 2019, AAAI CONF ARTIF INTE, P3886; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341; Kacem A, 2020, IEEE T PATTERN ANAL, V42, P1, DOI 10.1109/TPAMI.2018.2872564; KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502; Kim H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201283; Kingma D.P, P 3 INT C LEARNING R; Kollias D, 2020, INT J COMPUT VISION, V128, P1455, DOI 10.1007/s11263-020-01304-3; Lai YH, 2018, IEEE INT CONF AUTOMA, P263, DOI 10.1109/FG.2018.00046; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Li Z., 2018, ABS180201822 CORR; Lucey P., 2010, P IEEE COMP SOC C CO, P94, DOI [10.1109/CVPRW.2010.5543262, DOI 10.1109/CVPRW.2010.5543262]; Mirza M., 2014, ARXIV PREPRINT ARXIV; Oh J., 2015, P ADV NEUR INF PROC, P2863; Otberdout N., 2018, P BMVC, P159; Otberdout N, 2020, IEEE T NEUR NET LEAR, V31, P3892, DOI 10.1109/TNNLS.2019.2947244; Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075; Pumarola A, 2018, LECT NOTES COMPUT SC, V11214, P835, DOI 10.1007/978-3-030-01249-6_50; Radford I., 2016, P INT C LEARN REPR; Ronneberger O., 2015, P MED IM COMP ASS IN, P234, DOI DOI 10.1007/978-3-319-24574-4_28; Saito M, 2017, IEEE I CONF COMP VIS, P2849, DOI 10.1109/ICCV.2017.308; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Song LX, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P627, DOI 10.1145/3240508.3240612; Songsri-in K., 2019, ARXIV190411521; Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184; Tulyakov S, 2018, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2018.00165; Ververas E, 2020, INT J COMPUT VISION, V128, P2629, DOI 10.1007/s11263-020-01338-7; Vougioukas K, 2020, INT J COMPUT VISION, V128, P1398, DOI 10.1007/s11263-019-01251-8; Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917; Wang Ting-Chun, 2018, ARXIV180806601; Wang W, 2018, PROC CVPR IEEE, P7083, DOI 10.1109/CVPR.2018.00740; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wiles O, 2018, LECT NOTES COMPUT SC, V11217, P690, DOI 10.1007/978-3-030-01261-8_41; Yang HY, 2018, PROC CVPR IEEE, P31, DOI 10.1109/CVPR.2018.00011; Yin X, 2017, IEEE I CONF COMP VIS, P4010, DOI 10.1109/ICCV.2017.430; Zhang FF, 2018, PROC CVPR IEEE, P3359, DOI 10.1109/CVPR.2018.00354; Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463; Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002; Zhao L, 2018, LECT NOTES COMPUT SC, V11219, P403, DOI 10.1007/978-3-030-01267-0_24; Zhou YP, 2016, LECT NOTES COMPUT SC, V9912, P262, DOI 10.1007/978-3-319-46484-8_16; Zhou YQ, 2017, INT CONF AFFECT, P370; Zhou ZH, 2011, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.2011.5995345; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	62	14	15	36	63	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2022	44	2					848	863		10.1109/TPAMI.2020.3002500	http://dx.doi.org/10.1109/TPAMI.2020.3002500			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YC9LS	32750786	Green Submitted			2022-12-18	WOS:000740006100024
J	Fu, Y; Zhang, T; Zheng, YQ; Zhang, DB; Huang, H				Fu, Ying; Zhang, Tao; Zheng, Yinqiang; Zhang, Debing; Huang, Hua			Joint Camera Spectral Response Selection and Hyperspectral Image Recovery	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Camera spectral response selection; hyperspectral image recovery; spectral nonlinear mapping; spatial similarity; and classification	REFLECTANCE RECOVERY; SPECTROMETER; SENSITIVITY; DESIGN; SYSTEM	Hyperspectral image (HSI) recovery from a single RGB image has attracted much attention, whose performance has recently been shown to be sensitive to the camera spectral response (CSR). In this paper, we present an efficient convolutional neural network (CNN) based method, which can jointly select the optimal CSR from a candidate dataset and learn a mapping to recover HSI from a single RGB image captured with this algorithmically selected camera under multi-chip or single-chip setups. Given a specific CSR, we first present a HSI recovery network, which accounts for the underlying characteristics of the HSI, including spectral nonlinear mapping and spatial similarity. Later, we append a CSR selection layer onto the recovery network, and the optimal CSR under both multi-chip and single-chip setups can thus be automatically determined from the network weights under the nonnegative sparse constraint. Experimental results on three hyperspectral datasets and two camera spectral response datasets demonstrate that our HSI recovery network outperforms state-of-the-art methods in terms of both quantitative metrics and perceptive quality, and the selection layer always returns a CSR consistent to the best one determined by exhaustive search. Finally, we show that our method can also perform well in the real capture system, and collect a hyperspectral flower dataset to evaluate the effect from HSI recovery on classification problem.	[Fu, Ying; Zhang, Tao; Huang, Hua] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China; [Zheng, Yinqiang] Natl Inst Informat, Tokyo 1018430, Japan; [Zhang, Debing] DeepGlint, Beijing 100091, Peoples R China	Beijing Institute of Technology; Research Organization of Information & Systems (ROIS); National Institute of Informatics (NII) - Japan	Huang, H (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.	fuying@bit.edu.cn; tzhang@bit.edu.cn; yqzheng@nii.ac.jp; debingzhang@deepglint.com; huahuang@bit.edu.cn	张, 涛/GSD-3950-2022	张, 涛/0000-0002-7358-0603	National Natural Science Foundation of China [61672096]; JSPS KAKENHI [19K20307]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	This work was supported by the National Natural Science Foundation of China under Grant No. 61672096 and the JSPS KAKENHI under Grant No. 19K20307.	Akhtar N, 2020, IEEE T PATTERN ANAL, V42, P100, DOI 10.1109/TPAMI.2018.2873729; Akhtar N, 2014, LECT NOTES COMPUT SC, V8695, P63, DOI 10.1007/978-3-319-10584-0_5; Aly HA, 2014, IEEE T IMAGE PROCESS, V23, P2596, DOI 10.1109/TIP.2014.2316641; Arad B, 2017, IEEE I CONF COMP VIS, P3172, DOI 10.1109/ICCV.2017.342; Arad B, 2016, LECT NOTES COMPUT SC, V9911, P19, DOI 10.1007/978-3-319-46478-7_2; BASEDOW RW, 1995, P SOC PHOTO-OPT INS, V2480, P258, DOI 10.1117/12.210881; Bioucas-Dias JM, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2244672; Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38; Cao XY, 2018, IEEE T IMAGE PROCESS, V27, P2354, DOI 10.1109/TIP.2018.2799324; Cao X, 2011, IEEE T PATTERN ANAL, V33, P2423, DOI 10.1109/TPAMI.2011.80; Chakrabarti A, 2011, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2011.5995660; Chakrabarti Ayan, 2016, ADV NEURAL INFORM PR, P3081; Chi C, 2010, INT J COMPUT VISION, V86, P140, DOI 10.1007/s11263-008-0176-y; DAISUKE K, 2016, IEEE T IMAGE PROCESS, V25, P1288; Dian RW, 2017, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2017.411; Dong WS, 2016, IEEE T IMAGE PROCESS, V25, P2337, DOI 10.1109/TIP.2016.2542360; Dong WS, 2011, IEEE I CONF COMP VIS, P1259, DOI 10.1109/ICCV.2011.6126377; Ford BK, 2001, OPT EXPRESS, V9, P444, DOI 10.1364/OE.9.000444; Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621; Fu Y, 2018, LECT NOTES COMPUT SC, V11207, P812, DOI 10.1007/978-3-030-01219-9_48; Fu Y, 2018, IEEE T COMPUT IMAG, V4, P382, DOI 10.1109/TCI.2018.2855445; Fu Y, 2018, IEEE T IMAGE PROCESS, V27, P5539, DOI 10.1109/TIP.2018.2855412; Gao LA, 2010, OPT EXPRESS, V18, P14330, DOI 10.1364/OE.18.014330; GAT N, 2006, P SPIE OPTICS PHOTON; GEHM ME, 2007, OPT EXPRESS, V15; Glorot X., 2010, J MACH LEARN RES; Han S, 2014, INT J COMPUT VISION, V110, P172, DOI 10.1007/s11263-013-0687-z; Han XH, 2018, INT C PATT RECOG, P2664, DOI 10.1109/ICPR.2018.8545634; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Hunt RWG, 2011, WILEY-ISTE, P41; Jia Y, 2017, IEEE I CONF COMP VIS, P4715, DOI 10.1109/ICCV.2017.504; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jiang J, 2013, IEEE WORK APP COMP, P168, DOI 10.1109/WACV.2013.6475015; Kawakami R., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2329, DOI 10.1109/CVPR.2011.5995457; Kawakami R, 2013, INT J COMPUT VISION, V105, P187, DOI 10.1007/s11263-013-0632-1; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Kim SJ, 2011, PATTERN RECOGN, V44, P1461, DOI 10.1016/j.patcog.2010.12.019; Kingma D.P, P 3 INT C LEARNING R; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; KRUSE FA, 1993, AIP CONF PROC, P192, DOI 10.1016/0034-4257(93)90013-N; Kwon H, 2015, IEEE I CONF COMP VIS, P307, DOI 10.1109/ICCV.2015.43; Lanaras C, 2015, IEEE I CONF COMP VIS, P3586, DOI 10.1109/ICCV.2015.409; Li YS, 2017, PATTERN RECOGN, V63, P371, DOI 10.1016/j.patcog.2016.10.019; Lin X, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661262; Lohit S, 2018, IEEE T COMPUT IMAG, V4, P326, DOI 10.1109/TCI.2018.2846413; Ma CG, 2014, INT J COMPUT VISION, V110, P141, DOI 10.1007/s11263-013-0690-4; Monno Y, 2012, IEEE IMAGE PROC, P2137, DOI 10.1109/ICIP.2012.6467315; Nair V., 2010, ICML, P807; Nguyen RMH, 2014, LECT NOTES COMPUT SC, V8695, P186, DOI 10.1007/978-3-319-10584-0_13; Nie SJ, 2018, PROC CVPR IEEE, P4767, DOI 10.1109/CVPR.2018.00501; Pan ZH, 2003, IEEE T PATTERN ANAL, V25, P1552, DOI 10.1109/TPAMI.2003.1251148; Park IC, 2007, PR IEEE COMP DESIGN, P1, DOI 10.1109/ICCD.2007.4601872; Porter WM., 1987, P SOC PHOTO-OPT INS, P22, DOI DOI 10.1117/12.942280; Qu Y, 2018, PROC CVPR IEEE, P2511, DOI 10.1109/CVPR.2018.00266; Robles-Kelly A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P251, DOI 10.1145/2733373.2806223; Sankaranarayanan A. C., 2019, P IEEE INT C INT COM, P1; Shi Z, 2018, IEEE COMPUT SOC CONF, P1052, DOI 10.1109/CVPRW.2018.00139; Sitzmann V, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201333; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Tarabalka Y, 2010, PATTERN RECOGN, V43, P2367, DOI 10.1016/j.patcog.2010.01.016; Van Nguyen H., 2010, PROC IEEE C COMPUT V, P44; Wagadarikar A, 2008, APPL OPTICS, V47, pB44, DOI 10.1364/AO.47.000B44; Wang LZ, 2017, IEEE T PATTERN ANAL, V39, P2104, DOI 10.1109/TPAMI.2016.2621050; Wang LZ, 2015, APPL OPTICS, V54, P848, DOI 10.1364/AO.54.000848; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wu D, 2013, INNOV FOOD SCI EMERG, V19, P1, DOI 10.1016/j.ifset.2013.04.014; Xu X, 2016, IEEE T GEOSCI REMOTE, V54, P3083, DOI 10.1109/TGRS.2015.2511197; Xu Y, 2016, IEEE T GEOSCI REMOTE, V54, P1990, DOI 10.1109/TGRS.2015.2493201; YAMAGUCHI M, 2006, P SOC PHOTO-OPT INS; Yang JF, 2017, IEEE I CONF COMP VIS, P1753, DOI 10.1109/ICCV.2017.193	72	14	15	17	40	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					256	272		10.1109/TPAMI.2020.3009999	http://dx.doi.org/10.1109/TPAMI.2020.3009999			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	32750820				2022-12-18	WOS:000728561300019
J	Zimmer, L; Lindauer, M; Hutter, F				Zimmer, Lucas; Lindauer, Marius; Hutter, Frank			Auto-Pytorch: Multi-Fidelity MetaLearning for Efficient and Robust AutoDL	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Optimization; Open area test sites; Training; Computer architecture; Benchmark testing; Task analysis; Pipelines; Machine learning; deep learning; automated machine learning; hyperparameter optimization; neural architecture search; multi-fidelity optimization; meta-learning	NEURAL-NETWORKS	While early AutoML frameworks focused on optimizing traditional ML pipelines and their hyperparameters, a recent trend in AutoML is to focus on neural architecture search. In this paper, we introduce Auto-PyTorch, which brings together the best of these two worlds by jointly and robustly optimizing the network architecture and the training hyperparameters to enable fully automated deep learning (AutoDL). Auto-PyTorch achieves state-of-the-art performance on several tabular benchmarks by combining multi-fidelity optimization with portfolio construction for warmstarting and ensembling of deep neural networks (DNNs) and common baselines for tabular data. To thoroughly study our assumptions on how to design such an AutoDL system, we additionally introduce a new benchmark on learning curves for DNNs, dubbed LCBench, and run extensive ablation studies of the full Auto-PyTorch on typical AutoML benchmarks, eventually showing that Auto-PyTorch performs better than several state-of-the-art competitors.	[Zimmer, Lucas] Univ Freiburg, Inst Comp Sci, D-79085 Freiburg, Germany; [Lindauer, Marius] Leibniz Univ Hannover, Inst Informat Proc, D-30167 Hannover, Germany; [Hutter, Frank] Univ Freiburg, D-79085 Freiburg, Germany; [Hutter, Frank] Bosch Ctr Artificial Intelligence, D-71272 Renningen, Germany	University of Freiburg; Leibniz University Hannover; University of Freiburg	Zimmer, L (corresponding author), Univ Freiburg, Inst Comp Sci, D-79085 Freiburg, Germany.	zimmerl@cs.uni-freiburg.de; lindauer@tnt.uni-hannover.de; fh@cs.uni-freiburg.de		Hutter, Frank/0000-0002-2037-3694; Lindauer, Marius/0000-0002-9675-3175; Zimmer, Lucas/0000-0002-5167-2929	Robert Bosch GmbH; European Research Council (ERC) under the European Unions Horizon 2020 Research and Innovation Program [716721]	Robert Bosch GmbH; European Research Council (ERC) under the European Unions Horizon 2020 Research and Innovation Program(European Research Council (ERC))	This work was supported in part by the Robert Bosch GmbH and in part by the European Research Council (ERC) under the European Unions Horizon 2020 Research and Innovation Program under Grant 716721.	Ba J., 2017, P 3 INT C LEARN REPR; Biedenkapp A., 2018, LEARN INT OPT 12 INT, P115; Bischl B, 2016, ARTIF INTELL, V237, P41, DOI 10.1016/j.artint.2016.04.003; Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS); Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Caruana R, 2006, IEEE DATA MINING, P828; Caruana Rich, 2004, ICML, DOI DOI 10.1145/1015330.1015432; Dong XT, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3023706; Dong XY, 2019, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2019.00186; Dorogush A. V., 2018, ARXIV181011363; Dwork C, 2015, SCIENCE, V349, P636, DOI 10.1126/science.aaa9375; Eggensperger K., 2013, NIPS WORK BAYESIAN O; Elsken T, 2019, J MACH LEARN RES, V20; Erickson N., 2020, SURVEY SOLO TRAVEL H; Falkner S, 2018, PR MACH LEARN RES, V80; Feurer M., 2019, ARXIV191102490; Feurer M., 2018, P INT WORKSHOP AUTOM, P1189; Feurer M., 2020, ARXIV200704074; Feurer M, 2019, SPRING SER CHALLENGE, P3, DOI 10.1007/978-3-030-05318-5_1; Feurer M, 2015, ADV NEUR IN, V28; Feurer M, 2015, AAAI CONF ARTIF INTE, P1128; Gastaldi Xavier, 2017, INT C LEARN REPR; Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1; Gijsbers Pieter, 2019, arXiv; Guyon I, 2015, IEEE IJCNN; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hutter F, 2019, SPRING SER CHALLENGE, P1, DOI 10.1007/978-3-030-05318-5; Hutter F, 2018, ARXIV180706906, P1; Hutter Frank, 2014, P 31 INT C MACHINE L, V32, P754; Jamieson K, 2016, JMLR WORKSH CONF PRO, V51, P240; Jin HF, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1946, DOI 10.1145/3292500.3330648; Ke GL, 2017, ADV NEUR IN, V30; Klein A, 2017, PR MACH LEARN RES, V54, P528; Komer B, 2014, P 13 PYTH SCI C, P32, DOI [10.25080/majora-14bd3278-006, DOI 10.25080/MAJORA-14BD3278-006]; Kotila M, 2019, AUTONOMIO; Lindauer M., 2019, ARXIV190806756; Lindauer M, 2020, J MACH LEARN RES, V21; Liu H, 2019, PROCEEDINGS OF THE THIRD INTERNATIONAL SYMPOSIUM - EDUCATIONAL RESEARCH AND EDUCATIONAL TECHNOLOGY, 2019, P3; Loshchilov I., 2017, P INT C LEARNING REP; Mendoza H, 2016, PROC WORKSHOP AUTOM, P58; Mendoza H, 2019, SPRING SER CHALLENGE, P135, DOI 10.1007/978-3-030-05318-5_7; Olson RS, 2016, GECCO'16: PROCEEDINGS OF THE 2016 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P485, DOI 10.1145/2908812.2908918; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Pham H, 2018, PR MACH LEARN RES, V80; Sharma Abhinav, 2019, Discovery Science. 22nd International Conference, DS 2019. Proceedings. Lecture Notes in Artificial Intelligence (LNAI 11828), P112, DOI 10.1007/978-3-030-33778-0_10; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811; Thornton C, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P847, DOI 10.1145/2487575.2487629; Tsamardinos I, 2018, MACH LEARN, V107, P1895, DOI 10.1007/s10994-018-5714-4; van Rijn JN, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2367, DOI 10.1145/3219819.3220058; Vanschoren J., 2013, ACM SIGKDD EXPLOR NE, V15, P49, DOI [10.1145/2641190.2641198, DOI 10.1145/2641190.2641198]; Xu L., 2011, RCRA WORKSHOP EXPT E, P16; Xu L, 2010, AAAI CONF ARTIF INTE, P210; Yamada Y, 2019, IEEE ACCESS, V7, P186126, DOI 10.1109/ACCESS.2019.2960566; Yang A., 2020, PROC INT C LEARN REP; Ying C, 2019, PR MACH LEARN RES, V97; Zela A., 2020, INT C LEARN REPRESEN; Zhang H., 2018, 6 INT C LEARNING REP, DOI 10.48550/arXiv.1710.09412; Zoph B., 2017, P1	61	14	14	6	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEPT 1	2021	43	9					3079	3090		10.1109/TPAMI.2021.3067763	http://dx.doi.org/10.1109/TPAMI.2021.3067763			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TU6DH	33750687				2022-12-18	WOS:000681124300018
J	Guan, JC; Lu, ZW; Xiang, T; Li, AX; Zhao, A; Wen, JR				Guan, Jiechao; Lu, Zhiwu; Xiang, Tao; Li, Aoxue; Zhao, An; Wen, Ji-Rong			Zero and Few Shot Learning With Semantic Feature Synthesis and Competitive Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Prototypes; Training; Power line communications; Data models; Generators; Object recognition; Zero-shot learning; projection learning; data synthesis; competitive learning; few-shot learning	CLASSIFICATION; ALGORITHM	Zero-shot learning (ZSL) is made possible by learning a projection function between a feature space and a semantic space (e.g., an attribute space). Key to ZSL is thus to learn a projection that is robust against the often large domain gap between the seen and unseen class domains. In this work, this is achieved by unseen class data synthesis and robust projection function learning. Specifically, a novel semantic data synthesis strategy is proposed, by which semantic class prototypes (e.g., attribute vectors) are used to simply perturb seen class data for generating unseen class ones. As in any data synthesis/hallucination approach, there are ambiguities and uncertainties on how well the synthesised data can capture the targeted unseen class data distribution. To cope with this, the second contribution of this work is a novel projection learning model termed competitive bidirectional projection learning (BPL) designed to best utilise the ambiguous synthesised data. Specifically, we assume that each synthesised data point can belong to any unseen class; and the most likely two class candidates are exploited to learn a robust projection function in a competitive fashion. As a third contribution, we show that the proposed ZSL model can be easily extended to few-shot learning (FSL) by again exploiting semantic (class prototype guided) feature synthesis and competitive BPL. Extensive experiments show that our model achieves the state-of-the-art results on both problems.	[Guan, Jiechao; Lu, Zhiwu; Zhao, An; Wen, Ji-Rong] Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing Key Lab Big Data Management & Anal Method, Beijing 100872, Peoples R China; [Xiang, Tao] Univ Surrey, Dept Elect & Elect Engn, Guildford GU2 7XH, Surrey, England; [Li, Aoxue] Peking Univ, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China	Renmin University of China; University of Surrey; Peking University	Lu, ZW (corresponding author), Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing Key Lab Big Data Management & Anal Method, Beijing 100872, Peoples R China.	guanjiechao0660@163.com; zhiwu.lu@gmail.com; t.xiang@surrey.ac.uk; lax@pku.edu.cn; zhaoan_ruc@163.com; jrwen@ruc.edu.cn		Lu, Zhiwu/0000-0001-6429-7956; Lu, Zhiwu/0000-0003-0280-7724	National Natural Science Foundation of China [61976220, 61832017, 61573363]; Beijing Outstanding Young Scientist Program [BJJWZYJH012019100020098]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Outstanding Young Scientist Program	This work was supported in part by the National Natural Science Foundation of China (61976220, 61832017, and 61573363), and Beijing Outstanding Young Scientist Program (BJJWZYJH012019100020098).	Akata Z, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487986; Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911; Ba JL, 2015, IEEE I CONF COMP VIS, P4247, DOI 10.1109/ICCV.2015.483; Baldi P., 2012, ICML UNSUPERVISED TR, V27, P37; BARTELS RH, 1972, COMMUN ACM, V15, P820, DOI 10.1145/361573.361582; Bucher M, 2017, IEEE INT CONF COMP V, P2666, DOI 10.1109/ICCVW.2017.308; Chandar SAP, 2014, ADV NEURAL INFORM PR, P1853; Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575; Chao WL, 2016, LECT NOTES COMPUT SC, V9906, P52, DOI 10.1007/978-3-319-46475-6_4; Chen L, 2018, PROC CVPR IEEE, P1043, DOI 10.1109/CVPR.2018.00115; Felix R, 2018, LECT NOTES COMPUT SC, V11210, P21, DOI 10.1007/978-3-030-01231-1_2; Finn C, 2017, PR MACH LEARN RES, V70; Frome Andrea, 2013, NEURIPS; Fu YW, 2016, PROC CVPR IEEE, P5337, DOI 10.1109/CVPR.2016.576; Fu YW, 2015, IEEE T PATTERN ANAL, V37, P2332, DOI 10.1109/TPAMI.2015.2408354; Fu ZY, 2018, IEEE T PATTERN ANAL, V40, P2009, DOI 10.1109/TPAMI.2017.2737007; Hariharan B, 2017, IEEE I CONF COMP VIS, P3037, DOI 10.1109/ICCV.2017.328; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Kankuekul P, 2012, PROC CVPR IEEE, P3657, DOI 10.1109/CVPR.2012.6248112; Kodirov E, 2017, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2017.473; Kodirov E, 2015, IEEE I CONF COMP VIS, P2452, DOI 10.1109/ICCV.2015.282; Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140; Li AX, 2017, IEEE T GEOSCI REMOTE, V55, P4157, DOI 10.1109/TGRS.2017.2689071; Li X., 1992, ENG OPTIMIZ, V18, P277, DOI [10.1080/03052159208941026, DOI 10.1080/03052159208941026]; Long Y, 2017, PROC CVPR IEEE, P6165, DOI 10.1109/CVPR.2017.653; Lu, 2015, ARXIV PREPRINT ARXIV; Lu XG, 2013, INTERSPEECH, P436; Lu ZW, 2009, IEEE T SYST MAN CY B, V39, P901, DOI 10.1109/TSMCB.2008.2012119; Ma JW, 2006, IEEE T SYST MAN CY B, V36, P722, DOI 10.1109/TSMCB.2006.870633; Mikolov T., 2013, ARXIV; Mishra A, 2018, IEEE COMPUT SOC CONF, P2269, DOI 10.1109/CVPRW.2018.00294; Mishra N., 2018, INT C LEARN REPR, P1; Munkhdalai T, 2018, PR MACH LEARN RES, V80; MURRAY W, 1980, SIAM J SCI STAT COMP, V1, P345, DOI 10.1137/0901025; Norouzi Mohammad, 2014, ICLR; Oreshkin Boris N, 2018, ADV NEURAL INFORM PR; Patterson G, 2014, INT J COMPUT VISION, V108, P59, DOI 10.1007/s11263-013-0695-z; Qiao SY, 2018, PROC CVPR IEEE, P7229, DOI 10.1109/CVPR.2018.00755; Radovanovic M, 2010, J MACH LEARN RES, V11, P2487; Ravi S, 2017, P INT C LEARN REPR, P1; Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13; Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Rusu Andrei A, 2019, ICLR; Schonfeld E, 2019, PROC CVPR IEEE, P8239, DOI 10.1109/CVPR.2019.00844; Shigeto Y, 2015, LECT NOTES ARTIF INT, V9284, P135, DOI 10.1007/978-3-319-23528-8_9; Shojaee S. M., 2016, ABS160509016 CORR; Silva TC, 2012, IEEE T NEUR NET LEAR, V23, P385, DOI 10.1109/TNNLS.2011.2181866; Snell J., 2017, ADV NEURAL INFORM PR, P4077; Socher Richard, 2013, NEURIPS; Sung F., 2017, ARXIV170609529; Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Triantafillou E., 2017, ADV NEURAL INFORM PR, V30, P2255; Vinyals Oriol, 2016, ARXIV160604080, P3630; Wah C., 2011, TECH REP; Wang Q, 2017, INT J COMPUT VISION, V124, P356, DOI 10.1007/s11263-017-1027-5; Wang WL, 2018, AAAI CONF ARTIF INTE, P4211; Wang YX, 2018, PROC CVPR IEEE, P7278, DOI 10.1109/CVPR.2018.00760; Xian YQ, 2019, PROC CVPR IEEE, P10267, DOI 10.1109/CVPR.2019.01052; Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581; Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768; Xian YQ, 2017, PROC CVPR IEEE, P3077, DOI 10.1109/CVPR.2017.328; Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15; XU L, 1993, IEEE T NEURAL NETWOR, V4, P636, DOI 10.1109/72.238318; Zagoruyko S, 2016, P BRIT MACH VIS C BM, DOI [10.5244/C.30.87, DOI 10.5244/C.30.87]; Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321; Zhang ZM, 2016, PROC CVPR IEEE, P6034, DOI 10.1109/CVPR.2016.649; Zhang ZM, 2016, LECT NOTES COMPUT SC, V9911, P533, DOI 10.1007/978-3-319-46478-7_33; Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474; Zhu YZ, 2018, PROC CVPR IEEE, P1004, DOI 10.1109/CVPR.2018.00111	74	14	14	4	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2021	43	7					2510	2523		10.1109/TPAMI.2020.2965534	http://dx.doi.org/10.1109/TPAMI.2020.2965534			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL3FK	31940521	Green Submitted			2022-12-18	WOS:000692540900024
J	Han, JW; Yang, Y; Zhang, DW; Huang, D; Xu, D; De La Torre, F				Han, Junwei; Yang, Yang; Zhang, Dingwen; Huang, Dong; Xu, Dong; De La Torre, Fernando			Weakly-Supervised Learning of Category-Specific 3D Object Shapes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Shape; Solid modeling; Task analysis; Two dimensional displays; Image reconstruction; Image segmentation; 3D shape reconstruction; common object segmentation; viewpoint estimation		Category-specific 3D object shape models have greatly boosted the recent advances in object detection, recognition and segmentation. However, even the most advanced approach for learning 3D object shapes still requires heavy manual annotations on large-scale 2D images. Such annotations include object categories, object keypoints, and figure-ground segmentation for the instances in each image. In particular, annotating figure-ground segmentation is unbearably labor-intensive and time-consuming. To address this problem, this paper devotes to learn category-specific 3D shape models under weak supervision, where only object categories and keypoints are required to be manually annotated on the training 2D images. By exploring the underlying relationship between two tasks: object segmentation and category-specific 3D shape reconstruction, we propose a novel weakly-supervised learning framework to jointly address these two tasks and combine them to boost the final performance of the learned 3D shape models. Moreover, learning without using figure-ground segmentation leads to ambiguous solutions. To this end, we develop the confidence weighting schemes in the viewpoint estimation and 3D shape learning procedure. These schemes effectively reduce the confusion caused by the noisy data and thus increase the chances for recovering more reliable 3D object shapes. Comprehensive experiments on the challenging PASCAL VOC benchmark show that our framework achieves comparable performance with the state-of-the-art methods that use expensive manual segmentation-level annotations. In addition, our experiments also demonstrate that our 3D shape models improve object segmentation performance.	[Han, Junwei; Yang, Yang; Zhang, Dingwen] Northwestern Polytech Univ, Sch Automat, Xian 710129, Peoples R China; [Zhang, Dingwen] Xidian Univ, Sch Mech Elect Engn, Xian 710126, Peoples R China; [Huang, Dong; De La Torre, Fernando] Carnegie Mellon Univ, Robot Inst, Pittsburgh, PA 15213 USA; [Xu, Dong] Univ Sydney, Sch Elect & Informat Engn, Camperdown, NSW 2006, Australia	Northwestern Polytechnical University; Xidian University; Carnegie Mellon University; University of Sydney	Zhang, DW (corresponding author), Northwestern Polytech Univ, Sch Automat, Xian 710129, Peoples R China.; Zhang, DW (corresponding author), Xidian Univ, Sch Mech Elect Engn, Xian 710126, Peoples R China.	junweihan2010@gmail.com; tp030ny@mail.nwpu.edu.cn; zhangdingwen2006yyy@gmail.com; dghuang@andrew.cmu.edu; dong.xu@sydney.edu.au; ftorre@cs.cmu.edu	yang, yang/GWB-9426-2022; Xu, Dong/A-3694-2011; yang, yang/HGT-7999-2022; yang, yang/GVT-5210-2022; Yang, Yi/B-9273-2017	Xu, Dong/0000-0003-2775-9730; Yang, Yi/0000-0002-0512-880X	National Key R&D Program of China [2017YFB1002201]; National Science Foundation of China [61876140]; China Postdoctoral Support Scheme for Innovative Talents [BX20180236]	National Key R&D Program of China; National Science Foundation of China(National Natural Science Foundation of China (NSFC)); China Postdoctoral Support Scheme for Innovative Talents	This work was supported in part by the National Key R&D Program of China under Grant 2017YFB1002201, the National Science Foundation of China under Grant 61876140, and the China Postdoctoral Support Scheme for Innovative Talents under Grant BX20180236.	Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879; Bao SY, 2013, PROC CVPR IEEE, P1264, DOI 10.1109/CVPR.2013.167; Barron JT, 2012, LECT NOTES COMPUT SC, V7575, P57, DOI 10.1007/978-3-642-33765-9_5; BLANZ V, 1999, P 26 ANN C COMP GRAP, P187, DOI DOI 10.1145/311535.311556; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Carreira J, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2435707; Chen XL, 2014, PROC CVPR IEEE, P2035, DOI 10.1109/CVPR.2014.261; Cheng G, 2016, PROC CVPR IEEE, P2884, DOI 10.1109/CVPR.2016.315; Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38; Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036; Dai YC, 2014, INT J COMPUT VISION, V107, P101, DOI 10.1007/s11263-013-0684-2; Dame A, 2013, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2013.170; Eriksson A, 2010, PROC CVPR IEEE, P771, DOI 10.1109/CVPR.2010.5540139; Everingham Mark, 2010, IJCV; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Hariharan B, 2012, LECT NOTES COMPUT SC, V7575, P459, DOI 10.1007/978-3-642-33765-9_33; Joulin A, 2010, PROC CVPR IEEE, P1943, DOI 10.1109/CVPR.2010.5539868; Kanazawa A, 2016, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2016.354; Kar A, 2015, PROC CVPR IEEE, P1966, DOI 10.1109/CVPR.2015.7298807; Kumar M., 2010, NIPS, P1189, DOI DOI 10.5555/2997189.2997322; Lim JJ, 2013, IEEE I CONF COMP VIS, P2992, DOI 10.1109/ICCV.2013.372; Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; MARQUES M, 2009, PROC CVPR IEEE, V113, P261; Paladini M, 2012, INT J COMPUT VISION, V96, P252, DOI 10.1007/s11263-011-0468-5; Prasad M, 2010, PROC CVPR IEEE, P1720, DOI 10.1109/CVPR.2010.5539840; Quan R, 2016, PROC CVPR IEEE, P687, DOI 10.1109/CVPR.2016.81; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rezende DJ, 2016, ADV NEUR IN, V29; Satkin S, 2015, INT J COMPUT VISION, V111, P69, DOI 10.1007/s11263-014-0734-4; Schuster T, 2017, PROC CVPR IEEE, P6921, DOI 10.1109/CVPR.2017.732; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; TULSIANI S, 2017, PROC CVPR IEEE, V39, P719; Twarog N. R., 2012, P ACM S APPL PERC, P47; Vicente S, 2008, PROC CVPR IEEE, P767; Vicente S, 2014, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2014.13; Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801; Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101; ZHANG D, 2019, LECT NOTES COMPUT SC, V127, P363; Zhang DW, 2020, IEEE T PATTERN ANAL, V42, P475, DOI 10.1109/TPAMI.2018.2881114; Zhang DW, 2017, PROC CVPR IEEE, P3587, DOI 10.1109/CVPR.2017.382; Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393; Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4; Zhu SQ, 2010, PROC CVPR IEEE, P1165, DOI 10.1109/CVPR.2010.5540085; ZIA MZ, 2013, COMP GRAPH, V35, P2608	46	14	14	3	29	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2021	43	4					1423	1437		10.1109/TPAMI.2019.2949562	http://dx.doi.org/10.1109/TPAMI.2019.2949562			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QX0CP	31670664				2022-12-18	WOS:000629017400001
J	Li, S; Jia, K; Wen, YX; Liu, TL; Tao, DC				Li, Shuai; Jia, Kui; Wen, Yuxin; Liu, Tongliang; Tao, Dacheng			Orthogonal Deep Neural Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Training; Robustness; Jacobian matrices; Task analysis; Neural networks; Optimization; Deep learning; Deep neural networks; generalization error; robustness; spectral regularization; image classification	ROBUSTNESS; STABILITY	In this paper, we introduce the algorithms of Orthogonal Deep Neural Networks (OrthDNNs) to connect with recent interest of spectrally regularized deep learning methods. OrthDNNs are theoretically motivated by generalization analysis of modern DNNs, with the aim to find solution properties of network weights that guarantee better generalization. To this end, we first prove that DNNs are of local isometry on data distributions of practical interest; by using a new covering of the sample space and introducing the local isometry property of DNNs into generalization analysis, we establish a new generalization error bound that is both scale- and range-sensitive to singular value spectrum of each of networks' weight matrices. We prove that the optimal bound w.r.t. the degree of isometry is attained when each weight matrix has a spectrum of equal singular values, among which orthogonal weight matrix or a non-square one with orthonormal rows or columns is the most straightforward choice, suggesting the algorithms of OrthDNNs. We present both algorithms of strict and approximate OrthDNNs, and for the later ones we propose a simple yet effective algorithm called Singular Value Bounding (SVB), which performs as well as strict OrthDNNs, but at a much lower computational cost. We also propose Bounded Batch Normalization (BBN) to make compatible use of batch normalization with OrthDNNs. We conduct extensive comparative studies by using modern architectures on benchmark image classification. Experiments show the efficacy of OrthDNNs.	[Li, Shuai; Jia, Kui; Wen, Yuxin] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Guangdong, Peoples R China; [Liu, Tongliang; Tao, Dacheng] Univ Sydney, Fac Engn, UBTECH Sydney AI Ctr, 6 Cleveland St, Darlington, NSW 2008, Australia; [Liu, Tongliang; Tao, Dacheng] Univ Sydney, Fac Engn, Sch Comp Sci, 6 Cleveland St, Darlington, NSW 2008, Australia	South China University of Technology; University of Sydney; University of Sydney	Jia, K (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Guangdong, Peoples R China.	lishuai918@gmail.com; kuijia@scut.edu.cn; wen.yuxin@mail.scut.edu.cn; tongliang.liu@sydney.edu.au; dacheng.tao@sydney.edu.au	WEN, YUXIN/AAH-3106-2021; Liu, Tongliang/AAA-1506-2021	WEN, YUXIN/0000-0003-3719-9001; Liu, Tongliang/0000-0002-9640-6472; Li, Shawn W. M./0000-0002-4298-5165	National Natural Science Foundation of China [61771201]; Program for Guangdong Introducing Innovative and Enterpreneurial Teams [2017ZT07X183]; Australian Research Council [DP180103424, DE190101473, FL-170100117]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Program for Guangdong Introducing Innovative and Enterpreneurial Teams; Australian Research Council(Australian Research Council)	This work is supported in part by the National Natural Science Foundation of China (Grant No. 61771201), the Program for Guangdong Introducing Innovative and Enterpreneurial Teams (Grant No. 2017ZT07X183), and the Australian Research Council Projects DP180103424, DE190101473, and FL-170100117.	Absil P. A., OPTIMIZATION ALGORIT; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arjovsky M, 2016, PR MACH LEARN RES, V48; Baldi P., 2013, ADV NEURAL INFORM PR, V26, P2814, DOI DOI 10.17744/MEHC.25.2.XHYREGGXDCD0Q4NY; Bansal N, 2018, ADV NEUR IN, V31; Bansal Nitin, 2018, ARXIV181009102; Bonnabel S, 2013, IEEE T AUTOMAT CONTR, V58, P2217, DOI 10.1109/TAC.2013.2254619; Bousquet O, 2002, J MACH LEARN RES, V2, P499, DOI 10.1162/153244302760200704; Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979; Chen Yun, 2018, P 6 INT C LEARN REPR; Cisse M, 2017, PR MACH LEARN RES, V70; Dauphin Y.N., 2014, P 27 INT C NEUR INF, P2933, DOI DOI 10.5555/2969033.2969154; Dinh L, 2017, PR MACH LEARN RES, V70; Dodge Samuel, 2017, 2017 26 INT C COMP C, P1, DOI DOI 10.1109/ICCCN.2017.8038465; ecigneul G. B, 2017, EFFECT POOLING GEOME; FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251; Ganguli, 2017, ADV NEURAL INFORM PR, P4785; Ganguli S., 2014, INT C LEARN REPR; Geirhos R, 2018, ADV NEUR IN, V31; Glorot X., 2010, PROC MACH LEARN RES, P249; Glorot X., 2011, P 14 INT C ART INT S, P315; Hardt M, 2016, PR MACH LEARN RES, V48; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hendrycks D., 2019, ICLR, P1; Hinton G.E., 2012, COMPUT SCI, V3, P212, DOI DOI 10.9774/GLEAF.978-1-909493-38-42; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang JJ, 2015, ADV NEUR IN, V28; Jia K, 2017, PROC CVPR IEEE, P3994, DOI 10.1109/CVPR.2017.425; Kawaguchi K., 2017, ARXIV171005468V4STAT, DOI DOI 10.2196/jmir.5870; Kawaguchi Kenji, 2016, ADV NEURAL INFORM PR, P586; Keskar N.S., 2017, ICLR; Kingma D.P, P 3 INT C LEARNING R; Kolmogorov A. N., 2002, AM MATH SOC TRANSLAT, V17, P227; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Kuzborskij I., 2018, P MACHINE LEARNING R, P2820; LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562; Liang PH., 2013, ADV NEURAL INFORM PR, V26; Liu TL, 2017, PR MACH LEARN RES, V70; Mohri M., 2018, FDN MACHINE LEARNING; Montufar G.F., 2014, ADV NEURAL INF PROCE, V27, P2924, DOI DOI 10.5555/2969033.2969153; Ozay M., 2016, OPTIMIZATION SUBMANI; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sedghi Hanie, 2019, INT C LEARN REPR, P2; Sokolic J, 2017, IEEE T SIGNAL PROCES, V65, P4265, DOI 10.1109/TSP.2017.2708039; Sutskever I., 2013, P 30 INT C MACH LEAR, P1139, DOI DOI 10.1007/S00287-015-0911-Z; Terao H., ARRANGEMENTS HYPERPL; Vasiljevic I., 2016, ARXIV161105760; Verma N, 2013, J MACH LEARN RES, V14, P2415; Wang S., 2016, P 33 INT C MACH LEAR, P718; Wisdom S, 2016, ADV NEUR IN, V29; Xie D, 2017, PROC CVPR IEEE, P5075, DOI 10.1109/CVPR.2017.539; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Xu H, 2012, MACH LEARN, V86, P391, DOI 10.1007/s10994-011-5268-1; Zagoruyko S, 2016, 5 INT C LEARN REPRES, DOI DOI 10.5244/C.30.87; Zhang C., 2018, CORR; Zhang CX, 2018, PROTEINS, V86, P136, DOI 10.1002/prot.25414	62	14	14	3	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2021	43	4					1352	1368		10.1109/TPAMI.2019.2948352	http://dx.doi.org/10.1109/TPAMI.2019.2948352			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QT3YJ	31634826	Green Submitted			2022-12-18	WOS:000626525300018
J	Gong, C; Shi, H; Liu, TL; Zhang, C; Yang, J; Tao, DC				Gong, Chen; Shi, Hong; Liu, Tongliang; Zhang, Chuang; Yang, Jian; Tao, Dacheng			Loss Decomposition and Centroid Estimation for Positive and Unlabeled Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						PU learning; loss decomposition; centroid estimation; kernel extension; generalization bound		This paper studies Positive and Unlabeled learning (PU learning), of which the target is to build a binary classifier where only positive data and unlabeled data are available for classifier training. To deal with the absence of negative training data, we first regard all unlabeled data as negative examples with false negative labels, and then convert PU learning into the risk minimization problem in the presence of such one-side label noise. Specifically, we propose a novel PU learning algorithm dubbed "Loss Decomposition and Centroid Estimation" (LDCE). By decomposing the loss function of corrupted negative examples into two parts, we show that only the second part is affected by the noisy labels. Thereby, we may estimate the centroid of corrupted negative set via an unbiased way to reduce the adverse impact of such label noise. Furthermore, we propose the "Kernelized LDCE" (KLDCE) by introducing the kernel trick, and show that KLDCE can be easily solved by combining Alternative Convex Search (ACS) and Sequential Minimal Optimization (SMO). Theoretically, we derive the generalization error bound which suggests that the generalization risk of our model converges to the empirical risk with the order of O(1 root k+1/root n-k+1 root n)(n and k are the amounts of training data and positive data correspondingly). Experimentally, we conduct intensive experiments on synthetic dataset, UCI benchmark datasets and real-world datasets, and the results demonstrate that our approaches (LDCE and KLDCE) achieve the top-level performance when compared with both classic and state-of-the-art PU learning methods.	[Gong, Chen] Nanjing Univ Sci & Technol, Minist Educ, Key Lab Intelligent Percept & Syst High Dimens In, PCA Lab, Nanjing 210094, Peoples R China; [Gong, Chen] Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China; [Shi, Hong; Zhang, Chuang; Yang, Jian] Nanjing Univ Sci & Technol, Jiangsu Key Lab Image & Video Understanding Socia, Key Lab Intelligent Percept & Syst High Dimens In, PCA Lab,Minist Educ, Nanjing 210094, Peoples R China; [Shi, Hong; Zhang, Chuang; Yang, Jian] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China; [Liu, Tongliang; Tao, Dacheng] Univ Sydney, Fac Engn, Sch Comp Sci, UBTECH Sydney Artificial Intelligence Ctr, 6 Cleveland St, Darlington, NSW 2008, Australia	Nanjing University of Science & Technology; Xidian University; Nanjing University of Science & Technology; Nanjing University of Science & Technology; University of Sydney	Gong, C (corresponding author), Nanjing Univ Sci & Technol, Minist Educ, Key Lab Intelligent Percept & Syst High Dimens In, PCA Lab, Nanjing 210094, Peoples R China.	chen.gong@njust.edu.cn; shihong@njust.edu.cn; tongliang.liu@sydney.edu.au; c.zhang@njust.edu.cn; csjyang@njust.edu.cn; dacheng.tao@sydney.edu.au	Liu, Tongliang/AAA-1506-2021	Liu, Tongliang/0000-0002-9640-6472	NSF of China [61602246, 61973162, U1713208]; NSF of Jiangsu Province [BK20171430]; Fundamental Research Funds for the Central Universities [30918011319]; open project of State Key Laboratory of Integrated Services Networks (Xidian University) [ISN19-03]; "Summit of the Six Top Talents" Program [DZXX-027]; "Young Elite Scientists Sponsorship Program" by Jiangsu Province; "Young Elite Scientists Sponsorship Program" by CAST [2018QNRC001]; Program for Changjiang Scholars; "111" Program [AH92005]; ARC [FL-170100117, DP180103424, DE190101473]	NSF of China(National Natural Science Foundation of China (NSFC)); NSF of Jiangsu Province; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); open project of State Key Laboratory of Integrated Services Networks (Xidian University); "Summit of the Six Top Talents" Program; "Young Elite Scientists Sponsorship Program" by Jiangsu Province; "Young Elite Scientists Sponsorship Program" by CAST; Program for Changjiang Scholars(Program for Changjiang Scholars & Innovative Research Team in University (PCSIRT)); "111" Program(Ministry of Education, China - 111 Project); ARC(Australian Research Council)	This work was supported by NSF of China (No: 61602246, 61973162, U1713208), NSF of Jiangsu Province (No: BK20171430), the Fundamental Research Funds for the Central Universities (No: 30918011319), the open project of State Key Laboratory of Integrated Services Networks (Xidian University, ID: ISN19-03), the "Summit of the Six Top Talents" Program (No: DZXX-027), the "Young Elite Scientists Sponsorship Program" by Jiangsu Province, the "Young Elite Scientists Sponsorship Program" by CAST (No: 2018QNRC001), the Program for Changjiang Scholars, the "111" Program AH92005, the ARC FL-170100117, the DP180103424 and DE190101473.	Bartlett P. L., 2003, Journal of Machine Learning Research, V3, P463, DOI 10.1162/153244303321897690; Bekker J, 2018, AAAI CONF ARTIF INTE, P2712; Bing L, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P179, DOI 10.1109/icdm.2003.1250918; Cheng J., 2017, ARXIV170903768; Davis J., 2018, ARXIV181104820; De Comite F, 1999, LECT NOTES ARTIF INT, V1720, P219; Denis F, 1998, LECT NOTES ARTIF INT, V1501, P112; du Plessis MC, 2017, MACH LEARN, V106, P463, DOI 10.1007/s10994-016-5604-6; du Plessis MC, 2014, ADV NEUR IN, V27; du Plessis MC, 2015, PR MACH LEARN RES, V37, P1386; Dua D., 2019, US; Elkan Charles, 2008, P 14 ACM SIGKDD INT, P213, DOI DOI 10.1145/1401890.1401920; Gao W, 2016, AAAI CONF ARTIF INTE, P1575; Gong C., 2019, IEEE T CIRC SYST VID, DOI [10.1106/TCSVT.2019.2903563, DOI 10.1106/TCSVT.2019.2903563]; Gong C, 2019, IEEE T NEUR NET LEAR, V30, P3471, DOI 10.1109/TNNLS.2019.2892403; Gong C, 2015, IEEE T NEUR NET LEAR, V26, P2261, DOI 10.1109/TNNLS.2014.2376936; He F., 2018, ARXIV PREPRINT ARXIV; Hsieh CJ, 2015, PR MACH LEARN RES, V37, P2445; Hsieh Y.-G, 2019, PROC INT C MACH LEAR, P1; Hsu D, 2014, PR MACH LEARN RES, V32, P37; Jain Shantanu, 2016, ADV NEURAL INFORM PR, P2685, DOI DOI 10.1101/GR.160325.113; Joachims T., 1997, P 14 INT C MACHINE L, P143, DOI DOI 10.1016/J.ESWA.2016.09.009; Kiryo R, 2017, P ANN C NEUR INF PRO, P1674; Lee Wee Sun, 2003, ICML, P448, DOI DOI 10.1016/J.TCS.2005.09.007; Li G, 2013, SURVEY POSTIVE UNLAB; Li WK, 2011, IEEE T GEOSCI REMOTE, V49, P717, DOI 10.1109/TGRS.2010.2058578; Li Xiaoli, 2003, IJCAI 03 P 18 INT JO, P587; Liu B, 2002, ICML, P387; Liu TL, 2016, IEEE T PATTERN ANAL, V38, P447, DOI 10.1109/TPAMI.2015.2456899; Lu ZW, 2017, IEEE T PATTERN ANAL, V39, P486, DOI 10.1109/TPAMI.2016.2552172; Menon AK, 2015, PR MACH LEARN RES, V37, P125; Natarajan Nagarajan, 2013, ADV NEURAL INFORM PR; Nigam K, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P792; Northcutt Curtis G., 2017, ARXIV170501936; Patrini G, 2016, PR MACH LEARN RES, V48; Platt J C, 1999, ADV KERNEL METHODS S; Ramaswamy HG, 2016, PR MACH LEARN RES, V48; Sangineto E, 2019, IEEE T PATTERN ANAL, V41, P712, DOI 10.1109/TPAMI.2018.2804907; Sansone E., 2018, IEEE T PATTERN ANAL, DOI [10.1109/TPAMI.2018.28609995, DOI 10.1109/TPAMI.2018.28609995]; Scott C., 2013, P 26 ANN C LEARN THE, P489; Scott C, 2015, JMLR WORKSH CONF PRO, V38, P838; Shi H., 2018, IJCAI, P2689, DOI 10.24963/ijcai.2018/373..; Ward G, 2009, BIOMETRICS, V65, P554, DOI 10.1111/j.1541-0420.2008.01116.x; Xu XX, 2016, IEEE T PATTERN ANAL, V38, P1113, DOI 10.1109/TPAMI.2015.2476813; Yang P, 2012, BIOINFORMATICS, V28, P2640, DOI 10.1093/bioinformatics/bts504; Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981; Yu H., 2002, P 8 ACM SIGKDD INT C, P239, DOI DOI 10.1145/775047.775083; Yu X., 2017, ARXIV170709724; Zhang D, 2005, P 5 ANN UK WORKSH CO, P83; Zhang JQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P854, DOI 10.1145/3123266.3123304	50	14	14	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR 1	2021	43	3					918	932		10.1109/TPAMI.2019.2941684	http://dx.doi.org/10.1109/TPAMI.2019.2941684			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE6IS	31535983				2022-12-18	WOS:000616309900012
J	Fan, HY; Zhang, FB; Wei, YX; Li, ZY; Zou, CQ; Gao, Y; Dai, QH				Fan, Haoyi; Zhang, Fengbin; Wei, Yuxuan; Li, Zuoyong; Zou, Changqing; Gao, Yue; Dai, Qionghai			Heterogeneous Hypergraph Variational Autoencoder for Link Prediction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Semantics; Predictive models; Task analysis; Topology; Stochastic processes; Network topology; Fans; Heterogeneous information network; hypergraph; hyperedge attention; link prediction; variational inference		Link prediction aims at inferring missing links or predicting future ones based on the currently observed network. This topic is important for many applications such as social media, bioinformatics and recommendation systems. Most existing methods focus on homogeneous settings and consider only low-order pairwise relations while ignoring either the heterogeneity or high-order complex relations among different types of nodes, which tends to lead to a sub-optimal embedding result. This paper presents a method named Heterogeneous Hypergraph Variational Autoencoder (HeteHG-VAE) for link prediction in heterogeneous information networks (HINs). It first maps a conventional HIN to a heterogeneous hypergraph with a certain kind of semantics to capture both the high-order semantics and complex relations among nodes, while preserving the low-order pairwise topology information of the original HIN. Then, deep latent representations of nodes and hyperedges are learned by a Bayesian deep generative framework from the heterogeneous hypergraph in an unsupervised manner. Moreover, a hyperedge attention module is designed to learn the importance of different types of nodes in each hyperedge. The major merit of HeteHG-VAE lies in its ability of modeling multi-level relations in heterogeneous settings. Extensive experiments on real-world datasets demonstrate the effectiveness and efficiency of the proposed method.	[Fan, Haoyi; Zhang, Fengbin] Harbin Univ Sci & Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China; [Wei, Yuxuan; Gao, Yue] Tsinghua Univ, Sch Software, BRNist, THUICBS, Beijing 100084, Peoples R China; [Li, Zuoyong] Minjiang Univ, Fujian Prov Key Lab Informat Proc & Intelligent C, Fuzhou 350121, Peoples R China; [Zou, Changqing] Sun Yat Sen Univ, Guangzhou 510275, Peoples R China; [Dai, Qionghai] Tsinghua Univ, THUICBS, Dept Automat, BRNist, Beijing 100084, Peoples R China	Harbin University of Science & Technology; Tsinghua University; Minjiang University; Sun Yat Sen University; Tsinghua University	Zhang, FB (corresponding author), Harbin Univ Sci & Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.; Gao, Y (corresponding author), Tsinghua Univ, Sch Software, BRNist, THUICBS, Beijing 100084, Peoples R China.	isfanhy@gmail.com; zhangfengbin@hrbust.edu.cn; weiyuxua19@mails.tsinghua.edu.cn; fzulzytdq@126.com; aaronzou1125@gmail.com; kevin.gaoy@gmail.com; qhdai@tsinghua.edu.cn			National Natural Science Foundation of China [U1701262, 61972187, 61172168]; Tsinghua University Initiative Scientific Research Program [20197020003]; Natural Science Foundation of Fujian Province [2020J02024]; Fuzhou Science and Technology Project [2020-RC-186]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Tsinghua University Initiative Scientific Research Program; Natural Science Foundation of Fujian Province(Natural Science Foundation of Fujian Province); Fuzhou Science and Technology Project	This work was supported in part by the National Natural Science Foundation of China (Grants U1701262, 61972187, and 61172168), Tsinghua University Initiative Scientific Research Program (20197020003), Natural Science Foundation of Fujian Province (2020J02024), and Fuzhou Science and Technology Project (2020-RC-186).	Adamic LA, 2003, SOC NETWORKS, V25, P211, DOI 10.1016/S0378-8733(03)00009-1; Backstrom Lars, 2011, P 4 ACM INT C WEB SE, P635; Baytas IM, 2018, IEEE DATA MINING, P875, DOI 10.1109/ICDM.2018.00104; Berge C., 1973, GRAPHS HYPERGRAPHS; Bordes A., 2013, ADV NEURAL INFORM PR; Chami I, 2019, ADV NEUR IN, V32; Chen T, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P295, DOI 10.1145/3018661.3018735; Chen YL, 2015, IEEE DATA MINING, P51, DOI 10.1109/ICDM.2015.91; Chien I. E., 2019, PROC 22 INT C ARTIF, P2466; Clauset A, 2008, NATURE, V453, P98, DOI 10.1038/nature06830; Davidson TR, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P856; Dettmers T, 2018, AAAI CONF ARTIF INTE, P1811; Dong YX, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P135, DOI 10.1145/3097983.3098036; Duan L, 2017, IEEE T KNOWL DATA EN, V29, P2402, DOI 10.1109/TKDE.2017.2730207; Feng W., 2012, P 18 ACM SIGKDD INT, P1276; Feng YF, 2019, AAAI CONF ARTIF INTE, P3558; Fu GJ, 2019, IEEE IJCNN; Fu TY, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1797, DOI 10.1145/3132847.3132953; Ganea Octavian, 2018, ADV NEURAL INFORM PR, P5345; Gao Y, 2022, IEEE T PATTERN ANAL, V44, P2548, DOI 10.1109/TPAMI.2020.3039374; Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754; Gui H, 2017, IEEE T KNOWL DATA EN, V29, P2428, DOI 10.1109/TKDE.2017.2733530; Hamilton WL, 2017, ADV NEUR IN, V30; Hu ZN, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2704, DOI 10.1145/3366423.3380027; Huang YC, 2010, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2010.5540012; Katz L., 1953, PSYCHOMETRIKA, V18, P39, DOI [10.1007/BF02289026, DOI 10.1007/BF02289026, DOI 10.1016/j.clinph.2016.12.016]; Kingma D.P., 2014, P 2 INT C LEARN REPR, DOI DOI 10.1093/BIOINFORMATICS/BTAA169; Kingma DP, 2017, P INT C LEARN REPR I; Kipf T. N., 2016, PROC NIPS WORKSHOP B; Kipf T. N., 2017, 5 INT C LEARN REPR; Krioukov D, 2010, PHYS REV E, V82, DOI 10.1103/PhysRevE.82.036106; Li P., 2018, P 35 INT C MACHINE L, P3014; Li P, 2020, IEEE T INFORM THEORY, V66, P3065, DOI 10.1109/TIT.2019.2940246; Li P, 2017, ADV NEUR IN, V30; Liao LZ, 2018, IEEE T KNOWL DATA EN, V30, P2257, DOI 10.1109/TKDE.2018.2819980; Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591; Liu Q, 2019, ADV NEUR IN, V32; Lu LY, 2011, PHYSICA A, V390, P1150, DOI 10.1016/j.physa.2010.11.027; Nickel M, 2017, ADV NEUR IN, V30; Nickel Maximilian, 2014, ADV NEURAL INFORM PR, P1179; Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732; Probst M, 2020, J MACH LEARN RES, V21; Salha G., 2019, PROC WORKSHOP GRAPH; Sankar A., 2019, ICLRW; Scellato S., 2011, SIGKDD, P1046, DOI DOI 10.1145/2020408.2020575; Scheinerman E. R., 1997, FRACTIONAL GRAPH THE; Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38; Shi C, 2019, IEEE T KNOWL DATA EN, V31, P357, DOI 10.1109/TKDE.2018.2833443; Shi C, 2017, IEEE T KNOWL DATA EN, V29, P17, DOI 10.1109/TKDE.2016.2598561; Shi HY, 2019, IEEE T NEUR NET LEAR, V30, P2963, DOI 10.1109/TNNLS.2018.2869747; Shi Y, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2190, DOI 10.1145/3219819.3220006; Socher R., 2013, ADV NEURAL INFORM PR, V26, P1; Sunt YZ, 2011, PROC VLDB ENDOW, V4, P992; Tang J, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1165, DOI 10.1145/2783258.2783307; Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093; Tu K, 2018, AAAI CONF ARTIF INTE, P426; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Velickovi P., 2018, P INT C LEARN REPR I, P1, DOI DOI 10.48550/ARXIV.1710.10903; Wang H, 2017, AAAI CONF ARTIF INTE, P2688; Wang Q, 2017, IEEE T KNOWL DATA EN, V29, P2724, DOI 10.1109/TKDE.2017.2754499; Wang X, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2022, DOI 10.1145/3308558.3313562; Yadati Naganand, 2019, ADV NEURAL INFORM PR, P1511; Yang DQ, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2147, DOI 10.1145/3308558.3313635; You JX, 2019, PR MACH LEARN RES, V97; Zhang CX, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P793, DOI 10.1145/3292500.3330961; Zhang CX, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P709, DOI 10.1145/3178876.3186152; Zhang MH, 2018, AAAI CONF ARTIF INTE, P4438; Zhang MH, 2018, ADV NEUR IN, V31; Zhang ZZ, 2018, IEEE T IMAGE PROCESS, V27, P5957, DOI 10.1109/TIP.2018.2862625; Zhao H, 2017, PR MACH LEARN RES, V70; Zhou D, 2006, P 2006 C ADV NEURAL, V19, DOI 10.7551/mitpress/7503.003.0205; Zhou S, 2020, AAAI CONF ARTIF INTE, V34, P6949; Zitnik M, 2018, BIOINFORMATICS, V34, P457, DOI 10.1093/bioinformatics/bty294	73	14	15	17	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 15	2021	44	8					4125	4138		10.1109/TPAMI.2021.3059313	http://dx.doi.org/10.1109/TPAMI.2021.3059313			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	2Q6HR	33587699				2022-12-18	WOS:000820522100002
J	Shen, W; Guo, YL; Wang, Y; Zhao, K; Wang, B; Yuille, A				Shen, Wei; Guo, Yilu; Wang, Yan; Zhao, Kai; Wang, Bo; Yuille, Alan			Deep Differentiable Random Forests for Age Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Vegetation; Estimation; Forestry; Nonhomogeneous media; Aging; Facial features; Age estimation; random forest; regression; label distribution learning; deterministic annealing	RECOGNITION	Age estimation from facial images is typically cast as a label distribution learning or regression problem, since aging is a gradual progress. Its main challenge is the facial feature space w.r.t. ages is inhomogeneous, due to the large variation in facial appearance across different persons of the same age and the non-stationary property of aging. In this paper, we propose two Deep Differentiable Random Forests methods, Deep Label Distribution Learning Forest (DLDLF) and Deep Regression Forest (DRF), for age estimation. Both of them connect split nodes to the top layer of convolutional neural networks (CNNs) and deal with inhomogeneous data by jointly learning input-dependent data partitions at the split nodes and age distributions at the leaf nodes. This joint learning follows an alternating strategy: (1) Fixing the leaf nodes and optimizing the split nodes and the CNN parameters by Back-propagation; (2) Fixing the split nodes and optimizing the leaf nodes by Variational Bounding. Two Deterministic Annealing processes are introduced into the learning of the split and leaf nodes, respectively, to avoid poor local optima and obtain better estimates of tree parameters free of initial values. Experimental results show that DLDLF and DRF achieve state-of-the-art performance on three age estimation datasets.	[Shen, Wei; Wang, Yan; Yuille, Alan] Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA; [Guo, Yilu] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China; [Zhao, Kai] Nankai Univ, Coll Comp & Control Engn, Tianjin 300071, Peoples R China; [Wang, Bo] Univ Hlth Network, Vector Inst, Toronto, ON, Canada; [Wang, Bo] Univ Hlth Network, Peter Munk Cardiac Ctr, Toronto, ON, Canada	Johns Hopkins University; Shanghai University; Nankai University; University of Toronto; University Toronto Affiliates; University Health Network Toronto; University of Toronto; Peter Munk Cardiac Centre; University Toronto Affiliates; University Health Network Toronto	Wang, Y (corresponding author), Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA.	fshenwei1231@gmail.com; gyl.luan0@gmail.com; wyanny.9@gmail.com; zhaok1206@gmail.com; bowang@vectorinstitute.ai; alan.l.yuille@gmail.com	Wang, Bo/HDO-6738-2022	Wang, Bo/0000-0002-9620-3413; Guo, Yilu/0000-0002-5551-7053; Yuille, Alan L./0000-0001-5207-9249	National Natural Science Foundation of China [61672336]; ONR [N00014-15-1-2356]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); ONR(Office of Naval Research)	This work was supported in part by the National Natural Science Foundation of China No. 61672336 and in part by ONR N00014-15-1-2356. The authors would like to thank Chenxi Liu, Siyuan Qiao and Zhishuai Zhang for instructive discussions.	Agustsson E., 2017, P IEEE INT C COMP VI, DOI DOI 10.1109/ICCV.2017.182; Alkass K, 2010, MOL CELL PROTEOMICS, V9, P1022, DOI 10.1074/mcp.M900525-MCP200; Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; [Anonymous], 2017, NIPS; Berger AL, 1996, COMPUT LINGUIST, V22, P39; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.3390/risks8030083; Chang KY, 2011, PROC CVPR IEEE, P585, DOI 10.1109/CVPR.2011.5995437; Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374; Chen K, 2013, PROC CVPR IEEE, P2467, DOI 10.1109/CVPR.2013.319; Chen SX, 2017, PROC CVPR IEEE, P742, DOI 10.1109/CVPR.2017.86; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Criminisi A., 2013, DECISION FORESTCOM; Gao BB, 2017, IEEE T IMAGE PROCESS, V26, P2825, DOI 10.1109/TIP.2017.2689998; Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733; Geng X, 2016, IEEE T KNOWL DATA EN, V28, P1734, DOI 10.1109/TKDE.2016.2545658; Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51; Geng X, 2010, AAAI CONF ARTIF INTE, P451; Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280; Guo GD, 2014, IMAGE VISION COMPUT, V32, P761, DOI 10.1016/j.imavis.2014.04.011; Guo GD, 2011, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2011.5995404; Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681; Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759; Han Hu, 2013, P 2013 INT C BIOM IC, P1, DOI DOI 10.1109/ICB.2013.6613022; He ZZ, 2017, IEEE T IMAGE PROCESS, V26, P3846, DOI 10.1109/TIP.2017.2655445; Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601; Huang D, 2017, PROC CVPR IEEE, P4058, DOI 10.1109/CVPR.2017.432; Ioannou Y., 2016, ARXIV 1603 01250; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Kontschieder P, 2015, IEEE I CONF COMP VIS, P1467, DOI 10.1109/ICCV.2015.172; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kuang-Yu Chang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3396, DOI 10.1109/ICPR.2010.829; Lee CY, 2018, IEEE T PATTERN ANAL, V40, P863, DOI 10.1109/TPAMI.2017.2703082; Leistner C, 2010, LECT NOTES COMPUT SC, V6316, P29, DOI 10.1007/978-3-642-15567-3_3; Leistner C, 2009, IEEE I CONF COMP VIS, P506, DOI 10.1109/ICCV.2009.5459198; Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352; Luu K., 2011, IJCB, P1; Montilla A, 2009, IEEE IMAGE PROC, P2465, DOI 10.1109/ICIP.2009.5414103; Neal R. M., 1999, LEARNING GRAPHICALMO; Niu ZX, 2016, PROC CVPR IEEE, P4920, DOI 10.1109/CVPR.2016.532; Pan HY, 2018, PROC CVPR IEEE, P5285, DOI 10.1109/CVPR.2018.00554; Panis G, 2016, IET BIOMETRICS, V5, P37, DOI 10.1049/iet-bmt.2014.0053; Prati A, 2014, EUR C COMP VIS, P667; Ramanathan N., 2009, J VISUAL LANG COMPUT, V15, P3349; Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341; Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788; Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3; Rothe R, 2016, PROC CVPR IEEE, P5553, DOI 10.1109/CVPR.2016.599; Roy A, 2016, PROC CVPR IEEE, P5506, DOI 10.1109/CVPR.2016.594; Shen W, 2018, PROC CVPR IEEE, P2304, DOI 10.1109/CVPR.2018.00245; Simonyan K, 2015, 3 INT C LEARN REPR I; Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994; Ueda N, 1998, NEURAL NETWORKS, V11, P271, DOI 10.1016/S0893-6080(97)00133-0; Ueda N., 1994, P 7 INT C NEUR INF P, P545; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang JW, 2013, 2013 IEEE 10TH INTERNATIONAL CONFERENCE ON AND 10TH INTERNATIONAL CONFERENCE ON AUTONOMIC AND TRUSTED COMPUTING (UIC/ATC) UBIQUITOUS INTELLIGENCE AND COMPUTING, P17, DOI 10.1109/UIC-ATC.2013.19; Wang XL, 2015, IEEE WINT CONF APPL, P534, DOI 10.1109/WACV.2015.77; Yan SC, 2007, IEEE I CONF COMP VIS, P1735; Yang X., 2016, INT JOINT C ART INT, P2259; Yi D., 2014, P AS C COMP VIS, P144, DOI DOI 10.1007/978-3-319-16811-110; Yuille AL, 2003, NEURAL COMPUT, V15, P915, DOI 10.1162/08997660360581958; Zhang Y, 2010, PROC CVPR IEEE, P2622, DOI 10.1109/CVPR.2010.5539975	62	14	15	4	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2021	43	2					404	419		10.1109/TPAMI.2019.2937294	http://dx.doi.org/10.1109/TPAMI.2019.2937294			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PR6ZZ	31449007	Green Submitted			2022-12-18	WOS:000607383300003
J	Ofir, N; Galun, M; Alpert, S; Brandt, A; Nadler, B; Basri, R				Ofir, Nati; Galun, Meirav; Alpert, Sharon; Brandt, Achi; Nadler, Boaz; Basri, Ronen			On Detection of Faint Edges in Noisy Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Image edge detection; Noise measurement; Matched filters; Smoothing methods; Detection algorithms; Microscopy; Signal to noise ratio; Edge detection; fiber enhancement; multiscale methods; low signal-to-noise ratio; multiple hypothesis tests; microscopy images	COLOR; SEGMENTATION; ENHANCEMENT; BOUNDARIES; TRANSFORM; TEXTURE	A fundamental question for edge detection in noisy images is how faint can an edge be and still be detected. In this paper we offer a formalism to study this question and subsequently introduce computationally efficient multiscale edge detection algorithms designed to detect faint edges in noisy images. In our formalism we view edge detection as a search in a discrete, though potentially large, set of feasible curves. First, we derive approximate expressions for the detection threshold as a function of curve length and the complexity of the search space. We then present two edge detection algorithms, one for straight edges, and the second for curved ones. Both algorithms efficiently search for edges in a large set of candidates by hierarchically constructing difference filters that match the curves traced by the sought edges. We demonstrate the utility of our algorithms in both simulations and applications involving challenging real images. Finally, based on these principles, we develop an algorithm for fiber detection and enhancement. We exemplify its utility to reveal and enhance nerve axons in light microscopy images.	[Ofir, Nati; Galun, Meirav; Alpert, Sharon; Brandt, Achi; Nadler, Boaz; Basri, Ronen] Weizman Inst Sci, Dept Comp Sci & Appl Math, IL-7610001 Rehovot, Israel	Weizmann Institute of Science	Basri, R (corresponding author), Weizman Inst Sci, Dept Comp Sci & Appl Math, IL-7610001 Rehovot, Israel.	natiofir@gmail.com; meirav.galun@weizmann.ac.il; sharon.alpert@gmail.com; achibr@gmail.com; boaz.nadler@weizmann.ac.il; ronen.basri@weizmann.ac.il		Nadler, Boaz/0000-0002-9777-4576	Institute for Future Defense Technologies; European Commission [IST-2002-506766]	Institute for Future Defense Technologies; European Commission(European CommissionEuropean Commission Joint Research Centre)	Research was supported in part by the Institute for Future Defense Technologies Research named for the Medvedi, Shwartzman and Gensler Families, and by the European Commission Project IST-2002-506766 Aim Shape. Part of this research was conducted while RB was at TTI-C. At the Weizmann Institute research was conducted at the Moross Laboratory for Vision and Motor Control. We thank Eyal Shimoni and Ziv Reich for the images in Fig. 1 and Ida Rishal and Mike Fainzilber for the images in Fig. 14. We thank Pedro Felzenswalb for sharing his insights with us.	Alpert S, 2010, LECT NOTES COMPUT SC, V6314, P750, DOI 10.1007/978-3-642-15561-1_54; [Anonymous], 2007, COMP VIS 2007 ICCV 2; [Anonymous], [No title captured]; [Anonymous], [No title captured]; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Arbelaez P, 2009, PROC CVPR IEEE, P2294, DOI 10.1109/CVPRW.2009.5206707; Bowyer K, 2001, COMPUT VIS IMAGE UND, V84, P77, DOI 10.1006/cviu.2001.0931; Brandt A, 1999, SIAM J SCI COMPUT, V20, P1417, DOI 10.1137/S1064827595285718; Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chaudhury KN, 2012, IEEE SIGNAL PROC LET, V19, P745, DOI 10.1109/LSP.2012.2217329; Cormen T.H., 2001, INTRO ALGORITHMS, V6; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Desolneux A, 2000, INT J COMPUT VISION, V40, P7, DOI 10.1023/A:1026593302236; Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376; Dollar P., 2006, P IEEE COMP SOC C CO, V2, P1964, DOI DOI 10.1109/CVPR.2006.298; Dollar P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231; Donoho DL, 1999, ANN STAT, V27, P859, DOI 10.1214/aos/1018031261; Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195; Horev I, 2015, SIAM J IMAGING SCI, V8, P458, DOI 10.1137/140970331; Huo X., 2002, LECT NOTES COMPUTATI, P149, DOI DOI 10.1007/978-3-642-56205-1; Isola P, 2014, LECT NOTES COMPUT SC, V8691, P799, DOI 10.1007/978-3-319-10578-9_52; KAKARALA R, 1992, IEEE T PATTERN ANAL, V14, P777, DOI 10.1109/34.142913; Kalitzin SN, 1999, INT J COMPUT VISION, V31, P145, DOI 10.1023/A:1008013815039; Kimmel R, 2000, INT J COMPUT VISION, V39, P111, DOI 10.1023/A:1008171026419; Kimmel R, 2003, INT J COMPUT VISION, V53, P225, DOI 10.1023/A:1023030907417; Korostelev A. P., 1993, MINIMAX THEORY IMAGE; Lebrun M, 2012, ACTA NUMER, V21, P475, DOI 10.1017/S0962492912000062; Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2833, DOI 10.1109/CVPR.2011.5995309; Lindeberg T, 1996, PROC CVPR IEEE, P465, DOI 10.1109/CVPR.1996.517113; Liu C., 2006, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2006.207; Maire M., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587420; Maninis KK, 2016, LECT NOTES COMPUT SC, V9905, P580, DOI 10.1007/978-3-319-46448-0_35; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Nadarajah S, 2008, IEEE T VLSI SYST, V16, P210, DOI 10.1109/TVLSI.2007.912191; Ofir N, 2016, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2016.30; Papari G, 2011, IMAGE VISION COMPUT, V29, P79, DOI 10.1016/j.imavis.2010.08.009; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Ren X., 2012, ADV NEURAL INFORM PR, V1, P584, DOI DOI 10.5555/2999134.2999200; Rishal I, 2013, DEV NEUROBIOL, V73, P247, DOI 10.1002/dneu.22061; Ruzon MA, 2001, IEEE T PATTERN ANAL, V23, P1281, DOI 10.1109/34.969118; Shen W, 2017, IEEE I CONF COMP VIS, P2410, DOI 10.1109/ICCV.2017.262; Shen W, 2015, PROC CVPR IEEE, P3982, DOI 10.1109/CVPR.2015.7299024; Starck JL, 2003, IEEE T IMAGE PROCESS, V12, P706, DOI 10.1109/TIP.2003.813140; Tabb M, 1997, IEEE T IMAGE PROCESS, V6, P642, DOI 10.1109/83.568922; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; van Rijsbergen C., 1979, INFORM RETRIEVAL, V2nd; von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300; Wang RH, 2016, LECT NOTES COMPUT SC, V9719, P12, DOI 10.1007/978-3-319-40663-3_2; Wang YQ, 2017, J MATH IMAGING VIS, V59, P373, DOI 10.1007/s10851-016-0689-x; Weickert J, 1997, LECT NOTES COMPUT SC, V1252, P3; Wiggins, 2008, GESTALT THEORY IMAGE, V34; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Yang JM, 2016, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2016.28	59	14	15	3	36	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2020	42	4					894	908		10.1109/TPAMI.2019.2892134	http://dx.doi.org/10.1109/TPAMI.2019.2892134			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LE2GI	30629496	Green Submitted			2022-12-18	WOS:000526541100008
J	Campbell, D; Petersson, L; Kneip, L; Li, HD				Campbell, Dylan; Petersson, Lars; Kneip, Laurent; Li, Hongdong			Globally-Optimal Inlier Set Maximisation for Camera Pose and Correspondence Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Three-dimensional displays; Robustness; Optimization; Pose estimation; Geometry; Solid modeling; Camera pose estimation; registration; camera calibration; imaging geometry; global optimisation; branch-and-bound	EFFICIENT	Estimating the 6-DoF pose of a camera from a single image relative to a 3D point-set is an important task for many computer vision applications. Perspective-n-point solvers are routinely used for camera pose estimation, but are contingent on the provision of good quality 2D-3D correspondences. However, finding cross-modality correspondences between 2D image points and a 3D point-set is non-trivial, particularly when only geometric information is known. Existing approaches to the simultaneous pose and correspondence problem use local optimisation, and are therefore unlikely to find the optimal solution without a good pose initialisation, or introduce restrictive assumptions. Since a large proportion of outliers and many local optima are common for this problem, we instead propose a robust and globally-optimal inlier set maximisation approach that jointly estimates the optimal camera pose and correspondences. Our approach employs branch-and-bound to search the 6D space of camera poses, guaranteeing global optimality without requiring a pose prior. The geometry of SE(3) is used to find novel upper and lower bounds on the number of inliers and local optimisation is integrated to accelerate convergence. The algorithm outperforms existing approaches on challenging synthetic and real datasets, reliably finding the global optimum, with a GPU implementation greatly reducing runtime.	[Campbell, Dylan; Petersson, Lars; Li, Hongdong] Australian Natl Univ, Canberra, ACT 2600, Australia; [Campbell, Dylan; Petersson, Lars] Data61 CSIRO, Acton, ACT 2601, Australia; [Kneip, Laurent] ShanghaiTech Univ, Shanghai 201210, Peoples R China; [Li, Hongdong] Australian Ctr Robot Vis, Acton, ACT 2601, Australia	Australian National University; Commonwealth Scientific & Industrial Research Organisation (CSIRO); ShanghaiTech University; Australian Centre for Robotic Vision	Campbell, D (corresponding author), Australian Natl Univ, Canberra, ACT 2600, Australia.	dylan.campbell@anu.edu.au; lars.petersson@anu.edu.au; lkneip@shanghaitech.edu.cn; hongdong.li@anu.edu.au		Campbell, Dylan/0000-0002-4717-6850; li, hongdong/0000-0003-4125-1554	ARC Centre of Excellence for Robotic Vision [CE140100016]; Australian Government Research Training Program (RTP) Scholarship	ARC Centre of Excellence for Robotic Vision(Australian Research Council); Australian Government Research Training Program (RTP) Scholarship(Australian GovernmentDepartment of Industry, Innovation and Science)	The authors would like to thank the anonymous reviewers and chairs of ICCV'17 for their careful comments and recommendations which significantly improved the paper. HL is grateful for the support provided by the ARC Centre of Excellence for Robotic Vision (CE140100016). This research is supported by an Australian Government Research Training Program (RTP) Scholarship.	Armeni I., 2017, ARXIV E PRINTS; Ask E, 2013, PROC CVPR IEEE, P1722, DOI 10.1109/CVPR.2013.225; Aubry M, 2014, PROC CVPR IEEE, P3762, DOI 10.1109/CVPR.2014.487; Brachmann E, 2017, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2017.267; Breuel TM, 2003, COMPUT VIS IMAGE UND, V90, P258, DOI 10.1016/S1077-3142(03)00026-2; Brown M, 2015, IEEE I CONF COMP VIS, P2111, DOI 10.1109/ICCV.2015.244; Campbell D, 2017, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2017.10; Campbell D, 2016, PROC CVPR IEEE, P5685, DOI 10.1109/CVPR.2016.613; Cass TA, 1997, INT J COMPUT VISION, V21, P37, DOI 10.1023/A:1007971405872; Chin TJ, 2016, PROC CVPR IEEE, P5858, DOI 10.1109/CVPR.2016.631; Chum O, 2008, IEEE T PATTERN ANAL, V30, P1472, DOI 10.1109/TPAMI.2007.70787; David P, 2004, INT J COMPUT VISION, V59, P259, DOI 10.1023/B:VISI.0000025800.10423.1f; Enqvist O, 2008, LECT NOTES COMPUT SC, V5302, P141, DOI 10.1007/978-3-540-88682-2_12; Enqvist O, 2015, INT J COMPUT VISION, V112, P115, DOI 10.1007/s11263-014-0760-2; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fredriksson J, 2016, PROC CVPR IEEE, P1728, DOI 10.1109/CVPR.2016.191; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Grimson W. E. L., 1990, OBJECT RECOGNITION C; HARALICK RM, 1994, INT J COMPUT VISION, V13, P331, DOI 10.1007/BF02028352; Hartley RI, 2009, INT J COMPUT VISION, V82, P64, DOI 10.1007/s11263-008-0186-9; Hesch JA, 2011, IEEE I CONF COMP VIS, P383, DOI 10.1109/ICCV.2011.6126266; Jurie F, 1999, COMPUT VIS IMAGE UND, V73, P357, DOI 10.1006/cviu.1998.0735; Kendall A, 2017, PROC CVPR IEEE, P6555, DOI 10.1109/CVPR.2017.694; Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336; KIEFER J, 1953, P AM MATH SOC, V4, P502, DOI 10.2307/2032161; Kneip L., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2969, DOI 10.1109/CVPR.2011.5995464; Kneip L, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.16; Kneip L, 2014, IEEE INT CONF ROBOT, P1, DOI 10.1109/ICRA.2014.6906582; LAND AH, 1960, ECONOMETRICA, V28, P497, DOI 10.2307/1910129; Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6; Li YP, 2012, LECT NOTES COMPUT SC, V7572, P15, DOI 10.1007/978-3-642-33718-5_2; Lin WY, 2012, INT J COMPUT VISION, V96, P145, DOI 10.1007/s11263-011-0456-9; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Makadia A, 2007, INT J COMPUT VISION, V75, P311, DOI 10.1007/s11263-007-0035-2; Marchand E, 2016, IEEE T VIS COMPUT GR, V22, P2633, DOI 10.1109/TVCG.2015.2513408; Moreno-Noguer F, 2008, LECT NOTES COMPUT SC, V5303, P405, DOI 10.1007/978-3-540-88688-4_30; Namin ST, 2015, IEEE WINT CONF APPL, P1006, DOI 10.1109/WACV.2015.139; Olson CF, 2001, INT J COMPUT VISION, V45, P39, DOI 10.1023/A:1012317923177; Olson CF, 1997, INT J COMPUT VISION, V23, P131, DOI 10.1023/A:1007906812782; Olsson C, 2006, INT C PATT RECOG, P5; Olsson C, 2009, IEEE T PATTERN ANAL, V31, P783, DOI 10.1109/TPAMI.2008.131; Paudel DP, 2015, IEEE I CONF COMP VIS, P2048, DOI 10.1109/ICCV.2015.237; Sattler T, 2017, IEEE T PATTERN ANAL, V39, P1744, DOI 10.1109/TPAMI.2016.2611662; Sattler T, 2011, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2011.6126302; Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377; Sim Kristy, 2006, IEEE COMP SOC C COMP, P485; Svarm L, 2017, IEEE T PATTERN ANAL, V39, P1455, DOI 10.1109/TPAMI.2016.2598331; Yang JL, 2016, IEEE T PATTERN ANAL, V38, P2241, DOI 10.1109/TPAMI.2015.2513405; Yu L, 2007, IEEE INT C BIOINFORM, P9, DOI 10.1109/BIBM.2007.19; Zeisl B, 2015, IEEE I CONF COMP VIS, P2704, DOI 10.1109/ICCV.2015.310	50	14	14	3	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2020	42	2					328	342		10.1109/TPAMI.2018.2848650	http://dx.doi.org/10.1109/TPAMI.2018.2848650			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KE2KB	29994109				2022-12-18	WOS:000508386100007
J	Chevyrev, I; Nanda, V; Oberhauser, H				Chevyrev, Ilya; Nanda, Vidit; Oberhauser, Harald			Persistence Paths and Signature Features in Topological Data Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Bars; Extraterrestrial measurements; Algebra; Data analysis; Kernel; Topological data analysis; barcodes; signature features; kernel learning	HOMOLOGY	We introduce a new feature map for barcodes as they arise in persistent homology computation. The main idea is to first realize each barcode as a path in a convenient vector space, and to then compute its path signature which takes values in the tensor algebra of that vector space. The composition of these two operations-barcode to path, path to tensor series-results in a feature map that has several desirable properties for statistical learning, such as universality and characteristicness, and achieves state-of-the-art results on common classification benchmarks.	[Chevyrev, Ilya; Nanda, Vidit; Oberhauser, Harald] Univ Oxford, Math Inst, Oxford OX1 2JD, England; [Nanda, Vidit] Inst Adv Study, Sch Math, Princeton, NJ 08540 USA	University of Oxford; Institute for Advanced Study - USA	Chevyrev, I (corresponding author), Univ Oxford, Math Inst, Oxford OX1 2JD, England.	chevyrev@maths.ox.ac.uk; nanda@maths.ox.ac.uk; oberhauser@maths.ox.ac.uk		Chevyrev, Ilya/0000-0002-5630-9694; Nanda, Vidit/0000-0001-9243-6749	Junior Research Fellowship of St John's College, Oxford; Alan Turing Institute under the EPSRC [EP/N510129/1]; Friends of the Institute for Advanced Study; Oxford-Man Institute of Quantitative Finance	Junior Research Fellowship of St John's College, Oxford; Alan Turing Institute under the EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Friends of the Institute for Advanced Study; Oxford-Man Institute of Quantitative Finance	IC is funded by a Junior Research Fellowship of St John's College, Oxford. VN's work is supported by The Alan Turing Institute under the EPSRC grant number EP/N510129/1, and by the Friends of the Institute for Advanced Study. HO is supported by the Oxford-Man Institute of Quantitative Finance. We are grateful to Steve Oudot and Mathieu Carri~ere for generously sharing their data [15] with us.	Adams H, 2017, J MACH LEARN RES, V18; Adcock A, 2016, HOMOL HOMOTOPY APPL, V18, P381, DOI 10.4310/HHA.2016.v18.n1.a21; Boedihardjo H, 2016, ADV MATH, V293, P720, DOI 10.1016/j.aim.2016.02.011; Bubenik P, 2017, J SYMB COMPUT, V78, P91, DOI 10.1016/j.jsc.2016.03.009; Bubenik P, 2015, J MACH LEARN RES, V16, P77; Carriere M, 2017, PR MACH LEARN RES, V70; Cass T, 2016, J MATH SOC JPN, V68, P1505, DOI 10.2969/jmsj/06841505; Chazal F., 2016, STRUCTURE STABILITY; Chevyrev I., 2018, ARXIV E PRINTS; Chevyrev I, 2016, ANN PROBAB, V44, P4049, DOI 10.1214/15-AOP1068; Cohen-Steiner D, 2007, DISCRETE COMPUT GEOM, V37, P103, DOI 10.1007/s00454-006-1276-5; de Silva V, 2007, ALGEBR GEOM TOPOL, V7, P339, DOI 10.2140/agt.2007.7.339; Di Fabio B, 2015, LECT NOTES COMPUT SC, V9279, P294, DOI 10.1007/978-3-319-23231-7_27; FRIZ P. K., 2010, CAMBRIDGE STUD ADV M, V120, DOI 10.1017/CBO9780511845079; Gameiro M, 2015, JPN J IND APPL MATH, V32, P1, DOI 10.1007/s13160-014-0153-5; Ghrist R., 2002, ARXIV160600199V2MATH; Ghrist R, 2008, B AM MATH SOC, V45, P61, DOI 10.1090/s0273-0979-07-01191-3; GROMOV M, 1981, PUBL MATH-PARIS, P53; Hatcher A., 2005, ALGEBRAIC TOPOLOGY; Kahle M, 2014, CONTEMP MATH, V620, P201, DOI 10.1090/conm/620/12367; Kiraly F. J., 2016, 160108169 ARXIV; Lamar-Leon J, 2016, INT C PATT RECOG, P1083, DOI 10.1109/ICPR.2016.7899780; Lyons T. J., 2007, 34 SUMM SCH PROB THE, V1908; Mischaikow K, 2013, DISCRETE COMPUT GEOM, V50, P330, DOI 10.1007/s00454-013-9529-6; Nanda V., 2014, NATURAL COMPUTING SE, VVolume 48, P109; Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Perea JA, 2015, FOUND COMPUT MATH, V15, P799, DOI 10.1007/s10208-014-9206-z; Simon-Gabriel CJ, 2018, J MACH LEARN RES, V19; Sousbie T, 2011, MON NOT R ASTRON SOC, V414, P350, DOI 10.1111/j.1365-2966.2011.18394.x; Turner K, 2014, INF INFERENCE, V3, P310, DOI 10.1093/imaiai/iau011; Xia KL, 2015, J COMPUT CHEM, V36, P408, DOI 10.1002/jcc.23816; Zielinski B., 2018, ARXIV E PRINTS; Zomorodian A, 2005, DISCRETE COMPUT GEOM, V33, P249, DOI 10.1007/s00454-004-1146-y	35	14	14	1	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2020	42	1					192	202		10.1109/TPAMI.2018.2885516	http://dx.doi.org/10.1109/TPAMI.2018.2885516			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JV3VQ	30530312	Green Submitted, Green Accepted			2022-12-18	WOS:000502294300015
J	Tian, FP; Feng, W; Zhang, Q; Wang, XW; Sun, JZ; Loia, V; Liu, ZQ				Tian, Fei-peng; Feng, Wei; Zhang, Qian; Wang, Xiaowei; Sun, JiZhou; Loia, Vincenzo; Liu, Zhi-Qiang			Active Camera Relocalization from a Single Reference Image without Hand-Eye Calibration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cameras; Calibration; Three-dimensional displays; Simultaneous localization and mapping; Robot vision systems; Monitoring; Active camera relocalization (ACR); 6D camera pose; hand-eye calibration free; computational rephotography; fine-grained change monitoring; cultural heritage; preventive conservation		This paper studies active relocalization of 6D camera pose from a single reference image, a new and challenging problem in computer vision and robotics. Straightforward active camera relocalization (ACR) is a tricky and expensive task that requires elaborate hand-eye calibration on precision robotic platforms. In this paper, we show that high-quality camera relocalization can be achieved in an active and much easier way. We propose a hand-eye calibration free approach to actively relocating the camera to the same 6D pose that produces the input reference image. We theoretically prove that, given bounded unknown hand-eye pose displacement, this approach is able to rapidly reduce both 3D relative rotational and translational pose between current camera and the reference one to an identical matrix and a zero vector, respectively. Based on these findings, we develop an effective ACR algorithm with fast convergence rate, reliable accuracy and robustness. Extensive experiments validate the effectiveness and feasibility of our approach on both laboratory tests and challenging real-world applications in fine-grained change monitoring of cultural heritages.	[Tian, Fei-peng; Feng, Wei; Zhang, Qian; Sun, JiZhou] Tianjin Univ, Coll Intelligence & Comp, Sch Comp Sci & Technol, Tianjin 300350, Peoples R China; [Tian, Fei-peng; Feng, Wei; Zhang, Qian; Sun, JiZhou] State Adm Cultural Heritage, Key Res Ctr Surface Monitoring & Anal Cultural Re, Beijing, Peoples R China; [Wang, Xiaowei] Dunhuang Res Acad, Dunhuang, Gansu, Peoples R China; [Loia, Vincenzo; Liu, Zhi-Qiang] Univ Salerno, Dept Management & Innovat Syst, I-84084 Fisciano, SA, Italy	Tianjin University; University of Salerno	Feng, W (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Sch Comp Sci & Technol, Tianjin 300350, Peoples R China.; Feng, W (corresponding author), State Adm Cultural Heritage, Key Res Ctr Surface Monitoring & Anal Cultural Re, Beijing, Peoples R China.	tianfeipeng@tju.edu.cn; wfeng@ieee.org; zhangqian91@tju.edu.cn; wangxw@dha.ac.cn; jzsun@tju.edu.cn; loia@unisa.it; mcgliu@gmail.com			National Science and Technology Support Project [2013BAK01B01]; National Natural Science Foundation of China [61671325, 61572354]	National Science and Technology Support Project; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The authors thank all reviewers and the associate editor for their valuable comments to polish this paper. We thank Xudong Wang, Bomin Su, Mingming Wang, Gangquan Chen, Qinglin Guo, Bolong Chai, Shujun Ding, Shengli Sun of Dunhuang Academy China for valuable discussions on slowand-minute change monitoring of ancient murals. We thank Jiliang Sun, Jiawan Zhang, Qifeng Yue, Nan Zhang, Rui Huang, Yifeng Zhang, Dongrui Xiao, Dongxu Miao for their contributions to our platform development and onsite data collection. This work was supported by the National Science and Technology Support Project under grant 2013BAK01B01 and National Natural Science Foundation of China under Grant 61671325 and 61572354. F.-P. Tian and W. Feng are the joint first authors, who contribute equally to this work.	Agarwal S, 2011, COMMUN ACM, V54, P105, DOI 10.1145/2001269.2001293; Allibert G, 2010, IEEE T ROBOT, V26, P933, DOI 10.1109/TRO.2010.2056590; Altmann S. L., 1986, ROTATIONS QUATERNION; Bae S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805968; Birch Tony, 2017, HUMANITIES ENV INTEG, P195; Engel J, 2015, IEEE INT C INT ROBOT, P1935, DOI 10.1109/IROS.2015.7353631; Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54; Feng W, 2008, IEEE T IMAGE PROCESS, V17, P2413, DOI 10.1109/TIP.2008.2006435; Feng W, 2016, PROC CVPR IEEE, P4049, DOI 10.1109/CVPR.2016.439; Feng W, 2015, IEEE I CONF COMP VIS, P1260, DOI 10.1109/ICCV.2015.149; Feng W, 2010, IEEE T PATTERN ANAL, V32, P1871, DOI 10.1109/TPAMI.2010.24; Guo Q, 2018, NEUROCOMPUTING, V275, P2307, DOI 10.1016/j.neucom.2017.11.003; Guzman-Rivera A, 2014, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2014.146; Hartley R, 2013, INT J COMPUT VISION, V103, P267, DOI 10.1007/s11263-012-0601-0; Hartley RI, 2009, INT J COMPUT VISION, V82, P64, DOI 10.1007/s11263-008-0186-9; Heller J, 2016, IEEE T PATTERN ANAL, V38, P1027, DOI 10.1109/TPAMI.2015.2469299; Heller J, 2012, PROC CVPR IEEE, P1608, DOI 10.1109/CVPR.2012.6247853; Jiang NJ, 2013, IEEE I CONF COMP VIS, P481, DOI 10.1109/ICCV.2013.66; Kendall A, 2016, IEEE INT CONF ROBOT, P4762, DOI 10.1109/ICRA.2016.7487679; Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336; Lee KT, 2011, COMPUT GRAPH FORUM, V30, P1895, DOI 10.1111/j.1467-8659.2011.02042.x; Li L, 2013, PROC CVPR IEEE, P3174, DOI 10.1109/CVPR.2013.408; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Malis E, 1999, IEEE T ROBOTIC AUTOM, V15, P238, DOI 10.1109/70.760345; Mariottini GL, 2007, IEEE T ROBOT, V23, P87, DOI 10.1109/TRO.2006.886842; Meng C., 2018, P 9 INT C BRAIN INSP, P195; Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103; Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671; Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; Park DH, 2012, IEEE T IND ELECTRON, V59, P4735, DOI 10.1109/TIE.2011.2179270; Pfeiffer Mark, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1527, DOI 10.1109/ICRA.2017.7989182; Qiu WC, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1221, DOI 10.1145/3123266.3129396; Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544; Ruland T, 2012, PROC CVPR IEEE, P1035, DOI 10.1109/CVPR.2012.6247781; Sattler T, 2016, PROC CVPR IEEE, P1582, DOI 10.1109/CVPR.2016.175; Shi Y., 2018, P IEEE INT C MULT EX; Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377; Staniforth S., 2013, HIST PERSPECTIVES PR; Wells J., 2012, THESIS; West R., 2013, ACM SIGGRAPH STUDIO; Wilson WJ, 1996, IEEE T ROBOTIC AUTOM, V12, P684, DOI 10.1109/70.538974; Zamir AR, 2014, IEEE T PATTERN ANAL, V36, P1546, DOI 10.1109/TPAMI.2014.2299799; Zamir AR, 2010, LECT NOTES COMPUT SC, V6314, P255, DOI 10.1007/978-3-642-15561-1_19; Zhang Q, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4972; Zhang S., 2014, P IEEE INT C MULT EX, P1; Zhang XB, 2011, IEEE T ROBOT, V27, P1167, DOI 10.1109/TRO.2011.2162765; Zhao Q, 2015, INT J COMPUT VISION, V113, P143, DOI 10.1007/s11263-014-0787-4	48	14	15	6	50	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2019	41	12					2791	2806		10.1109/TPAMI.2018.2870646	http://dx.doi.org/10.1109/TPAMI.2018.2870646			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JQ0XI	31689178				2022-12-18	WOS:000498677600001
J	Bailer, C; Taetz, B; Stricker, D				Bailer, Christian; Taetz, Bertram; Stricker, Didier			Flow Fields: Dense Correspondence Fields for Highly Accurate Large Displacement Optical Flow Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Optical flow; dense matching; correspondence fields	PATCHMATCH	Modern large displacement optical flow algorithms usually use an initialization by either sparse descriptor matching techniques or dense approximate nearest neighbor fields. While the latter have the advantage of being dense, they have the major disadvantage of being very outlier-prone as they are not designed to find the optical flow, but the visually most similar correspondence. In this article we present a dense correspondence field approach that is much less outlier-prone and thus much better suited for optical flow estimation than approximate nearest neighbor fields. Our approach does not require explicit regularization, smoothing (like median filtering) or a new data term. Instead we solely rely on patch matching techniques and a novel multi-scale matching strategy. We also present enhancements for outlier filtering. We show that our approach is better suited for large displacement optical flow estimation than modern descriptor matching techniques. We do so by initializing EpicFlow with our approach instead of their originally used state-of-the-art descriptor matching technique. We significantly outperform the original EpicFlow on MPI-Sintel, KITTI 2012, KITTI 2015 and Middlebury. In this extended article of our former conference publication we further improve our approach in matching accuracy as well as runtime and present more experiments and insights.	[Bailer, Christian; Taetz, Bertram; Stricker, Didier] German Res Ctr Artificial Intelligence, Dept Augmented Vis, D-67663 Kaiserslautern, Germany; [Taetz, Bertram] Univ Kaiserslautern, Dept Comp Sci, D-67663 Kaiserslautern, Germany; [Stricker, Didier] Univ Kaiserslautern, D-67663 Kaiserslautern, Germany	University of Kaiserslautern; University of Kaiserslautern	Bailer, C (corresponding author), German Res Ctr Artificial Intelligence, Dept Augmented Vis, D-67663 Kaiserslautern, Germany.	christian.bailer@dfki.de; bertram.taetz@dfki.de; didier.stricker@dfki.de			BMBF projects DYNAMICS	BMBF projects DYNAMICS	This work was partially funded by the BMBF projects DYNAMICS and VIDETE.	Bai M, 2016, LECT NOTES COMPUT SC, V9910, P154, DOI 10.1007/978-3-319-46466-4_10; Bailer C, 2017, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2017.290; Bailer C, 2015, IEEE I CONF COMP VIS, P4015, DOI 10.1109/ICCV.2015.457; Bailer C, 2012, LECT NOTES COMPUT SC, V7574, P398, DOI 10.1007/978-3-642-33712-3_29; Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2; Bao LC, 2014, PROC CVPR IEEE, P3534, DOI 10.1109/CVPR.2014.452; Barnes C, 2010, LECT NOTES COMPUT SC, V6313, P29; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44; Chen ZY, 2013, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR.2013.316; DUCHON CE, 1979, J APPL METEOROL, V18, P1016, DOI 10.1175/1520-0450(1979)018<1016:LFIOAT>2.0.CO;2; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Gadot D, 2016, PROC CVPR IEEE, P4236, DOI 10.1109/CVPR.2016.459; Geiger A., 2013, INT J ROBOT RES; Goesele M, 2007, IEEE I CONF COMP VIS, P825, DOI 10.1109/iccv.2007.4408933; HaCohen Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964965; He KM, 2012, PROC CVPR IEEE, P111, DOI 10.1109/CVPR.2012.6247665; Hel-Or Y, 2005, IEEE T PATTERN ANAL, V27, P1430, DOI 10.1109/TPAMI.2005.184; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Hu YL, 2016, PROC CVPR IEEE, P5704, DOI 10.1109/CVPR.2016.615; Hur Junhwa, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P163, DOI 10.1007/978-3-319-46604-0_12; Jith OU Nirmal, 2014, ACOUSTICS SPEECH SIG, P673; Kennedy R, 2015, LECT NOTES COMPUT SC, V8932, P364, DOI 10.1007/978-3-319-14612-6_27; Korman S, 2011, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2011.6126421; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu JB, 2013, PROC CVPR IEEE, P1854, DOI 10.1109/CVPR.2013.242; Menze M., 2015, P COMP VIS PATT REC; Revaud J, 2015, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR.2015.7298720; Sevilla-Lara L, 2016, PROC CVPR IEEE, P3889, DOI 10.1109/CVPR.2016.422; Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939; Timofte R, 2015, IEEE WINT CONF APPL, P1100, DOI 10.1109/WACV.2015.151; Vogel C, 2013, LECT NOTES COMPUT SC, V8142, P343, DOI 10.1007/978-3-642-40602-7_37; Wedel A, 2009, IEEE I CONF COMP VIS, P1663, DOI 10.1109/ICCV.2009.5459375; Weinzaepfel P., 2013, P IEEE INT C COMP VI; Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345	39	14	14	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2019	41	8					1879	1892		10.1109/TPAMI.2018.2859970	http://dx.doi.org/10.1109/TPAMI.2018.2859970			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IG2BD	30106705	Bronze, Green Submitted			2022-12-18	WOS:000473598800007
J	Chhatkuli, A; Pizarro, D; Collins, T; Bartoli, A				Chhatkuli, Ajad; Pizarro, Daniel; Collins, Toby; Bartoli, Adrien			Inextensible Non-Rigid Structure-from-Motion by Second-Order Cone Programming	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Non-Rigid Structure-from-Motion; 3D reconstruction; maximum depth heuristic	SURFACE DETECTION; 3D SHAPE; TEMPLATE	We present a global and convex formulation for the template-less 3D reconstruction of a deforming object with the perspective camera. We show for the first time how to construct a Second-Order Cone Programming (SOCP) problem for Non-Rigid Structure-from-Motion (NRSfM) using the Maximum-Depth Heuristic (MDH). In this regard, we deviate strongly from the general trend of using affine cameras and factorization-based methods to solve NRSfM, which do not perform well with complex nonlinear deformations. In MDH, the points' depths are maximized so that the distance between neighbouring points in camera space are upper bounded by the geodesic distance. In NRSfM both geodesic and camera space distances are unknown. We show that, nonetheless, given point correspondences and the camera's intrinsics the whole problem can be solved with SOCP. This is the first convex formulation for NRSfM with physical constraints. We further present how robustness and temporal continuity can be included in the formulation to handle outliers and decrease the problem size, respectively. We show with extensive experiments that our methods accurately reconstruct quasi-isometric objects from partial views under articulated and strong deformations. Compared to the previous methods, our approach gives better or similar accuracy. It naturally handles missing correspondences, non-smooth objects and is very simple to implement compared to previous methods, with only one free parameter (the neighbourhood size).	[Chhatkuli, Ajad; Pizarro, Daniel; Collins, Toby; Bartoli, Adrien] Univ Clermont Auvergne, CNRS, Inst Pascal, F-63000 Clermont Ferrand, France; [Pizarro, Daniel] Univ Alcala, GEINTRA, Alcala De Henares 28801, Spain	Centre National de la Recherche Scientifique (CNRS); Universite Clermont Auvergne (UCA); Universidad de Alcala	Chhatkuli, A (corresponding author), Univ Clermont Auvergne, CNRS, Inst Pascal, F-63000 Clermont Ferrand, France.	ajad.chhatkuli@gmail.com; Dani.Pizarro@gmail.com; Toby.Collins@gmail.com; adrien.bartoli@gmail.com	Collins, Toby/Q-8967-2019	Collins, Toby/0000-0002-9441-8306; Pizarro, Daniel/0000-0003-0622-4884	EUs FP7 through the ERC research grant [307483 FLEXABLE]; Project ARTEMISA - Spanish Ministry of Economy, Industry and Competitiveness [TIN2016-80939-R]; Almerys Corporation	EUs FP7 through the ERC research grant; Project ARTEMISA - Spanish Ministry of Economy, Industry and Competitiveness; Almerys Corporation	This research has received funding from the EUs FP7 through the ERC research grant 307483 FLEXABLE. The work has also been supported by Project ARTEMISA (TIN2016-80939-R) funded by the Spanish Ministry of Economy, Industry and Competitiveness. The work is further supported by Almerys Corporation.	Agudo A, 2015, PROC CVPR IEEE, P2179, DOI 10.1109/CVPR.2015.7298830; Agudo A, 2014, PROC CVPR IEEE, P1558, DOI 10.1109/CVPR.2014.202; ApS M., 2015, MOSEK OPTIMIZATION T; Bartoli A, 2015, IEEE T PATTERN ANAL, V37, P2099, DOI 10.1109/TPAMI.2015.2392759; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Brunet F., 2010, THESIS U AUVERGNE CL; Chhatkuli A., 2014, P BRIT MACH VIS C; Chhatkuli A, 2017, IEEE T PATTERN ANAL, V39, P833, DOI 10.1109/TPAMI.2016.2562622; Chhatkuli A, 2016, PROC CVPR IEEE, P1719, DOI 10.1109/CVPR.2016.190; Chhatkuli A, 2014, PROC CVPR IEEE, P708, DOI 10.1109/CVPR.2014.96; Collins T., 2010, P INT WORKSHOP VISIO, P339; Dai YC, 2012, PROC CVPR IEEE, P2018, DOI 10.1109/CVPR.2012.6247905; Ngo DT, 2016, IEEE T PATTERN ANAL, V38, P172, DOI 10.1109/TPAMI.2015.2435739; Del Bue A, 2008, P IEEE C COMP VIS PA, P1; Garg R, 2013, PROC CVPR IEEE, P1272, DOI 10.1109/CVPR.2013.168; Gotardo PFU, 2011, IEEE I CONF COMP VIS, P802, DOI 10.1109/ICCV.2011.6126319; Gotardo PFU, 2011, IEEE T PATTERN ANAL, V33, P2051, DOI 10.1109/TPAMI.2011.50; Hartley R, 2008, LECT NOTES COMPUT SC, V5302, P276, DOI 10.1007/978-3-540-88682-2_22; Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271; Jensen R, 2014, PROC CVPR IEEE, P406, DOI 10.1109/CVPR.2014.59; Li HD, 2010, PROC CVPR IEEE, P2777, DOI 10.1109/CVPR.2010.5540005; Lofberg J., 2004, OPTIM, P284, DOI DOI 10.1109/CACSD.2004.1393890; Parashar S, 2016, PROC CVPR IEEE, P4679, DOI 10.1109/CVPR.2016.506; Perriollat M., 2008, P BRIT MACH VIS C; Perriollat M, 2011, INT J COMPUT VISION, V95, P124, DOI 10.1007/s11263-010-0352-8; Pilet J, 2008, INT J COMPUT VISION, V76, P109, DOI 10.1007/s11263-006-0017-9; Pizarro D, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.104; Pizarro D, 2012, INT J COMPUT VISION, V97, P54, DOI 10.1007/s11263-011-0452-0; Russell C, 2014, LECT NOTES COMPUT SC, V8695, P583, DOI 10.1007/978-3-319-10584-0_38; Salzmann M, 2007, IEEE I CONF COMP VIS, P1578; Salzmann M, 2011, IEEE T PATTERN ANAL, V33, P931, DOI 10.1109/TPAMI.2010.158; Salzmann M, 2009, PROC CVPR IEEE, P1054, DOI 10.1109/CVPRW.2009.5206759; Sundaram N, 2010, LECT NOTES COMPUT SC, V6311, P438, DOI 10.1007/978-3-642-15549-9_32; Tao LL, 2013, PROC CVPR IEEE, P1530, DOI 10.1109/CVPR.2013.201; TAYLOR J, 2010, PROC CVPR IEEE, P2761, DOI DOI 10.1109/CVPR.2010.5540002; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Varol A, 2012, PROC CVPR IEEE, P2248, DOI 10.1109/CVPR.2012.6247934; Varol A, 2009, IEEE I CONF COMP VIS, P1811, DOI 10.1109/ICCV.2009.5459403; Vicente S, 2012, LECT NOTES COMPUT SC, V7574, P426, DOI 10.1007/978-3-642-33712-3_31; Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175; White R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239485; Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25; Xiang Lingzhu, 2008, LIBFREENECT2 RELEASE, DOI [10.5281/zenodo.50641, DOI 10.5281/ZENODO.50641]	43	14	14	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2018	40	10					2428	2441		10.1109/TPAMI.2017.2762669	http://dx.doi.org/10.1109/TPAMI.2017.2762669			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GS7IZ	29035210				2022-12-18	WOS:000443875500011
J	Sourati, J; Akcakaya, M; Erdogmus, D; Leen, TK; Dy, JG				Sourati, Jamshid; Akcakaya, Murat; Erdogmus, Deniz; Leen, Todd K.; Dy, Jennifer G.			Probabilistic Active Learning Algorithm Based on Fisher Information Ratio	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Active learning; fisher information; discriminative classification; probabilistic querying		The task of labeling samples is demanding and expensive. Active learning aims to generate the smallest possible training data set that results in a classifier with high performance in the test phase. It usually consists of two steps of selecting a set of queries and requesting their labels. Among the suggested objectives to score the query sets, information theoretic measures have become very popular. Yet among them, those based on Fisher information (FI) have the advantage of considering the diversity among the queries and tractable computations. In this work, we provide a practical algorithm based on Fisher information ratio to obtain query distribution for a general framework where, in contrast to the previous FI-based querying methods, we make no assumptions over the test distribution. The empirical results on synthetic and real-world data sets indicate that this algorithm gives competitive results.	[Sourati, Jamshid; Erdogmus, Deniz; Dy, Jennifer G.] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA; [Akcakaya, Murat] Univ Pittsburgh, Dept Elect & Comp Engn, Pittsburgh, PA 15261 USA; [Leen, Todd K.] Georgetown Univ, Grad Sch Arts & Sci, Washington, DC 20057 USA	Northeastern University; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Georgetown University	Sourati, J (corresponding author), Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.	sourati@ece.neu.edu; akcakaya@pitt.edu; erdogmus@ece.neu.edu; todd.leen@georgetown.edu; jdy@ece.neu.edu		Sourati, Jamshid/0000-0002-4893-2793	NSF [IIS-1118061, IIS-1149570, CNS-1136027, SMA-0835976, 1258633, 1355603, 1454956, IIS 0915910]; Air Force Office of Scientific Research (AFOSR) [FA9550-16-1-0386]; NIH [R01HL089856]; Direct For Computer & Info Scie & Enginr [1736497] Funding Source: National Science Foundation	NSF(National Science Foundation (NSF)); Air Force Office of Scientific Research (AFOSR)(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Direct For Computer & Info Scie & Enginr(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This work is primarily supported by NSF IIS-1118061. In addition, Murat Akcakaya was supported by the Air Force Office of Scientific Research (AFOSR) under award number FA9550-16-1-0386; Deniz Erdogmus was supported by NSF IIS-1149570, CNS-1136027 and SMA-0835976; Todd Leen was supported under NSF 1258633, 1355603, and 1454956; and Jennifer Dy was also supported by NSF IIS 0915910 and NIH R01HL089856.	Angluin D., 1988, Machine Learning, V2, P319, DOI 10.1023/A:1022821128753; Azimi J., 2012, P 29 INT C MACH LEAR, P1; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Chaudhuri Kamalika, 2015, ADV NEURAL INFORM PR, P1090; Cohn D.A., 1994, ADV NEURAL INFORM PR, V6, P679, DOI DOI 10.1016/j.jspi.2009.08.006; Dasgupta S, 2005, LECT NOTES COMPUT SC, V3559, P249, DOI 10.1007/11503415_17; Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534; Fu YF, 2013, KNOWL INF SYST, V35, P249, DOI 10.1007/s10115-012-0507-8; Fukumizu K, 2000, IEEE T NEURAL NETWOR, V11, P17, DOI 10.1109/72.822506; Grant M., 2013, CVX MATLAB SOFTWARE; Grant MC, 2008, LECT NOTES CONTR INF, V371, P95, DOI 10.1007/978-1-84800-155-8_7; Gu Q., 2014, URBANA, V51; Guo Y, 2010, ADV NEURAL INFORM PR, P802; Guo YH, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P823; Guo Yuhong, 2008, ADV NEURAL INFORM PR, V20, P593; Hoi SCH, 2006, P 23 INT C MACH LEAR, V148, P417, DOI [10.1145/1143844.1143897, DOI 10.1145/1143844.1143897]; Hoi SCH, 2009, IEEE T KNOWL DATA EN, V21, P1233, DOI 10.1109/TKDE.2009.60; Holub A, 2008, PROC CVPR IEEE, P885; Krause A, 2008, J MACH LEARN RES, V9, P235; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lehmann E. L., 1998, THEORY POINT ESTIMAT, V31; Settles B., 2008, ADV NEURAL INFORM PR, V20, P1289; Settles B., 2012, SYNTHESIS LECT ARTIF, V6, P1, DOI [10.2200/s00429ed1v01y201207aim018, DOI 10.2200/S00429ED1V01Y201207AIM018]; Settles B, 2008, P 2008 C EMP METH NA, ppp1070, DOI DOI 10.3115/1613715.1613855; Sourati J, 2017, J MACH LEARN RES, V18; Sourati J, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18020051; Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243; Vandenberghe L, 1996, SIAM REV, V38, P49, DOI 10.1137/1038003; Wang Z, 2015, ACM T KNOWL DISCOV D, V9, DOI 10.1145/2700408; Wei K, 2015, PR MACH LEARN RES, V37, P1954; Welling M., 2014, ADV NEURAL INFORM PR, V27; Zhang Tong, 2000, P 17 INT C MACHINE L, P1191	32	14	14	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2018	40	8					2023	2029		10.1109/TPAMI.2017.2743707	http://dx.doi.org/10.1109/TPAMI.2017.2743707			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GL6DT	28858784	hybrid			2022-12-18	WOS:000437271100017
J	Liang, XD; Wei, YC; Lin, L; Chen, YP; Shen, XH; Yang, JC; Yan, SC				Liang, Xiaodan; Wei, Yunchao; Lin, Liang; Chen, Yunpeng; Shen, Xiaohui; Yang, Jianchao; Yan, Shuicheng			Learning to Segment Human by Watching YouTube	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Human segmentation; weakly-supervised learning; incremental learning; convolutional neural network		An intuition on human segmentation is that when a human is moving in a video, the video-context (e.g., appearance and motion clues) may potentially infer reasonable mask information for the whole human body. Inspired by this, based on popular deep convolutional neural networks (CNN), we explore a veryweakly supervised learning framework for human segmentation task, where only an imperfect human detector is available along with massive weakly-labeled YouTube videos. In our solution, the video-context guided human mask inference and CNN based segmentation network learning iterate to mutually enhance each other until no further improvement gains. In the first step, each video is decomposed into supervoxels by the unsupervised video segmentation. The superpixels within the supervoxels are then classified as human or non-human by graph optimization with unary energies from the imperfect human detection results and the predicted confidence maps by the CNN trained in the previous iteration. In the second step, the video-context derived human masks are used as direct labels to train CNN. Extensive experiments on the challenging PASCAL VOC 2012 semantic segmentation benchmark demonstrate that the proposed framework has already achieved superior results than all previous weakly-supervised methods with object class or bounding box annotations. In addition, by augmenting with the annotated masks from PASCAL VOC 2012, our method reaches a new state-ofthe- art performance on the human segmentation task.	[Liang, Xiaodan; Lin, Liang] Sun Yat Sen Univ, Guangzhou 510006, Guangdong, Peoples R China; [Liang, Xiaodan; Lin, Liang] Minist Educ, Engn Res Ctr Adv Comp Engn Software, Beijing, Peoples R China; [Shen, Xiaohui] Adobe Res, San Jose, CA 95110 USA; [Yang, Jianchao] SnapChat Inc, Venice, CA 90291 USA; [Wei, Yunchao; Chen, Yunpeng; Yan, Shuicheng] Natl Univ Singapore, Singapore 119077, Singapore; [Yan, Shuicheng] 360 AI Inst, Singapore 119077, Singapore	Sun Yat Sen University; Adobe Systems Inc.; National University of Singapore	Liang, XD (corresponding author), Sun Yat Sen Univ, Guangzhou 510006, Guangdong, Peoples R China.	xdliang328@gmail.com; wychao1987@gmail.com; linliang@ieee.org; chenyunpeng@u.nus.edu; xshen@adobe.com; jcyangenator@gmail.com; eleyans@nus.edu.sg	Yan, Shuicheng/HCI-1431-2022	Chen, Yunpeng/0000-0002-9830-8980; Liang, Lin/0000-0003-2248-3755	State Key Development Program [2016YFB1001000]; National Natural Science Foundation of China [61622214]; CCF-Tencent Open Fund	State Key Development Program; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); CCF-Tencent Open Fund	This work was in part supported by State Key Development Program under Grant NO. 2016YFB1001000, in part by the National Natural Science Foundation of China under Grant NO. 61622214, and sponsored by CCF-Tencent Open Fund. This work was partially performed when Xiaodan Liang was visiting National University of Singapore. Liang Lin is the corresponding author.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Chen L.- C., 2014, P INT C LEARN REPR; Chen TS, 2016, IEEE T NEUR NET LEAR, V27, P1135, DOI 10.1109/TNNLS.2015.2506664; Chen XL, 2013, IEEE I CONF COMP VIS, P1409, DOI 10.1109/ICCV.2013.178; Choi J, 2013, PROC CVPR IEEE, P875, DOI 10.1109/CVPR.2013.118; Dai JF, 2015, IEEE I CONF COMP VIS, P1635, DOI 10.1109/ICCV.2015.191; Dai JF, 2015, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR.2015.7299025; Divvala SK, 2014, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2014.412; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Guillaumin M, 2014, INT J COMPUT VISION, V110, P328, DOI 10.1007/s11263-014-0713-9; Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; Jain SD, 2014, LECT NOTES COMPUT SC, V8692, P656, DOI 10.1007/978-3-319-10593-2_43; Joulin A, 2014, LECT NOTES COMPUT SC, V8694, P253, DOI 10.1007/978-3-319-10599-4_17; Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Li CL, 2016, IEEE T IMAGE PROCESS, V25, P1947, DOI 10.1109/TIP.2016.2537211; Liang XD, 2015, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2015.120; Lin GS, 2016, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2016.348; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Mostajahi M, 2015, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2015.7298959; Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203; Pont-Tuset J, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481406; Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065; Russakovsky O, 2015, PROC CVPR IEEE, P2121, DOI 10.1109/CVPR.2015.7298824; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Shrivastava A, 2012, LECT NOTES COMPUT SC, V7574, P369, DOI 10.1007/978-3-642-33712-3_27; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tang K., 2014, P IEEE C COMP VIS PA, P991; Tang K, 2013, PROC CVPR IEEE, P2483, DOI 10.1109/CVPR.2013.321; Wang KZ, 2017, IEEE T CIRC SYST VID, V27, P2591, DOI 10.1109/TCSVT.2016.2589879; Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320; Xu CL, 2012, LECT NOTES COMPUT SC, V7577, P626, DOI 10.1007/978-3-642-33783-3_45; Xu J, 2015, PROC CVPR IEEE, P3781, DOI 10.1109/CVPR.2015.7299002; Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87; Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315; Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179	38	14	14	0	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2017	39	7					1462	1468		10.1109/TPAMI.2016.2598340	http://dx.doi.org/10.1109/TPAMI.2016.2598340			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EW8BZ	27514037	Green Submitted			2022-12-18	WOS:000402744400015
J	Chin, TJ; Purkait, P; Eriksson, A; Suter, D				Chin, Tat-Jun; Purkait, Pulak; Eriksson, Anders; Suter, David			Efficient Globally Optimal Consensus Maximisation with Tree Search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Robust regression; global optimisation; graph and tree search strategies	OPTIMIZATION; ALGORITHMS; GEOMETRY	Maximum consensus is one of the most popular criteria for robust estimation in computer vision. Despite its widespread use, optimising the criterion is still customarily done by randomised sample-and-test techniques, which do not guarantee optimality of the result. Several globally optimal algorithms exist, but they are too slow to challenge the dominance of randomised methods. Our work aims to change this state of affairs by proposing an efficient algorithm for global maximisation of consensus. Under the framework of LP-type methods, we show how consensus maximisation for a wide variety of vision tasks can be posed as a tree search problem. This insight leads to a novel algorithm based on A* search. We propose efficient heuristic and support set updating routines that enable A* search to efficiently find globally optimal results. On common estimation problems, our algorithm is much faster than previous exact methods. Our work identifies a promising direction for globally optimal consensus maximisation.	[Chin, Tat-Jun; Purkait, Pulak; Suter, David] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Eriksson, Anders] Queensland Univ Technol, Sch Elect Engn & Comp Sci, Brisbane, Qld 4000, Australia	University of Adelaide; Queensland University of Technology (QUT)	Chin, TJ (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.	tat-jun.chin@adelaide.edu.au; pulak.purkait@adelaide.edu.au; anders.eriksson@qut.edu.au; dsuter@cs.adelaide.edu.au		Suter, David/0000-0001-6306-3023; Eriksson, Anders/0000-0003-2652-7110	ARC grants [DP130102524, DE130101775, DP160103490]	ARC grants(Australian Research Council)	The authors gratefully acknowledge the support by ARC grants DP130102524, DE130101775 and DP160103490.	Agarwal S, 2008, PROC CVPR IEEE, P2894, DOI 10.1109/CVPR.2008.4587713; Amenta N, 1997, PROCEEDINGS OF THE EIGHTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P528; [Anonymous], GRAPH THEORY COMBINA; Aronov B, 2008, SIAM J COMPUT, V38, P899, DOI 10.1137/060669474; AVIS D, 1990, DISCRETE APPL MATH, V27, P39, DOI 10.1016/0166-218X(90)90127-X; Bazin JC, 2014, LECT NOTES COMPUT SC, V8690, P803, DOI 10.1007/978-3-319-10605-2_52; Ben-David S., 2000, P ANN C COMP LEARN T; Ben-David S., 2000, P 13 ANN C COMP LEAR, P255; Breuel T. M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P445, DOI 10.1109/CVPR.1992.223152; Bustos AP, 2014, PROC CVPR IEEE, P3930, DOI 10.1109/CVPR.2014.502; CHAZELLE B, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P281; CHENEY E. W, 1982, INTRO APPROXIMATION, V2nd; Chin TJ, 2015, PROC CVPR IEEE, P2413, DOI 10.1109/CVPR.2015.7298855; Enqvist O, 2015, INT J COMPUT VISION, V112, P115, DOI 10.1007/s11263-014-0760-2; Enqvist O, 2012, LECT NOTES COMPUT SC, V7572, P738, DOI 10.1007/978-3-642-33718-5_53; Eppstein D., 2005, COMBINATORIAL COMPUT, V52, P287; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136; Hartley R., 2004, ROBOTICA; Johnson D. S., 1978, Theoretical Computer Science, V6, P93, DOI 10.1016/0304-3975(78)90006-3; Kahl F, 2008, IEEE T PATTERN ANAL, V30, P1603, DOI 10.1109/TPAMI.2007.70824; Ke QF, 2005, IEEE I CONF COMP VIS, P986; Li HD, 2009, IEEE I CONF COMP VIS, P1074, DOI 10.1109/ICCV.2009.5459398; Matousek J, 1996, ALGORITHMICA, V16, P498, DOI 10.1007/BF01940877; MATOUSEK J, 1995, DISCRETE COMPUT GEOM, V14, P365, DOI 10.1007/BF02570713; Olsson C, 2008, PROC CVPR IEEE, P3230; Olsson C, 2007, IEEE I CONF COMP VIS, P2025; Olsson C, 2010, PROC CVPR IEEE, P1450, DOI 10.1109/CVPR.2010.5539800; Pearl J., 1984, INTELLIGENT SEARCH S; Seo Y., 2007, P S CRYPT INF SEC, P1; Sharir M., 1992, P 9 ANN S THEORETICA, P567; Sim Kristy, 2006, IEEE COMP SOC C COMP, P485; STROMBERG AJ, 1993, SIAM J SCI COMPUT, V14, P1289, DOI 10.1137/0914076; Yang JL, 2014, LECT NOTES COMPUT SC, V8689, P111, DOI 10.1007/978-3-319-10590-1_8; Yinqiang Zheng, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1825, DOI 10.1109/CVPR.2011.5995640; Yu J, 2011, IEEE I CONF COMP VIS, P399; Yu L, 2007, IEEE INT C BIOINFORM, P9, DOI 10.1109/BIBM.2007.19	37	14	14	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2017	39	4					758	772		10.1109/TPAMI.2016.2631531	http://dx.doi.org/10.1109/TPAMI.2016.2631531			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EP9UD	27893383				2022-12-18	WOS:000397717600012
J	Yu, X; Huang, JZ; Zhang, ST; Metaxas, DN				Yu, Xiang; Huang, Junzhou; Zhang, Shaoting; Metaxas, Dimitris N.			Face Landmark Fitting via Optimized Part Mixtures and Cascaded Deformable Model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face landmark localization; face tracking; deformable shape model; part based model	FACIAL EXPRESSION; RECOGNITION	This paper addresses the problem of facial landmark localization and tracking from a single camera. We present a two-stage cascaded deformable shape model to effectively and efficiently localize facial landmarks with large head pose variations. In initialization stage, we propose a group sparse optimized mixture model to automatically select the most salient facial landmarks. By introducing 3D face shape model, we apply procrustes analysis to provide pose-aware landmark initialization. In landmark localization stage, the first step uses mean-shift local search with constrained local model to rapidly approach the global optimum. The second step uses component-wise active contours to discriminatively refine the subtle shape variation. Our framework simultaneously handles face detection, pose-robust landmark localization and tracking in real time. Extensive experiments are conducted on both laboratory environmental databases and face-in-the-wild databases. The results reveal that our approach consistently outperforms state-of-the-art methods for face alignment and tracking.	[Yu, Xiang; Metaxas, Dimitris N.] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA; [Huang, Junzhou] Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA; [Zhang, Shaoting] Univ N Carolina, Dept Comp Sci, Charlotte, NC USA	Rutgers State University New Brunswick; University of Texas System; University of Texas Arlington; University of North Carolina; University of North Carolina Charlotte	Yu, X (corresponding author), Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA.	xiangyu@cs.rutgers.edu; jzhuang@uta.edu; dnm@cs.rutgers.edu			National Science Foundation: Information and Intelligent Systems (IIS) [1064965, IIS-1451292, IIS-1423056]; National Science Foundation: Industrial Innovation and Partnerships (IIP) [1069258]; National Science Foundation: Division of Graduate Education (DGE) [0549115]; National Science Foundation: Civial Mechanical and Manufacturing Innovation (CMMI) [1434401]; National Science Foundation: Computer, Network Systems (CNS) [1405985]; National Aeronautics and Space Administration (NCC) [9-58]	National Science Foundation: Information and Intelligent Systems (IIS); National Science Foundation: Industrial Innovation and Partnerships (IIP); National Science Foundation: Division of Graduate Education (DGE); National Science Foundation: Civial Mechanical and Manufacturing Innovation (CMMI); National Science Foundation: Computer, Network Systems (CNS); National Aeronautics and Space Administration (NCC)	This paper is based upon work supported in part by National Science Foundation: Information and Intelligent Systems (IIS)-1064965, IIS-1451292, IIS-1423056, Industrial Innovation and Partnerships (IIP)-1069258, Division of Graduate Education (DGE)-0549115, Civial Mechanical and Manufacturing Innovation (CMMI)-1434401 and Computer, Network Systems (CNS)-1405985 and National Aeronautics and Space Administration (NCC) 9-58. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied of the U.S. Government. J. Huang is the corresponding author.	Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442; Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602; Bettadapura V., 2012, FACE EXPRESSION RECO; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191; Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015; Cheng X, 2013, IEEE I CONF COMP VIS, P577, DOI 10.1109/ICCV.2013.77; Cootes T., 1997, P BRIT MACH VIS C; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cootes TF, 2012, LECT NOTES COMPUT SC, V7578, P278, DOI 10.1007/978-3-642-33786-4_21; Cristinacce D., 2007, P BMVC, P880; Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024; Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976; Dollar P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094; Everingham M., 2006, P 17 BRIT MACH VIS C; Fei Yang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P272, DOI 10.1109/FG.2011.5771410; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Gao H, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.118; Ghiasi G, 2014, PROC CVPR IEEE, P1899, DOI 10.1109/CVPR.2014.306; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Huang Gary B., 2007, 0749 U MASS, P7; Huang Y, 2007, AM SOC TEST MATER, V1486, P1; JONES M, 2003, P IEEE C COMP VIS PA; Kalal Z., 2008, P BRIT MACH VIS C, P1, DOI DOI 10.5244/C.22.42; Karlinsky L, 2012, LECT NOTES COMPUT SC, V7574, P326, DOI 10.1007/978-3-642-33712-3_24; Kemelmacher-Shlizerman I, 2011, IEEE T PATTERN ANAL, V33, P394, DOI 10.1109/TPAMI.2010.63; Li HX, 2014, PROC CVPR IEEE, P1843, DOI 10.1109/CVPR.2014.238; Liang L, 2008, LECT NOTES COMPUT SC, V5303, P72, DOI 10.1007/978-3-540-88688-4_6; Liu J., 2009, SLEP SPARSE LEARNING; Liu XM, 2007, PROC CVPR IEEE, P2264; Martinez, 1998, 24 CVC; Martinez B, 2013, IEEE T PATTERN ANAL, V35, P1149, DOI 10.1109/TPAMI.2012.205; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Mpiperis I., 2008, AUT FAC GEST REC 200, P1; Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106; Myung-Cheol Roh, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P239, DOI 10.1109/FG.2011.5771404; Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075; Rivera S, 2012, PATTERN RECOGN, V45, P1792, DOI 10.1016/j.patcog.2011.09.023; Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59; Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4; Smith BM, 2012, LECT NOTES COMPUT SC, V7574, P43, DOI 10.1007/978-3-642-33712-3_4; Tzimiropoulos G, 2013, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2013.79; Uricar M., 2012, P VISAPP; Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996; Vogler C, 2007, IEEE I CONF COMP VIS, P1456; Wang Y, 2008, PROC CVPR IEEE, P3621; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yang F, 2012, PROC CVPR IEEE, P861, DOI 10.1109/CVPR.2012.6247759; Yu X, 2014, LECT NOTES COMPUT SC, V8692, P105, DOI 10.1007/978-3-319-10593-2_8; Yu X, 2013, IEEE I CONF COMP VIS, P1944, DOI 10.1109/ICCV.2013.244; Zhang C., 2010, MSRTR201066; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; Zhou F, 2013, IEEE I CONF COMP VIS, P1025, DOI 10.1109/ICCV.2013.131; Zhou Y, 2005, PROC CVPR IEEE, P741; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	58	14	14	0	23	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2016	38	11					2212	2226		10.1109/TPAMI.2015.2509999	http://dx.doi.org/10.1109/TPAMI.2015.2509999			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	DZ6AW	26700972				2022-12-18	WOS:000385945000006
J	Fu, Y; Lam, A; Sato, I; Okabe, T; Sato, Y				Fu, Ying; Lam, Antony; Sato, Imari; Okabe, Takahiro; Sato, Yoichi			Reflectance and Fluorescence Spectral Recovery via Actively Lit RGB Images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article; Proceedings Paper	27th IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 23-28, 2014	Columbus, OH	Comp Vis Fdn, IEEE, IEEE Comp Soc		Reflectance and fluorescence spectra recovery; fluorescent chromaticity invariance; varying illumination	ILLUMINATION; COMPONENTS	In recent years, fluorescence analysis of scenes has received attention in computer vision. Fluorescence can provide additional information about scenes, and has been used in applications such as camera spectral sensitivity estimation, 3D reconstruction, and color relighting. In particular, hyperspectral images of reflective-fluorescent scenes provide a rich amount of data. However, due to the complex nature of fluorescence, hyperspectral imaging methods rely on specialized equipment such as hyperspectral cameras and specialized illuminants. In this paper, we propose a more practical approach to hyperspectral imaging of reflective-fluorescent scenes using only a conventional RGB camera and varied colored illuminants. The key idea of our approach is to exploit a unique property of fluorescence: the chromaticity of fluorescent emissions are invariant under different illuminants. This allows us to robustly estimate spectral reflectance and fluorescent emission chromaticity. We then show that given the spectral reflectance and fluorescent chromaticity, the fluorescence absorption and emission spectra can also be estimated. We demonstrate in results that all scene spectra can be accurately estimated from RGB images. Finally, we show that our method can be used to accurately relight scenes under novel lighting.	[Fu, Ying; Sato, Yoichi] Univ Tokyo, Inst Ind Sci, Tokyo, Japan; [Lam, Antony] Saitama Univ, Grad Sch Sci & Engn, Tokyo, Japan; [Sato, Imari] Natl Inst Informat, Tokyo, Japan; [Okabe, Takahiro] Kyushu Inst Technol, Grad Sch Comp Sci & Syst Engn, Tokyo, Japan	University of Tokyo; Saitama University; Research Organization of Information & Systems (ROIS); National Institute of Informatics (NII) - Japan; Kyushu Institute of Technology	Fu, Y (corresponding author), Univ Tokyo, Inst Ind Sci, Tokyo, Japan.	fuying@iis.u-tokyo.ac.jp; antonylam@cv.ics.saitama-u.ac.jp; imarik@nii.ac.jp; okabe@ai.kyutech.ac.jp; ysato@iis.u-tokyo.ac.jp						Alterman M., 2010, PROC IEEE INT C COMP, P1; [Anonymous], P AS C COMP VIS; Barnard K, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P257; Chi C, 2010, INT J COMPUT VISION, V86, P140, DOI 10.1007/s11263-008-0176-y; Feng Lu, 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P412, DOI 10.1007/978-3-642-19309-5_32; Fu Y, 2013, IEEE I CONF COMP VIS, P457, DOI 10.1109/ICCV.2013.63; Fu Y, 2014, LECT NOTES COMPUT SC, V8693, P203, DOI 10.1007/978-3-319-10602-1_14; Fuchs E, 2001, APPL OPTICS, V40, P3614, DOI 10.1364/AO.40.003614; Han S, 2012, PROC CVPR IEEE, P805, DOI 10.1109/CVPR.2012.6247752; Hullin M. B., 2008, ACM T GRAPHICS SIGGR, V87, P10; Hullin MB, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778834; Jiang J, 2013, IEEE WORK APP COMP, P168, DOI 10.1109/WACV.2013.6475015; Johnson GM, 1999, IEEE COMPUT GRAPH, V19, P47, DOI 10.1109/38.773963; Lakowicz J.R., 2006, PRINCIPLES FLUORESCE, DOI 10.1007/978-0-387-46312-4; Lam A, 2013, PROC CVPR IEEE, P1452, DOI 10.1109/CVPR.2013.191; Lee BK, 2001, OPT ENG, V40, P2069, DOI 10.1117/1.1399283; Leland J, 1997, P SOC PHOTO-OPT INS, V3140, P76, DOI 10.1117/12.284094; Liu JJ, 2012, IEEE INFOCOM SER, P1, DOI 10.1109/INFCOM.2012.6195580; Lu F, 2013, PROC CVPR IEEE, P1490, DOI 10.1109/CVPR.2013.196; McNamara G, 2006, CYTOM PART A, V69A, P863, DOI 10.1002/cyto.a.20304; Park IC, 2007, PR IEEE COMP DESIGN, P1, DOI 10.1109/ICCD.2007.4601872; PARKKINEN JPS, 1989, J OPT SOC AM A, V6, P318, DOI 10.1364/JOSAA.6.000318; Rost FW., 1992, FLUORESCENCE MICROSC; Sato I, 2012, PROC CVPR IEEE, P270, DOI 10.1109/CVPR.2012.6247685; Tominaga S, 1996, J OPT SOC AM A, V13, P2163, DOI 10.1364/JOSAA.13.002163; Tominaga S, 2011, NINETEENTH COLOR AND IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, AND APPLICATIONS, P352; Treibitz T, 2012, LECT NOTES COMPUT SC, V7578, P292, DOI 10.1007/978-3-642-33786-4_22; Wilkie A., 2006, GRAPHITE 06 P 4 INT, P321, DOI [10.1145/1174429.1174484, DOI 10.1145/1174429.1174484]; Zhang C, 2013, IEEE T PATTERN ANAL, V35, P2866, DOI 10.1109/TPAMI.2012.255; Zheng YQ, 2014, LECT NOTES COMPUT SC, V8693, P188, DOI 10.1007/978-3-319-10602-1_13	30	14	14	0	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2016	38	7							1313	10.1109/TPAMI.2015.2439270	http://dx.doi.org/10.1109/TPAMI.2015.2439270			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	DO6MH	27295456				2022-12-18	WOS:000377897100004
J	Seguin, G; Alahari, K; Sivic, J; Laptev, I				Seguin, Guillaume; Alahari, Karteek; Sivic, Josef; Laptev, Ivan			Pose Estimation and Segmentation of Multiple People in Stereoscopic Movies	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Person detection; pose estimation; segmentation; 3D data; stereo movies	FLEXIBLE MIXTURES; LAYER EXTRACTION; SPARSE	We describe a method to obtain a pixel-wise segmentation and pose estimation of multiple people in stereoscopic videos. This task involves challenges such as dealing with unconstrained stereoscopic video, non-stationary cameras, and complex indoor and outdoor dynamic scenes with multiple people. We cast the problem as a discrete labelling task involving multiple person labels, devise a suitable cost function, and optimize it efficiently. The contributions of our work are two-fold: First, we develop a segmentation model incorporating person detections and learnt articulated pose segmentation masks, as well as colour, motion, and stereo disparity cues. The model also explicitly represents depth ordering and occlusion. Second, we introduce a stereoscopic dataset with frames extracted from feature-length movies "StreetDance 3D" and "Pina". The dataset contains 587 annotated human poses, 1,158 bounding box annotations and 686 pixel-wise segmentations of people. The dataset is composed of indoor and outdoor scenes depicting multiple people with frequent occlusions. We demonstrate results on our new challenging dataset, as well as on the H2view dataset from (Sheasby et al. ACCV 2012).	[Seguin, Guillaume; Sivic, Josef; Laptev, Ivan] INRIA, WILLOW Project Team, Paris, France; [Seguin, Guillaume; Sivic, Josef; Laptev, Ivan] ENS Inria CNRS UMR 8548, Ecole Normale Super, Paris, France; [Alahari, Karteek] Inria Grenoble Rhone Alpes, LEAR Project Team, Lab Jean Kuntzmann, Grenoble, France	Inria; Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS); UDICE-French Research Universities; Communaute Universite Grenoble Alpes; Institut National Polytechnique de Grenoble; Universite Grenoble Alpes (UGA); Centre National de la Recherche Scientifique (CNRS); Inria	Seguin, G (corresponding author), INRIA, WILLOW Project Team, Paris, France.	guillaume.seguin@inria.fr; karteek.alahari@inria.fr; Josef.Sivic@ens.fr; ivan.laptev@inria.fr	Alahari, Karteek/AAL-1766-2020	Alahari, Karteek/0000-0002-1838-5936	Quaero programme - OSEO; MSR-INRIA laboratory; ERC grant Activia; ERC grant Leap; Google; EIT ICT Labs	Quaero programme - OSEO; MSR-INRIA laboratory; ERC grant Activia; ERC grant Leap; Google(Google Incorporated); EIT ICT Labs	The authors would like to thank Jean Ponce for helpful suggestions. This work was partly supported by the Quaero programme, funded by OSEO, MSR-INRIA laboratory, ERC grants Activia and Leap, Google, and EIT ICT Labs.	Alahari K, 2013, IEEE I CONF COMP VIS, P2112, DOI 10.1109/ICCV.2013.263; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Ayvaci A, 2012, INT J COMPUT VISION, V97, P322, DOI 10.1007/s11263-011-0490-7; Boros E, 2002, DISCRETE APPL MATH, V123, P155, DOI 10.1016/S0166-218X(01)00336-5; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y., 2001, P INT C COMP VIS, V1, P105, DOI DOI 10.1109/ICCV.2001.937505; Budvytis I., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2257, DOI 10.1109/CVPR.2011.5995600; Niebles JC, 2010, PROC CVPR IEEE, P655, DOI 10.1109/CVPR.2010.5540152; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Desai C, 2012, LECT NOTES COMPUT SC, V7575, P158, DOI 10.1007/978-3-642-33765-9_12; Eichner M, 2012, INT J COMPUT VISION, V99, P190, DOI 10.1007/s11263-012-0524-9; Eichner M, 2010, LECT NOTES COMPUT SC, V6311, P228, DOI 10.1007/978-3-642-15549-9_17; Everingham M., 2006, P BRIT MACH VIS C BM, P899, DOI DOI 10.5244/C.20.92; Fragkiadaki K, 2013, PROC CVPR IEEE, P2059, DOI 10.1109/CVPR.2013.268; Goldman DB, 2008, UIST 2008: PROCEEDINGS OF THE 21ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P3, DOI 10.1145/1449715.1449719; Gulshan V., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1127, DOI 10.1109/ICCVW.2011.6130376; Huayan Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2433, DOI 10.1109/CVPR.2011.5995722; Isack H, 2012, INT J COMPUT VISION, V97, P123, DOI 10.1007/s11263-011-0474-7; Johnson S, 2011, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR.2011.5995318; Keller CG, 2011, IEEE T INTELL TRANSP, V12, P1096, DOI 10.1109/TITS.2011.2143410; Kohli P, 2008, INT J COMPUT VISION, V79, P285, DOI 10.1007/s11263-007-0120-6; Kolmogorov V, 2005, PROC CVPR IEEE, P407; Koppal SJ, 2011, IEEE COMPUT GRAPH, V31, P20, DOI 10.1109/MCG.2010.37; Kumar MP, 2005, IEEE I CONF COMP VIS, P33; Ladicky L, 2013, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2013.459; Liu C., 2009, THESIS MIT CAMBRIDGE; Pishchulin L, 2013, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2013.433; Pishchulin L, 2012, PROC CVPR IEEE, P3178, DOI 10.1109/CVPR.2012.6248052; Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999; Sapp B, 2011, PROC CVPR IEEE, P1281, DOI 10.1109/CVPR.2011.5995607; Schindler K, 2010, ISPRS J PHOTOGRAMM, V65, P523, DOI 10.1016/j.isprsjprs.2010.06.006; Sheasby G., 2012, P AS C COMP VIS, P94; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Spinello L, 2011, IEEE INT C INT ROBOT, P3838, DOI 10.1109/IROS.2011.6048835; Sun D., 2010, ADV NEURAL INFORM PR, V23, P2226; Torr PHS, 2001, IEEE T PATTERN ANAL, V23, P297, DOI 10.1109/34.910882; Walk S, 2010, LECT NOTES COMPUT SC, V6316, P182, DOI 10.1007/978-3-642-15567-3_14; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Wedel A, 2008, LECT NOTES COMPUT SC, V5302, P739, DOI 10.1007/978-3-540-88682-2_56; Xiao JJ, 2005, IEEE T PATTERN ANAL, V27, P1644, DOI 10.1109/TPAMI.2005.202; Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261; Yang Y, 2012, IEEE T PATTERN ANAL, V34, P1731, DOI 10.1109/TPAMI.2011.208; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Yao BP, 2010, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2010.5540235	46	14	14	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2015	37	8					1643	1655		10.1109/TPAMI.2014.2369050	http://dx.doi.org/10.1109/TPAMI.2014.2369050			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CM3ON	26353001	Green Submitted			2022-12-18	WOS:000357591900009
J	Johnsson, K; Soneson, C; Fontes, M				Johnsson, Kerstin; Soneson, Charlotte; Fontes, Magnus			Low Bias Local Intrinsic Dimension Estimation from Expected Simplex Skewness	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Intrinsic dimension estimation; manifold learning	SHAPE DIMENSION; ALGORITHM; ENTROPY; NOISE; MODEL	In exploratory high-dimensional data analysis, local intrinsic dimension estimation can sometimes be used in order to discriminate between data sets sampled from different low-dimensional structures. Global intrinsic dimension estimators can in many cases be adapted to local estimation, but this leads to problems with high negative bias or high variance. We introduce a method that exploits the curse/blessing of dimensionality and produces local intrinsic dimension estimators that have very low bias, even in cases where the intrinsic dimension is higher than the number of data points, in combination with relatively low variance. We show that our estimators have a very good ability to classify local data sets by their dimension compared to other local intrinsic dimension estimators; furthermore we provide examples showing the usefulness of local intrinsic dimension estimation in general and our method in particular for stratification of real data sets.	[Johnsson, Kerstin; Fontes, Magnus] Lund Univ, Ctr Math Sci, Fac Engn, S-22100 Lund, Sweden; [Soneson, Charlotte] SIB Swiss Inst Bioinformat, Bioinformat Core Facil, Lausanne, Switzerland; [Fontes, Magnus] Inst Pasteur, Paris, France	Lund University; Swiss Institute of Bioinformatics; Le Reseau International des Instituts Pasteur (RIIP); Institut Pasteur Paris	Johnsson, K (corresponding author), Lund Univ, Ctr Math Sci, Fac Engn, S-22100 Lund, Sweden.	johnsson@maths.lth.se; charlottesoneson@gmail.com; fontes@maths.lth.se	Soneson, Charlotte/J-6740-2019	Soneson, Charlotte/0000-0003-3833-2169; Johnsson, Kerstin/0000-0002-1381-7031				Bell D, 2011, NATURE, V474, P609, DOI 10.1038/nature10166; Camastra F, 2002, IEEE T PATTERN ANAL, V24, P1404, DOI 10.1109/TPAMI.2002.1039212; Carlsson G, 2009, B AM MATH SOC, V46, P255, DOI 10.1090/S0273-0979-09-01249-X; Carter KM, 2010, IEEE T SIGNAL PROCES, V58, P650, DOI 10.1109/TSP.2009.2031722; Ceruti C., 2012, 12063881 ARXIV; Chavez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808; Cheng SW, 2009, PROCEEDINGS OF THE TWENTIETH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1001; Costa JA, 2006, MODEL SIMUL SCI ENG, P231; Dey TK, 2002, SIAM PROC S, P772; Diks C, 1996, PHYS REV E, V53, pR4263, DOI 10.1103/PhysRevE.53.R4263; Donoho D.L., 2000, HIGH DIMENSIONAL DAT, V1; Duong T, 2007, J STAT SOFTW, V21, P1, DOI 10.18637/jss.v021.i07; Fan M., 2010, 10022050 ARXIV; FUKUNAGA K, 1971, IEEE T COMPUT, VC 20, P176, DOI 10.1109/T-C.1971.223208; Giesen J, 2004, DISCRETE COMPUT GEOM, V32, P245, DOI 10.1007/s00454-004-1120-8; GRASSBERGER P, 1983, PHYSICA D, V9, P189, DOI 10.1016/0167-2789(83)90298-1; Gromov M., 1999, SERIES PROGR MATH, V152; Haro G, 2008, INT J COMPUT VISION, V80, P358, DOI 10.1007/s11263-008-0144-6; Harte D., 2001, MULTIFRACTALS THEORY, DOI DOI 10.1201/9781420036008; Hein M., 2005, P 22 INT C MACHINE L, P289; HILL BM, 1975, ANN STAT, V3, P1163, DOI 10.1214/aos/1176343247; Hoff PD, 2007, J AM STAT ASSOC, V102, P674, DOI 10.1198/016214506000001310; Johnsson K., 2013, DOCUMENTATION R PACK; JUDD K, 1994, PHYSICA D, V71, P421, DOI 10.1016/0167-2789(94)90008-6; Lee JA, 2007, INFORM SCI STAT, P1; Levina E., 2004, P ADV NEUR INF PROC, P777; Oltmans H, 1997, PHYS REV E, V56, P1160, DOI 10.1103/PhysRevE.56.1160; Pestov V, 2008, NEURAL NETWORKS, V21, P204, DOI 10.1016/j.neunet.2007.12.030; PETTIS KW, 1979, IEEE T PATTERN ANAL, V1, P25, DOI 10.1109/TPAMI.1979.4766873; Rozza A, 2012, MACH LEARN, V89, P37, DOI 10.1007/s10994-012-5294-7; SCHOUTEN JC, 1994, PHYS REV E, V50, P1851, DOI 10.1103/PhysRevE.50.1851; Schreiber T, 1997, PHYS REV E, V56, P274, DOI 10.1103/PhysRevE.56.274; SMITH RL, 1992, J ROY STAT SOC B MET, V54, P329; TAKENS F, 1985, LECT NOTES MATH, V1125, P99; Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196; TRUNK GV, 1976, IEEE T COMPUT, V25, P165, DOI 10.1109/TC.1976.5009231	37	14	14	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2015	37	1					196	202		10.1109/TPAMI.2014.2343220	http://dx.doi.org/10.1109/TPAMI.2014.2343220			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AX5ML	26353219				2022-12-18	WOS:000346970600017
J	Kang, H; Hebert, M; Efros, AA; Kanade, T				Kang, Hongwen; Hebert, Martial; Efros, Alexei A.; Kanade, Takeo			Data-Driven Objectness	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Objectness; data-driven; segment selection; object discovery; product images; activity of daily living (ADL)		We propose a data-driven approach to estimate the likelihood that an image segment corresponds to a scene object (its "objectness") by comparing it to a large collection of example object regions. We demonstrate that when the application domain is known, for example, in our case activity of daily living (ADL), we can capture the regularity of the domain specific objects using millions of exemplar object regions. Our approach to estimating the objectness of an image region proceeds in two steps: 1) finding the exemplar regions that are the most similar to the input image segment; 2) calculating the objectness of the image segment by combining segment properties, mutual consistency across the nearest exemplar regions, and the prior probability of each exemplar region. In previous work, parametric objectness models were built from a small number of manually annotated objects regions, instead, our data-driven approach uses 5 million object regions along with their metadata information. Results on multiple data sets demonstrates our data-driven approach compared to the existing model based techniques. We also show the application of our approach in improving the performance of object discovery algorithms.	[Kang, Hongwen; Hebert, Martial; Efros, Alexei A.; Kanade, Takeo] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Kang, H (corresponding author), Carnegie Mellon Univ, Sch Comp Sci, 5000 Forbes Ave,Smith Hall, Pittsburgh, PA 15213 USA.	hongwenk@cs.cmu.edu; hebert@cs.cmu.edu; efros@cs.cmu.edu; tk@cs.cmu.edu		Efros, Alexei A./0000-0001-5720-8070	National Science Foundation (NSF) [EEC-0540865]	National Science Foundation (NSF)(National Science Foundation (NSF))	This work was partially supported by National Science Foundation (NSF) Grant No. EEC-0540865.	Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226; [Anonymous], 2006, 2006 IEEE COMP SOC C, DOI DOI 10.1109/CVPR.2006.58; ARKIN EM, 1991, IEEE T PATTERN ANAL, V13, P209, DOI 10.1109/34.75509; Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; Choi MJ, 2012, PATTERN RECOGN LETT, V33, P853, DOI 10.1016/j.patrec.2011.12.004; COLLINS AM, 1975, PSYCHOL REV, V82, P407, DOI 10.1037/0033-295X.82.6.407; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Endres I, 2010, LECT NOTES COMPUT SC, V6315, P575, DOI 10.1007/978-3-642-15555-0_42; Fergus R, 2005, IEEE I CONF COMP VIS, P1816; Hays J., 2007, ACM SIGGRAPH T GRAPH, V26, P29; Kang H, 2012, LECT NOTES COMPUT SC, V7577, P794, DOI 10.1007/978-3-642-33783-3_57; Kang HW, 2011, IEEE I CONF COMP VIS, P762, DOI 10.1109/ICCV.2011.6126314; Kim J, 2012, LECT NOTES COMPUT SC, V7578, P444, DOI 10.1007/978-3-642-33786-4_33; Lai K., 2009, ROBOTICS SCI SYSTEMS; Lebiere C., 2007, P 8 INT C COGN MOD A, P67; Leskovec J., 2007, P 16 INT C WORLD WID, P471, DOI DOI 10.1145/1242572.1242636; Li L.-J., 2010, NEURAL INFORM PROCES, P1378; Li LJ, 2007, LECT NOTES ARTIF INT, V4456, P1; Liu C, 2009, PROC CVPR IEEE, P1972, DOI 10.1109/CVPRW.2009.5206536; Malisiewicz Tomasz, 2008, P IEEE C COMP VIS PA, P1; QUILLIAN MR, 1967, BEHAV SCI, V12, P410, DOI 10.1002/bs.3830120511; Russell Bryan, 2009, NIPS; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456; Xu H, 2011, IEEE I CONF COMP VIS, P1631, DOI 10.1109/ICCV.2011.6126424	28	14	14	1	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2015	37	1					189	195		10.1109/TPAMI.2014.2315811	http://dx.doi.org/10.1109/TPAMI.2014.2315811			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AX5ML	26353218				2022-12-18	WOS:000346970600016
J	Lopez-Rubio, E				Lopez-Rubio, Ezequiel			A Histogram Transform for Probability Density Function Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Probability density function estimation; nonparametric estimation; multivariate histograms; kernel density estimation	FAST GAUSS TRANSFORM; MULTIVARIATE HISTOGRAMS; SELECTION; ALGORITHMS	The estimation of multivariate probability density functions has traditionally been carried out by mixtures of parametric densities or by kernel density estimators. Here we present a new nonparametric approach to this problem which is based on the integration of several multivariate histograms, computed over affine transformations of the training data. Our proposal belongs to the class of averaged histogram density estimators. The inherent discontinuities of the histograms are smoothed, while their low computational complexity is retained. We provide a formal proof of the convergence to the real probability density function as the number of training samples grows, and we demonstrate the performance of our approach when compared with a set of standard probability density estimators.	Univ Malaga, Dept Comp Languages & Comp Sci, E-29071 Malaga, Spain	Universidad de Malaga	Lopez-Rubio, E (corresponding author), Univ Malaga, Dept Comp Languages & Comp Sci, E-29071 Malaga, Spain.	ezeqlr@lcc.uma.es	Lopez-Rubio, Ezequiel/K-3821-2014; López-Rubio, Ezequiel/N-7753-2019	Lopez-Rubio, Ezequiel/0000-0001-8231-5687; López-Rubio, Ezequiel/0000-0001-8231-5687	Ministry of Economy and Competitiveness of Spain [TIN2011-24141]; Autonomous Government of Andalusia (Spain) [TIC-6213, TIC-657]; FEDER funds	Ministry of Economy and Competitiveness of Spain(Spanish Government); Autonomous Government of Andalusia (Spain); FEDER funds(European Commission)	This work was partially supported by the Ministry of Economy and Competitiveness of Spain under Grant TIN2011-24141, project name Detection of anomalous activities in video sequences by self-organizing neural systems, and the Autonomous Government of Andalusia (Spain) under projects TIC-6213, project name Development of Self-Organizing Neural Networks for Information Technologies; and TIC-657, project name Self-organizing systems and robust estimators for video surveillance. All of them include FEDER funds. The author thankfully acknowledges the computer resources, technical expertise and assistance provided by the SCBI (Supercomputing and Bioinformatics) center of the University of Malaga. Finally, he would like to thank the Associate Editor and the anonymous reviewers for their valuable comments and suggestions.	Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494; [Anonymous], 2004, NONPARAMETRIC SEMIPA, DOI DOI 10.1007/978-3-642-17146-8; Asuncion A, 2007, UCI MACHINE LEARNING; Bagon S., 2012, MATLAB INTERFACE EDI; Banerjee A, 2010, IEEE T IMAGE PROCESS, V19, P2480, DOI 10.1109/TIP.2010.2047667; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Carreira-Perpinan M.A., 2006, 2006 IEEE COMPUTER S, V1, P1160, DOI 10.1109/CVPR.2006.44; Christoudias C.M., 2009, CODE EDGE DETECTION; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Devroye L, 2004, TEST, V13, P129, DOI 10.1007/BF02603004; DEVROYE L, 1985, NONPARAMETRIC DENSIT; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Duffy B., 2012, IEEE T VISUALIZATION, V19; Elgammal A, 2003, IEEE T PATTERN ANAL, V25, P1499, DOI 10.1109/TPAMI.2003.1240123; Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; Gray A.G., 2000, ADV NEURAL INF PROCE, V4, P521; GREENGARD L, 1991, SIAM J SCI STAT COMP, V12, P79, DOI 10.1137/0912004; Han M, 2011, NEUROCOMPUTING, V74, P1664, DOI 10.1016/j.neucom.2011.01.022; Hazelton ML, 2007, COMPUT STAT DATA AN, V51, P3057, DOI 10.1016/j.csda.2006.02.002; Hong X, 2008, IEEE T NEURAL NETWOR, V19, P193, DOI 10.1109/TNN.2007.908645; Huang SY, 1999, STAT SINICA, V9, P137; HWANG JN, 1994, IEEE T SIGNAL PROCES, V42, P2795, DOI 10.1109/78.324744; JEFFREYS H, 1946, PROC R SOC LON SER-A, V186, P453, DOI 10.1098/rspa.1946.0056; Kaftan JN, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P365; Klemela J, 2009, STAT SINICA, V19, P159; Kristan M, 2011, PATTERN RECOGN, V44, P2630, DOI 10.1016/j.patcog.2011.03.019; Kukar M, 2006, KNOWL INF SYST, V9, P364, DOI 10.1007/s10115-005-0203-z; Lang D., 2006, N BODY METHODS CODE; Leiva-Murillo JM, 2012, PATTERN RECOGN LETT, V33, P1717, DOI 10.1016/j.patrec.2012.06.006; Lopez-Rubio E, 2008, PATTERN RECOGN LETT, V29, P2085, DOI 10.1016/j.patrec.2008.07.010; Mezzadri F., 2007, NOTICES AMS, V54, P592; Mittelman R, 2008, IEEE T SIGNAL PROCES, V56, P5746, DOI 10.1109/TSP.2008.2005095; Moore A. W., 2000, UAI, P397; Morariu Vlad I, 2008, ADV NEURAL INFORM PR, P1113, DOI DOI 10.5555/2981780.2981919; NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308; Oyang YJ, 2005, IEEE T NEURAL NETWOR, V16, P225, DOI 10.1109/TNN.2004.836229; Ozertem U, 2011, J MACH LEARN RES, V12, P1249; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; ROKHLIN V, 1985, J COMPUT PHYS, V60, P187, DOI 10.1016/0021-9991(85)90002-6; Scott D. W., 1992, MULTIVARIATE DENSITY, DOI 10.1002/9780470316849; Scott D.W., 2004, HDB STAT, V24, P229; SCOTT DW, 1985, ANN STAT, V13, P1024, DOI 10.1214/aos/1176349654; SCOTT DW, 1985, COMMUN STAT-THEOR M, V14, P1353, DOI 10.1080/03610928508828980; Seo HJ, 2010, IEEE T PATTERN ANAL, V32, P1688, DOI 10.1109/TPAMI.2009.153; Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15; Vincent P., 2003, ADV NEURAL INFORM PR, P849; WEBER A, 2010, USC SIPI IMAGE DATAB; Weinberger KQ, 2010, IEEE SIGNAL PROC MAG, V27, P146, DOI 10.1109/MSP.2010.936013; Yang CJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P464; Yuan XT, 2012, IEEE T KNOWL DATA EN, V24, P209, DOI 10.1109/TKDE.2010.232	52	14	14	1	24	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2014	36	4					644	656		10.1109/TPAMI.2013.246	http://dx.doi.org/10.1109/TPAMI.2013.246			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	AE6MX	26353191				2022-12-18	WOS:000334109000002
J	Heas, P; Herzet, C; Memin, E; Heitz, D; Mininni, PD				Heas, Patrick; Herzet, Cedric; Memin, Etienne; Heitz, Dominique; Mininni, Pablo D.			Bayesian Estimation of Turbulent Motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Optic flow; turbulence; robust estimation; constrained optimization; Bayesian model selection	FLUID-FLOW	Based on physical laws describing the multiscale structure of turbulent flows, this paper proposes a regularizer for fluid motion estimation from an image sequence. Regularization is achieved by imposing some scale invariance property between histograms of motion increments computed at different scales. By reformulating this problem from a Bayesian perspective, an algorithm is proposed to jointly estimate motion, regularization hyperparameters, and to select the most likely physical prior among a set of models. Hyperparameter and model inference are conducted by posterior maximization, obtained by marginalizing out non-Gaussian motion variables. The Bayesian estimator is assessed on several image sequences depicting synthetic and real turbulent fluid flows. Results obtained with the proposed approach exceed the state-of-the-art results in fluid flow estimation.	[Heas, Patrick; Herzet, Cedric; Memin, Etienne] Inria, Rennes Bretagne Atlantique, F-35042 Rennes, France; [Heitz, Dominique] Irstea, UR TERE, F-35044 Rennes, France; [Mininni, Pablo D.] FCEN, Dept Fis, RA-1428 Buenos Aires, DF, Argentina; [Mininni, Pablo D.] Natl Ctr Atmospher Res, Boulder, CO 80307 USA	Inria; INRAE; University of Buenos Aires; National Center Atmospheric Research (NCAR) - USA	Heas, P (corresponding author), Inria, Rennes Bretagne Atlantique, F-35042 Rennes, France.	Patrick.Heas@inria.fr; Cedric.Herzet@inria.fr; Etienne.Memin@inria.fr; Dominique.Heitz@irstea.fr; mininni@df.uba.ar	Heitz, Dominique/O-3504-2014	Heitz, Dominique/0000-0001-6295-2822; Heas, Patrick/0000-0001-6860-7149; Mininni, Pablo/0000-0001-6858-6755				Baker S., 2007, P 11 IEEE INT C COMP; Beal MJ, 2003, BAYESIAN STATISTICS 7, P453; Becker F, 2012, IEEE T IMAGE PROCESS, V21, P3053, DOI 10.1109/TIP.2011.2181524; BERGEN JR, 1992, IEEE T PATTERN ANAL, V14, P886, DOI 10.1109/34.161348; Bertsekas D., 2003, CONVEX ANAL OPTIMIZA; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Carlier J, 2005, FLUID PROJECT DELIVE; Corpetti T, 2002, IEEE T PATTERN ANAL, V24, P365, DOI 10.1109/34.990137; Derian P., 2011, P 3 INT C SCAL SPAC; FRISCH U., 1995, TURBULENCE LEGACY AN; GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331; Harouna S.K., 2012, HAL00646104; Heas P., 2009, P 12 IEEE INT C COMP; Heas P, 2007, IEEE T GEOSCI REMOTE, V45, P4087, DOI 10.1109/TGRS.2007.906156; Heas P, 2012, IEEE T IMAGE PROCESS, V21, P1437, DOI 10.1109/TIP.2011.2179053; Heas P, 2012, TELLUS A, V64, DOI 10.3402/tellusa.v64i0.10962; Heitz D, 2010, EXP FLUIDS, V48, P369, DOI 10.1007/s00348-009-0778-3; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Idier J, 2001, IEEE T IMAGE PROCESS, V10, P1001, DOI 10.1109/83.931094; Jaynes ET., 1986, BAYESIAN METHODS GEN; Kolmogoroff A, 1941, CR ACAD SCI URSS, V30, P301, DOI 10.1098/rspa.1991.0075; KRAICHNAN RH, 1967, PHYS FLUIDS, V10, P1417, DOI 10.1063/1.1762301; Krajsek K, 2007, LECT NOTES COMPUT SC, V4713, P142; Lavoie P, 2007, J FLUID MECH, V585, P395, DOI 10.1017/S0022112007006763; Lindborg E, 2001, J GEOPHYS RES-ATMOS, V106, P10233, DOI 10.1029/2000JD900815; Liu TS, 2008, J FLUID MECH, V614, P253, DOI 10.1017/S0022112008003273; Lucas B.D., 1981, IJCAI 81 P 7 INT JOI, P674, DOI DOI 10.1109/HPDC.2004.1323531; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.448; Mininni PD, 2005, ASTROPHYS J, V619, P1019, DOI 10.1086/426534; Molina R, 1999, IEEE T IMAGE PROCESS, V8, P231, DOI 10.1109/83.743857; Monin AS., 1971, STAT FLUID MECH MECH; Papadakis N, 2008, SIAM J IMAGING SCI, V1, P343, DOI 10.1137/080713896; Robert C., 2007, BAYESIAN CHOICE DECI; Ruhnau P, 2007, EXP FLUIDS, V42, P61, DOI 10.1007/s00348-006-0220-z; Ruhnau P, 2007, MEAS SCI TECHNOL, V18, P755, DOI 10.1088/0957-0233/18/3/027; SKILLING J, 1989, FUND THEOR, V36, P455; Yuan J, 2007, J MATH IMAGING VIS, V28, P67, DOI 10.1007/s10851-007-0014-9	37	14	14	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2013	35	6					1343	1356		10.1109/TPAMI.2012.232	http://dx.doi.org/10.1109/TPAMI.2012.232			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	129QV	23599051	Green Submitted			2022-12-18	WOS:000317857900006
J	Payet, N; Todorovic, S				Payet, Nadia; Todorovic, Sinisa			Hough Forest Random Field for Object Recognition and Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Object recognition and segmentation; conditional random field; Hough forest; Metropolis-Hastings algorithm	MARKOV RANDOM-FIELDS; ENERGY MINIMIZATION; MRFS	This paper presents a new computational framework for detecting and segmenting object occurrences in images. We combine Hough forest (HF) and conditional random field (CRF) into HFRF to assign labels of object classes to image regions. HF captures intrinsic and contextual properties of objects. CRF then fuses the labeling hypotheses generated by HF for identifying every object occurrence. Interaction between HF and CRF happens in HFRF inference, which uses the Metropolis-Hastings algorithm. The Metropolis-Hastings reversible jumps depend on two ratios of proposal and posterior distributions. Instead of estimating four distributions, we directly compute the two ratios using HF. In leaf nodes, HF records class histograms of training examples and information about their configurations. This evidence is used in inference for nonparametric estimation of the two distribution ratios. Our empirical evaluation on benchmark datasets demonstrates higher average precision rates of object detection, smaller object segmentation error, and faster convergence rates of our inference, relative to the state of the art. The paper also presents theoretical error bounds of HF and HFRF applied to a two-class object detection and segmentation.	[Payet, Nadia; Todorovic, Sinisa] Oregon State Univ, Sch Elect Engn & Comp Sci, Corvallis, OR 97331 USA	Oregon State University	Payet, N (corresponding author), Oregon State Univ, Sch Elect Engn & Comp Sci, 1148 Kelley Engn Ctr, Corvallis, OR 97331 USA.	payetn@onid.orst.edu; sinisa@eecs.oregonstate.edu						Anguelov D, 2005, PROC CVPR IEEE, P169; ARBELAEZ P, 2009, P IEEE C COMP VIS PA; Barbu A, 2005, IEEE T PATTERN ANAL, V27, P1239, DOI 10.1109/TPAMI.2005.161; Beal M.J, 2003, THESIS; Bileschi S., 2005, PROC BRITISH MACHINE; Boros E, 2002, DISCRETE APPL MATH, V123, P155, DOI 10.1016/S0166-218X(01)00336-5; Bosch A., 2007, PROC 11TH IEEE INTL; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Cipoll Roberto, 2008, PROC CVPR IEEE, P1; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Desai C., 2009, PROC 12TH IEEE INTL; Everingham M., 2012, THE PASCAL VISUAL OB; Felzenszwalb PR, 2004, PROC CVPR IEEE, P261; Gall J, 2009, PROC CVPR IEEE, P1746, DOI 10.1109/CVPRW.2009.5206755; GALLEGUILLOS C., 2010, P IEEE C COMP VIS PA; Gonfaus JM, 2010, PROC CVPR IEEE, P3280, DOI 10.1109/CVPR.2010.5540048; Gould S., 2009, PROC ADVANCES NEURAL; Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211; Gradshteyn I. S., 2007, TABLE INTEGRALS SERI, V7th; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; He XM, 2004, PROC CVPR IEEE, P695; Koller D., 2009, PROBABILISTIC GRAPHI; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; Komodakis N, 2008, LECT NOTES COMPUT SC, V5304, P806, DOI 10.1007/978-3-540-88690-7_60; Komodakis N, 2008, COMPUT VIS IMAGE UND, V112, P14, DOI 10.1016/j.cviu.2008.06.007; Komodakis N, 2007, IEEE T PATTERN ANAL, V29, P1436, DOI 10.1109/TPAMI.2007.1061; Kumar M.P., 2008, P 25 INT C MACH LEAR, P680; Kumar MP, 2010, PROC CVPR IEEE, P3217, DOI 10.1109/CVPR.2010.5540072; Kumar S., 2005, PROC ENERGY MINIMIZA; Li F., 2010, P IEEE C COMP VIS PA; Li Li-Jia, 2009, P IEEE C COMP VIS PA, P1; Lim J.J., 2009, PROC 12TH IEEE INTL; Lin Y, 2006, J AM STAT ASSOC, V101, P578, DOI 10.1198/016214505000001230; LOMNICKI ZA, 1967, J ROY STAT SOC B, V29, P513; Maree R, 2005, PROC CVPR IEEE, P34; Martinez G., 2009, P IEEE C COMP VIS PA; Moosmann F., 2007, ADV NEURAL INF PROCE, V19, P985; Nowozin S., 2011, PROC 11TH IEEE INTL; Payet N., 2010, PROC NEURAL INFORMAT; Payet N., 2010, PROC 11TH EUROPEAN C; Pedersoli M, 2011, PROC CVPR IEEE, P1353, DOI 10.1109/CVPR.2011.5995668; Rabinovich A., 2007, PROC 11TH IEEE INTL; Rother C., 2007, P IEEE C COMP VIS PA; Russell C., 2009, PROC 12TH IEEE INTL; Schraudolph N. N., 2007, PROC 11 INT C ARTIF, P436; Schroff F., 2008, PROC BRITISH MACHINE; Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1; Sivic J., 2008, P IEEE C COMP VIS PA; Sontag D., 2008, PROC 24TH ANN CONF U; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; Szummer M, 2008, LECT NOTES COMPUT SC, V5303, P582, DOI 10.1007/978-3-540-88688-4_43; Todorovic S, 2008, IEEE T PATTERN ANAL, V30, P2158, DOI 10.1109/TPAMI.2008.24; Torralba A.B., 2004, PROC ADVANCES NEURAL; Triggs B., 2008, P ADV NEURAL INF PRO, P1553; Wainwright MJ, 2005, IEEE T INFORM THEORY, V51, P3697, DOI 10.1109/TIT.2005.856938; Winn J., 2006, CVPR; Yedidia J., 2003, EXPLORING ARTIFICIAL, V8, P236; Zhang L., 2005, P IEEE C COMP VIS PA; ZHU L., 2010, P IEEE C COMP VIS PA	64	14	15	0	54	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2013	35	5					1066	1079		10.1109/TPAMI.2012.194	http://dx.doi.org/10.1109/TPAMI.2012.194			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	106EZ	23520252	Green Submitted			2022-12-18	WOS:000316126800004
J	Gu, JW; Nayar, SK; Grinspun, E; Belhumeur, PN; Ramamoorthi, R				Gu, Jinwei; Nayar, Shree K.; Grinspun, Eitan; Belhumeur, Peter N.; Ramamoorthi, Ravi			Compressive Structured Light for Recovering Inhomogeneous Participating Media	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Compressive sensing; volume reconstruction; structured light; time varying	SPARSE	We propose a new method, named compressive structured light, for recovering inhomogeneous participating media. Whereas conventional structured light methods emit coded light patterns onto the surface of an opaque object to establish correspondence for triangulation, compressive structured light projects patterns into a volume of participating medium to produce images which are integral measurements of the volume density along the line of sight. For a typical participating medium encountered in the real world; the integral nature of the acquired images enables the use of compressive sensing techniques that can recover the entire volume density from only a few measurements. This makes the acquisition process more efficient and enables reconstruction of. dynamic volumetric phenomena. Moreover, our method requires the projection of multiplexed coded illumination, which has the added advantage of increasing the signal-to-noise ratio of the acquisition. Finally, we propose an iterative algorithm to correct for the attenuation of the participating medium during the reconstruction process. We show the effectiveness of our method with simulations as well as experiments on the volumetric recovery of multiple translucent layers, 3D point clouds etched in glass, and the dynamic process of milk drops dissolving in water.	[Gu, Jinwei] Rochester Inst Technol, Ctr Imaging Sci, Rochester, NY 14623 USA; [Nayar, Shree K.; Grinspun, Eitan; Belhumeur, Peter N.] Columbia Univ, New York, NY 10027 USA; [Ramamoorthi, Ravi] Univ Calif Berkeley, Berkeley, CA 94720 USA	Rochester Institute of Technology; Columbia University; University of California System; University of California Berkeley	Gu, JW (corresponding author), Rochester Inst Technol, Ctr Imaging Sci, 54 Lomb Mem Dr, Rochester, NY 14623 USA.	jwgu@cis.rit.edu; nayar@cs.columbia.edu; eitan@cs.columbia.edu; belhumeur@cs.columbia.edu; ravir@cs.berkeley.edu			US National Science Foundation (NSF) [ITR-03-25867, CCF-05-41259, IIS-04-12759, IIS-05-28402, CNS-06-14770, CCF-06-43268]; Sloan Research Fellowship [BR-4485]; US Office of Naval Research (ONR) [N00014-07-1-0900]; ONR PECASE [N00014-09-1-0741]	US National Science Foundation (NSF)(National Science Foundation (NSF)); Sloan Research Fellowship(Alfred P. Sloan Foundation); US Office of Naval Research (ONR)(Office of Naval Research); ONR PECASE(Office of Naval Research)	The authors would like to thank Tim-Hawkins for providing the smoke data and the anonymous reviewers for their valuable comments. This work was supported in part by the US National Science Foundation (NSF) (ITR-03-25867, CCF-05-41259, IIS-04-12759, IIS-05-28402, CNS-06-14770, and CCF-06-43268), a Sloan Research Fellowship BR-4485, a US Office of Naval Research (ONR) Young Investigator award N00014-07-1-0900, and an ONR PECASE grant N00014-09-1-0741.	Candes EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124; Deusch S, 2001, MEAS SCI TECHNOL, V12, P188, DOI 10.1088/0957-0233/12/2/310; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Fuchs C, 2007, COMPUT GRAPH-UK, V31, P205, DOI 10.1016/j.cag.2006.11.014; Gini C., 1921, ECON J, V31, P124, DOI [10.2307/2223319, DOI 10.2307/2223319]; Gu JW, 2008, LECT NOTES COMPUT SC, V5305, P845; Hasinoff SW, 2007, IEEE T PATTERN ANAL, V29, P870, DOI 10.1109/TPAMI.2007.1056; Hawkins T, 2005, ACM T GRAPHIC, V24, P812, DOI 10.1145/1073204.1073266; HITOMI Y., 2011, P IEEE INT C COMP VI; Hurley N, 2009, IEEE T INFORM THEORY, V55, P4723, DOI 10.1109/TIT.2009.2027527; Ihrke I., 2008, P EUR; Ihrke I., 2004, P ACM SIGGRAPH EUR S, P367; Ihrke I, 2006, GRAPH MODELS, V68, P484, DOI 10.1016/j.gmod.2006.08.001; Ishimaru A., 1978, IEEE OUP SERIES ELEC, V2; Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391; Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452; Narasimhan SG, 2005, IEEE I CONF COMP VIS, P420; Nayar SK, 2006, ACM T GRAPHIC, V25, P935, DOI 10.1145/1141911.1141977; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Protter M, 2009, IEEE T IMAGE PROCESS, V18, P27, DOI 10.1109/TIP.2008.2008065; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Salvi J, 2004, PATTERN RECOGN, V37, P827, DOI 10.1016/j.patcog.2003.10.002; Sankaranarayanan A., 2010, P EUR C COMP VIS; Schechner YY, 2007, IEEE T PATTERN ANAL, V29, P1339, DOI 10.1109/TPAMI.2007.1151; Schroeder W., 2006, VISUALIZATION TOOLKI, Vfourth; Sen P, 2009, COMPUT GRAPH FORUM, V28, P609, DOI 10.1111/j.1467-8659.2009.01401.x; Simoncelli E, 1997, P 31 AS C SIGN SYST, P673; Takhar D. etal, 2006, P COMP IM 4 SPIE EL; Trifonov B., 2006, PROC EUROGRAPHICS C, P51; Veeraraghavan A, 2011, IEEE T PATTERN ANAL, V33, P671, DOI 10.1109/TPAMI.2010.87; Weyrich T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531338; Willett R., 2007, P COMP IM 5 SPIE EL; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79	34	14	16	0	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	2013	35	3					555	567		10.1109/TPAMI.2012.130	http://dx.doi.org/10.1109/TPAMI.2012.130			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	087VS	22665721				2022-12-18	WOS:000314792900004
J	Mensink, T; Verbeek, J; Csurka, G				Mensink, Thomas; Verbeek, Jakob; Csurka, Gabriela			Tree-Structured CRF Models for Interactive Image Labeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Pattern recognition application computer vision; pattern recognition interactive systems; object recognition; content analysis and indexing; statistical pattern recognition		We propose structured prediction models for image labeling that explicitly take into account dependencies among image labels. In our tree-structured models, image labels are nodes, and edges encode dependency relations. To allow for more complex dependencies, we combine labels in a single node and use mixtures of trees. Our models are more expressive than independent predictors, and lead to more accurate label predictions. The gain becomes more significant in an interactive scenario where a user provides the value of some of the image labels at test time. Such an interactive scenario offers an interesting tradeoff between label accuracy and manual labeling effort. The structured models are used to decide which labels should be set by the user, and transfer the user input to more accurate predictions on other image labels. We also apply our models to attribute-based image classification, where attribute predictions of a test image are mapped to class probabilities by means of a given attribute-class mapping. Experimental results on three publicly available benchmark datasets show that in all scenarios our structured models lead to more accurate predictions, and leverage user input much more effectively than state-of-the-art independent models.	[Mensink, Thomas; Verbeek, Jakob] INRIA Rhone Alpes, LEAR Team, F-38330 Montbonnot St Martin, France; [Mensink, Thomas] Xerox Res Ctr Europe, TVPA, F-38330 Meylan, France; [Csurka, Gabriela] Xerox Res Ctr Europe Grenoble, F-38240 Meylan, France	Xerox	Mensink, T (corresponding author), INRIA Rhone Alpes, LEAR Team, 655 Ave Europe, F-38330 Montbonnot St Martin, France.	thomas.mensink@inria.fr; jakob.verbeek@inria.fr; gabriela.csurka@xrce.xerox.com		Mensink, Thomas/0000-0002-5730-713X				Bishop C.M, 2006, PATTERN RECOGN; Bradley J. K., 2010, P INT C MACH LEARN; Branson S., 2010, P 11 EUR C COMP VIS; Choi M. J., 2010, P IEEE C COMP VIS PA; CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142; Csurka G., 2004, P ECCV WORKSH STAT L; Deng J., 2010, P 11 EUR C COMP VIS; Desai Chaitanya, 2009, P IEEE INT C COMP VI; Dimitrovski I., 2010, P WORKSH IMAGECLEF; Everingham M., 2012, PASCAL VISUAL OBJECT; Grangier D, 2008, IEEE T PATTERN ANAL, V30, P1371, DOI 10.1109/TPAMI.2007.70791; Huiskes M.J., 2008, MIR 08 P 2008 ACM IN; Lampert C. H., 2009, P IEEE C COMP VIS PA; Lazebnik S., 2006, P IEEE COMP VIS PATT; Makadia A, 2008, P 10 EUR C COMP VIS; Mbanya E., 2010, P WORKSH IMAGECLEF; Mensink T., 2010, P WORKSH IMAGECLEF; Mensink T., 2011, P IEEE C COMP VIS PA; Motohashi N., 2010, P WORKSH IMAGECLEF; Nowak S., 2010, P WORK NOT CLEF; Nowozin S., 2010, P 11 EUR C COMP VIS; Nowozin S, 2010, FOUND TRENDS COMPUT, V6, pX, DOI 10.1561/0600000033; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Perronnin F., 2010, P 11 EUR C COMP VIS; Platt J. C., 2000, ADV LARGE MARGIN CLA; Pletscher P., 2009, P 12 INT C ART INT S; Rabinovich A., 2007, P IEEE INT C COMP VI; Schmid C., 2009, P 12 IEEE INT C COMP; Settles B., 2009, ACTIVE LEARNING LIT; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; van de Sande K., 2010, P WORKSH IMAGECLEF; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Vijayanarasimhan S., 2009, P NEUR INF PROC SYST; Weston J., 2010, P EUR C MACH LEARN; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4	35	14	15	0	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2013	35	2					476	489		10.1109/TPAMI.2012.100	http://dx.doi.org/10.1109/TPAMI.2012.100			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	057JX	22547428	Green Submitted			2022-12-18	WOS:000312560600018
J	Andreopoulos, A; Tsotsos, JK				Andreopoulos, Alexander; Tsotsos, John K.			On Sensor Bias in Experimental Methods for Comparing Interest-Point, Saliency, and Recognition Algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Active vision; attention; shutter speed; gain; feature detection; saliency; recognition	ATTENTION; SCALE; LIGHT; GAIN	Most current algorithm evaluation protocols use large image databases, but give little consideration to imaging characteristics used to create the data sets. This paper evaluates the effects of camera shutter speed and voltage gain under simultaneous changes in illumination and demonstrates significant differences in the sensitivities of popular vision algorithms under variable illumination, shutter speed, and gain. These results show that offline data sets used to evaluate vision algorithms typically suffer from a significant sensor specific bias which can make many of the experimental methodologies used to evaluate vision algorithms unable to provide results that generalize in less controlled environments. We show that for typical indoor scenes, the different saturation levels of the color filters are easily reached, leading to the occurrence of localized saturation which is not exclusively based on the scene radiance but on the spectral density of individual colors present in the scene. Even under constant illumination, foreshortening effects due to surface orientation can affect feature detection and saliency. Finally, we demonstrate that active and purposive control of the shutter speed and gain can lead to significantly more reliable feature detection under varying illumination and nonconstant viewpoints.	[Andreopoulos, Alexander; Tsotsos, John K.] York Univ, Ctr Vis Res, Dept Comp Sci & Engn, Comp Sci & Engn Bldg,4700 Keele St, Toronto, ON M3J 1P3, Canada	York University - Canada	Andreopoulos, A (corresponding author), York Univ, Ctr Vis Res, Dept Comp Sci & Engn, Comp Sci & Engn Bldg,4700 Keele St, Toronto, ON M3J 1P3, Canada.	alekos@cse.yorku.ca; tsotsos@cse.yorku.ca	Tsotsos, John/N-1131-2019	Tsotsos, John/0000-0002-8621-9147				Adams J, 1998, IEEE MICRO, V18, P20, DOI 10.1109/40.743681; Aggarwal M., 2001, P IEEE INT C COMP VI; ALOIMONOS J, 1987, INT J COMPUT VISION, V1, P333; Andreopoulos A., 2009, P IEEE INT C COMP VI; Andreopoulos A, 2011, IEEE T ROBOT, V27, P47, DOI 10.1109/TRO.2010.2090058; Bajcsy R., 1985, P IEEE WORKSH COMP V; BALLARD DH, 1991, ARTIF INTELL, V48, P57, DOI 10.1016/0004-3702(91)90080-4; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5; Burt PJ, 1993, P IEEE INT C COMP VI; Debevec P. E., 1997, P ACM SIGGRAPH; Faille F., 2003, P INT C DIG IM COMP; Gevrekci M, 2009, COMPUT VIS IMAGE UND, V113, P565, DOI 10.1016/j.cviu.2008.11.006; Hasinoff S. W., 2007, P IEEE INT C COMP VI; HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; Lim S, 2004, IEEE T CIRCUITS-I, V51, P779, DOI 10.1109/TCSI.2004.823666; Litwiller D., 2001, PHOTONICS SPECTRA, V35, P2001; Lok C, 2011, NATURE, V469, P284, DOI 10.1038/469284a; Mann S., 1995, P IS TS 48 ANN C; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; MITSUNAGA T, 1999, P IEEE C COMP VIS PA; Nayar S., 2000, P IEEE C COMP VIS PA; Nuske S., 2006, P INT C ROB AUT; Porod W, 2004, ANN NY ACAD SCI, V1013, P92, DOI 10.1196/annals.1305.011; PURPURA K, 1988, P NATL ACAD SCI USA, V85, P4534, DOI 10.1073/pnas.85.12.4534; Robertson M. A., 1999, P IEEE INT C IM PROC; Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446; Theuwissen A. J. P., 1995, SOLID STATE SCI TECH, V1; Tsotsos JK, 2011, COMPUTATIONAL PERSPECTIVE ON VISUAL ATTENTION, P1; TSOTSOS JK, 1992, INT J COMPUT VISION, V7, P127, DOI 10.1007/BF00128132; Unnikrishnan R., 2006, P BRIT MACH VIS C; VALETON JM, 1983, VISION RES, V23, P1539, DOI 10.1016/0042-6989(83)90167-0; Wandell BA, 2002, P IEEE, V90, P5, DOI 10.1109/5.982401; Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32	39	14	16	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2012	34	1					110	126		10.1109/TPAMI.2011.91	http://dx.doi.org/10.1109/TPAMI.2011.91			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	848RB	21576732				2022-12-18	WOS:000297069900008
J	Lanza, A; Di Stefano, L				Lanza, Alessandro; Di Stefano, Luigi			Statistical Change Detection by the Pool Adjacent Violators Algorithm	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Change detection; motion detection; illumination invariance; isotonic regression; Pool Adjacent Violators Algorithm	ILLUMINATION	In this paper, we present a statistical change detection approach aimed at being robust with respect to the main disturbance factors acting in real-world applications such as illumination changes, camera gain and exposure variations, noise. We rely on modeling the effects of disturbance factors on images as locally order-preserving transformations of pixel intensities plus additive noise. This allows us to identify within the space of all of the possible image change patterns the subspace corresponding to disturbance factors effects. Hence, scene changes can be detected by a-contrario testing the hypothesis that the measured pattern is due to disturbance factors, that is, by computing a distance between the pattern and the subspace. By assuming additive Gaussian noise, the distance can be computed within a maximum likelihood nonparametric isotonic regression framework. In particular, the projection of the pattern onto the subspace is computed by an O(N) iterative procedure known as Pool Adjacent Violators algorithm.	[Lanza, Alessandro; Di Stefano, Luigi] Univ Bologna, Fac Engn, Dept Elect Comp Sci & Syst DEIS, I-40136 Bologna, Italy	University of Bologna	Lanza, A (corresponding author), Univ Bologna, Fac Engn, Dept Elect Comp Sci & Syst DEIS, Viale Risorgimento 2, I-40136 Bologna, Italy.	alanza@arces.unibo.it; luigi.distefano@unibo.it	LANZA, ALESSANDRO/N-7220-2015	LANZA, ALESSANDRO/0000-0002-4904-0682				[Anonymous], PATTERN RECOGN LETT; AYER M, 1955, ANN MATH STAT, V26, P641, DOI 10.1214/aoms/1177728423; Barlow R. E., 1972, STAT INFERENCE ORDER; Bhat DN, 1998, IEEE T PATTERN ANAL, V20, P415, DOI 10.1109/34.677275; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Crow F. C., 1984, Computers & Graphics, V18, P207; Durucan E, 2001, P IEEE, V89, P1368, DOI 10.1109/5.959336; KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P115, DOI 10.1007/BF02289694; LANZA A, 2006, P INT C ADV VID SIGN, P1; Mann S, 2000, IEEE T IMAGE PROCESS, V9, P1389, DOI 10.1109/83.855434; Mester R., 2001, Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191), P170; PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839; Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698; Robertson T, 1988, ORDER RESTRICTED STA; SKIFSTAD K, 1989, COMPUT VISION GRAPH, V46, P387, DOI 10.1016/0734-189X(89)90039-X; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; Xie BL, 2004, IMAGE VISION COMPUT, V22, P117, DOI 10.1016/j.imavis.2003.07.003; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]	30	14	14	1	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	2011	33	9					1894	1910		10.1109/TPAMI.2011.42	http://dx.doi.org/10.1109/TPAMI.2011.42			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	792JN	21358002				2022-12-18	WOS:000292740000014
J	Chatzis, SP				Chatzis, Sotirios P.			Hidden Markov Models with Nonelliptically Contoured State Densities	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Hidden Markov models; multivariate normal inverse Gaussian (MNIG) distribution; expectation-maximization; sequential data modeling	MAXIMUM-LIKELIHOOD-ESTIMATION; STATISTICAL PROPERTIES; DISTRIBUTIONS	Hidden Markov models (HMMs) are a popular approach for modeling sequential data comprising continuous attributes. In such applications, the observation emission densities of the HMM hidden states are typically modeled by means of elliptically contoured distributions, usually multivariate Gaussian or Student's-t densities. However, elliptically contoured distributions cannot sufficiently model heavy-tailed or skewed populations which are typical in many fields, such as the financial and the communication signal processing domain. Employing finite mixtures of such elliptically contoured distributions to model the HMM state densities is a common approach for the amelioration of these issues. Nevertheless, the nature of the modeled data often requires postulation of a large number of mixture components for each HMM state, which might have a negative effect on both model efficiency and the training data set's size required to avoid overfitting. To resolve these issues, in this paper, we advocate for the utilization of a nonelliptically contoured distribution, the multivariate normal inverse Gaussian (MNIG) distribution, for modeling the observation densities of HMMs. As we experimentally demonstrate, our selection allows for more effective modeling of skewed and heavy-tailed populations in a simple and computationally efficient manner.	Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, Intelligent Syst & Networks Grp, London SW7 2BT, England	Imperial College London	Chatzis, SP (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, Intelligent Syst & Networks Grp, S Kensington Campus,Exhibit Rd, London SW7 2BT, England.	soteri0s@me.com	Chatzis, Sotirios/H-1975-2014	Chatzis, Sotirios/0000-0002-4956-4013				[Anonymous], 2001, FINANC STOCH, DOI DOI 10.1007/S007800000020; Asuncion A, 2007, UCI MACHINE LEARNING; Azzalini A, 1996, BIOMETRIKA, V83, P715, DOI 10.1093/biomet/83.4.715; BARNDORFFNIELSEN O, 1982, INT STAT REV, V50, P145, DOI 10.2307/1402598; Bartsch MA, 2005, IEEE T MULTIMEDIA, V7, P96, DOI 10.1109/TMM.2004.840597; Bilodeau M., 1999, THEORY MULTIVARIATE; Cappe O., 2005, SPR S STAT; Chatzis SP, 2009, IEEE T PATTERN ANAL, V31, P1657, DOI 10.1109/TPAMI.2008.215; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Giannakopoulos T, 2006, LECT NOTES COMPUT SC, V3955, P502; Gupta AK, 2003, STATISTICS-ABINGDON, V37, P359, DOI 10.1080/715019247; Karlis D, 2009, STAT COMPUT, V19, P73, DOI 10.1007/s11222-008-9072-0; Kosmopoulos D. I., 2006, International Journal of Intelligent Systems Technologies and Applications, V1, P359, DOI 10.1504/IJISTA.2006.009913; Kudo M, 1999, PATTERN RECOGN LETT, V20, P1103, DOI 10.1016/S0167-8655(99)00077-X; LEE KF, 1989, IEEE T ACOUST SPEECH, V37, P1641, DOI 10.1109/29.46546; LEYA C, J MULTIVARI IN PRESS; Lin TI, 2007, STAT SINICA, V17, P909; Lin TI, 2007, STAT COMPUT, V17, P81, DOI 10.1007/s11222-006-9005-8; Lin TI, 2009, J MULTIVARIATE ANAL, V100, P257, DOI 10.1016/j.jmva.2008.04.010; Mclachlan G., 2000, WILEY SER PROB STAT; Mukundan R., 1998, MOMENT FUNCTIONS IMA; Protassov RS, 2004, STAT COMPUT, V14, P67, DOI 10.1023/B:STCO.0000009419.12588.da; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; SALBERG AB, 2001, P 35 AS C SIGN SYST, V1, P143; Sha F., 2007, ADV NEURAL INFORM PR, P1249; Titterington DM, 1985, STAT ANAL FINITE MIX; TWEEDIE MCK, 1957, ANN MATH STAT, V28, P362, DOI 10.1214/aoms/1177706964; TWEEDIE MCK, 1957, ANN MATH STAT, V28, P696, DOI 10.1214/aoms/1177706881; Zhou TY, 2008, J STAT PLAN INFER, V138, P1542, DOI 10.1016/j.jspi.2007.04.033	33	14	14	0	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2010	32	12					2297	2304		10.1109/TPAMI.2010.153	http://dx.doi.org/10.1109/TPAMI.2010.153			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	672BT	20733221				2022-12-18	WOS:000283558700014
J	Raudys, S; Raudys, A				Raudys, Sarunas; Raudys, Aistis			Pairwise Costs in Multiclass Perceptrons	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Cost-sensitive learning; loss function; pairwise classification; perceptron		A novel loss function to train a net of K single-layer perceptrons (KSLPs) is suggested, where pairwise misclassification cost matrix can be incorporated directly. The complexity of the network remains the same; a gradient's computation of the loss function does not necessitate additional calculations. Minimization of the loss requires a smaller number of training epochs. Efficacy of cost-sensitive methods depends on the cost matrix, the overlap of the pattern classes, and sample sizes. Experiments with real-world pattern recognition (PR) tasks show that employment of novel loss function usually outperforms three benchmark methods.	[Raudys, Sarunas] Vilnius State Univ, Dept Math & Informat, LT-08303 Vilnius, Lithuania; [Raudys, Aistis] Inst Math & Informat, LT-08663 Vilnius, Lithuania	Vilnius University; Vilnius University	Raudys, S (corresponding author), Vilnius State Univ, Dept Math & Informat, Didlaukio 47, LT-08303 Vilnius, Lithuania.	sarunas.raudys@mif.vu.lt; aistis@raudys.com						AMARI S, 1967, IEEE TRANS ELECTRON, VEC16, P299, DOI 10.1109/PGEC.1967.264666; [Anonymous], MACHINE LEARNING TEC; Asuncion A, 2007, UCI MACHINE LEARNING; Bishop C.M, 2006, PATTERN RECOGN; David E., 1986, PARALLEL DISTRIBUTED, P318, DOI DOI 10.5555/104279.104293; Domingos P.M., 1999, P 5 ACM SIGKDD INT C, P155, DOI DOI 10.1145/312129.312220; Duda R.O., 2000, PATTERN CLASSIFICATI; Geibel P., 2004, Intelligent Data Analysis, V8, P439; Geibel P, 2004, APPL INTELL, V21, P45, DOI 10.1023/B:APIN.0000027766.72235.bc; Olshen R., 1984, CLASSIFICATION REGRE; Pekalska E, 2002, PATTERN RECOGN LETT, V23, P943, DOI 10.1016/S0167-8655(02)00024-7; Raudys S, 1998, NEURAL NETWORKS, V11, P283, DOI 10.1016/S0893-6080(97)00135-4; Raudys S, 1998, IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, P1530, DOI 10.1109/IJCNN.1998.686004; Raudys S., 2001, STAT NEURAL CLASSIFI, P209, DOI [10.1007/978-1-4471-0359-2_6, DOI 10.1007/978-1-4471-0359-2_6]; Santos-Rodriguez R, 2009, MACH LEARN, V76, P271, DOI 10.1007/s10994-009-5132-8; Skurichina M, 2000, IEEE T NEURAL NETWOR, V11, P504, DOI 10.1109/72.839019; Zhou Z., 2006, P 21 NAT C ART INT, P567	18	14	17	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2010	32	7					1324	1328		10.1109/TPAMI.2010.72	http://dx.doi.org/10.1109/TPAMI.2010.72			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	595YC	20489234				2022-12-18	WOS:000277649100014
J	Mary-Huard, T; Robin, S				Mary-Huard, Tristan; Robin, Stephane			Tailored Aggregation for Classification	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Classification; aggregation; selection; large-dimension data; ordered variables	FEATURE-SELECTION; EXPRESSION; TUMOR	Compression and variable selection are two classical strategies to deal with large-dimension data sets in classification. We propose an alternative strategy, called aggregation, which consists of a clustering step of redundant variables and a compression step within each group. We develop a statistical framework to define tailored aggregation methods that can be combined with selection methods to build reliable classifiers that benefit from the information contained in redundant variables. Two algorithms are proposed for ordered and nonordered variables, respectively. Applications to the kNN and CART algorithms are presented.	[Mary-Huard, Tristan; Robin, Stephane] AgroParisTech, UMR, INRA, MIA 518, F-75231 Paris 05, France	AgroParisTech; INRAE; UDICE-French Research Universities; Universite Paris Saclay	Mary-Huard, T (corresponding author), AgroParisTech, UMR, INRA, MIA 518, 16 Rue Claude Bernard, F-75231 Paris 05, France.	maryhuar@agroparistech.fr; robin@agroparistech.fr		Robin, Stephane/0000-0003-1045-069X				Alon U, 1999, P NATL ACAD SCI USA, V96, P6745, DOI 10.1073/pnas.96.12.6745; Anderberg MR, 1973, CLUSTER ANAL APPL; Ben-Dor A, 2000, J COMPUT BIOL, V7, P559, DOI 10.1089/106652700750050943; Biau G, 2005, IEEE T INFORM THEORY, V51, P2163, DOI 10.1109/TIT.2005.847705; Birge L, 2007, PROBAB THEORY REL, V138, P33, DOI 10.1007/s00440-006-0011-8; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; COSTANZO D, 2006, P 17 S COMP STAT, P821; DETTLING M, 2003, P C DISTR STAT COMP; Dettling M, 2002, GENOME BIOL, V3; Diaz-Uriarte R, 2004, MOL SIGNATURES GENE; Dudoit S, 2002, J AM STAT ASSOC, V97, P77, DOI 10.1198/016214502753479248; Elisseeff A., 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616; FIX E, 1991, NEAREST NEIGHBOR NN; HARMAN H, 1973, MODERN FACTOR ANAL; HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; Hastie T, 2001, GENOME BIOL, V2; Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X; Krishnapuram B, 2004, IEEE T PATTERN ANAL, V26, P1105, DOI 10.1109/TPAMI.2004.55; KRISHNAPURAM B, 2004, KERNEL METHODS COMPU; Lavielle M, 1999, STOCH PROC APPL, V83, P79, DOI 10.1016/S0304-4149(99)00023-X; Lavielle M, 2005, SIGNAL PROCESS, V85, P1501, DOI 10.1016/j.sigpro.2005.01.012; Mary-Huard T, 2007, J MULTIVARIATE ANAL, V98, P695, DOI 10.1016/j.jmva.2006.06.003; Michiels S, 2005, LANCET, V365, P488, DOI 10.1016/S0140-6736(05)17866-0; Olshen R., 1984, CLASSIFICATION REGRE; Preda C, 2007, COMPUTATION STAT, V22, P223, DOI 10.1007/s00180-007-0041-4; ROSSI F, 2006, NEURAL COMPUTING, V69, P223; SAPORTA G, 1990, PROBABILITES ANAL DO; Su Y, 2003, BIOINFORMATICS, V19, P1578, DOI 10.1093/bioinformatics/btg179; TULEAU C, 2005, THESIS U PARIS SUD 1; Xiong MM, 2001, MOL GENET METAB, V73, P239, DOI 10.1006/mgme.2001.3193; Yu L, 2004, J MACH LEARN RES, V5, P1205	33	14	14	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2009	31	11					2098	2105		10.1109/TPAMI.2009.55	http://dx.doi.org/10.1109/TPAMI.2009.55			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	493VV	19762936				2022-12-18	WOS:000269767600015
J	Zhang, H; Wong, KYK				Zhang, Hui; Wong, Kwan-Yee K.			Self-Calibration of Turntable Sequences from Silhouettes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Self-calibration; circular points; silhouettes; turntable motion	CAMERA CALIBRATION; MOTION; PROFILES; ROBUST	This paper addresses the problem of recovering both the intrinsic and extrinsic parameters of a camera from the silhouettes of an object in a turntable sequence. Previous silhouette-based approaches have exploited correspondences induced by epipolar tangents to estimate the image invariants under turntable motion and achieved a weak calibration of the cameras. In order to recover the rotation angles and obtain a euclidean reconstruction, these approaches require the prior knowledge of the camera intrinsics. In this paper, we propose a novel approach for recovering the rotation angles precisely in the absence of the camera intrinsics. It is known that the fundamental matrix relating any two views in a turntable sequence can be expressed explicitly in terms of the image invariants, the rotation angle, and a fixed scalar. It will be shown that the imaged circular points for the turntable plane can also be formulated in terms of the same image invariants and fixed scalar. This allows the imaged circular points to be recovered directly from the estimated image invariants. The imaged circular points and the image invariants provide constraints for the estimation of the imaged absolute conic, and the camera calibration matrix can thus be recovered. A robust method for estimating the fixed scalar from image triplets is introduced, and a method for recovering the rotation angles by using the estimated imaged circular points and epipoles is presented. Using the estimated camera intrinsics and extrinsics, a euclidean reconstruction can be obtained. Experimental results on real data sequences are presented which demonstrate the high precision achieved by the proposed method.	[Zhang, Hui] United Int Coll, Div Sci & Technol, Zhuhai 519085, Guangdong, Peoples R China; [Wong, Kwan-Yee K.] Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China	Beijing Normal University - Hong Kong Baptist University United International College; University of Hong Kong	Zhang, H (corresponding author), United Int Coll, Div Sci & Technol, 28 Jingeng Rd, Zhuhai 519085, Guangdong, Peoples R China.	amyzhang@uic.edu.hk; kykwong@cs.hku.hk	; Wong, Kenneth Kwan Yee/C-1577-2009	ZHANG, Hui/0000-0002-1681-7926; Wong, Kenneth Kwan Yee/0000-0001-8560-9007; Zhang, Hui/0000-0002-9807-5419				Astrom K, 1999, INT J COMPUT VISION, V33, P51, DOI 10.1023/A:1008113231241; CIPOLLA R, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P269, DOI 10.1109/ICCV.1995.466775; Cipolla R., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P616, DOI 10.1109/ICCV.1990.139606; CIPOLLA R, 1992, INT J COMPUT VISION, V9, P83, DOI 10.1007/BF00129682; Cipolla R., 1999, VISUAL MOTION CURVES; FITZGIBBON AW, 1998, P EUR WORKSH 3D STRU, P155; Furukawa Y, 2006, IEEE T PATTERN ANAL, V28, P302, DOI 10.1109/TPAMI.2006.41; Gentle J. E., 1998, STATIST COMP, P87; Hartley R., 2004, ROBOTICA; Hernandez C, 2007, IEEE T PATTERN ANAL, V29, P343, DOI 10.1109/TPAMI.2007.42; Jiang G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P221, DOI 10.1109/ICCV.2003.1238345; JIANG G, 2002, P 7 EUR C COMP VIS, P482; Joshi T, 1999, INT J COMPUT VISION, V31, P31, DOI 10.1023/A:1008042709602; Liang C, 2005, PROC CVPR IEEE, P878; Mendonca PRS, 2001, IEEE T PATTERN ANAL, V23, P604, DOI 10.1109/34.927461; MENDONCA PRS, 2000, P 6 EUR C COMP VIS, V2, P864; NIEM W, 1994, P SOC PHOTO-OPT INS, V2182, P388, DOI 10.1117/12.171088; PORRILL J, 1991, IMAGE VISION COMPUT, V9, P45, DOI 10.1016/0262-8856(91)90048-T; RIEGER JH, 1986, OPT LETT, V11, P123, DOI 10.1364/OL.11.000123; Semple J. G., 1998, ALGEBRAIC PROJECTIVE; Sinha SN, 2004, PROC CVPR IEEE, P195; Szeliski R., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P625, DOI 10.1109/CVPR.1991.139764; VIEVILLE T, 1996, P 4 EUR C COMP VIS, P207; Wong KYK, 2004, IEEE T IMAGE PROCESS, V13, P379, DOI 10.1109/TIP.2003.821113; Wong KYK, 2003, IEEE T PATTERN ANAL, V25, P147, DOI 10.1109/TPAMI.2003.1177148; Wong KYK, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P217, DOI 10.1109/ICCV.2001.937627; ZHANG G, 2006, P BRIT MACH VIS C, V1, P67; ZHANG H, 2005, P BRIT MACH VIS C, V1, P79	28	14	15	1	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2009	31	1					5	14		10.1109/TPAMI.2008.56	http://dx.doi.org/10.1109/TPAMI.2008.56			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	372GI	19029542				2022-12-18	WOS:000260889700002
J	Stewart, L; He, XM; Zemel, RS				Stewart, Liam; He, Xuming; Zemel, Richard S.			Learning flexible features for conditional random fields	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						machine learning; statistical models; induction; text analysis; pixel classification; Markov random fields		Extending traditional models for discriminative labeling of structured data to include a higher order structure in the labels results in an undesirable exponential increase in model complexity. In this paper, we present a model that is capable of learning such structures using a random field of parameterized features. These features can be functions of arbitrary combinations of observations, labels, and auxiliary hidden variables. We also present a simple induction scheme to learn these features, which can automatically determine the complexity needed for a given data set. We apply the model to two real-world tasks, information extraction and image labeling, and compare our results to several other methods for discriminative labeling.	[Stewart, Liam] Google, Mountain View, CA 94043 USA; [He, Xuming; Zemel, Richard S.] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada	Google Incorporated; University of Toronto	Stewart, L (corresponding author), Google, 1600 Amphitheatre Pkwy, Mountain View, CA 94043 USA.	liam@cs.toronto.edu; hexm@cs.toronto.edu; zemel@cs.toronto.edu						ALTUN Y, 2003, P 20 INT C MACH LEAR; BENGIO Y, 1995, ADV NEURAL INFORM PR, V7; HE X, 2004, P IEEE COMP VIS PATT; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; KAKADE S, 2002, P 19 INT C MACH LEAR; Kumar S., 2003, P 9 IEEE INT C COMP; LAFFERTY J, 2004, P 21 INT C MACH LEAR; Lafferty John, 2001, CONDITIONAL RANDOM F, P282; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; MacKay D. J. C., 2003, INFORM THEORY INFERE, P269; McCallum A., 2000, P 17 INT C MACH LEAR; MCCALLUM A, 2003, P 19 C UNC ART INT U; PENG F, 2004, P HUM LANG TECHN C N; Pietra S.D., 1997, IEEE T PATTERN ANAL, V19, P380; Roth S., 2005, P IEEE COMP VIS PATT; SARAWAGI S, 2005, ADV NEURAL INFORM PR, V17; Shotton J., 2006, P 9 EUR C COMP VIS E; Sutton Charles, 2004, P ICML WORKSH STAT R; SWENDSEN RH, 1987, PHYS REV LETT, V58, P86, DOI 10.1103/PhysRevLett.58.86; Taskar B., 2003, P NEUR INF PROC SYST; WELLING M, 2003, ADV NEURAL INFORM PR, V15; Welling M., 2005, ADV NEURAL INFORM PR, V17; Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627	23	14	14	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2008	30	8					1415	1426		10.1109/TPAMI.2007.70790	http://dx.doi.org/10.1109/TPAMI.2007.70790			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	312OC	18566495				2022-12-18	WOS:000256679700008
J	Katsoulas, D; Bastidas, CC; Kosmopoulos, D				Katsoulas, Dimitrios; Bastidas, Christian Cea; Kosmopoulos, Dimitrios			Superquadric segmentation in range images via fusion of region and boundary information	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						range data; shape; size and shape; region growing; partitioning; edge and feature detection; surface fitting; applications	OBJECTS; MODELS; SNAKES	The high potential of Superquadrics as modeling elements for image segmentation tasks has been pointed out for years in the computer vision community. In this work, we employ superquadrics as modeling elements for multiple object segmentation in range images. Segmentation is executed in two stages: First, a hypothesis about the values of the segmentation parameters is generated. Second, the hypothesis is refined locally. In both stages, object boundary and region information are considered. Boundary information is derived via model-based edge detection in the input range image. Hypothesis generation uses boundary information to isolate image regions that can be accurately described by superquadrics. Within hypothesis refinement, a game-theoretic framework is used to fuse the two information sources by associating an objective function to each information source. Iterative optimization of the two objective functions in succession, outputs a precise description of all image objects. We demonstrate experimentally that this approach substantially improves the most established method in superquadric segmentation in terms of accuracy and computational efficiency. We demonstrate the applicability of our segmentation framework in real-world applications by constructing a novel robotic system for automatic unloading of jumbled box-like objects from platforms.	[Katsoulas, Dimitrios; Kosmopoulos, Dimitrios] Demokritos Natl Ctr Sci Res, Computat Intelligence Lab, Inst Informat & Telecommun, GR-15310 Athens, Greece; [Bastidas, Christian Cea] Entel SA, Santiago 7550611, Chile	National Centre of Scientific Research "Demokritos"	Katsoulas, D (corresponding author), Demokritos Natl Ctr Sci Res, Computat Intelligence Lab, Inst Informat & Telecommun, GR-15310 Athens, Greece.	dkats@iit.demokritos.gr; ccea@entel.cl; dkosmo@iit.demokritos.gr	Kosmopoulos, Dimitrios/P-4325-2015	Kosmopoulos, Dimitrios/0000-0003-3325-1247				Barr A. H., 1981, IEEE Computer Graphics and Applications, V1, P11, DOI 10.1109/MCG.1981.1673799; BENOIS J, 1992, P 11 ICPR, VC, P331; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; BIEDERMAN I, 1985, COMPUT VISION GRAPH, V32, P29, DOI 10.1016/0734-189X(85)90002-7; BOZMA HI, 1994, IEEE T PATTERN ANAL, V16, P1074, DOI 10.1109/34.334387; CEA C, 2004, THESIS U FREIBURG; CHAKRABORTY A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P624; Chakraborty A, 1999, IEEE T PATTERN ANAL, V21, P12, DOI 10.1109/34.745730; CHAKRABORTY A, 1996, THESIS YALE U; CHEVALIER L, 2003, P INT C CENTR EUR CO; DeCarlo D, 1998, IEEE T PATTERN ANAL, V20, P1186, DOI 10.1109/34.730554; Dickinson C, 1997, J COUNTRY MUSIC, V19, P3; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Duda RO, 1973, PATTERN RECOGNITION; FERRIE FP, 1993, IEEE T PATTERN ANAL, V15, P771, DOI 10.1109/34.236252; Freixenet J, 2004, LECT NOTES COMPUT SC, V3022, P250; GUPTA A, 1993, CVGIP-IMAG UNDERSTAN, V58, P302, DOI 10.1006/ciun.1993.1044; GUPTA A, 1989, P SPIE S INT ROB COM, V8, P98; HANSON AJ, 1988, COMPUT VISION GRAPH, V44, P191, DOI 10.1016/S0734-189X(88)80005-7; Horikoshi T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P168, DOI 10.1109/CVPR.1993.340993; Jaklic A., 2000, COMPUTATIONAL IMAGIN, V20; Jiang XY, 1999, COMPUT VIS IMAGE UND, V73, P183, DOI 10.1006/cviu.1998.0715; Jiang XY, 2000, IEEE T PATTERN ANAL, V22, P1252, DOI 10.1109/34.888710; Katsoulas D, 2004, INT C PATT RECOG, P80, DOI 10.1109/ICPR.2004.1334045; Katsoulas D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P931; KATSOULAS D, 2004, THESIS U FREIBURG; Katsoulas D, 2006, INT C PATT RECOG, P719; KEREN D, 1994, IEEE T PATTERN ANAL, V16, P38, DOI 10.1109/34.273718; Leonardis A, 1997, IEEE T PATTERN ANAL, V19, P1289, DOI 10.1109/34.632988; LEONIDOPOULOS G, 1995, POLYM TEST, V14, P3, DOI 10.1016/0142-9418(95)90612-K; LI S, 1987, AUTOMATICA, V23, P523, DOI 10.1016/0005-1098(87)90081-1; Metaxas D., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P641, DOI 10.1109/ICCV.1993.378151; MUNOZ X, 2003, THESIS U GIRONA; MURAKI S, 1991, COMP GRAPH, V25, P227, DOI 10.1145/127719.122743; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; PARAGIOS N, 2002, P EUR C COMP VIS, V2, P224; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P107, DOI 10.1007/BF00127812; Pilu M, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P257; RAJA NS, 1992, IMAGE VISION COMPUT, V10, P179, DOI 10.1016/0262-8856(92)90069-F; Schoukens J., 1991, IDENTIFICATION LINEA; Sclaroff S, 2001, IEEE T PATTERN ANAL, V23, P475, DOI 10.1109/34.922706; SHIMBASHI T, 1995, P IEEE INT C IM PROC, VC, P65; SINCLAIR D, 1999, TR9904 AT T LAB; Skocaj D, 2000, INT C PATT RECOG, P778, DOI 10.1109/ICPR.2000.905506; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; TEK H, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P156, DOI 10.1109/ICCV.1995.466792; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; Terzopoulos D., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P269; Wu KN, 1997, IMAGE VISION COMPUT, V15, P143, DOI 10.1016/S0262-8856(96)01124-9; Ye C, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P2512, DOI 10.1109/ROBOT.2002.1013609; Zha HB, 1998, INT C PATT RECOG, P658, DOI 10.1109/ICPR.1998.711230; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	55	14	17	2	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2008	30	5					781	795		10.1109/TPAMI.2007.70736	http://dx.doi.org/10.1109/TPAMI.2007.70736			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	272SI	18369249	Green Submitted			2022-12-18	WOS:000253879700003
J	Kumar, S; Ong, SH; Ranganath, S; Chew, FT				Kumar, Saravana; Ong, Sim Heng; Ranganath, Surendra; Chew, Fook Tim			A luminance- and contrast-invariant edge-similarity measure	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						edge detection; filtering; projection angles; similarity measure		A novel similarity measure for edge-detection that is robust to varying luminance and contrast is presented. It incorporates a regularization term and employs directional FIR edge filters with hyperbolic tangent profiles to ensure improved noise performance and edge localization compared to classical methods.	Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore; Natl Univ Singapore, Dept Biol Sci, Singapore 117543, Singapore	National University of Singapore; National University of Singapore	Kumar, S (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Block E4,Level 5,Room 48,4 Engn Dr 3, Singapore 117576, Singapore.	engp2453@nus.edu.sg; eleongsh@nus.edu.sg; elesr@nus.edu.sg; dbscft@nus.edu.sg	Chew, Fook Tim/E-7259-2010; Ong, Sim-Heng/R-9244-2019	Chew, Fook Tim/0000-0003-1337-5146; Ong, Sim-Heng/0000-0003-2766-8150				CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Demigny D, 1997, IEEE T PATTERN ANAL, V19, P1199, DOI 10.1109/34.632980; Desolneux A, 2001, J MATH IMAGING VIS, V14, P271, DOI 10.1023/A:1011290230196; Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.1080/01621459.1995.10476626; FREI W, 1977, IEEE T COMPUT, V26, P988, DOI 10.1109/TC.1977.1674733; JOHNSON RP, 1990, PATTERN RECOGN, V23, P311, DOI 10.1016/0031-3203(90)90018-G; Kovesi P, 2000, PSYCHOL RES-PSYCH FO, V64, P136, DOI 10.1007/s004260000024; Kumar S, 2004, IEEE IMAGE PROC, P135; Kundu A., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P11, DOI 10.1109/CVPR.1989.37823; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MORRONE MC, 1986, NATURE, V324, P250, DOI 10.1038/324250a0; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; PETROU M, 1991, IEEE T PATTERN ANAL, V13, P483, DOI 10.1109/34.134047; Pratt W, 1991, DIGITAL IMAGE PROCES; Prewitt, 1970, PICTURE PROCESSING P, V10, P15, DOI DOI 10.4236/AD.2014.22003; Qian RJ, 1996, IEEE T IMAGE PROCESS, V5, P1215, DOI 10.1109/83.502412; Rosin PL, 1997, MACH VISION APPL, V9, P139, DOI 10.1007/s001380050036; TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769	18	14	15	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	2006	28	12					2042	2048		10.1109/TPAMI.2006.236	http://dx.doi.org/10.1109/TPAMI.2006.236			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	093UL	17108378				2022-12-18	WOS:000241195700014
J	Shimodaira, H				Shimodaira, H			A shape-from-shading method of polyhedral objects using prior information	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						vision and scene understanding; scene analysis; 3D/stereo scene analysis; modeling and recovery of physical attributes; shape; shading	IMAGE; VISION	We propose a new method for recovering the 3D shape of a polyhedral object from its single 2D image using the shading information contained in the image and the prior information on the object. In a strict sense, we cannot recover the shape of a polyhedron from an incorrect line drawing, even if it is practically almost correct. In order to overcome this problem, we propose a flexible face positioning method that can permit inconsistencies in the recovered shape that arise from vertex-position errors contained in incorrect line drawings. Also, we propose to use prior information about the horizontality and verticality of special faces and the convex and concave properties of the edges in order to attain good solutions and present a method of formulating such prior information as physical constraints. The shape-from-shading method is formulated as a minimization problem of a nonlinear cost function with the nonlinear constraints and its solution is searched by a global optimization algorithm. In the experiments with a synthetic image and three kinds of real images, shapes that are similar to those of the actual objects were recovered in all cases. As a result, the proposed method has proven to be effective in the shape recovery of simple-shape polyhedral objects.	Bunkyo Univ, Dept Informat & Commun, Kanagawa 2538550, Japan		Shimodaira, H (corresponding author), Bunkyo Univ, Dept Informat & Commun, 1100 Namegaya, Kanagawa 2538550, Japan.	shimo-hi@hi-ho.ne.jp						CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CLOWES MB, 1971, ARTIF INTELL, V2, P79, DOI 10.1016/0004-3702(71)90005-1; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; HUANG X, 1992, P INT JOINT C NEUR N, V1, P441; Huffman D. A., 1971, Machine Intelligence Volume 6, P295; HUFFMAN DA, 1977, MACH INTELL, V8, P493; JONES DR, 1993, J OPTIMIZ THEORY APP, V79, P157, DOI 10.1007/BF00941892; MACKWORTH AK, 1973, ARTIF INTELL, V4, P121, DOI 10.1016/0004-3702(73)90003-9; OKAMOTO Y, 1992, REPORT INFORM PROCES, V76, P87; OREN M, 1995, INT J COMPUT VISION, V14, P227, DOI 10.1007/BF01679684; PENNA MA, 1989, IEEE T PATTERN ANAL, V11, P545, DOI 10.1109/34.24790; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; Ros L, 2002, IEEE T PATTERN ANAL, V24, P456, DOI 10.1109/34.993554; Shimshoni I, 1997, COMPUT VIS IMAGE UND, V65, P296, DOI 10.1006/cviu.1996.0569; SHOMAR WJ, 1992, COMPUTER VISION IMAG, P459; Sugihara K, 1999, DISCRETE COMPUT GEOM, V21, P243, DOI 10.1007/PL00009419; SUGIHARA K, 1984, ARTIF INTELL, V23, P59, DOI 10.1016/0004-3702(84)90005-5; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19; Yang J, 1996, P SOC PHOTO-OPT INS, V2899, P66; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284	20	14	15	0	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2006	28	4					612	624		10.1109/TPAMI.2006.67	http://dx.doi.org/10.1109/TPAMI.2006.67			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	011FK	16566509				2022-12-18	WOS:000235253300010
J	Galbraith, JM; Kenyon, GT; Ziolkowski, RW				Galbraith, JM; Kenyon, GT; Ziolkowski, RW			Time-to-collision estimation from motion based on primate visual processing	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion processing; autonomous robotics; neuromorphic computing; computer vision; depth cues; time-to-collision; optic flow	OPTICAL-FLOW; IMAGE MOTION; SELF-MOTION; MODEL; NAVIGATION; FIELD; COMPUTATION; FILTERS; DIVERGENCE; VELOCITY	A population coded algorithm, built on established models of motion processing in the primate visual system, computes the time-to-collision of a mobile robot to real-world environmental objects from video imagery. A set of four transformations starts with motion energy, a spatiotemporal frequency based computation of motion features. The following processing stages extract image velocity features similar to, but distinct from, optic flow; "translation" features, which account for velocity errors including those resulting from the aperture problem; and finally, estimate the time-to-collision. Biologically motivated population coding distinguishes this approach from previous methods based on optic flow. A comparison of the population coded approach with the popular optic flow algorithm of Lucas and Kanade against three types of approaching objects shows that the proposed method produces more robust time-to-collision information from a real world input stimulus in the presence of the aperture problem and other noise sources. The improved performance comes with increased computational cost, which would ideally be mitigated by special purpose hardware architectures.	Los Alamos Natl Lab, Los Alamos, NM 87545 USA; Univ Arizona, Dept Elect Engn & Comp Sci, Tucson, AZ 85721 USA	United States Department of Energy (DOE); Los Alamos National Laboratory; University of Arizona	Galbraith, JM (corresponding author), Los Alamos Natl Lab, P-21,MS-D454,POB 1663, Los Alamos, NM 87545 USA.	jgalb@lanl.gov; gkenyon@lanl.gov; ziolkows@ece.arizona.edu		Ziolkowski, Richard/0000-0003-4256-6902; Kenyon, Garrett/0000-0003-4836-3938				ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141; Blanchard M, 2000, ROBOT AUTON SYST, V30, P17, DOI 10.1016/S0921-8890(99)00063-9; Branca A, 2000, IMAGE VISION COMPUT, V18, P833, DOI 10.1016/S0262-8856(99)00082-7; Camus T, 1997, REAL-TIME IMAGING, V3, P71, DOI 10.1006/rtim.1996.0048; Clifford CWG, 2000, BIOL CYBERN, V82, P383, DOI 10.1007/s004220050592; Colombo C, 2000, ROBOT AUTON SYST, V31, P5, DOI 10.1016/S0921-8890(99)00077-9; Coombs D, 1998, IEEE T ROBOTIC AUTOM, V14, P49, DOI 10.1109/70.660840; DUFFY CJ, 1991, J NEUROPHYSIOL, V65, P1329, DOI 10.1152/jn.1991.65.6.1329; FLEET DJ, 1995, IEEE T PATTERN ANAL, V17, P61, DOI 10.1109/34.368151; GALBRAITH J, 2002, THESIS U ARIZONA; GRZYWACZ NM, 1990, PROC R SOC SER B-BIO, V239, P129, DOI 10.1098/rspb.1990.0012; HARRIS LR, 1997, COMPUTATIONAL PSYCHO; HEEGER DJ, 1987, J OPT SOC AM A, V4, P1455, DOI 10.1364/JOSAA.4.001455; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; LEE DN, 1980, PHILOS T R SOC B, V290, P169, DOI 10.1098/rstb.1980.0089; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; Ludtke N, 2003, IEEE T NEURAL NETWOR, V14, P794, DOI 10.1109/TNN.2003.813838; MEYER FG, 1994, IEEE T ROBOTIC AUTOM, V10, P792, DOI 10.1109/70.338534; NELSON RC, 1989, IEEE T PATTERN ANAL, V11, P1102, DOI 10.1109/34.42840; Neven H, 1996, BIOL CYBERN, V75, P293, DOI 10.1007/s004220050296; NOWLAN SJ, 1994, J OPT SOC AM A, V11, P3177, DOI 10.1364/JOSAA.11.003177; Palmer S.E., 1999, VISION SCI PHOTONS P; PERRONE JA, 1994, VISION RES, V34, P2917, DOI 10.1016/0042-6989(94)90060-4; PERRONE JA, 1992, J OPT SOC AM A, V9, P177, DOI 10.1364/JOSAA.9.000177; PROESMANS M, 1994, LECT NOTES COMPUT SC, V801, P295; SANDINI G, 1990, IEEE T PATTERN ANAL, V12, P13, DOI 10.1109/34.41380; SantosVictor J, 1997, ROBOT AUTON SYST, V19, P299, DOI 10.1016/S0921-8890(96)00058-9; Simoncelli E. P., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P310, DOI 10.1109/CVPR.1991.139707; SOBEY PJ, 1994, BIOL CYBERN, V71, P433, DOI 10.1007/BF00198919; Tsai JJ, 2003, VISION RES, V43, P445, DOI 10.1016/S0042-6989(02)00510-2; Watanabe T, 1998, HIGH LEVEL MOTION PR; WEISS Y, 2001, PROBABILISTIC MODELS, P81	35	14	16	0	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	2005	27	8					1279	1291		10.1109/TPAMI.2005.168	http://dx.doi.org/10.1109/TPAMI.2005.168			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	934HW	16119266				2022-12-18	WOS:000229700900008
J	Braga-Neto, U; Goutsias, J				Braga-Neto, U; Goutsias, J			Object-based image analysis using multiscale connectivity	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						connectivity; connection; hierarchical clustering; hierarchical segmentation; mathematical morphology; multiscale image analysis; multiscale image decomposition; object-based image analysis; reconstruction opening	PATTERN-SPECTRUM; SEGMENTATION; EQUATIONS; OPERATORS	This paper introduces a novel approach for image analysis based on the notion of multiscale connectivity. We use the proposed approach to design several novel tools for object-based image representation and analysis which exploit the connectivity structure of images in a multiscale fashion. More specifically, we propose a nonlinear pyramidal image representation scheme, which decomposes an image at different scales by means of multiscale grain filters. These filters gradually remove connected components from an image that fail to satisfy a given criterion. We also use the concept of multiscale connectivity to design a hierarchical data partitioning tool. We employ this tool to construct another image representation scheme, based on the concept of component trees, which organizes partitions of an image in a hierarchical multiscale fashion. In addition, we propose a geometrically-oriented hierarchical clustering algorithm which generalizes the classical single-linkage algorithm. Finally, we propose two object-based multiscale image summaries, reminiscent of the well-known (morphological) pattern spectrum, which can be useful in image analysis and image understanding applications.	CPqAM, FIOCRUZ, Aggeu MAgalhaes Res Ctr, Virol & Expt Therapy Lab, Recife, PE, Brazil; Johns Hopkins Univ, Ctr Imaging Sci, Baltimore, MD 21218 USA; Johns Hopkins Univ, Dept Elect & Comp Engn, Baltimore, MD 21218 USA	Fundacao Oswaldo Cruz; Johns Hopkins University; Johns Hopkins University	Braga-Neto, U (corresponding author), CPqAM, FIOCRUZ, Aggeu MAgalhaes Res Ctr, Virol & Expt Therapy Lab, Recife, PE, Brazil.	ulisses_braga@cpqam.fiocruz.br; goutsias@jhu.edu	Braga-Neto, Ulisses/ABI-2677-2020; Goutsias, John/A-3274-2010; MA, Lei/I-4597-2014					Braga-Neto U, 2003, J MATH IMAGING VIS, V19, P5, DOI 10.1023/A:1024476403183; Braga-Neto U, 2004, IEEE T IMAGE PROCESS, V13, P1567, DOI 10.1109/TIP.2004.837514; Braga-Neto U, 2002, COMPUT VIS IMAGE UND, V85, P22, DOI 10.1006/cviu.2002.0961; Braga-Neto U, 2003, COMPUT VIS IMAGE UND, V89, P70, DOI 10.1016/S1077-3142(03)00014-6; Braga-Neto UM, 2000, COMP IMAG VIS, V18, P159; BRAGANETO UM, 2005, IN PRESS J MATH IMAG; BRAGANETO UM, 2001, THESIS J HOPKINS U; BRAGANETO UM, 2005, IN PRESS COMPUTER VI; BROCKETT RW, 1994, IEEE T SIGNAL PROCES, V42, P3377, DOI 10.1109/78.340774; Chakravarthy SV, 1996, IEEE T NEURAL NETWOR, V7, P1250, DOI 10.1109/72.536318; CHEN MH, 1989, IEEE T PATTERN ANAL, V11, P694, DOI 10.1109/34.192464; Cheng F, 1992, IEEE T IMAGE PROCESS, V1, P533, DOI 10.1109/83.199924; Crespo J, 1995, SIGNAL PROCESS, V47, P201, DOI 10.1016/0165-1684(95)00108-5; DOUGHERTY ER, 1995, PATTERN RECOGN, V28, P81, DOI 10.1016/0031-3203(94)00083-X; DUBES R, 1976, PATTERN RECOGN, V8, P247, DOI 10.1016/0031-3203(76)90045-5; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Goutsias J, 2000, IEEE T IMAGE PROCESS, V9, P1862, DOI 10.1109/83.877209; GOWER JC, 1969, APPL STATIST, V18, P54, DOI DOI 10.2307/2346439; Heijmans H., 1994, MORPHOLOGICAL IMAGE; Heijmans HJAM, 1999, COMPUT VIS IMAGE UND, V73, P99, DOI 10.1006/cviu.1998.0703; Heijmans HJAM, 2002, J VIS COMMUN IMAGE R, V13, P269, DOI 10.1006/jvci.2001.0480; Jackway PT, 1996, IEEE T PATTERN ANAL, V18, P38, DOI 10.1109/34.476009; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; Jones R, 1999, COMPUT VIS IMAGE UND, V75, P215, DOI 10.1006/cviu.1999.0777; KUNT M, 1985, P IEEE, V73, P549, DOI 10.1109/PROC.1985.13184; Leung Y, 2000, IEEE T PATTERN ANAL, V22, P1396, DOI 10.1109/34.895974; LIFSHITZ LM, 1990, IEEE T PATTERN ANAL, V12, P529, DOI 10.1109/34.56189; Mallat S., 1989, IEEE PAMI, V11, P674; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; Matheron G., 1975, RANDOM SETS INTEGRAL; Roberts SJ, 1997, PATTERN RECOGN, V30, P261, DOI 10.1016/S0031-3203(96)00079-9; Ronse C, 1998, J MATH IMAGING VIS, V8, P41, DOI 10.1023/A:1008210216583; SALEMBIER P, 1995, IEEE T IMAGE PROCESS, V4, P1153, DOI 10.1109/83.403422; Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500; SALEMBIER P, 1994, IEEE T IMAGE PROCESS, V3, P639, DOI 10.1109/83.334980; Serra J, 1998, J MATH IMAGING VIS, V9, P231, DOI 10.1023/A:1008324520475; Serra J., 2000, Fundamenta Informaticae, V41, P147; Serra J, 1988, IMAGE ANAL MATH MORP; SIBSON R, 1973, COMPUT J, V16, P30, DOI 10.1093/comjnl/16.1.30; Sivakumar K, 1999, IEEE T PATTERN ANAL, V21, P99, DOI 10.1109/34.748817; Sivakumar K, 1997, J ELECTRON IMAGING, V6, P31, DOI 10.1117/12.261931; SNEATH PHA, 1957, J GEN MICROBIOL, V17, P201, DOI 10.1099/00221287-17-1-201; Soille P., 1999, MORPHOLOGICAL IMAGE, DOI 10.1007/978-3-662-03939-7; Tzafestas CS, 2002, J MATH IMAGING VIS, V17, P109, DOI 10.1023/A:1020629402912; VANDENBOOMGAARD R, 1994, IEEE T PATTERN ANAL, V16, P1101, DOI 10.1109/34.334389; Vincent L., 1994, SHAPE PICTURE MATH D, P197; Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222; WILSON R, 1990, PATTERN RECOGN, V23, P1413, DOI 10.1016/0031-3203(90)90087-2; WONG YF, 1993, NEURAL COMPUT, V5, P89, DOI 10.1162/neco.1993.5.1.89	49	14	17	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2005	27	6					892	907		10.1109/TPAMI.2005.124	http://dx.doi.org/10.1109/TPAMI.2005.124			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	915TR	15943421				2022-12-18	WOS:000228334700005
J	Schechner, YY; Nayar, SK				Schechner, YY; Nayar, SK			Generalized mosaicing: Polarization panorama	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						mosaicing; color; image fusion; physics-based vision; illumination; transparent layers; biology-inspired	WIDE-FIELD; VISION; STEREO; IMAGES; COLOR; RANGE	We present an approach to image the polarization state of object points in a wide field of view, while enhancing the radiometric dynamic range of imaging systems by generalizing image mosaicing. The approach is biologically-inspired, as it emulates spatially varying polarization sensitivity of some animals. In our method, a spatially varying polarization and attenuation filter is rigidly attached to a camera. As the system moves, it senses each scene point multiple times, each time filtering it through a different filter polarizing angle, polarizance, and transmittance. Polarization is an additional dimension of the generalized mosaicing paradigm, which has recently yielded high dynamic range images and multispectral images in a wide field of view using other kinds of filters. The image acquisition is as easy as in traditional image mosaics. The computational algorithm can easily handle nonideal polarization filters ( partial polarizers), variable exposures, and saturation in a single framework. The resulting mosaic represents the polarization state at each scene point. Using data acquired by this method, we demonstrate attenuation and enhancement of specular reflections and semireflection separation in an image mosaic.	Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel; Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Technion Israel Institute of Technology; Columbia University	Schechner, YY (corresponding author), Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.	yoav@ee.technion.ac.il; nayar@cs.columbia.edu						Aggarwal M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P2, DOI 10.1109/ICCV.2001.937492; Candocia FM, 2003, IEEE T IMAGE PROCESS, V12, P1485, DOI 10.1109/TIP.2003.819222; Candocia FM, 2003, IEEE T IMAGE PROCESS, V12, P409, DOI 10.1109/TIP.2003.811497; Capel D, 1998, PROC CVPR IEEE, P885, DOI 10.1109/CVPR.1998.698709; Chipman R. A., 1995, HDB OPTICS; Coorg S, 2000, INT J COMPUT VISION, V37, P259, DOI 10.1023/A:1008184124789; CRONIN TW, 1994, INT C PATT RECOG, P606, DOI 10.1109/ICPR.1994.576374; Cronin TW, 2001, BIOL BULL, V200, P177, DOI 10.2307/1543312; Cronin TW, 2003, INTEGR COMP BIOL, V43, P549, DOI 10.1093/icb/43.4.549; Demos SG, 1997, APPL OPTICS, V36, P150, DOI 10.1364/AO.36.000150; Denes LJ, 1999, P SOC PHOTO-OPT INS, V3584, P106, DOI 10.1117/12.339812; Eckmann M, 2001, PROC SPIE, V4195, P192, DOI 10.1117/12.417301; Eustice R, 2002, PROCEEDINGS OF THE 2002 INTERNATIONAL SYMPOSIUM ON UNDERWATER TECHNOLOGY, P141, DOI 10.1109/UT.2002.1002415; Farid H, 1999, J OPT SOC AM A, V16, P2136, DOI 10.1364/JOSAA.16.002136; Garcia R, 2001, IEEE INT CONF ROBOT, P2779, DOI 10.1109/ROBOT.2001.933043; Glassner A. S., 1995, PRINCIPLES DIGITAL I; Harnett CK, 2002, APPL OPTICS, V41, P1291, DOI 10.1364/AO.41.001291; Harsdorf S, 1999, P SOC PHOTO-OPT INS, V3821, P378, DOI 10.1117/12.364201; Hermanto, 2001, IEICE T INF SYST, VE84D, P1241; Hsu S, 2002, IEEE COMPUT GRAPH, V22, P44, DOI 10.1109/38.988746; Irani M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P959, DOI 10.1109/ICCV.1998.710832; Irani M, 1996, SIGNAL PROCESS-IMAGE, V8, P327, DOI 10.1016/0923-5965(95)00055-0; Konnen G. P., 1985, POLARIZED LIGHT NATU; Lin S, 1997, COMPUT VIS IMAGE UND, V65, P336, DOI 10.1006/cviu.1996.0577; Mann S, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P193, DOI 10.1109/ICIP.1996.560417; Nayar SK, 1997, INT J COMPUT VISION, V21, P163, DOI 10.1023/A:1007937815113; Negahdaripour S, 1998, PROCEEDINGS OF THE 1998 WORKSHOP ON AUTONOMOUS UNDERWATER VEHICLES, (AUV '98), P191, DOI 10.1109/AUV.1998.744455; Nicolas H, 2001, IEEE T IMAGE PROCESS, V10, P1239, DOI 10.1109/83.935039; Peleg S, 2001, IEEE T PATTERN ANAL, V23, P279, DOI 10.1109/34.910880; Rahmann S, 2001, PROC CVPR IEEE, P149; Saito M, 1999, J OPT SOC AM A, V16, P2286, DOI 10.1364/JOSAA.16.002286; Sawhney HS, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P56; Schechner YY, 2004, PROC CVPR IEEE, P536; Schechner YY, 2001, PROC CVPR IEEE, P325; Schechner YY, 2003, INT J COMPUT VISION, V53, P245, DOI 10.1023/A:1023082924255; Schechner YY, 2002, IEEE T PATTERN ANAL, V24, P1334, DOI 10.1109/TPAMI.2002.1039205; Schechner YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P17, DOI 10.1109/ICCV.2001.937494; Schechner YY, 2000, J OPT SOC AM A, V17, P276, DOI 10.1364/JOSAA.17.000276; SCHECHNER YY, 1999, P SCIA, V1, P235; Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169; SHURCLIFF WA, 1964, POLARIZED LIGHT; SHUTOV AM, 1993, SOV J OPT TECHNOL+, V60, P295; Smolic A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P872, DOI 10.1109/ICIP.2001.958259; Szeliski R., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P44, DOI 10.1109/ACV.1994.341287; TALYOR JS, 2001, MTS IEEE OCEANS, V1, P107; Tyo JS, 1996, APPL OPTICS, V35, P1855, DOI 10.1364/AO.35.001855; USON JM, 1990, SCIENCE, V250, P539, DOI 10.1126/science.250.4980.539; Vasavada AR, 1998, ICARUS, V135, P265, DOI 10.1006/icar.1998.5984; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; Wallace AM, 1999, INT J COMPUT VISION, V32, P87, DOI 10.1023/A:1008154415349; Wolff LB, 1997, IMAGE VISION COMPUT, V15, P81, DOI 10.1016/S0262-8856(96)01123-7; WOLFF LB, 1994, J OPT SOC AM A, V11, P2935, DOI 10.1364/JOSAA.11.002935	52	14	20	0	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2005	27	4					631	636		10.1109/TPAMI.2005.79	http://dx.doi.org/10.1109/TPAMI.2005.79			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	895FG	15794167	Green Submitted			2022-12-18	WOS:000226845700013
J	Unsalan, C; Boyer, KL				Unsalan, C; Boyer, KL			A theoretical and experimental investigation of graph theoretical measures for land development in satellite imagery	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						land use classification; graph theoretical measures; measure fusion; satellite images; image analysis	CHARACTERISTIC VECTORS; BORDERED MATRICES; ORGANIZATION; EIGENVALUES	Today's commercial satellite images enable experts to classify region types in great detail. In previous work, we considered discriminating rural and urban regions [ 23]. However, a more detailed classification is required for many purposes. These fine classifications assist government agencies in many ways including urban planning, transportation management, and rescue operations. In a step toward the automation of the fine classification process, this paper explores graph theoretical measures over grayscale images. The graphs are constructed by assigning photometric straight line segments to vertices, while graph edges encode their spatial relationships. We then introduce a set of measures based on various properties of the graph. These measures are nearly monotonic ( positively correlated) with increasing structure ( organization) in the image. Thus, increased cultural activity and land development are indicated by increases in these measures-without explicit extraction of road networks, buildings, residences, etc. These latter, time consuming ( and still only partially automated) tasks can be restricted only to "promising" image regions, according to our measures. In some applications our measures may suffice. We present a theoretical basis for the measures followed by extensive experimental results in which the measures are first compared to manual evaluations of land development. We then present and test a method to focus on, and (pre)extract, suburban-style residential areas. These are of particular importance in many applications, and are especially difficult to extract. In this work, we consider commercial IKONOS data. These images are orthorectified to provide a fixed resolution of 1 meter per pixel on the ground. They are, therefore, metric in the sense that ground distance is fixed in scale to pixel distance. Our data set is large and diverse, including sea and coastline, rural, forest, residential, industrial, and urban areas.	Yeditepe Univ, Dept Elect & Elect Engn, TR-34755 Istanbul, Turkey; Ohio State Univ, Dept Elect & Comp Engn, Signal Anal & Machine Percept Lab, Columbus, OH 43210 USA	Yeditepe University; University System of Ohio; Ohio State University	Unsalan, C (corresponding author), Yeditepe Univ, Dept Elect & Elect Engn, TR-34755 Istanbul, Turkey.	unsalan@yeditepe.edu.tr; kim@ee.eng.ohio.edu	Unsalan, Cem/A-7249-2018	Unsalan, Cem/0000-0002-8904-3730				ARNOLD L, 1976, LINEAR ALGEBRA APPL, V13, P185, DOI 10.1016/0024-3795(76)90095-1; ARNOLD L, 1967, J MATH ANAL APPL, V20, P262, DOI 10.1016/0022-247X(67)90089-3; Berge Claude, 2001, THEORY GRAPHS; Bollobas Bla, 2001, RANDOM GRAPHS, P215; BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808; Cvetkovic D.M., 1988, RECENT RESULTS THEOR; Farkas IJ, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.026704; FIEDLER M, 1973, CZECH MATH J, V23, P298; FIEDLER M, 1975, CZECH MATH J, V25, P619; Fiedler M., 1989, COMBINATORICS GRAPH, V25, P57, DOI 10.4064/-25-1-57-70; Gdalyahu Y, 2001, IEEE T PATTERN ANAL, V23, P1053, DOI 10.1109/34.954598; Gutman I., 1986, MATH CONCEPTS ORGANI, DOI [DOI 10.1007/978-3-642-70982-1, 10.1007/978-3-642-70982-1]; Horn R. A., 1986, MATRIX ANAL; MOHAR B, 1998, P 6 QUADR C THEOR AP, V2, P871; Pavan M, 2003, PROC CVPR IEEE, P145; PERONA P, 1998, P EUR C COMP VIS, P655; Sarkar S, 1998, COMPUT VIS IMAGE UND, V71, P110, DOI 10.1006/cviu.1997.0637; SHAPIRO LS, 1992, IMAGE VISION COMPUT, V10, P283, DOI 10.1016/0262-8856(92)90043-3; Shen JH, 2001, LINEAR ALGEBRA APPL, V326, P1, DOI 10.1016/S0024-3795(00)00322-0; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Smits PC, 1999, IEEE T GEOSCI REMOTE, V37, P1244, DOI 10.1109/36.763282; STRANG G, 1988, LINER ALGEBRA ITS AP; Unsalan C, 2004, IEEE T GEOSCI REMOTE, V42, P907, DOI 10.1109/TGRS.2003.818835; Watts D. J., 1999, SMALL WORLDS DYNAMIC; Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918; Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P975, DOI 10.1109/ICCV.1999.790354; WIGNER EP, 1957, ANN MATH, V65, P203, DOI 10.2307/1969956; WIGNER EP, 1955, ANN MATH, V62, P548, DOI 10.2307/1970079; WIGNER EP, 1958, ANN MATH, V67, P325, DOI 10.2307/1970008	29	14	16	0	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR	2005	27	4					575	589		10.1109/TPAMI.2005.65	http://dx.doi.org/10.1109/TPAMI.2005.65			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	895FG	15794162				2022-12-18	WOS:000226845700008
J	Song, JQ; Lyu, MR; Cai, SJ				Song, JQ; Lyu, MR; Cai, SJ			Effective multiresolution arc segmentation: Algorithms and performance evaluation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						graphics recognition; arc segmentation; multiresolution; circular tracking; vectorization; performance evaluation	HOUGH TRANSFORM; VECTORIZATION; SYSTEM	Arc segmentation plays an important role in the process of graphics recognition from scanned images. The GREC arc segmentation contest shows there is a lot of room for improvement in this area. This paper proposes a multiresolution arc segmentation method based on our previous seeded circular tracking algorithm which largely depends on the OOPSV model. The newly-introduced multiresolution paradigm can handle arcs/circles with large radii well. We describe new approaches for arc seed detection, arc localization, and arc verification, making the proposed method self-contained and more efficient. Moreover, this paper also brings major improvement to the dynamic adjustment algorithm of circular tracking to make it more robust. A systematic performance evaluation of the proposed method has been conducted using the third-party evaluation tool and test images obtained from the GREC arc segmentation contests. The overall performance over various arc angles, arc lengths, line thickness, noises, arc-arc intersections, and arc-line intersections has been measured. The experimental results and time complexity analyses on real scanned images are also reported and compared with other approaches. The evaluation result demonstrates the stable performance and the significant improvement on processing large arcs/circles of the MAS method.	Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China; Nanjing Univ, Dept Comp Sci & Technol, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China	Chinese University of Hong Kong; Nanjing University	Song, JQ (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.	songjq@ieee.org; lyu@cse.cuhk.edu.hk; sjcai@netra.nju.edu.cn						AMIR I, 1990, COMPUT VISION GRAPH, V49, P398, DOI 10.1016/0734-189X(90)90112-9; ANDERSON DA, 1981, J ROY STAT SOC B MET, V43, P131; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BERMAN M, 1986, J ROY STAT SOC B MET, V48, P183; CHAUDHURI BB, 1993, PATTERN RECOGN LETT, V14, P1, DOI 10.1016/0167-8655(93)90126-X; Chhabra AK, 2000, INT C PATT RECOG, P864, DOI 10.1109/ICPR.2000.903053; CHHABRA AK, 1998, P IEEE COMP SOC WORK, P28; Chiang JY, 1998, PATTERN RECOGN, V31, P1541, DOI 10.1016/S0031-3203(97)00157-X; Dori D, 1999, IEEE T PATTERN ANAL, V21, P202, DOI 10.1109/34.754586; Dori D., 1998, International Journal on Document Analysis and Recognition, V1, P62; DORI D, 1995, IEEE T PATTERN ANAL, V17, P1057, DOI 10.1109/34.473231; Dosch P, 2000, INT C PATT RECOG, P243, DOI 10.1109/ICPR.2000.906058; Elliman D, 2002, LECT NOTES COMPUT SC, V2390, P350; Hilaire X, 2002, LECT NOTES COMPUT SC, V2390, P359; HO CT, 1995, PATTERN RECOGN, V28, P117, DOI 10.1016/0031-3203(94)00077-Y; HORI O, 1993, P INT DOC AN REC, P272; Janssen RDT, 1997, COMPUT VIS IMAGE UND, V65, P38, DOI 10.1006/cviu.1996.0484; Kovalevsky V. A., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P31, DOI 10.1109/ICPR.1990.119324; LEAVERS VF, 1992, CVGIP-IMAG UNDERSTAN, V56, P381, DOI 10.1016/1049-9660(92)90049-9; LIU W, 2001, P 3 CVPR WORKSH EMP; Liu WY, 2002, LECT NOTES COMPUT SC, V2390, P343; Liu WY, 1998, IEEE T PATTERN ANAL, V20, P424, DOI 10.1109/34.677280; MOURA L, 1991, COMPUT PHYS COMMUN, V64, P57, DOI 10.1016/0010-4655(91)90049-Q; Phillips IT, 1999, IEEE T PATTERN ANAL, V21, P849, DOI 10.1109/34.790427; ROSEBOROUGH JB, 1995, PATTERN RECOGN, V28, P421, DOI 10.1016/0031-3203(94)00113-Z; ROSIN PL, 1989, IMAGE VISION COMPUT, V7, P109, DOI 10.1016/0262-8856(89)90004-8; Song JQ, 2002, IEEE T PATTERN ANAL, V24, P1048, DOI 10.1109/TPAMI.2002.1023802; Song JQ, 2000, PROC CVPR IEEE, P383, DOI 10.1109/CVPR.2000.855844; WEI Y, 1998, P IEEE INT S GEOSC R, V2, P1190; WU ZQ, 1995, COMPUT VIS IMAGE UND, V62, P269, DOI 10.1006/cviu.1995.1054; YIP RKK, 1992, PATTERN RECOGN, V25, P1007, DOI 10.1016/0031-3203(92)90064-P	32	14	14	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	2004	26	11					1491	1506		10.1109/TPAMI.2004.103	http://dx.doi.org/10.1109/TPAMI.2004.103			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	852EC	15521496				2022-12-18	WOS:000223737000008
J	Torr, PHS; Fitzgibbon, AW				Torr, PHS; Fitzgibbon, AW			Invariant fitting of two view geometry	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						least squares approximation; least squares method; 3D/stereo scene analysis; motion; camera calibration	MOTION	This paper describes an extension of Bookstein's and Sampson's methods, for fitting conics, to the determination of epipolar geometry, both in the calibrated case, where the Essential matrix E is to be determined or in the uncalibrated case, where we seek the fundamental matrix F. We desire that the fitting of the relation be invariant to Euclidean transformations of the image, and show that there is only one suitable normalization of the coefficients and that this normalization gives rise to a quadratic form allowing eigenvector methods to be used to find E or F, or an arbitrary homography H. The resulting method has the advantage that it exhibits the improved stability of previous methods for estimating the epipolar geometry, such as the preconditioning method of Hartley, while also being invariant to equiform transformations.	Oxford Brookes Univ, Sch Math & Comp, Oxford OX33 1HX, England; Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England	Oxford Brookes University; University of Oxford	Torr, PHS (corresponding author), Oxford Brookes Univ, Sch Math & Comp, Oxford OX33 1HX, England.	philiptorr@brookes.ac.uk; awf@robots.ox.ac.uk						BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P564; Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658; HARTLEY R, 1992, P 2 EUR C COMP VIS, P579; HARTLEY RI, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1064; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LUONG QT, 1993, 1894 TR INRIA; Mundy J., 1992, GEOMETRIC INVARIANCE; SAMPSON PD, 1982, COMPUTER GRAPHICS IM, V18; SHAPIRO LS, 1995, AFFINE ANAL IMAGE SE; Torr P.H.S., 1995, THESIS U OXFORD; Torr PHS, 2002, INT J COMPUT VISION, V50, P35, DOI 10.1023/A:1020224303087; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779	14	14	15	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY	2004	26	5					648	650		10.1109/TPAMI.2004.1273967	http://dx.doi.org/10.1109/TPAMI.2004.1273967			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	811EY	15460285				2022-12-18	WOS:000220756400009
J	Goldenstein, SK; Vogler, C; Metaxas, D				Goldenstein, SK; Vogler, C; Metaxas, D			Statistical cue integration in DAG deformable models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						statistical cue integration; deformable model tracking; affine arithmetic; face tracking; directed acyclic graphs; deformable model representation	SHAPE; FLOW	Deformable models are a useful modeling paradigm in computer vision. A deformable model is a curve, a surface, or a volume, whose shape, position, and orientation are controlled through a set of parameters. They can represent manufactured objects, human faces and skeletons, and even bodies of fluid. With low-level computer vision and image processing techniques, such as optical flow, we extract relevant information from images. Then, we use this information to change the parameters of the model iteratively until we find a good approximation of the object in the images. When we have multiple computer vision algorithms providing distinct sources of information (cues), we have to deal with the difficult problem of combining these, sometimes conflicting contributions in a sensible way. In this paper, we introduce the use of a directed acyclic graph (DAG) to describe the position and Jacobian of each point of deformable models. This representation is dynamic, flexible, and allows computational optimizations that would be difficult to do otherwise. We then describe a new method for statistical cue integration method for tracking deformable models that scales well with the dimension of the parameter space. We use affine forms and affine arithmetic to represent and propagate the cues and their regions of confidence. We show that we can apply the Lindeberg theorem to approximate each cue with a Gaussian distribution, and can use a maximum-likelihood estimator to integrate them. Finally, we demonstrate the technique at work in a 3D cleformable face tracking system on monocular image sequences with thousands of frames.	Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA	Rutgers State University New Brunswick	Goldenstein, SK (corresponding author), Rutgers State Univ, Dept Comp Sci, 110 Frelinghuysen Rd,Hill Ctr, Piscataway, NJ 08854 USA.	siome@cs.rutgers.edu; cvogler@cs.rutgers.edu; dnm@cs.rutgers.edu	Goldenstein, Siome/A-4468-2013					Arras K.O, 1998, EPFLASLTR9801; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277; BLAKE A, 1999, ACTIVE CONTOURS APPL; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Brand M, 2001, PROC CVPR IEEE, P315; BRAUTIGAM CG, 1998, THESIS KTH; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CASCIA ML, 2000, IEEE T PATTERN ANAL, V22, P322; CHUNG KL, 1974, COURSE PROBABILISTIC; Craig JJ., 2018, INTRO ROBOTICS MECH; DeCarlo D, 2000, INT J COMPUT VISION, V38, P99, DOI 10.1023/A:1008122917811; DECARLO D, 1998, P SIGGRAPH 98, P67, DOI DOI 10.1145/280814.280823; deFigueiredo LH, 1996, PROC GRAPH INTERF, P168; EGIZIANO L, 1998, P 6 WORKSH COMP POW; FELLER W., 1966, INTRO PROBABILITY TH, VII; Foley J.D., 1995, COMPUTER GRAPHICS PR; GLEICHER M, 1993, GRAPH INTER, P138; Goldenstein S, 2001, PROC CVPR IEEE, P1098; GOLDENSTEIN S, 2002, THESIS U PENNSYLVANI; Gomes J., 1999, WARPING MORPHING GRA; Heckerman D, 1995, MSRTR9506; Ierusalimschy R, 1996, SOFTWARE PRACT EXPER, V26, P635, DOI 10.1002/(SICI)1097-024X(199606)26:6<635::AID-SPE26>3.0.CO;2-P; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Kamberova G, 1999, J STAT PLAN INFER, V79, P205, DOI 10.1016/S0378-3758(98)00237-7; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; MANDELBAUM R, 1998, P INT C COMP VIS 199; Maybeck P. S., 1979, MATH SCI ENG; MESSINE F, 1998, P IMACS GAMM INT S S; Moore R.E., 1979, METHODS APPL INTERVA; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Pighin F., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P143, DOI 10.1109/ICCV.1999.791210; REQUICHA AAG, 1980, COMPUT SURV, V12, P436; Samaras D, 2000, PROC CVPR IEEE, P480, DOI 10.1109/CVPR.2000.855858; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; STOLFI J, 1997, P 21 C BRAS MAT IMPA; Tomasi C, 1991, CMUCS91132	39	14	17	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2003	25	7					801	813		10.1109/TPAMI.2003.1206510	http://dx.doi.org/10.1109/TPAMI.2003.1206510			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	692NN					2022-12-18	WOS:000183667300003
J	Lourakis, MIA; Tzurbakis, SV; Argyros, AA; Orphanoudakis, SC				Lourakis, MIA; Tzurbakis, SV; Argyros, AA; Orphanoudakis, SC			Feature transfer and matching in disparate stereo views through the use of plane homographies	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						feature correspondence; feature transfer; projective transformations; plane homography; fundamental matrix; trifocal tensor; wide baseline matching	IMAGES	Many vision tasks rely upon the identification of sets of corresponding features among different images. This paper presents a method that, given some corresponding features in two stereo images, matches them with features extracted from a second stereo pair captured from a distant viewpoint. The proposed method is based on the assumption that the viewed scene contains two planar surfaces and exploits geometric constraints that are imposed by the existence of these planes to first transfer and then match image features between the two stereo pairs. The resulting scheme handles point and line features in a unified manner and Is capable of successfully matching features extracted from stereo pairs that are acquired from considerably different viewpoints. Experimental results are presented, which demonstrate that the performance of the proposed method compares favorably to that of epipolar and tensor-based approaches.	Fdn Res & Technol Hellas, Inst Comp Sci, Iraklion 71110, Crete, Greece	Foundation for Research & Technology - Hellas (FORTH)	Lourakis, MIA (corresponding author), Fdn Res & Technol Hellas, Inst Comp Sci, POB 1385, Iraklion 71110, Crete, Greece.	lourakis@ics.forth.gr; tzurbak@ics.forth.gr; argyros@ics.forth.gr; orphanou@ics.forth.gr	Argyros, Antonis/AAD-9251-2019; Argyros, Antonis/GPK-4775-2022	Argyros, Antonis/0000-0001-8230-3192; Argyros, Antonis/0000-0001-8230-3192; Lourakis, Manolis/0000-0003-4596-5773				AVIDAN S, 1998, IEEE T VISUALIZATION, V14, P293; BARTOLI A, 2001, P 8 INT C COMP VIS V, V1, P593; Baumberg A, 2000, PROC CVPR IEEE, P774, DOI 10.1109/CVPR.2000.855899; BURNS JB, 1992, ARTIF INT, P120; FAUGERAS O, 1995, J OPT SOC AM A, V12, P465, DOI 10.1364/JOSAA.12.000465; Faugeras O, 1996, INT J COMPUT VISION, V18, P5, DOI 10.1007/BF00126137; Georgis N, 1998, IMAGE VISION COMPUT, V16, P35, DOI 10.1016/S0262-8856(97)00044-9; Hartley RI, 1997, INT J COMPUT VISION, V22, P125, DOI 10.1023/A:1007936012022; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; LAVEAU S, 1994, RR2205 INRIA; LOURAKIS M, 2002, P BMVC 02, V2, P587; Lourakis MIA, 2000, INT C PATT RECOG, P419, DOI 10.1109/ICPR.2000.905366; Lourakis MIA, 2000, IMAGE VISION COMPUT, V18, P673, DOI 10.1016/S0262-8856(99)00071-2; LOURAKIS MIA, 1997, 208 I COMP SCI FDN R; LOURAKIS MIA, 1999, RR3748 INRIA; MEDIONI G, 1984, IEEE T PATTERN ANAL, V6, P675, DOI 10.1109/TPAMI.1984.4767592; Meer P, 1998, INT J COMPUT VISION, V26, P137, DOI 10.1023/A:1007944826230; Pritchett P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P754, DOI 10.1109/ICCV.1998.710802; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; Schmid C, 1997, PROC CVPR IEEE, P666, DOI 10.1109/CVPR.1997.609397; Torr PHS, 1997, IMAGE VISION COMPUT, V15, P591, DOI 10.1016/S0262-8856(97)00010-3; TUYTELAARS T, 2000, P 11 BRIT MACH VIS C, P421; Zhang ZY, 1997, J OPT SOC AM A, V14, P2938, DOI 10.1364/JOSAA.14.002938; ZHANG ZY, 1994, INT C PATT RECOG, P563; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4	25	14	15	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2003	25	2					271	276		10.1109/TPAMI.2003.1177157	http://dx.doi.org/10.1109/TPAMI.2003.1177157			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	637NX		Green Submitted			2022-12-18	WOS:000180519800010
J	Whitaker, RT; Gregor, J				Whitaker, RT; Gregor, J			A maximum-likelihood surface estimator for dense range data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						surface estimation; surface reconstruction; surface fitting; optimal estimation; parameter estimation; 3D range data; ladar; maximum-likelihood; Bayesian estimation; registration; calibration	REGISTRATION; CURVES; MODELS	This paper describes how to estimate 3D surface models from dense sets of noisy range data taken from different points of view, i.e., multiple range maps. The proposed method uses a sensor model to develop an expression for the likelihood of a 3D surface, conditional on a set of noisy range measurements. Optimizing this likelihood with respect to the model parameters provides an unbiased and efficient estimator. The proposed numerical algorithms make this estimation computationally practical for a wide variety of circumstances. The results from this method compare favorably with state-of-the-art approaches that rely on the closest-point or perpendicular distance metric, a convenient heuristic that produces biased solutions and fails completely when surfaces are not sufficiently smooth, as in the case of complex scenes or noisy range measurements Empirical results on both simulated and real ladar data demonstrate the effectiveness of the proposed method for several different types of problems. Furthermore, the proposed method offers a general framework that can accommodate extensions to include surface priors (i.e., maximum a posteriori), more sophisticated noise models, and other sensing modalities, such as sonar or synthetic aperture radar.	Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA; Univ Tennessee, Dept Comp Sci, Knoxville, TN 37996 USA	Utah System of Higher Education; University of Utah; University of Tennessee System; University of Tennessee Knoxville	Whitaker, RT (corresponding author), Univ Utah, Sch Comp, 50 S Cent Campus Dr,Rm 3190, Salt Lake City, UT 84112 USA.	whitaker@cs.utah.edu; jgregor@cs.utk.edu						BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BLAIS G, 1995, IEEE T PATTERN ANAL, V17, P820, DOI 10.1109/34.400574; BOLLE RM, 1991, IEEE T PATTERN ANAL, V13, P1, DOI 10.1109/34.67626; BOLLE RM, 1986, IEEE T PATTERN ANAL, V8, P619, DOI 10.1109/TPAMI.1986.4767836; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; COURANT R, 1962, METHODS MATH PHYSICS, V2; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; DECARLO D, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P834, DOI 10.1109/ICCV.1995.466851; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1131, DOI 10.1109/34.625115; Eggert DW, 1997, MACH VISION APPL, V9, P272, DOI 10.1007/s001380050048; FAUGERAS OD, 1986, TECHNIQUES 3 D MACHI, P13; Gregor J, 2001, GRAPH MODELS, V63, P304, DOI 10.1006/gmod.2001.0562; Hilton A., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P117, DOI 10.1007/BFb0015528; HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; Jokinen O., 1999, P 2 INT C 3D DIG IM, P180; Keeping ES, 1962, INTRO STAT INFERENCE; KEREN D, 1994, IEEE T PATTERN ANAL, V16, P38, DOI 10.1109/34.273718; KUMAR S, 1995, IEEE T PATTERN ANAL, V17, P1079, DOI 10.1109/34.473234; Lei ZB, 1998, IEEE T PATTERN ANAL, V20, P212, DOI 10.1109/34.659942; Levoy M, 2000, COMP GRAPH, P131, DOI 10.1145/344779.344849; MURAKI S, 1991, COMP GRAPH, V25, P227, DOI 10.1145/127719.122743; Pentland A. P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P612; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; SEQUEIRA V, 1995, ROBOT AUTON SYST, V16, P81, DOI 10.1016/0921-8890(95)00036-F; SIMON DA, 1994, IEEE INT CONF ROBOT, P2235, DOI 10.1109/ROBOT.1994.350953; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; Tukey J. W., 1977, EXPLORATORY DATA ANA; Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241; WERGHI N, 1999, P 2 INT C 3D DIG IM, P280; Whitaker RT, 1998, INT J COMPUT VISION, V29, P203, DOI 10.1023/A:1008036829907; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149; [No title captured]	36	14	15	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2002	24	10					1372	1387		10.1109/TPAMI.2002.1039208	http://dx.doi.org/10.1109/TPAMI.2002.1039208			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	596ZF					2022-12-18	WOS:000178196300007
J	Lu, ZK; Chi, ZR; Siu, WC				Lu, ZK; Chi, ZR; Siu, WC			Extraction and optimization of B-spline PBD templates for recognition of connected handwritten digit strings	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						connected handwritten digit recognition; pixel-to-boundary distance map; B-spline fitting; digit templates; template optimization; nearest neighbor classifier; multilayer perceptron classifier; evolutionary algorithm	CHARACTER-RECOGNITION; WORD RECOGNITION; NUMERAL STRINGS; SEGMENTATION; ALGORITHM; MODELS	Recognition of connected handwritten digit strings is a challenging task due mainly to two problems: poor character segmentation and unreliable isolated character recognition. In this paper, we first present a rational B-spline representation of digit templates based on Pixel-to-Boundary Distance (PBD) maps. We then present a neural network approach to extract B-spline PBD templates and an evolutionary algorithm to optimize these templates. In total, 1,000 templates (100 templates for each of 10 classes) were extracted from and optimized on 10,426 training samples from the NIST Special Database 3. By using these templates, a nearest neighbor classifier can successfully reject 90.7 percent of nondigit patterns while achieving a 96.4 percent correct classification of isolated test digits. When our classifier is applied to the recognition of 4,958 connected handwritten digit strings (4,555 2-digit, 355 3-digit, and 48 4-digit strings) from the NIST Special Database 3 with a dynamic programming approach, it has a correct classification rate of 82.4 percent with a rejection rate of as low as 0.85 percent. Cur classifier compares favorably in terms of correct classification rate and robustness with other classifiers that are tested.	Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; Hong Kong Polytech Univ, Ctr Multimedia Signal Proc, Dept Elect & Informat Engn, Hong Kong, Hong Kong, Peoples R China	Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; Hong Kong Polytechnic University	Lu, ZK (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.			Lu, Zhongkang/0000-0001-7379-3193; Chi, Zheru/0000-0003-0714-8713				Back T, 1993, EVOL COMPUT, V1, P1, DOI 10.1162/evco.1993.1.1.1; Bouchaffra D, 1999, IEEE T PATTERN ANAL, V21, P990, DOI 10.1109/34.799906; CHEUNG KW, 1995, P 2 AS C COMP VIS, V1, P344; DELIBASIS K, 1994, P IEE C GEN ALG IM P, V8, P1; FOGEL DB, 1994, IEEE T NEURAL NETWOR, V5, P1; Gader PD, 1997, IEEE T SYST MAN CY B, V27, P158, DOI 10.1109/3477.552199; GOVINDAN VK, 1990, PATTERN RECOGN, V23, P671, DOI 10.1016/0031-3203(90)90091-X; HA DM, 1998, PATTERN RECOGN, V31, P257; Impedovo S., 1991, International Journal of Pattern Recognition and Artificial Intelligence, V5, P1, DOI 10.1142/S0218001491000041; Jain AK, 1997, IEEE T PATTERN ANAL, V19, P1386, DOI 10.1109/34.643899; Kim G, 1997, IEEE T PATTERN ANAL, V19, P366, DOI 10.1109/34.588017; KOZEK T, 1993, IEEE T CIRCUITS-I, V40, P392, DOI 10.1109/81.238343; Lu ZK, 1999, PATTERN RECOGN, V32, P921, DOI 10.1016/S0031-3203(98)00123-X; Revow M, 1996, IEEE T PATTERN ANAL, V18, P592, DOI 10.1109/34.506410; ROCHA J, 1995, IEEE T PATTERN ANAL, V17, P903, DOI 10.1109/34.406657; Sarkar M, 1997, PATTERN RECOGN LETT, V18, P975, DOI 10.1016/S0167-8655(97)00122-0; Shi ZX, 1997, PATTERN RECOGN, V30, P1501, DOI 10.1016/S0031-3203(96)00118-5; SHRIDHAR M, 1987, IMAGE VISION COMPUT, V5, P3, DOI 10.1016/0262-8856(87)90071-0; Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2; VERSPRILLE KJ, 1975, THESIS SYRACUSE U; WAKAHARA T, 1994, IEEE T PATTERN ANAL, V16, P618, DOI 10.1109/34.295906; YAN H, 1993, PATTERN RECOGN, V26, P317, DOI 10.1016/0031-3203(93)90040-4	22	14	16	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	2002	24	1					132	139						8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	506FZ		Green Submitted			2022-12-18	WOS:000172960300010
J	Oliensis, J; Genc, Y				Oliensis, J; Genc, Y			Fast and accurate algorithms for projective multi-image structure from motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						projective multiframe structure from motion; structure from motion; projective geometry; factorization; linear algorithms; Sturm/Triggs factorization; dominant plane; bundle adjustment; shape from X; low level vision		We describe algorithms for computing projective structure and motion from a multi-image sequence of tracked points. The algorithms are essentially linear, work for any motion of moderate size, and give accuracies similar to those of a maximum-likelihood estimate. They give better results than the Sturm/Triggs factorization approach and are equally fast and they are much faster than bundle adjustment. Our experiments show that the (iterated) Sturm/Triggs approach often fails for linear camera motions. In addition, we study experimentally the common situation where the calibration is fixed and approximately known, comparing the projective versions of our algorithms to mixed projective/Euclidean strategies. We clarify the nature of dominant-plane compensation, showing that it can be considered a small-translation approximation rather than an approximation that the scene is planar. We show that projective algorithms accurately recover the (projected) inverse depths and homographies despite the possibility of transforming the structure and motion by a projective transformation.	NEC Res Inst, Princeton, NJ 08540 USA; Siemens Res, Princeton, NJ 08540 USA	NEC Corporation; Siemens AG	Oliensis, J (corresponding author), NEC Res Inst, 4 Independence Way, Princeton, NJ 08540 USA.	oliensis@research.nj.nec.com; ygenc@scr.siemens.com	Genc, Yakup/AAG-4668-2019	Genc, Yakup/0000-0002-6952-6735				BERTHILSSON R, 1997, COMPUTER VISION PATT, P444; CHIUSO A, 1999, OPTIMAL STRUCTURE MO; DUTTA R, 1989, CVPR, P159; Golub G.H., 2013, MATRIX COMPUTATIONS, P357; Hanna K. J., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P156, DOI 10.1109/WVM.1991.212812; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; HEYDEN A, 1997, P SCAND C IM AN, V2, P963; HORN BKP, 1988, INT J COMPUT VISION, V2, P51, DOI 10.1007/BF00836281; Irani M, 1998, IEEE T PATTERN ANAL, V20, P577, DOI 10.1109/34.683770; JEPSON AD, 1993, SPATIAL VISION IN HUMANS AND ROBOTS, P39; KUMAR R, 1994, INT C PATT RECOG, P685, DOI 10.1109/ICPR.1994.576402; MacLean W. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P753, DOI 10.1109/ICCV.1999.790297; MACLEAN WJ, 1996, THESIS; Oliensis J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P536, DOI 10.1109/ICCV.1999.791269; Oliensis J., 1995, Proceedings IEEE Workshop on Representation of Visual Scenes (In Conjunction with ICCV'95) (Cat. No.95TB8126), P77, DOI 10.1109/WVRS.1995.476855; Oliensis J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P737, DOI 10.1109/ICCV.1999.790295; Oliensis J, 1998, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.1998.698610; Oliensis J, 2000, IEEE T PATTERN ANAL, V22, P685, DOI 10.1109/34.865186; Oliensis J, 1999, INT J COMPUT VISION, V34, P163, DOI 10.1023/A:1008139920864; Oliensis J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P745, DOI 10.1109/ICCV.1999.790296; Oliensis J, 2000, INT C PATT RECOG, P889, DOI 10.1109/ICPR.2000.905565; Oliensis J, 2000, COMPUT VIS IMAGE UND, V80, P172, DOI 10.1006/cviu.2000.0869; OLIENSIS J, 1994, P IM UND WORKSH, P1225; OLIENSIS J, 1997, RECOVERING HEADING S; OLIENSIS J, 1996, CVPR, P335; OLIENSIS J, 2000, COMPUTER VISION PATT, V2, P599; SAWHNEY HS, 1994, INT C PATT RECOG, P403, DOI 10.1109/ICPR.1994.576308; Srinivasan S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P528, DOI 10.1109/ICCV.1999.791268; Srinivasan S, 2000, INT J COMPUT VISION, V37, P203, DOI 10.1023/A:1008111923880; Sturm P., 1996, LECT NOTES COMPUTER, V1065, P709, DOI [DOI 10.1007/3-540-61123-1, 10.1007/3-540-61123-1_183, DOI 10.1007/3-540-61123-1_183]; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Triggs B, 1996, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.1996.517170; Triggs B., 2000, LECT NOTES COMPUTER, V1883, P298, DOI [DOI 10.1007/3-540-44480-7, DOI 10.1007/3-540-44480-7_21]	33	14	16	0	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	2001	23	6					546	559		10.1109/34.927457	http://dx.doi.org/10.1109/34.927457			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	438DC		Green Submitted			2022-12-18	WOS:000169037600001
J	Redding, NJ				Redding, NJ			Implicit polynomials, orthogonal distance regression, and the closest point on a curve	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						fitting; orthogonal distance regression; implicit polynomials; algebraic curve; successive circular approximation; resultants; ionograms	ALGEBRAIC CURVE; PLANAR CURVES; REPRESENTATION; ALGORITHMS; SURFACES	Implicit polynomials (i.e., multinomials) have a number of properties that make them attractive for modeling curves and surfaces in computer vision. This paper considers the problem of finding the best fitting implicit polynomial (or algebraic curve) to a collection of paints in the plane using an orthogonal distance metric. Approximate methods far orthogonal distance regression have been shown by others to be prone to the problem of cusps in the solution and this is confirmed here. Consequently, this work focuses on exact methods for orthogonal distance regression. The most difficult and costly part of exact methods is computing the closest point on the algebraic curve to an arbitrary point in the plane. This paper considers three methods for achieving this in detail. The first is the standard Newton's method, the second is based on resultants which are recently making a resurgence in computer graphics. and the third is a novel technique based on successive circular approximations to the curve. It is shown that Newton's method is the quickest, but that it can fail sometimes even with a good initial guess. The successive circular approximation algorithm is not as fast, but is robust. The resultant method is the slowest of the three, but does not require an initial guess. The driving application of this work was the fitting of implicit quartics in two variables to thinned oblique ionogram traces.	Def Sci & Technol Org, Surveillance Syst Div, Salisbury, SA 5108, Australia	Defence Science & Technology	Redding, NJ (corresponding author), Def Sci & Technol Org, Surveillance Syst Div, POB 1500, Salisbury, SA 5108, Australia.	nick.redding@dsto.defence.gov.au						Boggs P. T., 1992, 924834 NISTIR US DEP; Chionh E.-W, 1990, THESIS U WATERLOO ON; Cox D., 1997, UNDERGRADUATE TEXTS, DOI 10.1007/978-3-662-41154-4; de Montaudouin Y., 1984, Computer-Aided Geometric Design, V1, P309, DOI 10.1016/0167-8396(84)90019-0; Dennis J.E., 1983, NUMERICAL METHODS UN; GOEDECKER S, 1994, SIAM J SCI COMPUT, V15, P1059, DOI 10.1137/0915064; Gohberg I., 1982, MATRIX POLYNOMIALS; Golub G. H., 1996, MATRIX COMPUTATIONS; GULLIKSSON M, 1995, OPT METH SOFT, V5, P247; HORN BKP, 1991, J OPT SOC AM A, V8, P1630, DOI 10.1364/JOSAA.8.001630; KANATANI K, 1994, IEEE T PATTERN ANAL, V16, P320, DOI 10.1109/34.276132; Kanatani K., 1996, STAT OPTIMIZATION GE; KETTLER DI, 1996, P 4 AUSTR NZ C INT I, P304; MANOCHA D, 1992, THESIS U CALIFORNIA; MANOCHA D, 1996, ACM SIGSAM B, V30, P4; MANOCHA D, 1994, IEEE COMPUT GRAPH, P46; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; MORGAN A. P., 1992, SYMBOLIC NUMERICAL C, P23; NEWSAM GN, 1997, P INT C IM PROC, V2, P752; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; REDDING N, 1996, DSTORR0074 DSTO EL S; REDDING NJ, 1997, P INT C IM PROC, V2, P410; REDDING NJ, 1996, P 4 AUSTR NZ C INT I, P155; SALMON G, 1866, MODERN HIGHER ALGEBR; Schittkowski K., 1986, Annals of Operations Research, V5, P485, DOI 10.1007/BF02739235; SEDERBERG TW, 1989, COMPUT AIDED DESIGN, V21, P547, DOI 10.1016/0010-4485(89)90015-8; SEDERBERG TW, 1984, COMPUT VISION GRAPH, V28, P72, DOI 10.1016/0734-189X(84)90140-3; SULLIVAN S, 1994, IEEE T PATTERN ANAL, V16, P1183, DOI 10.1109/34.387489; TAUBIN G, 1994, IEEE T PATTERN ANAL, V16, P287, DOI 10.1109/34.276128; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; *VIS NUM INC, 1995, IMSL C MATH LIB C FU; WALLACK A, 1998, P INT S SYMB ALG COM, P244; WATSON LT, 1987, ACM T MATH SOFTWARE, V13, P281, DOI 10.1145/29380.214343; YOUNG DM, 1973, SURVEY NUMERICAL MAT, V1; Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2	35	14	15	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	2000	22	2					191	199		10.1109/34.825757	http://dx.doi.org/10.1109/34.825757			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	292JU					2022-12-18	WOS:000085791400006
J	Bouchaffra, D; Govindaraju, V; Srihari, SN				Bouchaffra, D; Govindaraju, V; Srihari, SN			Postprocessing of recognized strings using Nonstationary Markovian Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						nonstationary hidden Markov models; zip code recognition; postprocessing; class conditional probability; Markov random fields	HANDWRITTEN	This paper presents Nonstationary Markovian Models and their application to recognition of strings of tokens. Domain specific knowledge is brought to bear on the application of recognizing zip Codes in the U.S. mailstream by the use of postal directory files. These files provide a wealth of information on the delivery points (mailstops) corresponding to each zip code. This data feeds into the models as n-grams, statistics that are seamlessly integrated with recognition scores of digit images. An especially interesting facet of the model is its ability to excite and inhibit certain positions in the n-grams leading to the familiar area of Markov Random Fields. The authors have previously described elsewhere [2] a methodology for deriving probability values from recognizer scores. These probability measures allow the Markov chain to be constructed in a truly Bayesian framework. We empirically illustrate the success of Markovian modeling in postprocessing applications of string recognition. We present the recognition accuracy of the different models on a set of 20,000 zip codes. The performance is superior to the present system which ignores all contextual information and simply relies on the recognition scores of the digit recognizers.	SUNY Buffalo, Ctr Excellence Document Anal & Recognit, Dept Comp Sci, Amherst, NY 14228 USA	State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Bouchaffra, D (corresponding author), SUNY Buffalo, Ctr Excellence Document Anal & Recognit, Dept Comp Sci, Amherst, NY 14228 USA.		Srihari, Sargur N/E-8100-2011					ANDERSON TW, 1957, ANN MATH STAT, V28, P89, DOI 10.1214/aoms/1177707039; BOUCHAFFRA D, 1996, INT J IMAGING SYSTEM, V7; BOUCHAFFRA D, 1998, P IEEE C COMP VIS PA; BOUCHAFFRA D, 1997, P 6 INT WORKSH ART I; Brown P. F., 1992, Computational Linguistics, V18, P467; CHEN MY, 1994, IEEE T PATTERN ANAL, V16, P481; Favata JT, 1996, INT J IMAG SYST TECH, V7, P304, DOI 10.1002/(SICI)1098-1098(199624)7:4<304::AID-IMA5>3.0.CO;2-C; GOVINDARAJU V, 1993, P IWFHR, V3; HA TM, 1997, OFF LINE HANDWRITTEN; HULL JJ, 1996, IEEE T PATTERN ANAL, V18; JESSOP A, 1990, INFORMED ASSESSMENTS; Kim G, 1997, IEEE T PATTERN ANAL, V19, P366, DOI 10.1109/34.588017; KIMURA F, 1991, PATTERN RECOGN, V24, P969, DOI 10.1016/0031-3203(91)90094-L; KUNDU A, 1991, PATTERN RECOGN, V24, P603, DOI 10.1016/0031-3203(91)90027-3; LAM L, 1988, PATTERN RECOGN, V21, P19, DOI 10.1016/0031-3203(88)90068-4; OLIVER C, 1997, INT J PATTERN RECOGN, V19; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Shi ZX, 1997, PATTERN RECOGN, V30, P1501, DOI 10.1016/S0031-3203(96)00118-5; SHINGAL R, 1979, IEEE T PATTERN ANAL, V1; SRIDHAR M, 1997, IMAGE VISION COMPUTE, V5, P3; SUEN CY, 1992, P IEEE, V80, P1162, DOI 10.1109/5.156477; YEE R, 1997, P 4 INT C DOC AN REC; ZHOU J, 1997, P 4 INT C DOC AN REC	24	14	15	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	1999	21	10					990	999		10.1109/34.799906	http://dx.doi.org/10.1109/34.799906			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	248DB					2022-12-18	WOS:000083259100003
J	Stein, GP; Shashua, A				Stein, GP; Shashua, A			On degeneracy of linear reconstruction from three views: Linear line complex and applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						shape representation and recovery; 3d motion and shape recovery from line correspondences; shape from motion; algebraic and projective geometry		This paper investigates the linear degeneracies of projective structure estimation from line features across three views. We show that the rank of the linear system of equations for recovering the trilinear tensor of three views reduces to 23 (instead of 26) when the scene is a Linear tine Complex (a set of lines in space intersecting at a common line). The LLC situation is only linearly degenerate, and one can obtain a unique solution when the admissibility constraints of the tensor are accounted for. The line configuration described by an LLC, rather than being some obscure case. is in fact quite typical. It includes, as a particular example, the case of a camera moving down a hallway in an office environment or down an urban street. Furthermore, an LLC situation may occur as an artifact such as in direct estimation from spatio-temporal derivatives of image brightness. Therefore, an investigation into degeneracies and their remedy is important also in practice.	Hebrew Univ Jerusalem, Inst Comp Sci, IL-91905 Jerusalem, Israel	Hebrew University of Jerusalem	Stein, GP (corresponding author), MIT, Artificial Intelligence Lab, Cambridge, MA 02139 USA.							AVIDAN S, 1996, P DARPA IM UND WORKS; BUCHANAN T, 1992, GEOMETRIAE DEDICATA, V44, P223; FAUGERAS OD, 1998, P INT C COMP VIS BOM; HARTLEY R, 1995, P INT C COMP VIS JUN; Hartley RI, 1997, INT J COMPUT VISION, V22, P125, DOI 10.1023/A:1007936012022; MAYBANK SJ, 1995, APPL ALGEBR ENG COMM, V6, P89, DOI 10.1007/BF01225646; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; NAVAB N, 1993, P INT C COMP VIS BER; PAPADOPOULO T, 1998, P EUR C COMP VIS FRE; SHASHUA A, 1995, IEEE T PATTERN ANAL, V17, P779, DOI 10.1109/34.400567; SHASHUA A, 1996, P DARPA IM UND WORKS; SHASHUA A, 1995, P INT C COMP VIS JUN; SHASHUA A, 1996, P EUR C COMP VIS CAM; SHASHUA A, 1997, LECT NOTES COMPUTER, V1315; SPETSAKIS ME, 1990, INT J COMPUT VISION, V4, P171, DOI 10.1007/BF00054994; SPETSAKIS ME, 1990, P DARPA IM UND WORKS; STEIN GP, 1997, P IEEE C COMP VIS PA; WENG J, 1992, IEEE T PATTERN ANAL, V14	18	14	22	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1999	21	3					244	251		10.1109/34.754590	http://dx.doi.org/10.1109/34.754590			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	178YD		Green Submitted			2022-12-18	WOS:000079296000006
J	Xu, G; Sugimoto, N				Xu, G; Sugimoto, N			A linear algorithm for motion from three weak perspective images using Euler angles	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						motion; structure; rotation matrix; Euler angles; epipolar equation; weak perspective projection		In this paper, we describe a new simple linear algorithm for motion and structure from three weak perspective projections using Euler angles. We first determine the epipolar equation between each pair of images, which determines the first and third Euler angles for the rotation between that pair of images, leaving only the second Euler angle undetermined. In the next step, combining the three rotations results in a very simple linear algorithm to determine the second Euler angles, up to a Necker reversal. Experimental results on synthetic and real images are presented. The degenerate cases are discussed. The program can be ftped from http://www.cv.cs.ritsumei.ac.jp/noriko/motion.html.	Ritsumeikan Univ, Dept Comp Sci, Comp Vis Lab, Shiga 525, Japan	Ritsumeikan University	Xu, G (corresponding author), Ritsumeikan Univ, Dept Comp Sci, Comp Vis Lab, Shiga 525, Japan.							Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P536, DOI 10.1109/34.24786; Ostuni J, 1996, IEEE T PATTERN ANAL, V18, P64, DOI 10.1109/34.476013; SHAPIRO LS, 1995, INT J COMPUT VISION, V16, P147, DOI 10.1007/BF01539553; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; TORR PHS, 1992, P BRIT MACHINE VISIO, P79; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; Xu A., 2018, KINETIC THEORY, DOI [10.1007/978-94-015-8668-9, DOI 10.1007/978]	8	14	14	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1999	21	1					54	57		10.1109/34.745734	http://dx.doi.org/10.1109/34.745734			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	163DZ					2022-12-18	WOS:000078388900007
J	Wakahara, T; Odaka, K				Wakahara, T; Odaka, K			On-line cursive kanji character recognition using stroke-based affine transformation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						on-line Kanji character recognition; one-to-one stroke correspondence; affine transformation; least-squares criterion; deformation model; distortion-tolerant shape matching	MODELS	We present a distortion-tolerant on-line cursive Kanji character recognition method that absorbs the stroke-based handwriting distortion expressible by uniform affine transformation. Experiments are made using two kinds of test data in the square style and in the cursive style for 2,980 Kanji character categories; recognition rates of 98.4 percent and 96.0 percent are obtained.	UNIV LIB & INFORMAT SCI, FAC LIB & INFORMAT SCI, TSUKUBA, IBARAKI 305, JAPAN	University of Tsukuba	Wakahara, T (corresponding author), NIPPON TELEGRAPH & TEL PUBL CORP, NTT HUMAN INTERFACE LABS, 1-1 HIKARINOOKA, YOKOSUKA, KANAGAWA 239, JAPAN.							BOTTOU L, 1994, INT C PATT RECOG, P77, DOI 10.1109/ICPR.1994.576879; CAMILLERAP J, 1992, PIXELS FEATURES FRON, P273; Hamanaka M., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P204, DOI 10.1109/ICDAR.1993.395748; ISHII Y, 1986, T I ELECT COMMUN E D, V69, P940; LEE SW, 1994, PATTERN RECOGN, V27, P895, DOI 10.1016/0031-3203(94)90155-4; Nishida H, 1996, IEEE T PATTERN ANAL, V18, P400, DOI 10.1109/34.491621; ODAKA K, 1986, REV ELEC COMMUN LAB, V34, P79; PLAMONDON R, 1989, IEEE T SYST MAN CYB, V19, P1060, DOI 10.1109/21.44021; TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669; TSUKUMO J, 1988, P 9 INT C PATT REC, P168; Wakahara T., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P1059, DOI 10.1109/ICDAR.1995.602091; WAKAHARA T, 1994, IEEE T PATTERN ANAL, V16, P618, DOI 10.1109/34.295906; WAKAHARA T, 1988, P 9 INT C PATT REC N, P1133; YAMADA H, 1990, PATTERN RECOGN, V23, P1023, DOI 10.1016/0031-3203(90)90110-7; YAMADA H, 1984, IEICE T D, V67, P351; YOSHIDA K, 1982, IEEE T CONSUM ELECTR, V28, P202, DOI 10.1109/TCE.1982.353911; Yurugi M., 1985, Transactions of the Institute of Electronics and Communication Engineers of Japan, Part D, VJ68D, P1320	17	14	14	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1997	19	12					1381	1385		10.1109/34.643898	http://dx.doi.org/10.1109/34.643898			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	YK781					2022-12-18	WOS:A1997YK78100008
J	Duric, Z; Fayman, JA; Rivlin, E				Duric, Z; Fayman, JA; Rivlin, E			Function from motion	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						object recognition; action perception; functionality; motion; normal flow	RECOGNITION; MODEL	In order for a robot to operate autonomously in its environment, it must be able to perceive its environment and take actions based on these perceptions. Recognizing the functionalities of objects is an important component of this ability. In this paper, we look into a new area of functionality recognition: determining the function of an object from its motion. Given a sequence of images of a known object performing some function, we attempt to determine what that function is. We show that the motion of an object, when combined with information about the object and its normal uses, provides us with strong constraints on possible functions that the object might be performing.	UNIV MARYLAND,CTR AUTOMAT RES,COLLEGE PK,MD 20742; TECHNION ISRAEL INST TECHNOL,DEPT COMP SCI,IL-32000 HAIFA,ISRAEL	University System of Maryland; University of Maryland College Park; Technion Israel Institute of Technology	Duric, Z (corresponding author), GEORGE MASON UNIV,MACHINE LEARNING & INFERENCE LAB,FAIRFAX,VA 22030, USA.							[Anonymous], P 6 EUR C ART INT 19; BIEDERMAN I, 1985, COMPUT VISION GRAPH, V32, P29, DOI 10.1016/0734-189X(85)90002-7; BOGONI L, 1994, P CVPR WORKSH VIS BE; DEMENTHON DF, 1995, INT J COMPUT VISION, V15, P123, DOI 10.1007/BF01450852; FREEMAN PA, 1971, 2ND P INT JOINT COMP, P621; Gould K., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P79, DOI 10.1109/CVPR.1989.37831; GREEN K, 1994, P AAAI 94 WORKSH REP, P56; HODGES J, 1992, IEEE EXPERT, V7, P14, DOI 10.1109/64.120684; HORN BKP, 1981, ARTIF INTELL, V17, P189; KENDER JR, 1987, P ARPA IMAGE UNDERST, P589; KISE K, 1993, P AS C COMP VIS, P656; Kitahashi T., 1991, Advances in information modelling and knowledge bases, P91; MURASE H, 1993, PROCEEDINGS OF THE ELEVENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P836; Polana R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P2, DOI 10.1109/CVPR.1993.341009; Rivlin E., 1994, Proceedings 1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.94CH3405-8), P267, DOI 10.1109/CVPR.1994.323839; RIVLIN E, 1993, P AAAI WORKSH REAS F; SOLINA F, 1983, P SPIE C, V726, P284; Stark L., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P795, DOI 10.1109/CVPR.1992.223170; Stark L., 1993, Proceedings of IEEE Workshop on Qualitative Vision (Cat. No.93TH0521-5), P11, DOI 10.1109/WQV.1993.262954; Stark L., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P251, DOI 10.1109/CVPR.1991.139697; STARK L, 1991, IEEE T PATTERN ANAL, V13, P1097, DOI 10.1109/34.99242; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; VAINA LM, 1991, INT J INTELL SYST, V6, P313, DOI 10.1002/int.4550060306; VERRI A, 1987, 1ST P INT C COMP VIS, P171; Winston P., 1983, P AAAI 83 WASHINGTON, P433	25	14	14	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1996	18	6					579	591		10.1109/34.506409	http://dx.doi.org/10.1109/34.506409			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UR254					2022-12-18	WOS:A1996UR25400002
J	WU, CH; DOERSCHUK, PC				WU, CH; DOERSCHUK, PC			CLUSTER EXPANSIONS FOR THE DETERMINISTIC COMPUTATION OF BAYESIAN-ESTIMATORS BASED ON MARKOV RANDOM-FIELDS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						MARKOV RANDOM FIELDS; IMAGE RESTORATION; BAYESIAN; ESTIMATION; THRESHOLDED POSTERIOR MEAN ESTIMATOR	SPATIAL-INTERACTION MODELS; X-RAY CRYSTALLOGRAPHY; SIGNAL RECONSTRUCTION; STATISTICAL-ANALYSIS; IMAGE ESTIMATION; ALGORITHMS; RESTORATION; RELAXATION	We describe a family of approximations, denoted by ''cluster approximations,'' for the computation of the mean of a Markov random field (MRF). This is a key computation in image processing when applied to the a posteriori MRF. The approximation is to, account exactly for only spatially local interactions. Application of the approximation requires the solution of a nonlinear multivariable fixed-point equation for which we prove several existence, uniqueness, and convergence-of-algorithm results. Four numerical examples are presented, including comparison with Monte Carlo calculations.	PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN	Purdue University System; Purdue University; Purdue University West Lafayette Campus	WU, CH (corresponding author), ITRI,OPTOELECTR & SYST LAB,DEPT IMAGE PROC,HSINCHU,TAIWAN.		Doerschuk, Peter/A-3424-2016	Doerschuk, Peter/0000-0002-4517-6582				Allgower E. L., 1990, NUMERICAL CONTINUATI; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1986, J R STAT SOC B, V48, P259; BESAG JE, 1972, J ROY STAT SOC B, V34, P75; BIEMOND J, 1990, P IEEE, V78, P856, DOI 10.1109/5.53403; BILBRO GL, 1992, IEEE T NEURAL NETWOR, V3, P131, DOI 10.1109/72.105426; BLAKE A, 1987, VISUAL RECONSTRUCTIO, P54; CHELLAPPA R, 1982, IEEE T ACOUST SPEECH, V30, P461, DOI 10.1109/TASSP.1982.1163911; Clark J.J., 1990, DATA FUSION SENSORY; DERIN H, 1984, IEEE T PATTERN ANAL, V6, P707, DOI 10.1109/TPAMI.1984.4767595; Devijver P. A., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P259; DEVIJVER PA, 1987, PATTERN RECOGN, P141; DOERSCHUK PC, 1991, J OPT SOC AM A, V8, P1207, DOI 10.1364/JOSAA.8.001207; DOERSCHUK PC, 1991, J OPT SOC AM A, V8, P1222, DOI 10.1364/JOSAA.8.001222; ELFADEL IM, 1992, SPIE P, V1766, P257; ELFADEL IM, 1991, SPIE INT SOC OPTICAL, V1569, P248; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HIRIYANNAIAH HP, 1989, J OPT SOC AM A, V6, P1901, DOI 10.1364/JOSAA.6.001901; Ising E, 1925, Z PHYS, V31, P253, DOI 10.1007/BF02980577; JAIN AK, 1981, P IEEE, V69, P512; JENG FC, 1990, IEEE T INFORM THEORY, V36, P94, DOI 10.1109/18.50377; JENG FC, 1991, IEEE T SIGNAL PROCES, V39, P683, DOI 10.1109/78.80887; JENG FC, 1993, MARKOV RANDOM FIELDS, pCH2; KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610; LEVINSON SE, 1983, AT&T TECH J, V62, P1035, DOI 10.1002/j.1538-7305.1983.tb03114.x; LEVY P, 1956, 3RD P BERK S MATH ST, V2; LUMSDAINE A, 1991, J VLSI SIGN, V3, P53, DOI 10.1007/BF00927834; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; ORTEGA J, 1970, INTERATIVE SOLUTION; PARISI G, 1988, STATISTICAL FIELD TH; Press WH, 1988, NUMERICAL RECIPES C; RABINER LR, 1983, AT&T TECH J, V62, P1075, DOI 10.1002/j.1538-7305.1983.tb03115.x; ROSANOV YA, 1967, THEOR PROBAB APPL+, V12, P381, DOI 10.1137/1112050; SENIOR A, 1994, CURSIVE HANDWRITING; SIMCHONY T, 1990, IEEE T INFORM THEORY, V36, P608, DOI 10.1109/18.54906; WOODS JW, 1972, IEEE T INFORM THEORY, V18, P232, DOI 10.1109/TIT.1972.1054786; WOODS JW, 1987, IEEE T PATTERN ANAL, V9, P245, DOI 10.1109/TPAMI.1987.4767898; WOODS JW, 1978, IEEE T AUTOMAT CONTR, V23, P846, DOI 10.1109/TAC.1978.1101866; WOODS JW, 1972, IEEE T INFORM THEORY, V23, P232; WU CL, THESIS PURDUE U W LA; ZHANG J, 1992, IEEE T SIGNAL PROCES, V40, P2570, DOI 10.1109/78.157297; Zhang J, 1993, IEEE T IMAGE PROCESS, V2, P27, DOI 10.1109/83.210863; [No title captured]	45	14	14	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1995	17	3					275	293		10.1109/34.368192	http://dx.doi.org/10.1109/34.368192			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QM090					2022-12-18	WOS:A1995QM09000005
J	JANG, JW; PARK, H; PRASANNA, VK				JANG, JW; PARK, H; PRASANNA, VK			A FAST ALGORITHM FOR COMPUTING A HISTOGRAM ON RECONFIGURABLE MESH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						HISTOGRAM; RECONFIGURABLE MESH; MAPPING; PARALLEL ALGORITHM	PARALLEL COMPUTER; PROCESSOR ARRAY; BUS SYSTEM	The reconfigurable mesh captures salient features from a variety of sources, including the CAAPP, the CHiP, the polymorphic-torus network and the bus automaton. It consists of an array of processors interconnected by a reconfigurable bus system. The bus system can be used to dynamically obtain various interconnection patterns between the processors. In this paper, we present a fast algorithm for computing the histogram of an N x N image with h grey levels in O(min{root h + log*(N / h), N}) time on an N x N reconfigurable mesh assuming each PE has a constant amount of local memory. This algorithm runs on the PARBUS and MRN/LRN models. In addition, histogram modification can be performed in O(root h) time on the same model. A variant of our algorithm runs in O(min{root h + loglog(N / h), N}) time on an N x N RMESH in which each PE has constant storage. This result improves the known time and memory bounds for histogramming on the RMESH model.	SAMSUNG ELECTR CO LTD,KYOUNGKI DO,SOUTH KOREA; UNIV SO CALIF,DEPT ELECT ENGN SYST,DIV COMP ENGN,LOS ANGELES,CA 90089	Samsung; University of Southern California	JANG, JW (corresponding author), SAMSUNG ELECTR CO LTD,APT 2-506,OKEUMDONG 160,SEOUL 138130,SOUTH KOREA.							Alnuweiri H. M., 1993, Proceedings of Seventh International Parallel Processing Symposium (Cat. No.93TH0513-2), P569, DOI 10.1109/IPPS.1993.262816; Baker A, 1984, CONCISE INTRO THEORY; BENASHER Y, 1991, J PARALLEL DISTR COM, V13, P139, DOI 10.1016/0743-7315(91)90084-M; BENASHER Y, 1992, 716 TECHN ISR I TECH; BESTUL T, 1989, IEEE T PATTERN ANAL, V11, P212, DOI 10.1109/34.16717; ELGINDY H, 1991, AUG P INT C PAR PROC; Hedlund K. S., 1982, Proceedings of the 1982 International Conference on Parallel Processing, P262; JA JJ, 1992, INTRO PARALLEL ALGOR, P556; Jang J., 1992, Proceedings of the Fourth IEEE Symposium on Parallel and Distributed Processing (Cat. No.92TH0492-9), P384, DOI 10.1109/SPDP.1992.242720; JANG J, 1992, MAR P INT PAR PROC S, P130; JANG J, 1992, P FRONTIERS MASSIVEL, P244; JANG J, 1992, P INT C PARALLEL PRO; JANG J, 1992, APR P REC ARCH WORKS; Jenq J.-F., 1992, Proceedings. Sixth International Parallel Processing Symposium (Cat. No.92TH0419-2), P425, DOI 10.1109/IPPS.1992.223008; KUMAR V, 1993, INTRO PARALLEL COMPU; KUMAR VKP, 1987, J PARALLEL DISTR COM, V4, P173, DOI 10.1016/0743-7315(87)90003-7; LI HW, 1989, IEEE T COMPUT, V38, P1345, DOI 10.1109/12.29479; LIN R, 1993, P INT PHOENIX C COMP; LIN WM, 1990, COMPUT VISION GRAPH, V49, P104, DOI 10.1016/0734-189X(90)90166-S; Miller R., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P925, DOI 10.1109/CVPR.1988.196343; MILLER R, 1988, 5TH P MIT C ADV RES, P163; MILLER R, 1993, IEEE T COMPUT, P678; NAKANO K, 1991, I ELECTRONICS INFO E, V74; NASSIMI D, 1981, IEEE T COMPUT, V30, P101, DOI 10.1109/TC.1981.6312172; NIGAM M, 1993, APR P INT PAR PROC S, P73; OLARIU S, 1992, IMAGE VISION COMPUT, P610; PARK H, 1993, P INT C PARALLEL PRO; RAJASHEKARAN S, 1993, UNPUB MESH CONNECTED; RAJASHEKARAN S, 1993, 1ST ANN EUR S ALG; ROTHSTEIN J, 1988, IEEE T SYST MAN CYB, V18, P522, DOI 10.1109/21.17370; SNYDER L, 1982, COMPUTER, V15, P47, DOI 10.1109/MC.1982.1653826; TANIMOTO SL, 1984, MULTIRESOLUTION IMAG, P136; THIRUCHELVAN RK, 1993, APR P INT PAR PROC S, P79; THOMPSON CD, 1977, COMMUN ACM, V20, P263, DOI 10.1145/359461.359481; THORNBURG M, 1994, APR P INT PAR PROC S; WANG BF, 1990, INFORM PROCESS LETT, V36, P31, DOI 10.1016/0020-0190(90)90182-W; WANG BF, 1990, INFORM PROCESS LETT, V34, P187, DOI 10.1016/0020-0190(90)90158-T; WANG BF, 1991, IEEE T PARALL DISTR, V1, P500; WEEMS CC, 1989, INT J COMPUT VISION, V2, P251, DOI 10.1007/BF00158166; [No title captured]; 1994, APR P REC ARCH WORKS	41	14	16	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1995	17	2					97	106		10.1109/34.368177	http://dx.doi.org/10.1109/34.368177			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QE825					2022-12-18	WOS:A1995QE82500001
J	TICHEM, M; COHEN, MS				TICHEM, M; COHEN, MS			SUB-MU-M REGISTRATION OF FIDUCIAL MARKS USING MACHINE VISION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						MACHINE VISION; SUB-MU-M REGISTRATION; FIDUCIAL MARKS; MICROSCOPY; DIFFRACTION EFFORTS	SUBPIXEL REGISTRATION; ACCURACY	Submum registration between circularly symmetric fiducial marks can be achieved simply by finding their centroids by fitting circles to distributed edge positions determined by the second-derivative zero-crossing method. However, because of diffraction fringes, substantial errors originating in the tilt of the microscope optical axis must be minimized.	IBM CORP,THOMAS J WATSON RES CTR,YORKTOWN HTS,NY 10598	International Business Machines (IBM)	TICHEM, M (corresponding author), DELFT UNIV TECHNOL,FAC MECH ENGN & MARINE TECHNOL,FLEX PROD AUTOMAT LAB,DELFT,NETHERLANDS.			Tichem, Marcel/0000-0001-6441-5748				ARMIENTO CA, 1991, ELECTRON LETT, V27, P1109, DOI 10.1049/el:19910689; BERENSTEIN CA, 1987, COMPUT VISION GRAPH, V40, P334, DOI 10.1016/S0734-189X(87)80146-9; BOSE CB, 1990, IEEE T PATTERN ANAL, V12, P1196, DOI 10.1109/34.62609; COHEN MS, 1992, IEEE T COMPONENTS HY, V15; COHEN MS, 1994, IN PRESS IEEE T CO B, V17; ENOCHS S, 1986, P SOC PHOTO-OPT INS, V703, P42; GLEASON SS, 1991, P SOC PHOTO-OPT INS, V1386, P135, DOI 10.1117/12.25387; HYDE PD, 1983, PATTERN RECOGN, V16, P413, DOI 10.1016/0031-3203(83)90063-8; JACKSON KP, 1992, 42ND P EL COMP TECHN, P93; OVERINGTON I, 1987, IMAGE VISION COMPUT, V5, P217, DOI 10.1016/0262-8856(87)90052-7; TABATABAI AJ, 1984, IEEE T PATTERN ANAL, V6, P188, DOI 10.1109/TPAMI.1984.4767502; THOMAS SM, 1989, COMPUT VISION GRAPH, V45, P362, DOI 10.1016/0734-189X(89)90088-1; TIAN Q, 1986, COMPUT VISION GRAPH, V35, P220, DOI 10.1016/0734-189X(86)90028-9; Wu F., COMMUNICATION	14	14	14	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1994	16	8					791	794		10.1109/34.308473	http://dx.doi.org/10.1109/34.308473			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PB475					2022-12-18	WOS:A1994PB47500003
J	COHN, D; RISKIN, EA; LADNER, R				COHN, D; RISKIN, EA; LADNER, R			THEORY AND PRACTICE OF VECTOR QUANTIZERS TRAINED ON SMALL TRAINING SETS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						IMAGE CODING; LEARNING THEORY; VAPNIK-CHERVONENKIS DIMENSION; VECTOR QUANTIZATION	CHERVONENKIS	We examine how the performance of a memoryless vector quantizer changes as a function of its training set size. Specifically, we study how well the training set distortion predicts test distortion when the training set is a randomly drawn subset of blocks from the test or training image(s). Using the Vapnik-Chervonenkis (VC) dimension, we derive formal bounds for the difference of test and training distortion of vector quantizer codebooks. We then describe extensive empirical simulations that test these bounds for a variety of codebook sizes and vector dimensions, and give practical suggestions for determining the training set size necessary to achieve good generalization from a codebook. We conclude that, by using training sets comprised of only a small fraction of the available data, one can produce results that are close to the results obtainable when all available data are used.	UNIV WASHINGTON, DEPT COMP SCI & ENGN, SEATTLE, WA 98195 USA; UNIV WASHINGTON, DEPT ELECT ENGN, SEATTLE, WA 98195 USA	University of Washington; University of Washington Seattle; University of Washington; University of Washington Seattle								BLUMER A, 1989, J ACM, V36, P929, DOI 10.1145/76359.76371; COHN D, 1992, NEURAL COMPUT, V4, P249, DOI 10.1162/neco.1992.4.2.249; COHN D, 1992, THESIS U WASHINGTON; COSMAN P, 1991, 25 AS C SIGN SYST CO, P434; Crutchfield J. P., 1990, COMPLEXITY ENTROPY P, P223; Floyd. R. W., 1975, SID DIGEST, P36; Gersho A., 1992, VECTOR QUANTIZATION; Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229; ITAKURA F, 1968, 6TH P INT C AC TOK, pC17; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; LINDER T, IN PRESS IEEE T INFO; Netravali A.N., 1988, DIGITAL PICTURES REP; POLLARD D, 1982, ANN PROBAB, V10, P919, DOI 10.1214/aop/1176993713; Ulichney Robert, 1987, DIGITAL HALFTONING, P5; Vapnik V., 1982, ESTIMATION DEPENDENC; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Weiss Sholom, 1991, COMPUTER SYSTEMS LEA; ZEHNA P, 1970, PROBABILITY DISTRIBU, P286; [No title captured]; [No title captured]	20	14	14	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1994	16	1					54	65		10.1109/34.273717	http://dx.doi.org/10.1109/34.273717			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MV733					2022-12-18	WOS:A1994MV73300005
J	QUEK, F; JAIN, R; WEYMOUTH, TE				QUEK, F; JAIN, R; WEYMOUTH, TE			AN ABSTRACTION-BASED APPROACH TO 3-D POSE DETERMINATION FROM RANGE IMAGES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						ABSTRACTION; ASSUMPTION; COMPOUND SURFACES; GEOMETRIC REASONING; LASER RANGE DATA; PARAMETRIC SURFACES; 3-D OBJECT RECOGNITION; 3-D POSE DETERMINATION	RECOGNITION; SHAPE; ORIENTATION; RECOVERY; OBJECT	An abstraction-based paradigm that makes explicit the process of imposing assumptions on data has been developed. The units of abstraction are models whose levels of abstraction are determined by the degree of assumption necessary for their application. A general-to-specific refinement process provides a mechanism to proceed gracefully through the abstraction hierarchy. The task of object recognition and pose determination becomes one of making increasingly stronger assumptions about the data. These assumptions yield model hypotheses that may then be applied and tested. This process of assumption and abstraction furnishes a path between symbolic descriptors of objects in the scene to their numeric specification. Throughout the process, abstractions are made to interpret better the original data to which the hypothesized models are fitted/computed. The strategy is thus data bound. This strategy was applied to the recognition and pose determination of objects comprising simple and compound cylindrical and planar surfaces in dense range data. For compound surfaces, especially, the assumptions of scene contents are necessary before specific split-and-merge operators can be used to segment the image. A method of computing reliable Gaussian and mean curvature sign-map descriptors from the polynomial approximations of surfaces is demonstrated. Such descriptors, which are invariant under perspective variation, are suitable for hypothesis generation. A means for determining the pose of constructed geometric forms whose algebraic surface descriptions are nonlinear in terms of their orienting parameters is developed. This is done by means of linear functions that are capable of approximating nonlinear forms and determining their parameters. It is shown that biquadratic surfaces are suitable companion-linear forms for cylinder approximation and parameter estimation. The estimates provided the initial parametric approximations necessary for a nonlinear regression stage to fine tune the estimates by fitting the actual nonlinear form to the data.	UNIV MICHIGAN,ARTIFICIAL INTELLIGENCE LAB,ANN ARBOR,MI 48109; UNIV CALIF SAN DIEGO,LA JOLLA,CA 92093	University of Michigan System; University of Michigan; University of California System; University of California San Diego	QUEK, F (corresponding author), UNIV ILLINOIS,DEPT ELECT ENGN & COMP SCI,CHICAGO,IL 60680, USA.							ASADA H, 1984, 2ND P IEEE WORKSH CO, P8; AUGUSTEIJN MF, 1986, COMPUT VISION GRAPH, V36, P76, DOI 10.1016/S0734-189X(86)80030-5; BALLARD DH, 1983, IEEE T PATTERN ANAL, V5, P653, DOI 10.1109/TPAMI.1983.4767456; BARROW HG, 1981, ARTIF INTELL, V17, P75, DOI 10.1016/0004-3702(81)90021-7; BEAUDET PR, 1978, 4TH P INT JOINT C PA; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; BESL PJ, 1988, SURFACES RANGE IMAGE; BESL PJ, 1985, COMPUT SURVEYS, V17; Binford T. O., 1982, INT J ROBOT RES, V1, P18; BOLLES RC, 1984, ROBOTICS RES, P413; BOYTER BA, 1986, IEEE EXPERT, P47; BRADY M, 1984, IEEE T PATTERN ANAL, V6, P288, DOI 10.1109/TPAMI.1984.4767521; BRADY M, 1984, P IEEE INT C ROB, P256; BROOKS RA, 1983, IEEE T PATTERN ANAL, V5, P140, DOI 10.1109/TPAMI.1983.4767366; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; BROOKS RA, 1979, 76TH P IJCAI, P105; BROU P, 1984, INT J ROBOT RES, V3, P89, DOI 10.1177/027836498400300406; Cheng J. K., 1982, Proceedings of PRIP 82. IEEE Computer Society Conference on Pattern Recognition and Image Processing, P343; CHIN RT, 1986, COMPUT SURV, V18, P67, DOI 10.1145/6462.6464; DHOME M, 1986, ERB985 NAT RES COUNC; ENGELBRECHT JR, 1988, PATTERN RECOGN, V21, P155, DOI 10.1016/0031-3203(88)90023-4; HORAUD P, 1984, MAR P INT C ROB ATL, P78; HORAUD R, 1987, 1ST P INT C COMP VIS, P374; HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073; IKEUCHI K, 1981, 7TH P INT JOINT C AR, P595; IKEUCHI K, 1983, MIT AI726 ART INT LA; KANADE T, 1981, ARTIF INTELL, V17, P409, DOI 10.1016/0004-3702(81)90031-X; KINDLE JH, 1950, ANAL GEOMETRY; KNOLL TF, 1987, 1ST P INT C COMP VIS; Little JJ, 1983, AUG P NAT C ART INT, P247; Milgram D. L., 1980, Proceedings of the 5th International Conference on Pattern Recognition, P912; Millman R.S., 1977, ELEMENTS DIFFERENTIA; OROURKE J, 1981, 7TH P INT JOINT C AR, P664; Press WH., 1980, NUMERICAL RECIPES FO; RIGGS AJ, 1986, 1973011S1 ENV RES I; SAMPSON RE, 1987, IEEE COMPUT, V20, P23; SVETKOFF DJ, 1986, OCT P SPIE C OPT ILL, V728; WILSON WA, 1937, ANAL GEOMETRY ALTERN; YOU KC, 1979, IEEE T SYST MAN CYB, V9, P334, DOI 10.1109/TSMC.1979.4310222; 1989, CONFIGURATION DESCRI	40	14	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1993	15	7					722	736		10.1109/34.221172	http://dx.doi.org/10.1109/34.221172			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LM185					2022-12-18	WOS:A1993LM18500006
J	WANG, XL; BERTRAND, G				WANG, XL; BERTRAND, G			SOME SEQUENTIAL ALGORITHMS FOR A GENERALIZED DISTANCE TRANSFORMATION BASED ON MINKOWSKI OPERATIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter						DISTANCE TRANSFORMATION; MATHEMATICAL MORPHOLOGY; MEDIAL AXIS TRANSFORMATION; N-PERIOD; SCANNING; STRUCTURING ELEMENT DECOMPOSITION	BINARY IMAGES; MATHEMATICAL MORPHOLOGY; REPRESENTATION	A generalized distance transformation (GDT) of binary images and the related medial axis transformation (MAT) are discussed. These transformations are defined in a discrete space of arbitrary dimension and arbitrary grids. The GDT is based on successive morphological operations using alternatively N arbitrary structuring elements: N is called the period of the GDT. The GDT differs from the classical distance transformations based on a point-to-point distance. However, the well-known chessboard, city-block, and hexagonal distance transformations are special cases of the one-period GDT, whereas the octagonal distance transformation is a special case of the two-period GDT. In this paper, both one- and two-period GDT's are discussed. Different sequential algorithms are proposed for computing such GDT's. These algorithms need a maximum of two scannings of the image. The computation of the MAT is also discussed.			WANG, XL (corresponding author), ECOLE SUPER INGN ELECTR & ELECT,INTELLIGENCE ARTIFICIELLE & ANAL IMAGES LAB,NOISY LE GRAND,FRANCE.							Abbott L., 1988, Machine Vision and Applications, V1, P23, DOI 10.1007/BF01212310; ARCELLI C, 1985, IEEE T PATTERN ANAL, V7, P463, DOI 10.1109/TPAMI.1985.4767685; ARCELLI C, 1987, PATTERN RECOGN LETT, V6, P245, DOI 10.1016/0167-8655(87)90084-5; Bertrand G., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P326; BERTRAND G, 1984, 4TH C REC FORM INT A, P265; Blum H., 1964, MODELS PERCEPTION SP, P362; BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; BORGEFORS G, 1984, COMPUT VISION GRAPH, V27, P321, DOI 10.1016/0734-189X(84)90035-5; CHEN MH, 1989, IEEE T PATTERN ANAL, V11, P694, DOI 10.1109/34.192464; DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4; DAS PP, 1988, PATT RECOGN LETT APR, P215; DILL AR, 1987, IEEE T PATTERN ANAL, V9, P495, DOI 10.1109/TPAMI.1987.4767937; Gong Wei, 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P836, DOI 10.1109/ICPR.1988.28374; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; JI L, 1989, PATTERN RECOGN LETT, V9, P201, DOI 10.1016/0167-8655(89)90055-X; Lantuejoul C., 1980, ISSUES DIGITAL IMAGE; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; MARAGOS PA, 1986, IEEE T ACOUST SPEECH, V34, P1228, DOI 10.1109/TASSP.1986.1164959; MARAGOS PA, 1985, DSPL851 TECH REP; MELTER RA, 1987, PATT RECOGN LETT SEP, P235; MILGRAM M, 1986, TRAITEMENT SIGNAL, V3, P303; MONTANARI U, 1968, J ACM, V15, P600, DOI 10.1145/321479.321486; MONTANVERT A, 1987, 6EME C REC FORM INT, P233; PECHT J, 1985, PATTERN RECOGN LETT, V3, P113, DOI 10.1016/0167-8655(85)90017-0; ROSENFEL.A, 1966, J ACM, V13, P471; ROSENFELD A, 1968, PATTERN RECOGN, V1, P33, DOI 10.1016/0031-3203(68)90013-7; Schonfeld D., 1991, Journal of Visual Communication and Image Representation, V2, P17, DOI 10.1016/1047-3203(91)90032-B; SCHONFELD D, 1991, IEEE T PATTERN ANAL, V13, P14, DOI 10.1109/34.67627; SCHONFELD D, 1988, SPIE P VISUAL COMMUN, V1001, P138; SCHONFELD D, 1991, IEEE T ACOUST SPEECH, V39, P411; Serra J, 1982, IMAGE ANAL MATH MORP; SHAPIRO LG, 1987, PATTERN RECOGN, V20, P75, DOI 10.1016/0031-3203(87)90019-7; Sternberg S. R., 1985, Integrated Technology for Parallel Image Processing, P79; SUZUKI S, 1985, IEEE T PATTERN ANAL, V7, P638, DOI 10.1109/TPAMI.1985.4767720; WANG X, 1988, 9TH ICPR ROM, P1163; WANG X, 1992, COMPUTATION MORPHOLO; YAMASHITA M, 1986, PATTERN RECOGN, V19, P237, DOI 10.1016/0031-3203(86)90014-2; YOKOI S, 1981, IEEE T PATTERN ANAL, V3, P424, DOI 10.1109/TPAMI.1981.4767128; ZHOU Z, 1989, P ICASSP, P1695; ZHOU Z, 1988, P IEEE INT C AC SPEE, P948; ZHUANG XH, 1986, COMPUT VISION GRAPH, V35, P370, DOI 10.1016/0734-189X(86)90006-X	41	14	15	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV	1992	14	11					1114	1121		10.1109/34.166628	http://dx.doi.org/10.1109/34.166628			8	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JX370					2022-12-18	WOS:A1992JX37000008
J	GU, J; WANG, W				GU, J; WANG, W			A NOVEL DISCRETE RELAXATION ARCHITECTURE	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note						ARC CONSISTENCY; BACKTRACK SEARCH; CONSTRAINT SATISFACTION PROBLEM (CSP); DISCRETE RELAXATION ALGORITHM (DRA); PARALLEL HARDWARE ARCHITECTURE	CONSISTENT LABELING PROBLEM; PARALLEL; OPERATIONS; NETWORKS	The discrete relaxation algorithm (DRA) is a computational technique that enforces arc consistency (AC) in a constraint satisfaction problem (CSP). It has been widely used in artificial intelligence, operations research, pattern recognition and computer vision, and many related areas. The original sequential AC-1 algorithm suffers from O(n3m3) time complexity, and even the optimal sequential AC-4 algorithm is O(n2m2) for an n-object and m-label DRA problem. Sample problem runs show that these algorithms are all too slow to meet the need for any useful, real-time CSP applications. In this paper, we give a parallel DRA5 algorithm that reaches a lower bound of O(nm) (where the number of processors is polynomial in the problem size). A fine-grained, massively parallel hardware computer architecture has been designed for the DRA5 algorithm. For practical problems, many orders of magnitude of efficiency improvement can be reached on such a hardware architecture.	UNIV UTAH, DEPT ELECT ENGN, SALT LAKE CITY, UT 84112 USA	Utah System of Higher Education; University of Utah	GU, J (corresponding author), UNIV CALGARY, DEPT ELECT & COMP ENGN, CALGARY T2N 1N4, ALBERTA, CANADA.							BELL CG, 1986, NOV ACM IEEE FALL JO; BELL G, 1989, COMMUN ACM, V32, P1091, DOI 10.1145/66451.66457; COOPER PR, 1988, TR255 U ROCH DEP COM; FLYNN MJ, 1972, IEEE T COMPUT, VC 21, P948, DOI 10.1109/TC.1972.5009071; FUJIMOTO RM, 1983, SIMON SIMULATOR MULT; GU J, 1989, COMPUTER, V22, P9, DOI 10.1109/2.43523; GU J, 1987, IEEE T PATTERN ANAL, V9, P816, DOI 10.1109/TPAMI.1987.4767988; GU J, 1990, 3RD SYMPOSIUM ON THE FRONTIERS OF MASSIVELY PARALLEL COMPUTATION, P215, DOI 10.1109/FMPC.1990.89462; GU J, IN PRESS IMPLEMENTAT; GU J, 1988, UUCSTR88006 U UT DEP; GU J, 1987, UUCSTR88006 U UT DEP; GU J, 1990, BENCHMARKING SAT ALG; HARALICK RM, 1979, IEEE T PATTERN ANAL, V1, P173, DOI 10.1109/TPAMI.1979.4766903; HUANG X, IN PRESS QUANTITATIV; HWANG K, 1987, P IEEE, V75, P1348, DOI 10.1109/PROC.1987.13894; JOHNSON RR, 1990, IEEE SPECTRUM, V27, P34, DOI 10.1109/6.48848; JOHNSON RR, 1987, COMMUNICATION; KAUTZ WH, 1970, SRI5509 STANF RES I; KU DCL, 1986, DRA1 CHIP IMPLEMENTA; LIN WM, 1989, AUG AAAI WORKSH PAR; MACKWORTH AK, 1977, ARTIF INTELL, V8, P99, DOI 10.1016/0004-3702(77)90007-8; MCCALL JT, 1985, IEEE T COMPUT, V34, P973, DOI 10.1109/TC.1985.1676530; MCLEAN CR, 1980, 5TH P INT C PATT REC, P58; MOHR R, 1986, RUNNING EFFICIENTLY; MOHR R, 1988, 8TH P EUR C ART INT, P651; MOHR R, 1987, CRININRIA87R030 TECH; MONTANAR.U, 1974, INFORM SCIENCES, V7, P95, DOI 10.1016/0020-0255(74)90008-5; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; SAMAL A, 1988, PARALLEL SPLIT LEVEL; SWAIN MJ, 1988, P IMAGE UNDERSTANDIN; SWAIN MJ, 1988, COMMUNICATION   0522; WANG W, 1987, IEEE T CIRCUITS SYST, V34, P1375, DOI 10.1109/TCS.1987.1086060; Weaver W., 1949, MATH THEORY INFORM; [No title captured]; [No title captured]	35	14	15	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	AUG	1992	14	8					857	865		10.1109/34.149596	http://dx.doi.org/10.1109/34.149596			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JG613					2022-12-18	WOS:A1992JG61300008
J	WILSON, SS				WILSON, SS			THEORY OF MATRIX MORPHOLOGY	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						DILATION; EROSION; GRAY SCALE; IMAGE ANALYSIS; MATRIX; MORPHOLOGY; OPENING; PATTERN RECOGNITION	OPERATIONS	In mathematical morphology, erosions and dilations are operations on images using structuring elements. These operators are useful for image analysis and have been well studied and formalized. The current concept of mathematical morphology (called scalar morphology here) can be extended to a matrix morphology formalism. A matrix of images is defined to be an array where each component is a separate image with a matrix indexing. A matrix of structuring elements is an array of separate structuring elements with a matrix indexing. Dilations or erosions of a matrix of images by a matrix of structuring elements consist of a number of dilations or erosions of various image components with structuring element components. The rules of matrix operations will tell which image components are transformed by which structuring element components and how the results are combined into a new array. The matrix representation concisely denotes operations occurring in several areas of morphology such as the hit-and-miss transform, look-up tables (LUT's) window transforms, threshold decompositions, and stack filters. The operations of matrix morphology are very useful for completely describing the underlying structure of many applications. Whereas scalar morphology deals with sets that are used to describe shapes, matrix morphology deals with the relationship of shapes used to describe feature spaces. In this paper, matrix morphology will be defined, and it will be shown that most of the formal properties of scalar morphology have a valid counterpart in the matrix theory.			WILSON, SS (corresponding author), APPL INTELLIGENT SYST INC,RES & DEV,ANN ARBOR,MI 48103, USA.							CRUMMINS TR, 1985, IEEE T AERO ELEC SYS, V21, P60; FITCH JP, 1985, IEEE T CIRCUITS SYST, V32, P445, DOI 10.1109/TCS.1985.1085740; HADWIGER H, 1957, VORLESUNGEN UBER INH, P142; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; LOUGHEED RM, 1980, 7TH P ANN INT S COMP; MARAGOS P, 1987, IEEE T ACOUST SPEECH, V35, P1170, DOI 10.1109/TASSP.1987.1165254; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P586, DOI 10.1109/34.24793; MATHERON G., 1975, RANDOM SETS INTEGRAL; NAKAGAWA Y, 1978, IEEE T SYST MAN CYB, V8, P632; SCHMITT LA, 1988, IEEE T PATTERN ANAL, V10, P320, DOI 10.1109/34.3897; Serra J, 1982, IMAGE ANAL MATH MORP; STERNBERG SR, 1986, COMPUT VISION GRAPH, V35, P333, DOI 10.1016/0734-189X(86)90004-6; WENDT PD, 1986, IEEE T ACOUST SPEECH, V34, P898, DOI 10.1109/TASSP.1986.1164871; WILSON SS, 1989, IEEE T SYST MAN CYBE, V19; WILSON SS, 1991, 36TH P SPIE ANN SYM, V1568, P21; WILSON SS, MATH MORPHOLOGY IMAG; WILSON SS, 1991, NEURAL INTELLIGENT S	17	14	16	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN	1992	14	6					636	652		10.1109/34.141554	http://dx.doi.org/10.1109/34.141554			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HX546					2022-12-18	WOS:A1992HX54600004
J	WEISS, RS; NAKATANI, H; RISEMAN, EM				WEISS, RS; NAKATANI, H; RISEMAN, EM			AN ERROR ANALYSIS FOR SURFACE ORIENTATION FROM VANISHING POINTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									SHIZUOKA UNIV,DEPT INFORMAT & KNOWLEDGE ENGN,HAMAMATSU,SHIZUOKA 432,JAPAN	Shizuoka University	WEISS, RS (corresponding author), UNIV MASSACHUSETTS,DEPT COMP & INFORMAT SCI,AMHERST,MA 01003, USA.							BARNARD ST, 1983, ARTIF INTELL, V21, P435, DOI 10.1016/S0004-3702(83)80021-6; BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808; COLLINS RT, 1989, JUN P OT SOC AM WORK, V14, P92; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; HERMAN M, 1984, IEEE T PATTERN ANAL, V6, P331, DOI 10.1109/TPAMI.1984.4767526; HORAUD R, 1987, IEEE T PATTERN ANAL, V9, P401, DOI 10.1109/TPAMI.1987.4767922; KANATANI KI, 1987, COMPUT VISION GRAPH, V39, P328, DOI 10.1016/S0734-189X(87)80185-8; MAGEE MJ, 1984, COMPUT VISION GRAPH, V26, P256, DOI 10.1016/0734-189X(84)90188-9; NAKATANI H, 1984, P SOC PHOTO-OPT INST, V507, P164, DOI 10.1117/12.944951; Nakatani H., 1980, Proceedings of the 5th International Conference on Pattern Recognition, P370; NAKATANI H, 1984, 1ST P INT C COMP APP; NAKATANI H, 1986, THESIS OSAKA U	12	14	15	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC	1990	12	12					1179	1185		10.1109/34.62606	http://dx.doi.org/10.1109/34.62606			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EN500					2022-12-18	WOS:A1990EN50000005
J	SINHA, D; GIARDINA, CR				SINHA, D; GIARDINA, CR			DISCRETE BLACK AND WHITE OBJECT RECOGNITION VIA MORPHOLOGICAL FUNCTIONS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									CUNY, COLL STATEN ISL, DEPT COMP SCI, STATEN ISL, NY 10312 USA	City University of New York (CUNY) System; College of Staten Island (CUNY)	SINHA, D (corresponding author), STEVENS INST TECHNOL LIB, DEPT ELECT ENGN & COMP SCI, HOBOKEN, NJ 07030 USA.							ALBERNY R, 1969, T METALL SOC AIME, V245, P55; Beucher S., 1979, P INT WORKSHOP IMAGE; BLUM H, 1964, P S MODELS PERCEPTIO; DAVIES ER, 1981, PATTERN RECOGN, V14, P53, DOI 10.1016/0031-3203(81)90045-5; DOUGHERTY ER, 1988, MORPHOLOGICAL METHOD; ELLIAS H, 1967, QUANTITATIVE METHODS; FLOOK AG, 1978, POWDER TECHNOL, V21, P295, DOI 10.1016/0032-5910(78)80099-0; GOETCHERIAN V, 1980, PATTERN RECOGN, V12, P7, DOI 10.1016/0031-3203(80)90049-7; HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Lantuejoul C., 1980, ISSUES DIGITAL IMAGE; Mac Lane S., 1967, ALGEBRA; Matheron G., 1975, RANDOM SETS INTEGRAL; MATHERON G, 1969, THEORIE ENSEMBLES AL; MEYER F, 1979, J HISTOCHEM CYTOCHEM, V27, P128, DOI 10.1177/27.1.438499; MMEYER F, 1980, THESIS PARIS SCH MIN; SERRA J, 1986, COMPUT VISION GRAPH, V35, P283, DOI 10.1016/0734-189X(86)90002-2; Serra J, 1982, IMAGE ANAL MATH MORP; SERRA J, 1972, J MICROSCOPY, P93; Serra J, 1988, IMAGE ANAL MATH MORP; Shapiro L. G., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P416; SHIH FY, 1988, P IEEE INT C ROB AUT, V3, P1764; SINHA D, 1988, CS8819 STEV TECH HOB; SINHA D, 1988, CS8806 STEV TECH HOB; SINHA D, 1988, CS8805 STEV TECH HOB; SINHA D, 1989, P SPIE C ADV INTELLI, V1192; SINHA D, 1987, THESIS STEVENS TECH; Sternberg S. R., 1983, Proceedings of the Robotic Intelligence and Productivity Conference, P35; STERNBERG SR, 1986, COMPUT VISION GRAPH, V35, P333, DOI 10.1016/0734-189X(86)90004-6; STERNBERG SR, 1985, IEEE T ACOUST SPEECH, V34, P1329; STERNBERG SR, 1979, 3RD P INT IEEE COMPS; VANDRIELKULKER AMJ, 1980, MICROSC ACTA, P73; VOSS K, 1981, STEREOL IUGOSL S1, V3, P139	34	14	14	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAR	1990	12	3					275	293		10.1109/34.49053	http://dx.doi.org/10.1109/34.49053			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	CP943					2022-12-18	WOS:A1990CP94300004
J	FERRIE, FP; LEVINE, MD				FERRIE, FP; LEVINE, MD			WHERE AND WHY LOCAL SHADING ANALYSIS WORKS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											FERRIE, FP (corresponding author), MCGILL UNIV,MCGILL RES CTR INTELLIGENT MACHINES,COMP VIS & ROBOT LAB,MONTREAL H3A 2A7,QUEBEC,CANADA.							BRUSS A, 1981, MIT AI623 MEM; FERRIE FP, 1986, THESIS MCGILL U MONT; FERRIE FP, 1988, JUN P IEEE COMP SOC; Horn Berthold K. P., 1975, PSYCHOL COMPUTER VIS, P115; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; HORN BKP, 1970, MIT MAC TR79; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; IKEUCHI K, 1983, MIT AI744 MEM; LECLERC YG, 1987, IEEE T PATTERN ANAL, V9, P341, DOI 10.1109/TPAMI.1987.4767918; LECLERC YG, 1985, JUN P IEEE C COMP VI, P34; LEE C, 1983, TR1277 U MAR TECH RE; PENTLAND AP, 1986, ARTIF INTELL, V29, P147, DOI 10.1016/0004-3702(86)90017-2; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P170, DOI 10.1109/TPAMI.1984.4767501; PENTLAND AP, 1982, J OPT SOC AM, V72, P448, DOI 10.1364/JOSA.72.000448; SMITH GB, 1983, SRI287 TECH NOT; STEVENS KA, 1979, THESIS MIT CAMBRIDGE; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9; ZUCKER SW, 1987, ENCY ARTIFICIAL INTE	18	14	14	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB	1989	11	2					198	206		10.1109/34.16715	http://dx.doi.org/10.1109/34.16715			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	R9989					2022-12-18	WOS:A1989R998900008
J	DODD, N				DODD, N			MULTISPECTRAL TEXTURE SYNTHESIS USING FRACTAL CONCEPTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											DODD, N (corresponding author), ROYAL SIGNALS & RADAR ESTAB, RES INITIAT PATTERN RECOGNIT, ST ANDREWS RD, MALVERN WR14 3PS, WORCS, ENGLAND.							FOURNIER A, 1982, COMMUN ACM, V25, P371, DOI 10.1145/358523.358553; KELLY DH, 1973, PERCEPT PSYCHOPHYS, V14, P313, DOI 10.3758/BF03212397; Mandelbrot, 1982, FRACTAL GEOMETRY NAT, P468, DOI DOI 10.1002/ESP3290080415; Mandelbrot B.B., 1977, FRACTALS FORM CHANCE; MANDELBROT BB, 1982, COMMUN ACM, V25, P581; Peleg S, 1984, IEEE Trans Pattern Anal Mach Intell, V6, P518, DOI 10.1109/TPAMI.1984.4767557; PENTLAND A, 1983, JUN IEEE C VIS PATT; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591; ROSENFELD A, 1982, IEEE T SYST MAN CYBE, V12; 1979, GEOMETRIC PATTERN RE	10	14	14	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	SEP	1987	9	5					703	707		10.1109/TPAMI.1987.4767967	http://dx.doi.org/10.1109/TPAMI.1987.4767967			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	J7393	21869431				2022-12-18	WOS:A1987J739300014
J	SANZ, JLC; DINSTEIN, I				SANZ, JLC; DINSTEIN, I			PROJECTION-BASED GEOMETRICAL FEATURE-EXTRACTION FOR COMPUTER VISION - ALGORITHMS IN PIPELINE ARCHITECTURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note									BEN GURION UNIV, DEPT ELECT ENGN, BEER SHEVA, ISRAEL	Ben Gurion University	SANZ, JLC (corresponding author), IBM ALMADEN RES CTR, DEPT COMP SCI, 650 HARRY RD, SAN JOSE, CA 95120 USA.							AKL S, 1979, 4TH P INT C PATT REC, P483; Bhattacharya B.K., 1983, IMAGE VISION COMPUT, V1, P140, DOI 10.1016/0262-8856(83)90065-3; Bracewell R.N., 1979, IMAGE RECONSTRUCTION; Breuer P., 1975, Problems of Control and Information Theory, V4, P339; CASASENT D, 1982, P SOC PHOTO-OPT INST, V360, P105; Duda R. O., 1972, COMMUN ACM, V15; DYER C, 1983, IEEE T PATTERN ANAL, V5; EDDY W, 1977, ACM T MATH SOFTWARE, V3, P399; Eddy W. F., 1977, ACM Transactions on Mathematical Software, V3, P411, DOI 10.1145/355759.355768; Herman G, 1980, IMAGE RECONSTRUCTION; HINKLE E, 1987, UNPUB J PARALLEL DIS; MA K, 1979, 7TH P NEW ENGL BIOEN, P177; MUNSON DC, 1984, P IEEE, V72, P661, DOI 10.1109/PROC.1984.12915; MUNSON DC, 1983, P IEEE, V71, P917, DOI 10.1109/PROC.1983.12698; PAVLIDIS T, 1978, 4TH P INT C PATT REC, P70; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; SANZ JLC, UNPUB COMMUN ACM; SANZ JLC, UNPUB PATTERN RECOGN; SANZ JLC, 1985, JUN CVPR 85 SAN FRAN; SANZ JLC, UNPUB IEEE T ACOUST; SKLANSKY J, 1970, PATTERN RECOGN, V2, P3, DOI 10.1016/0031-3203(70)90037-3; Sklansky J, 1982, PATTERN RECOGN LETT, V1, P79, DOI 10.1016/0167-8655(82)90016-2; TOUSSAINT G, 1983, PATTERN RECOGNIT MAY, P219; TOUSSAINT GT, 1980, 5TH P INT C PATT REC, P1324; UHR L, 1984, ALGORITHM STRUCTURED; VEILLON F, 1978, 4TH P INT C PATT REC, P672; VUYLSTEKE P, 1981, P SOC PHOTO-OPT INST, V301, P173; WANG YR, 1985, IEEE T COMPUT, V24; WONG RY, 1978, COMPUT GRAPHICS IMAG, V8; WU ZQ, 1983, PATTERN RECOGNITION, V16; YAMAMOTO K, 1978, 4TH P C PATT REC KYO, P794	32	14	14	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN	1987	9	1					160	168		10.1109/TPAMI.1987.4767883	http://dx.doi.org/10.1109/TPAMI.1987.4767883			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	F3785	21869388				2022-12-18	WOS:A1987F378500016
J	WAXMAN, AM; SINHA, SS				WAXMAN, AM; SINHA, SS			DYNAMIC STEREO - PASSIVE RANGING TO MOVING-OBJECTS FROM RELATIVE IMAGE FLOWS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MARYLAND,CTR AUTOMAT RES,COMP VIS LAB,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park								GRIMSON WEL, 1981, IMAGES SURFACES; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P122, DOI 10.1109/TPAMI.1983.4767365; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; MORAVEC H, 1981, ROBOT ROVER VISUAL N; NEVATIA R, 1976, COMPUTER VISION GRAP, V9, P203; NISHIHARA HK, 1984, MIT780 ART INT MEM; REGAN D, 1979, VISION RES, V19, P1331, DOI 10.1016/0042-6989(79)90205-0; SINHA S, 1984, 71 U MAR CTR AUT RES; TSAI RY, 1983, IEEE T PATTERN ANAL, V5, P159, DOI 10.1109/TPAMI.1983.4767368; WAXMAN AM, 1985, INT J ROBOT RES, V4, P72, DOI 10.1177/027836498500400306; WAXMAN AM, 1985, INT J ROBOT RES, V4, P95, DOI 10.1177/027836498500400307; WAXMAN AM, 1984, 45 U MAR CTR AUT RES; WAXMAN AM, 1986, UNPUB IEEE T PATTERN; WAXMAN AM, 1984, 58 U MAR CTR AUT RES; WAXMAN AM, 1985, 119 U MAR CTR AUT RE; WAXMAN AM, 1984, 2ND P IEEE WORKSH CO, P49; WILLIAMS TD, 1980, IEEE T PATTERN ANAL, V2, P511, DOI 10.1109/TPAMI.1980.6447697; WOHN K, 1985, 134 U MAR CTR AUT RE	20	14	16	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	1986	8	4					406	412		10.1109/TPAMI.1986.4767806	http://dx.doi.org/10.1109/TPAMI.1986.4767806			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	C7400					2022-12-18	WOS:A1986C740000001
J	DRAKE, KC; MCVEY, ES; INIGO, RM				DRAKE, KC; MCVEY, ES; INIGO, RM			SENSING ERROR FOR A MOBILE ROBOT USING LINE NAVIGATION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter											DRAKE, KC (corresponding author), UNIV VIRGINIA,SCH ENGN & APPL SCI,CHARLOTTESVILLE,VA 22901, USA.							ARIK Y, 1981, SYST COMPUT CONTR, V12, P37; ARIK Y, 1981, SYST COMPUT CONTR, V12, P28; COOKE RA, 1983, 13TH P INT S IND ROB, V2, P109; DANKER A, 1980, PATTERN RECOGN, V12, P97, DOI 10.1016/0031-3203(80)90008-4; DRAKE KC, 1984, THESIS U VIRGINIA CH; Duda R.O., 1973, J ROYAL STAT SOC SER; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; GENNERY DB, 1979, 6TH P INT JOINT C AR, P320; GIRALT G, 1979, 6TH P INT JOINT C AR, P335; Hopwood R. K., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V230, P72; INIGO RM, 1984, IEEE T PATTERN ANAL, V6, P820, DOI 10.1109/TPAMI.1984.4767606; JOHNSTON AR, 1979, IEEE T VEH TECHNOL, V28, P95, DOI 10.1109/T-VT.1979.23775; JULLIERE M, 1983, 13TH P INT S IND ROB, V2, P58; LARCOMMBE MHE, 1981, JUN P INT C AUT GUID, P137; MORAVEC HP, 1979, 6TH P INT JOINT C AR, P598; SCHMIDT RA, 1971, THESIS STANFORD U ST; WILLIAMS TD, 1980, IEEE T PATTERN ANAL, V2, P511, DOI 10.1109/TPAMI.1980.6447697	17	14	14	0	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1985	7	4					485	490		10.1109/TPAMI.1985.4767687	http://dx.doi.org/10.1109/TPAMI.1985.4767687			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	ALB69	21869286				2022-12-18	WOS:A1985ALB6900012
J	FUKUNAGA, K; FLICK, TE				FUKUNAGA, K; FLICK, TE			ESTIMATION OF THE PARAMETERS OF A GAUSSIAN MIXTURE USING THE METHOD OF MOMENTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											FUKUNAGA, K (corresponding author), PURDUE UNIV,SCH ELECT ENGN,W LAFAYETTE,IN 47907, USA.							AKESSON OA, 1916, ARK FOR MAT ASTR FYS, V11; CHARLIER CVL, 1923, ARK FOR MAT ASTR FYS, V18; COOPER DB, 1964, INFORM CONTROL, V7, P416, DOI 10.1016/S0019-9958(64)90502-9; DALY NE, 1962, 20033 STANF U TECH R; Duda R.O., 1973, J ROYAL STAT SOC SER; Everitt B., 1981, FINITE MIXTURE DISTR, P143; FRALICK SC, 1967, IEEE T INFORM THEORY, V13, P57, DOI 10.1109/TIT.1967.1053952; KATOPIS A, 1972, P MODELLING SIMULATI, P473; KAZAKOS D, 1980, IEEE T INFORM THEORY, V26, P113, DOI 10.1109/TIT.1980.1056124; KAZAKOS D, 1977, IEEE T INFORM THEORY, V23, P203, DOI 10.1109/TIT.1977.1055693; MAKOV UE, 1977, IEEE T INFORM THEORY, V23, P761, DOI 10.1109/TIT.1977.1055801; MIZOGUCHI R, 1975, IEEE T COMPUT, V24, P979, DOI 10.1109/T-C.1975.224104; PATRICK EA, 1966, IEEE T INFORM THEORY, V12, P362, DOI 10.1109/TIT.1966.1053901; PATRICK EA, 1970, IEEE T COMPUT, VC 19, P197, DOI 10.1109/T-C.1970.222897; Pearson K., 1894, Philosophical Transactions, V185a, P71, DOI 10.1098/rsta.1894.0003; POSTAIRE JG, 1981, IEEE T PATTERN ANAL, V3, P163, DOI 10.1109/TPAMI.1981.4767074; RAO CR, 1952, ADV STATISTICAL METH; REDNER RA, 1982, MAR P NASA WORKSH DE; YAKOWITZ SJ, 1970, IEEE T INFORM THEORY, V16, P330, DOI 10.1109/TIT.1970.1054442; YOUNG TY, 1970, IEEE T INFORM THEORY, V16, P258, DOI 10.1109/TIT.1970.1054454	20	14	15	0	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	4					410	416		10.1109/TPAMI.1983.4767410	http://dx.doi.org/10.1109/TPAMI.1983.4767410			7	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RA578	21869125				2022-12-18	WOS:A1983RA57800006
J	PERKINS, WA				PERKINS, WA			INSPECTOR - A COMPUTER VISION SYSTEM THAT LEARNS TO INSPECT PARTS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									GM CORP,RES LABS,DEPT COMP SCI,WARREN,MI 49090	General Motors								BARNARD ST, 1980, 1ST P ANN NAT C ART, P49; Bongard MM, 1970, PATTERN RECOGNITION; CHEN CH, 1973, STATISTICAL PATTERN; Duda R.O., 1973, J ROYAL STAT SOC SER; Eberlein R.B., 1976, COMPUT GRAPHICS IMAG, V5, P245, DOI [10.1016/0146-664X(76)90032-0, DOI 10.1016/0146-664X(76)90032-0]; Ejiri M., 1973, COMPUT VISION GRAPH, V2, P326, DOI 10.1016/0146-664X(73)90011-7; FU KS, 1976, DIGITAL PATTERN RECO; GLEASON GJ, 1979, 190 SRI INT AI CTR T; GOTO N, 1978, 4TH P INT JOINT C PA, P970; JARVIS JF, 1977, P IEEE CS C PATTERN, P153; LIN WC, 1975, P IEEE, V63, P1437, DOI 10.1109/PROC.1975.9972; Minsky M., 1969, PERCEPTRONS; MUNDY JL, 1977, P INT C PATT REC IM, P144; PERKINS WA, 1981, COMPUT VISION GRAPH, V17, P161, DOI 10.1016/0146-664X(81)90023-X; PERKINS WA, 1980, IEEE T PATTERN ANAL, V2, P8, DOI 10.1109/TPAMI.1980.4766965; PERKINS WA, 1978, IEEE T COMPUT, V27, P126, DOI 10.1109/TC.1978.1675046; Rosenblatt F., 1961, PRINCIPLES NEURODYNA, DOI 10.21236/AD0256582; Winston P. H., 1975, PSYCHOL COMPUTER VIS; [No title captured]	19	14	24	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	6					584	592		10.1109/TPAMI.1983.4767447	http://dx.doi.org/10.1109/TPAMI.1983.4767447			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	RV488	21869144				2022-12-18	WOS:A1983RV48800004
J	PRESTON, K				PRESTON, K			MULTIDIMENSIONAL LOGICAL TRANSFORMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV PITTSBURGH,DEPT RADIAT HLTH,PITTSBURGH,PA 15260	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh	PRESTON, K (corresponding author), CARNEGIE MELLON UNIV,DEPT ELECT ENGN,PITTSBURGH,PA 15213, USA.							ANDERBERG MR, 1973, CLUSTER ANAL APPLICA; [Anonymous], 1974, CLUSTER ANAL; Cole A.J., 1969, NUMERICAL TAXONOMY; DINEEN GP, 1955, P WJCC, P97; DUFF MJB, 1977, DIGITAL IMAGE PROCES, P101; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Fountain T. J., 1981, Languages and architectures for image processing, P283; GOLAY MJE, 1969, IEEE T COMPUT, VC 18, P733, DOI 10.1109/T-C.1969.222756; Graham M. D., 1980, Real-Time Medical Image Processing. Proceedings of the Japan-United States Seminar on Research Towards Real-Time Parallel Image Analysis and Recognition, P163; Hartigan J.A., 1975, CLUSTERING ALGORITHM; KEPPLER J, 1619, OMNIA OPERA, V5; LUCAS D, 1979, P AM MATH SOC, V74, P1; Moore E.F., 1970, MACHINE MODELS SELF; PRESTON K, 1983, COMPUTER, V16, P36, DOI 10.1109/MC.1983.1654164; PRESTON K, 1981, PATTERN RECOGN, V13, P17, DOI 10.1016/0031-3203(81)90029-7; PRESTON K, 1979, P IEEE, V67, P826, DOI 10.1109/PROC.1979.11331; PRESTON K, 1971, IEEE T COMPUT, VC 20, P1007, DOI 10.1109/T-C.1971.223396; PRESTON K, 1980, J COMBINATORICS INFO, V5, P281; PRESTON K, 1981, IEEE T PATTERN ANAL, V3, P47; SELFRIDGE O, 1955, P WJCC, P94; Smith A. R., 1969, 2 STANF U STANF EL L; Sneath PHA, 1973, NUMERICAL TAXONOMY P; STERNBERG SR, 1983, COMPUTER, V16, P22, DOI 10.1109/MC.1983.1654163; von Neumann J., 1948, HIX S	24	14	14	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	5					539	554		10.1109/TPAMI.1983.4767434	http://dx.doi.org/10.1109/TPAMI.1983.4767434			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	RM118	21869140				2022-12-18	WOS:A1983RM11800011
J	SHNEIER, M				SHNEIER, M			USING PYRAMIDS TO DEFINE LOCAL THRESHOLDS FOR BLOB DETECTION	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Letter									UNIV MARYLAND,CTR COMP SCI,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park								BURT PJ, 1981, IEEE T SYST MAN CYB, V11, P802, DOI 10.1109/TSMC.1981.4308619; Hanson A. R., 1978, COMPUTER VISION SYST, P129; KELLY MD, 1971, MACH INTELL, V6, P397; MCDONNELL MJ, 1981, COMPUT VISION GRAPH, V17, P65, DOI 10.1016/S0146-664X(81)80009-3; MILGRAM DL, 1979, COMPUT VISION GRAPH, V11, P1, DOI 10.1016/0146-664X(79)90073-X; MINOR LG, 1981, IEEE T SYST MAN CYBE, V11; SHNEIER M, 1982, IEEE T SYST MAN CYBE, V12; TANIMOTO SL, 1978, COMPUTER VISION SYST, P129; UHR L, 1978, COMPUTER VISION SYST, P363; WESZKA JS, 1978, COMPUT VISION GRAPH, V7, P259, DOI 10.1016/0146-664X(78)90116-8	10	14	15	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	3					345	349		10.1109/TPAMI.1983.4767397	http://dx.doi.org/10.1109/TPAMI.1983.4767397			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QS785	21869118				2022-12-18	WOS:A1983QS78500010
J	STOCKMAN, GC; KANAL, LN				STOCKMAN, GC; KANAL, LN			PROBLEM REDUCTION REPRESENTATION FOR THE LINGUISTIC ANALYSIS OF WAVEFORMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									UNIV MARYLAND,DEPT COMP SCI,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park	STOCKMAN, GC (corresponding author), MICHIGAN STATE UNIV,DEPT COMP SCI,E LANSING,MI 48824, USA.							CHANG LL, 1971, ARTIF INTELL, V2, P117; CHARTRES BA, 1968, J ACM, V15, P447, DOI 10.1145/321466.321476; COX JR, 1972, P IEEE, V60, P1137, DOI 10.1109/PROC.1972.8877; DUERR B, 1980, PATTERN RECOGN, V12, P189, DOI 10.1016/0031-3203(80)90043-6; Fu K.S., 1974, MATH SCI ENG; HALL PAV, 1973, COMMUN ACM, V16, P444, DOI 10.1145/362280.362302; KANAL LN, 1979, IEEE T PATTERN ANAL, V1, P193, DOI 10.1109/TPAMI.1979.4766905; KANAL LN, 1972, P IEEE, V60, P1200, DOI 10.1109/PROC.1972.8880; KANAL LN, 1981, 7TH P INT JOINT C AI, P569; KANAL LN, 1981, AUG P IEEE COMP SOC, P452; MILLER P, 1973, MIT TR503 LINC LAB R; Nilsson N.J., 1971, PROBLEM SOLVING METH; Pavlidis T., 1977, STRUCTURAL PATTERN R; STOCKMAN G, 1976, COMMUN ACM, V19, P688, DOI 10.1145/360373.360378; STOCKMAN GC, 1979, ARTIF INTELL, V12, P179, DOI 10.1016/0004-3702(79)90016-X; STOCKMAN GC, 1977, TR538 U MAR DEP COMP; VANDERBRUG GJ, 1975, COMMUN ACM, V18, P107, DOI 10.1145/360666.360672	17	14	14	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1983	5	3					287	298		10.1109/TPAMI.1983.4767391	http://dx.doi.org/10.1109/TPAMI.1983.4767391			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	QS785	21869112				2022-12-18	WOS:A1983QS78500004
J	LEVINE, B				LEVINE, B			THE USE OF TREE DERIVATIVES AND A SAMPLE SUPPORT PARAMETER FOR INFERRING TREE SYSTEMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article											LEVINE, B (corresponding author), OREGON STATE UNIV,DEPT COMP SCI,CORVALLIS,OR 97331, USA.							ARBIB MA, 1968, INFORM CONTROL, V12, P331, DOI 10.1016/S0019-9958(68)90374-4; BHARGAVA BK, 1973, IEEE T COMPUT, V22, P1087; BIERMANN AW, 1972, IEEE T COMPUT, VC 21, P592, DOI 10.1109/TC.1972.5009015; BOOTH TL, 1975, IEEE T SYST MAN CYB, V5, P409; BOOTH TL, 1975, IEEE T SYST MAN CYB, V5, P95; BRAINERD WS, 1969, INFORM CONTROL, V14, P217, DOI 10.1016/S0019-9958(69)90065-5; BRAINERD WS, 1968, INFORM CONTROL, V13, P484, DOI 10.1016/S0019-9958(68)90917-0; BRAYER JM, 1977, IEEE T SYST MAN CYB, V7, P293; BRZOZOWSKI JA, 1964, J ACM, V11, P481, DOI 10.1145/321239.321249; CRESPIREGHIZZI S, 1973, COMMUN ASS COMPUT MA, V16; Doner J., 1970, J COMPUT SYST SCI, V4, P406, DOI [10.1016/S0022-0000(70)80041-1, DOI 10.1016/S0022-0000(70)80041-1]; EDWARDS JJ, 1976, INT J COMPUT INFORM, V5; EVANS TG, 1971, SOFTWARE ENG, V2; FU KS, 1976, IEEE T COMPUT, V25, P262; Hopcroft J.E., 1969, FORMAL LANGUAGES THE; JOSHI AK, 1978, INFORM CONTR, V39, P192; LEVINE B, 1981, IEEE T PATTERN ANAL, V3, P285, DOI 10.1109/TPAMI.1981.4767101; LEVINE BA, 1979, THESIS OREGON STATE; WILLIAMS KL, 1975, PATTERN RECOGN, V7, P125, DOI 10.1016/0031-3203(75)90023-0	19	14	14	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1982	4	1					25	34		10.1109/TPAMI.1982.4767191	http://dx.doi.org/10.1109/TPAMI.1982.4767191			10	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MY534	21868999				2022-12-18	WOS:A1982MY53400005
J	YOKOI, S; TORIWAKI, JI; FUKUMURA, T				YOKOI, S; TORIWAKI, JI; FUKUMURA, T			ON GENERALIZED DISTANCE TRANSFORMATION OF DIGITIZED PICTURES	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									NAGOYA UNIV,FAC ENGN,DEPT ELECT ENGN,NAGOYA,AICHI 464,JAPAN; NAGOYA UNIV,FAC ENGN,DEPT INFORMAT SCI,NAGOYA,AICHI 464,JAPAN	Nagoya University; Nagoya University	YOKOI, S (corresponding author), MIE UNIV,FAC ENGN,DEPT ELECTR ENGN,TSU,MIE 514,JAPAN.							BAN T, 1979, IECE PRL7877 PAP TEC; Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154; CALABI L, 1968, AM MATH MON, V75, P335, DOI 10.2307/2313409; Galloway MM., 1975, COMPUT GRAPHICS IMAG, V4, DOI DOI 10.1016/S0146-664X(75)80008-6; LANTUEJOUL C, 1978, THESIS EC NAT SUP MI; LEVI G, 1972, INFORM CONTR, V17, P62; MONTANARI U, 1968, J ACM, V15, P600, DOI 10.1145/321479.321486; MOORE DJH, 1974, IEEE T SYST MAN CYB, VSMC4, P396, DOI 10.1109/TSMC.1974.5408464; MOTTSMITH C, 1970, PICTURE PROCESSING P, P267; PHILBRICK O, 1968, PICTORIAL PATTERN RE, P395; PRESTON K, 1979, P IEEE, V67, P826, DOI 10.1109/PROC.1979.11331; ROSENFEL.A, 1966, J ACM, V13, P471; ROSENFELD A, 1970, J ACM, V17, P146, DOI 10.1145/321556.321570; ROSENFELD A, 1968, PATTERN RECOGN, V1, P33, DOI 10.1016/0031-3203(68)90013-7; ROSENFELD A, 1969, PICTURE PROCESSING C; Rutovitz D, 1968, PICTORIAL PATTERN RE, P105; TORIWAKI J, 1979, IEEE T SYST MAN CYB, V9, P628, DOI 10.1109/TSMC.1979.4310092; TORIWAKI J, 1977, T IEICE JAPAN D, V60, P1101; TORIWAKI J, 1978, 4TH P IJCPR, P649; Toriwaki J.-I., 1978, 3rd USA-Japan Computer Conference Proceedings, P104; TORIWAKI JI, 1978, COMPUT VISION GRAPH, V7, P30, DOI 10.1016/S0146-664X(78)80012-4; Yokoi S., 1976, 3rd International Joint Conference on Pattern Recognition, P723; Yokoi S., 1975, COMPUT GRAPHICS IMAG, V4, P63, DOI DOI 10.1016/0146-664X(75)90022-2; YOKOI S, P US JAPAN SEMINAR R; YOKOI S, 1977, T IECE             D, V60, P411; YOKOI S, 1978, T IECE D, V61, P613; YOKOI S, 1973, MAR P ANN M I EL COM, P1155	27	14	15	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1981	3	4					424	443		10.1109/TPAMI.1981.4767128	http://dx.doi.org/10.1109/TPAMI.1981.4767128			20	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MQ357	21868963				2022-12-18	WOS:A1981MQ35700007
J	DEMORI, R; LAFACE, P				DEMORI, R; LAFACE, P			USE OF FUZZY ALGORITHMS FOR PHONETIC AND PHONEMIC LABELING OF CONTINUOUS SPEECH	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									POLITECN TORINO,IST ELETTROTECN,CENS,IENGF,TORINO,ITALY	Istituto Nazionale di Ricerca Metrologica (INRIM); Polytechnic University of Turin	DEMORI, R (corresponding author), UNIV TURIN,IST SCI INFORMAZIONE,I-10126 TURIN,ITALY.							Coppo M., 1976, Proceedings of the IEEE International Conference on Cybernetics and Society, P520; DEMORI R, 1979, IEEE T ACOUST SPEECH, V27, P538, DOI 10.1109/TASSP.1979.1163281; DEMORI R, 1976, IEEE T ACOUST SPEECH, V24, P365, DOI 10.1109/TASSP.1976.1162841; DEMORI R, 1973, IEEE T ACOUST SPEECH, VAU21, P89, DOI 10.1109/TAU.1973.1162442; DEMORI R, 1975, IEEE T COMPUT, V24, P1202, DOI 10.1109/T-C.1975.224164; DEMORI R, 1978, JUL P AISBGI C ART I, P201; DEMORI R, 1977, P IEEE C ACOUST SPEE, P644; DEMORI R, 1974, INFORMATION PROCESSI, P753; DEMORI R, 1977, SYNTACTIC PATTERN RE; DEMORI R, 1978, 4TH P INT JOINT C PA; DEMORI R, 1975, 4TH P INT JOINT C AR, P468; DEMORI R, UNPUBLISHED; Fu K.S., 1974, MATH SCI ENG; HUGHES GW, 1965, AFCRL65681 PURD U RE; JELINEK F, 1976, P IEEE, V64, P532, DOI 10.1109/PROC.1976.10159; KLATT DH, 1977, J ACOUST SOC AM, V62, P1345, DOI 10.1121/1.381666; LAFACE P, 1978, 4TH P INT JOINT C PA; LIBERMAN AM, 1970, COGNITIVE PSYCHOL, V1, P301, DOI 10.1016/0010-0285(70)90018-6; MARTIN TB, 1976, P IEEE, V64, P487, DOI 10.1109/PROC.1976.10157; MERMELSTEIN P, 1975, IEEE T ACOUST SPEECH, VAS23, P79, DOI 10.1109/TASSP.1975.1162633; MORI RD, 1976, P IEEE ASSP C PHILAD, P565; OHMAN SEG, 1966, J ACOUST SOC AM, V39, P151, DOI 10.1121/1.1909864; PAL SK, 1977, IEEE T SYST MAN CYB, V7, P625; RAJREDDY D, 1976, P IEEE, V64, P501; RAJREDDY D, 1975, SPEECH RECOGNITION I; RAJREDDY D, 1977, SPEECH UNDERSTANDING; STEVENS KN, 1973, MITRLE110 Q PROGR RE, P155; STUDDERTKENNEDY M, 1974, SR3940 HASK LAB STAT, P1; WALKER DE, 1977, SRI SPEECH UNDERSTAN; WEINSTEIN CJ, 1975, IEEE T ACOUST SPEECH, VAS23, P54, DOI 10.1109/TASSP.1975.1162651; WOLF JJ, 1976, DIGITAL PATTERN RECO; WOODS WA, 1976, 3438 BOLT BER NEWM I; Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, P3, DOI 10.1016/0165-0114(78)90029-5; ZADEH LA, 1975, INFORM SCIENCES, V8, P301, DOI 10.1016/0020-0255(75)90046-8; ZADEH LA, 1975, INFORM SCIENCES, V9, P43, DOI 10.1016/0020-0255(75)90017-1; ZADEH LA, 1976, INT J MAN MACH STUD, V8, P249, DOI 10.1016/S0020-7373(76)80001-6; ZADEH LA, 1971, INFORM SCIENCES, V3, P177, DOI 10.1016/S0020-0255(71)80005-1; ZADEH LA, 1972, P INT C MAN COMPUTER, P130	38	14	17	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	2					136	148		10.1109/TPAMI.1980.4766991	http://dx.doi.org/10.1109/TPAMI.1980.4766991			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	JH803	21868884				2022-12-18	WOS:A1980JH80300005
J	FORNASINI, E; MARCHESINI, G				FORNASINI, E; MARCHESINI, G			PROBLEMS OF CONSTRUCTING MINIMAL REALIZATIONS FOR TWO-DIMENSIONAL FILTERS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Note											FORNASINI, E (corresponding author), UNIV PADUA,DEPT ELECT ENGN,I-35100 PADUA,ITALY.							FLIESS M, 1974, J MATH PURE APPL, V53, P197; FLIESS M, 1970, B SCI MATH, V94, P231; FORNASINI E, 1978, IEEE T CIRCUITS SYST, V25, P290, DOI 10.1109/TCS.1978.1084475; Fornasini E., 1976, 3rd International Joint Conference on Pattern Recognition, P716; FORNASINI E, 1975, 5TH P ICEE; FORNASINI E, 1976, IEEE T AUTOMAT CONTR, V21; FORNASINI E, 1974, MAY P VAR STRUCT SYS; Ho B.L., 1965, 3RD P ANN ALL C CIRC, P449; SONTAG ED, 1978, IEEE T ACOUST SPEECH, V26, P480, DOI 10.1109/TASSP.1978.1163124; TETHER AJ, 1970, IEEE T AUTOMAT CONTR, VAC15, P427, DOI 10.1109/TAC.1970.1099514	10	14	14	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1980	2	2					172	176		10.1109/TPAMI.1980.4766996	http://dx.doi.org/10.1109/TPAMI.1980.4766996			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JH803	21868889				2022-12-18	WOS:A1980JH80300010
J	FINDLER, NV; VANLEEUWEN, J				FINDLER, NV; VANLEEUWEN, J			FAMILY OF SIMILARITY MEASURES BETWEEN 2 STRINGS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									STATE UNIV UTRECHT,DEPT COMP SCI,UTRECHT,NETHERLANDS	Utrecht University	FINDLER, NV (corresponding author), SUNY BUFFALO,DEPT COMP SCI,AMHERST,NY 14226, USA.							Findler N. V., 1972, Information Processing Letters, V1, P191, DOI 10.1016/0020-0190(72)90037-3; FINDLER NV, 1977, COMMUN ACM, V20, P230, DOI 10.1145/359461.363617; FINDLER NV, ASS NETWORKS REPRESE; KESSLER MJ, 1975, P ASS COMPUT MACH CO; MOODY JD, COMMUNICATION	5	14	16	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	1					116	118		10.1109/TPAMI.1979.4766885	http://dx.doi.org/10.1109/TPAMI.1979.4766885			3	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HA303	21868840				2022-12-18	WOS:A1979HA30300016
J	YEMINI, Y; PEARL, J				YEMINI, Y; PEARL, J			ASYMPTOTIC PROPERTIES OF DISCRETE UNITARY TRANSFORMS	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article									INFORMAT SCI INST,MARINA DEL REY,CA		YEMINI, Y (corresponding author), UNIV CALIF LOS ANGELES,SCH ENGN & APPL SCI,LOS ANGELES,CA 90024, USA.							AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784; ANDREWS HC, 1969, APR P POLYT I BROOKL, P63; CAMPANELLA SJ, 1970, MAR P S APPL WALSH F, P230; GRENANDER V, 1958, TOEPLITZ FORMS THEIR; HABIBI A, 1971, IEEE T COMMUN TECHN, VCO19, P50, DOI 10.1109/TCOM.1971.1090601; HAMIDI M, 1975, IEEE T INFORM THEORY, V21, P480, DOI 10.1109/TIT.1975.1055403; HAMIDI M, 1976, IEEE T ACOUST SPEECH, V24, P428, DOI 10.1109/TASSP.1976.1162839; JAIN AK, 1976, IEEE T COMMUN, V24, P1025; Krylov V.I., 2006, APPROXIMATE CALCULAT; MEANS RW, 1974, DEC P IEEE NAT TEL C; PEARL J, 1971, IEEE T INFORM THEORY, V17, P751, DOI 10.1109/TIT.1971.1054703; PEARL J, 1975, IEEE T ACOUST SPEECH, V23, P547, DOI 10.1109/TASSP.1975.1162736; PEARL J, 1973, IEEE T INFORM THEORY, V19, P229, DOI 10.1109/TIT.1973.1054985; Szego, 1959, ORTHOGONAL POLYNOMIA	14	14	14	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314	0162-8828			IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.		1979	1	4					366	371		10.1109/TPAMI.1979.4766945	http://dx.doi.org/10.1109/TPAMI.1979.4766945			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	HV227	21868871				2022-12-18	WOS:A1979HV22700005
J	Wu, YH; Liu, Y; Xu, J; Bian, JW; Gu, YC; Cheng, MM				Wu, Yu-Huan; Liu, Yun; Xu, Jun; Bian, Jia-Wang; Gu, Yu-Chao; Cheng, Ming-Ming			MobileSal: Extremely Efficient RGB-D Salient Object Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						RGB-D salient object detection; efficiency; implicit depth restoration	REGION DETECTION; NETWORK	The high computational cost of neural networks has prevented recent successes in RGB-D salient object detection (SOD) from benefiting real-world applications. Hence, this article introduces a novel network, MobileSal, which focuses on efficient RGB-D SOD using mobile networks for deep feature extraction. However, mobile networks are less powerful in feature representation than cumbersome networks. To this end, we observe that the depth information of color images can strengthen the feature representation related to SOD if leveraged properly. Therefore, we propose an implicit depth restoration (IDR) technique to strengthen the mobile networks' feature representation capability for RGB-D SOD. IDR is only adopted in the training phase and is omitted during testing, so it is computationally free. Besides, we propose compact pyramid refinement (CPR) for efficient multi-level feature aggregation to derive salient objects with clear boundaries. With IDR and CPR incorporated, MobileSal performs favorably against state-of-the-art methods on six challenging RGB-D SOD datasets with much faster speed (450fps for the input size of 320 x 320) and fewer parameters (6.5M). The code is released at https://mmcheng.net/mobilesal.	[Wu, Yu-Huan; Liu, Yun; Xu, Jun; Gu, Yu-Chao; Cheng, Ming-Ming] Nankai Univ, Coll Comp Sci, TKLNDST, Tianjin 300350, Peoples R China; [Bian, Jia-Wang] Univ Adelaide, Adelaide, SA 5005, Australia	Nankai University; University of Adelaide	Cheng, MM (corresponding author), Nankai Univ, Coll Comp Sci, TKLNDST, Tianjin 300350, Peoples R China.	wuyuhuan@mail.nankai.edu.cn; yun.liu@vision.ee.ethz.ch; nankaimathjunxu@gmail.com; jiawang.bian@gmail.com; ycgu@mail.nankai.edu.cn; cmm@nankai.edu.cn	; Cheng, Ming-Ming/A-2527-2009	Liu, Yun/0000-0001-6143-0264; Bian, Jiawang/0000-0003-2046-3363; Cheng, Ming-Ming/0000-0001-5550-8758; Wu, Yu-Huan/0000-0001-8666-3435	National Key Research and Development Program of China [2018AAA0100400]; NSFC [61922046]	National Key Research and Development Program of China; NSFC(National Natural Science Foundation of China (NSFC))	This work was supported in part by the National Key Research and Development Program of China under Grant 2018AAA0100400, and in part by NSFC under Grant 61922046.	Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Andrew G. Howard, 2017, Arxiv, DOI arXiv:1704.04861; Borji A, 2019, COMPUT VIS MEDIA, V5, P117, DOI 10.1007/s41095-019-0149-9; Chen H, 2018, PROC CVPR IEEE, P3051, DOI 10.1109/CVPR.2018.00322; Chen H, 2019, IEEE T IMAGE PROCESS, V28, P2825, DOI 10.1109/TIP.2019.2891104; Chen LZ, 2021, IEEE T IMAGE PROCESS, V30, P2313, DOI 10.1109/TIP.2021.3049332; Chen Q, 2021, AAAI CONF ARTIF INTE, V35, P1063; Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Cheng Y., 2014, P INT C INTERNET MUL, P23; Cheng-Feng Sun, 2020, Learning and Collaboration Technologies. Human and Technology Ecosystems. 7th International Conference, LCT 2020. Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12206), P520, DOI 10.1007/978-3-030-50506-6_35; Chongyi Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P225, DOI 10.1007/978-3-030-58598-3_14; Ciptadi A, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.112; Cong RM, 2016, IEEE SIGNAL PROC LET, V23, DOI 10.1109/LSP.2016.2557347; Desingh K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.98; Fan D.-P., 2021, SCI SINICA INFORM, V6, DOI [10.1360/SSI-2020-0370, DOI 10.1360/SSI-2020-0370]; Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487; Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406; Fan XX, 2014, INT CONF DIGIT SIG, P454, DOI 10.1109/ICDSP.2014.6900706; Fu KR, 2022, IEEE T PATTERN ANAL, V44, P5541, DOI 10.1109/TPAMI.2021.3073689; Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hong S, 2015, PR MACH LEARN RES, V37, P597; Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688; Hu SM, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-020-3097-4; Huang NAC, 2022, IEEE T MULTIMEDIA, V24, P1651, DOI 10.1109/TMM.2021.3069297; Ji W, 2021, PROC CVPR IEEE, P9466, DOI 10.1109/CVPR46437.2021.00935; Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222; Kingma D.P, 2015, P INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1412.6980; Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8; Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370; Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404; Liu Y, 2022, IEEE T PATTERN ANAL, V44, P3688, DOI 10.1109/TPAMI.2021.3053577; Liu Y, 2021, IEEE T IMAGE PROCESS, V30, P3804, DOI 10.1109/TIP.2021.3065239; Liu Y, 2022, IEEE T PATTERN ANAL, V44, P1415, DOI 10.1109/TPAMI.2020.3023152; Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8; Mehta S, 2019, PROC CVPR IEEE, P9182, DOI 10.1109/CVPR.2019.00941; Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79; Mingxing Tan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10778, DOI 10.1109/CVPR42600.2020.01079; Nair V, 2010, P 27 INT C MACHINE L, P807; Nian Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13753, DOI 10.1109/CVPR42600.2020.01377; Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708; Paszke A, 2019, ADV NEUR IN, V32; Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7; Piao YR, 2019, IEEE I CONF COMP VIS, P7253, DOI 10.1109/ICCV.2019.00735; Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Simonyan K., 2015, VERY DEEP CONVOLUTIO; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Tan MX, 2019, PROC CVPR IEEE, P2815, DOI 10.1109/CVPR.2019.00293; Wang JD, 2017, INT J COMPUT VISION, V123, P251, DOI 10.1007/s11263-016-0977-3; Wang NN, 2019, IEEE ACCESS, V7, P55277, DOI 10.1109/ACCESS.2019.2913107; Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3239, DOI 10.1109/TPAMI.2021.3051099; Wang WG, 2019, IEEE T PATTERN ANAL, V41, P1531, DOI 10.1109/TPAMI.2018.2840724; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wu RM, 2019, PROC CVPR IEEE, P8142, DOI 10.1109/CVPR.2019.00834; Wu YH, 2021, IEEE T IMAGE PROCESS, V30, P3897, DOI 10.1109/TIP.2021.3065822; Wu YH, 2021, IEEE T IMAGE PROCESS, V30, P3113, DOI 10.1109/TIP.2021.3058783; Xiaokang Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P561, DOI 10.1007/978-3-030-58621-8_33; Zhao XQ, 2021, Arxiv, DOI arXiv:2101.12482; Xiaoqi Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P646, DOI 10.1007/978-3-030-58542-6_39; Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407; Youwei Pang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P235, DOI 10.1007/978-3-030-58595-2_15; Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943; Wu YH, 2020, Arxiv, DOI arXiv:2012.13093; Zhang J, 2022, IEEE T PATTERN ANAL, V44, P5761, DOI 10.1109/TPAMI.2021.3073564; Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31; Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716; Zhang Z, 2021, IEEE T IMAGE PROCESS, V30, P1949, DOI 10.1109/TIP.2021.3049959; Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405; Zhao X., 2020, ECCV, P35, DOI [DOI 10.1007/978-3-030-58536-5_3, 10.1007/978-3-030-58536-5_3]; Zhou T, 2021, COMPUT VIS MEDIA, V7, P37, DOI 10.1007/s41095-020-0199-z; Zhu CB, 2017, IEEE INT CONF COMP V, P3008, DOI 10.1109/ICCVW.2017.355	79	13	14	15	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2022	44	12					10261	10269		10.1109/TPAMI.2021.3134684	http://dx.doi.org/10.1109/TPAMI.2021.3134684			9	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	6A4XX	34898430	Green Submitted			2022-12-18	WOS:000880661400121
J	Hu, QY; Yang, B; Xie, LH; Rosa, S; Guo, YL; Wang, ZH; Trigoni, N; Markham, A				Hu, Qingyong; Yang, Bo; Xie, Linhai; Rosa, Stefano; Guo, Yulan; Wang, Zhihua; Trigoni, Niki; Markham, Andrew			Learning Semantic Segmentation of Large-Scale Point Clouds With Random Sampling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Semantics; Memory management; Task analysis; Sampling methods; Space exploration; Feature extraction; Large-scale point clouds; semantic segmentation; random sampling; local feature aggregation	NETWORKS; NET	We study the problem of efficient semantic segmentation of large-scale 3D point clouds. By relying on expensive sampling techniques or computationally heavy pre/post-processing steps, most existing approaches are only able to be trained and operate over small-scale point clouds. In this paper, we introduce RandLA-Net, an efficient and lightweight neural architecture to directly infer per-point semantics for large-scale point clouds. The key to our approach is to use random point sampling instead of more complex point selection approaches. Although remarkably computation and memory efficient, random sampling can discard key features by chance. To overcome this, we introduce a novel local feature aggregation module to progressively increase the receptive field for each 3D point, thereby effectively preserving geometric details. Comparative experiments show that our RandLA-Net can process 1 million points in a single pass up to 200x faster than existing approaches. Moreover, extensive experiments on five large-scale point cloud datasets, including Semantic3D, SemanticKITTI, Toronto3D, NPM3D and S3DIS, demonstrate the state-of-the-art semantic segmentation performance of our RandLA-Net.	[Hu, Qingyong; Xie, Linhai; Rosa, Stefano; Wang, Zhihua; Trigoni, Niki; Markham, Andrew] Univ Oxford, Dept Comp Sci, Oxford OX1 2JD, England; [Yang, Bo] Hong Kong Polytech Univ, Dept Comp, Hung Hom, Hong Kong, Peoples R China; [Guo, Yulan] Sun Yat Sen Univ, Sch Elect & Commun Engn, Guangzhou 510275, Guangdong, Peoples R China; [Guo, Yulan] Natl Univ Def Technol, Coll Elect Sci & Technol, Zunyi 563003, Guizhou, Peoples R China	University of Oxford; Hong Kong Polytechnic University; Sun Yat Sen University; National University of Defense Technology - China	Yang, B (corresponding author), Hong Kong Polytech Univ, Dept Comp, Hung Hom, Hong Kong, Peoples R China.	qingyong.hu@cs.ox.ac.uk; bo.yang@polyu.edu.hk; linhai.xie@cs.ox.ac.uk; stefano.rosa@cs.ox.ac.uk; yulan.guo@nudt.edu.cn; zhihua.wang@cs.ox.ac.uk; Niki.Trigoni@cs.ox.ac.uk; andrew.markham@cs.ox.ac.uk		YANG, Bo/0000-0002-2419-4140; ROSA, STEFANO/0000-0001-6458-6344	Amazon Web Services in the Oxford-Singapore Human-Machine Collaboration Programme; China Scholarship Council (CSC) Scholarship; Natural Science Foundation of Guangdong Province [2019A1515011271]; Science and Technology Innovation Committee of Shenzhen Municipality [RCYX20200714114641140, JCYJ20190807152209394]; NationalNatural Science Foundation of China [U20A20185, 61972435]	Amazon Web Services in the Oxford-Singapore Human-Machine Collaboration Programme; China Scholarship Council (CSC) Scholarship(China Scholarship Council); Natural Science Foundation of Guangdong Province(National Natural Science Foundation of Guangdong Province); Science and Technology Innovation Committee of Shenzhen Municipality; NationalNatural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by Amazon Web Services in the Oxford-Singapore Human-Machine Collaboration Programme. The work of Qingyong Hu was supported by the China Scholarship Council (CSC) Scholarship. The work of Yulan Guowas supported in part by the NationalNatural Science Foundation of China under Grants U20A20185 and 61972435, in part by theNatural Science Foundation of Guangdong Province under Grant 2019A1515011271, and in part by the Science and Technology Innovation Committee of Shenzhen Municipality under Grants RCYX20200714114641140 and JCYJ20190807152209394.	Abid A, 2019, PR MACH LEARN RES, V97; Alexandre Boulch, 2020, Arxiv, DOI arXiv:1904.02375; Armeni I., 2017, ARXIV; Behley J, 2019, IEEE I CONF COMP VIS, P9296, DOI 10.1109/ICCV.2019.00939; Hua BS, 2018, PROC CVPR IEEE, P984, DOI 10.1109/CVPR.2018.00109; Boulch A., 2017, P EUR WORKSH 3D OBJ, P17; Boulch A., 2017, 3DOR, V2, P7, DOI [10.2312/3dor.20171047, DOI 10.2312/3DOR.20171047]; Boulogeorgos AAA, 2020, UEEE INT SYM PERS IN; Bridson R., 2007, ACM SIGGRAPH 2007 SK, DOI [10.1145/1278780.1278807, DOI 10.1145/1278780.1278807]; Chen C, 2019, PROC CVPR IEEE, P4989, DOI 10.1109/CVPR.2019.00513; Chen SH, 2019, IEEE IMAGE PROC, P4395, DOI 10.1109/ICIP.2019.8803525; Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691; Chen YL, 2019, IEEE I CONF COMP VIS, P9774, DOI 10.1109/ICCV.2019.00987; Chenfeng Xu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P1, DOI 10.1007/978-3-030-58604-1_1; Choy C, 2019, PROC CVPR IEEE, P3070, DOI 10.1109/CVPR.2019.00319; Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186; Contreras J, 2019, INT GEOSCI REMOTE SE, P5236, DOI 10.1109/IGARSS.2019.8899303; Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261; Deng-Ping Fan, 2019, Arxiv, DOI arXiv:1905.05442; Dovrat O, 2019, PROC CVPR IEEE, P2755, DOI 10.1109/CVPR.2019.00287; Engelmann F., 2019, P BRIT MACH VIS C; Eren Erdal Aksoy, 2020, Arxiv, DOI arXiv:2003.03653; Graham B, 2018, PROC CVPR IEEE, P9224, DOI 10.1109/CVPR.2018.00961; Groh F, 2019, LECT NOTES COMPUT SC, V11361, P105, DOI 10.1007/978-3-030-20887-5_7; Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434; Hackel T., 2017, ISPRS ANN PHOTOGRAMM, DOI [10.5194/isprs-annals-iv-1-w1-91-2017, DOI 10.5194/ISPRS-ANNALS-IV-1-W1-91-2017]; Hackel T, 2016, ISPRS ANN PHOTO REM, V3, P177, DOI 10.5194/isprsannals-III-3-177-2016; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hermosilla P, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275110; Huan Lei, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11608, DOI 10.1109/CVPR42600.2020.01163; Huang QG, 2018, PROC CVPR IEEE, P2626, DOI 10.1109/CVPR.2018.00278; Jiang L, 2019, IEEE I CONF COMP VIS, P10432, DOI 10.1109/ICCV.2019.01053; Kelvin Wong, 2019, Arxiv, DOI arXiv:1907.13079; Kingma D.P, 2015, P INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1412.6980; Komarichev A, 2019, PROC CVPR IEEE, P7413, DOI 10.1109/CVPR.2019.00760; Lan SY, 2019, PROC CVPR IEEE, P998, DOI 10.1109/CVPR.2019.00109; Landrieu L, 2018, PROC CVPR IEEE, P4558, DOI 10.1109/CVPR.2018.00479; Landrieu L, 2017, ISPRS J PHOTOGRAMM, V132, P102, DOI 10.1016/j.isprsjprs.2017.08.010; Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298; Le T, 2018, PROC CVPR IEEE, P9204, DOI 10.1109/CVPR.2018.00959; Lei H, 2021, IEEE T PATTERN ANAL, V43, P3664, DOI 10.1109/TPAMI.2020.2983410; Lei H, 2019, PROC CVPR IEEE, P9623, DOI 10.1109/CVPR.2019.00986; Li B, 2016, ROBOTICS: SCIENCE AND SYSTEMS XII; Li GH, 2019, IEEE I CONF COMP VIS, P9266, DOI 10.1109/ICCV.2019.00936; Li JX, 2018, PROC CVPR IEEE, P9397, DOI 10.1109/CVPR.2018.00979; Li YY, 2018, ADV NEUR IN, V31; Li Y, 2020, IEEE T GEOSCI REMOTE, V58, P3588, DOI 10.1109/TGRS.2019.2958517; Liang ZD, 2019, IEEE INT CONF ROBOT, P8152, DOI 10.1109/ICRA.2019.8794052; Liu JX, 2019, IEEE I CONF COMP VIS, P7545, DOI 10.1109/ICCV.2019.00764; Liu XY, 2019, IEEE I CONF COMP VIS, P9245, DOI 10.1109/ICCV.2019.00934; Liu YC, 2019, PROC CVPR IEEE, P8887, DOI 10.1109/CVPR.2019.00910; Liu ZJ, 2019, ADV NEUR IN, V32; Luo HF, 2020, IEEE T GEOSCI REMOTE, V58, P8301, DOI 10.1109/TGRS.2020.2985695; Ma LF, 2021, IEEE T INTELL TRANSP, V22, P821, DOI 10.1109/TITS.2019.2961060; Ma YN, 2020, IEEE WINT CONF APPL, P2920, DOI 10.1109/WACV45572.2020.9093411; Mao JG, 2019, IEEE I CONF COMP VIS, P1578, DOI 10.1109/ICCV.2019.00166; Meng HY, 2019, IEEE I CONF COMP VIS, P8499, DOI 10.1109/ICCV.2019.00859; Milioto A, 2019, IEEE INT C INT ROBOT, P4213, DOI 10.1109/IROS40897.2019.8967762; Mnih A, 2014, PR MACH LEARN RES, V32, P1791; Montoya-Zegarra JA, 2014, LECT NOTES COMPUT SC, V8753, P212, DOI 10.1007/978-3-319-11752-2_17; Paigwar A, 2019, IEEE COMPUT SOC CONF, P1297, DOI 10.1109/CVPRW.2019.00169; Qi CR, 2017, ADV NEUR IN, V30; Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16; Hu QY, 2021, Arxiv, DOI arXiv:2009.03137; Qingyong Hu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11105, DOI 10.1109/CVPR42600.2020.01112; Rethage D, 2018, LECT NOTES COMPUT SC, V11208, P625, DOI 10.1007/978-3-030-01225-0_37; Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701; Rosu R. A., 2019, ARXIV; Roynard X., 2018, PROC PLAN PERCEPTION; Roynard X., 2018, ARXIV; Roynard X, 2018, INT J ROBOT RES, V37, P545, DOI 10.1177/0278364918767506; Rusu RB, 2009, IEEE INT CONF ROBOT, P1848; Shen YR, 2018, PROC CVPR IEEE, P4548, DOI 10.1109/CVPR.2018.00478; Simonovsky M, 2017, PROC CVPR IEEE, P29, DOI 10.1109/CVPR.2017.11; Su H, 2018, PROC CVPR IEEE, P2530, DOI 10.1109/CVPR.2018.00268; Sutton RS, 2000, ADV NEUR IN, V12, P1057; Tan WK, 2020, IEEE COMPUT SOC CONF, P797, DOI 10.1109/CVPRW50498.2020.00109; Tatarchenko M, 2018, PROC CVPR IEEE, P3887, DOI 10.1109/CVPR.2018.00409; Tchapmi LP, 2017, INT CONF 3D VISION, P537, DOI 10.1109/3DV.2017.00067; Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651; Thomas H, 2018, INT CONF 3D VISION, P390, DOI 10.1109/3DV.2018.00052; Truong G, 2019, 2019 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P200; Ummenhofer Benjamin, 2019, INT C LEARN REPR; Varney N, 2020, IEEE COMPUT SOC CONF, P717, DOI 10.1109/CVPRW50498.2020.00101; Wang C, 2018, LECT NOTES COMPUT SC, V11208, P56, DOI 10.1007/978-3-030-01225-0_4; Wang L, 2019, PROC CVPR IEEE, P10288, DOI 10.1109/CVPR.2019.01054; Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274; Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362; Wu BC, 2019, IEEE INT CONF ROBOT, P4376, DOI 10.1109/ICRA.2019.8793495; Wu BC, 2018, IEEE INT CONF ROBOT, P1887; Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985; Xie SN, 2018, PROC CVPR IEEE, P4606, DOI 10.1109/CVPR.2018.00484; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Xu QG, 2020, PROC CVPR IEEE, P5660, DOI 10.1109/CVPR42600.2020.00570; Yan X, 2020, PROC CVPR IEEE, P5588, DOI 10.1109/CVPR42600.2020.00563; Yang B, 2018, PROC CVPR IEEE, P7652, DOI 10.1109/CVPR.2018.00798; Yang B, 2019, ADV NEUR IN, V32; Yang B, 2020, INT J COMPUT VISION, V128, P53, DOI 10.1007/s11263-019-01217-w; Yang JC, 2019, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2019.00344; Yang Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9598, DOI 10.1109/CVPR42600.2020.00962; Ye XQ, 2018, LECT NOTES COMPUT SC, V11211, P415, DOI 10.1007/978-3-030-01234-2_25; Zhang WX, 2019, PROC CVPR IEEE, P12428, DOI 10.1109/CVPR.2019.01272; Zhang ZY, 2019, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2019.00169; Zhao HS, 2019, PROC CVPR IEEE, P5550, DOI 10.1109/CVPR.2019.00571	104	13	13	38	61	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2022	44	11					8338	8354		10.1109/TPAMI.2021.3083288	http://dx.doi.org/10.1109/TPAMI.2021.3083288			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	5C5UY	34033533	Green Submitted			2022-12-18	WOS:000864325900075
J	Xie, JY; Ma, ZY; Chang, DL; Zhang, GQ; Guo, J				Xie, Jiyang; Ma, Zhanyu; Chang, Dongliang; Zhang, Guoqiang; Guo, Jun			GPCA: A Probabilistic Framework for Gaussian Process Embedded Channel Attention	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Task analysis; Probabilistic logic; Gaussian processes; Feature extraction; Correlation; Kernel; Visualization; Deep learning; Bayesian learning; convolutional neural network; attention mechanism; Gaussian process		Channel attention mechanisms have been commonly applied in many visual tasks for effective performance improvement. It is able to reinforce the informative channels as well as to suppress the useless channels. Recently, different channel attention modules have been proposed and implemented in various ways. Generally speaking, they are mainly based on convolution and pooling operations. In this paper, we propose Gaussian process embedded channel attention (GPCA) module and further interpret the channel attention schemes in a probabilistic way. The GPCA module intends to model the correlations among the channels, which are assumed to be captured by beta distributed variables. As the beta distribution cannot be integrated into the end-to-end training of convolutional neural networks (CNNs) with a mathematically tractable solution, we utilize an approximation of the beta distribution to solve this problem. To specify, we adapt a Sigmoid-Gaussian approximation, in which the Gaussian distributed variables are transferred into the interval [0,1]. The Gaussian process is then utilized to model the correlations among different channels. In this case, a mathematically tractable solution is derived. The GPCA module can be efficiently implemented and integrated into the end-to-end training of the CNNs. Experimental results demonstrate the promising performance of the proposed GPCA module. Codes are available at https://github.com/PRIS-CV/GPCA.	[Xie, Jiyang; Ma, Zhanyu; Chang, Dongliang; Guo, Jun] Beijing Univ Posts & Telecommun, Sch Artificial Intelligence, Pattern Recognit & Intelligent Syst Lab, Beijing 100876, Peoples R China; [Zhang, Guoqiang] Univ Technol Sydney, Sch Elect & Data Engn, Sydney, NSW 2007, Australia	Beijing University of Posts & Telecommunications; University of Technology Sydney	Ma, ZY (corresponding author), Beijing Univ Posts & Telecommun, Sch Artificial Intelligence, Pattern Recognit & Intelligent Syst Lab, Beijing 100876, Peoples R China.	xiejiyang2013@bupt.edu.cn; mazhanyu@bupt.edu.cn; changdongliang@bupt.edu.cn; guoqiang.zhang@uts.edu.au; guojun@bupt.edu.cn			National Key R&D Program of China [2019YFF0303300, 2019YFF0303302, 2020AAA0105200]; National Natural Science Foundation of China (NSFC) [61922015, 61773071, U19B2036]; Beijing Natural Science Foundation Project [Z200002]; BUPT Excellent PhD Students Foundation [CX2020105]	National Key R&D Program of China; National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Beijing Natural Science Foundation Project(Beijing Natural Science Foundation); BUPT Excellent PhD Students Foundation	This work was supported in part by the National Key R&D Program of China under Grants 2019YFF0303300, Subject II No. 2019YFF0303302, and 2020AAA0105200, in part by the National Natural Science Foundation of China (NSFC) under Grants 61922015, 61773071, and U19B2036, in part by the Beijing Natural Science Foundation Project under Grant Z200002, and in part by the BUPT Excellent PhD Students Foundation under Grant CX2020105.	Aaron van den Oord, 2016, Arxiv, DOI arXiv:1601.06759; Abdul Muqeet, 2019, Arxiv, DOI arXiv:1907.05514; Alex Krizhevsky, 2012, Arxiv, DOI arXiv:1207.0580; Andrew G. Howard, 2017, Arxiv, DOI arXiv:1704.04861; Andriy Mnih, 2017, Arxiv, DOI arXiv:1611.00712; Bello I, 2019, IEEE I CONF COMP VIS, P3285, DOI 10.1109/ICCV.2019.00338; Bishop C. M., 2006, PATTERN RECOGN, DOI DOI 10.1117/1.2819119.ARNING; Buyu Li, 2019, Arxiv, DOI arXiv:1906.07155; Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246; Charles Blundell, 2017, Arxiv, DOI arXiv:1606.04080; Chen BH, 2019, PROC CVPR IEEE, P2745, DOI 10.1109/CVPR.2019.00286; Chen GY, 2019, IEEE I CONF COMP VIS, P9636, DOI 10.1109/ICCV.2019.00973; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15; Choe J, 2021, IEEE T PATTERN ANAL, V43, P4256, DOI 10.1109/TPAMI.2020.2999099; Choe J, 2019, PROC CVPR IEEE, P2214, DOI 10.1109/CVPR.2019.00232; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132; Dan Dai, 2019, Arxiv, DOI arXiv:1904.09853; Dan Shiebler, 2019, Arxiv, DOI arXiv:1805.08819; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fang PF, 2019, IEEE I CONF COMP VIS, P8029, DOI 10.1109/ICCV.2019.00812; Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Hu JS, 2018, IEEE ICC; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Huang Z., 2019, ARXIV; Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069; Jaderberg M, 2015, ADV NEUR IN, V28; Jang DW, 2019, IEEE COMPUT SOC CONF, P1795, DOI 10.1109/CVPRW.2019.00230; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060; Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374; Maddox WJ, 2019, ADV NEUR IN, V32; MMSegmentation Contributors, 2020, MMSEGMENTATION OP SE; Park JH, 2018, POULTRY SCI, V97, P2854, DOI 10.3382/ps/pey151; Peng ZM, 2019, IEEE I CONF COMP VIS, P441, DOI 10.1109/ICCV.2019.00053; Qilong Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11531, DOI 10.1109/CVPR42600.2020.01155; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Rodriguez P, 2020, IEEE T MULTIMEDIA, V22, P502, DOI 10.1109/TMM.2019.2928494; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7; Simonyan K, 2015, 3 INT C LEARN REPR I; Singh KK, 2017, IEEE I CONF COMP VIS, P3544, DOI 10.1109/ICCV.2017.381; Sudhakaran S, 2019, PROC CVPR IEEE, P9946, DOI 10.1109/CVPR.2019.01019; Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584; Sun M, 2018, LECT NOTES COMPUT SC, V11220, P834, DOI 10.1007/978-3-030-01270-0_49; Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972; Vaswani A, 2017, ADV NEUR IN, V30; Wah C., 2011, TECH REP; Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813; Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1; Xie JY, 2019, IEEE INT WORKS MACH; Xue HL, 2019, IEEE I CONF COMP VIS, P6588, DOI 10.1109/ICCV.2019.00669; Yan YC, 2019, PATTERN RECOGN LETT, V127, P156, DOI 10.1016/j.patrec.2018.08.024; Yang L, 2019, IEEE T NEUR NET LEAR, V30, P1744, DOI 10.1109/TNNLS.2018.2873722; Yang YD, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091939; Yin JH, 2021, INT C PATT RECOG, P4229, DOI 10.1109/ICPR48806.2021.9412181; Yinpeng Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11027, DOI 10.1109/CVPR42600.2020.01104; Yuan YH, 2019, Arxiv, DOI arXiv:1909.11065; Zhang S., 2020, IEEE C COMP VIS PATT; Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716; Zhang XL, 2018, LECT NOTES COMPUT SC, V11216, P610, DOI 10.1007/978-3-030-01258-8_37; Zhao H, 2020, P IEEECVF C COMPUTER, P10076, DOI 10.1109/CVPR42600.2020.01009; Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320; Zheng ZX, 2021, IEEE T NEUR NET LEAR, V32, P334, DOI 10.1109/TNNLS.2020.2978613; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; Zhu Z, 2018, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2018.00064; Zongxin Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11791, DOI 10.1109/CVPR42600.2020.01181	78	13	13	7	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	NOV 1	2022	44	11					8230	8248		10.1109/TPAMI.2021.3102955	http://dx.doi.org/10.1109/TPAMI.2021.3102955			19	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	5C5UY	34375278	Green Submitted			2022-12-18	WOS:000864325900068
J	Qiu, HB; Gong, DH; Li, ZF; Liu, W; Tao, DC				Qiu, Haibo; Gong, Dihong; Li, Zhifeng; Liu, Wei; Tao, Dacheng			End2End Occluded Face Recognition by Masking Corrupted Features	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face recognition; Training; Decoding; Feature extraction; Mouth; Image restoration; Detectors; Occluded face recognition; feature mask; dynamically; end-to-end; deep convolutional neural network	OCCLUSION	With the recent advancement of deep convolutional neural networks, significant progress has been made in general face recognition. However, the state-of-the-art general face recognition models do not generalize well to occluded face images, which are exactly the common cases in real-world scenarios. The potential reasons are the absences of large-scale occluded face data for training and specific designs for tackling corrupted features brought by occlusions. This article presents a novel face recognition method that is robust to occlusions based on a single end-to-end deep neural network. Our approach, named FROM (Face Recognition with Occlusion Masks), learns to discover the corrupted features from the deep convolutional neural networks, and clean them by the dynamically learned masks. In addition, we construct massive occluded face images to train FROM effectively and efficiently. FROM is simple yet powerful compared to the existing methods that either rely on external detectors to discover the occlusions or employ shallow models which are less discriminative. Experimental results on the LFW, Megaface challenge 1, RMF2, AR dataset and other simulated occluded/masked datasets confirm that FROM dramatically improves the accuracy under occlusions, and generalizes well on general face recognition.	[Qiu, Haibo; Tao, Dacheng] JD Explore Acad, Shenzhen, Peoples R China; [Gong, Dihong; Li, Zhifeng; Liu, Wei] Tencent Data Platform, Shenzhen 518052, Peoples R China		Tao, DC (corresponding author), JD Explore Acad, Shenzhen, Peoples R China.; Li, ZF; Liu, W (corresponding author), Tencent Data Platform, Shenzhen 518052, Peoples R China.	qiuhaibo1@jd.com; gongdihong@gmail.com; michaelzfli@tencent.com; wl2223@columbia.edu; taodacheng@jd.com						Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Aqeel Anwar, 2020, Arxiv, DOI arXiv:2008.11104; Chen WP, 2010, LECT NOTES COMPUT SC, V6313, P496; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482; Dong Yi, 2014, Arxiv, DOI arXiv:1411.7923; Duan YQ, 2019, PROC CVPR IEEE, P3410, DOI 10.1109/CVPR.2019.00353; Ghazi MM, 2016, IEEE COMPUT SOC CONF, P102, DOI 10.1109/CVPRW.2016.20; Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6; Hadsell R., 2006, 2006 IEEE COMPUTER S, P1735, DOI DOI 10.1109/CVPR.2006.100; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He R, 2011, NEURAL COMPUT, V23, P2074, DOI 10.1162/NECO_a_00155; Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7; Huang G.B., 2008, WORKSH FAC REAL LIF; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Wang J, 2021, Arxiv, DOI arXiv:2101.04407; Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Li XX, 2013, IEEE T IMAGE PROCESS, V22, P1889, DOI 10.1109/TIP.2013.2237920; Li ZF, 2005, PROC CVPR IEEE, P961; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713; Liu WY, 2016, PR MACH LEARN RES, V48; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Martinez A. M, 1998, 24 CVC TECH; McLaughlin N, 2017, IEEE T CYBERNETICS, V47, P796, DOI 10.1109/TCYB.2016.2529300; Ng HW, 2014, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.2014.7025068; Oh HJ, 2008, IMAGE VISION COMPUT, V26, P1515, DOI 10.1016/j.imavis.2008.04.016; Rui Min, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P442, DOI 10.1109/FG.2011.5771439; Shao CB, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P666; Song LX, 2019, IEEE I CONF COMP VIS, P773, DOI 10.1109/ICCV.2019.00086; Tan MX, 2019, PR MACH LEARN RES, V97; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wan WT, 2017, IEEE IMAGE PROC, P3795; Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Weng RL, 2016, IEEE T IMAGE PROCESS, V25, P1163, DOI 10.1109/TIP.2016.2515987; Weng RL, 2013, IEEE I CONF COMP VIS, P601, DOI 10.1109/ICCV.2013.80; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yang J, 2017, IEEE T PATTERN ANAL, V39, P156, DOI 10.1109/TPAMI.2016.2535218; Yang M, 2013, IEEE T NEUR NET LEAR, V24, P900, DOI 10.1109/TNNLS.2013.2245340; Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393; Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360; Zhao F, 2018, IEEE T IMAGE PROCESS, V27, P778, DOI 10.1109/TIP.2017.2771408; Zhou ZH, 2009, IEEE I CONF COMP VIS, P1050, DOI 10.1109/ICCV.2009.5459383	45	13	13	20	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT 1	2022	44	10					6939	6952		10.1109/TPAMI.2021.3098962	http://dx.doi.org/10.1109/TPAMI.2021.3098962			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	4N2UL	34310287	Green Submitted			2022-12-18	WOS:000853875300077
J	Lu, H; Dai, YT; Shen, CH; Xu, SC				Lu, Hao; Dai, Yutong; Shen, Chunhua; Xu, Songcen			Index Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Upsampling operators; dynamic networks; image denoising; semantic segmentation; image matting; depth estimation		We show that existing upsampling operators in convolutional networks can be unified using the notion of the index function. This notion is inspired by an observation in the decoding process of deep image matting where indices-guided unpooling can often recover boundary details considerably better than other upsampling operators such as bilinear interpolation. By viewing the indices as a function of the feature map, we introduce the concept of 'learning to index', and present a novel index-guided encoder-decoder framework where indices are learned adaptively from data and are used to guide downsampling and upsampling stages, without extra training supervision. At the core of this framework is a new learnable module, termed Index Network (IndexNet), which dynamically generates indices conditioned on the feature map. IndexNet can be used as a plug-in, applicable to almost all convolutional networks that have coupled downsampling and upsampling stages, enabling the networks to dynamically capture variations of local patterns. In particular, we instantiate and investigate five families of IndexNet. We highlight their superiority in delivering spatial information over other upsampling operators with experiments on synthetic data, and demonstrate their effectiveness on four dense prediction tasks, including image matting, image denoising, semantic segmentation, and monocular depth estimation. Code and models are available at https://git.io/IndexNet	[Lu, Hao; Dai, Yutong] Univ Adelaide, Adelaide, SA 5005, Australia; [Shen, Chunhua] Univ Adelaide, Comp Sci, Adelaide, SA 5005, Australia; [Xu, Songcen] Huawei Technol, Noahs Ark Lab, Shenzhen 518129, Peoples R China	University of Adelaide; University of Adelaide; Huawei Technologies	Shen, CH (corresponding author), Univ Adelaide, Comp Sci, Adelaide, SA 5005, Australia.	hao.lu@adelaide.edu.au; yutong.dai@adelaide.edu.au; chunhua.shen@adelaide.edu.au; xusongcen@huawei.com	Lu, Hao/AFL-6512-2022	Shen, Chunhua/0000-0002-8648-8718				Aittala M., 2019, COMPUT RES REPOSITOR; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347; Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen QF, 2013, IEEE T PATTERN ANAL, V35, P2175, DOI 10.1109/TPAMI.2013.18; Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743; Chuang YY, 2001, PROC CVPR IEEE, P264; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; De Brabandere B, 2016, ADV NEUR IN, V29; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Hu JJ, 2019, IEEE WINT CONF APPL, P1043, DOI 10.1109/WACV.2019.00116; Jaderberg M, 2015, ADV NEUR IN, V28; Kaiming He, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2049, DOI 10.1109/CVPR.2011.5995495; Kingma D.P, P 3 INT C LEARNING R; Kraska T, 2018, INT CONF MANAGE DATA, P489, DOI 10.1145/3183713.3196909; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177; Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lu H, 2019, IEEE I CONF COMP VIS, P3265, DOI 10.1109/ICCV.2019.00336; Mao XJ, 2016, ADV NEUR IN, V29; Odena A, 2016, DISTILL, DOI [10.23915/distill.00003.-URL, 10.23915/distill.00003]; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Osendorfer C, 2014, LECT NOTES COMPUT SC, V8836, P250, DOI 10.1007/978-3-319-12643-2_31; Rhemann C, 2009, PROC CVPR IEEE, P1826, DOI 10.1109/CVPRW.2009.5206503; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655; Vollgraf, 2017, ARXIV COMPUT RES REP; Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683; Wang JQ, 2019, IEEE I CONF COMP VIS, P3007, DOI 10.1109/ICCV.2019.00310; Wolk D, 2019, IEEE INT CONF ROBOT, P6101, DOI 10.1109/ICRA.2019.8794182; Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1; Xian K, 2018, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2018.00040; Xiao TT, 2018, LECT NOTES COMPUT SC, V11209, P432, DOI 10.1007/978-3-030-01228-1_26; Xiong RQ, 2017, IEEE T IMAGE PROCESS, V26, DOI [10.1109/TIP.2016.2621478, 10.1109/TIP.2017.2689999]; Xu N, 2017, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2017.41; Yang, 2019, COMPUT RES REPOSITOR; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544	51	13	13	8	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2022	44	1					242	255		10.1109/TPAMI.2020.3004474	http://dx.doi.org/10.1109/TPAMI.2020.3004474			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	XM0XY	32750793				2022-12-18	WOS:000728561300018
J	Sun, SL; Dong, WB; Liu, QY				Sun, Shiliang; Dong, Wenbo; Liu, Qiuyang			Multi-View Representation Learning With Deep Gaussian Processes	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Global Positioning System; Gaussian processes; Uncertainty; Data models; Task analysis; Neural networks; Learning systems; Gaussian processes; deep learning; multi-view learning; representation learning	CANONICAL CORRELATION-ANALYSIS; VIEW	Multi-view representation learning is a promising and challenging research topic, which aims to integrate multiple data information from different views to improve the learning performance. The recent deep Gaussian processes (DGPs) have the advantages of good uncertainty estimates, powerful non-linear mapping ability and great generalization capability, which can be used as an excellent data representation learning method. However, DGPs only focus on single view data and are rarely applied to the multi-view scenario. In this paper, we propose a multi-view representation learning algorithm with deep Gaussian processes (named MvDGPs), which inherits the advantages of deep Gaussian processes and multi-view representation learning, and can learn more effective representation of multi-view data. The MvDGPs consist of two stages. The first stage is multi-view data representation learning, which is mainly used to learn more comprehensive representations of multi-view data. The second stage is classifier design, which aims to select an appropriate classifier to better employ the representations obtained in the first stage. In contrast with DGPs, MvDGPs support asymmetrical modeling depths for different views of data, resulting in better characterizations of the discrepancies among different views. Experimental results on real-world multi-view data sets verify the effectiveness of the proposed algorithm, which indicates that MvDGPs can integrate the complementary information in multiple views to discover a good representation of the data.	[Sun, Shiliang; Dong, Wenbo; Liu, Qiuyang] East China Normal Univ, Sch Comp Sci & Technol, 3663 North Zhongshan Rd, Shanghai 200062, Peoples R China	East China Normal University	Sun, SL (corresponding author), East China Normal Univ, Sch Comp Sci & Technol, 3663 North Zhongshan Rd, Shanghai 200062, Peoples R China.	slsun@cs.ecnu.edu.cn; 1623572531@qq.com; sunny_lqy@foxmail.com		Sun, Shiliang/0000-0001-7069-3752; Dong, Wenbo/0000-0001-9451-8502	National Natural Science Foundation of China [61673179]; Fundamental Research Funds for the Central Universities; Shanghai Knowledge Service Platform Project [ZF1213]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Shanghai Knowledge Service Platform Project	This work was supported by the National Natural Science Foundation of China under Project 61673179, ShanghaiKnowledge Service Platform Project (No. ZF1213), and the Fundamental Research Funds for the CentralUniversities.	Andrew G., 2013, INT C MACH LEARN, p1247?1255; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Blei DM, 2017, J AM STAT ASSOC, V112, P859, DOI 10.1080/01621459.2017.1285773; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Bui T. D., 2016, STAT-US, V23, P1; Bui TD, 2016, PR MACH LEARN RES, V48; Chao GQ, 2016, INFORM SCIENCES, V367, P296, DOI 10.1016/j.ins.2016.06.004; Chaudhuri K., 2009, PROC INT C MACHINE L, P129, DOI DOI 10.1145/1553374.1553391; Cutajar K, 2017, PR MACH LEARN RES, V70; Dai Z, 2015, ARXIV PREPRINT ARXIV; Damianou Andreas, 2013, ARTIF INTELL, P207, DOI DOI 10.1002/NME.1296; Dunlop MM, 2018, J MACH LEARN RES, V19; Eleftheriadis S, 2015, IEEE T IMAGE PROCESS, V24, P189, DOI 10.1109/TIP.2014.2375634; Fu YW, 2015, IEEE T PATTERN ANAL, V37, P2332, DOI 10.1109/TPAMI.2015.2408354; Gal Y, 2016, PR MACH LEARN RES, V48; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; Hou CP, 2010, PATTERN RECOGN, V43, P720, DOI 10.1016/j.patcog.2009.07.015; Hu JL, 2018, IEEE T PATTERN ANAL, V40, P2281, DOI 10.1109/TPAMI.2017.2749576; Kakade SM, 2007, LECT NOTES COMPUT SC, V4539, P82, DOI 10.1007/978-3-540-72927-3_8; Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740; Kandemir M, 2015, PR MACH LEARN RES, V37, P730; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Lawrence N. D., 2005, NIPS, P753; Lee JY, 2018, INT J COMPUT INTEG M, V31, P769, DOI 10.1080/0951192X.2018.1429669; Li JH, 2016, P IEEE RAS-EMBS INT, P1068, DOI 10.1109/BIOROB.2016.7523773; Liu QY, 2017, LECT NOTES ARTIF INT, V10235, P655, DOI 10.1007/978-3-319-57529-2_51; Mao L, 2016, P 25 INT JOINT C ART, P1839; Quinonero-Candela JQ, 2005, J MACH LEARN RES, V6, P1939; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Rezende DJ, 2015, PR MACH LEARN RES, V37, P1530; Sun SL, 2018, LECT NOTES COMPUT SC, V11301, P130, DOI 10.1007/978-3-030-04167-0_12; Sun SL, 2017, INFORM FUSION, V35, P117, DOI 10.1016/j.inffus.2016.09.008; Sun SL, 2013, NEURAL COMPUT APPL, V23, P2031, DOI 10.1007/s00521-013-1362-6; Titsias MK, 2010, P 13 INT C ARTIFICIA, V9, P844; Wang FS, 2013, NEURAL PROCESS LETT, V37, P135, DOI 10.1007/s11063-012-9238-9; Wang H., 2014, P 30 INT C MACH LEAR, P352; Wang W, 2016, 2016 IEEE INNOVATIVE SMART GRID TECHNOLOGIES - ASIA (ISGT-ASIA), P1, DOI [10.1109/ISGT-Asia.2016.7796352, 10.1109/CPEM.2016.7540636]; Wang WR, 2015, PR MACH LEARN RES, V37, P1083; Wang XQ, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1276; White Martha, 2012, ADV NEURAL INFORM PR, P1682; Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807; Wu Anqi, 2017, Adv Neural Inf Process Syst, V30, P3496; Xu C., 2013, COMPUTING RES REPOSI; Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578; Xu XX, 2016, IEEE T PATTERN ANAL, V38, P1113, DOI 10.1109/TPAMI.2015.2476813; Yin J, 2020, IEEE T NEUR NET LEAR, V31, P3442, DOI 10.1109/TNNLS.2019.2944664; Yu SP, 2011, J MACH LEARN RES, V12, P2649; Zhang C, 2019, PROC CVPR IEEE, P9444, DOI 10.1109/CVPR.2019.00968; Zhang C, 2019, IEEE T PATTERN ANAL, V41, P2008, DOI 10.1109/TPAMI.2018.2889774; Zhang ZY, 2017, IEEE T PATTERN ANAL, V39, P1675, DOI 10.1109/TPAMI.2016.2601608; Zhao J, 2017, INFORM FUSION, V38, P43, DOI 10.1016/j.inffus.2017.02.007	53	13	13	6	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	DEC 1	2021	43	12					4453	4468		10.1109/TPAMI.2020.3001433	http://dx.doi.org/10.1109/TPAMI.2020.3001433			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	WR0MQ	32750782				2022-12-18	WOS:000714203900022
J	Zhao, Y; Wang, HY; Pei, JH				Zhao, Yang; Wang, Huiyang; Pei, Jihong			Deep Non-Negative Matrix Factorization Architecture Based on Underlying Basis Images Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Linear programming; Image reconstruction; Kernel; Sparse matrices; Convergence; Data analysis; Non-negative matrix factorization; underlying basis images; deep factorization architecture; face recognition		The non-negative matrix factorization (NMF) algorithm represents the original image as a linear combination of a set of basis images. This image representation method is in line with the idea of "parts constitute a whole" in human thinking. The existing deep NMF performs deep factorization on the coefficient matrix. In these methods, the basis images used to represent the original image is essentially obtained by factorizing the original images once. To extract features reflecting the deep localization characteristics of images, a novel deep NMF architecture based on underlying basis images learning is proposed for the first time. The architecture learns the underlying basis images by deep factorization on the basis images matrix. The deep factorization architecture proposed in this paper has strong interpretability. To implement this architecture, this paper proposes a deep non-negative basis matrix factorization algorithm to obtain the underlying basis images. Then, the objective function is established with an added regularization term, which directly constrains the basis images matrix to obtain the basis images with good local characteristics, and a regularized deep non-negative basis matrix factorization algorithm is proposed. The regularized deep nonlinear non-negative basis matrix factorization algorithm is also proposed to handle pattern recognition tasks with complex data. This paper also theoretically proves the convergence of the algorithm. Finally, the experimental results show that the deep NMF architecture based on the underlying basis images learning proposed in this paper can obtain better recognition performance than the other state-of-the-art methods.	[Zhao, Yang; Pei, Jihong] Shenzhen Univ, Coll Elect & Informat Engn, Shenzhen 518160, Peoples R China; [Wang, Huiyang] Shenzhen Univ, Coll Mechatron & Control Engn, Shenzhen 518160, Peoples R China	Shenzhen University; Shenzhen University	Pei, JH (corresponding author), Shenzhen Univ, Coll Elect & Informat Engn, Shenzhen 518160, Peoples R China.	zhaoyangmaths@163.com; 2130090503@email.szu.edu.cn; jhpei@szu.edu.cn		Zhao, Yang/0000-0003-2066-1992	National Natural Science Foundation of China [61871269, 61331021]; Guangdong Basic and Applied Basic Research Foundation [2019A1515011861]; Shenzhen Science and Technology Projection [JCYJ20170818143547435]; DOD Counterdrug Technology Development Program Office	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Guangdong Basic and Applied Basic Research Foundation; Shenzhen Science and Technology Projection; DOD Counterdrug Technology Development Program Office	This paper was supported in part by the National Natural Science Foundation of China (Grant No.61871269, 61331021), Guangdong Basic and Applied Basic Research Foundation (2019A1515011861), Shenzhen Science and Technology Projection (Grant No. JCYJ20170818143547435). Portions of the research in this paper use the FERET database of facial images collected under the FERET program, sponsored by the DOD Counterdrug Technology Development Program Office. We thank Olivetti Research Laboratory, University of California, University of Stirling and Yale University for the contribution of the ORL database, CMU face database, Stirling face database and Yale face database. Special thanks are given to Xinyi Yao from Key School for her writing assistance.	[Anonymous], 2018, INT C APPL AN MATH M; Buciu I, 2008, IEEE T NEURAL NETWOR, V19, P1090, DOI 10.1109/TNN.2008.2000162; Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231; Chen WS, 2016, NEUROCOMPUTING, V205, P165, DOI 10.1016/j.neucom.2016.04.014; Chen ZS, 2019, PATTERN RECOGN, V91, P13, DOI 10.1016/j.patcog.2019.01.016; Choi S., 2004, P AS C COMP VIS, P1009; Cichocki A, 2006, ELECTRON LETT, V42, P947, DOI 10.1049/el:20060983; Cichocki A, 2007, INT J NEURAL SYST, V17, P431, DOI 10.1142/S0129065707001275; Ding C, 2010, IEEE T PATTERN ANAL, V32, P45, DOI 10.1109/TPAMI.2008.277; Fang H, 2018, PROC SPIE, V10846, DOI 10.1117/12.2505494; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Gligorijevic V, 2019, IEEE T PATTERN ANAL, V41, P928, DOI 10.1109/TPAMI.2018.2821146; Goceri Evgin, 2019, VipIMAGE 2019. Proceedings of the VII ECCOMAS Thematic Conference on Computational Vision and Medical Image Processing. Lecture Notes in Computational Vision and Biomechanics (LNCVB 34), P239, DOI 10.1007/978-3-030-32040-9_25; Goceri E, 2017, INT C COMP GRAPH VIS, P305, DOI DOI 10.1109/ICMLA.2015.229; Goceri E, 2019, INT CONF IMAG PROC; Goceri E, 2019, INT CONF IMAG PROC; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Hoyer PO, 2004, J MACH LEARN RES, V5, P1457; Imakura A, 2018, NEURAL PROCESS LETT, V47, P815, DOI 10.1007/s11063-017-9642-2; Kim H, 2019, P MED IM IM PROC; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Lee DD, 2001, ADV NEUR IN, V13, P556; Li Xuelong, 2017, IEEE Trans Cybern, V47, P3840, DOI 10.1109/TCYB.2016.2585355; Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750; Liu YL, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P249, DOI 10.1109/ICMLA.2017.0-151; Martinez A., 1998, AR FACE DATABASE CVC; Pan BB, 2011, PATTERN RECOGN, V44, P2800, DOI 10.1016/j.patcog.2011.03.023; Pascual-Montano A, 2006, IEEE T PATTERN ANAL, V28, P403, DOI 10.1109/TPAMI.2006.60; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819; Rousset F, 2018, IEEE T COMPUT IMAG, V4, P284, DOI 10.1109/TCI.2018.2811910; Sabzalian B, 2018, INT J ENG-IRAN, V31, P1698, DOI 10.5829/ije.2018.31.10a.12; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Shi T, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1105, DOI 10.1145/3178876.3186009; Song HA, 2015, NEUROCOMPUTING, V165, P63, DOI 10.1016/j.neucom.2014.08.095; Tharwat A., 2018, APPL COMPUT INF, V17, P168, DOI [DOI 10.1016/J.ACI.2018.08.003, 10.1016/j.aci.2018.08.003]; Tolic D, 2018, PATTERN RECOGN, V82, P40, DOI 10.1016/j.patcog.2018.04.029; Tong M, 2019, NEURAL COMPUT APPL, V31, P7447, DOI 10.1007/s00521-018-3554-6; Trigeorgis G, 2017, IEEE T PATTERN ANAL, V39, P417, DOI 10.1109/TPAMI.2016.2554555; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Varikuti DP, 2018, NEUROIMAGE, V173, P394, DOI 10.1016/j.neuroimage.2018.03.007; Wang YX, 2013, IEEE T KNOWL DATA EN, V25, P1336, DOI 10.1109/TKDE.2012.51; Wisdom S, 2017, IEEE WORK APPL SIG, P254; Ye FH, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1393, DOI 10.1145/3269206.3271697; Yi YG, 2020, IEEE T CIRC SYST VID, V30, P427, DOI 10.1109/TCSVT.2019.2892971; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X; Zafeiriou S, 2010, IEEE T IMAGE PROCESS, V19, P1050, DOI 10.1109/TIP.2009.2038816; Zong LL, 2017, NEURAL NETWORKS, V88, P74, DOI 10.1016/j.neunet.2017.02.003	50	13	13	6	33	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUN 1	2021	43	6					1897	1913		10.1109/TPAMI.2019.2962679	http://dx.doi.org/10.1109/TPAMI.2019.2962679			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	SA8YQ	31899412	hybrid			2022-12-18	WOS:000649590200007
J	Taira, H; Okutomi, M; Sattler, T; Cimpoi, M; Pollefeys, M; Sivic, J; Pajdla, T; Torii, A				Taira, Hajime; Okutomi, Masatoshi; Sattler, Torsten; Cimpoi, Mircea; Pollefeys, Marc; Sivic, Josef; Pajdla, Tomas; Torii, Akihiko			InLoc: Indoor Visual Localization with Dense Matching and View Synthesis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Three-dimensional displays; Visualization; Cameras; Pose estimation; Buildings; Databases; Feature extraction; Visual localization; place recognition; pose estimation; image retrieval; feature matching; view synthesis	SCALE	We seek to predict the 6 degree-of-freedom (6DoF) pose of a query photograph with respect to a large indoor 3D map. The contributions of this work are three-fold. First, we develop a new large-scale visual localization method targeted for indoor spaces. The method proceeds along three steps: (i) efficient retrieval of candidate poses that scales to large-scale environments, (ii) pose estimation using dense matching rather than sparse local features to deal with weakly textured indoor scenes, and (iii) pose verification by virtual view synthesis that is robust to significant changes in viewpoint, scene layout, and occlusion. Second, we release a new dataset with reference 6DoF poses for large-scale indoor localization. Query photographs are captured by mobile phones at a different time than the reference 3D map, thus presenting a realistic indoor localization scenario. Third, we demonstrate that our method significantly outperforms current state-of-the-art indoor localization approaches on this new challenging data. Code and data are publicly available.	[Taira, Hajime; Okutomi, Masatoshi; Torii, Akihiko] Tokyo Inst Technol, Sch Engn, Dept Syst & Control Engn, Tokyo 1528550, Japan; [Sattler, Torsten] Chalmers Univ Technol, Dept Elect Engn, S-41296 Gothenburg, Sweden; [Cimpoi, Mircea; Sivic, Josef; Pajdla, Tomas] Czech Tech Univ, CIIRC Czech Inst Informat Robot & Cybernet, Prague 16636 6, Czech Republic; [Pollefeys, Marc] Swiss Fed Inst Technol, Dept Comp Sci, CH-8092 Zurich, Switzerland; [Pollefeys, Marc] Microsoft Zurich, CH-8304 Zurich, Switzerland; [Sivic, Josef] PSL Res Univ, Willow, INRIA, Dept Informat,Ecole Normale Super,CNRS, F-75006 Paris, France	Tokyo Institute of Technology; Chalmers University of Technology; Czech Technical University Prague; Swiss Federal Institutes of Technology Domain; ETH Zurich; Centre National de la Recherche Scientifique (CNRS); Inria; UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS); Universite Paris Cite	Taira, H (corresponding author), Tokyo Inst Technol, Sch Engn, Dept Syst & Control Engn, Tokyo 1528550, Japan.	htaira@ok.ctrl.titech.ac.jp; mxo@sc.e.titech.ac.jp; torsat@chalmers.se; mircea.cimpoi@cvut.cz; marc.pollefeys@inf.ethz.ch; josef.sivic@cvut.cz; pajdla@cvut.cz; torii@sc.e.titech.ac.jp	Sattler, Torsten/AAM-3155-2021; cao, xiaoxiang/AAR-9291-2021; Pollefeys, Marc/I-7607-2013	Cimpoi, Mircea/0000-0002-5624-7593; Sattler, Torsten/0000-0001-9760-4553	JSPS KAKENHI [15H05313, 17H00744, 17J05908]; EU [731970]; ERC [336845]; CIFAR Learning in Machines Brains program; EU Structural and Investment Funds, Operational Programe Research, Development and Education under the project IMPACT [CZ.02.1.01/0.0/0.0/15_003/0000468]; NVIDIA Corporation	JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)); EU(European Commission); ERC(European Research Council (ERC)European Commission); CIFAR Learning in Machines Brains program; EU Structural and Investment Funds, Operational Programe Research, Development and Education under the project IMPACT; NVIDIA Corporation	This work was partially supported by JSPS KAKENHI Grant Numbers 15H05313, 17H00744, 17J05908, EU-H2020 project LADIO No. 731970, ERC grant LEAP No. 336845, CIFAR Learning in Machines & Brains program and the EU Structural and Investment Funds, Operational Programe Research, Development and Education under the project IMPACT (reg. no. CZ.02.1.01/0.0/0.0/15_003/0000468). The authors would like to gratefully acknowledge the support of NVIDIA Corporation with the donation of Quadro P6000 GPU. The authors would like to express the deepest appreciation to Yasutaka Furukawa for his arrangement to capture query photographs at Washington University in St. Louis.	Agarwal S., 2010, CERES SOLVER; Agarwal S, 2011, COMMUN ACM, V54, P105, DOI 10.1145/2001269.2001293; Agrawal P, 2014, LECT NOTES COMPUT SC, V8695, P329, DOI 10.1007/978-3-319-10584-0_22; Anand A, 2013, INT J ROBOT RES, V32, P19, DOI 10.1177/0278364912461538; Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/CVPR.2016.572, 10.1109/TPAMI.2017.2711011]; Arandjelovic R, 2015, LECT NOTES COMPUT SC, V9006, P188, DOI 10.1007/978-3-319-16817-3_13; Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Armeni I, 2016, PROC CVPR IEEE, P1534, DOI 10.1109/CVPR.2016.170; Balntas V, 2018, LECT NOTES COMPUT SC, V11218, P782, DOI 10.1007/978-3-030-01264-9_46; Brachmann E, 2019, IEEE I CONF COMP VIS, P7524, DOI 10.1109/ICCV.2019.00762; Brachmann E, 2018, PROC CVPR IEEE, P4654, DOI 10.1109/CVPR.2018.00489; Brachmann E, 2017, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2017.267; Brachmann E, 2016, PROC CVPR IEEE, P3364, DOI 10.1109/CVPR.2016.366; Brahmbhatt S, 2018, PROC CVPR IEEE, P2616, DOI 10.1109/CVPR.2018.00277; Camposeco F, 2018, PROC CVPR IEEE, P136, DOI 10.1109/CVPR.2018.00022; Camposeco F, 2017, PROC CVPR IEEE, P6700, DOI 10.1109/CVPR.2017.709; Cao S, 2014, PROC CVPR IEEE, P461, DOI 10.1109/CVPR.2014.66; Castle R, 2008, TWELFTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P15, DOI 10.1109/ISWC.2008.4911577; Chang A, 2017, INT CONF 3D VISION, P667, DOI 10.1109/3DV.2017.00081; Chen D, 2011, CONF REC ASILOMAR C, P850, DOI 10.1109/ACSSC.2011.6190128; Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610; Choudhary S, 2012, LECT NOTES COMPUT SC, V7576, P130, DOI 10.1007/978-3-642-33715-4_10; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Chum O, 2011, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2011.5995601; Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261; Debski A, 2015, PROCEDIA COMPUT SCI, V76, P139, DOI 10.1016/j.procs.2015.12.327; Dusmanu M, 2019, PROC CVPR IEEE, P8084, DOI 10.1109/CVPR.2019.00828; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Glocker B, 2013, INT SYM MIX AUGMENT, P173, DOI 10.1109/ISMAR.2013.6671777; Gronat P, 2013, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2013.122; Halber M, 2017, PROC CVPR IEEE, P6660, DOI 10.1109/CVPR.2017.705; Hartley R., 2011, P IEEE C COMP VIS PA, P3041, DOI DOI 10.1109/CVPR.2011.5995745; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Irschara A, 2009, PROC CVPR IEEE, P2591, DOI 10.1109/cvpr.2009.5206587; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Jegou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55; Jegou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609; Kendall A, 2017, PROC CVPR IEEE, P6555, DOI 10.1109/CVPR.2017.694; Kim HJ, 2017, PROC CVPR IEEE, P3251, DOI 10.1109/CVPR.2017.346; Lai K, 2014, IEEE INT CONF ROBOT, P3050, DOI 10.1109/ICRA.2014.6907298; Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95; Li YP, 2012, LECT NOTES COMPUT SC, V7572, P15, DOI 10.1007/978-3-642-33718-5_2; Lim H, 2012, PROC CVPR IEEE, P1043, DOI 10.1109/CVPR.2012.6247782; Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170; Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7_3; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas B. D., 1981, INT JOINT C ART INT, P674, DOI DOI 10.5555/1623264.1623280; Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498; Melekhov I, 2019, IEEE WINT CONF APPL, P1034, DOI 10.1109/WACV.2019.00115; Middelberg S, 2014, LECT NOTES COMPUT SC, V8690, P268, DOI 10.1007/978-3-319-10605-2_18; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378; Niessner M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508374; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383; Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537; Revaud J, 2016, INT J COMPUT VISION, V120, P300, DOI 10.1007/s11263-016-0908-3; Rocco I, 2018, ADV NEUR IN, V31; Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897; Sattler T, 2017, PROC CVPR IEEE, P6175, DOI 10.1109/CVPR.2017.654; Sattler T, 2017, IEEE T PATTERN ANAL, V39, P1744, DOI 10.1109/TPAMI.2016.2611662; Sattler T, 2016, PROC CVPR IEEE, P1582, DOI 10.1109/CVPR.2016.175; Sattler T, 2015, IEEE I CONF COMP VIS, P2102, DOI 10.1109/ICCV.2015.243; Schmidt T, 2017, IEEE ROBOT AUTOM LET, V2, P420, DOI 10.1109/LRA.2016.2634089; Schonberger JL, 2018, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR.2018.00721; Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Simonyan K, 2015, 3 INT C LEARN REPR I; Singh S, 2012, LECT NOTES COMPUT SC, V7573, P73, DOI 10.1007/978-3-642-33709-3_6; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Sun X, 2017, PROC CVPR IEEE, P5641, DOI 10.1109/CVPR.2017.598; Svarm L, 2017, IEEE T PATTERN ANAL, V39, P1455, DOI 10.1109/TPAMI.2016.2598331; Taira H, 2018, PROC CVPR IEEE, P7199, DOI 10.1109/CVPR.2018.00752; Toft C, 2018, LECT NOTES COMPUT SC, V11206, P391, DOI 10.1007/978-3-030-01216-8_24; Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77; Torii A., 2018, IPSJ T COMPUTER VISI, V10, DOI [10.1186/s41074-018-0042-y, DOI 10.1186/S41074-018-0042-Y]; Torii A, 2015, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2015.7298790; Torii A, 2013, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2013.119; Torralba A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P273; UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573; Valentin J, 2016, INT CONF 3D VISION, P323, DOI 10.1109/3DV.2016.41; van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132; Vedaldi Andrea, 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249; Wagner D, 2010, IEEE T VIS COMPUT GR, V16, P355, DOI 10.1109/TVCG.2009.99; Walch F, 2017, IEEE I CONF COMP VIS, P627, DOI 10.1109/ICCV.2017.75; Wang SL, 2015, IEEE I CONF COMP VIS, P2695, DOI 10.1109/ICCV.2015.309; Weyand T, 2016, LECT NOTES COMPUT SC, V9912, P37, DOI 10.1007/978-3-319-46484-8_3; Wijmans E, 2017, PROC CVPR IEEE, P1427, DOI 10.1109/CVPR.2017.156; Xiao JX, 2014, INT J COMPUT VISION, V110, P243, DOI 10.1007/978-3-642-33718-5_48; Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458; Yu X, 2018, IEEE INT C INT ROBOT, P3196, DOI 10.1109/IROS.2018.8594358; Zamir AR, 2010, LECT NOTES COMPUT SC, V6314, P255, DOI 10.1007/978-3-642-15561-1_19; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zeisl B, 2015, IEEE I CONF COMP VIS, P2704, DOI 10.1109/ICCV.2015.310	98	13	13	3	35	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2021	43	4					1293	1307		10.1109/TPAMI.2019.2952114	http://dx.doi.org/10.1109/TPAMI.2019.2952114			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QT3YJ	31722474	Green Submitted			2022-12-18	WOS:000626525300014
J	Wang, SS; Arroyo, J; Vogelstein, JT; Priebe, CE				Wang, Shangsi; Arroyo, Jesus; Vogelstein, Joshua T.; Priebe, Carey E.			Joint Embedding of Graphs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Feature extraction; Symmetric matrices; Numerical models; Task analysis; Inference algorithms; Stochastic processes; Machine learning algorithms; Graphs; embedding; feature extraction; statistical inference	VERTEX CLASSIFICATION; NETWORK ANALYSIS; ALGORITHM	Feature extraction and dimension reduction for networks is critical in a wide variety of domains. Efficiently and accurately learning features for multiple graphs has important applications in statistical inference on graphs. We propose a method to jointly embed multiple undirected graphs. Given a set of graphs, the joint embedding method identifies a linear subspace spanned by rank one symmetric matrices and projects adjacency matrices of graphs into this subspace. The projection coefficients can be treated as features of the graphs, while the embedding components can represent vertex features. We also propose a random graph model for multiple graphs that generalizes other classical models for graphs. We show through theory and numerical experiments that under the model, the joint embedding method produces estimates of parameters with small errors. Via simulation experiments, we demonstrate that the joint embedding method produces features which lead to state of the art performance in classifying graphs. Applying the joint embedding method to human brain graphs, we find it extracts interpretable features with good prediction accuracy in different tasks.	[Wang, Shangsi; Priebe, Carey E.] Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD 21218 USA; [Arroyo, Jesus] Johns Hopkins Univ, Ctr Imaging Sci, Baltimore, MD 21218 USA; [Vogelstein, Joshua T.] Johns Hopkins Univ, Inst Computat Med, Kavli Neurosci Discovery Inst, Dept Biomed Engn, Baltimore, MD 21218 USA	Johns Hopkins University; Johns Hopkins University; Johns Hopkins University	Arroyo, J (corresponding author), Johns Hopkins Univ, Ctr Imaging Sci, Baltimore, MD 21218 USA.	swang127@jhu.edu; jesus.arroyo@jhu.edu; jovo@jhu.edu; cep@jhu.edu		Arroyo, Jesus/0000-0003-3071-9043	GRAPHS program of the Defense Advanced Research Projects Agency (DARPA) [N66001-14-1-4028]; DARPA SIMPLEX program [N66001-15-C-4041]; DARPA D3M program [FA8750-17-2-0112]; DARPA MAA program [FA8750-18-2-0035]	GRAPHS program of the Defense Advanced Research Projects Agency (DARPA)(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); DARPA SIMPLEX program; DARPA D3M program; DARPA MAA program	The authors gratefully acknowledge support from the GRAPHS program of the Defense Advanced Research Projects Agency (DARPA) contract N66001-14-1-4028, the DARPA SIMPLEX program contract N66001-15-C-4041, the DARPA D3M program administered through AFRL contract FA8750-17-2-0112, and the DARPA MAA program contract FA8750-18-2-0035. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the Air Force Research Laboratory and DARPA or the U.S. Government. Shangsi Wang and Jesus Arroyo equally contributed to the project.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Airoldi EM, 2008, J MACH LEARN RES, V9, P1981; Athreya A, 2016, SANKHYA SER A, V78, P1; Beck A, 2013, SIAM J OPTIMIZ, V23, P2037, DOI 10.1137/120887679; Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317; Bell N, 2009, STUDENTS GUIDE TO THE MA TESOL, P1; Bezdek J. C., 2003, Neural, Parallel & Scientific Computations, V11, P351; BINI D, 1979, INFORM PROCESS LETT, V8, P234, DOI 10.1016/0020-0190(79)90113-3; Bullmore ET, 2011, ANNU REV CLIN PSYCHO, V7, P113, DOI 10.1146/annurev-clinpsy-040510-143934; Cape J., 2017, ARXIV PREPRINT ARXIV; CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S1064827596304010; de Silva V, 2008, SIAM J MATRIX ANAL A, V30, P1084, DOI 10.1137/06066518X; Dorogovtsev SN, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.046109; Finn ES, 2015, NAT NEUROSCI, V18, P1664, DOI 10.1038/nn.4135; FLURY BN, 1986, SIAM J SCI STAT COMP, V7, P169, DOI 10.1137/0907013; Ghasemian A, 2016, PHYS REV X, V6, DOI 10.1103/PhysRevX.6.031005; Govindan R., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P1371, DOI 10.1109/INFCOM.2000.832534; Han Q, 2014, P 32 ITN C MACH LEAR, P1511; Hillar CJ, 2013, J ACM, V60, DOI 10.1145/2512329; HOLLAND PW, 1983, SOC NETWORKS, V5, P109, DOI 10.1016/0378-8733(83)90021-7; Huan J, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P549; Jiang CT, 2013, KNOWL ENG REV, V28, P75, DOI 10.1017/S0269888912000331; Jolliffe IT, 2002, ENCY STATIST BEHAV S, DOI [10.1007/0-387-22440-8_13, 10.1007/b98835]; Karrer B, 2011, PHYS REV E, V83, DOI 10.1103/PhysRevE.83.016107; Kiar G., 2016, ZENODO; Kim H, 2008, SIAM J MATRIX ANAL A, V30, P713, DOI 10.1137/07069239X; Kivela M, 2014, J COMPLEX NETW, V2, P203, DOI 10.1093/comnet/cnu016; Klebanov L, 2007, BIOL DIRECT, V2, DOI 10.1186/1745-6150-2-9; Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1137; Kolda TG, 2015, MATH PROGRAM, V151, P225, DOI 10.1007/s10107-015-0895-0; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Lancaster J., 1997, NEUROIMAGE, V5, P238; Lyzinski V, 2017, IEEE T NETW SCI ENG, V4, P13, DOI 10.1109/TNSE.2016.2634322; Lyzinski V, 2014, ELECTRON J STAT, V8, P2905, DOI 10.1214/14-EJS978; Neyman J, 1948, ECONOMETRICA, V16, P1, DOI 10.2307/1914288; Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5; Nolte J., 1999, HUMAN BRAIN INTRO IT; Otte E, 2002, J INF SCI, V28, P441, DOI 10.1177/016555150202800601; Park HM, 2016, MACH VISION APPL, V27, P1021, DOI 10.1007/s00138-016-0786-2; Park Y, 2013, IEEE J-STSP, V7, P67, DOI 10.1109/JSTSP.2012.2233712; Shekhar S, 2009, CH CRC DATA MIN KNOW, P549; Sripada C, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-38406-5; Steinley D, 2004, PSYCHOL METHODS, V9, P386, DOI 10.1037/1082-989X.9.3.386; Sussman DL, 2014, IEEE T PATTERN ANAL, V36, P48, DOI 10.1109/TPAMI.2013.135; Sussman DL, 2012, J AM STAT ASSOC, V107, P1119, DOI 10.1080/01621459.2012.699795; Suwan S, 2016, ELECTRON J STAT, V10, P761, DOI 10.1214/16-EJS1115; Tang M, 2013, ANN STAT, V41, P1406, DOI 10.1214/13-AOS1112; Tang RZ, 2019, IEEE T MED IMAGING, V38, P1446, DOI 10.1109/TMI.2018.2885968; Tang W, 2009, IEEE DATA MINING, P1016, DOI 10.1109/ICDM.2009.125; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Wang S, 2015, FIGSHARE POSTER, DOI [10.6084/m9.figshare.1515021.v1, DOI 10.6084/M9.FIGSHARE.1515021.V1]; Ward MD, 2011, ANNU REV POLIT SCI, V14, P245, DOI 10.1146/annurev.polisci.12.040907.115949; Wright SJ, 2015, MATH PROGRAM, V151, P3, DOI 10.1007/s10107-015-0892-3; Yan JC, 2014, LECT NOTES COMPUT SC, V8689, P407, DOI 10.1007/978-3-319-10590-1_27; Young SJ, 2007, LECT NOTES COMPUT SC, V4863, P138; Zaki M. J., 2011, P 9 INT WORKSH MIN, V2; Zheng Z., 2007, P 24 INT C MACH LEAR, P1151, DOI DOI 10.1145/1273496.1273641; Ziehe A, 2004, J MACH LEARN RES, V5, P777; Zuo XN, 2014, SCI DATA, V1, DOI 10.1038/sdata.2014.49	61	13	13	2	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2021	43	4					1324	1336		10.1109/TPAMI.2019.2948619	http://dx.doi.org/10.1109/TPAMI.2019.2948619			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	QT3YJ	31675314	hybrid, Green Submitted			2022-12-18	WOS:000626525300016
J	Zhang, WC; Sun, CM				Zhang, Weichuan; Sun, Changming			Corner Detection Using Second-Order Generalized Gaussian Directional Derivative Representations	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Detectors; Image edge detection; Feature extraction; Corner detection; Mathematical model; Gaussian noise; Corner detection; second-order generalized (isotropic and anisotropic) Gaussian directional derivative filters; second-order generalized Gaussian directional derivative representations		Corner detection is a critical component of many image analysis and image understanding tasks, such as object recognition and image matching. Our research indicates that existing corner detection algorithms cannot properly depict the difference between edges and corners and this results in wrong corner detections. In this paper, the capability of second-order generalized (isotropic and anisotropic) Gaussian directional derivative filters to suppress Gaussian noise is evaluated. The second-order generalized Gaussian directional derivative representations of step edge, L-type corner, Y- or T-type corner, X-type corner, and star-type corner are investigated and obtained. A number of properties for edges and corners are discovered which enable us to propose a new image corner detection method. Finally, the criteria on detection accuracy and average repeatability under affine image transformation, JPEG compression, and noise degradation, and the criteria on region repeatability are used to evaluate the proposed detector against nine state-of-the-art methods. The experimental results show that our proposed detector outperforms all the other tested detectors.	[Zhang, Weichuan] Xian Polytech Univ, Coll Elect & Informat, Xian 710048, Peoples R China; [Sun, Changming] CSIRO Data61, POB 76, Epping, NSW 1710, Australia	Xi'an Polytechnic University; Commonwealth Scientific & Industrial Research Organisation (CSIRO)	Zhang, WC (corresponding author), Xian Polytech Univ, Coll Elect & Informat, Xian 710048, Peoples R China.	zwc2003@163.com; changming.sun@csiro.au	Zhang, Weichuan/AAF-2811-2020; Sun, Changming/A-3276-2008	Sun, Changming/0000-0001-5943-1989	National Natural Science Foundation of China [61401347]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the National Natural Science Foundation of China (No. 61401347). The authors would like to thank the anonymous reviewers for their detailed comments that substantially improved the paper.	Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16; Awrangjeb M, 2008, IEEE T MULTIMEDIA, V10, P1059, DOI 10.1109/TMM.2008.2001384; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Bowyer K, 2001, COMPUT VIS IMAGE UND, V84, P77, DOI 10.1006/cviu.2001.0931; Brox T, 2006, IMAGE VISION COMPUT, V24, P41, DOI 10.1016/j.imavis.2005.09.010; Cornelis N, 2008, PROC CVPR IEEE, P1013; DERICHE R, 1993, INT J COMPUT VISION, V10, P101, DOI 10.1007/BF01420733; DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060; Duval-Poo MA, 2015, IEEE T IMAGE PROCESS, V24, P3768, DOI 10.1109/TIP.2015.2451175; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Gao XT, 2007, IEEE T CIRC SYST VID, V17, P868, DOI 10.1109/TCSVT.2007.897473; Garding J, 1996, INT J COMPUT VISION, V17, P163, DOI 10.1007/BF00058750; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Huang FC, 2012, IEEE T CIRC SYST VID, V22, P340, DOI 10.1109/TCSVT.2011.2162760; Kanwal, 2011, 2011 5 INT C BIOINF, P1; Kenney CS, 2003, IEEE T PATTERN ANAL, V25, P1437, DOI 10.1109/TPAMI.2003.1240118; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Lenc K, 2016, LECT NOTES COMPUT SC, V9915, P100, DOI 10.1007/978-3-319-49409-8_11; Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188; Li YL, 2015, NEUROCOMPUTING, V149, P736, DOI 10.1016/j.neucom.2014.08.003; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Lowe D, 2004, IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2004), PROCEEDINGS, P91, DOI 10.1109/WI.2004.10159; Marimon D, 2010, PROC CVPR IEEE, P2416, DOI 10.1109/CVPR.2010.5539936; Maver J, 2010, IEEE T PATTERN ANAL, V32, P1211, DOI 10.1109/TPAMI.2009.105; Miao ZW, 2013, PATTERN RECOGN, V46, P2890, DOI 10.1016/j.patcog.2013.03.024; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Mokhtarian F, 1998, IEEE T PATTERN ANAL, V20, P1376, DOI 10.1109/34.735812; NOBLE JA, 1988, IMAGE VISION COMPUT, V6, P121, DOI 10.1016/0262-8856(88)90007-8; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877; Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275; Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446; Schonberger JL, 2017, PROC CVPR IEEE, P6959, DOI 10.1109/CVPR.2017.736; Shui PL, 2013, IEEE T IMAGE PROCESS, V22, P3204, DOI 10.1109/TIP.2013.2259834; Shui PL, 2012, PATTERN RECOGN, V45, P806, DOI 10.1016/j.patcog.2011.07.020; Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710; Su R, 2012, PATTERN RECOGN, V45, P3695, DOI 10.1016/j.patcog.2012.04.013; TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447; Trujillo L, 2006, GECCO 2006: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P887; Verdie Y, 2015, PROC CVPR IEEE, P5279, DOI 10.1109/CVPR.2015.7299165; Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190; Xia GS, 2014, INT J COMPUT VISION, V106, P31, DOI 10.1007/s11263-013-0640-1; Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4_28; Zhang WC, 2015, PATTERN RECOGN, V48, P2785, DOI 10.1016/j.patcog.2015.03.021; Zhang WC, 2014, IET IMAGE PROCESS, V8, P639, DOI 10.1049/iet-ipr.2013.0641; Zhang WC, 2019, IEEE T IMAGE PROCESS, V28, P4444, DOI 10.1109/TIP.2019.2910655; Zhang WC, 2017, PATTERN RECOGN, V63, P193, DOI 10.1016/j.patcog.2016.10.008; Zhang XH, 2015, IEEE T PATTERN ANAL, V37, P2207, DOI 10.1109/TPAMI.2015.2396074; Zhang X, 2017, PROC CVPR IEEE, P4923, DOI 10.1109/CVPR.2017.523; Zhong BJ, 2007, IEEE T PATTERN ANAL, V29, P508, DOI 10.1109/TPAMI.2007.50	51	13	15	12	46	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2021	43	4					1213	1224		10.1109/TPAMI.2019.2949302	http://dx.doi.org/10.1109/TPAMI.2019.2949302			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QT3YJ	31670662	Green Published			2022-12-18	WOS:000626525300008
J	Yang, HY; Huang, D; Wang, YH; Jain, AK				Yang, Hongyu; Huang, Di; Wang, Yunhong; Jain, Anil K.			Learning Continuous Face Age Progression: A Pyramid of GANs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Face; Aging; Training; Databases; Computational modeling; Gallium nitride; Generative adversarial networks; Generative adversarial networks; age progression; face aging simulation; face verification; age estimation		The two underlying requirements of face age progression, i.e., aging accuracy and identity permanence, are not well studied in the literature. This paper presents a novel generative adversarial network based approach to address the issues in a coupled manner. It separately models the constraints for the intrinsic subject-specific characteristics and the age-specific facial changes with respect to the elapsed time, ensuring that the generated faces present desired aging effects while keeping personalized properties stable. To render photo-realistic facial details, high-level age-specific features conveyed by the synthesized face are estimated by a pyramidal adversarial discriminator at multiple scales, which simulates the aging effects in a finer way. Further, an adversarial learning scheme is introduced to simultaneously train a single generator and multiple parallel discriminators, resulting in smooth continuous face aging sequences. The proposed method is applicable even in the presence of variations in pose, expression, makeup, etc., achieving remarkably vivid aging effects. Quantitative evaluations by a COTS face recognition system demonstrate that the target age distributions are accurately recovered, and 99.88 and 99.98 percent age progressed faces can be correctly verified at 0.001 percent FAR after age transformations of approximately 28 and 23 years elapsed time on the MORPH and CACD databases, respectively. Both visual and quantitative assessments show that the approach advances the state-of-the-art.	[Yang, Hongyu; Huang, Di; Wang, Yunhong] Beihang Univ, Beijing Adv Innovat Ctr Big Data & Brain Comp, Beijing 100191, Peoples R China; [Jain, Anil K.] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Beihang University; Michigan State University	Huang, D (corresponding author), Beihang Univ, Beijing Adv Innovat Ctr Big Data & Brain Comp, Beijing 100191, Peoples R China.	hongyuyang@buaa.edu.cn; dhuang@buaa.edu.cn; yhwang@buaa.edu.cn; jain@cse.msu.edu	Boothapati, Anil Kumar/HHS-1813-2022		National Key Research and Development Plan [2016YFC0801002]; National Natural Science Foundation of China [61673033, 61421003]; Fundamental Research Funds for the Central Universities	National Key Research and Development Plan; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	This work was partly supported by the National Key Research and Development Plan (Grant No. 2016YFC0801002), the National Natural Science Foundation of China (Grant No. 61673033 and 61421003), and the Fundamental Research Funds for the Central Universities.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2018, FACE RES TOOLK; [Anonymous], 2004, FG NET AGING DATABAS; [Anonymous], 2002, LIFE REVEALED; Arjovsky M, 2017, PR MACH LEARN RES, V70; Best-Rowden L., 2016, P 2016 INT C BIOMETR, P1; Best-Rowden L, 2018, IEEE T PATTERN ANAL, V40, P148, DOI 10.1109/TPAMI.2017.2652466; Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374; Duong CN, 2017, IEEE I CONF COMP VIS, P3755, DOI 10.1109/ICCV.2017.403; Deb D, 2017, IEEE COMPUT SOC CONF, P548, DOI 10.1109/CVPRW.2017.82; Dosovitskiy Alexey, 2016, NEURIPS; Duong CN, 2016, PROC CVPR IEEE, P5772, DOI 10.1109/CVPR.2016.622; Edraki M, 2018, LECT NOTES COMPUT SC, V11209, P90, DOI 10.1007/978-3-030-01228-1_6; Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Heafner H, 1996, P SOC PHOTO-OPT INS, V2645, P49, DOI 10.1117/12.233071; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kemelmacher-Shlizerman I, 2014, PROC CVPR IEEE, P3334, DOI 10.1109/CVPR.2014.426; Lanitis A, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/239480; Lanitis A, 2008, IEEE INT CONF AUTOMA, P993; Li PP, 2018, INT C PATT RECOG, P1073, DOI 10.1109/ICPR.2018.8545119; Liu S, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P82, DOI 10.1145/3123266.3123431; Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304; Mathieu Michael, 2016, ICLR; Ngan M., 2014, NIST INTERAGENCY REP; Odena A, 2017, PR MACH LEARN RES, V70; PITTENGER JB, 1975, J EXP PSYCHOL HUMAN, V1, P374, DOI 10.1037/0096-1523.1.4.374; Ramanathan N, 2008, IEEE INT CONF AUTOMA, P1006; Reed S, 2016, PR MACH LEARN RES, V48; Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341; Salimans T., 2016, ADV NEUR IN, P2234; Shu XB, 2015, IEEE I CONF COMP VIS, P3970, DOI 10.1109/ICCV.2015.452; Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8; Suo JL, 2012, IEEE T PATTERN ANAL, V34, P2083, DOI 10.1109/TPAMI.2012.22; Suo JL, 2010, IEEE T PATTERN ANAL, V32, P385, DOI 10.1109/TPAMI.2009.39; Taigman Yaniv, 2017, 5 INT C LEARN REPR I; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; TODD JT, 1980, SCI AM, V242, P132, DOI 10.1038/scientificamerican0280-132; Wang JY, 2006, INT C PATT RECOG, P913; Wang W, 2016, PROC CVPR IEEE, P2378, DOI 10.1109/CVPR.2016.261; Wang YH, 2012, IEEE T SYST MAN CY B, V42, P1107, DOI 10.1109/TSMCB.2012.2187051; Yang HY, 2018, PROC CVPR IEEE, P31, DOI 10.1109/CVPR.2018.00011; Yang HY, 2016, IEEE T IMAGE PROCESS, V25, P2493, DOI 10.1109/TIP.2016.2547587; Yin Wu, 1994, Proceedings of the Second Pacific Conference on Computer Graphics and Applications, Pacific Graphics '94. Fundamentals of Computer Graphics, P201; Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463; Zhou Z., 2018, PROC INT C COMPUT AI, P1; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	50	13	14	2	25	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	FEB 1	2021	43	2					499	515		10.1109/TPAMI.2019.2930985	http://dx.doi.org/10.1109/TPAMI.2019.2930985			17	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PR6ZZ	31352335	Green Submitted			2022-12-18	WOS:000607383300009
J	Zhang, Z; Wang, MZ; Nehorai, A				Zhang, Zhen; Wang, Mianzhi; Nehorai, Arye			Optimal Transport in Reproducing Kernel Hilbert Spaces: Theory and Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Kernel; Covariance matrices; Hilbert space; Task analysis; Geometry; Modeling; Optimal transport; reproducing kernel hilbert spaces; kernel methods; optimal transport map; Wasserstein distance; Wasserstein geometry; covariance operator; image classification; domain adaptation	DISTANCE; CLASSIFICATION	In this paper, we present a mathematical and computational framework for comparing and matching distributions in reproducing kernel Hilbert spaces (RKHS). This framework, called optimal transport in RKHS, is a generalization of the optimal transport problem in input spaces to (potentially) infinite-dimensional feature spaces. We provide a computable formulation of Kantorovich's optimal transport in RKHS. In particular, we explore the case in which data distributions in RKHS are Gaussian, obtaining closed-form expressions of both the estimated Wasserstein distance and optimal transport map via kernel matrices. Based on these expressions, we generalize the Bures metric on covariance matrices to infinite-dimensional settings, providing a new metric between covariance operators. Moreover, we extend the correlation alignment problem to Hilbert spaces, giving a new strategy for matching distributions in RKHS. Empirically, we apply the derived formulas under the Gaussianity assumption to image classification and domain adaptation. In both tasks, our algorithms yield state-of-the-art performances, demonstrating the effectiveness and potential of our framework.	[Zhang, Zhen; Wang, Mianzhi; Nehorai, Arye] Washington Univ, Dept Elect & Syst Engn, St Louis, MO 63130 USA	Washington University (WUSTL)	Nehorai, A (corresponding author), Washington Univ, Dept Elect & Syst Engn, St Louis, MO 63130 USA.	zhen.zhang@wustl.edu; mianzhi.wang@wustl.edu; nehorai@wustl.edu		Nehorai, Arye/0000-0002-9055-9865; ZHANG, ZHEN/0000-0001-8104-5785; Wang, Mianzhi/0000-0002-3317-7035	AFOSR [FA9550-16-1-0386]	AFOSR(United States Department of DefenseAir Force Office of Scientific Research (AFOSR))	This work was supported in part by the AFOSR grant FA9550-16-1-0386.	Alvarez M, 2006, LECT NOTES COMPUT SC, V4232, P747; Arjovsky M, 2017, PR MACH LEARN RES, V70; Bach F. R., 2003, P ADV NEUR INF PROC, P1033; Baktashmotlagh M, 2013, IEEE I CONF COMP VIS, P769, DOI 10.1109/ICCV.2013.100; Ben-Hur A, 2005, BIOINFORMATICS, V21, pI38, DOI 10.1093/bioinformatics/bti1016; Berlinet A., 2011, REPRODUCING KERNEL H; Bhatia R., 2018, EXPO MATH; Bonneel N, 2015, J MATH IMAGING VIS, V51, P22, DOI 10.1007/s10851-014-0506-3; Carrillo JA, 2012, ADV MATH, V231, P306, DOI 10.1016/j.aim.2012.03.036; Chen YX, 2019, IEEE ACCESS, V7, P6269, DOI 10.1109/ACCESS.2018.2889838; Cortes C, 2004, J MACH LEARN RES, V5, P1035; Cortes C., 2003, P IEEE INT C AC SPEE, V1; Courty N, 2017, IEEE T PATTERN ANAL, V39, P1853, DOI 10.1109/TPAMI.2016.2615921; CuestaAlbertos JA, 1996, J THEOR PROBAB, V9, P263, DOI 10.1007/BF02214649; CUTURI M., 2013, P INT C ADV NEURAL I, V26; Donahue J, 2014, PR MACH LEARN RES, V32; DOWSON DC, 1982, J MULTIVARIATE ANAL, V12, P450, DOI 10.1016/0047-259X(82)90077-X; El Moselhy TA, 2012, J COMPUT PHYS, V231, P7815, DOI 10.1016/j.jcp.2012.07.022; Faraki M, 2015, INT CONF ACOUST SPEE, P1364, DOI 10.1109/ICASSP.2015.7178193; Fernando B, 2013, IEEE I CONF COMP VIS, P2960, DOI 10.1109/ICCV.2013.368; Ferradans S., 2013, PROC 4 INT C SCALE S, P428, DOI [10.1007/978-3-642-38267-3_36.31, 10.1007/978-3-642-38267-3_36]; Ferradans S., 2013, LECT NOTES COMPUT SC, P137, DOI DOI 10.1007/978-3-642-38267-3_12; Frogner Charlie, 2015, ADV NEURAL INF PROCE, V2, P2053; Fukumizu K, 2013, J MACH LEARN RES, V14, P3753; Garnett R., 2016, ADV NEURAL INFORM PR, V29, P3718; GELBRICH M, 1990, MATH NACHR, V147, P185, DOI 10.1002/mana.19901470121; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Gramfort A, 2015, Inf Process Med Imaging, V24, P261, DOI 10.1007/978-3-319-19992-4_20; Gretton A, 2005, LECT NOTES ARTIF INT, V3734, P63; Gretton A, 2012, J MACH LEARN RES, V13, P723; Minh HQ, 2015, LECT NOTES COMPUT SC, V9389, P30, DOI 10.1007/978-3-319-25040-3_4; Harandi M, 2014, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2014.132; Huang S.-Y., 2006, KERNEL FISHER DISCRI; Jebara T, 2003, PROC 20 INT C INT C, P361; Kolouri S, 2016, PROC CVPR IEEE, P5258, DOI 10.1109/CVPR.2016.568; Kondor R.I., 2002, P 19 INT C MACHINE L, P315; Krizhevsky A., 2014, CORR; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Kusner MJ, 2015, PR MACH LEARN RES, V37, P957; Kylberg G, 2012, J MICROSC-OXFORD, V245, P140, DOI 10.1111/j.1365-2818.2011.03556.x; Kylberg G., 2011, EXTERNAL REPORT BLUE, V35; Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406; Liao ZC, 2013, PROC CVPR IEEE, P963, DOI 10.1109/CVPR.2013.129; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274; Mallasto Anton, 2017, P ADV NEUR INF PROC, P5665; Muandet K., 2012, PROC 25 INT C NEURAL, P10; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Pele O, 2009, IEEE I CONF COMP VIS, P460, DOI 10.1109/ICCV.2009.5459199; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Perrot M., 2016, ADV NEURAL INFORM PR, V29, P4197; Peyre G, 2016, PR MACH LEARN RES, V48; Quang M. H., 2014, ADV NEURAL INFORM PR, P388; RACHEV ST, 1990, THEOR PROBAB APPL+, V35, P110, DOI 10.1137/1135011; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Solomon J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766963; Sriperumbudur BK, 2011, J MACH LEARN RES, V12, P2389; Sun BC, 2016, AAAI CONF ARTIF INTE, P2058; Takatsu A, 2011, OSAKA J MATH, V48, P1005; Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75; Villani C., 2003, TOPICS OPTIMAL TRANS, V58; Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965; Wendel A., 2007, 31 ANN WORKSH AUSTR, P49; Xu Y, 2016, IEEE T IMAGE PROCESS, V25, P850, DOI 10.1109/TIP.2015.2510498; Zhang K., 2013, INT C MACH LEARN, P388; Zhang Z., 2004, HKUSTCS0403; Zhang Z, 2017, INT CONF ACOUST SPEE, P6528, DOI 10.1109/ICASSP.2017.7953414; Zhou SK, 2006, IEEE T PATTERN ANAL, V28, P917, DOI 10.1109/TPAMI.2006.120	71	13	13	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL 1	2020	42	7					1741	1754		10.1109/TPAMI.2019.2903050	http://dx.doi.org/10.1109/TPAMI.2019.2903050			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MC0DH	30843802				2022-12-18	WOS:000542967200017
J	Xiao, HX; Kang, BY; Liu, Y; Zhang, MJ; Feng, JS				Xiao, Huaxin; Kang, Bingyi; Liu, Yu; Zhang, Maojun; Feng, Jiashi			Online Meta Adaptation for Fast Video Object Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Adaptation models; Task analysis; Object segmentation; Optical imaging; Motion segmentation; Image segmentation; Runtime; Meta learning; video object segmentation; convolutional neural networks		Conventional deep neural networks based video object segmentation (VOS) methods are dominated by heavily fine-tuning a segmentation model on the first frame of a given video, which is time-consuming and inefficient. In this paper, we propose a novel method which rapidly adapts a base segmentation model to new video sequences with only a couple of model-update iterations, without sacrificing performance. Such attractive efficiency benefits from the meta-learning paradigm which leads to a meta-segmentation model and a novel continuous learning approach which enables online adaptation of the segmentation model. Concretely, we train a meta-learner on multiple VOS tasks such that the meta model can capture their common knowledge and gains the ability to fast adapt the segmentation model to new video sequences. Furthermore, to deal with unique challenges of VOS tasks from temporal variations in the video, e.g., object motion and appearance changes, we propose a principled online adaptation approach that continuously adapts the segmentation model across video frames by exploiting temporal context effectively, providing robustness to annoying temporal variations. Integrating the meta-learner with the online adaptation approach, the proposed VOS model achieves competitive performance against the state-of-the-arts and moreover provides faster per-frame processing speed.	[Xiao, Huaxin; Liu, Yu; Zhang, Maojun] Natl Univ Def Technol, Coll Syst Engn, Changsha 410073, Hunan, Peoples R China; [Kang, Bingyi; Feng, Jiashi] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119077, Singapore	National University of Defense Technology - China; National University of Singapore	Liu, Y (corresponding author), Natl Univ Def Technol, Coll Syst Engn, Changsha 410073, Hunan, Peoples R China.	xiaohuaxin@nudt.edu.cn; kang@u.nus.edu; jasonyuliu@nudt.edu.cn; mjzhang@nudt.edu.cn; elefjia@nus.edu.sg	Feng, Jiashi/AGX-6209-2022		NUS [R-263000-C08-133]; MOE Tier-I [R-263-000-C21-112]; NUS IDS [R-263-000-C67-646]; ECRA [R-263-000-C87-133]	NUS(National University of Singapore); MOE Tier-I; NUS IDS; ECRA	Jiashi Feng was partially supported by NUS startup R-263000-C08-133, MOE Tier-I R-263-000-C21-112, NUS IDS R-263-000-C67-646 and ECRA R-263-000-C87-133.	Al-Shedivat M., 2018, INT C LEARN REPR, P1; [Anonymous], COMPUT VISION PATTER; [Anonymous], P BRIT MACH VIS C; [Anonymous], 2017, PRACTICAL GUIDE; [Anonymous], 2017, IEEE WCNC; [Anonymous], P INT JOINT C NEUR N; Bao LC, 2018, PROC CVPR IEEE, P5977, DOI 10.1109/CVPR.2018.00626; Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565; Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen YH, 2018, PROC CVPR IEEE, P1189, DOI 10.1109/CVPR.2018.00130; Cheng JC, 2018, PROC CVPR IEEE, P7415, DOI 10.1109/CVPR.2018.00774; Cheng JC, 2017, IEEE I CONF COMP VIS, P686, DOI 10.1109/ICCV.2017.81; De Freitas N., 2016, ADV NEURAL INFORM PR, P3981; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Finn C, 2017, PR MACH LEARN RES, V70; Granet A, 2018, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS (ICPRAM 2018), P432, DOI 10.5220/0006598804320439; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu P, 2018, PROC CVPR IEEE, P1400, DOI 10.1109/CVPR.2018.00152; Jain SD, 2017, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2017.228; Jain SD, 2014, LECT NOTES COMPUT SC, V8692, P656, DOI 10.1007/978-3-319-10593-2_43; Jampani V, 2017, PROC CVPR IEEE, P3154, DOI 10.1109/CVPR.2017.336; Jang WD, 2017, PROC CVPR IEEE, P7474, DOI 10.1109/CVPR.2017.790; King DB, 2015, ACS SYM SER, V1214, P1; Koch Gregory, 2015, ICML DEEP LEARN WORK; Koh YJ, 2017, PROC CVPR IEEE, P7417, DOI 10.1109/CVPR.2017.784; Krahenbuhl P., 2011, ADV NEURAL INF PROCE, V24, P109; Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471; Li ZS, 2018, ACTA GEOTECH, V13, P51, DOI 10.1007/s11440-017-0527-3; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Ma TY, 2012, PROC CVPR IEEE, P670, DOI 10.1109/CVPR.2012.6247735; Marki N, 2016, PROC CVPR IEEE, P743, DOI 10.1109/CVPR.2016.87; Maninis KK, 2019, IEEE T PATTERN ANAL, V41, P1515, DOI 10.1109/TPAMI.2018.2838670; Mishra N., 2018, INT C LEARN REPR, P1; Oh SW, 2018, PROC CVPR IEEE, P7376, DOI 10.1109/CVPR.2018.00770; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Perazzi F, 2017, PROC CVPR IEEE, P3491, DOI 10.1109/CVPR.2017.372; Perazzi F, 2015, IEEE I CONF COMP VIS, P3227, DOI 10.1109/ICCV.2015.369; Pont-Tuset J., 2017, ARXIV170400675; Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065; Ravi S, 2017, P INT C LEARN REPR, P1; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Santoro A, 2016, PR MACH LEARN RES, V48; Schmidhuber J., 1987, THESIS TU MUNICH MUC; Snell J, 2017, ADV NEUR IN, V30; Tokmakov P, 2017, IEEE I CONF COMP VIS, P4491, DOI 10.1109/ICCV.2017.480; Tokmakov P, 2017, PROC CVPR IEEE, P531, DOI 10.1109/CVPR.2017.64; Tsai YH, 2016, PROC CVPR IEEE, P3899, DOI 10.1109/CVPR.2016.423; Vinyals Oriol, 2016, ARXIV160604080, P3630; Wang XB, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI), DOI 10.1109/ICEIEC.2017.8076499; Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961; Xiao FY, 2016, PROC CVPR IEEE, P933, DOI 10.1109/CVPR.2016.107; Xiao HX, 2018, PROC CVPR IEEE, P1140, DOI 10.1109/CVPR.2018.00125; Yang LJ, 2018, PROC CVPR IEEE, P6499, DOI 10.1109/CVPR.2018.00680; Yoon JS, 2017, IEEE I CONF COMP VIS, P2186, DOI 10.1109/ICCV.2017.238; Younger AS, 2001, IEEE IJCNN, P2001, DOI 10.1109/IJCNN.2001.938471	56	13	13	5	21	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	MAY 1	2020	42	5					1205	1217		10.1109/TPAMI.2018.2890659	http://dx.doi.org/10.1109/TPAMI.2018.2890659			13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LA0ZT	30640597				2022-12-18	WOS:000523685800014
J	Kuehne, H; Richard, A; Gall, J				Kuehne, Hilde; Richard, Alexander; Gall, Juergen			A Hybrid RNN-HMM Approach for Weakly Supervised Temporal Action Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Videos; Hidden Markov models; Task analysis; Training; Supervised learning; Training data; Computational modeling; Weakly supervised learning; temporal action segmentation; temporal action alignment; action recognition	SEMI-MARKOV MODEL; ACTION RECOGNITION; STATE DURATION	Action recognition has become a rapidly developing research field within the last decade. But with the increasing demand for large scale data, the need of hand annotated data for the training becomes more and more impractical. One way to avoid frame-based human annotation is the use of action order information to learn the respective action classes. In this context, we propose a hierarchical approach to address the problem of weakly supervised learning of human actions from ordered action labels by structuring recognition in a coarse-to-fine manner. Given a set of videos and an ordered list of the occurring actions, the task is to infer start and end frames of the related action classes within the video and to train the respective action classifiers without any need for hand labeled frame boundaries. We address this problem by combining a framewise RNN model with a coarse probabilistic inference. This combination allows for the temporal alignment of long sequences and thus, for an iterative training of both elements. While this system alone already generates good results, we show that the performance can be further improved by approximating the number of subactions to the characteristics of the different action classes as well as by the introduction of a regularizing length prior. The proposed system is evaluated on two benchmark datasets, the Breakfast and the Hollywood extended dataset, showing a competitive performance on various weak learning tasks such as temporal action segmentation and action alignment.	[Kuehne, Hilde; Richard, Alexander; Gall, Juergen] Univ Bonn, Inst Comp Sci 3, D-53113 Bonn, Germany	University of Bonn	Kuehne, H (corresponding author), Univ Bonn, Inst Comp Sci 3, D-53113 Bonn, Germany.	kuehne@iai.uni-bonn.de; richard@iai.uni-bonn.de; gall@iai.uni-bonn.de	Kuehne, Hilde/AAW-6860-2021; Kuehne, Hilde/ABG-5472-2020	Kuehne, Hilde/0000-0003-1079-4441; 	DFG [KU 3396/2-1, GA 1927/4-1, FOR 2535]; ERC Starting Grant ARCA [677650]; AWS Cloud Credits for Research program	DFG(German Research Foundation (DFG)); ERC Starting Grant ARCA; AWS Cloud Credits for Research program	The work has been financially supported by the DFG projects KU 3396/2-1 (Hierarchical Models for Action Recognition and Analysis in Video Data) and GA 1927/4-1 (DFG Research Unit FOR 2535 Anticipating Human Behavior) and the ERC Starting Grant ARCA (677650). This work has been supported by the AWS Cloud Credits for Research program. Hilde Kuehne and Alexander Richard are denotes equal contribution.	Alayrac JB, 2016, PROC CVPR IEEE, P4575, DOI 10.1109/CVPR.2016.495; [Anonymous], 2016, P INT C LEARN REPR; Bojanowski P, 2015, IEEE I CONF COMP VIS, P4462, DOI 10.1109/ICCV.2015.507; Bojanowski P, 2014, LECT NOTES COMPUT SC, V8693, P628, DOI 10.1007/978-3-319-10602-1_41; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Cho K., 2014, P SSST 8 8 WORKSH SY, P103; Chung Junyoung, 2014, ARXIV PREPRINT ARXIV; De-An Huang, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9908, P137, DOI 10.1007/978-3-319-46493-0_9; Dewar M, 2012, IEEE SIGNAL PROC LET, V19, P235, DOI 10.1109/LSP.2012.2184795; Ding L, 2018, PROC CVPR IEEE, P6508, DOI 10.1109/CVPR.2018.00681; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Duchenne O, 2009, IEEE I CONF COMP VIS, P1491, DOI 10.1109/ICCV.2009.5459279; Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213; Gan C, 2016, LECT NOTES COMPUT SC, V9907, P849, DOI 10.1007/978-3-319-46487-9_52; Girdhar R, 2017, PROC CVPR IEEE, P3165, DOI 10.1109/CVPR.2017.337; Graves A., 2006, P INT C MACH LEARN I; Jain M, 2015, PROC CVPR IEEE, P46, DOI 10.1109/CVPR.2015.7298599; Jiang Y.-G., 2014, ECCV WORKSH; Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342; JURAFSKY D, 1995, INT CONF ACOUST SPEE, P189, DOI 10.1109/ICASSP.1995.479396; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Koller O, 2017, PROC CVPR IEEE, P3416, DOI 10.1109/CVPR.2017.364; Koller O, 2016, PROC CVPR IEEE, P3793, DOI 10.1109/CVPR.2016.412; Kuehne H, 2017, COMPUT VIS IMAGE UND, V163, P78, DOI 10.1016/j.cviu.2017.06.004; Kuehne H, 2016, IEEE WINT CONF APPL; Kuehne H, 2014, PROC CVPR IEEE, P780, DOI 10.1109/CVPR.2014.105; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Lea C, 2017, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2017.113; Malmaud J., 2015, P C N AM CHAPT ASS C, P143; Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557; Narimatsu H, 2017, ANN MATH ARTIF INTEL, V81, P377, DOI 10.1007/s10472-017-9561-y; Ney H, 1999, IEEE SIGNAL PROC MAG, V16, P64, DOI 10.1109/79.790984; Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Nguyen P, 2018, PROC CVPR IEEE, P6752, DOI 10.1109/CVPR.2018.00706; Richard A, 2017, PROC CVPR IEEE, P1273, DOI 10.1109/CVPR.2017.140; Richard A, 2016, PROC CVPR IEEE, P3131, DOI 10.1109/CVPR.2016.341; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Simonyan K, 2014, ADV NEUR IN, V27; Singh B, 2016, PROC CVPR IEEE, P1961, DOI 10.1109/CVPR.2016.216; Soomro K., 2012, COMPUT SCI; Sun C, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P371, DOI 10.1145/2733373.2806226; VASEGHI SV, 1995, SIGNAL PROCESS, V41, P31, DOI 10.1016/0165-1684(94)00088-H; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2; Wang LM, 2017, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2017.678; WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337; Wu CX, 2015, PROC CVPR IEEE, P4362; Wu ZX, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P461, DOI 10.1145/2733373.2806222; Yan Y, 2017, PROC CVPR IEEE, P1022, DOI 10.1109/CVPR.2017.115; Zen H, 2007, IEICE T INF SYST, VE90D, P825, DOI 10.1093/ietisy/e90-d.5.825	54	13	14	1	18	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	APR 1	2020	42	4					765	779		10.1109/TPAMI.2018.2884469	http://dx.doi.org/10.1109/TPAMI.2018.2884469			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LE2GI	30582525	Green Submitted, hybrid			2022-12-18	WOS:000526541100001
J	Ferrer, MA; Diaz, M; Carmona-Duarte, C; Plamondon, R				Ferrer, Miguel A.; Diaz, Moises; Carmona-Duarte, Cristina; Plamondon, Rejean			iDeLog: Iterative Dual Spatial and Kinematic Extraction of Sigma-Lognormal Parameters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Trajectory; Visualization; Analytical models; Kinematics; Motor drives; Mathematical model; Biological system modeling; Biometrics; kinematic theory of rapid movements; motor equivalent model; sigma-lognormal model; signature	RAPID HUMAN MOVEMENTS; SIGNATURE VERIFICATION; DYNAMIC SIGNATURE; ONLINE; MECHANISMS; MODEL	The Kinematic Theory of rapid movements and its associated Sigma-Lognormal model have been extensively used in a large variety of applications. While the physical and biological meaning of the model have been widely tested and validated for rapid movements, some shortcomings have been detected when it is used with continuous long and complex movements. To alleviate such drawbacks, and inspired by the motor equivalence theory and a conceivable visual feedback, this paper proposes a novel framework to extract the Sigma-Lognormal parameters, namely iDeLog. Specifically, iDeLog consists of two steps. The first one, influenced by the motor equivalence model, separately derives an initial action plan defined by a set of virtual points and angles from the trajectory and a sequence of lognormals from the velocity. In the second step, based on a hypothetical visual feedback compatible with an open-loop motor control, the virtual target points of the action plan are iteratively moved to improve the matching between the observed and reconstructed trajectory and velocity. During experiments conducted with handwritten signatures, iDeLog obtained promising results as compared to the previous development of the Sigma-Lognormal.	[Ferrer, Miguel A.; Carmona-Duarte, Cristina] Univ Las Palmas Gran Canaria, Inst Univ Desarrollo Tecnol & Innovac Commun, Campus Tafira, Las Palmas Gran Canaria, Spain; [Diaz, Moises] Univ Atlantico Medio, Las Palmas Gran Canaria, Spain; [Plamondon, Rejean] Polytech Montreal, Montreal, PQ, Canada	Universidad de Las Palmas de Gran Canaria; Universite de Montreal; Polytechnique Montreal	Ferrer, MA (corresponding author), Univ Las Palmas Gran Canaria, Inst Univ Desarrollo Tecnol & Innovac Commun, Campus Tafira, Las Palmas Gran Canaria, Spain.	mferrer@idetic.eu; moises.diaz@atlanticomedio.es; ccarmona@idetic.eu; rejean.plamondon@polymtl.ca	Carmona-Duarte, Cristina/E-9031-2010; Ferrer, Miguel A A/L-3863-2013; Ferrer, Miguel/AFU-8286-2022; Diaz, Moises/L-3637-2013	Carmona-Duarte, Cristina/0000-0002-4441-6652; Ferrer, Miguel A A/0000-0002-2924-1225; Diaz, Moises/0000-0003-3878-3867	Spanish government's MIMECO [TEC2016-77791-C4-1-R]; European Union FEDER program/funds; NSERC-Canada [RGPIN-2015-06409]; Spanish MINECO [IJCI-2016-27682]	Spanish government's MIMECO; European Union FEDER program/funds; NSERC-Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)); Spanish MINECO(Spanish Government)	This study was funded by the Spanish government's MIMECO TEC2016-77791-C4-1-R research project and European Union FEDER program/funds and by the NSERC-Canada Grant RGPIN-2015-06409 to R. Plamondon. C. Carmona-Duarte is supported by a Juan de la Cierva (IJCI-2016-27682) from the Spanish MINECO.	Berio D., 2017, P 18 BIENN C INT GRA, P114; Bernstein N. A., 1968, J NEUROPATHOL EXP NE, V27, P104; Carmona-Duarte C, 2017, BIOSYST BIOROBOT, V15, P203, DOI 10.1007/978-3-319-46669-9_36; Carmona-Duarte C, 2017, PATTERN RECOGN, V68, P233, DOI 10.1016/j.patcog.2017.03.019; Diaz M, 2018, IEEE T CYBERNETICS, V48, P228, DOI 10.1109/TCYB.2016.2630419; Djeziri S, 2002, PATTERN RECOGN, V35, P1049, DOI 10.1016/S0031-3203(01)00093-0; Djioua M, 2009, IEEE T PATTERN ANAL, V31, P2060, DOI 10.1109/TPAMI.2008.264; Duval T, 2015, HUM MOVEMENT SCI, V43, P183, DOI 10.1016/j.humov.2015.04.005; Ferrer MA, 2018, IEEE T CYBERNETICS, V48, P2896, DOI 10.1109/TCYB.2017.2751740; Ferrer MA, 2017, IEEE T PATTERN ANAL, V39, P1041, DOI 10.1109/TPAMI.2016.2582167; Ferrer MA, 2015, IEEE T PATTERN ANAL, V37, P667, DOI 10.1109/TPAMI.2014.2343981; Fischer A, 2017, IEEE T HUM-MACH SYST, V47, P169, DOI 10.1109/THMS.2016.2634922; Fischer A, 2015, PROC INT CONF DOC, P241, DOI 10.1109/ICDAR.2015.7333760; Galbally J, 2015, PATTERN RECOGN, V48, P2921, DOI 10.1016/j.patcog.2015.03.019; Galbally J, 2012, PATTERN RECOGN, V45, P2622, DOI 10.1016/j.patcog.2011.12.007; Galbally J, 2012, PATTERN RECOGN, V45, P2610, DOI 10.1016/j.patcog.2011.12.011; Gomez-Barrero M, 2015, INT CONF BIOMETR, P501, DOI 10.1109/ICB.2015.7139065; Impedovo D, 2013, P 10 INT M COMP INT, P1; Kandel E. R., 2013, PRINCIPLES NEURAL SC, V4; Kholmatov A, 2009, PATTERN ANAL APPL, V12, P227, DOI 10.1007/s10044-008-0118-x; Lashley KS, 1930, PSYCHOL REV, V37, P1, DOI 10.1037/h0074134; Lebel K, 2017, FRONT BIOENG BIOTECH, V5, DOI 10.3389/fbioe.2017.00051; Leiva LA, 2017, INTERACT COMPUT, V29, P552, DOI 10.1093/iwc/iww039; Marquardt C, 1999, EXP BRAIN RES, V128, P224, DOI 10.1007/s002210050841; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030; Martin-Albo D, 2016, INFORM PROCESS MANAG, V52, P989, DOI 10.1016/j.ipm.2016.04.005; Martin-Albo D, 2015, PROC INT CONF DOC, P286, DOI 10.1109/ICDAR.2015.7333769; O'Reilly C, 2007, 2007 IEEE BIOMEDICAL CIRCUITS AND SYSTEMS CONFERENCE, P107, DOI 10.1109/BIOCAS.2007.4463320; O'Reilly C, 2011, HUM MOVEMENT SCI, V30, P792, DOI 10.1016/j.humov.2010.07.010; O'Reilly C, 2009, PATTERN RECOGN, V42, P3324, DOI 10.1016/j.patcog.2008.10.017; Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078; Pertsinakis M., 2017, P INT GRAPH SOC, P83; PLAMONDON R, 1995, BIOL CYBERN, V72, P309, DOI 10.1007/BF00202786; Plamondon R, 2003, BIOL CYBERN, V89, P126, DOI 10.1007/s00422-003-0407-9; Plamondon R, 1998, BIOL CYBERN, V78, P133, DOI 10.1007/s004220050420; Plamondon R, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00945; Plamondon R, 2014, PATTERN RECOGN LETT, V35, P225, DOI 10.1016/j.patrec.2012.06.004; Ramaiah C, 2015, PROC INT CONF DOC, P966, DOI 10.1109/ICDAR.2015.7333905; Raznakova M, 2017, PATTERN RECOGN, V72, P355, DOI 10.1016/j.patcog.2017.08.007; Sae-Bae N, 2014, IEEE T INF FOREN SEC, V9, P933, DOI 10.1109/TIFS.2014.2316472; Van Gemmert A, 2013, P 16 BIENN C INT GRA, P119; Wing AM, 2000, CURR BIOL, V10, pR245, DOI 10.1016/S0960-9822(00)00375-4	42	13	13	0	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JAN 1	2020	42	1					114	125		10.1109/TPAMI.2018.2879312	http://dx.doi.org/10.1109/TPAMI.2018.2879312			12	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	JV3VQ	30403620				2022-12-18	WOS:000502294300009
J	Bahri, M; Panagakis, Y; Zafeiriou, S				Bahri, Mehdi; Panagakis, Yannis; Zafeiriou, Stefanos			Robust Kronecker Component Analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						Component analysis; dictionary learning; separable dictionaries; low-rank; sparsity; global optimality	SPARSE REPRESENTATION; ALGORITHM; RECOVERY; COMPLEX; MODELS	Dictionary learning and component analysis models are fundamental for learning compact representations that are relevant to a given task (feature extraction, dimensionality reduction, denoising, etc.). The model complexity is encoded by means of specific structure, such as sparsity, low-rankness, or nonnegativity. Unfortunately, approaches like K-SVD - that learn dictionaries for sparse coding via Singular Value Decomposition (SVD) - are hard to scale to high-volume and high-dimensional visual data, and fragile in the presence of outliers. Conversely, robust component analysis methods such as the Robust Principal Component Analysis (RPCA) are able to recover low-complexity (e.g., low-rank) representations from data corrupted with noise of unknown magnitude and support, but do not provide a dictionary that respects the structure of the data (e.g., images), and also involve expensive computations. In this paper, we propose a novel Kronecker-decomposable component analysis model, coined as Robust Kronecker Component Analysis (RKCA), that combines ideas from sparse dictionary learning and robust component analysis. RKCA has several appealing properties, including robustness to gross corruption; it can be used for low-rank modeling, and leverages separability to solve significantly smaller problems. We design an efficient learning algorithm by drawing links with a restricted form of tensor factorization, and analyze its optimality and low-rankness properties. The effectiveness of the proposed approach is demonstrated on real-world applications, namely background subtraction and image denoising and completion, by performing a thorough comparison with the current state of the art.	[Bahri, Mehdi; Panagakis, Yannis; Zafeiriou, Stefanos] Imperial Coll London, Dept Comp, London SW7 2RH, England; [Panagakis, Yannis] Middlesex Univ, London NW4 4BT, England; [Zafeiriou, Stefanos] Univ Oulu, Oulu 90014, Finland	Imperial College London; Middlesex University; University of Oulu	Bahri, M (corresponding author), Imperial Coll London, Dept Comp, London SW7 2RH, England.	mehdi.bahri15@imperial.ac.uk; i.panagakis@imperial.ac.uk; s.zafeiriou@imperial.ac.uk	Panagakis, Yannis/AAZ-8090-2020	Panagakis, Ioannis/0000-0003-0153-5210; Bahri, Mehdi/0000-0002-2409-0261	Department of Computing, Imperial College London; European Community Horizon 2020 [H2020/2014-2020] [645094]; EPSRC [EP/N007743/1]; Google Faculty ResearchAward	Department of Computing, Imperial College London; European Community Horizon 2020 [H2020/2014-2020]; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Google Faculty ResearchAward(Google Incorporated)	Mehdi Bahri was partially funded by the Department of Computing, Imperial College London. The work of Y. Panagakis has been partially supported by the European Community Horizon 2020 [H2020/2014-2020] under Grant Agreement No. 645094 (SEWA). S. Zafeiriou was partially funded by EPSRC Project EP/N007743/1 (FACER2VM) and also partially funded by a Google Faculty ResearchAward.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Anandkumar A, 2016, JMLR WORKSH CONF PRO, V51, P268; Bahri M, 2017, IEEE I CONF COMP VIS, P3372, DOI 10.1109/ICCV.2017.363; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791; CHAN TF, 1982, ACM T MATH SOFTWARE, V8, P72, DOI 10.1145/355984.355990; Chen XA, 2016, PROC CVPR IEEE, P5213, DOI 10.1109/CVPR.2016.563; Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137; Fang Y, 2012, SCI CHINA INFORM SCI, V55, P889, DOI 10.1007/s11432-012-4551-5; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Goldfarb D, 2014, SIAM J MATRIX ANAL A, V35, P225, DOI 10.1137/130905010; GOLUB GH, 1979, IEEE T AUTOMAT CONTR, V24, P909, DOI 10.1109/TAC.1979.1102170; Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919; Grussler C, 2018, IEEE T AUTOMAT CONTR, V63, P4000, DOI 10.1109/TAC.2018.2813009; Haeffele B., 2015, ABS150607540 CORR; Haeffele B. D., P 31 INT C INT C MAC, V32; Harshman R.A., 1970, MULTIMODAL FACTOR AN; Hawe S, 2013, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2013.63; Hitchcock F.L., 1927, J MATH PHYS CAMB, V6, P164, DOI 10.1002/sapm192761164; Hong MY, 2016, SIAM J OPTIMIZ, V26, P337, DOI 10.1137/140990309; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Hsieh SH, 2014, 2014 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P492, DOI 10.1109/GlobalSIP.2014.7032166; Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X; Laub A.J., 2004, MATRIX ANAL SCI ENG; LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169; Lin Z., 2011, PROC INT 25 C NEURAL, P612, DOI DOI 10.1007/S11263-013-0611-6; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu GC, 2017, IEEE T PATTERN ANAL, V39, P47, DOI 10.1109/TPAMI.2016.2539946; Liu GC, 2016, IEEE T SIGNAL PROCES, V64, P5623, DOI 10.1109/TSP.2016.2586753; Lu CY, 2016, PROC CVPR IEEE, P5249, DOI 10.1109/CVPR.2016.567; Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828; Mohammadi P., 2014, ARXIV14067799; Netrapalli P., 2014, P ADV NEUR INF PROC, P1107; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Pan QH, 2014, AAAI CONF ARTIF INTE, P2027; Papamakarios G., 2014, P BRIT MACH VIS C, DOI [10.5244/C.28.116, DOI 10.5244/C.28.116]; Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720; Peng X, 2018, IEEE T NEUR NET LEAR, V29, P218, DOI 10.1109/TNNLS.2016.2608834; Peng X, 2017, IEEE T CYBERNETICS, V47, P3583, DOI 10.1109/TCYB.2016.2572306; Ramamoorthi R, 2001, COMP GRAPH, P497, DOI 10.1145/383259.383317; Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835; Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551; Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002; Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59; Sagonas C, 2013, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2013.132; Shakeri Z., 2017, P IEEE 7 INT WORKSH, P1; Shakeri Z, 2018, IEEE T INFORM THEORY, V64, P2706, DOI 10.1109/TIT.2018.2799931; Shakeri Z, 2017, INT CONF ACOUST SPEE, P4501, DOI 10.1109/ICASSP.2017.7953008; Shakeri Z, 2016, IEEE INT SYMP INFO, P1148, DOI 10.1109/ISIT.2016.7541479; Shang F., 2014, P 23 ACM INT C C INF, P1149, DOI DOI 10.1145/2661829.2662083; Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984; Wang Y, 2019, J SCI COMPUT, V78, P29, DOI 10.1007/s10915-018-0757-z; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Xu Y, 2017, ADV NEUR IN, V30; Xu ZL, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P71, DOI 10.1109/ICCAR.2017.7942663; Xue NN, 2017, EUR SIGNAL PR CONF, P1185, DOI 10.23919/EUSIPCO.2017.8081395; Yang YN, 2016, IEEE T NEUR NET LEAR, V27, P1933, DOI 10.1109/TNNLS.2015.2465178; Zhang HX, 2014, ELECTRON LETT, V50, P936, DOI 10.1049/el.2014.1396; Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730; Zhang ZM, 2014, PROC CVPR IEEE, P3842, DOI 10.1109/CVPR.2014.485; Zhao Q., 2015, IEEE T NEURAL NETWOR, V13, P736, DOI DOI 10.1109/TNNLS.2015.2423694; Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430	68	13	13	0	42	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	OCT	2019	41	10					2365	2379		10.1109/TPAMI.2018.2881476	http://dx.doi.org/10.1109/TPAMI.2018.2881476			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	JD1VC	30442601	Green Accepted, Green Submitted			2022-12-18	WOS:000489763000007
J	Cao, CS; Huang, YZ; Yang, Y; Wang, L; Wang, ZL; Tan, TN				Cao, Chunshui; Huang, Yongzhen; Yang, Yi; Wang, Liang; Wang, Zilei; Tan, Tieniu			Feedback Convolutional Neural Network for Visual Localization and Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						feedback; convolutional neural networks (CNNs); weakly supervised; object localization; object segmentation		Feedback is a fundamental mechanism existing in the human visual system, but has not been explored deeply in designing computer vision algorithms. In this paper, we claim that feedback plays a critical role in understanding convolutional neural networks (CNNs), e.g., how a neuron in CNNs describes an object's pattern, and how a collection of neurons form comprehensive perception to an object. To model the feedback in CNNs, we propose a novel model named Feedback CNN and develop two new processing algorithms, i.e., neural pathway pruning and pattern recovering. We mathematically prove that the proposed method can reach local optimum. Note that Feedback CNN belongs to weakly supervised methods and can be trained only using category-level labels. But it possesses a powerful capability to accurately localize and segment category-specific objects. We conduct extensive visualization analysis, and the results reveal the close relationship between neurons and object parts in Feedback CNN. Finally, we evaluate the proposed Feedback CNN over the tasks of weakly supervised object localization and segmentation, and the experimental results on ImageNet and Pascal VOC show that our method remarkably outperforms the state-of-the-art ones.	[Cao, Chunshui; Wang, Zilei] Univ Sci & Technol China, Hefei 230000, Anhui, Peoples R China; [Cao, Chunshui] Chinese Acad Sci CASIA, Ctr Res Intelligent Percept & Comp CRIPAC, NLPR, Inst Automat, Beijing 100864, Peoples R China; [Huang, Yongzhen; Wang, Liang; Tan, Tieniu] Univ Chinese Acad Sci, Huairou 101408, Peoples R China; [Huang, Yongzhen; Wang, Liang; Tan, Tieniu] Chinese Acad Sci, Ctr Res Intelligent Percept & Comp, Inst Automat, Natl Lab Pattern Recognit, Beijing 100864, Peoples R China; [Yang, Yi] Baidu Res, Sunnyvale, CA 94089 USA	Chinese Academy of Sciences; University of Science & Technology of China, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Institute of Automation, CAS; Baidu	Cao, CS (corresponding author), Univ Sci & Technol China, Hefei 230000, Anhui, Peoples R China.; Cao, CS (corresponding author), Chinese Acad Sci CASIA, Ctr Res Intelligent Percept & Comp CRIPAC, NLPR, Inst Automat, Beijing 100864, Peoples R China.	ccs@mail.ustc.edu.cn; yzhuang@nlpr.ac.cn; yangyi05@baidu.com; wangliang@nlpr.ac.cn; zlwang@ustc.edu.cn; tnt@nlpr.ac.cn	yang, yang/GVT-5210-2022; yang, yang/HGT-7999-2022; yang, yang/GWB-9426-2022; Yang, Yi/B-9273-2017	Yang, Yi/0000-0002-0512-880X; Wang, Yunlong/0000-0002-3535-308X	National Key Research and Development Program of China [2016YFB1001000]; National Natural Science Foundation of China [61721004, 61420106015]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work is jointly supported by National Key Research and Development Program of China (2016YFB1001000), and National Natural Science Foundation of China (61721004, 61420106015). We also thank Xianming Liu for participating in our initial experiments.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bazzani Loris, 2016, P IEEE WINT C APPL C, P1; Bearman A, 2016, LECT NOTES COMPUT SC, V9911, P549, DOI 10.1007/978-3-319-46478-7_34; Cao CS, 2015, IEEE I CONF COMP VIS, P2956, DOI 10.1109/ICCV.2015.338; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Cichy RM, 2014, NAT NEUROSCI, V17, P455, DOI 10.1038/nn.3635; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev.neuro.18.1.193; Dollar P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715; Dosovitskiy A., 2015, INVERTING CONVOLUTIO; Figurnov Mikhail, 2016, NEURIPS; Gilbert AC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1703; Gilbert CD, 2013, NAT REV NEUROSCI, V14, P350, DOI 10.1038/nrn3476; Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He SF, 2016, PROC CVPR IEEE, P5723, DOI 10.1109/CVPR.2016.617; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hu PY, 2016, PROC CVPR IEEE, P5600, DOI 10.1109/CVPR.2016.604; Karen Simonyan, 2014, ARXIV13126034CS, DOI DOI 10.1038/S41591-018-0335-9; Kim H E, 2016, SCALE INVARIANT FEAT; Kruger N, 2013, IEEE T PATTERN ANAL, V35, P1847, DOI 10.1109/TPAMI.2012.272; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Mnih V, 2014, ADV NEUR IN, V27; Molchanov P., 2017, P INT C LEARN REPR I, P1; Montavon G, 2017, PATTERN RECOGN, V65, P211, DOI 10.1016/j.patcog.2016.11.008; OQUAB M, 2015, PROC CVPR IEEE, P685, DOI DOI 10.1109/CVPR.2015.7298668; Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203; Pathak D, 2015, IEEE I CONF COMP VIS, P1796, DOI 10.1109/ICCV.2015.209; Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780; Shrivastava A., 2016, SKIP CONNECTIONS TOP; Sohn K, 2013, P 30 INT C MACHINE L, P217; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Stollenga M.F., 2014, ADV NEURAL INFORM PR, P3545; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Wang Q, 2014, 2014 INTERNATIONAL CONFERENCE ON MECHATRONICS AND CONTROL (ICMC), P332, DOI 10.1109/ICMC.2014.7231573; Zagoruyko S, 2016, 5 INT C LEARN REPRES, DOI DOI 10.5244/C.30.87; Zamir AR, 2017, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2017.196; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang JM, 2016, LECT NOTES COMPUT SC, V9908, P543, DOI 10.1007/978-3-319-46493-0_33; ZHOU B, 2016, PROC CVPR IEEE, P2921, DOI DOI 10.1109/CVPR.2016.319; Zhou Bolei, 2015, OBJECT DETECTORS EME, P2	42	13	14	2	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2019	41	7					1627	1640		10.1109/TPAMI.2018.2843329	http://dx.doi.org/10.1109/TPAMI.2018.2843329			14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IC4XW	29993535				2022-12-18	WOS:000470972300008
